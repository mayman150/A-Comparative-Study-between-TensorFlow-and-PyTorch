Issue Number,Issue Title,Issue Body
39059,Using autograph when calculating gradient over tf.case,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): YES
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): Binary
- TensorFlow version (use command below): TF 2.1.0
- Python version: Python 3.6.9
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10.1
- GPU model and memory: GeForce GTX 1080 Ti 11G

**Describe the current behavior**
I am trying to compute a gradient over tf.case using an autograph.

For example, let's say I have a case function where it takes a batch of input and computes output based on the sign of the input:
```python
def case_fn(x):                                                                                                                                                                                                                                                                                                          
    N = tf.shape(x)[0]                                                                                                                                                                                                                                                                                                   
    positive_idx = tf.cast(tf.squeeze(tf.where(tf.squeeze(tf.math.greater(x, 0.)))),tf.int32)                                                                                                                                                                                                                            
    negative_idx = tf.cast(tf.squeeze(tf.where(tf.squeeze(tf.math.less_equal(x, 0.)))),tf.int32)                                                                                                                                                                                                                         
    def all_positive_case():                                                                                                                                                                                                                                                                                             
        y_positive = x*2.                                                                                                                                                                                                                                                                                                
                                                                                                                                                                                                                                                                                                                         
        return y_positive                                                                                                                                                                                                                                                                                                
                                                                                                                                                                                                                                                                                                                         
    def all_negative_case():                                                                                                                                                                                                                                                                                             
        y_negative = x-2.                                                                                                                                                                                                                                                                                                
                                                                                                                                                                                                                                                                                                                         
        return y_negative                                                                                                                                                                                                                                                                                                
                                                                                                                                                                                                                                                                                                                         
    def some_positive_some_negative_case():                                                                                                                                                                                                                                                                              
        x_positive = tf.gather(x, positive_idx)                                                                                                                                                                                                                                                                          
        x_negative = tf.gather(x, negative_idx)                                                                                                                                                                                                                                                                          
                                                                                                                                                                                                                                                                                                                         
        y_positive = x_positive*2.                                                                                                                                                                                                                                                                                       
        y_negative = x_negative-2.                                                                                                                                                                                                                                                                                       
                                                                                                                                                                                                                                                                                                                         
        y_positive = tf.scatter_nd(tf.expand_dims(positive_idx,1),y_positive,tf.stack([N,1]))                                                                                                                                                                                                                            
        y_negative = tf.scatter_nd(tf.expand_dims(negative_idx,1),y_negative,tf.stack([N,1]))                                                                                                                                                                                                                            
                                                                                                                                                                                                                                                                                                                         
        return y_positive + y_negative                                                                                                                                                                                                                                                                                   
                                                                                                                                                                                                                                                                                                                         
    all_positive = tf.math.equal(tf.shape(negative_idx)[0], 0)                                                                                                                                                                                                                                                           
    all_negative = tf.math.equal(tf.shape(positive_idx)[0], 0)                                                                                                                                                                                                                                                           
    return tf.case([(all_positive, all_positive_case), (all_negative, all_negative_case)], default=some_positive_some_negative_case)
```
Then, I calculate a gradient with the following code:
```python
trainable_variable = tf.Variable([[1.], [-1.], [2.], [-2.]])                                                                                                                                                                                                                                                             
@tf.function                                                                                                                                                                                                                                                                                                             
def compute_grad():                                                                                                                                                                                                                                                                                                      
    with tf.GradientTape() as tape:                                                                                                                                                                                                                                                                                      
        y = case_fn(trainable_variable)                                                                                                                                                                                                                                                                                  
    grad = tape.gradient(y, trainable_variable)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           
    return grad                                                                                                                                                                                                                                                                                                          
                                                                                                                                                                                                                                                                                                                         
print(compute_grad())   
```
If I do not use ```@tf.function``` decorator, it returns a correct value which is ```IndexedSlices(indices=tf.Tensor([0, 2, 1, 3], shape=(4,), dtype=int32), values=tf.Tensor([[2.],[2.],[1.],[1.]], shape=(4, 1), dtype=float32), dense_shape=tf.Tensor([4 1], shape=(2,), dtype=int32))```.
However, if I use ```@tf.function``` decorator, it returns a value error saying
```
Traceback (most recent call last):
  File ""examples/case_gradient.py"", line 102, in <module>
    print(compute_grad())
  File ""/home/junhyeok/.venv/ccmbrl/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py"", line 568, in __call__
    result = self._call(*args, **kwds)
  File ""/home/junhyeok/.venv/ccmbrl/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py"", line 615, in _call
    self._initialize(args, kwds, add_initializers_to=initializers)
  File ""/home/junhyeok/.venv/ccmbrl/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py"", line 497, in _initialize
    *args, **kwds))
  File ""/home/junhyeok/.venv/ccmbrl/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py"", line 2389, in _get_concrete_function_internal_garbage_collected
    graph_function, _, _ = self._maybe_define_function(args, kwargs)
  File ""/home/junhyeok/.venv/ccmbrl/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py"", line 2703, in _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)
  File ""/home/junhyeok/.venv/ccmbrl/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py"", line 2593, in _create_graph_function
    capture_by_value=self._capture_by_value),
  File ""/home/junhyeok/.venv/ccmbrl/lib/python3.6/site-packages/tensorflow_core/python/framework/func_graph.py"", line 978, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File ""/home/junhyeok/.venv/ccmbrl/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py"", line 439, in wrapped_fn
    return weak_wrapped_fn().__wrapped__(*args, **kwds)
  File ""/home/junhyeok/.venv/ccmbrl/lib/python3.6/site-packages/tensorflow_core/python/framework/func_graph.py"", line 968, in wrapper
    raise e.ag_error_metadata.to_exception(e)
ValueError: in converted code:

    examples/case_gradient.py:99 compute_grad  *
        grad = tape.gradient(y, trainable_variable)
    /home/junhyeok/.venv/ccmbrl/lib/python3.6/site-packages/tensorflow_core/python/eager/backprop.py:1029 gradient
        unconnected_gradients=unconnected_gradients)
    /home/junhyeok/.venv/ccmbrl/lib/python3.6/site-packages/tensorflow_core/python/eager/imperative_grad.py:77 imperative_grad
        compat.as_str(unconnected_gradients.value))
    /home/junhyeok/.venv/ccmbrl/lib/python3.6/site-packages/tensorflow_core/python/eager/backprop.py:141 _gradient_function
        return grad_fn(mock_op, *out_grads)
    /home/junhyeok/.venv/ccmbrl/lib/python3.6/site-packages/tensorflow_core/python/ops/cond_v2.py:121 _IfGrad
        false_graph, grads, util.unique_grad_fn_name(false_graph.name))
    /home/junhyeok/.venv/ccmbrl/lib/python3.6/site-packages/tensorflow_core/python/ops/cond_v2.py:381 _create_grad_func
        func_graph=_CondGradFuncGraph(name, func_graph))
    /home/junhyeok/.venv/ccmbrl/lib/python3.6/site-packages/tensorflow_core/python/framework/func_graph.py:978 func_graph_from_py_func
        func_outputs = python_func(*func_args, **func_kwargs)
    /home/junhyeok/.venv/ccmbrl/lib/python3.6/site-packages/tensorflow_core/python/ops/cond_v2.py:380 <lambda>
        lambda: _grad_fn(func_graph, grads), [], {},
    /home/junhyeok/.venv/ccmbrl/lib/python3.6/site-packages/tensorflow_core/python/ops/cond_v2.py:371 _grad_fn
        src_graph=func_graph)
    /home/junhyeok/.venv/ccmbrl/lib/python3.6/site-packages/tensorflow_core/python/ops/gradients_util.py:669 _GradientsHelper
        lambda: grad_fn(op, *out_grads))
    /home/junhyeok/.venv/ccmbrl/lib/python3.6/site-packages/tensorflow_core/python/ops/gradients_util.py:336 _MaybeCompile
        return grad_fn()  # Exit early
    /home/junhyeok/.venv/ccmbrl/lib/python3.6/site-packages/tensorflow_core/python/ops/gradients_util.py:669 <lambda>
        lambda: grad_fn(op, *out_grads))
    /home/junhyeok/.venv/ccmbrl/lib/python3.6/site-packages/tensorflow_core/python/ops/cond_v2.py:183 _IfGrad
        building_gradient=True,
    /home/junhyeok/.venv/ccmbrl/lib/python3.6/site-packages/tensorflow_core/python/ops/cond_v2.py:219 _build_cond
        _make_indexed_slices_indices_types_match(_COND, [true_graph, false_graph])
    /home/junhyeok/.venv/ccmbrl/lib/python3.6/site-packages/tensorflow_core/python/ops/cond_v2.py:652 _make_indexed_slices_indices_types_match
        (current_index, len(branch_graphs[0].outputs)))

    ValueError: Insufficient elements in branch_graphs[0].outputs.
    Expected: 6
    Actual: 3
```

**Describe the expected behavior**
Behave equivalently even I use ```@tf.function``` decorator.
**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

One wierd thing is when I run this in colab, it doesn't return the value error.
But here is the colab link: https://colab.research.google.com/drive/1DmyMNffPOloFt66_FoqHxxHVMfYInCIf#scrollTo=cEqKALBoHzmB

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
39058,TF 2.2.0rc4 does not have python 3.8 macOS wheel,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: n/a
- TensorFlow installed from (source or binary): binary
- TensorFlow version: TF 2.2.0 rc4
- Python version: 3.8
- Installed using virtualenv? pip? conda?: pip
- Bazel version (if compiling from source): n/a
- GCC/Compiler version (if compiling from source): n/a
- CUDA/cuDNN version: n/a
- GPU model and memory: n/a

**Describe the problem**

While looking into the available pip wheel packages on pypi.org for 2.2.0rc4:

https://pypi.org/project/tensorflow/2.2.0rc4/#files

I noticed that pip wheel for macOS python 3.8 is not available (only two cp38 files on pypi.org, one is windows and another is linux).

However, pip wheel package for python 3.8 on macOS is available for 2.2.0rc3:

https://pypi.org/project/tensorflow/2.2.0rc4/#files

Wondering if 3.8 for macOS will be available when 2.2.0 final is released?"
39057,"XLA gives error about dynamic shapes in TF 2.1.0, but not in TF 1.15.2","<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: -
- TensorFlow installed from (source or binary): Binary I believe, it is part of a docker image
- TensorFlow version (use command below): 1.15.2 / 2.1.0
- Python version: 3.6.9
- Bazel version (if compiling from source): -
- GCC/Compiler version (if compiling from source): -
- CUDA/cuDNN version: 10.2.89 / 7.6.5
- GPU model and memory: Nvidia Tesla P100 (16GB)

**Describe the current behavior**

For the same code ([see gist here](https://gist.github.com/MatthiasKohl/3100f81e71309fb02e3b69773352e2c0)) I'm getting an error in TF2 but not in TF1 on XLA compile.

I need to migrate some code from TF1 to TF2 and want to find out what goes wrong here.
Somehow, I believe this has to do with a difference in `tf.compat.v1.data.make_initializable_iterator(tf_data_batched)` between TF1 and TF2 as it might give unknown shapes in TF2 but not TF1. But I'm not really sure and it won't always fail, such as for example when removing the following loss from the graph (lines 77/78 of the gist):
```python
gaussian = tfd.MultivariateNormalDiag(tf.zeros_like(samples), tf.ones_like(samples))
loss_samples = gaussian.log_prob(samples)
```

Can you help me figure out what's the issue here and how to migrate this to TF2 ? Thank you!
Below is the exact error I'm getting on TF2.

```
XLA compilation requires that operator arguments that represent shapes or dimensions be evaluated to concrete values at compile time. This error means that a shape or dimension argument could not be evaluate
d at compile time, usually because the value of the argument depends on a parameter to the computation, on a variable, or on a stateful operation such as a random number generator.
         [[{{node gradients/gradients/MultivariateNormalDiag_1/log_prob/MultivariateNormalDiag_chain_of_MultivariateNormalDiag_shift_of_MultivariateNormalDiag_scale_matvec_linear_operator/inverse/Multivariat
eNormalDiag_scale_matvec_linear_operator/inverse/LinearOperatorDiag/solve/LinearOperatorDiag/solve/mul_grad/Sum_grad/DynamicStitch}}]]
         [[gradients/while_loop_grad/while_loop_grad]]
        This error might be occurring with the use of xla.compile. If it is not necessary that every Op be compiled with XLA, an alternative is to use auto_jit with OptimizerOptions.global_jit_level = ON_2 o
r the environment variable TF_XLA_FLAGS=""tf_xla_auto_jit=2"" which will attempt to use xla to compile as much of the graph as the compiler is able to.
         [[cluster]]
         [[output_0/_3]]
0 successful operations.
0 derived errors ignored.
```

**Describe the expected behavior**
No error in TF2 just like in TF1.

**Standalone code to reproduce the issue**
See gist: https://gist.github.com/MatthiasKohl/3100f81e71309fb02e3b69773352e2c0
Note that this requires the tensorflow_probability package! I wasn't able to make a smaller example reproducing this bug, unfortunately.
"
39056,Serializing a tensor and writing to tf.train.Example from within a graph,"I would like to write tensorflow example records to a TFRecordWriter from inside an AutoGraph generated graph. I am running inference at scale over millions of examples and so don't want to collect all results in memory, but write them out as I go. I'm reading from a dataset.
Running everything inside a graph is way faster than breaking out every batch to process and save results.  So I just want to be able to write results from within the graph.

The documentation for tensorflow 2.0 states the following:

> The simplest way to handle non-scalar features is to use tf.serialize_tensor to convert tensors to binary-strings. Strings are scalars in tensorflow.

However, `tf.io.serialize_tensor` returns a tensor of byte-string. Creating an Example proto requires a bytes list, not a tensor.

How do I write a tf.train.Example to a tf record from inside a graph?

Code to reproduce:

```
%tensorflow_version 2.x
import tensorflow as tf

@tf.function
def example_write():
  writer = tf.io.TFRecordWriter(""test.tfr"")
  x = tf.constant([[0, 1], [2, 3]])
  x = tf.io.serialize_tensor(x)
  feature = {
      ""data"": tf.train.Features(
        bytes_list=tf.train.BytesList(value=[x]))
  }
  ex = tf.train.Example(features=tf.train.Features(
      feature=feature))
  writer.write(ex.SerializeToString())

example_write()
```

and the error

```
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
<ipython-input-6-df8a97eb17c9> in <module>()
     12   writer.write(ex.SerializeToString())
     13 
---> 14 example_write()

8 frames
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py in wrapper(*args, **kwargs)
    966           except Exception as e:  # pylint:disable=broad-except
    967             if hasattr(e, ""ag_error_metadata""):
--> 968               raise e.ag_error_metadata.to_exception(e)
    969             else:
    970               raise

TypeError: in user code:

    <ipython-input-6-df8a97eb17c9>:6 example_write  *
        feature = {

    TypeError: <tf.Tensor 'SerializeTensor:0' shape=() dtype=string> has type Tensor, but expected one of: bytes
```"
39054,Conv2d with large filters fails on V100 GPU,"**System information**
- Have I written custom code: **yes**
- OS Platform and Distribution: **Ubuntu 16.04**
- TensorFlow installed from: **binary**
- TensorFlow version: **2.1.0**
- Python version: **3.7.3**
- CUDA/cuDNN version: **10.1 and 7.6.4**
- GPU model and memory: **Tesla V100 with 16 or 32GB**

**Describe the current behavior**

Code segfaults when using a large 2D convolution kernel on a V100 GPU, but not on a GeForce GPU, e.g. GeForce Titan X. Also works fine without a GPU. On a V100, this code segfaults:
```
some_input = tf.random.normal((1, 512, 512, 1))
kernel = tf.random.normal((363, 363, 1, 1))
tf.nn.conv2d(some_input, kernel, strides=[1, 1, 1, 1], padding=""SAME"")
```
If we set the kernel size to 362 then it works again, but 363x363 and beyond segfaults on the V100 GPU.

**Describe the expected behavior**

It should not segfault on the V100.

**Standalone code to reproduce the issue**

Simple code snippet to reproduce is available here as a gist:
https://gist.github.com/CNugteren/138bc1ecbfbfa42e7b1be85923f48f62

**Other info / logs**

Example log of running the code in the above gist:
```
$ python tf_conv_bug.py
(... some TF GPU information)
>> kernel_size =  362
>> done for kernel_size =  362
>> kernel_size =  363
Segmentation fault (core dumped)
```
"
39053,Failure to convert model to tflite on local laptop,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- TensorFlow installed from (source or binary): binary
- TensorFlow version (or github SHA if from source): tf-nightly


**Command used to run the converter or code if you’re using the Python API**
If possible, please share a link to Colab/Jupyter/any notebook.

```
# Copy and paste here the exact command
```
converter = tf.lite.TFLiteConverter.from_keras_model(model)converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]
converter.optimizations = [tf.lite.Optimize.DEFAULT]
tflite_model = converter.convert()
open(""converted_model.tflite"", ""wb"").write(tflite_model)

**The output from the converter invocation**
ConverterError                            Traceback (most recent call last)
<ipython-input-7-d6af5d9fe17b> in <module>
     14 converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]
     15 converter.optimizations = [tf.lite.Optimize.DEFAULT]
---> 16 tflite_model = converter.convert()
     17 open(""converted_model.tflite"", ""wb"").write(tflite_model)
     18 e:\projecttools\venv_tf2.2\lib\site-packages\tensorflow\lite\python\lite.py in convert(self)
    709         input_tensors=input_tensors,
    710         output_tensors=output_tensors,
--> 711         **converter_kwargs)
    712 
    713     if quant_mode.post_training_int8_no_float():e:\projecttools\venv_tf2.2\lib\site-packages\tensorflow\lite\python\convert.py in toco_convert_impl(input_data, input_tensors, output_tensors, enable_mlir_converter, *args, **kwargs)
    546       input_data.SerializeToString(),
    547       debug_info_str=debug_info_str,
--> 548       enable_mlir_converter=enable_mlir_converter)
    549   return data
    550 e:\projecttools\venv_tf2.2\lib\site-packages\tensorflow\lite\python\convert.py in toco_convert_protos(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)
    251       stdout = _try_convert_to_unicode(stdout)
    252       stderr = _try_convert_to_unicode(stderr)
--> 253       raise ConverterError(""See console for info.\n%s\n%s\n"" % (stdout, stderr))
    254   finally:
    255     # Must manually cleanup files.ConverterError: See console for info.
2020-04-30 17:01:13.684285: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:307] Ignored output_format.
2020-04-30 17:01:13.684836: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:310] Ignored drop_control_dependency.
2020-04-30 17:01:13.802287: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance-critical operations:  AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-04-30 17:01:13.813650: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x27f74d24df0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-04-30 17:01:13.814159: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
loc(callsite(""model/time_distributed_1/lstm/while""(""e:\projecttools\venv_tf2.2\lib\site-packages\tensorflow\python\eager\def_function.py"":988:0) at callsite(""e:\projecttools\venv_tf2.2\lib\site-packages\tensorflow\python\eager\def_function.py"":1082:0 at callsite(""e:\projecttools\venv_tf2.2\lib\site-packages\tensorflow\lite\python\lite.py"":578:0 at callsite(""<ipython-input-7-d6af5d9fe17b>"":12:0 at callsite(""e:\projecttools\venv_tf2.2\lib\site-packages\IPython\core\interactiveshell.py"":3331:0 at callsite(""e:\projecttools\venv_tf2.2\lib\site-packages\IPython\core\interactiveshell.py"":3254:0 at callsite(""e:\projecttools\venv_tf2.2\lib\site-packages\IPython\core\interactiveshell.py"":3063:0 at callsite(""e:\projecttools\venv_tf2.2\lib\site-packages\IPython\core\async_helpers.py"":68:0 at callsite(""e:\projecttools\venv_tf2.2\lib\site-packages\IPython\core\interactiveshell.py"":2886:0 at ""e:\projecttools\venv_tf2.2\lib\site-packages\IPython\core\interactiveshell.py"":2858:0)))))))))): error: body function result type tensor<?x75x20xf32> is incompatible with result type tensor<15x1x20xf32> at index 3
Traceback (most recent call last):
  File ""E:\ProjectTools\Python3.6.8\lib\runpy.py"", line 193, in _run_module_as_main
    ""__main__"", mod_spec)
  File ""E:\ProjectTools\Python3.6.8\lib\runpy.py"", line 85, in _run_code
    exec(code, run_globals)
  File ""E:\ProjectTools\venv_tf2.2\Scripts\toco_from_protos.exe\__main__.py"", line 9, in <module>
  File ""e:\projecttools\venv_tf2.2\lib\site-packages\tensorflow\lite\toco\python\toco_from_protos.py"", line 93, in main
    app.run(main=execute, argv=[sys.argv[0]] + unparsed)
  File ""e:\projecttools\venv_tf2.2\lib\site-packages\tensorflow\python\platform\app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""e:\projecttools\venv_tf2.2\lib\site-packages\absl\app.py"", line 299, in run
    _run_main(main, args)
  File ""e:\projecttools\venv_tf2.2\lib\site-packages\absl\app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""e:\projecttools\venv_tf2.2\lib\site-packages\tensorflow\lite\toco\python\toco_from_protos.py"", line 56, in execute
    enable_mlir_converter)
Exception: e:\projecttools\venv_tf2.2\lib\site-packages\tensorflow\python\eager\def_function.py:988:1: error: body function result type tensor<?x75x20xf32> is incompatible with result type tensor<15x1x20xf32> at index 3
        self._initialize(args, kwargs, add_initializers_to=initializers)
^
e:\projecttools\venv_tf2.2\lib\site-packages\tensorflow\python\eager\def_function.py:1082:1: note: called from
    concrete = self._get_concrete_function_garbage_collected(*args, **kwargs)
^
e:\projecttools\venv_tf2.2\lib\site-packages\tensorflow\lite\python\lite.py:578:1: note: called from
    concrete_func = func.get_concrete_function()
^
<ipython-input-7-d6af5d9fe17b>:12:0: note: called from
e:\projecttools\venv_tf2.2\lib\site-packages\IPython\core\interactiveshell.py:3331:1: note: called from
                    exec(code_obj, self.user_global_ns, self.user_ns)
^
e:\projecttools\venv_tf2.2\lib\site-packages\IPython\core\interactiveshell.py:3254:1: note: called from
                    if (await self.run_code(code, result,  async_=asy)):
^
e:\projecttools\venv_tf2.2\lib\site-packages\IPython\core\interactiveshell.py:3063:1: note: called from
                       interactivity=interactivity, compiler=compiler, result=result)
^
e:\projecttools\venv_tf2.2\lib\site-packages\IPython\core\async_helpers.py:68:1: note: called from
        coro.send(None)
^
e:\projecttools\venv_tf2.2\lib\site-packages\IPython\core\interactiveshell.py:2886:1: note: called from
            return runner(coro)
^
e:\projecttools\venv_tf2.2\lib\site-packages\IPython\core\interactiveshell.py:2858:1: note: called from
                raw_cell, store_history, silent, shell_futures)
^
e:\projecttools\venv_tf2.2\lib\site-packages\tensorflow\python\eager\def_function.py:988:1: note: see current operation: %146:13 = ""tf.While""(%16, %7, %16, %3, %145, %50, %50, %49, %117, %127, %42, %43, %41) {_lower_using_switch_merge = false, _num_original_outputs = 13 : i64, _read_only_resource_inputs = [10, 11, 12], body = @model_time_distributed_1_lstm_while_body_5735_frozen0, cond = @model_time_distributed_1_lstm_while_cond_5734_frozen0, device = """", is_stateless = false, output_shapes = [#tf.shape<>, #tf.shape<>, #tf.shape<>, #tf.shape<>, #tf.shape<?x20>, #tf.shape<?x20>, #tf.shape<?x20>, #tf.shape<>, #tf.shape<>, #tf.shape<>, #tf.shape<10x80>, #tf.shape<80>, #tf.shape<20x80>], parallel_iterations = 32 : i64} : (tensor<i32>, tensor<i32>, tensor<i32>, tensor<15x1x20xf32>, tensor<75x20xf32>, tensor<75x20xf32>, tensor<75x20xf32>, tensor<i32>, tensor<15x75x10xf32>, tensor<15x75x1xi1>, tensor<10x80xf32>, tensor<80xf32>, tensor<20x80xf32>) -> (tensor<i32>, tensor<i32>, tensor<i32>, tensor<15x1x20xf32>, tensor<75x20xf32>, tensor<75x20xf32>, tensor<75x20xf32>, tensor<i32>, tensor<15x75x10xf32>, tensor<15x75x1xi1>, tensor<10x80xf32>, tensor<80xf32>, tensor<20x80xf32>)
        self._initialize(args, kwargs, add_initializers_to=initializers)
```

# Copy and paste the output here.
```

**Also, please include a link to the saved model or GraphDef**
NER implementation from the link https://www.depends-on-the-definition.com/lstm-with-char-embeddings-for-ner/
```

# Put link here or attach to the issue.
```
I am trying to implement NER from the link https://www.depends-on-the-definition.com/lstm-with-char-embeddings-for-ner/
I am able to generate model file(h5), but not able to convert the model to tflite with the command mentioned above

If I remove the line ""converter.optimizations = [tf.lite.Optimize.DEFAULT]"", then tflite model gets created. But can't infer from the model on mobile
The error i get while inferencing the model is
Failed to run on the given Interpreter: tensorflow/lite/kernels/concatenation.cc:74 t->dims->data != t0->dims->data (75 != 1)

Note: With the same command mentioned in ""Copy and paste here the exact command"" tflite conversion works fine with Colab. The same model works fine in mobile
The problem is happening in Local windows 10 PC"
39052,Inference blocks indefinitely on GPU when Eager mode is enabled,"<!--
Please make sure that this is a bug. 

As per our GitHub Policy (https://github.com/tensorflow/models/blob/master/ISSUES.md), we only address code bugs, documentation issues, and feature requests on GitHub.

Please go to Stack Overflow (http://stackoverflow.com/questions/tagged/tensorflow-model-garden) for help and support.

The research models (https://github.com/tensorflow/models/tree/master/research) are a large collection of models implemented in TensorFlow by researchers. They are not officially supported. It is up to the individual researchers to maintain the models and/or provide support on issues and pull requests.
-->

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
I made small changes (use of opencv to capture images) to the object_detection_tutorial file.
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- TensorFlow installed from (source or binary): python -m pip install tensorflow
- TensorFlow version (use command below): v2.1.0-rc2-17-ge5bf8de410 2.1.0
- Python version: 3.7
- CUDA/cuDNN version: 10.1 / 7.6.5.32
- GPU model and memory: GTX 960M 2GB or RTX2070 Super 8 GB

<!-- 
You can collect some of this information using our environment capture (https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 

1. TensorFlow 1.0
`python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 

2. TensorFlow 2.0
`python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
-->

**Describe the current behavior**
With GPU and Eager mode enabled, running inference blocks indefinitely after processing a few frames (<15).  
If I then disable Eager mode, it runs fine.

When eager is disabled and I use a session to process the data, it also blocks indefinitely on GPU. 

Everything works fine when only using the CPU

**Describe the expected behavior**
Being able to run inference on GPU without indefinite blocks with Eager mode enabled. 

**Code to reproduce the issue**

```
import os
import pathlib
import cv2
import numpy as np
import tensorflow as tf

#from object_detection.utils import ops as utils_ops

def load_model(model_name):
    base_url = 'http://download.tensorflow.org/models/object_detection/'
    model_file = model_name + '.tar.gz'
    model_dir = tf.keras.utils.get_file(
        fname=model_name,
        origin=base_url + model_file,
        untar=True)
    model_dir = pathlib.Path(model_dir)/""saved_model""
    model = tf.saved_model.load(str(model_dir))
    model = model.signatures['serving_default']
    return model

def run_inference_for_single_image(model, image):
    image = np.asarray(image)
    input_tensor = tf.convert_to_tensor(image)
    input_tensor = input_tensor[tf.newaxis, ...]
    # Run inference
    print(""Inference start"")
    model(input_tensor)
    print(""Inference end"")

if ""models"" in pathlib.Path.cwd().parts:
    while ""models"" in pathlib.Path.cwd().parts:
        os.chdir('..')

#disable eager mode
#tf.compat.v1.disable_eager_execution()

MODELNAME = 'ssd_mobilenet_v1_coco_2017_11_17'
DETECTION_MODEL = load_model(MODELNAME)

#utils_ops.tf = tf.compat.v1
tf.gfile = tf.io.gfile

#IMGPATH = PATH_TO_IMAGE
IMAGE = np.zeros((640, 480, 3), np.uint8)

while True:
    run_inference_for_single_image(DETECTION_MODEL, IMAGE)
```
I ran this from the research\object_detection folder

**Other info / logs**
I am not sure how to support the claim of it being a bug. I tried it on different machines and the code is based on an example. I thought it was because there are no error or warning messages before hanging, it works fine when just using the CPU (with or without Eager mode), it works on GPU without Eager mode and it hangs in a library function.

I never did anything like this before. If i did something wrong or more information is required, please let me know. 
"
39051,GPU Kernel for SparseFillEmptyRows OP,"**System information**
- TensorFlow version : 1.13.1
- Are you willing to contribute it ：Yes

I found that `SparseFillEmptyRowsOP` does not have GPU kernel support. Can someone explain the following reasons for that to me?

In my training, SparseFillEmptyRows executed on the CPU consumes a lot of time cost. Therefore, if you can move SparseFillEmptyRows OP to the GPU, I think there will be a considerable performance improvement."
39050,tf.nn.depthwise_conv2d with rank=1 kernels (separable filters),"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using):
nigthly
- Are you willing to contribute it (Yes/No):
no

**Describe the feature and the current behavior/state.**
There is a thread about twice calling DepWhiseConv2d TF ops when we have rank=1 kernels (separable filters) VS a single call to DepWhiseConv2d with 2d kernel.
I suppose that is would be hard to fuse on trace two DepWhiseConv2d on the separable filter.
So I was asking why with the current DepWhiseConv2d in TF doesn't handle the kernel rank=1 case with an parameter for down the stack compiler/transformations (kernel size, input size, device type, etc.).

**Will this change the current api? How?**
Yes
**Who will benefit with this feature?**
Separable filters (gaussian blur, etc)
**Any Other info.**
See https://github.com/tensorflow/addons/pull/1450#issuecomment-621351753 with follow-up @alextp and @rmlarsen comments."
39049,AttributeError: module 'tensorflow.python.data.experimental.ops.optimization' has no attribute 'AUTOTUNE',"system:ubuntu18.04
tf:2.0.0b0
python:3.6.9

I want to train a model for object recognition，Then I run [python3 train.py --logtostderr --train_dir=training/ --pipeline_config_path=ssd_mobilenet_v2_quantized_300x300_coco.config]

Get this error：AttributeError: module 'tensorflow.python.data.experimental.ops.optimization' has no attribute 'AUTOTUNE'

"
39047,Docstring is not misleading.,"The docstring says "" it is a negative quantity between -1 and 0, where 0 indicates orthogonality and values closer to -1 indicate greater similarity"". Although it is true that the function reverses the sign of the classic cosine similarity so that -1 will denote ""similarity"" instead of 1 in the original formula, the actual range is still -1 to 1 (not -1 to 0 as misleading by the docstring). 

https://github.com/tensorflow/tensorflow/blob/e5bf8de410005de06a7ff5393fafdf832ef1d4ad/tensorflow/python/keras/losses.py#L1073"
39046,"when using ""tensorboard --logdir"", reported ""ImportError: No module named '_markerlib""","when run the code
`cd  E:\python3\tensorflow1\Flower\log`
`tensorboard --logdir`
report error:
`Traceback (most recent call last):
  File ""d:\appdatas\anaconda3\envs\tensorflow\lib\runpy.py"", line 193, in _run_module_as_main
    ""__main__"", mod_spec)
  File ""d:\appdatas\anaconda3\envs\tensorflow\lib\runpy.py"", line 85, in _run_code
    exec(code, run_globals)
  File ""D:\AppDatas\Anaconda3\envs\tensorflow\Scripts\tensorboard.exe\__main__.py"", line 7, in <module>
  File ""d:\appdatas\anaconda3\envs\tensorflow\lib\site-packages\tensorboard\main.py"", line 58, in run_main
    default.get_plugins() + default.get_dynamic_plugins(),
  File ""d:\appdatas\anaconda3\envs\tensorflow\lib\site-packages\tensorboard\default.py"", line 110, in get_dynamic_plugins
    for entry_point in pkg_resources.iter_entry_points('tensorboard_plugins')
  File ""d:\appdatas\anaconda3\envs\tensorflow\lib\site-packages\tensorboard\default.py"", line 110, in <listcomp>
    for entry_point in pkg_resources.iter_entry_points('tensorboard_plugins')
  File ""e:\python3\whls\distribute-0.7.3\pkg_resources.py"", line 2241, in load
    if require: self.require(env, installer)
  File ""e:\python3\whls\distribute-0.7.3\pkg_resources.py"", line 2254, in require
    working_set.resolve(self.dist.requires(self.extras),env,installer)))
  File ""e:\python3\whls\distribute-0.7.3\pkg_resources.py"", line 2471, in requires
    dm = self._dep_map
  File ""e:\python3\whls\distribute-0.7.3\pkg_resources.py"", line 2682, in _dep_map
    self.__dep_map = self._compute_dependencies()
  File ""e:\python3\whls\distribute-0.7.3\pkg_resources.py"", line 2699, in _compute_dependencies
    from _markerlib import compile as compile_marker`
`ImportError: No module named '_markerlib'`
bg: tf-gpu 1.5 win10 X64 anaconda"
39045,tensorflow 2.0 does not detect the gpus ,"actually I have 2 gpus but 

```
> gpus = tf.config.experimental.list_physical_devices('GPU')
> [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]
> 
```

but this only detect the first gpu "
39044,Tensorflow GPU installation ,"## URL(s) with the issue:

https://www.tensorflow.org/install/gpu

## Description of issue (what needs changing):

The tf-nightly pip package does not support GPU. It should be: tf-nightly-gpu

On the Windows Setup section, the path:

SET PATH=C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.1\extras\CUPTI\libx64;%PATH%

should be:

SET PATH=C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.1\extras\CUPTI\lib64;%PATH% 

Since the CUDA toolkit generates this path with lib64 and not libx64.
"
39041,tensorflowrun for distributed training (MultiWorkerMirroredStrategy & ParameterServerStrategy),"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): 2.2
- Are you willing to contribute it (Yes/No): Yes



**Describe the feature and the current behavior/state.**
There currently is no unified way to run multiworkermirroredstrategy. From the tutorials we are expected to start each script on each instance manually. On GCP tutorials it comes with a premade run script. 

Horovod has horovodrun which like mpirun. For tensorflow, why don't create a tensorflowrun. 

Basic features of the horovodrun. 
tensorflowrun --n 2 --np 2 --clusterSpec cspec python tensorflow_script.py
Run on 2 workers, two processes locally
The clusterspec passed to tensorflowrun can have assumptions or explicitly setup. 
task ids will be defined by index in cluster

Example:
{""cluster"": {""worker"": [""192.168.1.1:5555"", ""192.168.1.2:5555""]}}
task id 0 assigned to *.1
task id 1 assigned to *.2

{'cluster': {'chief': ['10.0.0.4:2224'], 'worker': ['10.0.0.4:2223', '10.0.0.5:2222', '10.0.0.6:2222'], 'ps': ['10.0.0.4:2222']}, 'environment': 'cloud'}

worker
task id 0 *4
task id 1 *5
task id 2 *6

ps 
task id 0 *4


**Will this change the current api? How?**
No APIs will change

**Who will benefit with this feature?**
Anyone trying to run MultiWorkerMirrorredStrategy, Parameter Server can also be included.

**Any Other info.**
"
39040,Segmentation fault when converting a ReLU6 op to TFlite,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Mac OS
- TensorFlow installed from (source or binary): binary
- TensorFlow version (or github SHA if from source):  2.1


**Command used to run the converter or code if you’re using the Python API**
If possible, please share a link to Colab/Jupyter/any notebook.

```
import tensorflow as tf
from tensorflow.keras.layers import Input, Activation, Conv2D
from tensorflow.keras import Model
from tensorflow import lite

def model_relu6_only():
    input_ = Input(shape=[50, 50, 3])
    output = Activation(lambda x: tf.nn.relu6(x + 3) * 0.16667)(input_)
    return Model(inputs=input_, outputs=output)

def model_conv_relu6():
    input_ = Input(shape=[50, 50, 3])
    output = Conv2D(3, 3)(input_)
    output = Activation(lambda x: tf.nn.relu6(x + 3) * 0.16667)(output)
    return Model(inputs=input_, outputs=output)

def tflite_model_conversion(model, filename):
    converter = lite.TFLiteConverter.from_keras_model(model)
    tflite_model = converter.convert()
    with open(filename, ""wb+"") as f:
        f.write(tflite_model)

if __name__ == '__main__':

    model = model_conv_relu6()
    tflite_model_conversion(model, ""conv_relu6.tflite"")

    model = model_relu6_only()
    tflite_model_conversion(model, ""relu6_only.tflite"")
```

**The output from the converter invocation**

```
/Users/hw1000254892/miniconda3/envs/tf-2.1/bin/python /Users/hw1000254892/PycharmProjects/wd_obj_det/wd_obj_det/sandbox/relu_only_fail.py
2020-04-29 14:25:02.594509: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-04-29 14:25:02.630218: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa3a268ade0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-04-29 14:25:02.630237: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-04-29 14:25:02.665720: I tensorflow/core/grappler/devices.cc:60] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA support)
2020-04-29 14:25:02.665825: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session
2020-04-29 14:25:02.677242: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: graph_to_optimize
2020-04-29 14:25:02.677259: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0.414ms.
2020-04-29 14:25:02.677263: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0.002ms.
2020-04-29 14:25:02.692790: I tensorflow/core/grappler/devices.cc:60] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA support)
2020-04-29 14:25:02.692847: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session
2020-04-29 14:25:02.702864: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: graph_to_optimize
2020-04-29 14:25:02.702880: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   constant_folding: Graph size after: 11 nodes (-2), 12 edges (-2), time = 7.837ms.
2020-04-29 14:25:02.702883: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   constant_folding: Graph size after: 11 nodes (0), 12 edges (0), time = 0.287ms.
2020-04-29 14:25:05.324556: I tensorflow/core/grappler/devices.cc:60] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA support)
2020-04-29 14:25:05.324658: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session
2020-04-29 14:25:05.325629: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: graph_to_optimize
2020-04-29 14:25:05.325640: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0.002ms.
2020-04-29 14:25:05.325646: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-04-29 14:25:05.335367: I tensorflow/core/grappler/devices.cc:60] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA support)
2020-04-29 14:25:05.335431: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session
2020-04-29 14:25:05.337047: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: graph_to_optimize
2020-04-29 14:25:05.337060: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   constant_folding: Graph size after: 7 nodes (0), 6 edges (0), time = 0.322ms.
2020-04-29 14:25:05.337064: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   constant_folding: Graph size after: 7 nodes (0), 6 edges (0), time = 0.198ms.
Traceback (most recent call last):
  File ""/Users/hw1000254892/PycharmProjects/wd_obj_det/wd_obj_det/sandbox/relu_only_fail.py"", line 29, in <module>
    tflite_model_conversion(model, ""relu6_only.tflite"")
  File ""/Users/hw1000254892/PycharmProjects/wd_obj_det/wd_obj_det/sandbox/relu_only_fail.py"", line 19, in tflite_model_conversion
    tflite_model = converter.convert()
  File ""/Users/hw1000254892/miniconda3/envs/tf-2.1/lib/python3.7/site-packages/tensorflow_core/lite/python/lite.py"", line 464, in convert
    **converter_kwargs)
  File ""/Users/hw1000254892/miniconda3/envs/tf-2.1/lib/python3.7/site-packages/tensorflow_core/lite/python/convert.py"", line 457, in toco_convert_impl
    enable_mlir_converter=enable_mlir_converter)
  File ""/Users/hw1000254892/miniconda3/envs/tf-2.1/lib/python3.7/site-packages/tensorflow_core/lite/python/convert.py"", line 203, in toco_convert_protos
    raise ConverterError(""See console for info.\n%s\n%s\n"" % (stdout, stderr))
tensorflow.lite.python.convert.ConverterError: See console for info.
2020-04-29 14:25:08.186306: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 4 operators, 7 arrays (0 quantized)
2020-04-29 14:25:08.186470: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 4 operators, 7 arrays (0 quantized)
2020-04-29 14:25:08.186628: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 2 operators, 5 arrays (0 quantized)
Fatal Python error: Segmentation fault

Current thread 0x000000010c7e2dc0 (most recent call first):
  File ""/Users/hw1000254892/miniconda3/envs/tf-2.1/lib/python3.7/site-packages/tensorflow_core/lite/toco/python/toco_from_protos.py"", line 56 in execute
  File ""/Users/hw1000254892/miniconda3/envs/tf-2.1/lib/python3.7/site-packages/absl/app.py"", line 250 in _run_main
  File ""/Users/hw1000254892/miniconda3/envs/tf-2.1/lib/python3.7/site-packages/absl/app.py"", line 299 in run
  File ""/Users/hw1000254892/miniconda3/envs/tf-2.1/lib/python3.7/site-packages/tensorflow_core/python/platform/app.py"", line 40 in run
  File ""/Users/hw1000254892/miniconda3/envs/tf-2.1/lib/python3.7/site-packages/tensorflow_core/lite/toco/python/toco_from_protos.py"", line 93 in main
  File ""/Users/hw1000254892/miniconda3/envs/tf-2.1/bin/toco_from_protos"", line 8 in <module>




Process finished with exit code 1

```

**Also, please include a link to the saved model or GraphDef**

```
N/A
```

**Failure details**
If the conversion is successful, but the generated model is wrong,
state what is wrong:
- Producing wrong results and/or decrease in accuracy
- Producing correct results, but the model is slower than expected (model generated from old converter)

Conversion failed

**RNN conversion support**
If converting TF RNN to TFLite fused RNN ops, please prefix [RNN] in the title.

**Any other info / logs**

Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
39039,For the same model Keras trains about 4x slower compared to Estimators.,"<em>Please make sure that this is an issue related to performance of TensorFlow.
As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:performance_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Linux (Colab)
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 1.15 through 2.2-rc3
- Python version: 3.6

**Describe the current behavior**
For a simple model (3 layer neural net), Estimator trains about 4x faster compared to Keras. 
Something slows keras `model.fit()` down significantly.

**Describe the expected behavior**
Expecting Keras and Estimator performance to be roughly on par. 

**Standalone code to reproduce the issue**
https://colab.research.google.com/gist/yzhuang/35f037713f4181070f52b7502846f862/estimator_keras_speed_comparison.ipynb

(Reproduction script are written by @pavanky )"
39038,OwnedMultiDeviceIterator can cause an error on TPU pods,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.2.0-rc4
- Python version: 
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture


**Describe the current behavior**
OwnedMultiDeviceIterator can cause an error on TPU pods.

the resulting stack trace :

gc/0 E0428 07:24:15.171094 132699 main app.py:658 Top-level exception:  could not parse rpc response
	 [[{{node iterator_13/_89}}]] [Op:__inference_minimize_49326]
Function call stack:
minimize
gc/0 E0428 07:24:15.172459 132699 main app.py:659 Traceback (most recent call last):
  File ""/launcher_root/google3/third_party/py/absl/app.py"", line 463, in run
    _run_main(main, args)
  File ""/launcher_root/google3/third_party/py/absl/app.py"", line 392, in _run_main
    sys.exit(main(argv))
  File ""/launcher_root/google3/experimental/users/wendyshang/smarl/football/football/vtrace_main.py"", line 153, in main
    env.create_environment(0), create_agent, create_optimizer)
  File ""/launcher_root/google3/experimental/users/wendyshang/smarl/football/football/learner_object.py"", line 574, in learner_loop
    minimize(it)
  File ""/launcher_root/google3/third_party/tensorflow/python/eager/def_function.py"", line 695, in __call__
    result = self._call(*args, **kwds)
  File ""/launcher_root/google3/third_party/tensorflow/python/eager/def_function.py"", line 760, in _call
    return self._concrete_stateful_fn._filtered_call(canon_args, canon_kwds)  # pylint: disable=protected-access
  File ""/launcher_root/google3/third_party/tensorflow/python/eager/function.py"", line 1904, in _filtered_call
    cancellation_manager=cancellation_manager)
  File ""/launcher_root/google3/third_party/tensorflow/python/eager/function.py"", line 1981, in _call_flat
    ctx, args, cancellation_manager=cancellation_manager))
  File ""/launcher_root/google3/third_party/tensorflow/python/eager/function.py"", line 615, in call
    ctx=ctx)
  File ""/launcher_root/google3/third_party/tensorflow/python/eager/execute.py"", line 60, in quick_execute
    inputs, attrs, num_outputs)
google3.third_party.tensorflow.python.framework.errors_impl.InternalError:  could not parse rpc response
	 [[{{node iterator_13/_89}}]] [Op:__inference_minimize_49326]
Function call stack:
minimize
**Describe the expected behavior**

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
39037,Convert Mobilenet SSD to TensorFlowLite with quantization,"**System information**
- Didn't change the code but used my own data:
- Windows 10 + conda
- TensorFlow installed from binary
- TensorFlow version: v2.0.1 (also happened in newer version)
- Python version: 3.7.6
- CUDA/cuDNN version: 10.0
- GPU model and memory: GeForce GTX 1080 Ti


My goal is simple, I think. I want to convert a pre-trained mobilenetv2 (or v1) ssd model to TFLite with quantization and optimization as described [HERE](https://www.tensorflow.org/lite/convert/quantization). But even without any quantization, I am getting errors converting the model to TFLite model. 

```
    model = tf.saved_model.load(detection_model_dir)
    concrete_func = model.signatures[tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY]
    concrete_func.inputs[0].set_shape([1,300,300,3])
    converter = tf.lite.TFLiteConverter.from_concrete_functions([concrete_func])
    #converter = tf.compat.v1.lite.TFLiteConverter.from_saved_model(detection_model_dir, input_shapes={""image_tensor"" : [1,300,300,3]})
    tflite_model = converter.convert() 
```

Error Messages:

> 2020-04-29 13:23:58.432192: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayWriteV3
2020-04-29 13:23:58.432342: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayWriteV3
2020-04-29 13:23:58.782402: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 4058 operators, 6882 arrays (0 quantized)
2020-04-29 13:23:59.302999: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After Removing unused ops pass 1: 4005 operators, 6778 arrays (0 quantized)
2020-04-29 13:23:59.925648: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 4005 operators, 6778 arrays (0 quantized)
2020-04-29 13:24:00.227644: F .\tensorflow/lite/toco/toco_tooling.h:38] Check failed: s.ok() Found StridedSlice as non-selected output from Switch, but only Merge supported. Control flow ops like Switch and Merge are not generally supported. We are working on fixing this, please see the Github issue at https://github.com/tensorflow/tensorflow/issues/28485.
Fatal Python error: Aborted

I have spent days on converting a pretrained mobilenetv2 ssd model to TFLite. I know the command line (export_tflite_ssd_graph.py) solution works for the conversion but not the qualization part. I also would like to write python code to do the same thing and optimize (compress, quantize) the model. I have been failing in doing it. Any suggestions? 

My questions can be summarized as below:

1. How to convert a pre-trained mobilenetv2 (or v1) ssd model to TFLite with quantization and optimization using python code similar to the above code block. 
2. How to convert a pre-trained mobilenetv2 (or v1) ssd model to TFLite with quantization and optimization with command lines (object detection API and TFLite APIs if any) 
"
39036,Training Property on Keras Layers,"**System information**
- TensorFlow version (you are using): 2.1
- Are you willing to contribute it (Yes/No): Yes

**Describe the feature and the current behavior/state.**

Keras Layers support a `training` argument. Since `training` is only available as an argument it cannot be varied for sublayers without constructing a new class.

Consider a model with two subnetworks, backbone and head. The encapsulating model exposes an inputs and training arg, consistent with the Keras API. Without constructing a different model it becomes impossible to change the value of `training` passed to subnetworks. 

```
class Model(Layer):

    def __init__(self, backbone, head, **kwargs):
        super().__init__(**kwargs)
        self.backbone: Layer = backbone
        self.head: Layer = head

    def call(self, inputs, training=True, **kwargs):
        features = self.backbone(inputs, training=training)
        outputs = self.head(features, training=training)
        return outputs
    
    
# -- Training
model = Model(...)
x, y = dataset()
model(x, training=True)

# -- Inference
model(x, training=False)

# -- Transfer learning (Proposed)

model.backbone.trainable = False  # freeze backbone weights and batch norm
model.backbone.training = False # used later in fine tuning
# the head trains with trainable weights and active batchnorm
model(x, training=True)

# unfreeze backbone for fine tuning while keeping batchnorm frozen
model.backbone.trainable = True
model(x, training=True)

```




**Will this change the current api? How?**

It will alter the precedence for handling the `training` argument [here](https://github.com/tensorflow/tensorflow/blob/1e2c8c6873770a70ace0613a65c11826666c4623/tensorflow/python/keras/engine/base_layer.py#L843-L873). 

A possible implementation could look something like this:

A new property:
```
@property
def training(self):
    return self.__training


@training.setter
def training(self, value: bool):
    if value is not None:
        if tensor_util.is_tensor(value):
            training_value = math_ops.cast(value, dtypes.bool)
        else:
            training_value = bool(value)
        self.__training = training_value
        self._training_arg_passed_by_property = True

    else:
        training_value = None
        self._training_arg_passed_by_property = False
    self.__training = training_value
```


Inside `__call__`:
```
# Priority 1
if self._training_arg_passed_by_property:
    training_value = self.training
    if self._expects_training_arg:
        kwargs[""training""] = training_value
else:
    # Priority 2: `training` was explicitly passed.
    if self._call_arg_was_passed(""training"", args, kwargs):
        training_value = self._get_call_arg_value(""training"", args, kwargs)
        if not self._expects_training_arg:
            kwargs.pop(""training"")
```



**Who will benefit with this feature?**

Tensorflow users who have develop models using OO patterns that require setting of the `training` parameter for sublayers. 
"
39035,TF Lite Hexagon delegate support for snapdragon 865,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>

The Snapdragon 865 (Hexagon 698 DSP) is not included in the list of supported Qualcomm SoCs:
https://www.tensorflow.org/lite/performance/hexagon_delegate

Was wondering if you have plans to add support for it to the tflite Hexagon delegate."
39033,impl.OpError: file is too short to be an sstable & DataLossError: Checksum does not match- TensorFlow 2.1.0,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (Linux Ubuntu 16.04):
- TensorFlow version (2.1.0):
- Python version: (3.6)
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A
- Kubernetes version (v1.14.3)
- Kubeflow version (v1.0)

**Describe the current behavior**
Hi guys! i am trying to run this TensorFlow job on Kubernetes cluster using kubeflow. But i keep getting these indeterministic errors, which are really hard to follow. I have to run the same job again and again using different tfconfigs ... and every time, there's a chance that the job might fail because of one of the following issues. The job uses TensorFlow2.0, and kubeflow1.0. The fact that the job fails with a chance is really weird which makes it very hard to isolate. If I simply delete and restart the job, sometimes it runs fine(but there's a chance it might give the same error again - slight chance!). Could someone please point out the root cause that might be causing such behavior!

**Describe the expected behavior**
The jobs should not fail in an indeterministic manner. 

**Error Log1**
```
2020-04-16 03:32:10.840927: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory
2020-04-16 03:32:10.841009: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory
2020-04-16 03:32:10.841016: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
I0416 03:32:11.778649 140150905272128 dataset_builder.py:199] Overwrite dataset info from restored data version.
I0416 03:32:11.781358 140150905272128 dataset_builder.py:285] Reusing dataset cifar10 (./dataDir/cifar10/3.0.0)
I0416 03:32:11.781544 140150905272128 dataset_builder.py:458] Constructing tf.data.Dataset for split train, from ./dataDir/cifar10/3.0.0
2020-04-16 03:32:11.785308: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2020-04-16 03:32:11.785339: E tensorflow/stream_executor/cuda/cuda_driver.cc:351] failed call to cuInit: UNKNOWN ERROR (303)
2020-04-16 03:32:11.785361: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (tftestaccuracy7-testjob-temp-1-7-3-3-0-master-0): /proc/driver/nvidia/version does not exist
2020-04-16 03:32:11.785606: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2020-04-16 03:32:11.794453: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2194825000 Hz
2020-04-16 03:32:11.796551: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4895200 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-04-16 03:32:11.796574: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
INFO:1587007938.6536536:tensorflow:TF_CONFIG environment variable: {'cluster': {'master': ['tftestaccuracy7-testjob-temp-1-7-3-3-0-master-0.ali.svc:2222'], 'ps': ['tftestaccuracy7-testjob-temp-1-7-3-3-0-ps-0.ali.svc:2222', 'tftestaccuracy7-testjob-temp-1-7-3-3-0-ps-1.ali.svc:2222', 'tftestaccuracy7-testjob-temp-1-7-3-3-0-ps-2.ali.svc:2222', 'tftestaccuracy7-testjob-temp-1-7-3-3-0-ps-3.ali.svc:2222', 'tftestaccuracy7-testjob-temp-1-7-3-3-0-ps-4.ali.svc:2222', 'tftestaccuracy7-testjob-temp-1-7-3-3-0-ps-5.ali.svc:2222', 'tftestaccuracy7-testjob-temp-1-7-3-3-0-ps-6.ali.svc:2222'], 'worker': ['tftestaccuracy7-testjob-temp-1-7-3-3-0-worker-0.ali.svc:2222', 'tftestaccuracy7-testjob-temp-1-7-3-3-0-worker-1.ali.svc:2222', 'tftestaccuracy7-testjob-temp-1-7-3-3-0-worker-2.ali.svc:2222']}, 'task': {'type': 'master', 'index': 0}, 'environment': 'cloud'}
I0416 03:32:18.653653 140150905272128 run_config.py:535] TF_CONFIG environment variable: {'cluster': {'master': ['tftestaccuracy7-testjob-temp-1-7-3-3-0-master-0.ali.svc:2222'], 'ps': ['tftestaccuracy7-testjob-temp-1-7-3-3-0-ps-0.ali.svc:2222', 'tftestaccuracy7-testjob-temp-1-7-3-3-0-ps-1.ali.svc:2222', 'tftestaccuracy7-testjob-temp-1-7-3-3-0-ps-2.ali.svc:2222', 'tftestaccuracy7-testjob-temp-1-7-3-3-0-ps-3.ali.svc:2222', 'tftestaccuracy7-testjob-temp-1-7-3-3-0-ps-4.ali.svc:2222', 'tftestaccuracy7-testjob-temp-1-7-3-3-0-ps-5.ali.svc:2222', 'tftestaccuracy7-testjob-temp-1-7-3-3-0-ps-6.ali.svc:2222'], 'worker': ['tftestaccuracy7-testjob-temp-1-7-3-3-0-worker-0.ali.svc:2222', 'tftestaccuracy7-testjob-temp-1-7-3-3-0-worker-1.ali.svc:2222', 'tftestaccuracy7-testjob-temp-1-7-3-3-0-worker-2.ali.svc:2222']}, 'task': {'type': 'master', 'index': 0}, 'environment': 'cloud'}
INFO:1587007938.6553543:tensorflow:Using the Keras model provided.
I0416 03:32:18.655354 140150905272128 keras.py:540] Using the Keras model provided.
WARNING:1587007938.7225273:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
W0416 03:32:18.722527 140150905272128 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
INFO:1587007950.8246615:tensorflow:Using config: {'_model_dir': './out/tftestaccuracy7-testjob-temp-1-7-3-3-0', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 20000, '_save_checkpoints_secs': None, '_session_config': device_filters: ""/job:ps""
device_filters: ""/job:master""
allow_soft_placement: true
graph_options {
  rewrite_options {
    meta_optimizer_iterations: ONE
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({'master': ['tftestaccuracy7-testjob-temp-1-7-3-3-0-master-0.ali.svc:2222'], 'ps': ['tftestaccuracy7-testjob-temp-1-7-3-3-0-ps-0.ali.svc:2222', 'tftestaccuracy7-testjob-temp-1-7-3-3-0-ps-1.ali.svc:2222', 'tftestaccuracy7-testjob-temp-1-7-3-3-0-ps-2.ali.svc:2222', 'tftestaccuracy7-testjob-temp-1-7-3-3-0-ps-3.ali.svc:2222', 'tftestaccuracy7-testjob-temp-1-7-3-3-0-ps-4.ali.svc:2222', 'tftestaccuracy7-testjob-temp-1-7-3-3-0-ps-5.ali.svc:2222', 'tftestaccuracy7-testjob-temp-1-7-3-3-0-ps-6.ali.svc:2222'], 'worker': ['tftestaccuracy7-testjob-temp-1-7-3-3-0-worker-0.ali.svc:2222', 'tftestaccuracy7-testjob-temp-1-7-3-3-0-worker-1.ali.svc:2222', 'tftestaccuracy7-testjob-temp-1-7-3-3-0-worker-2.ali.svc:2222']}), '_task_type': 'master', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://tftestaccuracy7-testjob-temp-1-7-3-3-0-master-0.ali.svc:2222', '_evaluation_master': '', '_num_ps_replicas': 7, '_num_worker_replicas': 4, '_is_chief': True}
I0416 03:32:30.824661 140150905272128 estimator.py:216] Using config: {'_model_dir': './out/tftestaccuracy7-testjob-temp-1-7-3-3-0', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 20000, '_save_checkpoints_secs': None, '_session_config': device_filters: ""/job:ps""
device_filters: ""/job:master""
allow_soft_placement: true
graph_options {
  rewrite_options {
    meta_optimizer_iterations: ONE
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({'master': ['tftestaccuracy7-testjob-temp-1-7-3-3-0-master-0.ali.svc:2222'], 'ps': ['tftestaccuracy7-testjob-temp-1-7-3-3-0-ps-0.ali.svc:2222', 'tftestaccuracy7-testjob-temp-1-7-3-3-0-ps-1.ali.svc:2222', 'tftestaccuracy7-testjob-temp-1-7-3-3-0-ps-2.ali.svc:2222', 'tftestaccuracy7-testjob-temp-1-7-3-3-0-ps-3.ali.svc:2222', 'tftestaccuracy7-testjob-temp-1-7-3-3-0-ps-4.ali.svc:2222', 'tftestaccuracy7-testjob-temp-1-7-3-3-0-ps-5.ali.svc:2222', 'tftestaccuracy7-testjob-temp-1-7-3-3-0-ps-6.ali.svc:2222'], 'worker': ['tftestaccuracy7-testjob-temp-1-7-3-3-0-worker-0.ali.svc:2222', 'tftestaccuracy7-testjob-temp-1-7-3-3-0-worker-1.ali.svc:2222', 'tftestaccuracy7-testjob-temp-1-7-3-3-0-worker-2.ali.svc:2222']}), '_task_type': 'master', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://tftestaccuracy7-testjob-temp-1-7-3-3-0-master-0.ali.svc:2222', '_evaluation_master': '', '_num_ps_replicas': 7, '_num_worker_replicas': 4, '_is_chief': True}
INFO:1587007950.825566:tensorflow:Not using Distribute Coordinator.
I0416 03:32:30.825566 140150905272128 estimator_training.py:186] Not using Distribute Coordinator.
INFO:1587007950.8260767:tensorflow:Start Tensorflow server.
I0416 03:32:30.826076 140150905272128 training.py:744] Start Tensorflow server.
2020-04-16 03:32:30.835044: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:300] Initialize GrpcChannelCache for job master -> {0 -> localhost:2222}
2020-04-16 03:32:30.835109: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:300] Initialize GrpcChannelCache for job ps -> {0 -> tftestaccuracy7-testjob-temp-1-7-3-3-0-ps-0.ali.svc:2222, 1 -> tftestaccuracy7-testjob-temp-1-7-3-3-0-ps-1.ali.svc:2222, 2 -> tftestaccuracy7-testjob-temp-1-7-3-3-0-ps-2.ali.svc:2222, 3 -> tftestaccuracy7-testjob-temp-1-7-3-3-0-ps-3.ali.svc:2222, 4 -> tftestaccuracy7-testjob-temp-1-7-3-3-0-ps-4.ali.svc:2222, 5 -> tftestaccuracy7-testjob-temp-1-7-3-3-0-ps-5.ali.svc:2222, 6 -> tftestaccuracy7-testjob-temp-1-7-3-3-0-ps-6.ali.svc:2222}
2020-04-16 03:32:30.835125: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:300] Initialize GrpcChannelCache for job worker -> {0 -> tftestaccuracy7-testjob-temp-1-7-3-3-0-worker-0.ali.svc:2222, 1 -> tftestaccuracy7-testjob-temp-1-7-3-3-0-worker-1.ali.svc:2222, 2 -> tftestaccuracy7-testjob-temp-1-7-3-3-0-worker-2.ali.svc:2222}
2020-04-16 03:32:30.838051: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:390] Started server with target: grpc://localhost:2222
WARNING:1587007950.8507316:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0416 03:32:30.850731 140150905272128 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0416 03:32:30.867805 140150905272128 dataset_builder.py:199] Overwrite dataset info from restored data version.
I0416 03:32:30.875023 140150905272128 dataset_builder.py:285] Reusing dataset cifar10 (./dataDir/cifar10/3.0.0)
I0416 03:32:30.875263 140150905272128 dataset_builder.py:458] Constructing tf.data.Dataset for split train, from ./dataDir/cifar10/3.0.0
INFO:1587007951.0019863:tensorflow:Calling model_fn.
I0416 03:32:31.001986 140150905272128 estimator.py:1151] Calling model_fn.
INFO:1587007957.5129364:tensorflow:Done calling model_fn.
I0416 03:32:37.512936 140150905272128 estimator.py:1153] Done calling model_fn.
INFO:1587007957.5134861:tensorflow:Warm-starting with WarmStartSettings: WarmStartSettings(ckpt_to_initialize_from='./out/tftestaccuracy7-testjob-temp-1-7-3-3-0/keras/keras_model.ckpt', vars_to_warm_start='.*', var_name_to_vocab_info={}, var_name_to_prev_var_name={})
I0416 03:32:37.513486 140150905272128 estimator.py:1372] Warm-starting with WarmStartSettings: WarmStartSettings(ckpt_to_initialize_from='./out/tftestaccuracy7-testjob-temp-1-7-3-3-0/keras/keras_model.ckpt', vars_to_warm_start='.*', var_name_to_vocab_info={}, var_name_to_prev_var_name={})
INFO:1587007957.513585:tensorflow:Warm-starting from: ./out/tftestaccuracy7-testjob-temp-1-7-3-3-0/keras/keras_model.ckpt
I0416 03:32:37.513585 140150905272128 warm_starting_util.py:464] Warm-starting from: ./out/tftestaccuracy7-testjob-temp-1-7-3-3-0/keras/keras_model.ckpt
INFO:1587007957.513649:tensorflow:Warm-starting variables only in TRAINABLE_VARIABLES.
I0416 03:32:37.513648 140150905272128 warm_starting_util.py:343] Warm-starting variables only in TRAINABLE_VARIABLES.
tfds.core.DatasetInfo(
    name='cifar10',
    version=3.0.0,
    description='The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images.',
    homepage='https://www.cs.toronto.edu/~kriz/cifar.html',
    features=FeaturesDict({
        'image': Image(shape=(32, 32, 3), dtype=tf.uint8),
        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=10),
    }),
    total_num_examples=60000,
    splits={
        'test': 10000,
        'train': 50000,
    },
    supervised_keys=('image', 'label'),
    citation=""""""@TECHREPORT{Krizhevsky09learningmultiple,
        author = {Alex Krizhevsky},
        title = {Learning multiple layers of features from tiny images},
        institution = {},
        year = {2009}
    }"""""",
    redistribution_info=,
)

Input data (batch size 64): <DatasetV1Adapter shapes: ((None, 128, 128, 3), (None,)), types: (tf.float32, tf.int64)>
+++++ Building Keras model +++++
Output of feature extraction (original model): (64, 4, 4, 2048)
Output of 0th classification layer (<tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x7f766056aa58>): (64, 2048)
Output of 1th classification layer (<tensorflow.python.keras.layers.core.Dense object at 0x7f766056aba8>): (64, 10)
Model: ""sequential_1""
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
resnet50 (Model)             (None, 4, 4, 2048)        23587712  
_________________________________________________________________
sequential (Sequential)      (None, 10)                20490     
=================================================================
Total params: 23,608,202
Trainable params: 23,555,082
Non-trainable params: 53,120
_________________________________________________________________
Model: ""sequential""
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
global_average_pooling2d (Gl (None, 2048)              0         
_________________________________________________________________
dense (Dense)                (None, 10)                20490     
=================================================================
Total params: 20,490
Trainable params: 20,490
Non-trainable params: 0
_________________________________________________________________
+++++ Train and evaluate the Estimator model +++++
tfds.core.DatasetInfo(
    name='cifar10',
    version=3.0.0,
    description='The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images.',
    homepage='https://www.cs.toronto.edu/~kriz/cifar.html',
    features=FeaturesDict({
        'image': Image(shape=(32, 32, 3), dtype=tf.uint8),
        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=10),
    }),
    total_num_examples=60000,
    splits={
        'test': 10000,
        'train': 50000,
    },
    supervised_keys=('image', 'label'),
    citation=""""""@TECHREPORT{Krizhevsky09learningmultiple,
        author = {Alex Krizhevsky},
        title = {Learning multiple layers of features from tiny images},
        institution = {},
        year = {2009}
    }"""""",
    redistribution_info=,
)

Input data (batch size 64): <DatasetV1Adapter shapes: ((None, 128, 128, 3), (None,)), types: (tf.float32, tf.int64)>
Traceback (most recent call last):
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/py_checkpoint_reader.py"", line 95, in NewCheckpointReader
    return CheckpointReader(compat.as_bytes(filepattern))
RuntimeError: file is too short to be an sstable

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/app/keras_to_est.py"", line 242, in <module>
    app.run(main)
  File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""/app/keras_to_est.py"", line 227, in main
    tf.estimator.train_and_evaluate(model_est, train_spec, eval_spec)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py"", line 473, in train_and_evaluate
    return executor.run()
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py"", line 640, in run
    getattr(self, task_to_run)()
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py"", line 677, in run_master
    self._start_distributed_training(saving_listeners=saving_listeners)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py"", line 796, in _start_distributed_training
    saving_listeners=saving_listeners)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 374, in train
    loss = self._train_model(input_fn, hooks, saving_listeners)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1164, in _train_model
    return self._train_model_default(input_fn, hooks, saving_listeners)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1198, in _train_model_default
    saving_listeners)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1373, in _train_with_estimator_spec
    warm_starting_util.warm_start(*self._warm_start_settings)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/warm_starting_util.py"", line 476, in warm_start
    ckpt_to_initialize_from, grouped_variables.keys())
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/warm_starting_util.py"", line 397, in _get_object_checkpoint_renames
    names_to_keys = saver_lib.object_graph_key_mapping(fname)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py"", line 1617, in object_graph_key_mapping
    reader = py_checkpoint_reader.NewCheckpointReader(checkpoint_path)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/py_checkpoint_reader.py"", line 99, in NewCheckpointReader
    error_translator(e)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/py_checkpoint_reader.py"", line 48, in error_translator
    raise errors_impl.OpError(None, None, error_message, errors_impl.UNKNOWN)
tensorflow.python.framework.errors_impl.OpError: file is too short to be an sstable
```
**Error Log2**
```
2020-04-17 11:10:04.594547: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory
2020-04-17 11:10:04.594650: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory
2020-04-17 11:10:04.594665: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
I0417 11:10:05.664701 140220500707136 dataset_builder.py:199] Overwrite dataset info from restored data version.
I0417 11:10:05.667569 140220500707136 dataset_builder.py:285] Reusing dataset cifar10 (./dataDir/cifar10/3.0.0)
I0417 11:10:05.667821 140220500707136 dataset_builder.py:458] Constructing tf.data.Dataset for split train, from ./dataDir/cifar10/3.0.0
2020-04-17 11:10:05.672440: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2020-04-17 11:10:05.672469: E tensorflow/stream_executor/cuda/cuda_driver.cc:351] failed call to cuInit: UNKNOWN ERROR (303)
2020-04-17 11:10:05.672494: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (tftestaccuracy6-testjob-temp-1-6-11-11-0-master-0): /proc/driver/nvidia/version does not exist
2020-04-17 11:10:05.672896: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2020-04-17 11:10:05.685860: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2194855000 Hz
2020-04-17 11:10:05.688580: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4db8fe0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-04-17 11:10:05.688621: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
INFO:1587121814.71867:tensorflow:TF_CONFIG environment variable: {'cluster': {'master': ['tftestaccuracy6-testjob-temp-1-6-11-11-0-master-0.ali.svc:2222'], 'ps': ['tftestaccuracy6-testjob-temp-1-6-11-11-0-ps-0.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-ps-1.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-ps-2.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-ps-3.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-ps-4.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-ps-5.ali.svc:2222'], 'worker': ['tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-0.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-1.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-2.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-3.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-4.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-5.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-6.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-7.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-8.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-9.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-10.ali.svc:2222']}, 'task': {'type': 'master', 'index': 0}, 'environment': 'cloud'}
I0417 11:10:14.718669 140220500707136 run_config.py:535] TF_CONFIG environment variable: {'cluster': {'master': ['tftestaccuracy6-testjob-temp-1-6-11-11-0-master-0.ali.svc:2222'], 'ps': ['tftestaccuracy6-testjob-temp-1-6-11-11-0-ps-0.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-ps-1.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-ps-2.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-ps-3.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-ps-4.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-ps-5.ali.svc:2222'], 'worker': ['tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-0.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-1.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-2.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-3.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-4.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-5.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-6.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-7.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-8.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-9.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-10.ali.svc:2222']}, 'task': {'type': 'master', 'index': 0}, 'environment': 'cloud'}
INFO:1587121814.7204363:tensorflow:Using the Keras model provided.
I0417 11:10:14.720436 140220500707136 keras.py:540] Using the Keras model provided.
INFO:1587121814.7229145:tensorflow:Using config: {'_model_dir': './out/tftestaccuracy6-testjob-temp-1-6-11-11-0', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 20000, '_save_checkpoints_secs': None, '_session_config': device_filters: ""/job:ps""
device_filters: ""/job:master""
allow_soft_placement: true
graph_options {
  rewrite_options {
    meta_optimizer_iterations: ONE
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({'master': ['tftestaccuracy6-testjob-temp-1-6-11-11-0-master-0.ali.svc:2222'], 'ps': ['tftestaccuracy6-testjob-temp-1-6-11-11-0-ps-0.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-ps-1.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-ps-2.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-ps-3.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-ps-4.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-ps-5.ali.svc:2222'], 'worker': ['tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-0.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-1.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-2.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-3.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-4.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-5.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-6.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-7.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-8.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-9.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-10.ali.svc:2222']}), '_task_type': 'master', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://tftestaccuracy6-testjob-temp-1-6-11-11-0-master-0.ali.svc:2222', '_evaluation_master': '', '_num_ps_replicas': 6, '_num_worker_replicas': 12, '_is_chief': True}
I0417 11:10:14.722914 140220500707136 estimator.py:216] Using config: {'_model_dir': './out/tftestaccuracy6-testjob-temp-1-6-11-11-0', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 20000, '_save_checkpoints_secs': None, '_session_config': device_filters: ""/job:ps""
device_filters: ""/job:master""
allow_soft_placement: true
graph_options {
  rewrite_options {
    meta_optimizer_iterations: ONE
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({'master': ['tftestaccuracy6-testjob-temp-1-6-11-11-0-master-0.ali.svc:2222'], 'ps': ['tftestaccuracy6-testjob-temp-1-6-11-11-0-ps-0.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-ps-1.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-ps-2.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-ps-3.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-ps-4.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-ps-5.ali.svc:2222'], 'worker': ['tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-0.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-1.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-2.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-3.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-4.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-5.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-6.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-7.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-8.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-9.ali.svc:2222', 'tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-10.ali.svc:2222']}), '_task_type': 'master', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://tftestaccuracy6-testjob-temp-1-6-11-11-0-master-0.ali.svc:2222', '_evaluation_master': '', '_num_ps_replicas': 6, '_num_worker_replicas': 12, '_is_chief': True}
INFO:1587121814.7236319:tensorflow:Not using Distribute Coordinator.
I0417 11:10:14.723631 140220500707136 estimator_training.py:186] Not using Distribute Coordinator.
INFO:1587121814.7240767:tensorflow:Start Tensorflow server.
I0417 11:10:14.724076 140220500707136 training.py:744] Start Tensorflow server.
2020-04-17 11:10:14.731863: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:300] Initialize GrpcChannelCache for job master -> {0 -> localhost:2222}
2020-04-17 11:10:14.731898: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:300] Initialize GrpcChannelCache for job ps -> {0 -> tftestaccuracy6-testjob-temp-1-6-11-11-0-ps-0.ali.svc:2222, 1 -> tftestaccuracy6-testjob-temp-1-6-11-11-0-ps-1.ali.svc:2222, 2 -> tftestaccuracy6-testjob-temp-1-6-11-11-0-ps-2.ali.svc:2222, 3 -> tftestaccuracy6-testjob-temp-1-6-11-11-0-ps-3.ali.svc:2222, 4 -> tftestaccuracy6-testjob-temp-1-6-11-11-0-ps-4.ali.svc:2222, 5 -> tftestaccuracy6-testjob-temp-1-6-11-11-0-ps-5.ali.svc:2222}
2020-04-17 11:10:14.731910: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:300] Initialize GrpcChannelCache for job worker -> {0 -> tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-0.ali.svc:2222, 1 -> tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-1.ali.svc:2222, 2 -> tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-2.ali.svc:2222, 3 -> tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-3.ali.svc:2222, 4 -> tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-4.ali.svc:2222, 5 -> tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-5.ali.svc:2222, 6 -> tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-6.ali.svc:2222, 7 -> tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-7.ali.svc:2222, 8 -> tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-8.ali.svc:2222, 9 -> tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-9.ali.svc:2222, 10 -> tftestaccuracy6-testjob-temp-1-6-11-11-0-worker-10.ali.svc:2222}
2020-04-17 11:10:14.733813: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:390] Started server with target: grpc://localhost:2222
WARNING:1587121814.7500741:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
W0417 11:10:14.750074 140220500707136 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
WARNING:1587121814.7521474:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
W0417 11:10:14.752147 140220500707136 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
I0417 11:10:14.775437 140220500707136 dataset_builder.py:199] Overwrite dataset info from restored data version.
I0417 11:10:14.781437 140220500707136 dataset_builder.py:285] Reusing dataset cifar10 (./dataDir/cifar10/3.0.0)
I0417 11:10:14.781795 140220500707136 dataset_builder.py:458] Constructing tf.data.Dataset for split train, from ./dataDir/cifar10/3.0.0
INFO:1587121814.9113212:tensorflow:Calling model_fn.
I0417 11:10:14.911321 140220500707136 estimator.py:1151] Calling model_fn.
INFO:1587121822.074707:tensorflow:Done calling model_fn.
I0417 11:10:22.074707 140220500707136 estimator.py:1153] Done calling model_fn.
INFO:1587121822.0750966:tensorflow:Warm-starting with WarmStartSettings: WarmStartSettings(ckpt_to_initialize_from='./out/tftestaccuracy6-testjob-temp-1-6-11-11-0/keras/keras_model.ckpt', vars_to_warm_start='.*', var_name_to_vocab_info={}, var_name_to_prev_var_name={})
I0417 11:10:22.075096 140220500707136 estimator.py:1372] Warm-starting with WarmStartSettings: WarmStartSettings(ckpt_to_initialize_from='./out/tftestaccuracy6-testjob-temp-1-6-11-11-0/keras/keras_model.ckpt', vars_to_warm_start='.*', var_name_to_vocab_info={}, var_name_to_prev_var_name={})
INFO:1587121822.075177:tensorflow:Warm-starting from: ./out/tftestaccuracy6-testjob-temp-1-6-11-11-0/keras/keras_model.ckpt
I0417 11:10:22.075176 140220500707136 warm_starting_util.py:464] Warm-starting from: ./out/tftestaccuracy6-testjob-temp-1-6-11-11-0/keras/keras_model.ckpt
INFO:1587121822.0752382:tensorflow:Warm-starting variables only in TRAINABLE_VARIABLES.
I0417 11:10:22.075238 140220500707136 warm_starting_util.py:343] Warm-starting variables only in TRAINABLE_VARIABLES.
INFO:1587121823.262496:tensorflow:Warm-started 214 variables.
I0417 11:10:23.262495 140220500707136 warm_starting_util.py:538] Warm-started 214 variables.
INFO:1587121823.2661114:tensorflow:Create CheckpointSaverHook.
I0417 11:10:23.266111 140220500707136 basic_session_run_hooks.py:546] Create CheckpointSaverHook.
INFO:1587121825.0649378:tensorflow:Graph was finalized.
I0417 11:10:25.064937 140220500707136 monitored_session.py:246] Graph was finalized.
tfds.core.DatasetInfo(
    name='cifar10',
    version=3.0.0,
    description='The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images.',
    homepage='https://www.cs.toronto.edu/~kriz/cifar.html',
    features=FeaturesDict({
        'image': Image(shape=(32, 32, 3), dtype=tf.uint8),
        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=10),
    }),
    total_num_examples=60000,
    splits={
        'test': 10000,
        'train': 50000,
    },
    supervised_keys=('image', 'label'),
    citation=""""""@TECHREPORT{Krizhevsky09learningmultiple,
        author = {Alex Krizhevsky},
        title = {Learning multiple layers of features from tiny images},
        institution = {},
        year = {2009}
    }"""""",
    redistribution_info=,
)

Input data (batch size 64): <DatasetV1Adapter shapes: ((None, 128, 128, 3), (None,)), types: (tf.float32, tf.int64)>
+++++ Building Keras model +++++
Output of feature extraction (original model): (64, 4, 4, 2048)
Output of 0th classification layer (<tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D object at 0x7f86ec14b9e8>): (64, 2048)
Output of 1th classification layer (<tensorflow.python.keras.layers.core.Dense object at 0x7f86ec14bb38>): (64, 10)
Model: ""sequential_1""
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
resnet50 (Model)             (None, 4, 4, 2048)        23587712  
_________________________________________________________________
sequential (Sequential)      (None, 10)                20490     
=================================================================
Total params: 23,608,202
Trainable params: 23,555,082
Non-trainable params: 53,120
_________________________________________________________________
Model: ""sequential""
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
global_average_pooling2d (Gl (None, 2048)              0         
_________________________________________________________________
dense (Dense)                (None, 10)                20490     
=================================================================
Total params: 20,490
Trainable params: 20,490
Non-trainable params: 0
_________________________________________________________________
+++++ Train and evaluate the Estimator model +++++
tfds.core.DatasetInfo(
    name='cifar10',
    version=3.0.0,
    description='The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images.',
    homepage='https://www.cs.toronto.edu/~kriz/cifar.html',
    features=FeaturesDict({
        'image': Image(shape=(32, 32, 3), dtype=tf.uint8),
        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=10),
    }),
    total_num_examples=60000,
    splits={
        'test': 10000,
        'train': 50000,
    },
    supervised_keys=('image', 'label'),
    citation=""""""@TECHREPORT{Krizhevsky09learningmultiple,
        author = {Alex Krizhevsky},
        title = {Learning multiple layers of features from tiny images},
        institution = {},
        year = {2009}
    }"""""",
    redistribution_info=,
)

Input data (batch size 64): <DatasetV1Adapter shapes: ((None, 128, 128, 3), (None,)), types: (tf.float32, tf.int64)>
Traceback (most recent call last):
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1367, in _do_call
    return fn(*args)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1352, in _run_fn
    target_list, run_metadata)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1445, in _call_tf_sessionrun
    run_metadata)
tensorflow.python.framework.errors_impl.DataLossError: From /job:ps/replica:0/task:3:
Checksum does not match: stored 3880206044 vs. calculated on the restored bytes 1782481297
	 [[{{node checkpoint_initializer_53}}]]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/app/keras_to_est.py"", line 242, in <module>
    app.run(main)
  File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""/app/keras_to_est.py"", line 227, in main
    tf.estimator.train_and_evaluate(model_est, train_spec, eval_spec)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py"", line 473, in train_and_evaluate
    return executor.run()
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py"", line 640, in run
    getattr(self, task_to_run)()
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py"", line 677, in run_master
    self._start_distributed_training(saving_listeners=saving_listeners)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py"", line 796, in _start_distributed_training
    saving_listeners=saving_listeners)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 374, in train
    loss = self._train_model(input_fn, hooks, saving_listeners)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1164, in _train_model
    return self._train_model_default(input_fn, hooks, saving_listeners)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1198, in _train_model_default
    saving_listeners)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1493, in _train_with_estimator_spec
    log_step_count_steps=log_step_count_steps) as mon_sess:
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 604, in MonitoredTrainingSession
    stop_grace_period_secs=stop_grace_period_secs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1038, in __init__
    stop_grace_period_secs=stop_grace_period_secs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 749, in __init__
    self._sess = _RecoverableSession(self._coordinated_creator)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1231, in __init__
    _WrappedSession.__init__(self, self._create_session())
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 1236, in _create_session
    return self._sess_creator.create_session()
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 902, in create_session
    self.tf_sess = self._session_creator.create_session()
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py"", line 669, in create_session
    init_fn=self._scaffold.init_fn)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/session_manager.py"", line 300, in prepare_session
    sess.run(init_op, feed_dict=init_feed_dict)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 960, in run
    run_metadata_ptr)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1183, in _run
    feed_dict_tensor, options, run_metadata)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1361, in _do_run
    run_metadata)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1386, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.DataLossError: From /job:ps/replica:0/task:3:
Checksum does not match: stored 3880206044 vs. calculated on the restored bytes 1782481297
	 [[node checkpoint_initializer_53 (defined at usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py:1373) ]]

Original stack trace for 'checkpoint_initializer_53':
  File ""app/keras_to_est.py"", line 242, in <module>
    app.run(main)
  File ""usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""app/keras_to_est.py"", line 227, in main
    tf.estimator.train_and_evaluate(model_est, train_spec, eval_spec)
  File ""usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py"", line 473, in train_and_evaluate
    return executor.run()
  File ""usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py"", line 640, in run
    getattr(self, task_to_run)()
  File ""usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py"", line 677, in run_master
    self._start_distributed_training(saving_listeners=saving_listeners)
  File ""usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py"", line 796, in _start_distributed_training
    saving_listeners=saving_listeners)
  File ""usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 374, in train
    loss = self._train_model(input_fn, hooks, saving_listeners)
  File ""usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1164, in _train_model
    return self._train_model_default(input_fn, hooks, saving_listeners)
  File ""usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1198, in _train_model_default
    saving_listeners)
  File ""usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1373, in _train_with_estimator_spec
    warm_starting_util.warm_start(*self._warm_start_settings)
  File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/warm_starting_util.py"", line 533, in warm_start
    checkpoint_utils.init_from_checkpoint(ckpt_to_initialize_from, vocabless_vars)
  File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/checkpoint_utils.py"", line 291, in init_from_checkpoint
    init_from_checkpoint_fn)
  File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/distribute/distribute_lib.py"", line 1949, in merge_call
    return self._merge_call(merge_fn, args, kwargs)
  File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/distribute/distribute_lib.py"", line 1956, in _merge_call
    return merge_fn(self._strategy, *args, **kwargs)
  File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/checkpoint_utils.py"", line 286, in <lambda>
    ckpt_dir_or_file, assignment_map)
  File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/checkpoint_utils.py"", line 334, in _init_from_checkpoint
    _set_variable_or_list_initializer(var, ckpt_file, tensor_name_in_ckpt)
  File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/checkpoint_utils.py"", line 458, in _set_variable_or_list_initializer
    _set_checkpoint_initializer(variable_or_list, ckpt_file, tensor_name, """")
  File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/checkpoint_utils.py"", line 412, in _set_checkpoint_initializer
    ckpt_file, [tensor_name], [slice_spec], [base_type], name=name)[0]
  File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gen_io_ops.py"", line 1506, in restore_v2
    name=name)
  File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/op_def_library.py"", line 742, in _apply_op_helper
    attrs=attr_protos, op_def=op_def)
  File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py"", line 3322, in _create_op_internal
    op_def=op_def)
  File ""usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py"", line 1756, in __init__
    self._traceback = tf_stack.extract_stack()
```"
39030,TPU training error,"Tensorflow: 2.2.0-rc3
Python: 3.6.9

I am training on colab TPU. But got the following error:
```
NotFoundError: {{function_node __inference_train_function_128421}} No registered 'PyFunc' OpKernel for 'CPU' devices compatible with node {{node PyFunc}}
	.  Registered:  <no registered kernels>

	 [[PyFunc]]
	 [[MultiDeviceIteratorGetNextFromShard]]
	 [[RemoteCall]]
	 [[IteratorGetNextAsOptional]]
```

Then I tried to use tfrecord from generator. But got another error:

```
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
<ipython-input-7-a14d46c75435> in <module>()
      3 serialized_features_dataset = tf.data.Dataset.from_generator(train_D.__iter__, output_types=(tf.int32, tf.int32, tf.int32, tf.int32))
      4 with tf.io.TFRecordWriter(filename) as writer:
----> 5     writer.write(serialized_features_dataset)

/usr/local/lib/python3.6/dist-packages/tensorflow/python/lib/io/tf_record.py in write(self, record)
    311       record: str
    312     """"""
--> 313     super(TFRecordWriter, self).write(record)
    314 
    315   def flush(self):

TypeError: write(): incompatible function arguments. The following argument types are supported:
    1. (self: tensorflow.python._pywrap_record_io.RecordWriter, record: str) -> None

Invoked with: <tensorflow.python.lib.io.tf_record.TFRecordWriter object at 0x7f299d088b48>, <FlatMapDataset shapes: (<unknown>, <unknown>, <unknown>, <unknown>), types: (tf.int32, tf.int32, tf.int32, tf.int32)>
```

To help replicate my issue, this is my notebook
https://colab.research.google.com/drive/1tQbhe_gGhIFoMuHu-HqazHzlP0Z83kwj

And this is the dataset to run the codes:
https://drive.google.com/drive/folders/1abgTg2uuWBmo2TTvipqiXVhxkBuLmNwb?usp=sharing
"
39028,tf.one_hot should support strings,"**System information**
- TensorFlow version: 2.2.0rc3

**Describe the feature and the current behavior/state.**

I'm sure this has been asked before, but I can't find any issue related. `tf.one_hot` should support string tensors for encoding string labels. Currently, passing a string tensor gives:

```
>>> tf.one_hot(tf.constant([""a"", ""b"", ""c""]), depth=3)
---------------------------------------------------------------------------
NotFoundError                             Traceback (most recent call last)
<ipython-input-19-f9e0ea7fe045> in <module>
----> 1 tf.one_hot(tf.constant([""a"", ""b"", ""c""]), depth=3)

~/anaconda3/envs/ml/lib/python3.6/site-packages/tensorflow/python/util/dispatch.py in wrapper(*args, **kwargs)
    178     """"""Call target, and fall back on dispatchers if there is a TypeError.""""""
    179     try:
--> 180       return target(*args, **kwargs)
    181     except (TypeError, ValueError):
    182       # Note: convert_to_eager_tensor currently raises a ValueError, not a

~/anaconda3/envs/ml/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py in one_hot(indices, depth, on_value, off_value, axis, dtype, name)
   4008 
   4009     return gen_array_ops.one_hot(indices, depth, on_value, off_value, axis,
-> 4010                                  name)
   4011 
   4012 

~/anaconda3/envs/ml/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py in one_hot(indices, depth, on_value, off_value, axis, name)
   6191         pass  # Add nodes to the TensorFlow graph.
   6192     except _core._NotOkStatusException as e:
-> 6193       _ops.raise_from_not_ok_status(e, name)
   6194   # Add nodes to the TensorFlow graph.
   6195   if axis is None:

~/anaconda3/envs/ml/lib/python3.6/site-packages/tensorflow/python/framework/ops.py in raise_from_not_ok_status(e, name)
   6651   message = e.message + ("" name: "" + name if name is not None else """")
   6652   # pylint: disable=protected-access
-> 6653   six.raise_from(core._status_to_exception(e.code, message), None)
   6654   # pylint: enable=protected-access
   6655 

~/anaconda3/envs/ml/lib/python3.6/site-packages/six.py in raise_from(value, from_value)

NotFoundError: Could not find valid device for node.
```

This leads to clunky practices of encoding labels outside of TF before `one_hot` can be used, which is problematic in graph mode:

```python
from sklearn.preprocessing import LabelEncoder

classes = tf.constant([""a"", ""b"", ""c""]).numpy()  # problematic with graph mode
le = LabelEncoder().fit(classes)

>>> tf.one_hot(le.transform(classes), depth=3)
<tf.Tensor: shape=(3, 3), dtype=float32, numpy=
array([[1., 0., 0.],
       [0., 1., 0.],
       [0., 0., 1.]], dtype=float32)>
```

Can `tf.one_hot` be adapted to support string input with a vocabulary given a priori?

**Will this change the current api? How?**
It will add type support, but shouldn't change the API.

**Who will benefit with this feature?**
ML developers.
"
39026,C-API input tensor type of all run functions,"**System information**

- all platform: C-API
- version R2.2, R2.1, R2.0

**Describe the current behavior**

The C-API has two types for input and output tensor, no real difference just naming, but it is disturbing to use the prefix ""output"" for an ""input""

In the C API tensor API  has two types: input and ouput

```
// Represents a specific input of an operation.
typedef struct TF_Input {
  TF_Operation* oper;
  int index;  // The index of the input within oper.
} TF_Input;

// Represents a specific output of an operation.
typedef struct TF_Output {
  TF_Operation* oper;
  int index;  // The index of the output within oper.
} TF_Output;
```

However all the run session function has the following signature 

```
TF_CAPI_EXPORT extern void TF_SessionRun(
    TF_Session* session,
    // RunOptions
    const TF_Buffer* run_options,
    // Input tensors
    const TF_Output* inputs, TF_Tensor* const* input_values, int ninputs,
    // Output tensors
    const TF_Output* outputs, TF_Tensor** output_values, int noutputs,
        // Target operations
    const TF_Operation* const* target_opers, int ntargets,
    // RunMetadata
    TF_Buffer* run_metadata,
    // Output status
    TF_Status*);
```

Although `TF_Output*` type for input does not change anything, it is a bit disturbing to use an output convention name for an input 

**Describe the expected behavior**

API for the input should change `TF_Input` instead of `TF_Output`

```
TF_CAPI_EXPORT extern void TF_SessionRun(
    TF_Session* session,
    // RunOptions
    const TF_Buffer* run_options,
    // Input tensors
    const TF_Input* inputs, TF_Tensor* const* input_values, int ninputs,
    // Output tensors
    const TF_Output* outputs, TF_Tensor** output_values, int noutputs,
        // Target operations
    const TF_Operation* const* target_opers, int ntargets,
    // RunMetadata
    TF_Buffer* run_metadata,
    // Output status
    TF_Status*);
```

**Standalone code to reproduce the issue**

https://github.com/tensorflow/tensorflow/blob/master/tensorflow/c/c_api.h 

**Other info / logs** 

The change is cosmetic, but make more sense. I may miss something behind the current logic. all the best.
"
39025,Linker errors in individual TensorFlow Lite OpenGL delegate op tests for android_arm64,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS Mojave 10.14.06
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: OnePlus 6 (Android 10, OxygenOS 10.3.2)
- TensorFlow installed from (source or binary): using source
- TensorFlow version:  master, commit 277fa1bbd1ffa0a54b9a4fba51fb951033ce0eca
- Python version: 2.7.16
- Installed using virtualenv? pip? conda?: not installed
- Bazel version (if compiling from source): 2.0.0
- GCC/Compiler version (if compiling from source): Apple clang version 11.0.0 (clang-1100.0.33.12)
- CUDA/cuDNN version: none
- GPU model and memory: AMD Radeon R9 M370X 2 GB



**Describe the problem**
I cannot seem to build any of the *_test targets in tensorflow/lite/delegates/gpu/gl/kernels for Android arm64. It results in the errors shown in the long log at the bottom of this post.
I have tried adding `linkopts = [""-ldl"", ""-lm""]` to the target (resize_test), which results in a successful build, but attempting to run it on a device results in this error:
`adb shell /data/local/tmp/resize_test
WARNING: linker: Warning: unable to normalize ""$EXEC_ORIGIN/../../../../../../_solib_arm64-v8a/"" (ignoring)
WARNING: linker: Warning: unable to normalize ""$EXEC_ORIGIN/../../../../../../_solib___Caarch64-linux-android-clang7.0.2-libcpp/"" (ignoring)
WARNING: linker: Warning: unable to normalize ""$EXEC_ORIGIN/_solib___Caarch64-linux-android-clang7.0.2-libcpp/"" (ignoring)
CANNOT LINK EXECUTABLE ""/data/local/tmp/resize_test"": library ""libtensorflow_Slite_Sdelegates_Sgpu_Sgl_Skernels_Slibresize.so"" not found`

Trying to build for android_arm (32-bit) builds successfully without the linkopts change, but it results in a similar CANNOT LINK EXECUTABLE error:

`adb shell /data/local/tmp/resize_test_
WARNING: linker: Warning: unable to normalize ""$EXEC_ORIGIN/../../../../../../_solib_armeabi-v7a/"" (ignoring)
WARNING: linker: Warning: unable to normalize ""$EXEC_ORIGIN/../../../../../../_solib___Carm-linux-androideabi-clang7.0.2-v7a-libcpp/"" (ignoring)
WARNING: linker: Warning: unable to normalize ""$EXEC_ORIGIN/_solib___Carm-linux-androideabi-clang7.0.2-v7a-libcpp/"" (ignoring)
CANNOT LINK EXECUTABLE ""/data/local/tmp/resize_test_"": library ""libtensorflow_Slite_Sdelegates_Sgpu_Sgl_Skernels_Slibresize.so"" not found`

I am trying to add custom gpu ops, and need to be able to run similar tests for debugging.

**Provide the exact sequence of commands / steps that you executed before running into the problem**

`bazel build -s -c opt --config=android_arm64 tensorflow/lite/delegates/gpu/gl/kernels:resize_test`

**Any other info / logs**
`bazel build -s -c opt --config=android_arm64 tensorflow/lite/delegates/gpu/gl/kernels:resize_test
INFO: Options provided by the client:
  Inherited 'common' options: --isatty=1 --terminal_columns=272
INFO: Reading rc options for 'build' from /Users/valentinmiu/2019/tensorflow/.bazelrc:
  Inherited 'common' options: --experimental_repo_remote_exec
INFO: Reading rc options for 'build' from /Users/valentinmiu/2019/tensorflow/.bazelrc:
  'build' options: --apple_platform_type=macos --define framework_shared_object=true --define open_source_build=true --java_toolchain=//third_party/toolchains/java:tf_java_toolchain --host_java_toolchain=//third_party/toolchains/java:tf_java_toolchain --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --noincompatible_prohibit_aapt1 --enable_platform_specific_config --config=v2
INFO: Reading rc options for 'build' from /Users/valentinmiu/2019/tensorflow/.tf_configure.bazelrc:
  'build' options: --host_force_python=PY2 --action_env PYTHON_BIN_PATH=/usr/bin/python --action_env PYTHON_LIB_PATH=/Library/Python/2.7/site-packages --python_path=/usr/bin/python --config=xla --action_env ANDROID_NDK_HOME=/Users/valentinmiu/Downloads/android-ndk-r18b --action_env ANDROID_NDK_API_LEVEL=21 --action_env ANDROID_BUILD_TOOLS_VERSION=28.0.3 --action_env ANDROID_SDK_API_LEVEL=28 --action_env ANDROID_SDK_HOME=/Users/valentinmiu/library/Android/Sdk --action_env TF_CONFIGURE_IOS=1
INFO: Found applicable config definition build:v2 in file /Users/valentinmiu/2019/tensorflow/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1
INFO: Found applicable config definition build:xla in file /Users/valentinmiu/2019/tensorflow/.bazelrc: --action_env=TF_ENABLE_XLA=1 --define=with_xla_support=true
INFO: Found applicable config definition build:android_arm64 in file /Users/valentinmiu/2019/tensorflow/.bazelrc: --config=android --cpu=arm64-v8a --fat_apk_cpu=arm64-v8a
INFO: Found applicable config definition build:android in file /Users/valentinmiu/2019/tensorflow/.bazelrc: --crosstool_top=//external:android/crosstool --host_crosstool_top=@bazel_tools//tools/cpp:toolchain
INFO: Found applicable config definition build:macos in file /Users/valentinmiu/2019/tensorflow/.bazelrc: --copt=-w --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --cxxopt=-std=c++14 --host_cxxopt=-std=c++14
INFO: Analyzed target //tensorflow/lite/delegates/gpu/gl/kernels:resize_test (1 packages loaded, 92 targets configured).
INFO: Found 1 target...
SUBCOMMAND: # //tensorflow/lite/delegates/gpu/gl/kernels:resize_test [action 'Linking tensorflow/lite/delegates/gpu/gl/kernels/resize_test', configuration: 44182232d54477a9f9dc3ac6d26e592e936a6eb23e121761b47c234d0221e035]
(cd /private/var/tmp/_bazel_valentinmiu/94cd6c8db58787268db4435bda1fd58c/execroot/org_tensorflow && \
  exec env - \
    ANDROID_BUILD_TOOLS_VERSION=28.0.3 \
    ANDROID_NDK_API_LEVEL=21 \
    ANDROID_NDK_HOME=/Users/valentinmiu/Downloads/android-ndk-r18b \
    ANDROID_SDK_API_LEVEL=28 \
    ANDROID_SDK_HOME=/Users/valentinmiu/library/Android/Sdk \
    PATH=/usr/local/opt/qt/bin:/usr/local/opt/qt/bin:/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin:/usr/local/share/dotnet:/Users/valentinmiu/.dotnet/tools:/Library/Frameworks/Mono.framework/Versions/Current/Commands:/Users/valentinmiu/Library/Android/sdk/tools:/Users/valentinmiu/Library/Android/sdk/platform-tools \
    PWD=/proc/self/cwd \
    PYTHON_BIN_PATH=/usr/bin/python \
    PYTHON_LIB_PATH=/Library/Python/2.7/site-packages \
    TF2_BEHAVIOR=1 \
    TF_CONFIGURE_IOS=1 \
    TF_ENABLE_XLA=1 \
  external/androidndk/ndk/toolchains/llvm/prebuilt/darwin-x86_64/bin/clang -o bazel-out/arm64-v8a-opt/bin/tensorflow/lite/delegates/gpu/gl/kernels/resize_test '-Wl,-rpath,$EXEC_ORIGIN/../../../../../../_solib_arm64-v8a/' '-Wl,-rpath,$EXEC_ORIGIN/../../../../../../_solib___Caarch64-linux-android-clang7.0.2-libcpp/' '-Wl,-rpath,$EXEC_ORIGIN/_solib___Caarch64-linux-android-clang7.0.2-libcpp/' -Lbazel-out/arm64-v8a-opt/bin/_solib_arm64-v8a -Lbazel-out/arm64-v8a-opt/bin/_solib___Caarch64-linux-android-clang7.0.2-libcpp bazel-out/arm64-v8a-opt/bin/tensorflow/lite/delegates/gpu/gl/kernels/_objs/resize_test/resize_test.o -ltensorflow_Slite_Sdelegates_Sgpu_Sgl_Skernels_Slibresize -ltensorflow_Slite_Sdelegates_Sgpu_Sgl_Skernels_Slibtest_Uutil -ltensorflow_Slite_Sdelegates_Sgpu_Sgl_Slibapi -ltensorflow_Slite_Sdelegates_Sgpu_Sgl_Slibcompiler -ltensorflow_Slite_Sdelegates_Sgpu_Sgl_Slibfloat16_Uconversions -ltensorflow_Slite_Sdelegates_Sgpu_Sgl_Scompiler_Slibfuse_Uauto_Uinput -ltensorflow_Slite_Sdelegates_Sgpu_Sgl_Scompiler_Slibfuse_Uinline -ltensorflow_Slite_Sdelegates_Sgpu_Sgl_Scompiler_Slibfuse_Uinplace -ltensorflow_Slite_Sdelegates_Sgpu_Scommon_Slibmodel_Utransformer -ltensorflow_Slite_Sdelegates_Sgpu_Sgl_Scompiler_Slibshader_Ucodegen -ltensorflow_Slite_Sdelegates_Sgpu_Sgl_Scompiler_Slibcompiled_Unode -ltensorflow_Slite_Sdelegates_Sgpu_Sgl_Scompiler_Slibrename -ltensorflow_Slite_Sdelegates_Sgpu_Sgl_Scompiler_Slibobject_Uaccessor -ltensorflow_Slite_Sdelegates_Sgpu_Sgl_Scompiler_Slibvariable_Uaccessor -ltensorflow_Slite_Sdelegates_Sgpu_Sgl_Scompiler_Slibpreprocessor -ltensorflow_Slite_Sdelegates_Sgpu_Sgl_Slibruntime -ltensorflow_Slite_Sdelegates_Sgpu_Sgl_Slibcommand_Uqueue -ltensorflow_Slite_Sdelegates_Sgpu_Sgl_Slibgl_Usync -ltensorflow_Slite_Sdelegates_Sgpu_Sgl_Slibgl_Uprogram -ltensorflow_Slite_Sdelegates_Sgpu_Sgl_Slibgl_Ushader -ltensorflow_Slite_Sdelegates_Sgpu_Scommon_Slibmemory_Umanagement -lexternal_Scom_Ugoogle_Uabsl_Sabsl_Scontainer_Slibraw_Uhash_Uset -lexternal_Scom_Ugoogle_Uabsl_Sabsl_Scontainer_Slibhashtablez_Usampler -lexternal_Scom_Ugoogle_Uabsl_Sabsl_Sbase_Slibexponential_Ubiased -lexternal_Scom_Ugoogle_Uabsl_Sabsl_Ssynchronization_Slibsynchronization -lexternal_Scom_Ugoogle_Uabsl_Sabsl_Ssynchronization_Slibgraphcycles_Uinternal -lexternal_Scom_Ugoogle_Uabsl_Sabsl_Stime_Slibtime -lexternal_Scom_Ugoogle_Uabsl_Sabsl_Stime_Sinternal_Scctz_Slibtime_Uzone -lexternal_Scom_Ugoogle_Uabsl_Sabsl_Stime_Sinternal_Scctz_Slibcivil_Utime -ltensorflow_Slite_Sdelegates_Sgpu_Sgl_Slibserialization -lexternal_Sflatbuffers_Ssrc_Slibflatbuffers -ltensorflow_Slite_Sdelegates_Sgpu_Sgl_Slibegl_Uenvironment -ltensorflow_Slite_Sdelegates_Sgpu_Sgl_Slibegl_Ucontext -ltensorflow_Slite_Sdelegates_Sgpu_Sgl_Slibegl_Usurface -ltensorflow_Slite_Sdelegates_Sgpu_Sgl_Slibobject_Umanager -ltensorflow_Slite_Sdelegates_Sgpu_Sgl_Slibgl_Ubuffer -ltensorflow_Slite_Sdelegates_Sgpu_Sgl_Slibgl_Utexture -ltensorflow_Slite_Sdelegates_Sgpu_Scommon_Slibconvert -ltensorflow_Slite_Sdelegates_Sgpu_Sgl_Slibrequest_Ugpu_Uinfo -ltensorflow_Slite_Sdelegates_Sgpu_Sgl_Slibgl_Uerrors -ltensorflow_Slite_Sdelegates_Sgpu_Sgl_Sworkgroups_Slibdefault_Ucalculator -ltensorflow_Slite_Sdelegates_Sgpu_Sgl_Sworkgroups_Slibcalculator -ltensorflow_Slite_Sdelegates_Sgpu_Scommon_Slibgpu_Uinfo -lexternal_Scom_Ugoogle_Ugoogletest_Slibgtest_Umain -ltensorflow_Slite_Sdelegates_Sgpu_Scommon_Sliboperations -ltensorflow_Slite_Sdelegates_Sgpu_Scommon_Slibmodel -ltensorflow_Slite_Sdelegates_Sgpu_Scommon_Slibdata_Utype -lexternal_Scom_Ugoogle_Uabsl_Sabsl_Stypes_Slibbad_Uany_Ucast_Uimpl -ltensorflow_Slite_Sdelegates_Sgpu_Scommon_Slibshape -lexternal_Scom_Ugoogle_Uabsl_Sabsl_Shash_Slibhash -lexternal_Scom_Ugoogle_Uabsl_Sabsl_Shash_Slibcity -lexternal_Scom_Ugoogle_Uabsl_Sabsl_Sstatus_Slibstatus -lexternal_Scom_Ugoogle_Uabsl_Sabsl_Sdebugging_Slibstacktrace -lexternal_Scom_Ugoogle_Uabsl_Sabsl_Sdebugging_Slibsymbolize -lexternal_Scom_Ugoogle_Uabsl_Sabsl_Sdebugging_Slibdebugging_Uinternal -lexternal_Scom_Ugoogle_Uabsl_Sabsl_Sdebugging_Slibdemangle_Uinternal -lexternal_Scom_Ugoogle_Uabsl_Sabsl_Sbase_Slibmalloc_Uinternal -lexternal_Scom_Ugoogle_Uabsl_Sabsl_Sstrings_Slibcord -lexternal_Scom_Ugoogle_Uabsl_Sabsl_Sstrings_Slibstr_Uformat_Uinternal -lexternal_Scom_Ugoogle_Uabsl_Sabsl_Sstrings_Slibstrings -lexternal_Scom_Ugoogle_Uabsl_Sabsl_Sstrings_Slibinternal -lexternal_Scom_Ugoogle_Uabsl_Sabsl_Sbase_Slibbase -lexternal_Scom_Ugoogle_Uabsl_Sabsl_Sbase_Slibdynamic_Uannotations -lexternal_Scom_Ugoogle_Uabsl_Sabsl_Sbase_Slibspinlock_Uwait -lexternal_Scom_Ugoogle_Uabsl_Sabsl_Snumeric_Slibint128 -lexternal_Scom_Ugoogle_Uabsl_Sabsl_Sbase_Slibthrow_Udelegate -lexternal_Scom_Ugoogle_Uabsl_Sabsl_Stypes_Slibbad_Uoptional_Uaccess -lexternal_Scom_Ugoogle_Uabsl_Sabsl_Stypes_Slibbad_Uvariant_Uaccess -lexternal_Scom_Ugoogle_Uabsl_Sabsl_Sbase_Slibraw_Ulogging_Uinternal -lexternal_Scom_Ugoogle_Uabsl_Sabsl_Sbase_Sliblog_Useverity -lexternal_Scom_Ugoogle_Ugoogletest_Slibgtest -lc++_shared -lEGL -lGLESv3 -pthread -pthread -pthread -pthread -static-libgcc -gcc-toolchain external/androidndk/ndk/toolchains/aarch64-linux-android-4.9/prebuilt/darwin-x86_64 -target aarch64-none-linux-android -no-canonical-prefixes -Lexternal/androidndk/ndk/sources/cxx-stl/llvm-libc++/libs/arm64-v8a '--sysroot=external/androidndk/ndk/platforms/android-21/arch-arm64')
ERROR: /Users/valentinmiu/2019/tensorflow/tensorflow/lite/delegates/gpu/gl/kernels/BUILD:712:1: Linking of rule '//tensorflow/lite/delegates/gpu/gl/kernels:resize_test' failed (Exit 1)
bazel-out/arm64-v8a-opt/bin/_solib_arm64-v8a/libexternal_Scom_Ugoogle_Uabsl_Sabsl_Sstrings_Slibstrings.so: undefined reference to `nan'
bazel-out/arm64-v8a-opt/bin/_solib_arm64-v8a/libexternal_Scom_Ugoogle_Uabsl_Sabsl_Sbase_Slibexponential_Ubiased.so: undefined reference to `log2'
bazel-out/arm64-v8a-opt/bin/_solib_arm64-v8a/libexternal_Scom_Ugoogle_Uabsl_Sabsl_Sstrings_Slibstr_Uformat_Uinternal.so: undefined reference to `frexpf'
bazel-out/arm64-v8a-opt/bin/_solib_arm64-v8a/libexternal_Scom_Ugoogle_Uabsl_Sabsl_Sstrings_Slibstr_Uformat_Uinternal.so: undefined reference to `frexpl'
bazel-out/arm64-v8a-opt/bin/_solib_arm64-v8a/libexternal_Scom_Ugoogle_Uabsl_Sabsl_Stime_Slibtime.so: undefined reference to `modf'
bazel-out/arm64-v8a-opt/bin/_solib_arm64-v8a/libexternal_Scom_Ugoogle_Uabsl_Sabsl_Sstrings_Slibstr_Uformat_Uinternal.so: undefined reference to `frexp'
bazel-out/arm64-v8a-opt/bin/_solib_arm64-v8a/libexternal_Sflatbuffers_Ssrc_Slibflatbuffers.so: undefined reference to `acos'
bazel-out/arm64-v8a-opt/bin/_solib_arm64-v8a/libexternal_Sflatbuffers_Ssrc_Slibflatbuffers.so: undefined reference to `sin'
bazel-out/arm64-v8a-opt/bin/_solib_arm64-v8a/libexternal_Scom_Ugoogle_Uabsl_Sabsl_Sstrings_Slibstrings.so: undefined reference to `nanf'
bazel-out/arm64-v8a-opt/bin/_solib_arm64-v8a/libexternal_Sflatbuffers_Ssrc_Slibflatbuffers.so: undefined reference to `atan'
bazel-out/arm64-v8a-opt/bin/_solib_arm64-v8a/libexternal_Sflatbuffers_Ssrc_Slibflatbuffers.so: undefined reference to `asin'
bazel-out/arm64-v8a-opt/bin/_solib_arm64-v8a/libexternal_Sflatbuffers_Ssrc_Slibflatbuffers.so: undefined reference to `tan'
bazel-out/arm64-v8a-opt/bin/_solib_arm64-v8a/libexternal_Sflatbuffers_Ssrc_Slibflatbuffers.so: undefined reference to `cos'
bazel-out/arm64-v8a-opt/bin/_solib_arm64-v8a/libexternal_Scom_Ugoogle_Uabsl_Sabsl_Snumeric_Slibint128.so: undefined reference to `truncl'
bazel-out/arm64-v8a-opt/bin/_solib_arm64-v8a/libexternal_Scom_Ugoogle_Uabsl_Sabsl_Sstrings_Slibstr_Uformat_Uinternal.so: undefined reference to `ldexpl'
bazel-out/arm64-v8a-opt/bin/_solib_arm64-v8a/libexternal_Scom_Ugoogle_Uabsl_Sabsl_Sstrings_Slibstr_Uformat_Uinternal.so: undefined reference to `ldexpf'
clang: error: linker command failed with exit code 1 (use -v to see invocation)
Target //tensorflow/lite/delegates/gpu/gl/kernels:resize_test failed to build
Use --verbose_failures to see the command lines of failed build steps.
INFO: Elapsed time: 0.722s, Critical Path: 0.28s
INFO: 0 processes.
FAILED: Build did NOT complete successfully`

Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
39024,[TFLite] Failed to create Hexagon delegate on Pixel 3,"This template is for miscellaneous issues not covered by the other issue categories.

For questions on how to work with TensorFlow, or support for problems that are not verified bugs in TensorFlow, please go to [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).

If you are reporting a vulnerability, please use the [dedicated reporting process](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md).

For high-level discussions about TensorFlow, please post to discuss@tensorflow.org, for questions about the development or internal workings of TensorFlow, or if you would like to know how to contribute to TensorFlow, please post to developers@tensorflow.org.
#
* Device information
```
$ adb shell getprop ro.product.device
blueline
$ adb shell getprop ro.board.platform
sdm845
```
* ($APP_ROOT)/app/src/main/jniLibs
```
.
├── arm64-v8a
│   ├── libhexagon_nn_skel.so
│   ├── libhexagon_nn_skel_v65.so
│   └── libhexagon_nn_skel_v66.so
└── armeabi-v7a
    ├── libhexagon_nn_skel.so
    ├── libhexagon_nn_skel_v65.so
    └── libhexagon_nn_skel_v66.so
```

* ($APP_ROOT)/app/build.gradle
```
apply plugin: 'com.android.application'

android {
    compileSdkVersion 28
    defaultConfig {
        applicationId ""org.tensorflow.lite.examples.classification""
        minSdkVersion 21
        targetSdkVersion 28
        versionCode 1
        versionName ""1.0""
    }
    buildTypes {
        release {
            minifyEnabled false
            proguardFiles getDefaultProguardFile('proguard-android.txt'), 'proguard-rules.pro'
        }
    }
    aaptOptions {
        noCompress ""tflite""
    }
    compileOptions {
        sourceCompatibility = '1.8'
        targetCompatibility = '1.8'
    }
}

repositories {
    flatDir {
        dirs 'libs'
    }
}

// Download default models; if you wish to use your own models then
// place them in the ""assets"" directory and comment out this line.
apply from:'download.gradle'

dependencies {
    implementation fileTree(dir: 'libs', include: ['*.jar'])
    implementation 'com.android.support:appcompat-v7:28.0.0'
    implementation 'com.android.support:design:28.0.0'

    // Build off of nightly TensorFlow Lite
    implementation 'org.tensorflow:tensorflow-lite:0.0.0-nightly'
    implementation 'org.tensorflow:tensorflow-lite-hexagon:0.0.0-nightly'
}
```

I followed the [TensorFlow Lite Hexagon delegate](https://www.tensorflow.org/lite/performance/hexagon_delegate) guide on Pixel 3. Tensorflow Lite was failed to create Hexagon delegate.

* Log
```
W/inference: type=1400 audit(0.0:127864): avc: denied { search } for name=""soc0"" dev=""sysfs"" ino=66478 scontext=u:r:untrusted_app_27:s0:c190,c256,c512,c768 tcontext=u:object_r:sysfs_soc:s0 tclass=dir permissive=0
D/org.tensorflow.lite.examples.classification: vendor/qcom/proprietary/commonsys-intf/adsprpc/src/fastrpc_apps_user.c:1615: Error: Device node open failed for domain 3 (errno Permission denied)
D/org.tensorflow.lite.examples.classification: vendor/qcom/proprietary/commonsys-intf/adsprpc/src/fastrpc_apps_user.c:1916: Error 0x57: apps_dev_init failed for domain 3, errno Permission denied
D/org.tensorflow.lite.examples.classification: vendor/qcom/proprietary/commonsys-intf/adsprpc/src/fastrpc_apps_user.c:2009: Error 0x57: open_dev (-1) failed for domain 3
D/org.tensorflow.lite.examples.classification: vendor/qcom/proprietary/commonsys-intf/adsprpc/src/fastrpc_apps_user.c:1179: Error 0x3b: remote_handle_control_domain failed for request ID 1 on domain 3
D/org.tensorflow.lite.examples.classification: vendor/qcom/proprietary/commonsys-intf/adsprpc/src/fastrpc_apps_user.c:1190: Error 0x3b: remote_handle_control failed for request ID 1
W/tflite: Failed to fetch Hexagon NN version. This might be because you're using incompatible versions of libhexagon_interface and libhexagon_nn_skel. You must use compatible versions. Refer to Tensorflow Lite Hexagon Delegate Guide.
I/tflite: Hexagon Delegate is not supported.
W/System.err: java.lang.UnsupportedOperationException: This Device doesn't support Hexagon DSP execution.
W/System.err:     at org.tensorflow.lite.experimental.HexagonDelegate.<init>(HexagonDelegate.java:40)
W/System.err:     at org.tensorflow.lite.examples.classification.tflite.Classifier.<init>(Classifier.java:182)
W/System.err:     at org.tensorflow.lite.examples.classification.tflite.ClassifierQuantizedMobileNet.<init>(ClassifierQuantizedMobileNet.java:37)
W/System.err:     at org.tensorflow.lite.examples.classification.tflite.Classifier.create(Classifier.java:97)
W/System.err:     at org.tensorflow.lite.examples.classification.ClassifierActivity.recreateClassifier(ClassifierActivity.java:167)
W/System.err:     at org.tensorflow.lite.examples.classification.ClassifierActivity.lambda$onInferenceConfigurationChanged$0(ClassifierActivity.java:146)
W/System.err:     at org.tensorflow.lite.examples.classification.-$$Lambda$ClassifierActivity$83lGy2TUjuj0M5n4BhMB9qlLgSY.run(Unknown Source:8)
W/System.err:     at android.os.Handler.handleCallback(Handler.java:883)
W/System.err:     at android.os.Handler.dispatchMessage(Handler.java:100)
W/System.err:     at android.os.Looper.loop(Looper.java:214)
W/System.err:     at android.os.HandlerThread.run(HandlerThread.java:67)
```"
39021,Buggy behaviour of dataset API,"**System information**
- Have I written custom code: yes, see [https://colab.research.google.com/drive/1AeVRilpcGp8zb0hZijTIxGWdL9GkzfN_](https://colab.research.google.com/drive/1AeVRilpcGp8zb0hZijTIxGWdL9GkzfN_)
- OS Platform and Distribution: Google Colab (Ubuntu 18.04.3 LTS)
- TensorFlow installed from (source or binary): provided by Colab
- TensorFlow version (use command below): 2.2.0-rc3
- Python version: 3.6.9

**Describe the current behavior**
At Dataset graph branching points, the node, which is the root of the branching is resampled for each branch during one round of execution. With non-randomized inputs to the Dataset, this does not cause any problems. If the root node is after a .shuffle() call, the branches will receive different inputs in the same computation round. 

**Describe the expected behavior**
Downstream branches should receive the same data even if shuffle() is applied.

**Standalone code to reproduce the issue**
[https://colab.research.google.com/drive/1AeVRilpcGp8zb0hZijTIxGWdL9GkzfN_](https://colab.research.google.com/drive/1AeVRilpcGp8zb0hZijTIxGWdL9GkzfN_)

**More info**:

This behaviour is also present if the dataset is created from a generator, which handles the shuffling implicitly.

Edit: fixed the links here as well"
39020,"Micro kernel elementwise math ops issues (abs, sin, cos, log, sqrt, tanh)","@tensorflow/micro


The math ops in [elementwise.cc](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/kernels/elementwise.cc) seem a little askew.

Firstly AbsEval, which calls `std::abs`
```
TfLiteStatus AbsEval(TfLiteContext* context, TfLiteNode* node) {
  return EvalNumeric(context, node, std::abs);
}
```
The math.h `int abs(int j)` is an integer function, what is probably intended is `fabs`, or better still `float fabsf(float x)` : return the absolute value of the floating-point number x.

The other float operations are actually referencing the double valued functions, e.g.
```
TfLiteStatus SinEval(TfLiteContext* context, TfLiteNode* node) {
  return EvalNumeric(context, node, std::sin);
}
```
would be better referencing `std::sinf`, which is the float-valued counterpart. Same for `cosf`, `logf`, and `sqrtf`.

Unfortunately changing e.g. `std::cos` to `std::cosf` will not compile on gcc, due to [an issue](https://stackoverflow.com/questions/55458487/stdexpf-and-stdlogf-not-recognized-by-gcc-7-2-0) in the `<cmath>` header. So to make it compile with gcc-based compilers the include should be changed to `#include <math.h>` and the functions referenced without `std::` prefix.

I will make a PR that also includes the TANH op."
39019,bug with _VALID_SCOPE_NAME_REGEX,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  mac 10.13.5
- TensorFlow version (use command below):  1.11.0
- Python version:  3.6.5

**Describe the current behavior**
The `_VALID_SCOPE_NAME_REGEX` and `_VALID_OP_NAME_REGEX` are defined in line 1583 of `tensorflow/python/framework/ops.py`

```
_VALID_OP_NAME_REGEX = re.compile(""^[A-Za-z0-9.][A-Za-z0-9_.\\-/]*$"")
_VALID_SCOPE_NAME_REGEX = re.compile(""^[A-Za-z0-9_.\\-/]*$"")
```
which should recognize the `\` symbol.

The result are: 
```
>>> _VALID_SCOPE_NAME_REGEX = re.compile(""^[A-Za-z0-9_.\\-/]*$"")
>>> _VALID_SCOPE_NAME_REGEX.match(""n_CatCntc_campaign/c_campaign"")
<_sre.SRE_Match object; span=(0, 29), match='n_CatCntc_campaign/c_campaign'>
>>> _VALID_SCOPE_NAME_REGEX.match(""n_CatCntc_campaign\c_campaign"")
>>> _VALID_SCOPE_NAME_REGEX.match(""n_CatCntc_campaign\\c_campaign"")
>>> _VALID_SCOPE_NAME_REGEX.match(""n_CatCntc_campaign\\\c_campaign"")
>>> 
```
The above pattern can't recognize `\`, but with below pattern, it works.

```
>>> _VALID_SCOPE_NAME_REGEX = re.compile(r""^[A-Za-z0-9_.\\\-/]*$"")
>>> _VALID_SCOPE_NAME_REGEX.match(""n_CatCntc_campaign\c_campaign"")
<_sre.SRE_Match object; span=(0, 29), match='n_CatCntc_campaign\\c_campaign'>
>>> _VALID_SCOPE_NAME_REGEX.match(""n_CatCntc_campaign\\c_campaign"")
<_sre.SRE_Match object; span=(0, 29), match='n_CatCntc_campaign\\c_campaign'>
>>> _VALID_SCOPE_NAME_REGEX.match(""n_CatCntc_campaign/c_campaign"")
<_sre.SRE_Match object; span=(0, 29), match='n_CatCntc_campaign/c_campaign'>

```

**Describe the expected behavior**


"
39018,"""file not found"" Error in generating tfrecords","Hello,
I am getting a error saying that the file or directory was not found while generating the tfrecords. I am running the code in Google Colaboratory.

- **Here is the command I am using:**

 ```command output
!cd '/content/kangaroo';python '/content/drive/My Drive/Colab Notebooks/n.py' --csv_input='/content/kangaroo/images/test_labels.csv' --image_dir='/content/kangaroo/test' --output_path='/content/kangaroo/test.record'
```

- **Here is the full traceback**
```
WARNING:tensorflow:From /content/drive/My Drive/Colab Notebooks/n.py:238: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.

WARNING:tensorflow:From /content/drive/My Drive/Colab Notebooks/n.py:223: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.

W0429 10:10:48.066490 139827938125696 module_wrapper.py:139] From /content/drive/My Drive/Colab Notebooks/n.py:223: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.

WARNING:tensorflow:From /content/drive/My Drive/Colab Notebooks/n.py:182: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.

W0429 10:10:48.075507 139827938125696 module_wrapper.py:139] From /content/drive/My Drive/Colab Notebooks/n.py:182: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.

Traceback (most recent call last):
  File ""/content/drive/My Drive/Colab Notebooks/n.py"", line 238, in <module>
    tf.app.run()
  File ""/tensorflow-1.15.2/python3.6/tensorflow_core/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""/content/drive/My Drive/Colab Notebooks/n.py"", line 228, in main
    tf_example = create_tf_example(group, path)
  File ""/content/drive/My Drive/Colab Notebooks/n.py"", line 183, in create_tf_example
    encoded_jpg = fid.read()
  File ""/tensorflow-1.15.2/python3.6/tensorflow_core/python/lib/io/file_io.py"", line 122, in read
    self._preread_check()
  File ""/tensorflow-1.15.2/python3.6/tensorflow_core/python/lib/io/file_io.py"", line 84, in _preread_check
    compat.as_bytes(self.__name), 1024 * 512)
tensorflow.python.framework.errors_impl.NotFoundError: /content/kangaroo/test/0004.jpg; No such file or directory
```

- **Here is the code I am using to generate tfrecords**
```python
""""""
Usage:
  # From tensorflow/models/
  # Create train data:
  python generate_tfrecord.py --csv_input=data/train_labels.csv  --output_path=train.record
  # Create test data:
  python generate_tfrecord.py --csv_input=data/test_labels.csv  --output_path=test.record
""""""
from __future__ import division
from __future__ import print_function
from __future__ import absolute_import

import os
import io
import pandas as pd
import tensorflow as tf

from PIL import Image
from object_detection.utils import dataset_util
from collections import namedtuple, OrderedDict

flags = tf.app.flags
flags.DEFINE_string('csv_input', '', 'Path to the CSV input')
flags.DEFINE_string('output_path', '', 'Path to output TFRecord')
flags.DEFINE_string('image_dir', '', 'Path to images')
FLAGS = flags.FLAGS


# TO-DO replace this with label map
def class_text_to_int(row_label):
    if row_label == 'A':
        return 1
    elif row_label == 'B':
        return 2
    elif row_label == 'C':
        return 3
    elif row_label == 'D':
        return 4
    elif row_label == 'E':
        return 5
    elif row_label == 'F':
        return 6
    elif row_label == 'G':
        return 7
    elif row_label == 'H':
        return 8
    elif row_label == 'I':
        return 9
    else:
        None


def split(df, group):
    data = namedtuple('data', ['filename', 'object'])
    gb = df.groupby(group)
    return [data(filename, gb.get_group(x)) for filename, x in zip(gb.groups.keys(), gb.groups)]


def create_tf_example(group, path):
    with tf.gfile.GFile(os.path.join(path, '{}'.format(group.filename)), 'rb') as fid:
        encoded_jpg = fid.read()
    encoded_jpg_io = io.BytesIO(encoded_jpg)
    image = Image.open(encoded_jpg_io)
    width, height = image.size

    filename = group.filename.encode('utf8')
    image_format = b'jpg'
    xmins = []
    xmaxs = []
    ymins = []
    ymaxs = []
    classes_text = []
    classes = []

    for index, row in group.object.iterrows():
        xmins.append(row['xmin'] / width)
        xmaxs.append(row['xmax'] / width)
        ymins.append(row['ymin'] / height)
        ymaxs.append(row['ymax'] / height)
        classes_text.append(row['class'].encode('utf8'))
        classes.append(class_text_to_int(row['class']))

    tf_example = tf.train.Example(features=tf.train.Features(feature={
        'image/height': dataset_util.int64_feature(height),
        'image/width': dataset_util.int64_feature(width),
        'image/filename': dataset_util.bytes_feature(filename),
        'image/source_id': dataset_util.bytes_feature(filename),
        'image/encoded': dataset_util.bytes_feature(encoded_jpg),
        'image/format': dataset_util.bytes_feature(image_format),
        'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),
        'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),
        'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),
        'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),
        'image/object/class/text': dataset_util.bytes_list_feature(classes_text),
        'image/object/class/label': dataset_util.int64_list_feature(classes),
    }))
    return tf_example


def main(_):
    writer = tf.python_io.TFRecordWriter(FLAGS.output_path)
    path = os.path.join(FLAGS.image_dir)
    examples = pd.read_csv(FLAGS.csv_input)
    grouped = split(examples, 'filename')
    for group in grouped:
        tf_example = create_tf_example(group, path)
        writer.write(tf_example.SerializeToString())

    writer.close()
    output_path = os.path.join(os.getcwd(), FLAGS.output_path)
    print('Successfully created the TFRecords: {}'.format(output_path))



if __name__ == '__main__':
    tf.app.run()
```
- **My Directory stucture looks something like this**
![Directory Structure](https://raw.githubusercontent.com/Monster-Gaming-Studios/hello/master/Capture.JPG)

**P.S.:-** If you want some additional information like how I generated the csv files, ask me and I will be glad to provide"
39017,Tf.reshape: allow different reshape order (e.g. column-wise),"**System information**
- TensorFlow version (you are using): '2.1.0'/ latest
- Are you willing to contribute it (Yes/No): Yes

**Describe the feature and the current behavior/state.**

Currently, tf.reshape returns a new tf.Tensor(tensor, shape, name=None) that has the same values as tensor **in the same order**, except with a new shape given by shape ([see tf.reshape](https://www.tensorflow.org/api_docs/python/tf/reshape)).

However, in some cases it would be beneficial to adjust the ordering; e.g. [np.reshape](https://docs.scipy.org/doc/numpy/reference/generated/numpy.reshape.html) allows ‘C’, ‘F’, ‘A’ orders - I am in particular interested in column-wise order. 

**For example:** Given a tf.Tensor with multiple image patches (denoted by seq_len) of shape h, w, c: `(batch_size, seq_len, h, w, c)`. I would like to concat/ reshape these image patches horizontally along axis 3 that result in shape `(batch_size, h, w * seq_len, c)`, without rearranging the pixel values within the image patches. In the **fully convolutional setting**, where seq_len varies, I can not iterate over unknown axis dimension seq_len in order to achieve this goal by e.g. using tf.split/ tf.concat (as far as I understand). Please see example below for more details.

**Will this change the current api? How?**

Yes - tf.reshape requires another optional parameter, e.g. 'order'.

**Who will benefit with this feature?**

Everyone.

**Any Other info.**

The following example shall demonstrate the desired behaviour of tf.reshape:

```
# simulate batch of image patches
x = np.arange(3 * 2 * 8).reshape(3, 2, 4, 2, 1)

# reshape/ concat image patches along axis 3
x_new = tf.reshape(x, (3, 4, 4, 1))
```

Visualize first batch sample **(current behaviour)**

```
print(x_new[0, :, :, 0])
<tf.Tensor: shape=(4, 4), dtype=int64, numpy=
array([[ 0,  1,  2,  3],
       [ 4,  5,  6,  7],
       [ 8,  9, 10, 11],
       [12, 13, 14, 15]])>
```

Visualize first batch sample **(desired behaviour)**

```
<tf.Tensor: shape=(4, 4), dtype=int64, numpy=
array([[ 0, 4, 8, 12],
       [ 1, 5,  9, 13],
       [ 2, 6, 10, 14],
       [ 3, 7, 11, 15]])>
```

Please correct me if I missed something. Thanks."
39016,Increase consitency of tensorShape,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version : 2.2.0rc3 python API
- Are you willing to contribute it : No (not enough experience of tensorflow architecture)

**Describe the feature and the current behavior/state.**
Using `where` I met an unexpecting behaviour on tensor shape testing, behaviour with tensorshape differs to tensor.

`r = tf.random.uniform([2,3,4], 0, 4, dtype=tf.int32)`
`print(tf.where(r==0, 0, 1).shape)` # (2,3,4) => ok
`print(tf.where(r.shape==3, 0, 1).shape)` **() => expecting (3,)**


**Will this change the current api? How?**
Sure, but consistency will increase. Tensorshape could be considered as a kind of tensor itself

**Who will benefit with this feature?**

1. community: code will be clearer to read, the concept is the same for tensorshape & tensor
2. optimisation ?: tensorshape could be processed by tensor graph instead of python object evaluation

"
39015,Tensorflow hang in TF1.10.,"- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): centos6
- TensorFlow installed from (source or binary):source
- TensorFlow version (use command below):1.10
- Python version:2.7
- Bazel version (if compiling from source):0.15.0
- GCC/Compiler version (if compiling from source):gcc 5.3

I find data race in rendevous in TF1.10. I try to recurrence in TF1.15, but I failed, I want to confirm data race is fixed in TF1.15.
Problem is:
thread A: Normally start recv in RpcRemoteRendezvous::RecvFromRemoteAsync. It has 4 steps
**A1**. New a call.
**A2**. Register this call to waitting set.
**A3**. Add cancel function to this call('opts_).
**A4**. Start Recv
thread B: run abort in BaseRemoteRendezvous::StartAbort.

Normal condition:
1. A call obj is waitting in thread A, then thread B forcely call all cancel function in waitting set, then this Call is cancelled.
2. Thread B forcely cancel all call objs in waitting set, then thread A try to register a call obj in queue, and failed then done and quit.

But I find a condition in TF1.10 that:
Thread A register a call obj successly,  then thread B try to cancel any call obj in waitting set, but A's call obj have no time to set cancel function, when B call this call obj 's cancel function, then thread A continue, thread A start to wait. this op don't finish forever, executor is hang.
In other words, CPU order is:
A1, A2, B, A3, A4.
Do you think this CPU order is a problem in TF1.15 ?

I notice some extra codes in TF1.15, I don't know that codes can avoid this question.
![image](https://user-images.githubusercontent.com/33950866/80574266-1c8a9c80-8a34-11ea-9cc8-daf00e41218d.png)
"
39014,TFLiteConverter doesn't support int8 quantization of PReLU,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- TensorFlow installed from (source or binary): from binary
- TensorFlow version (or github SHA if from source): 2.1

**Problem description**
TFLiteConverter doesn't support int8 quantization of PReLU. Since the PReLU is implemented as two ReLU operations, it seems that the real blocker is the negation operation as shown in the network graph picture and TFLiteConverter runtime error. Could someone check if there would be a quick fix for this problem? Thanks a lot for your help.
Cheers

**Provide the text output from tflite_convert**

```
RuntimeError: Quantization not yet supported for op: NEG
```

**Standalone code to reproduce the issue** 
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

```
import numpy as np
import tensorflow as tf
from tensorflow.keras import Model, Input
from tensorflow.keras.layers import Conv2D, PReLU, MaxPooling2D

# define dummy network
def network():
    input_shape = (600, 800, 3)
    input_tensor = Input(input_shape, name='model_input')
    x = Conv2D(10, kernel_size=(3, 3), strides=(1, 1), padding=""valid"")(input_tensor)
    x = PReLU(alpha_initializer='ones',shared_axes=[1, 2])(x)
    x = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding=""same"")(x)
    
    x = Conv2D(16, kernel_size=(3, 3), strides=(1, 1), padding=""valid"")(x)
    x = PReLU(shared_axes=[1, 2], alpha_initializer='ones')(x)
    
    x = Conv2D(32, kernel_size=(3, 3), strides=(1, 1), padding=""valid"")(x)
    x = PReLU(shared_axes=[1, 2], alpha_initializer='ones')(x)
    
    return Model(input_tensor, x)

model = network()
dummy_input = tf.random.uniform((1,600,800,3))
dummy_output = model.predict(dummy_input)

def dataset_gen():
    for i in range(100):
        img_input = 2*np.random.rand(1,600,800,3)-1
        yield [img_input.astype(np.float32)]

converter = tf.lite.TFLiteConverter.from_keras_model(model)
converter.experimental_new_converter = True
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]
converter.inference_input_type = tf.int8
converter.inference_output_type = tf.int8
converter.optimizations = [tf.lite.Optimize.DEFAULT]
converter.representative_dataset = dataset_gen
tflite_quant_model = converter.convert()

with open('dummy_model_int8.tflite', 'wb') as file:
    file.write(tflite_quant_model)
```
<img width=""274"" alt=""prelu3"" src=""https://user-images.githubusercontent.com/9253234/80573217-7d47b400-89f7-11ea-9b21-de8da0ca0475.PNG"">


Also, please include a link to a GraphDef or the model if possible.

**Any other info / logs**

Include any logs or source code that would be helpful to diagnose the problem.
If including tracebacks, please include the full traceback. Large logs and files
should be attached.
"
39013,Loading a saved multi-input model,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
I have written a simple standalone code to reproduce the error
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Colab
- TensorFlow version (use command below):
v2.2.0-rc3-0-gaad398b5e9 2.2.0-rc3
- Python version:
Python 3.6.9
- CUDA/cuDNN version:
CUDA Version 10.1.243

**Describe the current behavior**
1. I save the whole model with a ModelCheckpoint callback
2. I try to load the model from de checkpoint files
3. ```TypeError: Error converting shape to a TensorShape: Dimension value must be integer or None or have an __index__ method, got TensorShape([None, 16]).```

**Describe the expected behavior**
The model should be loaded and ready to continue training or to be used for evaluation
**Standalone code to reproduce the issue**
[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1CWRU1k2d0xtlww6hCavWHbKYb5aRrjw9)

**Other info / logs** 
```
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py in make_shape(v, arg_name)
    210   try:
--> 211     shape = tensor_shape.as_shape(v)
    212   except TypeError as e:

21 frames
TypeError: Dimension value must be integer or None or have an __index__ method, got TensorShape([None, 16])

During handling of the above exception, another exception occurred:

TypeError                                 Traceback (most recent call last)
/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py in make_shape(v, arg_name)
    211     shape = tensor_shape.as_shape(v)
    212   except TypeError as e:
--> 213     raise TypeError(""Error converting %s to a TensorShape: %s."" % (arg_name, e))
    214   except ValueError as e:
    215     raise ValueError(""Error converting %s to a TensorShape: %s."" % (arg_name,

TypeError: Error converting shape to a TensorShape: Dimension value must be integer or None or have an __index__ method, got TensorShape([None, 16]).
```"
39012,gher,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below):
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**

**Describe the expected behavior**

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
39009,Custom Constraint not working,"I created a custom constraint using [this](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/constraints.py) which forces the sum of the elements to have sum(axis=1) to be one and be NonNeg at the same time, 
```
class SumConstraint(Constraint):
    def __init__(self, axis):
        super(SumConstraint, self).__init__()
        self.axis = axis
    def __call__(self, w):
        w = w * K.cast(K.greater_equal(w, 0.), K.floatx())
        s = K.sum(w, axis = self.axis)
        s = s.numpy()
        for i in range(6):
            w[i]/=s[i]
        return w
    def get_config(self):
        return {'axis': self.axis}
```
But when I give, ```x = Dense(3, kernel_initializer = SumConstraint(axis = 1))```

I get, **``` ValueError: Unknown constraint: SumConstraint ```**"
39008,tf-nightly-cpu couldn't trace any graph with subclass models.,"**System information**
- Have I written custom code: Yes.
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Win 10.
- TensorFlow installed from (source or binary): pip intall tf-nightly-cpu.
- TensorFlow version (use command below):  2.2.0-dev20200426.
- Python version: 3.7.7
- Tensorboard version: 2.3.0a20200412 or 2.1.1

**Describe the current behavior**

I've created a `subclass model`, and trained it with tensorboard callback. Then I start tensorboard and select `Graphs dashboard`, but it shows error messages that `Graph visualization failed` as the picture shows：

![image](https://user-images.githubusercontent.com/15494997/80565099-3d49f680-8a22-11ea-994d-ddc55ba4ee10.png)

I've checked the issue [1961](https://github.com/tensorflow/tensorboard/issues/1961) here but didn't get any help.

By the way, `Sequential Model` could trace the graph.

**Describe the expected behavior**

Things works well when I use `tensorflow 2.1.0` with both `tensorboard 2.3.0a20200412` and `2.1.1`.
So I think `tf-nightly-cpu` should work as well.

**Standalone code to reproduce the issue**

```python
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np


class ThreeLayerMLP(keras.Model):
    def __init__(self, name=None):
        super().__init__(name=name)
        self.dense_1 = layers.Dense(64, activation='relu', name='dense_1')
        self.dense_2 = layers.Dense(64, activation='relu', name='dense_2')
        self.pred_layer = layers.Dense(10, name='predictions')

    def call(self, inputs):
        x = self.dense_1(inputs)
        x = self.dense_2(x)
        return self.pred_layer(x)


model = ThreeLayerMLP(name='3_layer_mlp')

x_train, y_train = (np.random.random(
    (60000, 784)), np.random.randint(10, size=(60000, 1)))
x_test, y_test = (np.random.random(
    (10000, 784)), np.random.randint(10, size=(10000, 1)))

model.compile(
    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),
    optimizer=keras.optimizers.RMSprop())

callback = tf.keras.callbacks.TensorBoard(
    'subclass_logs',
    update_freq=2,
)
history = model.fit(x_train,
                    y_train,
                    batch_size=64,
                    epochs=10,
                    callbacks=[callback])

```"
39007,ImportError: DLL load failed while importing _pywrap_tensorflow_internal: The specified module could not be found.,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 64-bit
- TensorFlow installed from (source or binary): 
- TensorFlow version: 20.1
- Python version: Python 3.8 (64-bit)
- Installed using virtualenv? pip? conda?: pip
- GCC/Compiler version (if compiling from source): Jupyter
- CUDA/cuDNN version:
- GPU model and memory: Intel HD graphics 620 8239 MB
- CPU Intel(R) Core(TM) i5-7300U CPU @ 2.60GHz 2.71 GHz


Python 3.8.2 (tags/v3.8.2:7b3ab59, Feb 25 2020, 23:03:10) [MSC v.1916 64 bit (AMD64)] on win32
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import tensorflow as tf
Traceback (most recent call last):
  File ""C:\Users\linj\AppData\Local\Programs\Python\Python38\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\linj\AppData\Local\Programs\Python\Python38\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\linj\AppData\Local\Programs\Python\Python38\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\linj\AppData\Local\Programs\Python\Python38\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\linj\AppData\Local\Programs\Python\Python38\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed while importing _pywrap_tensorflow_internal: The specified module could not be found.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""C:\Users\linj\AppData\Local\Programs\Python\Python38\lib\site-packages\tensorflow\__init__.py"", line 41, in <module>
    from tensorflow.python.tools import module_util as _module_util
  File ""C:\Users\linj\AppData\Local\Programs\Python\Python38\lib\site-packages\tensorflow\python\__init__.py"", line 50, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\Users\linj\AppData\Local\Programs\Python\Python38\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 69, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""C:\Users\linj\AppData\Local\Programs\Python\Python38\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\linj\AppData\Local\Programs\Python\Python38\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\linj\AppData\Local\Programs\Python\Python38\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\linj\AppData\Local\Programs\Python\Python38\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\linj\AppData\Local\Programs\Python\Python38\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed while importing _pywrap_tensorflow_internal: The specified module could not be found.


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/errors

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.
>>>
"
39006,Thread hang for Stage/MapStage op when setting inter_op_parallelism_threads=1,"**System information**

 - OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04
 - TensorFlow version (use command below): tf-nightly
 - Python version: 3.6.8

**Describe the current behavior**

Thread will hang if setting `inter_op_parallelism_threads=1`.

**Standalone code to reproduce the issue**

```python
from six.moves import queue as Queue
import threading

import tensorflow as tf
from tensorflow.python.framework import dtypes
from tensorflow.python.framework import ops
from tensorflow.python.framework.ops import disable_eager_execution
from tensorflow.python.ops import array_ops
from tensorflow.python.ops import data_flow_ops
from tensorflow.python.platform import test

disable_eager_execution()
tf.config.threading.set_inter_op_parallelism_threads(num_threads=1)  # pass if set 2


class ThreadHangTest(test.TestCase):
    """"""test Stage/MapStage""""""

    def testStage(self):
        capacity = 3
        with ops.device(test.gpu_device_name()):
            x = array_ops.placeholder(dtypes.int32, name='x')
            stager = data_flow_ops.StagingArea([dtypes.int32, ], capacity=capacity, shapes=[[]])

        queue = Queue.Queue()
        with self.session() as sess:
            def thread_run():
                for i in range(capacity + 1):
                    sess.run(stager.put([x]), feed_dict={x: i})
                    queue.put(0)

            t = threading.Thread(target=thread_run)
            t.daemon = True
            t.start()

            try:
                for i in range(capacity + 1):
                    queue.get(timeout=1)
            except Queue.Empty:
                pass

            for i in range(capacity):
                sess.run(stager.get())

    def testMapStage(self):
        capacity = 3
        with ops.device(test.gpu_device_name()):
            x = array_ops.placeholder(dtypes.int32, name='x')
            pi = array_ops.placeholder(dtypes.int64, name='pi')
            map_stager = data_flow_ops.MapStagingArea([dtypes.int32, ], capacity=capacity, shapes=[[]])

        queue = Queue.Queue()
        with self.session() as sess:
            def thread_run():
                for i in range(capacity + 1):
                    sess.run(map_stager.put(pi, [x], [0]), feed_dict={x: i, pi: i})
                    queue.put(0)

            t = threading.Thread(target=thread_run)
            t.daemon = True
            t.start()

            try:
                for i in range(capacity + 1):
                    queue.get(timeout=1)
            except Queue.Empty:
                pass

            for i in range(capacity):
                sess.run(map_stager.get())


if __name__ == '__main__':
    test.main()

```"
39004,Huber Loss crashes training loop due to data type mismatch,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): somewhat custom
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: laptop
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below): 
- Python version: 3.6.10
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source): 7.3.0
- CUDA/cuDNN version: None
- GPU model and memory: None

**Describe the current behavior**
Huber Loss crashes the script with the following error message:

> TypeError: Input 'y' of 'Mul' Op has type float64 that does not match type float32 of argument 'x'.

That happens even though I cast everything to either `tf.float32` or `tf.float64` manually. It **does** work if I put this line 
```
tf.keras.backend.set_floatx('float32')
```
Or if I remove the original line with `float64`. Seems to me like setting the global data type fails somewhere. And, I get the following warning that tensors are being re-casted automatically:
>WARNING:tensorflow:Layer dense_8 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.

**Standalone code to reproduce the issue**
```import os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'
from sklearn.datasets import load_linnerud
import tensorflow as tf
tf.keras.backend.set_floatx('float64')
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Dense, Dropout, LSTM, Concatenate

X, y = load_linnerud(return_X_y=True)

data = tf.data.Dataset.from_tensor_slices((X, y)).\
    map(lambda a, b: (tf.divide(a, tf.reduce_max(X, axis=0, keepdims=True)), b))

train_data = data.take(16).shuffle(16).batch(4)
test_data = data.skip(16).shuffle(4).batch(4)


class FullyConnectedNetwork(Model):
    def __init__(self):
        super(FullyConnectedNetwork, self).__init__()
        self.layer1 = Dense(9, input_shape=(3,))
        self.layer2 = LSTM(8, return_sequences=True)
        self.layer3 = Dense(27)
        self.layer4 = Dropout(5e-1)
        self.layer5 = Dense(27)
        self.layer6 = Concatenate()
        self.layer7 = Dense(3)

    def __call__(self, x, *args, **kwargs):
        x = tf.nn.tanh(self.layer1(x))
        y = self.layer2(x)
        x = tf.nn.selu(self.layer3(x))
        x = self.layer4(x)
        x = tf.nn.relu(self.layer5(x))
        x = self.layer6([x, y])
        x = self.layer7(x)
        return x


model = FullyConnectedNetwork()

loss_object = tf.keras.losses.Huber()

train_loss = tf.keras.metrics.Mean()
test_loss = tf.keras.metrics.Mean()

optimizer = tf.keras.optimizers.Adamax()


@tf.function
def train_step(inputs, targets):
    with tf.GradientTape() as tape:
        outputs = model(inputs)
        loss = loss_object(outputs, targets)
        train_loss(loss)

    gradients = tape.gradient(loss, model.trainable_variables)
    optimizer.apply_gradients(zip(gradients, model.trainable_variables))


@tf.function
def test_step(inputs, targets):
    outputs = model(inputs)
    print(outputs.dtype, targets.dtype)
    loss = loss_object(outputs, targets)
    test_loss(loss)


def main():
    train_loss.reset_states()
    test_loss.reset_states()

    for epoch in range(1, 10_000 + 1):
        for x, y in train_data:
            train_step(x, y)

        for x, y in test_data:
            test_step(x, y)

        if epoch % 25 == 0:
            print(f'Epoch: {epoch:>4} Train Loss: {train_loss.result().numpy():.2f} '
                  f'Test Loss: {test_loss.result().numpy():.2f}')


if __name__ == '__main__':
    main()
```
```
Traceback (most recent call last):
  File ""/home/nicolas/anaconda3/envs/condaenv/lib/python3.6/site-packages/IPython/core/interactiveshell.py"", line 3331, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File ""<ipython-input-30-b08781047662>"", line 86, in <module>
    main()
  File ""<ipython-input-30-b08781047662>"", line 75, in main
    train_step(x, y)
  File ""/home/nicolas/anaconda3/envs/condaenv/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py"", line 568, in __call__
    result = self._call(*args, **kwds)
  File ""/home/nicolas/anaconda3/envs/condaenv/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py"", line 615, in _call
    self._initialize(args, kwds, add_initializers_to=initializers)
  File ""/home/nicolas/anaconda3/envs/condaenv/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py"", line 497, in _initialize
    *args, **kwds))
  File ""/home/nicolas/anaconda3/envs/condaenv/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py"", line 2389, in _get_concrete_function_internal_garbage_collected
    graph_function, _, _ = self._maybe_define_function(args, kwargs)
  File ""/home/nicolas/anaconda3/envs/condaenv/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py"", line 2703, in _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)
  File ""/home/nicolas/anaconda3/envs/condaenv/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py"", line 2593, in _create_graph_function
    capture_by_value=self._capture_by_value),
  File ""/home/nicolas/anaconda3/envs/condaenv/lib/python3.6/site-packages/tensorflow_core/python/framework/func_graph.py"", line 978, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File ""/home/nicolas/anaconda3/envs/condaenv/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py"", line 439, in wrapped_fn
    return weak_wrapped_fn().__wrapped__(*args, **kwds)
  File ""/home/nicolas/anaconda3/envs/condaenv/lib/python3.6/site-packages/tensorflow_core/python/framework/func_graph.py"", line 968, in wrapper
    raise e.ag_error_metadata.to_exception(e)
TypeError: in converted code:
    <ipython-input-20-f2c31267a363>:54 train_step  *
        loss = loss_object(outputs, targets)
    /home/nicolas/anaconda3/envs/condaenv/lib/python3.6/site-packages/tensorflow_core/python/keras/losses.py:126 __call__
        losses = self.call(y_true, y_pred)
    /home/nicolas/anaconda3/envs/condaenv/lib/python3.6/site-packages/tensorflow_core/python/keras/losses.py:221 call
        return self.fn(y_true, y_pred, **self._fn_kwargs)
    /home/nicolas/anaconda3/envs/condaenv/lib/python3.6/site-packages/tensorflow_core/python/keras/losses.py:915 huber_loss
        math_ops.multiply(delta, linear))
    /home/nicolas/anaconda3/envs/condaenv/lib/python3.6/site-packages/tensorflow_core/python/util/dispatch.py:180 wrapper
        return target(*args, **kwargs)
    /home/nicolas/anaconda3/envs/condaenv/lib/python3.6/site-packages/tensorflow_core/python/ops/math_ops.py:334 multiply
        return gen_math_ops.mul(x, y, name)
    /home/nicolas/anaconda3/envs/condaenv/lib/python3.6/site-packages/tensorflow_core/python/ops/gen_math_ops.py:6125 mul
        ""Mul"", x=x, y=y, name=name)
    /home/nicolas/anaconda3/envs/condaenv/lib/python3.6/site-packages/tensorflow_core/python/framework/op_def_library.py:504 _apply_op_helper
        inferred_from[input_arg.type_attr]))
    TypeError: Input 'y' of 'Mul' Op has type float64 that does not match type float32 of argument 'x'.
```"
39001,'Sequential' object has no attribute '_get_save_spec',"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Google Colab
- TensorFlow installed from (source or binary): -
- TensorFlow version (or github SHA if from source): 2.2


**Command used to run the converter or code if you’re using the Python API**
https://colab.research.google.com/drive/1IJWCGMZ9Wrf8C89oLJ_AWnGPH1ea4dma

converter = tf.lite.TFLiteConverter.from_keras_model(model)

**The output from the converter invocation**
---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
<ipython-input-17-83ed6c530300> in <module>()
----> 1 converter = tf.lite.TFLiteConverter.from_keras_model(model)

1 frames
/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saving_utils.py in model_input_signature(model, keep_original_batch_size)
     75     TensorSpecs. This list does not contain the `training` argument.
     76   """"""
---> 77   input_specs = model._get_save_spec(dynamic_batch=not keep_original_batch_size)  # pylint: disable=protected-access
     78   if input_specs is None:
     79     return None

AttributeError: 'Sequential' object has no attribute '_get_save_spec'

**Failure details**
Fails to convert

**Any other info / logs**
When running the exact same code on a Windows 10 machine with TF2.1, the error is different :

D:\dev\Anaconda3\lib\site-packages\keras\engine\base_layer.py in __call__(self, inputs, **kwargs)
    487             # Actually call the layer,
    488             # collecting output(s), mask(s), and shape(s).
--> 489             output = self.call(inputs, **kwargs)
    490             output_mask = self.compute_mask(inputs, previous_mask)
    491 

TypeError: call() got an unexpected keyword argument 'training'"
38999,Does not compile on windows not even close why bother,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below):
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**

**Describe the expected behavior**

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
38998,saved keras model with custom layers supports ragged inputs cannot be loaded back,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): linux
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): TF2.2 rc3
- Python version: 3.6
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:


**Describe the current behavior**
I created a custom keras Layer that accepts ragged inputs:

```
class EmbeddingMean(tf.keras.layers.Layer):
  def __init__(self, **kwargs):
    super(EmbeddingMean, self).__init__()
    self._supports_ragged_inputs = True
  def call(self, inputs, **kwargs):
    return tf.reduce_mean(inputs, axis=1)
```
If i create a model like this:

```
feature = Input(shape=(None,), ragged=True, name='input_1', dtype=tf.int32)
embedded = Embedding(10, 3)(feature)
embedded_mean = EmbeddingMean()(embedded)
m = Model(feature, Dense(1)(embedded_mean))
```
And save the model as a keras model:
`m.save('/tmp/test')`

I cannot reload that model using 
`model_reloaded = tf.keras.models.load_model('/tmp/test')`
> ValueError: Layer embedding_mean_1 does not support RaggedTensors as input. 

If i save the model as a saved model it works correctly but i loose all the keras features.

**Describe the expected behavior**
We should be able to load back the model as expected. 

**Standalone code to reproduce the issue**
https://colab.research.google.com/gist/tanguycdls/c9b1026bbea22cca4018139f447f249c/untitled7.ipynb

**Additional Informations**
The issue seems to come from the fact that `self._supports_ragged_inputs` is not correctly saved: when we load the model the layer has the attribute set to False instead of True. "
38997,checkpoint conversion to tf2.0 question,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
ubuntu19.10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
source
- TensorFlow version (use command below):
tf2.1.0
- Python version:
python 3.7.4
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
GCC 7.3.0
- CUDA/cuDNN version:
10.1/7.6.5
- GPU model and memory:
RTX2060S 8GB

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
Hi, 
This is just a general question
I have a model which is written in tf1.x and the model is like this: 
https://github.com/CR-Ko/MegaDepth_Tensorflow/blob/master/hourglass_mega_tf_resize_bilinear_tflayer_prepost.py
It has checkpoint as well in tf1.x style. However, I have to rewrite it in TF2.1. For the rewrited 2.1 model, can I still use the TF1.X checkpoint? Or do I need use converter for the checkpoint?
https://github.com/tensorflow/estimator/blob/master/tensorflow_estimator/python/estimator/tools/checkpoint_converter.py
Also, about naming layers in rewrited 2.1 model, how should I do it to make sure correspondance between pretrain TF1.X checkpoint and rewrited TF2.1 model? 
"
38995,Object detection - Training of MobileNet-SSD,"**System information**
- OS Platform and Distribution (Windows 10 / OSX / Rapsbian):
- TensorFlow installed from (source or binary): pip install tensorflow==1.5.0
- TensorFlow version: 1.5.0
- Python version: 3.6.1
- Installed using virtualenv? pip? conda?: pip



Hi everyone,
I wanted your help to solve a problem with my project at the University. I want to recognize magpie with a Raspberry Pi to studied there behavior.
I'm doing this tutorial at this part : https://pythonprogramming.net/training-custom-objects-tensorflow-object-detection-api-tutorial/

I succeed every last command like : 

`python generate_tfrecord.py --csv_input=data/train_labels.csv --output_path=data/train.record`
`python generate_tfrecord.py --csv_input=data/test_labels.csv --output_path=data/test.record`

And I've my `train.record` et `test.record` well created in my data folder.

But after that, when I run the training, I've that error : 

```
C:\Users\ALIENWARE\Desktop\workspace\models\research\object_detection>python train.py --logtostderr --train_dir=training/ --pipeline_config_path=training/ssd_mobilenet_v1_custom.config
WARNING:tensorflow:From C:\Users\ALIENWARE\Desktop\workspace\models\research\object_detection\trainer.py:210: create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Please switch to tf.train.create_global_step
INFO:tensorflow:depth of additional conv before box predictor: 0
INFO:tensorflow:depth of additional conv before box predictor: 0
INFO:tensorflow:depth of additional conv before box predictor: 0
INFO:tensorflow:depth of additional conv before box predictor: 0
INFO:tensorflow:depth of additional conv before box predictor: 0
INFO:tensorflow:depth of additional conv before box predictor: 0
INFO:tensorflow:Summary name /clone_loss is illegal; using clone_loss instead.
WARNING:tensorflow:From C:\Python\lib\site-packages\tensorflow\contrib\slim\python\slim\learning.py:736: Supervisor.__init__ (from tensorflow.python.training.supervisor) is deprecated and will be removed in a future version.
Instructions for updating:
Please switch to tf.train.MonitoredTrainingSession
2020-04-28 21:18:30.194654: I C:\tf_jenkins\workspace\rel-win\M\windows\PY\36\tensorflow\core\platform\cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX
INFO:tensorflow:Restoring parameters from training/model.ckpt-0
2020-04-28 21:18:34.687701: W C:\tf_jenkins\workspace\rel-win\M\windows\PY\36\tensorflow\core\framework\op_kernel.cc:1198] Out of range: Read fewer bytes than requested
 
…
 
2020-04-28 21:18:34.692416: W C:\tf_jenkins\workspace\rel-win\M\windows\PY\36\tensorflow\core\framework\op_kernel.cc:1198] Out of range: Read fewer bytes than requested
2020-04-28 21:18:34.696681: W C:\tf_jenkins\workspace\rel-win\M\windows\PY\36\tensorflow\core\framework\op_kernel.cc:1198] Out of range: Read fewer bytes than requested
Traceback (most recent call last):
  File ""train.py"", line 164, in <module>
    tf.app.run()
  File ""C:\Python\lib\site-packages\tensorflow\python\platform\app.py"", line 124, in run
    _sys.exit(main(argv))
  File ""train.py"", line 160, in main
    worker_job_name, is_chief, FLAGS.train_dir)
  File ""C:\Users\ALIENWARE\Desktop\workspace\models\research\object_detection\trainer.py"", line 332, in train
    saver=saver)
  File ""C:\Python\lib\site-packages\tensorflow\contrib\slim\python\slim\learning.py"", line 746, in train
    master, start_standard_services=False, config=session_config) as sess:
  File ""C:\Python\lib\contextlib.py"", line 84, in __enter__
    raise RuntimeError(""generator didn't yield"") from None
RuntimeError: generator didn't yield

```

I tried everything, impossible to have any correction of this. I tried this on my Macbook, on the Raspberry, on Windows and still nothing.
I tried that with Python 3.5.3, 3.6.0, 3.6.1, with TensorFlow 1.4.0, 1.5.0, 1.10.0, 1.11.0, 1.12.0.

It is the final step of my project to pass my year, if someone can help me that would be amazing.

Anthony T.
"
38994,Can't load saved keras model.h5,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): pip
- TensorFlow version (use command below): 2.1.0
- Python version: 3.7
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10.2 & 10.1
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
When loading the model with keras.models.load_model the activation functions are not recognized. This happens only when activation functions are not builtin strings

**Describe the expected behavior**
To load the model with success

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

```python
import tensorflow as tf

layer = tf.keras.layers.Dense(1, activation=tf.keras.layers.PReLU(alpha_initializer='random_uniform', alpha_regularizer=None, alpha_constraint=None, shared_axes=None),\
                            name='layerX', kernel_initializer=tf.keras.initializers.he_normal())
model = tf.keras.Sequential(layer)
model.compile(""adam"", ""binary_crossentropy"", [""accuracy""])
model.fit([[1]], [1])
model.save(""keras_model.h5"", save_format='h5' "")
model = tf.keras.models.load_model(""keras_model.h5"")
```
**EDIT**: After reading the docs I saved the model with save_format h5, first time I tried without any format (the default is tf for tensorflow 2.0+)
Instead I found a workaround: I can load the model if I save it with (default) save_format='tf'

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
```Traceback (most recent call last):
  File ""C:\Users\Teo\OneDrive\Licenta\main.py"", line 138, in <module>
    main()
  File ""C:\Users\Teo\OneDrive\Licenta\main.py"", line 135, in main
    model = keras.models.load_model(os.path.join(dataset_path, ""keras_model.h5""))
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\keras\saving\save.py"", line 146, in load_model
    return hdf5_format.load_model_from_hdf5(filepath, custom_objects, compile)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\keras\saving\hdf5_format.py"", line 168, in load_model_from_hdf5
    custom_objects=custom_objects)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\keras\saving\model_config.py"", line 55, in model_from_config
    return deserialize(config, custom_objects=custom_objects)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\keras\layers\serialization.py"", line 106, in deserialize
    printable_module_name='layer')
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\keras\utils\generic_utils.py"", line 303, in deserialize_keras_object
    list(custom_objects.items())))
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\keras\engine\sequential.py"", line 377, in from_config
    custom_objects=custom_objects)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\keras\layers\serialization.py"", line 106, in deserialize
    printable_module_name='layer')
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\keras\utils\generic_utils.py"", line 305, in deserialize_keras_object
    return cls.from_config(cls_config)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\keras\engine\base_layer.py"", line 519, in from_config
    return cls(**config)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\keras\layers\core.py"", line 1082, in __init__
    self.activation = activations.get(activation)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\keras\activations.py"", line 450, in get
    identifier, printable_module_name='activation')
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\keras\utils\generic_utils.py"", line 292, in deserialize_keras_object
    config, module_objects, custom_objects, printable_module_name)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\keras\utils\generic_utils.py"", line 250, in class_and_config_for_serialized_keras_object
    raise ValueError('Unknown ' + printable_module_name + ': ' + class_name)
ValueError: Unknown activation: PReLU
```"
38993,Reshape causing segmentation fault in TFLite Python interpreter,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04 xenial
- Kernel: x86_64 Linux 4.15.0-88-generic
- Shell: zsh 5.1.1
- CPU: Intel Core i7-7800X CPU @ 4GHz
- GPU: GeForce GTX 1080 Ti, GeForce GTX 1080 Ti
- TensorFlow installed from (source or binary): binary, via conda
- TensorFlow version (or github SHA if from source): 1.15.0


**Command used to run the converter or code if you’re using the Python API**

Below is a reproducable script that creates a very simple graph that reshapes `X` that segfaults on my and my collegues devices.

```python
import numpy as np
import tensorflow as tf


def _interpreter_predict(input_data: np.ndarray, interpreter: tf.lite.Interpreter):
    """"""Run inference on the interpreter.""""""
    input_details = interpreter.get_input_details()
    output_details = interpreter.get_output_details()
    input_tensor_index = input_details[0][""index""]
    input_dtype = input_details[0][""dtype""]
    output_tensor_index = output_details[0][""index""]
    input_data = input_data.astype(input_dtype)
    interpreter.set_tensor(input_tensor_index, input_data)
    interpreter.invoke()
    return interpreter.get_tensor(output_tensor_index)


# Create a basic graph that reshapes the input (in lieu of an op such as expand dims)
input_shape = [1, 4096, 1]
with tf.Graph().as_default() as graph:
    X = tf.placeholder(shape=input_shape, dtype=tf.float32, name=""input"")
    y = tf.reshape(X, [1, 1, 4096, 1], name=""output"")
    with tf.Session(graph=graph) as sess:
        converter = tf.lite.TFLiteConverter.from_session(sess, [X], [y])
        tflite_model = converter.convert()
        with open(""mvp.tflite"", ""wb"") as stream:
            stream.write(tflite_model)

# Load models.
float32_model = tf.lite.Interpreter(model_path=""mvp.tflite"")
# Create data.
input_data = np.random.uniform(size=input_shape)
activations = _interpreter_predict(input_data, float32_model)
```

**The output from the converter invocation**
N/A - _it may be more appropraite to say this appear to be an issue with the Interpreter_

**Also, please include a link to the saved model or GraphDef**
I don't freeze the graph def, so haven't uploaded, but I'll include the tflite file `mvp.tflite` here (I've zipped it up because Github doesn't allow `.tflite` extensions to be attached)

[mvp.tflite.zip](https://github.com/tensorflow/tensorflow/files/4548044/mvp.tflite.zip)

**Failure details**

Summary:
* As mentioned, the conversion appears to be successful, but there are issues with the generated model.
* The tflite flatbuffer is successfully loaded.
* When the script gets to this line, (in `def _interpreter_predict`):

```python
    interpreter.set_tensor(input_tensor_index, input_data)
```
* We get a segfault.

**Any other info / logs**

I can also run the attached script with gdb, to inspect the stack with the command:
```bash
$ PYTHONMALLOC=malloc gdb -ex r --args python
```

There is a lot of output **(please scroll to the end to see me inspect the stack)**:
```
(dev) ➜  study_id=9156 PYTHONMALLOC=malloc gdb -ex r --args python mvp_segfault.py
GNU gdb (Ubuntu 7.11.1-0ubuntu1~16.5) 7.11.1
Copyright (C) 2016 Free Software Foundation, Inc.
License GPLv3+: GNU GPL version 3 or later <http://gnu.org/licenses/gpl.html>
This is free software: you are free to change and redistribute it.
There is NO WARRANTY, to the extent permitted by law.  Type ""show copying""
and ""show warranty"" for details.
This GDB was configured as ""x86_64-linux-gnu"".
Type ""show configuration"" for configuration details.
For bug reporting instructions, please see:
<http://www.gnu.org/software/gdb/bugs/>.
Find the GDB manual and other documentation resources online at:
<http://www.gnu.org/software/gdb/documentation/>.
For help, type ""help"".
Type ""apropos word"" to search for commands related to ""word""...
Reading symbols from python...done.
Starting program: /home/leonfedden/miniconda3/envs/dev/bin/python mvp_segfault.py
[Thread debugging using libthread_db enabled]
Using host libthread_db library ""/lib/x86_64-linux-gnu/libthread_db.so.1"".
[New Thread 0x7fff9a755700 (LWP 12246)]
WARNING:tensorflow:From mvp_segfault.py:20: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From mvp_segfault.py:22: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2020-04-28 20:30:27.108799: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
[New Thread 0x7fff98b7a700 (LWP 12249)]
2020-04-28 20:30:27.141296: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties:
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:17:00.0
2020-04-28 20:30:27.141774: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 1 with properties:
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:65:00.0
2020-04-28 20:30:27.155220: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2020-04-28 20:30:27.167354: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2020-04-28 20:30:27.175155: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2020-04-28 20:30:27.180762: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2020-04-28 20:30:27.190838: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2020-04-28 20:30:27.199906: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2020-04-28 20:30:27.211992: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-04-28 20:30:27.217731: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0, 1
2020-04-28 20:30:27.218362: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
[New Thread 0x7fff835b0700 (LWP 12250)]
[New Thread 0x7fff82daf700 (LWP 12251)]
[New Thread 0x7fff825ae700 (LWP 12252)]
[New Thread 0x7fff81dad700 (LWP 12253)]
[New Thread 0x7fff815ac700 (LWP 12254)]
[New Thread 0x7fff80dab700 (LWP 12255)]
[New Thread 0x7fff2bfff700 (LWP 12256)]
[New Thread 0x7fff2b7fe700 (LWP 12257)]
[New Thread 0x7fff2affd700 (LWP 12258)]
[New Thread 0x7fff2a7fc700 (LWP 12259)]
[New Thread 0x7fff29ffb700 (LWP 12260)]
[New Thread 0x7fff297fa700 (LWP 12261)]
[New Thread 0x7fff28ff9700 (LWP 12262)]
[New Thread 0x7fff13fff700 (LWP 12263)]
[New Thread 0x7fff137fe700 (LWP 12264)]
2020-04-28 20:30:27.246123: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3500000000 Hz
[Thread 0x7fff13fff700 (LWP 12263) exited]
[New Thread 0x7fff13fff700 (LWP 12265)]
[New Thread 0x7fff12ffd700 (LWP 12266)]
[New Thread 0x7fff127fc700 (LWP 12267)]
[New Thread 0x7fff11ffb700 (LWP 12268)]
[New Thread 0x7fff117fa700 (LWP 12269)]
[New Thread 0x7fff10ff9700 (LWP 12270)]
[New Thread 0x7ffeeffff700 (LWP 12271)]
[New Thread 0x7ffeef7fe700 (LWP 12272)]
[New Thread 0x7ffeeeffd700 (LWP 12273)]
[New Thread 0x7ffeee7fc700 (LWP 12274)]
[New Thread 0x7ffeedffb700 (LWP 12275)]
[New Thread 0x7ffeed7fa700 (LWP 12276)]
2020-04-28 20:30:27.248566: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55555e3af020 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-04-28 20:30:27.248605: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[New Thread 0x7ffeecff9700 (LWP 12277)]
[New Thread 0x7ffecffff700 (LWP 12278)]
[New Thread 0x7ffecf7fe700 (LWP 12279)]
[New Thread 0x7ffeceffd700 (LWP 12280)]
[New Thread 0x7ffece7fc700 (LWP 12281)]
[New Thread 0x7ffecdffb700 (LWP 12282)]
[New Thread 0x7ffecd7fa700 (LWP 12283)]
2020-04-28 20:30:27.453872: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties:
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:17:00.0
2020-04-28 20:30:27.454308: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 1 with properties:
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:65:00.0
2020-04-28 20:30:27.454346: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2020-04-28 20:30:27.454355: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2020-04-28 20:30:27.454365: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2020-04-28 20:30:27.454374: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2020-04-28 20:30:27.454383: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2020-04-28 20:30:27.454392: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2020-04-28 20:30:27.454400: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-04-28 20:30:27.455918: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0, 1
2020-04-28 20:30:27.455949: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2020-04-28 20:30:27.457102: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-04-28 20:30:27.457113: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 1
2020-04-28 20:30:27.457119: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N Y
2020-04-28 20:30:27.457124: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 1:   Y N
2020-04-28 20:30:27.458736: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10479 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:17:00.0, compute capability: 6.1)
[New Thread 0x7ffeccff9700 (LWP 12284)]
[New Thread 0x7ffec5fff700 (LWP 12285)]
2020-04-28 20:30:27.460287: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 10322 MB memory) -> physical GPU (device: 1, name: GeForce GTX 1080 Ti, pci bus id: 0000:65:00.0, compute capability: 6.1)
[New Thread 0x7ffec57fe700 (LWP 12286)]
[New Thread 0x7ffec4ffd700 (LWP 12287)]
[New Thread 0x7ffeb1fff700 (LWP 12288)]
[New Thread 0x7ffeb17fe700 (LWP 12289)]
[New Thread 0x7ffeb0ffd700 (LWP 12290)]
[Thread 0x7ffeb17fe700 (LWP 12289) exited]
2020-04-28 20:30:27.462897: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55555f27b300 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-04-28 20:30:27.462912: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce GTX 1080 Ti, Compute Capability 6.1
2020-04-28 20:30:27.462918: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): GeForce GTX 1080 Ti, Compute Capability 6.1
[Thread 0x7ffeb0ffd700 (LWP 12290) exited]
[New Thread 0x7ffeb0ffd700 (LWP 12291)]
[New Thread 0x7ffeb17fe700 (LWP 12292)]
[New Thread 0x7ffe99fff700 (LWP 12293)]
[New Thread 0x7ffe997fe700 (LWP 12294)]
[New Thread 0x7ffe98ffd700 (LWP 12295)]
[New Thread 0x7ffe73fff700 (LWP 12296)]
[New Thread 0x7ffe737fe700 (LWP 12297)]
[New Thread 0x7ffe72ffd700 (LWP 12298)]
[New Thread 0x7ffe727fc700 (LWP 12299)]
[New Thread 0x7ffe71ffb700 (LWP 12300)]
[New Thread 0x7ffe717fa700 (LWP 12301)]
[New Thread 0x7ffe70ff9700 (LWP 12302)]
[New Thread 0x7ffe4ffff700 (LWP 12303)]
2020-04-28 20:30:27.468970: I tensorflow/core/grappler/devices.cc:55] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 2
[New Thread 0x7ffe4f7fe700 (LWP 12304)]
[New Thread 0x7ffe4effd700 (LWP 12305)]
2020-04-28 20:30:27.469634: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session
[New Thread 0x7ffe4e7fc700 (LWP 12306)]
[New Thread 0x7ffe4dffb700 (LWP 12307)]
[Thread 0x7ffe4f7fe700 (LWP 12304) exited]
[Thread 0x7ffe4effd700 (LWP 12305) exited]
[New Thread 0x7ffe4effd700 (LWP 12308)]
[New Thread 0x7ffe4f7fe700 (LWP 12309)]
2020-04-28 20:30:27.474639: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties:
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:17:00.0
2020-04-28 20:30:27.475820: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 1 with properties:
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:65:00.0
2020-04-28 20:30:27.475881: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2020-04-28 20:30:27.475907: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2020-04-28 20:30:27.475931: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2020-04-28 20:30:27.475954: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2020-04-28 20:30:27.475977: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2020-04-28 20:30:27.476000: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2020-04-28 20:30:27.476023: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-04-28 20:30:27.480329: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0, 1
2020-04-28 20:30:27.480424: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-04-28 20:30:27.480442: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 1
2020-04-28 20:30:27.480457: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N Y
2020-04-28 20:30:27.480469: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 1:   Y N
2020-04-28 20:30:27.485406: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10479 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:17:00.0, compute capability: 6.1)
2020-04-28 20:30:27.486411: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 10322 MB memory) -> physical GPU (device: 1, name: GeForce GTX 1080 Ti, pci bus id: 0000:65:00.0, compute capability: 6.1)
[New Thread 0x7ffe4d7fa700 (LWP 12310)]
[New Thread 0x7ffe4cff9700 (LWP 12311)]
[New Thread 0x7ffe2ffff700 (LWP 12312)]
[New Thread 0x7ffe2f7fe700 (LWP 12313)]
[New Thread 0x7ffe2effd700 (LWP 12314)]
[New Thread 0x7ffe2e7fc700 (LWP 12315)]
[New Thread 0x7ffe2dffb700 (LWP 12316)]
[New Thread 0x7ffe2d7fa700 (LWP 12317)]
[New Thread 0x7ffe2cff9700 (LWP 12318)]
[New Thread 0x7ffe0ffff700 (LWP 12319)]
[New Thread 0x7ffe0f7fe700 (LWP 12320)]
[New Thread 0x7ffe0effd700 (LWP 12321)]
[New Thread 0x7ffe0e7fc700 (LWP 12322)]
[New Thread 0x7ffe0dffb700 (LWP 12323)]
[New Thread 0x7ffe0d7fa700 (LWP 12324)]
[Thread 0x7ffe4e7fc700 (LWP 12306) exited]
[Thread 0x7ffe4dffb700 (LWP 12307) exited]
[Thread 0x7ffe0d7fa700 (LWP 12324) exited]
[Thread 0x7ffe0dffb700 (LWP 12323) exited]
[Thread 0x7ffe2f7fe700 (LWP 12313) exited]
[Thread 0x7ffe0e7fc700 (LWP 12322) exited]
[Thread 0x7ffe2ffff700 (LWP 12312) exited]
[Thread 0x7ffe2cff9700 (LWP 12318) exited]
[Thread 0x7ffe2effd700 (LWP 12314) exited]
[Thread 0x7ffe0effd700 (LWP 12321) exited]
[Thread 0x7ffe2e7fc700 (LWP 12315) exited]
[Thread 0x7ffe0f7fe700 (LWP 12320) exited]
[Thread 0x7ffe0ffff700 (LWP 12319) exited]
[Thread 0x7ffe2d7fa700 (LWP 12317) exited]
[Thread 0x7ffe2dffb700 (LWP 12316) exited]
[Thread 0x7ffe4effd700 (LWP 12308) exited]
[Thread 0x7ffe4d7fa700 (LWP 12310) exited]
[Thread 0x7ffe4cff9700 (LWP 12311) exited]
2020-04-28 20:30:27.502006: I tensorflow/core/grappler/devices.cc:55] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 2
[New Thread 0x7ffe4cff9700 (LWP 12325)]
[New Thread 0x7ffe4d7fa700 (LWP 12326)]
2020-04-28 20:30:27.502577: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session
[New Thread 0x7ffe4effd700 (LWP 12327)]
[New Thread 0x7ffe0dffb700 (LWP 12328)]
[Thread 0x7ffe4d7fa700 (LWP 12326) exited]
[Thread 0x7ffe4cff9700 (LWP 12325) exited]
[New Thread 0x7ffe4d7fa700 (LWP 12329)]
2020-04-28 20:30:27.507610: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties:
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:17:00.0
2020-04-28 20:30:27.508716: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 1 with properties:
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:65:00.0
2020-04-28 20:30:27.508769: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2020-04-28 20:30:27.508794: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2020-04-28 20:30:27.508817: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2020-04-28 20:30:27.508838: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2020-04-28 20:30:27.508860: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2020-04-28 20:30:27.508881: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2020-04-28 20:30:27.508903: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-04-28 20:30:27.515729: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0, 1
2020-04-28 20:30:27.515825: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-04-28 20:30:27.515844: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 1
2020-04-28 20:30:27.515858: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N Y
2020-04-28 20:30:27.515871: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 1:   Y N
2020-04-28 20:30:27.519266: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10479 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:17:00.0, compute capability: 6.1)
2020-04-28 20:30:27.520407: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 10322 MB memory) -> physical GPU (device: 1, name: GeForce GTX 1080 Ti, pci bus id: 0000:65:00.0, compute capability: 6.1)
[New Thread 0x7ffe4cff9700 (LWP 12330)]
[New Thread 0x7ffe4e7fc700 (LWP 12331)]
[New Thread 0x7ffe4dffb700 (LWP 12332)]
[New Thread 0x7ffe2ffff700 (LWP 12333)]
[New Thread 0x7ffe2f7fe700 (LWP 12334)]
[New Thread 0x7ffe2effd700 (LWP 12335)]
[New Thread 0x7ffe2e7fc700 (LWP 12336)]
[New Thread 0x7ffe2dffb700 (LWP 12337)]
[New Thread 0x7ffe2d7fa700 (LWP 12338)]
[New Thread 0x7ffe2cff9700 (LWP 12339)]
[New Thread 0x7ffe0ffff700 (LWP 12340)]
[New Thread 0x7ffe0f7fe700 (LWP 12341)]
[New Thread 0x7ffe0effd700 (LWP 12342)]
[New Thread 0x7ffe0e7fc700 (LWP 12343)]
[New Thread 0x7ffe0d7fa700 (LWP 12344)]
[Thread 0x7ffe0dffb700 (LWP 12328) exited]
[Thread 0x7ffe4effd700 (LWP 12327) exited]
[Thread 0x7ffe0d7fa700 (LWP 12344) exited]
[Thread 0x7ffe0e7fc700 (LWP 12343) exited]
[Thread 0x7ffe2f7fe700 (LWP 12334) exited]
[Thread 0x7ffe0effd700 (LWP 12342) exited]
[Thread 0x7ffe2ffff700 (LWP 12333) exited]
[Thread 0x7ffe0f7fe700 (LWP 12341) exited]
[Thread 0x7ffe4dffb700 (LWP 12332) exited]
[Thread 0x7ffe2cff9700 (LWP 12339) exited]
[Thread 0x7ffe2effd700 (LWP 12335) exited]
[Thread 0x7ffe0ffff700 (LWP 12340) exited]
[Thread 0x7ffe2e7fc700 (LWP 12336) exited]
[Thread 0x7ffe2dffb700 (LWP 12337) exited]
[Thread 0x7ffe2d7fa700 (LWP 12338) exited]
[Thread 0x7ffe4d7fa700 (LWP 12329) exited]
[Thread 0x7ffe4cff9700 (LWP 12330) exited]
[Thread 0x7ffe4e7fc700 (LWP 12331) exited]
[Thread 0x7fff28ff9700 (LWP 12262) exited]
[Thread 0x7ffeb1fff700 (LWP 12288) exited]
[Thread 0x7ffeb0ffd700 (LWP 12291) exited]
Thread 1 ""python"" received signal SIGSEGV, Segmentation fault.
__memmove_avx_unaligned () at ../sysdeps/x86_64/multiarch/memcpy-avx-unaligned.S:238
238     ../sysdeps/x86_64/multiarch/memcpy-avx-unaligned.S: No such file or directory.
```

Note it finishes with:
```
Thread 1 ""python"" received signal SIGSEGV, Segmentation fault.
__memmove_avx_unaligned () at ../sysdeps/x86_64/multiarch/memcpy-avx-unaligned.S:238
238     ../sysdeps/x86_64/multiarch/memcpy-avx-unaligned.S: No such file or directory.
```

I then (in gdb) call backtrace/bt which gives me this:
```
(gdb) bt
#0  __memmove_avx_unaligned () at ../sysdeps/x86_64/multiarch/memcpy-avx-unaligned.S:238
#1  0x00007fff480e3f4d in tflite::interpreter_wrapper::InterpreterWrapper::SetTensor(int, _object*) () from /home/leonfedden/miniconda3/envs/dev/lib/python3.7/site-packages/tensorflow_core/lite/python/interpreter_wrapper/_tensorflow_wrap_interpreter_wrapper.so
#2  0x00007fff480e1dde in _wrap_InterpreterWrapper_SetTensor () from /home/leonfedden/miniconda3/envs/dev/lib/python3.7/site-packages/tensorflow_core/lite/python/interpreter_wrapper/_tensorflow_wrap_interpreter_wrapper.so
#3  0x00005555556bda30 in _PyMethodDef_RawFastCallKeywords () at /tmp/build/80754af9/python_1585235023510/work/Objects/call.c:698
#4  0x00005555556bdbd1 in _PyCFunction_FastCallKeywords (func=0x55555f21aa30, args=<optimised out>, nargs=<optimised out>, kwnames=<optimised out>) at /tmp/build/80754af9/python_1585235023510/work/Objects/call.c:734
#5  0x000055555572457b in call_function (kwnames=0x0, oparg=3, pp_stack=<synthetic pointer>) at /tmp/build/80754af9/python_1585235023510/work/Python/ceval.c:4568
#6  _PyEval_EvalFrameDefault () at /tmp/build/80754af9/python_1585235023510/work/Python/ceval.c:3093
#7  0x00005555556bd02b in function_code_fastcall (globals=<optimised out>, nargs=3, args=<optimised out>, co=<optimised out>) at /tmp/build/80754af9/python_1585235023510/work/Objects/call.c:283
#8  _PyFunction_FastCallKeywords () at /tmp/build/80754af9/python_1585235023510/work/Objects/call.c:408
#9  0x00005555557241e9 in call_function (kwnames=0x0, oparg=<optimised out>, pp_stack=<synthetic pointer>) at /tmp/build/80754af9/python_1585235023510/work/Python/ceval.c:4616
#10 _PyEval_EvalFrameDefault () at /tmp/build/80754af9/python_1585235023510/work/Python/ceval.c:3093
#11 0x00005555556bd02b in function_code_fastcall (globals=<optimised out>, nargs=3, args=<optimised out>, co=<optimised out>) at /tmp/build/80754af9/python_1585235023510/work/Objects/call.c:283
#12 _PyFunction_FastCallKeywords () at /tmp/build/80754af9/python_1585235023510/work/Objects/call.c:408
#13 0x000055555571fd40 in call_function (kwnames=0x0, oparg=<optimised out>, pp_stack=<synthetic pointer>) at /tmp/build/80754af9/python_1585235023510/work/Python/ceval.c:4616
#14 _PyEval_EvalFrameDefault () at /tmp/build/80754af9/python_1585235023510/work/Python/ceval.c:3110
#15 0x00005555556bd02b in function_code_fastcall (globals=<optimised out>, nargs=2, args=<optimised out>, co=<optimised out>) at /tmp/build/80754af9/python_1585235023510/work/Objects/call.c:283
#16 _PyFunction_FastCallKeywords () at /tmp/build/80754af9/python_1585235023510/work/Objects/call.c:408
#17 0x000055555571fac6 in call_function (kwnames=0x0, oparg=<optimised out>, pp_stack=<synthetic pointer>) at /tmp/build/80754af9/python_1585235023510/work/Python/ceval.c:4616
#18 _PyEval_EvalFrameDefault () at /tmp/build/80754af9/python_1585235023510/work/Python/ceval.c:3124
#19 0x0000555555669389 in _PyEval_EvalCodeWithName () at /tmp/build/80754af9/python_1585235023510/work/Python/ceval.c:3930
#20 0x000055555566a2b4 in PyEval_EvalCodeEx () at /tmp/build/80754af9/python_1585235023510/work/Python/ceval.c:3959
#21 0x000055555566a2dc in PyEval_EvalCode (co=<optimised out>, globals=<optimised out>, locals=<optimised out>) at /tmp/build/80754af9/python_1585235023510/work/Python/ceval.c:524
#22 0x0000555555780664 in run_mod () at /tmp/build/80754af9/python_1585235023510/work/Python/pythonrun.c:1035
#23 0x000055555578aa91 in PyRun_FileExFlags () at /tmp/build/80754af9/python_1585235023510/work/Python/pythonrun.c:988
#24 0x000055555578ac83 in PyRun_SimpleFileExFlags () at /tmp/build/80754af9/python_1585235023510/work/Python/pythonrun.c:429
#25 0x000055555578bdb5 in pymain_run_file (p_cf=0x7fffffffdea0, filename=0x5555558c3430 L""mvp_segfault.py"", fp=0x555555a8b6a0) at /tmp/build/80754af9/python_1585235023510/work/Modules/main.c:462
#26 pymain_run_filename (cf=0x7fffffffdea0, pymain=0x7fffffffdfb0) at /tmp/build/80754af9/python_1585235023510/work/Modules/main.c:1641
#27 pymain_run_python (pymain=0x7fffffffdfb0) at /tmp/build/80754af9/python_1585235023510/work/Modules/main.c:2902
#28 pymain_main () at /tmp/build/80754af9/python_1585235023510/work/Modules/main.c:3442
#29 0x000055555578bedc in _Py_UnixMain () at /tmp/build/80754af9/python_1585235023510/work/Modules/main.c:3477
#30 0x00007ffff7810830 in __libc_start_main (main=0x55555564a1f0 <main>, argc=2, argv=0x7fffffffe108, init=<optimised out>, fini=<optimised out>, rtld_fini=<optimised out>, stack_end=0x7fffffffe0f8) at ../csu/libc-start.c:291
#31 0x000055555572f3e0 in _start () at ../sysdeps/x86_64/elf/start.S:103
```

"
38992,TFLMicro mul kernel input shapes broadcasting,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Mac OS 10.14.6
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): 2.2 (master)
- Python version: 3.7

**Describe the current behavior**
tensorflow/lite/kernels/mul.cc kernel does not appear to be working with inputs that need broadcasting. An example pair of input shapes is (1, 1, 13) and (13,). Here is a test case that fails:

```
TF_LITE_MICRO_TEST(FloatBroadcast2) {
  float output_data[6];
  tflite::testing::TestMulFloat(
      {2, 1, 6},                      // input1 shape
      {-2.0, 0.2, 0.7, 0.8, 1.1, 2.0},      // input1 data
      {1, 6},                               // input2 shape
      {0.1,0.1,0.1,0.1,0.1,0.1},                                // input2 data
      {2, 1, 6},                      // output shape
      {-0.2, 0.02, 0.07, 0.08, 0.11, 0.2},  // expected output data
      output_data, kTfLiteActNone);
}
```

```
> make -f tensorflow/lite/micro/tools/make/Makefile test_kernel_mul_test
tensorflow/lite/micro/tools/make/Makefile:280: warning: overriding recipe for target 'tensorflow/lite/micro/tools/make/downloads/person_model_grayscale'
tensorflow/lite/micro/tools/make/Makefile:280: warning: ignoring old recipe for target 'tensorflow/lite/micro/tools/make/downloads/person_model_grayscale'
tensorflow/lite/micro/testing/test_linux_binary.sh tensorflow/lite/micro/tools/make/gen/osx_x86_64/bin/kernel_mul_test '~~~ALL TESTS PASSED~~~'
tensorflow/lite/micro/testing/test_linux_binary.sh: line 46: 22443 Abort trap: 6           $1 > ${MICRO_LOG_FILENAME} 2>&1
make: *** [tensorflow/lite/micro/tools/make/Makefile:340: test_kernel_mul_test] Error 134
```
**Describe the expected behavior**
The kernel is supposed to broadcast inputs if necessary. 

**Other info / logs** 
It appears that the problem is in `ProcessBroadcastShapes()`. If in `EvalFloat()` in mul.cc, I force broadcast using `TF_LITE_MUL(BroadcastMul4DSlow)`, I get correct results.  
"
38991,Speech Command Recognition example crashes with GPUDelegate,"Tensorflow lite issue:

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
Yes:


In SpeechActivity when the interpreter is created:
(https://github.com/tensorflow/examples/blob/master/lite/examples/speech_commands/android/app/src/main/java/org/tensorflow/lite/examples/speech/SpeechActivity.java line: 182)

(deprecated)
tfLite = new Interpreter(loadModelFile(getAssets(), actualModelFilename));

I change to:
      Interpreter.Options options = new Interpreter.Options();
      options.addDelegate(new GpuDelegate());
      options.setNumThreads(1);
      tfLite = new Interpreter(loadModelFile(getAssets(), actualModelFilename), options);

**Standalone code to reproduce the issue**
I have an instrumented test that reproduces the bug, I will attach it

**Crashes with GpuDelegate, does not crash with NnapiDelegate**

(Change to .java for use, also include the proper dependencies in gradle, and create the proper directories for gradle to find and build out test: androidtest->java-> etc)
[SpeechTest.txt](https://github.com/tensorflow/tensorflow/files/4547752/SpeechTest.txt)
"
38990,"Tensorflow is not detecting GPU, while it is detected in PyTorch","**System information**
- Kali GNU/Linux 2020.1
- TensorFlow installed from (source or binary): pip source
- TensorFlow version: 2.1.0
- Python version: 3.7.7
- Installed using virtualenv? pip? conda?: pip in virtualenv
- CUDA/cuDNN version: (deepl) root@root:~/Documents/deepl# nvcc --version
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2019 NVIDIA Corporation
Built on Wed_Apr_24_19:10:27_PDT_2019
Cuda compilation tools, release 10.1, V10.1.168
- GPU model and memory:
deepl) root@root:~/Documents/deepl# nvidia-smi
Tue Apr 28 23:46:25 2020       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 440.82       Driver Version: 440.82       CUDA Version: 10.2     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  GeForce RTX 2080    Off  | 00000000:01:00.0  On |                  N/A |
| 41%   37C    P8     7W / 225W |    632MiB /  7981MiB |     35%      Default |
+-------------------------------+----------------------+----------------------+



**Problem Description**
import tensorflow as tf
tf.test.gpu_device_name()

it throws a blank string not detecting a gpu while drivers are installed perfectly as PyTorch detected the gpu

tf.test.gpu_device_name()
''

while in PyTorch
import torch
torch.cuda.is_available()
true


**Any other info / logs**
There is no error in loading modules here are installation logs

`(deepl) root@root:~/Documents/deepl# pip install tensorflow-gpu
Collecting tensorflow-gpu
  Using cached tensorflow_gpu-2.1.0-cp37-cp37m-manylinux2010_x86_64.whl (421.8 MB)
Requirement already satisfied: wrapt>=1.11.1 in ./lib/python3.7/site-packages (from tensorflow-gpu) (1.12.1)
Requirement already satisfied: astor>=0.6.0 in ./lib/python3.7/site-packages (from tensorflow-gpu) (0.8.1)
Requirement already satisfied: absl-py>=0.7.0 in ./lib/python3.7/site-packages (from tensorflow-gpu) (0.9.0)
Requirement already satisfied: scipy==1.4.1; python_version >= ""3"" in ./lib/python3.7/site-packages (from tensorflow-gpu) (1.4.1)
Requirement already satisfied: gast==0.2.2 in ./lib/python3.7/site-packages (from tensorflow-gpu) (0.2.2)
Requirement already satisfied: protobuf>=3.8.0 in ./lib/python3.7/site-packages (from tensorflow-gpu) (3.11.3)
Requirement already satisfied: google-pasta>=0.1.6 in ./lib/python3.7/site-packages (from tensorflow-gpu) (0.2.0)
Requirement already satisfied: tensorflow-estimator<2.2.0,>=2.1.0rc0 in ./lib/python3.7/site-packages (from tensorflow-gpu) (2.1.0)
Requirement already satisfied: termcolor>=1.1.0 in ./lib/python3.7/site-packages (from tensorflow-gpu) (1.1.0)
Requirement already satisfied: keras-preprocessing>=1.1.0 in ./lib/python3.7/site-packages (from tensorflow-gpu) (1.1.0)
Requirement already satisfied: wheel>=0.26; python_version >= ""3"" in ./lib/python3.7/site-packages (from tensorflow-gpu) (0.34.2)
Requirement already satisfied: opt-einsum>=2.3.2 in ./lib/python3.7/site-packages (from tensorflow-gpu) (3.2.1)
Requirement already satisfied: numpy<2.0,>=1.16.0 in ./lib/python3.7/site-packages (from tensorflow-gpu) (1.18.3)
Requirement already satisfied: keras-applications>=1.0.8 in ./lib/python3.7/site-packages (from tensorflow-gpu) (1.0.8)
Requirement already satisfied: tensorboard<2.2.0,>=2.1.0 in ./lib/python3.7/site-packages (from tensorflow-gpu) (2.1.1)
Requirement already satisfied: six>=1.12.0 in ./lib/python3.7/site-packages (from tensorflow-gpu) (1.14.0)
Requirement already satisfied: grpcio>=1.8.6 in ./lib/python3.7/site-packages (from tensorflow-gpu) (1.28.1)
Requirement already satisfied: setuptools in ./lib/python3.7/site-packages (from protobuf>=3.8.0->tensorflow-gpu) (46.1.3)
Requirement already satisfied: h5py in ./lib/python3.7/site-packages (from keras-applications>=1.0.8->tensorflow-gpu) (2.10.0)
Requirement already satisfied: requests<3,>=2.21.0 in ./lib/python3.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (2.23.0)
Requirement already satisfied: google-auth<2,>=1.6.3 in ./lib/python3.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (1.14.1)
Requirement already satisfied: werkzeug>=0.11.15 in ./lib/python3.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (1.0.1)
Requirement already satisfied: markdown>=2.6.8 in ./lib/python3.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (3.2.1)
Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in ./lib/python3.7/site-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (0.4.1)
Requirement already satisfied: idna<3,>=2.5 in ./lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (2.9)
Requirement already satisfied: chardet<4,>=3.0.2 in ./lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (3.0.4)
Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in ./lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (1.25.9)
Requirement already satisfied: certifi>=2017.4.17 in ./lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (2020.4.5.1)
Requirement already satisfied: pyasn1-modules>=0.2.1 in ./lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (0.2.8)
Requirement already satisfied: rsa<4.1,>=3.1.4 in ./lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (4.0)
Requirement already satisfied: cachetools<5.0,>=2.0.0 in ./lib/python3.7/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (4.1.0)
Requirement already satisfied: requests-oauthlib>=0.7.0 in ./lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (1.3.0)
Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in ./lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (0.4.8)
Requirement already satisfied: oauthlib>=3.0.0 in ./lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (3.1.0)
Installing collected packages: tensorflow-gpu
Successfully installed tensorflow-gpu-2.1.0`


>> I have tried installing pip install tensorflow-gpu==2.0.0 as well.
"
38988,AttributeError: 'dict' object has no attribute 'name',"**System information**
- Have I written custom code: No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Mac OS X Catalina
- TensorFlow installed from: binary
- TensorFlow version: ` 2.2.0.dev20200427` 
- Python version: 3.7.5

**Describe the current behavior**

I get the error

> AttributeError: 'dict' object has no attribute 'name'

when I try to plot a model, with `tf.keras.utils.plot_model`, where I specify the loss to the `compile` method as a dictionary. According to [the documentation](https://www.tensorflow.org/api_docs/python/tf/keras/Model?version=nightly#compile), this should be possible and this was actually possible in TF 2.1 (i.e. until recently I was using the exact same code with TF 2.1 and no error was thrown).

**Describe the expected behavior**

No error.

**Standalone code to reproduce the issue**

```
import tensorflow as tf


def get_model(input_shape, num_classes=10):
    model_input = tf.keras.layers.Input(shape=input_shape)
    x = tf.keras.layers.Conv2D(6, 3)(model_input)
    x = tf.keras.layers.Flatten()(x)
    model_output = tf.keras.layers.Dense(num_classes, name=""my_output_layer"")(x)
    model = tf.keras.Model(model_input, model_output)
    model.summary()
    return model


def train():
    model = get_model((28, 28, 1))

    model.compile(loss={""my_output_layer"": ""categorical_crossentropy""})

    # IF YOU COMMENT THIS, NO ERROR OCCURS!!!
    tf.keras.utils.plot_model(model, to_file=""model.png"", show_shapes=True)


if __name__ == '__main__':
    train()
```

I installed `pydot` with `pip install pydot`. The version that was installed is `1.4.1`.

Clearly, the error is due to the fact that `plot_model` thinks that the loss is also a layer.

I need to use TF 2.2 because I am using another library that requires the nightly version of TF."
38987,Sigmoid returns negative values,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
CentOs Linux 7 (Core)
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
pip3 installed tensorflow-gpu
- TensorFlow version (use command below):
2.1.0
- Python version:
3.6.0
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
cuda 10.1 cudnn 7.6.4
- GPU model and memory:
Tesla P100 75GB

**Describe the current behavior**
The last output layer is a sigmoid function, but the AUC metric says output is not >= 0 element-wise. I've also tried this using `activation='sigmoid'` in the output layer directly, which also results in the same error.

I've verified that after removing AUC as a metric,  the code works but the min output value becomes negative after a few epochs. 

**Describe the expected behavior**
Sigmoid output should be 0-1

**Last part of the code **

```
    ypred = tf.keras.layers.Dense(                                              
            1, name=""%s_out"" % target_variable,                                 
            kernel_regularizer=tf.keras.regularizers.l2(beta))(x)               
                                                                    
    ypred = tf.nn.sigmoid(ypred)                                            

                                                                                
    model = tf.keras.models.Model(inputs=inputs, outputs=ypred)                 
    optimizer = tf.keras.optimizers.Adam(lr)                                    
    model.compile(optimizer=optimizer,                                          
                  loss='binary_crossentropy',                                   
                  metrics=['accuracy', 'AUC', 'mse'])             
                                                                                                                                        
    early_stopping = tf.keras.callbacks.EarlyStopping(patience=100)             
                  
    callbacks = [early_stopping]                                                
                                                                                
    model_start_time = time.time()                                              
   
    model.evaluate(test_ds, verbose=2)                                      
                                                                                
    history = model.fit(                                                        
            train_ds, validation_data=(test_ds), epochs=num_epochs,             
            verbose=2, callbacks=callbacks)
```
**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

```
Traceback (most recent call last):
  File ""lol_embed_ntf_champs.py"", line 162, in <module>
    save_results=args.save_results, **datum)
  File ""/auto/rcf-40/yioujian/ntf-embed/lol_embedding_ntf_champs.py"", line 160, in run_embed_ntf
    verbose=2, callbacks=callbacks)
  File ""/home/rcf-proj2/ef/yioujian/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py"", line 819, in fit
    use_multiprocessing=use_multiprocessing)
  File ""/home/rcf-proj2/ef/yioujian/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py"", line 342, in fit
    total_epochs=epochs)
  File ""/home/rcf-proj2/ef/yioujian/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py"", line 128, in run_one_epoch
    batch_outs = execution_function(iterator)
  File ""/home/rcf-proj2/ef/yioujian/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py"", line 98, in execution_function
    distributed_function(input_fn))
  File ""/home/rcf-proj2/ef/yioujian/.local/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py"", line 568, in __call__
    result = self._call(*args, **kwds)
  File ""/home/rcf-proj2/ef/yioujian/.local/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py"", line 599, in _call
    return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable
  File ""/home/rcf-proj2/ef/yioujian/.local/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py"", line 2363, in __call__
    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access
  File ""/home/rcf-proj2/ef/yioujian/.local/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py"", line 1611, in _filtered_call
    self.captured_inputs)
  File ""/home/rcf-proj2/ef/yioujian/.local/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py"", line 1692, in _call_flat
    ctx, args, cancellation_manager=cancellation_manager))
  File ""/home/rcf-proj2/ef/yioujian/.local/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py"", line 545, in call
    ctx=ctx)
  File ""/home/rcf-proj2/ef/yioujian/.local/lib/python3.6/site-packages/tensorflow_core/python/eager/execute.py"", line 67, in quick_execute
    six.raise_from(core._status_to_exception(e.code, message), None)
  File ""<string>"", line 3, in raise_from
tensorflow.python.framework.errors_impl.InvalidArgumentError: 2 root error(s) found.
  (0) Invalid argument:  assertion failed: [predictions must be >= 0] [Condition x >= y did not hold element-wise:] [x (model/tf_op_layer_Sigmoid/Sigmoid:0) = ] [[0.323994398][0.177097648][0.000274539]...] [y (metrics/AUC/Cast_1/x:0) = ] [0]
	 [[{{node metrics/AUC/assert_greater_equal/Assert/AssertGuard/else/_1/Assert}}]]
	 [[metrics/AUC/assert_less_equal/Assert/AssertGuard/pivot_f/_13/_39]]
  (1) Invalid argument:  assertion failed: [predictions must be >= 0] [Condition x >= y did not hold element-wise:] [x (model/tf_op_layer_Sigmoid/Sigmoid:0) = ] [[0.323994398][0.177097648][0.000274539]...] [y (metrics/AUC/Cast_1/x:0) = ] [0]
	 [[{{node metrics/AUC/assert_greater_equal/Assert/AssertGuard/else/_1/Assert}}]]
0 successful operations.
0 derived errors ignored. [Op:__inference_distributed_function_4015]

Function call stack:
distributed_function -> distributed_function
```"
38986,The app crash when i apply my mobilenet model.,"Device: HUAWEI nova 3i
I downloaded the ""TensorFlowLiteInceptionTutorial"" from https://github.com/soum-io/TensorFlowLiteInceptionTutorial. I change to my mobilenet model.

Labels is show but Confidence value = 0% all.

ChooseModel.java
```
package com.soumio.inceptiontutorial;

import android.Manifest;
import android.content.ContentValues;
import android.content.Intent;
import android.content.pm.ActivityInfo;
import android.content.pm.PackageManager;
import android.net.Uri;
import android.os.Build;
import android.provider.MediaStore;
import android.support.annotation.NonNull;
import android.support.v4.app.ActivityCompat;
import android.support.v4.content.ContextCompat;
import android.support.v7.app.AppCompatActivity;
import android.os.Bundle;
import android.util.Log;
import android.view.View;
import android.widget.Button;
import android.widget.Toast;

import com.soundcloud.android.crop.Crop;

import java.io.File;

public class ChooseModel extends AppCompatActivity {

    // button for each available classifier
    private Button inceptionQuant;

    // for permission requests
    public static final int REQUEST_PERMISSION = 300;

    // request code for permission requests to the os for image
    public static final int REQUEST_IMAGE = 100;

    // will hold uri of image obtained from camera
    private Uri imageUri;

    // string to send to next activity that describes the chosen classifier
    private String chosen;

    //boolean value dictating if chosen model is quantized version or not.
    private boolean quant;


    @Override
    protected void onCreate(Bundle savedInstanceState) {
        super.onCreate(savedInstanceState);
        setContentView(R.layout.activity_choose_model);

        // request permission to use the camera on the user's phone
        if (ActivityCompat.checkSelfPermission(this.getApplicationContext(), android.Manifest.permission.CAMERA) != PackageManager.PERMISSION_GRANTED){
            ActivityCompat.requestPermissions(this, new String[] {android.Manifest.permission.CAMERA}, REQUEST_PERMISSION);
        }

        // request permission to write data (aka images) to the user's external storage of their phone
        if (Build.VERSION.SDK_INT >= Build.VERSION_CODES.M
                && ContextCompat.checkSelfPermission(this, Manifest.permission.WRITE_EXTERNAL_STORAGE) != PackageManager.PERMISSION_GRANTED) {
            ActivityCompat.requestPermissions(this, new String[]{Manifest.permission.WRITE_EXTERNAL_STORAGE},
                    REQUEST_PERMISSION);
        }

        // request permission to read data (aka images) from the user's external storage of their phone
        if (Build.VERSION.SDK_INT >= Build.VERSION_CODES.M
                && ContextCompat.checkSelfPermission(this, Manifest.permission.READ_EXTERNAL_STORAGE) != PackageManager.PERMISSION_GRANTED) {
            ActivityCompat.requestPermissions(this, new String[]{Manifest.permission.READ_EXTERNAL_STORAGE},
                    REQUEST_PERMISSION);
        }

        // on click for inception quant model
        inceptionQuant = (Button)findViewById(R.id.inception_quant);
        inceptionQuant.setOnClickListener(new View.OnClickListener() {
            @Override
            public void onClick(View view) {
                // filename in assets
                chosen = ""mushroom_mobilenetv1_batch270-2.tflite"";
                // model in not quantized
                quant = true;
                // open camera
                openCameraIntent();
            }
        });
    }

    // opens camera for user
    private void openCameraIntent(){
        ContentValues values = new ContentValues();
        values.put(MediaStore.Images.Media.TITLE, ""New Picture"");
        values.put(MediaStore.Images.Media.DESCRIPTION, ""From your Camera"");
        // tell camera where to store the resulting picture
        imageUri = getContentResolver().insert(
                MediaStore.Images.Media.EXTERNAL_CONTENT_URI, values);
        Intent intent = new Intent(MediaStore.ACTION_IMAGE_CAPTURE);
        intent.putExtra(MediaStore.EXTRA_OUTPUT, imageUri);
        setRequestedOrientation(ActivityInfo.SCREEN_ORIENTATION_UNSPECIFIED);
        // start camera, and wait for it to finish
        startActivityForResult(intent, REQUEST_IMAGE);
    }

    // checks that the user has allowed all the required permission of read and write and camera. If not, notify the user and close the application
    @Override
    public void onRequestPermissionsResult(final int requestCode, @NonNull final String[] permissions, @NonNull final int[] grantResults) {
        super.onRequestPermissionsResult(requestCode, permissions, grantResults);
        if (requestCode == REQUEST_PERMISSION) {
            if (!(grantResults.length > 0 && grantResults[0] == PackageManager.PERMISSION_GRANTED)) {
                Toast.makeText(getApplicationContext(),""This application needs read, write, and camera permissions to run. Application now closing."",Toast.LENGTH_LONG);
                System.exit(0);
            }
        }
    }

    // dictates what to do after the user takes an image, selects and image, or crops an image
    @Override
    protected void onActivityResult(int requestCode, int resultCode, Intent data){
        super.onActivityResult(requestCode, resultCode, data);
        // if the camera activity is finished, obtained the uri, crop it to make it square, and send it to 'Classify' activity
        if(requestCode == REQUEST_IMAGE && resultCode == RESULT_OK) {

            Intent i = new Intent(ChooseModel.this, Classify.class);
            // put image data in extras to send
            i.putExtra(""resID_uri"", imageUri);
            // put filename in extras
            i.putExtra(""chosen"", chosen);
            // put model type in extras
            i.putExtra(""quant"", quant);
            // send other required data
            startActivity(i);

        }
```
Classify.java
```
package com.soumio.inceptiontutorial;

import android.content.Intent;
import android.content.res.AssetFileDescriptor;
import android.graphics.Bitmap;
import android.graphics.Matrix;
import android.graphics.drawable.BitmapDrawable;
import android.net.Uri;
import android.provider.MediaStore;
import android.support.v7.app.AppCompatActivity;
import android.os.Bundle;
import android.util.Log;
import android.view.View;
import android.widget.Button;
import android.widget.ImageView;
import android.widget.TextView;

import org.tensorflow.lite.Interpreter;

import java.io.BufferedReader;
import java.io.FileInputStream;
import java.io.IOException;
import java.io.InputStreamReader;
import java.nio.ByteBuffer;
import java.nio.ByteOrder;
import java.nio.MappedByteBuffer;
import java.nio.channels.FileChannel;
import java.util.AbstractMap;
import java.util.ArrayList;
import java.util.Comparator;
import java.util.List;
import java.util.Map;
import java.util.PriorityQueue;

public class Classify extends AppCompatActivity {

    // presets for rgb conversion
    private static final int RESULTS_TO_SHOW = 3;
    private static final float IMAGE_MEAN = 127.5f;
    private static final float IMAGE_STD = 127.5f;


    // options for model interpreter
    private final Interpreter.Options tfliteOptions = new Interpreter.Options();
    // tflite graph
    private Interpreter tflite;
    // holds all the possible labels for model
    private List<String> labelList;
    // holds the selected image data as bytes
    private ByteBuffer imgData = null;
    // holds the probabilities of each label for quantized graphs
    private float[][] labelProbArrayB = null;
    // array that holds the labels with the highest probabilities
    private String[] topLables = null;
    // array that holds the highest probabilities
    private String[] topConfidence = null;


    // selected classifier information received from extras
    private String chosen;
    private boolean quant;

    // input image dimensions for the Inception Model
    private int DIM_IMG_SIZE_X = 224;
    private int DIM_IMG_SIZE_Y = 224;
    private int DIM_PIXEL_SIZE = 3;

    // int array to hold image data
    private int[] intValues;

    // activity elements
    private ImageView selected_image;
    private Button classify_button;
    private Button back_button;
    private TextView label1;
    private TextView label2;
    private TextView label3;
    private TextView Confidence1;
    private TextView Confidence2;
    private TextView Confidence3;

    // priority queue that will hold the top results from the CNN
    private PriorityQueue<Map.Entry<String, Float>> sortedLabels =
            new PriorityQueue<>(
                    RESULTS_TO_SHOW,
                    new Comparator<Map.Entry<String, Float>>() {
                        @Override
                        public int compare(Map.Entry<String, Float> o1, Map.Entry<String, Float> o2) {
                            return (o1.getValue()).compareTo(o2.getValue());
                        }
                    });

    @Override
    protected void onCreate(Bundle savedInstanceState) {
        // get all selected classifier data from classifiers
        chosen = (String) getIntent().getStringExtra(""chosen"");
        quant = (boolean) getIntent().getBooleanExtra(""quant"", false);

        // initialize array that holds image data
        intValues = new int[DIM_IMG_SIZE_X * DIM_IMG_SIZE_Y];

        super.onCreate(savedInstanceState);

        //initilize graph and labels
        try{
            tflite = new Interpreter(loadModelFile(), tfliteOptions);
            labelList = loadLabelList();
        } catch (Exception ex){
            ex.printStackTrace();
        }

        // initialize byte array. The size depends if the input data needs to be quantized or not
        if(quant){
            imgData =
                    ByteBuffer.allocateDirect(
                            4 * DIM_IMG_SIZE_X * DIM_IMG_SIZE_Y * DIM_PIXEL_SIZE );
        }
        imgData.order(ByteOrder.nativeOrder());

        // initialize probabilities array. The datatypes that array holds depends if the input data needs to be quantized or not
        if(quant){
            labelProbArrayB= new float[1][labelList.size()];
        }

        setContentView(R.layout.activity_classify);

        // labels that hold top three results of CNN
        label1 = (TextView) findViewById(R.id.label1);
        label2 = (TextView) findViewById(R.id.label2);
        label3 = (TextView) findViewById(R.id.label3);
        // displays the probabilities of top labels
        Confidence1 = (TextView) findViewById(R.id.Confidence1);
        Confidence2 = (TextView) findViewById(R.id.Confidence2);
        Confidence3 = (TextView) findViewById(R.id.Confidence3);
        // initialize imageView that displays selected image to the user
        selected_image = (ImageView) findViewById(R.id.selected_image);

        // initialize array to hold top labels
        topLables = new String[RESULTS_TO_SHOW];
        // initialize array to hold top probabilities
        topConfidence = new String[RESULTS_TO_SHOW];

        // allows user to go back to activity to select a different image
        back_button = (Button)findViewById(R.id.back_button);
        back_button.setOnClickListener(new View.OnClickListener() {
            @Override
            public void onClick(View view) {
                Intent i = new Intent(Classify.this, ChooseModel.class);
                startActivity(i);
            }
        });

        // classify current dispalyed image
        classify_button = (Button)findViewById(R.id.classify_image);
        classify_button.setOnClickListener(new View.OnClickListener() {
            @Override
            public void onClick(View view) {
                // get current bitmap from imageView
                Bitmap bitmap_orig = ((BitmapDrawable)selected_image.getDrawable()).getBitmap();
                // resize the bitmap to the required input size to the CNN
                Bitmap bitmap = getResizedBitmap(bitmap_orig, DIM_IMG_SIZE_X, DIM_IMG_SIZE_Y);
                // convert bitmap to byte array
                convertBitmapToByteBuffer(bitmap);
                // pass byte data to the graph
                if(quant){
                    try {
                        tflite.run(imgData, labelProbArrayB);
                    } catch (Exception e) {
                        Log.e(""Error on Contact"", e.getMessage());
                    }
                }
                // display the results
                printTopKLabels();
            }
        });

        // get image from previous activity to show in the imageView
        Uri uri = (Uri)getIntent().getParcelableExtra(""resID_uri"");
        try {
            Bitmap bitmap = MediaStore.Images.Media.getBitmap(getContentResolver(), uri);
            selected_image.setImageBitmap(bitmap);
            selected_image.setRotation(selected_image.getRotation());
        } catch (IOException e) {
            e.printStackTrace();
        }
    }

    // loads tflite grapg from file
    private MappedByteBuffer loadModelFile() throws IOException {
        AssetFileDescriptor fileDescriptor = this.getAssets().openFd(chosen);
        FileInputStream inputStream = new FileInputStream(fileDescriptor.getFileDescriptor());
        FileChannel fileChannel = inputStream.getChannel();
        long startOffset = fileDescriptor.getStartOffset();
        long declaredLength = fileDescriptor.getDeclaredLength();
        return fileChannel.map(FileChannel.MapMode.READ_ONLY, startOffset, declaredLength);
    }

    // converts bitmap to byte array which is passed in the tflite graph
    private void convertBitmapToByteBuffer(Bitmap bitmap) {
        if (imgData == null) {
            return;
        }
        imgData.rewind();
        bitmap.getPixels(intValues, 0, bitmap.getWidth(), 0, 0, bitmap.getWidth(), bitmap.getHeight());
        // loop through all pixels
        int pixel = 0;
        for (int i = 0; i < DIM_IMG_SIZE_X; ++i) {
            for (int j = 0; j < DIM_IMG_SIZE_Y; ++j) {
                final int val = intValues[pixel++];
                // get rgb values from intValues where each int holds the rgb values for a pixel.
                // if quantized, convert each rgb value to a byte, otherwise to a float
                if(quant){
                    imgData.putFloat((((val >> 16) & 0xFF)-IMAGE_MEAN)/IMAGE_STD);
                    imgData.putFloat((((val >> 8) & 0xFF)-IMAGE_MEAN)/IMAGE_STD);
                    imgData.putFloat(((val & 0xFF)-IMAGE_MEAN)/IMAGE_STD);
                }

            }
        }
    }

    // loads the labels from the label txt file in assets into a string array
    private List<String> loadLabelList() throws IOException {
        List<String> labelList = new ArrayList<String>();
        BufferedReader reader =
                new BufferedReader(new InputStreamReader(this.getAssets().open(""labels_without_background_mushroom.txt"")));
        String line;
        while ((line = reader.readLine()) != null) {
            labelList.add(line);
        }
        reader.close();
        return labelList;
    }

    // print the top labels and respective confidences
    private void printTopKLabels() {
        // add all results to priority queue
        for (int i = 0; i < labelList.size(); ++i) {
            if(quant){
                    sortedLabels.add(new AbstractMap.SimpleEntry<>(labelList.get(i), ((int) labelProbArrayB[0][i] & 0xff) / 255.0f));
            }
            if (sortedLabels.size() > RESULTS_TO_SHOW) {
                sortedLabels.poll();
            }
        }

        // get top results from priority queue
        final int size = sortedLabels.size();
        for (int i = 0; i < size; ++i) {

            Map.Entry<String, Float> label = sortedLabels.poll();
            topLables[i] = label.getKey();
            topConfidence[i] = String.format(""%.1f%%"",label.getValue()*100.0f);
        }

        // set the corresponding textviews with the results
        label1.setText(""1. ""+topLables[2]);
        label2.setText(""2. ""+topLables[1]);
        label3.setText(""3. ""+topLables[0]);
        Confidence1.setText(topConfidence[2]);
        Confidence2.setText(topConfidence[1]);
        Confidence3.setText(topConfidence[0]);
    }


    // resizes bitmap to given dimensions
    public Bitmap getResizedBitmap(Bitmap bm, int newWidth, int newHeight) {
        int width = bm.getWidth();
        int height = bm.getHeight();
        float scaleWidth = ((float) newWidth) / width;
        float scaleHeight = ((float) newHeight) / height;
        Matrix matrix = new Matrix();
        matrix.postScale(scaleWidth, scaleHeight);
        Bitmap resizedBitmap = Bitmap.createBitmap(
                bm, 0, 0, width, height, matrix, false);
        return resizedBitmap;
    }
}
```

"
38985,"model.save raise ValueError: If specifying TensorSpec names for nested structures, either zero or all names have to be specified.","<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
I am using colab to reproduce the issue and the ipynb is attached below.

You can collect some of this information using our environment capture
tf.version.GIT_VERSION: v1.12.1-30689-g428cdeda09
tf.version.VERSION: 2.2.0-dev20200428


**Describe the current behavior**
cannot save the keras model with tft layer for serving.

**Describe the expected behavior**
successifully save the model and serve it like this example: https://github.com/tensorflow/transform/blob/master/examples/census_example_v2_test.py

**Standalone code to reproduce the issue**
https://drive.google.com/open?id=1h2QIX_QZetIzSuG0J6lNWkHoSa2nnIyS


**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

error is show in the last cell of the colab notebook."
38984,[TF2.2rc3] dict of ragged tensors as an input of keras layer does not support serialization,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): linux
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.2rc3
- Python version: 3.6
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

**Describe the current behavior**
We have a layer that takes a dict of ragged tensors as input:

```
class EmbeddingMerger(tf.keras.layers.Layer):
  def __init__(self, list_features, **kwargs):
    super().__init__(**kwargs)
    self._supports_ragged_inputs = True
    self.embeddings = {feature: Embedding(10, 3) for feature in list_features}
    self.mean = tf.keras.layers.Lambda(tf.reduce_mean, arguments=dict(axis=1))
  def call(self, inputs):
    tensors = [self.embeddings[col](inputs[col]) for col in inputs]
    tensors = [self.mean(inp) for inp in tensors]
    return Add()(tensors)
```
before saving it the model works well:
```
list_features = ['feature_1', 'feature_2']
feature_1 = tf.ragged.constant([[0], [1, 3]])
feature_2 = tf.ragged.constant([[1, 2], [4]])
f = {'feature_1': feature_1,
     'feature_2': feature_2}
f_inputs = {'feature_1': Input(shape=(), name='feature_1', ragged=True),
            'feature_2': Input(shape=(), name='feature_2', ragged=True)}
out = EmbeddingMerger(list_features)(f_inputs)
model = Model(f_inputs, out)
```

```
truth = model.predict(f)
truth
```
> array([[-0.01802131, -0.01703345,  0.0267079 ],
       [ 0.0096956 , -0.05128085, -0.04486313]], dtype=float32)

If we serialize the model and reload it : 

```
model.save('/tmp/test')
model_reloaded = tf.keras.models.load_model('/tmp/test')
model_reloaded.predict(f)
```
>     ValueError: Layer embedding_merger does not support RaggedTensors as input. Inputs received: {'feature_1': tf.RaggedTensor(values=Tensor(""model/Cast_1:0"", shape=(None,), dtype=float32), row_splits=Tensor(""RaggedFromVariant/RaggedTensorFromVariant:0"", shape=(None,), dtype=int64)), 'feature_2': tf.RaggedTensor(values=Tensor(""model/Cast_3:0"", shape=(None,), dtype=float32), row_splits=Tensor(""RaggedFromVariant_1/RaggedTensorFromVariant:0"", shape=(None,), dtype=int64))}. You can try converting your input to an uniform tensor.

**Describe the expected behavior**
The model should work as well serialized and not serialized and keep its support for ragged inputs in the dict.

**Standalone code to reproduce the issue**
https://colab.research.google.com/gist/tanguycdls/552347a77758674c39b37471f72c3bdf/copie-de-untitled5.ipynb

**TF nighlty**
I found that https://www.tensorflow.org/guide/concrete_function#nested_arguments that stands that TF 2.3 will support that usage in a concrete function. I tried but its actually worse the model does not even support dict of ragged in the non serialized model: https://colab.research.google.com/gist/tanguycdls/e78f2c5329f85b84a8d8db7d1b6a40f1/copie-de-untitled5.ipynb

**TF 2.1.0**
Same as nightly breaks even non serialized on another error:

> ValueError: Error when checking input: expected feature_1 to have 1 dimensions, but got array with shape (2, None)

https://colab.research.google.com/gist/tanguycdls/996ea1f53de753c14cb837f1071e509c/copie-de-untitled5.ipynb
"
38983,[TF2.2rc3] dict of tensors as an input of a keras layer,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): linux
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary pip
- TensorFlow version (use command below): 2.2rc3
- Python version: 3.7
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

**Describe the current behavior**
When we create a keras layer which takes a dict as input the behavior of the layer is not always consistent: 
we create a custom layer such as : 

```
class EmbeddingMerger(tf.keras.layers.Layer):
  def __init__(self, list_features, **kwargs):
    super().__init__(**kwargs)
    self.embeddings = {feature: Embedding(10, 3) for feature in list_features}
  def call(self, inputs):
    tensors = [self.embeddings[col](inputs[col]) for col in inputs]
    return Add()(tensors)
```

We can create a model from it:

```
list_features = ['feature_1', 'feature_2']
feature_1 = tf.constant([0, 1, 3])
feature_2 = tf.constant([1, 2, 4])
f = {'feature_1': feature_1,
     'feature_2': feature_2}
f_inputs = {'feature_1': Input(shape=(), name='feature_1'),
            'feature_2': Input(shape=(), name='feature_2')}
out = EmbeddingMerger(list_features)(f_inputs)
model = Model(f_inputs, out)
```

If we pass to the model:
- the dict with the two features with the correct names **it works as expected.** (called truth) ({'feature_1'; feature_1, 'feature_12: feature_2})`
- the dict with the two features but dict inserted in the wrong order : **gives same result as above** `({'feature_2'; feature_2, 'feature_1': feature_1})`
- the dict with only one feature  breaks with an assertion error because ** it cannot compute such result its the good behavior ** `({'feature_1': feature_1})`
- the dict with the two features and one additional key of name 'test' : **same result as truth which is the correct behavior ( ignoring the feature not used by the layer.)** `({'feature_1': feature_1, 'feature_2': feature_2, 'test': feature_2})`
- a dict with key feature_1 but not feature_2 and one additional key 'test' of value feature_2 : **it gives a result which is not the same as the truth...** `({'feature_1': feature_1, 'test': feature_2})`
> That one should not be calculable since we did not pass 'feature_2'

The same behavior happens with 3, 4 etc... keys I think i can extrapolate that if the correct keys are available everything is fine and the calculation is correct. However if one feature is missing it will take another feature in the dict and use it as it is. 

**Describe the expected behavior**
If the keys needed to run are not available always break with an assertion error. 

**Standalone code to reproduce the issue**
https://colab.research.google.com/gist/tanguycdls/552d6c5f02d8aff0b03fe1ad93825b52/untitled5.ipynb 
Code to do the experiments above. ping me for more use cases. 
"
38982,MirroredStrategy Keras Example Hangs,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): Jupyter Nodebook of a official kubeflow image
`gcr.io/kubeflow-images-public/tensorflow-2.1.0-notebook-gpu:1.0.0` on my kubeflow platform.
- TensorFlow version (use command below): 2.1.0-gpu
- Python version: 3.6.9
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):gcc (Ubuntu 7.4.0-1ubuntu1~18.04.1) 7.4.0
- CUDA/cuDNN version: release 10.1, V10.1.243, but I can't find cuDNN libraries using a command `cat /usr/local/cuda/include/cudnn.h | grep CUDNN_MAJOR -A 2`
- GPU model and memory: T4 / 16G

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: `v1.12.1-30591-g2d3828de27 2.2.0-dev20200427`
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
In my notebook having 4 GPUs, I ran a MirroredStrategy Keras example documented in [here](https://www.tensorflow.org/tutorials/distribute/keras) and all GPUs's memories are occupied, but after printing below logs it hangs.
- logs
```
mkc_choi@hbseo-m$ kubectl -nhanbae-seo logs -cdemo02 demo02-0
[W 09:04:55.882 NotebookApp] All authentication is disabled.  Anyone who can connect to this server will be able to run code.
[I 09:04:56.129 NotebookApp] JupyterLab extension loaded from /usr/local/lib/python3.6/dist-packages/jupyterlab
[I 09:04:56.129 NotebookApp] JupyterLab application directory is /usr/local/share/jupyter/lab
[I 09:04:56.349 NotebookApp] Serving notebooks from local directory: /home/jovyan
[I 09:04:56.349 NotebookApp] The Jupyter Notebook is running at:
[I 09:04:56.349 NotebookApp] http://demo02-0:8888/notebook/hanbae-seo/demo02/
[I 09:04:56.349 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).
[I 09:05:07.112 NotebookApp] 302 GET /notebook/hanbae-seo/demo02/ (127.0.0.1) 0.85ms
[I 09:05:12.368 NotebookApp] Creating new notebook in
[I 09:05:13.255 NotebookApp] Kernel started: 85970d11-8ffb-4259-a0f9-29614d194712
[I 09:07:14.315 NotebookApp] Saving file at /Untitled1.ipynb
[I 09:07:31.203 NotebookApp] Starting buffering for 85970d11-8ffb-4259-a0f9-29614d194712:f7966791845643a9bcb0bc02a3b60f8c
2020-04-28 09:07:46.689575: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-04-28 09:07:54.871181: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-04-28 09:07:55.100937: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-28 09:07:55.101951: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1544] Found device 0 with properties:
pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2020-04-28 09:07:55.102094: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-28 09:07:55.103013: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1544] Found device 1 with properties:
pciBusID: 0000:00:05.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2020-04-28 09:07:55.103126: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-28 09:07:55.104070: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1544] Found device 2 with properties:
pciBusID: 0000:00:06.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2020-04-28 09:07:55.104191: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-28 09:07:55.105138: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1544] Found device 3 with properties:
pciBusID: 0000:00:07.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2020-04-28 09:07:55.105182: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-04-28 09:07:55.108010: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-04-28 09:07:55.110338: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-04-28 09:07:55.111236: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-04-28 09:07:55.113969: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-04-28 09:07:55.115693: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-04-28 09:07:55.120921: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-04-28 09:07:55.121047: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-28 09:07:55.122079: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-28 09:07:55.123059: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-28 09:07:55.124069: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-28 09:07:55.125118: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-28 09:07:55.126190: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-28 09:07:55.127161: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-28 09:07:55.128182: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-28 09:07:55.129220: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1686] Adding visible gpu devices: 0, 1, 2, 3
2020-04-28 09:07:55.130294: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-04-28 09:07:55.138816: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2200000000 Hz
2020-04-28 09:07:55.139503: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x58629a0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-04-28 09:07:55.139544: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-04-28 09:07:56.141806: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-28 09:07:56.157822: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-28 09:07:56.171327: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-28 09:07:56.191060: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-28 09:07:56.193694: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x208f270 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-04-28 09:07:56.193722: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5
2020-04-28 09:07:56.193728: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5
2020-04-28 09:07:56.193733: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (2): Tesla T4, Compute Capability 7.5
2020-04-28 09:07:56.193738: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (3): Tesla T4, Compute Capability 7.5
2020-04-28 09:07:56.199679: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-28 09:07:56.201632: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1544] Found device 0 with properties:
pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2020-04-28 09:07:56.201722: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-28 09:07:56.203759: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1544] Found device 1 with properties:
pciBusID: 0000:00:05.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2020-04-28 09:07:56.203839: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-28 09:07:56.205793: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1544] Found device 2 with properties:
pciBusID: 0000:00:06.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2020-04-28 09:07:56.205876: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-28 09:07:56.207830: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1544] Found device 3 with properties:
pciBusID: 0000:00:07.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2020-04-28 09:07:56.207873: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-04-28 09:07:56.207902: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-04-28 09:07:56.207918: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-04-28 09:07:56.207933: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-04-28 09:07:56.207942: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-04-28 09:07:56.207955: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-04-28 09:07:56.207965: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-04-28 09:07:56.208030: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-28 09:07:56.209924: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-28 09:07:56.211728: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-28 09:07:56.212713: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-28 09:07:56.213698: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-28 09:07:56.214697: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-28 09:07:56.215598: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-28 09:07:56.216512: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-28 09:07:56.217462: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1686] Adding visible gpu devices: 0, 1, 2, 3
2020-04-28 09:07:56.217520: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-04-28 09:07:59.142161: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1085] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-04-28 09:07:59.142208: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1091]      0 1 2 3
2020-04-28 09:07:59.142216: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1104] 0:   N Y N N
2020-04-28 09:07:59.142221: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1104] 1:   Y N N N
2020-04-28 09:07:59.142226: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1104] 2:   N N N Y
2020-04-28 09:07:59.142230: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1104] 3:   N N Y N
2020-04-28 09:07:59.142584: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-28 09:07:59.143574: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-28 09:07:59.144696: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-28 09:07:59.145672: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-28 09:07:59.146611: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-28 09:07:59.147517: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1230] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13969 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)
2020-04-28 09:07:59.148310: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-28 09:07:59.149214: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1230] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 13969 MB memory) -> physical GPU (device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5)
2020-04-28 09:07:59.149788: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-28 09:07:59.150683: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1230] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 13969 MB memory) -> physical GPU (device: 2, name: Tesla T4, pci bus id: 0000:00:06.0, compute capability: 7.5)
2020-04-28 09:07:59.151243: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-28 09:07:59.152188: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1230] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 13969 MB memory) -> physical GPU (device: 3, name: Tesla T4, pci bus id: 0000:00:07.0, compute capability: 7.5)
2020-04-28 09:07:59.157773: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
[I 09:09:33.647 NotebookApp] Saving file at /Untitled1.ipynb
[I 09:10:40.103 NotebookApp] 302 GET /notebook/hanbae-seo/demo02/ (127.0.0.1) 0.62ms
[I 09:12:43.364 NotebookApp] Saving file at /Untitled1.ipynb
[I 09:14:42.569 NotebookApp] Kernel interrupted: 85970d11-8ffb-4259-a0f9-29614d194712
[I 09:14:44.638 NotebookApp] Kernel interrupted: 85970d11-8ffb-4259-a0f9-29614d194712
[I 09:14:46.183 NotebookApp] Kernel interrupted: 85970d11-8ffb-4259-a0f9-29614d194712
[I 09:14:50.198 NotebookApp] Kernel interrupted: 85970d11-8ffb-4259-a0f9-29614d194712
[I 09:14:52.650 NotebookApp] Kernel interrupted: 85970d11-8ffb-4259-a0f9-29614d194712
[I 09:14:54.470 NotebookApp] Kernel interrupted: 85970d11-8ffb-4259-a0f9-29614d194712
[I 09:14:55.575 NotebookApp] Kernel interrupted: 85970d11-8ffb-4259-a0f9-29614d194712
[I 09:14:58.246 NotebookApp] Kernel interrupted: 85970d11-8ffb-4259-a0f9-29614d194712
Error in atexit._run_exitfuncs:
Traceback (most recent call last):
  File ""/usr/lib/python3.6/logging/__init__.py"", line 1945, in shutdown
    h.flush()
  File ""/usr/local/lib/python3.6/dist-packages/absl/logging/__init__.py"", line 892, in flush
    self._current_handler.flush()
  File ""/usr/local/lib/python3.6/dist-packages/absl/logging/__init__.py"", line 785, in flush
    self.stream.flush()
  File ""/usr/local/lib/python3.6/dist-packages/ipykernel/iostream.py"", line 341, in flush
    if self.pub_thread.thread.is_alive():
AttributeError: 'NoneType' object has no attribute 'thread'
[I 09:15:06.715 NotebookApp] Kernel restarted: 85970d11-8ffb-4259-a0f9-29614d194712
2020-04-28 09:15:12.082666: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-04-28 09:15:42.166324: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-04-28 09:15:42.402363: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
.
.
.
.
.
2020-04-28 11:50:42.127628: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-28 11:50:42.130778: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1544] Found device 0 with properties:
pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2020-04-28 11:50:42.130944: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-28 11:50:42.135680: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1544] Found device 1 with properties:
pciBusID: 0000:00:05.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2020-04-28 11:50:42.135781: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-28 11:50:42.143098: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1544] Found device 2 with properties:
pciBusID: 0000:00:06.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2020-04-28 11:50:42.143189: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-28 11:50:42.150307: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1544] Found device 3 with properties:
pciBusID: 0000:00:07.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2020-04-28 11:50:42.150351: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-04-28 11:50:42.152504: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-04-28 11:50:42.154902: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-04-28 11:50:42.155426: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-04-28 11:50:42.157576: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-04-28 11:50:42.158808: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-04-28 11:50:42.163515: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-04-28 11:50:42.163622: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-28 11:50:42.170033: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-28 11:50:42.173795: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-28 11:50:42.178082: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-28 11:50:42.187495: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-28 11:50:42.194851: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-28 11:50:42.202891: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-28 11:50:42.208997: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-28 11:50:42.213464: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1686] Adding visible gpu devices: 0, 1, 2, 3
2020-04-28 11:50:42.214783: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-04-28 11:50:42.222662: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2200000000 Hz
2020-04-28 11:50:42.223394: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5d3a7c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-04-28 11:50:42.223423: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-04-28 11:50:43.541123: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-28 11:50:43.558363: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-28 11:50:43.569507: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-28 11:50:43.585723: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-28 11:50:43.587840: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5669ea0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-04-28 11:50:43.587865: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5
2020-04-28 11:50:43.587871: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5
2020-04-28 11:50:43.587876: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (2): Tesla T4, Compute Capability 7.5
2020-04-28 11:50:43.587880: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (3): Tesla T4, Compute Capability 7.5
2020-04-28 11:50:43.593961: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-28 11:50:43.595914: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1544] Found device 0 with properties:
pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2020-04-28 11:50:43.595983: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-28 11:50:43.597987: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1544] Found device 1 with properties:
pciBusID: 0000:00:05.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2020-04-28 11:50:43.598069: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-28 11:50:43.600110: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1544] Found device 2 with properties:
pciBusID: 0000:00:06.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2020-04-28 11:50:43.600215: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-28 11:50:43.602185: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1544] Found device 3 with properties:
pciBusID: 0000:00:07.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2020-04-28 11:50:43.602229: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-04-28 11:50:43.602250: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-04-28 11:50:43.602265: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-04-28 11:50:43.602275: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-04-28 11:50:43.602287: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-04-28 11:50:43.602296: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-04-28 11:50:43.602305: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-04-28 11:50:43.602363: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-28 11:50:43.604392: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-28 11:50:43.606481: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-28 11:50:43.608546: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-28 11:50:43.610742: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-28 11:50:43.612800: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-28 11:50:43.615044: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-28 11:50:43.616887: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-28 11:50:43.618745: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1686] Adding visible gpu devices: 0, 1, 2, 3
2020-04-28 11:50:43.618810: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-04-28 11:50:45.761140: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1085] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-04-28 11:50:45.761202: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1091]      0 1 2 3
2020-04-28 11:50:45.761210: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1104] 0:   N Y N N
2020-04-28 11:50:45.761216: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1104] 1:   Y N N N
2020-04-28 11:50:45.761220: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1104] 2:   N N N Y
2020-04-28 11:50:45.761225: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1104] 3:   N N Y N
2020-04-28 11:50:45.761562: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-28 11:50:45.762656: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-28 11:50:45.763675: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-28 11:50:45.764693: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-28 11:50:45.765747: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-28 11:50:45.766736: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1230] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13969 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)
2020-04-28 11:50:45.767518: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-28 11:50:45.768518: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1230] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 13969 MB memory) -> physical GPU (device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5)
2020-04-28 11:50:45.769142: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-28 11:50:45.770076: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1230] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 13969 MB memory) -> physical GPU (device: 2, name: Tesla T4, pci bus id: 0000:00:06.0, compute capability: 7.5)
2020-04-28 11:50:45.770664: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-28 11:50:45.771659: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1230] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 13969 MB memory) -> physical GPU (device: 3, name: Tesla T4, pci bus id: 0000:00:07.0, compute capability: 7.5)
2020-04-28 11:50:47.091531: I tensorflow/core/profiler/lib/profiler_session.cc:154] Profiler session started.
2020-04-28 11:50:47.091683: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1372] Profiler found 4 GPUs
2020-04-28 11:50:47.093991: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcupti.so.10.1
2020-04-28 11:50:47.194680: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1422] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI_ERROR_INSUFFICIENT_PRIVILEGES
2020-04-28 11:50:47.283735: W tensorflow/core/kernels/data/captured_function.cc:458] Disabling multi-device execution for a function that uses the experimental_ints_on_device attribute.
2020-04-28 11:50:47.302659: W tensorflow/core/kernels/data/captured_function.cc:458] Disabling multi-device execution for a function that uses the experimental_ints_on_device attribute.
2020-04-28 11:50:47.321059: W tensorflow/core/kernels/data/captured_function.cc:458] Disabling multi-device execution for a function that uses the experimental_ints_on_device attribute.
2020-04-28 11:50:47.341426: W tensorflow/core/kernels/data/captured_function.cc:458] Disabling multi-device execution for a function that uses the experimental_ints_on_device attribute.
2020-04-28 11:50:47.342187: W tensorflow/core/kernels/data/captured_function.cc:458] Disabling multi-device execution for a function that uses the experimental_ints_on_device attribute.
2020-04-28 11:50:47.344125: W tensorflow/core/kernels/data/captured_function.cc:458] Disabling multi-device execution for a function that uses the experimental_ints_on_device attribute.
2020-04-28 11:50:47.345834: W tensorflow/core/kernels/data/captured_function.cc:458] Disabling multi-device execution for a function that uses the experimental_ints_on_device attribute.
2020-04-28 11:50:47.347581: W tensorflow/core/kernels/data/captured_function.cc:458] Disabling multi-device execution for a function that uses the experimental_ints_on_device attribute.
2020-04-28 11:50:47.404901: W tensorflow/core/kernels/data/captured_function.cc:458] Disabling multi-device execution for a function that uses the experimental_ints_on_device attribute.
2020-04-28 11:50:47.424905: W tensorflow/core/kernels/data/captured_function.cc:458] Disabling multi-device execution for a function that uses the experimental_ints_on_device attribute.
2020-04-28 11:50:47.444686: W tensorflow/core/kernels/data/captured_function.cc:458] Disabling multi-device execution for a function that uses the experimental_ints_on_device attribute.
2020-04-28 11:50:47.463115: W tensorflow/core/kernels/data/captured_function.cc:458] Disabling multi-device execution for a function that uses the experimental_ints_on_device attribute.
2020-04-28 11:50:47.463881: W tensorflow/core/kernels/data/captured_function.cc:458] Disabling multi-device execution for a function that uses the experimental_ints_on_device attribute.
2020-04-28 11:50:47.465529: W tensorflow/core/kernels/data/captured_function.cc:458] Disabling multi-device execution for a function that uses the experimental_ints_on_device attribute.
2020-04-28 11:50:47.467173: W tensorflow/core/kernels/data/captured_function.cc:458] Disabling multi-device execution for a function that uses the experimental_ints_on_device attribute.
2020-04-28 11:50:47.468860: W tensorflow/core/kernels/data/captured_function.cc:458] Disabling multi-device execution for a function that uses the experimental_ints_on_device attribute.
2020-04-28 11:50:51.405795: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-04-28 11:50:52.668100: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
```

- Outputs generated with the example on Nodebook
```
WARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.
Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.
To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.
2.2.0-dev20200427
INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')
INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')
Number of devices: 4
Epoch 1/12
INFO:tensorflow:batch_all_reduce: 6 all-reduces with algorithm = nccl, num_packs = 1
INFO:tensorflow:batch_all_reduce: 6 all-reduces with algorithm = nccl, num_packs = 1
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:batch_all_reduce: 6 all-reduces with algorithm = nccl, num_packs = 1
INFO:tensorflow:batch_all_reduce: 6 all-reduces with algorithm = nccl, num_packs = 1
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
```

- The MirroredStrategy Keras example I applied (https://www.tensorflow.org/tutorials/distribute/keras)
```
import tensorflow_datasets as tfds
import tensorflow as tf
tfds.disable_progress_bar()

import os

print(tf.__version__)

datasets, info = tfds.load(name='mnist', with_info=True, as_supervised=True)
mnist_train, mnist_test = datasets['train'], datasets['test']
strategy = tf.distribute.MirroredStrategy()

print('Number of devices: {}'.format(strategy.num_replicas_in_sync))

# You can also do info.splits.total_num_examples to get the total
# number of examples in the dataset.

num_train_examples = info.splits['train'].num_examples
num_test_examples = info.splits['test'].num_examples

BUFFER_SIZE = 10000
BATCH_SIZE_PER_REPLICA = 64
BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync

def scale(image, label):
  image = tf.cast(image, tf.float32)
  image /= 255

  return image, label

train_dataset = mnist_train.map(scale).cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE)
eval_dataset = mnist_test.map(scale).batch(BATCH_SIZE)

with strategy.scope():
  model = tf.keras.Sequential([
      tf.keras.layers.Conv2D(32, 3, activation='relu', input_shape=(28, 28, 1)),
      tf.keras.layers.MaxPooling2D(),
      tf.keras.layers.Flatten(),
      tf.keras.layers.Dense(64, activation='relu'),
      tf.keras.layers.Dense(10)
  ])

  model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
                optimizer=tf.keras.optimizers.Adam(),
                metrics=['accuracy'])

# Define the checkpoint directory to store the checkpoints
checkpoint_dir = './training_checkpoints'
# Name of the checkpoint files
checkpoint_prefix = os.path.join(checkpoint_dir, ""ckpt_{epoch}"")

# Function for decaying the learning rate.
# You can define any decay function you need.
def decay(epoch):
  if epoch < 3:
    return 1e-3
  elif epoch >= 3 and epoch < 7:
    return 1e-4
  else:
    return 1e-5

# Callback for printing the LR at the end of each epoch.
class PrintLR(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs=None):
    print('\nLearning rate for epoch {} is {}'.format(epoch + 1,
                                                      model.optimizer.lr.numpy()))
callbacks = [
    tf.keras.callbacks.TensorBoard(log_dir='./logs'),
    tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_prefix,
                                       save_weights_only=True),
    tf.keras.callbacks.LearningRateScheduler(decay),
    PrintLR()
]

model.fit(train_dataset, epochs=12, callbacks=callbacks)
```

- And GPU memories are occupied but all GPU's `GPU-Util Compute M.` is 0%.
```
mkc_choi@hbseo-g1:~/tf-operator/examples/v1/multi$ nvidia-smi
Tue Apr 28 13:50:50 2020       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 440.82       Driver Version: 440.82       CUDA Version: 10.2     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |
| N/A   71C    P0    32W /  70W |  14612MiB / 15109MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   1  Tesla T4            Off  | 00000000:00:05.0 Off |                    0 |
| N/A   41C    P0    27W /  70W |  14612MiB / 15109MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   2  Tesla T4            Off  | 00000000:00:06.0 Off |                    0 |
| N/A   41C    P0    26W /  70W |  14612MiB / 15109MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   3  Tesla T4            Off  | 00000000:00:07.0 Off |                    0 |
| N/A   41C    P0    27W /  70W |  14612MiB / 15109MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|    0     24210      C   /usr/bin/python3                           14601MiB |
|    1     24210      C   /usr/bin/python3                           14601MiB |
|    2     24210      C   /usr/bin/python3                           14601MiB |
|    3     24210      C   /usr/bin/python3                           14601MiB |
+-----------------------------------------------------------------------------+
```

- When I specify `CUDA_VISIBLE_DEVICES` number as below, it run, but on only one GPU.
```
os.environ['CUDA_VISIBLE_DEVICES'] = '0'
```

- And I tried to set ""tf.data.experimental.AutoShardPolicy.OFF"" described in an existing issue [here](https://github.com/tensorflow/tensorflow/issues/35878), but the result is same. codes are below
```
import os
import tensorflow_datasets as tfds
import tensorflow as tf
strategy = tf.distribute.MirroredStrategy()
# strategy = tf.distribute.MirroredStrategy() # NCCL vs RING
print('Number of devices: {}'.format(strategy.num_replicas_in_sync))
BUFFER_SIZE = 10000
BATCH_SIZE = 64
def make_datasets_unbatched():
  # Scaling MNIST data from (0, 255] to (0., 1.]
  def scale(image, label):
    image = tf.cast(image, tf.float32)
    image /= 255
    return image, label
  datasets, info = tfds.load(name='mnist',
                            with_info=True,
                            as_supervised=True)
  return datasets['train'].map(scale).cache().shuffle(BUFFER_SIZE)

def build_and_compile_cnn_model():
  model = tf.keras.Sequential([
    tf.keras.layers.Conv2D(32, 3, activation='relu', input_shape=(28, 28, 1)),
    tf.keras.layers.MaxPooling2D(),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(10, activation='softmax')
  ])
  model.compile(
    loss=tf.keras.losses.sparse_categorical_crossentropy,
    optimizer=tf.keras.optimizers.SGD(learning_rate=0.001),
    metrics=['accuracy'])
  return model
GLOBAL_BATCH_SIZE = 64 * 2
with strategy.scope():
  train_datasets = make_datasets_unbatched().batch(GLOBAL_BATCH_SIZE).repeat()
  options = tf.data.Options()
  options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.DATA
  train_datasets = train_datasets.with_options(options)
  multi_worker_model = build_and_compile_cnn_model()
multi_worker_model.fit(x=train_datasets, epochs=3, steps_per_epoch=5)
```

**Describe the expected behavior**

- The example runs with multiple GPUs

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached."
38981,Build won't start.,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):MacOS 10.13.6(17g65)
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):source
- TensorFlow version:1.14
- Python version:3.6.5
- Installed using virtualenv? pip? conda?:
- Bazel version (if compiling from source):0.24.1
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:10
- GPU model and memory:GTX GeForce 1080ti



**Describe the problem**
I want to build tensorflow 1.14, but I get an error like this and I can't start it.
Please tell why it is

`ERROR: Skipping '//tensorflow/tools/pip_package:build_pip_package': error loading package 'tensorflow/tools/pip_package': Encountered error while reading extension file 'cuda/build_defs.bzl': no such package '@local_config_cuda//cuda': Traceback (most recent call last):
	File ""/Users/zen/tensorflow/third_party/gpus/cuda_configure.bzl"", line 1266
		_create_local_cuda_repository(repository_ctx)
	File ""/Users/zen/tensorflow/third_party/gpus/cuda_configure.bzl"", line 1033, in _create_local_cuda_repository
		_find_libs(repository_ctx, cuda_config)
	File ""/Users/zen/tensorflow/third_party/gpus/cuda_configure.bzl"", line 607, in _find_libs
		_find_cuda_lib(""cuda"", repository_ctx, cpu_value, (cu...), ...)
	File ""/Users/zen/tensorflow/third_party/gpus/cuda_configure.bzl"", line 588, in _find_cuda_lib
		find_lib(repository_ctx, [(""%s/%s"" % (based...))], ...)))
	File ""/Users/zen/tensorflow/third_party/gpus/cuda_configure.bzl"", line 565, in find_lib
		auto_configure_fail((""No library found under: "" + "",...)))
	File ""/Users/zen/tensorflow/third_party/gpus/cuda_configure.bzl"", line 324, in auto_configure_fail
		fail((""\n%sCuda Configuration Error:%...)))

Cuda Configuration Error: No library found under: /usr/local/cuda/lib/stubs/libcuda.dylib
WARNING: Target pattern parsing failed.
ERROR: error loading package 'tensorflow/tools/pip_package': Encountered error while reading extension file 'cuda/build_defs.bzl': no such package '@local_config_cuda//cuda': Traceback (most recent call last):
	File ""/Users/zen/tensorflow/third_party/gpus/cuda_configure.bzl"", line 1266
		_create_local_cuda_repository(repository_ctx)
	File ""/Users/zen/tensorflow/third_party/gpus/cuda_configure.bzl"", line 1033, in _create_local_cuda_repository
		_find_libs(repository_ctx, cuda_config)
	File ""/Users/zen/tensorflow/third_party/gpus/cuda_configure.bzl"", line 607, in _find_libs
		_find_cuda_lib(""cuda"", repository_ctx, cpu_value, (cu...), ...)
	File ""/Users/zen/tensorflow/third_party/gpus/cuda_configure.bzl"", line 588, in _find_cuda_lib
		find_lib(repository_ctx, [(""%s/%s"" % (based...))], ...)))
	File ""/Users/zen/tensorflow/third_party/gpus/cuda_configure.bzl"", line 565, in find_lib
		auto_configure_fail((""No library found under: "" + "",...)))
	File ""/Users/zen/tensorflow/third_party/gpus/cuda_configure.bzl"", line 324, in auto_configure_fail
		fail((""\n%sCuda Configuration Error:%...)))

Cuda Configuration Error: No library found under: /usr/local/cuda/lib/stubs/libcuda.dylib
`

**Provide the exact sequence of commands / steps that you executed before running into the problem**


**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached."
38978,mismatching quantization parameters(scale and zero point),"**System information**
- Linux Ubuntu 18.04  x86-CPU
- TensorFlow installed from binary
- TensorFlow version 1.15 - GPU


**Command used to run the converter or code if you’re using the Python API**

`import tensorflow as tf
import numpy as np

def representative_dataset_gen():
  for _ in range(100):
    fake_image = np.random.random((1,432,368,3)).astype(np.float32)
    yield [fake_image]

graph_pb = 'graph_freeze.pb'
inp = ['image']
out = ['Openpose/concat_stage7']
converter=tf.lite.TFLiteConverter.from_frozen_graph(
        graph_pb, inp, out,input_shapes={""image"":[1,432,368,3]})
converter.optimizations = [tf.lite.Optimize.DEFAULT]
converter.representative_dataset = representative_dataset_gen
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]
converter.inference_input_type = tf.uint8
converter.inference_output_type = tf.uint8
tflite_model = converter.convert()

f = open(""tflite_model/mobilenet_thin_openpose_opt_fullint_tf1.tflite"", ""wb"")
f.write(tflite_model)

f.close()

print(""conversion complete"")
`
**GraphDef used for conversion**
https://drive.google.com/file/d/1uMdkXXklwDNczD5ZGQR73Rkg9MFEax82/view?usp=sharing

**converted model**
https://drive.google.com/file/d/1BZ0gVX00Vnqhthx_wxmMXQAbkisSAftN/view?usp=sharing

**Failure details**
I'm currently trying to convert a graghdef file into a fully quantized tflite model. I want to use Coral Edge TPU for inference for which the converted TFLite model needs to be passed through EdgeTPU Compiler. Unfortunately the converted TFlite model is rejected by the compiler. Upon Investigation with a person from Coral Team he pointed me out to this ""There is a layer name Openpose/MConv_Stage3_concat with 2 preceeded layers that has mismatching quantization parameters(scale and zero point)""  

You can also take a look at the discussion in the issues thread pertaining to the Coral EdgeTPU Implementation. #https://github.com/google-coral/edgetpu/issues/100#issue-604992155
Would be nice if I could fix the issue.

Thanks"
38976,How to check if a tensor is empty in TensorFlow,"Hi there,

I am just using TensorFlow to train a CNN model. I used a command:

    t_iteration = tf.placeholder('int32', [], name='t_iteration') to initialize a tensor with shape of (0,).

I would want to know how to judge if the tensor t_iteration is empty? I have tried to use

    x = tf.constant(3)
    y = tf.constant(5)
     idx0 = tf.shape(t_iteration)
            A = tf.cond(tf.cast(idx0 == 0, tf.bool),
                                        lambda: tf.multiply(x, 17),
                                        lambda: tf.add(y, 23))
But I found that this method didn't work-as the `idx0' always equals to 0 even the tensor has not been assigned any value.

How to solve this tricky issue?

Thanks!"
38974,Add seed parameter to a Dense layer so that kernel initializers could use it for reproducibility,"
**System information**
- TensorFlow version (you are using): tf.version.GIT_VERSION = v2.1.0-rc2-17-ge5bf8de410
- Are you willing to contribute it (Yes/No): Yes



**Describe the feature and the current behavior/state.**
Right now `initializers.py` package has initializers that could be seeded but there is no way for users to specify seed when model and its layers are being specified.

**Will this change the current api? How?**
Yes, adds seed parameter to a Dense layer. So docs would probably need to be updated.

**Who will benefit with this feature?**
Anyone who will want to have reproducible results from their neural network. Some initializers already have `seed` parameter in their API so this PR is just an attempt to make integration of APIs more complete.
**Any Other info.**

- As there probably are other Layers that have kernel initializers we need to check them and add support for  them as well
- regularizers and constraints theoretically can also leverage availability of seed but in current implementation I don't see any of them to be using seeds
- I was trying to run all tests in tensorflow by using Docker but not sure that I'm doing it correctly. It was taking too long and I could see C++ tests to be running. I would appreciate some guidance here. So I was able to run only my own test that I will submit within upcoming PR
"
38973,Error of installation,"**System information**
- Windows 10 Pro
- Python version: 3.8.2
- GPU model and memory: 
   -GeForce GTX 1080 Ti
   - 19281 MB

**Describe the problem**

Hi everyone, I had a problem on installing Tensorflow 2.1.0 via pip on Windows; as soon as i use this command i get this error:
    pip install tensorflow
    ERROR: Could not find a version that satisfies the requirement tensorflow (from versions: none)
    ERROR: No matching distribution found for tensorflow
How can I fix this problem?"
38972,Adam optimizing performance issue,"Hi,
Using tensorflow 2.2.0-rc3 on Ubuntu 18.04 and Python 3.8.2, I've converted my code for both compat.v1 and v2 which was required by tf2onnx.
There is a huge difference in speed between v1 and v2 and I was wondering how to solve this.
My v2 implementation is:
```python
	built_model = tf.keras.Model(inputs=model.inputs, outputs=model.outputs)
	model.load_weights()

	@tf.function
	def train_fn(inputs, targets):
		with tf.GradientTape() as tape:
			outputs = built_model(inputs)
			loss, metrics, _ = dataset.loss(outputs, targets)

		gradients = tape.gradient(loss, built_model.trainable_variables)
		optimizer.apply_gradients(zip(gradients, built_model.trainable_variables))
		return loss, metrics, learning_rate, global_step
```

while my v1 is:

```python
	session = tf.compat.v1.Session()
	tf.compat.v1.keras.backend.set_session(session)
	model.load_weights(session=session)

	loss, metrics, targets_pl = dataset.loss(model.outputs)
	tvars = tf.compat.v1.trainable_variables()
	gvs = optimizer.get_gradients(loss, tvars)
	train_op = optimizer.apply_gradients(zip(gvs, tvars))

	def train_fn(inputs, targets):
		loss_, _, global_step_, metrics_, lr_ = session.run([loss, train_op, global_step, metrics, learning_rate], feed_dict=dict(zip(model.inputs+targets_pl, inputs+targets)))
		return loss_, metrics_, lr_, global_step_
```

I also have a predict function that is as fast. It looks like the derivative is slow. 
I would like to migrate everything to v2.
Thank you for your help.
"
38970,RaggedTensor raises error with Keras TimeDistributed Layer,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): CentOS 7
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary, pip installed
- TensorFlow version (use command below): pip install tensorflow-gpu==2.2.0rc3
- Python version: 3.7.0
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: CUDA 10.1 / cuDNN 7.6.5
- GPU model and memory: GTX 1080 Ti 11G / 128G RAM

**Describe the current behavior**

I builded a hierarchical lstm model for binary classification:

```python
model = Sequential()
model.add(layers.TimeDistributed(layers.Masking(-1),input_shape=(None,20,1)))
model.add(layers.TimeDistributed(layers.LSTM(num_units_1,dropout=0.4)))
model.add(layers.LSTM(num_units_2))
model.add(layers.Dense(1))
model.summary()
```

I then generated my `x_train` as a tf.RaggedTensor, with shape `[10000, None, 20, 1]`, each slice over the out most dimension of this ragged tensor is a tf.Tensor with shape `[x, 20, 1]`.

The reason I have to use RaggedTensor is I can't figure out a way to do padding over the 2nd dimension. My each input sequence is a variable length sequence of variable length sequences, I padded the lower time dimension and then mask it with time distributed masking, but there seems no apparent way how to do masking before the 2nd lstm layer.

Now if run it with:

```python
history = model.fit(train_data, epochs=epochs, verbose=1, steps_per_epoch=-(-sample_count//batch_size))
```

I'd get:

>ValueError: All inputs to `ConcreteFunction`s must be Tensors; on invocation of __backward_standard_lstm_1179546, the 0-th input (IndexedSlices(indices=Tensor(""gradient_tape/sequential_29/lstm_55/RaggedToTensor/boolean_mask_1/GatherV2:0"", shape=(None,), dtype=int32), values=Tensor(""gradient_tape/sequential_29/lstm_55/RaggedToTensor/boolean_mask/GatherV2:0"", shape=(None, 32), dtype=float32), dense_shape=Tensor(""gradient_tape/sequential_29/lstm_55/RaggedToTensor/Shape:0"", shape=(2,), dtype=int32))) was not a Tensor.


**Describe the expected behavior**

TimeDistributed layer should support RaggedTensor if the underlying model can process slice of RaggedTensor and output dimension is matched.

**Standalone code to reproduce the issue**
```python
import tensorflow as tf
from tensorflow.keras import layers, Model, Sequential
import numpy as np

x = tf.RaggedTensor.from_row_splits(np.ones((100,20,1)),[0,4,20,100])
y = np.ones((3,1))

model = Sequential()
model.add(layers.TimeDistributed(layers.LSTM(32,dropout=0.4),input_shape=(None,20,1)))
model.add(layers.LSTM(24))
model.add(layers.Dense(1,activation='sigmoid'))
model.compile(loss='binary_crossentropy', optimizer='adam')
history = model.fit(x=x, y=y, epochs=10, verbose=1)
```
"
38969,Thread hang when setting inter_op_parallelism_threads=1,"**System information**

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04
- TensorFlow version (use command below): tf-nightly
- Python version: 3.6.8



**Describe the current behavior**



Thread will hang if setting `inter_op_parallelism_threads=1`.



**Standalone code to reproduce the issue**



```python
import tensorflow as tf

from tensorflow.python.eager import context
from tensorflow.python.eager import function
from tensorflow.python.framework import constant_op
from tensorflow.python.framework import dtypes
from tensorflow.python.framework import test_util
from tensorflow.python.framework.ops import disable_eager_execution
from tensorflow.python.ops import array_ops
from tensorflow.python.ops import cond_v2
from tensorflow.python.platform import test

disable_eager_execution()
tf.config.threading.set_inter_op_parallelism_threads(num_threads=1)  # pass if set 2


class ThreadHangTest(test_util.TensorFlowTestCase):
    """"""reproduce thread hang when setting inter_op=1.""""""

    def testLoweringDisabledWithSingleThreadedExecutorContext(self):
        with self.session() as sess:
            @function.defun
            def _add_cond(y):
                return cond_v2.cond_v2(constant_op.constant(True, name=""pred""),
                                       lambda: y,
                                       lambda: y + 1)

            x = array_ops.placeholder(shape=None, dtype=dtypes.float32)
            with context.function_executor_type(""SINGLE_THREADED_EXECUTOR""):
                out_cond = _add_cond(x)
            sess.run(out_cond, feed_dict={x: 1.0})
            
 
if __name__ == '__main__':
    test.main()

```

**Other info**

Call stack on C++ side: `PartitionedCallOp::ComputeAsync() -> PartitionedCallOp::RunFunction() -> FunctionLibirayRuntimeImpl::Run()`. 


"
38967,tensorflow ,"![error](https://user-images.githubusercontent.com/60228576/80450122-7446dc00-893e-11ea-8520-6ad83835c874.png)

"
38966,How to convert TenorFlow model with functional ops to graph definition with no Tensorflow version installed?,"In TensorFlow V2, functional control ops such if/while/for/case are introduced, if the model contains such functional control ops, how to convert them to graph definition?
In TensorFlow, there are some methods to transmit original node names correctly in file.
InstantiateFunction - AddDefaultAttrs
                                - helper.BuildNodeOutputIndex
				- helper.InstantiateNode
But in some other circustances if there is no TensorFlow installed, how to convert TenorFlow model with functional ops to graph definition?"
38963,"image.image_gradients error ""Duplicate node name in graph: 'stack'""","### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10.0.17134
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: v2.0.0-rc2-26-g64c3d382ca 2.0.0
- **Python version**: 3.7.7
- **CUDA/cuDNN version**: Running on CPU
- **GPU model and memory**:
- **Exact command to reproduce**:

### Describe the problem
When trying to use tf.image.image_gradients, get an error: ""ValueError: Duplicate node name in graph: 'stack'"", when trying to predict the model.

### Source code / logs
The source code can be found below:

```
from tensorflow import image
from tensorflow.keras import layers, Model
import tensorflow as tf
from tensorflow.keras import backend as K
import numpy as np

myInput = layers.Input(shape=(4, 4, 1))

[deltaP_t_i, deltaP_t_j] = image.image_gradients(myInput[:, :, :, 0:1])
loss_grad = tf.norm(deltaP_t_i, axis=(1, 2)) + tf.norm(deltaP_t_i, axis=(1, 2))
loss_grad = K.mean(loss_grad, axis=-1)

myModel = Model(inputs=[myInput], outputs=[loss_grad])

x = np.array([[1, 2, 3, 4],
                [5, 6, 7, 8.1],
                [9, 10, 11, 12],
                [13, 14, 15, 16]])

x = np.reshape(x, (1, 4, 4, 1))

out1 = myModel.predict([x])
```

and the output is below:

``` 
2020-04-27 18:50:11.221070: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2
Traceback (most recent call last):
  File ""C:\Users\emiliocoutinho\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\framework\ops.py"", line 1610, in _create_c_op
    c_op = c_api.TF_FinishOperation(op_desc)
tensorflow.python.framework.errors_impl.InvalidArgumentError: Duplicate node name in graph: 'stack'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""D:/test/TestPhysicalLossToReport.py"", line 9, in <module>
    [deltaP_t_i, deltaP_t_j] = image.image_gradients(myInput[:, :, :, 0:1])
  File ""C:\Users\emiliocoutinho\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\ops\image_ops_impl.py"", line 3456, in image_gradients
    shape = array_ops.stack([batch_size, height, 1, depth])
  File ""C:\Users\emiliocoutinho\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\util\dispatch.py"", line 180, in wrapper
    return target(*args, **kwargs)
  File ""C:\Users\emiliocoutinho\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\ops\array_ops.py"", line 1165, in stack
    return gen_array_ops.pack(values, axis=axis, name=name)
  File ""C:\Users\emiliocoutinho\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\ops\gen_array_ops.py"", line 6303, in pack
    ""Pack"", values=values, axis=axis, name=name)
  File ""C:\Users\emiliocoutinho\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\framework\op_def_library.py"", line 793, in _apply_op_helper
    op_def=op_def)
  File ""C:\Users\emiliocoutinho\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\framework\func_graph.py"", line 548, in create_op
    compute_device)
  File ""C:\Users\emiliocoutinho\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\framework\ops.py"", line 3429, in _create_op_internal
    op_def=op_def)
  File ""C:\Users\emiliocoutinho\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\framework\ops.py"", line 1773, in __init__
    control_input_ops)
  File ""C:\Users\emiliocoutinho\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\framework\ops.py"", line 1613, in _create_c_op
    raise ValueError(str(e))
ValueError: Duplicate node name in graph: 'stack'

Process finished with exit code 1
```"
38962,Pip could not find version under 2.2 on Windows,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- TensorFlow installed from (source or binary): Pip
- TensorFlow version: 1.15
- Python version: 3.8
- Installed using virtualenv? pip? conda?: pip
- GPU model and memory:NVIDIA GeForce GTX1070, 8GB

*Describe the problem*
When attempting to install tensorflow 1.15 with pip on Windows 10, I receive an error that only various versions of 2.2 are available.

> C:\>pip3 install tensorflow==1.15
> ERROR: Could not find a version that satisfies the requirement tensorflow==1.15 (from versions: 2.2.0rc1, 2.2.0rc2, 2.2.0rc3)
> ERROR: No matching distribution found for tensorflow==1.15

Problem also exists when trying to install another package with tensorflow<2.2 as a dependency - pip install magenta stops and gives the same error:

> ERROR: Could not find a version that satisfies the requirement tensorflow<2.0.0,>=1.15.0 (from magenta) (from versions: 2.2.0rc1, 2.2.0rc2, 2.2.0rc3)
> ERROR: No matching distribution found for tensorflow<2.0.0,>=1.15.0 (from magenta)

"
38961,EdgeTPU compiler creates a model with different behaviour,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): YES
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04.1
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: -
- TensorFlow installed from (source or binary): Docker image latest-gpu-py3-jupyter
- TensorFlow version (use command below): 2.1.0
- Python version: 3.6
- Bazel version (if compiling from source): -
- GCC/Compiler version (if compiling from source): -
- CUDA/cuDNN version: 10.1
- GPU model and memory: Nvidia RTX 2080TI / 12 GB

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
When I try to compile fot edgeTPU a full-quatized and fully working model it just shows a different not expected output

**Describe the expected behavior**
Same output for same input in both models: full quantized and compiled for EdgeTPU from the previous full quantized.

**Standalone code to reproduce the issue**
You can see the problem here
https://gist.github.com/ianholing/cbda145cfeb03124d6a286c619302aa6

And here there are anything you need to reproduce the notebook:
https://drive.google.com/open?id=1u9fH3PVmfmR4xXIJnXOPlx789eyKhVOS

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
38954,Random uniform is inconsistent given same seed values," 
**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
  _I was trying to use one of example usages from tensorflow docs and wanted to make results reproducible. After investigation it looks to me that `gen_random_ops.random_uniform` is inconsistent given seeds. That is why I have written a test ( custom code)_
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
   _Darwin-18.0.0-x86_64-i386-64bit_
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: _No_
- TensorFlow installed from : _pip install tensorflow_
- TensorFlow version : _v2.1.0-rc2-17-ge5bf8de410 2.1.0_
- Python version: python version: _3.7.6_
- Bazel version (if compiling from source): _brew installation_
- GCC/Compiler version (if compiling from source): -
- CUDA/cuDNN version: -
- GPU model and memory: -


**Describe the current behavior**
`gen_random_ops.random_uniform` return different values even with same seeds
**Describe the expected behavior**
consistent behaviour is expected give same seeds

**Standalone code to reproduce the issue**
```
shape = (8,12)
dtype = 'float32'
seed = 5
seed2 = 1234
tf.random.set_seed(seed)
rnd = gen_random_ops.random_uniform(shape, dtype, seed=seed, seed2=seed2)
rnd2 = gen_random_ops.random_uniform(shape, dtype, seed=seed, seed2=seed2)
# rnd and rnd2 will be different
```

**Other info / logs** 
code does not throw exceptions. Just expected behaviour is different from results.

From `random_seed.py` I can see that probably it is expected behaviour but I don't understand why is that. This counter that keeps changing seed  by default is a way to avoid generation of same values? But usually for tests we need reproducibility. Does it mean that It should be done through re-setting of the `tf.random.set_seed(1234)`?
"
38951,hlo_algorithm_blacklist.cc compilation fails,"
**System information**
- OS Platform and Distribution: Windows 10 (10.0.18363 N/A Build 18363)
- Mobile device if the issue happens on mobile device: n/a
- TensorFlow installed from (source or binary): Source
- TensorFlow version: r.2.1
- Python version: 3.6.10
- Installed using virtualenv? pip? conda?: conda
- Bazel version (if compiling from source): 0.29.1
- GCC/Compiler version (if compiling from source): VS2019
- CUDA/cuDNN version: 10.1, 7.6.5
- GPU model and memory: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.607GHz coreCount: 28 deviceMemorySize: 11.00GiB deviceMemoryBandwidth: 451.17GiB/s

**Describe the problem**

I git cloned the tensorflow, followed the build instructions for a windows build...
the output from the configure script is:
```
build --action_env PYTHON_BIN_PATH=""C:/Users/Eric/anaconda3/envs/compileTF/python.exe""
build --action_env PYTHON_LIB_PATH=""C:/Users/Eric/anaconda3/envs/compileTF/lib/site-packages""
build --python_path=""C:/Users/Eric/anaconda3/envs/compileTF/python.exe""
build:xla --define with_xla_support=true
build --config=xla
build --action_env CUDA_TOOLKIT_PATH=""C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v10.1""
build --action_env TF_CUDA_COMPUTE_CAPABILITIES=""6.1""
build --config=cuda
build:opt --copt=/arch:AVX
build:opt --define with_default_optimizations=true
build --config monolithic
build --copt=-w --host_copt=-w
build --copt=-DWIN32_LEAN_AND_MEAN --host_copt=-DWIN32_LEAN_AND_MEAN --copt=-DNOGDI --host_copt=-DNOGDI --copt=-D_USE_MATH_DEFINES
build --verbose_failures
build --distinct_host_configuration=false
build --define=override_eigen_strong_inline=true
test --flaky_test_attempts=3
test --test_size_filters=small,medium
test --test_tag_filters=-benchmark-test,-no_oss,-oss_serial
test --build_tag_filters=-benchmark-test,-no_oss
test --test_tag_filters=-no_windows,-gpu
test --build_tag_filters=-no_windows,-gpu
build --action_env TF_CONFIGURE_IOS=""0""
```

then I started the compilation with: 
`bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package`

the error message is the following:
```
cl : Command line warning D9002 : ignoring unknown option '-std=c++14'
tensorflow/compiler/xla/service/gpu/hlo_algorithm_blacklist.cc(28): error C2131: expression did not evaluate to a constant
external/com_google_absl\absl/strings/string_view.h(186): note: a non-constant (sub-)expression was encountered
Target //tensorflow/tools/pip_package:build_pip_package failed to build
```

**Any other info / logs**
the code surrounding the error:
```c++
// MSVC requires the extra const. Without, it reports an
// ""error C2131: expression did not evaluate to a constant"".
constexpr const absl::string_view kDefaultBlacklist = R""pb(
)pb"";
```
appears to indicate that such issue was already encounter before.

This issue appears in the context of trying to resolve issue #38867 .
This issue appears very close to issue #35796 .

"
38950,validation_data documentation entry incomplete,"## URL(s) with the issue: https://www.tensorflow.org/api_docs/python/tf/keras/Model?authuser=1#fit

## Description of issue (what needs changing):
validation_data: Data on which to evaluate the loss and any model metrics at the end of each epoch. The model will not be trained on this data. validation_data will override validation_split. validation_data could be:

This is incomplete. It can also be 
A generator or keras.utils.Sequence returning (inputs, targets) or (inputs, targets, sample weights). A more detailed description of unpacking behavior for iterator types (Dataset, generator, Sequence) is given below.

### Correct links

I'm failing to find the respective location in https://github.com/tensorflow/docs of this page to make a pull request directly


"
38949,TF 2.x release for CPU only,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): 2.1



**Describe the feature and the current behavior/state.**
The current TF 2.x install size is very large and is not suitable for small size deployments due to many restrictions. A CPU only release would be very helpful in this case due to its smaller size than the GPU or combined release. 

A CPU only release will provide more flexibility to the user in terms of deployment options. 


"
38948,Tensor Manipulation and Slicing Feature supported by Auto Gradient,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using):2.1.0
- Are you willing to contribute it (Yes/No):Yes



**Describe the feature and the current behavior/state.**

**Will this change the current api? How?**Yes, tf.Variable support slicing but assigning to it , it hinders the auto grad.

**Who will benefit with this feature?**Every One Who want to do more custom work and want more control over tensors

**Any Other info.**
"
38947,WARNING:tensorflow:AutoGraph could not transform <function affine at 0x0000021B750C1E58> and will run it as-is.,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- TensorFlow version: 2.2.0-rc3
- TensorFlow-probability version: 0.10.0-rc0
- Python version: 3.7.6

**Describe the current behavior**
I am using Anaconda, TensorFlow, and Spyder. When I run my script, I get the following error message:
```
INFO:tensorflow:Converted call: <function affine at 0x0000021B778A51F8>
    args: (<tf.Tensor 'x:0' shape=(6768,) dtype=float32>, <tf.Tensor 'kernel_diag:0' shape=(1,) dtype=float32>, <tf.Tensor 'bias:0' shape=() dtype=float32>)
    kwargs: {}

Converted call: <function affine at 0x0000021B778A51F8>
    args: (<tf.Tensor 'x:0' shape=(6768,) dtype=float32>, <tf.Tensor 'kernel_diag:0' shape=(1,) dtype=float32>, <tf.Tensor 'bias:0' shape=() dtype=float32>)
    kwargs: {}

INFO:tensorflow:Cache hit for entity <function affine at 0x0000021B778A51F8> subkey (<tensorflow.python.autograph.core.converter.ConversionOptions object at 0x0000021B790D2188>, frozenset()): _ConvertedEntityFactoryInfo(tf__affine in tmpta8nc9zk)
Cache hit for entity <function affine at 0x0000021B778A51F8> subkey (<tensorflow.python.autograph.core.converter.ConversionOptions object at 0x0000021B790D2188>, frozenset()): _ConvertedEntityFactoryInfo(tf__affine in tmpta8nc9zk)
INFO:tensorflow:Error transforming entity <function affine at 0x0000021B778A51F8>
Traceback (most recent call last):
  File ""C:\Users\jason\Anaconda3\lib\site-packages\tensorflow\python\autograph\impl\api.py"", line 538, in converted_call
    converted_f = conversion.convert(target_entity, program_ctx)
  File ""C:\Users\jason\Anaconda3\lib\site-packages\tensorflow\python\autograph\impl\conversion.py"", line 362, in convert
    return _instantiate(entity, converted_entity_info, free_nonglobal_var_names)
  File ""C:\Users\jason\Anaconda3\lib\site-packages\tensorflow\python\autograph\impl\conversion.py"", line 300, in _instantiate
    factory = converted_entity_info.get_factory()
  File ""C:\Users\jason\Anaconda3\lib\site-packages\tensorflow\python\autograph\impl\conversion.py"", line 94, in get_factory
    assert self.module_name in sys.modules
AssertionError
Error transforming entity <function affine at 0x0000021B778A51F8>
WARNING:tensorflow:AutoGraph could not transform <function affine at 0x0000021B778A51F8> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: 
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
WARNING: AutoGraph could not transform <function affine at 0x0000021B778A51F8> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: 
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
INFO:tensorflow:Converted call: <function affine at 0x0000021B778A51F8>
    args: (<tf.Tensor 'x:0' shape=(6768,) dtype=float32>, <tf.Tensor 'kernel_diag:0' shape=(6768,) dtype=float32>, <tf.Tensor 'bias:0' shape=(6768,) dtype=float32>)
    kwargs: {}

Converted call: <function affine at 0x0000021B778A51F8>
    args: (<tf.Tensor 'x:0' shape=(6768,) dtype=float32>, <tf.Tensor 'kernel_diag:0' shape=(6768,) dtype=float32>, <tf.Tensor 'bias:0' shape=(6768,) dtype=float32>)
    kwargs: {}

INFO:tensorflow:Whitelisted <function affine at 0x0000021B778A51F8>: from cache
Whitelisted <function affine at 0x0000021B778A51F8>: from cache
Traceback (most recent call last):
  File ""C:\Users\jason\Anaconda3\lib\site-packages\tensorflow\python\autograph\impl\api.py"", line 538, in converted_call
    converted_f = conversion.convert(target_entity, program_ctx)
  File ""C:\Users\jason\Anaconda3\lib\site-packages\tensorflow\python\autograph\impl\conversion.py"", line 362, in convert
    return _instantiate(entity, converted_entity_info, free_nonglobal_var_names)
  File ""C:\Users\jason\Anaconda3\lib\site-packages\tensorflow\python\autograph\impl\conversion.py"", line 300, in _instantiate
    factory = converted_entity_info.get_factory()
  File ""C:\Users\jason\Anaconda3\lib\site-packages\tensorflow\python\autograph\impl\conversion.py"", line 94, in get_factory
    assert self.module_name in sys.modules
AssertionError
```
**Standalone code to reproduce the issue**
```
import pandas as pd
import tensorflow as tf
# tf.autograph.set_verbosity(10,True)
import tensorflow_probability as tfp
from tensorflow_probability import distributions as tfd
# Read the data
df = pd.read_csv(""https://raw.githubusercontent.com/jfhawkin/bayes_discrete_choice/master/swissmetro.dat"",sep='\t')

""""""Basic data and model setup""""""

# Removing some observations can be done directly using pandas.
remove = (((df.PURPOSE != 1) & (df.PURPOSE != 3)) | (df.CHOICE == 0))
df.drop(df[remove].index,inplace=True)

# Definition of new variables: as tensorflow vectors
df.reset_index(inplace=True)
IDX = tf.expand_dims(tf.convert_to_tensor(df.index),1)
TRAIN_TT_SCALED = tf.expand_dims(tf.convert_to_tensor(df.TRAIN_TT / 100, dtype=tf.float32),1)
TRAIN_COST_SCALED = tf.expand_dims(tf.convert_to_tensor(df.TRAIN_CO / 100, dtype=tf.float32),1)
SM_TT_SCALED = tf.expand_dims(tf.convert_to_tensor(df.SM_TT / 100, dtype=tf.float32),1)
SM_COST_SCALED = tf.expand_dims(tf.convert_to_tensor(df.SM_CO / 100, dtype=tf.float32),1)
CAR_TT_SCALED = tf.expand_dims(tf.convert_to_tensor(df.CAR_TT / 100, dtype=tf.float32),1)
CAR_CO_SCALED = tf.expand_dims(tf.convert_to_tensor(df.CAR_CO / 100, dtype=tf.float32),1)

DATA = tf.concat([TRAIN_TT_SCALED,TRAIN_COST_SCALED,SM_TT_SCALED,SM_COST_SCALED,CAR_TT_SCALED,CAR_CO_SCALED], axis=1)

# Definition of new variables for availability, etc.: as tensorflow vectors
CHOICE = tf.convert_to_tensor(pd.get_dummies(df.CHOICE), dtype=tf.float32)
CAR_AV_SP =  tf.expand_dims(tf.convert_to_tensor(df.CAR_AV, dtype=tf.float32),1)
TRAIN_AV_SP =  tf.expand_dims(tf.convert_to_tensor(df.TRAIN_AV, dtype=tf.float32),1)
SM_AV_SP =  tf.expand_dims(tf.convert_to_tensor(df.SM_AV, dtype=tf.float32),1)

AV = tf.concat([TRAIN_AV_SP, SM_AV_SP, CAR_AV_SP], axis=1)

num_idx = df.shape[0]

""""""Define the model as a partial pooling hierarchical model with varying slope for the time parameter""""""

@tf.function
def affine(x, kernel_diag, bias=tf.zeros([])):
  """"""`kernel_diag * x + bias` with broadcasting.""""""
  kernel_diag = tf.ones_like(x) * kernel_diag
  bias = tf.ones_like(x) * bias
  return x * kernel_diag + bias

def mmnl_func():
    adj_AV_train = (tf.ones(num_idx) - AV[:,0]) * -9999
    adj_AV_SM = (tf.ones(num_idx) - AV[:,1]) * -9999
    adj_AV_car = (tf.ones(num_idx) - AV[:,2]) * -9999

    return tfd.JointDistributionSequential([
        tfd.Normal(loc=0., scale=1e5),  # mu_b_time
        tfd.HalfCauchy(loc=0., scale=5),  # sigma_b_time
        lambda sigma_b_time,mu_b_time: tfd.MultivariateNormalDiag(  # b_time
        loc=affine(tf.ones([num_idx]), mu_b_time[..., tf.newaxis]),
        scale_identity_multiplier=sigma_b_time),
        tfd.Normal(loc=0, scale=1e5), # a_train
        tfd.Normal(loc=0, scale=1e5), # a_car
        tfd.Normal(loc=0, scale=1e5), # b_cost
        lambda b_cost,a_car,a_train,b_time: tfd.Independent(tfd.Multinomial(
          total_count=1,
          logits=tf.stack([
              affine(DATA[:,0], tf.gather(b_time, IDX[:,0], axis=-1), (a_train + b_cost * DATA[:,1] + adj_AV_train)),
              affine(DATA[:,2], tf.gather(b_time, IDX[:,0], axis=-1), (b_cost * DATA[:,3] + adj_AV_SM)),
              affine(DATA[:,4], tf.gather(b_time, IDX[:,0], axis=-1), (a_car + b_cost * DATA[:,5] + adj_AV_car))
          ], axis=1)
        ),reinterpreted_batch_ndims=1)
    ])

mmnl_func().sample()
```

Full code on colab:
https://drive.google.com/file/d/10OBeDVNC4tN4c8Ro2SuYhw5YfGzpXnx4/view?usp=sharing

**Other info / logs**
Full tracebook is attached. Full code implements a sampler. Final error from full code is:
`ValueError: Dimensions must be equal, but are 6768 and 3 for '{{node JointDistributionSequential_1/log_prob/JointDistributionSequential_1_log_prob_IndependentJointDistributionSequential_1_log_prob_Multinomial/log_prob/JointDistributionSequential_1_log_prob_Multinomial/log_prob/mul}} = Mul[T=DT_FLOAT](value, JointDistributionSequential_1/log_prob/JointDistributionSequential_1_log_prob_IndependentJointDistributionSequential_1_log_prob_Multinomial/log_prob/JointDistributionSequential_1_log_prob_Multinomial/log_prob/LogSoftmax)' with input shapes: [6768,3], [1,3,6768].`
[output.txt](https://github.com/tensorflow/tensorflow/files/4540276/output.txt)

"
38946,Docs:  multi_worker_with_keras.ipynb shows init() instead of __init__(),"Thank you for submitting a TensorFlow documentation issue. Per our GitHub
policy, we only address code/doc bugs, performance issues, feature requests, and
build/installation issues on GitHub.

The TensorFlow docs are open source! To get involved, read the documentation
contributor guide: https://www.tensorflow.org/community/contribute/docs

## URL(s) with the issue:

Please provide a link to the documentation entry, for example:
https://github.com/tensorflow/docs/edit/master/site/en/tutorials/distribute/multi_worker_with_keras.ipynb

## Description of issue (what needs changing):
When rendered, the literal \_\_init\_\_ is replaced with init
### Clear description
\_\_init\_\_ is a ""built-in"" python function for classes.  In the ipynb source code it is correct.  However, when rendered at: https://www.tensorflow.org/tutorials/distribute/multi_worker_with_keras , it is incorrect.

For example, why should someone use this method? How is it useful?

### Correct links

Is the link to the source code correct?

### Parameters defined

Are all parameters defined and formatted correctly?

### Returns defined

Are return values defined?

### Raises listed and defined

Are the errors defined? For example,
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises

### Usage example

Is there a usage example?

See the API guide: https://www.tensorflow.org/community/contribute/docs_ref
on how to write testable usage examples.

### Request visuals, if applicable

Are there currently visuals? If not, will it clarify the content?
Yes, please see the notebook in the docs.  The text is:
```
Note: TF_CONFIG is parsed and TensorFlow's GRPC servers are started at the time MultiWorkerMirroredStrategy.init() is called, so TF_CONFIG environment variable must be set before a tf.distribute.Strategy instance is created.
```
vs
```
Note: TF_CONFIG is parsed and TensorFlow's GRPC servers are started at the time MultiWorkerMirroredStrategy.__init__() is called, so TF_CONFIG environment variable must be set before a tf.distribute.Strategy instance is created.
```
Notice that .init() is shown when .\_\_init\_\_() should be shown.

### Submit a pull request?

Are you planning to also submit a pull request to fix the issue? See the docs
contributor guide: https://www.tensorflow.org/community/contribute/docs,
docs API guide: https://www.tensorflow.org/community/contribute/docs_ref and the
docs style guide: https://www.tensorflow.org/community/contribute/docs_style
No:  I didn't know how to escape the underscores, but I believe it is as in this report using a backslash before each underscore.
"
38945,Memory leak on TF2.1 model.fit with validation_split,"- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04.3
- TensorFlow installed from (source or binary): Binary
- TensorFlow version (use command below): 2.1.0
- Python version: 3.7.5
- GPU model and memory: No GPU

**Describe the current behavior**
Fitting a simple LSTM model causes memory leak

**Standalone code to reproduce the issue**
```
import os
import psutil

import numpy as np
from tensorflow.keras.layers import (
    LSTM,
    Bidirectional,
    Dense,
    Input,
)
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam


def dummy_model(n_classes, n_features, seq_length):
    input = Input(shape=(seq_length, n_features))
    main = Bidirectional(LSTM(128, return_sequences=False))(input)

    prediction = Dense(n_classes, activation=""softmax"")(main)
    optimiser = Adam(lr=1e-3)
    model = Model(inputs=[input], outputs=prediction)
    model.compile(optimiser, ""categorical_crossentropy"", metrics=[""accuracy""])
    return model


def fit_model():
    x_train = np.random.random_sample((1000, 50, 100))
    x_train = x_train.astype(np.float32)
    y_train = np.zeros((1000, 10), dtype=np.float32)
    model = dummy_model(n_classes=10, n_features=100, seq_length=50)
    model.fit(
        x_train, y_train, epochs=1,
        validation_split=0.1, batch_size=64,
        verbose=0
    )


if __name__ == ""__main__"":
    process = psutil.Process(os.getpid())
    n = 20

    for i in range(n):
        fit_model()
        print(f""#--- Run {i + 1} of {n} memory used (MB): {process.memory_info().rss / 1e6}"")
```



**Other info / logs** 
```
#--- Run 1 of 20 memory used (MB): 731.81184
#--- Run 2 of 20 memory used (MB): 991.137792
#--- Run 3 of 20 memory used (MB): 1027.985408
#--- Run 4 of 20 memory used (MB): 1089.724416
#--- Run 5 of 20 memory used (MB): 1127.616512
#--- Run 6 of 20 memory used (MB): 1165.471744
#--- Run 7 of 20 memory used (MB): 1211.96544
#--- Run 8 of 20 memory used (MB): 1247.653888
#--- Run 9 of 20 memory used (MB): 1272.410112
#--- Run 10 of 20 memory used (MB): 1289.478144
#--- Run 11 of 20 memory used (MB): 1298.57536
#--- Run 12 of 20 memory used (MB): 1317.429248
#--- Run 13 of 20 memory used (MB): 1346.781184
#--- Run 14 of 20 memory used (MB): 1369.145344
#--- Run 15 of 20 memory used (MB): 1402.55232
#--- Run 16 of 20 memory used (MB): 1409.634304
#--- Run 17 of 20 memory used (MB): 1413.599232
#--- Run 18 of 20 memory used (MB): 1419.091968
#--- Run 19 of 20 memory used (MB): 1450.14784
#--- Run 20 of 20 memory used (MB): 1468.604416
```

Issue also appears to occur with `2.2.0rc3`

Explicitly setting the following (as was recommended in this blog post - http://gregoryzynda.com/python/tensorflow/memory/leak/rnn/lstm/2019/10/17/lstm-memory-leak.html) appears to help mitigate this (although memory still increases):
```
tf.config.threading.set_intra_op_parallelism_threads(2)
tf.config.threading.set_inter_op_parallelism_threads(5)
```

As does explicitly running garbage collection `gc.collect()` after each iteration."
38944,UnrecognizedFlagError when using tf.vectorized_map() with lbfgs_minimize(),"
**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04.2
- Mobile device (e.g. iPhone UnrecognizedFlagErrortf8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: -
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): 2.1.0   (v2.1.0-rc2-17-ge5bf8de)
- Python version: 3.7.6
- Bazel version (if compiling from source): -
- GCC/Compiler version (if compiling from source): -
- CUDA/cuDNN version: -
- GPU model and memory: -


**Describe the current behavior**
when trying to access the `tfp.optimizer.lbfgs_minimize()` - object parameters during a `tf.vectorized_map()` operation, it throws the error: `UnrecognizedFlagError: Unknown command line flag 'f'` as well as `ERROR:tensorflow:Got error while pfor was converting op name: ""loop_body/PartitionedCall""`


**Describe the expected behavior**
you can simply extract the position of this object during the loop


**Standalone code to reproduce the issue**
the issue was originally created with following code on my laptop (with above mentioned versions) but can also be reproduced in this colab: 
https://colab.research.google.com/drive/1gOF9qTqzdjYmlbbugIYxzXlH7MpBsEbl


**Other info / logs** 
the large error traceback file is appended

[tf_vectorized_map_traceback.txt](https://github.com/tensorflow/tensorflow/files/4540178/tf_vectorized_map_traceback.txt)

"
38943,Using tf.data.Dataset has big overhead,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): RHEL 7.5
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.1.0
- Python version: 3.7.4
- CUDA/cuDNN version: 10.1
- GPU model and memory: GTX 1080

**Describe the current behavior**

Using a `Dataset` reduces performance by a small but significant amount, ~7% for ImageNet like data

**Describe the expected behavior**

Using `Dataset` has no or only marginal performance impact

**Standalone code to reproduce the issue**

```
import tensorflow as tf
from timeit import timeit


@tf.function
def train_step(x, y):
    model.train_on_batch(x, y)


for useData in (True, False):
    model = tf.keras.applications.ResNet50(weights=None, classes=1000)
    model.compile(
        loss=tf.losses.SparseCategoricalCrossentropy(),
        optimizer=tf.keras.optimizers.SGD(),
        metrics=['accuracy'],
        experimental_run_tf_function=True)

    if useData:
        x = tf.random.uniform([1, 32, 224, 224, 3])
        y = tf.random.uniform([1, 32, 1], minval=0, maxval=999, dtype=tf.int64)
        dataset = tf.data.Dataset.from_tensor_slices((x, y)).repeat()

        def train(steps):
            for x, y in dataset.take(steps):
                train_step(x, y)
    else:
        x = tf.random.uniform([32, 224, 224, 3])
        y = tf.random.uniform([32, 1], minval=0, maxval=999, dtype=tf.int64)

        def train(steps):
            for _ in range(steps):
                train_step(x, y)

    # warmup
    train(2)
    t = timeit(lambda: train(50), number=10)
    print('useData: %s -> %s' % (useData, t))
```

Sample output:
useData: True -> 89.92945478390902
useData: False -> 86.73652107780799

For more realistic training loops (e.g. including callbacks) the difference is even bigger.
Some of my tests:

```
constant: total images/sec: 496.47 (calculation(497.53) + preprocessing(1.06)) 
dataset:  total images/sec: 465.09 (calculation(478.64) + preprocessing(13.55)) 
```

First number is calculated from training loop execution time (after warmup) the latter only the train-step and the difference (to the first number) which I called ""preprocessing"" as it is iterating over the dataset (calling next on the iterator by the for loop) and hence dominated by preprocessing functions if present (none here) including the `repeat` and `take` Dataset adapters.

So 2 conclusions: Getting elements from the iterator seems to be quite costly (1->13.6) and even the training loop itself gets slower (498 -> 479)

This would be a reason to avoid the dataset API."
38942,Impossible to create a simple LSTM layer with tensorflow > 2.1 version,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
Trying to follow these instructions : https://www.tensorflow.org/guide/keras/rnn

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10

- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No
 
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): tested on tf-nightly 2.2.0.dev20200422, tensorflow 2.2.0rc3, tensorflow 2.2.0rc2, tensorflow 2.2.0rc1, tensorflow 2.2.0rc0
- Python version: 3.7

- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:  10.1
- GPU model and memory: 

The following instructions is working with tensorflow 2.1 but do not work on tensorflow version > 2.1 in my environment. 

```
import collections
import matplotlib.pyplot as plt
import numpy as np
import tensorflow as tf
from tensorflow.keras import layers

model = tf.keras.Sequential()
model.add(layers.Embedding(input_dim=1000, output_dim=64))
model.add(layers.LSTM(128))
```

I get the following error in building LSTM layer:

`ValueError: Shape must be at least rank 3 but is rank 2 for '{{node BiasAdd}} = BiasAdd[T=DT_FLOAT, data_format=""NCHW""](add, bias)' with input shapes: [?,512], [512].`

This is working correctly with tensorflow 2.1 and in google colab: https://colab.research.google.com/drive/1evEbvAtAElZqx3cqD4wCPJxC5OUmJeSp). 

It seems that tensorflow is using cached parameters (512 might be a batch size used in previous tests...)"
38941,how to dynamic link cuda library when building tensorflow?,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Ubuntu 18.04
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
TensorFlow installed from (source or binary):
source
TensorFlow version:
r1.14
Python version:
3.6.9
Installed using virtualenv? pip? conda?:
build on raw linux environment, with pip installed
Bazel version (if compiling from source):
0.24.1
GCC/Compiler version (if compiling from source):
4.8.5
CUDA/cuDNN version:
CUDA 10.0 CUDNN 7.6.5
GPU model and memory:
Nvidia GTX 1660Ti 6GB

Describe the problem
i want to build tensorflow  with gpu support, and it should dynamically link the cuda libraries(libcudart.so and so on). 
On windows, I tried bazel build --config=opt --config=cuda --copt=-nvcc_options=cudart=shared //tensorflow/tools/pip_package:libtensorflow. And I used dependency walker on the tensorflow.dll it built, it had cuda related dll in its dependencies, so it seemed work.
but on ubuntu,i tried with the same command line, but get error: gcc un recognized command line

**Provide the exact sequence of commands / steps that you executed before running into the problem**
bazel build --config=opt --config=cuda --copt=-nvcc_options=cudart=shared //tensorflow/tools/pip_package:libtensorflow

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
/root/.cache/bazel/_bazel_root/5ac94cf1f70fd575be3807b8a4a32ede/external/com_google_absl/absl/debugging/BUILD.bazel:190:1: C++ compilation of rule '@com_google_absl//absl/debugging:leak_check' failed (Exit 1)
gcc: error: unrecognized command line option '-nvcc_options=cudart=shared'
Target //tensorflow/tools/pip_package:build_pip_package failed to build
Use --verbose_failures to see the command lines of failed build steps.
INFO: Elapsed time: 152.342s, Critical Path: 48.24s
INFO: 1236 processes: 1236 local.
FAILED: Build did NOT complete successfully"
38939,Tensorflow lite Quantization aware training in Keras FAIL,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Linux 39df84b83a78 4.19.104+ #1 SMP Wed Feb 19 05:26:34 PST 2020 x86_64 x86_64 x86_64 GNU/Linux
- TensorFlow installed from (source or binary): 
2.2.0-dev20200427


**Command used to run the converter or code if you’re using the Python API**
Here's the Colab https://colab.research.google.com/drive/1H_DGK2VjIKSNhNboW_XfqHr7kzXR-rrI

```
! pip uninstall -y tensorflow
! pip install -q tf-nightly
! pip install -q tensorflow-model-optimization
import tempfile
import os
import tensorflow as tf
from tensorflow import keras
# Load MNIST dataset
mnist = keras.datasets.mnist
(train_images, train_labels), (test_images, test_labels) = mnist.load_data()

# Normalize the input image so that each pixel value is between 0 to 1.
train_images = train_images / 255.0
test_images = test_images / 255.0

# Define the MODIFIED model architecture.
model = keras.Sequential([
  keras.layers.InputLayer(input_shape=(28, 28)),
  keras.layers.Reshape(target_shape=(28, 28, 1)),
  keras.layers.Conv2D(filters=12, kernel_size=(3, 3),name='conv1'),
  keras.layers.BatchNormalization(),
  keras.layers.ReLU(),
  keras.layers.MaxPooling2D(pool_size=(2, 2)),
  keras.layers.Flatten(),
  keras.layers.Dense(10, activation=tf.nn.softmax)
])

# Train the digit classification model
model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

model.fit(
  train_images,
  train_labels,
  epochs=1,
  validation_split=0.1,
)
import tensorflow_model_optimization as tfmot
quantize_model = tfmot.quantization.keras.quantize_model
# q_aware stands for for quantization aware.
q_aware_model = quantize_model(model)

```

**The output from the converter invocation**

```
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
<ipython-input-5-5fc1d8762a1f> in <module>()
      4 
      5 # q_aware stands for for quantization aware.
----> 6 q_aware_model = quantize_model(model)

8 frames
/usr/local/lib/python3.6/dist-packages/tensorflow_model_optimization/python/core/quantization/keras/quantize.py in quantize_model(to_quantize)
    136 
    137   annotated_model = quantize_annotate_model(to_quantize)
--> 138   return quantize_apply(annotated_model)
    139 
    140 

/usr/local/lib/python3.6/dist-packages/tensorflow_model_optimization/python/core/quantization/keras/quantize.py in quantize_apply(model)
    401   # layer_quantize_map gets modified by the transformations.
    402   transformed_model, layer_quantize_map = quantize_transform.apply(
--> 403       unwrapped_model, layer_quantize_map)
    404 
    405   # TODO(pulkitb): Think more about how to introduce Default specific code.

/usr/local/lib/python3.6/dist-packages/tensorflow_model_optimization/python/core/quantization/keras/default_8bit/default_8bit_quantize_layout_transform.py in apply(self, model, layer_quantize_map)
     65     return model_transformer.ModelTransformer(
     66         model, transforms,
---> 67         layer_quantize_map.keys(), layer_quantize_map).transform()

/usr/local/lib/python3.6/dist-packages/tensorflow_model_optimization/python/core/quantization/keras/graph_transformations/model_transformer.py in transform(self)
    550     else:
    551       transformed_model = keras.Sequential.from_config(self._config,
--> 552                                                        custom_objects)
    553 
    554     for layer in transformed_model.layers:

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py in from_config(cls, config, custom_objects)
    498       layer = layer_module.deserialize(layer_config,
    499                                        custom_objects=custom_objects)
--> 500       model.add(layer)
    501     if (not model.inputs and build_input_shape and
    502         isinstance(build_input_shape, (tuple, list))):

/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/base.py in _method_wrapper(self, *args, **kwargs)
    454     self._self_setattr_tracking = False  # pylint: disable=protected-access
    455     try:
--> 456       result = method(self, *args, **kwargs)
    457     finally:
    458       self._self_setattr_tracking = previous_value  # pylint: disable=protected-access

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py in add(self, layer)
    227       # If the model is being built continuously on top of an input layer:
    228       # refresh its output.
--> 229       output_tensor = layer(self.outputs[0])
    230       if len(nest.flatten(output_tensor)) != 1:
    231         raise ValueError(SINGLE_LAYER_OUTPUT_ERROR_MSG)

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py in __call__(self, *args, **kwargs)
    892         # are casted, not before.
    893         input_spec.assert_input_compatibility(self.input_spec, inputs,
--> 894                                               self.name)
    895         if (any(isinstance(x, ragged_tensor.RaggedTensor) for x in input_list)
    896             and not self._supports_ragged_inputs):

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/input_spec.py in assert_input_compatibility(input_spec, inputs, layer_name)
    178                          'expected ndim=' + str(spec.ndim) + ', found ndim=' +
    179                          str(ndim) + '. Full shape received: ' +
--> 180                          str(x.shape.as_list()))
    181     if spec.max_ndim is not None:
    182       ndim = x.shape.ndims

ValueError: Input 0 of layer conv1 is incompatible with the layer: expected ndim=4, found ndim=2. Full shape received: [None, 196]
```
"
38938,Keras: model.fit_generator or model.fit not working properly,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution: Ubuntu 18.04.3 LTS
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.2.0-rc3
- Python version: 3.6.9
- CUDA/cuDNN version: (colab)
- GPU model and memory: (colab)

**Describe the current behavior**
While using ```model.fit``` or ```model.fit_generator``` the sub iterations in epoch shows unknown number of iterations which is goes on despite surpassing the batch size.

**Describe the expected behavior**
While using ```model.fit``` or ```model.fit_generator``` the sub iterations in epoch must be definite.

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to [Colab](https://colab.research.google.com/drive/1dWbszUUjRagXyJUUqjdsM1yXtaAmKc23).

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

```shell
WARNING:tensorflow:From <ipython-input-23-2da3481afcb0>:1: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
Please use Model.fit, which supports generators.
Epoch 1/20
     13/Unknown - 20s 2s/step - loss: 1.0732 - accuracy: 0.2602
```"
38937,Tensorflow TPU - ValueError: No gradients provided for any variable,"`Tensorflow version 2.2.0-rc3`


I went through most of git posts, SO and others but unable to get around it.

Here is how model and training pattern look like...

```python
def create_model():    
    input_img = Input(shape=(1280, 1280, 3)) 
    
    x = Conv2D(256, (3, 3), activation='relu', padding='same')(input_img)
    x = MaxPooling2D((2, 2), padding='same')(x)
    x = Conv2D(256, (3, 3), activation='relu', padding='same')(x)
    x = MaxPooling2D((2, 2), padding='same')(x)
    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)
    x = MaxPooling2D((2, 2), padding='same')(x)
    x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)
    x = MaxPooling2D((2, 2), padding='same')(x)
    x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)
    encoded = MaxPooling2D((2, 2), padding='same')(x)
    
    x = Conv2D(16, (3, 3), activation='relu', padding='same')(encoded)
    x = UpSampling2D((2, 2))(x)
    x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)
    x = UpSampling2D((2, 2))(x)
    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)
    x = UpSampling2D((2, 2))(x)
    x = Conv2D(256, (3, 3), activation='relu', padding='same')(x)
    x = UpSampling2D((2, 2))(x)
    x = Conv2D(256, (3, 3), activation='relu', padding='same')(x)
    x = UpSampling2D((2, 2))(x)
    decoded = Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)
    
    autoencoder = Model(input_img, decoded)
    
    return autoencoder


## training
with strategy.scope():
    model = create_model()
    model.summary()
    model.compile(optimizer='adam', loss='binary_crossentropy')
    print(f""optimizer >>> {autoencoder.optimizer.get_config()}"")
    
model.fit(training_dataset, steps_per_epoch=steps_per_epoch, epochs=50, validation_data=validation_dataset)
model.save(SAVE_WEIGHT)
```



**This is same code which is running without any issues on CPU as well on GCP. With this same code I have already completed more than 70 epochs but due to slowness of CPU I decided to move to TPU.** 







Here is stack trace of error.

```python

optimizer >>> {'name': 'Adam', 'learning_rate': 0.001, 'decay': 0.0, 'rho': 0.95, 'epsilon': 1e-07}

_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d (Conv2D)              (None, 1280, 1280, 256)   7168      
_________________________________________________________________
max_pooling2d (MaxPooling2D) (None, 640, 640, 256)     0         
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 640, 640, 256)     590080    
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 320, 320, 256)     0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 320, 320, 64)      147520    
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 160, 160, 64)      0         
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 160, 160, 32)      18464     
_________________________________________________________________
max_pooling2d_3 (MaxPooling2 (None, 80, 80, 32)        0         
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 80, 80, 16)        4624      
_________________________________________________________________
max_pooling2d_4 (MaxPooling2 (None, 40, 40, 16)        0         
_________________________________________________________________
conv2d_5 (Conv2D)            (None, 40, 40, 16)        2320      
_________________________________________________________________
up_sampling2d (UpSampling2D) (None, 80, 80, 16)        0         
_________________________________________________________________
conv2d_6 (Conv2D)            (None, 80, 80, 32)        4640      
_________________________________________________________________
up_sampling2d_1 (UpSampling2 (None, 160, 160, 32)      0         
_________________________________________________________________
conv2d_7 (Conv2D)            (None, 160, 160, 64)      18496     
_________________________________________________________________
up_sampling2d_2 (UpSampling2 (None, 320, 320, 64)      0         
_________________________________________________________________
conv2d_8 (Conv2D)            (None, 320, 320, 256)     147712    
_________________________________________________________________
up_sampling2d_3 (UpSampling2 (None, 640, 640, 256)     0         
_________________________________________________________________
conv2d_9 (Conv2D)            (None, 640, 640, 256)     590080    
_________________________________________________________________
up_sampling2d_4 (UpSampling2 (None, 1280, 1280, 256)   0         
_________________________________________________________________
conv2d_10 (Conv2D)           (None, 1280, 1280, 3)     6915      
=================================================================
Total params: 1,538,019
Trainable params: 1,538,019
Non-trainable params: 0
_________________________________________________________________
Epoch 1/50
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
<ipython-input-9-41a8a30839cf> in <module>()
     70 
     71 
---> 72 autoencoder.fit(training_dataset, steps_per_epoch=STEPS_PER_EPOCH, epochs=50, validation_data=validation_dataset)
     73 
     74 autoencoder.save(SAVE_WEIGHT)

10 frames
/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py in _method_wrapper(self, *args, **kwargs)
     64   def _method_wrapper(self, *args, **kwargs):
     65     if not self._in_multi_worker_mode():  # pylint: disable=protected-access
---> 66       return method(self, *args, **kwargs)
     67 
     68     # Running inside `run_distribute_coordinator` already.

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)
    849                 batch_size=batch_size):
    850               callbacks.on_train_batch_begin(step)
--> 851               tmp_logs = train_function(iterator)
    852               # Catch OutOfRangeError for Datasets of unknown size.
    853               # This blocks until the batch has finished executing.

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py in __call__(self, *args, **kwds)
    578         xla_context.Exit()
    579     else:
--> 580       result = self._call(*args, **kwds)
    581 
    582     if tracing_count == self._get_tracing_count():

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py in _call(self, *args, **kwds)
    625       # This is the first call of __call__, so we have to initialize.
    626       initializers = []
--> 627       self._initialize(args, kwds, add_initializers_to=initializers)
    628     finally:
    629       # At this point we know that the initialization is complete (or less

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py in _initialize(self, args, kwds, add_initializers_to)
    504     self._concrete_stateful_fn = (
    505         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access
--> 506             *args, **kwds))
    507 
    508     def invalid_creator_scope(*unused_args, **unused_kwds):

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py in _get_concrete_function_internal_garbage_collected(self, *args, **kwargs)
   2444       args, kwargs = None, None
   2445     with self._lock:
-> 2446       graph_function, _, _ = self._maybe_define_function(args, kwargs)
   2447     return graph_function
   2448 

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py in _maybe_define_function(self, args, kwargs)
   2775 
   2776       self._function_cache.missed.add(call_context_key)
-> 2777       graph_function = self._create_graph_function(args, kwargs)
   2778       self._function_cache.primary[cache_key] = graph_function
   2779       return graph_function, args, kwargs

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py in _create_graph_function(self, args, kwargs, override_flat_arg_shapes)
   2665             arg_names=arg_names,
   2666             override_flat_arg_shapes=override_flat_arg_shapes,
-> 2667             capture_by_value=self._capture_by_value),
   2668         self._function_attributes,
   2669         # Tell the ConcreteFunction to clean up its graph once it goes out of

/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)
    979         _, original_func = tf_decorator.unwrap(python_func)
    980 
--> 981       func_outputs = python_func(*func_args, **func_kwargs)
    982 
    983       # invariant: `func_outputs` contains only Tensors, CompositeTensors,

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py in wrapped_fn(*args, **kwds)
    439         # __wrapped__ allows AutoGraph to swap in a converted function. We give
    440         # the function a weak reference to itself to avoid a reference cycle.
--> 441         return weak_wrapped_fn().__wrapped__(*args, **kwds)
    442     weak_wrapped_fn = weakref.ref(wrapped_fn)
    443 

/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py in wrapper(*args, **kwargs)
    966           except Exception as e:  # pylint:disable=broad-except
    967             if hasattr(e, ""ag_error_metadata""):
--> 968               raise e.ag_error_metadata.to_exception(e)
    969             else:
    970               raise

ValueError: in user code:

    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:571 train_function  *
        outputs = self.distribute_strategy.run(
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/tpu_strategy.py:170 run  **
        return self.extended.tpu_run(fn, args, kwargs, options)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/tpu_strategy.py:863 tpu_run
        return func(args, kwargs)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/tpu_strategy.py:930 tpu_function
        padding_spec=padding_spec)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/tpu/tpu.py:893 replicate
        padding_spec=padding_spec)[1]
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/tpu/tpu.py:1280 split_compile_and_replicate
        outputs = computation(*computation_inputs)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/tpu_strategy.py:892 replicated_fn
        result[0] = fn(*replica_args, **replica_kwargs)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:541 train_step  **
        self.trainable_variables)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1807 _minimize
        trainable_variables))
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:521 _aggregate_gradients
        filtered_grads_and_vars = _filter_grads(grads_and_vars)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:1219 _filter_grads
        ([v.name for _, v in grads_and_vars],))

    ValueError: No gradients provided for any variable: ['conv2d/kernel:0', 'conv2d/bias:0', 'conv2d_1/kernel:0', 'conv2d_1/bias:0', 'conv2d_2/kernel:0', 'conv2d_2/bias:0', 'conv2d_3/kernel:0', 'conv2d_3/bias:0', 'conv2d_4/kernel:0', 'conv2d_4/bias:0', 'conv2d_5/kernel:0', 'conv2d_5/bias:0', 'conv2d_6/kernel:0', 'conv2d_6/bias:0', 'conv2d_7/kernel:0', 'conv2d_7/bias:0', 'conv2d_8/kernel:0', 'conv2d_8/bias:0', 'conv2d_9/kernel:0', 'conv2d_9/bias:0', 'conv2d_10/kernel:0', 'conv2d_10/bias:0'].


```

"
38936,Shuffling and batching operations results in keras model not running,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes  
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux (Ubuntu)
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): Source (Google Colab)
- TensorFlow version (use command below): 2.2.0-rc3
- Python version: 3.6.9
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: 10.1



I have a dataset of about 70,000 image files.  I'm following the tutorial - (https://www.tensorflow.org/tutorials/load_data/images#load_using_tfdata) to load them and preprocess them. However this function was causing problems:
```
def prepare_for_training(ds, cache=True, shuffle_buffer_size=1000):
  # This is a small dataset, only load it once, and keep it in memory.
  # use `.cache(filename)` to cache preprocessing work for datasets that don't
  # fit in memory.
  if cache:
    if isinstance(cache, str):
      ds = ds.cache(cache)
    else:
      ds = ds.cache()

  ds = ds.shuffle(buffer_size=shuffle_buffer_size)

  # Repeat forever
  ds = ds.repeat()

  ds = ds.batch(BATCH_SIZE)

  # `prefetch` lets the dataset fetch batches in the background while the model
  # is training.
  ds = ds.prefetch(buffer_size=AUTOTUNE)

  return ds

```
After applying this function as the final processing step, my model would run but not even start on the first epoch.  The same applied to even a model consisting of a single Dense unit.  Examining the function step by step  I tried to do just the shuffle step or batching step - 
` ds = ds.shuffle(buffer_size=shuffle_buffer_size)  `
` ds = ds.batch(BATCH_SIZE)`
This alone resulted in the issue described above. 


The preprocessing I have done before this is the same as in the tutorial.

Note: The Image data has no labels (by design) .  This might possibly causing the issue? 
"
38935,[RNN] Bidirectional LSTM conversion fail,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 64-bit
- TensorFlow installed from (source or binary): 
- TensorFlow version (or github SHA if from source): 2.2.0-dev20200422


**Command used to run the converter or code if you’re using the Python API**
If possible, please share a link to Colab/Jupyter/any notebook.

```
converter = tf.lite.TFLiteConverter.from_keras_model_file(
    'model.h5',
    input_shapes={'embedding_input': (128,1900)}
)

# converter = tf.lite.TFLiteConverter.from_keras_model(loaded_model) 
converter.experimental_new_converter = True
# # converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS,
# #                                        tf.lite.OpsSet.SELECT_TF_OPS]
tfmodel = converter.convert() 
open ('model.tflite' , ""wb"") .write(tfmodel)
```

**The output from the converter invocation**

```
Traceback (most recent call last):
  File ""convert.py"", line 25, in <module>
    tfmodel = converter.convert()
  File ""C:\Users\jing_\anaconda3\envs\tf2-gpu\lib\site-packages\tensorflow\lite\python\lite.py"", line 1326, in convert
    **converter_kwargs)
  File ""C:\Users\jing_\anaconda3\envs\tf2-gpu\lib\site-packages\tensorflow\lite\python\convert.py"", line 536, in toco_convert_impl
    enable_mlir_converter=enable_mlir_converter)
  File ""C:\Users\jing_\anaconda3\envs\tf2-gpu\lib\site-packages\tensorflow\lite\python\convert.py"", line 241, in toco_convert_protos
    raise ConverterError(""See console for info.\n%s\n%s\n"" % (stdout, stderr))
tensorflow.lite.python.convert.ConverterError: See console for info.
2020-04-27 15:43:22.425922: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:307] Ignored output_format.
2020-04-27 15:43:22.426100: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:310] Ignored drop_control_dependency.
2020-04-27 15:43:22.443931: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance-critical operations:  AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-04-27 15:43:22.449382: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x27c7543e550 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-04-27 15:43:22.449555: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
loc(callsite(""sequential/bidirectional/backward_lstm/PartitionedCall/while""(""C:\Users\jing_\anaconda3\envs\tf2-gpu\lib\site-packages\tensorflow\python\framework\convert_to_constants.py"":406:0) at callsite(""C:\Users\jing_\anaconda3\envs\tf2-gpu\lib\site-packages\tensorflow\python\framework\convert_to_constants.py"":680:0 at callsite(""C:\Users\jing_\anaconda3\envs\tf2-gpu\lib\site-packages\tensorflow\lite\python\lite.py"":1086:0 at ""convert.py"":13:0)))): error: body function result type tensor<?x128x128xf32> is incompatible with result type tensor<1900x1x128xf32> at index 3
Traceback (most recent call last):
  File ""c:\users\jing_\anaconda3\envs\tf2-gpu\lib\runpy.py"", line 193, in _run_module_as_main
    ""__main__"", mod_spec)
  File ""c:\users\jing_\anaconda3\envs\tf2-gpu\lib\runpy.py"", line 85, in _run_code
    exec(code, run_globals)
  File ""C:\Users\jing_\anaconda3\envs\tf2-gpu\Scripts\toco_from_protos.exe\__main__.py"", line 7, in <module>
  File ""c:\users\jing_\anaconda3\envs\tf2-gpu\lib\site-packages\tensorflow\lite\toco\python\toco_from_protos.py"", line 93, in main
    app.run(main=execute, argv=[sys.argv[0]] + unparsed)
  File ""c:\users\jing_\anaconda3\envs\tf2-gpu\lib\site-packages\tensorflow\python\platform\app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""c:\users\jing_\anaconda3\envs\tf2-gpu\lib\site-packages\absl\app.py"", line 299, in run
    _run_main(main, args)
  File ""c:\users\jing_\anaconda3\envs\tf2-gpu\lib\site-packages\absl\app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""c:\users\jing_\anaconda3\envs\tf2-gpu\lib\site-packages\tensorflow\lite\toco\python\toco_from_protos.py"", line 56, in execute
    enable_mlir_converter)
Exception: C:\Users\jing_\anaconda3\envs\tf2-gpu\lib\site-packages\tensorflow\python\framework\convert_to_constants.py:406:52: error: body function result type tensor<?x128x128xf32> is incompatible with result type tensor<1900x1x128xf32> at index 3
                                                   new_output_names)
                                                   ^
C:\Users\jing_\anaconda3\envs\tf2-gpu\lib\site-packages\tensorflow\python\framework\convert_to_constants.py:680:3: note: called from
  return _construct_concrete_function(func, output_graph_def, converted_inputs)
  ^
C:\Users\jing_\anaconda3\envs\tf2-gpu\lib\site-packages\tensorflow\lite\python\lite.py:1086:11: note: called from
          concrete_func, lower_control_flow=False)
          ^
convert.py:13:5: note: called from
    input_shapes={'embedding_input': (128,1900)}
    ^
C:\Users\jing_\anaconda3\envs\tf2-gpu\lib\site-packages\tensorflow\python\framework\convert_to_constants.py:406:52: note: see current operation: %75:11 = ""tf.While""(%6, %17, %6, %0, %73, %74, %5, %70, %43, %46, %49) {_lower_using_switch_merge = false, _num_original_outputs = 11 : i64, _read_only_resource_inputs = [], body = @while_body_3631_frozen0, cond = @while_cond_3630_frozen0, device = """", is_stateless = true, output_shapes = [""tfshape$"", ""tfshape$"", ""tfshape$"", ""tfshape$"", ""tfshape$dim { size: -1 } dim { size: 128 }"", ""tfshape$dim { size: -1 } dim { size: 128 }"", ""tfshape$"", ""tfshape$"", ""tfshape$dim { size: 128 } dim { size: 512 }"", ""tfshape$dim { size: 128 } dim { size: 512 }"", ""tfshape$dim { size: 512 }""], parallel_iterations = 32 : i64} : (tensor<i32>, tensor<i32>, tensor<i32>, tensor<1900x1x128xf32>, tensor<128x128xf32>, tensor<128x128xf32>, tensor<i32>, tensor<1900x128x128xf32>, tensor<128x512xf32>, tensor<128x512xf32>, tensor<512xf32>) -> (tensor<i32>, tensor<i32>, tensor<i32>, tensor<1900x1x128xf32>, tensor<128x128xf32>, tensor<128x128xf32>, tensor<i32>, tensor<1900x128x128xf32>, tensor<128x512xf32>, tensor<128x512xf32>, tensor<512xf32>)
                                                   new_output_names)
                                                   ^
```



**Failure details**

I am trying to utilize GPU delegate on the Android platform. When I use the normal way of converting i.e converter = tf.lite.TFLiteConverter.from_keras_model(loaded_model) without enabling GPU delegate, everything works fine, just that the inference time cost is a bit high. So I want to enable GPU delegate to see if it improves the time cost. However, GPU delegate doesn't allow dynamic-sized tensors, thus, when converting, I need to set the size of my input layer, which I did in the above code, but I couldn't get the model to convert after that.
Summary of my model is as follows:
```
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
embedding (Embedding)        (None, 1900, 128)         377600
_________________________________________________________________
bidirectional (Bidirectional (None, 1900, 256)         263168
_________________________________________________________________
batch_normalization (BatchNo (None, 1900, 256)         1024
_________________________________________________________________
global_max_pooling1d (Global (None, 256)               0
_________________________________________________________________
dense (Dense)                (None, 64)                16448
_________________________________________________________________
dense_1 (Dense)              (None, 32)                2080
_________________________________________________________________
dense_2 (Dense)              (None, 2)                 66
=================================================================
Total params: 660,386
Trainable params: 659,874
Non-trainable params: 512
```

"
38934,"ValueError: Attempted to save a function b'__inference_GRU-Dense_layer_call_fn_29299' which references a symbolic Tensor Tensor(""dropout/mul_1:0"", shape=(?, 384), dtype=float32) that is not a simple constant. This is not supported.","<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version:2.1.0
- Python version:3.6
- Installed using virtualenv? pip? conda?:virtualenv
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:



**Describe the problem**
INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(?, ?), dtype=tf.float32, name='inputs'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f27ac4592b0>), {}).
INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(?, ?), dtype=tf.float32, name='inputs'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f27ac465668>), {}).
INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(?, ?), dtype=tf.float32, name='inputs'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f27ac4755f8>), {}).
INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(?, ?), dtype=tf.float32, name='inputs'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f27ac3fe940>), {}).
INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(?, ?), dtype=tf.float32, name='inputs'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f27ac465668>), {}).
INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(?, ?), dtype=tf.float32, name='inputs'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f27ac4592b0>), {}).
INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(?, ?), dtype=tf.float32, name='inputs'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f27ac4592b0>), {}).
INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(?, ?), dtype=tf.float32, name='inputs'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f27ac3fe940>), {}).
INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(?, ?), dtype=tf.float32, name='inputs'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f27ac4755f8>), {}).
INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(?, ?), dtype=tf.float32, name='inputs'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f27ac4755f8>), {}).
INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(?, ?), dtype=tf.float32, name='inputs'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f27ac4592b0>), {}).
INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(?, ?), dtype=tf.float32, name='inputs'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f27ac465668>), {}).
INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(?, ?), dtype=tf.float32, name='inputs'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f27ac4755f8>), {}).
INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(?, ?), dtype=tf.float32, name='inputs'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f27ac3fe940>), {}).
INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(?, ?), dtype=tf.float32, name='inputs'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f27ac465668>), {}).
INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(?, ?), dtype=tf.float32, name='inputs'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f27ac4592b0>), {}).
INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(?, ?), dtype=tf.float32, name='inputs'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f27ac4592b0>), {}).
INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(?, ?), dtype=tf.float32, name='inputs'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f27ac3fe940>), {}).
INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(?, ?), dtype=tf.float32, name='inputs'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f27ac4755f8>), {}).
INFO:tensorflow:Unsupported signature for serialization: ((TensorSpec(shape=(?, ?), dtype=tf.float32, name='inputs'), <tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f27ac4755f8>), {}).
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
<ipython-input-5-68ef369094e8> in <module>
      4 
      5 # set_gpu_ratio(ratio=0.65)
----> 6 train_model(train_csv_file, dict_path, model_file_path)

<ipython-input-4-872233fb1b6b> in train_model(train_csv_file, dict_path, model_file_path)
     56 #     model_file_path = '/data1/xuyingjie/project/zhihu_project2020Q1/user_feedback_algorithm_v2_py3/model/'
     57 #     tf.saved_model.save(model, 'model_file_path')
---> 58     tf.keras.models.save_model(model, 'model_file_path', save_format=""tf"")
     59 
     60     # 保存为pd模型的方式二：

~/.virtualenvs/py3venv/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py in save_model(model, filepath, overwrite, include_optimizer, save_format, signatures, options)
    113   else:
    114     saved_model_save.save(model, filepath, overwrite, include_optimizer,
--> 115                           signatures, options)
    116 
    117 

~/.virtualenvs/py3venv/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/saved_model/save.py in save(model, filepath, overwrite, include_optimizer, signatures, options)
     76     # we use the default replica context here.
     77     with distribution_strategy_context._get_default_replica_context():  # pylint: disable=protected-access
---> 78       save_lib.save(model, filepath, signatures, options)
     79 
     80   if not include_optimizer:

~/.virtualenvs/py3venv/lib/python3.6/site-packages/tensorflow_core/python/saved_model/save.py in save(obj, export_dir, signatures, options)
    907   object_saver = util.TrackableSaver(checkpoint_graph_view)
    908   asset_info, exported_graph = _fill_meta_graph_def(
--> 909       meta_graph_def, saveable_view, signatures, options.namespace_whitelist)
    910   saved_model.saved_model_schema_version = (
    911       constants.SAVED_MODEL_SCHEMA_VERSION)

~/.virtualenvs/py3venv/lib/python3.6/site-packages/tensorflow_core/python/saved_model/save.py in _fill_meta_graph_def(meta_graph_def, saveable_view, signature_functions, namespace_whitelist)
    551   resource_initializer_ops = []
    552   with exported_graph.as_default():
--> 553     object_map, resource_map, asset_info = saveable_view.map_resources()
    554     for resource_initializer_function in resource_initializer_functions:
    555       asset_dependencies = []

~/.virtualenvs/py3venv/lib/python3.6/site-packages/tensorflow_core/python/saved_model/save.py in map_resources(self)
    283                 (""Attempted to save a function {} which references a symbolic ""
    284                  ""Tensor {} that is not a simple constant. This is not ""
--> 285                  ""supported."").format(concrete_function.name, capture))
    286           copied_tensor = constant_op.constant(capture_constant_value)
    287           node_id = len(self.nodes)

ValueError: Attempted to save a function b'__inference_GRU-Dense_layer_call_fn_29299' which references a symbolic Tensor Tensor(""dropout/mul_1:0"", shape=(?, 384), dtype=float32) that is not a simple constant. This is not supported.

**Provide the exact sequence of commands / steps that you executed before running into the problem**


**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
38933,how to add -std=c++17 to any cc_library,"gcc 7.3.0
tensorflow 2.1
os:centos
bazel:0.27.1

please tell me how to add -std=c++17 to any cc_library !!!

why any file compile with c++0x ?

my build command : bazel build -s -j 32 --verbose_failures -c opt --cxxopt=-D_GLIBCXX_USE_CXX17_ABI=1  --cxxopt=-std=c++11 --cxxopt='-std=c++17'  --copt=-march=native --copt=-mfpmath=both //tensorflow/tools/pip_package:build_pip_package --sandbox_debug --cxxopt=-D_GLIBCXX_USE_CXX17_ABI=1  --cxxopt='-std=c++17' --linkopt='-std=c++17'

any compile log has c++0x.like this

gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections -fdata-sections '**-std=c++0x'** -MD -MF bazel-out/host/bin/external/local_config_mlir/_objs/mlir-tblgen/LLVMIRConversionGen.d '-frandom-seed=bazel-out/host/bin/external/local_config_mlir/_objs/mlir-tblgen/LLVMIRConversionGen.o' -DUNICODE -DLLVM_ENABLE_STATS -D__STDC_LIMIT_MACROS -D__STDC_CONSTANT_MACROS -D__STDC_FORMAT_MACROS -DLLVM_BUILD_GLOBAL_ISEL -iquote external/local_config_mlir -iquote bazel-out/host/bin/external/local_config_mlir -iquote external/llvm -iquote bazel-out/host/bin/external/llvm -iquote external/zlib_archive -iquote bazel-out/host/bin/external/zlib_archive -iquote external/bazel_tools -iquote bazel-out/host/bin/external/bazel_tools -isystem external/local_config_mlir/include -isystem bazel-out/host/bin/external/local_config_mlir/include -isystem external/llvm/include -isystem bazel-out/host/bin/external/llvm/include -isystem external/zlib_archive -isystem bazel-out/host/bin/external/zlib_archive -g0 -g0 -fno-canonical-system-headers -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' -c external/local_config_mlir/tools/mlir-tblgen/LLVMIRConversionGen.cpp -o bazel-out/host/bin/external/local_config_mlir/_objs/mlir-tblgen/LLVMIRConversionGen.o


why ?"
38932,New TFLiteConverter not working with tf.complex64,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Colab CPU
- TensorFlow version (use command below): 2.2.0-rc3

**Describe the current behavior**
New `TFLiteConverter` not working with `tf.complex64`
Disabling the new converter (`converter.experimental_new_converter = False`) works.

**Standalone code to reproduce the issue**

```python3
@tf.function
def foo(x, y):
    return x @ y


x = tf.constant([[1, 2, 3], [4, 5, 6]], dtype=tf.complex64)
y = tf.constant([[2, 3], [4, 5], [6, 7]], dtype=tf.complex64)

foo_concrete = foo.get_concrete_function(x, y)
converter = tf.lite.TFLiteConverter.from_concrete_functions([foo_concrete])
foo_tflite = converter.convert()
```

[colab example](https://colab.research.google.com/drive/1snYjxYYJaOYPQOeQ1ec2o0xPHQB0ILY2)


Thanks"
38931,Tensorflow Lite Object Detection on mobile devices,"Suppose, say I have 30 interested objects on an image, is it possible to get all 30 box proposals on a single image without splitting the image, or the number of proposals on an image is limited to 10.
Thank you for the help! "
38930,Build does not succeed and the error content changes every time,"I want to install Tensorflow 1.8 gpu on macOS, but the build does not go through and the error content changes every time even if I try to refer to the following site. How can we make it work?

https://developpaper.com/tensorflow-1-8-with-gpu-on-macos-high-sierra-10-13-6/


**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):High Sierra 10.13.6(17g65)
- TensorFlow installed from (source or binary):https://github.com/tensorflow/tensorflow -b r1.8
- TensorFlow version:1.8
- Python version:3.6.3
- Bazel version (if compiling from source):0.14.0
- CUDA/cuDNN version:9.2/7.2
- GPU model and memory:GTX GeForce 1080 ti
- Command Line Tool 8.2.1

`ERROR: /Users/zen/tensorflow/tensorflow/core/kernels/BUILD:1201:1: output 'tensorflow/core/kernels/_objs/gather_functor_gpu/tensorflow/core/kernels/gather_functor_gpu.cu.pic.o' was not created
ERROR: /Users/zen/tensorflow/tensorflow/core/kernels/BUILD:1201:1: not all outputs were created or valid
Target //tensorflow/tools/pip_package:build_pip_package failed to build
`

`ERROR: /Users/zen/tensorflow/tensorflow/core/kernels/BUILD:3434:1: output 'tensorflow/core/kernels/_objs/histogram_op_gpu/tensorflow/core/kernels/histogram_op_gpu.cu.o' was not created
ERROR: /Users/zen/tensorflow/tensorflow/core/kernels/BUILD:3434:1: not all outputs were created or valid
Target //tensorflow/tools/pip_package:build_pip_package failed to build
`

I'm getting all sorts of errors when I do the exact same situation





"
38929,Failed to get convolution algorithm. This is probably because cuDNN failed to initialize,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version: 1.14
- Python version: 3.7.6
- Installed using virtualenv? pip? conda?: pip
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: CUDA -- 10.0, cuDNN -- 7.4.2
- GPU model and memory:

Quadro RTX 4000 -- 8G
GeForce RTX 2080 ti -- 12G



**Describe the problem**

I have two GPU on two machines, Quadro RTX 4000 and GeForce RTX 2080 ti. And I install the same NVIDIA-driver 440.59. I did the cuDNN sample test and it passed the test. And I ran the tensorflow [benchmark](https://github.com/tensorflow/models/tree/master/official/benchmark) using the below commands.  I used a small enough batch to avoid the OOM issue. The machine with GeForce RTX 2080 ti can successfully run the benchmark. But the machine with Quadro RTX 4000 cannot run the benchmark, which said ""Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above."" Do you have any idea about this issue? Is it related to hardware? 

**Provide the exact sequence of commands / steps that you executed before running into the problem**
$python tf_cnn_benchmarks.py --data_format=NCHW --batch_size=32 --model=resnet50 --optimizer=momentum --variable_update=replicated --nodistortions --gradient_repacking=8 --num_gpus=2 --num_epochs=90 --weight_decay=1e-4 --use_fp16 --train_dir=/home/lab2

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

I0426 23:04:18.110438 139678773683968 session_manager.py:502] Done running local_init_op.
INFO:tensorflow:Starting standard services.
I0426 23:04:24.543723 139678773683968 supervisor.py:737] Starting standard services.
INFO:tensorflow:Starting queue runners.
I0426 23:04:24.543950 139678773683968 supervisor.py:743] Starting queue runners.
Running warm up
2020-04-26 23:04:29.404714: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2020-04-26 23:04:30.068934: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2020-04-26 23:04:31.178428: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR
2020-04-26 23:04:32.225534: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR
2020-04-26 23:04:32.261894: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR
2020-04-26 23:04:32.295444: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR
INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.UnknownError'>, 2 root error(s) found.
  (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.
	 [[node tower_0/v0/cg/conv0/conv2d/Conv2D (defined at /tmp/tmpq2hyfuxj.py:12) ]]
  (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.
	 [[node tower_0/v0/cg/conv0/conv2d/Conv2D (defined at /tmp/tmpq2hyfuxj.py:12) ]]
	 [[Reshape_603/_2957]]
0 successful operations.
1 derived errors ignored.

Errors may have originated from an input operation.
Input Source operations connected to node tower_0/v0/cg/conv0/conv2d/Conv2D:
 Cast (defined at /root/benchmarks/scripts/tf_cnn_benchmarks/convnet_builder.py:101)	
 tower_0/v0/cg/conv0/Pad (defined at /root/benchmarks/scripts/tf_cnn_benchmarks/convnet_builder.py:204)

Input Source operations connected to node tower_0/v0/cg/conv0/conv2d/Conv2D:
 Cast (defined at /root/benchmarks/scripts/tf_cnn_benchmarks/convnet_builder.py:101)	
 tower_0/v0/cg/conv0/Pad (defined at /root/benchmarks/scripts/tf_cnn_benchmarks/convnet_builder.py:204)

Original stack trace for 'tower_0/v0/cg/conv0/conv2d/Conv2D':
  File ""tf_cnn_benchmarks.py"", line 73, in <module>
    app.run(main)  # Raises error on invalid flags, unlike tf.app.run()
  File ""/root/anaconda3/lib/python3.7/site-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/root/anaconda3/lib/python3.7/site-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""tf_cnn_benchmarks.py"", line 68, in main
    bench.run()
  File ""/root/benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py"", line 1880, in run
    return self._benchmark_train()
  File ""/root/benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py"", line 2076, in _benchmark_train
    build_result = self._build_graph()
  File ""/root/benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py"", line 2110, in _build_graph
    (input_producer_op, enqueue_ops, fetches) = self._build_model()
  File ""/root/benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py"", line 2828, in _build_model
    gpu_compute_stage_ops, gpu_grad_stage_ops)
  File ""/root/benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py"", line 3345, in add_forward_pass_and_gradients
    outputs = maybe_compile(forward_pass_and_gradients, self.params)
  File ""/root/benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py"", line 3542, in maybe_compile
    return computation()
  File ""/root/benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py"", line 3199, in forward_pass_and_gradients
    input_list, phase_train, nclass)
  File ""/root/benchmarks/scripts/tf_cnn_benchmarks/models/model.py"", line 293, in build_network
    self.add_inference(network)
  File ""/root/benchmarks/scripts/tf_cnn_benchmarks/models/resnet_model.py"", line 308, in add_inference
    cnn.conv(64, 7, 7, 2, 2, mode='SAME_RESNET', use_batch_norm=True)
  File ""/root/benchmarks/scripts/tf_cnn_benchmarks/convnet_builder.py"", line 209, in conv
    kernel_initializer=kernel_initializer)
  File ""/root/benchmarks/scripts/tf_cnn_benchmarks/convnet_builder.py"", line 134, in _conv2d_impl
    use_bias=False)
  File ""/root/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py"", line 324, in new_func
    return func(*args, **kwargs)
  File ""/root/anaconda3/lib/python3.7/site-packages/tensorflow/python/layers/convolutional.py"", line 424, in conv2d
    return layer.apply(inputs)
  File ""/root/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py"", line 1479, in apply
    return self.__call__(inputs, *args, **kwargs)
  File ""/root/anaconda3/lib/python3.7/site-packages/tensorflow/python/layers/base.py"", line 537, in __call__
    outputs = super(Layer, self).__call__(inputs, *args, **kwargs)
  File ""/root/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py"", line 634, in __call__
    outputs = call_fn(inputs, *args, **kwargs)
  File ""/root/anaconda3/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py"", line 146, in wrapper
    ), args, kwargs)
  File ""/root/anaconda3/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py"", line 450, in converted_call
    result = converted_f(*effective_args, **kwargs)
  File ""/tmp/tmpq2hyfuxj.py"", line 12, in tf__call
    outputs = ag__.converted_call('_convolution_op', self, ag__.ConversionOptions(recursive=True, force_conversion=False, optional_features=(), internal_convert_user_code=True), (inputs, self.kernel), None)
  File ""/root/anaconda3/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py"", line 356, in converted_call
    return _call_unconverted(f, args, kwargs)
  File ""/root/anaconda3/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py"", line 255, in _call_unconverted
    return f(*args)
  File ""/root/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/nn_ops.py"", line 1079, in __call__
    return self.conv_op(inp, filter)
  File ""/root/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/nn_ops.py"", line 635, in __call__
    return self.call(inp, filter)
  File ""/root/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/nn_ops.py"", line 234, in __call__
    name=self.name)
  File ""/root/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/nn_ops.py"", line 1953, in conv2d
    name=name)
  File ""/root/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/gen_nn_ops.py"", line 1071, in conv2d
    data_format=data_format, dilations=dilations, name=name)
  File ""/root/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py"", line 788, in _apply_op_helper
    op_def=op_def)
  File ""/root/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py"", line 507, in new_func
    return func(*args, **kwargs)
  File ""/root/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py"", line 3616, in create_op
    op_def=op_def)
  File ""/root/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py"", line 2005, in __init__
    self._traceback = tf_stack.extract_stack()

I0426 23:04:32.326952 139678773683968 coordinator.py:224] Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.UnknownError'>, 2 root error(s) found.
  (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.
	 [[node tower_0/v0/cg/conv0/conv2d/Conv2D (defined at /tmp/tmpq2hyfuxj.py:12) ]]
  (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.
	 [[node tower_0/v0/cg/conv0/conv2d/Conv2D (defined at /tmp/tmpq2hyfuxj.py:12) ]]
	 [[Reshape_603/_2957]]
0 successful operations.
1 derived errors ignored.

Errors may have originated from an input operation.
Input Source operations connected to node tower_0/v0/cg/conv0/conv2d/Conv2D:
 Cast (defined at /root/benchmarks/scripts/tf_cnn_benchmarks/convnet_builder.py:101)	
 tower_0/v0/cg/conv0/Pad (defined at /root/benchmarks/scripts/tf_cnn_benchmarks/convnet_builder.py:204)

Input Source operations connected to node tower_0/v0/cg/conv0/conv2d/Conv2D:
 Cast (defined at /root/benchmarks/scripts/tf_cnn_benchmarks/convnet_builder.py:101)	
 tower_0/v0/cg/conv0/Pad (defined at /root/benchmarks/scripts/tf_cnn_benchmarks/convnet_builder.py:204)

Original stack trace for 'tower_0/v0/cg/conv0/conv2d/Conv2D':
  File ""tf_cnn_benchmarks.py"", line 73, in <module>
    app.run(main)  # Raises error on invalid flags, unlike tf.app.run()
  File ""/root/anaconda3/lib/python3.7/site-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/root/anaconda3/lib/python3.7/site-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""tf_cnn_benchmarks.py"", line 68, in main
    bench.run()
  File ""/root/benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py"", line 1880, in run
    return self._benchmark_train()
  File ""/root/benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py"", line 2076, in _benchmark_train
    build_result = self._build_graph()
  File ""/root/benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py"", line 2110, in _build_graph
    (input_producer_op, enqueue_ops, fetches) = self._build_model()
  File ""/root/benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py"", line 2828, in _build_model
    gpu_compute_stage_ops, gpu_grad_stage_ops)
  File ""/root/benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py"", line 3345, in add_forward_pass_and_gradients
    outputs = maybe_compile(forward_pass_and_gradients, self.params)
  File ""/root/benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py"", line 3542, in maybe_compile
    return computation()
  File ""/root/benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py"", line 3199, in forward_pass_and_gradients
    input_list, phase_train, nclass)
  File ""/root/benchmarks/scripts/tf_cnn_benchmarks/models/model.py"", line 293, in build_network
    self.add_inference(network)
  File ""/root/benchmarks/scripts/tf_cnn_benchmarks/models/resnet_model.py"", line 308, in add_inference
    cnn.conv(64, 7, 7, 2, 2, mode='SAME_RESNET', use_batch_norm=True)
  File ""/root/benchmarks/scripts/tf_cnn_benchmarks/convnet_builder.py"", line 209, in conv
    kernel_initializer=kernel_initializer)
  File ""/root/benchmarks/scripts/tf_cnn_benchmarks/convnet_builder.py"", line 134, in _conv2d_impl
    use_bias=False)
  File ""/root/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py"", line 324, in new_func
    return func(*args, **kwargs)
  File ""/root/anaconda3/lib/python3.7/site-packages/tensorflow/python/layers/convolutional.py"", line 424, in conv2d
    return layer.apply(inputs)
  File ""/root/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py"", line 1479, in apply
    return self.__call__(inputs, *args, **kwargs)
  File ""/root/anaconda3/lib/python3.7/site-packages/tensorflow/python/layers/base.py"", line 537, in __call__
    outputs = super(Layer, self).__call__(inputs, *args, **kwargs)
  File ""/root/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py"", line 634, in __call__
    outputs = call_fn(inputs, *args, **kwargs)
  File ""/root/anaconda3/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py"", line 146, in wrapper
    ), args, kwargs)
  File ""/root/anaconda3/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py"", line 450, in converted_call
    result = converted_f(*effective_args, **kwargs)
  File ""/tmp/tmpq2hyfuxj.py"", line 12, in tf__call
    outputs = ag__.converted_call('_convolution_op', self, ag__.ConversionOptions(recursive=True, force_conversion=False, optional_features=(), internal_convert_user_code=True), (inputs, self.kernel), None)
  File ""/root/anaconda3/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py"", line 356, in converted_call
    return _call_unconverted(f, args, kwargs)
  File ""/root/anaconda3/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py"", line 255, in _call_unconverted
    return f(*args)
  File ""/root/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/nn_ops.py"", line 1079, in __call__
    return self.conv_op(inp, filter)
  File ""/root/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/nn_ops.py"", line 635, in __call__
    return self.call(inp, filter)
  File ""/root/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/nn_ops.py"", line 234, in __call__
    name=self.name)
  File ""/root/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/nn_ops.py"", line 1953, in conv2d
    name=name)
  File ""/root/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/gen_nn_ops.py"", line 1071, in conv2d
    data_format=data_format, dilations=dilations, name=name)
  File ""/root/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py"", line 788, in _apply_op_helper
    op_def=op_def)
  File ""/root/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py"", line 507, in new_func
    return func(*args, **kwargs)
  File ""/root/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py"", line 3616, in create_op
    op_def=op_def)
  File ""/root/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py"", line 2005, in __init__
    self._traceback = tf_stack.extract_stack()

Traceback (most recent call last):
  File ""/root/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py"", line 1356, in _do_call
    return fn(*args)
  File ""/root/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py"", line 1341, in _run_fn
    options, feed_dict, fetch_list, target_list, run_metadata)
  File ""/root/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py"", line 1429, in _call_tf_sessionrun
    run_metadata)
tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found.
  (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.
	 [[{{node tower_0/v0/cg/conv0/conv2d/Conv2D}}]]
  (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.
	 [[{{node tower_0/v0/cg/conv0/conv2d/Conv2D}}]]
	 [[Reshape_603/_2957]]
0 successful operations.
1 derived errors ignored.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""tf_cnn_benchmarks.py"", line 73, in <module>
    app.run(main)  # Raises error on invalid flags, unlike tf.app.run()
  File ""/root/anaconda3/lib/python3.7/site-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/root/anaconda3/lib/python3.7/site-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""tf_cnn_benchmarks.py"", line 68, in main
    bench.run()
  File ""/root/benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py"", line 1880, in run
    return self._benchmark_train()
  File ""/root/benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py"", line 2085, in _benchmark_train
    return self._benchmark_graph(result_to_benchmark, eval_build_results)
  File ""/root/benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py"", line 2294, in _benchmark_graph
    is_chief, summary_writer, profiler)
  File ""/root/benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py"", line 2430, in benchmark_with_session
    collective_graph_key=collective_graph_key)
  File ""/root/benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py"", line 869, in benchmark_one_step
    results = sess.run(fetches, options=run_options, run_metadata=run_metadata)
  File ""/root/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py"", line 950, in run
    run_metadata_ptr)
  File ""/root/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py"", line 1173, in _run
    feed_dict_tensor, options, run_metadata)
  File ""/root/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py"", line 1350, in _do_run
    run_metadata)
  File ""/root/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py"", line 1370, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found.
  (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.
	 [[node tower_0/v0/cg/conv0/conv2d/Conv2D (defined at /tmp/tmpq2hyfuxj.py:12) ]]
  (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.
	 [[node tower_0/v0/cg/conv0/conv2d/Conv2D (defined at /tmp/tmpq2hyfuxj.py:12) ]]
	 [[Reshape_603/_2957]]
0 successful operations.
1 derived errors ignored.

Errors may have originated from an input operation.
Input Source operations connected to node tower_0/v0/cg/conv0/conv2d/Conv2D:
 Cast (defined at /root/benchmarks/scripts/tf_cnn_benchmarks/convnet_builder.py:101)	
 tower_0/v0/cg/conv0/Pad (defined at /root/benchmarks/scripts/tf_cnn_benchmarks/convnet_builder.py:204)

"
38928,Get grpc error when I use tensorflow java API to load model.,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS 10.14.2
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 1.15.0
- Python version: 3.7

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
I run tensorflow java api to load model in flink cluster, it works fine the first time. But When I run the job the second time in cluster,  it turns out to be an error like below:

**[libprotobuf ERROR external/protobuf_archive/src/google/protobuf/descriptor_database.cc:58] File already exists in database: tensorflow/core/protobuf/eager_service.proto
[libprotobuf FATAL external/protobuf_archive/src/google/protobuf/descriptor.cc:1358] CHECK failed: GeneratedDatabase()->Add(encoded_file_descriptor, size): 
libc++abi.dylib: terminating with uncaught exception of type google::protobuf::FatalException: CHECK failed: GeneratedDatabase()->Add(encoded_file_descriptor, size):**
**Describe the expected behavior**

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
38927,ICU dependency needs to be updated to at least 66.1 for C++20,"TF depends on ICU 64.2. Version 66.1 contains a bug fix needed to compile in C++20 mode. Might as well update to 67.1, though, since it just came out. See https://unicode-org.atlassian.net/browse/ICU-20972"
38926,TFLite failed to run Transpose Conv2D on mobile.,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): N
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Virtual
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): tf-nightly
- Python version: 3.7.6
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
```
Internal error: Unexpected failure when preparing tensor allocations: tensorflow/lite/kernels/transpose_conv.cc:247 NumInputs(node) != 3 (4 != 3)
```

**Describe the expected behavior**
Python API run fine but when i run on mobile i get above error. Tflite 2.1.0 on mobile can avoid this bug but i will get ""Didn't find op for builtin opcode 'SPACE_TO_BATCH_ND' version '3'"" bug instead.

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
38925,DLL load failed while importing _pywrap_tensorflow_internal,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below):
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**

**Describe the expected behavior**

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
38924,mirroredstrategy not working? parallel GPUs working like serial,"I'm working with TF2.0
I find a situation confusing when using mirroredstrategy just the same as the tutorial:

    strategy = tf.distribute.MirroredStrategy()

    # Create a dataset
    dataset = dataset_ops.Dataset.TFRecordDataset([
      ""/a/1.tfr"", ""/a/2.tfr"", ""/a/3.tfr"", ""/a/4.tfr""])

    # Distribute that dataset
    dist_dataset = strategy.experimental_distribute_dataset(dataset)
    # Iterate over the distributed dataset
    for x in dist_dataset:
      # process dataset elements
      strategy.experimental_run_v2(train_step, args=(x,))

here's step_fn() in function train_step(), I made 2 time stamp in the code:

    # @tf.function(experimental_relax_shapes=True)
    def train_step(dist_inputs):
        def step_fn(inputs):
            (mel_specs, pred_inp, 
             spec_lengths, label_lengths, labels) = inputs
            with tf.GradientTape() as tape:
                outputs = model([mel_specs, pred_inp], 
                    training=True)
                # adding line below
               begin_time = time.tme()
                loss = loss_fn(labels, outputs,
                    spec_lengths, label_lengths)
                loss *= (1. / batch_size)

            if train_metrics is not None:
                metric_results = run_metrics(mel_specs, labels,
                    metrics=train_metrics)
                metric_results = {name: result * (1. / max(len(gpus), 1)) for name, result in metric_results.items()}

            gradients = tape.gradient(loss, model.trainable_variables)

            # adding line below before update gradients
            end_time = time.time()
            print(begin_time, end_time, end_time-begin_time)
           optimizer.apply_gradients(zip(gradients, model.trainable_variables))

            return loss, metric_results
        losses, metrics_results = strategy.experimental_run_v2(step_fn, args=(dist_inputs,))
        mean_loss = strategy.reduce(
            tf.distribute.ReduceOp.SUM, losses, axis=0)
        mean_metrics = {name: strategy.reduce(
            tf.distribute.ReduceOp.SUM, result, axis=0) for name, result in metrics_results.items()}
        return mean_loss, mean_metrics

I found that if using 2 GPUs(say gpu0 and gpu1),
the two gpu printing time_stamp: bg1, ed1 and bg2, ed2
the four params relationship is like this:
bg1<ed1<bg2<ed2
that is only when gpu0 finished inference, gpu1 start inferencing
Was the MirroredStrategy not working?
I commented the tf.function() ,was there any relationship?
when I not comment the tf.function(), the code ran into the ERROR: python segment fault (core dumped)...

someone can help me? thanks"
38923,tensorflow 2.1  loading model when saved with `tf` format does not work,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 64 bit
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): v2.2.0-rc1-34-ge6e5d6df2a 2.2.0-rc2
- Python version: 3.8
- Bazel version (if compiling from source): NA
- GCC/Compiler version (if compiling from source): NA
- CUDA/cuDNN version: NA
- GPU model and memory: 16 GB RAM

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
Check the code below to create and save model

[Test the code on Google-Colab](https://github.com/SpikingNeuron/tfpy_warrior/blob/master/tf2_save_and_load_custom_model.ipynb)


```python
# import necessary modules
import tensorflow as tf
import tensorflow.keras as tk
print(tf.__version__)

# define a custom model
class MyModel(tk.Model):
    ...

# Define a simple sequential model
def create_model():
    a = tk.Input(shape=(32,))
    b = tk.layers.Dense(32)(a)
    model = MyModel(inputs=a, outputs=b)

    model.compile(optimizer='adam',
                loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),
                metrics=['accuracy'])
    return model


# create model
my_model = create_model()

# Display the model's architecture
my_model.summary()

# save model
my_model.save(filepath=""./saved_model"", save_format=""tf"")
```

Now I want to load back the weights from disk. When I use the code below I get the error.

```python
# load back model
my_model.load_weights(filepath=""./saved_model"")
```

This gives the error:

```txt
/usr/local/lib/python3.6/dist-packages/h5py/_hl/files.py in make_fid(name, mode, userblock_size, fapl, fcpl, swmr)
    171         if swmr and swmr_support:
    172             flags |= h5f.ACC_SWMR_READ
--> 173         fid = h5f.open(name, flags, fapl=fapl)
    174     elif mode == 'r+':
    175         fid = h5f.open(name, h5f.ACC_RDWR, fapl=fapl)

h5py/_objects.pyx in h5py._objects.with_phil.wrapper()

h5py/_objects.pyx in h5py._objects.with_phil.wrapper()

h5py/h5f.pyx in h5py.h5f.open()

OSError: Unable to open file (file read failed: time = Tue Apr 28 15:30:40 2020
, filename = './saved_model', file descriptor = 57, errno = 21, error message = 'Is a directory', buf = 0x7fff093afd50, total read size = 8, bytes this sub-read = 8, bytes actually read = 18446744073709551615, offset = 0)
```

But then I debugged and found the TensorFlow library confuses itself in thinking that it is an `h5` file. So I modified the code as below and now it works. I also get to use my custom `MyModel`

Basically I added extra path i.e. `\\variables\\variables` so that it detects the folder as `tf` checkpoint. Can anyone suggest a better approach?

```python
my_model.load_weights(filepath=""./saved_model/variables/variables"")
print(my_model.__class__)
```

The other option is to use `tk.models.load(...)` as in the code below. But, the
problem is I lose my sub-classed model `MyModel`

```python
_loaded_my_model = tk.models.load_model(""./saved_model"")
print(_loaded_my_model.__class__)
```

**Describe the expected behavior**
Was expecting the below code to work:

```python
# load back model
# .... this does not work
my_model.load_weights(filepath=""saved_model"")
```

Or else provide extra method `my_model.load(filepath=..., save_format='tf')` which is in line with `my_model.save(filepath=..., load_format='tf')` with extra kwarg `load_format` if needed.

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

[Test the code on Google-Colab](https://github.com/SpikingNeuron/tfpy_warrior/blob/master/tf2_save_and_load_custom_model.ipynb)

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
38922,LSTMCell Dropout mask is reset at every call,"**System information**
- TensorFlow version (use command below):2.2.0-rc3

**Describe the current behavior**
The dropout mask is being reset at every call

**Describe the expected behavior**
The dropout mask should be fixed unless reset is called

**Standalone code to reproduce the issue**
```python
import numpy as np
import tensorflow as tf
from tensorflow.keras.preprocessing import sequence
from tensorflow.keras import Sequential
from tensorflow.keras.layers import Dense, Embedding
from tensorflow.keras.layers import LSTM
from tensorflow.keras.datasets import imdb

max_features = 20000
maxlen = 80

(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)
x_train = sequence.pad_sequences(x_train, maxlen=maxlen)
x_test = sequence.pad_sequences(x_test, maxlen=maxlen)

model = Sequential()
model.add(Embedding(max_features, 128))
model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))
model.add(Dense(1, activation='sigmoid'))

model.compile(loss='binary_crossentropy',
              optimizer='adam',
              metrics=['accuracy'])

x_sample = x_train[:1]
a = model(x_sample, training=True)
dp_mask1 = model.layers[1].cell.get_dropout_mask_for_cell(x_sample, training=True, count=4)
rec_dp_mask1 = model.layers[1].cell.get_dropout_mask_for_cell(x_sample, training=True, count=4)

b = model(x_sample, training=True)
dp_mask2 = model.layers[1].cell.get_dropout_mask_for_cell(x_sample, training=True, count=4)
rec_dp_mask2 = model.layers[1].cell.get_dropout_mask_for_cell(x_sample, training=True, count=4)

# check if masks are the same after call
print(np.all([np.all(dp_mask1[i] == dp_mask2[i]) for i in range(len(dp_mask1))]))
print(np.all([np.all(rec_dp_mask1[i] == rec_dp_mask2[i]) for i in range(len(rec_dp_mask1))]))
```

Jupyter Notebook example [here](https://colab.research.google.com/gist/zacwellmer/f56a9e1959e687d03ee89069d78af683/untitled4.ipynb)"
38921,unable to  install tensorflow!,"  File ""d:/anaconda/AI,CSS50/src5/banknotes/banknotes.py"", line 2, in <module>
    import tensorflow as tf
  File ""C:\Users\user\AppData\Local\Programs\Python\Python37-32\lib\site-packages\tensorflow\__init__.py"", line 24, in <module>
    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import
  File ""C:\Users\user\AppData\Local\Programs\Python\Python37-32\lib\site-packages\tensorflow\python\__init__.py"",
line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\Users\user\AppData\Local\Programs\Python\Python37-32\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\user\AppData\Local\Programs\Python\Python37-32\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 114
    def TFE_ContextOptionsSetAsync(arg1, async):
                                             ^
SyntaxError: invalid `syntax**  File ""d:/anaconda/AI,CSS50/src5/banknotes/banknotes.py"", line 2, in <module>
    import tensorflow as tf
  File ""C:\Users\user\AppData\Local\Programs\Python\Python37-32\lib\site-packages\tensorflow\__init__.py"", line 24, in <module>
    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import
  File ""C:\Users\user\AppData\Local\Programs\Python\Python37-32\lib\site-packages\tensorflow\python\__init__.py"",
line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\Users\user\AppData\Local\Programs\Python\Python37-32\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\user\AppData\Local\Programs\Python\Python37-32\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 114
    def TFE_ContextOptionsSetAsync(arg1, async):
                                             ^
SyntaxError: invalid synta  File ""d:/anaconda/AI,CSS50/src5/banknotes/banknotes.py"", line 2, in <module>
    import tensorflow as tf
  File ""C:\Users\user\AppData\Local\Programs\Python\Python37-32\lib\site-packages\tensorflow\__init__.py"", line 24, in <module>
    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import
  File ""C:\Users\user\AppData\Local\Programs\Python\Python37-32\lib\site-packages\tensorflow\python\__init__.py"",
line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\Users\user\AppData\Local\Programs\Python\Python37-32\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\user\AppData\Local\Programs\Python\Python37-32\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 114
    def TFE_ContextOptionsSetAsync(arg1, async):
                                             ^
SyntaxError: invalid `syntax**``"
38920, AutoGraph failed  to convert if statement into the equivalent tf.cond  in a RNN custom cell,"
**System information**
- I have written custom code.
- OS Windows 10:
- TensorFlow version : 2 . 1 .0
- Python version: 3.6

- CUDA/cuDNN version: 10.1   /  7.6.5
- GPU model and memory: rtx 2070


**Describe the current behavior**
I write a custom cell to be used in  a RNN model, the cell has some 'if' statements where a condition is  tf.Variable.  When I use @function to build a graph, the 'if 'condition work fine in  the model class but throw an error in the custom cell class :


    TypeError: You are attempting to use Python control flow in a layer that was not declared to be dynamic. Pass `dynamic=True` to the class constructor.
    Encountered error:
    
    using a `tf.Tensor` as a Python `bool` is not allowed: AutoGraph did not convert this function. Try decorating it directly with @tf.function.

  
**Describe the expected behavior**

AutoGraph should convert if statements into the equivalent tf.cond 

**Standalone code to reproduce the issue**

# custom cell
```
class tst_cell(tf.keras.layers.Layer):

    def __init__(self ):
         super(tst_cell , self).__init__()
         self.corr      = tf.keras.layers.Dense(4)
         self.state_size = 1
      
    def call (self ,inpt ,  states  ):
   
        if ee == 0 :            #  throw the error  !!!!!!
            print('cell  ee == 0')
            
        self.corr_s    = self.corr(inpt)
    
        return self.corr_s , states
 

 
    def get_initial_state(self,inputs, batch_size , dtype ):
   
       
      init_stat= tf.zeros((2,1) , dtype = dtype)
        
      return init_stat    


```
 ` ee = tf.Variable(0) # global variable used in 'if' condition 
`
# the model 
```
class tst_rnn_model(tf.keras.Model):
     def __init__ (self):
        super(tst_rnn_model , self).__init__()
       
        self.msk = tf.keras.layers.Masking(mask_value=0. , input_shape = (6,3))
        
        self.tst_gmm_cell        = tst_cell()
        
        self.tst_rnn_gmm          = tf.keras.layers.RNN(self.tst_gmm_cell ,  return_sequences=True )

     @tf.function  
     def call (self , inpt ):
        
        if ee == 0 :        # work fine  !!!!!
            print('model ee == 0')
            
        x = self.msk(inpt)
        mask = self.msk.compute_mask(inpt)
        outputs = self.tst_rnn_gmm(x , mask = mask)

        return outputs


data=np.arange(36.).reshape(2,6,3)
tst_model = tst_rnn_model()
out = tst_model(data)   
out
```
**Other info / logs** Include any logs 


---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
<ipython-input-222-ee4d06aa06c9> in <module>
     29 #run the model
     30 tst_model = tst_rnn_model()
---> 31 out = tst_model(data)
     32 out

c:\users\ultrapc\anaconda3\envs\env3.6\lib\site-packages\tensorflow_core\python\keras\engine\base_layer.py in __call__(self, inputs, *args, **kwargs)
    820           with base_layer_utils.autocast_context_manager(
    821               self._compute_dtype):
--> 822             outputs = self.call(cast_inputs, *args, **kwargs)
    823           self._handle_activity_regularization(inputs, outputs)
    824           self._set_mask_metadata(inputs, outputs, input_masks)

c:\users\ultrapc\anaconda3\envs\env3.6\lib\site-packages\tensorflow_core\python\eager\def_function.py in __call__(self, *args, **kwds)
    566         xla_context.Exit()
    567     else:
--> 568       result = self._call(*args, **kwds)
    569 
    570     if tracing_count == self._get_tracing_count():

c:\users\ultrapc\anaconda3\envs\env3.6\lib\site-packages\tensorflow_core\python\eager\def_function.py in _call(self, *args, **kwds)
    613       # This is the first call of __call__, so we have to initialize.
    614       initializers = []
--> 615       self._initialize(args, kwds, add_initializers_to=initializers)
    616     finally:
    617       # At this point we know that the initialization is complete (or less

c:\users\ultrapc\anaconda3\envs\env3.6\lib\site-packages\tensorflow_core\python\eager\def_function.py in _initialize(self, args, kwds, add_initializers_to)
    495     self._concrete_stateful_fn = (
    496         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access
--> 497             *args, **kwds))
    498 
    499     def invalid_creator_scope(*unused_args, **unused_kwds):

c:\users\ultrapc\anaconda3\envs\env3.6\lib\site-packages\tensorflow_core\python\eager\function.py in _get_concrete_function_internal_garbage_collected(self, *args, **kwargs)
   2387       args, kwargs = None, None
   2388     with self._lock:
-> 2389       graph_function, _, _ = self._maybe_define_function(args, kwargs)
   2390     return graph_function
   2391 

c:\users\ultrapc\anaconda3\envs\env3.6\lib\site-packages\tensorflow_core\python\eager\function.py in _maybe_define_function(self, args, kwargs)
   2701 
   2702       self._function_cache.missed.add(call_context_key)
-> 2703       graph_function = self._create_graph_function(args, kwargs)
   2704       self._function_cache.primary[cache_key] = graph_function
   2705       return graph_function, args, kwargs

c:\users\ultrapc\anaconda3\envs\env3.6\lib\site-packages\tensorflow_core\python\eager\function.py in _create_graph_function(self, args, kwargs, override_flat_arg_shapes)
   2591             arg_names=arg_names,
   2592             override_flat_arg_shapes=override_flat_arg_shapes,
-> 2593             capture_by_value=self._capture_by_value),
   2594         self._function_attributes,
   2595         # Tell the ConcreteFunction to clean up its graph once it goes out of

c:\users\ultrapc\anaconda3\envs\env3.6\lib\site-packages\tensorflow_core\python\framework\func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)
    976                                           converted_func)
    977 
--> 978       func_outputs = python_func(*func_args, **func_kwargs)
    979 
    980       # invariant: `func_outputs` contains only Tensors, CompositeTensors,

c:\users\ultrapc\anaconda3\envs\env3.6\lib\site-packages\tensorflow_core\python\eager\def_function.py in wrapped_fn(*args, **kwds)
    437         # __wrapped__ allows AutoGraph to swap in a converted function. We give
    438         # the function a weak reference to itself to avoid a reference cycle.
--> 439         return weak_wrapped_fn().__wrapped__(*args, **kwds)
    440     weak_wrapped_fn = weakref.ref(wrapped_fn)
    441 

c:\users\ultrapc\anaconda3\envs\env3.6\lib\site-packages\tensorflow_core\python\eager\function.py in bound_method_wrapper(*args, **kwargs)
   3209     # However, the replacer is still responsible for attaching self properly.
   3210     # TODO(mdan): Is it possible to do it here instead?
-> 3211     return wrapped_fn(*args, **kwargs)
   3212   weak_bound_method_wrapper = weakref.ref(bound_method_wrapper)
   3213 

c:\users\ultrapc\anaconda3\envs\env3.6\lib\site-packages\tensorflow_core\python\framework\func_graph.py in wrapper(*args, **kwargs)
    966           except Exception as e:  # pylint:disable=broad-except
    967             if hasattr(e, ""ag_error_metadata""):
--> 968               raise e.ag_error_metadata.to_exception(e)
    969             else:
    970               raise

TypeError: in converted code:

    <ipython-input-219-ee4d06aa06c9>:22 call  *
        outputs = self.tst_rnn_gmm(x , mask = mask)
    c:\users\ultrapc\anaconda3\envs\env3.6\lib\site-packages\tensorflow_core\python\keras\layers\recurrent.py:644 __call__
        return super(RNN, self).__call__(inputs, **kwargs)
    c:\users\ultrapc\anaconda3\envs\env3.6\lib\site-packages\tensorflow_core\python\keras\engine\base_layer.py:785 __call__
        str(e) + '\n""""""')

    TypeError: You are attempting to use Python control flow in a layer that was not declared to be dynamic. Pass `dynamic=True` to the class constructor.
    Encountered error:
    """"""
    using a `tf.Tensor` as a Python `bool` is not allowed: AutoGraph did not convert this function. Try decorating it directly with @tf.function.
    """"""


      "
38919,Discrepancy of soname for libtensorflow_framework.[dylib|so] on macOS and Linux,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04 + macOS
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: n/a
- TensorFlow installed from (source or binary): binary (tf-nightly)
- TensorFlow version: tf-nightly-2.2.0.dev20200426
- Python version: 3.6 on Ubuntu 18.04 and 3.7 on macOS
- Installed using virtualenv? pip? conda?: pip
- Bazel version (if compiling from source): n/a
- GCC/Compiler version (if compiling from source): n/a
- CUDA/cuDNN version: n/a
- GPU model and memory: n/a
**Describe the problem**

While trying to link against `libtensorflow_framework.so` for custom ops, we noticed that the soname on macOS and Linux are different:
**[macOS]:**
```
ls -la /Library/Python/3.7/site-packages/tensorflow
total 169680
...
-rwxr-xr-x   1 root  wheel  28946620 Apr 26 08:42 libtensorflow_framework.2.2.0.dylib
-rwxr-xr-x   1 root  wheel  28946620 Apr 26 08:42 libtensorflow_framework.2.dylib
-rwxr-xr-x   1 root  wheel  28946620 Apr 26 08:42 libtensorflow_framework.dylib
...
```

**[Linux]:**
```
ls -la /usr/local/lib/python3.6/dist-packages/tensorflow
total 37000
...
-rwxr-xr-x  1 root staff 37806248 Apr 26 15:40 libtensorflow_framework.so.2
...
```

From the above, it looks like macOS ties the soname to 2.2.0 while Linux still stays with 2. Given the fact that libtensorflow_framework.so largely relies on C++ API which does not guarantee compatibility across different version, it would be desirable to apply the same of macOS [`2.2.0`] to Linux [`2`] as well. This will help downstream projects to better hand version compatibility issue I think. /cc @seanpmorgan @perfinion "
38918,Propagate loss throw models,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Colab
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.2.0-rc3
- Python version: 3

**Describe the current behavior**
I have two models i want to run sequentially : a generator and a classifier.
The loss from the generator is depending from the classifier outputs.
In the code i provide, i can't manage to get the backpropagation working : 
ValueError: No gradients provided for any variable: ['dense_generator/kernel:0', 'dense_generator/bias:0']

No grad seems computed for the generator.

The code i wrote is strongly inspired from [dcgan tensorflow tutorial](https://www.tensorflow.org/tutorials/generative/dcgan)

**Describe the expected behavior**
I expect to be able to generate gradients for my generator based on a loss computed at my classifier level.

**Standalone code to reproduce the issue**
Copy paste the following code into a colab notebook and execute it : 

```
import tensorflow as tf
import numpy as np
print(tf.__version__)

def build_generator():
    in_data = tf.keras.layers.Input(shape=(1,), dtype=tf.int32, name=""in"")
    
    out = tf.keras.layers.Dense(10, name='dense_generator')(in_data)
    return tf.keras.Model(inputs=in_data, outputs=out)
    
def build_classifier():
    features = tf.keras.layers.Input(shape=(10,), dtype=tf.int32, name=""features"")
    out = tf.keras.layers.Dense(1, activation='sigmoid', dtype = tf.float32, name='dense_class')(features)

    return tf.keras.Model(inputs=features, outputs=out)

generator = build_generator()
classifier_toxic = build_classifier()

generator_optimizer = tf.keras.optimizers.Adam()
class_toxic_optimizer = tf.keras.optimizers.Adam() 

classifier_loss = lambda a,b: tf.keras.losses.binary_crossentropy(a, b, from_logits=True)

@tf.function
def train_step(inputs):
    with tf.GradientTape() as generator_tape:
        features = generator(inputs, training=True)
        preds = classifier_toxic(features)
        loss = classifier_loss(tf.zeros_like(preds), preds)
        # with this folowing loss that takes output from generator, it works but this is not what i want
        #loss = classifier_loss(tf.zeros_like(features), features)      
    # apply gradient on generator
    grads_generator = generator_tape.gradient(loss, generator.trainable_variables)
    generator_optimizer.apply_gradients(zip(grads_generator, generator.trainable_variables))

train_dataset = tf.data.Dataset.from_tensor_slices(np.arange(10)).batch(1)

for count, inputs in enumerate(train_dataset):
    # run training step
    train_step(inputs)
    print('done :', count)
```

"
38916,Failed to load the native TensorFlow runtime. ImportError DLL load failed.,"
**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- TensorFlow installed from (source or binary): binary (I think)
- TensorFlow version: 2.2.0rc3 CPU version
- Python version: 3.8.2
- Installed using virtualenv? pip? conda?: pip




**Describe the problem**
trying to run ascript that is importing tensorflow as follows:
```
import tensorflow as tf

ImportError: DLL load failed while importing _pywrap_tensorflow_internal: The specified module could not be found.

Failed to load the native TensorFlow runtime.

```
*the full trace back is below*

This `ImportError: DLL load failed while importing _pywrap_tensorflow_internal: The specified module could not be found` is evidently the issue but I am unsure how to fix it after having gone through your other responses to similar github issues.

**Provide the exact sequence of commands / steps that you executed before running into the problem**


**Any other info / logs**
```
Traceback (most recent call last):
  File ""C:\Users\wmn262\Anaconda3\envs\tensorflow1\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\wmn262\Anaconda3\envs\tensorflow1\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\wmn262\Anaconda3\envs\tensorflow1\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\wmn262\Anaconda3\envs\tensorflow1\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\wmn262\Anaconda3\envs\tensorflow1\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed while importing _pywrap_tensorflow_internal: The specified module could not be found.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""C:\Users\wmn262\Anaconda3\envs\tensorflow1\lib\site-packages\tensorflow\__init__.py"", line 41, in <module>
    from tensorflow.python.tools import module_util as _module_util
  File ""C:\Users\wmn262\Anaconda3\envs\tensorflow1\lib\site-packages\tensorflow\python\__init__.py"", line 50, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\Users\wmn262\Anaconda3\envs\tensorflow1\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 69, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""C:\Users\wmn262\Anaconda3\envs\tensorflow1\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\wmn262\Anaconda3\envs\tensorflow1\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\wmn262\Anaconda3\envs\tensorflow1\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\wmn262\Anaconda3\envs\tensorflow1\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\wmn262\Anaconda3\envs\tensorflow1\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
```
"
38915,Loding dataset with TFRecord throws incompatible with the layer,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 (also colab)
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.2.0-rc3
- Python version: 3.8.2 64 bit
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: 10.1
- GPU model and memory: RTX 2080 8gb

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
Model.fit throws
    
> ValueError: Input 0 of layer srcnn is incompatible with the layer: its rank is undefined, but the layer requires a defined rank.

**Describe the expected behavior**
trains network with loaded dataset from TFRecord

**Standalone code to reproduce the issue**
https://colab.research.google.com/drive/1GcIhMHv8GJff03WADzTo29oUFgjdMd_N

**Other info / logs** 
```
ValueError                                Traceback (most recent call last)

<ipython-input-96-ee31b3c773a3> in <module>()
     20     train_dataset_count/BATCH_SIZE).numpy()
     21 model.fit(parsed_dataset, epochs=epochs, steps_per_epoch=steps_per_epoch,
---> 22           callbacks=[cp_callback], use_multiprocessing=True)

10 frames

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py in _method_wrapper(self, *args, **kwargs)
     64   def _method_wrapper(self, *args, **kwargs):
     65     if not self._in_multi_worker_mode():  # pylint: disable=protected-access
---> 66       return method(self, *args, **kwargs)
     67 
     68     # Running inside `run_distribute_coordinator` already.

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)
    849                 batch_size=batch_size):
    850               callbacks.on_train_batch_begin(step)
--> 851               tmp_logs = train_function(iterator)
    852               # Catch OutOfRangeError for Datasets of unknown size.
    853               # This blocks until the batch has finished executing.

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py in __call__(self, *args, **kwds)
    578         xla_context.Exit()
    579     else:
--> 580       result = self._call(*args, **kwds)
    581 
    582     if tracing_count == self._get_tracing_count():

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py in _call(self, *args, **kwds)
    616       # In this case we have not created variables on the first call. So we can
    617       # run the first trace but we should fail if variables are created.
--> 618       results = self._stateful_fn(*args, **kwds)
    619       if self._created_variables:
    620         raise ValueError(""Creating variables on a non-first call to a function""

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py in __call__(self, *args, **kwargs)
   2417     """"""Calls a graph function specialized to the inputs.""""""
   2418     with self._lock:
-> 2419       graph_function, args, kwargs = self._maybe_define_function(args, kwargs)
   2420     return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access
   2421 

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py in _maybe_define_function(self, args, kwargs)
   2772           and self.input_signature is None
   2773           and call_context_key in self._function_cache.missed):
-> 2774         return self._define_function_with_shape_relaxation(args, kwargs)
   2775 
   2776       self._function_cache.missed.add(call_context_key)

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py in _define_function_with_shape_relaxation(self, args, kwargs)
   2704         relaxed_arg_shapes)
   2705     graph_function = self._create_graph_function(
-> 2706         args, kwargs, override_flat_arg_shapes=relaxed_arg_shapes)
   2707     self._function_cache.arg_relaxed[rank_only_cache_key] = graph_function
   2708 

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py in _create_graph_function(self, args, kwargs, override_flat_arg_shapes)
   2665             arg_names=arg_names,
   2666             override_flat_arg_shapes=override_flat_arg_shapes,
-> 2667             capture_by_value=self._capture_by_value),
   2668         self._function_attributes,
   2669         # Tell the ConcreteFunction to clean up its graph once it goes out of

/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)
    979         _, original_func = tf_decorator.unwrap(python_func)
    980 
--> 981       func_outputs = python_func(*func_args, **func_kwargs)
    982 
    983       # invariant: `func_outputs` contains only Tensors, CompositeTensors,

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py in wrapped_fn(*args, **kwds)
    439         # __wrapped__ allows AutoGraph to swap in a converted function. We give
    440         # the function a weak reference to itself to avoid a reference cycle.
--> 441         return weak_wrapped_fn().__wrapped__(*args, **kwds)
    442     weak_wrapped_fn = weakref.ref(wrapped_fn)
    443 

/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py in wrapper(*args, **kwargs)
    966           except Exception as e:  # pylint:disable=broad-except
    967             if hasattr(e, ""ag_error_metadata""):
--> 968               raise e.ag_error_metadata.to_exception(e)
    969             else:
    970               raise

ValueError: in user code:

    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:571 train_function  *
        outputs = self.distribute_strategy.run(
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:951 run  **
        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2290 call_for_each_replica
        return self._call_for_each_replica(fn, args, kwargs)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2649 _call_for_each_replica
        return fn(*args, **kwargs)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:531 train_step  **
        y_pred = self(x, training=True)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py:886 __call__
        self.name)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/input_spec.py:168 assert_input_compatibility
        layer_name + ' is incompatible with the layer: '

    ValueError: Input 0 of layer srcnn is incompatible with the layer: its rank is undefined, but the layer requires a defined rank.
```



"
38914,Can't seem to use mirrored strategy in graph mode using tf.function,"<em>Please make sure that this is an issue related to performance of TensorFlow.
As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:performance_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): 2.1
- Python version: 3.7
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: CUDA: 10.1 cudNN:7.6
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

My main objective is achieve parallelism during model training. I have been following the tutorial from the below: 
https://www.tensorflow.org/tutorials/distribute/custom_training

At first, I tried to use eager mode and did not use tf.function to decorate any of my functions. There is no runtime error but the GPUs were still being used sequentially and i as getting the warning that Mirrored Strategy has significant overhead in eager mode and to decorate my APIs with `@tf.function`.
So, I proceeded to do everything exactly like in the above link.

But, now I am getting the error that I cannot iterate over a `tf.tensor` in Graph Mode while iterating over the distributed batched dataset. I am unable to get past this issue. 

This is how i create my dataset. `list_ds` is list of lists , each sublist has 5 strings in it.
`dataset = tf.data.Dataset.from_tensor_slices(list_ds)`
`train_dataset` = dataset.batch(GLOBAL_BATCH_SIZE, drop_remainder=True)`
`train_data_dataset = strategy.experimental_distribute_dataset(train_dataset)`

Only the API where I call `strategy.experimental_run_v2` is decorated with tf.function.
`def train_step(input): `
    `.....`
`@tf.function`
`def distributed_train_step(dataset_inputs):`
    `strategy.experimental_run_v2(train_step, args=dataset_inputs)`
`for epoch in range(EPOCHS):`
    `for batch in train_dist_dataset:`
    `distributed_train_step(batch)`

Unfortunately, I will be unable to upload the exact code that I have written. That's why the indentations are wrong
**Describe the expected behavior**
 I should be able to iterate over my dataset in Graph mode as according to the tutorial it is possible.

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
38913,How to use cudnn LSTMP,"Firstly, I've posted this on [stackoverflow
](https://stackoverflow.com/questions/61438013/how-to-use-cudnn-lstmp) before. And I know this is not a bug or something so if there is an answer I'll delete this issue. Much appreciated!

Usually I use `tf.contrib.cudnn_rnn.CudnnLSTM` (tensorflow 1.15) and want to use LSTMP(LSTM projection) now. I know that `tf.contrib.rnn.LSTMCell` has LSTMP but that additional training time is too long for me. And I found that [nvidia support LSTMP](https://docs.nvidia.com/deeplearning/sdk/cudnn-developer-guide/index.html#features-of-rnn-functions). How to use it on tensorflow?

Thanks!"
38912,How to pass flags to nvcc when building tensorflow with bazel?,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
source
- TensorFlow version:
r1.14
- Python version:
3.6.9
- Installed using virtualenv? pip? conda?:
build on raw linux environment, with pip installed
- Bazel version (if compiling from source):
0.24.1
- GCC/Compiler version (if compiling from source):
4.8.5
- CUDA/cuDNN version:
CUDA 10.0 CUDNN 7.6.5
- GPU model and memory:
Nvidia GTX 1660Ti 6GB


**Describe the problem**
I want to pass some custom flags to nvcc during the build, like telling nvcc dynamically link the cuda runtime library with the flag --cudart=shared. On windows 10 with visual studio 2015, I could just use the following command line:
bazel build --config=opt --config=cuda --copt=-nvcc_options=cudart=shared //tensorflow/tools/pip_package:build_pip_package, and msvc will just pass the flag specified by the -nvcc_options to nvcc,  but on linux it doesn't work, with the following errors pop out:

ERROR: /root/.cache/bazel/_bazel_root/5ac94cf1f70fd575be3807b8a4a32ede/external/com_google_absl/absl/debugging/BUILD.bazel:190:1: C++ compilation of rule '@com_google_absl//absl/debugging:leak_check' failed (Exit 1)
gcc: error: unrecognized command line option '-nvcc_options=cudart=shared'
Target //tensorflow/tools/pip_package:build_pip_package failed to build
Use --verbose_failures to see the command lines of failed build steps.
INFO: Elapsed time: 152.342s, Critical Path: 48.24s
INFO: 1236 processes: 1236 local.
FAILED: Build did NOT complete successfully

**Provide the exact sequence of commands / steps that you executed before running into the problem**
just as the official build document said, build with command line:
bazel build --config=opt --config=cuda --copt=-nvcc_options=cudart=shared //tensorflow/tools/pip_package:build_pip_package

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

ERROR: /root/.cache/bazel/_bazel_root/5ac94cf1f70fd575be3807b8a4a32ede/external/com_google_absl/absl/debugging/BUILD.bazel:190:1: C++ compilation of rule '@com_google_absl//absl/debugging:leak_check' failed (Exit 1)
gcc: error: unrecognized command line option '-nvcc_options=cudart=shared'
Target //tensorflow/tools/pip_package:build_pip_package failed to build
Use --verbose_failures to see the command lines of failed build steps.
INFO: Elapsed time: 152.342s, Critical Path: 48.24s
INFO: 1236 processes: 1236 local.
FAILED: Build did NOT complete successfully"
38910,Simple loop is slow,"<em>Please make sure that this is an issue related to performance of TensorFlow.
As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:performance_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): True
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- TensorFlow installed from (source or binary): pip
- TensorFlow version (use command below): v2.1.0-rc2-17-ge5bf8de410
- Python version: 3.7
- CUDA/cuDNN version: 10.1
- GPU model and memory: GTX 1080Ti

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
Trivial loop is 300 times slower than in pure python or pytorch, note that the ratio doesn't change with the size of the loop.
Note that I do get a speed up by implementing the loop using while_loop syntax, but it's far (still >250 times slower) from catching up.


**Standalone code to reproduce the issue**
# TO BE RUN IN A NOTEBOOK
```python
import tensorflow as tf

tf.config.set_visible_devices([], 'GPU')

@tf.function
def tf_loop(n_iter):
    val = 0.
    for i in tf.range(n_iter):
        val += 0.
    return val

def loop(n_iter):
    val = 0.
    for i in range(n_iter):
        val += 0.
    return val

n_iter = tf.constant(10000)
%timeit tf_loop(n_iter) # 92.3 ms ± 566 µs
%timeit loop(10000) # 288 µs ± 4.31 µs

```

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
38909,Sampling uniforms is slow,"<em>Please make sure that this is an issue related to performance of TensorFlow.
As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:performance_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): True
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- TensorFlow installed from (source or binary): pip
- TensorFlow version (use command below): v2.1.0-rc2-17-ge5bf8de410
- Python version: 3.7
- CUDA/cuDNN version: 10.1
- GPU model and memory: GTX 1080Ti

**Describe the current behavior**
Sampling uniforms is 100 times slower in tensorflow on GPU than in pytorch, it's 30 times slower on CPU. 

**Standalone code to reproduce the issue**
# TO BE RUN IN A NOTEBOOK
```python
import tensorflow as tf
import torch
# tf.config.set_visible_devices([], 'GPU') # if no GPU tensorflow is now 30 times slower
%timeit tf.random.uniform([], 0., 1.) # 310 µs ± 3.53 µs per loop
%timeit torch.rand([]) # 2.04 µs ± 38.7 ns per loop
``` "
38908,    TypeError: len is not well defined for symbolic Tensors. (transpose:0) Please call `x.shape` rather than `len(x)` for shape information.,"I'm try to make my `padd_spectrograms`  function execute faster. So I add `@tf.function` but when I add `@tf.function` decorator I'm getting ` TypeError: len is not well defined for symbolic Tensors. (transpose:0) Please call `x.shape` rather than `len(x)` for shape information.`

I'm using `colab tensorflow 2.x`

If I do not use `@tf.function` it works without any error

```python
@tf.function
def padd_spectrograms(spectogram, padd_len):
    t = tf.transpose(spectogram) # feature x timestep -> timestep x feature
    p = tf.keras.preprocessing.sequence.pad_sequences(
        t, maxlen=padd_len, dtype='float', padding='post', truncating='post')
    return tf.transpose(p) # back to feature x timestep
```
```python
TypeError: in user code:

    /content/utils/helper.py:83 padd_spectrograms  *
        p = tf.keras.preprocessing.sequence.pad_sequences(
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/preprocessing/sequence.py:158 pad_sequences  **
        padding=padding, truncating=truncating, value=value)
    /usr/local/lib/python3.6/dist-packages/keras_preprocessing/sequence.py:56 pad_sequences
        num_samples = len(sequences)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:754 __len__
        ""shape information."".format(self.name))

    TypeError: len is not well defined for symbolic Tensors. (transpose:0) Please call `x.shape` rather than `len(x)` for shape information.
```

Thanks"
38907,%%bash cd models/research/ protoc object_detection/protos/*.proto --python_out= ./object_detection/protos/anchor_generator_pb2.py: Permission denied,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Python version**:
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with:

```bash
python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""
```

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
38906,MemoryOptimizer produces broken graph with AlreadyExistsError exception while running GRU layer on Tensorflow 2.2.0rc_3,"**System information**
- Custom model built using keras
- MacBook Pro, 8-Core Intel Core i9, macOS Catalina 10.15.4 
- TensorFlow installed from `pip` in virtual environment
- TensorFlow `v2.2.0-rc2-77-gaad398b5e9 2.2.0-rc3`
- Python 3.7.5
- Running on CPU

**Describe the current behavior**
The code snippet listed below outputs multiple `tensorflow/core/framework/op_kernel.cc:1753] OP_REQUIRES failed at variable_ops.cc:104 : Already exists: Resource` warnings and finally exists with `tensorflow.python.framework.errors_impl.AlreadyExistsError` exception.

Note: the code works correctly if the GRU layer size is decreased from `320` to `80`. It also works if TensorFlow is downgraded to version `2.0.1`.

The issue is related to https://github.com/tensorflow/tensorflow/issues/23780 issue reported in 2018. This issue offers code to reproduce it and occurs on the latest version of TensorFlow.

**Describe the expected behavior**
The code should work without exception.

**Standalone code to reproduce the issue**
```python
import numpy as np

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Flatten, Bidirectional, GRU
from tensorflow.keras.layers import Conv1D, MaxPooling1D

x = np.random.rand(1000, 401, 17)
y = np.random.choice([0, 1], size=(1000, 301))

model = Sequential()
model.add(Conv1D(filters=320, kernel_size=26, activation='relu', input_shape=(401, x.shape[2])))
model.add(MaxPooling1D(pool_size=13, strides=13))
model.add(Bidirectional(GRU(320, dropout=0.2, recurrent_dropout=0.2, return_sequences=True)))
model.add(Flatten())
model.add(Dense(2000, activation=""relu""))
model.add(Dense(301, activation=""sigmoid""))
model.compile(loss=""binary_crossentropy"", optimizer=""rmsprop"", metrics=[""accuracy""])

model.summary()

model.fit(x=x, y=y, epochs=1, verbose=1)
```

The Google Colab notebook is available [here](https://colab.research.google.com/drive/1YohTA6Hxi3H6aOQgFj34C0tKErW2V_rL). The error is reproducible.

**Other info / logs** 
The code above generates following output:
```
Model: ""sequential""
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv1d (Conv1D)              (None, 376, 320)          141760    
_________________________________________________________________
max_pooling1d (MaxPooling1D) (None, 28, 320)           0         
_________________________________________________________________
bidirectional (Bidirectional (None, 28, 640)           1232640   
_________________________________________________________________
flatten (Flatten)            (None, 17920)             0         
_________________________________________________________________
dense (Dense)                (None, 2000)              35842000  
_________________________________________________________________
dense_1 (Dense)              (None, 301)               602301    
=================================================================
Total params: 37,818,701
Trainable params: 37,818,701
Non-trainable params: 0
_________________________________________________________________
2020-04-26 10:19:57.349570: W tensorflow/core/framework/op_kernel.cc:1753] OP_REQUIRES failed at variable_ops.cc:104 : Already exists: Resource __per_step_0/gradient_tape/sequential/bidirectional/backward_gru/while/sequential/bidirectional/backward_gru/while_grad/body/_877/gradients/AddN_8/tmp_var/N10tensorflow19TemporaryVariableOp6TmpVarE
2020-04-26 10:19:57.363399: W tensorflow/core/framework/op_kernel.cc:1753] OP_REQUIRES failed at variable_ops.cc:104 : Already exists: Resource __per_step_0/gradient_tape/sequential/bidirectional/backward_gru/while/sequential/bidirectional/backward_gru/while_grad/body/_877/gradients/AddN_7/tmp_var/N10tensorflow19TemporaryVariableOp6TmpVarE
2020-04-26 10:19:57.377361: W tensorflow/core/framework/op_kernel.cc:1753] OP_REQUIRES failed at variable_ops.cc:104 : Already exists: Resource __per_step_0/gradient_tape/sequential/bidirectional/backward_gru/while/sequential/bidirectional/backward_gru/while_grad/body/_877/gradients/AddN_8/tmp_var/N10tensorflow19TemporaryVariableOp6TmpVarE
... (repeated multiple times) ...
2020-04-26 10:19:57.677304: W tensorflow/core/framework/op_kernel.cc:1753] OP_REQUIRES failed at variable_ops.cc:104 : Already exists: Resource __per_step_0/gradient_tape/sequential/bidirectional/forward_gru/while/sequential/bidirectional/forward_gru/while_grad/body/_577/gradients/AddN_7/tmp_var/N10tensorflow19TemporaryVariableOp6TmpVarE
Traceback (most recent call last):
  File ""alreadyexists_err.py"", line 21, in <module>
    model.fit(x=x, y=y, epochs=1, verbose=1)
  File ""venv/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py"", line 66, in _method_wrapper
    return method(self, *args, **kwargs)
  File ""venv/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py"", line 851, in fit
    tmp_logs = train_function(iterator)
  File ""venv/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py"", line 580, in __call__
    result = self._call(*args, **kwds)
  File ""venv/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py"", line 644, in _call
    return self._stateless_fn(*args, **kwds)
  File ""venv/lib/python3.7/site-packages/tensorflow/python/eager/function.py"", line 2420, in __call__
    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access
  File ""venv/lib/python3.7/site-packages/tensorflow/python/eager/function.py"", line 1665, in _filtered_call
    self.captured_inputs)
  File ""venv/lib/python3.7/site-packages/tensorflow/python/eager/function.py"", line 1746, in _call_flat
    ctx, args, cancellation_manager=cancellation_manager))
  File ""venv/lib/python3.7/site-packages/tensorflow/python/eager/function.py"", line 598, in call
    ctx=ctx)
  File ""venv/lib/python3.7/site-packages/tensorflow/python/eager/execute.py"", line 60, in quick_execute
    inputs, attrs, num_outputs)
tensorflow.python.framework.errors_impl.AlreadyExistsError:  Resource __per_step_0/gradient_tape/sequential/bidirectional/backward_gru/while/sequential/bidirectional/backward_gru/while_grad/body/_877/gradients/AddN_8/tmp_var/N10tensorflow19TemporaryVariableOp6TmpVarE
	 [[{{node gradient_tape/sequential/bidirectional/backward_gru/while/sequential/bidirectional/backward_gru/while_grad/body/_877/gradients/AddN_8/tmp_var}}]] [Op:__inference_train_function_7551]

Function call stack:
train_function
```
"
38905,Run a GitHub project on google Colabratory,"I have a question, there is a GitHub project about text to speech with deep-learning but i can't neither run it on local machine nor google colaboratory,

can anyone help on how to run it? as i downloaded the files but it has many files i dont know how to run it.

it's git hub link==>

https://github.com/AlisterTA/Persian-text-to-speech
Thanks"
38903,[TFLite] TFlite failed to build the whl package,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): CentOS7.6
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): source 
- TensorFlow version: latest master branch [64c32cf5100fc8807fe6598bc5517c3456b68b97]
- Python version: 3.6.8
- Installed using virtualenv? pip? conda?: virtualenv
- Bazel version (if compiling from source): 3.0.0
- GCC/Compiler version (if compiling from source): 8.3

**Describe the problem**
Following the BKM[https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/tools/pip_package] to build tflite, failed with the error:

_interpreter_wrapper/interpreter_wrapper_pybind11.cc:16:10: fatal error: pybind11/pybind11.h: No such file or directory
 #include ""pybind11/pybind11.h""
          ^~~~~~~~~~~~~~~~~~~~~
compilation terminated.
error: command 'gcc' failed with exit status 1_

I have install pybind11 and numpy through pip. and I have checked pybind11.h do exsit in the PATH. suspect the bug relates with the build file.

**Provide the exact sequence of commands / steps that you executed before running into the problem**
```
sudo apt install swig libjpeg-dev zlib1g-dev python3-dev python3-numpy
pip install numpy pybind11
sh tensorflow/lite/tools/make/download_dependencies.sh
sh tensorflow/lite/tools/pip_package/build_pip_package.sh

```

"
38902,There are no control inputs between 'Assign' and 'read' nodes,"I thought there should be some dependencies between 'Assign' and 'read' nodes, so that 'read' only executes after 'Assign' is done. But through the following toy example, this seems to be not the case:

    import tensorflow as tf
    a = tf.get_variable('a', shape = (2,3))

    print ('op_name', 'control_inputs', 'input_ops', 'output[0]_shape')
    for op in tf.get_default_graph().get_operations():
      print (op.name, op.control_inputs, [inp.op.name for inp in op.inputs], op.outputs[0].shape)

output:

    op_name control_inputs input_ops output[0]_shape
    a/Initializer/random_uniform/shape [] [] (2,)
    a/Initializer/random_uniform/min [] [] ()
    a/Initializer/random_uniform/max [] [] ()
    a/Initializer/random_uniform/RandomUniform [] ['a/Initializer/random_uniform/shape'] (2, 3)
    a/Initializer/random_uniform/sub [] ['a/Initializer/random_uniform/max', 'a/Initializer/random_uniform/min'] ()
    a/Initializer/random_uniform/mul [] ['a/Initializer/random_uniform/RandomUniform', 'a/Initializer/random_uniform/sub'] (2, 3)
    a/Initializer/random_uniform [] ['a/Initializer/random_uniform/mul', 'a/Initializer/random_uniform/min'] (2, 3)
    a [] [] (2, 3)
    a/Assign [] ['a', 'a/Initializer/random_uniform'] (2, 3)
    a/read [] ['a'] (2, 3)

So `a/Assign` and `a/read` nodes have no dependencies, and may execute in any order. Is there supposed to be any?"
38901,"Expected image (JPEG, PNG, or GIF), got unknown format starting with 'BM\""\360\003\000\000\000\000\0006\000\000\000(\000' 	 [[{{node DecodeJpeg}}]]","
## System information
**I have followed examples from tensorflow official website with some changes but essentially the same. I want to get an image generator that is efficient at its task of generating only images without caring about labels (its only cat images), -- AND I am using jupyter notebook.**

- **OS Platform and Distribution - Linux Ubuntu 19.10**
- **TensorFlow installed from conda using -- ```conda install tensorflow-gpu```**
- **TensorFlow version == 2.1.0**
- **Python version == 3.7.7**
- **CUDA Toolkit version == 10.1.243**
- **cuDNN version == 7.6.5**
- **GPU model and memory == NVIDIA GTX 1050 (4GB)**



## **Source code sniplet**:
```python
data_dir = pathlib.Path('cat/')
list_ds = tf.data.Dataset.list_files(str(data_dir/'CAT/*.jpg'))

def parse_image(filename):
    image = tf.io.read_file(filename)
    image = tf.image.decode_jpeg(image)
    image = tf.image.convert_image_dtype(image, tf.float32)
    image = tf.image.resize(image, [64,64])
    return image

AUTOTUNE = tf.data.experimental.AUTOTUNE
# Set `num_parallel_calls` so multiple images are loaded/processed in parallel.
images_ds = list_ds.map(parse_image, num_parallel_calls=AUTOTUNE)

images_ds = images_ds.prefetch(buffer_size=AUTOTUNE)
images_ds = images_ds.repeat()
images_ds = images_ds.cache().batch(BATCH_SIZE)
images_ds = images_ds.shuffle(buffer_size=1000)

image_batch = next(iter(images_ds)) ## This line causes error
```



### **I have seen this error pop up for many users on the internet but did not find a viable solution to it. Some suggested to check all the images if they were not corrupted. I used the below script but everything turned out to be fine.**
```python
import os
import tensorflow as tf

for i, file_name in enumerate(os.walk('cat/CAT/')):
#     print(file_name[2])
    try:
        img = tf.io.read_file('cat/CAT/'+file_name[2][i])
        img = tf.image.decode_jpeg(img)
    except Exception as e:
        print(e)
        print('******************************************************')
        print('{} - broken'.format(file_name[2][i]))
```

### **Please help me in this issue.**


## Detailed Error
```python
---------------------------------------------------------------------------
InvalidArgumentError                      Traceback (most recent call last)
~/anaconda3/envs/sci/lib/python3.7/site-packages/tensorflow_core/python/eager/context.py in execution_mode(mode)
   1896     ctx.executor = executor_new
-> 1897     yield
   1898   finally:

~/anaconda3/envs/sci/lib/python3.7/site-packages/tensorflow_core/python/data/ops/iterator_ops.py in _next_internal(self)
    658             output_types=self._flat_output_types,
--> 659             output_shapes=self._flat_output_shapes)
    660 

~/anaconda3/envs/sci/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_dataset_ops.py in iterator_get_next_sync(iterator, output_types, output_shapes, name)
   2478     except _core._NotOkStatusException as e:
-> 2479       _ops.raise_from_not_ok_status(e, name)
   2480   # Add nodes to the TensorFlow graph.

~/anaconda3/envs/sci/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py in raise_from_not_ok_status(e, name)
   6605   # pylint: disable=protected-access
-> 6606   six.raise_from(core._status_to_exception(e.code, message), None)
   6607   # pylint: enable=protected-access

~/anaconda3/envs/sci/lib/python3.7/site-packages/six.py in raise_from(value, from_value)

InvalidArgumentError: Expected image (JPEG, PNG, or GIF), got unknown format starting with 'BM\""\360\003\000\000\000\000\0006\000\000\000(\000'
	 [[{{node DecodeJpeg}}]] [Op:IteratorGetNextSync]

During handling of the above exception, another exception occurred:

InvalidArgumentError                      Traceback (most recent call last)
<ipython-input-119-e1154546d6ba> in <module>
----> 1 image_batch = next(iter(images_ds))

~/anaconda3/envs/sci/lib/python3.7/site-packages/tensorflow_core/python/data/ops/iterator_ops.py in __next__(self)
    628 
    629   def __next__(self):  # For Python 3 compatibility
--> 630     return self.next()
    631 
    632   def _next_internal(self):

~/anaconda3/envs/sci/lib/python3.7/site-packages/tensorflow_core/python/data/ops/iterator_ops.py in next(self)
    672     """"""Returns a nested structure of `Tensor`s containing the next element.""""""
    673     try:
--> 674       return self._next_internal()
    675     except errors.OutOfRangeError:
    676       raise StopIteration

~/anaconda3/envs/sci/lib/python3.7/site-packages/tensorflow_core/python/data/ops/iterator_ops.py in _next_internal(self)
    663         return self._element_spec._from_compatible_tensor_list(ret)  # pylint: disable=protected-access
    664       except AttributeError:
--> 665         return structure.from_compatible_tensor_list(self._element_spec, ret)
    666 
    667   @property

~/anaconda3/envs/sci/lib/python3.7/contextlib.py in __exit__(self, type, value, traceback)
    128                 value = type()
    129             try:
--> 130                 self.gen.throw(type, value, traceback)
    131             except StopIteration as exc:
    132                 # Suppress StopIteration *unless* it's the same exception that

~/anaconda3/envs/sci/lib/python3.7/site-packages/tensorflow_core/python/eager/context.py in execution_mode(mode)
   1898   finally:
   1899     ctx.executor = executor_old
-> 1900     executor_new.wait()
   1901 
   1902 

~/anaconda3/envs/sci/lib/python3.7/site-packages/tensorflow_core/python/eager/executor.py in wait(self)
     65   def wait(self):
     66     """"""Waits for ops dispatched in this executor to finish.""""""
---> 67     pywrap_tensorflow.TFE_ExecutorWaitForAllPendingNodes(self._handle)
     68 
     69   def clear_error(self):

InvalidArgumentError: Expected image (JPEG, PNG, or GIF), got unknown format starting with 'BM\""\360\003\000\000\000\000\0006\000\000\000(\000'
	 [[{{node DecodeJpeg}}]]
```"
38898,unique_with_counts is quite slow,"**System information**
- Have I written custom code: yes
- OS Platform and Distribution: docker image nvcr.io/nvidia/tensorflow:20.03-tf2-py3 (Linux x86_64 Ubuntu 18.04.4 LTS)
- TensorFlow installed from: docker image
- TensorFlow version: 2.1.0
- Python version: 3.6.9
- CUDA/cuDNN version: 10.2 / 7.6
- GPU model and memory: Tesla V100-SXM2 32GB

**Describe the current behavior**
unique_with_counts is quite slow. In comparison pytorch is 50 - 100 times faster:

| framework   |   mean (ms) | dtype   |
| ----------- | ----------: | ------- |
| tensorflow  |   234.770   | int32   |
| tensorflow  |   231.738   | int16   |
| tensorflow  |   400.438   | float32 |
| tensorflow  |   307.234   | float16 |
| pytorch     |     5.372   | int32   |
| pytorch     |     4.086   | int16   |
| pytorch     |     5.080   | float32 |
| pytorch     |     3.511   | float16 |

The script to produce these results can be found here: https://github.com/liob/bugreport_tf_unique_with_counts

**Describe the expected behavior**
It is apparent that tf implements unique_with_counts as a single-threaded CPU routine. A GPU implementation, such as in pytorch, will most certainly speed up the operation dramatically.

**Standalone code to reproduce the issue**
https://colab.research.google.com/drive/1ye_wN-DkfIgz-AtQncbiM0h0zsVe7sKx
"
38897,Qualify TensorFlow Docker Hub image as Docker Certified,"The TensorFlow Docker Hub image should apply for Docker Certified qualification, just like most other popular Docker Hub images. This will not change the current API.

According to the official Docker documentation:

> The Docker Certification program for Containers and Plugins is designed for both technology partners and enterprise customers to recognize high-quality Containers and Plugins, provide collaborative support, and ensure compatibility with the Docker Enterprise platform. Docker Certified products give enterprises a trusted way to run more technology in containers with support from both Docker and the publisher. The Docker Technology Partner guide explains the Technology Partner program, inclusive of process and requirements to Certify Containers and Plugins.

More information:
- https://docs.docker.com/docker-hub/publish/publisher_faq/#what-is-the-certification-program-for-containers-and-plugins-and-what-are-some-benefits
- https://docs.docker.com/docker-hub/publish/certify-images/"
38893,Cannot save tensorflow_probability.distributions.PixelCNN with tf.train.Checkpoint,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): v2.1.0-rc2-17-ge5bf8de 2.1.0
- Python version: 3.6.9
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10.1
- GPU model and memory: GTX 1070

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
Trying to save a model which includes a tfd.PixelCNN gives the traceback:
```Traceback (most recent call last):
  File ""test.py"", line 16, in <module>
    checkpoint.save(file_prefix='fails_before_here')
  File ""/home/equint/GitHub/pyroclast/env/lib/python3.6/site-packages/tensorflow_core/python/training/tracking/util.py"", line 1902, in save
    file_path = self.write(""%s-%d"" % (file_prefix, checkpoint_number))
  File ""/home/equint/GitHub/pyroclast/env/lib/python3.6/site-packages/tensorflow_core/python/training/tracking/util.py"", line 1832, in write
    output = self._saver.save(file_prefix=file_prefix)
  File ""/home/equint/GitHub/pyroclast/env/lib/python3.6/site-packages/tensorflow_core/python/training/tracking/util.py"", line 1168, in save
    file_prefix=file_prefix_tensor, object_graph_tensor=object_graph_tensor)
  File ""/home/equint/GitHub/pyroclast/env/lib/python3.6/site-packages/tensorflow_core/python/training/tracking/util.py"", line 1108, in _save_cached_when_graph_building
    object_graph_tensor=object_graph_tensor)
  File ""/home/equint/GitHub/pyroclast/env/lib/python3.6/site-packages/tensorflow_core/python/training/tracking/util.py"", line 1076, in _gather_saveables
    feed_additions) = self._graph_view.serialize_object_graph()
  File ""/home/equint/GitHub/pyroclast/env/lib/python3.6/site-packages/tensorflow_core/python/training/tracking/graph_view.py"", line 379, in serialize_object_graph
    trackable_objects, path_to_root = self._breadth_first_traversal()
  File ""/home/equint/GitHub/pyroclast/env/lib/python3.6/site-packages/tensorflow_core/python/training/tracking/graph_view.py"", line 199, in _breadth_first_traversal
    for name, dependency in self.list_dependencies(current_trackable):
  File ""/home/equint/GitHub/pyroclast/env/lib/python3.6/site-packages/tensorflow_core/python/training/tracking/graph_view.py"", line 159, in list_dependencies
    return obj._checkpoint_dependencies
  File ""/home/equint/GitHub/pyroclast/env/lib/python3.6/site-packages/tensorflow_core/python/training/tracking/data_structures.py"", line 509, in _checkpoint_dependencies
    ""automatically un-wrapped and subsequently ignored."" % (self,)))
ValueError: Unable to save the object ListWrapper([0, 1, 2]) (a list wrapper constructed to track trackable TensorFlow objects). A list element was replaced (__setitem__, __setslice__), deleted (__delitem__, __delslice__), or moved (sort). In order to support restoration on object creation, tracking is exclusively for append-only data structures
```

**Describe the expected behavior**
Shouldn't have a problem saving a distribution using `tf.train.Checkpoint.save`

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.
```
import tensorflow as tf
import tensorflow_probability as tfp

tfd = tfp.distributions

model = tfd.PixelCNN(
    image_shape=(28, 28, 1),
    conditional_shape=(28, 28, 1),
    num_resnet=1,
    num_hierarchies=2,
    num_filters=32,
    num_logistic_mix=4,
    dropout_p=.3,
)
checkpoint = tf.train.Checkpoint(model=model)
checkpoint.save(file_prefix='fails_before_here')
```

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
38892,Internal tensorflow-keras error loading hd5 model,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
no
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
pip
- TensorFlow version (use command below):
2.0.0b1
- Python version:
3.7
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
not using cuda
- GPU model and memory:
N/A

I'm trying to load a trained model in an aws EC2 machine and I get the following:

```
Traceback (most recent call last):
  File ""/home/ubuntu/kraken/krk_modeling/src/services/logger.py"", line 51, in wrapper
    return function(*args, **kwargs)
  File ""src/wrapper.py"", line 81, in execute_pipeline
    conv.build(wkobflow, wkobwthr, wkfcwthr, LOG)
  File ""/home/ubuntu/kraken/krk_modeling/src/models/neuralnet.py"", line 41, in build
    self.models[s] = load_model(self.PATH + self.FORMAT(s))
  File ""/home/ubuntu/kraken/venv/lib/python3.7/site-packages/tensorflow/python/keras/saving/save.py"", line 137, in load_model
    return hdf5_format.load_model_from_hdf5(filepath, custom_objects, compile)
  File ""/home/ubuntu/kraken/venv/lib/python3.7/site-packages/tensorflow/python/keras/saving/hdf5_format.py"", line 162, in load_model_from_hdf5
    custom_objects=custom_objects)
  File ""/home/ubuntu/kraken/venv/lib/python3.7/site-packages/tensorflow/python/keras/saving/model_config.py"", line 55, in model_from_config
    return deserialize(config, custom_objects=custom_objects)
  File ""/home/ubuntu/kraken/venv/lib/python3.7/site-packages/tensorflow/python/keras/layers/serialization.py"", line 90, in deserialize
    printable_module_name='layer')
  File ""/home/ubuntu/kraken/venv/lib/python3.7/site-packages/tensorflow/python/keras/utils/generic_utils.py"", line 192, in deserialize_keras_object
    list(custom_objects.items())))
  File ""/home/ubuntu/kraken/venv/lib/python3.7/site-packages/tensorflow/python/keras/engine/network.py"", line 1123, in from_config
    process_layer(layer_data)
  File ""/home/ubuntu/kraken/venv/lib/python3.7/site-packages/tensorflow/python/keras/engine/network.py"", line 1107, in process_layer
    layer = deserialize_layer(layer_data, custom_objects=custom_objects)
  File ""/home/ubuntu/kraken/venv/lib/python3.7/site-packages/tensorflow/python/keras/layers/serialization.py"", line 90, in deserialize
    printable_module_name='layer')
  File ""/home/ubuntu/kraken/venv/lib/python3.7/site-packages/tensorflow/python/keras/utils/generic_utils.py"", line 194, in deserialize_keras_object
    return cls.from_config(cls_config)
  File ""/home/ubuntu/kraken/venv/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py"", line 451, in from_config
    return cls(**config)
  File ""/home/ubuntu/kraken/venv/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py"", line 2417, in __init__
    self.node_def = node_def_pb2.NodeDef.FromString(node_def)
TypeError: a bytes-like object is required, not 'dict'
```

I am running the same code in my machine normally, the models load and run. on EC2 I'm using tensorflow 2.0.0b1, same version used in training. Also, the model is in production in another machine and loading normally too. I tried to re-install hdf5 and re-install tensorflow after that, and still getting the error. Please help =]

the problem is generated only by loading the model. no code is required, since the problem is originated from tensorflow.keras.models.load_model.
"
38891,Adding regularization losses with the `model.add_loss` method doesn't seem to do the intended thing,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.2.0-rc3
- Python version: 3.7


**Describe the current behavior**
I was trying to add regularization losses to models that are already build, for example `keras_applications` models. I did this using the `model.add_loss` method. After adding losses from all the layers, calling model.losses seems to return a list containing the same loss value for each of the layers, which seems weird.
```
inputs = tf.keras.Input(shape=[100])
x = tf.keras.layers.Dense(10)(inputs)
x = tf.keras.layers.Dense(15)(x)
x = tf.keras.layers.Dense(5)(x)
outputs = tf.keras.layers.Dense(5)(x)

model = tf.keras.Model(inputs, outputs)

assert model.losses == []

l2_regularizer = tf.keras.regularizers.l2(1e-4)
for i in range(len(model.layers)):
    layer = model.layers[i]
    if isinstance(layer, tf.keras.layers.Dense):
        model.add_loss(lambda: l2_regularizer(layer.kernel))
        
print(model.losses)
```
ouptut:
```
[<tf.Tensor: shape=(), dtype=float32, numpy=0.0004718543>,
 <tf.Tensor: shape=(), dtype=float32, numpy=0.0004718543>,
 <tf.Tensor: shape=(), dtype=float32, numpy=0.0004718543>,
 <tf.Tensor: shape=(), dtype=float32, numpy=0.0004718543>]
```

Interesting thing to note is, if i add the losses without a loop, everything seems to work as intended
```
inputs = tf.keras.Input(shape=[100])
x = tf.keras.layers.Dense(10)(inputs)
x = tf.keras.layers.Dense(15)(x)
x = tf.keras.layers.Dense(5)(x)
outputs = tf.keras.layers.Dense(5)(x)

model = tf.keras.Model(inputs, outputs)

assert model.losses == []

l2_regularizer = tf.keras.regularizers.l2(1e-4)
model.add_loss(lambda: l2_regularizer(model.layers[1].kernel))
model.add_loss(lambda: l2_regularizer(model.layers[2].kernel))
model.add_loss(lambda: l2_regularizer(model.layers[3].kernel))
model.add_loss(lambda: l2_regularizer(model.layers[4].kernel))
        
print(model.losses)
```
output:
```
[<tf.Tensor: shape=(), dtype=float32, numpy=0.0018836524>,
 <tf.Tensor: shape=(), dtype=float32, numpy=0.0012256705>,
 <tf.Tensor: shape=(), dtype=float32, numpy=0.0007460108>,
 <tf.Tensor: shape=(), dtype=float32, numpy=0.0004328331>]
```

I am aware that i can always set the `kernel_regularizer` in layer's arg while building the model, but in this case i wanted to add a regularization loss to the model that was already built.
 "
38890,tensorflow lite build for imx6 with poky toolchain,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>


**step 1:** 
**Clone: Clone branch r1.12**
git clone https://github.com/tensorflow/tensorflow.git -b r1.12

alexvatti@SYR-DEEPLEARN2:~/AlexBuildLocation/jadak/April_24/tensorflowlite/tensorflow$ .**/tensorflow/contrib/lite/tools/make/download_dependencies.sh** 


**Cross Compilation / Build for i.MX6 with Poky Tool chain**

### System information
- **OS Platform and Distribution : ubuntu 18.04 [Linux SYR 4.15.0-96-generic #97-Ubuntu SMP Wed Apr 1 03:25:46 UTC 2020 x86_64 x86_64 x86_64 GNU/Linux]
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: r1.12
- **Python version**: python 3.7
- **Bazel version (if compiling from source)**: bazel release 0.26.1
- **GCC/Compiler version (if compiling from source)**: COLLECT_GCC=arm-poky-linux-gnueabi-gcc , gcc version 9.2.0 (GCC) 
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**:

**arm-poky-linux-gnueabi-gcc**
COLLECT_GCC=arm-poky-linux-gnueabi-gcc
COLLECT_LTO_WRAPPER=/opt/poky/3.0.2/sysroots/x86_64-pokysdk-linux/usr/libexec/arm-poky-linux-gnueabi/gcc/arm-poky-linux-gnueabi/9.2.0/lto-wrapper
Target: arm-poky-linux-gnueabi
Configured with: ../../../../../../work-shared/gcc-9.2.0-r0/gcc-9.2.0/configure --build=x86_64-linux --host=x86_64-pokysdk-linux --target=arm-poky-linux-gnueabi --prefix=/opt/poky/3.0.2/sysroots/x86_64-pokysdk-linux/usr --exec_prefix=/opt/poky/3.0.2/sysroots/x86_64-pokysdk-linux/usr --bindir=/opt/poky/3.0.2/sysroots/x86_64-pokysdk-linux/usr/bin/arm-poky-linux-gnueabi --sbindir=/opt/poky/3.0.2/sysroots/x86_64-pokysdk-linux/usr/bin/arm-poky-linux-gnueabi --libexecdir=/opt/poky/3.0.2/sysroots/x86_64-pokysdk-linux/usr/libexec/arm-poky-linux-gnueabi --datadir=/opt/poky/3.0.2/sysroots/x86_64-pokysdk-linux/usr/share --sysconfdir=/opt/poky/3.0.2/sysroots/x86_64-pokysdk-linux/etc --sharedstatedir=/opt/poky/3.0.2/sysroots/x86_64-pokysdk-linux/com --localstatedir=/opt/poky/3.0.2/sysroots/x86_64-pokysdk-linux/var --libdir=/opt/poky/3.0.2/sysroots/x86_64-pokysdk-linux/usr/lib/arm-poky-linux-gnueabi --includedir=/opt/poky/3.0.2/sysroots/x86_64-pokysdk-linux/usr/include --oldincludedir=/opt/poky/3.0.2/sysroots/x86_64-pokysdk-linux/usr/include --infodir=/opt/poky/3.0.2/sysroots/x86_64-pokysdk-linux/usr/share/info --mandir=/opt/poky/3.0.2/sysroots/x86_64-pokysdk-linux/usr/share/man --disable-silent-rules --disable-dependency-tracking --with-libtool-sysroot=/media/samsungQVO2TB/alexvatti/jadak/yocto/build/tmp/work/x86_64-nativesdk-pokysdk-linux/gcc-cross-canadian-arm/9.2.0-r0/recipe-sysroot --with-gnu-ld --enable-shared --enable-languages=c,c++ --enable-threads=posix --enable-multilib --enable-default-pie --enable-c99 --enable-long-long --enable-symvers=gnu --enable-libstdcxx-pch --program-prefix=arm-poky-linux-gnueabi- --without-local-prefix --enable-lto --disable-libssp --enable-libitm --disable-bootstrap --disable-libmudflap --with-system-zlib --with-linker-hash-style=gnu --enable-linker-build-id --with-ppl=no --with-cloog=no --enable-checking=release --enable-cheaders=c_global --without-isl --with-gxx-include-dir=/not/exist/usr/include/c++/9.2.0 --with-build-time-tools=/media/samsungQVO2TB/alexvatti/jadak/yocto/build/tmp/work/x86_64-nativesdk-pokysdk-linux/gcc-cross-canadian-arm/9.2.0-r0/recipe-sysroot-native/usr/arm-poky-linux-gnueabi/bin --with-sysroot=/not/exist --with-build-sysroot=/media/samsungQVO2TB/alexvatti/jadak/yocto/build/tmp/work/x86_64-nativesdk-pokysdk-linux/gcc-cross-canadian-arm/9.2.0-r0/recipe-sysroot --enable-poison-system-directories --disable-static --enable-nls --with-glibc-version=2.28 --enable-initfini-array
gcc version 9.2.0 (GCC)


**Describe the problem**

alexvatti@SYR-DEEPLEARN2:~/AlexBuildLocation/jadak/April_24/tensorflowlite/tensorflow$ ./tensorflow/contrib/lite/tools/make/build_rpi_lib.sh
+ set -e
+++ dirname ./tensorflow/contrib/lite/tools/make/build_rpi_lib.sh
++ cd ./tensorflow/contrib/lite/tools/make
++ pwd
+ SCRIPT_DIR=/home/alexvatti/AlexBuildLocation/jadak/April_24/tensorflowlite/tensorflow/tensorflow/contrib/lite/tools/make
+ cd /home/alexvatti/AlexBuildLocation/jadak/April_24/tensorflowlite/tensorflow/tensorflow/contrib/lite/tools/make/../../../../..
+ CC_PREFIX=arm-poky-linux-gnueabi-
+ make -j 3 -f tensorflow/contrib/lite/tools/make/Makefile TARGET=rpi TARGET_ARCH=armv7l
/bin/sh: 1: [[: not found
arm-poky-linux-gnueabi-g++ -O3 -DNDEBUG --std=c++11 -march=armv7-a -mfpu=neon -funsafe-math-optimizations -ftree-vectorize -fPIC -I. -I/media/samsungQVO2TB/alexvatti/jadak/April_24/tensorflowlite/tensorflow/tensorflow/contrib/lite/tools/make/../../../../../ -I/media/samsungQVO2TB/alexvatti/jadak/April_24/tensorflowlite/tensorflow/tensorflow/contrib/lite/tools/make/../../../../../../ -I/media/samsungQVO2TB/alexvatti/jadak/April_24/tensorflowlite/tensorflow/tensorflow/contrib/lite/tools/make/downloads/ -I/media/samsungQVO2TB/alexvatti/jadak/April_24/tensorflowlite/tensorflow/tensorflow/contrib/lite/tools/make/downloads/eigen -I/media/samsungQVO2TB/alexvatti/jadak/April_24/tensorflowlite/tensorflow/tensorflow/contrib/lite/tools/make/downloads/absl -I/media/samsungQVO2TB/alexvatti/jadak/April_24/tensorflowlite/tensorflow/tensorflow/contrib/lite/tools/make/downloads/gemmlowp -I/media/samsungQVO2TB/alexvatti/jadak/April_24/tensorflowlite/tensorflow/tensorflow/contrib/lite/tools/make/downloads/neon_2_sse -I/media/samsungQVO2TB/alexvatti/jadak/April_24/tensorflowlite/tensorflow/tensorflow/contrib/lite/tools/make/downloads/farmhash/src -I/media/samsungQVO2TB/alexvatti/jadak/April_24/tensorflowlite/tensorflow/tensorflow/contrib/lite/tools/make/downloads/flatbuffers/include -I -I/usr/local/include -c tensorflow/contrib/lite/allocation.cc -o /media/samsungQVO2TB/alexvatti/jadak/April_24/tensorflowlite/tensorflow/tensorflow/contrib/lite/tools/make/gen/rpi_armv7l/obj/tensorflow/contrib/lite/allocation.o
arm-poky-linux-gnueabi-g++ -O3 -DNDEBUG --std=c++11 -march=armv7-a -mfpu=neon -funsafe-math-optimizations -ftree-vectorize -fPIC -I. -I/media/samsungQVO2TB/alexvatti/jadak/April_24/tensorflowlite/tensorflow/tensorflow/contrib/lite/tools/make/../../../../../ -I/media/samsungQVO2TB/alexvatti/jadak/April_24/tensorflowlite/tensorflow/tensorflow/contrib/lite/tools/make/../../../../../../ -I/media/samsungQVO2TB/alexvatti/jadak/April_24/tensorflowlite/tensorflow/tensorflow/contrib/lite/tools/make/downloads/ -I/media/samsungQVO2TB/alexvatti/jadak/April_24/tensorflowlite/tensorflow/tensorflow/contrib/lite/tools/make/downloads/eigen -I/media/samsungQVO2TB/alexvatti/jadak/April_24/tensorflowlite/tensorflow/tensorflow/contrib/lite/tools/make/downloads/absl -I/media/samsungQVO2TB/alexvatti/jadak/April_24/tensorflowlite/tensorflow/tensorflow/contrib/lite/tools/make/downloads/gemmlowp -I/media/samsungQVO2TB/alexvatti/jadak/April_24/tensorflowlite/tensorflow/tensorflow/contrib/lite/tools/make/downloads/neon_2_sse -I/media/samsungQVO2TB/alexvatti/jadak/April_24/tensorflowlite/tensorflow/tensorflow/contrib/lite/tools/make/downloads/farmhash/src -I/media/samsungQVO2TB/alexvatti/jadak/April_24/tensorflowlite/tensorflow/tensorflow/contrib/lite/tools/make/downloads/flatbuffers/include -I -I/usr/local/include -c tensorflow/contrib/lite/arena_planner.cc -o /media/samsungQVO2TB/alexvatti/jadak/April_24/tensorflowlite/tensorflow/tensorflow/contrib/lite/tools/make/gen/rpi_armv7l/obj/tensorflow/contrib/lite/arena_planner.o
arm-poky-linux-gnueabi-gcc -O3 -DNDEBUG -march=armv7-a -mfpu=neon-vfpv4 -funsafe-math-optimizations -ftree-vectorize -fPIC -I. -I/media/samsungQVO2TB/alexvatti/jadak/April_24/tensorflowlite/tensorflow/tensorflow/contrib/lite/tools/make/../../../../../ -I/media/samsungQVO2TB/alexvatti/jadak/April_24/tensorflowlite/tensorflow/tensorflow/contrib/lite/tools/make/../../../../../../ -I/media/samsungQVO2TB/alexvatti/jadak/April_24/tensorflowlite/tensorflow/tensorflow/contrib/lite/tools/make/downloads/ -I/media/samsungQVO2TB/alexvatti/jadak/April_24/tensorflowlite/tensorflow/tensorflow/contrib/lite/tools/make/downloads/eigen -I/media/samsungQVO2TB/alexvatti/jadak/April_24/tensorflowlite/tensorflow/tensorflow/contrib/lite/tools/make/downloads/absl -I/media/samsungQVO2TB/alexvatti/jadak/April_24/tensorflowlite/tensorflow/tensorflow/contrib/lite/tools/make/downloads/gemmlowp -I/media/samsungQVO2TB/alexvatti/jadak/April_24/tensorflowlite/tensorflow/tensorflow/contrib/lite/tools/make/downloads/neon_2_sse -I/media/samsungQVO2TB/alexvatti/jadak/April_24/tensorflowlite/tensorflow/tensorflow/contrib/lite/tools/make/downloads/farmhash/src -I/media/samsungQVO2TB/alexvatti/jadak/April_24/tensorflowlite/tensorflow/tensorflow/contrib/lite/tools/make/downloads/flatbuffers/include -I -I/usr/local/include -c tensorflow/contrib/lite/c/c_api_internal.c -o /media/samsungQVO2TB/alexvatti/jadak/April_24/tensorflowlite/tensorflow/tensorflow/contrib/lite/tools/make/gen/rpi_armv7l/obj/tensorflow/contrib/lite/c/c_api_internal.o
In file included from ./tensorflow/contrib/lite/c/c_api_internal.h:34,
                 from tensorflow/contrib/lite/c/c_api_internal.c:16:
/opt/poky/3.0.2/sysroots/x86_64-pokysdk-linux/usr/lib/arm-poky-linux-gnueabi/gcc/arm-poky-linux-gnueabi/9.2.0/include/stdint.h:9:16: fatal error: stdint.h: No such file or directory
    9 | # include_next <stdint.h>
      |                ^~~~~~~~~~
compilation terminated.
tensorflow/contrib/lite/tools/make/Makefile:173: recipe for target '/media/samsungQVO2TB/alexvatti/jadak/April_24/tensorflowlite/tensorflow/tensorflow/contrib/lite/tools/make/gen/rpi_armv7l/obj/tensorflow/contrib/lite/c/c_api_internal.o' failed
make: *** [/media/samsungQVO2TB/alexvatti/jadak/April_24/tensorflowlite/tensorflow/tensorflow/contrib/lite/tools/make/gen/rpi_armv7l/obj/tensorflow/contrib/lite/c/c_api_internal.o] Error 1
make: *** Waiting for unfinished jobs....
In file included from tensorflow/contrib/lite/allocation.cc:16:
./tensorflow/contrib/lite/allocation.h:20:10: fatal error: cstdio: No such file or directory
   20 | #include <cstdio>
      |          ^~~~~~~~
In file included from tensorflow/contrib/lite/arena_planner.cc:15:
./tensorflow/contrib/lite/arena_planner.h:18:10: fatal error: memory: No such file or directory
   18 | #include <memory>
      |          ^~~~~~~~
compilation terminated.
compilation terminated.
tensorflow/contrib/lite/tools/make/Makefile:169: recipe for target '/media/samsungQVO2TB/alexvatti/jadak/April_24/tensorflowlite/tensorflow/tensorflow/contrib/lite/tools/make/gen/rpi_armv7l/obj/tensorflow/contrib/lite/arena_planner.o' failed
make: *** [/media/samsungQVO2TB/alexvatti/jadak/April_24/tensorflowlite/tensorflow/tensorflow/contrib/lite/tools/make/gen/rpi_armv7l/obj/tensorflow/contrib/lite/arena_planner.o] Error 1
tensorflow/contrib/lite/tools/make/Makefile:169: recipe for target '/media/samsungQVO2TB/alexvatti/jadak/April_24/tensorflowlite/tensorflow/tensorflow/contrib/lite/tools/make/gen/rpi_armv7l/obj/tensorflow/contrib/lite/allocation.o' failed
make: *** [/media/samsungQVO2TB/alexvatti/jadak/April_24/tensorflowlite/tensorflow/tensorflow/contrib/lite/tools/make/gen/rpi_armv7l/obj/tensorflow/contrib/lite/allocation.o] Error 1



**Provide the exact sequence of commands / steps that you executed before running into the problem**

**cat ./tensorflow/contrib/lite/tools/make/build_rpi_lib.sh**
#!/bin/bash -x
# Copyright 2017 The TensorFlow Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ==============================================================================

set -e

SCRIPT_DIR=""$(cd ""$(dirname ""${BASH_SOURCE[0]}"")"" && pwd)""
cd ""$SCRIPT_DIR/../../../../..""

CC_PREFIX=arm-poky-linux-gnueabi- make -j 3 -f tensorflow/contrib/lite/tools/make/Makefile TARGET=rpi TARGET_ARCH=armv7l

**alexvatti@SYR-DEEPLEARN2:~/AlexBuildLocation/jadak/April_24/tensorflowlite/tensorflow$ cat tensorflow/contrib/lite/tools/make/targets/rpi_makefile.inc**
# Settings for Raspberry Pi.
ifeq ($(TARGET),rpi)
  # Default to the architecture used on the Pi Two/Three (ArmV7), but override this
  # with TARGET_ARCH=armv6 to build for the Pi Zero or One.
  TARGET_ARCH := armv7l
  **TARGET_TOOLCHAIN_PREFIX := arm-poky-linux-gnueabi-**

  ifeq ($(TARGET_ARCH), armv7l)
    CXXFLAGS += \
      -march=armv7-a \
      -mfpu=neon \
      -funsafe-math-optimizations \
      -ftree-vectorize \
      -fPIC


**alexvatti@SYR-DEEPLEARN2:~/AlexBuildLocation/jadak/April_24/tensorflowlite/tensorflow$ ./tensorflow/contrib/lite/tools/make/build_rpi_lib.sh**


**Any other info / logs**


Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
38889,"why does tensorflow2 use multiple Gpu but only one is used, the other always can not use","<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below):
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**

**Describe the expected behavior**

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

When I run my code to train, I found only one gpu is used while the others can not fully used. Exactly, for example, when the first gpu almost out of memory,  the code can not use the memory of other gpus. I don't know if it is a bug?"
38887,Can we auto-convert a tensor into a numpy value when necessary in computing graph executing mode(&tf.function mode)?,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (2.1): 2.1
- Are you willing to contribute it (Yes/No): Yes

**Describe the feature and the current behavior/state.**
```
  def testTensorAndNumpy():
    npArray=np.random.uniform(0, 10000, size=200)
    #npArray=tf.random.uniform((200,), 0, 10000)
    @tf.function
    def myFunc(tensorValue):
      return(npArray[tensorValue])

    #tensorValue=3
    tensorValue=tf.convert_to_tensor(3)
    print(myFunc(tensorValue))
    print(npArray[tensorValue])

```
The above code works fine if we comment the @tf.function, but when we use @tf.function, it'll reporting the following errors:
```

....
    NotImplementedError: Cannot convert a symbolic Tensor (tensorValue:0) to a numpy array.
....
```
The root cause should be that the tensorflow's computing graph executing mode couldn't auto-convert the tensor to numpy value, but when in eager mode, this conversion could happen correctly and automatically. It seems not only my test case could trigger this bug, many other bugs report also relate to this root cause.

**Will this change the current api? How?**
No, it seems no need change the API spec, but we need change the implementation for tensorflow's tf.function.

**Who will benefit with this feature?**
Many engineers, it seems not only my test codes could trigger this error, many other tensorflow users also found similar issue. I searched ""NotImplementedError: Cannot convert a symbolic Tensor "", about 10 issues exists, I guess the root cause for most them should be same as this test failure's root cause. 
https://github.com/tensorflow/tensorflow/issues?q=NotImplementedError%3A+Cannot+convert+a+symbolic+Tensor

**Any Other info.**
We could change the npArray to a tensor, and then we could use tensor as the index for another tensor, this works fine(by disabling the first line and enable the second line). But because in my usage scenario, I need use numpy data array as the data source, and use tensor variable to access different part of this numpy data array. Because this combination could help me save lots of GPU memory, the GPU memory is much more expensive than CPU memory, and all tensors malloc need consume GPU memory. So I consider this issue as a new feature request instead of a bug report. 
After implmenting this feature, engineers could feel more nature when switching between tensorflow's eager mode and graph mode, and most of those old connected bugs should also be fixed automatically."
38886,ImportError: DLL load failed: The specified procedure could not be found.,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 Home Single Language
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No
- TensorFlow installed from (source or binary): 
- TensorFlow version: 2.0
- Python version: 3.6
- Installed using virtualenv? pip? conda?: pip
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory: None



**Describe the problem**

**Provide the exact sequence of commands / steps that you executed before running into the problem**
I am trying to build an application and this error seems to stay even after I downgraded my tensor flow version from 2.1 to 2.0.

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

C:\Users\Dell\AppData\Local\Programs\Python\Python36\python.exe C:/Users/Dell/PycharmProjects/MajorProject017/ChatBot.py
Traceback (most recent call last):
  File ""C:/Users/Dell/PycharmProjects/MajorProject017/ChatBot.py"", line 2, in <module>
    import tensorflow
  File ""C:\Users\Dell\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\__init__.py"", line 98, in <module>
    from tensorflow_core import *
  File ""C:\Users\Dell\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow_core\__init__.py"", line 40, in <module>
    from tensorflow.python.tools import module_util as _module_util
  File ""C:\Users\Dell\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\__init__.py"", line 50, in __getattr__
    module = self._load()
  File ""C:\Users\Dell\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\__init__.py"", line 44, in _load
    module = _importlib.import_module(self.__name__)
  File ""C:\Users\Dell\AppData\Local\Programs\Python\Python36\lib\importlib\__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""C:\Users\Dell\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow_core\python\__init__.py"", line 52, in <module>
    from tensorflow.core.framework.graph_pb2 import *
  File ""C:\Users\Dell\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow_core\core\framework\graph_pb2.py"", line 7, in <module>
    from google.protobuf import descriptor as _descriptor
  File ""C:\Users\Dell\AppData\Local\Programs\Python\Python36\lib\site-packages\google\protobuf\descriptor.py"", line 47, in <module>
    from google.protobuf.pyext import _message
ImportError: DLL load failed: The specified procedure could not be found.

Process finished with exit code 1

"
38885,tf.compat.v1.resource_loader.get_path_to_datafile,"I had implemented this code:

import tensorflow as tf

_flow_warp_ops = tf.load_op_library(
    tf.compat.v1.resource_loader.get_path_to_datafile(""./lib/flow_warp.so""))

But it is showing error:

Traceback (most recent call last):

  File ""<ipython-input-12-d0892143bf54>"", line 2, in <module>
    tf.compat.v1.resource_loader.get_path_to_datafile(""./lib/flow_warp.so""))

  File ""/home/akshat_suwalka/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/load_library.py"", line 57, in load_op_library
    lib_handle = py_tf.TF_LoadLibrary(library_filename)

NotFoundError: libcudart.so.8.0: cannot open shared object file: No such file or directory


As you can see that file already i have in ""lib/flow_warp.so""
![Screenshot from 2020-04-25 14-05-38](https://user-images.githubusercontent.com/35618437/80275290-e9779e80-86fd-11ea-94d4-00dfd3bd30a1.png)



"
38884,How use model(saved by tf1.14.0) in the tf1.5.0?,"Hi,  tensorflow team:
    I have a model saved by tensorflow-1.14.0. In my case, I must use this model in a tensorflow-1.5.0 environment. Is there any ways to convert the high-tensorflow-version model (pb file or ckpt) to a low-tensorflow-version model? 
                 Looking  forward to your repply
"
38883,PR #34911 not being included in releases,"**System information**
- Have I written custom code (as opposed to using example directory):  Nope
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Windows 10 x64
- TensorFlow backend (yes / no):  Yes
- TensorFlow version:  2.1.0
- Keras version:  2.2.4-tf (using tf.keras)
- Python version:  3.7.5
- CUDA/cuDNN version:  11
- GPU model and memory:  1070 with 8GB

**Describe the current behavior**
In `site-packages/tensorflow_core/python/keras/utils/generic_utils.py`, the PR I made [here](https://github.com/tensorflow/tensorflow/pull/34911) on December 6, 2019 isn't being applied to PyPi releases of TensorFLow, specifically TF 2.1.0 in my case. The code in that file when cleanly installing TensorFlow is as follows:
```python
self._dynamic_display = ((hasattr(sys.stdout, 'isatty') and
                          sys.stdout.isatty()) or
                         'ipykernel' in sys.modules or
                         'posix' in sys.modules)
```

**Describe the expected behavior**
When it should be:
```python
self._dynamic_display = ((hasattr(sys.stdout, 'isatty') and
                          sys.stdout.isatty()) or
                         'ipykernel' in sys.modules or
                         'posix' in sys.modules or
                         'PYCHARM_HOSTED' in os.environ)
```
as changed in the PR. Is there some other place I need to create a PR for this change to take effect in the releases?

**Code to reproduce the issue**  
Install TensorFlow 2.1.0 on Windows 10, Python 3.7.5
"
38882,Tensorflow.Contrib Not Found,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- TensorFlow installed from (source or binary): Pip installed
- TensorFlow version:2.2.0
- Python version:3.8.2 64 Bit
- Installed using virtualenv? pip? conda?: Pip
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:No graphic Card
- GPU model and memory: ---



I am using Tflearn library which uses Tensorflow.contrib as a module. But It is showing error that it has no library as such
The stack code is here
2020-04-25 09:45:43.517997: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'cudart64_101.dll'; dlerror: cudart64_101.dll not found
2020-04-25 09:45:43.525381: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on
your machine.
Traceback (most recent call last):
  File ""f:/MACHINE LEARNING/chatbot/main.py"", line 10, in <module>
    import tflearn
  File ""C:\Users\HP\AppData\Local\Programs\Python\Python38\lib\site-packages\tflearn\__init__.py"", line 4, in <module>
    from . import config
  File ""C:\Users\HP\AppData\Local\Programs\Python\Python38\lib\site-packages\tflearn\config.py"", line 5, in <module>
    from .variables import variable
  File ""C:\Users\HP\AppData\Local\Programs\Python\Python38\lib\site-packages\tflearn\variables.py"", line 7, in <module>
    from tensorflow.contrib.framework.python.ops import add_arg_scope as contrib_add_arg_scope
ModuleNotFoundError: No module named 'tensorflow.contrib'


I just imported Tflearn and Tensorflow and no code was written.
"
38879,"If tf.data.Dataset.list_files shuffles files, a subsequent take is ignored","<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **Linux Ubuntu 18.04**
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): **binary (pip install tensorflow)**
- TensorFlow version (use command below): **2.1.0**
- Python version: **2.7**
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: **CUDA 10.1, cuDNN 7.6.5** (the bug happens even `with tf.device('/cpu')`
- GPU model and memory: **Quadro M1200, 4096MB**

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
There are 100 TFRecord examples stored on disk, sharded over multiple files.  I first do `tf.data.Dataset.list_files`, then an `interleave`d map, mapping the dataset to a `TFRecordDataset`.  Then I do a `map`, with a mapper that parses each serialized example.  Then a `take` to keep 17 elements, then and a `repeat` (forever).

I iterate over the (infinite) dataset for 400 iterations, keeping track of the number of **unique** elements seen.  If I set `shuffle=False` in the call to `list_files`, I see only 17 unique elements.  If I set `shuffle=True`, I see all 100 unique elements, which is wrong. 

**Describe the expected behavior**
I expect to only see 17 unique elements, regardless of whether or not I pass `shuffle=True` or `shuffle=False`.

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.
Please download the attached file (called `reproduce_bug.txt` because GitHub doesn't like it if I attach .py files).  Rename it to `reproduce_bug.py` and run with `python reproduce_bug.py`.  The file has many comments that further illustrate the bug.
[reproduce_bug.txt](https://github.com/tensorflow/tensorflow/files/4531280/reproduce_bug.txt)


**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
38878,BatchNormalization layer has different output when loading a checkpoint saved from TF 2.0b1,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Official Tensorflow Docker Container (2.0.0, 2.0.0-beta1, latest) with py3 and gpu support
- TensorFlow installed from (source or binary): Docker
- TensorFlow version (use command below): 2.0
- Python version: 3
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10.0 / 10.2
- GPU model and memory: Tested on RTX 2080Ti, Titan V, GTX 1080


**Describe the current behavior**
In my project I trained several (adversarial) segmentation models using both Tensorflow 2.0.0-a0 and 2.0.0-b1. 
Upon upgrading Tensorflow to version 2.1 I noticed a decrease in the accuracy of my models between 5~15% (Dice Score) with respect to the version 2.0.0-b1. 
I ran several tests loading the same checkpoints in multiple tensorflow versions by comparing the layer outputs and I noticed that starting from the first BatchNormalization layer the outputs of networks loaded with TF 2.0.0 (stable) are different from those loaded using TF <= 2.0.0-b1(even though the loaded weights are the same). BatchNormalization behavior is consistent starting from 2.0 stable onward. 

**Describe the expected behavior**
The output of BatchNormalization layer (and thus of the network) should be the same when using TF 2.0.0b1 and 2.0.0, when the checkpoint has been trained and saved using beta1.

**Standalone code to reproduce the issue**
I tried reproducing the issue using the examples or pretrained networks, but the differences are not noticeable as they are in my models. I wrote a notebook that can be run on both 2.0.0b1 and 2.1 to highlight the differences. 
https://drive.google.com/open?id=1vw3vaPU32lqI2jAOvp0toXIgD84R_Tx4
Besides the notebook there are also the input data I used for testing and the output of the last layer for both TF2.0-b1 and TF2.1 (other versions are not inclued as they seem to match with either b1 or 2.1). I'm not including individual layers outputs due to size constraints.
In the pics fodler can find also some visual examples of the network outputs.


**Other info / logs** 
I'm attaching just an example of just one mismatching output for the same input. In the drive folder you can find the test for an entire batch.
![hist-61-2 0 0-beta1](https://user-images.githubusercontent.com/9888197/80245680-69085d80-866b-11ea-8e26-ee7fd8797f0f.jpg)
![hist-61-2 1 0](https://user-images.githubusercontent.com/9888197/80245684-69a0f400-866b-11ea-982e-1722c6733861.jpg)

I couldn't understand what this could be related to, I'd like to have some insights of what could be the cause.
Thank you!"
38877,K.in_train_phase() broken in eager mode when used outside of Lambda layer,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Google Colab
- TensorFlow version (use command below): 2.2.0-rc3 (v2.2.0-rc3-0-gaad398b5e9)
- Python version: 3.0

**Describe the current behavior**
K.in_train_phase(). It always returns the alternative option (both during model.fit() and model.predict() in keras).  But it does work when you disable eager mode or when you wrap it in a Lambda layer. This is unexpected because in TF1 and when eager is disabled the function works as expected.

**Describe the expected behavior**
I would expect K.in_train_phase() to work as described in the documentation.

**Standalone code to reproduce the issue**
https://colab.research.google.com/drive/1yaw-UhOgj7UyLC4NEtQPYiZRYvnxhz_G
"
38876,Creating multiple stacked variable within tf.map_fn  ,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): 1.10
- Are you willing to contribute it (Yes/No): No



**Describe the feature and the current behavior/state.**
Currently, I am trying to create multiple variables within tf.map_fn but it just creates a single variable copied multiple times.

**Will this change the current api? How?**
Maybe

**Who will benefit with this feature?**
Projects related to multi-object tracking

**Any Other info.**
"
38875,Passing tf.keras.Model as tf.function argument does not create concrete function,"**System information**
- Have I written custom code: Yes
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.1.0
- Python version: 3.7.5

**Describe the current behavior**

Passing a `tf.keras.Model` or `tf.keras.Optimizer` as argument into `tf.function` does not create a concrete function. I expect that it would, since function tracing works as it should if the model/optimizer is a global variable.

**Standalone code to reproduce the issue**
```python
import tensorflow as tf

class MyModel(tf.keras.Model):
    def __init__(self):
        super().__init__()

    def call(self, inputs):
        return 2 * inputs

@tf.function
def step_model(model, inputs):
    return model(inputs)

@tf.function
def step(inputs):
    return model(inputs)

inputs = tf.convert_to_tensor(1, dtype=tf.float32)
model = MyModel()
# This works as expected
print(f""step() = {step(inputs)}"") # 2.0
print(f""step() concrete functions: {step._list_all_concrete_functions_for_serialization()}"") # [<tensorflow.python.eager.function.ConcreteFunction object at 0x13a2c0510>]
# This does not, no concrete function is saved
print(f""step_model() = {step_model(model, inputs)}"") # 2.0
print(f""step_model() concrete functions: {step_model._list_all_concrete_functions_for_serialization()}"") # []
```

Output:
```bash
step() = 2.0
step() concrete functions: [<tensorflow.python.eager.function.ConcreteFunction object at 0x133788410>]
step_model() = 2.0
step_model() concrete functions: []
```



It appears that passing a `tf.keras.Model` as an argument into `tf.function` is not supported, as tracing fails. In a different use case, this error appears:
```bash
INFO:tensorflow:Unsupported signature for serialization: ((<tensorflow.python.framework.func_graph.UnknownArgument object at 0x13a2c0510>))
```

My use case requires limiting usage of global variables, since there are several models running simultaneously and they need to be garbage collected efficiently. How can I pass a model as a function argument into a `tf.function`?
"
38874,Migrate mobilenet_v3 from keras-team/keras-applications to tensorflow/tensorflow/python/keras/applications/,"Just like mobilenet_v2.py and all the others migrated to https://github.com/tensorflow/tensorflow/tree/master/tensorflow/python/keras/applications on Apr 3rd, https://github.com/keras-team/keras-applications/blob/master/keras_applications/mobilenet_v3.py is ready to be migrated since Apr 2nd


**Are you willing to contribute it (Yes/No):** No

**Will this change the current api? How?** No

**Who will benefit with this feature?** All users"
38872,[TF2.2] Mixed Ragged and tensors inputs breaks function tensors spec names,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): linux
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): tf2.2 rc3
- TensorFlow version (use command below):2.2 rc3 collab
- Python version: google collab
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

**Describe the current behavior**
I'm trying to save a model with two inputs:
- one ragged
- one tensor

both are embedded into a 3 dim vector and then summed up together. If we save that model it breaks because the tensors names are not well defined. 

```
inp_tensor = Input(shape=[], ragged=False, dtype=tf.int32)
inp_ragged = Input(shape=[None, ], ragged=True, dtype=tf.int32, name='test')

out = Embedding(10, 3)(inp_tensor)
out2 = Embedding(10, 3)(inp_ragged)
out2 = Lambda(tf.reduce_sum, arguments=dict(axis=1))(out2)
summed = Add()([out, out2])
m = Model([inp_tensor, inp_ragged], summed)
m.save('/tmp/test')
```
> ValueError: If specifying TensorSpec names for nested structures, either zero or all names have to be specified.

If we debug we find out that the non ragged tensor has a name while the two others have name=None. I tried to name the ragged_input to fix that but the issue stays the same. 
```
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py(1196)_get_defun_inputs()
   1194     specified_names = [arg.name for arg in tensor_specs if arg.name]
   1195     if specified_names and len(specified_names) < len(tensor_specs):
-> 1196       raise ValueError(""If specifying TensorSpec names for nested structures, ""
   1197                        ""either zero or all names have to be specified."")
   1198 

ipdb> specified_names
['inputs/0']
ipdb> tensor_specs
[TensorSpec(shape=(None,), dtype=tf.int32, name='inputs/0'), TensorSpec(shape=(None,), dtype=tf.int32, name=None), TensorSpec(shape=(None,), dtype=tf.int64, name=None)]
```
**Describe the expected behavior**
We should be able to save that model, the same model with two ragged inputs can be saved !

**Standalone code to reproduce the issue**
https://colab.research.google.com/gist/tanguycdls/200096266d1cb0c5a6c83cbb416c1279/untitled4.ipynb
"
38871,Quantize Model for Deploying on the Cloud using TF Serving,"**System information**
- TensorFlow version (you are using): 2.2.0rc3
- Are you willing to contribute it (Yes/No): No

**Describe the feature and the current behavior/state.**
Actually, Tensorflow Lite is assumed as the default for model optimization, but it is focused on Edge Devices, what are the alternatives to Cloud Deployments with Tensorflow Serving? The docs do not seem to have some guidance about this topic. How to Quantize a model that will be deployed on the Cloud using TensorFlow Serving?

This StackOverflow post from 1 month ago with no responses have the same problem: https://stackoverflow.com/questions/60491542/tensorflow-model-quantization-best-strategy (I'm not the poster of that question)

PD: This type of question never receives responses in StackOverflow, so, there's no more option than asks for support here, Thanks in advance!
"
38870,Gradients for tf.py_function with mixed arguments,"**System information**
- Have I written custom code: yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Mint 19.3
- TensorFlow installed from (source or binary): conda binary
- TensorFlow version (use command below): 2.1
- Python version: 3.7

**Describe the current behavior**
gradient calculation throws an error if a py_function is used that has both integer and floating point inputs/outputs.

**Describe the expected behavior**
Gradients with respect to all integers should be zero/None, and others should be correctly calculated.

**Standalone code to reproduce the issue**
```
import tensorflow as tf

def pf(x, y):
    return x ** 2, y ** 2

def pyf(x, y):
    return tf.py_function(pf, [x, y], [tf.int32, tf.float32])

x = tf.constant(5)
v = tf.Variable(0.5)
with tf.GradientTape() as tape:
    y, m = pyf(x, v)
    z = tf.cast(y, tf.float32) * m

print(tape.gradient(z, v))
```
When calling `pf`, gradient computation works, but for `pyf` we get first a warning and then an error. 


The problematic code seems to be in `script_ops.py`:
```
@ops.RegisterGradient(""EagerPyFunc"")
def _EagerPyFuncGrad(op, *dy):
  """"""Computes the gradient of an EagerPyFunc.""""""

  token = op.get_attr(""token"")

  def eagerly_executed_grad(*dy):
    tape, eager_inputs, eager_outputs = tape_cache.pop(compat.as_bytes(token))
    return tape.gradient(eager_outputs, eager_inputs, output_gradients=dy)

  with ops.control_dependencies(op.outputs):
    return _internal_py_func(
        func=eagerly_executed_grad,
        inp=dy,
        Tout=[tensor.dtype for tensor in op.inputs],
        eager=True,
        is_grad_func=True)
```"
38868,Distribution algorithm has limited performance on CPU,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): (Red Hat 4.8.5-16)
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA
- TensorFlow installed from (source or binary): source build
- TensorFlow version (use command below): 2.1 
- Python version: 3.7.6
- Bazel version (if compiling from source): 2.0.0
- GCC/Compiler version (if compiling from source): 7.4.0 
- CUDA/cuDNN version: NA
- GPU model and memory: NA

**Describe the current behavior**
Random generator uses specific philox_4x32_10 algorithm. It will generate 4 elements per [call](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/lib/random/random_distributions.h#L114) in Distribution and do additional computation for these 4 elements. Is there any special consideration for this design? As you know, 4 elements are not very friendly for CPU AVX feature, especial for those low precision type(Half, Bfloat16) w/o native instructs support, because **conversion** overhead will become obvious if we can't fulfill vectorization register, that will make bad overall performance for the [result](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/lib/random/random_distributions.h#L764).

**Describe the expected behavior**
Is it possible to handle the **conversion** and **computation** out of the Distribution? I mean handle them in the place where is needed. For example, `RandomUniform` op calls Distribution [here ](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/random_op_cpu.h#L95) many times and we may handle data out of the Distribution and loop. The fake code is somehow like this
```C
// https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/lib/random/random_distributions.h
// Helper function to convert an 16-bit integer to a half between [1..2).
PHILOX_DEVICE_INLINE Eigen::half NewUint16ToHalf(uint16 x) {
  // IEEE754 halfs are formatted as follows (MSB first):
  //    sign(1) exponent(5) mantissa(10)
  // Conceptually construct the following:
  //    sign == 0
  //    exponent == 15  -- an excess 15 representation of a zero exponent
  //    mantissa == 10 random bits
  const uint16 man = x & 0x3ffu;  // 10 bit mantissa
  const uint16 exp = static_cast<uint16>(15);
  const uint16 val = (exp << 10) | man;

  Eigen::half result;
  result.x = val;
  /***********************************************
      do not do the conversion and minus here.
      return result - Eigen::half(1.0);
  ************************************************/
  return result;
}

...
    // https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/random_op_cpu.h#L95
    gen.Skip(start_group);
    int64 offset = start_group * kGroupSize;

    // First fill all the full-size groups
    int64 limit_group_full = std::min(limit_group, size / kGroupSize);
    for (int64 index = start_group; index < limit_group_full; ++index) {
      /********************************************************
        Use new Distribution without conversion and minus
        auto samples = dist(&gen);
      *********************************************************/
      auto samples = new_dist(&gen);
      std::copy(&samples[0], &samples[0] + kGroupSize, data + offset);
      offset += kGroupSize;
    }
    /****************************************************************************
      Do the vector conversion and minus out of loop to get CPU AVX feature
    *****************************************************************************/
    new_dist.vectorize(start, length);
```

Is this kind optimization reasonable?

**Standalone code to reproduce the issue**
I made some simple test, low precision Distribution are usually slower 10~30%  with current implementation.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
38867,issue converting a model defined and compiled with Keras into tflite,"**System information**
- OS Platform and Distribution Windows 10 (10.0.18363 N/A Build 18363)
- TensorFlow installed from: binary (conda)
- TensorFlow version: 2.1.0


**Provide the text output from tflite_convert**

```
2020-04-24 14:07:48.857192: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll
2020-04-24 14:07:53.751094: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library nvcuda.dll
2020-04-24 14:07:53.926489: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties:
pciBusID: 0000:17:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.607GHz coreCount: 28 deviceMemorySize: 11.00GiB deviceMemoryBandwidth: 451.17GiB/s
2020-04-24 14:07:53.942398: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 1 with properties:
pciBusID: 0000:65:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.607GHz coreCount: 28 deviceMemorySize: 11.00GiB deviceMemoryBandwidth: 451.17GiB/s
2020-04-24 14:07:53.954174: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll
2020-04-24 14:07:53.963600: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll
2020-04-24 14:07:53.970994: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_10.dll
2020-04-24 14:07:53.975195: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_10.dll
2020-04-24 14:07:53.981892: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_10.dll
2020-04-24 14:07:53.987511: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_10.dll
2020-04-24 14:07:53.997545: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll
2020-04-24 14:07:54.002301: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0, 1
2020-04-24 14:07:54.005077: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2
2020-04-24 14:07:54.268811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties:
pciBusID: 0000:17:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.607GHz coreCount: 28 deviceMemorySize: 11.00GiB deviceMemoryBandwidth: 451.17GiB/s
2020-04-24 14:07:54.283187: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 1 with properties:
pciBusID: 0000:65:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.607GHz coreCount: 28 deviceMemorySize: 11.00GiB deviceMemoryBandwidth: 451.17GiB/s
2020-04-24 14:07:54.295258: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll
2020-04-24 14:07:54.300726: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll
2020-04-24 14:07:54.304884: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_10.dll
2020-04-24 14:07:54.308414: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_10.dll
2020-04-24 14:07:54.312322: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_10.dll
2020-04-24 14:07:54.315485: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_10.dll
2020-04-24 14:07:54.318772: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll
2020-04-24 14:07:54.322343: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0, 1
2020-04-24 14:07:55.346759: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-04-24 14:07:55.353942: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 1
2020-04-24 14:07:55.360645: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N N
2020-04-24 14:07:55.365830: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 1:   N N
2020-04-24 14:07:55.371746: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 8779 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:17:00.0, compute capability: 6.1)
2020-04-24 14:07:55.387124: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 8778 MB memory) -> physical GPU (device: 1, name: GeForce GTX 1080 Ti, pci bus id: 0000:65:00.0, compute capability: 6.1)
2020-04-24 14:08:10.543940: I tensorflow/core/grappler/devices.cc:55] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 2
2020-04-24 14:08:10.551744: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session
2020-04-24 14:08:10.558479: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties:
pciBusID: 0000:17:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.607GHz coreCount: 28 deviceMemorySize: 11.00GiB deviceMemoryBandwidth: 451.17GiB/s
2020-04-24 14:08:10.572134: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 1 with properties:
pciBusID: 0000:65:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.607GHz coreCount: 28 deviceMemorySize: 11.00GiB deviceMemoryBandwidth: 451.17GiB/s
2020-04-24 14:08:10.582103: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll
2020-04-24 14:08:10.585591: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll
2020-04-24 14:08:10.589055: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_10.dll
2020-04-24 14:08:10.592316: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_10.dll
2020-04-24 14:08:10.599428: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_10.dll
2020-04-24 14:08:10.602331: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_10.dll
2020-04-24 14:08:10.605021: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll
2020-04-24 14:08:10.608479: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0, 1
2020-04-24 14:08:10.611352: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-04-24 14:08:10.614149: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 1
2020-04-24 14:08:10.615877: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N N
2020-04-24 14:08:10.617604: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 1:   N N
2020-04-24 14:08:10.619906: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 8779 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:17:00.0, compute capability: 6.1)
2020-04-24 14:08:10.626586: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 8778 MB memory) -> physical GPU (device: 1, name: GeForce GTX 1080 Ti, pci bus id: 0000:65:00.0, compute capability: 6.1)
2020-04-24 14:08:10.712742: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: graph_to_optimize
2020-04-24 14:08:10.719884: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: Graph size after: 425 nodes (377), 829 edges (780), time = 12.367ms.
2020-04-24 14:08:10.729092: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: Graph size after: 425 nodes (0), 829 edges (0), time = 4.555ms.
2020-04-24 14:08:10.739369: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: __inference_while_cond_449002_1018
2020-04-24 14:08:10.746241: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-04-24 14:08:10.753806: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-04-24 14:08:10.758528: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: __inference_while_body_449003_9686
2020-04-24 14:08:10.763111: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-04-24 14:08:10.769022: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-04-24 14:08:10.772939: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: __inference_while_body_448562_6255
2020-04-24 14:08:10.777007: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-04-24 14:08:10.782953: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-04-24 14:08:10.786952: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: __inference_while_cond_448561_10216
2020-04-24 14:08:10.791234: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-04-24 14:08:10.795335: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-04-24 14:08:19.431007: I tensorflow/core/grappler/devices.cc:55] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 2
2020-04-24 14:08:19.439743: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session
2020-04-24 14:08:19.447312: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties:
pciBusID: 0000:17:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.607GHz coreCount: 28 deviceMemorySize: 11.00GiB deviceMemoryBandwidth: 451.17GiB/s
2020-04-24 14:08:19.464579: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 1 with properties:
pciBusID: 0000:65:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.607GHz coreCount: 28 deviceMemorySize: 11.00GiB deviceMemoryBandwidth: 451.17GiB/s
2020-04-24 14:08:19.479745: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll
2020-04-24 14:08:19.486868: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll
2020-04-24 14:08:19.491302: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_10.dll
2020-04-24 14:08:19.495128: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_10.dll
2020-04-24 14:08:19.501121: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_10.dll
2020-04-24 14:08:19.505040: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_10.dll
2020-04-24 14:08:19.508921: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll
2020-04-24 14:08:19.513748: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0, 1
2020-04-24 14:08:19.519839: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-04-24 14:08:19.524028: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 1
2020-04-24 14:08:19.528399: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N N
2020-04-24 14:08:19.533433: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 1:   N N
2020-04-24 14:08:19.537068: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 8779 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:17:00.0, compute capability: 6.1)
2020-04-24 14:08:19.543946: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 8778 MB memory) -> physical GPU (device: 1, name: GeForce GTX 1080 Ti, pci bus id: 0000:65:00.0, compute capability: 6.1)
2020-04-24 14:08:31.567997: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: graph_to_optimize
2020-04-24 14:08:31.575109: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   constant_folding: Graph size after: 294 nodes (-45), 587 edges (-84), time = 7337.03613ms.
2020-04-24 14:08:31.586441: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   constant_folding: Graph size after: 294 nodes (0), 587 edges (0), time = 2786.70288ms.
2020-04-24 14:08:31.597388: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: __inference_while_cond_449002_1018_frozen
2020-04-24 14:08:31.605102: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   constant_folding: Graph size after: 14 nodes (0), 4 edges (0), time = 1.129ms.
2020-04-24 14:08:31.615276: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   constant_folding: Graph size after: 14 nodes (0), 4 edges (0), time = 0.159ms.
2020-04-24 14:08:31.620189: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: __inference_while_body_448562_6255_frozen
2020-04-24 14:08:31.628466: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   constant_folding: Graph size after: 53 nodes (-1), 71 edges (0), time = 1.975ms.
2020-04-24 14:08:31.632827: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   constant_folding: Graph size after: 53 nodes (0), 71 edges (0), time = 0.657ms.
2020-04-24 14:08:31.637156: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: __inference_while_cond_448561_10216_frozen
2020-04-24 14:08:31.643592: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   constant_folding: Graph size after: 14 nodes (0), 4 edges (0), time = 0.932ms.
2020-04-24 14:08:31.647864: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   constant_folding: Graph size after: 14 nodes (0), 4 edges (0), time = 0.154ms.
2020-04-24 14:08:31.652114: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: __inference_while_body_449003_9686_frozen
2020-04-24 14:08:31.657508: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   constant_folding: Graph size after: 53 nodes (-1), 71 edges (0), time = 1.836ms.
2020-04-24 14:08:31.661923: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   constant_folding: Graph size after: 53 nodes (0), 71 edges (0), time = 0.594ms.
Traceback (most recent call last):
  File ""tflite_converter.py"", line 9, in <module>
    liteModel = converter.convert()
  File ""C:\Users\Eric\anaconda3\envs\gpu\lib\site-packages\tensorflow_core\lite\python\lite.py"", line 464, in convert
    **converter_kwargs)
  File ""C:\Users\Eric\anaconda3\envs\gpu\lib\site-packages\tensorflow_core\lite\python\convert.py"", line 457, in toco_convert_impl
    enable_mlir_converter=enable_mlir_converter)
  File ""C:\Users\Eric\anaconda3\envs\gpu\lib\site-packages\tensorflow_core\lite\python\convert.py"", line 203, in toco_convert_protos
    raise ConverterError(""See console for info.\n%s\n%s\n"" % (stdout, stderr))
tensorflow.lite.python.convert.ConverterError: See console for info.
2020-04-24 14:12:51.450709: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll
2020-04-24 14:12:56.829530: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2
2020-04-24 14:12:56.838592: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library nvcuda.dll
2020-04-24 14:12:57.156479: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties:
pciBusID: 0000:17:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.607GHz coreCount: 28 deviceMemorySize: 11.00GiB deviceMemoryBandwidth: 451.17GiB/s
2020-04-24 14:12:57.157270: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 1 with properties:
pciBusID: 0000:65:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.607GHz coreCount: 28 deviceMemorySize: 11.00GiB deviceMemoryBandwidth: 451.17GiB/s
2020-04-24 14:12:57.157878: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll
2020-04-24 14:12:57.161964: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll
2020-04-24 14:12:57.165048: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_10.dll
2020-04-24 14:12:57.166358: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_10.dll
2020-04-24 14:12:57.169654: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_10.dll
2020-04-24 14:12:57.171887: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_10.dll
2020-04-24 14:12:57.177220: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll
2020-04-24 14:12:57.178160: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0, 1
2020-04-24 14:12:58.109700: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-04-24 14:12:58.110013: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 1
2020-04-24 14:12:58.110180: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N N
2020-04-24 14:12:58.110389: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 1:   N N
2020-04-24 14:12:58.111497: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 8779 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:17:00.0, compute capability: 6.1)
2020-04-24 14:12:58.113651: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 8778 MB memory) -> physical GPU (device: 1, name: GeForce GTX 1080 Ti, pci bus id: 0000:65:00.0, compute capability: 6.1)
2020-04-24 14:12:59.553038: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorListFromTensor
2020-04-24 14:12:59.553307: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 21
2020-04-24 14:12:59.553612: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorListFromTensor
2020-04-24 14:12:59.553856: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 21
2020-04-24 14:12:59.554132: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorListReserve
2020-04-24 14:12:59.554405: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 21
2020-04-24 14:12:59.554652: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorListReserve
2020-04-24 14:12:59.554902: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 21
2020-04-24 14:12:59.555149: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: While
2020-04-24 14:12:59.555403: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 21
2020-04-24 14:12:59.555651: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 21
2020-04-24 14:12:59.555922: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: While
2020-04-24 14:12:59.556169: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 21
2020-04-24 14:12:59.556419: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 21
2020-04-24 14:12:59.556686: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorListStack
2020-04-24 14:12:59.556952: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorListStack
2020-04-24 14:12:59.702664: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 119 operators, 258 arrays (0 quantized)
2020-04-24 14:12:59.704661: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 119 operators, 258 arrays (0 quantized)
2020-04-24 14:13:01.157666: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 61 operators, 174 arrays (0 quantized)
2020-04-24 14:13:01.159147: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 2: 56 operators, 168 arrays (0 quantized)
2020-04-24 14:13:01.160554: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 3: 53 operators, 162 arrays (0 quantized)
2020-04-24 14:13:01.161927: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Group bidirectional sequence lstm/rnn: 53 operators, 162 arrays (0 quantized)
2020-04-24 14:13:01.162962: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before dequantization graph transformations: 53 operators, 162 arrays (0 quantized)
2020-04-24 14:13:01.164011: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Identify nearest upsample.: 53 operators, 162 arrays (0 quantized)
2020-04-24 14:13:01.165730: I tensorflow/lite/toco/allocate_transient_arrays.cc:345] Total transient array allocated size: 52352 bytes, theoretical optimal value: 49280 bytes.
2020-04-24 14:13:01.166257: I tensorflow/lite/toco/toco_tooling.cc:471] Number of parameters: 133230663
2020-04-24 14:13:01.167066: E tensorflow/lite/toco/toco_tooling.cc:498] We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md
 and pasting the following:

Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: CONCATENATION, DEPTHWISE_CONV_2D, FULLY_CONNECTED, PACK, RESHAPE, REVERSE_V2, SHAPE, STRIDED_SLICE, TRANSPOSE. Here is a list of operators for which you will need custom implementations: TensorListFromTensor, TensorListReserve, TensorListStack, While.
Traceback (most recent call last):
  File ""C:\Users\Eric\anaconda3\envs\gpu\Scripts\toco_from_protos-script.py"", line 10, in <module>
    sys.exit(main())
  File ""C:\Users\Eric\anaconda3\envs\gpu\lib\site-packages\tensorflow_core\lite\toco\python\toco_from_protos.py"", line 93, in main
    app.run(main=execute, argv=[sys.argv[0]] + unparsed)
  File ""C:\Users\Eric\anaconda3\envs\gpu\lib\site-packages\tensorflow_core\python\platform\app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""C:\Users\Eric\anaconda3\envs\gpu\lib\site-packages\absl\app.py"", line 299, in run
    _run_main(main, args)
  File ""C:\Users\Eric\anaconda3\envs\gpu\lib\site-packages\absl\app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""C:\Users\Eric\anaconda3\envs\gpu\lib\site-packages\tensorflow_core\lite\toco\python\toco_from_protos.py"", line 56, in execute
    enable_mlir_converter)
Exception: We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md
 and pasting the following:

Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: CONCATENATION, DEPTHWISE_CONV_2D, FULLY_CONNECTED, PACK, RESHAPE, REVERSE_V2, SHAPE, STRIDED_SLICE, TRANSPOSE. Here is a list of operators for which you will need custom implementations: TensorListFromTensor, TensorListReserve, TensorListStack, While.

```

**Standalone code to reproduce the issue** 
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

```python
import tensorflow as tf 
import numpy as np

INPATH = ""Path_to_saved_model""
OUTPATH = ""Path_to_lite_model""

converter = tf.lite.TFLiteConverter.from_saved_model(INPATH)
liteModel = converter.convert()

print(""saving converted model: "", OUTPATH)
open(OUTPATH, ""wb"").write(liteModel)
print(""Completed"")

# Load TFLite model and allocate tensors.
interpreter = tf.lite.Interpreter(model_content=liteModel)
interpreter.allocate_tensors()

# Get input and output tensors.
input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()

# Test the TensorFlow Lite model on random input data.
input_shape = input_details[0]['shape']
input_data = np.array(np.random.random_sample(input_shape), dtype=np.float16)
interpreter.set_tensor(input_details[0]['index'], input_data)
```

Also, please include a link to a GraphDef or the model if possible.
I am not exactly sure what that is, I hope thi is the output of the keras summary
```
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
inputs (InputLayer)             [(None, 250, 1)]     0                                            
__________________________________________________________________________________________________
bidirectional (Bidirectional)   (None, 250, 100)     20800       inputs[0][0]                     
__________________________________________________________________________________________________
conv1d (Conv1D)                 (None, 246, 25)      150         inputs[0][0]                     
__________________________________________________________________________________________________
flatten (Flatten)               (None, 25000)        0           bidirectional[0][0]              
__________________________________________________________________________________________________
flatten_1 (Flatten)             (None, 6150)         0           conv1d[0][0]                     
__________________________________________________________________________________________________
concatenate (Concatenate)       (None, 31150)        0           flatten[0][0]                    
                                                                 flatten_1[0][0]                  
__________________________________________________________________________________________________
dense (Dense)                   (None, 2048)         63797248    concatenate[0][0]                
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1024)         2098176     dense[0][0]                      
__________________________________________________________________________________________________
dense_2 (Dense)                 (None, 512)          524800      dense_1[0][0]                    
__________________________________________________________________________________________________
dense_7 (Dense)                 (None, 2048)         63797248    concatenate[0][0]                
__________________________________________________________________________________________________
dense_3 (Dense)                 (None, 256)          131328      dense_2[0][0]                    
__________________________________________________________________________________________________
dense_8 (Dense)                 (None, 1024)         2098176     dense_7[0][0]                    
__________________________________________________________________________________________________
dense_4 (Dense)                 (None, 128)          32896       dense_3[0][0]                    
__________________________________________________________________________________________________
dense_9 (Dense)                 (None, 512)          524800      dense_8[0][0]                    
__________________________________________________________________________________________________
dense_5 (Dense)                 (None, 50)           6450        dense_4[0][0]                    
__________________________________________________________________________________________________
dense_10 (Dense)                (None, 256)          131328      dense_9[0][0]                    
__________________________________________________________________________________________________
reshape (Reshape)               (None, 50, 1)        0           dense_5[0][0]                    
__________________________________________________________________________________________________
dense_11 (Dense)                (None, 128)          32896       dense_10[0][0]                   
__________________________________________________________________________________________________
time_distributed (TimeDistribut (None, 50, 1)        2           reshape[0][0]                    
__________________________________________________________________________________________________
dense_12 (Dense)                (None, 50)           6450        dense_11[0][0]                   
__________________________________________________________________________________________________
om (Reshape)                    (None, 50, 1)        0           time_distributed[0][0]           
__________________________________________________________________________________________________
reshape_1 (Reshape)             (None, 50, 1)        0           dense_12[0][0]                   
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 50, 2)        0           om[0][0]                         
                                                                 reshape_1[0][0]                  
__________________________________________________________________________________________________
flatten_2 (Flatten)             (None, 100)          0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dense_13 (Dense)                (None, 100)          10100       flatten_2[0][0]                  
__________________________________________________________________________________________________
dense_14 (Dense)                (None, 100)          10100       dense_13[0][0]                   
__________________________________________________________________________________________________
dense_15 (Dense)                (None, 50)           5050        dense_14[0][0]                   
__________________________________________________________________________________________________
dense_16 (Dense)                (None, 50)           2550        dense_15[0][0]                   
__________________________________________________________________________________________________
reshape_2 (Reshape)             (None, 50, 1)        0           dense_16[0][0]                   
__________________________________________________________________________________________________
time_distributed_1 (TimeDistrib (None, 50, 1)        2           reshape_2[0][0]                  
__________________________________________________________________________________________________
of (Reshape)                    (None, 50, 1)        0           time_distributed_1[0][0]         
```


**Any other info / logs**
I also tried setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter() 
by doing this:
```python
tf.lite.TFLiteConverter.target_ops = set([""TFLITE_BUILTINS"",""SELECT_TF_OPS""])
converter = tf.lite.TFLiteConverter.from_saved_model(INPATH)
```
but I could not spot any difference.

Any help would be much appreciated.

Sorry if the issue is illformed, I am new to the TF world, please let me know what additional info is needed.

"
38866,Fit an Use the Keras scikit-learn wrapper with Generator dataset,"**System information**
- TensorFlow version (you are using) : tf  2.2.0-rc3

- Are you willing to contribute it (Yes/No) : Yes


**Describe the feature and the current behavior/state.**
With the Keras scikit-learn wrapper, I want that the fit using generator dataset and generator validation dataset will be available. Actually its requires X,y like-arrays.

**Will this change the current api? How?**
It will extend the  Keras scikit-learn wrapper functionalities by permiting to use data augmentation using ImageGenarator.

**Who will benefit with this feature?**
Every Keras users that use the wrapper for Computer Vision.

**Any Other info.**
It will be useful for memory efficiency usage also."
38865,Error : tf.compat.v1.resource_loader.get_path_to_datafile,"While implementing this code:
import tensorflow as tf

_flow_warp_ops = tf.load_op_library(
    tf.compat.v1.resource_loader.get_path_to_datafile(""./lib/flow_warp.so""))


def flow_warp(image, flow):
    return _flow_warp_ops.flow_warp(image, flow)


@tf.RegisterGradient(""FlowWarp"")
def _flow_warp_grad(flow_warp_op, gradients):
    return _flow_warp_ops.flow_warp_grad(flow_warp_op.inputs[0],
                                         flow_warp_op.inputs[1],
                                         gradients)


I got the following error:

Traceback (most recent call last):

  File ""/home/akshat_suwalka/Fully-Automatic-Video-Colorization-with-Self-Regularization-and-Diversity-master/flow_warp.py"", line 4, in <module>
    tf.compat.v1.resource_loader.get_path_to_datafile(""./lib/flow_warp.so""))

  File ""/home/akshat_suwalka/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/load_library.py"", line 57, in load_op_library
    lib_handle = py_tf.TF_LoadLibrary(library_filename)

NotFoundError: libcudart.so.8.0: cannot open shared object file: No such file or directory

I am not able to deal with this error.
Can anyone help?"
38863,Windows PC Don't Need GPU get could not retrieve CUDA device attribute error ,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 8
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: n/a
- TensorFlow installed from (source or binary): binary downloaded from tf website
- TensorFlow version: latest from site at 24/04/20 
- Python version: 3.7
- Installed using virtualenv? pip? conda?: pip
- Bazel version (if compiling from source): n/a
- GCC/Compiler version (if compiling from source): n/a
- CUDA/cuDNN version: not applicable
- GPU model and memory: not applicable

Ran Beginners Tensorflow Demo Code in local Python envt (Thonny)

import tensorflow as tf, got 
2020-04-24 09:32:36.144859: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'cudart64_101.dll'; dlerror: cudart64_101.dll not found
2020-04-24 09:32:36.145180: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.

so as instructed ignored this

then did
mnist = tf.keras.datasets.mnist

(x_train, y_train), (x_test, y_test) = mnist.load_data()
x_train, x_test = x_train / 255.0, x_test / 255.0

ran OK
then did
model = tf.keras.models.Sequential([
  tf.keras.layers.Flatten(input_shape=(28, 28)),
  tf.keras.layers.Dense(128, activation='relu'),
  tf.keras.layers.Dropout(0.2),
  tf.keras.layers.Dense(10)
])
and got the following
2020-04-24 09:32:38.363170: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library nvcuda.dll

2020-04-24 09:32:38.575980: F tensorflow/stream_executor/lib/statusor.cc:34] Attempting to fetch value instead of handling error Internal: Could not retrieve CUDA device attribute (81: UNKNOWN ERROR (1)

So seems need a workaround to get it to continue to ignore the fact there is no GPU (I want it to run on the CPU only.

Thanks very much

**Describe the problem**

**Provide the exact sequence of commands / steps that you executed before running into the problem**


**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
38862,tf.ragged.stack may return tf.Tensor instead of tf.RaggedTensor,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Mint
- TensorFlow installed from (source or binary): conda
- TensorFlow version (use command below): unknown 2.1.0
- Python version: 3.7

**Describe the current behavior**
A call like 
```
print(tf.ragged.stack([tf.constant(5)], axis=0))
>>> tf.Tensor([5], shape=(1,), dtype=int32)
```
returns a `tf.Tensor` instead of a `RaggedTensor`

**Describe the expected behavior**
According to the documentation, the result should be a `RaggedTensor`. One might consider this a documentation error, but I think the return type of this function should not change depending on the values that are stacked.

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

```
import tensorflow as tf
print(tf.ragged.stack([tf.constant(5)], axis=0))
```"
38860,"A problem about ""bazel workspace""","I want to use ""tensorflow/tensorflow/lite/tools/evaluation/tasks/imagenet_image_classification/run_eval.cc"" to evaluate a .tflite model. I run the command ""bazel run -c opt ......"", but returned ""ERROR: The 'run' command is only supported from within a workspace"". What does workspace mean?"
38859,Wrong description in Digit classifier : Tensorflow Lite examples,"## URL with the issue: https://www.tensorflow.org/lite/examples

## Description of issue:
The digit classifier example card has the wrong description : 
""Generate reply suggestions to input conversational chat messages.""

## Screenshot

![image](https://user-images.githubusercontent.com/23613193/80188049-4441c500-862e-11ea-998d-b66c246de3d2.png)
"
38858,"[CPU] Best CPU Build found with MKL config in bazel build BUT with MKL Disabled in script, especially on LSTM, can't undestand why","<em>Please make sure that this is an issue related to performance of TensorFlow.
As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:performance_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: -
- TensorFlow installed from (source or binary): Build from source
- TensorFlow version (use command below): 2.1.0
- Python version: 3.8
- Bazel version (if compiling from source): 0.27.1
- GCC/Compiler version (if compiling from source): msvc2019
- CUDA/cuDNN version: -
- GPU model and memory: -

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

Hello there, I'm trying to find one of the best possible build option config while build tensorflow from source on my computers.

First I thought (as my two coputers are using i7 CPUs) building with MKL was the best option. But tuning correctly intra and inter op thread is hard because it really depends on the model used and the size of data used.

I created a micro benchmark (not really great I admit) but I found some huge discrepencies between build config options AND between Defines while running the script. I'm only benchmarking inference.

All builds were using /arch:AVX2

Here are the results of the microbenchmark with each build config options and define pairs :

### Build Command (With MKL) :
```
bazel --output_base=output_dir build --define=no_tensorflow_py_deps=true --config=v2 --config=mkl --config=opt -c opt --copt=""/Ob3"" --copt=""/fp:fast"" --copt=""/O2""  //tensorflow/tools/pip_package:build_pip_package
```
### Define Config (MKL Disabled)
```
os.environ['TF_DISABLE_MKL'] = '1'
os.environ[""CUDA_VISIBLE_DEVICES""] = ""-1""
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1' 

tf.compat.v1.disable_eager_execution()
```
### Results
```
Big Dense pass 1 : it took 10.544710159301758 seconds
Big Dense pass 2 : it took 9.63374948501587 seconds
Big Dense pass 3 : it took 9.610066175460815 seconds
Xception pass 1 : it took 5.660003900527954 seconds
Xception pass 2 : it took 5.289057493209839 seconds
Xception pass 3 : it took 5.238063812255859 seconds
LSTM pass 1 : it took 10.222216606140137 seconds
LSTM pass 2 : it took 8.22239375114441 seconds
LSTM pass 3 : it took 8.210553884506226 seconds
LSTM unrolled pass 1 : it took 14.414194822311401 seconds
LSTM unrolled  pass 2 : it took 7.88745903968811 seconds
LSTM unrolled pass 3 : it took 8.34917140007019 seconds
Linear Model pass 1 : it took 1.0033559799194336 seconds
Linear Model pass 2 : it took 0.0069768428802490234 seconds
Linear Model pass 3 : it took 0.010947227478027344 seconds
Linear Model small data pass 1 : it took 1.0467493534088135 seconds
Linear Model small data pass 2 : it took 0.08178114891052246 seconds
Linear Model small data pass 3 : it took 0.15857625007629395 seconds
```

### Build Command (with MKL) :
```
bazel --output_base=output_dir build --define=no_tensorflow_py_deps=true --config=v2 --config=mkl --config=opt -c opt --copt=""/Ob3"" --copt=""/fp:fast"" --copt=""/O2""  //tensorflow/tools/pip_package:build_pip_package
```
### Define Config (MKL Enabled)
```
#os.environ['TF_DISABLE_MKL'] = '1'
os.environ[""CUDA_VISIBLE_DEVICES""] = ""-1""
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1' 

tf.compat.v1.disable_eager_execution()
```
### Results
```
Big Dense pass 1 : it took 13.546119928359985 seconds
Big Dense pass 2 : it took 12.425012588500977 seconds
Big Dense pass 3 : it took 12.265166759490967 seconds
Xception pass 1 : it took 16.793854475021362 seconds
Xception pass 2 : it took 15.786102056503296 seconds
Xception pass 3 : it took 15.787992000579834 seconds
LSTM pass 1 : it took 10.035675525665283 seconds
LSTM pass 2 : it took 8.080043315887451 seconds
LSTM pass 3 : it took 7.926990509033203 seconds
LSTM unrolled pass 1 : it took 20.55500102043152 seconds
LSTM unrolled  pass 2 : it took 7.7295191287994385 seconds
LSTM unrolled pass 3 : it took 7.706652879714966 seconds
Linear Model pass 1 : it took 1.0731301307678223 seconds
Linear Model pass 2 : it took 0.007978677749633789 seconds
Linear Model pass 3 : it took 0.01296544075012207 seconds
Linear Model small data pass 1 : it took 1.1389260292053223 seconds
Linear Model small data pass 2 : it took 0.07978606224060059 seconds
Linear Model small data pass 3 : it took 0.1665961742401123 seconds
```

### Build Command (Without MKL)
```
bazel --output_base=output_dir build --define=no_tensorflow_py_deps=true --config=v2 --config=opt -c opt --copt=""/Ob3"" --copt=""/fp:fast"" --copt=""/O2""  //tensorflow/tools/pip_package:build_pip_package
```
### Define Config (MKL Disabled/Enabled should not matter as there it is not an MKL build)
```
os.environ['TF_DISABLE_MKL'] = '1'
os.environ[""CUDA_VISIBLE_DEVICES""] = ""-1""
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1' 

tf.compat.v1.disable_eager_execution()
```
### Results
```
Big Dense pass 1 : it took 10.71854853630066 seconds
Big Dense pass 2 : it took 9.549690961837769 seconds
Big Dense pass 3 : it took 9.396085262298584 seconds
Xception pass 1 : it took 5.693288326263428 seconds
Xception pass 2 : it took 5.287402391433716 seconds
Xception pass 3 : it took 5.261985540390015 seconds
LSTM pass 1 : it took 22.114120721817017 seconds
LSTM pass 2 : it took 20.470056772232056 seconds
LSTM pass 3 : it took 20.77280902862549 seconds
LSTM unrolled pass 1 : it took 27.426076889038086 seconds
LSTM unrolled  pass 2 : it took 21.209628105163574 seconds
LSTM unrolled pass 3 : it took 21.19388747215271 seconds
Linear Model pass 1 : it took 1.0153882503509521 seconds
Linear Model pass 2 : it took 0.007978439331054688 seconds
Linear Model pass 3 : it took 0.010976552963256836 seconds
Linear Model small data pass 1 : it took 1.046147108078003 seconds
Linear Model small data pass 2 : it took 0.08078360557556152 seconds
Linear Model small data pass 3 : it took 0.1626284122467041 seconds
```

What we see is : 
- on XCeption model, MKL Enabled run is very slow, and any amount of intra/extra threads config didn't manage to put these numbers down
- without BUILDING with MKL, LSTM benches are very slow !


**Describe the expected behavior**

I can't undestand why the best results were obtained with building with MKL **enabled** in build and then **disabling** its usage via script.

By the way when installing tensorflow via pip, we observe the same behaviour (bad results on LSTM) and performance is a little bit worse on all other benchmarks (as it is not build with AVX2 and other optimisation flags I guess)

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

The benchmark naive code is attached below :
[bench.zip](https://github.com/tensorflow/tensorflow/files/4527325/bench.zip)



**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
38857,Tensorflow lite for unity,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version: 1.14
- Python version: 3.6
- Installed using virtualenv? pip? conda?: pip
- Bazel version (if compiling from source): 1.1.0
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10.0
- GPU model and memory: Tesla K80/ 12GB



**Describe the problem**
Not able to find libraries while building tensorflow lite for unity

**Provide the exact sequence of commands / steps that you executed before running into the problem**
bazel build -c opt --config android_arm64 --copt -Os --copt -DTFLITE_GPU_BINARY_RELEASE --copt -fvisibility=hidden --linkopt -s --strip always //tensorflow/lite/delegates/gpu:libtensorflowlite_gpu_delegate.so

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

ERROR: Skipping '//tensorflow/lite/delegates/gpu:libtensorflowlite_gpu_delegate.so': no such target '//tensorflow/lite/delegates/gpu:libtensorflowlite_gpu_delegate.so': target 'libtensorflowlite_gpu_delegate.so' not declared in package 'tensorflow/lite/delegates/gpu' defined by /home/ubuntu/tf_1.14/tensorflow/tensorflow/lite/delegates/gpu/BUILD
WARNING: Target pattern parsing failed.
ERROR: no such target '//tensorflow/lite/delegates/gpu:libtensorflowlite_gpu_delegate.so': target 'libtensorflowlite_gpu_delegate.so' not declared in package 'tensorflow/lite/delegates/gpu' defined by /home/ubuntu/tf_1.14/tensorflow/tensorflow/lite/delegates/gpu/BUILD
"
38856,ImportError: DLL load failed while importing _pywrap_tensorflow_internal: The specified module could not be found.,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):-Windows 10
- TensorFlow installed from (source or binary): Pip Install Tensorflow
- TensorFlow version:2.2.0
- Python version:3.8.2 64 bit
- Installed using virtualenv? pip? conda?: PIP
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: i=I don't have Nvidia Graphic Card
- GPU model and memory: Intel R HD family (2160 MB)
-Laptop- Hp EliteBook 8 GB ram ; core i5



**Describe the problem**
I am having a problem as Import error. Here is the stack code.

Traceback (most recent call last):
  File ""C:\Users\HP\AppData\Local\Programs\Python\Python38\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\HP\AppData\Local\Programs\Python\Python38\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\HP\AppData\Local\Programs\Python\Python38\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\HP\AppData\Local\Programs\Python\Python38\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\HP\AppData\Local\Programs\Python\Python38\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed while importing _pywrap_tensorflow_internal: The specified module could not be found.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""f:/MACHINE LEARNING/chatbot/main.py"", line 9, in <module>
    import tensorflow
  File ""C:\Users\HP\AppData\Local\Programs\Python\Python38\lib\site-packages\tensorflow\__init__.py"", line 41, in <module>
    from tensorflow.python.tools import module_util as _module_util
  File ""C:\Users\HP\AppData\Local\Programs\Python\Python38\lib\site-packages\tensorflow\python\__init__.py"", line 50, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\Users\HP\AppData\Local\Programs\Python\Python38\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 69, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""C:\Users\HP\AppData\Local\Programs\Python\Python38\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\HP\AppData\Local\Programs\Python\Python38\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\HP\AppData\Local\Programs\Python\Python38\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\HP\AppData\Local\Programs\Python\Python38\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\HP\AppData\Local\Programs\Python\Python38\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed while importing _pywrap_tensorflow_internal: The specified module could not be found.


It happened only after I just imported TensorFlow. Is it because I don't have a graphic card?

Please Help.
"
38855,Batch normalization performs different in tf.kera.Model and tf.estimator.Estimator.,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: v2.0.0-rc2-26-g64c3d38 2.0.0
- **Python version**: 3.5
- **CUDA/cuDNN version**: 10.1
- **GPU model and memory**: GeForce RTX 2080Ti 11GB

### Describe the problem
Batch normalization performs different in tf.kera.Model and tf.estimator.Estimator.
When run the following code, it is easy to get the output among ①Model ②Estimator transformed by tf.keras.estimator.model_to_estimator ③ Hand-made Estimator(pre-trained model is transformed to ckpt for ensuring the same weights).

VGG16(No BN layers in VGG): Three methods performs the same, ranging from 0.0 ~ 9.249033.
ResNet50: ①0.0 ~ 11.896655 ②0.0 ~ 11.621841 ③0.0 ~ 11.621841
MobileNetV2(alpha=1.0): ①0.0 ~ 3.871163 ②0.0 ~ 0.7918996 ③0.0 ~ 0.7918996
Conv2D + BN(Default initialization): ① performs the same to ②
Conv2D + BN(Random initialization): ① performs differ from ②

The above result means that all Keras pre-trained model cannot performs right in estimator.
I do the same comparison in TF 1.14, and it results the same thing.

So, how can I train a model with BN by using estimator correctly?

### Source code / logs
```
import numpy as np
import tensorflow as tf
import logging

LOGGER = logging.getLogger(""tensorflow"")

# Build model.
def build_model(name, random_bn_params=None):
    if name == ""ResNet50"":
        model = tf.keras.applications.ResNet50(
            input_shape=(224, 224, 3),
            include_top=False,
            pooling=""avg"")
    elif name == ""MobileNetV2_1.0"":
        model = tf.keras.applications.MobileNetV2(
            input_shape=(224, 224, 3),
            include_top=False,
            pooling=""avg"")
    elif name == ""VGG16"":
        model = tf.keras.applications.VGG16(
            input_shape=(224, 224, 3),
            include_top=False,
            pooling=""avg"")
    else:
        if random_bn_params:
            params = {""beta_initializer"": tf.random_normal_initializer(),
                      ""gamma_initializer"": tf.random_normal_initializer(),
                      ""moving_mean_initializer"": tf.random_normal_initializer(),
                      ""moving_variance_initializer"": tf.random_normal_initializer()}
        else:
            params = dict()
        layer = tf.keras.layers.Conv2D(1, (3, 3), use_bias=False)
        layer_bn = tf.compat.v1.keras.layers.BatchNormalization(**params)
        inp = tf.keras.layers.Input((224, 224, 3))
        out = layer(inp)
        out = layer_bn(out)
        model = tf.keras.Model(inputs=inp,
                               outputs=out)
    return model

# Model params.
MODEL_NAME = ""VGG161""  # ResNet50、VGG16、MobileNetV2_1.0 are available, pre-trained models are loaded. Name not in the above three will build a Conv2D + BN network.
RANDOM_BN_PARAMS = True  # Whether to initialize BN  by randomized params when using a customized Conv2D + BN network.
INPUT_TENSOR_FUNC = lambda: tf.ones((1, 224, 224, 3))  # Fixed model input.

# Use Keras model to predict.
model = build_model(MODEL_NAME, RANDOM_BN_PARAMS)
model.compile(optimizer = tf.keras.optimizers.RMSprop(lr=0, decay=1.0),
              loss='mean_squared_error')
model_output = model.predict(INPUT_TENSOR_FUNC())

# Use Estimator transformed from Keras model to predict.
estimator = tf.keras.estimator.model_to_estimator(model)
estimator_output = next(estimator.predict(INPUT_TENSOR_FUNC))

# Use a handmake model equivalent to Keras model to predict.
def _init_variables_from_checkpoint(checkpoint_path, model_dir):
    flags_checkpoint_path = checkpoint_path
    # Warn the user if a checkpoint exists in the model_dir. Then ignore.
    if tf.compat.v1.train.latest_checkpoint(model_dir):
        LOGGER.info(
            ""Ignoring model_init_name because a checkpoint already exists in %s."" % model_dir)
        return None
    if flags_checkpoint_path is """":
        return None

    # Gather all trainable variables to initialize.
    variables_to_init = tf.compat.v1.trainable_variables()

    variables_to_init_dict = {var.name.rsplit("":"", 1)[0]: var for var in variables_to_init}

    if tf.compat.v1.gfile.IsDirectory(flags_checkpoint_path):
        checkpoint_path = tf.compat.v1.train.latest_checkpoint(flags_checkpoint_path)
    else:
        checkpoint_path = flags_checkpoint_path

    LOGGER.info(""Fine-tuning from %s."" % checkpoint_path)

    # Gather all available variables to initialize.
    available_var_map = _get_variables_available_in_checkpoint(variables_to_init_dict,
                                                               checkpoint_path)

    init_op = tf.compat.v1.train.init_from_checkpoint(checkpoint_path, available_var_map)
    LOGGER.info(""%d/%d variables in checkpoint has been restored."" % (len(available_var_map),
                                                                      len(variables_to_init)))

    return tf.compat.v1.train.Scaffold(init_op=init_op)


def _get_variables_available_in_checkpoint(variables,
                                           checkpoint_path,
                                           include_global_step=False):
    """"""Returns the subset of variables in the checkpoint.

    Inspects given checkpoint and returns the subset of variables that are
    available in it.

    Args:
        variables: A dictionary of variables to find in checkpoint.
        checkpoint_path: Path to the checkpoint to restore variables from.
        include_global_step: Whether to include `global_step` variable, if it
            exists. Default True.

    Returns:
        A dictionary of variables.

    Raises:
        ValueError: If `variables` is not a dict.
    """"""
    if not isinstance(variables, dict):
        raise ValueError(""`variables` is expected to be a dict."")

    # Available variables
    ckpt_reader = tf.compat.v1.train.NewCheckpointReader(checkpoint_path)
    ckpt_vars_to_shape_map = ckpt_reader.get_variable_to_shape_map()
    if not include_global_step:
        ckpt_vars_to_shape_map.pop(tf.compat.v1.GraphKeys.GLOBAL_STEP, None)
    vars_in_ckpt = {}

    # for key in ckpt_vars_to_shape_map:
    #     LOGGER.info(""Available variable name: %s"", key)

    for variable_name, variable in sorted(variables.items()):
        if variable_name in ckpt_vars_to_shape_map:
            if ckpt_vars_to_shape_map[variable_name] == variable.shape.as_list():
                vars_in_ckpt[variable_name] = variable
            else:
                LOGGER.warning(""Variable [%s] is available in checkpoint, but has an incompatible ""
                               ""shape with model variable. Checkpoint shape: [%s], model variable ""
                               ""shape: [%s]. This variable will not be initialized from the ""
                               ""checkpoint."",
                               variable_name,
                               ckpt_vars_to_shape_map[variable_name],
                               variable.shape.as_list())
        else:
            LOGGER.warning(""Variable [%s] is not available in checkpoint"", variable_name)
    return vars_in_ckpt

def model_fn(features, labels, mode):
    # Set Keras learning phase for alter BatchNorm and Dropout performance.
    tf.keras.backend.set_learning_phase(mode == tf.estimator.ModeKeys.TRAIN)

    m = build_model(MODEL_NAME, RANDOM_BN_PARAMS)
    predictions = m(features)
    
    scaffold = None
    if MODEL_NAME in {""ResNet50"", ""VGG16"", ""MobileNetV2_1.0""}:
        scaffold = _init_variables_from_checkpoint(""w:/keras/%s.ckpt"" % MODEL_NAME, ""."")

    # Create estimator_spec for Estimator.
    estimator_spec = tf.estimator.EstimatorSpec(
        mode=mode,
        predictions=predictions,
        scaffold = scaffold
    )
    return estimator_spec
estimator_handmake = tf.estimator.Estimator(model_fn=model_fn)
estimator_handmake_output = next(estimator_handmake.predict(INPUT_TENSOR_FUNC))

# Compare the output range.
print(np.max(model_output), np.min(model_output))
print(np.max(estimator_output[list(estimator_output.keys())[0]]), np.min(estimator_output[list(estimator_output.keys())[0]]))
print(np.max(estimator_handmake_output), np.min(estimator_handmake_output))
```"
38852,TFLite on Windows?  Efficient embedded TF2 x86-64 Windows CPU inference?,"On our ARMv8 Android embedded platform, we are using the following workflow and it's working great:

    Train on Linux servers using TF2 ---> embedded inference on Android using TFLite

On our x86-64 Windows embedded platform, we are using the following workflow:

    Train on Linux servers using TF1 ---> embedded inference on Windows using OpenVINO

We are stuck with TF1 for Windows because Intel's OpenVINO does not yet support TF2; they may have support next fall or later.

In the meantime, this presents a problem for us because we have teams using both TF1 and TF2 for the same AI feature.   We would like to standardize on TF2:

    Train on Linux servers using TF2 ---> embedded inference on Windows using ?????

For example, is there a way to run efficient TFLite CPU inference on x86-64 Windows?   Ideas:

- try to compile the TFLite runtime for Windows with x86-64 intrinsics (e.g. AVX, FMA, SSE)
- try the TFLite XNNPack Delegate which seems to have x86 support (but maybe not Windows)

https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/delegates/xnnpack

We tried going through an intermediate path like TF2 -> ONNX, but have not had success yet.

Any advice would be appreciated, especially from anyone who may have already gone down this path.

"
38851,Issues creating Frozen_graph for this model,"I am using Windows 10
Tensorflow v 1.14

I am trying to create a frozen graph for the checkpoint data in the following gitrepo:
https://github.com/una-dinosauria/3d-pose-baseline 
using the code below:
`
with tf.Session() as sess:
    
    saver=tf.train.import_meta_graph(meta_path)
    
    saver.restore(sess,'C:\\Users\\alecd\\3d-pose-baseline\\checks\\checkpoint-4874200.meta')
    
    frozen_graph_def=tf.graph_util.convert_variables_to_constants(sess,sess.graph_def,output_node_names)
    
    with open('output_graph.pb', 'wb') as f:
        f.write(frozen_graph_def.SerializeToString())
    
`
Now, when I would try to serve the model in python I would get the following error: 

`
ValueError: Input 0 of node learning_rate/Assign was passed float from learning_rate:0 incompatible with expected float_ref.
`

I thought that one of the possible issues was that I was not passing a specific output node so I decided to try and visualize the graph inside tensorboard using:

`
tf.train.import_meta_graph(""checkpoint-4874200.meta"")
for n in tf.get_default_graph().as_graph_def().node:
   print(n)
with tf.Session() as sess:
  writer = tf.summary.FileWriter(""./output/"", sess.graph)
  writer.close()
`
but when I would run
`
tensorboard --logdir=data/ --host localhost --port 8088
`
I get a tensorboard page with no information which made me start to wonder whether or not the meta graph was corrupted or something else was going on. 

Just looking for general advice and or help here if anyone has any idea as to what is going on?

As a side note the frozen_graph I created can be found at 
https://github.com/alecda573/frozen_graph"
38850,Mixed Precision + Gaussian Noise throws data type error float16 / float 32,"I get the following error:

```

  File ""<ipython-input-1-447a869fb5df>"", line 171, in ae
    encoder,decoder = AddLayers(neurons,setup['AFunction'],setup['BatchNorm'],setup['Dropout'],setup['Layers'],dim,setup['Noise'])

  File ""C:\MA\RecommenderSystems\code\helper.py"", line 89, in AddLayers
    encoder.add(GaussianNoise(noise))

  File ""C:\Users\Admin\Anaconda3\envs\tf2\lib\site-packages\tensorflow_core\python\training\tracking\base.py"", line 457, in _method_wrapper
    result = method(self, *args, **kwargs)

  File ""C:\Users\Admin\Anaconda3\envs\tf2\lib\site-packages\tensorflow_core\python\keras\engine\sequential.py"", line 196, in add
    output_tensor = layer(self.outputs[0])

  File ""C:\Users\Admin\Anaconda3\envs\tf2\lib\site-packages\tensorflow_core\python\keras\engine\base_layer.py"", line 842, in __call__
    outputs = call_fn(cast_inputs, *args, **kwargs)

  File ""C:\Users\Admin\Anaconda3\envs\tf2\lib\site-packages\tensorflow_core\python\keras\layers\noise.py"", line 70, in call
    return K.in_train_phase(noised, inputs, training=training)

  File ""C:\Users\Admin\Anaconda3\envs\tf2\lib\site-packages\tensorflow_core\python\keras\backend.py"", line 4285, in in_train_phase
    x = switch(training, x, alt)

  File ""C:\Users\Admin\Anaconda3\envs\tf2\lib\site-packages\tensorflow_core\python\keras\backend.py"", line 4218, in switch
    x = control_flow_ops.cond(condition, then_expression_fn, else_expression_fn)

  File ""C:\Users\Admin\Anaconda3\envs\tf2\lib\site-packages\tensorflow_core\python\util\deprecation.py"", line 507, in new_func
    return func(*args, **kwargs)

  File ""C:\Users\Admin\Anaconda3\envs\tf2\lib\site-packages\tensorflow_core\python\ops\control_flow_ops.py"", line 1174, in cond
    return cond_v2.cond_v2(pred, true_fn, false_fn, name)

  File ""C:\Users\Admin\Anaconda3\envs\tf2\lib\site-packages\tensorflow_core\python\ops\cond_v2.py"", line 84, in cond_v2
    op_return_value=pred)

  File ""C:\Users\Admin\Anaconda3\envs\tf2\lib\site-packages\tensorflow_core\python\framework\func_graph.py"", line 915, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)

  File ""C:\Users\Admin\Anaconda3\envs\tf2\lib\site-packages\tensorflow_core\python\keras\layers\noise.py"", line 68, in noised
    shape=array_ops.shape(inputs), mean=0., stddev=self.stddev)

  File ""C:\Users\Admin\Anaconda3\envs\tf2\lib\site-packages\tensorflow_core\python\ops\math_ops.py"", line 899, in binary_op_wrapper
    return func(x, y, name=name)

  File ""C:\Users\Admin\Anaconda3\envs\tf2\lib\site-packages\tensorflow_core\python\ops\math_ops.py"", line 1197, in _add_dispatch
    return gen_math_ops.add_v2(x, y, name=name)

  File ""C:\Users\Admin\Anaconda3\envs\tf2\lib\site-packages\tensorflow_core\python\ops\gen_math_ops.py"", line 549, in add_v2
    ""AddV2"", x=x, y=y, name=name)

  File ""C:\Users\Admin\Anaconda3\envs\tf2\lib\site-packages\tensorflow_core\python\framework\op_def_library.py"", line 563, in _apply_op_helper
    inferred_from[input_arg.type_attr]))

TypeError: Input 'y' of 'AddV2' Op has type float32 that does not match type float16 of argument 'x'.
```
**System information**
- Windows 10 [Version 10.0.18362.418]
- TensorFlow version 2.0.0 via Conda
- Python version: 3.6.10
- CUDA/cuDNN version: 10.0.0130 / 7.6.5
- GPU model and memory: NVIDIA 2060 Super 8GB

**Describe the current behavior**
The error only occurs only if mixed precision **and** noise is applied.

When mixed precision is applied, then:
```
os.environ['TF_ENABLE_AUTO_MIXED_PRECISION'] = '1' #using tensor cores
policy = tf.keras.mixed_precision.experimental.Policy('mixed_float16')
tf.keras.mixed_precision.experimental.set_policy(policy)
```
and data are converted to float16.

Converting the output of the previous dense layer to float16 couldn't solve the problem.
```
encoder.add(Dense(eneurons[0],input_dim=dim,dtype=tf.float16))

if noise:
        encoder.add(GaussianNoise(noise))
```

I cannot update to a higher TF version."
38847,Getting “CUDA_ERROR_INVALID_VALUE: invalid argument” in python with Tensorflow 1.14,"When I run the snippet below, as `python test.py`

```python
import os
# Enable '0' or disable '-1' GPU use
# os.environ[""CUDA_DEVICE_ORDER""]=""PCI_BUS_ID""
os.environ['CUDA_VISIBLE_DEVICES'] = ""0""
import warnings

with warnings.catch_warnings():
	warnings.filterwarnings(""ignore"", category=FutureWarning)
	import tensorflow as tf
	config = tf.compat.v1.ConfigProto()
	# config.gpu_options.visible_device_list = ""0""  # pylint: disable=no-member
	config.gpu_options.allow_growth = True  # pylint: disable=no-member
	session = tf.compat.v1.Session(config=config)

# check if successfully using GPU
if tf.test.gpu_device_name():
	print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))
else:
	print('GPU not being used')
```

I get the following error

```bash
2020-04-23 13:13:15.969352: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2020-04-23 13:13:15.974088: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2020-04-23 13:13:15.990122: W tensorflow/compiler/xla/service/platform_util.cc:256] unable to create StreamExecutor for CUDA:0: failed initializing StreamExecutor for CUDA device ordinal 0: Internal: failed call to cuDevicePrimaryCtxRetain: CUDA_ERROR_INVALID_VALUE: invalid argument
2020-04-23 13:13:15.990240: F tensorflow/stream_executor/lib/statusor.cc:34] Attempting to fetch value instead of handling error Internal: no supported devices found for platform CUDA
Aborted (core dumped)
```

When I set `os.environ['CUDA_VISIBLE_DEVICES'] = ""-1""`(ie no GPU use), there is no error and the output is as expected shown below.

```bash
2020-04-23 13:18:24.911806: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2020-04-23 13:18:24.916849: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2020-04-23 13:18:24.920347: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2020-04-23 13:18:24.920384: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: vumacs
2020-04-23 13:18:24.920389: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: vumacs
2020-04-23 13:18:24.920456: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 440.64.0
2020-04-23 13:18:24.920482: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 440.64.0
2020-04-23 13:18:24.920489: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 440.64.0
2020-04-23 13:18:24.938734: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3299990000 Hz
2020-04-23 13:18:24.939659: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4849f40 executing computations on platform Host. Devices:
2020-04-23 13:18:24.939686: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
GPU not being used
```
Is there any way to resolve this erro since I previously used the same code by setting `CUDA_VISIBLE_DEVICES` to 0 both through the script as well as shell and there were no issues. The error seems to be occuring when setting the session with `tf.compat.v1.Session(config=config)`

Additional information

`python: 3.6.9`
`tensorflow-gpu==1.14.0`
`protobuf==3.11.3`
`tensorflow-estimator==1.14.0`

```bash
$ nvcc --version
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2018 NVIDIA Corporation
Built on Sat_Aug_25_21:08:01_CDT_2018
Cuda compilation tools, release 10.0, V10.0.130

$ nvidia-smi
Thu Apr 23 13:22:06 2020       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 440.64       Driver Version: 440.64       CUDA Version: 10.2     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  GeForce RTX 208...  Off  | 00000000:B3:00.0 Off |                  N/A |
| 26%   28C    P8    12W / 250W |    119MiB / 11019MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|    0      1277      G   /usr/lib/xorg/Xorg                            39MiB |
|    0      1388      G   /usr/bin/gnome-shell                          77MiB |
+-----------------------------------------------------------------------------+
```
I believe it is not a CUDA mismatch error as someone might believe (tf 1.14 does not work with CUDA 10.2) but here CUDA for tensorflow is 10.0. Also cuda is being loaded properly as you might notice in either of those cases.

Providing a few further logs
```python
import tensorflow as tf
print(""Num GPUs Available: "", len(tf.config.experimental.list_physical_devices('GPU')))
```
```bash
2020-04-23 15:32:47.855593: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2020-04-23 15:32:47.884652: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.545
pciBusID: 0000:b3:00.0
2020-04-23 15:32:47.885146: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2020-04-23 15:32:47.886730: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2020-04-23 15:32:47.888298: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2020-04-23 15:32:47.888855: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2020-04-23 15:32:47.890673: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2020-04-23 15:32:47.892068: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2020-04-23 15:32:47.895348: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2020-04-23 15:32:47.896233: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0
Num GPUs Available:  1
```
But then executing this line gives me the same error
```python
tf.test.gpu_device_name()
```
```bash
2020-04-23 15:34:50.948097: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2020-04-23 15:34:50.983906: W tensorflow/compiler/xla/service/platform_util.cc:256] unable to create StreamExecutor for CUDA:0: failed initializing StreamExecutor for CUDA device ordinal 0: Internal: failed call to cuDevicePrimaryCtxRetain: CUDA_ERROR_INVALID_VALUE: invalid argument
2020-04-23 15:34:50.984119: F tensorflow/stream_executor/lib/statusor.cc:34] Attempting to fetch value instead of handling error Internal: no supported devices found for platform CUDA
Aborted (core dumped)
```"
38845,Quantized Conv2D op gives different result in TensorFlow and TFLite,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
`No`
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
`Linux Ubuntu 18.04`
- TensorFlow installed from (source or binary):
`pip`
- TensorFlow version (use command below):
`2.0.0`
- Python version:
`3.7.7`
- GPU model and memory:
`CPU only`

**Describe the current behavior**
Conv2D op from the quanitzation-aware training graph yields different results when converted to TensorFlow Lite and executed in uint8. Manual quantization has been done when comparing the float value to the uint8 value. Both TF and TFLite models are run on x86-64 CPU.
**Describe the expected behavior**
The op should give exactly the same result when comparing the node output of the TFLite node to the output of the fake-quantization node in the TF graph to ensure the correctness of the TFLite model.

**Standalone code to reproduce the issue**
```import os
import numpy as np
import tensorflow as tf
from imageio import imread
from typing import Any, AnyStr, Mapping, Sequence


def saved_model_to_tflite(saved_model_dir: AnyStr, output_path: AnyStr):
    converter = tf.compat.v1.lite.TFLiteConverter.from_saved_model(
        saved_model_dir=saved_model_dir)
    converter.inference_type = tf.uint8
    converter.inference_input_type = tf.uint8

    converter.quantized_input_stats = {""ToFloat"": [127, 127.5]}
    converter.optimizations = []
    converter.change_concat_input_ranges = False
    converter.reorder_across_fake_quant = False
    tflite_model = converter.convert()

    with open(output_path, 'wb') as f:
        f.write(tflite_model)


def compare_models(saved_model_dir: AnyStr, tflite_path: AnyStr, image_path: AnyStr):
    image = imread(image_path)
    image = np.ascontiguousarray(image, dtype=np.float32)
    image = image[np.newaxis, ...]
    normalized_image = ((image - 127) / 127.5)
    
    imported_model = tf.saved_model.load(saved_model_dir)
    imported_model.variables.trainable = False
    model = imported_model.signatures[tf.compat.v1.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY]
    
    interpreter = tf.lite.Interpreter(tflite_path)
    interpreter.allocate_tensors()
    interpreter.tensor(interpreter.get_input_details()[0][""index""])()[:, :, :, :] = image.astype(np.uint8)
    
    tf_result = list(model(tf.constant(normalized_image)).values())[0].numpy()
    interpreter.invoke()
    tflite_result = interpreter.tensor(interpreter.get_output_details()[0][""index""])().copy()
    # Manually apply de-quantization
    tflite_result = (tflite_result.astype(np.float) - 107) * 0.1115700826048851
 
    ae = np.abs(tf_result - tflite_result)
    max_ae = ae.max()
    max_diff_indices = np.argwhere(ae == np.max(ae))
    print(max_diff_indices)
    print(f""Max absolute error: {max_ae}. Example values tf: {tf_result[ae==np.max(ae)][0]}; tflite: {tflite_result[ae==np.max(ae)][0]}"")
```
**Other info / logs** Include any logs or source code that would be helpful to
TensorFlow and TFLite model visualization of the minimum model containing only one Conv2d op:
![Screenshot from 2020-04-23 14-37-54](https://user-images.githubusercontent.com/10414613/80136811-3af22300-8570-11ea-8eb5-e936e8e22251.png)
![Screenshot from 2020-04-23 14-31-10](https://user-images.githubusercontent.com/10414613/80136822-3ded1380-8570-11ea-8ef7-f1eee7211c0d.png)


A minimum example including a saved model a converted TFLite model and an image has been attached to help reproduce the issue.
[tf_issue.zip](https://github.com/tensorflow/tensorflow/files/4524528/tf_issue.zip)
"
38842,ValueError: Could not interpret optimizer identifier (tf.keras) ,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- I have written a custom callback for learning_rate_scheduler in keras
- Code is running on Google Colaboratory:
- TensorFlow version (use command below): tensorflow 2.2.0-rc3.
I need to be able to set and get my learning_rate and other params in my optimizer,

 I need to be able to use the constructor of optimizer to set the parameters in it

Used the sample code in the keras documentation 
""Issue Reproducing steps""
1. Run this code in Google colab
from keras import optimizers

model = Sequential()
model.add(Dense(64, kernel_initializer='uniform', input_shape=(10,)))
model.add(Activation('softmax'))

sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)
model.compile(loss='mean_squared_error', optimizer=sgd)
2. Throws Deserialization error
3. Attaching the screenshot of the erro
4.Please help with a resolution/workaround for this issue, as i am working on a critical course assignment which I need to submit soon .
![error 2020-04-23 222914](https://user-images.githubusercontent.com/21074002/80129974-824ed280-85b5-11ea-9eac-5dd4791e8d6a.jpg)

Thanks


"
38841,NotFoundError: No registered 'AssignSubVariableOp' OpKernel for 'GPU' devices compatible with node {{node AssignSubVariableOp}},"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
`no`
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
`windows10 x64`
- TensorFlow installed from (source or binary):
`anaconda`
- TensorFlow version (use command below):
`2.1.0`
- Python version:
`3.7.7`
- CUDA/cuDNN version:
`10.1 update2`
- GPU model and memory:
`gtx1050ti 4GB`

import tensorflow as tf
print(tf.version.GIT_VERSION, tf.version.VERSION)""

result:unknown 2.1.0

**Describe the current behavior**
see the code 

**Describe the expected behavior**
see the error

**Standalone code to reproduce the issue**
cmd：
```
conda create -n tf2g python=3.7
conda activate tf2g
conda install tensorflow-gpu spyder
spyder
```
spyder:
```
import tensorflow as tf

epoch = 2

x = tf.Variable([[0. + 0.j]], tf.complex128)
y = tf.constant([[1. + 1.j]], tf.complex128)

#variables = [x]

for i in range(epoch):
    with tf.GradientTape() as tape:
        loss_value = (x - y)
    #print(loss_value)
    grad = tape.gradient(loss_value, x)
    #print(grad)
    x.assign_sub(0.1 * tf.math.conj(grad))

print(epoch)
```
debug:
```
runfile('E:/Projects/Python/tensorflow/temp/004/001.py', wdir='E:/Projects/Python/tensorflow/temp/004')
Traceback (most recent call last):

  File ""E:\Projects\Python\tensorflow\temp\004\001.py"", line 23, in <module>
    x.assign_sub(0.1 * tf.math.conj(grad))

  File ""D:\ProgramData\Anaconda3\envs\tf2g\lib\site-packages\tensorflow_core\python\ops\resource_variable_ops.py"", line 762, in assign_sub
    name=name)

  File ""D:\ProgramData\Anaconda3\envs\tf2g\lib\site-packages\tensorflow_core\python\ops\gen_resource_variable_ops.py"", line 102, in assign_sub_variable_op
    _ops.raise_from_not_ok_status(e, name)

  File ""D:\ProgramData\Anaconda3\envs\tf2g\lib\site-packages\tensorflow_core\python\framework\ops.py"", line 6606, in raise_from_not_ok_status
    six.raise_from(core._status_to_exception(e.code, message), None)

  File ""<string>"", line 3, in raise_from

NotFoundError: No registered 'AssignSubVariableOp' OpKernel for 'GPU' devices compatible with node {{node AssignSubVariableOp}}
	 (OpKernel was found, but attributes didn't match) Requested Attributes: dtype=DT_COMPLEX128
	.  Registered:  device='CPU'; dtype in [DT_INT64]
  device='CPU'; dtype in [DT_INT32]
  device='CPU'; dtype in [DT_UINT16]
  device='CPU'; dtype in [DT_INT16]
  device='CPU'; dtype in [DT_UINT8]
  device='CPU'; dtype in [DT_INT8]
  device='CPU'; dtype in [DT_HALF]
  device='CPU'; dtype in [DT_BFLOAT16]
  device='CPU'; dtype in [DT_FLOAT]
  device='CPU'; dtype in [DT_DOUBLE]
  device='CPU'; dtype in [DT_COMPLEX64]
  device='CPU'; dtype in [DT_COMPLEX128]
  device='GPU'; dtype in [DT_HALF]
  device='GPU'; dtype in [DT_FLOAT]
  device='GPU'; dtype in [DT_DOUBLE]
  device='GPU'; dtype in [DT_INT64]
 [Op:AssignSubVariableOp]
```
"
38840,Build error: No matching toolchains on ppc64le,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): ppc64le, CentOS 7 manylinux 2014 container
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): source
- TensorFlow version: master branch
- Python version: 3.6
- Installed using virtualenv? pip? conda?: N/A
- Bazel version (if compiling from source): 3.0.0
- GCC/Compiler version (if compiling from source): 8.3.1
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A

**Describe the problem**

This commit: https://github.com/tensorflow/tensorflow/commit/f5bb64336039646cae91884f7177bdcb6f29a7e2, broke the build on ppc64le.

builds on ppc64le have been working fine until that commit. To do a build with that commit, I must modify `third_party/remote_config/BUILD.tpl` to replace with `platforms:x86_64` with `platforms:ppc`.

**Provide the exact sequence of commands / steps that you executed before running into the problem**
```
git clone https://github.com/tensorflow/tensorflow
cd tensorflow
./configure (accept all defaults)
bazel build -c opt --config=v2 --local_cpu_resources 4 --local_ram_resources 4096 //tensorflow/tools/pip_package:build_pip_package
```

**Any other info / logs**
build fails with:
```
ERROR: While resolving toolchains for target //tensorflow/tools/build_info:gen_build_info: No matching toolchains found for types @bazel_tools//tools/cpp:toolchain_type. Maybe --incompatible_use_cc_configure_from_rules_cc has been flipped and there is no default C++ toolchain added in the WORKSPACE file? See https://github.com/bazelbuild/bazel/issues/10134 for details and migration instructions.
ERROR: Analysis of target '//tensorflow/tools/pip_package:build_pip_package' failed; build aborted: No matching toolchains found for types @bazel_tools//tools/cpp:toolchain_type. Maybe --incompatible_use_cc_configure_from_rules_cc has been flipped and there is no default C++ toolchain added in the WORKSPACE file? See https://github.com/bazelbuild/bazel/issues/10134 for details and migration instructions.
```

if I add `--toolchain_resolution_debug` to the command line:

`bazel build -c opt --config=v2 --local_cpu_resources 4 --local_ram_resources 4096 --toolchain_resolution_debug //tensorflow/tools/pip_package:build_pip_package`

I get this additional debug:
```
INFO: Build option --toolchain_resolution_debug has changed, discarding analysis cache.
INFO: ToolchainResolution: Selected execution platform @local_execution_config_platform//:platform,
INFO: ToolchainResolution: Looking for toolchain of type @bazel_tools//tools/cpp:toolchain_type...
INFO: ToolchainResolution:   Considering toolchain @local_config_cc//:cc-compiler-armeabi-v7a...
INFO: ToolchainResolution:     Toolchain constraint @platforms//cpu:cpu has value @platforms//cpu:arm, which does not match value @platforms//cpu:ppc from the target platform @local_config_platform//:host
INFO: ToolchainResolution:     Toolchain constraint @platforms//os:os has value @platforms//os:android, which does not match value @platforms//os:linux from the target platform @local_config_platform//:host
INFO: ToolchainResolution:   Rejected toolchain @local_config_cc//:cc-compiler-armeabi-v7a, because of target platform mismatch
INFO: ToolchainResolution:   Considering toolchain @local_config_cc//:cc-compiler-ppc...
INFO: ToolchainResolution:     Toolchain constraint @platforms//cpu:cpu has value @platforms//cpu:ppc, which does not match value @platforms//cpu:x86_64 from the execution platform @local_execution_config_platform//:platform
INFO: ToolchainResolution:   For toolchain type @bazel_tools//tools/cpp:toolchain_type, possible execution platforms and toolchains: {@local_config_platform//:host -> @local_config_cc//:cc-compiler-ppc}
INFO: ToolchainResolution: Looking for toolchain of type @bazel_tools//tools/python:toolchain_type...
INFO: ToolchainResolution: Looking for toolchain of type @bazel_tools//tools/cpp:toolchain_type...
INFO: ToolchainResolution: Looking for toolchain of type @bazel_tools//tools/python:toolchain_type...
INFO: ToolchainResolution:   Considering toolchain @local_execution_config_python//:py_runtime_pair...
INFO: ToolchainResolution: Selected execution platform @local_execution_config_platform//:platform,
INFO: ToolchainResolution:     Toolchain constraint @local_execution_config_platform//:platform_setting has value @local_execution_config_platform//:platform_constraint, which does not match value <missing> from the target platform @local_config_platform//:host
INFO: ToolchainResolution:   Rejected toolchain @local_execution_config_python//:py_runtime_pair, because of target platform mismatch
INFO: ToolchainResolution:   Considering toolchain @local_config_cc//:cc-compiler-armeabi-v7a...
INFO: ToolchainResolution:   Considering toolchain @local_execution_config_python//:py_runtime_pair...
INFO: ToolchainResolution:     Toolchain constraint @platforms//cpu:cpu has value @platforms//cpu:arm, which does not match value @platforms//cpu:ppc from the target platform @local_config_platform//:host
INFO: ToolchainResolution:   Considering toolchain @local_config_python//:py_runtime_pair...
INFO: ToolchainResolution: Selected execution platform @local_config_platform//:host, type @bazel_tools//tools/cpp:toolchain_type -> toolchain @local_config_cc//:cc-compiler-ppc
INFO: ToolchainResolution:     Toolchain constraint @platforms//os:os has value @platforms//os:android, which does not match value @platforms//os:linux from the target platform @local_config_platform//:host
INFO: ToolchainResolution:     Toolchain constraint @local_execution_config_platform//:platform_setting has value @local_execution_config_platform//:platform_constraint, which does not match value <missing> from the target platform @local_config_platform//:host
INFO: ToolchainResolution:   Rejected toolchain @local_config_cc//:cc-compiler-armeabi-v7a, because of target platform mismatch
INFO: ToolchainResolution:   Considering toolchain @bazel_tools//tools/python:_autodetecting_py_runtime_pair...
INFO: ToolchainResolution:   Considering toolchain @local_config_cc//:cc-compiler-ppc...
INFO: ToolchainResolution:   Rejected toolchain @local_execution_config_python//:py_runtime_pair, because of target platform mismatch
INFO: ToolchainResolution:     Toolchain constraint @platforms//cpu:cpu has value @platforms//cpu:ppc, which does not match value @platforms//cpu:x86_64 from the execution platform @local_execution_config_platform//:platform
INFO: ToolchainResolution:   For toolchain type @bazel_tools//tools/python:toolchain_type, possible execution platforms and toolchains: {@local_execution_config_platform//:platform -> @local_config_python//:py_runtime_pair, @local_config_platform//:host -> @local_config_python//:py_runtime_pair}
INFO: ToolchainResolution: Selected execution platform @local_execution_config_platform//:platform,
INFO: ToolchainResolution:   For toolchain type @bazel_tools//tools/cpp:toolchain_type, possible execution platforms and toolchains: {@local_config_platform//:host -> @local_config_cc//:cc-compiler-ppc}
INFO: ToolchainResolution: Selected execution platform @local_config_platform//:host, type @bazel_tools//tools/cpp:toolchain_type -> toolchain @local_config_cc//:cc-compiler-ppc
INFO: ToolchainResolution:   Considering toolchain @local_config_python//:py_runtime_pair...
INFO: ToolchainResolution: Looking for toolchain of type @bazel_tools//tools/cpp:toolchain_type...
INFO: ToolchainResolution: Selected execution platform @local_config_platform//:host, type @bazel_tools//tools/cpp:toolchain_type -> toolchain @local_config_cc//:cc-compiler-ppc, type @bazel_tools//tools/python:toolchain_type -> toolchain @local_config_python//:py_runtime_pair
INFO: ToolchainResolution: Removed execution platform @local_config_platform//:host from available execution platforms, it is missing constraint @local_execution_config_platform//:platform_constraint
INFO: ToolchainResolution:   Considering toolchain @local_config_cc//:cc-compiler-armeabi-v7a...
INFO: ToolchainResolution:     Toolchain constraint @platforms//cpu:cpu has value @platforms//cpu:arm, which does not match value @platforms//cpu:x86_64 from the target platform @local_execution_config_platform//:platform
INFO: ToolchainResolution:   Considering toolchain @bazel_tools//tools/python:_autodetecting_py_runtime_pair...
INFO: ToolchainResolution:     Toolchain constraint @platforms//os:os has value @platforms//os:android, which does not match value @platforms//os:linux from the target platform @local_execution_config_platform//:platform
INFO: ToolchainResolution:   Rejected toolchain @local_config_cc//:cc-compiler-armeabi-v7a, because of target platform mismatch
INFO: ToolchainResolution: Looking for toolchain of type @bazel_tools//tools/python:toolchain_type...
INFO: ToolchainResolution: Looking for toolchain of type @bazel_tools//tools/cpp:toolchain_type...
INFO: ToolchainResolution:   Considering toolchain @local_config_cc//:cc-compiler-armeabi-v7a...
INFO: ToolchainResolution:   Considering toolchain @local_execution_config_python//:py_runtime_pair...
INFO: ToolchainResolution:   Considering toolchain @local_config_cc//:cc-compiler-ppc...
INFO: ToolchainResolution:   For toolchain type @bazel_tools//tools/python:toolchain_type, possible execution platforms and toolchains: {@local_execution_config_platform//:platform -> @local_config_python//:py_runtime_pair, @local_config_platform//:host -> @local_config_python//:py_runtime_pair}
INFO: ToolchainResolution:     Toolchain constraint @platforms//cpu:cpu has value @platforms//cpu:ppc, which does not match value @platforms//cpu:x86_64 from the target platform @local_execution_config_platform//:platform
INFO: ToolchainResolution:   Considering toolchain @local_config_python//:py_runtime_pair...
INFO: ToolchainResolution:     Toolchain constraint @platforms//cpu:cpu has value @platforms//cpu:arm, which does not match value @platforms//cpu:x86_64 from the target platform @local_execution_config_platform//:platform
INFO: ToolchainResolution: Selected execution platform @local_config_platform//:host, type @bazel_tools//tools/cpp:toolchain_type -> toolchain @local_config_cc//:cc-compiler-ppc, type @bazel_tools//tools/python:toolchain_type -> toolchain @local_config_python//:py_runtime_pair
INFO: ToolchainResolution:   Considering toolchain @bazel_tools//tools/python:_autodetecting_py_runtime_pair...
INFO: ToolchainResolution:   Rejected toolchain @local_config_cc//:cc-compiler-ppc, because of target platform mismatch
INFO: ToolchainResolution:   No toolchains found
INFO: ToolchainResolution:   For toolchain type @bazel_tools//tools/python:toolchain_type, possible execution platforms and toolchains: {@local_execution_config_platform//:platform -> @local_execution_config_python//:py_runtime_pair}
INFO: ToolchainResolution:     Toolchain constraint @platforms//os:os has value @platforms//os:android, which does not match value @platforms//os:linux from the target platform @local_execution_config_platform//:platform
```

"
38839,tf.repeat AttributeError: module 'tensorflow' has no attribute 'repeat' on versions 2.0.0 and 2.0.1,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Tried on Windows 10 and on Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): tried 2.0.0 and 2.0.1
- TensorFlow version (use command below):
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
```
>>> tf.repeat(['a', 'b', 'c'], repeats=[3, 0, 2], axis=0)
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
AttributeError: module 'tensorflow' has no attribute 'repeat'
```
**Describe the expected behavior**
I found that this works on 2.1.0 and 1.15.2

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
38838, 'module' object has no attribute 'tf',"its part of my code:

```
    def call(self, inputs):
        s = K.tf.gather(inputs[0], self.sel_inds[0], axis=1)
        p = K.tf.gather(inputs[1], self.sel_inds[1], axis=1)
        o = K.tf.gather(inputs[2], self.sel_inds[2], axis=1)
        return s*p*o
```

and then : 

```
  File ""/content/VidVRD-helper-master/baseline/model.py"", line 177, in call
    s = K.tf.gather(inputs[0], self.sel_inds[0], axis=1)
AttributeError: 'module' object has no attribute 'tf'
```

I use tensorflow=1.8.0 python=2.7
what should I do for fix it?"
38837,Bad accuracy results after training speech_commands example,"I trained two models with 1 wanted word (""help"") as in this [example](https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/sequences/audio_recognition.md). I've had 500 samples of my word, in right format and prepared for hashing function. First model was trained with arguments `--silence_percentage=10 --unknown_percentage=10`, second with `--silence_percentage=30 --unknown_percentage=30`. 
Output of `test_streaming_accuracy` gives following results: 
1st model - `78.0% matched, 35.5% correctly, 42.5% wrongly, 34.5% false positives`
2nd model -`85.5% matched, 37.0% correctly, 48.5% wrongly, 24.0% false positives`
Is it because of small number of samples?"
38836,NotImplementedError: Cannot convert a symbolic Tensor (truediv_2:0) to a numpy array,"**System information**
- Have I written custom code: Yes
- OS Platform and Distribution: Mac OS Catalina
- TensorFlow installed from: binary
- TensorFlow version (use command below): 2.1.0
- Python version: 3.7.0

**Describe the current behavior**

I get the following error

> NotImplementedError: Cannot convert a symbolic Tensor (truediv_2:0) to a numpy array.

When executing the following code

```
import tensorflow as tf
import tensorflow_probability as tfp

tf.config.experimental_run_functions_eagerly(True)


def get_mnist_data(normalize=True, categorize=True):
    img_rows, img_cols = 28, 28
    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()

    if tf.keras.backend.image_data_format() == 'channels_first':
        x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)
        x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)
        input_shape = (1, img_rows, img_cols)
    else:
        x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)
        x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)
        input_shape = (img_rows, img_cols, 1)

    x_train = x_train.astype('float32')
    x_test = x_test.astype('float32')

    if normalize:
        x_train /= 255
        x_test /= 255

    if categorize:
        y_train = tf.keras.utils.to_categorical(y_train)
        y_test = tf.keras.utils.to_categorical(y_test)

    return x_train, y_train, x_test, y_test, input_shape


def get_model(input_shape, num_classes=10):
    model = tf.keras.Sequential()
    model.add(tfp.layers.Convolution2DFlipout(6, input_shape=input_shape, kernel_size=3, padding=""SAME"",
                                              activation=tf.nn.relu))
    model.add(tf.keras.layers.Flatten())
    model.add(tfp.layers.DenseFlipout(num_classes))
    return model


def train():
    x_train, y_train, x_test, y_test, input_shape = get_mnist_data()

    batch_size = 64

    model = get_model(input_shape)

    model.summary()

    model.compile(loss=""categorical_crossentropy"")

    model.fit(x_train, y_train, batch_size=batch_size, epochs=1)


if __name__ == '__main__':
    train()
```

This error is caused by the statement `tf.config.experimental_run_functions_eagerly(True)`. However, if I remove that statement, I get another well known, older and extremely annoying problem/bug that is described in this other issue: https://github.com/tensorflow/tensorflow/issues/33729 that doesn't allow me to do anything for my work.

**Describe the expected behavior**

NO BUG or ERROR.

See also https://github.com/tensorflow/tensorflow/issues/38775 and https://stackoverflow.com/q/61388919/3924118."
38832,Weights mismatch in model.load_weights does not rise a ValueError,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS Mojave 10.14.6
- TensorFlow installed from (source or binary): pip
- TensorFlow version (use command below): 2.1.0
- Python version: 3.7

**Describe the current behavior**
I constructed a model using the Keras API and save the weights of the model using
the function model.save_weight for later usage.

Later I rebuilt the model and loaded the weights using model.load_weights.
If during re-building the model I change parts of the architecture, for instance the number of layers. When trying to load the weights I get the reasoble error:

    ValueError: You are trying to load a weight file containing 4 layers into a model with 5 layers.

However, when I change the number of units, no ValueError is prompted.
Note, that this only happens if I have eager mode disabled with:

    tf.compat.v1.disable_eager_execution()

If eager mode is on it correctly outputs an error.
The question is, what does TensorFlow do if there is no error prompted? How does it deal with the mismatch of weights then?

**Standalone code to reproduce the issue**

    import tensorflow as tf
     tf.compat.v1.disable_eager_execution()
     from tensorflow.keras.models import Model
     from tensorflow.keras.layers import Input, Dense, LeakyReLU

    def DenseBlock(inputs, units, layers):
        x = inputs
        for i in range(layers):
                x = Dense(units)(x)
                x = LeakyReLU()(x)
        return x

    def model_1():
            # Input
            g_input = Input(shape=(10,))

            # Dense block
            x = DenseBlock(g_input, 12, 3)

            # Final layer
            g_output = Dense(1)(x)

            G = Model(g_input, g_output, name='Model_1')
            return G

    def model_2():
            # Input
            g_input = Input((10,))

            # Dense block
            x = DenseBlock(g_input, 10, 3)

            # Final layer
            g_output = Dense(1)(x)

            G = Model(g_input, g_output, name='Model_2')
            return G

    Model1 = model_1()
    Model2 = model_2()

    Model1.save_weights(""weights_test.h5"")
    Model2.load_weights(""weights_test.h5"")

Note that if you instead change the number of layers from 3 to 4 in model_2 then you get the expected ValueError:

    ValueError: You are trying to load a weight file containing 4 layers into a model with 5 layers.

 Also If you comment out disabling eager mode it also gives you the expected error:

    ValueError: Shapes (10, 10) and (10, 12) are incompatible

"
38831,tf.keras.utils.get_file inconsistent behavior with keras.utils.get_file,"**System information**
- OS Platform and Distribution: Colab
- TensorFlow version: v2.2.0-rc3-0-gaad398b5e9 2.2.0-rc3
- Python version: 3.6.9

**Describe the current behavior**
`tensorflow.keras.utils.get_file` by default saves any file to a subdirectory of `~/.keras`. This behavior is specified [here](https://github.com/tensorflow/tensorflow/blob/v2.2.0-rc3/tensorflow/python/keras/utils/data_utils.py#L214-L215).

**Describe the expected behavior**
The function should behave the same as `keras.utils.get_file`, which uses the path specified in the `KERAS_HOME` environment variable instead of `~/.keras` if it is set. This behavior is specified [here](https://github.com/keras-team/keras/blob/2.3.1/keras/utils/data_utils.py#L172-L176)

**Standalone code to reproduce the issue**
https://colab.research.google.com/drive/1pfS-BgACkgkCQ9nXT_iz123lvdlTk9Hg

**Other info / logs**
This is relevant especially for cases where the user is not able to specify the `fname` parameter manually to set an absolute path. One example for this mentioned in #33501 are the weights downloaded by `tensorflow.keras.applications` models. In my case, the user home directory is write-protected on the compute nodes of our HPC cluster and the fallback `/tmp` also should not be used.
The issue keras-team/keras#11923 set the behavior in keras."
38830,ImportError: DLL load failed: The specified module could not be found,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: no
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10
- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:No
![tensorflow import error](https://user-images.githubusercontent.com/16195067/80086569-8825c300-8577-11ea-92c3-ffee44a67b25.png)

- **TensorFlow installed from (source or binary)**:  pip install
- **TensorFlow version (use command below)**: 2.1.0
- **Python version**:3.6.6
- **Bazel version (if compiling from source)**: --
- **GCC/Compiler version (if compiling from source)**: --
- **CUDA/cuDNN version**: --
- **GPU model and memory**: CPU -8gb Ram 
- **Exact command to reproduce**: import tensorflow

![tensorflow import error](https://user-images.githubusercontent.com/16195067/80086905-ff5b5700-8577-11ea-8817-674d31e620b6.png)

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with:

```bash
python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""
```

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.


"
38829,Tensorboard projector does not display logits when using TPUEstimator,"I develop a neural network using `TPUEstimator` in TensorFlow 2.1 to run on TPU. I try to project neural network logits using a TensorBoard as in the [proposed solution](https://github.com/tensorflow/tensorboard/issues/2471#issuecomment-580423961), but nothing is displayed. 

First, in `model_fn`, I register the projected logit (using `register_embedding`). Then I create a neural network and get logits from it (by calling `get_model`). Next, I reshape this logit (I set the name of this logit to the same as during registration) and send it to `host_call_fn`. In `host_call_fn`, I create a summary file and write the received logit into it using `tf2.summary.write (tag = 'projector', tensor = tensor_embeddings, step = gs, name = EMBEDDINGS_TENSOR_NAME)`. And nothing is displayed. Although if you initialize the random tensor in `host_call_fn`, the tensor is displayed.
![image](https://user-images.githubusercontent.com/10575983/80080378-f87a1780-856a-11ea-874c-cc13aa7bfa82.png)

Here is the complete program code:
```
import tensorflow.compat.v1 as tf
import tensorflow as tf2
from tensorboard.plugins import projector
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Conv2D, Activation, Input, BatchNormalization, Layer
from tensorflow.core.protobuf import rewriter_config_pb2
import numpy as np
import tensorflow_datasets as tfds
import os

height = 5
width = 5
n_filters = 8
use_tpu = ""COLAB_TPU_ADDR"" in os.environ
train_batch_size = 8 * (8 if use_tpu else 1)
steps = 100
learning_rate = 1e-4
iterations_per_loop = 100
log_step_count_steps = 100
use_async_checkpointing = False
EMBEDDINGS_TENSOR_NAME = 'reshaped_head_conv_0_0'
META_DATA_FNAME = 'meta.tsv'

if use_async_checkpointing:
    save_checkpoints_steps = None
else:
    save_checkpoints_steps = max(500, iterations_per_loop)
model_dir=""/content/my_storage/model""
data_dir=""/content/my_storage/datasets""
gcp_project = ""my_project""
tpu_zone = ""us-central1""

if use_tpu:
    tpu = 'grpc://' + os.environ['COLAB_TPU_ADDR']
    tpu_cluster_resolver = tf.distribute.cluster_resolver.TPUClusterResolver(
                                tpu, zone=tpu_zone, project=gcp_project)
    master = tpu_cluster_resolver.get_master()
else:
    tpu_cluster_resolver = None
    master = None

class Conv2d:
    def __init__(self, x, kernel, name, strides=(1, 1), padding='SAME', activation='relu', reuse=True):
        with tf.variable_scope(name, reuse=reuse):
            self.name = name
            self.x = tf.nn.conv2d(x, kernel, strides=strides, padding=padding, 
                                  name=name)
            bn_name = name + '_bn'
            self.x = tf.layers.batch_normalization(self.x,
                                              scale=False,
                                              name=bn_name)
            ac_name = name + '_ac'
            self.x = tf.nn.relu(self.x, name=ac_name)

    def get_x(self):
        return self.x

class OutputLayer(Layer):
    def __init__(self, name, **kwargs):
        super(OutputLayer, self).__init__(name=name, **kwargs)

    def call(self, inputs):
        return inputs

def make_input_fn(dataset_fn, params):

    def input_fn(params):
        x_train = dataset_fn()[0][""train""]
        batch_size = params[""batch_size""]
        y_true = tf.random.uniform(
                    shape=(batch_size // (8 if use_tpu else 1), 32*32*n_filters,), 
                    minval=0.0, maxval=1.0, dtype=tf.dtypes.float32, seed=7777)

        def preprocess(x, y):
            x = tf.cast(x, tf.float32) * (1. / 255)
            labels_dic = {}
            for h in range(height):
                for w in range(width):
                    labels_dic[""head_conv_{}_{}"".format(h, w)] = y_true
            return x, labels_dic

        dataset = (x_train
                    .map(preprocess, 
                         num_parallel_calls=tf.data.experimental.AUTOTUNE)
                    .repeat()
                    .shuffle(128, seed=7777, reshuffle_each_iteration=True)
                    .batch(batch_size, drop_remainder=True)
                    .prefetch(-1))
        return dataset

    return input_fn

def get_model(features, theta, input_shape, reuse):
    with tf.variable_scope('model', reuse=reuse):
        seqs = []
        i = 0
        for h in range(height):
            seq = []
            for w in range(width):
                name = ""conv_{}_{}"".format(h, w)
                if seq == []:
                    if h==0 and w==0: 
                        filters = (3, 3, 3, theta[i])
                    else:
                        filters = (3, 3, theta[i-1], theta[i])
                else:
                      filters = (3, 3, theta[i-1], theta[i])
                kernel = tf.Variable(lambda: 
                                     tf.truncated_normal(filters, stddev=5e-2), 
                                     name=name)
                if seq == []:
                    if not(h==0 and w==0): 
                        features = seqs[-1][0].get_x()
                else:
                    features = seq[-1].get_x()
                seq.append(Conv2d(
                            features,
                            kernel,
                            name=name,
                            reuse=reuse))
                i += 1
            seqs.append(seq)
        outputs = []
        heads = []
        i = 0
        for seq in seqs:
            for x in seq:
                outputs.append(OutputLayer(name=""output_""+x.name)(x.get_x()))
                heads.append(tf.estimator.RegressionHead(
                                               label_dimension=32*32*theta[i],
                                               name=""head_""+x.name))
                i += 1
        head = tf.estimator.MultiHead(heads)
    return head, outputs

def register_embedding(embedding_tensor_name, meta_data_fname, log_dir):
  if not os.path.isdir(log_dir):
     os.makedirs(log_dir)
  config = projector.ProjectorConfig()
  embedding = config.embeddings.add()
  embedding.tensor_name = embedding_tensor_name
  embedding.metadata_path = meta_data_fname
  projector.visualize_embeddings(log_dir, config)

def save_labels_tsv(labels, filepath, log_dir):
  if not os.path.isdir(log_dir):
     os.makedirs(log_dir)
  with open(os.path.join(log_dir, filepath), 'w') as f:
    for label in labels:
      f.write('{}\n'.format(label))

def model_fn(features, labels, mode, params):
    def host_call_fn(gs, loss, lr, tensor_embeddings):
        gs = gs[0]

        with tf2.summary.create_file_writer(
            model_dir,
            max_queue=iterations_per_loop).as_default():
          with tf2.summary.record_if(True):
            tf2.summary.write(tag='projector', tensor=tensor_embeddings,
                              step=gs, name=EMBEDDINGS_TENSOR_NAME)
            tf2.summary.scalar('loss', loss[0], step=gs)
            tf2.summary.scalar('learning_rate', lr[0], step=gs)

          return tf.summary.all_v2_summary_ops()

    batch_size = params['batch_size']

    theta = width * height * [n_filters]

    assert EMBEDDINGS_TENSOR_NAME == ""reshaped_head_conv_0_0""
    register_embedding(""reshaped_head_conv_0_0"", META_DATA_FNAME, model_dir)

    head, logits_train = get_model(features, theta, params['input_shape'], 
                                   reuse=False)
    logits_train_dic = {}
    i = 0
    for h in range(height):
        for w in range(width):
            logits_train_dic[""head_conv_{}_{}"".format(h, w)] = \
                tf.reshape(logits_train[i], (batch_size, 32*32*8,), 
                           name=""reshaped_head_conv_{}_{}"".format(h, w))
            i += 1
    pred_classes = tf.argmax(logits_train, axis=1)
    if mode == tf.estimator.ModeKeys.PREDICT:
        return tf.estimator.tpu.TPUEstimatorSpec(mode, predictions=pred_classes)

    new_labels = {}
    for key in labels:
        new_labels[key] = labels[key][0]
    loss = 0.0
    for key in logits_train_dic:
        logit_train = logits_train_dic[key]
        loss += tf.square(labels[key]-logit_train)
    loss_op = tf.reduce_mean(loss)

    optimizer = tf.train.AdamOptimizer(learning_rate=params['learning_rate'])
    if params['use_tpu']:
        optimizer = tf.tpu.CrossShardOptimizer(optimizer)
    train_op_fn = lambda loss_op: optimizer.minimize(
                                  loss_op,
                                  global_step=tf.train.get_global_step())

    gs_t = tf.reshape(tf.train.get_global_step(), [1])
    loss_t = tf.reshape(loss_op, [1])
    lr_t = tf.reshape(params['learning_rate'], [1])

    y = np.zeros((batch_size,), np.int32)
    save_labels_tsv(y, META_DATA_FNAME, model_dir)

    host_call = (host_call_fn, [gs_t, loss_t, lr_t, logits_train_dic[""head_conv_0_0""]])
                
    estim_specs = tf.estimator.tpu.TPUEstimatorSpec(
                  mode=mode, loss=loss_op, train_op=train_op_fn(loss_op), 
                  host_call=host_call)
    return estim_specs

tf.logging.set_verbosity(tf.logging.INFO)
tf.disable_v2_behavior()

dataset_fn = lambda: tfds.load(name='cifar10', with_info=True, as_supervised=True, 
                               try_gcs=True, data_dir=data_dir)
info = dataset_fn()[1]
n_samples = info.splits['train'].get_proto().statistics.num_examples
n_classes = info.features['label'].num_classes
train_shape = info.features['image'].shape
tf.config.set_soft_device_placement(True)

config = tf.estimator.tpu.RunConfig(
              master=master,
              model_dir=model_dir,
              save_checkpoints_steps=save_checkpoints_steps,
              log_step_count_steps=log_step_count_steps,
              session_config=tf.ConfigProto(
                  graph_options=tf.GraphOptions(
                      rewrite_options=rewriter_config_pb2.RewriterConfig(
                          disable_meta_optimizer=True))),
              tpu_config=tf.estimator.tpu.TPUConfig(
                  iterations_per_loop=iterations_per_loop,
                  per_host_input_for_training=tf.estimator.tpu.InputPipelineConfig
                  .PER_HOST_V2))

params = {
    'use_tpu': use_tpu,
    'input_shape': train_shape,
    'learning_rate': learning_rate
}

model = tf.estimator.tpu.TPUEstimator(
          model_fn, use_tpu=use_tpu,
          config=config,
          train_batch_size=train_batch_size,
          params=params)
model.train(make_input_fn(dataset_fn, params), steps=steps)
```
And [here](https://colab.research.google.com/gist/Kirill94a/7ab0a13a2bd836937c3be323c2287cdb/tensorboard-and-tpuestimator-issue.ipynb) is Colab Notebook (runs on CPU, since when working on TPU it is impossible to save tensorboard logs to a local disk, but the issue is the same for both CPU and TPU).

How to display logits in Tensorboard projector?"
38828,AutoGraph and tf.function are not working for TPU,"It seems that TPU only supports keras fit() function, but unable to use functions from tf.function and autographs.

Tensorflow version 2.1
python version 3.6

Issue can be reproduced in colab."
38827,Extremely slow retraining after loading model,"When it comes to loading a model from a `.h5` file, and fitting more data to it- the training process becomes incredibly slow compared to initial training. *Slow as in 10 seconds to 43 seconds per epoch*

_[https://www.tensorflow.org/install/gpu](https://www.tensorflow.org/install/gpu) was followed 04/22/2020_
I use pip, I'm not using Anaconda, etc. Nor am I using a notebook.

- OS = Windows 10 x64
- Python version = 3.7 
- Tensorflow = 2.1.0
- CudaToolkit =  10.1
- cuDNN SDK = 7.6
- NVIDIA GPU driver = 445.75

_The following I'm assuming came with tensorflow because I didn't install them myself:_

- Keras-Applications = 1.0.8
- Keras-Preprocessing = 1.1.0





















_The code below trains a model, saves it, deletes it then loads the previously saved model to train again_

```
# Imports
import pandas as pd
import numpy as np

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, LSTM, BatchNormalization
from tensorflow.keras.models import load_model



# Create dummy dataset
dummydata = pd.DataFrame(np.random.random_sample((10000, 51)))

predictors_list = dummydata.columns.tolist()
predictors_list.remove(predictors_list[-1])

X_rgs = dummydata[predictors_list]
y_rgs = dummydata[dummydata.columns[-1]]




# Train, Test split
train_length = int(len(dummydata)*0.70)
X_rgs_train = X_rgs[:train_length]
X_rgs_test = X_rgs[train_length:]
y_rgs_train = y_rgs[:train_length]
y_rgs_test = y_rgs[train_length:]




# pandas to numpy
X_rgs_train = X_rgs_train.to_numpy()
X_rgs_test = X_rgs_test.to_numpy()



# Reshape data
y_rgs_train = y_rgs_train.values
y_rgs_train = y_rgs_train.reshape(len(y_rgs_train), 1)
y_rgs_train = np.ravel(y_rgs_train)

y_rgs_test = y_rgs_test.values
y_rgs_test = y_rgs_test.reshape(len(y_rgs_test), 1)
y_rgs_test = np.ravel(y_rgs_test)


X_train_lstm = []
y_train_lstm = []

for i in range(60, X_rgs_train.shape[0]):
    X_train_lstm.append(X_rgs_train[i-60:i])
    y_train_lstm.append(X_rgs_train[i, 0])


len_y_train_lstm = len(y_train_lstm) 
y_train_lstm = y_rgs_train[:len_y_train_lstm]
X_train_lstm, y_train_lstm = np.array(X_train_lstm), np.array(y_train_lstm)


X_test_lstm = []
y_test_lstm = []

for i in range(60, X_rgs_test.shape[0]):
    X_test_lstm.append(X_rgs_test[i-60:i])
    y_test_lstm.append(X_rgs_test[i, 0])

len_y_test_lstm = len(y_test_lstm) 
y_test_lstm = y_rgs_test[:len_y_test_lstm]
X_test_lstm, y_test_lstm = np.array(X_test_lstm), np.array(y_test_lstm)





# Model architecture and vars
EPOCHS = 1 
BATCH_SIZE = 32 

model = Sequential()
model.add(LSTM(128, input_shape=(X_train_lstm.shape[1:]), return_sequences=True))
model.add(Dropout(0.2))
model.add(BatchNormalization()) 

model.add(LSTM(128, return_sequences=True))
model.add(Dropout(0.2))
model.add(BatchNormalization())

model.add(LSTM(128, return_sequences=True))
model.add(Dropout(0.2))
model.add(BatchNormalization())

model.add(LSTM(128))
model.add(Dropout(0.5))
model.add(BatchNormalization())

model.add(Dense(1))

model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mean_absolute_error'])




model.fit(X_train_lstm, y_train_lstm, batch_size=BATCH_SIZE, epochs=EPOCHS, validation_data=(X_test_lstm, y_test_lstm)) # fit
model.save(""model_ISSUE.h5"") # save entire model


del model 


model = load_model('model_ISSUE.h5') # load entire model
model.fit(X_train_lstm, y_train_lstm, batch_size=BATCH_SIZE, epochs=EPOCHS, validation_data=(X_test_lstm, y_test_lstm)) # fit

```

Output:
```
2020-04-29 22:15:21.184146: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll
2020-04-29 22:15:23.126105: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library nvcuda.dll
2020-04-29 22:15:23.151009: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties:
pciBusID: 0000:09:00.0 name: GeForce GTX 1060 6GB computeCapability: 6.1
coreClock: 1.835GHz coreCount: 10 deviceMemorySize: 6.00GiB deviceMemoryBandwidth: 178.99GiB/s
2020-04-29 22:15:23.155805: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll
2020-04-29 22:15:23.161197: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll
2020-04-29 22:15:23.166549: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_10.dll
2020-04-29 22:15:23.170036: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_10.dll
2020-04-29 22:15:23.176026: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_10.dll
2020-04-29 22:15:23.180542: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_10.dll
2020-04-29 22:15:23.191606: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll
2020-04-29 22:15:23.194041: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-04-29 22:15:23.196244: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2
2020-04-29 22:15:23.199798: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties:
pciBusID: 0000:09:00.0 name: GeForce GTX 1060 6GB computeCapability: 6.1
coreClock: 1.835GHz coreCount: 10 deviceMemorySize: 6.00GiB deviceMemoryBandwidth: 178.99GiB/s
2020-04-29 22:15:23.204240: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll
2020-04-29 22:15:23.206834: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll
2020-04-29 22:15:23.208947: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_10.dll
2020-04-29 22:15:23.210997: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_10.dll
2020-04-29 22:15:23.213076: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_10.dll
2020-04-29 22:15:23.215705: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_10.dll
2020-04-29 22:15:23.218272: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll
2020-04-29 22:15:23.221158: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-04-29 22:15:23.773119: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-04-29 22:15:23.775514: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0
2020-04-29 22:15:23.776821: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N
2020-04-29 22:15:23.778805: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 4702 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1060 6GB, pci bus id: 0000:09:00.0, compute capability: 6.1)

Train on 6940 samples, validate on 2940 samples
2020-04-29 22:15:28.206970: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll
2020-04-29 22:15:28.443339: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll
6940/6940 [==============================] - 10s 1ms/sample - loss: 0.8105 - mean_absolute_error: 0.6987 - val_loss: 0.1208 - val_mean_absolute_error: 0.2886

Train on 6940 samples, validate on 2940 samples
6940/6940 [==============================] - 43s 6ms/sample - loss: 0.2288 - mean_absolute_error: 0.3845 - val_loss: 0.0986 - val_mean_absolute_error: 0.2647
```
As seen above, it becomes incredibly slow to retrain the model after it's loaded. _(10s --> 43s)_


I've seen one other person seem to have this problem and their 'solution' was to ""swap to pytorch""

How can I go about dealing with this issue?

Regards,

"
38826,Failed to load the native TensorFlow runtime.,"I have installed Tensorflow successfully on my computer but can not load it to use. Please help. Below is stack trace. Many thanks.

Microsoft Windows [Version 10.0.18362.778]
(c) 2019 Microsoft Corporation. All rights reserved.

C:\Users\B>python
Python 3.7.6 (tags/v3.7.6:43364a7ae0, Dec 19 2019, 00:42:30) [MSC v.1916 64 bit (AMD64)] on win32
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import tensorflow as tf
Traceback (most recent call last):
  File ""C:\Users\B\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\B\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\B\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\B\AppData\Local\Programs\Python\Python37\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\B\AppData\Local\Programs\Python\Python37\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: A dynamic link library (DLL) initialization routine failed.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""C:\Users\B\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow\__init__.py"", line 101, in <module>
    from tensorflow_core import *
  File ""C:\Users\B\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow_core\__init__.py"", line 40, in <module>
    from tensorflow.python.tools import module_util as _module_util
  File ""C:\Users\B\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow\__init__.py"", line 50, in __getattr__
    module = self._load()
  File ""C:\Users\B\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow\__init__.py"", line 44, in _load
    module = _importlib.import_module(self.__name__)
  File ""C:\Users\B\AppData\Local\Programs\Python\Python37\lib\importlib\__init__.py"", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""C:\Users\B\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow_core\python\__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\Users\B\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 74, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""C:\Users\B\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\B\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\B\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\B\AppData\Local\Programs\Python\Python37\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\B\AppData\Local\Programs\Python\Python37\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: A dynamic link library (DLL) initialization routine failed.


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/errors

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.
>>>"
38825,Why the output of my tflite model running on the CPU and GPU of the Android phone is not the same,"**System information**
- windows10:
- python3.7:
- tensorflow-gpu 2.1.0 installed via pip:
- androidstudio 3.6.2:
- org.tensorflow:tensorflow-lite-gpu:2.1.0:
- org.tensorflow:tensorflow-lite:2.1.0:

**As the title says, the tflite model I converted runs on the CPU of the Android phone and the result on the GPU is inconsistent. I tried two Android phones with the same problem (SoC is Snapdragon 660 / Snapdragon 845)
The result of the model running on the Android CPU is consistent with that on the computer. I think this should explain that the model itself is not a problem?
`https://github.com/TCBocean/tflite_test`
This is the code of my Android Studio project. This is a very simple project. I use Log.e to view the output.
Among them, the 52 ~ 53 behavior of MainActivity.java opens the GpuDelegate, and then deletes it to get the CPU operation result.
My GPU operation results are:
```
2020-04-23 14: 24: 01.682 9335-9335 / com.stars.tflite_test1 E / 1111: output1: 1.2991362E28
2020-04-23 14: 24: 01.682 9335-9335 / com.stars.tflite_test1 E / 1111: output2: Infinity
```
My CPU operation result is
```
2020-04-23 14: 25: 59.974 10058-10058 / com.stars.tflite_test1 E / 1111: output1: 378560.0
2020-04-23 14: 25: 59.974 10058-10058 / com.stars.tflite_test1 E / 1111: output2: 6.6762416E10
```
It can be seen that there are obvious differences
Below is my model generation code:**

```
import tensorflow as tf

class test_model(tf.keras.Model):
    def __init__(self):
        super(test_model, self).__init__()
        self.conv1 = tf.keras.layers.Conv2D(filters=40, kernel_size=3, padding=""SAME"", kernel_initializer=tf.ones)
        self.conv2 = tf.keras.layers.Conv2D(filters=56, kernel_size=3, padding=""SAME"", kernel_initializer=tf.ones)
        self.conv3 = tf.keras.layers.Conv2D(filters=98, kernel_size=3, padding=""SAME"", kernel_initializer=tf.ones)
        self.conv4 = tf.keras.layers.Conv2D(filters=33, kernel_size=3, padding=""SAME"", kernel_initializer=tf.ones)
        self.conv5 = tf.keras.layers.Conv2D(filters=14, kernel_size=3, padding=""SAME"", kernel_initializer=tf.ones)

    @tf.function
    def call(self, inputs):
        output1 = self.conv1(inputs)
        output1 = self.conv2(output1)
        output_temp = output1
        output1 = self.conv4(output1)
        output2 = self.conv3(output1)
        output2 = tf.concat([output2, output_temp], axis=-1)
        output2 = self.conv5(output2)

        return output1, output2


model = test_model()
test_input = tf.ones((1, 6, 6, 1))

tf.keras.backend.set_learning_phase(False)
test_output1 = model(test_input)
for output in test_output1:
    print(output)

model._set_inputs(inputs=test_input)

converter = tf.lite.TFLiteConverter.from_keras_model(model)
tflite_model = converter.convert()
open(""./save6/converted_model.tflite"", ""wb"").write(tflite_model)
```

Can anyone help me see what went wrong?
thank you very much : )


"
38824,What is the minimum subset of cuda toolkit to install for tensorflow gpu to work?,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- TensorFlow installed from (source or binary): binary
- TensorFlow version: 2.1.0
- Python version: 3.7.7
- Installed using virtualenv? pip? conda?: pip
- CUDA/cuDNN version: Cuda 10.1 && cuDNN 7.6.5
- GPU model and memory: Nvidia Geforce GTX 950M 2G



**Describe the problem**
Actually, there is not much of a problem. I'm just wondering what are the necessary parts for tensorflow gpu to work. I guess a subset of CUDA runtime dynamic libraries, CUPTI, and cuDNN runtime dynamic library should suffice? However, I failed to find detailed information about this in the installation guide."
38823,Could not import Tensorflow?,"In my machine Tensorflow 2.1.0 is OK. The tensorflow 2.1.0 was installed using pip.
But Tensorflow 1.3.0 is not working after installing using pip in different environment.
It gives the following error: 
```
Traceback (most recent call last):
  File ""C:\Users\Ibrahim Khalilullah\.conda\envs\MaskrcnnTF1point3\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 18, in swig_import_helper
    return importlib.import_module(mname)
  File ""C:\Users\Ibrahim Khalilullah\.conda\envs\MaskrcnnTF1point3\lib\importlib\__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""<frozen importlib._bootstrap>"", line 994, in _gcd_import
  File ""<frozen importlib._bootstrap>"", line 971, in _find_and_load
  File ""<frozen importlib._bootstrap>"", line 955, in _find_and_load_unlocked
  File ""<frozen importlib._bootstrap>"", line 658, in _load_unlocked
  File ""<frozen importlib._bootstrap>"", line 571, in module_from_spec
  File ""<frozen importlib._bootstrap_external>"", line 922, in create_module
  File ""<frozen importlib._bootstrap>"", line 219, in _call_with_frames_removed
ImportError: DLL load failed: The specified module could not be found.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\Ibrahim Khalilullah\.conda\envs\MaskrcnnTF1point3\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 41, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\Ibrahim Khalilullah\.conda\envs\MaskrcnnTF1point3\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 21, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\Ibrahim Khalilullah\.conda\envs\MaskrcnnTF1point3\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 20, in swig_import_helper
    return importlib.import_module('_pywrap_tensorflow_internal')
  File ""C:\Users\Ibrahim Khalilullah\.conda\envs\MaskrcnnTF1point3\lib\importlib\__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
ModuleNotFoundError: No module named '_pywrap_tensorflow_internal'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""C:\Users\Ibrahim Khalilullah\.conda\envs\MaskrcnnTF1point3\lib\site-packages\tensorflow\__init__.py"", line 24, in <module>
    from tensorflow.python import *
  File ""C:\Users\Ibrahim Khalilullah\.conda\envs\MaskrcnnTF1point3\lib\site-packages\tensorflow\python\__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\Users\Ibrahim Khalilullah\.conda\envs\MaskrcnnTF1point3\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 52, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""C:\Users\Ibrahim Khalilullah\.conda\envs\MaskrcnnTF1point3\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 18, in swig_import_helper
    return importlib.import_module(mname)
  File ""C:\Users\Ibrahim Khalilullah\.conda\envs\MaskrcnnTF1point3\lib\importlib\__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""<frozen importlib._bootstrap>"", line 994, in _gcd_import
  File ""<frozen importlib._bootstrap>"", line 971, in _find_and_load
  File ""<frozen importlib._bootstrap>"", line 955, in _find_and_load_unlocked
  File ""<frozen importlib._bootstrap>"", line 658, in _load_unlocked
  File ""<frozen importlib._bootstrap>"", line 571, in module_from_spec
  File ""<frozen importlib._bootstrap_external>"", line 922, in create_module
  File ""<frozen importlib._bootstrap>"", line 219, in _call_with_frames_removed
ImportError: DLL load failed: The specified module could not be found.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\Ibrahim Khalilullah\.conda\envs\MaskrcnnTF1point3\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 41, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\Ibrahim Khalilullah\.conda\envs\MaskrcnnTF1point3\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 21, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\Ibrahim Khalilullah\.conda\envs\MaskrcnnTF1point3\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 20, in swig_import_helper
    return importlib.import_module('_pywrap_tensorflow_internal')
  File ""C:\Users\Ibrahim Khalilullah\.conda\envs\MaskrcnnTF1point3\lib\importlib\__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
ModuleNotFoundError: No module named '_pywrap_tensorflow_internal'


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/install_sources#common_installation_problems

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.
>>>

```
Previously I can run both of them (Tensorflow 2.1.0 and Tensorflow 1.3.0). However, I changed some software (reinstalling anaconda and some packages with different environments).
I want to use both of them (Tensorflow 2.1.0 and Tensorflow 1.3.0).
Is there any solution please?

My working platform:
Windows 10
Anaconda 3
python 3.6
Microsoft Visual C++ Redistributable for Visual Studio 2015-2019




"
38822,Could not load dynamic library 'cudart64_101.dll'; dlerror: cudart64_101.dll not found,"OS : Windows
Error:
C:\Users\OneDrive\Desktop\Cheque Clearance Project\2 Bank-Cheque-OCR-master\Bank-Cheque-OCR-master\scripts>python main.py
Using TensorFlow backend.
2020-04-22 21:10:43.537143: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'cudart64_101.dll'; dlerror: cudart64_101.dll not found
2020-04-22 21:10:43.546929: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2020-04-22 21:10:45.486138: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library nvcuda.dll
2020-04-22 21:10:46.270844: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties:
pciBusID: 0000:02:00.0 name: GeForce GTX 960M computeCapability: 5.0
coreClock: 1.176GHz coreCount: 5 deviceMemorySize: 4.00GiB deviceMemoryBandwidth: 74.65GiB/s
2020-04-22 21:10:46.283679: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'cudart64_101.dll'; dlerror: cudart64_101.dll not found
2020-04-22 21:10:46.290302: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'cublas64_10.dll'; dlerror: cublas64_10.dll not found
2020-04-22 21:10:46.296248: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'cufft64_10.dll'; dlerror: cufft64_10.dll not found
2020-04-22 21:10:46.303130: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'curand64_10.dll'; dlerror: curand64_10.dll not found
2020-04-22 21:10:46.309457: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'cusolver64_10.dll'; dlerror: cusolver64_10.dll not found
2020-04-22 21:10:46.317877: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'cusparse64_10.dll'; dlerror: cusparse64_10.dll not found
2020-04-22 21:10:46.325132: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'cudnn64_7.dll'; dlerror: cudnn64_7.dll not found
2020-04-22 21:10:46.330768: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1592] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2020-04-22 21:10:46.360475: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2
2020-04-22 21:10:46.368318: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-04-22 21:10:46.379055: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]
Traceback (most recent call last):
File ""main.py"", line 13, in
if img_color.ndim == 3:
AttributeError: 'NoneType' object has no attribute 'ndim'

Is there any solution for this,please do also mention the steps

Regards"
38821,TF 2.1.0 savedModel input_fn from TF 1.15.x,"TensorFlow installed from : binary

TensorFlow version : 2.1.0

Python version: 3.7.3






```
import numpy as np
import tensorflow.compat.v1 as tf
tf.disable_v2_behavior()


print(tf.__version__)

############### Function we wrote ############

@tf.function
def tile_nd_ragged2(a, b):
  # Need a sentinel, otherwise it's hard to give it the initial shape we need.
  # We'll drop the sentinel at the end.
  acc = tf.ragged.constant([[[]]], dtype=a.dtype)
  
  print('acc is', acc)
  # Work one row at a time...
  # for i1 in tf.range(len(a.nested_row_lengths()[0])):    # Should be able to write `for a1, b1 in zip(a, b)` soon.
  def outer_loop_test(i1, _):
    return i1 < len(a.nested_row_lengths()[0])

  def outer_loop_body(i1, acc):
    
    a1 = a[i1]
    b1 = b[i1]

    # If the components have variable length, we can't use a TensorArray anymore,
    # so use a RaggedTensor instead.
    acc1 = tf.ragged.constant([[]], dtype=a.dtype)
    def loop_test(i2, _):
      shape = None
      if isinstance(a1, tf.RaggedTensor):
        print("" --- ragged --- "")
        print(a1)
        print(shape)
        shape = tf.shape(a1.nested_row_lengths()[0])[0]
      else:
        print("" --- tensor --- "")
        print(a1)
        
        shape = tf.shape(a1)[0]
        print(tf.shape(a1))
        print(shape)

      return i2 < shape
      #return i2 < tf.cast(a1.nested_row_lengths()[0][i1], tf.int32)
    def loop_body(i2, acc1):
      #print(a1[i2])
      a2 = a1[i2]
      b2 = b1[i2]

      for _ in range(len(b2)):
        acc1 = tf.concat([acc1, tf.expand_dims(a2, 0)], axis=0)
      return i2 + 1, acc1

    _, acc1 = tf.while_loop(loop_test, loop_body, [0, acc1],shape_invariants=[tf.TensorShape([]), tf.TensorShape([None, None])])
    acc1 = acc1[1:]  # Drop the sentinel.
    acc = tf.concat([acc, tf.expand_dims(acc1, 0)], axis=0)    # Add the row to the final result.

    return i1 + 1, acc

  _, acc = tf.while_loop(
      outer_loop_test, outer_loop_body,
      [0, acc],
      shape_invariants=[
                        tf.TensorShape([]),
                        tf.TensorShape([None, None, None])
                        ]
      )
  acc = acc[1:]  # Drop the sentinel.
  return acc



###############  export_input_fn ############


def export_input_fn():
    serialized_tf_example = tf.placeholder(dtype=tf.string, shape=(None), name =""text"") 

    s1Split = tf.strings.split([serialized_tf_example],result_type=""RaggedTensor"")
    s1Split = tf.strings.split(s1Split,sep='@',result_type=""RaggedTensor"")
    result  = tile_nd_ragged2(s1Split,s1Split)
    result_tf = result.to_tensor()[:1,:,:][0][0]
    #result_tf = result.to_tensor()
    result_int = tf.strings.to_number(result_tf,out_type=tf.int32)

    features ={}
    features[""f1""]=result_int ### this will be tf.Tensor([1], shape=(1,), dtype=int32)
    
    reciever_tensor = {""text"": serialized_tf_example}
    print(reciever_tensor)   
    return tf.estimator.export.ServingInputReceiver(features, reciever_tensor)

########### Training ###############
x_feature = tf.feature_column.numeric_column('f1')
train_input_fn = tf.compat.v1.estimator.inputs.numpy_input_fn(
      x = {""f1"": np.array([1., 2., 3., 4.])},      # Input features
      y = np.array([1.5, 3.5, 5.5, 7.5]),         # true labels
      batch_size=1,
      num_epochs=1,
      shuffle=True)

regressor = tf.estimator.LinearRegressor(feature_columns=[x_feature])
regressor.train(input_fn=train_input_fn, steps=10)

samples = np.array([1])
predict_input_fn = tf.compat.v1.estimator.inputs.numpy_input_fn(x={""f1"": samples},num_epochs=1,shuffle=False)
predictions = list(regressor.predict(input_fn=predict_input_fn))
print(""---------"")
print(predictions)


print(""--------- training finished ---------"")


regressor.export_saved_model(""./model"",export_input_fn,as_text=False)
```

I have above code originally written in TF 1.15.0 , currently i am trying to port it to TF 2.1.0. I am basically trying to generate savedModel using customized feature transformation as above . When I run the above code it works well but its due to `tf.disable_v2_behavior()` .

I am currently trying to comment out 
```
import tensorflow.compat.v1 as tf
tf.disable_v2_behavior()
```
and use 

```
import tensorflow  as tf
```
and try to convert  to TF 2.1.0 . 

Now TF 2.1.0 has no `tf.placeholder`  so i tried converting it using 
```serialized_tf_example = tf.placeholder(dtype=tf.string, shape=(None), name =""text"") ```

and got error 
```TypeError: Expected int32, got None of type 'NoneType' instead```  at```serialized_tf_example = tf.Variable(tf.zeros([None]), dtype=tf.string, name='text')```

This might not be the right way to do it but all i want is to get savedModel having feature processing inside savedModel in TF 2.1.0 . 

Any help will be appreciated. "
38818,Documentation updates,"ksizes should be sizes on:
https://github.com/tensorflow/tensorflow/blob/e5bf8de410005de06a7ff5393fafdf832ef1d4ad/tensorflow/python/ops/array_ops.py#L4806

also on lines 4805 and 4835 the call needs updating to

`tf.image.extract_patches`

https://github.com/tensorflow/tensorflow/blob/e5bf8de410005de06a7ff5393fafdf832ef1d4ad/tensorflow/python/ops/array_ops.py#L4805


https://github.com/tensorflow/tensorflow/blob/e5bf8de410005de06a7ff5393fafdf832ef1d4ad/tensorflow/python/ops/array_ops.py#L4835

"
38817,merge.concatenate layer not connected to input layer. Summary not printing correct total number of weights.,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): 
- TensorFlow version (use command below): 2.1.0
- Python version: 3.6.8
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**

I am working on training a classifier to classify two distributions with an adversary that learns the noise from the distributions. Model.summary() indicates that my adversary model is not connected to input. merge.concatenate layer seems to break the models continuity but I do not understand why.  Loss is not decreasing when I train this model. The combined model consists of 2 models (classifier and adversary) with 501 and 1276 weights respectively. Total number of trainable weights listed by model.summary is 1276 instead of 1777. 

**Describe the expected behavior**

Loss should decrease during training, combined model should have 1777 weights and adversary model should have an entry in summary.connected to.

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

N = 62500

# Make data - 2 class that are 2D gaussian distributed. Gaussian noise affecting y coord of Y=1 class
cov0 = np.array([[1,-0.5],[-0.5,1]])
cov1 = np.array([[1,0],[0,1]])

train_data0 = np.random.multivariate_normal([0,0],cov0,N)
train_labels0 = np.zeros((N,1))
train_data1 = np.random.multivariate_normal([1,1],cov1,N)
train_labels1 = np.ones((N,1))
train_z = np.random.normal(0,1,N*2)
train_data1[:,1] = train_data1[:,1]+train_z[N:]
#train_z[:N] = 0
train_data = np.vstack([train_data0,train_data1])
train_labels = np.append(train_labels0,train_labels1)

#shuffle data
indices = np.random.permutation(len(train_data))
train_data = train_data[indices]
train_labels =train_labels[indices]
train_z = train_z[indices]

#train test split
train_data, valid_data, train_labels, valid_labels, train_z, valid_z = train_test_split(train_data,train_labels,train_z,test_size=50000)

#Models 
inputs = Input(shape=(train_data.shape[1],))

# Classifier model
Dx = Dense(20, activation=""tanh"")(inputs)
Dx = Dense(20, activation=""relu"")(Dx)
Dx = Dense(1, activation=""sigmoid"")(Dx)
f = Model([inputs],[Dx])

#adversary model
from keras.layers.merge import concatenate
out = f(inputs)
out = Dense(20,activation=""relu"")(out)
out = Dense(20,activation=""relu"")(out)
mu = Dense(5,activation=""linear"")(out)
sigma = Dense(5,activation=backend.exp)(out)
pi = Dense(5,activation=""softmax"")(out)
out = concatenate([mu,sigma,pi])
r = Model([inputs],[out]) 

# Loss for r 
def rloss(lam):
  def loss_r(y_true,y_pred):
    #y_true = y_true.flatten()
    mu = y_pred[:,:5]
    sig = y_pred[:,5:10]
    pi = y_pred[:,10:]
    pdf = 0
    for i in range(5):
      pdf += pi[:,i] *(1.0/(sig[:,i]*np.sqrt(2.0*np.pi)))*backend.exp(-((y_true-mu[:,i])**2)/(2.0*(sig[:,i]**2)))
    return lam * tf.math.reduce_mean(-backend.log(pdf))
  return loss_r


f.compile(loss = backend.binary_crossentropy, optimizer = SGD())

#combined model
adv1 = Model([inputs], [f(inputs), r(inputs)])
adv1.compile(loss=[backend.binary_crossentropy,rloss(-50)],optimizer=SGD(momentum=0.0))

# adversary
adv2 = Model(inputs,[r(inputs)])
adv2.compile(loss=[rloss(1.0)],optimizer=SGD(momentum=0.0))

# adv1 summary total trainable params != sum of params of individual models
adv1.summary()

#adv2 missing ""connected to""
adv2.summary()

#Loss of adversary does not decrease as expected
f.trainable = False
r.trainable = True
adv2.fit(train_data,train_z,epochs=20)

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

I am trying to reproduce the model of the paper. Paper's code is on github: https://github.com/glouppe/paper-learning-to-pivot/blob/master/code/Toy.ipynb
"
38816,"Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: ADD, CAST, EXPAND_DIMS, FILL, FULLY_CONNECTED, GATHER, LOGISTIC, MUL, NOT_EQUAL, PACK, RESHAPE, SHAPE, SOFTMAX, SPLIT, STRIDED_SLICE, TANH, TRANSPOSE, ZEROS_LIKE. Here is a list of operators for which you will need custom implementations: TensorListFromTensor, TensorListReserve, TensorListStack, While.","**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- TensorFlow installed from (source or binary):
- TensorFlow version (or github SHA if from source):


**Provide the text output from tflite_convert**

```
# Copy and paste here
```

**Standalone code to reproduce the issue** 
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

Also, please include a link to a GraphDef or the model if possible.

**Any other info / logs**

Include any logs or source code that would be helpful to diagnose the problem.
If including tracebacks, please include the full traceback. Large logs and files
should be attached.
"
38815,Docker Image tensorflow:latest-gpu contains 450 MB of pip cache under root directory,"Docker Image tensorflow:latest-gpu contains 450+ MB of pip cache under root user's home directory.

Steps to reproduce:

    docker run --rm -it docker.apple.com/tensorflow/tensorflow:latest-gpu bash

then inside the container:

    root@9eae8825ebd9:/# cd 
    root@9eae8825ebd9:~# du -h -d 1
    458M	./.cache
    458M	.

I noticed this while pulling the tensorflow:2.1.0-gpu-py3 Image and then pulled latest to see if the issue had been fixed since...

Other images may be affected as well, I haven't verified."
38814,EagerTensor - Tensorboard & Projector.,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- I have used a combination of some custom code with tensorflow provided scripts. 
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): OSX 10.15.4
- TensorFlow installed from (source or binary): pip 
- TensorFlow version (use command below): >>> '2.1.0'
- Python version: 3.7.7
- GPU model and memory: Radeon Pro 560X 4GB


**Describe the current behavior**
I recieve an error of trying to capture EagerTensor.

:168] XLA service 0x7fd4c0649fd0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-04-22 13:05:21.461935: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
Traceback (most recent call last):
  File ""unstructuredData.py"", line 32, in <module>
    saver = tf.compat.v1.train.Saver([tf_data])
  File ""/usr/local/lib/python3.7/site-packages/tensorflow_core/python/training/saver.py"", line 828, in __init__
    self.build()
  File ""/usr/local/lib/python3.7/site-packages/tensorflow_core/python/training/saver.py"", line 840, in build
    self._build(self._filename, build_save=True, build_restore=True)
  File ""/usr/local/lib/python3.7/site-packages/tensorflow_core/python/training/saver.py"", line 878, in _build
    build_restore=build_restore)
  File ""/usr/local/lib/python3.7/site-packages/tensorflow_core/python/training/saver.py"", line 505, in _build_internal
    save_tensor = self._AddSaveOps(filename_tensor, saveables)
  File ""/usr/local/lib/python3.7/site-packages/tensorflow_core/python/training/saver.py"", line 206, in _AddSaveOps
    save = self.save_op(filename_tensor, saveables)
  File ""/usr/local/lib/python3.7/site-packages/tensorflow_core/python/training/saver.py"", line 110, in save_op
    tensors.append(spec.tensor)
  File ""/usr/local/lib/python3.7/site-packages/tensorflow_core/python/training/saving/saveable_object.py"", line 52, in tensor
    return self._tensor() if callable(self._tensor) else self._tensor
  File ""/usr/local/lib/python3.7/site-packages/tensorflow_core/python/training/saving/saveable_object_util.py"", line 91, in f
    x = v.read_value()
  File ""/usr/local/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py"", line 635, in read_value
    value = self._read_variable_op()
  File ""/usr/local/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py"", line 613, in _read_variable_op
    self._dtype)
  File ""/usr/local/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_resource_variable_ops.py"", line 483, in read_variable_op
    ""ReadVariableOp"", resource=resource, dtype=dtype, name=name)
  File ""/usr/local/lib/python3.7/site-packages/tensorflow_core/python/framework/op_def_library.py"", line 468, in _apply_op_helper
    preferred_dtype=default_dtype)
  File ""/usr/local/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py"", line 1280, in convert_to_tensor
    raise RuntimeError(""Attempting to capture an EagerTensor without ""
RuntimeError: Attempting to capture an EagerTensor without building a function.


**Describe the expected behavior**
Tensorflow runs and saves the logs so tensorboard may render the results.

 
**Standalone code to reproduce the issue**
```
import os
import tensorflow as tf
import numpy as np 
import pandas as pd 
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA


##Global Varables 
PATH = os.getcwd()

##Log path for embedding
LOG_DIR = PATH + '/project-tensorboard/log-1/'

##load Data
df = pd.read_csv(""us.csv"", index_col=0)

#Load the metadata
metadata = os.path.join(LOG_DIR, 'df_labels.tsv')

#Generating PCA
pca = PCA(n_components=2, random_state=123, svd_solver='auto')

df_pca = pd.DataFrame(pca.fit_transform(df))
df_pca = df_pca.values

#Tensorflow from data
tf_data = tf.Variable(df_pca)

with  tf.compat.v1.Session() as sess:
    tf.executing_eagerly()
    saver = tf.compat.v1.train.Saver([tf_data])
    sess.run(tf_data.initializer)
    saver.save(sess, os.path.join(LOG_DIR, 'tf_data.ckpt'))
    config = projector.ProjectorConfig()

    embedding = config.embeddings.add()
    embedding.tensor_name = tf_data.tensor_name

    embedding.metadata_path = metadata

    projector.visualize_embeddings(tf.summary.FileWriter(LOG_DIR), config)
```


Provide a reproducible test case that is the bare minimum necessary to generate the problem.

Grab any COVID-19 data in a CSV format. Store it in the root directory. Run tensorboard. Run script. View EagerTensor error.

**Other info / logs** 
I have tried v1 imports. I have tried Tensorflow GPU. I have removed and added the tf.executing_eagerly(). I am trying to build the embedding projector locally however, the EagerTensor error has no solution.
"
38813,latest-devel-gpu and devel-gpu docker images out of sync,"latest-devel and devel are the same image as expected, but that's not the case for latest-devel-gpu and devel-gpu.

$ docker images
REPOSITORY | TAG | IMAGE ID | CREATED | SIZE
-|-|-|-|-
tensorflow/tensorflow | latest-devel | 468b5e19fd6a | 6 hours ago | 1.97GB
tensorflow/tensorflow | devel | 468b5e19fd6a | 6 hours ago | 1.97GB
tensorflow/tensorflow | latest-devel-gpu | 08aacdcc1422 | 7 hours ago | 4.17GB
tensorflow/tensorflow | devel-gpu | 72b4573fd1c4| 30 hours ago | 4.17GB"
38812,Some similar Docker images don't have the same image ID,"latest and 2.1.0 are the same image as expected, but that's not the case for latest-gpu and 2.1.0-gpu.

$ docker images
REPOSITORY | TAG | IMAGE ID | CREATED | SIZE
-|-|-|-|-
tensorflow/tensorflow | latest | 9bf93bf90865 | 3 months ago | 2.47GB
tensorflow/tensorflow | 2.1.0 | 9bf93bf90865 | 3 months ago | 2.47GB
tensorflow/tensorflow | latest-gpu | 3c0df9ad26cc | 3 months ago | 4.09GB
tensorflow/tensorflow | 2.1.0-gpu | cb908459d986 | 3 months ago | 4.09GB"
38811,Need to update nightly-devel and nightly-devel-gpu docker images,"Currently (as expected):
$ docker run --rm -it tensorflow/tensorflow:nightly bash
\# python -c ""import tensorflow as tf; print(tf.__version__)""
2.2.0-dev20200422

However:
$ docker run --rm -it tensorflow/tensorflow:nightly-devel bash
\# python -c ""import tensorflow as tf; print(tf.__version__)""
1.12.0-rc0

Same goes for the nightly-devel-gpu docker image."
38810,Verbose between epochs in tf version 2.2.0-rc3,"Started to receive this today when **colab upgraded to 2.2.0-rc3.** Yesterday I've trained and tf.version was 2.2.0-rc2.
The model I'm using is created using tf.keras.

Epoch 1/2
2020-04-22 18:49:48.629597: I tensorflow/core/profiler/lib/profiler_session.cc:159] Profiler session started.
1/2 [==============>...............] - ETA: 0s - loss: 0.8884 - categorical_accuracy: 0.7188 

>2020-04-22 18:49:48.646518: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1479] CUPTI activity buffer flushed
2020-04-22 18:49:48.646786: I tensorflow/core/profiler/internal/gpu/device_tracer.cc:216]  GpuTracer has collected 133 callback api events and 133 activity events.
2020-04-22 18:49:48.663147: I tensorflow/core/profiler/rpc/client/save_profile.cc:168] Creating directory: /content/drive/My Drive/Colab Notebooks/model_log_dirs_new1/logs_board/train/plugins/profile/2020_04_22_18_49_48
2020-04-22 18:49:48.670211: I tensorflow/core/profiler/rpc/client/save_profile.cc:174] Dumped gzipped tool data for trace.json.gz to /content/drive/My Drive/Colab Notebooks/model_log_dirs_new1/logs_board/train/plugins/profile/2020_04_22_18_49_48/ea98f4633ef6.trace.json.gz
2020-04-22 18:49:48.672098: I tensorflow/core/profiler/utils/event_span.cc:288] Generation of step-events took 0.026 ms
2020-04-22 18:49:48.689016: I tensorflow/python/profiler/internal/profiler_wrapper.cc:87] Creating directory: /content/drive/My Drive/Colab Notebooks/model_log_dirs_new1/logs_board/train/plugins/profile/2020_04_22_18_49_48Dumped tool data for overview_page.pb to /content/drive/My Drive/Colab Notebooks/model_log_dirs_new1/logs_board/train/plugins/profile/2020_04_22_18_49_48/ea98f4633ef6.overview_page.pb
Dumped tool data for input_pipeline.pb to /content/drive/My Drive/Colab Notebooks/model_log_dirs_new1/logs_board/train/plugins/profile/2020_04_22_18_49_48/ea98f4633ef6.input_pipeline.pb
Dumped tool data for tensorflow_stats.pb to /content/drive/My Drive/Colab Notebooks/model_log_dirs_new1/logs_board/train/plugins/profile/2020_04_22_18_49_48/ea98f4633ef6.tensorflow_stats.pb
Dumped tool data for kernel_stats.pb to /content/drive/My Drive/Colab Notebooks/model_log_dirs_new1/logs_board/train/plugins/profile/2020_04_22_18_49_48/ea98f4633ef6.kernel_stats.pb

2/2 [==============================] - 1s 306ms/step - loss: 0.9273 - categorical_accuracy: 0.6797 - val_loss: 0.7531 - val_categorical_accuracy: 0.7508
Epoch 2/2
2/2 [==============================] - 1s 253ms/step - loss: 0.8796 - categorical_accuracy: 0.7188 - val_loss: 0.6971 - val_categorical_accuracy: 0.7675

**Between epochs I'm getting all this mumbo jumbo, previous version never resulted in this.**"
38809,OSError:savedmodel file does not exist at .. path/savedmodel.pbtxt:saved model.pb,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution windows 8
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):pip
- TensorFlow version:2.2.0rc3
- Python version:3.7
- Installed using virtualenv? pip? conda?:yes
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:10.1
- GPU model and memory:nvdia gforce 940m



when i tried to run object detection model for first time in starting everything was going fine but at the end of the program i got this error 


<PIL.Image.Image image mode=RGB size=1352x900 at 0xF58A584A88>
---------------------------------------------------------------------------
OSError                                   Traceback (most recent call last)
G:\A!\compressed\models\research\object_detection\object_detection_tutorialasdf.
py in <module>
    270
    271 model_name = ""mask_rcnn_inception_resnet_v2_atrous_coco_2018_01_28""
--> 272 masking_model = load_model(""mask_rcnn_inception_resnet_v2_atrous_coco_20
18_01_28"")
    273
    274

G:\A!\compressed\models\research\object_detection\object_detection_tutorialasdf.
py in load_model(model_name)
    132   model_dir = pathlib.Path(model_dir)/""saved_model""
    133
--> 134   model = tf.saved_model.load(str(model_dir))
    135   model = model.signatures['serving_default']
    136

~\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\python\saved_mod
el\load.py in load(export_dir, tags)
    526     ValueError: If `tags` don't match a MetaGraph in the SavedModel.
    527   """"""
--> 528   return load_internal(export_dir, tags)
    529
    530

~\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\python\saved_mod
el\load.py in load_internal(export_dir, tags, loader_cls)
    535     # sequences for nest.flatten, so we put those through as-is.
    536     tags = nest.flatten(tags)
--> 537   saved_model_proto = loader_impl.parse_saved_model(export_dir)
    538   if (len(saved_model_proto.meta_graphs) == 1
    539       and saved_model_proto.meta_graphs[0].HasField(""object_graph_def""))
:

~\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\python\saved_mod
el\loader_impl.py in parse_saved_model(export_dir)
     81                   (export_dir,
     82                    constants.SAVED_MODEL_FILENAME_PBTXT,
---> 83                    constants.SAVED_MODEL_FILENAME_PB))
     84
     85

OSError: SavedModel file does not exist at: C:\Users\zerocoolz1\.keras\datasets\
mask_rcnn_inception_resnet_v2_atrous_coco_2018_01_28\saved_model/{saved_model.pb
txt|saved_model.pb}



and when i went to the directory i found these files
1: checkpoint
2:model.ckpt.data-00000-of-000001
3:model.ckpt.index
4:pipeline.config"
38805,TF 2.x Java Binding ,"I am reading this doc - https://www.tensorflow.org/api_docs/java/reference/org/tensorflow/package-summary

This page tells for TF 2.1.0 java binding is available , however when i check  https://mvnrepository.com/artifact/org.tensorflow where can i find TF 2.1.0 java library ?

"
38804,model.predict(tensor_array) returns predictions[0] instead of all predictions[:],"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
no
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): 
win 10 v 1909 b 18363.778

- TensorFlow installed from (source or binary):
pip install 
- TensorFlow version (use command below): 2.1.0.
- Python version: v3.6.8:3c6b436a57
- CUDA/cuDNN version:  10.1.243
- GPU model and memory: RTX 2080

**Describe the current behavior**
The following code to classify digits returns only one prediction

![image](https://user-images.githubusercontent.com/12736950/80022234-0b91d680-84dc-11ea-85bf-7f1956d8d742.png)

input: [[...],[....],[...],[...],[...]]

```
def predict(list_images):
    global model
    predictions = model.predict(list_images)
    return predictions
```
output: [[...]]

![image](https://user-images.githubusercontent.com/12736950/80019526-f2872680-84d7-11ea-88cc-9aa0eba2d669.png)


**Describe the expected behavior**
the same function should return the same number of predictions as input tensors (like in jupyter notebooks)

input: [[...],[....],[...],[...],[...]]

```
model = tf.keras.models.load_model('number_ocr_v2')

def predict(list_images):
    global model
    print(""length:"")
    print(len(list_images))
    #predictions = model.predict(list_images)
    predictions = model.predict_on_batch(list_images)
    #predictions = model.predict_classes(list_images)
    print(len(predictions))
    print(predictions)
```
output: [[...],[....],[...],[...],[...]]
![image](https://user-images.githubusercontent.com/12736950/80020860-fe73e800-84d9-11ea-9eb0-6801216718e5.png)


**Standalone code to reproduce the issue**
hard to do, because same code works perfectly fine in jupyter"
38803,[Keras] Support multiple validation sets in Model.fit,"**System information**
- TensorFlow version (you are using): 2.2-rc3
- Are you willing to contribute it (Yes/No): No

**Describe the feature and the current behavior/state.**
Currently there's no way to use multiple validation sets with independent tracking of metrics.

**Will this change the current api? How?**

Simplest way I can think of is to accept a list of datasets in the `validation_data` parameter in `Model.fit`. Ideally there should also be a way to specify the name of each set so that the logs indicate what set each validation step corresponds to.

**Who will benefit with this feature?**

Anyone training with multiple validation sets.
"
38800,ModuleNotFoundError : from tensorflow.compat.v1 import *,"ModuleNotFoundError: No module named `tensorflow.compat.v1` in **tensorflow==2.2.0-rc3**

**python == 3.6.8** in MacBook Pro"
38799,Build Windows Library using Docker,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 (1909) x64
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version: v2.1
- Python version: v3.7
- Installed using virtualenv? pip? conda?: conda
- Bazel version (if compiling from source): v0.29.1
- GCC/Compiler version (if compiling from source): VC2019
- CUDA/cuDNN version:
- GPU model and memory:



**Describe the problem**

How can I build tensorflow windows library using Docker container?
I just built tensorflow linux library using dev Docker.
But I can't build windows library using dev Docker.
Please help me. Thank you.
"
38797,overriding `make_train_function` does not work.,"**System information**
- TensorFlow version (you are using): 2.2.X
- Are you willing to contribute it (Yes/No): Yes

**Describe the feature and the current behavior/state.**
Reference: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/engine/training.py

Overriding the `train_step`  function of the Model class works well. But if you want to go a bit deeper down and override ` make_train_function` then it does not work.

In the document, it says that it is possible

`This method can be overridden to support custom training logic.`

But when you do that, it gives some errors. I tried to import what it asks for in the errors but it still wants more to import. 

Here is a sample code based on the recent François Chollet's notebook:

https://colab.research.google.com/drive/1pQX2pjXSU1AU182LuQge7xNeBJcFA3yb

Here you see that when you override it, it gives an error.

**Will this change the current api? How?**
It can.

**Who will benefit with this feature?**
Everybody who wants to write a customized training loop while taking advantage of the Keras `fit`.

As François Chollet' says:

""what if you need a custom training algorithm, but you still want to benefit from the convenient features of fit(), such as callbacks, built-in distribution support, or step fusing?""
"
38796,A high learning rate may cause a nan or an inf loss with tf.keras.optimizers.SGD,"There is a sample which would cause a nan or an inf loss in TFv2.2.0-rc2.
```
import numpy as np
import tensorflow as tf
from tensorflow.keras import Model
from tensorflow.keras.applications import VGG16
from tensorflow.keras.layers import *

vgg = tf.keras.applications.VGG16(include_top=False, input_shape=(300, 400, 3))
o = Conv2D(512, [1, 1])(vgg.output)
l = tf.keras.losses.MSE(vgg.output, o)
m = Model(vgg.input, l)
m.add_loss(l)
m.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=1e-3))
m.fit(np.ones([2, 300, 400, 3]), epochs=10)
```
When I decrease the learning rate, it is of less probability to happen.

Code correction: 
```
m.add_loss(o)
```
to 
```
m.add_loss(l)
```"
38795,"tf.keras model.fit causes sytem reboot (cpu,centOS)","<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):centos-release-7-7.1908.0.el7.centos.x86_64- TensorFlow installed from (source or binary):source
- TensorFlow version (use command below):2.1.0
- Python version:3.7
- GPU model and memory: running on cpu
- Ram: 64gb
- I'am using a VGG16 model(at least part of it)


**Describe the current behavior**
When using model.fit or model.fit_generator on models with large amounts of parameters my server reboots and I get a timeout on ssh. The log files don't show any errors, just the execution of my program and then the normal boot sequence. It seems like the issue starts when using over 60000 parameters. If I increase the amount of parameters this phenomena appears faster(earlier in the training process), when using around 200000 parameters it most times happens in the first epoch, but it's not consistent(I managed to train my model with 1million parameters for 10 epochs). Monitoring my Ram usage reveals that I' am just using fractions of what's available (6.5 gb out of 64gb). Furthermore in each epoch I'am getting this warning: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled
My code (I reduced parameters by removing layers):
<img width=""2210"" alt=""Bildschirmfoto 2020-04-22 um 15 26 47"" src=""https://user-images.githubusercontent.com/37218380/79987429-b17a1c80-84ad-11ea-8cee-f79140f573ad.png"">

Same code works on Raspbian beside it not having enough RAM

**Describe the expected behavior**
Working without a problem or an error warning.  
Could it be a hardware problem?



**Other info / logs** No errors are visible in the log file.
"
38794,Deploy Sequence to Sequence Model with Tensorflow Serving,"I have created a seq2seq model for question and answering by following the tensorflow tutorial here: https://www.tensorflow.org/tutorials/text/nmt_with_attention

The model works well and I want to deploy it with Tensorflow serving. it's not clear how I could do this efficiently because:
- The decoder can only make a prediction for the next word, by taking as input the last predicted word. Surely it's not efficient to send multiple inference requests word by word instead of generating the whole sentence server side?
- is there any way to do the preprocessing server side? (e.g. client only has to send the tensorflow serving text, instead of numpy arrays).
"
38793,"tf.data.Dataset.from_tensor_slices: ValueError: Failed to convert a NumPy array to a Tensor (Unsupported␣ ,→object type list), worked on 2.0.0-beta1","<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10/Juniper lab
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Notebook
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.2.0-rc3
- Python version: 3.8.1
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: no idea
- GPU model and memory: Geforce GTX 960M

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
I get an error when call tf.data.Dataset.from_tensor_slices with
ValueError: Failed to convert a NumPy array to a Tensor (Unsupported␣
,→object type list), see attachment
[Answer.Tensorflow.pad.sequence.feature.column.DenseFeatures.pdf](https://github.com/tensorflow/tensorflow/files/4515932/Answer.Tensorflow.pad.sequence.feature.column.DenseFeatures.pdf)


**Describe the expected behavior**
I tried to use this example
https://github.com/EgorBEremeev/SoloLearnML/blob/master/stackoverflow/Answer.%20Tensorflow%20pad%20sequence%20feature%20column.%20DenseFeatures.ipynb

It looks like it was running on 2.0.0-beta1, but not more in the current version. You can use this notebook to reproduce the case.

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.
https://github.com/EgorBEremeev/SoloLearnML/blob/master/stackoverflow/Answer.%20Tensorflow%20pad%20sequence%20feature%20column.%20DenseFeatures.ipynb
You need to adapt the path the the csv file which will also be available in the repository.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
38792,Embedding Lookup Sparse behavior with empty ids,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): linux 
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: na
- TensorFlow installed from (source or binary): binar
- TensorFlow version (use command below): 2.1
- Python version: 3.6
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

**Describe the current behavior**

```
list_input = tf.ragged.constant([[], [], [], [1], []], dtype=tf.int32)
list_input.shape
# TensorShape([5, None])
embedding = tf.Variable(tf.random.truncated_normal([3, 3]))
tf.nn.embedding_lookup_sparse(embedding, list_input.to_sparse(), None, combiner='mean').shape
# TensorShape([4, 3]) # the last row disappeared
list_input = tf.ragged.constant([[], [], [], [1]], dtype=tf.int32)
list_input.shape
# TensorShape([4, None]) # correct output shape
tf.nn.embedding_lookup_sparse(embedding, list_input.to_sparse(), None, combiner='mean').shape
# TensorShape([4, 3]) The first 3 vectors are zeroes the last one has the correct value.
```
Embedding lookup sparse states that it is not usable if one rows does not contains at least 1 id. 

> This op assumes that there is at least one id for each row in the dense tensor represented by sp_ids (i.e. there are no rows with empty features), and that all the indices of sp_ids are in canonical row-major order.

However based on my experiments it does not work at expected if the last item of the list array has no ids. If the first items have no ids it will be filled with zeroes but if the last ones dont have indices its not filled with zeroes and the output shape is not consistant.

**Describe the expected behavior**
A more consistent behavior i think we should fill every empty items with a zero vector if there are no ids or break explicitely.

I found safe_embedding_lookup_sparse which solves the issue however its not clear to me what are the differences between the two ? are there any performance issue with safe one ? 

**Standalone code to reproduce the issue**
https://colab.research.google.com/gist/tanguycdls/11a399c750ce72b92a002c9b11909e12/embeddingsparse.ipynb

"
38791, The _pywrap_tensorflow_internal.so files generated by the two compilations are different，why？,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- TensorFlow installed from source :
- TensorFlow version:1.15.2
- Python version:3.7
- Installed using pip:
- Bazel version 0.25.0:
- GCC/Compiler version :7.3.0






"
38790,Tensorflow/keras custom loss problem (external inputs),"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- Tensorflow 1.15
- Yes




Lets assume that we have a model model_A and we want to build up a backpropagation based on 3 different loss functions. The first loss (`Loss_1`) should be based on the output of model_A, `Loss_2 `and `Loss_3 `can come from something else. Think about it like a deviation from an unknown source, like in process-automation if you want to build up ur PID-controller. The easiest way is my approach down there, but it actually fails, because the graph isnt constructed the way i want, because X_realB and X_realC have no connection to model_A, and are ignored by keras with tensorflow backend.  


**Main Question:** How can i pass new variables in my loss function, without processing them in the model, and stil influencing the minimization problem ?

```
def generator_model(model_A):

  model_A.trainable = True

# import
  X_realA = Input(shape=image_shape)
  X_realB = Input(shape=image_shape)
  X_realC = Input(shape=image_shape)

# generate Fake image
  Fake_A=model_A(X_realA)


  model = Model([X_realA],[Fake_A,X_realB ,X_realC])

  opt = Adam(lr=0.0002, beta_1=0.5)
  model.compile(loss=[""mse"",""mse"",""mse""],loss_weights=[1,1,1], optimizer=opt)
  model.summary()
  return model
```

I tried something else in the past 2 days. Wrapping `[FakeA,B,C]` in a custom lambda-layer, to calculate combined loss (one value output of that custom layer). Than passing this loss, in a dummy custom loss-function, which just outputs the combined value of the lambda layer. Here is an example:

```
    # import A,B,C and than pass A into Generator .... and after that:
    
    combined_loss= Lambda(lambda x: combined_loss_func(x))([FakeA,B,C])

    model=Model([A,B,C],[combined_loss],loss=dummy_loss)

    def dummy_loss(y_pred,y_true):
      return y_pred


`combined_loss` could look like that:
    
    def combined_loss_func(x):
    
      FakeA,B,C=x[0],x[1],x[2]
    
      # transform all inputs into one row-tensors
      shape=tf.shape(FakeA)
      FakeA=tf.reshape(FakeA,[1,shape[0]*shape[1]*shape[2]*shape[3]])   
      shape=tf.shape(B)
      B=tf.reshape(B,[1,shape[0]*shape[1]*shape[2]*shape[3]]) 
      shape=tf.shape(C)
      C=tf.reshape(C,[1,shape[0]*shape[1]*shape[2]*shape[3]]) 
    
      # build up a hypothetical ground truth
      FakeA_ones=tf.ones_like(FakeA)
      A_ones=tf.ones_like(A)
      B_ones=tf.ones_like(B)
    
      # calculate losses
      loss0=keras.losses.mse(FakeA,FakeA_ones)
      loss1=keras.losses.mse(A,A_ones)
      loss2=keras.losses.mse(B,B_ones)
    
      # sum them up
      summe=tf.math.add(loss0,loss1)
      summe=tf.math.add(summe,loss2)
    
      # average them
      avg=tf.math.truediv(summe,3.0)
      avg=tf.expand_dims(summe,axis=-1)
    
      return avg
```


If i now try, to set the FakeA loss to zero, no backpropagation to `modelA` happens anymore, or at least nothing in the system changes anymore:

```
       # calculate losses
      loss0=keras.losses.mse(FakeA,FakeA_ones) * 0
      loss1=keras.losses.mse(A,A_ones)
      loss2=keras.losses.mse(B,B_ones)
```

First it seemes really good, but when i go now into the custom-function, and not use `FakeA`, which is the one and only tensor which passed through the generator. Than i stil get a value for my loss function, which seems to be rigth, but actually nothing is happening, my cycle Gan isnt improving at all, and all images passed though stil look the same, even after 100 epochs. 

Doesnt that mean, that the other losses not even really considered, and i stil just use the loss1 over FakeA, and i just get different results because of the typical divergation of GANs dynamic system ?

"
38789,ModuleNotFoundError: No module named '_pywrap_tensorflow_internal',"Code:-
from imageai.Prediction import ImagePrediction
import tensorflow as tf
import os
execution_path=os.getcwd()

prediction = ImagePrediction()
prediction.setModelTypeAsSqueezeNet() #To select which model we want to use
prediction.setModelPath(os.path.join(execution_path, ""squeezenet_weights_tf_dim_ordering_tf_kernels.h5""))
prediction.loadModel()

predictions, probabilities = prediction.predictImage(os.path.join(execution_path, ""photo_2020-04-22_11-05-49.jpg""), result_count=5 )
for eachPrediction, eachProbability in zip(predictions, probabilities):
    print(eachPrediction , "" : "" , eachProbability)



Error:--

(ReallysmartBrain) C:\Users\Akhilu\PycharmProjects\ReallysmartBrain>python brain.py
Traceback (most recent call last):
  File ""C:\Users\Akhilu\PycharmProjects\ReallysmartBrain\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 18, in swig_import_helper
    fp, pathname, description = imp.find_module('_pywrap_tensorflow_internal', [dirname(__file__)])
  File ""C:\Users\Akhilu\AppData\Local\Programs\Python\Python38-32\lib\imp.py"", line 296, in find_module
    raise ImportError(_ERR_MSG.format(name), name=name)
ImportError: No module named '_pywrap_tensorflow_internal'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\Akhilu\PycharmProjects\ReallysmartBrain\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\Akhilu\PycharmProjects\ReallysmartBrain\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\Akhilu\PycharmProjects\ReallysmartBrain\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 20, in swig_import_helper
    import _pywrap_tensorflow_internal
ModuleNotFoundError: No module named '_pywrap_tensorflow_internal'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""brain.py"", line 1, in <module>
    from imageai.Prediction import ImagePrediction
  File ""C:\Users\Akhilu\PycharmProjects\ReallysmartBrain\lib\site-packages\imageai\Prediction\__init__.py"", line 2, in <module>
    from tensorflow.python.keras.preprocessing import image
  File ""C:\Users\Akhilu\PycharmProjects\ReallysmartBrain\lib\site-packages\tensorflow\__init__.py"", line 24, in <module>
    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import
  File ""C:\Users\Akhilu\PycharmProjects\ReallysmartBrain\lib\site-packages\tensorflow\python\__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\Users\Akhilu\PycharmProjects\ReallysmartBrain\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 74, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""C:\Users\Akhilu\PycharmProjects\ReallysmartBrain\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 18, in swig_import_helper
    fp, pathname, description = imp.find_module('_pywrap_tensorflow_internal', [dirname(__file__)])
  File ""C:\Users\Akhilu\AppData\Local\Programs\Python\Python38-32\lib\imp.py"", line 296, in find_module
    raise ImportError(_ERR_MSG.format(name), name=name)
ImportError: No module named '_pywrap_tensorflow_internal'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\Akhilu\PycharmProjects\ReallysmartBrain\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\Akhilu\PycharmProjects\ReallysmartBrain\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\Akhilu\PycharmProjects\ReallysmartBrain\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 20, in swig_import_helper
    import _pywrap_tensorflow_internal
ModuleNotFoundError: No module named '_pywrap_tensorflow_internal'"
38788,ImportError: DLL load failed: 找不到指定的模块。(The specified module cannot be found(translate from Chinese) ),"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):pip install tensorflow===1.14.0
- TensorFlow version (use command below):1.14.0
- Python version:3.7.4
- CUDA/cuDNN version:10.0
- GPU model and memory:1660ti 16g ram
- Keras version: 2.2.5

```
Python 3.7.4 (default, Aug  9 2019, 18:34:13) [MSC v.1915 64 bit (AMD64)]
Type 'copyright', 'credits' or 'license' for more information
IPython 7.8.0 -- An enhanced Interactive Python. Type '?' for help.
PyDev console: using IPython 7.8.0
Python 3.7.4 (default, Aug  9 2019, 18:34:13) [MSC v.1915 64 bit (AMD64)] on win32
runfile('C:/junji/datas.py', wdir='C:/junji')
Using TensorFlow backend.
Traceback (most recent call last):
  File ""C:\Users\hp\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""E:\PyCharm Community Edition 2019.2.3\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import
    module = self._system_import(name, *args, **kwargs)
  File ""C:\Users\hp\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\hp\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\hp\Anaconda3\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\hp\Anaconda3\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: 找不到指定的模块。
During handling of the above exception, another exception occurred:
Traceback (most recent call last):
  File ""C:\Users\hp\Anaconda3\lib\site-packages\IPython\core\interactiveshell.py"", line 3326, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File ""<ipython-input-2-3564911e8277>"", line 1, in <module>
    runfile('C:/junji/datas.py', wdir='C:/junji')
  File ""E:\PyCharm Community Edition 2019.2.3\helpers\pydev\_pydev_bundle\pydev_umd.py"", line 197, in runfile
    pydev_imports.execfile(filename, global_vars, local_vars)  # execute the script
  File ""E:\PyCharm Community Edition 2019.2.3\helpers\pydev\_pydev_imps\_pydev_execfile.py"", line 18, in execfile
    exec(compile(contents+""\n"", file, 'exec'), glob, loc)
  File ""C:/junji/datas.py"", line 1, in <module>
    import keras
  File ""E:\PyCharm Community Edition 2019.2.3\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import
    module = self._system_import(name, *args, **kwargs)
  File ""C:\Users\hp\Anaconda3\lib\site-packages\keras\__init__.py"", line 3, in <module>
    from . import utils
  File ""E:\PyCharm Community Edition 2019.2.3\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import
    module = self._system_import(name, *args, **kwargs)
  File ""C:\Users\hp\Anaconda3\lib\site-packages\keras\utils\__init__.py"", line 6, in <module>
    from . import conv_utils
  File ""E:\PyCharm Community Edition 2019.2.3\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import
    module = self._system_import(name, *args, **kwargs)
  File ""C:\Users\hp\Anaconda3\lib\site-packages\keras\utils\conv_utils.py"", line 9, in <module>
    from .. import backend as K
  File ""E:\PyCharm Community Edition 2019.2.3\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import
    module = self._system_import(name, *args, **kwargs)
  File ""C:\Users\hp\Anaconda3\lib\site-packages\keras\backend\__init__.py"", line 1, in <module>
    from .load_backend import epsilon
  File ""E:\PyCharm Community Edition 2019.2.3\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import
    module = self._system_import(name, *args, **kwargs)
  File ""C:\Users\hp\Anaconda3\lib\site-packages\keras\backend\load_backend.py"", line 89, in <module>
    from .tensorflow_backend import *
  File ""E:\PyCharm Community Edition 2019.2.3\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import
    module = self._system_import(name, *args, **kwargs)
  File ""C:\Users\hp\Anaconda3\lib\site-packages\keras\backend\tensorflow_backend.py"", line 5, in <module>
    import tensorflow as tf
  File ""E:\PyCharm Community Edition 2019.2.3\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import
    module = self._system_import(name, *args, **kwargs)
  File ""C:\Users\hp\AppData\Roaming\Python\Python37\site-packages\tensorflow\__init__.py"", line 101, in <module>
    from tensorflow_core import *
  File ""E:\PyCharm Community Edition 2019.2.3\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import
    module = self._system_import(name, *args, **kwargs)
  File ""C:\Users\hp\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\__init__.py"", line 40, in <module>
    from tensorflow.python.tools import module_util as _module_util
  File ""E:\PyCharm Community Edition 2019.2.3\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import
    module = self._system_import(name, *args, **kwargs)
  File ""C:\Users\hp\AppData\Roaming\Python\Python37\site-packages\tensorflow\__init__.py"", line 50, in __getattr__
    module = self._load()
  File ""C:\Users\hp\AppData\Roaming\Python\Python37\site-packages\tensorflow\__init__.py"", line 44, in _load
    module = _importlib.import_module(self.__name__)
  File ""C:\Users\hp\Anaconda3\lib\importlib\__init__.py"", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""C:\Users\hp\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\python\__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""E:\PyCharm Community Edition 2019.2.3\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import
    module = self._system_import(name, *args, **kwargs)
  File ""C:\Users\hp\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 74, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""C:\Users\hp\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""E:\PyCharm Community Edition 2019.2.3\helpers\pydev\_pydev_bundle\pydev_import_hook.py"", line 21, in do_import
    module = self._system_import(name, *args, **kwargs)
  File ""C:\Users\hp\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\hp\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\hp\Anaconda3\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\hp\Anaconda3\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: 找不到指定的模块。(The specified module cannot be found(translate from Chinese) )
Failed to load the native TensorFlow runtime.
See https://www.tensorflow.org/install/errors
for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.
```

I have met this problem when I'm using  lenet-5 model. And 
"
38787,Error: tensorflow/tensorflow/lite/java/ovic/demo/app/BUILD:9:1: no such package '@androidsdk//com.android.support': BUILD file not found in directory 'com.android.support' of external repository @androidsdk. Add a BUILD file to a directory to mark it as a package. and referenced by '//tensorflow/lite/java/ovic/demo/app:ovic_benchmarker_binary',"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- LG G8
- TensorFlow installed from (source or binary): binary
- TensorFlow version: 1.14.0
- Python version: 3.6.9
- Installed using virtualenv? pip? conda?: pip3
- Bazel version (if compiling from source): 
- GCC/Compiler version (if compiling from source): 8.3.0
- CUDA/cuDNN version: no
- GPU model and memory: no


**Describe the problem**
I trying to test the tflite model according to  [OVIC Benchmarker for LPCV 2020](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/java/ovic). 
I installed Bazel 3.0.0 using Bazel's apt repository.
I installed Android ndk17c.
I installed Android SDK using android-sdk_r24.4.1-linux.tgz by the sequent command:
`tar -zxvf android-sdk_r24.4.1-linux.tgz`
changed path for android SDK
used `android update sdk -u -a -t 8,213,58 ` to install SDK platform, build-tools and SDK API.
Then I use` ./configure` to config WORKSPACE for bazel.
My .tf_configure.bazelrc is like this:

> build --action_env PYTHON_BIN_PATH=""/usr/bin/python3""
> build --action_env PYTHON_LIB_PATH=""/usr/lib/python3/dist-packages""
> build --python_path=""/usr/bin/python3""
> build --config=xla
> build:opt --copt=-march=native
> build:opt --copt=-Wno-sign-compare
> build:opt --host_copt=-march=native
> build:opt --define with_default_optimizations=true
> build --action_env ANDROID_NDK_HOME=""/mnt/d/Share/software/android-ndk-r17c""
> build --action_env ANDROID_NDK_API_LEVEL=""21""
> build --action_env ANDROID_BUILD_TOOLS_VERSION=""28.0.3""
> build --action_env ANDROID_SDK_API_LEVEL=""23""
> build --action_env ANDROID_SDK_HOME=""/mnt/d/Share/software/android-sdk-linux""
> test --flaky_test_attempts=3
> test --test_size_filters=small,medium
> test:v1 --test_tag_filters=-benchmark-test,-no_oss,-gpu,-oss_serial
> test:v1 --build_tag_filters=-benchmark-test,-no_oss,-gpu
> test:v2 --test_tag_filters=-benchmark-test,-no_oss,-gpu,-oss_serial,-v1only
> test:v2 --build_tag_filters=-benchmark-test,-no_oss,-gpu,-v1only
> build --action_env TF_CONFIGURE_IOS=""0""

Then I run
`bazel build -c opt --cxxopt=-Wno-all //tensorflow/lite/java/ovic/demo/app:ovic_benchmarker_binary`

Error occurred.

> ERROR: 
> /mnt/e/research/model_compression/proj/tensorflow/tensorflow/lite/java/ovic/demo/app/BUILD:9:1: no such package '@androidsdk//com.android.support': BUILD file not found in directory 'com.android.support' of external repository @androidsdk. Add a BUILD file to a directory to mark it as a package. and referenced by '//tensorflow/lite/java/ovic/demo/app:ovic_benchmarker_binary'
> ERROR: /mnt/e/research/model_compression/proj/tensorflow/tensorflow/lite/java/ovic/demo/app/BUILD:9:1: no such package '@androidsdk//com.android.support': BUILD file not found in directory 'com.android.support' of external repository @androidsdk. Add a BUILD file to a directory to mark it as a package. and referenced by '//tensorflow/lite/java/ovic/demo/app:ovic_benchmarker_binary'
> ERROR: Analysis of target '//tensorflow/lite/java/ovic/demo/app:ovic_benchmarker_binary' failed; build aborted: no such package '@androidsdk//com.android.support': BUILD file not found in directory 'com.android.support' of external repository @androidsdk. Add a BUILD file to a directory to mark it as a package.
> INFO: Elapsed time: 7.424s
> INFO: 0 processes.
> FAILED: Build did NOT complete successfully (18 packages loaded, 28 targets configured)

I have no idea how to fix this problem. And I tried to install Android Studio, it doesn't help either.
"
38786,AttributeError: type object 'TFLiteConverter' has no attribute 'from_keras_model',"ubuntu18.04 use [jupyter notebook]
tensorflow (1.14.0)
tensorflow-estimator (1.14.0)
tensorflow-gpu (1.14.0)

I follow[https://www.tensorflow.org/lite/performance/post_training_integer_quant]   can do
but I follow [https://www.tensorflow.org/lite/convert/python_api]Converting a Keras model There is such an error ： 
（AttributeError: type object 'TFLiteConverter' has no attribute 'from_keras_model'）
"
38785,xla kernel load error,"W0422 13:19:03.825152 25290 tf_model.cpp:326] TF error: 2 root error(s) found.
(0) Internal: Unable to load kernel 'fusion_22'
[[{{node cluster_86_1/xla_run}}]]
[[cluster_86_1/merge_oidx_0/_3]]
(1) Internal: Unable to load kernel 'fusion_22'
[[{{node cluster_86_1/xla_run}}]]
0 successful operations.
0 derived errors ignored.
W0422 13:19:04.673285 25290 tf_model.cpp:326] TF error: 2 root error(s) found.
(0) Internal: Unable to load kernel 'fusion_22'
[[{{node cluster_86_1/xla_run}}]]
[[cluster_86_1/merge_oidx_0/_3]]
(1) Internal: Unable to load kernel 'fusion_22'
[[{{node cluster_86_1/xla_run}}]]

========================
we used c api to load model from graph_def. the tf version is 1.14. this error ocurs when the online system try to load new model to replace the old one.the online system update the tf model for every two hours. we can't replicate this issue on our offline system."
38784,xla kernel load error,"W0422 13:19:03.825152 25290 tf_model.cpp:326] TF error: 2 root error(s) found.
  (0) Internal: Unable to load kernel 'fusion_22'
         [[{{node cluster_86_1/xla_run}}]]
         [[cluster_86_1/merge_oidx_0/_3]]
  (1) Internal: Unable to load kernel 'fusion_22'
         [[{{node cluster_86_1/xla_run}}]]
0 successful operations.
0 derived errors ignored.
W0422 13:19:04.673285 25290 tf_model.cpp:326] TF error: 2 root error(s) found.
  (0) Internal: Unable to load kernel 'fusion_22'
         [[{{node cluster_86_1/xla_run}}]]
         [[cluster_86_1/merge_oidx_0/_3]]
  (1) Internal: Unable to load kernel 'fusion_22'
         [[{{node cluster_86_1/xla_run}}]]"
38783,Issues running jupyter notebook to do object detection api,"Hi i have facing this issues and i am using tensorflow 2 cpu version and i have  AMD radeon graphics card in my laptop
%%bash
cd models/research/
protoc object_detection/protos/*.proto --python_out=.
Couldn't find program: 'bash'
%%bash 
cd models/research
pip install .
Couldn't find program: 'bash'

ImportError                               Traceback (most recent call last)
~\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow\python\pywrap_tensorflow.py in <module>
     57 
---> 58   from tensorflow.python.pywrap_tensorflow_internal import *
     59 

~\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py in <module>
     27             return _mod
---> 28     _pywrap_tensorflow_internal = swig_import_helper()
     29     del swig_import_helper

~\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py in swig_import_helper()
     23             try:
---> 24                 _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
     25             finally:

~\AppData\Local\Programs\Python\Python37\lib\imp.py in load_module(name, file, filename, details)
    241         else:
--> 242             return load_dynamic(name, filename, file)
    243     elif type_ == PKG_DIRECTORY:

~\AppData\Local\Programs\Python\Python37\lib\imp.py in load_dynamic(name, path, file)
    341             name=name, loader=loader, origin=path)
--> 342         return _load(spec)
    343 

ImportError: DLL load failed: The specified module could not be found.

During handling of the above exception, another exception occurred:

ImportError                               Traceback (most recent call last)
<ipython-input-6-cdfb01024084> in <module>
      4 import sys
      5 import tarfile
----> 6 import tensorflow as tf
      7 import zipfile
      8 

~\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow\__init__.py in <module>
     39 import sys as _sys
     40 
---> 41 from tensorflow.python.tools import module_util as _module_util
     42 from tensorflow.python.util.lazy_loader import LazyLoader as _LazyLoader
     43 

~\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow\python\__init__.py in <module>
     48 import numpy as np
     49 
---> 50 from tensorflow.python import pywrap_tensorflow
     51 
     52 # Protocol buffers

~\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow\python\pywrap_tensorflow.py in <module>
     67 for some common reasons and solutions.  Include the entire stack trace
     68 above this error message when asking for help."""""" % traceback.format_exc()
---> 69   raise ImportError(msg)
     70 
     71 # pylint: enable=wildcard-import,g-import-not-at-top,unused-import,line-too-long

ImportError: Traceback (most recent call last):
  File ""C:\Users\vilsuresh\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\vilsuresh\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\vilsuresh\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\vilsuresh\AppData\Local\Programs\Python\Python37\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\vilsuresh\AppData\Local\Programs\Python\Python37\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: The specified module could not be found.


Failed to load the native TensorFlow runtime.
"
38782,Import error traceback(most recent call last,"Hi this issue is perisisting me when i try to run the object detection api on jupyter notebook .I am using tensorflow  2 cpu version 

ImportError                               Traceback (most recent call last)
~\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow\python\pywrap_tensorflow.py in <module>
     57 
---> 58   from tensorflow.python.pywrap_tensorflow_internal import *
     59 

~\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py in <module>
     27             return _mod
---> 28     _pywrap_tensorflow_internal = swig_import_helper()
     29     del swig_import_helper

~\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py in swig_import_helper()
     23             try:
---> 24                 _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
     25             finally:

~\AppData\Local\Programs\Python\Python37\lib\imp.py in load_module(name, file, filename, details)
    241         else:
--> 242             return load_dynamic(name, filename, file)
    243     elif type_ == PKG_DIRECTORY:

~\AppData\Local\Programs\Python\Python37\lib\imp.py in load_dynamic(name, path, file)
    341             name=name, loader=loader, origin=path)
--> 342         return _load(spec)
    343 

ImportError: DLL load failed: The specified module could not be found.

During handling of the above exception, another exception occurred:

ImportError                               Traceback (most recent call last)
<ipython-input-6-cdfb01024084> in <module>
      4 import sys
      5 import tarfile
----> 6 import tensorflow as tf
      7 import zipfile
      8 

~\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow\__init__.py in <module>
     39 import sys as _sys
     40 
---> 41 from tensorflow.python.tools import module_util as _module_util
     42 from tensorflow.python.util.lazy_loader import LazyLoader as _LazyLoader
     43 

~\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow\python\__init__.py in <module>
     48 import numpy as np
     49 
---> 50 from tensorflow.python import pywrap_tensorflow
     51 
     52 # Protocol buffers

~\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow\python\pywrap_tensorflow.py in <module>
     67 for some common reasons and solutions.  Include the entire stack trace
     68 above this error message when asking for help."""""" % traceback.format_exc()
---> 69   raise ImportError(msg)
     70 
     71 # pylint: enable=wildcard-import,g-import-not-at-top,unused-import,line-too-long

ImportError: Traceback (most recent call last):
  File ""C:\Users\vilsuresh\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\vilsuresh\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\vilsuresh\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\vilsuresh\AppData\Local\Programs\Python\Python37\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\vilsuresh\AppData\Local\Programs\Python\Python37\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: The specified module could not be found."
38781,[TFlite dynamic range quantization]How can I disable dynamic quantization of activations? in inference?,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
-  Ubuntu 16.04:
- pip installed:
- TensorFlow version 2.1.0:





This document [https://tensorflow.google.cn/lite/performance/post_training_quantization](url)
said that we can use ""Dynamic range quantization"",which statically quantizes only the weights from floating point to 8-bits of precision.And ""dynamic-range"" operators will dynamically quantize activations based on their range to 8-bits and perform computations with 8-bit weights and activations.

But I want to quantize the weights to int8/uint8, and make sure all the operators are computed using only floating-point kernels at inference,which means no activations will be quantized.

So,how can I realize this?How can I avoid quantization of these ""dynamic-range"" operators?
"
38780,gather nd op does not support string input,"As the title.
Thanks for your help."
38779,can't use adadelta,"tensorflow.python.framework.errors_impl.NotFoundError: No registered 'ResourceSparseApplyAdadelta' OpKernel for 'GPU' devices compatible with node {{node ResourceSparseApplyAdadelta}}
	.  Registered:  device='CPU'; T in [DT_DOUBLE]; Tindices in [DT_INT64]
  device='CPU'; T in [DT_DOUBLE]; Tindices in [DT_INT32]
  device='CPU'; T in [DT_FLOAT]; Tindices in [DT_INT64]
  device='CPU'; T in [DT_FLOAT]; Tindices in [DT_INT32]
  device='CPU'; T in [DT_BFLOAT16]; Tindices in [DT_INT64]
  device='CPU'; T in [DT_BFLOAT16]; Tindices in [DT_INT32]
  device='CPU'; T in [DT_HALF]; Tindices in [DT_INT64]
  device='CPU'; T in [DT_HALF]; Tindices in [DT_INT32]
 [Op:ResourceSparseApplyAdadelta]
"
38778,Considerations about micro_speech example,"@tensorflow/micro

**System information**
- Host OS Platform and Distribution: Linux Ubuntu 18.04
- TensorFlow installed from: pip
- Tensorflow version: master branch
- Target platform: mbed, STM32F746

**Describe the problem**
I decided to open this issue because there are some others issues and pull requests related to the `micro_speech` example (like https://github.com/tensorflow/tensorflow/issues/35889),  and so I would like to take stock of the situation, describe the issues I found and how to solve them (see below).

**Please provide the exact sequence of commands/steps when you ran into the problem**
To build the `micro_speech` example I used the steps provided by the documentation related to the example in [README.md](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/examples/micro_speech/README.md):

- `git clone https://github.com/tensorflow/tensorflow.git`
- `cd tensorflow`
- `make -f tensorflow/lite/micro/tools/make/Makefile TARGET=mbed TAGS=""CMSIS disco_f746ng"" generate_micro_speech_mbed_project`

However, I obtained the following error:
`make: *** No rule to make target ""tensorflow/lite/micro/tools/make/gen/mbed_cortex-m4/prj/micro_speech/mbed/tensorflow/lite/micro/tools/make/downloads/CMSIS_ext/arm_cmplx_mag_squared_q10p6.c"", needed by ""generate_micro_speech_mbed_project"".  Stop.`

So, as suggested in https://github.com/tensorflow/tensorflow/pull/36444, I removed `arm_cmplx_mag_squared_q10p6.c/h` from `tensorflow/lite/micro/examples/micro_speech/CMSIS/Makefile.inc`.
But when I launched again the build I obtained this other issue:
`make: *** No rule to make target ""tensorflow/lite/micro/tools/make/gen/mbed_cortex-m4/prj/micro_speech/mbed/third_party/CMSIS_ext/README.md"", needed by ""generate_micro_speech_mbed_project"".  Stop.`
I managed to solve the new issue by removing `third_party/CMSIS_ext/README.md` line from `tensorflow/lite/micro/examples/micro_speech/CMSIS/Makefile.inc` since it is not a header file needed for the build.

At this point the project is created in `tensorflow/lite/micro/tools/make/gen/mbed_cortex-m4/prj/micro_speech/mbed`, but when I launched the command `mbed compile -m DISCO_F746NG -t GCC_ARM` I got this other error:
`Compile [ 95.6%]: arm_mult_q15.c
[Error] arm_mult_q15.c@101,6: conflicting types for 'arm_mult_q15'
[ERROR] ./tensorflow/lite/micro/tools/make/downloads/cmsis/CMSIS/DSP/Source/BasicMathFunctions/arm_mult_q15.c:101:6: error: conflicting types for 'arm_mult_q15'
 void arm_mult_q15(
      ^~~~~~~~~~~~
In file included from ./tensorflow/lite/micro/tools/make/downloads/cmsis/CMSIS/DSP/Source/BasicMathFunctions/arm_mult_q15.c:29:0:
./mbed-os/cmsis/TARGET_CORTEX_M/arm_math.h:1924:8: note: previous declaration of 'arm_mult_q15' was here
   void arm_mult_q15(
        ^~~~~~~~~~~~`
But again I managed to fix it by simply upgrading Mbed to 6.0.0-alpha-3 version as suggested in https://github.com/tensorflow/tensorflow/pull/37930.

**I added all the 3 changes in the [micro_speech_fix branch](https://github.com/biagiom/tensorflow/tree/micro_speech_fix) of my tensorflow repo.**

**Moreover, another useful way to solve the build issues is to use the `cmsis-nn` TAG instead of `CMSIS` (see also https://github.com/tensorflow/tensorflow/issues/35889), that is:**
`make -f tensorflow/lite/micro/tools/make/Makefile TARGET=mbed TAGS=""cmsis-nn disco_f746ng"" generate_micro_speech_mbed_project`.
This also has some ""advantages"":

- when adding `CMSIS` to `TAGS=,` the [CMSIS-NN optimized kernels](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/micro/kernels/cmsis-nn) are not added to the example during the build instead of the `cmsis-nn` tag. Moreover, since the _tiny_conv_ model is based on a conv2D layer, we can benefit for the optimized implementation of the convolution.
- the source code in [`tensorflow/lite/micro/examples/micro_speech/CMSIS`](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/micro/examples/micro_speech/CMSIS) that will be  added to the build using the `CMSIS` TAG is not directly related to the `micro_speech` example but (as far as I know) it is mostly used for [testing purposes (simple_features_generator_test)](https://github.com/tensorflow/tensorflow/blob/2ced38fde44235e3684c91280572fe55707df1a1/tensorflow/lite/micro/examples/micro_speech/Makefile.inc#L249) and for the apollo3 board but not for mbed/stm32f7. In particular, I also noticed that also when building the `simple_features_generator_test` with the `CMSIS` tag, it generates an error which says that the `arm_cmplx_mag_squared_q10p6.c` is not found. This is because make tries to find that file in the CMSIS_ext directory in `tensorflow/lite/micro/tools/make/downloads` but this doesn't exists. Moreover there is no way to download the custom CMSIS (CMSIS_ext) because its url is not defined in [third_party_downloads.inc](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/tools/make/third_party_downloads.inc). I also noticed that [mbed_makefile.inc](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/tools/make/targets/mbed_makefile.inc) includes [this line](https://github.com/tensorflow/tensorflow/blob/b9edec000c94761fc52e2ce38efa6385fff45f42/tensorflow/lite/micro/tools/make/targets/mbed_makefile.inc#L5), but `CUST_CMSIS_URL` and `CUST_CMSIS_MD5` are never defined.

In conclusion, I would like to suggest the following changes:

1. Update the [README](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/examples/micro_speech/README.md) related to the `micro_speech` example in order to use the `cmsis-nn` TAG instead of `CMSIS` (or use both if needed).
2. Remove `arm_cmplx_mag_squared_q10p6.c/h` from [`tensorflow/lite/micro/examples/micro_speech/CMSIS/Makefile.inc`](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/examples/micro_speech/CMSIS/Makefile.inc). Otherwise if the files are useful, I suggest to add them directly into [the `tensorflow/lite/micro/examples/micro_speech/CMSIS/` folder](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/examples/micro_speech/CMSIS) and remove the dependency from CMSIS_ext. Also we need to update the [mbed_makefile.inc](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/tools/make/targets/mbed_makefile.inc) file.
3. Update Mbed to 6.0.0-alpha-3 version (see https://github.com/tensorflow/tensorflow/pull/37930).
4. Remove [`third_party/CMSIS_ext/README.md` line](https://github.com/tensorflow/tensorflow/blob/b9f8df3930b34de2f461bb99813ade4b890e82c6/tensorflow/lite/micro/examples/micro_speech/CMSIS/Makefile.inc#L20) from `tensorflow/lite/micro/examples/micro_speech/CMSIS/Makefile.inc` since it is not a header file needed for the build.

I can contribute with some pull requests based on the above ideas if needed and I'm open to other suggestions/ideas in order to improve the `micro_speech` example and solve its issues.

Best regards,
Biagio.
"
38777,Blank outputs when using CTC loss on TensorFlow 2,"Hello.

I'm trying to use Tensorflow's ``tf.nn.ctc_loss`` for a speech recognition problem, but it seems it's causing the network to learn that the best way to reduce loss is to output blank. I've tried other implementations, like [this](https://github.com/igormq/ctc_tensorflow_example) and [this](https://github.com/ysoullard/CTCModel), but they have the same problem.

[Here](https://gist.github.com/Victor-Almeida/df1d0dc2cea318216d320d029dc8e64f) is the gist for my own implementation and [here](https://drive.google.com/open?id=1bgGte_wVyaYAycBntQA8uQWmVQZqhPYH) is the link to my Google Drive folder with the files used.

I'm using Google Colab's high-RAM runtime with GPU and Tensorflow version 2.2.0-rc3.

Also, for some reason I get this error ``    ValueError: Dimension must be 2 but is 3 for '{{node transpose}} = Transpose[T=DT_FLOAT, Tperm=DT_INT32](model_52/Placeholder, transpose/perm)' with input shapes: [1200,29], [3].`` when trying to use ``tf.function`` on the ``train_step`` method from the ``CTC_SR`` class when using the ``Encoder_Decoder`` class, but not when using the actual Keras' layers. 
When using ``tf.function`` with Keras layers, though, training takes waaaaaay longer. Why is that?"
38776,[RNN] [TFLiteConverter.] Input tensors containing unknown dimensions fails when coupled with LSTM,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Linux-4.19.104+-x86_64-with-Ubuntu-18.04-bionic (Google Colab's default environment)
- TensorFlow installed from (source or binary):
pip install tf-nightly
- TensorFlow version (or github SHA if from source):
2.2.0-dev20200421

**Command used to run the converter or code if you’re using the Python API**
If possible, please share a link to Colab/Jupyter/any notebook.

https://colab.research.google.com/drive/1-hjOM3qW5gY1PAqEZhFGHj7FFY5BaZsm

```
from tensorflow.lite.python import lite
from tensorflow.python import keras
import numpy as np

input_a = keras.layers.Input(shape=(3,3,), name='input_a')
interm_b = tf.keras.layers.LSTM(4, name='interm_1')(input_a)
output_c = keras.layers.Dense(1, name='dense_1')(interm_b)

model = tf.keras.models.Model(inputs=[input_a], outputs=[output_c])
model.compile(optimizer='sgd', loss='mean_squared_error')
model.summary()

batch_size = 10
sample_input = np.ones((batch_size,3,3),dtype=np.float32)

expected_value = model.predict(sample_input)

converter = lite.TFLiteConverterV2.from_keras_model(model = model)
converter.experimental_new_converter = True
with open(""model.tflite"", ""wb"") as f:
    f.write(converter.convert())

interpreter = lite.Interpreter(model_path=""model.tflite"")
print(interpreter.get_input_details())
interpreter.resize_tensor_input(0,[batch_size, 3,3])
interpreter.allocate_tensors()
interpreter.set_tensor(0, sample_input)
interpreter.invoke()
interpreter.get_tensor(interpreter.get_output_details()[0][""index""])
```

**The output from the converter invocation**

```
Model: ""model_2""
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_a (InputLayer)         [(None, 3, 3)]            0         
_________________________________________________________________
interm_1 (LSTM)              (None, 4)                 128       
_________________________________________________________________
dense_1 (Dense)              (None, 1)                 5         
=================================================================
Total params: 133
Trainable params: 133
Non-trainable params: 0
_________________________________________________________________
[{'name': 'input_a', 'index': 0, 'shape': array([1, 3, 3], dtype=int32), 'shape_signature': array([-1,  3,  3], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]
---------------------------------------------------------------------------
RuntimeError                              Traceback (most recent call last)
<ipython-input-3-492497848c68> in <module>()
     27 interpreter.allocate_tensors()
     28 interpreter.set_tensor(0, sample_input)
---> 29 interpreter.invoke()
     30 interpreter.get_tensor(interpreter.get_output_details()[0][""index""])

/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/interpreter.py in invoke(self)
    512     """"""
    513     self._ensure_safe()
--> 514     self._interpreter.Invoke()
    515 
    516   def reset_all_variables(self):

RuntimeError: tensorflow/lite/kernels/concatenation.cc:74 t->dims->data[d] != t0->dims->data[d] (10 != 1)Node number 50 (CONCATENATION) failed to prepare.
Node number 10 (WHILE) failed to invoke.
```

**Failure details**
The conversion is successful, but the generated model cannot be resized to variable batch size.
Input tensors containing unknown dimensions fails when coupled with LSTM
Same script would work just fine if one removes creation of _interm_b_ and pass _input_a_ as the input to generate the _output_c_.
"
38775,tf.executing_eagerly returns False in TensorFlow 2 without using tf.function,"**System information**
- Have I written custom code: Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Mac OS Catalina
- TensorFlow installed from: binary
- TensorFlow version: 2.1.0
- Python version: 3.7.5

**Describe the current behavior**

The following statement

    print(tf.executing_eagerly())

prints `False` inside a function of a custom layer WHILE BUILDING THE MODEL, so before `compile` is called. None of those functions has the decorator `@tf.function`. In [the documentation](https://www.tensorflow.org/api_docs/python/tf/executing_eagerly) it says that the only time where the statement above can produce false is when either we are using `@tf.function` (which is not the case), ""Executing inside a transformation function for tf.dataset"" (which is not the case) or `tf.compat.v1.disable_eager_execution()` is called (which is not the case).

**Describe the expected behavior**

The statement above should return True.

See [the related Stack Overflow question](https://stackoverflow.com/q/61355474/3924118)."
38773,Allow name argument of tf.name_scope to be a tf.string,"**System information**
- TensorFlow version (you are using): 2.1.0
- Are you willing to contribute it (Yes/No): Yes (if it's not too difficult/time-taking)

**Describe the feature and the current behavior/state.**
Currently, something like the following doesn't work since `name` in `tf.name_scope` must be a Python `str`:
```python
import tensorflow as tf


for i in tf.range(4):
    tag = tf.strings.format('tag{}', i + 1)
    with tf.name_scope(tag):
        tf.summary.scalar('value', tf.constant(i**4))
```

**Will this change the current API? How?**
Not significantly.

**Who will benefit with this feature?**
Users of autograph who want to use a Tensor's value in `tf.name_scope`.

**Any Other info.**
"
38772,No default summary writer available when using tf.py_function with autograph,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): 3.6.8
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS 10.15.5 Beta
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: n/a
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.1.0
- Python version: 3.6.8
- Bazel version (if compiling from source): n/a
- GCC/Compiler version (if compiling from source): n/a
- CUDA/cuDNN version: n/a
- GPU model and memory: n/a

**Describe the current behavior**
Using `tf.summary` returns `False` inside a `tf.py_function` when using autograph.

**Describe the expected behavior**
`tf.summary` should return `True`.

**Standalone code to reproduce the issue**
```python
import tensorflow as tf


@tf.function
def eager_pyfunc():
    def inner_func():
        bool_out = tf.summary.scalar('myscalar', tf.constant(32.9))
        tf.print(bool_out, name='log-myscalar-success')

    tf.py_function(inner_func, [], [], name='log-myscalar')

    bool_out2 = tf.summary.scalar('myscalar2', tf.constant(52.3))
    tf.print(bool_out2, name='log-myscalar2-success')


with tf.summary.create_file_writer('./logs').as_default():
    tf.summary.experimental.set_step(0)
    eager_pyfunc()
```
outputs:
```
0
1
```
Removing the `tf.function` outputs:
```
1
1
```

**Other info / logs** 
Could be related to https://github.com/tensorflow/tensorflow/issues/26409."
38770,.NET Language Bindings,".NET is one of the top languages and yet there are no Tensorflow language bindings.  This makes it hard to use in an Enterprise setting and is limiting the adoption of Tensorflow.  This is a huge lever as well to drive adoption deeper into traditional companies.

**Describe the feature and the current behavior/state.**

Currently there are Java and Python language bindings for Tensorflow, but no official .NET bindings.  There is a third party unofficial project but it only supports old versions of Tensorflow and is not officially maintained

**Will this change the current api? How?**

No

**Who will benefit with this feature?**

The entire .NET ecosystem, which is about the same size or larger than the Java ecosystem.  Visual Studio is the #1 IDE in the world.

**Any Other info.**
"
38768,TF 1.15.0  savedModel running in  TF 2.1.0,"OS Platform and Distribution : macOS Catalina 10.15.3

TensorFlow installed from : binary

TensorFlow version : 1.15.0

Python version: 3.7.3

Hi All,

I have general question (so no code is provided) . Are below 2 questions possible :

1. Can we run TF 1.15.0 savedModel (which has feature transformation ported as part of savedModel) in TF 2.1.0 directly ? 

2. Is there any way to convert TF 1.15.0 savedModel (which has feature transformation ported as part of savedModel) directly to TF 2.1.0 ? 


"
38767,"ConvRNN2D.build() - TypeError: can only concatenate list (not ""tuple"") to list","**System information**
- Have I written custom code: Yes, see code snippet below
- OS Platform and Distribution: `Ubuntu 19.10`
- TensorFlow installed from: `pip install tensorflow==2.1`
- TensorFlow version: `v2.1.0-rc2-17-ge5bf8de 2.1.0`
- Python version: `3.7.5`
- CUDA/cuDNN version: `CUDA 10.1`
- GPU model and memory: `GeForce GTX 1080 Ti 11GB`

**Describe the current behavior**
ConvRNN2D fails to build when restoring from config.

**Standalone code to reproduce the issue**
```
from tensorflow.python.keras.layers.convolutional_recurrent import (
    ConvRNN2D,
    ConvLSTM2DCell,
)

cell = ConvLSTM2DCell(filters=32, kernel_size=(3, 3))
rnn = ConvRNN2D(cell)
rnn = ConvRNN2D.from_config(rnn.get_config())
rnn.build(input_shape=(1, 10, 15, 15, 16))
```

**Other info / logs**
```
Traceback (most recent call last):
  File ""/home/kevin/dev/tf_bug.py"", line 9, in <module>
    rnn.build(input_shape=(1, 10, 15, 15, 16))
  File ""/home/kevin/dev/.venv/lib/python3.7/site-packages/tensorflow_core/python/keras/utils/tf_utils.py"", line 306, in wrapper
    output_shape = fn(instance, input_shape)
  File ""/home/kevin/dev/.venv/lib/python3.7/site-packages/tensorflow_core/python/keras/layers/convolutional_recurrent.py"", line 244, in build
    self.cell.build([step_input_shape] + constants_shape)
TypeError: can only concatenate list (not ""tuple"") to list
```
"
38766,Gradient checkpointing for TF keras models,"**System information**
- TensorFlow version (you are using): 2.1
- Are you willing to contribute it (Yes/No): Yes

**Describe the feature and the current behavior/state.**
I have implemented a version of gradient check pointing for TF keras sequential models (with future plans to extend it for Keras functional API and custom models). The PR can be found here - https://github.com/tensorflow/addons/pull/1600. I initially envisioned it as a package in TF addons repo but reviewers felt it was not right place and could potentially go in as a fix for the existing recompute_grad functionality in TF core - https://github.com/tensorflow/tensorflow/blob/64f4a59d5e39b60d67047d5e0b82de0cbcc6c2df/tensorflow/python/ops/custom_gradient.py#L458

Here are the issues with the existing implementation of recompute_grad in TF core and my solutions to those
1. Issue - Not usable. Most people have no idea how to use it. No docs or tutorials that explains how to use it.
Solution - My PR provides a notebook tutorial to demonstrate how to use the implemented functionality.
2. For people who did figure out how to use it, no memory savings was observed.
Solution - My PR provides links to results with observed memory savings. Caveat - only CPU profiled results available. GPU and TPU results need to be done.
3. There is probably an expectation that the user explicitly has to partition the model and decorate each partition. This is not user friendly and can make tasks such as transfer learning difficult.
Solution - My PR expects no explicit partitioning of the model. The user just needs to add a single decorator to the model. That is it.
4. No checkpointing functionality is implemented.
Solution - My PR implements the checkpointing functionality that allows the user to balance the tradeoff between memory and compute time.

Does it make sense to port the PR to TF core?

**Will this change the current api? How?**
The existing implementation can potentially be shoe horned into the existing API for recompute_grad if desirable.

**Who will benefit with this feature?**
Anyone who wants to train models in resource constrained environments.

**Any Other info.**
"
38765,tf.keras.callbacks.ProgbarLogger(count_mode='samples') does not work,"**System information**
(I'm sorry, this is my first time writing an issue.)
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Google Colab
- TensorFlow version (use command below): 2.2.0-rc3
- Python version: 3.6

**Describe the current behavior**
I noticed from [this commit](https://github.com/tensorflow/tensorflow/commit/10666c59dd4858645d1b03ce01f4450da80710ec) that the default behavior of `ProgbarLogger` has been changed to always show the number of `'steps'` instead of `'samples'`. I was curious and tried to manually use a `ProgbarLogger` callback argument to `Model.fit()` with `count_mode='samples'` instead, but then an error showed up.

**Describe the expected behavior**
 I expected it to work normally as with the older version of TensorFlow?

**Standalone code to reproduce the issue**
```python
# Assuming we use mnist data set
model = Sequential([
    Flatten(),
    Dense(128, activation='relu'),
    Dense(10)
])

loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)
model.compile(optimizer='adam', loss=loss_fn, metrics=['accuracy'])

model.fit(x_train, y_train, callbacks=[tf.keras.callbacks.ProgbarLogger('steps')])
```

**Other info / logs**
On my local machine (TF 2.1), this is the default behavior:
```
Epoch 1/5
16500/16500 [==============================] - 3s 207us/sample - loss: 0.4841 - accuracy: 0.8584
Epoch 2/5
16500/16500 [==============================] - 2s 95us/sample - loss: 0.2430 - accuracy: 0.9276
Epoch 3/5
...
```

On Google Colab (TF 2.2), I got this when I tried my code:
```
0/Unknown - 1s 0s/sample - loss: 0.3902 - accuracy: 0.8912

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/generic_utils.py:595: RuntimeWarning: divide by zero encountered in log10
  numdigits = int(np.log10(self.target)) + 1

---------------------------------------------------------------------------
OverflowError                             Traceback (most recent call last)
<ipython-input-51-834d420b09ab> in <module>()
      8 model.compile(optimizer='adam', loss=loss_fn, metrics=['accuracy'])
      9 
---> 10 model.fit(x_train, y_train, callbacks=[tf.keras.callbacks.ProgbarLogger('samples')])

5 frames
/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py in _method_wrapper(self, *args, **kwargs)
     64   def _method_wrapper(self, *args, **kwargs):
     65     if not self._in_multi_worker_mode():  # pylint: disable=protected-access
---> 66       return method(self, *args, **kwargs)
     67 
     68     # Running inside `run_distribute_coordinator` already.

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)
    877           epoch_logs.update(val_logs)
    878 
--> 879         callbacks.on_epoch_end(epoch, epoch_logs)
    880         if self.stop_training:
    881           break

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py in on_epoch_end(self, epoch, logs)
    363     logs = self._process_logs(logs)
    364     for callback in self.callbacks:
--> 365       callback.on_epoch_end(epoch, logs)
    366 
    367   def on_train_batch_begin(self, batch, logs=None):

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py in on_epoch_end(self, epoch, logs)
    892 
    893   def on_epoch_end(self, epoch, logs=None):
--> 894     self._finalize_progbar(logs)
    895 
    896   def on_test_end(self, logs=None):

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/callbacks.py in _finalize_progbar(self, logs)
    933       self.progbar.target = self.seen
    934     logs = logs or {}
--> 935     self.progbar.update(self.seen, list(logs.items()), finalize=True)
    936 
    937 

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/generic_utils.py in update(self, current, values, finalize)
    593 
    594       if self.target is not None:
--> 595         numdigits = int(np.log10(self.target)) + 1
    596         bar = ('%' + str(numdigits) + 'd/%d [') % (current, self.target)
    597         prog = float(current) / self.target

OverflowError: cannot convert float infinity to integer
```
"
38764,tpu lstm,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Python version**:
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with:

```bash
python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""
```

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
38763,Large overhead when calling custom pure python code in training loop ,"
**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 
- TensorFlow installed from (source or binary): binary 
- TensorFlow version (use command below): 2.1.0
- Python version: 3.7
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A

**Describe the current behavior**
I am training a deep RL agent using tensorflow on a custom environment and have noticed that calling the environment.step method in my training loop is much slower than just calling it outside. Specifically, if I time how long it takes to run the environment.step inside my agent.train method, it takes ~50 times longer than when I just run environment.step by itself. 

**Describe the expected behavior**
There shouldn't be any overheads running my custom environment.step method inside agent.train

**Standalone code to reproduce the issue**
download 
https://github.com/ronan-keane/havsim/tree/DL3 
navigate to folder, pip install havsim . 
run traintest.py in scripts/meng assignments/control 1/ folder 

**Other info / logs** 
I tested gym's cartpole environment and it doesn't have the issue. Since cartpole and my custom environment are both implemented in pure python it makes me think the issue is that the custom environment has attributes which are dictionaries. 
"
38762,TPU PyFunction results in UnavailableError: failed to connect to all addresses,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Modified [Colab MNIST guide](https://www.tensorflow.org/guide/tpu)
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Google Colab
- TensorFlow version (use command below): `2.2-rc3`

**Describe the current behavior**
When processing pipeline for `tf.data.Dataset` contains usage of `tf.py_function` the `UnavailableError: failed to connect to all addresses` is thrown on TPU environment.

**Describe the expected behavior**
`tf.py_function` is working on TPU environments. 

**Standalone code to reproduce the issue**
[Colab notebook](https://colab.research.google.com/drive/1D7qU4f1FZqieYHdyUezUEFPWoVZZJSxi) with simplified example. In my original code the preprocessing function is more complicated. 

**Other info / logs**
Related issue: [34346](https://github.com/tensorflow/tensorflow/issues/34346).
Stacktrace:
```
---------------------------------------------------------------------------
UnavailableError                          Traceback (most recent call last)
/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/context.py in execution_mode(mode)
   1985       ctx.executor = executor_new
-> 1986       yield
   1987     finally:

14 frames
/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/iterator_ops.py in _next_internal(self)
    660       except AttributeError:
--> 661         return structure.from_compatible_tensor_list(self._element_spec, ret)
    662 

/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/util/structure.py in from_compatible_tensor_list(element_spec, tensor_list)
    229       lambda spec, value: spec._from_compatible_tensor_list(value),
--> 230       element_spec, tensor_list)
    231 

/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/util/structure.py in _from_tensor_list_helper(decode_fn, element_spec, tensor_list)
    204     value = tensor_list[i:i + num_flat_values]
--> 205     flat_ret.append(decode_fn(component_spec, value))
    206     i += num_flat_values

/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/util/structure.py in <lambda>(spec, value)
    228   return _from_tensor_list_helper(
--> 229       lambda spec, value: spec._from_compatible_tensor_list(value),
    230       element_spec, tensor_list)

/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/tensor_spec.py in _from_compatible_tensor_list(self, tensor_list)
    176     assert len(tensor_list) == 1
--> 177     tensor_list[0].set_shape(self._shape)
    178     return tensor_list[0]

/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py in set_shape(self, shape)
   1103   def set_shape(self, shape):
-> 1104     if not self.shape.is_compatible_with(shape):
   1105       raise ValueError(

/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py in shape(self)
   1066       except core._NotOkStatusException as e:
-> 1067         six.raise_from(core._status_to_exception(e.code, e.message), None)
   1068 

/usr/local/lib/python3.6/dist-packages/six.py in raise_from(value, from_value)

UnavailableError: failed to connect to all addresses
Additional GRPC error information:
{""created"":""@1587494349.376555159"",""description"":""Failed to pick subchannel"",""file"":""third_party/grpc/src/core/ext/filters/client_channel/client_channel.cc"",""file_line"":3959,""referenced_errors"":[{""created"":""@1587494349.376552078"",""description"":""failed to connect to all addresses"",""file"":""third_party/grpc/src/core/ext/filters/client_channel/lb_policy/pick_first/pick_first.cc"",""file_line"":394,""grpc_status"":14}]}

During handling of the above exception, another exception occurred:

UnavailableError                          Traceback (most recent call last)
<ipython-input-8-f9a6a321af70> in <module>()
      1 train_dataset, test_dataset = get_dataset()
----> 2 list(train_dataset.take(1))

/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/iterator_ops.py in __next__(self)
    629 
    630   def __next__(self):  # For Python 3 compatibility
--> 631     return self.next()
    632 
    633   def _next_internal(self):

/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/iterator_ops.py in next(self)
    668     """"""Returns a nested structure of `Tensor`s containing the next element.""""""
    669     try:
--> 670       return self._next_internal()
    671     except errors.OutOfRangeError:
    672       raise StopIteration

/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/iterator_ops.py in _next_internal(self)
    659         return self._element_spec._from_compatible_tensor_list(ret)  # pylint: disable=protected-access
    660       except AttributeError:
--> 661         return structure.from_compatible_tensor_list(self._element_spec, ret)
    662 
    663   @property

/usr/lib/python3.6/contextlib.py in __exit__(self, type, value, traceback)
     97                 value = type()
     98             try:
---> 99                 self.gen.throw(type, value, traceback)
    100             except StopIteration as exc:
    101                 # Suppress StopIteration *unless* it's the same exception that

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/context.py in execution_mode(mode)
   1987     finally:
   1988       ctx.executor = executor_old
-> 1989       executor_new.wait()
   1990 
   1991 

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/executor.py in wait(self)
     65   def wait(self):
     66     """"""Waits for ops dispatched in this executor to finish.""""""
---> 67     pywrap_tfe.TFE_ExecutorWaitForAllPendingNodes(self._handle)
     68 
     69   def clear_error(self):

UnavailableError: failed to connect to all addresses
Additional GRPC error information:
{""created"":""@1587494349.376555159"",""description"":""Failed to pick subchannel"",""file"":""third_party/grpc/src/core/ext/filters/client_channel/client_channel.cc"",""file_line"":3959,""referenced_errors"":[{""created"":""@1587494349.376552078"",""description"":""failed to connect to all addresses"",""file"":""third_party/grpc/src/core/ext/filters/client_channel/lb_policy/pick_first/pick_first.cc"",""file_line"":394,""grpc_status"":14}]}
```"
38761,Matching Keras Backend functions,"`tensorflow.keras.backend` is missing a function `logsumexp`

I was orginally just going to add the function from `tf.math` but it turns out that `tensorflow.keras.backend` is machine-generated. When I go to `create_python_api.py` to see if I could add it I was hit with nontrivial code on how this file finds what should be included as imports for the keras backend.

Is there anything I could do to get a change like this added to the project or was this already considered?

**System information**
- TensorFlow version (you are using): 2.*
- Are you willing to contribute it (Yes/No): yes
"
38760,Problem with read and get batch from 2d array tfrecords dataset,"## URL(s) with the issue:
https://www.tensorflow.org/tutorials/load_data/tfrecord#tfrecord_files_using_tfdata

## Description of issue (what needs changing):
Problem with read and get batch from 2d array tfrecords dataset

### Clear description

Hello. I use Tensorflow 2.0 version. I have some problems with reading Tfrecords file when get batch.

First, this is my read_tfrecords.py file.

```
import tensorflow as tf
import os
from glob import glob
import numpy as np


def serialize_example(batch, list1, list2):
    filename = ""./train_set.tfrecords""
    writer = tf.io.TFRecordWriter(filename)

    for i in range(batch):
        feature = {}
        feature1 = np.load(list1[i])
        feature2 = np.load(list2[i])
        print('feature1 shape {} feature2 shape {}'.format(feature1.shape, feature2.shape)) 
        feature['input'] = tf.train.Feature(float_list=tf.train.FloatList(value=feature1.flatten()))
        feature['target'] = tf.train.Feature(float_list=tf.train.FloatList(value=feature2.flatten()))

        features = tf.train.Features(feature=feature)
        example = tf.train.Example(features=features)
        serialized = example.SerializeToString()
        writer.write(serialized)
        print(""{}th input {} target {} finished"".format(i, list1[i], list2[i]))



list_inp = sorted(glob('./input/2d_magnitude/*'))
list_tar = sorted(glob('./target/2d_magnitude/*'))


print(len(list_inp))
serialize_example(len(list_inp), list_inp, list_tar)
```

My input and target shapes are 2d array (Material of dataset is spectrogram). Therefore, my **Tfrecords** file includes two features likes ```[number_of_dataset, x, y]```. About 100,000 dataset was successfully saved as **Tfrecords** file.

And I have problem when I read **Tfrecords** file to get batch. This is my code ```read_tfrecords.py```:

```
import tensorflow as tf
import os
import numpy as np

shuffle_buffer_size = 50000
batch_size = 10
record_file = '/data2/dataset/tfrecords/train_set.tfrecords'

raw_dataset = tf.data.TFRecordDataset(record_file)
print('raw_dataset', raw_dataset) # ==> raw_dataset <TFRecordDatasetV2 shapes: (), types: tf.string>

raw_dataset = raw_dataset.repeat()
print('repeat', raw_dataset) # ==> repeat <RepeatDataset shapes: (), types: tf.string>

raw_dataset = raw_dataset.shuffle(shuffle_buffer_size)
print('shuffle', raw_dataset) # ==> shuffle <ShuffleDataset shapes: (), types: tf.string>

raw_dataset = raw_dataset.batch(batch_size, drop_remainder=True)
print('batch', raw_dataset) # ==> batch <BatchDataset shapes: (10,), types: tf.string>

raw_example = next(iter(raw_dataset)) 

parsed = tf.train.Example.FromString(raw_example.numpy()) # ==> read_tfrecords.py:25: RuntimeWarning: Unexpected end-group tag: Not all data was converted

print('parsed', parsed) # ==> ''

input = parsed.features.feature['input'].float_list.value
print('input', input) # ==> []
target = parsed.features.feature['target'].float_list.value
print('target', target) # ==> []
```

Here are results from code:
```
raw_dataset <TFRecordDatasetV2 shapes: (), types: tf.string>
repeat <RepeatDataset shapes: (), types: tf.string>
shuffle <ShuffleDataset shapes: (), types: tf.string>
batch <BatchDataset shapes: (10,), types: tf.string>
read_tfrecords.py:25: RuntimeWarning: Unexpected end-group tag: Not all data was converted
  parsed = tf.train.Example.FromString(raw_example.numpy())
parsed
input []
target []
```
As a result, I wonder how I get the batch from Tfrecords file to train. 
**read_tfrecords.py:25: RuntimeWarning: Unexpected end-group tag: Not all data was converted**
Could you give advice? Thank you very much.


### Usage example
Maybe...

```
raw_dataset = tf.data.TFRecordDataset(record_file)

raw_dataset = raw_dataset.repeat()

raw_dataset = raw_dataset.shuffle(shuffle_buffer_size)

raw_dataset = raw_dataset.batch(batch_size, drop_remainder=True)

raw_example = next(iter(raw_dataset)) 

parsed = tf.train.Example.FromString(raw_example.numpy())

input = parsed.features.feature['input'].float_list.value
target = parsed.features.feature['target'].float_list.value
```
"
38758,installation issue,"
*Traceback (most recent call last):
  File ""C:\Users\girid\AppData\Local\Programs\Python\Python38\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\girid\AppData\Local\Programs\Python\Python38\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\girid\AppData\Local\Programs\Python\Python38\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\girid\AppData\Local\Programs\Python\Python38\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\girid\AppData\Local\Programs\Python\Python38\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed while importing _pywrap_tensorflow_internal: The specified module could not be found.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""C:\Users\girid\AppData\Local\Programs\Python\Python38\lib\site-packages\tensorflow\__init__.py"", line 41, in <module>
    from tensorflow.python.tools import module_util as _module_util
  File ""C:\Users\girid\AppData\Local\Programs\Python\Python38\lib\site-packages\tensorflow\python\__init__.py"", line 50, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\Users\girid\AppData\Local\Programs\Python\Python38\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 69, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""C:\Users\girid\AppData\Local\Programs\Python\Python38\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\girid\AppData\Local\Programs\Python\Python38\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\girid\AppData\Local\Programs\Python\Python38\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\girid\AppData\Local\Programs\Python\Python38\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\girid\AppData\Local\Programs\Python\Python38\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed while importing _pywrap_tensorflow_internal: The specified module could not be found.


Failed to load the native TensorFlow runtime.

this is showin up when i was tryi'n to import the tensorflow"
38756,tf.name_scope has no effect when used with tf.cond and autograph,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS 10.15.5 Beta
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: n/a
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.1.0
- Python version: 3.6.8
- Bazel version (if compiling from source): n/a
- GCC/Compiler version (if compiling from source): n/a
- CUDA/cuDNN version: n/a
- GPU model and memory: n/a

**Describe the current behavior**
Using `tf.summary.scalar` in a method that is called in `tf.cond` logs the scalar without the `name_scope`. The results are different than when eager execution is used.

**Describe the expected behavior**
`tf.name_scope` should be used.

**Standalone code to reproduce the issue**
### Eager Execution
```python
import tensorflow as tf


def test_summary():
    with tf.name_scope('MyScope') as scope:
        mynum = tf.convert_to_tensor(43.9, name=scope)

        def log_mynum():
            tf.summary.scalar('mynum', data=mynum)
        tf.cond(tf.math.equal(mynum, 43.9), true_fn=log_mynum,
                false_fn=lambda: None, name='tb-mynum')

        log_mynum()

with tf.summary.create_file_writer('./logs').as_default():
    tf.summary.experimental.set_step(0)
    test_summary()
```
![eager](https://user-images.githubusercontent.com/31281983/79886925-e2802180-83c7-11ea-8579-f7a5fddb5fa6.png)

### Autograph
```python
import tensorflow as tf


@tf.function
def test_summary():
    with tf.name_scope('MyScope') as scope:
        mynum = tf.convert_to_tensor(43.9, name=scope)

        def log_mynum():
            tf.summary.scalar('mynum', data=mynum)
        tf.cond(tf.math.equal(mynum, 43.9), true_fn=log_mynum,
                false_fn=lambda: None, name='tb-mynum')

        log_mynum()

with tf.summary.create_file_writer('./logs').as_default():
    tf.summary.experimental.set_step(0)
    test_summary()
```
![autograph](https://user-images.githubusercontent.com/31281983/79887247-689c6800-83c8-11ea-8d3d-e4fb7465ad04.png)


**Other info / logs**
n/a
"
38754,tf.name_scope with spaces does not raise ValueError in eager execution ,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS 10.15.5 Beta
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: n/a
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.1.0
- Python version: 3.6.8
- Bazel version (if compiling from source):  n/a
- GCC/Compiler version (if compiling from source): n/a
- CUDA/cuDNN version: n/a
- GPU model and memory: n/a

**Describe the current behavior**
In autograph, `tf.name_scope` does not allow spaces in the string argument. In eager execution, `tf.name_scope` *does* allow spaces in the string argument. 

**Describe the expected behavior**
The constraints on `tf.name_scope` should be the same across eager execution and autograph. 

**Standalone code to reproduce the issue**
```python
import tensorflow as tf


# eager execution since there's no @tf.function decorator
def graphcry():
    myscalar = tf.constant(83.2)  # just a random number

    with tf.name_scope('scalaragain scope'):  # doesn't work
        tf.summary.scalar('scalaragain', data=myscalar)

    with tf.name_scope('nospace_scope'):  # works
        tf.summary.scalar('nospace', data=myscalar)

graphcry()
```

**Other info / logs**
CC @jvishnuvardhan, also see #38661 
"
38751,[Keras Application]May a bug under gradientTape?,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Window 10 1804
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
None
- TensorFlow installed from (source or binary):
binary
- TensorFlow version (use command below):
every 2.1.0 cpu/gpu
- Python version:
3.7.7
- Bazel version (if compiling from source):None
- GCC/Compiler version (if compiling from source):None
- CUDA/cuDNN version:10
- GPU model and memory: MSI GTX 1070 8GB

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
unknown 2.1.0
install from conda

**Describe the current behavior**
 tf.keras.application work under GradientTape may crash by:
LookupError: No gradient defined for operation 'IteratorGetNext' (op type: IteratorGetNext)

**Describe the expected behavior**
May GradientTape need pass Keras Application's Model?
Or Keras Application's Model could be set distrainable?

**Standalone code to reproduce the issue**
simple
```python
def vgg16_encode(vgg_input_img_tensor):
    vgg16_model = VGG16(weights='imagenet', include_top=False)
    vgg_input_img = preprocess_input(vgg_input_img_tensor)
    vgg16_output = vgg16_model.predict(vgg_input_img)
    return vgg16_output

with tf.GradientTape() as tape:
    //use vgg16_encode here
```
**Other info / logs**
tree:
  File ""C:/233/test.py"", line 29, in vgg16_encode
    vgg16_output = vgg16_model.predict(vgg_input_img)
  File ""C:\Users\Administrator\anaconda3\envs\detaining-master\lib\site-packages\tensorflow_core\python\keras\engine\training.py"", line 1013, in predict
    use_multiprocessing=use_multiprocessing)
  File ""C:\Users\Administrator\anaconda3\envs\detaining-master\lib\site-packages\tensorflow_core\python\keras\engine\training_v2.py"", line 498, in predict
    workers=workers, use_multiprocessing=use_multiprocessing, **kwargs)
  File ""C:\Users\Administrator\anaconda3\envs\detaining-master\lib\site-packages\tensorflow_core\python\keras\engine\training_v2.py"", line 475, in _model_iteration
    total_epochs=1)
  File ""C:\Users\Administrator\anaconda3\envs\detaining-master\lib\site-packages\tensorflow_core\python\keras\engine\training_v2.py"", line 128, in run_one_epoch
    batch_outs = execution_function(iterator)
  File ""C:\Users\Administrator\anaconda3\envs\detaining-master\lib\site-packages\tensorflow_core\python\keras\engine\training_v2_utils.py"", line 98, in execution_function
    distributed_function(input_fn))
  File ""C:\Users\Administrator\anaconda3\envs\detaining-master\lib\site-packages\tensorflow_core\python\eager\def_function.py"", line 568, in __call__
    result = self._call(*args, **kwds)
  File ""C:\Users\Administrator\anaconda3\envs\detaining-master\lib\site-packages\tensorflow_core\python\eager\def_function.py"", line 638, in _call
    return self._concrete_stateful_fn._filtered_call(canon_args, canon_kwds)  # pylint: disable=protected-access
  File ""C:\Users\Administrator\anaconda3\envs\detaining-master\lib\site-packages\tensorflow_core\python\eager\function.py"", line 1611, in _filtered_call
    self.captured_inputs)
  File ""C:\Users\Administrator\anaconda3\envs\detaining-master\lib\site-packages\tensorflow_core\python\eager\function.py"", line 1697, in _call_flat
    forward_function, args_with_tangents = forward_backward.forward()
  File ""C:\Users\Administrator\anaconda3\envs\detaining-master\lib\site-packages\tensorflow_core\python\eager\function.py"", line 1423, in forward
    self._inference_args, self._input_tangents)
  File ""C:\Users\Administrator\anaconda3\envs\detaining-master\lib\site-packages\tensorflow_core\python\eager\function.py"", line 1185, in forward
    self._forward_and_backward_functions(inference_args, input_tangents))
  File ""C:\Users\Administrator\anaconda3\envs\detaining-master\lib\site-packages\tensorflow_core\python\eager\function.py"", line 1379, in _forward_and_backward_functions
    outputs, inference_args, input_tangents)
  File ""C:\Users\Administrator\anaconda3\envs\detaining-master\lib\site-packages\tensorflow_core\python\eager\function.py"", line 890, in _build_functions_for_outputs
    src_graph=self._func_graph)
  File ""C:\Users\Administrator\anaconda3\envs\detaining-master\lib\site-packages\tensorflow_core\python\ops\gradients_util.py"", line 623, in _GradientsHelper
    (op.name, op.type))
LookupError: No gradient defined for operation 'IteratorGetNext' (op type: IteratorGetNext)

Process finished with exit code 1

"
38750,Issue installing tensor flow python,"Please I have issues installing tensorflow in python using pip. I tried
```shell
pip install tensorflow
```
And 
 
```shell
pip3 install tensorflow 
```

**System information**
- OS Platform Linux Ubuntu 18):
- Mobile device (Android (using termux) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version:
- Python version: 3
- Installed using virtualenv? No 
pip? Yes 
conda?: No
I am using android 

Log : 

> Could not find a version that satisfies the requirement tensorflow (from versions: )
No matching distribution found for tensorflow
"
38749,Excute `coco_object_detection:preprocess_coco_minival` error(ImportError: cannot import name preprocessing_steps_pb2),"@tensorflow/micro

**System information**
- Host OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04
- TensorFlow installed from (source or binary): source
- Tensorflow version (commit SHA if source): master
- Target platform (e.g. Arm Mbed OS, Arduino Nano 33 etc.): 

**Describe the problem**
```
INFO: Analyzed target //tensorflow/lite/tools/evaluation/tasks/coco_object_detection:preprocess_coco_minival (0 packages loaded, 0 targets configured).
INFO: Found 1 target...
Target //tensorflow/lite/tools/evaluation/tasks/coco_object_detection:preprocess_coco_minival up-to-date:
  bazel-bin/tensorflow/lite/tools/evaluation/tasks/coco_object_detection/preprocess_coco_minival
INFO: Elapsed time: 0.242s, Critical Path: 0.01s
INFO: 0 processes.
INFO: Build completed successfully, 1 total action
INFO: Running command line: bazel-bin/tensorflow/lite/tools/evaluation/tasks/coco_object_detection/preprocess_coco_minival '--images_folder=/paddle/data/coco/INFO: Build completed successfully, 1 total action
Traceback (most recent call last):
  File ""/root/.cache/bazel/_bazel_root/71ecaedffe808614528ea8e9600b0716/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/lite/tools/evaluation/tasks/coco_object_detection/preprocess_coco_minival.runfiles/org_tensorflow/tensorflow/lite/tools/evaluation/tasks/coco_object_detection/preprocess_coco_minival.py"", line 39, in <module>
    from tensorflow.lite.tools.evaluation.proto import evaluation_stages_pb2
  File ""/root/.cache/bazel/_bazel_root/71ecaedffe808614528ea8e9600b0716/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/lite/tools/evaluation/tasks/coco_object_detection/preprocess_coco_minival.runfiles/org_tensorflow/tensorflow/lite/tools/evaluation/proto/evaluation_stages_pb2.py"", line 16, in <module>
    from tensorflow.lite.tools.evaluation.proto import preprocessing_steps_pb2 as tensorflow_dot_lite_dot_tools_dot_evaluation_dot_proto_dot_preprocessing__steps__pb2
ImportError: cannot import name preprocessing_steps_pb2
```
**Please provide the exact sequence of commands/steps when you ran into the problem**
```
bazel run //tensorflow/lite/tools/evaluation/tasks/coco_object_detection:preprocess_coco_minival --  \
--images_folder=/paddle/data/coco/val2017  \
--instances_file=/paddle/data/coco/annotations/instances_val2017.json  \
--output_folder=../models/research/coco_data/
```
I try commend:
```
wget -O protobuf.zip https://github.com/google/protobuf/releases/download/v3.0.0/protoc-3.0.0-linux-x86_64.zip
./bin/protoc tensorflow/lite/tools/evaluation/proto/*.proto --python_out=.
```
But not useful.
"
38748,Using tf.Dataset in non-eager mode impossible,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.1.0
- Python version: 3.7.4

**Describe the current behavior**

I'd like to compare eager and non-eager mode using a custom training loop and a TF Dataset as the input.

This seems to be impossible as shape information seems to be unavailable and even basic training loops throw ""Attempting to capture an EagerTensor without building a function.""

I also couldn't find any documentation on how to do that.

**Describe the expected behavior**

Custom training loops should be possible in graph (non-eager) mode with tf.Dataset and documented

**Standalone code to reproduce the issue**
Heavily reduced example:

```
import tensorflow as tf
tf.compat.v1.disable_eager_execution()

def preprocess(x, l):
    return tf.image.convert_image_dtype(x, tf.float32), l

train_data, test_data = tf.keras.datasets.mnist.load_data()
train_data = tf.data.Dataset.from_tensor_slices(train_data).map(preprocess)

@tf.function
def run_loop(model, data):
    res = True
    for x, y in data:
        batch_size = int(x.shape[0])
        res = model(x)[0] == 1.
    return res

model = tf.keras.Sequential([tf.keras.layers.Dense(10, activation='softmax')])
result = run_loop(model, train_data.batch(32, drop_remainder=False)) # drop_remainder=True for ""EagerTensor"" exception
```

**Other info / logs** 

The first failure in the above is the line with `batch_size` as it tries to convert a `None` value, but at that point the value should be known already.
Changing the default `drop_remainder` to `True` avoids this.

The tensor causing the ""capture..."" failure has a dtype of `resource`. Not sure what that is.

Obviously the above doesn't do much, but reproduces the failure. My real training loop has all the GradientTape, loss, callbacks etc."
38747,tf.experimental.tensorrt.Converter sample code not working in tf 2.1.0,"Ubuntu 14
Python 3.5.2
Tensorflow-gpu 'v2.1.0-rc2-17-ge5bf8de'

The sample codes provided on page https://www.tensorflow.org/api_docs/python/tf/experimental/tensorrt/Converter do not work, raise exception:
> NameError: name 'DEFAULT_TRT_CONVERSION_PARAMS' is not defined

This fix worked for me:
> from tensorflow.python.compiler.tensorrt import trt_convert as trt
> params = trt.DEFAULT_TRT_CONVERSION_PARAMS._replace(
>     precision_mode='FP16')
"
38746,tflite gpu delegate create and load model use v2 api is very slow compare with v1 api(10x) why ?,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): android
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below): 2.2 rc2
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

i compile tflite.a (2.2 rc2) from source and use ndk c++ api to run tflite model as follow:
`
#ifdef V2
    TfLiteGpuDelegateOptionsV2 tOptions = TfLiteGpuDelegateOptionsV2Default();
    if (m_bGPUAllowFP16)
    {
        tOptions.is_precision_loss_allowed = 1;
    }
    tOptions.inference_preference = 1;

    m_pGPUDelegate = TfLiteGpuDelegateV2Create(&tOptions);
#else
    TfLiteGpuDelegateOptions tOptions = {.metadata = nullptr, .compile_options = {.precision_loss_allowed = 0, .preferred_gl_object_type = TFLITE_GL_OBJECT_TYPE_FASTEST, .dynamic_batch_enabled = 0,},};
    if (m_bGPUAllowFP16)
    {
        tOptions.compile_options.precision_loss_allowed = 1;
    }

    m_pGPUDelegate = TfLiteGpuDelegateCreate(&tOptions);
#endif

    auto iRetCode = m_pInterp->ModifyGraphWithDelegate(m_pGPUDelegate);
    if (iRetCode != kTfLiteOk)
    {
        return -1;
    }
`

but the time cost is very different, v1 load time cost is only 10% of v2 load time.  the model has Conv2DTranspose op, if use v1 api the inference time is 4x of v2 api, so why has this performance different?"
38745,tf.keras.Model#load_weights() cannot be used on a directory generated by tf.keras.callback.ModelCheckpoint,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04, Windows 10
- TensorFlow installed from (source or binary): pipy, anaconda
- TensorFlow version (use command below): 2.1
- Python version: 3.7

**Describe the current behavior**

When using the `tf.keras.callbacks.ModelCheckpoint('path/to/checkpoint.tf', save_weights_only=False)` callback when training with `tf.keras.Model#fit()`,  tensorflow stores a checkpoint as a directory with the following content:

```
/path/to/checkpoint.tf/
|  saved_model.pb
|  assets/
     | ....
| variables
     | variables.data-00000-of-x
     | ....
     | variables.index
```

According to the documentation of [`ModelCheckpoint`](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ModelCheckpoint), `save_weights_only=False` uses [`tf.keras.Model#save()`](https://www.tensorflow.org/api_docs/python/tf/keras/Model#save), which will save:

> * The model architecture, allowing to re-instantiate the model.
> * The model weights.
> * The state of the optimizer, allowing to resume training exactly where you left off.


When `tf.keras.callbacks.ModelCheckpoint('/path/to/weights.tf', save_weights_only=True)`  is used, a checkpoint is stored as:
```
/path/to/
| checkpoint
| weights.tf.data-00000-of-00002
| weights.tf.data-00001-of-00002
| weights.tf.index
```
Side note: `save_weights_only=False` expects a directory path, `save_weights_only=True`expects a file path. 

Using `save_weights_only=True` uses [`tf.keras.Model#save_weights()`](https://www.tensorflow.org/api_docs/python/tf/keras/Model#save_weights).

Consequently, the model can be loaded by using

```python
# this works
def build_model():
    ...
    return tf.keras.Model()

model1 = tf.keras.models.load_model(""path/to/checkpoint.tf"")

model2 = build_model()
model2.load_weights(""path/to/weights.tf"")
```

However, using `path/to/checkpoint.tf` with `tf.keras.Model#load_weights()` fails.

```python
model3 = build_model()
model3.load_weights(""path/to/checkpoint.tf"")
```
outputs:
```

OSError                                   Traceback (most recent call last)
<ipython-input-16-af9095619790> in <module>()
----> 1 model = build_model().load_weights(str(save_full))

3 frames
/usr/local/lib/python3.6/dist-packages/h5py/_hl/files.py in make_fid(name, mode, userblock_size, fapl, fcpl, swmr)
    171         if swmr and swmr_support:
    172             flags |= h5f.ACC_SWMR_READ
--> 173         fid = h5f.open(name, flags, fapl=fapl)
    174     elif mode == 'r+':
    175         fid = h5f.open(name, h5f.ACC_RDWR, fapl=fapl)

h5py/_objects.pyx in h5py._objects.with_phil.wrapper()

h5py/_objects.pyx in h5py._objects.with_phil.wrapper()

h5py/h5f.pyx in h5py.h5f.open()

OSError: Unable to open file (file read failed: time = Tue Apr 21 10:08:58 2020
, filename = 'checkpoint.tf', file descriptor = 60, errno = 21, error message = 'Is a directory', buf = 0x7ffced128070, total read size = 8, bytes this sub-read = 8, bytes actually read = 18446744073709551615, offset = 0)
```
Instead, I need to do:

```python
# this works
new_model = build_model()
new_model.load_weights(""path/to/checkpoint.tf/variables/variables"")
```

**Describe the expected behavior**

As `tf.keras.callbacks.ModelCheckpoint` hides the differences between `tf.keras.Model#save()` and `tf.keras.Model#save_weights()` from users, I expect the following code to work:

```python
def build_model():
    ...

path = ""path/to/checkpoint.tf""
callbacks = [tf.keras.callbacks.ModelCheckpoint(path, save_weights_only=False)]
model = build_model()
model.fit(..., callbacks=callbacks)

# now I can either load the whole model
new_model = tf.keras.models.load_model(path)

# or I can only load the weights
another_new_model = build_model()
another_new_model = another_new_model.load_weights(path)
```

**Standalone code to reproduce the issue**

https://colab.research.google.com/drive/104UFbStlddH8tH_xOD58dTbjEAj9SsKE
"
38743,solve all python related issues,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Python version**:
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with:

```bash
python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""
```

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
38742,"[TF 2.2.0rc] Regression - the `{predict,train,test}_on_batch` trace functions with fixed batch size #34907","See #34907 for description.

Even if the referenced issue was fixed for 2.1, it is again present in TF 2.2.0rc3."
38741,'CollectBatchStats' object has no attribute 'batch_losses',"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below):
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
when I learn ""https://tensorflow.google.cn/tutorials/images/transfer_learning_with_hub"", 
the following code shows an error ""AttributeError: 'CollectBatchStats' object has no attribute 'batch_losses'""
the code is following:
`plt.figure()
plt.ylabel(""Loss"")
plt.xlabel(""Training Steps"")
plt.ylim([0,2])
plt.plot(batch_stats_callback.batch_losses)`
**Describe the expected behavior**
I can't find any solution for this , please give me some advice about this, thanks
**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
38740,Generate  C++ code from TensorFlow Lite metadata,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using):  Master branch.
- Are you willing to contribute it (Yes/No):  Yes

**Describe the feature and the current behavior/state.**
I was so excited to hear that we can generate Android Java code from TensorFlow Lite meta-data with some codegen tools in TFLite. However, in our cases, most of the AI implementations are preferred to be wrapped into C++ interfaces, which reduce lots of work to maintain different  AI codes on different platforms. So,  I think C++ wrappers code generator of TensorFlow Lite metadata would be more favorable on business sight, which always has apps on lots of platform e.g. Android, IOS, other OS on devices and so on, and without develop AI implementations redundantly.  

**Will this change the current api? How?**
Maybe not, just support some new tools to generate a class I guessed.

**Who will benefit with this feature?**
I think lots of CPU manufacturers, solutions developers, smart devices manufacturers would be happy to hear good news from C++ code generator, they always need to develop some AI SDKs for their customers and they hardly know which platforms will run their SDKs, so C/C++ interfaces is the best choices for them.

**Any Other info.**
"
38739,Can't import tflearn in Tensorflow 2.1.0.  ModuleNotFoundError: No module named 'tensorflow.contrib',"Tried importing tflearn and it's component for building a CNN model.
```import tflearn
from tflearn.layers.conv import conv_2d, max_pool_2d
from tflearn.layers.core import input_data, dropout, fully_connected
from tflearn.layers.estimator import regression
import tflearn.datasets.mnist as mnist 
```
But it is thowing an error :
```
ModuleNotFoundError Traceback (most recent call last)
in
----> 1 import tflearn
2 from tflearn.layers.conv import conv_2d, max_pool_2d
3 from tflearn.layers.core import input_data, dropout, fully_connected
4 from tflearn.layers.estimator import regression
5

~\Anaconda3\Lib\site-packages\tflearn_init_.py in
2
3 # Config
----> 4 from . import config
5 from .config import is_training, get_training_mode, init_graph
6

~\Anaconda3\Lib\site-packages\tflearn\config.py in
3 import tensorflow as tf
4
----> 5 from .variables import variable
6
7 # -------------------

~\Anaconda3\Lib\site-packages\tflearn\variables.py in
5 import tflearn
6
----> 7 from tensorflow.contrib.framework.python.ops import add_arg_scope as contrib_add_arg_scope
8 from tensorflow.python.framework import ops
9 from tensorflow.python.ops import variable_scope

ModuleNotFoundError: No module named 'tensorflow.contrib'
```
Found this issue on many other forums and it says 'tensorflow.contrib' was removed in version 2.0 and can't find a solution except downgrading the tensorflow version from 2.1.0 to 1.14.0. "
38737,Build Tensorflow with triSYCL?,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04.4
- TensorFlow installed from (source or binary): build from source 
- TensorFlow version: 2.1.0
- Python version: 3.6.9
- Installed using virtualenv? pip? conda?: pip
- Bazel version (if compiling from source): 3.0.0 
- GCC/Compiler version (if compiling from source): gcc (Ubuntu/Linaro 7.5.0-3ubuntu1~18.04) 7.5.0
- CUDA/cuDNN version: [triSYCL](https://github.com/triSYCL/triSYCL)



**Describe the problem**

**Bazel 3.0.0** has been installed onto my **aarch64** successfully:

```console
$ bazel version
Extracting Bazel installation...
Starting local Bazel server and connecting to it...
Build label: 3.0.0- (@non-git)
Build target: bazel-out/aarch64-opt/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Mon Apr 20 22:21:14 2020 (1587421274)
Build timestamp: 1587421274
Build timestamp as int: 1587421274
```

However, when I tried to build Tensorflow with SYCL enabled, I got the following error messages:

```console
ERROR: ~/.cache/bazel/_bazel_khadas/0de19da26a472240f23447517e34d888/external/local_config_sycl/crosstool/BUILD:12:1: Target '@local_config_sycl//crosstool:empty' contains an error and its package is in error and referenced by '@local_config_sycl//crosstool:cc-compiler-local'
ERROR: ~/.cache/bazel/_bazel_khadas/0de19da26a472240f23447517e34d888/external/local_config_sycl/crosstool/BUILD:5:1: Target '@local_config_sycl//crosstool:cc-compiler-local' contains an error and its package is in error and referenced by '@local_config_sycl//crosstool:toolchain'
ERROR: ~/.cache/bazel/_bazel_khadas/0de19da26a472240f23447517e34d888/external/bazel_tools/src/tools/launcher/BUILD:9:1: every rule of type cc_binary implicitly depends upon the target '@local_config_sycl//crosstool:toolchain', but this target could not be found because of: Target '@local_config_sycl//crosstool:toolchain' contains an error and its package is in error
ERROR: Analysis of target '//tensorflow/tools/pip_package:build_pip_package' failed; build aborted: Analysis failed
INFO: Elapsed time: 0.724s
INFO: 0 processes.
FAILED: Build did NOT complete successfully (0 packages loaded, 3 targets configured)
```

It seems it's telling that **bazel DIDN'T successfully specify crosstool:toolchain** ?

Well, yes, I didn't specify the toolchain, but on my **aarch64 board**, the toolchain are **ALREADY** **symbolic linked** to things including: **gcc**, **g++**, etc. I believe **it does relate to triSYCL** ....

Cheers
Pei
"
38736,'bazel' --batch mode deprecated issue for Fedora,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Fedora 29
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: n/a
- TensorFlow installed from (source or binary): source
- TensorFlow version: v2.1.0-rc2-17-ge5bf8de
- Python version: 3.7.6
- Installed using virtualenv? pip? conda?: N/A
- Bazel version (if compiling from source): 0.21.0 and the latest.
- GCC/Compiler version (if compiling from source): N/A, command?
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A



**Describe the problem**
Can't compile from source due to `bazel` issue. Tried switching to recommended version of bazel, still unsuccessful.

This happened when trying to modify the source and build for the patch suggested here:

`https://github.com/tensorflow/tensorflow/issues/31945`

**Provide the exact sequence of commands / steps that you executed before running into the problem**

from tensorflow directory:

`python configure.py`




**Any other info / logs**
`INFO: Options provided by the client:
  Inherited 'common' options: --isatty=1 --terminal_columns=190
INFO: Reading rc options for 'version' from /home/andre/tensorflow/.bazelrc:
  Inherited 'common' options: --experimental_repo_remote_exec
ERROR: Unrecognized option: --experimental_repo_remote_exec
WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command ""bazel shutdown"".
INFO: Invocation ID: 0e4f21d3-187f-4d35-8f91-27a3ea88e768
Traceback (most recent call last):
  File ""configure.py"", line 1551, in <module>
    main()
  File ""configure.py"", line 1368, in main
    _TF_MAX_BAZEL_VERSION)
  File ""configure.py"", line 483, in check_bazel_version
    ['bazel', '--batch', '--bazelrc=/dev/null', 'version'])
  File ""configure.py"", line 159, in run_shell
    output = subprocess.check_output(cmd, stderr=stderr)
  File ""/usr/lib64/python3.7/subprocess.py"", line 411, in check_output
    **kwargs).stdout
  File ""/usr/lib64/python3.7/subprocess.py"", line 512, in run
    output=stdout, stderr=stderr)
subprocess.CalledProcessError: Command '['bazel', '--batch', '--bazelrc=/dev/null', 'version']' returned non-zero exit status 2.
`"
38735,"Confusing use of ""Validation Set"" in beginner example","Thank you for submitting a TensorFlow documentation issue. Per our GitHub
policy, we only address code/doc bugs, performance issues, feature requests, and
build/installation issues on GitHub.

The TensorFlow docs are open source! To get involved, read the documentation
contributor guide: https://www.tensorflow.org/community/contribute/docs

## URL(s) with the issue:

https://www.tensorflow.org/tutorials/quickstart/beginner

## Description of issue (what needs changing):

Tutorial makes use of model.evaluate(), and the documentation says that this is usually done on a ""Validation Set"". Everything else I read (glossary, docs for model.fit()... including validation set parameters) points to this relating to a ""Test Set"" since it occurs after the training phase, and the parameters passed are ""x_test"" and ""y_test"". The confusion is unhelpful to beginners. Change from ""Validation Set"" to ""Test Set""?

### Correct links

n/a

### Parameters defined

n/a

### Returns defined

n/a

### Raises listed and defined

n/a

### Usage example

n/a


### Request visuals, if applicable
n/a

### Submit a pull request?

No. I'm a beginner, so I don't want to do anything, lest I create more confusion.
"
38734,What version of gast is required?,"
**System information**
- OS Platform and Distribution : MacOS 10.14.3 
- TensorFlow installed from (source or binary): source
- TensorFlow version: 2.1.0
- Python version: 3.5
- Installed using virtualenv? pip? conda?: pip

**Describe the problem**
In file [`setup.py`](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/pip_package/setup.py#L60), gast  is required to be version 0.3.3, but after I installed tensorflow version 2.1.0, gast was version 0.2.2. I want to use gast 0.3.3, but error
```Python
ERROR: tensorflow 2.1.0 has requirement gast==0.2.2, but you'll have gast 0.3.3 which is incompatible
```"
38733,tf.data.DatasetSpec is not accepted as `input_signature` of `@tf.function` decorator,"System info
- OS Ubuntu 18.10
- Tensorflow 2.2

I am unable to `@tf.function`-decorate a function that would accept tf.data.Dataset and specify input signature explicitly in the function definition:

Simple example that produces an error (pasted in the bottom)
```
simple_dataset = tf.data.Dataset.from_tensor_slices(np.arange(10).astype(np.int32)).batch(5)

# plug in the output of this as an input signature fails
# tf.data.DatasetSpec.from_value(simple_dataset)

@tf.function(input_signature=[
        tf.data.DatasetSpec(
            tf.TensorSpec(shape=(None,), dtype=tf.int32, name=None), tf.TensorShape([]))
        ])
def simple_function(dataset):
  pass

simple_function(simple_dataset)
```
Also `get_concrete_function` method after retracing function _without specifying_ input signature also suggests the above signature should work
```
simple_function.get_concrete_function(simple_dataset).structured_input_signature
```

Traceback when executing a function after specifying the signature:
```
---------------------------------------------------------------------------
KeyError                                  Traceback (most recent call last)
<ipython-input-222-f3452c0ea6c1> in <module>()
      8   pass
      9 
---> 10 simple_function(simple_dataset)

7 frames
/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py in __call__(self, *args, **kwds)
    578         xla_context.Exit()
    579     else:
--> 580       result = self._call(*args, **kwds)
    581 
    582     if tracing_count == self._get_tracing_count():

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py in _call(self, *args, **kwds)
    646       canon_args, canon_kwds = \
    647           self._stateful_fn._function_spec.canonicalize_function_inputs(  # pylint: disable=protected-access
--> 648               *args, **kwds)
    649       # If we did not create any variables the trace we have is good enough.
    650       return self._concrete_stateful_fn._filtered_call(canon_args, canon_kwds)  # pylint: disable=protected-access

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py in canonicalize_function_inputs(self, *args, **kwargs)
   2236           inputs,
   2237           self._input_signature,
-> 2238           self._flat_input_signature)
   2239       return inputs, {}
   2240 

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py in _convert_inputs_to_signature(inputs, input_signature, flat_input_signature)
   2278         inputs[:len(input_signature)],
   2279         expand_composites=True,
-> 2280         check_types=False)  # lists are convert to tuples for `tf.data`.
   2281   except ValueError:
   2282     raise ValueError(""Structure of Python function inputs does not match ""

/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py in flatten_up_to(shallow_tree, input_tree, check_types, expand_composites)
    932                            expand_composites=expand_composites)
    933   # Discard paths returned by _yield_flat_up_to.
--> 934   return list(v for _, v in _yield_flat_up_to(shallow_tree, input_tree, is_seq))
    935 
    936 

/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py in <genexpr>(.0)
    932                            expand_composites=expand_composites)
    933   # Discard paths returned by _yield_flat_up_to.
--> 934   return list(v for _, v in _yield_flat_up_to(shallow_tree, input_tree, is_seq))
    935 
    936 

/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py in _yield_flat_up_to(shallow_tree, input_tree, is_seq, path)
    726       for leaf_path, leaf_value in _yield_flat_up_to(shallow_subtree,
    727                                                      input_subtree, is_seq,
--> 728                                                      path=subpath):
    729         yield (leaf_path, leaf_value)
    730 

/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py in _yield_flat_up_to(shallow_tree, input_tree, is_seq, path)
    723     for shallow_key, shallow_subtree in _yield_sorted_items(shallow_tree):
    724       subpath = path + (shallow_key,)
--> 725       input_subtree = input_tree[shallow_key]
    726       for leaf_path, leaf_value in _yield_flat_up_to(shallow_subtree,
    727                                                      input_subtree, is_seq,

KeyError: '_VariantDataset'
```

"
38732,TFLite MaxPool2D GPU op seems to modify source tensor,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Mac os x 10.15.4
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Pixel 4
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): tf-nightly==2.2.0.dev20200420, also using the nightly tflite (cpu and gpu) build on android.
- Python version: 3.6.10


**Describe the current behavior**
Here's a fun one.  When running the max pool operator on the gpu (only tested the CL delegate), the input tensor was modified.  When running the model on the cpu, it outputs the original tensor as expected.

I unfortunately don't have good code to repro on android, but the models produced in the snippet below should should the expected behavior when running on the cpu and then the gpu. 

**Describe the expected behavior**
The input tensor is not modified when running a max pool 2d on the source tensor.

**Standalone code to reproduce the issue**
```python
import tensorflow as tf
import pathlib
import numpy

def convert(model, name):
    converter = tf.lite.TFLiteConverter.from_keras_model(model)
    tflite_model = converter.convert()
    pathlib.Path(name).write_bytes(tflite_model)
    

inpt = tf.keras.layers.Input(shape=[256, 256, 3])
conv = tf.keras.layers.Conv2D(32, 1, padding=""same"")(inpt)

out = tf.keras.layers.Lambda(
    lambda x: tf.nn.max_pool2d(
        x, 16, strides=1, padding=""SAME""
    )
)(conv)
model = tf.keras.Model(inpt, [conv, out])
convert(model, 'out_gpu.tflite')

# Now force this to the maxpool to run on the cpu
inpt = tf.keras.layers.Input(shape=[256, 256, 3])
conv = tf.keras.layers.Conv2D(32, 1, padding=""same"")(inpt)
# This op should force the tensor onto the cpu.
out = tf.where(tf.equal(conv, conv), conv, tf.zeros_like(conv))
out = tf.keras.layers.Lambda(
    lambda x: tf.nn.max_pool2d(
        x, 16, strides=1, padding=""SAME""
    )
)(out)
model = tf.keras.Model(inpt, [conv, out])
convert(model, 'out_cpu.tflite')
```


**Other info / logs** 
Sample output of running `out_gpu.tflite` on the GPU.
```
// conv
Row 0: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,]
// out
Row 0: [0.0029296875, 0.0029296875, 0.0029296875, 0.0029296875, 0.0029296875, 0.0029296875, 0.0029296875, 0.0029296875, -0.0087890625]
```

Same model, but ran on cpu only:
```
// conv
Row 0: [-0.23471934, -0.25280565, -0.26997373, -0.27565137, -0.2950689, -0.3190521, -0.34115076, -0.346938]
// out:
Row 0: [0.0030363789, 0.0030363789, 0.0030363789, 0.0030363789, 0.0030363789, 0.0030363789, 0.0030363789, 0.0030363789, -0.0088257985]
```"
38731,TF 1.15 GPU version is not working as intended.,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes, I wrote a custom code.
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: running on servers
- TensorFlow installed from (source or binary): pip
- TensorFlow version (use command below): 1.15
- Python version: Python 3.6.9
- Bazel version (if compiling from source): None
- GCC/Compiler version (if compiling from source): None
- CUDA/cuDNN version: 10.0/7
- GPU model and memory: GTX1060, 6GB

**Describe the current behavior**
I'm trying to build up Capsule Network using TF 1.15 by referring tutorial.
The source code seemed to work well with CPU.
But if GPU is used, the model did not seem to be trained.
I turned on/off GPU by modifying LD_LIBRARY_PATH.
![image](https://user-images.githubusercontent.com/661463/79819478-0a21ba80-83c5-11ea-8166-459df2d4615f.png)
![image](https://user-images.githubusercontent.com/661463/79819492-0e4dd800-83c5-11ea-85b8-f1ed923569c5.png)

**Describe the expected behavior**
CPU and GPU version of the models need to be trained.

**Standalone code to reproduce the issue**
```
import numpy as np
import tensorflow as tf

caps1_n = 32
caps1_dim = 8
caps2_n = 10
caps2_dim = 16
exp_caps1_n = caps1_n * 6 * 6  # 1152 primary capsules

m_plus = 0.9
m_minus = 0.1
lambda_ = 0.5

conv1_params = {
    ""filters"": 256,
    ""kernel_size"": 9,
    ""strides"": 1,
    ""padding"": ""valid"",
    ""activation"": tf.nn.relu,
}

conv2_params = {
    ""filters"": caps1_n * caps1_dim, # 256 convolutional filters
    ""kernel_size"": 9,
    ""strides"": 2,
    ""padding"": ""valid"",
    ""activation"": tf.nn.relu
}

def squash(s, axis=-1, epsilon=1e-7):
    squared_norm = tf.reduce_sum(tf.square(s), axis=axis, keep_dims=True)
    safe_norm = tf.sqrt(squared_norm + epsilon)
    squash_factor = squared_norm / (1. + squared_norm)
    unit_vector = s / safe_norm
    return squash_factor * unit_vector

def safe_norm(s, axis=-1, epsilon=1e-7, keep_dims=False):
    squared_norm = tf.reduce_sum(tf.square(s), axis=axis, keep_dims=keep_dims)
    return tf.sqrt(squared_norm + epsilon)

from tensorflow.examples.tutorials.mnist import input_data

mnist = input_data.read_data_sets(""data/"")

tf.reset_default_graph()
np.random.seed(42)
tf.set_random_seed(42)

# Placeholders
X = tf.placeholder(shape=[None, 28, 28, 1], dtype=tf.float32)
Y = tf.placeholder(shape=[None], dtype=tf.int64)
batch_size = tf.shape(X)[0]

# CapsuleizationLayer
conv1 = tf.layers.conv2d(X, **conv1_params)
conv2 = tf.layers.conv2d(conv1, **conv2_params)
caps1_raw = tf.reshape(conv2, [-1, exp_caps1_n, caps1_dim])
caps1_output = squash(caps1_raw)

init_sigma = 0.1
W = tf.Variable(tf.random_normal(shape=(1, exp_caps1_n, caps2_n, caps2_dim, caps1_dim),
                                 stddev=init_sigma, dtype=tf.float32))
W_tiled = tf.tile(W, [batch_size, 1, 1, 1, 1])

caps1_output_expanded = tf.expand_dims(caps1_output, -1)
caps1_output_tile = tf.expand_dims(caps1_output_expanded, 2)
caps1_output_tiled = tf.tile(caps1_output_tile, [1, 1, caps2_n, 1, 1])
u_hat = tf.matmul(W_tiled, caps1_output_tiled)

#===============================================================
# Dynamic Routing
#===============================================================
raw_weights = tf.zeros([batch_size, exp_caps1_n, caps2_n, 1, 1], dtype=np.float32)

# Round1, Line 4
routing_weights = tf.nn.softmax(raw_weights, dim=2)
# Round1, Line 5
weighted_predictions = tf.multiply(routing_weights, u_hat)
weighted_sum = tf.reduce_sum(weighted_predictions, axis=1, keep_dims=True)
# Round1, Line 6
caps2_output_round_1 = squash(weighted_sum, axis=-2)
# Round1, Line 7
caps2_output_round_1_tiled = tf.tile(caps2_output_round_1, [1, exp_caps1_n, 1, 1, 1])
raw_weights2 = raw_weights + tf.matmul(u_hat, caps2_output_round_1_tiled, transpose_a=True)

# Round2, Line 4
routing_weights_round_2 = tf.nn.softmax(raw_weights2, dim=2)
# Round2, Line 5
weighted_predictions_round_2 = tf.multiply(routing_weights_round_2, u_hat)
weighted_sum_round_2 = tf.reduce_sum(weighted_predictions_round_2, axis=1, keep_dims=True)
# Round2, Line 6
caps2_output = squash(weighted_sum_round_2, axis=-2)
#===============================================================

y_proba = safe_norm(caps2_output, axis=-2)
y_proba_argmax = tf.argmax(y_proba, axis=2)
y_pred = tf.squeeze(y_proba_argmax, axis=[1, 2])

# Loss: Margin loss
T = tf.one_hot(Y, depth=caps2_n)
caps2_output_norm = safe_norm(caps2_output, axis=-2, keep_dims=True)
present_error_raw = tf.square(tf.maximum(0., m_plus - caps2_output_norm))
present_error = tf.reshape(present_error_raw, shape=(-1, 10))
absent_error_raw = tf.square(tf.maximum(0., caps2_output_norm - m_minus))
absent_error = tf.reshape(absent_error_raw, shape=(-1, 10))
L = tf.add(T * present_error, lambda_ * (1.0 - T) * absent_error)
loss = margin_loss = tf.reduce_mean(tf.reduce_sum(L, axis=1))

# Loss: Reconstruction loss
correct = tf.equal(Y, y_pred)
accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))

#default option for Adam
optimizer = tf.train.AdamOptimizer()
training_op = optimizer.minimize(loss)

init = tf.global_variables_initializer()
saver = tf.train.Saver()

batch_size = 50
n_iterations_per_epoch = mnist.train.num_examples // batch_size
n_iterations_validation = mnist.validation.num_examples // batch_size

with tf.Session() as sess:
    init.run()

    for epoch in range(10):
        for iteration in range(1, n_iterations_per_epoch + 1):
            X_batch, Y_batch = mnist.train.next_batch(batch_size)
            # Run the training operation and measure the loss:
            _, loss_train, acc_train = sess.run(
                [training_op, loss, accuracy],
                feed_dict={X: X_batch.reshape([-1, 28, 28, 1]),
                           Y: Y_batch})
            print(""Iteration: {}/{} ({:.1f}%)  Loss: {:.5f}, Acc: {:.5f}"".format(
                      iteration, n_iterations_per_epoch,
                      iteration * 100 / n_iterations_per_epoch,
                      loss_train, acc_train * 100)
                  )
```

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

**GPU version log**
```
Iteration: 1/1100 (0.1%)  Loss: 0.30913, Acc: 6.00000
Iteration: 2/1100 (0.2%)  Loss: 0.47852, Acc: 16.00000
Iteration: 3/1100 (0.3%)  Loss: 0.00000, Acc: 8.00000
Iteration: 4/1100 (0.4%)  Loss: 0.33996, Acc: 4.00000
Iteration: 5/1100 (0.5%)  Loss: 0.00000, Acc: 10.00000
Iteration: 6/1100 (0.5%)  Loss: 0.21045, Acc: 12.00000
Iteration: 7/1100 (0.6%)  Loss: 0.33996, Acc: 8.00000
Iteration: 8/1100 (0.7%)  Loss: 0.00000, Acc: 12.00000
Iteration: 9/1100 (0.8%)  Loss: 0.00000, Acc: 10.00000
Iteration: 10/1100 (0.9%)  Loss: 0.00000, Acc: 8.00000
Iteration: 11/1100 (1.0%)  Loss: 0.21045, Acc: 16.00000
Iteration: 12/1100 (1.1%)  Loss: 0.21045, Acc: 12.00000
Iteration: 13/1100 (1.2%)  Loss: 0.40472, Acc: 6.00000
Iteration: 14/1100 (1.3%)  Loss: 0.00000, Acc: 8.00000
Iteration: 15/1100 (1.4%)  Loss: 0.61517, Acc: 14.00000
Iteration: 16/1100 (1.5%)  Loss: 0.33996, Acc: 10.00000
Iteration: 17/1100 (1.5%)  Loss: 0.00000, Acc: 14.00000
Iteration: 18/1100 (1.6%)  Loss: 0.33996, Acc: 12.00000
Iteration: 19/1100 (1.7%)  Loss: 0.00000, Acc: 8.00000
Iteration: 20/1100 (1.8%)  Loss: 0.21045, Acc: 12.00000
Iteration: 21/1100 (1.9%)  Loss: 0.33996, Acc: 18.00000
Iteration: 22/1100 (2.0%)  Loss: 0.00000, Acc: 4.00000
Iteration: 23/1100 (2.1%)  Loss: 0.21045, Acc: 8.00000
Iteration: 24/1100 (2.2%)  Loss: 0.33996, Acc: 12.00000
Iteration: 25/1100 (2.3%)  Loss: 0.00000, Acc: 10.00000
Iteration: 26/1100 (2.4%)  Loss: 0.21045, Acc: 16.00000
Iteration: 27/1100 (2.5%)  Loss: 0.61517, Acc: 8.00000
Iteration: 28/1100 (2.5%)  Loss: 0.33996, Acc: 8.00000
Iteration: 29/1100 (2.6%)  Loss: 0.00000, Acc: 16.00000
Iteration: 30/1100 (2.7%)  Loss: 0.21045, Acc: 6.00000
Iteration: 31/1100 (2.8%)  Loss: 0.00000, Acc: 6.00000
Iteration: 32/1100 (2.9%)  Loss: 0.21045, Acc: 10.00000
Iteration: 33/1100 (3.0%)  Loss: 0.61517, Acc: 14.00000
Iteration: 34/1100 (3.1%)  Loss: 0.21045, Acc: 10.00000
Iteration: 35/1100 (3.2%)  Loss: 0.21045, Acc: 4.00000
Iteration: 36/1100 (3.3%)  Loss: 0.21045, Acc: 12.00000
Iteration: 37/1100 (3.4%)  Loss: 0.61517, Acc: 10.00000
Iteration: 38/1100 (3.5%)  Loss: 0.21045, Acc: 12.00000
Iteration: 39/1100 (3.5%)  Loss: 0.21045, Acc: 6.00000
Iteration: 40/1100 (3.6%)  Loss: 0.00000, Acc: 12.00000
Iteration: 41/1100 (3.7%)  Loss: 0.00000, Acc: 14.00000
Iteration: 42/1100 (3.8%)  Loss: 0.21045, Acc: 16.00000
Iteration: 43/1100 (3.9%)  Loss: 0.21045, Acc: 16.00000
Iteration: 44/1100 (4.0%)  Loss: 0.33996, Acc: 12.00000
Iteration: 45/1100 (4.1%)  Loss: 0.00000, Acc: 6.00000
Iteration: 46/1100 (4.2%)  Loss: 0.00000, Acc: 4.00000
Iteration: 47/1100 (4.3%)  Loss: 0.21045, Acc: 10.00000
Iteration: 48/1100 (4.4%)  Loss: 0.33996, Acc: 12.00000
Iteration: 49/1100 (4.5%)  Loss: 0.00000, Acc: 14.00000
Iteration: 50/1100 (4.5%)  Loss: 0.21045, Acc: 10.00000
```
**CPU Version log**
```
Iteration: 1/1100 (0.1%)  Loss:  0.80942, Acc: 8.00000
Iteration: 2/1100 (0.2%)  Loss:  0.63684, Acc: 10.00000
Iteration: 3/1100 (0.3%)  Loss:  1.88716, Acc: 8.00000
Iteration: 4/1100 (0.4%)  Loss:  0.80636, Acc: 4.00000
Iteration: 5/1100 (0.5%)  Loss:  0.60099, Acc: 10.00000
Iteration: 6/1100 (0.5%)  Loss:  0.54984, Acc: 12.00000
Iteration: 7/1100 (0.6%)  Loss:  0.52977, Acc: 28.00000
Iteration: 8/1100 (0.7%)  Loss:  0.52300, Acc: 12.00000
Iteration: 9/1100 (0.8%)  Loss:  0.54408, Acc: 8.00000
Iteration: 10/1100 (0.9%)  Loss: 0.49441, Acc: 16.00000
Iteration: 11/1100 (1.0%)  Loss: 0.48491, Acc: 20.00000
Iteration: 12/1100 (1.1%)  Loss: 0.49179, Acc: 36.00000
Iteration: 13/1100 (1.2%)  Loss: 0.46365, Acc: 50.00000
Iteration: 14/1100 (1.3%)  Loss: 0.45733, Acc: 54.00000
Iteration: 15/1100 (1.4%)  Loss: 0.41508, Acc: 64.00000
Iteration: 16/1100 (1.5%)  Loss: 0.40333, Acc: 64.00000
Iteration: 17/1100 (1.5%)  Loss: 0.37526, Acc: 58.00000
Iteration: 18/1100 (1.6%)  Loss: 0.37363, Acc: 58.00000
Iteration: 19/1100 (1.7%)  Loss: 0.37349, Acc: 50.00000
Iteration: 20/1100 (1.8%)  Loss: 0.37024, Acc: 52.00000
Iteration: 21/1100 (1.9%)  Loss: 0.31172, Acc: 64.00000
Iteration: 22/1100 (2.0%)  Loss: 0.29889, Acc: 64.00000
Iteration: 23/1100 (2.1%)  Loss: 0.32116, Acc: 66.00000
Iteration: 24/1100 (2.2%)  Loss: 0.31103, Acc: 74.00000
Iteration: 25/1100 (2.3%)  Loss: 0.28157, Acc: 76.00000
Iteration: 26/1100 (2.4%)  Loss: 0.22721, Acc: 82.00000
Iteration: 27/1100 (2.5%)  Loss: 0.24645, Acc: 80.00000
Iteration: 28/1100 (2.5%)  Loss: 0.28085, Acc: 76.00000
Iteration: 29/1100 (2.6%)  Loss: 0.21644, Acc: 82.00000
Iteration: 30/1100 (2.7%)  Loss: 0.22552, Acc: 82.00000
Iteration: 31/1100 (2.8%)  Loss: 0.19832, Acc: 84.00000
Iteration: 32/1100 (2.9%)  Loss: 0.18913, Acc: 86.00000
Iteration: 33/1100 (3.0%)  Loss: 0.18527, Acc: 86.00000
Iteration: 34/1100 (3.1%)  Loss: 0.19863, Acc: 84.00000
Iteration: 35/1100 (3.2%)  Loss: 0.16656, Acc: 90.00000
Iteration: 36/1100 (3.3%)  Loss: 0.17566, Acc: 80.00000
Iteration: 37/1100 (3.4%)  Loss: 0.16723, Acc: 82.00000
Iteration: 38/1100 (3.5%)  Loss: 0.13901, Acc: 94.00000
Iteration: 39/1100 (3.5%)  Loss: 0.14630, Acc: 88.00000
Iteration: 40/1100 (3.6%)  Loss: 0.16909, Acc: 84.00000
Iteration: 41/1100 (3.7%)  Loss: 0.13749, Acc: 90.00000
Iteration: 42/1100 (3.8%)  Loss: 0.16060, Acc: 84.00000
Iteration: 43/1100 (3.9%)  Loss: 0.12409, Acc: 92.00000
Iteration: 44/1100 (4.0%)  Loss: 0.16228, Acc: 82.00000
Iteration: 45/1100 (4.1%)  Loss: 0.14838, Acc: 86.00000
Iteration: 46/1100 (4.2%)  Loss: 0.13091, Acc: 90.00000
Iteration: 47/1100 (4.3%)  Loss: 0.13386, Acc: 92.00000
Iteration: 48/1100 (4.4%)  Loss: 0.15651, Acc: 84.00000
Iteration: 49/1100 (4.5%)  Loss: 0.15982, Acc: 84.00000
Iteration: 50/1100 (4.5%)  Loss: 0.12564, Acc: 90.00000
```

"
38729,ModelCheckpoint results in Input 0 of layer is incompatible with the layer,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.1.0
- Python version: 3.7.4
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: 10.1
- GPU model and memory: NVIDIA GTX 970

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
Saving a model using keras ModelCheckpoint callback results in the following error:
```
ValueError: Input 0 of layer cls_outputs is incompatible with the layer: its rank is undefined, but the layer requires a defined rank.
```
**Describe the expected behavior**
Should save the model without errors.

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.
https://colab.research.google.com/drive/1Bf6EhjmnjzsZQUoiGAi1XVxjrFOPa2Cp

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
The ModelCheckpoint callback works when using `save_weights_only=True`, but I need to save the whole model for deployment to AI platform."
38727,Does TensorFlow provide a half normal initialiser?,"**System information**
- TensorFlow version (you are using): 2.
- Are you willing to contribute it (Yes/No): maybe

**Describe the feature and the current behavior/state.**

I would like to have access to more initializers for variables (not just the weights of layers), but also variables e.g. created with `add_weight`. Specifically, I would like to have an initializer for half normals, i.e. normals that produce only positive numbers (it's like applying the absolute value to a normal).

**Will this change the current api? How?**

No.

**Who will benefit with this feature?**

Everyone.

**Any Other info.**

I've asked a [question on Stack Overflow regarding my specific problem that TF currently doesn't seem to address](https://stackoverflow.com/q/61333274/3924118).
"
38726,Tensorflow failed to load model,"The main model was trained on my local machine with a GTX 1050 Ti GPU.  The error below is from the docker container being deployed in a VM in the Digital Ocean, and I've also tried it again on my local machine and works perfectly. 

**Dockerfile config:**
```
FROM  tensorflow/tensorflow:latest-py3
RUN apt update

COPY requirements.txt /requirements.txt
RUN python3 -m pip install -r requirements.txt && mkdir /app

COPY . /app
WORKDIR /app

ENTRYPOINT [""python3"", ""app.py""]
```

Error within the VM, where CPU is already being forced to be used via ""tf.config.set_visible_devices([], 'GPU')""
```
2020-04-20 23:02:03.505874: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory
2020-04-20 23:02:03.505973: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory
2020-04-20 23:02:03.505983: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2020-04-20 23:02:04.285763: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2020-04-20 23:02:04.285824: E tensorflow/stream_executor/cuda/cuda_driver.cc:351] failed call to cuInit: UNKNOWN ERROR (303)
2020-04-20 23:02:04.285854: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (sanic-server-5f779b76c9-xth26): /proc/driver/nvidia/version does not exist
2020-04-20 23:02:04.920805: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2020-04-20 23:02:04.928642: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2294605000 Hz
2020-04-20 23:02:04.929167: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x41ce6a0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-04-20 23:02:04.929206: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
Traceback (most recent call last):
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/py_checkpoint_reader.py"", line 70, in get_tensor
    self, compat.as_bytes(tensor_str))
RuntimeError: The length checksum does not match: expected 1137107832 but actual is 432382948

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""app.py"", line 17, in <module>
    TF = TensorflowImg()
  File ""/app/ml_modules/tensorflow_img.py"", line 28, in __init__
    self.model = self.__load_model()
  File ""/app/ml_modules/tensorflow_img.py"", line 48, in __load_model
    ""KerasLayer"": hub.KerasLayer})
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/saving/save.py"", line 150, in load_model
    return saved_model_load.load(filepath, compile)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/saving/saved_model/load.py"", line 89, in load
    model = tf_load.load_internal(path, loader_cls=KerasObjectLoader)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/saved_model/load.py"", line 552, in load_internal
    export_dir)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/saving/saved_model/load.py"", line 118, in __init__
    super(KerasObjectLoader, self).__init__(*args, **kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/saved_model/load.py"", line 128, in __init__
    self._restore_checkpoint()
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/saved_model/load.py"", line 280, in _restore_checkpoint
    load_status = saver.restore(variables_path)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/tracking/util.py"", line 1248, in restore
    object_graph_string = reader.get_tensor(base.OBJECT_GRAPH_PROTO_KEY)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/py_checkpoint_reader.py"", line 74, in get_tensor
    error_translator(e)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/py_checkpoint_reader.py"", line 48, in error_translator
    raise errors_impl.OpError(None, None, error_message, errors_impl.UNKNOWN)
tensorflow.python.framework.errors_impl.OpError: The length checksum does not match: expected 1137107832 but actual is 432382948
```

Here a successful one from my local-machine
```
2020-04-21 01:55:36.154300: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory
2020-04-21 01:55:36.156770: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory  
2020-04-21 01:55:36.157413: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2020-04-21 01:55:37.103847: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2020-04-21 01:55:37.105032: E tensorflow/stream_executor/cuda/cuda_driver.cc:351] failed call to cuInit: UNKNOWN ERROR (303)
2020-04-21 01:55:37.105865: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (332fc060f5f6): /proc/driver/nvidia/version does not exist
2020-04-21 01:55:37.703255: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-04-21 01:55:37.722212: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2495995000 Hz
2020-04-21 01:55:37.724314: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4d226c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-04-21 01:55:37.724943: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2020-04-21 01:55:41 +0000] [1] [INFO] Starting localhost development
[2020-04-21 01:55:41 +0000] [1] [DEBUG]

                 Sanic
         Build Fast. Run Fast.


[2020-04-21 01:55:41 +0000] [1] [INFO] Goin' Fast @ http://0.0.0.0:8000
2020-04-21 01:55:42.388099: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory
2020-04-21 01:55:42.389311: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory  
2020-04-21 01:55:42.390228: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2020-04-21 01:55:43.083080: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2020-04-21 01:55:43.083171: E tensorflow/stream_executor/cuda/cuda_driver.cc:351] failed call to cuInit: UNKNOWN ERROR (303)
2020-04-21 01:55:43.083197: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (332fc060f5f6): /proc/driver/nvidia/version does not exist
2020-04-21 01:55:43.682208: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-04-21 01:55:43.690862: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2495995000 Hz
2020-04-21 01:55:43.692032: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x3a17d60 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-04-21 01:55:43.692692: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[2020-04-21 01:55:47 +0000] [964] [INFO] Starting localhost development
[2020-04-21 01:55:47 +0000] [964] [INFO] Starting worker [964]
^CProcess Process-1:
[2020-04-21 01:56:43 +0000] [964] [INFO] Stopping worker [964]
[2020-04-21 01:56:43 +0000] [964] [INFO] Server Stopped
```"
38725,Casting a string tensor to a list of string,"I couldn't find an approach to casting a string tensor to a list of string. 
For instance, if someone has the following `sample_string_tensor`:

```python
import tensorflow as tf

batch_size = 4
sample_string_tensor = tf.convert_to_tensor([""sãmple utf-8 stríng - "" + str(i) for i in range(n_strings)])
sample_string_tensor
# <tf.Tensor: shape=(4,), dtype=string, numpy=
# array([b's\xc3\xa3mple utf-8 str\xc3\xadng - 0',
#        b's\xc3\xa3mple utf-8 str\xc3\xadng - 1',
#        b's\xc3\xa3mple utf-8 str\xc3\xadng - 2',
#        b's\xc3\xa3mple utf-8 str\xc3\xadng - 3'], dtype=object)>
```
how to cast to list of string below?
```python
['sãmple utf-8 stríng - 0',
 'sãmple utf-8 stríng - 1',
 'sãmple utf-8 stríng - 2',
 'sãmple utf-8 stríng - 3']

```
Note there are some no `ascii` character.
"
38724,mixed precision for non-Keras TensorFlow scripts,"**System information**
- TensorFlow version (you are using): 2.1.0
- Are you willing to contribute it (Yes/No): No (it would take too long for me to learn the low-level functionality of mixed-precision)

**Describe the feature and the current behavior/state.**
Currently, https://www.tensorflow.org/guide/keras/mixed_precision only works with Keras. 

**Will this change the current API? How?**
The mixed_precision module will either be relocated so that it is not exclusively for Keras, or a new submodule will be created.

**Who will benefit with this feature?**
Users who want to use mixed-precision but aren't using Keras.

**Any Other info.**
I'm not sure if this is even possible."
38723,Tflite model provides good accuracy on edge device but not in pythonic Interpreter,"OS system: linux (mintos)
Graphics Card: Nvidia 1660 ti MaxQ
System: Rog Zephyrus 

Problem:
I have converted my model to tflite and installed it on android device. The performance and accuracy seems to be good enough for a started point but when I use the tflite model in the tflite interpreter I get completly bad results. 
I would like to know what I have done wrong.

This is the code to load tflite and the interpreter


[tflite_detect.txt](https://github.com/tensorflow/tensorflow/files/4506390/tflite_detect.txt)
"
38722,TensorRT Converter could not work well with Bert model,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Centos 7
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): tf-nightly(2.2.0-dev20200420)
- Python version: 3.6
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10.1
- GPU model and memory: P100

**Describe the current behavior**

I tried to run the Bert-NER inference using TensorRT. I converted the model using the below code:
```python
def convert(input_saved_model_dir, output_saved_model_dir):
    params = DEFAULT_TRT_CONVERSION_PARAMS._replace(
        max_batch_size=512,
        maximum_cached_engines=16)
    converter = tf.experimental.tensorrt.Converter(
        input_saved_model_dir=input_saved_model_dir, conversion_params=params)
    converter.convert()

    def input_fn():
        for _ in range(100):
            yield np.ones(shape=[32, 128], dtype=np.int32), \
                  np.ones(shape=[32, 128], dtype=np.int32), \
                  np.ones(shape=[32, 128], dtype=np.int32)
    converter.build(input_fn=input_fn)
    converter.save(output_saved_model_dir)
```
However, I met a few issues:
1. The shape for the batch dimension is not correct in the converted model; The original model could work with the same input data; The error log is in below:
```
2020-04-20 15:18:03.775850: W tensorflow/core/framework/op_kernel.cc:1751] OP_REQUIRES failed at trt_engine_op.cc:572 : Invalid argument: Input shapes are inconsistent on the batch dimension, for StatefulPartitionedCall/model_1/bert_model/embedding_postprocessor/TRTEngineOp_0_0: [[32,128,768], [32,128,768], [1,128,768]]
Traceback (most recent call last):
  File ""/home/feihu/miniconda3/lib/python3.6/runpy.py"", line 193, in _run_module_as_main
    ""__main__"", mod_spec)
  File ""/home/feihu/miniconda3/lib/python3.6/runpy.py"", line 85, in _run_code
    exec(code, run_globals)
  File ""/home/feihu/.vscode-server/extensions/ms-python.python-2020.3.71659/pythonFiles/lib/python/debugpy/no_wheels/debugpy/__main__.py"", line 45, in <module>
    cli.main()
  File ""/home/feihu/.vscode-server/extensions/ms-python.python-2020.3.71659/pythonFiles/lib/python/debugpy/no_wheels/debugpy/../debugpy/server/cli.py"", line 429, in main
    run()
  File ""/home/feihu/.vscode-server/extensions/ms-python.python-2020.3.71659/pythonFiles/lib/python/debugpy/no_wheels/debugpy/../debugpy/server/cli.py"", line 266, in run_file
    runpy.run_path(options.target, run_name=compat.force_str(""__main__""))
  File ""/home/feihu/miniconda3/lib/python3.6/runpy.py"", line 263, in run_path
    pkg_name=pkg_name, script_name=fname)
  File ""/home/feihu/miniconda3/lib/python3.6/runpy.py"", line 96, in _run_module_code
    mod_name, mod_spec, pkg_name, script_name)
  File ""/home/feihu/miniconda3/lib/python3.6/runpy.py"", line 85, in _run_code
    exec(code, run_globals)
  File ""/home/feihu/github_projects/Named-Entity-Recognition/src/trt/trt_savedmodel_convert.py"", line 28, in <module>
    convert(input_saved_model_dir, output_saved_model_dir)
  File ""/home/feihu/github_projects/Named-Entity-Recognition/src/trt/trt_savedmodel_convert.py"", line 21, in convert
    converter.build(input_fn=input_fn)
  File ""/home/feihu/py-virtualenv/bert-compression-ner/lib/python3.6/site-packages/tensorflow/python/compiler/tensorrt/trt_convert.py"", line 1174, in build
    func(*map(ops.convert_to_tensor, inp))
  File ""/home/feihu/py-virtualenv/bert-compression-ner/lib/python3.6/site-packages/tensorflow/python/eager/function.py"", line 1612, in __call__
    return self._call_impl(args, kwargs)
  File ""/home/feihu/py-virtualenv/bert-compression-ner/lib/python3.6/site-packages/tensorflow/python/eager/wrap_function.py"", line 247, in _call_impl
    args, kwargs, cancellation_manager)
  File ""/home/feihu/py-virtualenv/bert-compression-ner/lib/python3.6/site-packages/tensorflow/python/eager/function.py"", line 1649, in _call_impl
    return self._call_flat(args, self.captured_inputs, cancellation_manager)
  File ""/home/feihu/py-virtualenv/bert-compression-ner/lib/python3.6/site-packages/tensorflow/python/eager/function.py"", line 1746, in _call_flat
    ctx, args, cancellation_manager=cancellation_manager))
  File ""/home/feihu/py-virtualenv/bert-compression-ner/lib/python3.6/site-packages/tensorflow/python/eager/function.py"", line 609, in call
    ctx=ctx)
  File ""/home/feihu/py-virtualenv/bert-compression-ner/lib/python3.6/site-packages/tensorflow/python/eager/execute.py"", line 60, in quick_execute
    inputs, attrs, num_outputs)
tensorflow.python.framework.errors_impl.InvalidArgumentError:  Input shapes are inconsistent on the batch dimension, for StatefulPartitionedCall/model_1/bert_model/embedding_postprocessor/TRTEngineOp_0_0: [[32,128,768], [32,128,768], [1,128,768]]
         [[node StatefulPartitionedCall/model_1/bert_model/embedding_postprocessor/TRTEngineOp_0_0 (defined at /github_projects/Named-Entity-Recognition/src/trt/trt_savedmodel_convert.py:14) ]] [Op:__inference_pruned_26783]
```
2. The saved model could not be larger than 2GB; Otherwise, there will be an error from protobuf about `GraphDef object could not exceed the size of 2GB`; 

3. The converted model could not work under the distributed strategy.



"
38721,Kernel dies in Anaconda ,"Good morning
I'm still have the coronavirus in my set-up:

MacPro (older), HighSierra -> Anaconda (the last version) -> select a Python (3,7) code which on other Macs/Anaconda worked -> RUN -> Kernel dies with the first Import command.

I tried as here suggested:
- re-istalled NumPy, directly in Anaconda and also with pip, nothing
- hided NumPy some cells lower, nothing
- installed some libraries here suggested, nothing

I think it must be an Installation issue, but don't know where the problems could be, thanks for help



"
38720,How can I write some layer's logic based on the current epoch or step of epoch?,"**System information**
- TensorFlow version (you are using): 2.1
- Are you willing to contribute it (Yes/No): maybe

**Describe the feature and the current behavior/state.**

I want to implement the logic of a custom layer based on the current epoch or step of epoch.

**Will this change the current api? How?**

I don't know.

**Who will benefit with this feature?**

Everyone.

**Any Other info.**

Yes, I've asked this question also on Stack Overflow: https://stackoverflow.com/q/61329343/3924118
"
42780,[ko][zh-cn] How to get chinese/korean fonts to work in matplotlib + Colab?,"The default Matplotlib setup in Colab doesn't include Chinese or Korean fonts, so these characters don't render.

I believe this is one of the reasons we have not been translating figure text.

I can get the browser to render this text by outputting svg-text:

```
from IPython.display import set_matplotlib_formats
set_matplotlib_formats('svg')
matplotlib.rcParams['svg.fonttype'] = 'none'
```

But that messes up a lot of the formatting.

Some searching shows that it might just be a matter of installing the right fonts and adding them to the `matplotlib.rc` configuration, but I haven't found a end-to-end setup that works yet. 

Does anyone have experience setting this up?

"
38718,libstdc++.so.6: version `GLIBCXX_3.4.21' not found ,"OS: Centos 6.2
Tensorflow installed from source
Tensorflow version: 2.1.0
Python version: 3.5
Bazel version: 0.28
GCC version: 6.3.0
GPU support: NO.

When i tried to compile tensorflow from source i get the following error:

COMMAND: bazel build //tensorflow/tools/pip_package:build_pip_package

ERROR: /tmp/tensor/tensorflow-2.1.0/tensorflow/lite/python/optimize/BUILD:29:1: SWIGing tensorflow/lite/python/optimize/calibration_wrapper.i failed (Exit 1)
/root/.cache/bazel/_bazel_root/install/aa7e5eb7da84c1e7540941e7c9d19262/_embedded_binaries/process-wrapper: /usr/lib64/libstdc++.so.6: version `GLIBCXX_3.4.21' not found (required by /root/.cache/bazel/_bazel_root/install/aa7e5eb7da84c1e7540941e7c9d19262/_embedded_binaries/process-wrapper)
Target //tensorflow/tools/pip_package:build_pip_package failed to build
Use --verbose_failures to see the command lines of failed build steps.
INFO: Elapsed time: 58.251s, Critical Path: 14.93s
INFO: 231 processes: 231 local.
FAILED: Build did NOT complete successfully

I tried to add the path of the libraries to the LD_LIBRARY_PATH but it always try to find it in /usr/lib64. 

Also i tried with the following command:

BAZEL_LINKOPTS=-static-libstdc++ BAZEL_LINKLIBS=-l%:libstdc++.a bazel build //tensorflow/tools/pip_package:build_pip_package

But the issue is still there.

The directory where the library is installed is:  /share/apps/gcc-6.3.0/lib64/libstdc++.so.6

Thanks.

"
38714,Ragged tensor input for keras.Model,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): 2.1.0
- Python version: 3.7.4

**Describe the current behavior**
If a ragged-tensor-input to a keras model e.g. by tensorflow.keras.layers.Input(ragged=True) or tensorflow.keras.Input(ragged=True) is not used or directly connected to the output, an error is raised (see below). This is may not be a problem since the ragged tensor is not used anyway, however, I encountered the same issue for a ragged tensor which is only used for indexing or reshaping. 
>ValueError: Layer input_5 does not support RaggedTensors as input. Inputs received: [tf.RaggedTensor(values=Tensor(""RaggedFromVariant_1/RaggedTensorFromVariant:1"", shape=(None, 1), dtype=float32), row_splits=Tensor(""RaggedFromVariant_1/RaggedTensorFromVariant:0"", shape=(None,), dtype=int64))]. You can try converting your input to an uniform tensor.


**Describe the expected behavior**
The ragged-tensor-input is accepted as an input, even if it is not used in the model. Hopefully this will also resolve the issue in a more complex model with the same error message/behavior.

**Standalone code to reproduce the issue**
The code below shows model3 which does not work, although model and model2 work perfectly.

```python3
import tensorflow as tf
import numpy as np

class DenseRagged(tf.keras.layers.Layer):
    def __init__(self, 
        units,
        use_bias=True,
        activation = 'linear',
        **kwargs):
        super(DenseRagged, self).__init__(**kwargs)
        self._supports_ragged_inputs = True 
        self.units = units
        self.use_bias = use_bias
        self.activation = tf.keras.activations.get(activation)
    def build(self, input_shape):
        last_dim = input_shape[-1]
        self.kernel = self.add_weight(
                'kernel',
                shape=[last_dim, self.units],
                trainable=True)
        if self.use_bias:
            self.bias = self.add_weight(
                    'bias',
                    shape=[self.units,],
                    trainable=True)
        else:
            self.bias = None
        super(DenseRagged, self).build(input_shape)
    def call(self, inputs):
        outputs = tf.ragged.map_flat_values(tf.matmul,inputs, self.kernel)
        if self.use_bias:
            outputs = tf.ragged.map_flat_values(tf.nn.bias_add,outputs, self.bias)
        outputs =  tf.ragged.map_flat_values(self.activation,outputs)
        return outputs    

class PoolingRagged(tf.keras.layers.Layer):
    def __init__(self, **kwargs):
        super(PoolingRagged, self).__init__(**kwargs)
        self._supports_ragged_inputs = True 
    def build(self, input_shape):
        super(PoolingRagged, self).build(input_shape)
    def call(self, inputs):
        node = inputs
        out = tf.math.reduce_mean(node,axis=1)
        return out


data_A = tf.ragged.constant([[[2.0],[ 2.0]], [[3.0]], [[4.0], [5.0],[ 6.0]]] ,ragged_rank=1) 
data_B = tf.ragged.constant([[[4.0],[ 4.0]], [[6.0]], [[8.0], [10.0],[12.0]]],ragged_rank=1) 
data_y = np.array([3.9,5.8,11])
print(data_A.shape,data_B.shape)

in_A = tf.keras.Input(shape=(None,1),dtype =""float32"",ragged=True)
out = DenseRagged(1)(in_A)
out = PoolingRagged()(out)
model = tf.keras.models.Model(inputs=in_A, outputs=out)

optimizer = tf.keras.optimizers.Adam(lr=1e-3)
model.compile(loss='mean_squared_error',
              optimizer=optimizer,
              metrics=['mean_absolute_error', 'mean_squared_error'])

model.fit(x=data_A,y=data_y,epochs=200)
print(""this works"")

in_A2 = tf.keras.Input(shape=(None,1),dtype =""float32"",ragged=True)
in_B2 = tf.keras.Input(shape=(None,1),dtype =""float32"",ragged=True)
outA2 = DenseRagged(1)(in_A2)
outB2 = DenseRagged(1)(in_B2)
outA2 = PoolingRagged()(outA2)
outB2 = PoolingRagged()(outB2)
out2 = tf.keras.layers.Add()([outA2,outB2])
model2 = tf.keras.models.Model(inputs=[in_A2,in_B2], outputs=out2)


optimizer = tf.keras.optimizers.Adam(lr=1e-3)
model2.compile(loss='mean_squared_error',
              optimizer=optimizer,
              metrics=['mean_absolute_error', 'mean_squared_error'])

model2.fit(x=[data_A,data_B],y=data_y,epochs=200)
print(""this works,too"")

in_A3 = tf.keras.Input(shape=(None,1),dtype =""float32"",ragged=True)
in_B3 = tf.keras.Input(shape=(None,1),dtype =""float32"",ragged=True)
out3 = DenseRagged(1)(in_A3)
out3 = PoolingRagged()(out3)
model3 = tf.keras.models.Model(inputs=[in_A3,in_B3], outputs=out3)


optimizer = tf.keras.optimizers.Adam(lr=1e-3)
model3.compile(loss='mean_squared_error',
              optimizer=optimizer,
              metrics=['mean_absolute_error', 'mean_squared_error'])

model3.fit(x=[data_A,data_B],y=data_y,epochs=200)
print(""this does not work"")
```
"
38713,Online documentation missing python docs,"## URL(s) with the issue:
https://www.tensorflow.org/api_docs/python/tf/keras/experimental/CosineDecay
https://www.tensorflow.org/api_docs/python/tf/keras/experimental/CosineDecayRestarts
https://www.tensorflow.org/api_docs/python/tf/keras/experimental/LinearCosineDecay
https://www.tensorflow.org/api_docs/python/tf/keras/experimental/NoisyLinearCosineDecay
https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/schedules/ExponentialDecay
https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/schedules/InverseTimeDecay
https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/schedules/PiecewiseConstantDecay
https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/schedules/PolynomialDecay

May be present on others, but I'm not going to scour the web site looking.

## Description of issue (what needs changing):
The general documentation of these classes does not show up on the web site. This leads to confusion as many of them have argument documentation containing statements such as *""See the decay computation above""*, when there is no documented computation above.

Instead you have to open the source code to see the documentation that is mentioned.

Here's an example:
![image](https://user-images.githubusercontent.com/1826947/79771096-4f2dea00-82fc-11ea-8373-ec3572b00f3b.png)
And here's the missing documentation:
![image](https://user-images.githubusercontent.com/1826947/79771213-77b5e400-82fc-11ea-9d0d-2dc9efc02232.png)
"
38712,Cannot build TF 2.2 rc2 or rc3 on Windows,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **Windows 10 x64**
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): **source (git)**
- TensorFlow version: **2.2.0-rc2 or rc3** (same issue)
- Python version: **3.6.8**
- Installed using virtualenv? pip? conda?: **venv and pip**
- Bazel version (if compiling from source): **2.0.0**
- GCC/Compiler version (if compiling from source): **VS build tools 2019** (I believe 14.25.28610)
- CUDA/cuDNN version: **10.2 / 7.6**
- GPU model and memory: **build machine does not have a supported GPU. Just using this machine to do builds. Building TF 2.1.0 was successful on this machine a week ago**.



**Describe the problem**

**Provide the exact sequence of commands / steps that you executed before running into the problem**

Plenty of disk space available (> 400GB). Using a 6GB RAM system.

- git clone of tensorflow
- git checkout v2.2.0-rc2 (also tried rc3, same result)
- bazel clean --expunge
- python ./configure.py
  ROCm: no
  CUDA: yes
  Compute Capability: 6.1
  all other default options
- bazel build //tensorflow/tools/pip_package:build_pip_package

The error I get is :

ERROR: C:/users/....../tensorflow/tensorflow/core/kernels/BUILD:1321:1: C++ compilation of rule '//tensorflow/core/kernels:tile_ops_gpu' failed (Exit 2)


**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
38711,ResNeXt seems to be missing,"[Keras applications](https://github.com/keras-team/keras-applications) has [ResNeXt nets](https://github.com/keras-team/keras-applications/blob/master/keras_applications/resnext.py) (since 17 months). TF2 does not seem to provide constructors for them.

Although there are a couble to lines in TF2 that refer to ResNeXt:

https://github.com/tensorflow/tensorflow/blob/5041f45fdb0f3ff10645080a06d7ab7b13fa0a95/tensorflow/python/keras/applications/resnet.py#L52

https://github.com/tensorflow/tensorflow/blob/5041f45fdb0f3ff10645080a06d7ab7b13fa0a95/tensorflow/python/keras/applications/resnet.py#L73

https://github.com/tensorflow/tensorflow/blob/5041f45fdb0f3ff10645080a06d7ab7b13fa0a95/tensorflow/python/keras/applications/resnet.py#L90

https://github.com/tensorflow/tensorflow/blob/5041f45fdb0f3ff10645080a06d7ab7b13fa0a95/tensorflow/python/keras/applications/resnet.py#L92

What's up here? Did you forget them? Are they buggy?"
38710,Training Loaded Models is MUCH slower,"**System information**
Windows 7
Python 3.8
Tensorflow 2.1

**Describe the current behaviour**

When I create a model ""from scratch"" and train it, with some configs, and data. Each epoch takes around 3 minutes to terminate.

If I stop the training after the first epoch, and load the model to continue training (same data, same configs) instead of taking the 3 minutes, every epoch takes around 12 minutes (4x) to conclude.

This is how I am creating the model:

```python

model = Sequential()
model.add(LSTM(128, input_shape=(train_x.shape[1:]), return_sequences=True))
model.add(Dropout(0.3))
model.add(BatchNormalization())


model.add(LSTM(128, return_sequences=True))
model.add(Dropout(0.3))
model.add(BatchNormalization())

model.add(LSTM(128))
model.add(Dropout(0.2))
model.add(BatchNormalization())

model.add(Dense(32, activation='relu'))
model.add(Dropout(0.3))

model.add(Dense(2, activation='softmax'))


opt = tf.keras.optimizers.Adam(lr=0.001, decay=1e-6)

filepath = ""tf/checkpoints/RNN_Final-{epoch:02d}-{val_accuracy:.3f}.hdf5""  # unique file name that will include the epoch and the validation acc for that epoch
checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath, verbose=1, monitor='val_accuracy', save_best_only=True, mode='max') # saves only the best ones

history = model.fit(
    train_x, train_y,
    batch_size=BATCH_SIZE,
    epochs=EPOCHS,
    validation_data=(validation_x, validation_y),
    callbacks=[checkpoint,tensorboard],
)
```

After the first Epoch, I am running the code like this:


```python

model = load_model(""mymodel_1EPOCH. hdf5"")

history = model.fit(
    train_x, train_y,
    batch_size=BATCH_SIZE,
    epochs=EPOCHS,
    initial_epoch = 1,
    validation_data=(validation_x, validation_y),
    callbacks=[checkpoint,tensorboard],
)
```






**Describe the expected behaviour**
I was expecting the loaded model, to run at the same speed as the new model. I am saving the models in _.hdf5_. Should I use any other file type?"
38709,Input_shape changeable in some models but not in others.,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS 10.15.4
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): 
- TensorFlow version (use command below): Tensorflow 2.2 / tf-nightly 2.3.0 (installing nightly didn't help solve the problem)
- Python version: 3.7.7
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
I want to do transfer learning but change the input_shape of the model. I used code from a Udacity tutorial on transfer learning, in which I reduce the input size of the tfhub feature_vector by more than half and everything works fine. When I tried to to this with another network, it doesn't work. Why is this?
**Describe the expected behavior**
Input shape should be changeable and the model's summary should be outputted without a problem.
**Standalone code to reproduce the issue**
https://colab.research.google.com/drive/1AIH9d-sqISB1BVi01g7Eqtv6nzBiiAnR

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

(Udacity)
2020-04-20 15:27:55.636605: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f9a3907cc60 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-04-20 15:27:55.636646: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
Model: ""sequential""
...
Total params: 21,813,029
Trainable params: 10,245
Non-trainable params: 21,802,784
_________________________________________________________________


vs.

(my code)
2020-04-20 15:35:21.610011: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f82a0172350 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-04-20 15:35:21.610056: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
Traceback (most recent call last):
  File ""network_model.py"", line 17, in <module>
    tf.keras.layers.Dense(NUM_CLASSES, activation = 'softmax')])
  File ""/Users/carlos/Library/Python/3.7/lib/python/site-packages/tensorflow/python/training/tracking/base.py"", line 456, in _method_wrapper
    result = method(self, *args, **kwargs)
  File ""/Users/carlos/Library/Python/3.7/lib/python/site-packages/tensorflow/python/keras/engine/sequential.py"", line 137, in __init__
    self.add(layer)
  File ""/Users/carlos/Library/Python/3.7/lib/python/site-packages/tensorflow/python/training/tracking/base.py"", line 456, in _method_wrapper
    result = method(self, *args, **kwargs)
  File ""/Users/carlos/Library/Python/3.7/lib/python/site-packages/tensorflow/python/keras/engine/sequential.py"", line 210, in add
    layer(x)
  File ""/Users/carlos/Library/Python/3.7/lib/python/site-packages/tensorflow/python/keras/engine/base_layer.py"", line 930, in __call__
    outputs = call_fn(cast_inputs, *args, **kwargs)
  File ""/Users/carlos/Library/Python/3.7/lib/python/site-packages/tensorflow/python/autograph/impl/api.py"", line 262, in wrapper
    raise e.ag_error_metadata.to_exception(e)
ValueError: in user code:

    /Users/carlos/Library/Python/3.7/lib/python/site-packages/tensorflow_hub/keras_layer.py:229 call  *
        result = smart_cond.smart_cond(training,
    /Users/carlos/Library/Python/3.7/lib/python/site-packages/tensorflow/python/saved_model/load.py:486 _call_attribute  **
        return instance.__call__(*args, **kwargs)
    /Users/carlos/Library/Python/3.7/lib/python/site-packages/tensorflow/python/eager/def_function.py:695 __call__
        result = self._call(*args, **kwds)
    /Users/carlos/Library/Python/3.7/lib/python/site-packages/tensorflow/python/eager/def_function.py:737 _call
        self._initialize(args, kwds, add_initializers_to=initializers)
    /Users/carlos/Library/Python/3.7/lib/python/site-packages/tensorflow/python/eager/def_function.py:617 _initialize
        *args, **kwds))
    /Users/carlos/Library/Python/3.7/lib/python/site-packages/tensorflow/python/eager/function.py:2447 _get_concrete_function_internal_garbage_collected
        graph_function, _, _ = self._maybe_define_function(args, kwargs)
    /Users/carlos/Library/Python/3.7/lib/python/site-packages/tensorflow/python/eager/function.py:2775 _maybe_define_function
        graph_function = self._create_graph_function(args, kwargs)
    /Users/carlos/Library/Python/3.7/lib/python/site-packages/tensorflow/python/eager/function.py:2665 _create_graph_function
        capture_by_value=self._capture_by_value),
    /Users/carlos/Library/Python/3.7/lib/python/site-packages/tensorflow/python/framework/func_graph.py:981 func_graph_from_py_func
        func_outputs = python_func(*func_args, **func_kwargs)
    /Users/carlos/Library/Python/3.7/lib/python/site-packages/tensorflow/python/eager/def_function.py:528 wrapped_fn
        return weak_wrapped_fn().__wrapped__(*args, **kwds)
    /Users/carlos/Library/Python/3.7/lib/python/site-packages/tensorflow/python/saved_model/function_deserialization.py:251 restored_function_body
        ""\n\n"".join(signature_descriptions)))

    ValueError: Could not find matching function to call loaded from the SavedModel. Got:
      Positional arguments (4 total):
        * Tensor(""inputs:0"", shape=(None, 64, 64, 3), dtype=float32)
        * False
        * False
        * 0.99
      Keyword arguments: {}
    
    Expected these arguments to match one of the following 4 option(s):
    
    Option 1:
      Positional arguments (4 total):
        * TensorSpec(shape=(None, 96, 96, 3), dtype=tf.float32, name='inputs')
        * True
        * True
        * TensorSpec(shape=(), dtype=tf.float32, name='batch_norm_momentum')
      Keyword arguments: {}
    
    Option 2:
      Positional arguments (4 total):
        * TensorSpec(shape=(None, 96, 96, 3), dtype=tf.float32, name='inputs')
        * True
        * False
        * TensorSpec(shape=(), dtype=tf.float32, name='batch_norm_momentum')
      Keyword arguments: {}
    
    Option 3:
      Positional arguments (4 total):
        * TensorSpec(shape=(None, 96, 96, 3), dtype=tf.float32, name='inputs')
        * False
        * False
        * TensorSpec(shape=(), dtype=tf.float32, name='batch_norm_momentum')
      Keyword arguments: {}
    
    Option 4:
      Positional arguments (4 total):
        * TensorSpec(shape=(None, 96, 96, 3), dtype=tf.float32, name='inputs')
        * False
        * True
        * TensorSpec(shape=(), dtype=tf.float32, name='batch_norm_momentum')
      Keyword arguments: {}"
38708,LSTM Keras conversion to tflite model work fine. But the MLkit firebase ml model interpreter error on loading model,"**System information**
- OS Platform: Google Colab, Android 9 (Poco F1)
- TensorFlow installed from (source or binary): binary
- TensorFlow version (or github SHA if from source): 2.2.0-rc3
- firebase ml model interpreter version: firebase-ml-model-interpreter:22.0.2

**I used this following code to produce my LSTM model**
```
model = Sequential()
model.add(LSTM(128, input_shape=X.shape[1:], return_sequences=True))
model.add(Dropout(0.2))
model.add(BatchNormalization())

model.add(LSTM(128, input_shape=X.shape[1:], return_sequences=True))
model.add(Dropout(0.2))
model.add(BatchNormalization())

model.add(LSTM(128, input_shape=X.shape[1:]))
model.add(Dropout(0.1))
model.add(BatchNormalization())

model.add(Dense(64, activation=""relu""))
model.add(Dropout(0.2))

model.add(Dense(1, activation=""sigmoid""))

opt = tf.keras.optimizers.Adam(lr=0.001, decay=1e-6)
model.compile(loss=""binary_crossentropy"",
             optimizer=opt,
             metrics=[""accuracy""])
```

**Command used to run the converter or code if you’re using the Python API**

```
converter = tf.lite.TFLiteConverter.from_keras_model(model)
tflite_model = converter.convert()
```


**Failure details**
the conversion run just fine, no error and I can download the TFlite model. However, when I tried to put this model into my android app, it shows error caused by `Caused by: java.lang.IllegalArgumentException: ByteBuffer is not a valid flatbuffer model`. 

I think if the conversion to tflite model is successful, we should be able to run it on the interpreter 


**Any other info / logs**
here is the full logs of the error
```
E/ModelResourceManager: Error preloading model resource
    com.google.firebase.ml.common.FirebaseMLException: Local model load failed with the model options: Local model path: drowsy-detector-v21.tflite. Remote model name: unspecified. 
        at com.google.firebase.ml.common.internal.modeldownload.zzj.zza(com.google.firebase:firebase-ml-common@@22.1.0:36)
        at com.google.android.gms.internal.firebase_ml.zzrj.zza(com.google.firebase:firebase-ml-model-interpreter@@22.0.2:111)
        at com.google.android.gms.internal.firebase_ml.zzrj.zzol(com.google.firebase:firebase-ml-model-interpreter@@22.0.2:107)
        at com.google.android.gms.internal.firebase_ml.zzqr.zzf(com.google.firebase:firebase-ml-common@@22.1.0:53)
        at com.google.android.gms.internal.firebase_ml.zzqr$zza.zzoo(com.google.firebase:firebase-ml-common@@22.1.0:7)
        at com.google.android.gms.internal.firebase_ml.zzqr$zza.call(com.google.firebase:firebase-ml-common@@22.1.0:24)
        at com.google.android.gms.internal.firebase_ml.zzpx.zza(com.google.firebase:firebase-ml-common@@22.1.0:32)
        at com.google.android.gms.internal.firebase_ml.zzpw.run(Unknown Source:4)
        at android.os.Handler.handleCallback(Handler.java:873)
        at android.os.Handler.dispatchMessage(Handler.java:99)
        at com.google.android.gms.internal.firebase_ml.zze.dispatchMessage(com.google.firebase:firebase-ml-common@@22.1.0:6)
        at android.os.Looper.loop(Looper.java:201)
        at android.os.HandlerThread.run(HandlerThread.java:65)
     Caused by: java.lang.IllegalArgumentException: ByteBuffer is not a valid flatbuffer model
        at org.tensorflow.lite.NativeInterpreterWrapper.createModelWithBuffer(Native Method)
        at org.tensorflow.lite.NativeInterpreterWrapper.<init>(NativeInterpreterWrapper.java:59)
        at org.tensorflow.lite.Interpreter.<init>(Interpreter.java:207)
        at com.google.android.gms.internal.firebase_ml.zzrj.zzb(com.google.firebase:firebase-ml-model-interpreter@@22.0.2:174)
        at com.google.android.gms.internal.firebase_ml.zzrl.zzc(Unknown Source:0)
        at com.google.android.gms.internal.firebase_ml.zzrj.zza(com.google.firebase:firebase-ml-model-interpreter@@22.0.2:170)
        at com.google.android.gms.internal.firebase_ml.zzrk.zza(Unknown Source:6)
        at com.google.firebase.ml.common.internal.modeldownload.zzj.zzb(com.google.firebase:firebase-ml-common@@22.1.0:61)
        at com.google.firebase.ml.common.internal.modeldownload.zzj.zza(com.google.firebase:firebase-ml-common@@22.1.0:21)
        at com.google.android.gms.internal.firebase_ml.zzrj.zza(com.google.firebase:firebase-ml-model-interpreter@@22.0.2:111) 
        at com.google.android.gms.internal.firebase_ml.zzrj.zzol(com.google.firebase:firebase-ml-model-interpreter@@22.0.2:107) 
        at com.google.android.gms.internal.firebase_ml.zzqr.zzf(com.google.firebase:firebase-ml-common@@22.1.0:53) 
        at com.google.android.gms.internal.firebase_ml.zzqr$zza.zzoo(com.google.firebase:firebase-ml-common@@22.1.0:7) 
        at com.google.android.gms.internal.firebase_ml.zzqr$zza.call(com.google.firebase:firebase-ml-common@@22.1.0:24) 
        at com.google.android.gms.internal.firebase_ml.zzpx.zza(com.google.firebase:firebase-ml-common@@22.1.0:32) 
        at com.google.android.gms.internal.firebase_ml.zzpw.run(Unknown Source:4) 
        at android.os.Handler.handleCallback(Handler.java:873) 
        at android.os.Handler.dispatchMessage(Handler.java:99) 
        at com.google.android.gms.internal.firebase_ml.zze.dispatchMessage(com.google.firebase:firebase-ml-common@@22.1.0:6) 
        at android.os.Looper.loop(Looper.java:201) 
        at android.os.HandlerThread.run(HandlerThread.java:65) 
```
"
38707,InternalError: Unsupported object type float,"Getting this error even though there are no NaNs and X_train and y_train have relevant datatype.
```
    InternalError                             Traceback (most recent call last)
C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\client\session.py in _do_call(self, fn, *args)
   1366     try:
-> 1367       return fn(*args)
   1368     except errors.OpError as e:

C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\client\session.py in _run_fn(feed_dict, fetch_list, target_list, options, run_metadata)
   1351       return self._call_tf_sessionrun(options, feed_dict, fetch_list,
-> 1352                                       target_list, run_metadata)
   1353 

C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\client\session.py in _call_tf_sessionrun(self, options, feed_dict, fetch_list, target_list, run_metadata)
   1444                                             fetch_list, target_list,
-> 1445                                             run_metadata)
   1446 

InternalError: Unsupported object type float

During handling of the above exception, another exception occurred:

InternalError                             Traceback (most recent call last)
<ipython-input-69-24be0b0bc7db> in <module>
----> 1 lin_reg.train(train_input_fn, steps=1000)

C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_estimator\python\estimator\estimator.py in train(self, input_fn, hooks, steps, max_steps, saving_listeners)
    372 
    373       saving_listeners = _check_listeners_type(saving_listeners)
--> 374       loss = self._train_model(input_fn, hooks, saving_listeners)
    375       logging.info('Loss for final step: %s.', loss)
    376       return self

C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_estimator\python\estimator\estimator.py in _train_model(self, input_fn, hooks, saving_listeners)
   1162       return self._train_model_distributed(input_fn, hooks, saving_listeners)
   1163     else:
-> 1164       return self._train_model_default(input_fn, hooks, saving_listeners)
   1165 
   1166   def _train_model_default(self, input_fn, hooks, saving_listeners):

C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_estimator\python\estimator\estimator.py in _train_model_default(self, input_fn, hooks, saving_listeners)
   1196       return self._train_with_estimator_spec(estimator_spec, worker_hooks,
   1197                                              hooks, global_step_tensor,
-> 1198                                              saving_listeners)
   1199 
   1200   def _train_model_distributed(self, input_fn, hooks, saving_listeners):

C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_estimator\python\estimator\estimator.py in _train_with_estimator_spec(self, estimator_spec, worker_hooks, hooks, global_step_tensor, saving_listeners)
   1496       while not mon_sess.should_stop():
   1497         _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])
-> 1498         any_step_done = True
   1499     if not any_step_done:
   1500       logging.warning('Training with estimator made no steps. '

C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\training\monitored_session.py in __exit__(self, exception_type, exception_value, traceback)
    883     if exception_type in [errors.OutOfRangeError, StopIteration]:
    884       exception_type = None
--> 885     self._close_internal(exception_type)
    886     # __exit__ should return True to suppress an exception.
    887     return exception_type is None

C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\training\monitored_session.py in _close_internal(self, exception_type)
    921         if self._sess is None:
    922           raise RuntimeError('Session is already closed.')
--> 923         self._sess.close()
    924       finally:
    925         self._sess = None

C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\training\monitored_session.py in close(self)
   1188     if self._sess:
   1189       try:
-> 1190         self._sess.close()
   1191       except _PREEMPTION_ERRORS as e:
   1192         logging.warning(

C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\training\monitored_session.py in close(self)
   1356       self._coord.join(
   1357           stop_grace_period_secs=self._stop_grace_period_secs,
-> 1358           ignore_live_threads=True)
   1359     finally:
   1360       try:

C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\training\coordinator.py in join(self, threads, stop_grace_period_secs, ignore_live_threads)
    387       self._registered_threads = set()
    388       if self._exc_info_to_raise:
--> 389         six.reraise(*self._exc_info_to_raise)
    390       elif stragglers:
    391         if ignore_live_threads:

C:\ProgramData\Anaconda3\lib\site-packages\six.py in reraise(tp, value, tb)
    690                 value = tp()
    691             if value.__traceback__ is not tb:
--> 692                 raise value.with_traceback(tb)
    693             raise value
    694         finally:

C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_estimator\python\estimator\inputs\queues\feeding_queue_runner.py in _run(self, sess, enqueue_op, feed_fn, coord)
     92         try:
     93           feed_dict = None if feed_fn is None else feed_fn()
---> 94           sess.run(enqueue_op, feed_dict=feed_dict)
     95         except (errors.OutOfRangeError, errors.CancelledError):
     96           # This exception indicates that a queue was closed.

C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\client\session.py in run(self, fetches, feed_dict, options, run_metadata)
    958     try:
    959       result = self._run(None, fetches, feed_dict, options_ptr,
--> 960                          run_metadata_ptr)
    961       if run_metadata:
    962         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)

C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\client\session.py in _run(self, handle, fetches, feed_dict, options, run_metadata)
   1181     if final_fetches or final_targets or (handle and feed_dict_tensor):
   1182       results = self._do_run(handle, final_targets, final_fetches,
-> 1183                              feed_dict_tensor, options, run_metadata)
   1184     else:
   1185       results = []

C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\client\session.py in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)
   1359     if handle is None:
   1360       return self._do_call(_run_fn, feeds, fetches, targets, options,
-> 1361                            run_metadata)
   1362     else:
   1363       return self._do_call(_prun_fn, handle, feeds, fetches)

C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\client\session.py in _do_call(self, fn, *args)
   1384                     '\nsession_config.graph_options.rewrite_options.'
   1385                     'disable_meta_optimizer = True')
-> 1386       raise type(e)(node_def, op, message)
   1387 
   1388   def _extend_graph(self):

InternalError: Unsupported object type float


```"
42800,[ar] How to show the titles in Arabic for already translated tutorials in the side navigation menu?,"When I choose the Arabic language, for a given tutorial, like this one: https://www.tensorflow.org/tutorials/keras/classification?hl=ar, I was expecting to see the title of this already translated tutorial in Arabic in the right side navigation menu, but it's showing in English as you can see in the following picture:
 
<img width=""1265"" alt=""image"" src=""https://user-images.githubusercontent.com/2883926/79729137-55699980-82ef-11ea-890b-3dab9c932652.png"">

Showing the translated tutorials' title in Arabic for already translated tutorial can be useful to reader as a visual identification of what is already in Arabic.

@lamberta
Could you explain whether it's something I can configure myself with a PR or it requires extra development?

Thanks."
38703,Mixed Precision: which 'endpoint layer' to set dtype='float32' in Dueling DQN,"Hi, following the [mixed precision documentation](https://www.tensorflow.org/guide/keras/mixed_precision#overview) , it is recommended to have dtype of output layer as float32

>  And regardless of what your model ends in, make sure the output is float32.

However, I am not sure which 'layer' to apply float32 for Dueling DQN model. The architecture is as follows:
```
body = tf.keras.Sequential([tf.keras.layers.Dense(256, activation='relu'),
                             tf.keras.layers.Dense(256, activation='relu'),
                             tf.keras.layers.Dense(256, activation='relu'),])

value = tf.keras.Sequential([tf.keras.layers.Dense(256, activation='relu'),
                              tf.keras.layers.Dense(1),])

advantage = tf.keras.Sequential([tf.keras.layers.Dense(256, activation='relu'),
                                  tf.keras.layers.Dense(3, use_bias=False),])

q = body(training_input)

v = value(q)

a = advantage(q)
a -= tf.reduce_mean(a, axis=-1, keepdims=True)

final_q = v + a 
# final_q is used to calculate loss
```
should I set dtype='float32' at cases (1, 2, or 3):

1. value **&** advantage `Sequential` function
2. value `Sequential` function **&**`tf.reduce_mean()` function
3. **cast** final_q as float32

or maybe something else?"
38702,Data cardinality,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Google colab
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): preinstalled
- TensorFlow version (use command below): v2.2.0-rc3-0-gaad398b5e9, 2.2.0-rc3
- Python version: 3.6.9
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

**Describe the current behavior**

I build a model with to independent sequential sub-models like:
![image](https://user-images.githubusercontent.com/44928904/79725338-5229da00-82fe-11ea-943b-58c2af493e8b.png)
 but number of samples for two sub-models are different and i am seeing this error:
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
<ipython-input-33-a01d55a188be> in <module>()
----> 5 model.fit({'input1':x1.to_numpy(), 'input2':x2.to_numpy()}, {'output1':y1.to_numpy(), 'output2':y2.to_numpy()}, epochs=10)

3 frames
/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py in __init__(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)
    280             label, "", "".join(str(i.shape[0]) for i in nest.flatten(data)))
    281       msg += ""Please provide data which shares the same first dimension.""
--> 282       raise ValueError(msg)
    283     num_samples = num_samples.pop()
    284 

ValueError: Data cardinality is ambiguous:
  x sizes: 2408, 2371
  y sizes: 2408, 2371
Please provide data which shares the same first dimension.
**Describe the expected behavior**
because the number of batches are the same, so i think it must work...

"
38701,TFLite Concatenation Fails on GPU delegate,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes.
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Mac
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Tested on Samsung Galaxy
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): v2.1.0-rc2-17-ge5bf8de410 2.1.0
- Python version: 3.7
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:


**Describe the current behavior**
Concatenation Op for non BCHW dimensions fails on GPU delegate, same model runs fine on CPU delegate.

(See below code for creating `model.tflite`)

The following benchmark runs successfully (CPU):
```
adb shell /data/local/tmp/benchmark_model      --graph=/data/local/tmp/model.tflite     --num_threads=4 --use_gpu=false --num_runs=1000
```

The following benchmark run fails (GPU):
```
adb shell /data/local/tmp/benchmark_model      --graph=/data/local/tmp/model.tflite     --num_threads=4 --use_gpu=true --num_runs=1000
```
Error message:
```
INFO: Initialized TensorFlow Lite runtime.
INFO: Created TensorFlow Lite delegate for GPU.
ERROR: TfLiteGpuDelegate Init: CONCATENATION: Dimensions are not BHWC: 2 1 30
ERROR: TfLiteGpuDelegate Prepare: delegate is not initialized
ERROR: Node number 1 (TfLiteGpuDelegateV2) failed to prepare.
```

**Describe the expected behavior**

TFLite Model should run concat op succesfully both on CPU and GPU.

**Standalone code to reproduce the issue**
```
import numpy as np
import tensorflow as tf

# Construct a basic model.
root = tf.train.Checkpoint()
root.v1 = tf.Variable(np.ones((1, 10), dtype=np.float32))
root.v2 = tf.Variable(np.ones((1, 20), dtype=np.float32))
root.f = tf.function(lambda x: tf.concat([root.v1, root.v2, x], axis=1))

# Save the model.
export_dir = ""/tmp/test_saved_model""
input_data = tf.constant(np.ones((1, 30), dtype=np.float32))
to_save = root.f.get_concrete_function(input_data)
tf.saved_model.save(root, export_dir, to_save)

# Convert the model.
converter = tf.lite.TFLiteConverter.from_saved_model(export_dir)
tflite_model = converter.convert()
open(""model.tflite"", ""wb"").write(tflite_model)
```

"
38700,[1.14] get_graph_def_from_url_tarball more explicit exception when unfinished donwload.,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): -
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS Catalin 10.15.3
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: - 
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 1.14.0
- Python version: 3.6.5
- Bazel version (if compiling from source): - 
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: - 
- GPU model and memory: - 

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
Hi, currently in version `1.14.0` using `contrib.gan` package. When using `get_graph_def_from_url_tarball` internally by default it fetch file from remote, however when such file name presented on disk or you stopped download in progress after you restart it you will get `EOFError: Compressed file ended before the end-of-stream marker was reached`. This is a bit confusion and may take some time to explore reason. It would be better if `get_graph_def_from_url_tarball` raised more verbose exception when it can find file with such name here 
https://github.com/tensorflow/tensorflow/blob/r1.14/tensorflow/contrib/gan/python/eval/python/classifier_metrics_impl.py#L212-L223

If you consider it reasonable, i can work on PR."
38699,"Tensorflow hangs, requires reboot","<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):

Yes

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):

Linux Ubuntu 18.04

- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:

N/A

- TensorFlow installed from (source or binary):

binary

- TensorFlow version (use command below):

v2.1.0-rc2-17-ge5bf8de 
2.1.0

- Python version:

3.7.7

- Bazel version (if compiling from source):

N/A


- GCC/Compiler version (if compiling from source):

N/A

- CUDA/cuDNN version:

10.1

- GPU model and memory:

GTX 1080ti 11GB


**Describe the current behavior**

Using TF dataset after ~1000 batches TF hangs, nvidia-smi reports 100% usage (but fan is at 0% so that is bogus).  After I kill the process I get an XLI warning in nvidia-smi and have to reboot to try again.  

I have the same version of this code running with a Keras sequence and multiprocessing and it runs fine.  It is actually faster than the TF dataset code, keeping my GPU pegged at 60% where the TF dataset only does around 50% (while it is running but it hangs pretty fast).  

I have the GUI turned off for Ubuntu and TF is the only process on my GPU and it is set to keep all the memory.  There are no other signficant processes on the machine.  The machine is brand new with 128GB of RAM, NVM hard drives and 12 core AMD Ryzen (so speed should not be an issue).


**Describe the expected behavior**

TF not to hang and force me to reboot, as well as TF dataset to be faster than a keras sequence with multiprocessing.

**Standalone code to reproduce the issue**

This is really hard to do, I have thousands of lines of code that go into running this, plus 400 GB of data.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

GDB output below, when it hangs out, I ctrl-c and bt to get this.  If there is a better way to get a stacktrace where it hangs let me know and I'll do it.

```
(gdb) bt
#0  syscall () at ../sysdeps/unix/sysv/linux/x86_64/syscall.S:38
#1  0x00007fff7f9d5b1b in nsync::nsync_mu_semaphore_p_with_deadline(nsync::nsync_semaphore_s_*, timespec) ()
   from /home/jostheim/virtualenvs/data_science/lib/python3.7/site-packages/tensorflow_core/python/_pywrap_tensorflow_internal.so
#2  0x00007fff7f9d5139 in nsync::nsync_sem_wait_with_cancel_(nsync::waiter*, timespec, nsync::nsync_note_s_*) ()
   from /home/jostheim/virtualenvs/data_science/lib/python3.7/site-packages/tensorflow_core/python/_pywrap_tensorflow_internal.so
#3  0x00007fff7f9d26fb in nsync::nsync_cv_wait_with_deadline_generic(nsync::nsync_cv_s_*, void*, void (*)(void*), void (*)(void*), timespec, nsync::nsync_note_s_*) ()
   from /home/jostheim/virtualenvs/data_science/lib/python3.7/site-packages/tensorflow_core/python/_pywrap_tensorflow_internal.so
#4  0x00007fff7f9d2bd3 in nsync::nsync_cv_wait_with_deadline(nsync::nsync_cv_s_*, nsync::nsync_mu_s_*, timespec, nsync::nsync_note_s_*) ()
   from /home/jostheim/virtualenvs/data_science/lib/python3.7/site-packages/tensorflow_core/python/_pywrap_tensorflow_internal.so
#5  0x00007fff77ab888c in tensorflow::KernelAndDeviceFunc::Run(tensorflow::ScopedStepContainer*, tensorflow::EagerKernelArgs const&, std::vector<tensorflow::Tensor, std::allocator<tensorflow::Tensor> >*, tensorflow::CancellationManager*, absl::optional<tensorflow::EagerRemoteFunctionParams> const&) () from /home/jostheim/virtualenvs/data_science/lib/python3.7/site-packages/tensorflow_core/python/_pywrap_tensorflow_internal.so
#6  0x00007fff77ab8ce9 in tensorflow::KernelAndDeviceFunc::Run(tensorflow::EagerKernelArgs const&, std::vector<tensorflow::Tensor, std::allocator<tensorflow::Tensor> >*, tensorflow::CancellationManager*, absl::optional<tensorflow::EagerRemoteFunctionParams> const&) () from /home/jostheim/virtualenvs/data_science/lib/python3.7/site-packages/tensorflow_core/python/_pywrap_tensorflow_internal.so
#7  0x00007fff77a95b38 in tensorflow::EagerKernelExecute(tensorflow::EagerContext*, absl::InlinedVector<tensorflow::TensorHandle*, 4ul, std::allocator<tensorflow::TensorHandle*> > const&, absl::optional<tensorflow::EagerRemoteFunctionParams> const&, std::unique_ptr<tensorflow::KernelAndDevice, tensorflow::core::RefCountDeleter> const&, tensorflow::GraphCollector*, tensorflow::CancellationManager*, absl::Span<tensorflow::TensorHandle*>) () from /home/jostheim/virtualenvs/data_science/lib/python3.7/site-packages/tensorflow_core/python/_pywrap_tensorflow_internal.so
#8  0x00007fff77a9612d in tensorflow::ExecuteNode::Run() () from /home/jostheim/virtualenvs/data_science/lib/python3.7/site-packages/tensorflow_core/python/_pywrap_tensorflow_internal.so
#9  0x00007fff77ad6cf5 in tensorflow::EagerExecutor::RunItem(std::unique_ptr<tensorflow::EagerExecutor::NodeItem, tensorflow::core::RefCountDeleter>) ()
   from /home/jostheim/virtualenvs/data_science/lib/python3.7/site-packages/tensorflow_core/python/_pywrap_tensorflow_internal.so
#10 0x00007fff77ad744b in tensorflow::EagerExecutor::AddOrExecute(std::unique_ptr<tensorflow::EagerNode, std::default_delete<tensorflow::EagerNode> >) ()
   from /home/jostheim/virtualenvs/data_science/lib/python3.7/site-packages/tensorflow_core/python/_pywrap_tensorflow_internal.so
#11 0x00007fff77a9078e in tensorflow::(anonymous namespace)::EagerLocalExecute(tensorflow::EagerOperation*, tensorflow::TensorHandle**, int*) ()
   from /home/jostheim/virtualenvs/data_science/lib/python3.7/site-packages/tensorflow_core/python/_pywrap_tensorflow_internal.so
#12 0x00007fff77a93d60 in tensorflow::EagerExecute(tensorflow::EagerOperation*, tensorflow::TensorHandle**, int*) ()
---Type <return> to continue, or q <return> to quit---
   from /home/jostheim/virtualenvs/data_science/lib/python3.7/site-packages/tensorflow_core/python/_pywrap_tensorflow_internal.so
#13 0x00007fff7792219d in TFE_Execute () from /home/jostheim/virtualenvs/data_science/lib/python3.7/site-packages/tensorflow_core/python/_pywrap_tensorflow_internal.so
#14 0x00007fff778a8844 in TFE_Py_ExecuteCancelable(TFE_Context*, char const*, char const*, absl::InlinedVector<TFE_TensorHandle*, 4ul, std::allocator<TFE_TensorHandle*> >*, _object*, TFE_CancellationManager*, absl::InlinedVector<TFE_TensorHandle*, 2ul, std::allocator<TFE_TensorHandle*> >*, TF_Status*) () from /home/jostheim/virtualenvs/data_science/lib/python3.7/site-packages/tensorflow_core/python/_pywrap_tensorflow_internal.so
#15 0x00007fff778a8d81 in TFE_Py_Execute(TFE_Context*, char const*, char const*, absl::InlinedVector<TFE_TensorHandle*, 4ul, std::allocator<TFE_TensorHandle*> >*, _object*, absl::InlinedVector<TFE_TensorHandle*, 2ul, std::allocator<TFE_TensorHandle*> >*, TF_Status*) () from /home/jostheim/virtualenvs/data_science/lib/python3.7/site-packages/tensorflow_core/python/_pywrap_tensorflow_internal.so
#16 0x00007fff76f1940a in _wrap_TFE_Py_Execute () from /home/jostheim/virtualenvs/data_science/lib/python3.7/site-packages/tensorflow_core/python/_pywrap_tensorflow_internal.so
#17 0x0000555555684f77 in _PyMethodDef_RawFastCallKeywords ()
#18 0x0000555555684d80 in _PyCFunction_FastCallKeywords ()
#19 0x00005555556f7de5 in _PyEval_EvalFrameDefault ()
#20 0x00005555556f2715 in _PyEval_EvalCodeWithName ()
#21 0x000055555568671a in _PyFunction_FastCallKeywords ()
#22 0x00005555556f4406 in _PyEval_EvalFrameDefault ()
#23 0x00005555556f2715 in _PyEval_EvalCodeWithName ()
#24 0x000055555568671a in _PyFunction_FastCallKeywords ()
#25 0x00005555556f4406 in _PyEval_EvalFrameDefault ()
#26 0x00005555556f2715 in _PyEval_EvalCodeWithName ()
#27 0x000055555568671a in _PyFunction_FastCallKeywords ()
#28 0x00005555556f3840 in _PyEval_EvalFrameDefault ()
#29 0x000055555568663a in _PyFunction_FastCallKeywords ()
#30 0x00005555556f3840 in _PyEval_EvalFrameDefault ()
#31 0x00005555556f2715 in _PyEval_EvalCodeWithName ()
#32 0x0000555555686db1 in _PyObject_Call_Prepend ()
#33 0x00005555556c9319 in ?? ()
---Type <return> to continue, or q <return> to quit---
#34 0x00005555556871d1 in PyObject_Call ()
#35 0x00005555556f4d75 in _PyEval_EvalFrameDefault ()
#36 0x00005555556f2d15 in _PyEval_EvalCodeWithName ()
#37 0x0000555555686db1 in _PyObject_Call_Prepend ()
#38 0x00005555556871d1 in PyObject_Call ()
#39 0x00005555556f4d75 in _PyEval_EvalFrameDefault ()
#40 0x00005555556f2715 in _PyEval_EvalCodeWithName ()
#41 0x0000555555686db1 in _PyObject_Call_Prepend ()
#42 0x00005555556c9319 in ?? ()
#43 0x0000555555685792 in _PyObject_FastCallKeywords ()
#44 0x00005555556f790d in _PyEval_EvalFrameDefault ()
#45 0x00005555556f28ac in _PyEval_EvalCodeWithName ()
#46 0x000055555568671a in _PyFunction_FastCallKeywords ()
#47 0x00005555556f35e6 in _PyEval_EvalFrameDefault ()
#48 0x00005555556f2715 in _PyEval_EvalCodeWithName ()
#49 0x000055555568671a in _PyFunction_FastCallKeywords ()
#50 0x00005555556f4406 in _PyEval_EvalFrameDefault ()
#51 0x00005555556f2715 in _PyEval_EvalCodeWithName ()
#52 0x000055555568671a in _PyFunction_FastCallKeywords ()
#53 0x00005555556f4406 in _PyEval_EvalFrameDefault ()
#54 0x00005555556f2715 in _PyEval_EvalCodeWithName ()
#55 0x000055555568671a in _PyFunction_FastCallKeywords ()
#56 0x00005555556f4406 in _PyEval_EvalFrameDefault ()
#57 0x00005555556f2715 in _PyEval_EvalCodeWithName ()
---Type <return> to continue, or q <return> to quit---
#58 0x000055555568671a in _PyFunction_FastCallKeywords ()
#59 0x00005555556f4406 in _PyEval_EvalFrameDefault ()
#60 0x000055555568663a in _PyFunction_FastCallKeywords ()
#61 0x00005555556f35e6 in _PyEval_EvalFrameDefault ()
#62 0x00005555556f2715 in _PyEval_EvalCodeWithName ()
#63 0x00005555556f2413 in PyEval_EvalCode ()
#64 0x00005555557bc802 in ?? ()
#65 0x00005555557bcb7d in PyRun_FileExFlags ()
#66 0x00005555557bca26 in PyRun_SimpleFileExFlags ()
#67 0x0000555555794203 in ?? ()
#68 0x0000555555793eac in _Py_UnixMain ()
#69 0x00007ffff6bf2b97 in __libc_start_main (main=0x5555556818a0 <main>, argc=3, argv=0x7fffffffe058, init=<optimized out>, fini=<optimized out>, rtld_fini=<optimized out>, stack_end=0x7fffffffe048)
    at ../csu/libc-start.c:310
#70 0x0000555555793d8a in _start ()```
"
38698,NaN's in saved model only when training with tensorflow-gpu,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  I believe Debian 9 ""Stretch"" on google cloud and whatever distro Google colab uses.
- TensorFlow installed from (source or binary): Installed as binary
- TensorFlow version (use command below): v2.1.0-rc2-17-ge5bf8de 2.1.0 and v2.2.0-rc2-77-gaad398b5e9 2.2.0-rc3
- Python version: 3.7
- CUDA/cuDNN version: Uncertain
- GPU model and memory: Tesla V100 on google cloud, uncertain on colab

**Describe the current behavior**
I have been building off of the [tensorflow pix2pix example](https://www.tensorflow.org/tutorials/generative/pix2pix).

Steps:
1. Train the network and save checkpoints along the way. Training proceeds normally with reasonable losses, and intermediate outputs are look correct. 

2. Reload the network from a checkpoint and export the generator as an .h5: `generator.save('generator.h5', save_format=""h5"")`.

3. Reload the saved h5 network using `tf.keras.models.load_model('generator.h5')`

4. If the network was trained with tensorflow-gpu, a block of weights on one layer (only part of sequential_9) will be NaN. If the network was trained with tensorflow cpu, the weights and outputs are appropriate.

**Describe the expected behavior**

I expect the saved and loaded network to behave in the same way as the network as it is training, and the weights to not contain any nan values.

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

Apologies for including the full pix2pix script. I'll attempt to slim down the code later. Here is a colab notebook that contains the pix2pix script, and the weights from the `sequential_9` layer trained on tf-gpu and tf-cpu. To reproduce, change the runtime type between GPU and CPU.
https://colab.research.google.com/drive/1im9dVf63vuldIGsnQ48sHBKHHpDVuHvG

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached."
38696,Tensorflow Lite iOS opengl delegate,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): 2.2.0
- Are you willing to contribute it (Yes/No): Yes

**Describe the feature and the current behavior/state.**
Metal delegate works perfectly. But in some cases, I am forced to use opengles 3.0 as the render pipeline because of essential external libraries. It will then be great to have opengl delegate in iOS so users could bind SSBO to tensors.

**Will this change the current api? How?**
No

**Who will benefit with this feature?**
iOS developers who can't use Metal render pipeline and want high inference performance.

**Any Other info.**
"
38695,"keras.layers.Add() uses 'tf_op_layer_add', which can not be renamed","
**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Linux Ubuntu 18.04
- TensorFlow installed from (source or binary): 
pip
- TensorFlow version (use command below): 
2.1
- Python version: 
3.6.9

**Describe the current behavior**

I currently have a trained model and I want to add the output of an intermediate layer with a numpy array that I have. I first converted the numpy array to a tensor using `tf.keras.backend.constant`, and then I used `tf.keras.layers.Add()` to sum them up. 

But I got the error: `The name ""tf_op_layer_add"" is used 2 times in the model. All layer names should be unique`. Because there exists another add operation in the model. So I tried to name this add layer, and I got this error: `Can't set the attribute ""name"", likely because it conflicts with an existing read-only @property of the object. Please choose a different name`.

Normally, `tf.keras.layers.Add()` should be of type `<tensorflow.python.keras.layers.merge.Add>`, but in my case, it became into `<tensorflow.python.keras.engine.base_layer.TensorFlowOpLayer>`, which does not allow me to change its name.

I simply want to change the name of that `tf.keras.layers.Add()` layer, is there a way I can do that or another way around? Thanks!

**Standalone code to reproduce the issue**

Here's a way to reproduce the error. You'll see that `tf.keras.layers.Add()` uses tensorflow operation layer which can not be named.

```
bias = np.ones((32, 32, 3))
bias = tf.keras.backend.constant(bias)
bias = keras.backend.reshape(bias, [-1,32,32,3])
               
inputs = tf.keras.Input(shape=(32, 32, 3))
x = tf.keras.layers.Conv2D(filters=3, kernel_size=(3, 3),padding = 'same')(inputs)
x = tf.keras.layers.Add(name = 'add_1')([x, bias])
model = tf.keras.Model(inputs, x)
model.summary()
add_layer = model.get_layer('tf_op_layer_add')
add_layer.name = 'add_1'
```
"
38694,TF1 tf.image.resize_image does not work with unbatched variable size image anymore since 1.12,"(Sorry for not adhering to the template, I can point to the problematic commit)

I use tf.image.resize_images to resize variable sized images in an unbatched manner, like so:

    tf.image.resize_images(
                tf.reshape(x, [-1, 100, 3]),
                size,
                method=tf.image.ResizeMethod.BILINEAR
            )

I.e. some images are 100x100, some 110x100 etc. Upon updating tensorflow I received the following error:

```
Traceback (most recent call last):
[...]
  File ""data_preprocess_amass.py"", line 32, in __init__
    method=tf.image.ResizeMethod.BILINEAR
  File ""/mnt/HDD1/julian/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow_core/python/ops/image_ops_impl.py"", line 1187, in resize_images
    skip_resize_if_same=True)
  File ""/mnt/HDD1/julian/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow_core/python/ops/image_ops_impl.py"", line 1053, in _resize_images_common
    new_height_const = size_const_as_shape.dims[0].value
TypeError: 'NoneType' object is not subscriptable
```
I investigated it and it seems that the commit f43d458a318d4d97298710654f1692f6e8364f82 is the culprit, introducing the following lines to image_ops_impl.py:

    new_height_const = size_const_as_shape.dims[0].value
    new_width_const = size_const_as_shape.dims[1].value

blame: https://github.com/tensorflow/tensorflow/blame/r1.15/tensorflow/python/ops/image_ops_impl.py#L1053

It is included since 1.12.1. Downgrading to 1.11 solved it for me. Might be a very special use case on a already deprecated function but I thought its worth reporting."
38693,Does `tf.constant()` waste memory? What is the alternative?,"This is about [this tutorial](https://www.tensorflow.org/guide/data) on input pipelines, and in particular the following note under ""Reading input data"" > ""Consuming NumPy arrays"":

> Note: The above code snippet will embed the features and labels arrays in your TensorFlow graph as tf.constant() operations. This works well for a small dataset, but wastes memory---because the contents of the array will be copied multiple times---and can run into the 2GB limit for the tf.GraphDef protocol buffer.

Could we have a slightly more detailed justification for this note, namely as to why `tf.data.Dataset.from_tensor_slices()` is suboptimal in this case. In particular:

1. In which way are the contents of the array copied multiple times?
2. What is the alternative to that code if we don't want to run into the 2GB limit? What is the best practice in general?"
38692,"warn(""IPython.utils.traitlets has moved to a top-level traitlets package."") google colab","I was running a code in colab notebook and  my colab crashed after some iterations and logs showed me this-
warn(""IPython.utils.traitlets has moved to a top-level traitlets package."") 

can anyone one help me about what happened and how can i solve this"
38691,WARNING:tensorflow:Entity <function <lambda> at 0x000002343DCF24C8> could not be transformed and will be executed as-is.,"What can be done to solve this warning?

## Warning message

Below is the full warning:

> WARNING:tensorflow:Entity <function <lambda> at 0x000002343DCF24C8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'
> WARNING: Entity <function <lambda> at 0x000002343DCF24C8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'

## Minimum working example

The code that generated the warning was discussed in #38471 and stored in this [gist](https://colab.research.google.com/drive/1gExuU2sCs6OeHtexI22srN7gAti9C9c4#scrollTo=8TvMWDmhlcSY).
```
import tensorflow as tf

def compute_length(x): 
    return tf.strings.length(x)

def check_substring(x, substring):
    return tf.strings.regex_full_match(x,substring)


def compute_palindrome(x):
    extra_split = tf.strings.bytes_split(x)
    reverse = tf.reverse(extra_split,[0])
    reversedStr = tf.strings.reduce_join([reverse])
    return reversedStr
    
ds = tf.data.Dataset.from_tensor_slices([""Ottawa"", ""Stockholm"", ""Rabat""])

ds = ds.map(
    lambda city: (city, 
                  compute_length(city), 
                  check_substring(city, "".*lm.*""),
                  compute_palindrome(city),
                  ),
        )

num_elems = len(ds.element_spec)
for elem in ds:
   print(''.join([f""{elem[i]}"" for i in range(num_elems)]))
```

## Environment

- python 3.7.4
- tensorflow-gpu 2.0.0
- tensorflow-datasets 1.3.0
- gast 0.2.2

Running on Windows 10 under conda 4.8.3."
38690,What is recommended system configuration for Deep Learning?,"Basically I am having Acer Nitro 50 Desktop with system configuration
Processor: Intel® Core™ i5-8400 CPU @ 2.80GHz × 6
Graphics: GeForce GTX 1050/PCIe/SSE2 (2 GB)
Memory(RAM): 8GB DDR4 Memory

I am working with **tensorflow_gpu-1.12.0 | python 3.5 | GCC 4.8 | Bazel 0.15.0 | cudnn 7 | Cuda 9.0** to train a faster_rcnn_inception_v2 model on my custom dataset with 10.4 GB(65000 images) of training data and 533.4 MB(3333) of validation data for object detection for 600k epochs(num_steps it will be training at 640 x 640 resolution). I am training and validation model on 8 classes. So when I am training the model the accuracy(map) is not increasing and loss is not decreasing after a while. After the completion of the training successfully I ran the model on various images and noticed couple of things.

1)    Less accuracy
 2)   In some images objects does not get detected at all no bounding boxes. while in some multiclass object detection is spot on perfectly all objects gets detected but with less accuracy around 60 - 75.
 3)   From second point above If I train a separate model with less images and less number of classes(3 or 4) it works well but with decent amount of accuracy around 75 - 95

Question 1) What would be ideal system to work comfortably with deep learning? and get desired amount of results

So based on my system configuration should I keep on training or invest into new system which will be lot faster and accurate in deep learning. It would be really helpful for me to continue my learning if anyone could suggest or recommend something "
38689,keras with tensorflow backend is 4x slower than normal keras on GPU machines,"Same model written in tf.keras runs much slower compared to keras imported directly.

System information (whatever a default GPU session in Colab is):
- Linux Ubuntu 16.04
- Tensorflow 2.2, Keras 2.3.1
- CUDA/cuDNN version: 10.1
- GPU model and memory: Tesla K80

Current behavior. Two identical models defined with **tensorflow.keras** and **keras** have similar training time in CPU session (the code for models is identical). However, when GPU is available tensorflow.keras model doesn't get any acceleration whereas keras model performs 4x faster

```
# returns True
tf.test.is_gpu_available(cuda_only=True, min_cuda_compute_capability=None)
```

Expected behavior. Both models must take advantage of GPU acceleration.

The model below attempts to find an embedding with vectors of unit L2 norm. It takes about 2 minutes / epoch to run on CPU. With GPU, tf.keras model runs in about the same time, normal keras model runs in about 25 seconds.

```
import numpy as np
import tensorflow as tf

vocab_size = 5000
sample_size = 300000
embedding_size = 300

data = np.random.randint(0, vocab_size, sample_size)
y_true = np.ones(sample_size, dtype = np.float32)

# Using tensorflow keras backend
from tensorflow.keras.layers import Input, Embedding, Dot, Reshape
from tensorflow.keras.models import Model

# define the model
input_layer = Input((1,))
embed_layer = Embedding(vocab_size
                              , output_dim = embedding_size
                              , embeddings_initializer='normal')
dot_layer = Dot(axes = -1)

embedded = embed_layer(input_layer)
dotted = dot_layer([embedded, embedded])
out = Reshape((1,))(dotted)

model = Model(inputs = [input_layer], outputs = out)
model.compile(optimizer=tf.keras.optimizers.Adam(1e-3), loss = tf.keras.losses.MeanSquaredError())
model.fit([data], y_true, epochs = 1, verbose = True)
```

To switch to normal keras backend replace the two keras import statements with:
```
from keras.layers import Input, Embedding, Dot, Reshape
from keras.models import Model
```





"
38688,"I've got an error for ""Build a handwritten digit classifier app with TensorFlow Lite""","I have done all the same way, shown in the official website.

But, I have got an error message as below.

**_Only safe (?.) or non-null asserted (!!.) calls are allowed on a nullable receiver of type Tensor?_**

I could not find any solution through web surfing in github and others.

Could you help me, please?

Regards,"
38686,Feed 1 frame to 2 models in tensorflow,"
**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): ubnutu 16.04
- TensorFlow version (use command below): tensorflow-gpu
- Python version: 35
- CUDA/cuDNN version: 9 
- GPU model and memory: Titan

Tf version "" tensorflow-gpu=1.12)

I have two tensorflow models (A.pb , B.pb ). I have two written two python codes. Both of these take same frame Input and produce output. (Currently, I run both of them in different terminals.)

Since they take same image frame as inputs... Can I do something in tensorflow like...

In 1 single python file :

    Put the both codes in 1 single file.
    Open both A.pb and B.pb models.
    Feed the same input image frame two both A.pb and B.pb parallely
    Superimpose the output of A.pb & B.pb and produce 1 single output.

Kindly help me in this regard. :)
"
38685,libcuda.so.1 is missing with conda env tf-gpu,"I get the following errors:

```
2020-04-19 05:56:24.050072: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2020-04-19 05:56:24.050125: E tensorflow/stream_executor/cuda/cuda_driver.cc:351] failed call to cuInit: UNKNOWN ERROR (303)
2020-04-19 05:56:24.050149: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:163] no NVIDIA GPU device is present: /dev/nvidia0 does not exist
2020-04-19 05:56:24.050476: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2020-04-19 05:56:24.066026: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2199900000 Hz
2020-04-19 05:56:24.068548: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x558e75a5b2c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-04-19 05:56:24.068591: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.
WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.
WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.
```
when I execute
```
 trainds = tf.data.Dataset.from_tensor_slices((helper.trainx,helper.trainm,helper.trainy)).batch(setup['BatchSize'])
```
Tensorflow cannot find the file libcuda.so.1.

I get this error in a Docker Container which uses miniconda and the tensorflow-gpu environment.
```
FROM continuumio/miniconda3
RUN conda create -n tf-gpu tensorflow-gpu
```
I don't get the error on my local machine with the same code.

As far as I understood, conda should automatically install cuda and its libraries.

When I search for the missing file I get an empty line. `find -name ""libcuda.so.1""`
Other versions of libcuda.so. can't be found either. Even `*cuda*` couldn't be found. It seems to be that cuda was entirely skipped during the installation. 

nvidia-smi returns this:
```
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 410.104      Driver Version: 410.104      CUDA Version: N/A      |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  Tesla P100-SXM2...  Off  | 00000000:89:00.0 Off |                    0 |
| N/A   30C    P0    31W / 300W |      0MiB / 16280MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+

+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
```

**System information**
```
Python 3.7.6 | packaged by conda-forge | (default, Mar 23 2020, 23:03:20)
[GCC 7.3.0] on linux
```
- TensorFlow version: 2.1.0
- Python version: 3.7.6
- GPU model and memory: P100 / 16 GB

Additional information:
```
print(tf.test.is_gpu_available())             # False
print(tf.config.list_physical_devices('GPU')) # []
```


"
38684,Train simple audio recognition model,"@petewarden 
I trained this model in colab and it is working in arduino for ""yes"" and ""no"" command but when I tried for ""on"" and ""off"" I am not getting output in my arduino board( I have done the necessary changes in tensorflow example code ""micro_speech"" ).
 Can you please suggest how to get model working for ""on"" and ""off"".
"
38683,NotImplementedError: ,"i am using the code below : 

```
def build_model(transformer, loss='binary_crossentropy', max_len=512):
    input_word_ids = Input(shape=(max_len,), dtype=tf.int32, name=""input_word_ids"")
    sequence_output = transformer(input_word_ids)[0]
    cls_token = sequence_output[:, 0, :]
    x = tf.keras.layers.Dropout(0.3)(cls_token)
    out = Dense(1, activation='sigmoid')(x)
    
    model = Model(inputs=input_word_ids, outputs=out)
    model.compile(Adam(lr=3e-5), loss=loss, metrics=[tf.keras.metrics.AUC()])
    
    return model


%%time
with strategy.scope():
    transformer_layer = transformers.TFXLMRobertaModel.from_pretrained(MODEL)
    model = build_model(transformer_layer,loss='binary_crossentropy', max_len=maxlen)
model.summary()


def build_lrfn(lr_start=0.000001, lr_max=0.000002, 
               lr_min=0.0000001, lr_rampup_epochs=7, 
               lr_sustain_epochs=0, lr_exp_decay=.87):
    lr_max = lr_max * strategy.num_replicas_in_sync

    def lrfn(epoch):
        if epoch < lr_rampup_epochs:
            lr = (lr_max - lr_start) / lr_rampup_epochs * epoch + lr_start
        elif epoch < lr_rampup_epochs + lr_sustain_epochs:
            lr = lr_max
        else:
            lr = (lr_max - lr_min) * lr_exp_decay**(epoch - lr_rampup_epochs - lr_sustain_epochs) + lr_min
        return lr
    
    return lrfn


model_path = 'jigsawMultilingual.hdf5'
model_path1 = '/kaggle/working/jigsawMultilingual.hdf5'


from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler

checkpoint = ModelCheckpoint(model_path, monitor='val_loss', mode='min', save_best_only=True)
es = EarlyStopping(monitor='val_loss', mode='min', patience=2, 
                   restore_best_weights=True, verbose=1)
lr_callback = LearningRateScheduler(lrfn, verbose=1)

callback_list = [checkpoint, es, lr_callback]


%%time
N_STEPS = x_train.shape[0] // BATCH_SIZE
EPOCHS = 2
train_history = model.fit(
    train_dataset,
    steps_per_epoch=N_STEPS,
    validation_data=valid_dataset,
    callbacks=callback_list,
    epochs=EPOCHS
)
```

and i am getting NotImplementedError after 1st epoch,here is the notebook : https://www.kaggle.com/mobassir/understanding-cross-lingual-models?scriptVersionId=32280074

i am unable to save checkpoint, for me  monitor='val_loss' throwing me NotImplementedError
i tried monitor='val_acc'  and monitor='val_accuracy'  and none of them saving weights for me,where am i making mistakes?"
38682,New train_op for estimator in tensorflow,"I would like to write a novel train_op to test a new training algorithm without using any gradient or loss, which is a little bit like a UCB algorithm in bandit. How can I define such a train_op to add it in my custom estimator? 

Thank you very much!

"
38681,Can I use other Microcontrollers other than which are specified by tensorflow?,"Can other Microcontrollers can be used other than these mentioned below for tensorflow modules-
Arduino Nano 33 BLE Sense
SparkFun Edge
STM32F746 Discovery kit
Adafruit EdgeBadge
Adafruit TensorFlow Lite for Microcontrollers Kit 
Adafruit Circuit Playground Bluefruit
Espressif ESP32-DevKitC 
Espressif ESP-EYE 
If yes can. Is there any documentation to follow?"
38680,Why my modelcheckpoint is not saving weights based on best val_accuracy?,"the code i tried in kaggle kernel for saving weights is this :

`model_path = '/kaggle/working/jigsawMultilingual.h5'
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler

checkpoint = ModelCheckpoint(model_path, monitor='val_accuracy', mode='max', save_best_only=True)
es = EarlyStopping(monitor='val_accuracy', mode='max', patience=2, 
                   restore_best_weights=True, verbose=1)
lr_callback = LearningRateScheduler(lrfn, verbose=1)

callback_list = [checkpoint, es, lr_callback]


%%time
N_STEPS = x_train.shape[0] // BATCH_SIZE
EPOCHS = 4
train_history = model.fit(
    train_dataset,
    steps_per_epoch=N_STEPS,
    validation_data=valid_dataset,
    callbacks=callback_list,
    epochs=EPOCHS
)

 # have a look at the training results : 

Train for 4414 steps, validate for 63 steps

Epoch 00001: LearningRateScheduler reducing learning rate to 1e-06.
Epoch 1/4
4414/4414 [==============================] - 2301s 521ms/step - loss: 0.3190 - auc: 0.9200 - val_loss: 0.2821 - val_auc: 0.9171

Epoch 00002: LearningRateScheduler reducing learning rate to 3.142857142857143e-06.
Epoch 2/4
4414/4414 [==============================] - 2090s 473ms/step - loss: 0.1909 - auc: 0.9718 - val_loss: 0.2581 - val_auc: 0.9249

Epoch 00003: LearningRateScheduler reducing learning rate to 5.285714285714285e-06.
Epoch 3/4
4414/4414 [==============================] - 2090s 473ms/step - loss: 0.1639 - auc: 0.9791 - val_loss: 0.2730 - val_auc: 0.9214

Epoch 00004: LearningRateScheduler reducing learning rate to 7.4285714285714275e-06.
Epoch 4/4
4414/4414 [==============================] - 2090s 473ms/step - loss: 0.1491 - auc: 0.9826 - val_loss: 0.2761 - val_auc: 0.9252
CPU times: user 9min 46s, sys: 35.5 s, total: 10min 21s
Wall time: 2h 22min 50s`

but i don't see any model in this path : model_path = '/kaggle/working/jigsawMultilingual.h5'

note that i also tried ""checkpoint = ModelCheckpoint(model_path, monitor='val_acc', mode='max', save_best_only=True)"" and it also didn't work

i mean jigsawMultilingual.h5 is not saving in '/kaggle/working/' directory

is it happening because validation accuracy is improving every time? but still it should save the model after 1st epoch,right?"
38678,Could we have more helpful error messages?,"## Description of issue (what needs changing):
Tensorflow gives many errors, and most of them aren't very helpful.  Something like ""module tensorflow has no attribute reset_graph.""  Can we change the error messages so they are more constructive?  In this situation, the issue was partially solved by downgrading to tensorflow 1.12.  It would be helpful if instead of the ""reset_graph"" error message, we could get a message more like: ""this version of tensorflow is incompatible with the current project.  Please downgrade to tensorflow 1.12 using: pip install tensorflow==1.12

### Clear description

For example, why should someone use this method? How is it useful?
To keep from tearing their own hair out.


"
38677,Failed to load the native TensorFlow runtime.,"hi, installed tensorflow version 2.1 using pip command anaconda with windows 10 64 bit python 3.6 and getting this issue ,cant find any solution  to this anywhere  ,any help would be appreciated .
i am installing it for cpu not gpu .
![Screenshot (17)](https://user-images.githubusercontent.com/49184195/79679691-bcbb1700-8225-11ea-8ebe-9aadaeb24d61.png)




Traceback (most recent call last):
  File ""C:\Users\yadav\Anaconda3\envs\tensor\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\yadav\Anaconda3\envs\tensor\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\yadav\Anaconda3\envs\tensor\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\yadav\Anaconda3\envs\tensor\lib\imp.py"", line 243, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\yadav\Anaconda3\envs\tensor\lib\imp.py"", line 343, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: The specified module could not be found.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:/Users/yadav/PycharmProjects/tensor/tensor.py"", line 1, in <module>
    import tensorflow
  File ""C:\Users\yadav\Anaconda3\envs\tensor\lib\site-packages\tensorflow\__init__.py"", line 101, in <module>
    from tensorflow_core import *
  File ""C:\Users\yadav\Anaconda3\envs\tensor\lib\site-packages\tensorflow_core\__init__.py"", line 40, in <module>
    from tensorflow.python.tools import module_util as _module_util
  File ""C:\Users\yadav\Anaconda3\envs\tensor\lib\site-packages\tensorflow\__init__.py"", line 50, in __getattr__
    module = self._load()
  File ""C:\Users\yadav\Anaconda3\envs\tensor\lib\site-packages\tensorflow\__init__.py"", line 44, in _load
    module = _importlib.import_module(self.__name__)
  File ""C:\Users\yadav\Anaconda3\envs\tensor\lib\importlib\__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""C:\Users\yadav\Anaconda3\envs\tensor\lib\site-packages\tensorflow_core\python\__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\Users\yadav\Anaconda3\envs\tensor\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 74, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""C:\Users\yadav\Anaconda3\envs\tensor\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\yadav\Anaconda3\envs\tensor\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\yadav\Anaconda3\envs\tensor\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\yadav\Anaconda3\envs\tensor\lib\imp.py"", line 243, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\yadav\Anaconda3\envs\tensor\lib\imp.py"", line 343, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: The specified module could not be found.


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/errors




"
38676,"import tensorflow as tfimport tensorflow.contrib.layers as layers   File ""<ipython-input-23-4e7964698c5b>"", line 1     import tensorflow as tfimport tensorflow.contrib.layers as layer SyntaxError: invalid syntax","<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below):
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**

**Describe the expected behavior**

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
38675,[2.2] XLA requires 2x GPU memory with sparse_categorical_crossentropy,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.1.0, 2.2.0rc3 and tf-nightly
- Python version: 3.7
- CUDA/cuDNN version: 10.1 / 7.6.5.32
- GPU model and memory: 4 x NVIDIA V100 on GCP

**Describe the current behavior**

I am currently trying to upgrade from TensorFlow 2.0.0 to 2.2.0rc3 and noticed a regression related to model training using XLA in a multi-GPU environment (GCP VM with 4 NVIDIA V100s).

The training code linked below runs comfortably with a huge batch size of 3072 on 4 GPUs using the normal TensorFlow runtime. However when enabling XLA with `TF_XLA_FLAGS=--tf_xla_auto_jit=2` the same code runs out of GPU memory on the first batch of data. With XLA I can only use a maximum batch size of 1536 (50%) to prevent the code from running out of memory which doesn't seem right.

**In which cases are the memory requirements of XLA and the default runtime similar?**
To narrow down the possible causes for this I found a few cases where the maximum batch size for XLA and the normal runtime are the same:

1. TensorFlow 2.0.0 doesn't seem to show this issue.

2. Removing `.prefetch(1)` from the datapipline fixes the issue.

3. Changing the training to one-hot encoded labels seems to fix the increase XLA memory requirements as well. To test this I changed the preprocessing and loss to:
   ```python
   def preprocessing(data):
    return (
        tf.cast(_decode_and_center_crop(data[""image""]), tf.float32),
        tf.cast(tf.one_hot(data[""label""], 1000), tf.float32),
    )
   ```
   and
   ```python
       model.compile(
        optimizer=""adam"",
        loss=""categorical_crossentropy"",
        metrics=[""accuracy"", ""top_k_categorical_accuracy""],
    )
   ```

The above conditions suggest that the prefetched `int32` labels and sparse categorical cross entropy might cause the regression with XLA, though I might miss something here. Any help would be very appreciated.

**Describe the expected behavior**

GPU memory requirements (messured here by maximum usable batch size) should be similar between XLA and the default runtime.

**Standalone code to reproduce the issue**
```python
import tensorflow as tf
import tensorflow_datasets as tfds
import larq_zoo as lqz  # !pip install larq_zoo==1.0b4

batch_size = 3072


def _decode_and_center_crop(image_bytes):
    """"""Crops to center of image with padding then scales image_size.""""""
    shape = tf.image.extract_jpeg_shape(image_bytes)
    image_height = shape[0]
    image_width = shape[1]
    image_size = 224

    padded_center_crop_size = tf.cast(
        (
            (image_size / (image_size + 32))
            * tf.cast(tf.minimum(image_height, image_width), tf.float32)
        ),
        tf.int32,
    )

    offset_height = ((image_height - padded_center_crop_size) + 1) // 2
    offset_width = ((image_width - padded_center_crop_size) + 1) // 2
    crop_window = tf.stack(
        [offset_height, offset_width, padded_center_crop_size, padded_center_crop_size]
    )
    image = tf.image.decode_and_crop_jpeg(image_bytes, crop_window, channels=3)
    return tf.image.resize(image, [image_size, image_size], method=""bicubic"")


def preprocessing(data):
    return (
        tf.cast(_decode_and_center_crop(data[""image""]), tf.float32),
        data[""label""],
    )


dataset = tfds.load(
    ""imagenet2012:5.0.0"",
    decoders={""image"": tfds.decode.SkipDecoding()},
    split=""train"",
    data_dir=""gs://my-data-bucket"",
)

dataset = (
    dataset.map(preprocessing, num_parallel_calls=tf.data.experimental.AUTOTUNE)
    .batch(batch_size)
    .prefetch(1)
)

with tf.distribute.MirroredStrategy().scope():
    model = lqz.sota.QuickNet(weights=None)

    model.compile(
        optimizer=""adam"",
        loss=""sparse_categorical_crossentropy"",
        metrics=[""accuracy"", ""sparse_top_k_categorical_accuracy""],
    )

model.fit(dataset, epochs=5)
```

**Other info / logs**

I attached the [XLA dumps](https://www.tensorflow.org/xla#reproducible_bug_reports) below:
[xla_dumps.tar.gz](https://github.com/tensorflow/tensorflow/files/4497906/xla_dumps.tar.gz)"
38674,Model with multiple outputs throws error about shape of output,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Yes
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below): v2.1.0-rc2-17-ge5bf8de 2.1.0
- Python version: 3.7
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10.1
- GPU model and memory: RTX 2080, 12 GB

**Describe the current behavior**

I have an ensemble of MLP's, where each ensemble outputs two values, a `mean`, and a `variance`, as shown below:
```
    def call(self, inputs, training=None, mask=None):
        mean_predictions = []
        variance_predictions = []
        for idx in range(self.num_models):
            mean_predictions.append(self.mean[idx](inputs, training=training))
            variance_predictions.append(self.variance[idx](inputs, training=training))
        mean_stack = tf.stack(mean_predictions)
        variance_stack = tf.stack(variance_predictions)
        return mean_stack, variance_stack
```

Additionally, I have a custom loss function that takes these two values and outputs a loss. In particular, the loss is negative log-likelihood of the Gaussian distribution:
```
class GaussianNLL(Loss):

    def __init__(self):
        super(GaussianNLL, self).__init__()

    def call(self, y_true, y_pred):

        mean, variance = y_pred
        variance = y_pred + 0.0001
        nll = (tf.math.log(variance) / 2 + ((y_true - mean) ** 2) / (2 * variance))
        nll = tf.math.reduce_mean(nll)
        return nll
```
And calling
```
model.compile(optimizer='adam',
                  loss=loss_fn)
history = model.fit(x_train, y_train, y_train,
                        batch_size=2048,
                        epochs=10000,
                        verbose=1,
                        validation_data=(x_val, y_val))
```
I get the following error:  `tensorflow.python.framework.errors_impl.OperatorNotAllowedInGraphError: iterating over `tf.Tensor` is not allowed in Graph execution. Use Eager execution or decorate this function with @tf.function.
`, 
which I fixed using a slight hack: instead of unpacking the outputs, I do
``` 
mean = y_pred[0]
variance = y_pred[1] + 0.0001
```
Which yields
```
Error when checking model target: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 2 array(s), for inputs ['output_1', 'output_2'] but instead got the following list of 1 arrays:... 
```
**Describe the expected behavior**`

I expect to be able to define how handle my model's multiple outputs if I have custom loss functions. 

**Standalone code to reproduce the issue**
In the following colab, the code runs fine, but you can see that `fit` function outputs multiple losses, when it should really only be one. I don't know what all the other outputs are.
I just checked, and the reason it runs on colab and not my machine is tensorflow's version. But the above still stands.
https://colab.research.google.com/drive/1EnKOiGPmKIYt5f7QvcwN8VMBLniyuqhK
**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
```"
38673,Unable To Find Relevant Documentation For Quantization from python/tf/dtype/DType ,"## URL(s) with the issue:

https://www.tensorflow.org/api_docs/python/tf/dtypes/DType

## Description of issue (what needs changing):

The dtypes, such as, `tf.qint8`, `tf.quint8`, `tf.qint16`, `tf.quint16`, `tf.qint32`, are a bit unclear. What is `Quantized` suppose to mean? Where should a reader go to learn more about it? Clicking on the hyperlink of any of the dtypes of the above leads to [tf](https://www.tensorflow.org/api_docs/python/tf) which is just text. It does not give info about variable itself ( what is `quantization`? How and why is it an `int` ? )

### Clear description

No clear description about what `quantization` really means. 
Googling for `quantized tensorflow` leads us to,
1): [Post training quantization](https://www.tensorflow.org/lite/performance/post_training_quantization)
2): [TensorFlow Lite 8-bit quantization specification](https://www.tensorflow.org/lite/performance/quantization_spec)
3): [Converting Quantized Models](https://www.tensorflow.org/lite/convert/quantization)
4): [tf.quantization.quantize](https://www.tensorflow.org/api_docs/python/tf/quantization/quantize)
5): [Post-training dynamic range quantization](https://www.tensorflow.org/lite/performance/post_training_quant)

None of which give a quick definition into what `quantization` is and what it is in Tensorflow.

### Correct links

The link is correct, it is this https://www.tensorflow.org/api_docs/python/tf/dtypes/DType#tf.qint32 .

### Parameters defined

Not related to code.

### Returns defined

Not based on code.

### Raises listed and defined

Not related to code.

### Usage example

Not related to code.

### Request visuals, if applicable

Not really.

### Submit a pull request?

I do not plan to. Don't really have the time. 

This is similar to issue #15 , closed, at [here](https://github.com/tensorflow/tensorflow/issues/15) and #494, [here](https://github.com/tensorflow/tensorflow/issues/494).

Thank you! And have a nice day. 
"
38672,How properly apply a tokenizer map function to a Tensorflow batched dataset?,"Considering the following `batched_dataset`:

```python3
samples =  ([{""query"": ""this is a query 1"", ""doc"": ""this is one relevant document regarding query 1""}, 
              {""query"": ""this is a query 2"", ""doc"": ""this is one relevant document regarding query 2""},
              {""query"": ""this is a query 3"", ""doc"": ""this is one relevant document regarding query 3""},
              {""query"": ""this is a query 4"", ""doc"": ""this is one relevant document regarding query 4""},
              ])
dataset = tf.data.Dataset.from_generator( 
    lambda: samples, {""query"": tf.string, ""doc"": tf.string})

batched_dataset = dataset.batch(2)

#{
#'doc': <tf.Tensor: shape=(2,), dtype=string, numpy=array(
#     [b'this is one relevant document regarding query 1',
#      b'this is one relevant document regarding query 2'], dtype=object)>,
# 
#'query': <tf.Tensor: shape=(2,), dtype=string, numpy=array(
#     [b'this is a query 1', 
#      b'this is a query 2'], dtype=object)>
#}

```
and a map function to tokenize this `batched_dataset`:

```python3
def tokenize(sample):
    tokenized_query = tokenizer.batch_encode_plus(sample[""query""].numpy().astype('str'), ...)
    tokenized_doc = tokenizer.batch_encode_plus(sample[""doc""].numpy().astype('str'), ...)
    return (tokenized_query, tokenized_doc) 
```
I could tokenize the entire batched_dataset using a for-loop:

```python3
for batch in batched_dataset:
    tokenize(batch)
# (
# {'input_ids': <tf.Tensor: shape=(2, 8), dtype=int32, numpy=
#   array([[  101,  2023,  2003,  1037, 23032,  1015,   102,     0],
#          [  101,  2023,  2003,  1037, 23032,  1016,   102,     0]],
#      dtype=int32)>, 
#  'attention_mask': <tf.Tensor: shape=(2, 8), dtype=int32, numpy=
#   array([[1, 1, 1, 1, 1, 1, 1, 0],
#          [1, 1, 1, 1, 1, 1, 1, 0]], dtype=int32)>}, 

# {'input_ids': <tf.Tensor: shape=(2, 8), #dtype=int32, numpy=
#   array([[ 101, 2023, 2003, 2028, 7882, 6254, 4953,  102],
#          [ 101, 2023, 2003, 2028, 7882, 6254, 4953,  102]], dtype=int32)>, 
#  'attention_mask': <tf.Tensor: shape=(2, 8), dtype=int32, numpy=
#   array([[1, 1, 1, 1, 1, 1, 1, 1],
#          [1, 1, 1, 1, 1, 1, 1, 1]], dtype=int32)>})
#  ...
```
 
However, when using [`tf.data.Dataset.map`][1] the following error arises:
```python3
tokenized_dataset = batched_dataset.map(tokenize)
AttributeError: 'Tensor' object has no attribute 'numpy'
```

Then, how properly apply a tokenizer map function to a batched dataset?

**Note**: I published a working example on [`Google Colab`][2].


  [1]: https://www.tensorflow.org/api_docs/python/tf/data/Dataset?version=nightly#map
  [2]: https://colab.research.google.com/drive/1TUbWwEgbgPHwY1QjgRLIqLpjin310pdh"
38670,Make it simpler to write custom metrics! ,"Why is it so complicated to write a simple custom metric? I do not want to deal with tensors, just numpy arrays. Please make it simpler and ability to use only numpy arrays. This request is for Keras.


<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): 2.1
- Are you willing to contribute it (Yes/No):



**Describe the feature and the current behavior/state.**

**Will this change the current api? How?**

**Who will benefit with this feature?**

**Any Other info.**
"
38668,"In ModelCheckpoint, filepath is not accepting batch as formatting parameter.","In `ModelCheckpoint` callback, there is a parameter given named `save_freq` to save model. If `save_freq` is set to `epoch`, it will save model at the end of every epoch. (This works perfectly fine). But when `save_freq` is set to an integer let's say `N`, then the callback should save the model after `N` batches in every epoch. But the problem here is the callback doesn't accept the filepath as `file.batch{batch:02d}epoch{epoch:02d}.h5` and raises error as `batch` is invalid key.  
The problem in the code that I have noticed is that the `_save_model` function has access to `epoch` but it doesn't have access to `batch`. And that's why `_get_file_path()` has access to `epoch` but not `batch`.  The functionality should be changed little bit. I am raising PR to add access to `batch` param in both `_save_model` and `_get_file_path` variable.
I noticed this error in tf code during the work on my PR [#1702](https://github.com/tensorflow/addons/pull/1702) in tensorflow/addons.  

cc @gabrieldemarmiesse.
"
38665,deviceMemoryBandwidth: -1B/s with tensorflow-rocm,"**Describe the problem**
I have a fresh install of Ubuntu (18.04.4) and just followed  [this instruction](https://www.videogames.ai/Install-ROCM-Machine-Learning-AMD-GPU) to install rocm and tensorflow. After importing tensorflow and executing ""tf.config.list_physical_devices('GPU')"", I get this output:
```
2020-04-18 10:17:47.965008: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libhip_hcc.so
2020-04-18 10:17:48.016723: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1573] Found device 0 with properties: 
pciBusID: 0000:29:00.0 name: Ellesmere [Radeon RX 470/480/570/570X/580/580X]     ROCm AMD GPU ISA: gfx803
coreClock: 1.35GHz coreCount: 36 deviceMemorySize: 8.00GiB deviceMemoryBandwidth: -1B/s
2020-04-18 10:17:48.051748: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library librocblas.so
2020-04-18 10:17:48.053144: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libMIOpen.so
2020-04-18 10:17:48.055482: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library librocfft.so
2020-04-18 10:17:48.055669: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library librocrand.so
2020-04-18 10:17:48.055769: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
```
The problem is that the deviceMemoryBandwidth seems to not be found and set to -1B/s. This results in tensorflow only allocating memory, but not using the GPU.

**System information**
- OS Platform and Distribution: Ubuntu 18.04.4
- TensorFlow installed from: pip
- TensorFlow version: 2.1.1
- Python version: 3.6.9
- GPU model and memory: AMD RX 580 8GB "
38664,"WARNING: 3 cannot be handled by this delegate. Only the first 0 ops will run on the GPU, and the remaining 17 on the CPU.","
    OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows10
    Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:Iphone XR
    TensorFlow installed from (source or binary):binary
    TensorFlow version: 1.14 (gpu)
    Python version:3.6
    Installed using virtualenv? pip? conda?:pip
    Bazel version (if compiling from source):
    GCC/Compiler version (if compiling from source):
    CUDA/cuDNN version: 10
    GPU model and memory: 1070Ti - 8GB

I have converted .h5 to .tflite. It's working perfectly with CPU but not with GPU. 
It's showing following error:
'WARNING: 3 cannot be handled by this delegate. Only the first 0 ops will run on the GPU, and the remaining 17 on the CPU.'
Here is my model: 
https://drive.google.com/file/d/1osGt-pr9hh9qvslrKY2TaxOLkwWsEA-2/view?usp=sharing"
38662,TFLiteConverter ConverterError with tf.float16 layers,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): colab
- TensorFlow installed from (source or binary): colab
- TensorFlow version (or github SHA if from source): 2.2.0-rc3


**Command used to run the converter or code if you’re using the Python API**

Colab:
https://colab.research.google.com/drive/1yLEzIz2O1opjQDHUTaZJGRSgg8DKHfeW

To get Error1:
```
import tensorflow as tf

input_layer = tf.keras.layers.Input(shape=(224,224,3), dtype=tf.float16)
final = tf.keras.layers.Dense(10, dtype=tf.float32)(input_layer)
model = tf.keras.models.Model(input_layer, final)

converter = tf.lite.TFLiteConverter.from_keras_model(model)
converter.optimizations = [tf.lite.Optimize.DEFAULT]

quantized_tflite_model = converter.convert()
```

To get Error2:
```
import tensorflow as tf

input_layer = tf.keras.layers.Input(shape=(224,224,3))
final = tf.keras.layers.Dense(10, dtype=tf.float16)(input_layer)
model = tf.keras.models.Model(input_layer, final)

converter = tf.lite.TFLiteConverter.from_keras_model(model)
converter.optimizations = [tf.lite.Optimize.DEFAULT]

quantized_tflite_model = converter.convert()
```

**The output from the converter invocation**

Error1:
```
---------------------------------------------------------------------------
ConverterError                            Traceback (most recent call last)
<ipython-input-3-cfb1369fd448> in <module>()
      2 converter.optimizations = [tf.lite.Optimize.DEFAULT]
      3 
----> 4 quantized_tflite_model = converter.convert()

2 frames
/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/convert.py in toco_convert_protos(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)
    225       stdout = _try_convert_to_unicode(stdout)
    226       stderr = _try_convert_to_unicode(stderr)
--> 227       raise ConverterError(""See console for info.\n%s\n%s\n"" % (stdout, stderr))
    228   finally:
    229     # Must manually cleanup files.

ConverterError: See console for info.
Traceback (most recent call last):
  File ""/usr/local/bin/toco_from_protos"", line 8, in <module>
    sys.exit(main())
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow_core/lite/toco/python/toco_from_protos.py"", line 93, in main
    app.run(main=execute, argv=[sys.argv[0]] + unparsed)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run
    _run_main(main, args)
  File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main
    sys.exit(main(argv))
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow_core/lite/toco/python/toco_from_protos.py"", line 56, in execute
    enable_mlir_converter)
Exception: Use '' if want to use the type from graph.

```

Error2:
```

---------------------------------------------------------------------------
ConverterError                            Traceback (most recent call last)
<ipython-input-5-cfb1369fd448> in <module>()
      2 converter.optimizations = [tf.lite.Optimize.DEFAULT]
      3 
----> 4 quantized_tflite_model = converter.convert()

2 frames
/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/convert.py in toco_convert_protos(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)
    225       stdout = _try_convert_to_unicode(stdout)
    226       stderr = _try_convert_to_unicode(stderr)
--> 227       raise ConverterError(""See console for info.\n%s\n%s\n"" % (stdout, stderr))
    228   finally:
    229     # Must manually cleanup files.

ConverterError: See console for info.
2020-04-18 02:25:05.438485: W tensorflow/compiler/mlir/lite/python/graphdef_to_tfl_flatbuffer.cc:89] Ignored output_format.
2020-04-18 02:25:05.438531: W tensorflow/compiler/mlir/lite/python/graphdef_to_tfl_flatbuffer.cc:95] Ignored drop_control_dependency.
2020-04-18 02:25:05.460283: E tensorflow/stream_executor/cuda/cuda_driver.cc:351] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
loc(callsite(""model_1/dense_1/Cast""(""/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py"":865:0) at callsite(""/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py"":959:0 at callsite(""/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/lite.py"":435:0 at callsite(""<ipython-input-5-cfb1369fd448>"":1:0 at callsite(""/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py"":2882:0 at callsite(""/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py"":2822:0 at callsite(""/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py"":2718:0 at callsite(""/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py"":537:0 at callsite(""/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py"":208:0 at ""/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py"":399:0)))))))))): error: 'tfl.cast' op result #0 must be tensor of 32-bit float or 1-bit integer or 32-bit integer or 64-bit integer values, but got 'tensor<1x224x224x3xf16>'
Traceback (most recent call last):
  File ""/usr/local/bin/toco_from_protos"", line 8, in <module>
    sys.exit(main())
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow_core/lite/toco/python/toco_from_protos.py"", line 93, in main
    app.run(main=execute, argv=[sys.argv[0]] + unparsed)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 300, in run
    _run_main(main, args)
  File ""/usr/local/lib/python2.7/dist-packages/absl/app.py"", line 251, in _run_main
    sys.exit(main(argv))
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow_core/lite/toco/python/toco_from_protos.py"", line 56, in execute
    enable_mlir_converter)
Exception: /usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py:865:9: error: 'tfl.cast' op result #0 must be tensor of 32-bit float or 1-bit integer or 32-bit integer or 64-bit integer values, but got 'tensor<1x224x224x3xf16>'
        self._initialize(args, kwargs, add_initializers_to=initializers)
        ^
/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py:959:5: note: called from
    concrete = self._get_concrete_function_garbage_collected(*args, **kwargs)
    ^
/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/lite.py:435:5: note: called from
    concrete_func = func.get_concrete_function()
    ^
<ipython-input-5-cfb1369fd448>: note: called from
/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2882:17: note: called from
                exec(code_obj, self.user_global_ns, self.user_ns)
                ^
/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2822:17: note: called from
                if self.run_code(code, result):
                ^
/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718:20: note: called from
                   interactivity=interactivity, compiler=compiler, result=result)
                   ^
/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py:537:9: note: called from
        return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)
        ^
/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py:208:13: note: called from
            res = shell.run_cell(code, store_history=store_history, silent=silent)
            ^
/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py:399:41: note: called from
                                        user_expressions, allow_stdin)
                                        ^




```

**Failure details**
TFLiteConverter throws a ConverterError if a layer is build with dtype=tf.float16
"
38661,Using variable value in tf.name_scope raises ValueError in graph mode,"**System information**
- Have I written custom code: Yes
- OS Platform and Distribution: macOS 10.15.5 Beta
- Mobile device: n/a
- TensorFlow installed from binary (`pip`)
- TensorFlow version: 
    - `tf.version.GIT_VERSION`: v2.1.0-rc2-17-ge5bf8de410
    - `tf.version.VERSION`: 2.1.0
- Python version: 3.6.8
- Bazel version (if compiling from source): n/a
- GCC/Compiler version (if compiling from source): n/a
- CUDA/cuDNN version: n/a
- GPU model and memory: n/a (currently developing on CPU)


**Describe the current behavior**
Example code:
```python
import tensorflow as tf

class MyModule(tf.Module):
    def __init__(self, name):
        super(MyModule, self).__init__(name=name)

@tf.function
def graphcry():
    mod_inst1 = MyModule(name='inst1')
    mod_inst2 = MyModule(name='inst2')
    myscalar = tf.constant(83.2)
    with tf.name_scope('scalaragain'):
        tf.summary.scalar('scalaragain', data=myscalar)
    with tf.name_scope(mod_inst1.name + ' and ' + mod_inst2.name):
        tf.summary.scalar('myscalar', data=myscalar)

graphcry()
```
results in this error:
```
 with tf.name_scope(mod_inst1.name + ' and ' + mod_inst2.name):
    .../site-packages/tensorflow_core/python/framework/ops.py:6392 __enter__
        scope_name = scope.__enter__()
    /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/contextlib.py:81 __enter__
        return next(self.gen)
   .../site-packages/tensorflow_core/python/framework/ops.py:4024 name_scope
        raise ValueError(""'%s' is not a valid scope name"" % name)

    ValueError: 'inst1 and inst2' is not a valid scope name
```
I may be misunderstanding something about Graph mode, but at the very least, I think a better error should be shown (the docs say `ValueError` is raised when the argument to `tf.name_scope` is `None` or not a string). 

And excuse my poor variable naming and nonadherence to PEP 8—I wrote this in nano. 

**Describe the expected behavior**
The scalar should be logged to TensorBoard without any errors, and under the name scope `inst1` and `inst2`. 

**Standalone code to reproduce the issue**
A minimal reproducible example is in the current behavior section.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
38660,Build from sources: An error occurred during the fetch of repository 'local_config_cuda',"**System information**
- OS Platform and Distribution: Linux Ubuntu 18.04
- TensorFlow installed from: source
- TensorFlow version: 3.0.0 
- Python version: 3.6.9
- Bazel version (if compiling from source): 2.1.0
- GCC/Compiler version (if compiling from source):7.5.0
- CUDA/cuDNN version: 10.2
- GPU model and memory: NVIDIA QUADRO K600



**Problem**
UnicodeDecodeError: 'ascii' codec can't decode byte 0xd1 in position 70: ordinal not in range(128)


**Sequence of commands**
bazel build  //tensorflow/tools/pip_package:build_pip_packageDD


**logs**

ERROR: An error occurred during the fetch of repository 'local_config_cuda':
   Traceback (most recent call last):
	File ""/home/andrey/tensorflow/third_party/gpus/cuda_configure.bzl"", line 1213
		_create_local_cuda_repository(<1 more arguments>)
	File ""/home/andrey/tensorflow/third_party/gpus/cuda_configure.bzl"", line 935, in _create_local_cuda_repository
		_find_libs(repository_ctx, <2 more arguments>)
	File ""/home/andrey/tensorflow/third_party/gpus/cuda_configure.bzl"", line 578, in _find_libs
		_check_cuda_libs(repository_ctx, <2 more arguments>)
	File ""/home/andrey/tensorflow/third_party/gpus/cuda_configure.bzl"", line 480, in _check_cuda_libs
		execute(repository_ctx, <1 more arguments>)
	File ""/home/andrey/tensorflow/third_party/remote_config/common.bzl"", line 208, in execute
		fail(<1 more arguments>)
Repository command failed
Traceback (most recent call last):
  File ""script.py"", line 88, in <module>
    main()
  File ""script.py"", line 77, in main
    check_cuda_lib(path, check_soname=args[i + 1] == ""True"")
  File ""script.py"", line 62, in check_cuda_lib
    output = subprocess.check_output([objdump, ""-p"", path]).decode(""ascii"")
UnicodeDecodeError: 'ascii' codec can't decode byte 0xd1 in position 70: ordinal not in range(128)
ERROR: Skipping '//tensorflow/tools/pip_package:build_pip_package': no such package '@local_config_cuda//cuda': Traceback (most recent call last):
	File ""/home/andrey/tensorflow/third_party/gpus/cuda_configure.bzl"", line 1213
		_create_local_cuda_repository(<1 more arguments>)
	File ""/home/andrey/tensorflow/third_party/gpus/cuda_configure.bzl"", line 935, in _create_local_cuda_repository
		_find_libs(repository_ctx, <2 more arguments>)
	File ""/home/andrey/tensorflow/third_party/gpus/cuda_configure.bzl"", line 578, in _find_libs
		_check_cuda_libs(repository_ctx, <2 more arguments>)
	File ""/home/andrey/tensorflow/third_party/gpus/cuda_configure.bzl"", line 480, in _check_cuda_libs
		execute(repository_ctx, <1 more arguments>)
	File ""/home/andrey/tensorflow/third_party/remote_config/common.bzl"", line 208, in execute
		fail(<1 more arguments>)
Repository command failed
Traceback (most recent call last):
  File ""script.py"", line 88, in <module>
    main()
  File ""script.py"", line 77, in main
    check_cuda_lib(path, check_soname=args[i + 1] == ""True"")
  File ""script.py"", line 62, in check_cuda_lib
    output = subprocess.check_output([objdump, ""-p"", path]).decode(""ascii"")
UnicodeDecodeError: 'ascii' codec can't decode byte 0xd1 in position 70: ordinal not in range(128)
WARNING: Target pattern parsing failed.
ERROR: no such package '@local_config_cuda//cuda': Traceback (most recent call last):
	File ""/home/andrey/tensorflow/third_party/gpus/cuda_configure.bzl"", line 1213
		_create_local_cuda_repository(<1 more arguments>)
	File ""/home/andrey/tensorflow/third_party/gpus/cuda_configure.bzl"", line 935, in _create_local_cuda_repository
		_find_libs(repository_ctx, <2 more arguments>)
	File ""/home/andrey/tensorflow/third_party/gpus/cuda_configure.bzl"", line 578, in _find_libs
		_check_cuda_libs(repository_ctx, <2 more arguments>)
	File ""/home/andrey/tensorflow/third_party/gpus/cuda_configure.bzl"", line 480, in _check_cuda_libs
		execute(repository_ctx, <1 more arguments>)
	File ""/home/andrey/tensorflow/third_party/remote_config/common.bzl"", line 208, in execute
		fail(<1 more arguments>)
Repository command failed
Traceback (most recent call last):
  File ""script.py"", line 88, in <module>
    main()
  File ""script.py"", line 77, in main
    check_cuda_lib(path, check_soname=args[i + 1] == ""True"")
  File ""script.py"", line 62, in check_cuda_lib
    output = subprocess.check_output([objdump, ""-p"", path]).decode(""ascii"")
UnicodeDecodeError: 'ascii' codec can't decode byte 0xd1 in position 70: ordinal not in range(128)
INFO: Elapsed time: 9.036s
INFO: 0 processes.
FAILED: Build did NOT complete successfully (0 packages loaded)
    currently loading: tensorflow/tools/pip_package
"
38659,tf2+yolov3 Convert to tflite quession,"o use: AVX2
Model: ""yolov3""
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to
==================================================================================================
input (InputLayer)              [(None, None, None,  0
__________________________________________________________________________________________________
yolo_darknet (Model)            ((None, None, None,  40620640    input[0][0]
__________________________________________________________________________________________________
yolo_conv_0 (Model)             (None, None, None, 5 11024384    yolo_darknet[1][2]
__________________________________________________________________________________________________
yolo_conv_1 (Model)             (None, None, None, 2 2957312     yolo_conv_0[1][0]
                                                                 yolo_darknet[1][1]
__________________________________________________________________________________________________
yolo_conv_2 (Model)             (None, None, None, 1 741376      yolo_conv_1[1][0]
                                                                 yolo_darknet[1][0]
__________________________________________________________________________________________________
yolo_output_0 (Model)           (None, None, None, 3 4984063     yolo_conv_0[1][0]
__________________________________________________________________________________________________
yolo_output_1 (Model)           (None, None, None, 3 1312511     yolo_conv_1[1][0]
__________________________________________________________________________________________________
yolo_output_2 (Model)           (None, None, None, 3 361471      yolo_conv_2[1][0]
__________________________________________________________________________________________________
yolo_boxes_0 (Lambda)           ((None, None, None,  0           yolo_output_0[1][0]
__________________________________________________________________________________________________
yolo_boxes_1 (Lambda)           ((None, None, None,  0           yolo_output_1[1][0]
__________________________________________________________________________________________________
yolo_boxes_2 (Lambda)           ((None, None, None,  0           yolo_output_2[1][0]
__________________________________________________________________________________________________
yolo_nms (Lambda)               ((None, 100, 4), (No 0           yolo_boxes_0[0][0]
                                                                 yolo_boxes_0[0][1]
                                                                 yolo_boxes_0[0][2]
                                                                 yolo_boxes_1[0][0]
                                                                 yolo_boxes_1[0][1]
                                                                 yolo_boxes_1[0][2]
                                                                 yolo_boxes_2[0][0]
                                                                 yolo_boxes_2[0][1]
                                                                 yolo_boxes_2[0][2]
==================================================================================================
Total params: 62,001,757
Trainable params: 61,949,149
Non-trainable params: 52,608
__________________________________________________________________________________________________
I0418 07:57:30.913888 54352 convert.py:19] model created
I0418 07:57:30.922950 54352 utils.py:45] yolo_darknet/conv2d bn
I0418 07:57:30.924918 54352 utils.py:45] yolo_darknet/conv2d_1 bn
I0418 07:57:30.926922 54352 utils.py:45] yolo_darknet/conv2d_2 bn
I0418 07:57:30.928931 54352 utils.py:45] yolo_darknet/conv2d_3 bn
I0418 07:57:30.933943 54352 utils.py:45] yolo_darknet/conv2d_4 bn
I0418 07:57:30.936951 54352 utils.py:45] yolo_darknet/conv2d_5 bn
I0418 07:57:30.939996 54352 utils.py:45] yolo_darknet/conv2d_6 bn
I0418 07:57:30.944971 54352 utils.py:45] yolo_darknet/conv2d_7 bn
I0418 07:57:30.947012 54352 utils.py:45] yolo_darknet/conv2d_8 bn
I0418 07:57:30.948982 54352 utils.py:45] yolo_darknet/conv2d_9 bn
I0418 07:57:30.956000 54352 utils.py:45] yolo_darknet/conv2d_10 bn
I0418 07:57:30.960010 54352 utils.py:45] yolo_darknet/conv2d_11 bn
I0418 07:57:30.966026 54352 utils.py:45] yolo_darknet/conv2d_12 bn
I0418 07:57:30.970039 54352 utils.py:45] yolo_darknet/conv2d_13 bn
I0418 07:57:30.973078 54352 utils.py:45] yolo_darknet/conv2d_14 bn
I0418 07:57:30.976053 54352 utils.py:45] yolo_darknet/conv2d_15 bn
I0418 07:57:30.981098 54352 utils.py:45] yolo_darknet/conv2d_16 bn
I0418 07:57:30.983071 54352 utils.py:45] yolo_darknet/conv2d_17 bn
I0418 07:57:30.989118 54352 utils.py:45] yolo_darknet/conv2d_18 bn
I0418 07:57:30.991132 54352 utils.py:45] yolo_darknet/conv2d_19 bn
I0418 07:57:30.996108 54352 utils.py:45] yolo_darknet/conv2d_20 bn
I0418 07:57:30.998111 54352 utils.py:45] yolo_darknet/conv2d_21 bn
I0418 07:57:31.002122 54352 utils.py:45] yolo_darknet/conv2d_22 bn
I0418 07:57:31.004158 54352 utils.py:45] yolo_darknet/conv2d_23 bn
I0418 07:57:31.007134 54352 utils.py:45] yolo_darknet/conv2d_24 bn
I0418 07:57:31.010144 54352 utils.py:45] yolo_darknet/conv2d_25 bn
I0418 07:57:31.014154 54352 utils.py:45] yolo_darknet/conv2d_26 bn
I0418 07:57:31.026219 54352 utils.py:45] yolo_darknet/conv2d_27 bn
I0418 07:57:31.029193 54352 utils.py:45] yolo_darknet/conv2d_28 bn
I0418 07:57:31.041259 54352 utils.py:45] yolo_darknet/conv2d_29 bn
I0418 07:57:31.044235 54352 utils.py:45] yolo_darknet/conv2d_30 bn
I0418 07:57:31.055304 54352 utils.py:45] yolo_darknet/conv2d_31 bn
I0418 07:57:31.058273 54352 utils.py:45] yolo_darknet/conv2d_32 bn
I0418 07:57:31.068298 54352 utils.py:45] yolo_darknet/conv2d_33 bn
I0418 07:57:31.071306 54352 utils.py:45] yolo_darknet/conv2d_34 bn
I0418 07:57:31.085376 54352 utils.py:45] yolo_darknet/conv2d_35 bn
I0418 07:57:31.088377 54352 utils.py:45] yolo_darknet/conv2d_36 bn
I0418 07:57:31.100429 54352 utils.py:45] yolo_darknet/conv2d_37 bn
I0418 07:57:31.103426 54352 utils.py:45] yolo_darknet/conv2d_38 bn
I0418 07:57:31.116426 54352 utils.py:45] yolo_darknet/conv2d_39 bn
I0418 07:57:31.119471 54352 utils.py:45] yolo_darknet/conv2d_40 bn
I0418 07:57:31.130496 54352 utils.py:45] yolo_darknet/conv2d_41 bn
I0418 07:57:31.133472 54352 utils.py:45] yolo_darknet/conv2d_42 bn
I0418 07:57:31.147543 54352 utils.py:45] yolo_darknet/conv2d_43 bn
I0418 07:57:31.193630 54352 utils.py:45] yolo_darknet/conv2d_44 bn
I0418 07:57:31.200688 54352 utils.py:45] yolo_darknet/conv2d_45 bn
I0418 07:57:31.245767 54352 utils.py:45] yolo_darknet/conv2d_46 bn
I0418 07:57:31.252820 54352 utils.py:45] yolo_darknet/conv2d_47 bn
I0418 07:57:31.299911 54352 utils.py:45] yolo_darknet/conv2d_48 bn
I0418 07:57:31.307933 54352 utils.py:45] yolo_darknet/conv2d_49 bn
I0418 07:57:31.353052 54352 utils.py:45] yolo_darknet/conv2d_50 bn
I0418 07:57:31.361075 54352 utils.py:45] yolo_darknet/conv2d_51 bn
I0418 07:57:31.404188 54352 utils.py:45] yolo_conv_0/conv2d_52 bn
I0418 07:57:31.411207 54352 utils.py:45] yolo_conv_0/conv2d_53 bn
I0418 07:57:31.459374 54352 utils.py:45] yolo_conv_0/conv2d_54 bn
I0418 07:57:31.466355 54352 utils.py:45] yolo_conv_0/conv2d_55 bn
I0418 07:57:31.511475 54352 utils.py:45] yolo_conv_0/conv2d_56 bn
I0418 07:57:31.518527 54352 utils.py:45] yolo_output_0/conv2d_57 bn
I0418 07:57:31.562608 54352 utils.py:45] yolo_output_0/conv2d_58 bias
I0418 07:57:31.566619 54352 utils.py:45] yolo_conv_1/conv2d_59 bn
I0418 07:57:31.568628 54352 utils.py:45] yolo_conv_1/conv2d_60 bn
I0418 07:57:31.570631 54352 utils.py:45] yolo_conv_1/conv2d_61 bn
I0418 07:57:31.579694 54352 utils.py:45] yolo_conv_1/conv2d_62 bn
I0418 07:57:31.582699 54352 utils.py:45] yolo_conv_1/conv2d_63 bn
I0418 07:57:31.591723 54352 utils.py:45] yolo_conv_1/conv2d_64 bn
I0418 07:57:31.593731 54352 utils.py:45] yolo_output_1/conv2d_65 bn
I0418 07:57:31.602754 54352 utils.py:45] yolo_output_1/conv2d_66 bias
I0418 07:57:31.604759 54352 utils.py:45] yolo_conv_2/conv2d_67 bn
I0418 07:57:31.605724 54352 utils.py:45] yolo_conv_2/conv2d_68 bn
I0418 07:57:31.606727 54352 utils.py:45] yolo_conv_2/conv2d_69 bn
I0418 07:57:31.609774 54352 utils.py:45] yolo_conv_2/conv2d_70 bn
I0418 07:57:31.610738 54352 utils.py:45] yolo_conv_2/conv2d_71 bn
I0418 07:57:31.613745 54352 utils.py:45] yolo_conv_2/conv2d_72 bn
I0418 07:57:31.614750 54352 utils.py:45] yolo_output_2/conv2d_73 bn
I0418 07:57:31.617794 54352 utils.py:45] yolo_output_2/conv2d_74 bias
I0418 07:57:31.618758 54352 convert.py:22] weights loaded
I0418 07:57:32.081988 54352 convert.py:26] sanity check passed
I0418 07:57:32.725983 54352 convert.py:29] weights saved

(yolov3-tf2-cpu) C:\Users\EZSHIPE\Downloads\yolov3-tf2-peng\yolov3-tf2-master>
(yolov3-tf2-cpu) C:\Users\EZSHIPE\Downloads\yolov3-tf2-peng\yolov3-tf2-master>python tools/export_tflite.py
2020-04-18 07:58:00.586491: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'cudart64_101.dll'; dlerror: cudart64_101.dll not fo
und
2020-04-18 07:58:00.591208: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2020-04-18 07:58:08.994699: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'nvcuda.dll'; dlerror: nvcuda.dll not found
2020-04-18 07:58:08.999120: E tensorflow/stream_executor/cuda/cuda_driver.cc:351] failed call to cuInit: UNKNOWN ERROR (303)
2020-04-18 07:58:09.008186: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: CN-00012968
2020-04-18 07:58:09.012520: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: CN-00012968
2020-04-18 07:58:09.015456: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2
I0418 07:58:14.900625 14620 export_tflite.py:34] weights loaded
2020-04-18 07:58:15.624135: I tensorflow/core/grappler/devices.cc:55] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0
2020-04-18 07:58:15.628949: I tensorflow/core/grappler/clusters/single2020-04-18 07:58:15.676348: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization res
ults for grappler item: graph_to_optimize
2020-04-18 07:58:15.680926: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0.005ms.
2020-04-18 07:58:15.685573: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-04-18 07:58:22.022971: I tensorflow/core/grappler/devices.cc:55] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0
2020-04-18 07:58:22.027511: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session
2020-04-18 07:58:26.747778: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: graph_to_optimize
2020-04-18 07:58:26.751954: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   constant_folding: Graph size after: 993 nodes (-366), 2545 edges (-366), time = 3012
.25903ms.
2020-04-18 07:58:26.755753: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   constant_folding: Graph size after: 993 nodes (0), 2545 edges (0), time = 833.124ms.

Traceback (most recent call last):
  File ""tools/export_tflite.py"", line 65, in <module>
    app.run(main)
  File ""C:\Users\EZSHIPE\.conda\envs\yolov3-tf2-cpu\lib\site-packages\absl\app.py"", line 299, in run
    _run_main(main, args)
  File ""C:\Users\EZSHIPE\.conda\envs\yolov3-tf2-cpu\lib\site-packages\absl\app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""tools/export_tflite.py"", line 37, in main
    tflite_model = converter.convert()
  File ""C:\Users\EZSHIPE\.conda\envs\yolov3-tf2-cpu\lib\site-packages\tensorflow_core\lite\python\lite.py"", line 464, in convert
    **converter_kwargs)
  File ""C:\Users\EZSHIPE\.conda\envs\yolov3-tf2-cpu\lib\site-packages\tensorflow_core\lite\python\convert.py"", line 457, in toco_convert_impl
    enable_mlir_converter=enable_mlir_converter)
  File ""C:\Users\EZSHIPE\.conda\envs\yolov3-tf2-cpu\lib\site-packages\tensorflow_core\lite\python\convert.py"", line 203, in toco_convert_protos
    raise ConverterError(""See console for info.\n%s\n%s\n"" % (stdout, stderr))
tensorflow.lite.python.convert.ConverterError: See console for info.
2020-04-18 07:58:29.920472: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'cudart64_101.dll'; dlerror: cudart64_101.dll not fo
und
2020-04-18 07:58:29.920864: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2020-04-18 07:58:39.215598: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Size
2020-04-18 07:58:39.215864: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Size
2020-04-18 07:58:39.216436: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Size
2020-04-18 07:58:39.216683: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Size
2020-04-18 07:58:39.217119: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Size
2020-04-18 07:58:39.217325: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Size
2020-04-18 07:58:39.217665: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: CombinedNonMaxSuppression
2020-04-18 07:58:39.276378: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 735 operators, 1368 arrays (0 quantized)
2020-04-18 07:58:39.295435: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 735 operators, 1368 arrays (0 quant
ized)
2020-04-18 07:58:39.987076: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 284 operators, 533 arrays (0
quantized)
2020-04-18 07:58:39.993843: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 2: 284 operators, 533 arrays (0
quantized)
2020-04-18 07:58:40.000453: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Group bidirectional sequence lstm/rnn: 284 operators, 533 arrays (
0 quantized)
2020-04-18 07:58:40.005543: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before dequantization graph transformations: 284 operators, 533 arrays (0
 quantized)
2020-04-18 07:58:40.009657: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Identify nearest upsample.: 284 operators, 533 arrays (0 quantized
)
2020-04-18 07:58:40.020140: I tensorflow/lite/toco/allocate_transient_arrays.cc:345] Total transient array allocated size: 66560128 bytes, theoretical optimal value: 44408960
bytes.
2020-04-18 07:58:40.021499: I tensorflow/lite/toco/toco_tooling.cc:471] Number of parameters: 61923215
2020-04-18 07:58:40.029275: E tensorflow/lite/toco/toco_tooling.cc:498] We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpfu
l if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md
 and pasting the following:

Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended r
untime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implem
entation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin ope
rators you are using: ADD, CAST, CONCATENATION, CONV_2D, DIV, EXP, EXPAND_DIMS, FILL, LEAKY_RELU, LOGISTIC, MUL, PACK, PAD, RESHAPE, RESIZE_NEAREST_NEIGHBOR, SHAPE, SPLIT_V, S
TRIDED_SLICE, SUB. Here is a list of operators for which you will need custom implementations: CombinedNonMaxSuppression, Size.
Traceback (most recent call last):
  File ""c:\users\ezshipe\.conda\envs\yolov3-tf2-cpu\lib\runpy.py"", line 193, in _run_module_as_main
    ""__main__"", mod_spec)
  File ""c:\users\ezshipe\.conda\envs\yolov3-tf2-cpu\lib\runpy.py"", line 85, in _run_code
    exec(code, run_globals)
  File ""C:\Users\EZSHIPE\.conda\envs\yolov3-tf2-cpu\Scripts\toco_from_protos.exe\__main__.py"", line 7, in <module>
  File ""c:\users\ezshipe\.conda\envs\yolov3-tf2-cpu\lib\site-packages\tensorflow_core\lite\toco\python\toco_from_protos.py"", line 93, in main
    app.run(main=execute, argv=[sys.argv[0]] + unparsed)
  File ""c:\users\ezshipe\.conda\envs\yolov3-tf2-cpu\lib\site-packages\tensorflow_core\python\platform\app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""c:\users\ezshipe\.conda\envs\yolov3-tf2-cpu\lib\site-packages\absl\app.py"", line 299, in run
    _run_main(main, args)
  File ""c:\users\ezshipe\.conda\envs\yolov3-tf2-cpu\lib\site-packages\absl\app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""c:\users\ezshipe\.conda\envs\yolov3-tf2-cpu\lib\site-packages\tensorflow_core\lite\toco\python\toco_from_protos.py"", line 56, in execute
    enable_mlir_converter)
Exception: We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by openi
ng a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md
 and pasting the following:

Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended r
untime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implem
entation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin ope
rators you are using: ADD, CAST, CONCATENATION, CONV_2D, DIV, EXP, EXPAND_DIMS, FILL, LEAKY_RELU, LOGISTIC, MUL, PACK, PAD, RESHAPE, RESIZE_NEAREST_NEIGHBOR, SHAPE, SPLIT_V, S
TRIDED_SLICE, SUB. Here is a list of operators for which you will need custom implementations: CombinedNonMaxSuppression, Size.

"
38658,clip_by_value handles python float and numpy float differently,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): ubuntu 16.04 & macos10.14.6
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): ubuntu 16.04: v2.1.0-rc2-17-ge5bf8de & macos: v2.1.0-rc2-17-ge5bf8de410
- Python version: 3.7.6
- Bazel version (if compiling from source): NA
- GCC/Compiler version (if compiling from source): NA
- CUDA/cuDNN version: NA
- GPU model and memory: NA

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
`clip_by_value(t, clip_value_min, clip_value_max)` treats python float and numpy float32/float64 differently for parameters `clip_value_min` and `clip_value_max`.

It throws exception when `t` is `int`, `clip_value_min` and `clip_value_max` are `float`, but it **doesn't** throw exception when `clip_value_min` and `clip_value_max` are numpy float. See the example below.

**Describe the expected behavior**
I expect the behavior should be consistent whether the passed in `clip_value_min` and `clip_value_max` are python `float` or numpy `float`. 

It shouldn't silently cast numpy `float` to `int` and report unexpected result.

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.
```python
import tensorflow as tf
import numpy as np

# ok case
tf.clip_by_value([1,2,3], clip_value_min=0, clip_value_max=1) 

# exception when using python float
tf.clip_by_value([1,2,3], clip_value_min=0., clip_value_max=1.)

# no exception when using numpy float16/32/64
tf.clip_by_value([1,2,3], clip_value_min=np.float32(0.), clip_value_max=np.float32(1.))

# no exception; same output as above;
# 0.5 is silenlty casted to 0, and 1.2 is silently casted to 1
tf.clip_by_value([1,2,3], clip_value_min=np.float32(0.5), clip_value_max=np.float32(1.2))
```
**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
38655,[2.2rc3] Keras validation data doesn't respect cache in MirroredStrategy,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.2.0rc3
- Python version: 3.7
- CUDA/cuDNN version: 10.1 / 7.6.5.32
- GPU model and memory: 4 x NVIDIA V100 on GCP

**Describe the current behavior**

When running the code below with cached training and validations datasets in a multi-GPU environment (I am using a GCP VM with 312GB of memory and 4 NVIDIA V100s) with `tf.distribute.MirroredStrategy()` the validation dataset isn't correctly cached and examples are still read from GCS during validation.

The memory usage suggests that the validation dataset is cached, but during the Keras validation loop it looks like that data is still read from GCS instead of from the cache which can be observed by the very high network usage during validation. I would expect no network usage after the first epoch.

In the example below I intentionally use an very large validation set to make this issue very obvious and easy to detect through monitoring network usage. This behaviour can also be observed with other datasets, but the unexpected network access will be less noticible on smaller datsets.

**In which cases can this issue not be observed?**
To narrow down the possible causes for this I found two cases where this issue doesn't exist:

1. When running on a single GPU without `MirroredStrategy` the validation data is correctly read from the cache and after the start of the second epoch no additional network traffic reading from GCS can be observed.

2. When not using a validation dataset at all the network usage is zero after the first epoch so caching of the training set works as expected.

This seems to be a complicated interaction between `tf.data`, `tf.keras` and `tf.distribute`, do you have an idea what could cause this behaviour? Please let me know what additional information I could provide.

**Describe the expected behavior**

Network usage should be zero after the start of the second epoch since both datasets are cached  in memory and no additional reads from GCS should be required.

**Standalone code to reproduce the issue**
```python
import tensorflow as tf
import tensorflow_datasets as tfds


batch_size = 1024
decoders = {""image"": tfds.decode.SkipDecoding()}

dataset = tfds.load(
    ""imagenet2012:5.0.0"",
    decoders=decoders,
    split=""validation"",
    data_dir=""gs://my-data-bucket"",
)

val_dataset = tfds.load(
    ""imagenet2012:5.0.0"",
    decoders=decoders,
    split=""train"",
    data_dir=""gs://my-data-bucket"",
)


def _decode_and_center_crop(image_bytes):
    """"""Crops to center of image with padding then scales image_size.""""""
    shape = tf.image.extract_jpeg_shape(image_bytes)
    image_height = shape[0]
    image_width = shape[1]
    image_size = 224

    padded_center_crop_size = tf.cast(
        (
            (image_size / (image_size + 32))
            * tf.cast(tf.minimum(image_height, image_width), tf.float32)
        ),
        tf.int32,
    )

    offset_height = ((image_height - padded_center_crop_size) + 1) // 2
    offset_width = ((image_width - padded_center_crop_size) + 1) // 2
    crop_window = tf.stack(
        [offset_height, offset_width, padded_center_crop_size, padded_center_crop_size]
    )
    image = tf.image.decode_and_crop_jpeg(image_bytes, crop_window, channels=3)
    return tf.image.resize(image, [image_size, image_size], method=""bicubic"")


def preprocessing(data):
    return tf.cast(_decode_and_center_crop(data[""image""]), tf.float32), data[""label""]


def apply_preprocessing(dataset):
    return (
        dataset.cache()
        .map(preprocessing, num_parallel_calls=tf.data.experimental.AUTOTUNE)
        .batch(batch_size)
        .prefetch(1)
    )


dataset = apply_preprocessing(dataset)
val_dataset = apply_preprocessing(val_dataset)

with tf.distribute.MirroredStrategy().scope():
    model = tf.keras.models.Sequential(
        [
            tf.keras.layers.GlobalMaxPool2D(input_shape=(224, 224, 3)),
            tf.keras.layers.Dense(1000, activation=""softmax"",),
        ]
    )

    model.compile(
        optimizer=""adam"",
        loss=""sparse_categorical_crossentropy"",
        metrics=[""accuracy"", ""sparse_top_k_categorical_accuracy""],
    )

model.fit(
    dataset, epochs=5, validation_data=val_dataset,
)
```

**Other info / logs**

To monitor the network usage over time tools like [`ytop`](https://github.com/cjbassi/ytop/) can be used."
38651,Cross-posting from Keras Memory leaks hang on GPU; no PID to kill (not sudo user so cannot install nvtop),https://github.com/keras-team/keras/issues/13975
38650,LossScaleOptimizer compatible with DecoupledWeightDecayExtension,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): 2.1
- Are you willing to contribute it (Yes/No): Yes



**Describe the feature and the current behavior/state.**

The features allows for use decoupled weight decay optimizers

https://www.tensorflow.org/addons/api_docs/python/tfa/optimizers/weight_decay_optimizers/DecoupledWeightDecayExtension

with mixed precision using

https://www.tensorflow.org/api_docs/python/tf/keras/mixed_precision/experimental/LossScaleOptimizer

**Will this change the current api? How?**

Don't believe so

**Who will benefit with this feature?**

Those used decoupled weight decay and mixed precision.

**Any Other info.**

That's it.
"
38648,save_best_only does not work,"**System information**
Windows 7
Python 3.8
Tensorflow 2.1

**Describe the current behavior**

```python
filepath = ""RNN_Final-{epoch:02d}-{val_accuracy:.3f}""

checkpoint = ModelCheckpoint(""models\{}.hdf5"".format(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max'))
```

```python
history = model.fit(
    train_x, train_y,
    batch_size=BATCH_SIZE,
    epochs=EPOCHS,
    validation_data=(validation_x, validation_y),
    callbacks=[checkpoint],
)
```

I train the model with  _save_best_only_  enabled. It saves **all** the models in the directory, even when the val_accuracy reduces. I tried also switching to val_loss mode='min' but same behavior occurs.

**Describe the expected behavior**

I was expecting it to save only the models that had higher val / lower loss (According to definitions)
![tensorflow](https://user-images.githubusercontent.com/4284362/79604094-634bce80-80e5-11ea-8d5b-fe69262205b6.png)
"
38646,Facing issue with installation of witwidget (google what-if too) on Windows in Anaconda," I am facing issue with installation of What-If tool.

Step 1 : pip install tensorflow (This completed successfully)

Step 2 : pip install witwidget (this completed successfully)

Step 3 : jupyter nbextension install --py --symlink --sys-prefix witwidget (this failed and the error log is given below)

Environment : Windows 10 Python version : 3.7.0

(base) C:\Users\ankitagarwal5>jupyter nbextension install --py --symlink --sys-prefix witwidget Traceback (most recent call last): File ""C:\Users\ankitagarwal5\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in from tensorflow.python.pywrap_tensorflow_internal import * File ""C:\Users\ankitagarwal5\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in _pywrap_tensorflow_internal = swig_import_helper() File ""C:\Users\ankitagarwal5\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description) File ""C:\Users\ankitagarwal5\AppData\Local\Continuum\anaconda3\lib\imp.py"", line 243, in load_module return load_dynamic(name, filename, file) File ""C:\Users\ankitagarwal5\AppData\Local\Continuum\anaconda3\lib\imp.py"", line 343, in load_dynamic return _load(spec) ImportError: DLL load failed: The specified module could not be found.

During handling of the above exception, another exception occurred:

Traceback (most recent call last): File ""C:\Users\ankitagarwal5\AppData\Local\Continuum\anaconda3\Scripts\jupyter-nbextension-script.py"", line 10, in sys.exit(main()) File ""C:\Users\ankitagarwal5\AppData\Local\Continuum\anaconda3\lib\site-packages\jupyter_core\application.py"", line 266, in launch_instance return super(JupyterApp, cls).launch_instance(argv=argv, **kwargs) File ""C:\Users\ankitagarwal5\AppData\Local\Continuum\anaconda3\lib\site-packages\traitlets\config\application.py"", line 658, in launch_instance app.start() File ""C:\Users\ankitagarwal5\AppData\Local\Continuum\anaconda3\lib\site-packages\notebook\nbextensions.py"", line 988, in start super(NBExtensionApp, self).start() File ""C:\Users\ankitagarwal5\AppData\Local\Continuum\anaconda3\lib\site-packages\jupyter_core\application.py"", line 255, in start self.subapp.start() File ""C:\Users\ankitagarwal5\AppData\Local\Continuum\anaconda3\lib\site-packages\notebook\nbextensions.py"", line 716, in start self.install_extensions() File ""C:\Users\ankitagarwal5\AppData\Local\Continuum\anaconda3\lib\site-packages\notebook\nbextensions.py"", line 695, in install_extensions **kwargs File ""C:\Users\ankitagarwal5\AppData\Local\Continuum\anaconda3\lib\site-packages\notebook\nbextensions.py"", line 211, in install_nbextension_python m, nbexts = _get_nbextension_metadata(module) File ""C:\Users\ankitagarwal5\AppData\Local\Continuum\anaconda3\lib\site-packages\notebook\nbextensions.py"", line 1122, in _get_nbextension_metadata m = import_item(module) File ""C:\Users\ankitagarwal5\AppData\Local\Continuum\anaconda3\lib\site-packages\traitlets\utils\importstring.py"", line 42, in import_item return import(parts[0]) File ""C:\Users\ankitagarwal5\AppData\Local\Continuum\anaconda3\lib\site-packages\witwidget__init__.py"", line 15, in from witwidget.notebook.visualization import * File ""C:\Users\ankitagarwal5\AppData\Local\Continuum\anaconda3\lib\site-packages\witwidget\notebook\visualization.py"", line 17, in import tensorflow as tf File ""C:\Users\ankitagarwal5\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow__init__.py"", line 101, in from tensorflow_core import * File ""C:\Users\ankitagarwal5\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core__init__.py"", line 40, in from tensorflow.python.tools import module_util as _module_util File ""C:\Users\ankitagarwal5\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow__init__.py"", line 50, in getattr module = self._load() File ""C:\Users\ankitagarwal5\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow__init__.py"", line 44, in _load module = _importlib.import_module(self.name) File ""C:\Users\ankitagarwal5\AppData\Local\Continuum\anaconda3\lib\importlib__init__.py"", line 127, in import_module return _bootstrap._gcd_import(name[level:], package, level) File ""C:\Users\ankitagarwal5\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python__init__.py"", line 49, in from tensorflow.python import pywrap_tensorflow File ""C:\Users\ankitagarwal5\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 74, in raise ImportError(msg) ImportError: Traceback (most recent call last): File ""C:\Users\ankitagarwal5\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in from tensorflow.python.pywrap_tensorflow_internal import * File ""C:\Users\ankitagarwal5\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in _pywrap_tensorflow_internal = swig_import_helper() File ""C:\Users\ankitagarwal5\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description) File ""C:\Users\ankitagarwal5\AppData\Local\Continuum\anaconda3\lib\imp.py"", line 243, in load_module return load_dynamic(name, filename, file) File ""C:\Users\ankitagarwal5\AppData\Local\Continuum\anaconda3\lib\imp.py"", line 343, in load_dynamic return _load(spec) ImportError: DLL load failed: The specified module could not be found.

Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/errors

for some common reasons and solutions. Include the entire stack trace above this error message when asking for help."
38645,Issue with Tensorshape and Datasets,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):

Yes

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):

Linux Ubuntu 18.04

- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:

N/A

- TensorFlow installed from (source or binary):

binary (pip)

- TensorFlow version (use command below):

v2.1.0-rc2-17-ge5bf8de
2.1.0

- Python version:

3.7.7

- Bazel version (if compiling from source):

N/A

- GCC/Compiler version (if compiling from source):

N/A

- CUDA/cuDNN version:

10.1

- GPU model and memory:

GTX 1080 Ti, 11 GB

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**

I am trying to use tf.Dataset with generators, I am getting the following very strange error trying to build tf.TensorShape:

```
TypeError: in converted code:

    <ipython-input-86-05d6b5f23a20>:11 None  *
        ds = ds.interleave(lambda gen_idx: tf.data.Dataset.from_generator(gen_wrapper,
    /home/jostheim/virtualenvs/data_science/lib/python3.7/site-packages/tensorflow_core/python/data/ops/dataset_ops.py:744 from_generator
        output_types, tensor_shape.as_shape, output_shapes)
    /home/jostheim/virtualenvs/data_science/lib/python3.7/site-packages/tensorflow_core/python/data/util/nest.py:471 map_structure_up_to
        results = [func(*tensors) for tensors in zip(*all_flattened_up_to)]
    /home/jostheim/virtualenvs/data_science/lib/python3.7/site-packages/tensorflow_core/python/data/util/nest.py:471 <listcomp>
        results = [func(*tensors) for tensors in zip(*all_flattened_up_to)]
    /home/jostheim/virtualenvs/data_science/lib/python3.7/site-packages/tensorflow_core/python/framework/tensor_shape.py:1211 as_shape
        return TensorShape(shape)
    /home/jostheim/virtualenvs/data_science/lib/python3.7/site-packages/tensorflow_core/python/framework/tensor_shape.py:771 __init__
        self._dims = [as_dimension(d) for d in dims_iter]
    /home/jostheim/virtualenvs/data_science/lib/python3.7/site-packages/tensorflow_core/python/framework/tensor_shape.py:771 <listcomp>
        self._dims = [as_dimension(d) for d in dims_iter]
    /home/jostheim/virtualenvs/data_science/lib/python3.7/site-packages/tensorflow_core/python/framework/tensor_shape.py:716 as_dimension
        return Dimension(value)
    /home/jostheim/virtualenvs/data_science/lib/python3.7/site-packages/tensorflow_core/python/framework/tensor_shape.py:200 __init__
        None)
    <string>:3 raise_from
        

    TypeError: Dimension value must be integer or None or have an __index__ method, got TensorShape([1])
```


**Describe the expected behavior**

The ints I pass into TensorShape should be recognized as ints and not throw an error.

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

```
def gen(): 
  for i in itertools.count(1): 
    yield (i, [1] * i) 
ds = tf.data.Dataset.from_tensor_slices(list(range(24)))
ds = ds.interleave(lambda gen_idx: tf.data.Dataset.from_generator(gen,
                                                                  output_types=(tf.float32),
                                                                  args=(gen_idx,),
                                                                  output_shapes=(tf.TensorShape([]), tf.TensorShape([None]))),
                   cycle_length=24,
                   block_length=1,
                   num_parallel_calls=24)
```

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
38644,The output of BatchNormalization may contain Nan under certain parameters,"**System information**  
- Have I written custom code (as opposed to using example directory):  
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):   Linux Ubuntu 18.04
- TensorFlow backend (yes / no):  yes
- TensorFlow version:  2.1.0-CPU
- Python version:  3.6.9
- CUDA/cuDNN version:  -
- GPU model and memory:  -

**Describe the current behavior**  
I found that the output of  `BatchNormalization` in `tensorflow.keras` may contain ""Nan"" under certain parameters. As an operation for normalization calculations, this is quite abnormal for `BatchNormalization` with nan output. This may lead to horrible results for the models with `BatchNormalization`, for example, accidental termination in training.  Detailed reproduction can be found in the following codes.

![image](https://user-images.githubusercontent.com/46860123/79631824-f5a7ad00-818d-11ea-8474-c72228a6cf65.png)


## Code to reproduce the issue

```
import os
import numpy as np
import pickle
import argparse
import tensorflow as tf
import tensorflow.keras.layers as L
from tensorflow.keras.models import load_model


if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='reproduce')
    parser.add_argument('-path', '-p', type=str,help='Path')
    args = parser.parse_args('-p ./Your Path/nan'.split( ))# Your path is where you unzip nan.zip
    root_path = os.path.abspath(args.path)
    with open(os.path.join(root_path, 'input.pkl'), 'rb') as f:#input,bug type,params
        meta = pickle.load(f)
    input1 = meta['input']
    input=input1.astype(np.float32)
    model_path = os.path.join(root_path, 'model.h5')
    model = load_model(model_path)
    output = model.predict(input)
    nanresult=np.isnan(output).any()
    print(nanresult)

```
[nan.zip](https://github.com/tensorflow/tensorflow/files/4494054/nan.zip)

Unzip the nan.zip, you can find the model.h5 and input.pkl in it."
38643,Resize Second Derivatives,"**System information**
- TensorFlow version (you are using): 2.2.0.dev20200416
- Are you willing to contribute it (Yes/No): No

**Describe the feature and the current behavior/state.**

`tf.image.resize` can calculate derivatives but there exists no gradient for the gradient of it.

**Will this change the current api? How?**

No (the API will not change, but the higher-order derivative will be calculable)

**Who will benefit with this feature?**

I ran into this issue when implemented ProGAN with a regularized JS-GAN, as it requires the second derivative of the discriminator, which involves a resize operation. If a second-order derivative is added, this will be possible.

**Any Other info.**

N/A"
38642,Roadmap for publishing TFLite runtime on PyPi?,"First off, congrats to the team for all the great progress made towards publishing tflite runtime 2.x binaries for a matrix of architectures and python versions.

I know the topic of publishing tflite-runtime on pypi has been discussed, but I cannot find an issue or thread to follow. Could you please point me to it if there is one?

Thank you!"
38640,"K.cast_to_floatx() will convert ""None"" to ""Nan"" and lead the ReLU to Nan output.","**System information**  
- Have I written custom code (as opposed to using example directory):  
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):   Linux Ubuntu 18.04
- TensorFlow backend (yes / no):  yes
- TensorFlow version:  1.14.0-cpu
- Python version:  3.6.9
- CUDA/cuDNN version:  -
- GPU model and memory:  -

**Describe the current behavior**  

I found that if I used `ReLU(threshold = None)` in `tensorflow.keras`, without any errors or warnings, Tensorflow will return a matrix with Nan.  (Detailed configuration and codes for reproduction can be found in the following part) .

For this reason, I did some investigations and found that when the parameters in `ReLU` are passed to `/tensorflow/python/keras/layers/advanced_activations.py line near line 311`, `K.cast_to_floatx()`  will incorrectly convert the ""None"" parameter to ""Nan"" and pass it to the backend for calculation (refer to Figure 1 and Figure 2).  

""Nan"" and ""None"" should have different meanings, but `K.cast_to_floatx` did not distinguish between ""Nan"" and ""None"" during the calculation, which led to the usage of a ""Nan"" parameter in the tensorflow calculation. This further affects the final output result and makes the output with  ""Nan"". This operation may confuse the users.  

**Is there a difference in meaning between None and Nan in the implementation of `K.cast_to_floatx`?  Judging from the current results, their meanings are different.**   This issue n**ot only affect ReLU, but also affect ThresholdReLU, LeakyReLU and other operations using `K.cast_to_floatx()`** to convert the parameters.

## Code to reproduce the issue

```
import os
import numpy as np
import tensorflow as tf
import tensorflow.keras.layers as L
from tensorflow.keras.models import load_model


root_path = ""./Your Path""
layer_name=""ReLU""
kwargs={'max_value': 0.5761369157060329, 'negative_slope': 0.7845179761191806, 'threshold': None}
input= (10 * np.random.randn(1,32,32,16)).astype(np.float32)
from tensorflow.keras import Model, Input
layer_cls = getattr(L, layer_name)
layer = layer_cls(**kwargs)
x = Input(batch_shape=input.shape)
y = layer(x)
bk_model =Model(x, y)
model_path = os.path.join(root_path, 'model.h5')
bk_model.save(model_path, bk_model)
model = load_model(model_path)     
output = model.predict(input)
nanresult=np.isnan(output).any()
print(nanresult)
```"
38638,Dilated convolution pass not working on standard TCN model,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- TensorFlow installed from (source or binary): source
- TensorFlow version (or github SHA if from source): 17dfa4e121c080a547e9cf6443b8fe2ae9ed45ed


**Command used to run the converter or code if you’re using the Python API**
If possible, please share a link to Colab/Jupyter/any notebook.

```
# Copy and paste here the exact command (in Python)
model = load_model(model_path, custom_objects={'TCN': TCN})
converter = tf.lite.TFLiteConverter.from_keras_model(model)
converter.experimental_new_converter = True
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS]
```
```
# Copy and paste here the exact command (tf_tfl_translate command-line utility)
tf_tfl_translate  --tf-input-arrays=input_1 --tf-input-shapes=1,784,1 --tf-output-arrays=dense/BiasAdd --print-function-result-mapping -o=$HOME/Desktop/converted.tflite --emit-builtin-tflite-ops ~/smnist.pb
```
**The output from the converter invocation**

```
# Copy and paste the output here. (tf_tfl_translate output)
'main' inputs:
	name: 'input_1' buffer: 0
'main' outputs:
	name: 'dense/BiasAdd' buffer: 271 loc(""dense/BiasAdd"")
```

**Also, please include a link to the saved model or GraphDef**
[smnist.zip](https://github.com/tensorflow/tensorflow/files/4492741/smnist.zip) contains the model in both .h5 and .pb format, and the converted Flatbuffers.


**Failure details**
I'm converting the Keras-TCN model from https://github.com/philipperemy/keras-tcn to TF Lite.

Method 1:
I convert the Keras model (.h5) to a TF Lite Flatbuffer via the Python API as above. The conversion is successful, inference with the model has the correct accuracy, but I want to get rid of the SpaceToBatchNd and BatchToSpaceNd nodes resulting from the Conv1D ops present in the model. Commit f54bb6f5578b931d79884302768996ba1073f685 claims to do so solving issue #29509. However this does not happen to be so in my converted model, which I attach.

Method 2:
To investigate further, I built the tf_tfl_translate tool from source and invoked it with the command above on a GraphDef (.pb) of the model. Conversions happen to be successful but again the STB and BTS ops are still present in the TF Lite Flatbuffer. The sequence of ops in the GraphDef seems to comply to the sequences specified in https://github.com/tensorflow/tensorflow/blob/master/tensorflow/compiler/mlir/lite/transforms/dilated_conv.h. 
However, this time the ExpandDims and Squeeze ops are correctly converted to Reshape operations, as specified here https://github.com/tensorflow/tensorflow/blob/master/tensorflow/compiler/mlir/lite/transforms/optimize_patterns.td, whereas this would not happen with the method above, and although I would like to avoid this being done on my final Flatbuffer.

"
38637,Why there are serveral topkv2 ops,"<em>Please make sure that this is an issue related to performance of TensorFlow.
As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:performance_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):ubuntu18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):binary
- TensorFlow version (use command below):tensorflow2.1
- Python version:3.6.8
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:10.1
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
![Screenshot from 2020-04-17 18-27-35](https://user-images.githubusercontent.com/17592563/79559932-27ab0780-80d9-11ea-9472-f89f98a04ea8.png)
**Describe the expected behavior**
Only one topkV2
**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

https://github.com/google/automl/blob/028789605f1f140b00c045f77be2c4e13638d17c/efficientdet/det_model_fn.py#L313

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

[trace.json](https://drive.google.com/open?id=1lPiHuSDjdcBL9IoQg3kRHE3Ff2toyVwB)"
38636,ImportError: DLL load failed,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- TensorFlow installed from (source or binary): pip install tensorflow
- TensorFlow version: 2.1
- Python version: 3.7.7 64-bit
- Installed using virtualenv? pip? conda?: no
- CUDA/cuDNN version: 10.1/  v7.6.5 (November 5th, 2019), for CUDA 10.1
- GPU model and memory: GTX 1070 Nividia 8GB
- GPU driver 445.75
- CPU Intel Celeron G3900 2,8 GHz

**Describe the problem**
while trying import tensorflow i got such error below. i used Visual Studio Code, i have tried different versions of tensorflow 2.0, 2.1 ang GPU version - still this problem :(

I have installed newest VC_redist.x64, i have also in my system env variables path to:
C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.1\bin
C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.1\libnvvp
C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.1\extras\CUPTI\lib64
C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.1\include
C:\tools\cuda\bin
C:\tools\cuda\include
C:\tools\cuda\lib\x64

I have tried every solution which a found on Github but nothing works form me, and please help me with it.

**Provide the exact sequence of commands / steps that you executed before running into the problem**
import tensorflow 

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

Traceback (most recent call last):
  File ""C:\Users\Dominik\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\Dominik\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\Dominik\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\Dominik\AppData\Local\Programs\Python\Python37\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\Dominik\AppData\Local\Programs\Python\Python37\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: Procedura inicjowania biblioteki do\u0142\u0105czanej dynamicznie (DLL) nie powiod\u0142a si\u0119.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""c:\Users\Dominik\Documents\Python Scripts\NLP\06-Deep-Learning\import tensorflow.py"", line 1, in <module>
    import tensorflow
  File ""C:\Users\Dominik\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow\__init__.py"", line 101, in <module>
    from tensorflow_core import *
  File ""C:\Users\Dominik\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow_core\__init__.py"", line 40, in <module>
    from tensorflow.python.tools import module_util as _module_util
  File ""C:\Users\Dominik\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow\__init__.py"", line 50, in __getattr__
    module = self._load()
  File ""C:\Users\Dominik\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow\__init__.py"", line 44, in _load
    module = _importlib.import_module(self.__name__)
  File ""C:\Users\Dominik\AppData\Local\Programs\Python\Python37\lib\importlib\__init__.py"", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""C:\Users\Dominik\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow_core\python\__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\Users\Dominik\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 74, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""C:\Users\Dominik\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\Dominik\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\Dominik\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\Dominik\AppData\Local\Programs\Python\Python37\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\Dominik\AppData\Local\Programs\Python\Python37\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: Procedura inicjowania biblioteki do\u0142\u0105czanej dynamicznie (DLL) nie powiod\u0142a si\u0119.


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/errors

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.
"
38635,How to Save Model with TF2.x Keras Multiworker Distributed Training?,"**Description:**

I've created a  `Keras` model, and trained it with `multiworker distributed strategy`.

Every worker uses the same python scripts for training. I uses `model.save` function for model saving with the same `hdfs path`.

After training, every worker would try to save model to the `path`, and it will cause race condition, because all of them want to handle the same `variables files`.

**Code snippets**

```python
tf_config = {
    ""task"": {
        ""index"": 0,
        ""type"": ""worker""
    },
    ""cluster"": {
        ""worker"": [""localhost:21834"", ""localhost:27271""],
    }
}
os.environ[""TF_CONFIG""] = json.dumps(tf_config)
print(json.loads(os.environ[""TF_CONFIG""]))


def main(argv):
    del argv  # Unused
    BATCH_SIZE = 100
    SAMPLE_SIZE = 50000
    strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()
    with strategy.scope():
        model = tf.keras.Sequential([
            layers.Dense(64, activation='relu'),
            layers.Dense(32, activation='relu'),
            layers.Dense(1, activation='sigmoid')
        ])
        model.compile(optimizer=tf.keras.optimizers.Adam(),
                      loss=tf.keras.losses.BinaryCrossentropy(),
                      metrics=[tf.keras.metrics.AUC()])
    log_dir = FLAGS.logs
    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir,
                                                          histogram_freq=1,
                                                          update_freq='epoch')
    train_dataset = tf.data.Dataset.from_tensor_slices(
        (np.random.randint(1000, size=(SAMPLE_SIZE, 31)),
         np.random.randint(2, size=(SAMPLE_SIZE, 1))))
    train_dataset = train_dataset.batch(BATCH_SIZE)
    validation_dataset = tf.data.Dataset.from_tensor_slices(
        (np.random.randint(1000, size=(SAMPLE_SIZE, 31)),
         np.random.randint(2, size=(SAMPLE_SIZE, 1))))
    validation_dataset = validation_dataset.batch(BATCH_SIZE)
    options = tf.data.Options()
    options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.DATA
    train_dataset = train_dataset.with_options(options)
    validation_dataset = validation_dataset.with_options(options)
    model.fit(train_dataset,
              epochs=5,
              steps_per_epoch=10,
              validation_data=validation_dataset,
              validation_steps=5)
    model_dir = FLAGS.logs + '/models'
    model.save(model_dir)

if __name__ == '__main__':
    app.run(main)
```

**Question:**

In my opinion, the save should only be done by the `chief worker` not all of them. So

1. Is there some problem with my `save` code?
2. Should I change the path for different workers? If so, which model is the final model for serving?
3. Is there a way that chief worker saves model only?

Thanks ~
"
38633,"How does the ""tensorflow/compiler/mlir/tensorflow/ir/tf_generated_ops.td"" file generated?","How does the ""tensorflow/compiler/mlir/tensorflow/ir/tf_generated_ops.td"" file generated?"
38632,Some bugs of CategoricalCrossentropy and SparseCategoricalCrossentropy in tf.keras.losses ,"It seems that there are some bugs of CategoricalCrossentropy and SparseCategoricalCrossentropy. The codes below will go wrong in tensorflow with version 2.2.0rc2.
1. Error of no gradients provided with categorical crossentropy .
```
import numpy as np
import tensorflow as tf
import tensorflow.keras as keras
import tensorflow.keras.backend as K
from tensorflow.keras.layers import *

i = Input([], dtype='int32')
o = Dense(2, activation='softmax')(i[:, None])
l = tf.keras.losses.categorical_crossentropy(K.one_hot(i, 2), o)
m = keras.Model(inputs=i, outputs=o)
m.add_loss(l)
m.compile(optimizer='adam')
m.fit(np.ones([1]))
```
and the same with the code below
```
import numpy as np
import tensorflow as tf
import tensorflow.keras as keras
import tensorflow.keras.backend as K
from tensorflow.keras.layers import *

i = Input([], dtype='int32')
o = Dense(2, activation='softmax')(i[:, None])
l = tf.keras.losses.CategoricalCrossentropy()(K.one_hot(i, 2), o)
m = keras.Model(inputs=i, outputs=o)
m.add_loss(l)
m.compile(optimizer='adam')
m.fit(np.ones([1]))
```
2. Showing error that 'Sparse ops are not supported with functional models with built-in layer wrapping...' with sparse categorical crossentropy.
```
import numpy as np
import tensorflow as tf
import tensorflow.keras as keras
import tensorflow.keras.backend as K
from tensorflow.keras.layers import *

i = Input([], dtype='int32')
o = Dense(2, activation='softmax')(i[:, None])
l = tf.keras.losses.sparse_categorical_crossentropy(i, o)
m = keras.Model(inputs=i, outputs=o)
m.add_loss(l)
m.compile(optimizer='adam')
m.fit(np.ones([1]))
```
as well as the one below
```
import numpy as np
import tensorflow as tf
import tensorflow.keras as keras
import tensorflow.keras.backend as K
from tensorflow.keras.layers import *

i = Input([], dtype='int32')
o = Dense(2, activation='softmax')(i[:, None])
l = tf.keras.losses.SparseCategoricalCrossentropy()(i, o)
m = keras.Model(inputs=i, outputs=o)
m.add_loss(l)
m.compile(optimizer='adam')
m.fit(np.ones([1]))
```
"
38631,ValueError: No gradients provided for any variable,"I just don't see the problem here, so I created two simple examples. One simple Feed Forwad network to solve XOR and one simple LSTM for a word-completion task. The XOR works as it should but the word-completion keeps throwing the `ValueError` and it's not clear _why_.


**System information**
- Have I written custom code: Yes
- OS Platform and Distribution: Ubuntu 18.04
- TensorFlow installed from: pip
- TensorFlow version: tf-nightly==2.2.0.dev20200410
- Python version: 3.7

**Describe the current behavior**

Trying to `fit()` a model raises `ValueError: No gradients provided for any variable` for no apparent reason.

**Describe the expected behavior**

It should work as shown in the XOR example.

**Standalone code to reproduce the issue**

## Not working: Word Completion

I created an executable [gist here](https://gist.github.com/stefan-falk/42ef89c6636fd9f91fc471584659512f).

The exception I am getting:

```none
ValueError: No gradients provided for any variable: ['embedding/embeddings:0', 'rnn/gru_cell/kernel:0', 'rnn/gru_cell/recurrent_kernel:0', 'rnn/gru_cell/bias:0', 'rnn_1/gru_cell_1/kernel:0', 'rnn_1/gru_cell_1/recurrent_kernel:0', 'rnn_1/gru_cell_1/bias:0', 'time_distributed/kernel:0', 'time_distributed/bias:0', 'outputs/kernel:0', 'outputs/bias:0'].
````


<details>
  <summary>Click to show code</summary>

```python
import random
from functools import partial

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow_datasets.core.features.text import SubwordTextEncoder

EOS = '<eos>'
PAD = '<pad>'

RESERVED_TOKENS = [EOS, PAD]
EOS_ID = RESERVED_TOKENS.index(EOS)
PAD_ID = RESERVED_TOKENS.index(PAD)

dictionary = [
    'verstehen',
    'verstanden',
    'vergessen',
    'verlegen',
    'verlernen',
    'vertun',
    'vertan',
    'verloren',
    'verlieren',
    'verlassen',
    'verhandeln',
]

dictionary = [word.lower() for word in dictionary]


def get_model(params) -> keras.models.Model:

    inputs = layers.Input((None,), dtype=tf.int64, name='inputs')

    x = inputs

    vocab_size = params['vocab_size']
    hidden_size = params['hidden_size']
    max_input_length = params['max_input_length']
    max_target_length = params['max_target_length']

    x = layers.Embedding(vocab_size, hidden_size, input_length=max_input_length)(x)

    # Encoder
    x = layers.RNN(layers.GRUCell(hidden_size))(x)
    x = layers.RepeatVector(max_target_length)(x)

    # Deoder
    x = layers.RNN(layers.GRUCell(hidden_size), return_sequences=True)(x)
    x = layers.TimeDistributed(layers.Dense(hidden_size, activation='relu'))(x)

    # Outputs
    output_dense_layer = layers.Dense(vocab_size, activation='softmax')
    outputs = layers.TimeDistributed(output_dense_layer, name='outputs')(x)

    return keras.models.Model(inputs=[inputs], outputs=[outputs])


def sample_generator(text_encoder: SubwordTextEncoder, max_sample: int = None):
    count = 0

    while True:
        random.shuffle(dictionary)

        for word in dictionary:

            for i in range(1, len(word)):

                inputs = word[:i]
                targets = word

                example = dict(
                    inputs=text_encoder.encode(inputs) + [EOS_ID],
                    targets=text_encoder.encode(targets) + [EOS_ID],
                )
                count += 1

                yield example

                if max_sample is not None and count >= max_sample:
                    print('Reached max_samples (%d)' % max_sample)
                    return


def make_dataset(generator_fn, params, training):

    dataset = tf.data.Dataset.from_generator(
        generator_fn,
        output_types={
            'inputs': tf.int64,
            'targets': tf.int64,
        }
    )

    if training:
        dataset = dataset.shuffle(100)

    dataset = dataset.padded_batch(
        params['batch_size'],
        padded_shapes={
            'inputs': (None,),
            'targets': (None,)
        },
    )

    if training:
        dataset = dataset.map(lambda example: to_train_example(example, params=params)).repeat()

    return dataset


def to_train_example(example: dict, params: dict):
    # Make sure targets are one-hot encoded
    example['targets'] = tf.one_hot(example['targets'], depth=params['vocab_size'])
    return example


def main():

    text_encoder = SubwordTextEncoder.build_from_corpus(
        iter(dictionary),
        target_vocab_size=1000,
        max_subword_length=6,
        reserved_tokens=RESERVED_TOKENS
    )

    generator_fn = partial(sample_generator, text_encoder=text_encoder, max_sample=10)

    params = dict(
        batch_size=20,
        vocab_size=text_encoder.vocab_size,
        hidden_size=32,
        max_input_length=30,
        max_target_length=30,
        enable_metrics_in_training=True
    )

    model = get_model(params)

    model.compile(
        optimizer=keras.optimizers.Adam(0.001),
        loss='categorical_crossentropy',
    )

    assert len(model.trainable_variables), 'There are no trainable_variables'
    model.summary()

    train_dataset = make_dataset(generator_fn, params, training=True)

    model.fit(
        train_dataset,
        epochs=5,
        steps_per_epoch=100,
    )


if __name__ == '__main__':
    main()
```
</details>

## Working: XOR

This example works as it should. Here I am subclassing `keras.models.Model`. The reason why I am using the functional API above is s.t. I can debug more easily.

<details>
  <summary>Click to show code</summary>

```python
import tensorflow as tf
from tensorflow import keras


def xor_data():
    inputs = [[0, 0], [0, 1], [1, 0], [1, 1]]
    targets = [[0], [1], [1], [0]]
    while True:
        for x, y in zip(inputs, targets):
            yield x, y


class FeedForwardNetwork(keras.models.Model):

    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self._layers = [
            keras.layers.Dense(4, activation='sigmoid'),
            keras.layers.Dense(4, activation='sigmoid'),
            keras.layers.Dense(1, activation='sigmoid')
        ]

    def call(self, x, **kwargs):
        for layer in self._layers:
            x = layer(x)
        return x


class XorCallback(keras.callbacks.Callback):

    def on_epoch_end(self, epoch, logs=None):
        all_data = [[0, 0], [0, 1], [1, 0], [1, 1]]
        y = self.model.predict(all_data)

        print('\nPredictions: ')
        print((y > 0.5) * 1)


def main():

    dataset = tf.data.Dataset.from_generator(xor_data, output_types=(tf.int64, tf.int64)).batch(10).shuffle(100)

    train_dataset = dataset.repeat()
    dev_dataset = dataset

    for batch in dataset:
        print(batch)
        break

    model_internal = FeedForwardNetwork()

    inputs = keras.layers.Input(shape=(2,))
    logits = model_internal(inputs)

    model = keras.models.Model(inputs=[inputs], outputs=[logits])

    model.compile(
        optimizer=keras.optimizers.Adam(0.0001),
        loss='mse',
        metrics=['mse']
    )

    model.summary()

    model_fp = '/tmp/xor/model'

    callbacks = [
        keras.callbacks.ModelCheckpoint(
          model_fp,
          save_best_only=True,
          save_weights_only=False
        ),
        XorCallback()
    ]

    model.fit(
        train_dataset,
        epochs=5,
        steps_per_epoch=5000,
        validation_data=dev_dataset,
        validation_steps=100,
        callbacks=callbacks
    )


if __name__ == '__main__':
    main()
```
</details>

[stackoverflow](https://stackoverflow.com/questions/61249708/valueerror-no-gradients-provided-for-any-variable-tensorflow-2-0-keras)

### Potentially related

- https://github.com/tensorflow/tensorflow/issues/1511
- https://github.com/tensorflow/tensorflow/issues/27949
"
38629,Does not have sufficient slices for partitioned tensor,"https://stackoverflow.com/questions/56930685/pywrap-tensorflow-checkpoint-reader-fails-for-ftrl-states-of-partitioned-variabl
i meet the same problem, can anyone solve it? thanks"
38628,Autograph unrolling for loop,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows, Linux on cluster
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): v2.1.0-rc2-17-ge5bf8de410 2.1.0
- Python version: 3.7
- CUDA/cuDNN version: reproducible on CPU or GPU
- GPU model and memory:

**Describe the current behavior**

In a function decorated by `@tf.function`, I use a `for` loop to run an RNN step-by-step for beam search. There is a reduced example in the gist below.

Executing the function for the first time takes a long time (10 seconds in this minimal example, 300 seconds for my true model) and creates a very large graph (traced with `tf.summary.trace_on`; 3.5MB in this minimal example, 30-50MB for my true model, and more or less crashing Tensorboard when I try to open it.) 

If I write the same loop as a `tf.while_loop`, first execution is nearly instant, and the resulting graph is healthy (180KB minimal example, 500KB for my true model.) `back_prop = True` or `False` makes almost no difference.

Later iterations perform more or less identically for both.

It looks like instead of converting the `for` loop to `tf.while_loop`, AutoGraph unrolls it completely.

Note that using `unroll=True` in the RNN (since it's only one step anyway) slashes AutoGraph tracing and graph size in half, perhaps not so surprisingly. 

**Describe the expected behavior**
I would expect AutoGraph to interpret the `for` loop as a `tf.while_loop`.

I understand there is always first execution overhead, but it seems very unnecessary here.

**Standalone code to reproduce the issue**
https://colab.research.google.com/drive/1aALb-2wQoHIomJ7S5sLwJYmcciX5kpoM
https://gist.github.com/meowcat/8b3b4b9c66264e685e339ff4e43af882

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
38627,feature_column._is_v2_column always return true,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): 
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): source 
- TensorFlow version (use command below): 2.1
- Python version: 3.6.8
- Bazel version (if compiling from source): bazel 2.0
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

**Describe the current behavior**
Upgrade me code from TF1.14 to TF2.0, I got the unexpected error:
```
  File ""/use/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/canned/linear.py"", line 432, in linear_logit_fn
    variables.remove(bias)
ValueError: list.remove(x): x not in list
```

**Describe the expected behavior**
It should works and train successfully.

**Standalone code to reproduce the issue**
```
import collections
import tensorflow.compat.v1 as tf

tf.disable_v2_behavior()
tf.disable_eager_execution()

INPUT = [""name"", ""id"", ""study""]
LABEL = [""label""]
ALL = LABEL + INPUT

def input_fn():
    def parse_data(value):
        input_defaults = [["" ""] for i in range(1, 4)]
        label_defaults = [['0']]
        all_columns = collections.OrderedDict(zip(ALL, tf.io.decode_csv(value, record_defaults= label_defaults + input_defaults)))
        labels = all_columns.pop(LABEL[0])
        features = all_columns
        return features, labels
    # Extract lines from input files using the Dataset API.
    dataset = tf.data.Dataset.from_tensor_slices([['a', 'b', 'c', '0'], ['b', 'b', 'c', '1']])
    dataset = dataset.batch(1)
    dataset = dataset.map(parse_data)
    return dataset

def train():
    input_column = []
    for name in INPUT:
        input_column.append(tf.feature_column.categorical_column_with_hash_bucket(
            name, hash_bucket_size=3))
    model = tf.estimator.LinearClassifier(feature_columns=input_column)
    model.train(input_fn=lambda: input_fn())

if __name__ == ""__main__"":
    train()
```

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
38626,Add Post-training integer quantization converter for depth_to_space,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04
- TensorFlow installed from (source or binary): binary
- TensorFlow version (or github SHA if from source): 1.15.2 / 2.1


**Command used to run the converter or code if you’re using the Python API**
If possible, please share a link to Colab/Jupyter/any notebook.

```
    model_name = args.model_name + ""_integer_quant"" +""_%d"" %(args.input_width) + "".tflite""
    converter.representative_dataset = representative_data_gen
    converter.optimizations = [tf.lite.Optimize.DEFAULT]
    converter.inference_input_type = tf.uint8
    converter.inference_output_type = tf.uint8
    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]
    
    tflite_model_quant = converter.convert()
    tflite_model_quant_file = tflite_models_dir/model_name
    tflite_model_quant_file.write_bytes(tflite_model_quant)
    print('Convert using full integer quantization DONE !!!')
```

**The output from the converter invocation**

```
Note the output min/max is different from the input min/max for op RESIZE_BILINEAR at index 29 in subgraph 0. This is legal but should happens rarely.
Note the output min/max is different from the input min/max for op RESIZE_BILINEAR at index 68 in subgraph 0. This is legal but should happens rarely.
Traceback (most recent call last):
  File ""gen_quan_tflite.py"", line 122, in <module>
    main()    
  File ""gen_quan_tflite.py"", line 116, in main
    tflite_model_quant = converter.convert()
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/lite/python/lite.py"", line 993, in convert
    inference_output_type)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/lite/python/lite.py"", line 239, in _calibrate_quantize_model
    inference_output_type, allow_float)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/lite/python/optimize/calibrator.py"", line 78, in calibrate_and_quantize
    np.dtype(output_type.as_numpy_dtype()).num, allow_float)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/lite/python/optimize/tensorflow_lite_wrap_calibration_wrapper.py"", line 115, in QuantizeModel
    return _tensorflow_lite_wrap_calibration_wrapper.CalibrationWrapper_QuantizeModel(self, input_py_type, output_py_type, allow_float)
RuntimeError: Quantization not yet supported for op: DEPTH_TO_SPACE
```
_RuntimeError: Quantization not yet supported for op: DEPTH_TO_SPACE_


**Also, please include a link to the saved model or GraphDef**

```
# Put link here or attach to the issue.
```

**Failure details**
If the conversion is successful, but the generated model is wrong,
state what is wrong:
- Producing wrong results and/or decrease in accuracy
- Producing correct results, but the model is slower than expected (model generated from old converter)


**Any other info / logs**

Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
38625,ImageDataGenerator complains about lack of stratification but I'm doing regression,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): `yes` but it's basic
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): `macOS 10.15.4`
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): `binary`
- TensorFlow version (use command below): `v2.1.0-rc2-17-ge5bf8de410 2.1.0`
- Python version: `3.7.7`
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A

**Describe the current behavior**

When using `ImageDataGenerator.flow()` with a `validation_split` argument, a `ValueError` exception is raised that states:

> Training and validation subsets have different number of classes after the split. If your numpy arrays are sorted by the label, you might want to shuffle them.

However, my labels data is continuous (floats) and I'm doing regression.

**Describe the expected behavior**

This code should not throw. At the very least, it should be a warning and I should be able to silence it.

**Standalone code to reproduce the issue**

```python
y = 500 * numpy.random.rand(200)  # labels are float values
datagen = ImageDataGenerator(validation_split=0.2)
gen_train = datagen.flow(
    x, y, shuffle=True, subset='training'
)
```

"
38624,tf.keras h5 file to pb xx is not in graph,"my tensorflow version is 2.1, i want from tf.keras .h5 model transform to pb file. but i get follow  issues. 


```

def freeze_session(session, keep_var_names=None, output_names=None, clear_devices=True):

    graph = session.graph
    with graph.as_default():
        freeze_var_names = list(set(v.op.name for v in tf.compat.v1.global_variables()).difference(keep_var_names or []))
        output_names = output_names or []
        output_names += [v.op.name for v in tf.compat.v1.global_variables()]
        # Graph -> GraphDef ProtoBuf
        input_graph_def = graph.as_graph_def()
        if clear_devices:
            for node in input_graph_def.node:
                node.device = """"
        frozen_graph = tf.compat.v1.graph_util.convert_variables_to_constants(session, input_graph_def,
                                                      output_names, freeze_var_names)
        return frozen_graph
```

```
frozen_graph = freeze_session(tf.compat.v1.keras.backend.get_session(),
                              output_names=[out.op.name for out in model.outputs])

```
AssertionError                            Traceback (most recent call last)
<ipython-input-10-ec0ab52adbd4> in <module>
      3 
      4 frozen_graph = freeze_session(tf.compat.v1.keras.backend.get_session(),
----> 5                               output_names=[out.op.name for out in model.outputs])

<ipython-input-8-b5cce8f2cb8f> in freeze_session(session, keep_var_names, output_names, clear_devices)
     12                 node.device = """"
     13         frozen_graph = tf.compat.v1.graph_util.convert_variables_to_constants(session, input_graph_def,
---> 14                                                       output_names, freeze_var_names)
     15         return frozen_graph

~/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/util/deprecation.py in new_func(*args, **kwargs)
    322               'in a future version' if date is None else ('after %s' % date),
    323               instructions)
--> 324       return func(*args, **kwargs)
    325     return tf_decorator.make_decorator(
    326         func, new_func, 'deprecated',

~/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/framework/graph_util_impl.py in convert_variables_to_constants(sess, input_graph_def, output_node_names, variable_names_whitelist, variable_names_blacklist)
    275   # This graph only includes the nodes needed to evaluate the output nodes, and
    276   # removes unneeded nodes like those involved in saving and assignment.
--> 277   inference_graph = extract_sub_graph(input_graph_def, output_node_names)
    278 
    279   # Identify the ops in the graph.

~/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/util/deprecation.py in new_func(*args, **kwargs)
    322               'in a future version' if date is None else ('after %s' % date),
    323               instructions)
--> 324       return func(*args, **kwargs)
    325     return tf_decorator.make_decorator(
    326         func, new_func, 'deprecated',

~/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/framework/graph_util_impl.py in extract_sub_graph(graph_def, dest_nodes)
    195   name_to_input_name, name_to_node, name_to_seq_num = _extract_graph_summary(
    196       graph_def)
--> 197   _assert_nodes_are_present(name_to_node, dest_nodes)
    198 
    199   nodes_to_keep = _bfs_for_reachable_nodes(dest_nodes, name_to_input_name)

~/anaconda3/envs/tf2/lib/python3.6/site-packages/tensorflow_core/python/framework/graph_util_impl.py in _assert_nodes_are_present(name_to_node, nodes)
    150   """"""Assert that nodes are present in the graph.""""""
    151   for d in nodes:
--> 152     assert d in name_to_node, ""%s is not in graph"" % d
    153 
    154 

AssertionError: dense_5/Identity is not in graph
"
38623,Tensor eats up all my memory in gpu,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below):
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**

**Describe the expected behavior**

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
38622,tf.custom_gradient expects an additional output when declaring temp Variable(),"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Fedora 29
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): v2.1.0-rc2-17-ge5bf8de
- Python version: Python 3.7.6
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A

**Describe the current behavior**
Thanks in advance for your time.

I'm attempting to implement a custom loss function. It requires storage of a temporary variable, and custom gradient. For many reasons, numerical stability and flexibility, I'd like to just implement the gradient by hand. The model here is just a `foo/bar` model.

It seems it’s related to this issue: https://github.com/tensorflow/tensorflow/issues/31945

I'm also happy to open a PR.

However, I haven't been able to get the patch suggested to work, because I can't build from source via some `Bazel` issue.

Any references are appreciated. 

I've also tried to implement the loss function as a subclass of type `Loss`, but was unsuccessful.

Thanks for all of the hard work that goes into this project.

**Describe the expected behavior**

Run model via EagerExecution. When using `GradientTape()` to evaluate gradients, I'm getting error: `ValueError: not enough values to unpack (expected 2, got 1)`. The loss function is only a function of one input, and thus only has one partial derivative, wrt to that input.


**Standalone code to reproduce the issue**
```
import tensorflow as tf
from tensorflow.keras.layers import Layer
import numpy as np

class Linear(Layer):
  """"""y = w.x + b""""""

  def __init__(self, units=32):
      super(Linear, self).__init__()
      self.units = units

  def build(self, input_shape):
      self.w = self.add_weight(shape=(input_shape[-1], self.units),
                               initializer='random_normal',
                               trainable=True)
      self.b = self.add_weight(shape=(self.units,),
                               initializer='random_normal',
                               trainable=True)

  def call(self, inputs):
      return tf.matmul(inputs, self.w) + self.b


@tf.custom_gradient
def loss_fn(x):
    r = tf.Variable(tf.zeros([100]), dtype = tf.float32)
    ## create r
    def grad(df, variables = None):
        return [df * 2 * tf.reduce_sum(r)]
    
    return tf.pow(tf.norm(r), 2), grad

M = 100
m = np.arange(0, M)
x = [[m / M]]

linear_layer = Linear(10)

optimizer = tf.keras.optimizers.SGD(learning_rate=1e-3)

dataset = tf.data.Dataset.from_tensor_slices(x)

for step, x in enumerate(dataset):
    
    with tf.GradientTape() as tape:
        logits = linear_layer(x)
        loss = loss_fn(x)

    gradients = tape.gradient(loss, linear_layer.trainable_weights)
    optimizer.apply_gradients(zip(gradients, linear_layer.trainable_weights))
```
"
38621,TopKV2 comp,"<em>Please make sure that this is an issue related to performance of TensorFlow.
As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:performance_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below):
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
https://github.com/tensorflow/tensorflow/blob/ddabed4285d27785213322d05dcbe0ebc392849d/tensorflow/core/kernels/topk_op.cc#L183
I found TopK use stable comp when I set sorted=False.
Is it will faster if use unstable comp?
**Describe the expected behavior**

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
38620,Mask missing in restored Keras SavedModel,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): **Yes**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **macOS 10.15.4** and **Linux Ubuntu 18.04**
- TensorFlow installed from (source or binary): **binary**
- TensorFlow version (use command below): **v2.1.0-rc2-17-ge5bf8de410 2.1.0** and **v2.2.0-rc3**
- Python version: **3.6.0**
- CUDA/cuDNN version: **N/A**
- GPU model and memory: **N/A**


**Describe the current behavior**

Calling the model directly returns correct results:
```
array([[1, 2], [3, 0]], dtype=int32)
```
But if we save the model to a SavedModel and restore it, the new model fails to pass the mask from the first layer to the second layer, resulting in:
```
ValueError: Could not find matching function to call loaded from the SavedModel.
  Positional arguments (2 total):
    * Tensor(""inputs:0"", shape=(None, 2), dtype=int32)
    * None
  Keyword arguments: {}

Expected these arguments to match one of the following 1 option(s):

Option 1:
  Positional arguments (2 total):
    * TensorSpec(shape=(None, 2), dtype=tf.int32, name='inputs')
    * TensorSpec(shape=(None, 2), dtype=tf.bool, name='mask')
  Keyword arguments: {}
```

I've updated TensorFlow to v2.2.0-rc3 and nightly, the issue is still reproducible.

**Describe the expected behavior**

The model restored from the SavedModel should behave exactly the same as the original model: the first layer passing mask to the second layer.

**Standalone code to reproduce the issue**

Colab notebook:
[https://colab.research.google.com/drive/1VlL9on7myJIX9xP2efIwvgESmWGafdfx](https://colab.research.google.com/drive/1VlL9on7myJIX9xP2efIwvgESmWGafdfx)

Plain text:
```python
import tensorflow as tf


class MyMasking(tf.keras.layers.Layer):

    def call(self, inputs):
        return inputs

    def compute_mask(self, inputs, mask=None):
        mask = tf.not_equal(inputs, 0)
        return mask


class MyLayer(tf.keras.layers.Layer):

    def call(self, inputs, mask=None):
        return inputs


samples = tf.constant([[1, 2], [3, 0]], dtype=tf.int32)
model = tf.keras.Sequential([MyMasking(), MyLayer()])
tf.print(model.predict(samples))

model.save('./temp_model', save_format='tf')

new_model = tf.keras.models.load_model('./temp_model')
tf.print(new_model.predict(samples))
```"
38619,"InvalidArgumentError: 2 root error(s) found.   (0) Invalid argument:  indices[39,107] = 85525 is not in [0, 85525) 	 [[node model_5/embedding_8/embedding_lookup (defined at <ipython-input-203-ee38e6490bb7>:2) ]] 	 [[model_5/embedding_8/embedding_lookup/_14]]   (1) Invalid argument:  indices[39,107] = 85525 is not in [0, 85525)  in  Colab . ","<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version:
- Python version:
- Installed using virtualenv? pip? conda?:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:



**Describe the problem**

InvalidArgumentError: 2 root error(s) found.
  (0) Invalid argument:  indices[39,107] = 85525 is not in [0, 85525)
	 [[node model_5/embedding_8/embedding_lookup (defined at <ipython-input-203-ee38e6490bb7>:2) ]]
	 [[model_5/embedding_8/embedding_lookup/_14]]
  (1) Invalid argument:  indices[39,107] = 85525 is not in [0, 85525)

**Provide the exact sequence of commands / steps that you executed before running into the problem**
**This is the Error message I got,** 
`nvalidArgumentError                      Traceback (most recent call last)
<ipython-input-203-ee38e6490bb7> in <module>()
      1 model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics= ['accuracy'])
----> 2 a = model.fit( train_padded, y_train ,epochs=15, validation_data=(  test_padded  , y_test  ) , callbacks = learningrate_callback,   batch_size=128   )

8 frames
/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)
     58     ctx.ensure_initialized()
     59     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
---> 60                                         inputs, attrs, num_outputs)
     61   except core._NotOkStatusException as e:
     62     if name is not None:

InvalidArgumentError: 2 root error(s) found.
  (0) Invalid argument:  indices[39,107] = 85525 is not in [0, 85525)
	 [[node model_5/embedding_8/embedding_lookup (defined at <ipython-input-203-ee38e6490bb7>:2) ]]
	 [[model_5/embedding_8/embedding_lookup/_14]]
  (1) Invalid argument:  indices[39,107] = 85525 is not in [0, 85525)
	 [[node model_5/embedding_8/embedding_lookup (defined at <ipython-input-203-ee38e6490bb7>:2) ]]
0 successful operations.
0 derived errors ignored. [Op:__inference_train_function_10924]

Errors may have originated from an input operation.
Input Source operations connected to node model_5/embedding_8/embedding_lookup:
 model_5/embedding_8/embedding_lookup/10486 (defined at /usr/lib/python3.6/contextlib.py:81)

Input Source operations connected to node model_5/embedding_8/embedding_lookup:
 model_5/embedding_8/embedding_lookup/10486 (defined at /usr/lib/python3.6/contextlib.py:81)

Function call stack:
train_function -> train_function`

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.


**Here's a part of the source code ,** 
`
input_tensor = tf.keras.Input(  shape = ( maxlength , )  )

embedd = tf.keras.layers.Embedding( input_dim = vocab     , output_dim = 300 , embedding_initalizer=  tf.keras.initializers.Constant(embedding_matrix) ,  input_length = maxlength  ) (input_tensor)

conv1d_1 = tf.keras.layers.Conv1D (  filters = 16 , kernel_size = 3 , strides = 1 , padding = 'valid'  , activation = 'relu', kernel_initializer = 'he_uniform' ) (embedd)
conv1d_2 =tf.keras.layers.Conv1D (  filters = 16 , kernel_size = 3 , strides = 1 , padding = 'valid'  , activation = 'relu', kernel_initializer = 'he_uniform' ) (embedd)
conv1d_3 = tf.keras.layers.Conv1D (  filters = 16 , kernel_size = 3 , strides = 1 , padding = 'valid'  , activation = 'relu', kernel_initializer = 'he_uniform' ) (embedd)
concat_1 = tf.keras.layers.concatenate(   [conv1d_1, conv1d_2 , conv1d_3 ] ) 
`

here embedding_matrix has a shape of (85525, 300) (unknown token included while tokenizing)
I'm trying to replicate the  Example at https://keras.io/examples/pretrained_word_embeddings/
with a different structure.
"
38618,Keras ProgbarLogger: OverflowError: cannot convert float infinity to integer,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Colab

**Describe the current behavior**

It seems that if, at some time accuracy is equal 0 this code will error and stop training.

With TF 2.2-rc3 the following piece of code returns an error:

```
import tensorflow as tf
data = tf.random.uniform(shape=(1000, 784),  maxval=15)
labels = tf.random.uniform(shape=(1000,10), maxval = 1, dtype=tf.int32)
model = tf.keras.Sequential([
  tf.keras.layers.Dense(32, activation = ""relu""),
  tf.keras.layers.Dense(10, activation = ""softmax"")
])
model.compile(loss = ""binary_crossentropy"", optimizer=""sgd"", metrics=[""accuracy""])
model.fit(data, labels, callbacks = [tf.keras.callbacks.ProgbarLogger()])
```

> OverflowError: cannot convert float infinity to integer

**Describe the expected behavior**

With current 2.1, no error is returned:

```
import tensorflow as tf
data = tf.random.uniform(shape=(1000, 784),  maxval=15)
labels = tf.random.uniform(shape=(1000,10), maxval = 1, dtype=tf.int32)
model = tf.keras.Sequential([
  tf.keras.layers.Dense(32, activation = ""relu""),
  tf.keras.layers.Dense(10, activation = ""softmax"")
])
model.compile(loss = ""binary_crossentropy"", optimizer=""sgd"", metrics=[""accuracy""])
model.fit(data, labels, callbacks = [tf.keras.callbacks.ProgbarLogger()])
```

**Standalone code to reproduce the issue**

See colab here for 2.2-rc3 version: https://colab.research.google.com/drive/1Cyu0pBYCYtoxzUs2JPc-oSRr_WG9PNQt

And here with 2.1 working version:

https://colab.research.google.com/drive/1Aq7vhnt91C8MbNP35RUrhszR9xomn-hM
"
38617,[2.2rc3] Distibuted training with Keras and ThreadPoolDataset runs out of memory,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.2.0rc3 and tf-nightly
- Python version: 3.7
- CUDA/cuDNN version: 10.1 / 7.6.5.32
- GPU model and memory: 4 x NVIDIA V100 on GCP

**Describe the current behavior**

When running the code below with cached training and validations datasets in a multi-GPU environment (I am using a GCP VM with 312GB of memory and 4 NVIDIA V100s) memory increases during each validation run until the VM runs out of memory. This behaviour can be observed on 2.2.0-rc3 and on the latest nightly.

It looks like the validation dataset is not properly cached since I can still see network access during validation and the memory usage drops below the theoretical cached memory requirements after validation has finished and then increases linearly during the next validation round to a point larger than the memory usage in the previous epoch.
In the example below I intentionally use an very large validation set to make this memory increase very obvious and make training crash within the first 5 epochs. This behaviour can also be observed with other datasets, but the memory increase will be less noticible on smaller datsets.

**In which cases is the memory usage still stable?**
To narrow down the possible causes for this I found two cases where this issue doesn't exist:

1. When running on a single GPU memory usage is stable.

2. Tensorflow Datasets uses a [`_PrivateThreadPoolDataset`](https://github.com/tensorflow/tensorflow/blob/8e0eecc8e396f8c1859b1b3954a89a41da8b5b45/tensorflow/python/data/ops/dataset_ops.py#L360-L362) by setting the [`experimental_threading.private_threadpool_size=16`](https://github.com/tensorflow/datasets/blob/8277548d5bdbc264a50d84ef702adc15bee8d4ae/tensorflow_datasets/core/tfrecords_reader.py#L62) as a default option. When disabling this option the memory usage is stable again. Unfortunately this is not a valid workaround in userland since the dataset option cannot be overwritten with `experimental_threading.private_threadpool_size=None` as it expects an integer.

@yhliang2018 @tomerk @byronyi This seems to be a complicated interaction between `tf.data`, `tf.keras` and `tf.distribute`, do you have an idea what could cause this behaviour? Please let me know what additional information I could provide.
I've ran into similar issues with `experimental_threading.private_threadpool_size` on TF 2.0.0 in the past though never investigated the root cause in detail, so this might not be an entirely new regression.

**Describe the expected behavior**

Memory usage should be stable after the first epoch.

**Standalone code to reproduce the issue**
```python
import tensorflow as tf
import tensorflow_datasets as tfds


batch_size = 1024

dataset = tfds.load(
    ""imagenet2012:5.0.0"",
    decoders={""image"": tfds.decode.SkipDecoding()},
    split=""train"",
    data_dir=""gs://my-cloud-bucket"",
)

val_dataset = tfds.load(
    ""imagenet2012:5.0.0"",
    decoders={""image"": tfds.decode.SkipDecoding()},
    split=""validation"",
    data_dir=""gs://my-cloud-bucket"",
)


def _decode_and_center_crop(image_bytes):
    """"""Crops to center of image with padding then scales image_size.""""""
    shape = tf.image.extract_jpeg_shape(image_bytes)
    image_height = shape[0]
    image_width = shape[1]
    image_size = 224

    padded_center_crop_size = tf.cast(
        (
            (image_size / (image_size + 32))
            * tf.cast(tf.minimum(image_height, image_width), tf.float32)
        ),
        tf.int32,
    )

    offset_height = ((image_height - padded_center_crop_size) + 1) // 2
    offset_width = ((image_width - padded_center_crop_size) + 1) // 2
    crop_window = tf.stack(
        [offset_height, offset_width, padded_center_crop_size, padded_center_crop_size]
    )
    image = tf.image.decode_and_crop_jpeg(image_bytes, crop_window, channels=3)
    return tf.image.resize(image, [image_size, image_size], method=""bicubic"")


def preprocessing(data):
    return tf.cast(_decode_and_center_crop(data[""image""]), tf.float32), data[""label""]

dataset = (
    dataset.cache()
    .map(preprocessing, num_parallel_calls=tf.data.experimental.AUTOTUNE)
    .batch(batch_size)
    .prefetch(1)
)

val_dataset = (
    val_dataset.cache()
    .map(preprocessing, num_parallel_calls=tf.data.experimental.AUTOTUNE)
    .batch(batch_size)
    .prefetch(1)
)

with tf.distribute.MirroredStrategy().scope():
    model = tf.keras.models.Sequential(
        [
            tf.keras.layers.GlobalMaxPool2D(input_shape=(224, 224, 3)),
            tf.keras.layers.Dense(1000, activation=""softmax"",),
        ]
    )

    model.compile(
        optimizer=""adam"",
        loss=""sparse_categorical_crossentropy"",
        metrics=[""accuracy"", ""sparse_top_k_categorical_accuracy""],
    )

model.fit(
    val_dataset, epochs=5, validation_data=dataset,
)
```

**Other info / logs**

To monitor memory usage over time tools like [`ytop`](https://github.com/cjbassi/ytop/) can be used.
"
38615,Not able to import tensorflow,"**System information**
- OS Platform: Windows10
- TensorFlow installed from (source or binary): Installed tensorflow with Python's pip package manager
- TensorFlow version: tensorflow 2
- Python version: Python 3.7.4
- Installed using virtualenv? pip? conda?: pip 20.0.2
- Bazel version (if compiling from source): No
- GCC/Compiler version (if compiling from source): No
- CUDA/cuDNN version: No
- GPU model and memory:

**Describe the problem**
I am not able to import tensorflow after installing it using pip.
I get: ImportError: DLL load failed: The specified module could not be found.
Microsoft Visual C++ Redistributable for Visual Studio 2015 is installed.
Desperate for help.

**Provide the exact sequence of commands / steps that you executed before running into the problem**

```
>>> import tensorflow
Traceback (most recent call last):
  File ""C:\Users\A492267\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\A492267\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\A492267\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\A492267\AppData\Local\Continuum\anaconda3\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\A492267\AppData\Local\Continuum\anaconda3\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: The specified module could not be found.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""C:\Users\A492267\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow\__init__.py"", line 101, in <module>
    from tensorflow_core import *
  File ""C:\Users\A492267\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\__init__.py"", line 40, in <module>
    from tensorflow.python.tools import module_util as _module_util
  File ""C:\Users\A492267\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow\__init__.py"", line 50, in __getattr__
    module = self._load()
  File ""C:\Users\A492267\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow\__init__.py"", line 44, in _load
    module = _importlib.import_module(self.__name__)
  File ""C:\Users\A492267\AppData\Local\Continuum\anaconda3\lib\importlib\__init__.py"", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""C:\Users\A492267\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\Users\A492267\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 74, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""C:\Users\A492267\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\A492267\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\A492267\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\A492267\AppData\Local\Continuum\anaconda3\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\A492267\AppData\Local\Continuum\anaconda3\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: The specified module could not be found.


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/errors

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.

```
"
38613,"in train_validation_split raise ValueError( ValueError: `validation_split` is only supported for Tensors or NumPy arrays, found: (array([[[[0.24705882]","**PyCharm
Debian 10.3
Python 3.8.2
Cuda 10.2
cuDNN 7.6
Quadro K5200d drivers 440.82
Tensorflow 2.2.0-rc2**

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D
import pickle

pickle_in = open('X.pickle', 'rb')
X = pickle.load(pickle_in)
pickle_in = open('y.pickle', 'rb')
y = pickle.load(pickle_in)
X = X/255.0

model = Sequential()
model.add(Conv2D(256, (3, 3), input_shape=X.shape[1:]))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Conv2D(256, (3, 3)))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Flatten())
model.add(Dense(64))
model.add(Dense(1))
model.add(Activation('sigmoid'))
model.compile(loss='binary_crossentropy',
              optimizer='adam',
              metrics=['accuracy'])
model.fit(X, y, batch_size=64, epochs=3, validation_split=0.3)


2020-04-16 23:15:02.420846: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-04-16 23:15:02.438037: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: 
pciBusID: 0000:03:00.0 name: Quadro K5200 computeCapability: 3.5
coreClock: 0.771GHz coreCount: 12 deviceMemorySize: 7.94GiB deviceMemoryBandwidth: 179.05GiB/s
2020-04-16 23:15:02.438206: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory
2020-04-16 23:15:02.439862: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-04-16 23:15:02.441466: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-04-16 23:15:02.441717: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-04-16 23:15:02.443456: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-04-16 23:15:02.444460: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-04-16 23:15:02.448122: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-04-16 23:15:02.448136: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1598] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2020-04-16 23:15:02.448470: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-04-16 23:15:02.480562: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2394460000 Hz
2020-04-16 23:15:02.484972: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fd3dc000b20 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-04-16 23:15:02.484998: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-04-16 23:15:02.487117: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-04-16 23:15:02.487134: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      
Traceback (most recent call last):
  File ""/home/dominik/PycharmProjects/TensorFlow/dog_cat/model.py"", line 25, in <module>
    model.fit(X, y, batch_size=64, epochs=3, validation_split=0.3)
  File ""/home/dominik/PycharmProjects/TensorFlow/venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py"", line 66, in _method_wrapper
    return method(self, *args, **kwargs)
  File ""/home/dominik/PycharmProjects/TensorFlow/venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py"", line 732, in fit
    data_adapter.train_validation_split((x, y, sample_weight),
  File ""/home/dominik/PycharmProjects/TensorFlow/venv/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py"", **line 1314, in train_validation_split
    raise ValueError(
ValueError: `validation_split` is only supported for Tensors or NumPy arrays, found:** (array([[[[0.24705882],
         [0.3372549 ],
         [0.36078431],"
38612,No Upsampling2D layer in Tensorflow C++,"I am Rahul, an M.Sc. in Digital Engineering student at University of Magdeburg, Germany. I am currently pursuing my master thesis and it involves developing a U-Net (a neural network designed for biomedical image segmentation, you can read more about it here : https://arxiv.org/pdf/1505.04597.pdf). And deploying/loading it in a C++ Application. The U-Net has a couple of layers namely Concatenate, UpSampling2D which are not common in Image processing. 

To deploy it I am guessing I need all the layers used U-Net available in Tensorflow C++ here : https://www.tensorflow.org/api_docs/cc/group/nn-ops

I can't find Upsampling2D there. 

Am I looking at the wrong location? 

I would like to know if  loading the protobuf and predicting using it is independent of the structure and layers used in the model I developed or it only supports standard layers such as flatten, convolution, maxpool etc…."
38611,transformers.modeling_tf_utils  - loading weights file from cache at None (!),"Hi, desperately need your help! 
We are trying to run TF and transformers (bert-multilingual-base-uncased) in our docker environment. Starting the training, we are getting the following error:

`INFO     transformers.modeling_tf_utils  - loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-uncased-tf_model.h5 from cache at None`

This happens, however, only with weights, config file and vocab are linked successfully.
For instance:
`transformers.configuration_utils  - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-uncased-config.json from cache at bert_cache/33b56ce0f312e47e4d77a57791a4fc6233ae4a560dd2bdd186107058294e58ab.c7892120c5a9b21e515abc904e398dbabddf9510b122f659063cbf361fe16868`

Any idea why this can happen?

Many thanks in advance for any feedback and help!



"
38610,How to right pad data in Tensorflow Transform to feed into a LSTM ?,"I am building a data pipeline using Tensorflow Transform using Apache Beam. Inside the preprocessing function I am generating vocabulary which is converting my input sentences to list of integers.
My data has 3 features:
Column 1 = Context (dtype = String) (Sentences of varying Length)
Column 2 = Utterance (dtype = String) (Sentences of varying Length)
Column 3 = Label (0/1)
I want to right pad my list of integers as soon as they are generated in the preprocessing function below to a max length of 160 words.
Example:
""I love Pizza"" --> [34, 67, 78] --> Max length I want = 10
then I want [34, 67, 78,0,0,0,0,0,0,0] and if the length of my sentence is already greater than 10, then I want to trim the extra portion to make it length  =10

Now to use tf.keras.preprocessing.sequence.pad_sequences you need as input a list of sequences but as shown below, my mapped_context and mapped_utterance are tf.int64 tensors. So I am not able to use the padding functionality of Keras.
Can someone please help me achieve this ?

The reference code I am following is Tensorflow Sentiment Analysis Example:
https://github.com/tensorflow/transform/blob/599691c8b94bbd6ee7f67c11542e7fef1792a566/examples/sentiment_example.py
------------------------------------------------------------------------------------------------------------

My code's preprocessing function is below:

![image](https://user-images.githubusercontent.com/27782859/79493187-1a195300-7fef-11ea-9d5c-560787e137b8.png)


My Dataset is below:

![image](https://user-images.githubusercontent.com/27782859/79533358-a5bdce80-8045-11ea-8e40-d820cf935f42.png)

"
38609,Docker ERROR: Could not find a version that satisfies the requirement tensorflow-cpu,"I am trying to build a docker image and when the docker build reaches the tensorflow-cpu requirement, I get the following error: 

```
ERROR: Could not find a version that satisfies the requirement tensorflow-cpu (from socialworks-nn==0.0.7->-r requirements.txt (line 16)) (from versions: none)
ERROR: No matching distribution found for tensorflow-cpu (from socialworks-nn==0.0.7->-r requirements.txt (line 16))
```
Here is my Dockerfile:

```
FROM python:3.6-alpine3.7

RUN apk add --no-cache python3-dev \
    && pip3 install --upgrade pip

RUN apk --no-cache add git
RUN apk add mariadb-dev

WORKDIR /socialworks-api

COPY . /socialworks-api

RUN pip3 --no-cache-dir install -r requirements.txt
```

May I ask what should I run to install tensorflow? My application must run on Python 3.6. I am new to Docker, this is my first build. Also, I have tried commenting out tensorflow, but I am receiving the same error with numpy.

I have also tried running this command in my Dockerfile:

`RUN python3 -m pip install --upgrade https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow_gpu-2.1.0-cp36-cp36m-manylinux2010_x86_64.whl`

But after that, I would receive this error: 

`ERROR: tensorflow_gpu-2.1.0-cp36-cp36m-manylinux2010_x86_64.whl is not a supported wheel on this platform.`

Any help will be appreciated"
38608,"After quantifying the model, the speed of model inference slows down","Today, I learned how to use tensorflow Lite to quantify the model. I ran the code in the example. I found that the model inference speed after quantification is 0.3 seconds slower than the original model. Is this normal? I firstly do it and who can answer, thank you~~~
"
38607,Gradients do not exist for variables manually added to wrapper layer,"**System information** 
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04.3
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: n/a
- TensorFlow installed from (source or binary): binary
- TensorFlow version: v2.1.0-rc2-17-ge5bf8de
- Python version: 3.6.9
- Bazel version (if compiling from source): n/a
- GCC/Compiler version (if compiling from source): n/a 
- CUDA/cuDNN version: 10.2
- GPU model and memory: RTX 2080 TI

**Describe the current behavior**
When using a `Wrapper` layer, parameters added using `self.add_weight` are being ignored by gradients although the outputs depend on those parameters. A regularization term added using `self.add_loss` also depends on the same parameters.

This is visible as the warnings `WARNING:tensorflow:Gradients do not exist for variables ['loss_ignored_3/p_logit:0', 'loss_ignored_4/p_logit:0'] when minimizing the loss.` come up.

This happened when I was trying to port the concrete dropout implementation in https://github.com/yaringal/ConcreteDropout/blob/master/concrete-dropout-keras.ipynb to tensorflow 2.

A minimal example with some of the complexity stripped away and not necessarily sensible math is posted below.

**Describe the expected behavior**
Gradients should exist for those variables, which should be optimized together with the neural network weights.

**Standalone code to reproduce the issue** 
https://colab.research.google.com/drive/1VQHWXn9UtI--aztmrUYuAgMdeOJ5p22u

An earlier version of this problem was posted in https://stackoverflow.com/questions/61164373/loss-added-to-custom-layer-in-tensorflow-2-is-cleared-when-compiling
"
38606,Inconsistent behaviour when passing arguments to experimental_run_v2 (strategy.run) between TPU and CPU,"**System information**

Have I written custom code (as opposed to using a stock
example script provided in TensorFlow): Yes
OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04): Debian GNU/Linux 9.11
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if
the issue happens on mobile device: N/A
TensorFlow installed from (source or
binary): binary
TensorFlow version (use command below): 2.2.0.dev20200406
Python version: Python 3.7.6
Bazel version (if compiling from source): N/A
GCC/Compiler version (if compiling from
source): N/A
CUDA/cuDNN version: N/A
GPU model and memory: N/A

**Describe the current behavior**

The behaviour for passing arguments to `experimental_run_v2` (now `strategy.run`) is inconsistent between TPU and CPU. For code as below: 

`outputs = strategy.experimental_run_v2(loop, args=((context, mask), var))`

On TPU this gets correctly parsed as `loop((context, mask), var)`.

On CPU (which defaults to MirroredStrategy) this gets automatically unpacked as `loop(context, mask, var)`, which breaks the function signature.

**Describe the expected behavior**

On CPU the first argument should get passed as a tuple, not automatically unpacked, to be consistent with the TPU behaviour. Then CPU execution can be used for testing.

**Standalone code to reproduce the issue** 
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
38605,Adam optimizer behavior between W10/Dell and Ubuntu/DGX,"Hello,

I am working on semantic segmentation of 2D/3D images for medical applications and I have a Dell workstation with a Quadro GV100 32Go for development and DGX servers (workstation and server) with 4 and 8 Tesla V100 DGXS (32Go) for model deployment, training, parameters optimization, ...

The Dell and the DGX's use Tensorflow 1.15.x with the only differences being that the Dell run Windows 10 and the DGX use GNU/Linux 4.15 and the models are trained within Docker images of Ubuntu 18.0x provided by [NVIDIA](https://docs.nvidia.com/deeplearning/frameworks/tensorflow-release-notes/index.html). I think the CUDA library are different between the workstation and NVIDIA servers but both are using CUDA 10.

I am currently working on the Tensorflow implementation of the DeepLabV3+ for the segmentation of background + 12 classes. And my data consist of CT scan slices of around 55,000 images+labels for the training and 13,000 images+labels for the validation set. 

The issue that I have is that for the exact same codes, data and model architecture, the Adam optimizer behavior is completely different between the Dell and DGX. The difference is that on the DGX the validation loss increases after 3-6 epochs (depending on the learning rate) and reach a plateau with give us a prediction of an empty label for each class. The training accuracy/loss is however exactly the same between the Dell and DGX. On the Dell, the validation accuracy/loss increase/decrease smoothly and is stable, never get close to zero/reach a high plateau. Again, same exact code, data, data_generator, no data augmentation... no weird value in the images/label on the Dell workstation nor on the RAID hard drive on any of the DGX. Behavior is the same for the DGX workstation and DGX server 1.

[Tensorboard screenshot of training/validation](https://drive.google.com/file/d/1hIv4r70QHH7Ukg5SJknfkzrsS2dq6ZOq/view?usp=sharing)

I have tried to simplify the model by working on other data with only 1 label and small FOV around this label. The behavior is exactly the same and as soon as we use a LR > 0.0001 the validation accuracy drops to zero on the DGX. If we specify the LR < 0.00005 the validation accuracy increase but is still VERY unstable. 

In the end, I switched to SGD optimizer and there is no difference in term of training and validation accuracy/loss between the Dell and the DGX workstation anymore, regardless of fixed LR value or LR scheduler pattern. However, I would like to use the Adam as well and I cannot afford to no use the DGX because of that. I did not try another model such a 2D UNet.

We are very confused in our team about why the Adam optimizer does not behave the same way with the exact same codes/model/data. I also asked a colleague of mine to use the same model with his codes on my data on the DGX, validation accuracy dropped to zero for him as well. What could explain such difference while the SGD provide the same behavior? 

Hope I provided enough information, I can share more information if needed. 

Best,"
38603,tensorflow.python.framework.ops,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Python version**:
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with:

```bash
python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""
```

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
38602,compilation error,"@tensorflow/micro

**System information**
- Host OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 7 Professional
- TensorFlow installed from (source or binary): source
- Tensorflow version (commit SHA if source): SHA
- Target platform (e.g. Arm Mbed OS, Arduino Nano 33 etc.): STM32F746 discovery kit

**Describe the problem**
Error during compilation
**Please provide the exact sequence of commands/steps when you ran into the problem**
I downloaded source code as described in the manual and installed MBED CLI. I open cmd line and run command:
make -f tensorflow/lite/micro/tools/make/Makefile TARGET=mbed TAGS=""CMSIS disco_f746ng"" generate_micro_speech_mbed_project

I get following error messages:

C:\Users\anton.paus\voice\tensorflowmaster2>make -f tensorflow/lite/micro/tools/
make/Makefile TARGET=mbed TAGS=""CMSIS disco_f746ng"" generate_micro_speech_mbed_p
roject
process_begin: CreateProcess(NULL, uname -m, ...) failed.
make: tensorflow/lite/micro/tools/make/Makefile:28: pipe: No error
tensorflow/lite/micro/tools/make/download_and_extract.sh ""https://github.com/goo
gle/gemmlowp/archive/719139ce755a0f31cbf1c37f7f98adcc7fc9f425.zip"" ""7e8191b24853
d75de2af87622ad293ba"" tensorflow/lite/micro/tools/make/downloads/gemmlowp
tensorflow/lite/micro/tools/make/download_and_extract.sh: line 110: syntax error
: bad for loop variable
tensorflow/lite/micro/tools/make/Makefile:271: recipe for target 'tensorflow/lit
e/micro/tools/make/downloads/gemmlowp' failed
make: *** [tensorflow/lite/micro/tools/make/downloads/gemmlowp] Error 2

I have no idea what could be wrong. During the installation of mbed CLI the installer could not instal serial drivers because it didnt recgnized the mbed enabled board."
38601,Symbol not found: ____chkstk_darwin,"Hi!

I am trying to install TensorFlow on an older desktop Mac (no GPU or anything other fancy stuff). It's the first time I am doing that, so maybe I'm just being dense, but installation completed without error yet TensorFlow cannot be loaded (see below). I have no idea what may be wrong and would appreciate any type of help.

Frank

**System information**

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS 10.13.6
- TensorFlow installed from (source or binary): via pip install --upgrade tensorflow (binary, I guess?)
- TensorFlow version: 2.2.0rc3
- Python version: 3.8.2
- Installed using virtualenv? pip? conda?: virtualenv & pip (following https://www.tensorflow.org/install/pip#virtualenv-install to the letter)
- Bazel version (if compiling from source): -
- GCC/Compiler version (if compiling from source): -
- CUDA/cuDNN version: -
- GPU model and memory: -

**Describe the problem**

I followed the procedure described on https://www.tensorflow.org/install to install TensorFlow in a virtual environment using pip. Everything seems to have worked smoothly. In particular, 
pip install --upgrade tensorflow
terminated with a success message. However, the verification using
python -c ""import tensorflow as tf;print(tf.reduce_sum(tf.random.normal([1000, 1000])))""
fails to load the TensorFlow runtime, reporting
ImportError: dlopen(.../_pywrap_tensorflow_internal.so, 6): Symbol not found: ____chkstk_darwin.

**Provide the exact sequence of commands / steps that you executed before running into the problem**

mkdir tensorflow
cd tensorflow/
virtualenv --system-site-packages -p python3 ./venv
source ./venv/bin/activate
pip install --upgrade pip
pip list
pip install --upgrade tensorflow
python -c ""import tensorflow as tf;print(tf.reduce_sum(tf.random.normal([1000, 1000])))""

**Any other info / logs**

I attach both the messages the TensorFlow installation resulted in as well as the traceback. In case it's useful to know, `pip list` gives

absl-py                0.9.0      
astunparse             1.6.3      
cachetools             4.1.0      
certifi                2020.4.5.1 
chardet                3.0.4      
gast                   0.3.3      
google-auth            1.14.0     
google-auth-oauthlib   0.4.1      
google-pasta           0.2.0      
grpcio                 1.28.1     
h5py                   2.10.0     
idna                   2.9        
Keras-Preprocessing    1.1.0      
Markdown               3.2.1      
numpy                  1.18.2     
oauthlib               3.1.0      
opt-einsum             3.2.1      
pip                    20.0.2     
protobuf               3.11.3     
pyasn1                 0.4.8      
pyasn1-modules         0.2.8      
requests               2.23.0     
requests-oauthlib      1.3.0      
rsa                    4.0        
scipy                  1.4.1      
setuptools             46.1.3     
six                    1.14.0     
tensorboard            2.2.1      
tensorboard-plugin-wit 1.6.0.post3
tensorflow             2.2.0rc3   
tensorflow-estimator   2.2.0rc0   
termcolor              1.1.0      
urllib3                1.25.8     
Werkzeug               1.0.1      
wheel                  0.34.2     
wrapt                  1.12.1    


[tf_installation_messages.txt](https://github.com/tensorflow/tensorflow/files/4486772/tf_installation_messages.txt)
[traceback.txt](https://github.com/tensorflow/tensorflow/files/4486773/traceback.txt)


"
38599,Image segmentation model,"I'm trying to implement the image segmentation model in my android application, using tflite -

https://github.com/tensorflow/examples/tree/master/lite/examples/image_segmentation/android
https://www.tensorflow.org/lite/models/segmentation/overview

And I wonder if there is any other model that I can use instead of the deeplabv3_257_mv_gpu.tflite model, [I saw this project on GitHub ](https://github.com/dailystudio/ml/tree/master/deeplab#performance), and it seems that there is TF Mobile model with 513 x 513 inputs somewhere.

Thanks in advance,
Nirel."
38598,Memory-leak-like behavior on subsequent predictions (since TF 2.1.0),"The following minimal example produces (and logs) continuous memory growth:

```python3
# tf_memleak.py

import os

import numpy as np
import psutil

# Disable GPU, use CPU only
os.environ['CUDA_VISIBLE_DEVICES'] = '-1'
import tensorflow as tf

print(tf.version.GIT_VERSION, tf.version.VERSION)

inputs = tf.keras.layers.Input((None, None, 3))
x = tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3), padding='same')(inputs)
model = tf.keras.models.Model(inputs=inputs, outputs=x)

for count in range(10000):
    memory_usage_in_MiB = psutil.Process().memory_info().rss / (1024 * 1024)
    print(f'Memory usage after {count} prediction(s):',
          f'{memory_usage_in_MiB:.3f} MiB',
          flush=True)
    image_shape = [*np.random.randint(128, 1024, (2,)).tolist(), 3]
    image = np.random.uniform(0, 256, image_shape)
    model.predict(image[np.newaxis])
```

[Output](https://gist.githubusercontent.com/Dobiasd/09c63fbbf6ec11e2aa631f6f4b8adf2f/raw/ce410998c82bcc514a516617a69975208a9f26c0/gistfile1.txt):

```
[...]
v2.1.0-rc2-17-ge5bf8de 2.1.0
[...]
Memory usage after 0 prediction(s): 306.641 MiB
Memory usage after 1 prediction(s): 328.238 MiB
Memory usage after 2 prediction(s): 344.785 MiB
Memory usage after 3 prediction(s): 349.023 MiB
Memory usage after 4 prediction(s): 417.152 MiB
WARNING: Logging before flag parsing goes to stderr.
W0416 10:25:29.859581 140207157561088 def_function.py:586] 5 out of the last 5 calls to <function _make_execution_function.<locals>.distributed_function at 0x7f83e8146440> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.
Memory usage after 5 prediction(s): 424.629 MiB
W0416 10:25:29.972562 140207157561088 def_function.py:586] 6 out of the last 6 calls to <function _make_execution_function.<locals>.distributed_function at 0x7f83e8146440> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.
Memory usage after 6 prediction(s): 426.527 MiB
[...]
W0416 10:25:31.405993 140207157561088 def_function.py:586] 11 out of the last 11 calls to <function _make_execution_function.<locals>.distributed_function at 0x7f83e8146440> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.
Memory usage after 20 prediction(s): 534.414 MiB
[...]
Memory usage after 100 prediction(s): 660.227 MiB
[...]
Memory usage after 200 prediction(s): 825.668 MiB
[...]
Memory usage after 1000 prediction(s): 1152.734 MiB
[...]
Memory usage after 2000 prediction(s): 1608.641 MiB
[...]
Memory usage after 3000 prediction(s): 1973.738 MiB
[...]
Memory usage after 4000 prediction(s): 2450.891 MiB
[...]
Memory usage after 9000 prediction(s): 4416.121 MiB
[...]
```

The situation can also be created using Docker by running `docker build -t deleteme .` with the following `Dockerfile`:

```
FROM python:3.7

RUN pip install tensorflow==2.1.0 psutil==5.7.0

# Disable the Docker cache from this stage on, see https://stackoverflow.com/a/58801213/1866775
ADD ""https://www.random.org/cgi-bin/randbyte?nbytes=10&format=h"" skipcache

ADD ./tf_memleak.py /
RUN python /tf_memleak.py
```

The problem persists even when using the following:

```python3
tf.config.threading.set_inter_op_parallelism_threads(1)
tf.config.threading.set_intra_op_parallelism_threads(1)
```

And `tf.config.experimental.set_memory_growth(tf.config.list_physical_devices()[0], True)` fails with `ValueError: Cannot set memory growth on non-GPU devices`.

I've tested with different versions of TensorFlow:
- `1.15.2`: ok
- `2.0.0`: ok
- `2.0.1`: ok
- `2.1.0rc0`: leaky
- `2.1.0`: leaky
- `2.2.0`: leaky

So it seems the problem was introduced between versions `2.0.1` and `2.1.0rc0`. Also, the ""ok"" versions don't show the tf.function-retracing warnings, and all the ""leaky"" versions do."
38597,NotFoundError: Op type not registered 'SentencepieceOp' in binary,"**System information** 
- OS Platform and Distribution: Ubuntu 18.04.2 LTS
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.1.0
- Python version: 3.6.10
- CUDA/cuDNN version: CUDA 10.2 
- GPU model and memory: Tesla V100-SXM2-32GB 


**Describe the current behavior**
NotFoundError: Op type not registered 'SentencepieceOp' in binary running on 42c9348a7da5. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.


**Standalone code to reproduce the issue** 
https://tfhub.dev/google/universal-sentence-encoder-multilingual-large/3




**Other info / logs**

Traceback (most recent call last):
  File ""/home//anaconda3/envs/tf-test/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py"", line 3708, in _get_op_def
    return self._op_def_cache[type]
KeyError: 'SentencepieceOp'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""create_sentence_embeddings.py"", line 19, in <module>
    embed = hub.load(""https://tfhub.dev/google/universal-sentence-encoder-multilingual-large/3"")
  File ""/home//.local/lib/python3.6/site-packages/tensorflow_hub/module_v2.py"", line 102, in load
    obj = tf_v1.saved_model.load_v2(module_path, tags=tags)
  File ""/home//anaconda3/envs/tf-test/lib/python3.6/site-packages/tensorflow_core/python/saved_model/load.py"", line 528, in load
    return load_internal(export_dir, tags)
  File ""/home//anaconda3/envs/tf-test/lib/python3.6/site-packages/tensorflow_core/python/saved_model/load.py"", line 552, in load_internal
    export_dir)
  File ""/home//anaconda3/envs/tf-test/lib/python3.6/site-packages/tensorflow_core/python/saved_model/load.py"", line 114, in __init__
    meta_graph.graph_def.library))
  File ""/home//anaconda3/envs/tf-test/lib/python3.6/site-packages/tensorflow_core/python/saved_model/function_deserialization.py"", line 312, in load_function_def_library
    func_graph = function_def_lib.function_def_to_graph(copy)
  File ""/home//anaconda3/envs/tf-test/lib/python3.6/site-packages/tensorflow_core/python/framework/function_def_to_graph.py"", line 59, in function_def_to_graph
    fdef, input_shapes)
  File ""/home//anaconda3/envs/tf-test/lib/python3.6/site-packages/tensorflow_core/python/framework/function_def_to_graph.py"", line 218, in function_def_to_graph_def
    op_def = default_graph._get_op_def(node_def.op)  # pylint: disable=protected-access
  File ""/home//anaconda3/envs/tf-test/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py"", line 3712, in _get_op_def
    c_api.TF_GraphGetOpDef(self._c_graph, compat.as_bytes(type), buf)
tensorflow.python.framework.errors_impl.NotFoundError: Op type not registered 'SentencepieceOp' in binary running on 3dad5b69905940a4b13b587d16329be5-master-0. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.
"
38596,Keras fails to account for smaller last batch in loss metric calculation,"## System information
- OS Platform and Distribution: Google Colab Notebook
- TensorFlow version (use command below): 2.2.0-rc2
- Python version: 3.6

## Describe the current behavior

In `tf.keras` models, the `model.test_step()` method (which is called by `model.fit()` and `model.evaluate()`) incorrectly computes the mean loss over all batches in an epoch when the dataset size is not evenly divisible by the batch size. This applies for both training and validation loss. This bug affects the reported epoch loss, but NOT the training loss used for computing gradient updates.

Currently, TensorFlow-Keras computes the loss for each batch, adds together the losses across batches, then divides by the number of batches. In other words, the reported loss at the end of each epoch is (incorrectly) unweighted with respect to the size of each batch.

For example, suppose there are 3 samples in a dataset, and the batch size is 2. Then there are 2 batches of size 2 and 1. If the first batch has mean loss of 10 and the second batch has mean loss of 9, then the mean loss over the entire dataset is currently (incorrectly) computed as `(10 + 9) / 2 = 9.5`.

## Describe the expected behavior

Continuing with the example above, the correct mean loss over the dataset should be a weighted mean of the batch losses, where the weights are given by each batch size. Thus, the correct mean loss should be `(10*2 + 9*1) / (2 + 1) = 9.66666`. This is shown in the code below.

## Standalone code to reproduce the issue

Code ([gist here](https://colab.research.google.com/gist/bentyeh/9ec7fd68564f411cc4a1f8a7060c9b92/tf_keras_issue38596.ipynb))

```python
import tensorflow as tf

X = tf.constant([[1],
                 [2],
                 [3]], dtype=tf.float32)
y = tf.constant([[5],
                 [4],
                 [6]], dtype=tf.float32)

# y_pred = a * x + b, where weights are intialized as a = 1, b = 0
# thus, MSE = (x - y)**2 / len(x)
model = tf.keras.Sequential([
    tf.keras.layers.Dense(1, input_dim=1, kernel_initializer='ones', bias_initializer='zeros')])
model.compile(optimizer='sgd', loss='mean_squared_error')

def mse(y, y_pred):
    assert len(y) == len(y_pred)
    return sum((y - y_pred)**2)/len(y)

print('model.evaluate():')
print('- batch_size=1:', model.evaluate(X, y, batch_size=1, verbose=0))
print('- batch_size=2:', model.evaluate(X, y, batch_size=2, verbose=0))
print('- batch_size=3:', model.evaluate(X, y, batch_size=3, verbose=0))
print()

# incorrect mean of two different-sized batches
# Batch 1 is size 2, but Batch 2 is size 1
# So we should compute a weighted mean, but Tensorflow-Keras fails to do so
print((mse(X[:-1], y[:-1]) + mse(X[-1], y[-1]))/2)
```

Output
```
model.evaluate():
- batch_size=1: 9.666666984558105
- batch_size=2: 9.5
- batch_size=3: 9.666666984558105

tf.Tensor([9.5], shape=(1,), dtype=float32)
```

## Where this error occurs in TensorFlow source code

The following line in the `model.test_step()` method calls the `self.compiled_loss` object.

https://github.com/tensorflow/tensorflow/blob/42052dcb8ea0265e9b8b6eafd2ab3dcb4cb1f73c/tensorflow/python/keras/engine/training.py#L971-L972

`self.compiled_loss` is a `compile_utils.LossesContainer` object whose `__call__()` method seems to be implemented incorrectly. Specifically, the following line is where each batch's total loss is accumulated over an epoch, but the accumulation is done without any record of the batch size.

https://github.com/tensorflow/tensorflow/blob/42052dcb8ea0265e9b8b6eafd2ab3dcb4cb1f73c/tensorflow/python/keras/engine/compile_utils.py#L235

Consequently, the mean epoch loss is calculated (`m.result()` below)

https://github.com/tensorflow/tensorflow/blob/42052dcb8ea0265e9b8b6eafd2ab3dcb4cb1f73c/tensorflow/python/keras/engine/training.py#L975

by dividing the total accumulated loss by the number of batches (`self.count`).

https://github.com/tensorflow/tensorflow/blob/a5a8ceea2180665b660862d1efd1de51ea8cb0c2/tensorflow/python/keras/metrics.py#L383

## Proposed solution

I don't know what the best way to solve this problem may be, but the accumulation of each batch's loss should clearly track each batch's actual size. One possible solution may be to use the `sample_weight` argument and replace

https://github.com/tensorflow/tensorflow/blob/42052dcb8ea0265e9b8b6eafd2ab3dcb4cb1f73c/tensorflow/python/keras/engine/compile_utils.py#L235

with

`self._loss_metric.update_state(total_loss_metric_value, sample_weight=ACTUAL_BATCH_SIZE)`

## Related Issues

To the best of my knowledge, the problem described above is the root problem for a number of other reported issues: #35585 #35533 #38004 #38165"
38594,C++ compilation of rule '//tensorflow/core/kernels:sparse_redu ce_op' failed (Exit 1),"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Debian GNU/Linux 9 (stretch), kernel : Linux 4.9.0-12-amd64
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: n/a
- TensorFlow installed from (source or binary): source
- TensorFlow version: 1.14
- Python version: Python 3.5.3
- Installed using virtualenv? pip? conda?: n/a
- Bazel version (if compiling from source): tried with Bazel 0.24.1 and 2.0.0
- GCC/Compiler version (if compiling from source): gcc (Debian 6.3.0-18+deb9u1) 6.3.0 20170516
- CUDA/cuDNN version: n/a
- GPU model and memory: n/a



**Describe the problem**
I'm using jupyterlab from Google Cloud Platform to build the Tensorflow from source, intended to convert the Tensorflow model to flat buffer (tflite).  Bazel installed from binary (0.24.1) and from apt get, configured with all 'no' installation options in ./configure.  After hours of the building process, it came up with C++ compilation of rule '//tensorflow/core/kernels:sparse_redu
ce_op' failed (Exit 1).
**Provide the exact sequence of commands/steps that you executed before running into the problem**
bazel build --config=v1 //tensorflow/tools/pip_package:build_pip_package

**Any other info / logs**
In file included from external/eigen_archive/unsupported/Eigen/CXX11/Tensor:104:0,
                 from ./third_party/eigen3/unsupported/Eigen/CXX11/Tensor:1,
                 from ./tensorflow/core/framework/numeric_types.h:20,
                 from ./tensorflow/core/framework/allocator.h:26,
                 from ./tensorflow/core/framework/op_kernel.h:24,
                 from tensorflow/core/kernels/sparse_reduce_op.cc:20:
external/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorReduction.h: In static member function 'static void std::_Function_handler<void(_ArgTypes ...), _Functor>::_M_invoke(const std::_Any_data&, _ArgTypes&& ...) [with _Functor = Eigen::internal::TensorExecutor<Expression, Eigen::ThreadPoolDevice, Vectorizable, Tiling>::run(const Expression&, const Eigen::ThreadPoolDevice&) [with Expression = const Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::TensorFixedSize<std::complex<float>, Eigen::Sizes<>, 1, long int>, 16, Eigen::MakePointer>, const Eigen::TensorReductionOp<Eigen::internal::SumReducer<std::complex<float> >, const Eigen::DimensionList<long int, 1ul>, const Eigen::TensorMap<Eigen::Tensor<std::complex<float>, 1, 1, long int>, 0, Eigen::MakePointer>, Eigen::MakePointer> >; bool Vectorizable = true; Eigen::internal::TiledEvaluation Tiling = (Eigen::internal::TiledEvaluation)0u]::<lambda(Eigen::internal::TensorExecutor<const Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::TensorFixedSize<std::complex<float>, Eigen::Sizes<>, 1, long int>, 16, Eigen::MakePointer>, const Eigen::TensorReductionOp<Eigen::internal::SumReducer<std::complex<float> >, const Eigen::DimensionList<long int, 1ul>, const Eigen::TensorMap<Eigen::Tensor<std::complex<float>, 1, 1, long int>, 0, Eigen::MakePointer>, Eigen::MakePointer> >, Eigen::ThreadPoolDevice, true, (Eigen::internal::TiledEvaluation)0u>::StorageIndex, Eigen::internal::TensorExecutor<const Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::TensorFixedSize<std::complex<float>, Eigen::Sizes<>, 1, long int>, 16, Eigen::MakePointer>, const Eigen::TensorReductionOp<Eigen::internal::SumReducer<std::complex<float> >, const Eigen::DimensionList<long int, 1ul>, const Eigen::TensorMap<Eigen::Tensor<std::complex<float>, 1, 1, long int>, 0, Eigen::MakePointer>, Eigen::MakePointer> >, Eigen::ThreadPoolDevice, true, (Eigen::internal::TiledEvaluation)0u>::StorageIndex)>; _ArgTypes = {long int, long int}]':
external/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorReduction.h:806:9: internal compiler error: in emit_move_insn, at expr.c:3547
         values[i] = internal::InnerMostDimReducer<Self, Op>::reduce(*this, firstIndex + i * num_values_to_reduce,
         ^~~~~~
Please submit a full bug report,
with preprocessed source if appropriate.
See <file:///usr/share/doc/gcc-6/README.Bugs> for instructions.
Target //tensorflow/lite/python:tflite_convert failed to build
Use --verbose_failures to see the command lines of failed build steps.
INFO: Elapsed time: 9462.045s, Critical Path: 223.49s
INFO: 7684 processes: 7684 local.
FAILED: Build did NOT complete successfully
FAILED: Build did NOT complete successfully

** This is error log when building tflite_convert, similar error when building tensorflow

any advice is much appreciated"
38593,Create serving graph separately from training,"OS Platform and Distribution : macOS Catalina 10.15.3

TensorFlow installed from : binary

TensorFlow version : 1.15.0

Python version: 3.7.3

Can we get example of this - https://cloud.google.com/ai-platform/prediction/docs/exporting-savedmodel-for-prediction#create_serving_graph_separately_from_training  , its not very clear from docs 

I basically have checkpoint file and what to convert that into .pb file with feature transformation part of it . I already have code for converting to feature using TF API . "
38591,"Make ""history"" return by fit store the initial losses","**System information**
- TensorFlow version (you are using): 2.1
- Are you willing to contribute it (Yes/No): Yes

**Describe the feature and the current behavior/state.**

Currently, the returned `history `class by `fit` store the losses start from loss after first epoch training. Hence it doesn't contain the initial loss before training start, which is very important for investigating the influence of first epoch training and the impact of different initialization methods. 

Besides, in this case, the epoch indexes stored in `history` are not aligned with the real training epoch because epoch 0 in `history` corresponds to epoch 1 in real training. If we set epoch 0 in history to represent the initial state, things will look more reasonable. 

Therefore I suggest making the `history` class return by `fit` stores the initial losses, on both train and validation set,  and flag it as epoch 0 by default.

**Will this change the current api? How?** 

It depends. Either add an extra argument to the fit function or make this as default so no need to change the current usage of API.

**Who will benefit with this feature?**
All users want to log the initial loss. And those who want to do something with 'history'
"
38590,TextVectorization inside TimeDistributed throws reshape error,"**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04): docker tensorflow/tensorflow:nightly-gpu-py3 on linux
- Enviroment Capture script
<details>
  <summary>Click to expand!</summary>
  

== check python ===================================================
python version: 3.6.9
python branch: 
python build version: ('default', 'Nov  7 2019 10:44:02')
python compiler version: GCC 8.3.0
python implementation: CPython


== check os platform ===============================================
os: Linux
os kernel version: #1 SMP Thu Oct 17 19:31:58 UTC 2019
os release version: 4.19.76-linuxkit
os platform: Linux-4.19.76-linuxkit-x86_64-with-Ubuntu-18.04-bionic
linux distribution: ('Ubuntu', '18.04', 'bionic')
linux os distribution: ('Ubuntu', '18.04', 'bionic')
mac version: ('', ('', '', ''), '')
uname: uname_result(system='Linux', node='cc3076fc09d8', release='4.19.76-linuxkit', version='#1 SMP Thu Oct 17 19:31:58 UTC 2019', machine='x86_64', processor='x86_64')
architecture: ('64bit', '')
machine: x86_64


== are we in docker =============================================
Yes

== compiler =====================================================
c++ (Ubuntu 7.4.0-1ubuntu1~18.04.1) 7.4.0
Copyright (C) 2017 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.


== check pips ===================================================
numpy                1.18.1      
protobuf             3.11.2      
tensorflow-estimator 2.1.0       
tensorflow-gpu       2.1.0       

== check for virtualenv =========================================
False

== tensorflow import ============================================
tf.version.VERSION = 2.1.0
tf.version.GIT_VERSION = v2.1.0-rc2-17-ge5bf8de
tf.version.COMPILER_VERSION = 7.3.1 20180303
        34:	find library=libc.so.6 [0]; searching
        34:	 search path=/usr/local/cuda/extras/CUPTI/lib64/tls/x86_64/x86_64:/usr/local/cuda/extras/CUPTI/lib64/tls/x86_64:/usr/local/cuda/extras/CUPTI/lib64/tls/x86_64:/usr/local/cuda/extras/CUPTI/lib64/tls:/usr/local/cuda/extras/CUPTI/lib64/x86_64/x86_64:/usr/local/cuda/extras/CUPTI/lib64/x86_64:/usr/local/cuda/extras/CUPTI/lib64/x86_64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64/tls/x86_64/x86_64:/usr/local/cuda/lib64/tls/x86_64:/usr/local/cuda/lib64/tls/x86_64:/usr/local/cuda/lib64/tls:/usr/local/cuda/lib64/x86_64/x86_64:/usr/local/cuda/lib64/x86_64:/usr/local/cuda/lib64/x86_64:/usr/local/cuda/lib64:/usr/local/nvidia/lib/tls/x86_64/x86_64:/usr/local/nvidia/lib/tls/x86_64:/usr/local/nvidia/lib/tls/x86_64:/usr/local/nvidia/lib/tls:/usr/local/nvidia/lib/x86_64/x86_64:/usr/local/nvidia/lib/x86_64:/usr/local/nvidia/lib/x86_64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64/tls/x86_64/x86_64:/usr/local/nvidia/lib64/tls/x86_64:/usr/local/nvidia/lib64/tls/x86_64:/usr/local/nvidia/lib64/tls:/usr/local/nvidia/lib64/x86_64/x86_64:/usr/local/nvidia/lib64/x86_64:/usr/local/nvidia/lib64/x86_64:/usr/local/nvidia/lib64		(LD_LIBRARY_PATH)
        34:	  trying file=/usr/local/cuda/extras/CUPTI/lib64/tls/x86_64/x86_64/libc.so.6
        34:	  trying file=/usr/local/cuda/extras/CUPTI/lib64/tls/x86_64/libc.so.6
        34:	  trying file=/usr/local/cuda/extras/CUPTI/lib64/tls/x86_64/libc.so.6
        34:	  trying file=/usr/local/cuda/extras/CUPTI/lib64/tls/libc.so.6
        34:	  trying file=/usr/local/cuda/extras/CUPTI/lib64/x86_64/x86_64/libc.so.6
        34:	  trying file=/usr/local/cuda/extras/CUPTI/lib64/x86_64/libc.so.6
        34:	  trying file=/usr/local/cuda/extras/CUPTI/lib64/x86_64/libc.so.6
        34:	  trying file=/usr/local/cuda/extras/CUPTI/lib64/libc.so.6
        34:	  trying file=/usr/local/cuda/lib64/tls/x86_64/x86_64/libc.so.6
        34:	  trying file=/usr/local/cuda/lib64/tls/x86_64/libc.so.6
        34:	  trying file=/usr/local/cuda/lib64/tls/x86_64/libc.so.6
        34:	  trying file=/usr/local/cuda/lib64/tls/libc.so.6
        34:	  trying file=/usr/local/cuda/lib64/x86_64/x86_64/libc.so.6
        34:	  trying file=/usr/local/cuda/lib64/x86_64/libc.so.6
        34:	  trying file=/usr/local/cuda/lib64/x86_64/libc.so.6
        34:	  trying file=/usr/local/cuda/lib64/libc.so.6
        34:	  trying file=/usr/local/nvidia/lib/tls/x86_64/x86_64/libc.so.6
        34:	  trying file=/usr/local/nvidia/lib/tls/x86_64/libc.so.6
        34:	  trying file=/usr/local/nvidia/lib/tls/x86_64/libc.so.6
        34:	  trying file=/usr/local/nvidia/lib/tls/libc.so.6
        34:	  trying file=/usr/local/nvidia/lib/x86_64/x86_64/libc.so.6
        34:	  trying file=/usr/local/nvidia/lib/x86_64/libc.so.6
        34:	  trying file=/usr/local/nvidia/lib/x86_64/libc.so.6
        34:	  trying file=/usr/local/nvidia/lib/libc.so.6
        34:	  trying file=/usr/local/nvidia/lib64/tls/x86_64/x86_64/libc.so.6
        34:	  trying file=/usr/local/nvidia/lib64/tls/x86_64/libc.so.6
        34:	  trying file=/usr/local/nvidia/lib64/tls/x86_64/libc.so.6
        34:	  trying file=/usr/local/nvidia/lib64/tls/libc.so.6
        34:	  trying file=/usr/local/nvidia/lib64/x86_64/x86_64/libc.so.6
        34:	  trying file=/usr/local/nvidia/lib64/x86_64/libc.so.6
        34:	  trying file=/usr/local/nvidia/lib64/x86_64/libc.so.6
        34:	  trying file=/usr/local/nvidia/lib64/libc.so.6
        34:	 search cache=/etc/ld.so.cache
        34:	  trying file=/lib/x86_64-linux-gnu/libc.so.6
        34:	
        34:	find library=libpthread.so.0 [0]; searching
        34:	 search path=/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64		(LD_LIBRARY_PATH)
        34:	  trying file=/usr/local/cuda/extras/CUPTI/lib64/libpthread.so.0
        34:	  trying file=/usr/local/cuda/lib64/libpthread.so.0
        34:	 search cache=/etc/ld.so.cache
        34:	  trying file=/lib/x86_64-linux-gnu/libpthread.so.0
        34:	
        34:	find library=libdl.so.2 [0]; searching
        34:	 search path=/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64		(LD_LIBRARY_PATH)
        34:	  trying file=/usr/local/cuda/extras/CUPTI/lib64/libdl.so.2
        34:	  trying file=/usr/local/cuda/lib64/libdl.so.2
        34:	 search cache=/etc/ld.so.cache
        34:	  trying file=/lib/x86_64-linux-gnu/libdl.so.2
        34:	
        34:	find library=libutil.so.1 [0]; searching
        34:	 search path=/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64		(LD_LIBRARY_PATH)
        34:	  trying file=/usr/local/cuda/extras/CUPTI/lib64/libutil.so.1
        34:	  trying file=/usr/local/cuda/lib64/libutil.so.1
        34:	 search cache=/etc/ld.so.cache
        34:	  trying file=/lib/x86_64-linux-gnu/libutil.so.1
        34:	
        34:	find library=libexpat.so.1 [0]; searching
        34:	 search path=/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64		(LD_LIBRARY_PATH)
        34:	  trying file=/usr/local/cuda/extras/CUPTI/lib64/libexpat.so.1
        34:	  trying file=/usr/local/cuda/lib64/libexpat.so.1
        34:	 search cache=/etc/ld.so.cache
        34:	  trying file=/lib/x86_64-linux-gnu/libexpat.so.1
        34:	
        34:	find library=libz.so.1 [0]; searching
        34:	 search path=/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64		(LD_LIBRARY_PATH)
        34:	  trying file=/usr/local/cuda/extras/CUPTI/lib64/libz.so.1
        34:	  trying file=/usr/local/cuda/lib64/libz.so.1
        34:	 search cache=/etc/ld.so.cache
        34:	  trying file=/lib/x86_64-linux-gnu/libz.so.1
        34:	
        34:	find library=libm.so.6 [0]; searching
        34:	 search path=/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64		(LD_LIBRARY_PATH)
        34:	  trying file=/usr/local/cuda/extras/CUPTI/lib64/libm.so.6
        34:	  trying file=/usr/local/cuda/lib64/libm.so.6
        34:	 search cache=/etc/ld.so.cache
        34:	  trying file=/lib/x86_64-linux-gnu/libm.so.6
        34:	
        34:	
        34:	calling init: /lib/x86_64-linux-gnu/libpthread.so.0
        34:	
        34:	
        34:	calling init: /lib/x86_64-linux-gnu/libc.so.6
        34:	
        34:	
        34:	calling init: /lib/x86_64-linux-gnu/libm.so.6
        34:	
        34:	
        34:	calling init: /lib/x86_64-linux-gnu/libz.so.1
        34:	
        34:	
        34:	calling init: /lib/x86_64-linux-gnu/libexpat.so.1
        34:	
        34:	
        34:	calling init: /lib/x86_64-linux-gnu/libutil.so.1
        34:	
        34:	
        34:	calling init: /lib/x86_64-linux-gnu/libdl.so.2
        34:	
        34:	
        34:	initialize program: /usr/local/bin/python
        34:	
        34:	
        34:	transferring control: /usr/local/bin/python
        34:	
        34:	
        34:	calling init: /usr/lib/python3.6/lib-dynload/_opcode.cpython-36m-x86_64-linux-gnu.so
        34:	
        34:	find library=libffi.so.6 [0]; searching
        34:	 search path=/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64		(LD_LIBRARY_PATH)
        34:	  trying file=/usr/local/cuda/extras/CUPTI/lib64/libffi.so.6
        34:	  trying file=/usr/local/cuda/lib64/libffi.so.6
        34:	 search cache=/etc/ld.so.cache
        34:	  trying file=/usr/lib/x86_64-linux-gnu/libffi.so.6
        34:	
        34:	
        34:	calling init: /usr/lib/x86_64-linux-gnu/libffi.so.6
        34:	
        34:	
        34:	calling init: /usr/lib/python3.6/lib-dynload/_ctypes.cpython-36m-x86_64-linux-gnu.so
        34:	
        34:	find library=libopenblasp-r0-34a18dc3.3.7.so [0]; searching
        34:	 search path=/usr/local/lib/python3.6/dist-packages/numpy/core/../.libs/tls/x86_64/x86_64:/usr/local/lib/python3.6/dist-packages/numpy/core/../.libs/tls/x86_64:/usr/local/lib/python3.6/dist-packages/numpy/core/../.libs/tls/x86_64:/usr/local/lib/python3.6/dist-packages/numpy/core/../.libs/tls:/usr/local/lib/python3.6/dist-packages/numpy/core/../.libs/x86_64/x86_64:/usr/local/lib/python3.6/dist-packages/numpy/core/../.libs/x86_64:/usr/local/lib/python3.6/dist-packages/numpy/core/../.libs/x86_64:/usr/local/lib/python3.6/dist-packages/numpy/core/../.libs		(RPATH from file /usr/local/lib/python3.6/dist-packages/numpy/core/_multiarray_umath.cpython-36m-x86_64-linux-gnu.so)
        34:	  trying file=/usr/local/lib/python3.6/dist-packages/numpy/core/../.libs/tls/x86_64/x86_64/libopenblasp-r0-34a18dc3.3.7.so
        34:	  trying file=/usr/local/lib/python3.6/dist-packages/numpy/core/../.libs/tls/x86_64/libopenblasp-r0-34a18dc3.3.7.so
        34:	  trying file=/usr/local/lib/python3.6/dist-packages/numpy/core/../.libs/tls/x86_64/libopenblasp-r0-34a18dc3.3.7.so
        34:	  trying file=/usr/local/lib/python3.6/dist-packages/numpy/core/../.libs/tls/libopenblasp-r0-34a18dc3.3.7.so
        34:	  trying file=/usr/local/lib/python3.6/dist-packages/numpy/core/../.libs/x86_64/x86_64/libopenblasp-r0-34a18dc3.3.7.so
        34:	  trying file=/usr/local/lib/python3.6/dist-packages/numpy/core/../.libs/x86_64/libopenblasp-r0-34a18dc3.3.7.so
        34:	  trying file=/usr/local/lib/python3.6/dist-packages/numpy/core/../.libs/x86_64/libopenblasp-r0-34a18dc3.3.7.so
        34:	  trying file=/usr/local/lib/python3.6/dist-packages/numpy/core/../.libs/libopenblasp-r0-34a18dc3.3.7.so
        34:	
        34:	find library=libgfortran-ed201abd.so.3.0.0 [0]; searching
        34:	 search path=/usr/local/lib/python3.6/dist-packages/numpy/core/../.libs		(RPATH from file /usr/local/lib/python3.6/dist-packages/numpy/core/_multiarray_umath.cpython-36m-x86_64-linux-gnu.so)
        34:	  trying file=/usr/local/lib/python3.6/dist-packages/numpy/core/../.libs/libgfortran-ed201abd.so.3.0.0
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/numpy/core/../.libs/libgfortran-ed201abd.so.3.0.0
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/numpy/core/../.libs/libopenblasp-r0-34a18dc3.3.7.so
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/numpy/core/_multiarray_umath.cpython-36m-x86_64-linux-gnu.so
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/numpy/core/_multiarray_tests.cpython-36m-x86_64-linux-gnu.so
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/numpy/linalg/lapack_lite.cpython-36m-x86_64-linux-gnu.so
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/numpy/linalg/_umath_linalg.cpython-36m-x86_64-linux-gnu.so
        34:	
        34:	find library=libbz2.so.1.0 [0]; searching
        34:	 search path=/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64		(LD_LIBRARY_PATH)
        34:	  trying file=/usr/local/cuda/extras/CUPTI/lib64/libbz2.so.1.0
        34:	  trying file=/usr/local/cuda/lib64/libbz2.so.1.0
        34:	 search cache=/etc/ld.so.cache
        34:	  trying file=/lib/x86_64-linux-gnu/libbz2.so.1.0
        34:	
        34:	
        34:	calling init: /lib/x86_64-linux-gnu/libbz2.so.1.0
        34:	
        34:	
        34:	calling init: /usr/lib/python3.6/lib-dynload/_bz2.cpython-36m-x86_64-linux-gnu.so
        34:	
        34:	find library=liblzma.so.5 [0]; searching
        34:	 search path=/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64		(LD_LIBRARY_PATH)
        34:	  trying file=/usr/local/cuda/extras/CUPTI/lib64/liblzma.so.5
        34:	  trying file=/usr/local/cuda/lib64/liblzma.so.5
        34:	 search cache=/etc/ld.so.cache
        34:	  trying file=/lib/x86_64-linux-gnu/liblzma.so.5
        34:	
        34:	
        34:	calling init: /lib/x86_64-linux-gnu/liblzma.so.5
        34:	
        34:	
        34:	calling init: /usr/lib/python3.6/lib-dynload/_lzma.cpython-36m-x86_64-linux-gnu.so
        34:	
        34:	find library=libmpdec.so.2 [0]; searching
        34:	 search path=/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64		(LD_LIBRARY_PATH)
        34:	  trying file=/usr/local/cuda/extras/CUPTI/lib64/libmpdec.so.2
        34:	  trying file=/usr/local/cuda/lib64/libmpdec.so.2
        34:	 search cache=/etc/ld.so.cache
        34:	  trying file=/usr/lib/x86_64-linux-gnu/libmpdec.so.2
        34:	
        34:	
        34:	calling init: /usr/lib/x86_64-linux-gnu/libmpdec.so.2
        34:	
        34:	
        34:	calling init: /usr/lib/python3.6/lib-dynload/_decimal.cpython-36m-x86_64-linux-gnu.so
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/numpy/fft/_pocketfft_internal.cpython-36m-x86_64-linux-gnu.so
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/numpy/random/mtrand.cpython-36m-x86_64-linux-gnu.so
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/numpy/random/_bit_generator.cpython-36m-x86_64-linux-gnu.so
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/numpy/random/_common.cpython-36m-x86_64-linux-gnu.so
        34:	
        34:	find library=libcrypto.so.1.1 [0]; searching
        34:	 search path=/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64		(LD_LIBRARY_PATH)
        34:	  trying file=/usr/local/cuda/extras/CUPTI/lib64/libcrypto.so.1.1
        34:	  trying file=/usr/local/cuda/lib64/libcrypto.so.1.1
        34:	 search cache=/etc/ld.so.cache
        34:	  trying file=/usr/lib/x86_64-linux-gnu/libcrypto.so.1.1
        34:	
        34:	
        34:	calling init: /usr/lib/x86_64-linux-gnu/libcrypto.so.1.1
        34:	
        34:	
        34:	calling init: /usr/lib/python3.6/lib-dynload/_hashlib.cpython-36m-x86_64-linux-gnu.so
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/numpy/random/_bounded_integers.cpython-36m-x86_64-linux-gnu.so
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/numpy/random/_mt19937.cpython-36m-x86_64-linux-gnu.so
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/numpy/random/_philox.cpython-36m-x86_64-linux-gnu.so
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/numpy/random/_pcg64.cpython-36m-x86_64-linux-gnu.so
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/numpy/random/_sfc64.cpython-36m-x86_64-linux-gnu.so
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/numpy/random/_generator.cpython-36m-x86_64-linux-gnu.so
        34:	
        34:	find library=libtensorflow_framework.so.2 [0]; searching
        34:	 search path=/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/../../_solib_local/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal.so___Utensorflow/tls/x86_64/x86_64:/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/../../_solib_local/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal.so___Utensorflow/tls/x86_64:/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/../../_solib_local/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal.so___Utensorflow/tls/x86_64:/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/../../_solib_local/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal.so___Utensorflow/tls:/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/../../_solib_local/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal.so___Utensorflow/x86_64/x86_64:/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/../../_solib_local/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal.so___Utensorflow/x86_64:/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/../../_solib_local/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal.so___Utensorflow/x86_64:/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/../../_solib_local/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal.so___Utensorflow:/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tls/x86_64/x86_64:/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tls/x86_64:/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tls/x86_64:/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tls:/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/x86_64/x86_64:/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/x86_64:/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/x86_64:/usr/local/lib/python3.6/dist-packages/tensorflow_core/python:/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/../tls/x86_64/x86_64:/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/../tls/x86_64:/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/../tls/x86_64:/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/../tls:/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/../x86_64/x86_64:/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/../x86_64:/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/../x86_64:/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/..		(RPATH from file /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/_pywrap_tensorflow_internal.so)
        34:	  trying file=/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/../../_solib_local/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal.so___Utensorflow/tls/x86_64/x86_64/libtensorflow_framework.so.2
        34:	  trying file=/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/../../_solib_local/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal.so___Utensorflow/tls/x86_64/libtensorflow_framework.so.2
        34:	  trying file=/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/../../_solib_local/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal.so___Utensorflow/tls/x86_64/libtensorflow_framework.so.2
        34:	  trying file=/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/../../_solib_local/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal.so___Utensorflow/tls/libtensorflow_framework.so.2
        34:	  trying file=/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/../../_solib_local/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal.so___Utensorflow/x86_64/x86_64/libtensorflow_framework.so.2
        34:	  trying file=/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/../../_solib_local/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal.so___Utensorflow/x86_64/libtensorflow_framework.so.2
        34:	  trying file=/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/../../_solib_local/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal.so___Utensorflow/x86_64/libtensorflow_framework.so.2
        34:	  trying file=/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/../../_solib_local/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal.so___Utensorflow/libtensorflow_framework.so.2
        34:	  trying file=/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tls/x86_64/x86_64/libtensorflow_framework.so.2
        34:	  trying file=/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tls/x86_64/libtensorflow_framework.so.2
        34:	  trying file=/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tls/x86_64/libtensorflow_framework.so.2
        34:	  trying file=/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tls/libtensorflow_framework.so.2
        34:	  trying file=/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/x86_64/x86_64/libtensorflow_framework.so.2
        34:	  trying file=/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/x86_64/libtensorflow_framework.so.2
        34:	  trying file=/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/x86_64/libtensorflow_framework.so.2
        34:	  trying file=/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/libtensorflow_framework.so.2
        34:	  trying file=/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/../tls/x86_64/x86_64/libtensorflow_framework.so.2
        34:	  trying file=/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/../tls/x86_64/libtensorflow_framework.so.2
        34:	  trying file=/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/../tls/x86_64/libtensorflow_framework.so.2
        34:	  trying file=/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/../tls/libtensorflow_framework.so.2
        34:	  trying file=/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/../x86_64/x86_64/libtensorflow_framework.so.2
        34:	  trying file=/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/../x86_64/libtensorflow_framework.so.2
        34:	  trying file=/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/../x86_64/libtensorflow_framework.so.2
        34:	  trying file=/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/../libtensorflow_framework.so.2
        34:	
        34:	find library=librt.so.1 [0]; searching
        34:	 search path=/usr/local/lib/python3.6/dist-packages/tensorflow_core/python:/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/..		(RPATH from file /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/_pywrap_tensorflow_internal.so)
        34:	  trying file=/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/librt.so.1
        34:	  trying file=/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/../librt.so.1
        34:	 search path=/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64		(LD_LIBRARY_PATH)
        34:	  trying file=/usr/local/cuda/extras/CUPTI/lib64/librt.so.1
        34:	  trying file=/usr/local/cuda/lib64/librt.so.1
        34:	 search cache=/etc/ld.so.cache
        34:	  trying file=/lib/x86_64-linux-gnu/librt.so.1
        34:	
        34:	find library=libstdc++.so.6 [0]; searching
        34:	 search path=/usr/local/lib/python3.6/dist-packages/tensorflow_core/python:/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/..		(RPATH from file /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/_pywrap_tensorflow_internal.so)
        34:	  trying file=/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/libstdc++.so.6
        34:	  trying file=/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/../libstdc++.so.6
        34:	 search path=/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64		(LD_LIBRARY_PATH)
        34:	  trying file=/usr/local/cuda/extras/CUPTI/lib64/libstdc++.so.6
        34:	  trying file=/usr/local/cuda/lib64/libstdc++.so.6
        34:	 search cache=/etc/ld.so.cache
        34:	  trying file=/usr/lib/x86_64-linux-gnu/libstdc++.so.6
        34:	
        34:	find library=libgcc_s.so.1 [0]; searching
        34:	 search path=/usr/local/lib/python3.6/dist-packages/tensorflow_core/python:/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/..		(RPATH from file /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/_pywrap_tensorflow_internal.so)
        34:	  trying file=/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/libgcc_s.so.1
        34:	  trying file=/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/../libgcc_s.so.1
        34:	 search path=/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64		(LD_LIBRARY_PATH)
        34:	  trying file=/usr/local/cuda/extras/CUPTI/lib64/libgcc_s.so.1
        34:	  trying file=/usr/local/cuda/lib64/libgcc_s.so.1
        34:	 search cache=/etc/ld.so.cache
        34:	  trying file=/lib/x86_64-linux-gnu/libgcc_s.so.1
        34:	
        34:	
        34:	calling init: /lib/x86_64-linux-gnu/libgcc_s.so.1
        34:	
        34:	
        34:	calling init: /usr/lib/x86_64-linux-gnu/libstdc++.so.6
        34:	
        34:	
        34:	calling init: /lib/x86_64-linux-gnu/librt.so.1
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/../libtensorflow_framework.so.2
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/_pywrap_tensorflow_internal.so
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/_pywrap_utils.so
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/_pywrap_tfprof.so
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/_pywrap_events_writer.so
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/_pywrap_util_port.so
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/_pywrap_stat_summarizer.so
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/_pywrap_py_exception_registry.so
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/_pywrap_kernel_registry.so
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/_pywrap_quantize_training.so
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/_pywrap_scoped_annotation.so
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/_pywrap_transform_graph.so
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/_pywrap_traceme.so
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/_pywrap_stacktrace_handler.so
        34:	
        34:	
        34:	
        34:	
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/_tf_stack.so
        34:	
        34:	
        34:	calling init: /usr/lib/python3.6/lib-dynload/termios.cpython-36m-x86_64-linux-gnu.so
        34:	
        34:	
        34:	calling init: /usr/lib/python3.6/lib-dynload/_csv.cpython-36m-x86_64-linux-gnu.so
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/wrapt/_wrappers.cpython-36m-x86_64-linux-gnu.so
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/fast_tensor_util.so
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/_op_def_registry.so
        34:	
        34:	find library=libuuid.so.1 [0]; searching
        34:	 search path=/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64		(LD_LIBRARY_PATH)
        34:	  trying file=/usr/local/cuda/extras/CUPTI/lib64/libuuid.so.1
        34:	  trying file=/usr/local/cuda/lib64/libuuid.so.1
        34:	 search cache=/etc/ld.so.cache
        34:	  trying file=/lib/x86_64-linux-gnu/libuuid.so.1
        34:	
        34:	
        34:	calling init: /lib/x86_64-linux-gnu/libuuid.so.1
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/_pywrap_py_func.so
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/_pywrap_checkpoint_reader.so
        34:	
        34:	
        34:	calling init: /usr/lib/python3.6/lib-dynload/_json.cpython-36m-x86_64-linux-gnu.so
        34:	
        34:	find library=libssl.so.1.1 [0]; searching
        34:	 search path=/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64		(LD_LIBRARY_PATH)
        34:	  trying file=/usr/local/cuda/extras/CUPTI/lib64/libssl.so.1.1
        34:	  trying file=/usr/local/cuda/lib64/libssl.so.1.1
        34:	 search cache=/etc/ld.so.cache
        34:	  trying file=/usr/lib/x86_64-linux-gnu/libssl.so.1.1
        34:	
        34:	
        34:	calling init: /usr/lib/x86_64-linux-gnu/libssl.so.1.1
        34:	
        34:	
        34:	calling init: /usr/lib/python3.6/lib-dynload/_ssl.cpython-36m-x86_64-linux-gnu.so
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/_pywrap_device_lib.so
        34:	
        37:	find library=libc.so.6 [0]; searching
        37:	 search path=/usr/local/cuda/extras/CUPTI/lib64/tls/x86_64/x86_64:/usr/local/cuda/extras/CUPTI/lib64/tls/x86_64:/usr/local/cuda/extras/CUPTI/lib64/tls/x86_64:/usr/local/cuda/extras/CUPTI/lib64/tls:/usr/local/cuda/extras/CUPTI/lib64/x86_64/x86_64:/usr/local/cuda/extras/CUPTI/lib64/x86_64:/usr/local/cuda/extras/CUPTI/lib64/x86_64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64/tls/x86_64/x86_64:/usr/local/cuda/lib64/tls/x86_64:/usr/local/cuda/lib64/tls/x86_64:/usr/local/cuda/lib64/tls:/usr/local/cuda/lib64/x86_64/x86_64:/usr/local/cuda/lib64/x86_64:/usr/local/cuda/lib64/x86_64:/usr/local/cuda/lib64:/usr/local/nvidia/lib/tls/x86_64/x86_64:/usr/local/nvidia/lib/tls/x86_64:/usr/local/nvidia/lib/tls/x86_64:/usr/local/nvidia/lib/tls:/usr/local/nvidia/lib/x86_64/x86_64:/usr/local/nvidia/lib/x86_64:/usr/local/nvidia/lib/x86_64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64/tls/x86_64/x86_64:/usr/local/nvidia/lib64/tls/x86_64:/usr/local/nvidia/lib64/tls/x86_64:/usr/local/nvidia/lib64/tls:/usr/local/nvidia/lib64/x86_64/x86_64:/usr/local/nvidia/lib64/x86_64:/usr/local/nvidia/lib64/x86_64:/usr/local/nvidia/lib64		(LD_LIBRARY_PATH)
        37:	  trying file=/usr/local/cuda/extras/CUPTI/lib64/tls/x86_64/x86_64/libc.so.6
        37:	  trying file=/usr/local/cuda/extras/CUPTI/lib64/tls/x86_64/libc.so.6
        37:	  trying file=/usr/local/cuda/extras/CUPTI/lib64/tls/x86_64/libc.so.6
        37:	  trying file=/usr/local/cuda/extras/CUPTI/lib64/tls/libc.so.6
        37:	  trying file=/usr/local/cuda/extras/CUPTI/lib64/x86_64/x86_64/libc.so.6
        37:	  trying file=/usr/local/cuda/extras/CUPTI/lib64/x86_64/libc.so.6
        37:	  trying file=/usr/local/cuda/extras/CUPTI/lib64/x86_64/libc.so.6
        37:	  trying file=/usr/local/cuda/extras/CUPTI/lib64/libc.so.6
        37:	  trying file=/usr/local/cuda/lib64/tls/x86_64/x86_64/libc.so.6
        37:	  trying file=/usr/local/cuda/lib64/tls/x86_64/libc.so.6
        37:	  trying file=/usr/local/cuda/lib64/tls/x86_64/libc.so.6
        37:	  trying file=/usr/local/cuda/lib64/tls/libc.so.6
        37:	  trying file=/usr/local/cuda/lib64/x86_64/x86_64/libc.so.6
        37:	  trying file=/usr/local/cuda/lib64/x86_64/libc.so.6
        37:	  trying file=/usr/local/cuda/lib64/x86_64/libc.so.6
        37:	  trying file=/usr/local/cuda/lib64/libc.so.6
        37:	  trying file=/usr/local/nvidia/lib/tls/x86_64/x86_64/libc.so.6
        37:	  trying file=/usr/local/nvidia/lib/tls/x86_64/libc.so.6
        37:	  trying file=/usr/local/nvidia/lib/tls/x86_64/libc.so.6
        37:	  trying file=/usr/local/nvidia/lib/tls/libc.so.6
        37:	  trying file=/usr/local/nvidia/lib/x86_64/x86_64/libc.so.6
        37:	  trying file=/usr/local/nvidia/lib/x86_64/libc.so.6
        37:	  trying file=/usr/local/nvidia/lib/x86_64/libc.so.6
        37:	  trying file=/usr/local/nvidia/lib/libc.so.6
        37:	  trying file=/usr/local/nvidia/lib64/tls/x86_64/x86_64/libc.so.6
        37:	  trying file=/usr/local/nvidia/lib64/tls/x86_64/libc.so.6
        37:	  trying file=/usr/local/nvidia/lib64/tls/x86_64/libc.so.6
        37:	  trying file=/usr/local/nvidia/lib64/tls/libc.so.6
        37:	  trying file=/usr/local/nvidia/lib64/x86_64/x86_64/libc.so.6
        37:	  trying file=/usr/local/nvidia/lib64/x86_64/libc.so.6
        37:	  trying file=/usr/local/nvidia/lib64/x86_64/libc.so.6
        37:	  trying file=/usr/local/nvidia/lib64/libc.so.6
        37:	 search cache=/etc/ld.so.cache
        37:	  trying file=/lib/x86_64-linux-gnu/libc.so.6
        37:	
        37:	
        37:	calling init: /lib/x86_64-linux-gnu/libc.so.6
        37:	
        37:	
        37:	initialize program: /bin/sh
        37:	
        37:	
        37:	transferring control: /bin/sh
        37:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/tensorflow_core/compiler/tf2tensorrt/_wrap_py_utils.so
        34:	
        34:	find library=libnvinfer.so.6 [0]; searching
        34:	 search path=/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/..		(RPATH from file /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/_pywrap_tensorflow_internal.so)
        34:	  trying file=/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/../libnvinfer.so.6
        34:	 search path=/usr/local/lib/python3.6/dist-packages/tensorflow_core/python:/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/..		(RPATH from file /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/_pywrap_tensorflow_internal.so)
        34:	  trying file=/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/libnvinfer.so.6
        34:	  trying file=/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/../libnvinfer.so.6
        34:	 search path=/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64		(LD_LIBRARY_PATH)
        34:	  trying file=/usr/local/cuda/extras/CUPTI/lib64/libnvinfer.so.6
        34:	  trying file=/usr/local/cuda/lib64/libnvinfer.so.6
        34:	 search cache=/etc/ld.so.cache
        34:	  trying file=/usr/lib/x86_64-linux-gnu/libnvinfer.so.6
        34:	
        34:	find library=libcudnn.so.7 [0]; searching
        34:	 search path=/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64		(LD_LIBRARY_PATH)
        34:	  trying file=/usr/local/cuda/extras/CUPTI/lib64/libcudnn.so.7
        34:	  trying file=/usr/local/cuda/lib64/libcudnn.so.7
        34:	 search cache=/etc/ld.so.cache
        34:	  trying file=/usr/lib/x86_64-linux-gnu/libcudnn.so.7
        34:	
        34:	find library=libcublas.so.10 [0]; searching
        34:	 search path=/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64		(LD_LIBRARY_PATH)
        34:	  trying file=/usr/local/cuda/extras/CUPTI/lib64/libcublas.so.10
        34:	  trying file=/usr/local/cuda/lib64/libcublas.so.10
        34:	 search cache=/etc/ld.so.cache
        34:	  trying file=/usr/lib/x86_64-linux-gnu/libcublas.so.10
        34:	
        34:	find library=libcudart.so.10.1 [0]; searching
        34:	 search path=/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64		(LD_LIBRARY_PATH)
        34:	  trying file=/usr/local/cuda/extras/CUPTI/lib64/libcudart.so.10.1
        34:	  trying file=/usr/local/cuda/lib64/libcudart.so.10.1
        34:	
        34:	find library=libcublasLt.so.10 [0]; searching
        34:	 search path=/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64		(LD_LIBRARY_PATH)
        34:	  trying file=/usr/local/cuda/extras/CUPTI/lib64/libcublasLt.so.10
        34:	  trying file=/usr/local/cuda/lib64/libcublasLt.so.10
        34:	 search cache=/etc/ld.so.cache
        34:	  trying file=/usr/lib/x86_64-linux-gnu/libcublasLt.so.10
        34:	
        34:	
        34:	calling init: /usr/lib/x86_64-linux-gnu/libcublasLt.so.10
        34:	
        34:	
        34:	calling init: /usr/local/cuda/lib64/libcudart.so.10.1
        34:	
        34:	
        34:	calling init: /usr/lib/x86_64-linux-gnu/libcublas.so.10
        34:	
        34:	
        34:	calling init: /usr/lib/x86_64-linux-gnu/libcudnn.so.7
        34:	
        34:	
        34:	calling init: /usr/lib/x86_64-linux-gnu/libnvinfer.so.6
        34:	
2020-04-16 05:35:48.013573: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libnvinfer.so.6
        34:	find library=libnvinfer_plugin.so.6 [0]; searching
        34:	 search path=/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/..		(RPATH from file /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/_pywrap_tensorflow_internal.so)
        34:	  trying file=/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/../libnvinfer_plugin.so.6
        34:	 search path=/usr/local/lib/python3.6/dist-packages/tensorflow_core/python:/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/..		(RPATH from file /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/_pywrap_tensorflow_internal.so)
        34:	  trying file=/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/libnvinfer_plugin.so.6
        34:	  trying file=/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/../libnvinfer_plugin.so.6
        34:	 search path=/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64		(LD_LIBRARY_PATH)
        34:	  trying file=/usr/local/cuda/extras/CUPTI/lib64/libnvinfer_plugin.so.6
        34:	  trying file=/usr/local/cuda/lib64/libnvinfer_plugin.so.6
        34:	 search cache=/etc/ld.so.cache
        34:	  trying file=/usr/lib/x86_64-linux-gnu/libnvinfer_plugin.so.6
        34:	
        34:	find library=libnvrtc.so.10.1 [0]; searching
        34:	 search path=/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64		(LD_LIBRARY_PATH)
        34:	  trying file=/usr/local/cuda/extras/CUPTI/lib64/libnvrtc.so.10.1
        34:	  trying file=/usr/local/cuda/lib64/libnvrtc.so.10.1
        34:	
        34:	
        34:	calling init: /usr/local/cuda/lib64/libnvrtc.so.10.1
        34:	
        34:	
        34:	calling init: /usr/lib/x86_64-linux-gnu/libnvinfer_plugin.so.6
        34:	
2020-04-16 05:35:48.022692: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libnvinfer_plugin.so.6
        34:	find library=libhdf5-beac1db3.so.103.0.0 [0]; searching
        34:	 search path=/usr/local/lib/python3.6/dist-packages/h5py/.libs/tls/x86_64/x86_64:/usr/local/lib/python3.6/dist-packages/h5py/.libs/tls/x86_64:/usr/local/lib/python3.6/dist-packages/h5py/.libs/tls/x86_64:/usr/local/lib/python3.6/dist-packages/h5py/.libs/tls:/usr/local/lib/python3.6/dist-packages/h5py/.libs/x86_64/x86_64:/usr/local/lib/python3.6/dist-packages/h5py/.libs/x86_64:/usr/local/lib/python3.6/dist-packages/h5py/.libs/x86_64:/usr/local/lib/python3.6/dist-packages/h5py/.libs		(RPATH from file /usr/local/lib/python3.6/dist-packages/h5py/_errors.cpython-36m-x86_64-linux-gnu.so)
        34:	  trying file=/usr/local/lib/python3.6/dist-packages/h5py/.libs/tls/x86_64/x86_64/libhdf5-beac1db3.so.103.0.0
        34:	  trying file=/usr/local/lib/python3.6/dist-packages/h5py/.libs/tls/x86_64/libhdf5-beac1db3.so.103.0.0
        34:	  trying file=/usr/local/lib/python3.6/dist-packages/h5py/.libs/tls/x86_64/libhdf5-beac1db3.so.103.0.0
        34:	  trying file=/usr/local/lib/python3.6/dist-packages/h5py/.libs/tls/libhdf5-beac1db3.so.103.0.0
        34:	  trying file=/usr/local/lib/python3.6/dist-packages/h5py/.libs/x86_64/x86_64/libhdf5-beac1db3.so.103.0.0
        34:	  trying file=/usr/local/lib/python3.6/dist-packages/h5py/.libs/x86_64/libhdf5-beac1db3.so.103.0.0
        34:	  trying file=/usr/local/lib/python3.6/dist-packages/h5py/.libs/x86_64/libhdf5-beac1db3.so.103.0.0
        34:	  trying file=/usr/local/lib/python3.6/dist-packages/h5py/.libs/libhdf5-beac1db3.so.103.0.0
        34:	
        34:	find library=libhdf5_hl-db841637.so.100.1.1 [0]; searching
        34:	 search path=/usr/local/lib/python3.6/dist-packages/h5py/.libs		(RPATH from file /usr/local/lib/python3.6/dist-packages/h5py/_errors.cpython-36m-x86_64-linux-gnu.so)
        34:	  trying file=/usr/local/lib/python3.6/dist-packages/h5py/.libs/libhdf5_hl-db841637.so.100.1.1
        34:	
        34:	find library=libsz-1c7dd0cf.so.2.0.1 [0]; searching
        34:	 search path=/usr/local/lib/python3.6/dist-packages/h5py/.libs/./tls/x86_64/x86_64:/usr/local/lib/python3.6/dist-packages/h5py/.libs/./tls/x86_64:/usr/local/lib/python3.6/dist-packages/h5py/.libs/./tls/x86_64:/usr/local/lib/python3.6/dist-packages/h5py/.libs/./tls:/usr/local/lib/python3.6/dist-packages/h5py/.libs/./x86_64/x86_64:/usr/local/lib/python3.6/dist-packages/h5py/.libs/./x86_64:/usr/local/lib/python3.6/dist-packages/h5py/.libs/./x86_64:/usr/local/lib/python3.6/dist-packages/h5py/.libs/.		(RPATH from file /usr/local/lib/python3.6/dist-packages/h5py/.libs/libhdf5-beac1db3.so.103.0.0)
        34:	  trying file=/usr/local/lib/python3.6/dist-packages/h5py/.libs/./tls/x86_64/x86_64/libsz-1c7dd0cf.so.2.0.1
        34:	  trying file=/usr/local/lib/python3.6/dist-packages/h5py/.libs/./tls/x86_64/libsz-1c7dd0cf.so.2.0.1
        34:	  trying file=/usr/local/lib/python3.6/dist-packages/h5py/.libs/./tls/x86_64/libsz-1c7dd0cf.so.2.0.1
        34:	  trying file=/usr/local/lib/python3.6/dist-packages/h5py/.libs/./tls/libsz-1c7dd0cf.so.2.0.1
        34:	  trying file=/usr/local/lib/python3.6/dist-packages/h5py/.libs/./x86_64/x86_64/libsz-1c7dd0cf.so.2.0.1
        34:	  trying file=/usr/local/lib/python3.6/dist-packages/h5py/.libs/./x86_64/libsz-1c7dd0cf.so.2.0.1
        34:	  trying file=/usr/local/lib/python3.6/dist-packages/h5py/.libs/./x86_64/libsz-1c7dd0cf.so.2.0.1
        34:	  trying file=/usr/local/lib/python3.6/dist-packages/h5py/.libs/./libsz-1c7dd0cf.so.2.0.1
        34:	
        34:	find library=libaec-2147abcd.so.0.0.4 [0]; searching
        34:	 search path=/usr/local/lib/python3.6/dist-packages/h5py/.libs/.		(RPATH from file /usr/local/lib/python3.6/dist-packages/h5py/.libs/libhdf5-beac1db3.so.103.0.0)
        34:	  trying file=/usr/local/lib/python3.6/dist-packages/h5py/.libs/./libaec-2147abcd.so.0.0.4
        34:	
        34:	find library=libz-a147dcb0.so.1.2.3 [0]; searching
        34:	 search path=/usr/local/lib/python3.6/dist-packages/h5py/.libs/.		(RPATH from file /usr/local/lib/python3.6/dist-packages/h5py/.libs/libhdf5-beac1db3.so.103.0.0)
        34:	  trying file=/usr/local/lib/python3.6/dist-packages/h5py/.libs/./libz-a147dcb0.so.1.2.3
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/h5py/.libs/./libz-a147dcb0.so.1.2.3
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/h5py/.libs/./libaec-2147abcd.so.0.0.4
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/h5py/.libs/./libsz-1c7dd0cf.so.2.0.1
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/h5py/.libs/libhdf5-beac1db3.so.103.0.0
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/h5py/.libs/libhdf5_hl-db841637.so.100.1.1
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/h5py/_errors.cpython-36m-x86_64-linux-gnu.so
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/h5py/h5.cpython-36m-x86_64-linux-gnu.so
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/h5py/defs.cpython-36m-x86_64-linux-gnu.so
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/h5py/_objects.cpython-36m-x86_64-linux-gnu.so
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/h5py/_conv.cpython-36m-x86_64-linux-gnu.so
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/h5py/h5r.cpython-36m-x86_64-linux-gnu.so
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/h5py/h5t.cpython-36m-x86_64-linux-gnu.so
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/h5py/utils.cpython-36m-x86_64-linux-gnu.so
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/h5py/h5z.cpython-36m-x86_64-linux-gnu.so
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/h5py/h5a.cpython-36m-x86_64-linux-gnu.so
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/h5py/h5s.cpython-36m-x86_64-linux-gnu.so
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/h5py/h5p.cpython-36m-x86_64-linux-gnu.so
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/h5py/h5ac.cpython-36m-x86_64-linux-gnu.so
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/h5py/_proxy.cpython-36m-x86_64-linux-gnu.so
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/h5py/h5d.cpython-36m-x86_64-linux-gnu.so
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/h5py/h5ds.cpython-36m-x86_64-linux-gnu.so
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/h5py/h5f.cpython-36m-x86_64-linux-gnu.so
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/h5py/h5g.cpython-36m-x86_64-linux-gnu.so
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/h5py/h5i.cpython-36m-x86_64-linux-gnu.so
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/h5py/h5fd.cpython-36m-x86_64-linux-gnu.so
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/h5py/h5pl.cpython-36m-x86_64-linux-gnu.so
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/h5py/h5o.cpython-36m-x86_64-linux-gnu.so
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/h5py/h5l.cpython-36m-x86_64-linux-gnu.so
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/scipy/_lib/_ccallback_c.cpython-36m-x86_64-linux-gnu.so
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/scipy/_lib/_uarray/_uarray.cpython-36m-x86_64-linux-gnu.so
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/scipy/fft/_pocketfft/pypocketfft.cpython-36m-x86_64-linux-gnu.so
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/scipy/sparse/_sparsetools.cpython-36m-x86_64-linux-gnu.so
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/scipy/sparse/_csparsetools.cpython-36m-x86_64-linux-gnu.so
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/scipy/sparse/csgraph/_shortest_path.cpython-36m-x86_64-linux-gnu.so
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/scipy/sparse/csgraph/_tools.cpython-36m-x86_64-linux-gnu.so
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/scipy/sparse/csgraph/_traversal.cpython-36m-x86_64-linux-gnu.so
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/scipy/sparse/csgraph/_min_spanning_tree.cpython-36m-x86_64-linux-gnu.so
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/scipy/sparse/csgraph/_flow.cpython-36m-x86_64-linux-gnu.so
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/scipy/sparse/csgraph/_matching.cpython-36m-x86_64-linux-gnu.so
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/scipy/sparse/csgraph/_reordering.cpython-36m-x86_64-linux-gnu.so
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/pandas/_libs/tslibs/conversion.cpython-36m-x86_64-linux-gnu.so
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/pandas/_libs/tslibs/c_timestamp.cpython-36m-x86_64-linux-gnu.so
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/pandas/_libs/tslibs/nattype.cpython-36m-x86_64-linux-gnu.so
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/pandas/_libs/missing.cpython-36m-x86_64-linux-gnu.so
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/pandas/_libs/tslibs/np_datetime.cpython-36m-x86_64-linux-gnu.so
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/pandas/_libs/ops_dispatch.cpython-36m-x86_64-linux-gnu.so
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/pandas/_libs/tslibs/timezones.cpython-36m-x86_64-linux-gnu.so
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/pandas/_libs/tslibs/tzconversion.cpython-36m-x86_64-linux-gnu.so
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/pandas/_libs/tslibs/timedeltas.cpython-36m-x86_64-linux-gnu.so
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/pandas/_libs/tslibs/offsets.cpython-36m-x86_64-linux-gnu.so
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/pandas/_libs/tslibs/ccalendar.cpython-36m-x86_64-linux-gnu.so
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/pandas/_libs/tslibs/strptime.cpython-36m-x86_64-linux-gnu.so
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/pandas/_libs/tslibs/fields.cpython-36m-x86_64-linux-gnu.so
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/pandas/_libs/tslibs/parsing.cpython-36m-x86_64-linux-gnu.so
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/pandas/_libs/tslibs/frequencies.cpython-36m-x86_64-linux-gnu.so
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/pandas/_libs/tslibs/period.cpython-36m-x86_64-linux-gnu.so
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/pandas/_libs/tslibs/timestamps.cpython-36m-x86_64-linux-gnu.so
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/pandas/_libs/tslibs/resolution.cpython-36m-x86_64-linux-gnu.so
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/pandas/_libs/hashtable.cpython-36m-x86_64-linux-gnu.so
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/pandas/_libs/lib.cpython-36m-x86_64-linux-gnu.so
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/pandas/_libs/tslib.cpython-36m-x86_64-linux-gnu.so
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/pandas/_libs/interval.cpython-36m-x86_64-linux-gnu.so
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/pandas/_libs/algos.cpython-36m-x86_64-linux-gnu.so
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/pandas/_libs/properties.cpython-36m-x86_64-linux-gnu.so
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/pandas/_libs/hashing.cpython-36m-x86_64-linux-gnu.so
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/pandas/_libs/ops.cpython-36m-x86_64-linux-gnu.so
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/pandas/_libs/index.cpython-36m-x86_64-linux-gnu.so
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/pandas/_libs/join.cpython-36m-x86_64-linux-gnu.so
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/pandas/_libs/sparse.cpython-36m-x86_64-linux-gnu.so
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/pandas/_libs/indexing.cpython-36m-x86_64-linux-gnu.so
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/pandas/_libs/writers.cpython-36m-x86_64-linux-gnu.so
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/pandas/_libs/internals.cpython-36m-x86_64-linux-gnu.so
        34:	
        34:	
        34:	calling init: /usr/lib/python3.6/lib-dynload/mmap.cpython-36m-x86_64-linux-gnu.so
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/pandas/_libs/reshape.cpython-36m-x86_64-linux-gnu.so
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/pandas/_libs/window/aggregations.cpython-36m-x86_64-linux-gnu.so
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/pandas/_libs/window/indexers.cpython-36m-x86_64-linux-gnu.so
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/pandas/_libs/groupby.cpython-36m-x86_64-linux-gnu.so
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/pandas/_libs/reduction.cpython-36m-x86_64-linux-gnu.so
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/pandas/_libs/parsers.cpython-36m-x86_64-linux-gnu.so
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/pandas/_libs/json.cpython-36m-x86_64-linux-gnu.so
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/pandas/_libs/testing.cpython-36m-x86_64-linux-gnu.so
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/_pywrap_debug_events_writer.so
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/tensorflow_core/lite/experimental/microfrontend/python/ops/_audio_microfrontend_op.so
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/_pywrap_toco_api.so
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/scipy/ndimage/_nd_image.cpython-36m-x86_64-linux-gnu.so
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/scipy/ndimage/_ni_label.cpython-36m-x86_64-linux-gnu.so
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/scipy/linalg/_fblas.cpython-36m-x86_64-linux-gnu.so
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/scipy/linalg/_flapack.cpython-36m-x86_64-linux-gnu.so
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/scipy/linalg/_flinalg.cpython-36m-x86_64-linux-gnu.so
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/scipy/linalg/_solve_toeplitz.cpython-36m-x86_64-linux-gnu.so
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/scipy/linalg/_decomp_update.cpython-36m-x86_64-linux-gnu.so
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/scipy/linalg/cython_blas.cpython-36m-x86_64-linux-gnu.so
        34:	
        34:	
        34:	calling init: /usr/local/lib/python3.6/dist-packages/scipy/linalg/cython_lapack.cpython-36m-x86_64-linux-gnu.so
        34:	
        34:	
        34:	calling fini: /usr/local/bin/python [0]
        34:	
        34:	
        34:	calling fini: /lib/x86_64-linux-gnu/libutil.so.1 [0]
        34:	
        34:	
        34:	calling fini: /lib/x86_64-linux-gnu/libexpat.so.1 [0]
        34:	
        34:	
        34:	calling fini: /lib/x86_64-linux-gnu/libz.so.1 [0]
        34:	
        34:	
        34:	calling fini: /usr/lib/python3.6/lib-dynload/_opcode.cpython-36m-x86_64-linux-gnu.so [0]
        34:	
        34:	
        34:	calling fini: /usr/lib/python3.6/lib-dynload/_ctypes.cpython-36m-x86_64-linux-gnu.so [0]
        34:	
        34:	
        34:	calling fini: /usr/lib/x86_64-linux-gnu/libffi.so.6 [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/numpy/core/_multiarray_umath.cpython-36m-x86_64-linux-gnu.so [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/numpy/core/_multiarray_tests.cpython-36m-x86_64-linux-gnu.so [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/numpy/linalg/lapack_lite.cpython-36m-x86_64-linux-gnu.so [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/numpy/linalg/_umath_linalg.cpython-36m-x86_64-linux-gnu.so [0]
        34:	
        34:	
        34:	calling fini: /usr/lib/python3.6/lib-dynload/_bz2.cpython-36m-x86_64-linux-gnu.so [0]
        34:	
        34:	
        34:	calling fini: /lib/x86_64-linux-gnu/libbz2.so.1.0 [0]
        34:	
        34:	
        34:	calling fini: /usr/lib/python3.6/lib-dynload/_lzma.cpython-36m-x86_64-linux-gnu.so [0]
        34:	
        34:	
        34:	calling fini: /lib/x86_64-linux-gnu/liblzma.so.5 [0]
        34:	
        34:	
        34:	calling fini: /usr/lib/python3.6/lib-dynload/_decimal.cpython-36m-x86_64-linux-gnu.so [0]
        34:	
        34:	
        34:	calling fini: /usr/lib/x86_64-linux-gnu/libmpdec.so.2 [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/numpy/fft/_pocketfft_internal.cpython-36m-x86_64-linux-gnu.so [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/numpy/random/mtrand.cpython-36m-x86_64-linux-gnu.so [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/numpy/random/_bit_generator.cpython-36m-x86_64-linux-gnu.so [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/numpy/random/_common.cpython-36m-x86_64-linux-gnu.so [0]
        34:	
        34:	
        34:	calling fini: /usr/lib/python3.6/lib-dynload/_hashlib.cpython-36m-x86_64-linux-gnu.so [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/numpy/random/_bounded_integers.cpython-36m-x86_64-linux-gnu.so [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/numpy/random/_mt19937.cpython-36m-x86_64-linux-gnu.so [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/numpy/random/_philox.cpython-36m-x86_64-linux-gnu.so [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/numpy/random/_pcg64.cpython-36m-x86_64-linux-gnu.so [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/numpy/random/_sfc64.cpython-36m-x86_64-linux-gnu.so [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/numpy/random/_generator.cpython-36m-x86_64-linux-gnu.so [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/_pywrap_utils.so [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/_pywrap_tfprof.so [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/_pywrap_events_writer.so [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/_pywrap_util_port.so [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/_pywrap_stat_summarizer.so [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/_pywrap_py_exception_registry.so [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/_pywrap_kernel_registry.so [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/_pywrap_quantize_training.so [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/_pywrap_scoped_annotation.so [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/_pywrap_transform_graph.so [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/_pywrap_traceme.so [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/_pywrap_stacktrace_handler.so [0]
        34:	
        34:	
        34:	
        34:	
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/_tf_stack.so [0]
        34:	
        34:	
        34:	calling fini: /usr/lib/python3.6/lib-dynload/termios.cpython-36m-x86_64-linux-gnu.so [0]
        34:	
        34:	
        34:	calling fini: /usr/lib/python3.6/lib-dynload/_csv.cpython-36m-x86_64-linux-gnu.so [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/wrapt/_wrappers.cpython-36m-x86_64-linux-gnu.so [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/fast_tensor_util.so [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/_op_def_registry.so [0]
        34:	
        34:	
        34:	calling fini: /lib/x86_64-linux-gnu/libuuid.so.1 [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/_pywrap_py_func.so [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/_pywrap_checkpoint_reader.so [0]
        34:	
        34:	
        34:	calling fini: /usr/lib/python3.6/lib-dynload/_json.cpython-36m-x86_64-linux-gnu.so [0]
        34:	
        34:	
        34:	calling fini: /usr/lib/python3.6/lib-dynload/_ssl.cpython-36m-x86_64-linux-gnu.so [0]
        34:	
        34:	
        34:	calling fini: /usr/lib/x86_64-linux-gnu/libssl.so.1.1 [0]
        34:	
        34:	
        34:	calling fini: /usr/lib/x86_64-linux-gnu/libcrypto.so.1.1 [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/_pywrap_device_lib.so [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/tensorflow_core/compiler/tf2tensorrt/_wrap_py_utils.so [0]
        34:	
        34:	
        34:	calling fini: /usr/lib/x86_64-linux-gnu/libnvinfer_plugin.so.6 [0]
        34:	
        34:	
        34:	calling fini: /usr/lib/x86_64-linux-gnu/libnvinfer.so.6 [0]
        34:	
        34:	
        34:	calling fini: /usr/local/cuda/lib64/libcudart.so.10.1 [0]
        34:	
        34:	
        34:	calling fini: /usr/lib/x86_64-linux-gnu/libcublas.so.10 [0]
        34:	
        34:	
        34:	calling fini: /usr/lib/x86_64-linux-gnu/libcublasLt.so.10 [0]
        34:	
        34:	
        34:	calling fini: /usr/lib/x86_64-linux-gnu/libcudnn.so.7 [0]
        34:	
        34:	
        34:	calling fini: /usr/local/cuda/lib64/libnvrtc.so.10.1 [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/h5py/_errors.cpython-36m-x86_64-linux-gnu.so [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/h5py/h5.cpython-36m-x86_64-linux-gnu.so [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/h5py/defs.cpython-36m-x86_64-linux-gnu.so [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/h5py/_objects.cpython-36m-x86_64-linux-gnu.so [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/h5py/_conv.cpython-36m-x86_64-linux-gnu.so [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/h5py/h5r.cpython-36m-x86_64-linux-gnu.so [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/h5py/h5t.cpython-36m-x86_64-linux-gnu.so [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/h5py/utils.cpython-36m-x86_64-linux-gnu.so [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/h5py/h5z.cpython-36m-x86_64-linux-gnu.so [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/h5py/h5a.cpython-36m-x86_64-linux-gnu.so [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/h5py/h5s.cpython-36m-x86_64-linux-gnu.so [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/h5py/h5p.cpython-36m-x86_64-linux-gnu.so [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/h5py/h5ac.cpython-36m-x86_64-linux-gnu.so [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/h5py/_proxy.cpython-36m-x86_64-linux-gnu.so [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/h5py/h5d.cpython-36m-x86_64-linux-gnu.so [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/h5py/h5ds.cpython-36m-x86_64-linux-gnu.so [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/h5py/h5f.cpython-36m-x86_64-linux-gnu.so [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/h5py/h5g.cpython-36m-x86_64-linux-gnu.so [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/h5py/h5i.cpython-36m-x86_64-linux-gnu.so [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/h5py/h5fd.cpython-36m-x86_64-linux-gnu.so [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/h5py/h5pl.cpython-36m-x86_64-linux-gnu.so [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/h5py/h5o.cpython-36m-x86_64-linux-gnu.so [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/h5py/h5l.cpython-36m-x86_64-linux-gnu.so [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/h5py/.libs/libhdf5_hl-db841637.so.100.1.1 [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/h5py/.libs/libhdf5-beac1db3.so.103.0.0 [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/h5py/.libs/./libz-a147dcb0.so.1.2.3 [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/h5py/.libs/./libsz-1c7dd0cf.so.2.0.1 [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/h5py/.libs/./libaec-2147abcd.so.0.0.4 [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/scipy/_lib/_ccallback_c.cpython-36m-x86_64-linux-gnu.so [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/scipy/_lib/_uarray/_uarray.cpython-36m-x86_64-linux-gnu.so [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/scipy/fft/_pocketfft/pypocketfft.cpython-36m-x86_64-linux-gnu.so [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/scipy/sparse/_sparsetools.cpython-36m-x86_64-linux-gnu.so [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/scipy/sparse/_csparsetools.cpython-36m-x86_64-linux-gnu.so [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/scipy/sparse/csgraph/_shortest_path.cpython-36m-x86_64-linux-gnu.so [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/scipy/sparse/csgraph/_tools.cpython-36m-x86_64-linux-gnu.so [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/scipy/sparse/csgraph/_traversal.cpython-36m-x86_64-linux-gnu.so [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/scipy/sparse/csgraph/_min_spanning_tree.cpython-36m-x86_64-linux-gnu.so [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/scipy/sparse/csgraph/_flow.cpython-36m-x86_64-linux-gnu.so [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/scipy/sparse/csgraph/_matching.cpython-36m-x86_64-linux-gnu.so [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/scipy/sparse/csgraph/_reordering.cpython-36m-x86_64-linux-gnu.so [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/pandas/_libs/tslibs/conversion.cpython-36m-x86_64-linux-gnu.so [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/pandas/_libs/tslibs/c_timestamp.cpython-36m-x86_64-linux-gnu.so [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/pandas/_libs/tslibs/nattype.cpython-36m-x86_64-linux-gnu.so [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/pandas/_libs/missing.cpython-36m-x86_64-linux-gnu.so [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/pandas/_libs/tslibs/np_datetime.cpython-36m-x86_64-linux-gnu.so [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/pandas/_libs/ops_dispatch.cpython-36m-x86_64-linux-gnu.so [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/pandas/_libs/tslibs/timezones.cpython-36m-x86_64-linux-gnu.so [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/pandas/_libs/tslibs/tzconversion.cpython-36m-x86_64-linux-gnu.so [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/pandas/_libs/tslibs/timedeltas.cpython-36m-x86_64-linux-gnu.so [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/pandas/_libs/tslibs/offsets.cpython-36m-x86_64-linux-gnu.so [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/pandas/_libs/tslibs/ccalendar.cpython-36m-x86_64-linux-gnu.so [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/pandas/_libs/tslibs/strptime.cpython-36m-x86_64-linux-gnu.so [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/pandas/_libs/tslibs/fields.cpython-36m-x86_64-linux-gnu.so [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/pandas/_libs/tslibs/parsing.cpython-36m-x86_64-linux-gnu.so [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/pandas/_libs/tslibs/frequencies.cpython-36m-x86_64-linux-gnu.so [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/pandas/_libs/tslibs/period.cpython-36m-x86_64-linux-gnu.so [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/pandas/_libs/tslibs/timestamps.cpython-36m-x86_64-linux-gnu.so [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/pandas/_libs/tslibs/resolution.cpython-36m-x86_64-linux-gnu.so [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/pandas/_libs/hashtable.cpython-36m-x86_64-linux-gnu.so [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/pandas/_libs/lib.cpython-36m-x86_64-linux-gnu.so [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/pandas/_libs/tslib.cpython-36m-x86_64-linux-gnu.so [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/pandas/_libs/interval.cpython-36m-x86_64-linux-gnu.so [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/pandas/_libs/algos.cpython-36m-x86_64-linux-gnu.so [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/pandas/_libs/properties.cpython-36m-x86_64-linux-gnu.so [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/pandas/_libs/hashing.cpython-36m-x86_64-linux-gnu.so [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/pandas/_libs/ops.cpython-36m-x86_64-linux-gnu.so [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/pandas/_libs/index.cpython-36m-x86_64-linux-gnu.so [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/pandas/_libs/join.cpython-36m-x86_64-linux-gnu.so [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/pandas/_libs/sparse.cpython-36m-x86_64-linux-gnu.so [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/pandas/_libs/indexing.cpython-36m-x86_64-linux-gnu.so [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/pandas/_libs/writers.cpython-36m-x86_64-linux-gnu.so [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/pandas/_libs/internals.cpython-36m-x86_64-linux-gnu.so [0]
        34:	
        34:	
        34:	calling fini: /usr/lib/python3.6/lib-dynload/mmap.cpython-36m-x86_64-linux-gnu.so [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/pandas/_libs/reshape.cpython-36m-x86_64-linux-gnu.so [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/pandas/_libs/window/aggregations.cpython-36m-x86_64-linux-gnu.so [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/pandas/_libs/window/indexers.cpython-36m-x86_64-linux-gnu.so [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/pandas/_libs/groupby.cpython-36m-x86_64-linux-gnu.so [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/pandas/_libs/reduction.cpython-36m-x86_64-linux-gnu.so [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/pandas/_libs/parsers.cpython-36m-x86_64-linux-gnu.so [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/pandas/_libs/json.cpython-36m-x86_64-linux-gnu.so [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/pandas/_libs/testing.cpython-36m-x86_64-linux-gnu.so [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/_pywrap_debug_events_writer.so [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/tensorflow_core/lite/experimental/microfrontend/python/ops/_audio_microfrontend_op.so [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/_pywrap_toco_api.so [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/_pywrap_tensorflow_internal.so [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/../libtensorflow_framework.so.2 [0]
        34:	
        34:	
        34:	calling fini: /usr/lib/x86_64-linux-gnu/libstdc++.so.6 [0]
        34:	
        34:	
        34:	calling fini: /lib/x86_64-linux-gnu/librt.so.1 [0]
        34:	
        34:	
        34:	calling fini: /lib/x86_64-linux-gnu/libdl.so.2 [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/scipy/ndimage/_nd_image.cpython-36m-x86_64-linux-gnu.so [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/scipy/ndimage/_ni_label.cpython-36m-x86_64-linux-gnu.so [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/scipy/linalg/_fblas.cpython-36m-x86_64-linux-gnu.so [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/scipy/linalg/_flapack.cpython-36m-x86_64-linux-gnu.so [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/scipy/linalg/_flinalg.cpython-36m-x86_64-linux-gnu.so [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/scipy/linalg/_solve_toeplitz.cpython-36m-x86_64-linux-gnu.so [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/scipy/linalg/_decomp_update.cpython-36m-x86_64-linux-gnu.so [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/scipy/linalg/cython_blas.cpython-36m-x86_64-linux-gnu.so [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/scipy/linalg/cython_lapack.cpython-36m-x86_64-linux-gnu.so [0]
        34:	
        34:	
        34:	calling fini: /lib/x86_64-linux-gnu/libgcc_s.so.1 [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/numpy/core/../.libs/libopenblasp-r0-34a18dc3.3.7.so [0]
        34:	
        34:	
        34:	calling fini: /usr/local/lib/python3.6/dist-packages/numpy/core/../.libs/libgfortran-ed201abd.so.3.0.0 [0]
        34:	
        34:	
        34:	calling fini: /lib/x86_64-linux-gnu/libm.so.6 [0]
        34:	
        34:	
        34:	calling fini: /lib/x86_64-linux-gnu/libpthread.so.0 [0]
        34:	

== env ==========================================================
LD_LIBRARY_PATH /usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64
DYLD_LIBRARY_PATH is unset

== nvidia-smi ===================================================
./tfcheck.sh: line 145: nvidia-smi: command not found

== cuda libs  ===================================================
/usr/local/cuda-10.1/targets/x86_64-linux/lib/libcudart.so.10.1.243
/usr/local/cuda-10.1/targets/x86_64-linux/lib/libcudart_static.a

== tensorflow installed from info ==================

== python version  ==============================================
(major, minor, micro, releaselevel, serial)
(3, 6, 9, 'final', 0)

== bazel version  ===============================================

== check python ===================================================
python version: 3.6.9
python branch: 
python build version: ('default', 'Nov  7 2019 10:44:02')
python compiler version: GCC 8.3.0
python implementation: CPython


== check os platform ===============================================
os: Linux
os kernel version: #1 SMP PREEMPT Sun, 05 Apr 2020 05:13:14 +0000
os release version: 5.6.2-arch1-2
os platform: Linux-5.6.2-arch1-2-x86_64-with-Ubuntu-18.04-bionic
linux distribution: ('Ubuntu', '18.04', 'bionic')
linux os distribution: ('Ubuntu', '18.04', 'bionic')
mac version: ('', ('', '', ''), '')
uname: uname_result(system='Linux', node='31f7b339f7aa', release='5.6.2-arch1-2', version='#1 SMP PREEMPT Sun, 05 Apr 2020 05:13:14 +0000', machine='x86_64', processor='x86_64')
architecture: ('64bit', '')
machine: x86_64


== are we in docker =============================================
Yes

== compiler =====================================================
c++ (Ubuntu 7.4.0-1ubuntu1~18.04.1) 7.4.0
Copyright (C) 2017 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.


== check pips ===================================================
numpy                1.18.1      
protobuf             3.11.2      
tensorflow-estimator 2.1.0       
tensorflow-gpu       2.1.0       

== check for virtualenv =========================================
False

== tensorflow import ============================================
tf.version.VERSION = 2.1.0
tf.version.GIT_VERSION = v2.1.0-rc2-17-ge5bf8de
tf.version.COMPILER_VERSION = 7.3.1 20180303
        51:	find library=libc.so.6 [0]; searching
        51:	 search path=/usr/local/cuda/extras/CUPTI/lib64/tls/haswell/x86_64:/usr/local/cuda/extras/CUPTI/lib64/tls/haswell:/usr/local/cuda/extras/CUPTI/lib64/tls/x86_64:/usr/local/cuda/extras/CUPTI/lib64/tls:/usr/local/cuda/extras/CUPTI/lib64/haswell/x86_64:/usr/local/cuda/extras/CUPTI/lib64/haswell:/usr/local/cuda/extras/CUPTI/lib64/x86_64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64/tls/haswell/x86_64:/usr/local/cuda/lib64/tls/haswell:/usr/local/cuda/lib64/tls/x86_64:/usr/local/cuda/lib64/tls:/usr/local/cuda/lib64/haswell/x86_64:/usr/local/cuda/lib64/haswell:/usr/local/cuda/lib64/x86_64:/usr/local/cuda/lib64:/usr/local/nvidia/lib/tls/haswell/x86_64:/usr/local/nvidia/lib/tls/haswell:/usr/local/nvidia/lib/tls/x86_64:/usr/local/nvidia/lib/tls:/usr/local/nvidia/lib/haswell/x86_64:/usr/local/nvidia/lib/haswell:/usr/local/nvidia/lib/x86_64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64/tls/haswell/x86_64:/usr/local/nvidia/lib64/tls/haswell:/usr/local/nvidia/lib64/tls/x86_64:/usr/local/nvidia/lib64/tls:/usr/local/nvidia/lib64/haswell/x86_64:/usr/local/nvidia/lib64/haswell:/usr/local/nvidia/lib64/x86_64:/usr/local/nvidia/lib64		(LD_LIBRARY_PATH)
        51:	  trying file=/usr/local/cuda/extras/CUPTI/lib64/tls/haswell/x86_64/libc.so.6
        51:	  trying file=/usr/local/cuda/extras/CUPTI/lib64/tls/haswell/libc.so.6
        51:	  trying file=/usr/local/cuda/extras/CUPTI/lib64/tls/x86_64/libc.so.6
        51:	  trying file=/usr/local/cuda/extras/CUPTI/lib64/tls/libc.so.6
        51:	  trying file=/usr/local/cuda/extras/CUPTI/lib64/haswell/x86_64/libc.so.6
        51:	  trying file=/usr/local/cuda/extras/CUPTI/lib64/haswell/libc.so.6
        51:	  trying file=/usr/local/cuda/extras/CUPTI/lib64/x86_64/libc.so.6
        51:	  trying file=/usr/local/cuda/extras/CUPTI/lib64/libc.so.6
        51:	  trying file=/usr/local/cuda/lib64/tls/haswell/x86_64/libc.so.6
        51:	  trying file=/usr/local/cuda/lib64/tls/haswell/libc.so.6
        51:	  trying file=/usr/local/cuda/lib64/tls/x86_64/libc.so.6
        51:	  trying file=/usr/local/cuda/lib64/tls/libc.so.6
        51:	  trying file=/usr/local/cuda/lib64/haswell/x86_64/libc.so.6
        51:	  trying file=/usr/local/cuda/lib64/haswell/libc.so.6
        51:	  trying file=/usr/local/cuda/lib64/x86_64/libc.so.6
        51:	  trying file=/usr/local/cuda/lib64/libc.so.6
        51:	  trying file=/usr/local/nvidia/lib/tls/haswell/x86_64/libc.so.6
        51:	  trying file=/usr/local/nvidia/lib/tls/haswell/libc.so.6
        51:	  trying file=/usr/local/nvidia/lib/tls/x86_64/libc.so.6
        51:	  trying file=/usr/local/nvidia/lib/tls/libc.so.6
        51:	  trying file=/usr/local/nvidia/lib/haswell/x86_64/libc.so.6
        51:	  trying file=/usr/local/nvidia/lib/haswell/libc.so.6
        51:	  trying file=/usr/local/nvidia/lib/x86_64/libc.so.6
        51:	  trying file=/usr/local/nvidia/lib/libc.so.6
        51:	  trying file=/usr/local/nvidia/lib64/tls/haswell/x86_64/libc.so.6
        51:	  trying file=/usr/local/nvidia/lib64/tls/haswell/libc.so.6
        51:	  trying file=/usr/local/nvidia/lib64/tls/x86_64/libc.so.6
        51:	  trying file=/usr/local/nvidia/lib64/tls/libc.so.6
        51:	  trying file=/usr/local/nvidia/lib64/haswell/x86_64/libc.so.6
        51:	  trying file=/usr/local/nvidia/lib64/haswell/libc.so.6
        51:	  trying file=/usr/local/nvidia/lib64/x86_64/libc.so.6
        51:	  trying file=/usr/local/nvidia/lib64/libc.so.6
        51:	 search cache=/etc/ld.so.cache
        51:	  trying file=/lib/x86_64-linux-gnu/libc.so.6
        51:	
        51:	find library=libpthread.so.0 [0]; searching
        51:	 search path=/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64		(LD_LIBRARY_PATH)
        51:	  trying file=/usr/local/cuda/extras/CUPTI/lib64/libpthread.so.0
        51:	  trying file=/usr/local/cuda/lib64/libpthread.so.0
        51:	 search cache=/etc/ld.so.cache
        51:	  trying file=/lib/x86_64-linux-gnu/libpthread.so.0
        51:	
        51:	find library=libdl.so.2 [0]; searching
        51:	 search path=/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64		(LD_LIBRARY_PATH)
        51:	  trying file=/usr/local/cuda/extras/CUPTI/lib64/libdl.so.2
        51:	  trying file=/usr/local/cuda/lib64/libdl.so.2
        51:	 search cache=/etc/ld.so.cache
        51:	  trying file=/lib/x86_64-linux-gnu/libdl.so.2
        51:	
        51:	find library=libutil.so.1 [0]; searching
        51:	 search path=/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64		(LD_LIBRARY_PATH)
        51:	  trying file=/usr/local/cuda/extras/CUPTI/lib64/libutil.so.1
        51:	  trying file=/usr/local/cuda/lib64/libutil.so.1
        51:	 search cache=/etc/ld.so.cache
        51:	  trying file=/lib/x86_64-linux-gnu/libutil.so.1
        51:	
        51:	find library=libexpat.so.1 [0]; searching
        51:	 search path=/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64		(LD_LIBRARY_PATH)
        51:	  trying file=/usr/local/cuda/extras/CUPTI/lib64/libexpat.so.1
        51:	  trying file=/usr/local/cuda/lib64/libexpat.so.1
        51:	 search cache=/etc/ld.so.cache
        51:	  trying file=/lib/x86_64-linux-gnu/libexpat.so.1
        51:	
        51:	find library=libz.so.1 [0]; searching
        51:	 search path=/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64		(LD_LIBRARY_PATH)
        51:	  trying file=/usr/local/cuda/extras/CUPTI/lib64/libz.so.1
        51:	  trying file=/usr/local/cuda/lib64/libz.so.1
        51:	 search cache=/etc/ld.so.cache
        51:	  trying file=/lib/x86_64-linux-gnu/libz.so.1
        51:	
        51:	find library=libm.so.6 [0]; searching
        51:	 search path=/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64		(LD_LIBRARY_PATH)
        51:	  trying file=/usr/local/cuda/extras/CUPTI/lib64/libm.so.6
        51:	  trying file=/usr/local/cuda/lib64/libm.so.6
        51:	 search cache=/etc/ld.so.cache
        51:	  trying file=/lib/x86_64-linux-gnu/libm.so.6
        51:	
        51:	
        51:	calling init: /lib/x86_64-linux-gnu/libpthread.so.0
        51:	
        51:	
        51:	calling init: /lib/x86_64-linux-gnu/libc.so.6
        51:	
        51:	
        51:	calling init: /lib/x86_64-linux-gnu/libm.so.6
        51:	
        51:	
        51:	calling init: /lib/x86_64-linux-gnu/libz.so.1
        51:	
        51:	
        51:	calling init: /lib/x86_64-linux-gnu/libexpat.so.1
        51:	
        51:	
        51:	calling init: /lib/x86_64-linux-gnu/libutil.so.1
        51:	
        51:	
        51:	calling init: /lib/x86_64-linux-gnu/libdl.so.2
        51:	
        51:	
        51:	initialize program: /usr/local/bin/python
        51:	
        51:	
        51:	transferring control: /usr/local/bin/python
        51:	
        51:	
        51:	calling init: /usr/lib/python3.6/lib-dynload/_opcode.cpython-36m-x86_64-linux-gnu.so
        51:	
        51:	find library=libffi.so.6 [0]; searching
        51:	 search path=/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64		(LD_LIBRARY_PATH)
        51:	  trying file=/usr/local/cuda/extras/CUPTI/lib64/libffi.so.6
        51:	  trying file=/usr/local/cuda/lib64/libffi.so.6
        51:	 search cache=/etc/ld.so.cache
        51:	  trying file=/usr/lib/x86_64-linux-gnu/libffi.so.6
        51:	
        51:	
        51:	calling init: /usr/lib/x86_64-linux-gnu/libffi.so.6
        51:	
        51:	
        51:	calling init: /usr/lib/python3.6/lib-dynload/_ctypes.cpython-36m-x86_64-linux-gnu.so
        51:	
        51:	find library=libopenblasp-r0-34a18dc3.3.7.so [0]; searching
        51:	 search path=/usr/local/lib/python3.6/dist-packages/numpy/core/../.libs/tls/haswell/x86_64:/usr/local/lib/python3.6/dist-packages/numpy/core/../.libs/tls/haswell:/usr/local/lib/python3.6/dist-packages/numpy/core/../.libs/tls/x86_64:/usr/local/lib/python3.6/dist-packages/numpy/core/../.libs/tls:/usr/local/lib/python3.6/dist-packages/numpy/core/../.libs/haswell/x86_64:/usr/local/lib/python3.6/dist-packages/numpy/core/../.libs/haswell:/usr/local/lib/python3.6/dist-packages/numpy/core/../.libs/x86_64:/usr/local/lib/python3.6/dist-packages/numpy/core/../.libs		(RPATH from file /usr/local/lib/python3.6/dist-packages/numpy/core/_multiarray_umath.cpython-36m-x86_64-linux-gnu.so)
        51:	  trying file=/usr/local/lib/python3.6/dist-packages/numpy/core/../.libs/tls/haswell/x86_64/libopenblasp-r0-34a18dc3.3.7.so
        51:	  trying file=/usr/local/lib/python3.6/dist-packages/numpy/core/../.libs/tls/haswell/libopenblasp-r0-34a18dc3.3.7.so
        51:	  trying file=/usr/local/lib/python3.6/dist-packages/numpy/core/../.libs/tls/x86_64/libopenblasp-r0-34a18dc3.3.7.so
        51:	  trying file=/usr/local/lib/python3.6/dist-packages/numpy/core/../.libs/tls/libopenblasp-r0-34a18dc3.3.7.so
        51:	  trying file=/usr/local/lib/python3.6/dist-packages/numpy/core/../.libs/haswell/x86_64/libopenblasp-r0-34a18dc3.3.7.so
        51:	  trying file=/usr/local/lib/python3.6/dist-packages/numpy/core/../.libs/haswell/libopenblasp-r0-34a18dc3.3.7.so
        51:	  trying file=/usr/local/lib/python3.6/dist-packages/numpy/core/../.libs/x86_64/libopenblasp-r0-34a18dc3.3.7.so
        51:	  trying file=/usr/local/lib/python3.6/dist-packages/numpy/core/../.libs/libopenblasp-r0-34a18dc3.3.7.so
        51:	
        51:	find library=libgfortran-ed201abd.so.3.0.0 [0]; searching
        51:	 search path=/usr/local/lib/python3.6/dist-packages/numpy/core/../.libs		(RPATH from file /usr/local/lib/python3.6/dist-packages/numpy/core/_multiarray_umath.cpython-36m-x86_64-linux-gnu.so)
        51:	  trying file=/usr/local/lib/python3.6/dist-packages/numpy/core/../.libs/libgfortran-ed201abd.so.3.0.0
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/numpy/core/../.libs/libgfortran-ed201abd.so.3.0.0
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/numpy/core/../.libs/libopenblasp-r0-34a18dc3.3.7.so
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/numpy/core/_multiarray_umath.cpython-36m-x86_64-linux-gnu.so
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/numpy/core/_multiarray_tests.cpython-36m-x86_64-linux-gnu.so
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/numpy/linalg/lapack_lite.cpython-36m-x86_64-linux-gnu.so
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/numpy/linalg/_umath_linalg.cpython-36m-x86_64-linux-gnu.so
        51:	
        51:	find library=libbz2.so.1.0 [0]; searching
        51:	 search path=/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64		(LD_LIBRARY_PATH)
        51:	  trying file=/usr/local/cuda/extras/CUPTI/lib64/libbz2.so.1.0
        51:	  trying file=/usr/local/cuda/lib64/libbz2.so.1.0
        51:	 search cache=/etc/ld.so.cache
        51:	  trying file=/lib/x86_64-linux-gnu/libbz2.so.1.0
        51:	
        51:	
        51:	calling init: /lib/x86_64-linux-gnu/libbz2.so.1.0
        51:	
        51:	
        51:	calling init: /usr/lib/python3.6/lib-dynload/_bz2.cpython-36m-x86_64-linux-gnu.so
        51:	
        51:	find library=liblzma.so.5 [0]; searching
        51:	 search path=/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64		(LD_LIBRARY_PATH)
        51:	  trying file=/usr/local/cuda/extras/CUPTI/lib64/liblzma.so.5
        51:	  trying file=/usr/local/cuda/lib64/liblzma.so.5
        51:	 search cache=/etc/ld.so.cache
        51:	  trying file=/lib/x86_64-linux-gnu/liblzma.so.5
        51:	
        51:	
        51:	calling init: /lib/x86_64-linux-gnu/liblzma.so.5
        51:	
        51:	
        51:	calling init: /usr/lib/python3.6/lib-dynload/_lzma.cpython-36m-x86_64-linux-gnu.so
        51:	
        51:	find library=libmpdec.so.2 [0]; searching
        51:	 search path=/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64		(LD_LIBRARY_PATH)
        51:	  trying file=/usr/local/cuda/extras/CUPTI/lib64/libmpdec.so.2
        51:	  trying file=/usr/local/cuda/lib64/libmpdec.so.2
        51:	 search cache=/etc/ld.so.cache
        51:	  trying file=/usr/lib/x86_64-linux-gnu/libmpdec.so.2
        51:	
        51:	
        51:	calling init: /usr/lib/x86_64-linux-gnu/libmpdec.so.2
        51:	
        51:	
        51:	calling init: /usr/lib/python3.6/lib-dynload/_decimal.cpython-36m-x86_64-linux-gnu.so
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/numpy/fft/_pocketfft_internal.cpython-36m-x86_64-linux-gnu.so
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/numpy/random/mtrand.cpython-36m-x86_64-linux-gnu.so
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/numpy/random/_bit_generator.cpython-36m-x86_64-linux-gnu.so
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/numpy/random/_common.cpython-36m-x86_64-linux-gnu.so
        51:	
        51:	find library=libcrypto.so.1.1 [0]; searching
        51:	 search path=/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64		(LD_LIBRARY_PATH)
        51:	  trying file=/usr/local/cuda/extras/CUPTI/lib64/libcrypto.so.1.1
        51:	  trying file=/usr/local/cuda/lib64/libcrypto.so.1.1
        51:	 search cache=/etc/ld.so.cache
        51:	  trying file=/usr/lib/x86_64-linux-gnu/libcrypto.so.1.1
        51:	
        51:	
        51:	calling init: /usr/lib/x86_64-linux-gnu/libcrypto.so.1.1
        51:	
        51:	
        51:	calling init: /usr/lib/python3.6/lib-dynload/_hashlib.cpython-36m-x86_64-linux-gnu.so
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/numpy/random/_bounded_integers.cpython-36m-x86_64-linux-gnu.so
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/numpy/random/_mt19937.cpython-36m-x86_64-linux-gnu.so
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/numpy/random/_philox.cpython-36m-x86_64-linux-gnu.so
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/numpy/random/_pcg64.cpython-36m-x86_64-linux-gnu.so
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/numpy/random/_sfc64.cpython-36m-x86_64-linux-gnu.so
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/numpy/random/_generator.cpython-36m-x86_64-linux-gnu.so
        51:	
        51:	find library=libtensorflow_framework.so.2 [0]; searching
        51:	 search path=/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/../../_solib_local/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal.so___Utensorflow/tls/haswell/x86_64:/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/../../_solib_local/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal.so___Utensorflow/tls/haswell:/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/../../_solib_local/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal.so___Utensorflow/tls/x86_64:/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/../../_solib_local/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal.so___Utensorflow/tls:/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/../../_solib_local/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal.so___Utensorflow/haswell/x86_64:/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/../../_solib_local/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal.so___Utensorflow/haswell:/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/../../_solib_local/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal.so___Utensorflow/x86_64:/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/../../_solib_local/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal.so___Utensorflow:/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tls/haswell/x86_64:/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tls/haswell:/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tls/x86_64:/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tls:/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/haswell/x86_64:/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/haswell:/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/x86_64:/usr/local/lib/python3.6/dist-packages/tensorflow_core/python:/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/../tls/haswell/x86_64:/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/../tls/haswell:/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/../tls/x86_64:/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/../tls:/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/../haswell/x86_64:/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/../haswell:/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/../x86_64:/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/..		(RPATH from file /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/_pywrap_tensorflow_internal.so)
        51:	  trying file=/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/../../_solib_local/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal.so___Utensorflow/tls/haswell/x86_64/libtensorflow_framework.so.2
        51:	  trying file=/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/../../_solib_local/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal.so___Utensorflow/tls/haswell/libtensorflow_framework.so.2
        51:	  trying file=/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/../../_solib_local/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal.so___Utensorflow/tls/x86_64/libtensorflow_framework.so.2
        51:	  trying file=/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/../../_solib_local/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal.so___Utensorflow/tls/libtensorflow_framework.so.2
        51:	  trying file=/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/../../_solib_local/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal.so___Utensorflow/haswell/x86_64/libtensorflow_framework.so.2
        51:	  trying file=/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/../../_solib_local/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal.so___Utensorflow/haswell/libtensorflow_framework.so.2
        51:	  trying file=/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/../../_solib_local/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal.so___Utensorflow/x86_64/libtensorflow_framework.so.2
        51:	  trying file=/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/../../_solib_local/_U_S_Stensorflow_Spython_C_Upywrap_Utensorflow_Uinternal.so___Utensorflow/libtensorflow_framework.so.2
        51:	  trying file=/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tls/haswell/x86_64/libtensorflow_framework.so.2
        51:	  trying file=/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tls/haswell/libtensorflow_framework.so.2
        51:	  trying file=/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tls/x86_64/libtensorflow_framework.so.2
        51:	  trying file=/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tls/libtensorflow_framework.so.2
        51:	  trying file=/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/haswell/x86_64/libtensorflow_framework.so.2
        51:	  trying file=/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/haswell/libtensorflow_framework.so.2
        51:	  trying file=/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/x86_64/libtensorflow_framework.so.2
        51:	  trying file=/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/libtensorflow_framework.so.2
        51:	  trying file=/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/../tls/haswell/x86_64/libtensorflow_framework.so.2
        51:	  trying file=/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/../tls/haswell/libtensorflow_framework.so.2
        51:	  trying file=/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/../tls/x86_64/libtensorflow_framework.so.2
        51:	  trying file=/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/../tls/libtensorflow_framework.so.2
        51:	  trying file=/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/../haswell/x86_64/libtensorflow_framework.so.2
        51:	  trying file=/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/../haswell/libtensorflow_framework.so.2
        51:	  trying file=/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/../x86_64/libtensorflow_framework.so.2
        51:	  trying file=/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/../libtensorflow_framework.so.2
        51:	
        51:	find library=librt.so.1 [0]; searching
        51:	 search path=/usr/local/lib/python3.6/dist-packages/tensorflow_core/python:/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/..		(RPATH from file /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/_pywrap_tensorflow_internal.so)
        51:	  trying file=/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/librt.so.1
        51:	  trying file=/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/../librt.so.1
        51:	 search path=/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64		(LD_LIBRARY_PATH)
        51:	  trying file=/usr/local/cuda/extras/CUPTI/lib64/librt.so.1
        51:	  trying file=/usr/local/cuda/lib64/librt.so.1
        51:	 search cache=/etc/ld.so.cache
        51:	  trying file=/lib/x86_64-linux-gnu/librt.so.1
        51:	
        51:	find library=libstdc++.so.6 [0]; searching
        51:	 search path=/usr/local/lib/python3.6/dist-packages/tensorflow_core/python:/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/..		(RPATH from file /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/_pywrap_tensorflow_internal.so)
        51:	  trying file=/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/libstdc++.so.6
        51:	  trying file=/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/../libstdc++.so.6
        51:	 search path=/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64		(LD_LIBRARY_PATH)
        51:	  trying file=/usr/local/cuda/extras/CUPTI/lib64/libstdc++.so.6
        51:	  trying file=/usr/local/cuda/lib64/libstdc++.so.6
        51:	 search cache=/etc/ld.so.cache
        51:	  trying file=/usr/lib/x86_64-linux-gnu/libstdc++.so.6
        51:	
        51:	find library=libgcc_s.so.1 [0]; searching
        51:	 search path=/usr/local/lib/python3.6/dist-packages/tensorflow_core/python:/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/..		(RPATH from file /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/_pywrap_tensorflow_internal.so)
        51:	  trying file=/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/libgcc_s.so.1
        51:	  trying file=/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/../libgcc_s.so.1
        51:	 search path=/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64		(LD_LIBRARY_PATH)
        51:	  trying file=/usr/local/cuda/extras/CUPTI/lib64/libgcc_s.so.1
        51:	  trying file=/usr/local/cuda/lib64/libgcc_s.so.1
        51:	 search cache=/etc/ld.so.cache
        51:	  trying file=/lib/x86_64-linux-gnu/libgcc_s.so.1
        51:	
        51:	
        51:	calling init: /lib/x86_64-linux-gnu/libgcc_s.so.1
        51:	
        51:	
        51:	calling init: /usr/lib/x86_64-linux-gnu/libstdc++.so.6
        51:	
        51:	
        51:	calling init: /lib/x86_64-linux-gnu/librt.so.1
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/../libtensorflow_framework.so.2
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/_pywrap_tensorflow_internal.so
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/_pywrap_utils.so
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/_pywrap_tfprof.so
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/_pywrap_events_writer.so
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/_pywrap_util_port.so
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/_pywrap_stat_summarizer.so
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/_pywrap_py_exception_registry.so
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/_pywrap_kernel_registry.so
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/_pywrap_quantize_training.so
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/_pywrap_scoped_annotation.so
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/_pywrap_transform_graph.so
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/_pywrap_traceme.so
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/_pywrap_stacktrace_handler.so
        51:	
        51:	
        51:	
        51:	
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/_tf_stack.so
        51:	
        51:	
        51:	calling init: /usr/lib/python3.6/lib-dynload/termios.cpython-36m-x86_64-linux-gnu.so
        51:	
        51:	
        51:	calling init: /usr/lib/python3.6/lib-dynload/_csv.cpython-36m-x86_64-linux-gnu.so
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/wrapt/_wrappers.cpython-36m-x86_64-linux-gnu.so
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/fast_tensor_util.so
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/_op_def_registry.so
        51:	
        51:	find library=libuuid.so.1 [0]; searching
        51:	 search path=/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64		(LD_LIBRARY_PATH)
        51:	  trying file=/usr/local/cuda/extras/CUPTI/lib64/libuuid.so.1
        51:	  trying file=/usr/local/cuda/lib64/libuuid.so.1
        51:	 search cache=/etc/ld.so.cache
        51:	  trying file=/lib/x86_64-linux-gnu/libuuid.so.1
        51:	
        51:	
        51:	calling init: /lib/x86_64-linux-gnu/libuuid.so.1
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/_pywrap_py_func.so
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/_pywrap_checkpoint_reader.so
        51:	
        51:	
        51:	calling init: /usr/lib/python3.6/lib-dynload/_json.cpython-36m-x86_64-linux-gnu.so
        51:	
        51:	find library=libssl.so.1.1 [0]; searching
        51:	 search path=/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64		(LD_LIBRARY_PATH)
        51:	  trying file=/usr/local/cuda/extras/CUPTI/lib64/libssl.so.1.1
        51:	  trying file=/usr/local/cuda/lib64/libssl.so.1.1
        51:	 search cache=/etc/ld.so.cache
        51:	  trying file=/usr/lib/x86_64-linux-gnu/libssl.so.1.1
        51:	
        51:	
        51:	calling init: /usr/lib/x86_64-linux-gnu/libssl.so.1.1
        51:	
        51:	
        51:	calling init: /usr/lib/python3.6/lib-dynload/_ssl.cpython-36m-x86_64-linux-gnu.so
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/_pywrap_device_lib.so
        51:	
        64:	find library=libc.so.6 [0]; searching
        64:	 search path=/usr/local/cuda/extras/CUPTI/lib64/tls/haswell/x86_64:/usr/local/cuda/extras/CUPTI/lib64/tls/haswell:/usr/local/cuda/extras/CUPTI/lib64/tls/x86_64:/usr/local/cuda/extras/CUPTI/lib64/tls:/usr/local/cuda/extras/CUPTI/lib64/haswell/x86_64:/usr/local/cuda/extras/CUPTI/lib64/haswell:/usr/local/cuda/extras/CUPTI/lib64/x86_64:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64/tls/haswell/x86_64:/usr/local/cuda/lib64/tls/haswell:/usr/local/cuda/lib64/tls/x86_64:/usr/local/cuda/lib64/tls:/usr/local/cuda/lib64/haswell/x86_64:/usr/local/cuda/lib64/haswell:/usr/local/cuda/lib64/x86_64:/usr/local/cuda/lib64:/usr/local/nvidia/lib/tls/haswell/x86_64:/usr/local/nvidia/lib/tls/haswell:/usr/local/nvidia/lib/tls/x86_64:/usr/local/nvidia/lib/tls:/usr/local/nvidia/lib/haswell/x86_64:/usr/local/nvidia/lib/haswell:/usr/local/nvidia/lib/x86_64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64/tls/haswell/x86_64:/usr/local/nvidia/lib64/tls/haswell:/usr/local/nvidia/lib64/tls/x86_64:/usr/local/nvidia/lib64/tls:/usr/local/nvidia/lib64/haswell/x86_64:/usr/local/nvidia/lib64/haswell:/usr/local/nvidia/lib64/x86_64:/usr/local/nvidia/lib64		(LD_LIBRARY_PATH)
        64:	  trying file=/usr/local/cuda/extras/CUPTI/lib64/tls/haswell/x86_64/libc.so.6
        64:	  trying file=/usr/local/cuda/extras/CUPTI/lib64/tls/haswell/libc.so.6
        64:	  trying file=/usr/local/cuda/extras/CUPTI/lib64/tls/x86_64/libc.so.6
        64:	  trying file=/usr/local/cuda/extras/CUPTI/lib64/tls/libc.so.6
        64:	  trying file=/usr/local/cuda/extras/CUPTI/lib64/haswell/x86_64/libc.so.6
        64:	  trying file=/usr/local/cuda/extras/CUPTI/lib64/haswell/libc.so.6
        64:	  trying file=/usr/local/cuda/extras/CUPTI/lib64/x86_64/libc.so.6
        64:	  trying file=/usr/local/cuda/extras/CUPTI/lib64/libc.so.6
        64:	  trying file=/usr/local/cuda/lib64/tls/haswell/x86_64/libc.so.6
        64:	  trying file=/usr/local/cuda/lib64/tls/haswell/libc.so.6
        64:	  trying file=/usr/local/cuda/lib64/tls/x86_64/libc.so.6
        64:	  trying file=/usr/local/cuda/lib64/tls/libc.so.6
        64:	  trying file=/usr/local/cuda/lib64/haswell/x86_64/libc.so.6
        64:	  trying file=/usr/local/cuda/lib64/haswell/libc.so.6
        64:	  trying file=/usr/local/cuda/lib64/x86_64/libc.so.6
        64:	  trying file=/usr/local/cuda/lib64/libc.so.6
        64:	  trying file=/usr/local/nvidia/lib/tls/haswell/x86_64/libc.so.6
        64:	  trying file=/usr/local/nvidia/lib/tls/haswell/libc.so.6
        64:	  trying file=/usr/local/nvidia/lib/tls/x86_64/libc.so.6
        64:	  trying file=/usr/local/nvidia/lib/tls/libc.so.6
        64:	  trying file=/usr/local/nvidia/lib/haswell/x86_64/libc.so.6
        64:	  trying file=/usr/local/nvidia/lib/haswell/libc.so.6
        64:	  trying file=/usr/local/nvidia/lib/x86_64/libc.so.6
        64:	  trying file=/usr/local/nvidia/lib/libc.so.6
        64:	  trying file=/usr/local/nvidia/lib64/tls/haswell/x86_64/libc.so.6
        64:	  trying file=/usr/local/nvidia/lib64/tls/haswell/libc.so.6
        64:	  trying file=/usr/local/nvidia/lib64/tls/x86_64/libc.so.6
        64:	  trying file=/usr/local/nvidia/lib64/tls/libc.so.6
        64:	  trying file=/usr/local/nvidia/lib64/haswell/x86_64/libc.so.6
        64:	  trying file=/usr/local/nvidia/lib64/haswell/libc.so.6
        64:	  trying file=/usr/local/nvidia/lib64/x86_64/libc.so.6
        64:	  trying file=/usr/local/nvidia/lib64/libc.so.6
        64:	 search cache=/etc/ld.so.cache
        64:	  trying file=/lib/x86_64-linux-gnu/libc.so.6
        64:	
        64:	
        64:	calling init: /lib/x86_64-linux-gnu/libc.so.6
        64:	
        64:	
        64:	initialize program: /bin/sh
        64:	
        64:	
        64:	transferring control: /bin/sh
        64:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/tensorflow_core/compiler/tf2tensorrt/_wrap_py_utils.so
        51:	
        51:	find library=libnvinfer.so.6 [0]; searching
        51:	 search path=/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/..		(RPATH from file /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/_pywrap_tensorflow_internal.so)
        51:	  trying file=/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/../libnvinfer.so.6
        51:	 search path=/usr/local/lib/python3.6/dist-packages/tensorflow_core/python:/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/..		(RPATH from file /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/_pywrap_tensorflow_internal.so)
        51:	  trying file=/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/libnvinfer.so.6
        51:	  trying file=/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/../libnvinfer.so.6
        51:	 search path=/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64		(LD_LIBRARY_PATH)
        51:	  trying file=/usr/local/cuda/extras/CUPTI/lib64/libnvinfer.so.6
        51:	  trying file=/usr/local/cuda/lib64/libnvinfer.so.6
        51:	 search cache=/etc/ld.so.cache
        51:	  trying file=/usr/lib/x86_64-linux-gnu/libnvinfer.so.6
        51:	
        51:	find library=libcudnn.so.7 [0]; searching
        51:	 search path=/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64		(LD_LIBRARY_PATH)
        51:	  trying file=/usr/local/cuda/extras/CUPTI/lib64/libcudnn.so.7
        51:	  trying file=/usr/local/cuda/lib64/libcudnn.so.7
        51:	 search cache=/etc/ld.so.cache
        51:	  trying file=/usr/lib/x86_64-linux-gnu/libcudnn.so.7
        51:	
        51:	find library=libcublas.so.10 [0]; searching
        51:	 search path=/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64		(LD_LIBRARY_PATH)
        51:	  trying file=/usr/local/cuda/extras/CUPTI/lib64/libcublas.so.10
        51:	  trying file=/usr/local/cuda/lib64/libcublas.so.10
        51:	 search cache=/etc/ld.so.cache
        51:	  trying file=/usr/lib/x86_64-linux-gnu/libcublas.so.10
        51:	
        51:	find library=libcudart.so.10.1 [0]; searching
        51:	 search path=/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64		(LD_LIBRARY_PATH)
        51:	  trying file=/usr/local/cuda/extras/CUPTI/lib64/libcudart.so.10.1
        51:	  trying file=/usr/local/cuda/lib64/libcudart.so.10.1
        51:	
        51:	find library=libcublasLt.so.10 [0]; searching
        51:	 search path=/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64		(LD_LIBRARY_PATH)
        51:	  trying file=/usr/local/cuda/extras/CUPTI/lib64/libcublasLt.so.10
        51:	  trying file=/usr/local/cuda/lib64/libcublasLt.so.10
        51:	 search cache=/etc/ld.so.cache
        51:	  trying file=/usr/lib/x86_64-linux-gnu/libcublasLt.so.10
        51:	
        51:	
        51:	calling init: /usr/lib/x86_64-linux-gnu/libcublasLt.so.10
        51:	
        51:	
        51:	calling init: /usr/local/cuda/lib64/libcudart.so.10.1
        51:	
        51:	
        51:	calling init: /usr/lib/x86_64-linux-gnu/libcublas.so.10
        51:	
        51:	
        51:	calling init: /usr/lib/x86_64-linux-gnu/libcudnn.so.7
        51:	
        51:	
        51:	calling init: /usr/lib/x86_64-linux-gnu/libnvinfer.so.6
        51:	
2020-04-16 05:51:27.539346: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libnvinfer.so.6
        51:	find library=libnvinfer_plugin.so.6 [0]; searching
        51:	 search path=/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/..		(RPATH from file /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/_pywrap_tensorflow_internal.so)
        51:	  trying file=/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/../libnvinfer_plugin.so.6
        51:	 search path=/usr/local/lib/python3.6/dist-packages/tensorflow_core/python:/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/..		(RPATH from file /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/_pywrap_tensorflow_internal.so)
        51:	  trying file=/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/libnvinfer_plugin.so.6
        51:	  trying file=/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/../libnvinfer_plugin.so.6
        51:	 search path=/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64		(LD_LIBRARY_PATH)
        51:	  trying file=/usr/local/cuda/extras/CUPTI/lib64/libnvinfer_plugin.so.6
        51:	  trying file=/usr/local/cuda/lib64/libnvinfer_plugin.so.6
        51:	 search cache=/etc/ld.so.cache
        51:	  trying file=/usr/lib/x86_64-linux-gnu/libnvinfer_plugin.so.6
        51:	
        51:	find library=libnvrtc.so.10.1 [0]; searching
        51:	 search path=/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64		(LD_LIBRARY_PATH)
        51:	  trying file=/usr/local/cuda/extras/CUPTI/lib64/libnvrtc.so.10.1
        51:	  trying file=/usr/local/cuda/lib64/libnvrtc.so.10.1
        51:	
        51:	
        51:	calling init: /usr/local/cuda/lib64/libnvrtc.so.10.1
        51:	
        51:	
        51:	calling init: /usr/lib/x86_64-linux-gnu/libnvinfer_plugin.so.6
        51:	
2020-04-16 05:51:27.540821: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libnvinfer_plugin.so.6
        51:	find library=libhdf5-beac1db3.so.103.0.0 [0]; searching
        51:	 search path=/usr/local/lib/python3.6/dist-packages/h5py/.libs/tls/haswell/x86_64:/usr/local/lib/python3.6/dist-packages/h5py/.libs/tls/haswell:/usr/local/lib/python3.6/dist-packages/h5py/.libs/tls/x86_64:/usr/local/lib/python3.6/dist-packages/h5py/.libs/tls:/usr/local/lib/python3.6/dist-packages/h5py/.libs/haswell/x86_64:/usr/local/lib/python3.6/dist-packages/h5py/.libs/haswell:/usr/local/lib/python3.6/dist-packages/h5py/.libs/x86_64:/usr/local/lib/python3.6/dist-packages/h5py/.libs		(RPATH from file /usr/local/lib/python3.6/dist-packages/h5py/_errors.cpython-36m-x86_64-linux-gnu.so)
        51:	  trying file=/usr/local/lib/python3.6/dist-packages/h5py/.libs/tls/haswell/x86_64/libhdf5-beac1db3.so.103.0.0
        51:	  trying file=/usr/local/lib/python3.6/dist-packages/h5py/.libs/tls/haswell/libhdf5-beac1db3.so.103.0.0
        51:	  trying file=/usr/local/lib/python3.6/dist-packages/h5py/.libs/tls/x86_64/libhdf5-beac1db3.so.103.0.0
        51:	  trying file=/usr/local/lib/python3.6/dist-packages/h5py/.libs/tls/libhdf5-beac1db3.so.103.0.0
        51:	  trying file=/usr/local/lib/python3.6/dist-packages/h5py/.libs/haswell/x86_64/libhdf5-beac1db3.so.103.0.0
        51:	  trying file=/usr/local/lib/python3.6/dist-packages/h5py/.libs/haswell/libhdf5-beac1db3.so.103.0.0
        51:	  trying file=/usr/local/lib/python3.6/dist-packages/h5py/.libs/x86_64/libhdf5-beac1db3.so.103.0.0
        51:	  trying file=/usr/local/lib/python3.6/dist-packages/h5py/.libs/libhdf5-beac1db3.so.103.0.0
        51:	
        51:	find library=libhdf5_hl-db841637.so.100.1.1 [0]; searching
        51:	 search path=/usr/local/lib/python3.6/dist-packages/h5py/.libs		(RPATH from file /usr/local/lib/python3.6/dist-packages/h5py/_errors.cpython-36m-x86_64-linux-gnu.so)
        51:	  trying file=/usr/local/lib/python3.6/dist-packages/h5py/.libs/libhdf5_hl-db841637.so.100.1.1
        51:	
        51:	find library=libsz-1c7dd0cf.so.2.0.1 [0]; searching
        51:	 search path=/usr/local/lib/python3.6/dist-packages/h5py/.libs/./tls/haswell/x86_64:/usr/local/lib/python3.6/dist-packages/h5py/.libs/./tls/haswell:/usr/local/lib/python3.6/dist-packages/h5py/.libs/./tls/x86_64:/usr/local/lib/python3.6/dist-packages/h5py/.libs/./tls:/usr/local/lib/python3.6/dist-packages/h5py/.libs/./haswell/x86_64:/usr/local/lib/python3.6/dist-packages/h5py/.libs/./haswell:/usr/local/lib/python3.6/dist-packages/h5py/.libs/./x86_64:/usr/local/lib/python3.6/dist-packages/h5py/.libs/.		(RPATH from file /usr/local/lib/python3.6/dist-packages/h5py/.libs/libhdf5-beac1db3.so.103.0.0)
        51:	  trying file=/usr/local/lib/python3.6/dist-packages/h5py/.libs/./tls/haswell/x86_64/libsz-1c7dd0cf.so.2.0.1
        51:	  trying file=/usr/local/lib/python3.6/dist-packages/h5py/.libs/./tls/haswell/libsz-1c7dd0cf.so.2.0.1
        51:	  trying file=/usr/local/lib/python3.6/dist-packages/h5py/.libs/./tls/x86_64/libsz-1c7dd0cf.so.2.0.1
        51:	  trying file=/usr/local/lib/python3.6/dist-packages/h5py/.libs/./tls/libsz-1c7dd0cf.so.2.0.1
        51:	  trying file=/usr/local/lib/python3.6/dist-packages/h5py/.libs/./haswell/x86_64/libsz-1c7dd0cf.so.2.0.1
        51:	  trying file=/usr/local/lib/python3.6/dist-packages/h5py/.libs/./haswell/libsz-1c7dd0cf.so.2.0.1
        51:	  trying file=/usr/local/lib/python3.6/dist-packages/h5py/.libs/./x86_64/libsz-1c7dd0cf.so.2.0.1
        51:	  trying file=/usr/local/lib/python3.6/dist-packages/h5py/.libs/./libsz-1c7dd0cf.so.2.0.1
        51:	
        51:	find library=libaec-2147abcd.so.0.0.4 [0]; searching
        51:	 search path=/usr/local/lib/python3.6/dist-packages/h5py/.libs/.		(RPATH from file /usr/local/lib/python3.6/dist-packages/h5py/.libs/libhdf5-beac1db3.so.103.0.0)
        51:	  trying file=/usr/local/lib/python3.6/dist-packages/h5py/.libs/./libaec-2147abcd.so.0.0.4
        51:	
        51:	find library=libz-a147dcb0.so.1.2.3 [0]; searching
        51:	 search path=/usr/local/lib/python3.6/dist-packages/h5py/.libs/.		(RPATH from file /usr/local/lib/python3.6/dist-packages/h5py/.libs/libhdf5-beac1db3.so.103.0.0)
        51:	  trying file=/usr/local/lib/python3.6/dist-packages/h5py/.libs/./libz-a147dcb0.so.1.2.3
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/h5py/.libs/./libz-a147dcb0.so.1.2.3
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/h5py/.libs/./libaec-2147abcd.so.0.0.4
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/h5py/.libs/./libsz-1c7dd0cf.so.2.0.1
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/h5py/.libs/libhdf5-beac1db3.so.103.0.0
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/h5py/.libs/libhdf5_hl-db841637.so.100.1.1
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/h5py/_errors.cpython-36m-x86_64-linux-gnu.so
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/h5py/h5.cpython-36m-x86_64-linux-gnu.so
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/h5py/defs.cpython-36m-x86_64-linux-gnu.so
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/h5py/_objects.cpython-36m-x86_64-linux-gnu.so
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/h5py/_conv.cpython-36m-x86_64-linux-gnu.so
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/h5py/h5r.cpython-36m-x86_64-linux-gnu.so
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/h5py/h5t.cpython-36m-x86_64-linux-gnu.so
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/h5py/utils.cpython-36m-x86_64-linux-gnu.so
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/h5py/h5z.cpython-36m-x86_64-linux-gnu.so
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/h5py/h5a.cpython-36m-x86_64-linux-gnu.so
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/h5py/h5s.cpython-36m-x86_64-linux-gnu.so
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/h5py/h5p.cpython-36m-x86_64-linux-gnu.so
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/h5py/h5ac.cpython-36m-x86_64-linux-gnu.so
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/h5py/_proxy.cpython-36m-x86_64-linux-gnu.so
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/h5py/h5d.cpython-36m-x86_64-linux-gnu.so
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/h5py/h5ds.cpython-36m-x86_64-linux-gnu.so
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/h5py/h5f.cpython-36m-x86_64-linux-gnu.so
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/h5py/h5g.cpython-36m-x86_64-linux-gnu.so
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/h5py/h5i.cpython-36m-x86_64-linux-gnu.so
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/h5py/h5fd.cpython-36m-x86_64-linux-gnu.so
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/h5py/h5pl.cpython-36m-x86_64-linux-gnu.so
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/h5py/h5o.cpython-36m-x86_64-linux-gnu.so
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/h5py/h5l.cpython-36m-x86_64-linux-gnu.so
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/scipy/_lib/_ccallback_c.cpython-36m-x86_64-linux-gnu.so
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/scipy/_lib/_uarray/_uarray.cpython-36m-x86_64-linux-gnu.so
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/scipy/fft/_pocketfft/pypocketfft.cpython-36m-x86_64-linux-gnu.so
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/scipy/sparse/_sparsetools.cpython-36m-x86_64-linux-gnu.so
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/scipy/sparse/_csparsetools.cpython-36m-x86_64-linux-gnu.so
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/scipy/sparse/csgraph/_shortest_path.cpython-36m-x86_64-linux-gnu.so
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/scipy/sparse/csgraph/_tools.cpython-36m-x86_64-linux-gnu.so
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/scipy/sparse/csgraph/_traversal.cpython-36m-x86_64-linux-gnu.so
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/scipy/sparse/csgraph/_min_spanning_tree.cpython-36m-x86_64-linux-gnu.so
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/scipy/sparse/csgraph/_flow.cpython-36m-x86_64-linux-gnu.so
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/scipy/sparse/csgraph/_matching.cpython-36m-x86_64-linux-gnu.so
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/scipy/sparse/csgraph/_reordering.cpython-36m-x86_64-linux-gnu.so
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/pandas/_libs/tslibs/conversion.cpython-36m-x86_64-linux-gnu.so
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/pandas/_libs/tslibs/c_timestamp.cpython-36m-x86_64-linux-gnu.so
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/pandas/_libs/tslibs/nattype.cpython-36m-x86_64-linux-gnu.so
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/pandas/_libs/missing.cpython-36m-x86_64-linux-gnu.so
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/pandas/_libs/tslibs/np_datetime.cpython-36m-x86_64-linux-gnu.so
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/pandas/_libs/ops_dispatch.cpython-36m-x86_64-linux-gnu.so
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/pandas/_libs/tslibs/timezones.cpython-36m-x86_64-linux-gnu.so
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/pandas/_libs/tslibs/tzconversion.cpython-36m-x86_64-linux-gnu.so
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/pandas/_libs/tslibs/timedeltas.cpython-36m-x86_64-linux-gnu.so
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/pandas/_libs/tslibs/offsets.cpython-36m-x86_64-linux-gnu.so
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/pandas/_libs/tslibs/ccalendar.cpython-36m-x86_64-linux-gnu.so
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/pandas/_libs/tslibs/strptime.cpython-36m-x86_64-linux-gnu.so
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/pandas/_libs/tslibs/fields.cpython-36m-x86_64-linux-gnu.so
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/pandas/_libs/tslibs/parsing.cpython-36m-x86_64-linux-gnu.so
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/pandas/_libs/tslibs/frequencies.cpython-36m-x86_64-linux-gnu.so
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/pandas/_libs/tslibs/period.cpython-36m-x86_64-linux-gnu.so
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/pandas/_libs/tslibs/timestamps.cpython-36m-x86_64-linux-gnu.so
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/pandas/_libs/tslibs/resolution.cpython-36m-x86_64-linux-gnu.so
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/pandas/_libs/hashtable.cpython-36m-x86_64-linux-gnu.so
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/pandas/_libs/lib.cpython-36m-x86_64-linux-gnu.so
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/pandas/_libs/tslib.cpython-36m-x86_64-linux-gnu.so
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/pandas/_libs/interval.cpython-36m-x86_64-linux-gnu.so
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/pandas/_libs/algos.cpython-36m-x86_64-linux-gnu.so
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/pandas/_libs/properties.cpython-36m-x86_64-linux-gnu.so
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/pandas/_libs/hashing.cpython-36m-x86_64-linux-gnu.so
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/pandas/_libs/ops.cpython-36m-x86_64-linux-gnu.so
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/pandas/_libs/index.cpython-36m-x86_64-linux-gnu.so
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/pandas/_libs/join.cpython-36m-x86_64-linux-gnu.so
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/pandas/_libs/sparse.cpython-36m-x86_64-linux-gnu.so
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/pandas/_libs/indexing.cpython-36m-x86_64-linux-gnu.so
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/pandas/_libs/writers.cpython-36m-x86_64-linux-gnu.so
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/pandas/_libs/internals.cpython-36m-x86_64-linux-gnu.so
        51:	
        51:	
        51:	calling init: /usr/lib/python3.6/lib-dynload/mmap.cpython-36m-x86_64-linux-gnu.so
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/pandas/_libs/reshape.cpython-36m-x86_64-linux-gnu.so
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/pandas/_libs/window/aggregations.cpython-36m-x86_64-linux-gnu.so
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/pandas/_libs/window/indexers.cpython-36m-x86_64-linux-gnu.so
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/pandas/_libs/groupby.cpython-36m-x86_64-linux-gnu.so
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/pandas/_libs/reduction.cpython-36m-x86_64-linux-gnu.so
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/pandas/_libs/parsers.cpython-36m-x86_64-linux-gnu.so
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/pandas/_libs/json.cpython-36m-x86_64-linux-gnu.so
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/pandas/_libs/testing.cpython-36m-x86_64-linux-gnu.so
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/_pywrap_debug_events_writer.so
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/tensorflow_core/lite/experimental/microfrontend/python/ops/_audio_microfrontend_op.so
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/_pywrap_toco_api.so
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/scipy/ndimage/_nd_image.cpython-36m-x86_64-linux-gnu.so
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/scipy/ndimage/_ni_label.cpython-36m-x86_64-linux-gnu.so
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/scipy/linalg/_fblas.cpython-36m-x86_64-linux-gnu.so
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/scipy/linalg/_flapack.cpython-36m-x86_64-linux-gnu.so
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/scipy/linalg/_flinalg.cpython-36m-x86_64-linux-gnu.so
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/scipy/linalg/_solve_toeplitz.cpython-36m-x86_64-linux-gnu.so
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/scipy/linalg/_decomp_update.cpython-36m-x86_64-linux-gnu.so
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/scipy/linalg/cython_blas.cpython-36m-x86_64-linux-gnu.so
        51:	
        51:	
        51:	calling init: /usr/local/lib/python3.6/dist-packages/scipy/linalg/cython_lapack.cpython-36m-x86_64-linux-gnu.so
        51:	
        51:	
        51:	calling fini: /usr/local/bin/python [0]
        51:	
        51:	
        51:	calling fini: /lib/x86_64-linux-gnu/libutil.so.1 [0]
        51:	
        51:	
        51:	calling fini: /lib/x86_64-linux-gnu/libexpat.so.1 [0]
        51:	
        51:	
        51:	calling fini: /lib/x86_64-linux-gnu/libz.so.1 [0]
        51:	
        51:	
        51:	calling fini: /usr/lib/python3.6/lib-dynload/_opcode.cpython-36m-x86_64-linux-gnu.so [0]
        51:	
        51:	
        51:	calling fini: /usr/lib/python3.6/lib-dynload/_ctypes.cpython-36m-x86_64-linux-gnu.so [0]
        51:	
        51:	
        51:	calling fini: /usr/lib/x86_64-linux-gnu/libffi.so.6 [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/numpy/core/_multiarray_umath.cpython-36m-x86_64-linux-gnu.so [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/numpy/core/_multiarray_tests.cpython-36m-x86_64-linux-gnu.so [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/numpy/linalg/lapack_lite.cpython-36m-x86_64-linux-gnu.so [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/numpy/linalg/_umath_linalg.cpython-36m-x86_64-linux-gnu.so [0]
        51:	
        51:	
        51:	calling fini: /usr/lib/python3.6/lib-dynload/_bz2.cpython-36m-x86_64-linux-gnu.so [0]
        51:	
        51:	
        51:	calling fini: /lib/x86_64-linux-gnu/libbz2.so.1.0 [0]
        51:	
        51:	
        51:	calling fini: /usr/lib/python3.6/lib-dynload/_lzma.cpython-36m-x86_64-linux-gnu.so [0]
        51:	
        51:	
        51:	calling fini: /lib/x86_64-linux-gnu/liblzma.so.5 [0]
        51:	
        51:	
        51:	calling fini: /usr/lib/python3.6/lib-dynload/_decimal.cpython-36m-x86_64-linux-gnu.so [0]
        51:	
        51:	
        51:	calling fini: /usr/lib/x86_64-linux-gnu/libmpdec.so.2 [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/numpy/fft/_pocketfft_internal.cpython-36m-x86_64-linux-gnu.so [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/numpy/random/mtrand.cpython-36m-x86_64-linux-gnu.so [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/numpy/random/_bit_generator.cpython-36m-x86_64-linux-gnu.so [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/numpy/random/_common.cpython-36m-x86_64-linux-gnu.so [0]
        51:	
        51:	
        51:	calling fini: /usr/lib/python3.6/lib-dynload/_hashlib.cpython-36m-x86_64-linux-gnu.so [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/numpy/random/_bounded_integers.cpython-36m-x86_64-linux-gnu.so [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/numpy/random/_mt19937.cpython-36m-x86_64-linux-gnu.so [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/numpy/random/_philox.cpython-36m-x86_64-linux-gnu.so [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/numpy/random/_pcg64.cpython-36m-x86_64-linux-gnu.so [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/numpy/random/_sfc64.cpython-36m-x86_64-linux-gnu.so [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/numpy/random/_generator.cpython-36m-x86_64-linux-gnu.so [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/_pywrap_utils.so [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/_pywrap_tfprof.so [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/_pywrap_events_writer.so [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/_pywrap_util_port.so [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/_pywrap_stat_summarizer.so [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/_pywrap_py_exception_registry.so [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/_pywrap_kernel_registry.so [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/_pywrap_quantize_training.so [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/_pywrap_scoped_annotation.so [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/_pywrap_transform_graph.so [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/_pywrap_traceme.so [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/_pywrap_stacktrace_handler.so [0]
        51:	
        51:	
        51:	
        51:	
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/_tf_stack.so [0]
        51:	
        51:	
        51:	calling fini: /usr/lib/python3.6/lib-dynload/termios.cpython-36m-x86_64-linux-gnu.so [0]
        51:	
        51:	
        51:	calling fini: /usr/lib/python3.6/lib-dynload/_csv.cpython-36m-x86_64-linux-gnu.so [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/wrapt/_wrappers.cpython-36m-x86_64-linux-gnu.so [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/fast_tensor_util.so [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/_op_def_registry.so [0]
        51:	
        51:	
        51:	calling fini: /lib/x86_64-linux-gnu/libuuid.so.1 [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/_pywrap_py_func.so [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/_pywrap_checkpoint_reader.so [0]
        51:	
        51:	
        51:	calling fini: /usr/lib/python3.6/lib-dynload/_json.cpython-36m-x86_64-linux-gnu.so [0]
        51:	
        51:	
        51:	calling fini: /usr/lib/python3.6/lib-dynload/_ssl.cpython-36m-x86_64-linux-gnu.so [0]
        51:	
        51:	
        51:	calling fini: /usr/lib/x86_64-linux-gnu/libssl.so.1.1 [0]
        51:	
        51:	
        51:	calling fini: /usr/lib/x86_64-linux-gnu/libcrypto.so.1.1 [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/_pywrap_device_lib.so [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/tensorflow_core/compiler/tf2tensorrt/_wrap_py_utils.so [0]
        51:	
        51:	
        51:	calling fini: /usr/lib/x86_64-linux-gnu/libnvinfer_plugin.so.6 [0]
        51:	
        51:	
        51:	calling fini: /usr/lib/x86_64-linux-gnu/libnvinfer.so.6 [0]
        51:	
        51:	
        51:	calling fini: /usr/local/cuda/lib64/libcudart.so.10.1 [0]
        51:	
        51:	
        51:	calling fini: /usr/lib/x86_64-linux-gnu/libcublas.so.10 [0]
        51:	
        51:	
        51:	calling fini: /usr/lib/x86_64-linux-gnu/libcublasLt.so.10 [0]
        51:	
        51:	
        51:	calling fini: /usr/lib/x86_64-linux-gnu/libcudnn.so.7 [0]
        51:	
        51:	
        51:	calling fini: /usr/local/cuda/lib64/libnvrtc.so.10.1 [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/h5py/_errors.cpython-36m-x86_64-linux-gnu.so [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/h5py/h5.cpython-36m-x86_64-linux-gnu.so [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/h5py/defs.cpython-36m-x86_64-linux-gnu.so [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/h5py/_objects.cpython-36m-x86_64-linux-gnu.so [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/h5py/_conv.cpython-36m-x86_64-linux-gnu.so [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/h5py/h5r.cpython-36m-x86_64-linux-gnu.so [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/h5py/h5t.cpython-36m-x86_64-linux-gnu.so [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/h5py/utils.cpython-36m-x86_64-linux-gnu.so [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/h5py/h5z.cpython-36m-x86_64-linux-gnu.so [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/h5py/h5a.cpython-36m-x86_64-linux-gnu.so [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/h5py/h5s.cpython-36m-x86_64-linux-gnu.so [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/h5py/h5p.cpython-36m-x86_64-linux-gnu.so [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/h5py/h5ac.cpython-36m-x86_64-linux-gnu.so [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/h5py/_proxy.cpython-36m-x86_64-linux-gnu.so [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/h5py/h5d.cpython-36m-x86_64-linux-gnu.so [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/h5py/h5ds.cpython-36m-x86_64-linux-gnu.so [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/h5py/h5f.cpython-36m-x86_64-linux-gnu.so [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/h5py/h5g.cpython-36m-x86_64-linux-gnu.so [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/h5py/h5i.cpython-36m-x86_64-linux-gnu.so [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/h5py/h5fd.cpython-36m-x86_64-linux-gnu.so [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/h5py/h5pl.cpython-36m-x86_64-linux-gnu.so [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/h5py/h5o.cpython-36m-x86_64-linux-gnu.so [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/h5py/h5l.cpython-36m-x86_64-linux-gnu.so [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/h5py/.libs/libhdf5_hl-db841637.so.100.1.1 [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/h5py/.libs/libhdf5-beac1db3.so.103.0.0 [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/h5py/.libs/./libz-a147dcb0.so.1.2.3 [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/h5py/.libs/./libsz-1c7dd0cf.so.2.0.1 [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/h5py/.libs/./libaec-2147abcd.so.0.0.4 [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/scipy/_lib/_ccallback_c.cpython-36m-x86_64-linux-gnu.so [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/scipy/_lib/_uarray/_uarray.cpython-36m-x86_64-linux-gnu.so [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/scipy/fft/_pocketfft/pypocketfft.cpython-36m-x86_64-linux-gnu.so [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/scipy/sparse/_sparsetools.cpython-36m-x86_64-linux-gnu.so [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/scipy/sparse/_csparsetools.cpython-36m-x86_64-linux-gnu.so [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/scipy/sparse/csgraph/_shortest_path.cpython-36m-x86_64-linux-gnu.so [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/scipy/sparse/csgraph/_tools.cpython-36m-x86_64-linux-gnu.so [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/scipy/sparse/csgraph/_traversal.cpython-36m-x86_64-linux-gnu.so [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/scipy/sparse/csgraph/_min_spanning_tree.cpython-36m-x86_64-linux-gnu.so [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/scipy/sparse/csgraph/_flow.cpython-36m-x86_64-linux-gnu.so [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/scipy/sparse/csgraph/_matching.cpython-36m-x86_64-linux-gnu.so [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/scipy/sparse/csgraph/_reordering.cpython-36m-x86_64-linux-gnu.so [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/pandas/_libs/tslibs/conversion.cpython-36m-x86_64-linux-gnu.so [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/pandas/_libs/tslibs/c_timestamp.cpython-36m-x86_64-linux-gnu.so [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/pandas/_libs/tslibs/nattype.cpython-36m-x86_64-linux-gnu.so [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/pandas/_libs/missing.cpython-36m-x86_64-linux-gnu.so [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/pandas/_libs/tslibs/np_datetime.cpython-36m-x86_64-linux-gnu.so [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/pandas/_libs/ops_dispatch.cpython-36m-x86_64-linux-gnu.so [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/pandas/_libs/tslibs/timezones.cpython-36m-x86_64-linux-gnu.so [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/pandas/_libs/tslibs/tzconversion.cpython-36m-x86_64-linux-gnu.so [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/pandas/_libs/tslibs/timedeltas.cpython-36m-x86_64-linux-gnu.so [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/pandas/_libs/tslibs/offsets.cpython-36m-x86_64-linux-gnu.so [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/pandas/_libs/tslibs/ccalendar.cpython-36m-x86_64-linux-gnu.so [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/pandas/_libs/tslibs/strptime.cpython-36m-x86_64-linux-gnu.so [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/pandas/_libs/tslibs/fields.cpython-36m-x86_64-linux-gnu.so [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/pandas/_libs/tslibs/parsing.cpython-36m-x86_64-linux-gnu.so [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/pandas/_libs/tslibs/frequencies.cpython-36m-x86_64-linux-gnu.so [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/pandas/_libs/tslibs/period.cpython-36m-x86_64-linux-gnu.so [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/pandas/_libs/tslibs/timestamps.cpython-36m-x86_64-linux-gnu.so [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/pandas/_libs/tslibs/resolution.cpython-36m-x86_64-linux-gnu.so [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/pandas/_libs/hashtable.cpython-36m-x86_64-linux-gnu.so [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/pandas/_libs/lib.cpython-36m-x86_64-linux-gnu.so [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/pandas/_libs/tslib.cpython-36m-x86_64-linux-gnu.so [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/pandas/_libs/interval.cpython-36m-x86_64-linux-gnu.so [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/pandas/_libs/algos.cpython-36m-x86_64-linux-gnu.so [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/pandas/_libs/properties.cpython-36m-x86_64-linux-gnu.so [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/pandas/_libs/hashing.cpython-36m-x86_64-linux-gnu.so [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/pandas/_libs/ops.cpython-36m-x86_64-linux-gnu.so [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/pandas/_libs/index.cpython-36m-x86_64-linux-gnu.so [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/pandas/_libs/join.cpython-36m-x86_64-linux-gnu.so [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/pandas/_libs/sparse.cpython-36m-x86_64-linux-gnu.so [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/pandas/_libs/indexing.cpython-36m-x86_64-linux-gnu.so [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/pandas/_libs/writers.cpython-36m-x86_64-linux-gnu.so [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/pandas/_libs/internals.cpython-36m-x86_64-linux-gnu.so [0]
        51:	
        51:	
        51:	calling fini: /usr/lib/python3.6/lib-dynload/mmap.cpython-36m-x86_64-linux-gnu.so [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/pandas/_libs/reshape.cpython-36m-x86_64-linux-gnu.so [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/pandas/_libs/window/aggregations.cpython-36m-x86_64-linux-gnu.so [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/pandas/_libs/window/indexers.cpython-36m-x86_64-linux-gnu.so [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/pandas/_libs/groupby.cpython-36m-x86_64-linux-gnu.so [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/pandas/_libs/reduction.cpython-36m-x86_64-linux-gnu.so [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/pandas/_libs/parsers.cpython-36m-x86_64-linux-gnu.so [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/pandas/_libs/json.cpython-36m-x86_64-linux-gnu.so [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/pandas/_libs/testing.cpython-36m-x86_64-linux-gnu.so [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/_pywrap_debug_events_writer.so [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/tensorflow_core/lite/experimental/microfrontend/python/ops/_audio_microfrontend_op.so [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/_pywrap_toco_api.so [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/_pywrap_tensorflow_internal.so [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/../libtensorflow_framework.so.2 [0]
        51:	
        51:	
        51:	calling fini: /usr/lib/x86_64-linux-gnu/libstdc++.so.6 [0]
        51:	
        51:	
        51:	calling fini: /lib/x86_64-linux-gnu/librt.so.1 [0]
        51:	
        51:	
        51:	calling fini: /lib/x86_64-linux-gnu/libdl.so.2 [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/scipy/ndimage/_nd_image.cpython-36m-x86_64-linux-gnu.so [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/scipy/ndimage/_ni_label.cpython-36m-x86_64-linux-gnu.so [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/scipy/linalg/_fblas.cpython-36m-x86_64-linux-gnu.so [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/scipy/linalg/_flapack.cpython-36m-x86_64-linux-gnu.so [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/scipy/linalg/_flinalg.cpython-36m-x86_64-linux-gnu.so [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/scipy/linalg/_solve_toeplitz.cpython-36m-x86_64-linux-gnu.so [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/scipy/linalg/_decomp_update.cpython-36m-x86_64-linux-gnu.so [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/scipy/linalg/cython_blas.cpython-36m-x86_64-linux-gnu.so [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/scipy/linalg/cython_lapack.cpython-36m-x86_64-linux-gnu.so [0]
        51:	
        51:	
        51:	calling fini: /lib/x86_64-linux-gnu/libgcc_s.so.1 [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/numpy/core/../.libs/libopenblasp-r0-34a18dc3.3.7.so [0]
        51:	
        51:	
        51:	calling fini: /usr/local/lib/python3.6/dist-packages/numpy/core/../.libs/libgfortran-ed201abd.so.3.0.0 [0]
        51:	
        51:	
        51:	calling fini: /lib/x86_64-linux-gnu/libm.so.6 [0]
        51:	
        51:	
        51:	calling fini: /lib/x86_64-linux-gnu/libpthread.so.0 [0]
        51:	

== env ==========================================================
LD_LIBRARY_PATH /usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64
DYLD_LIBRARY_PATH is unset

== nvidia-smi ===================================================
./env.sh: line 147: nvidia-smi: command not found

== cuda libs  ===================================================
/usr/local/cuda-10.1/targets/x86_64-linux/lib/libcudart.so.10.1.243
/usr/local/cuda-10.1/targets/x86_64-linux/lib/libcudart_static.a

== tensorflow installed from info ==================

== python version  ==============================================
(major, minor, micro, releaselevel, serial)
(3, 6, 9, 'final', 0)

== bazel version  ===============================================


</details>

**Describe the current behavior**
When using a `TimeDistributed` keras layer on another layer that contains a `tensorflow.keras.layers.experimental.preprocessing.TextVectorization` layer, it throws a reshape error on the `fit`
Increasing the dim of the output of the inner model only increases the dim target meaning it can never be satisfied


```
2.1.0
2020-04-16 13:54:14.323367: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
2020-04-16 13:54:14.343838: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3599380000 Hz
2020-04-16 13:54:14.344417: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5621dd30ec50 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-04-16 13:54:14.344440: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-04-16 13:54:14.344528: I tensorflow/core/common_runtime/process_util.cc:147] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
WARNING:tensorflow:AutoGraph could not transform <function split_text at 0x7f92eb2bee50> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: invalid value for ""node"": expected ""ast.AST"", got ""<class 'NoneType'>""; to visit lists of nodes, use ""visit_block"" instead
Train on 5 samples
2020-04-16 13:54:16.161612: W tensorflow/core/common_runtime/base_collective_executor.cc:217] BaseCollectiveExecutor::StartAbort Invalid argument: Input to reshape is a tensor with 1280 values, but the requested shape requires a multiple of 2560
         [[{{node model_1/flatten/Reshape}}]]
5/5 [==============================] - 1s 261ms/sample
Traceback (most recent call last):
  File ""/home/me/.vscode/extensions/ms-python.python-2020.3.71659/pythonFiles/ptvsd_launcher.py"", line 48, in <module>
    main(ptvsdArgs)
  File ""/home/me/.vscode/extensions/ms-python.python-2020.3.71659/pythonFiles/lib/python/old_ptvsd/ptvsd/__main__.py"", line 432, in main
    run()
  File ""/home/me/.vscode/extensions/ms-python.python-2020.3.71659/pythonFiles/lib/python/old_ptvsd/ptvsd/__main__.py"", line 316, in run_file
    runpy.run_path(target, run_name='__main__')
  File ""/usr/lib/python3.8/runpy.py"", line 263, in run_path
    return _run_module_code(code, init_globals, run_name,
  File ""/usr/lib/python3.8/runpy.py"", line 96, in _run_module_code
    _run_code(code, mod_globals, init_globals,
  File ""/usr/lib/python3.8/runpy.py"", line 86, in _run_code
    exec(code, run_globals)
  File ""/home/me/Documents/projects/nowhere/src/trainer/testo.py"", line 65, in <module>
    model.fit({""a"": np.array([""heasdasdre"", ""is somdfas"", ""dfae "", ""mads d!"", ""asd dfa%# 12""]),
  File ""/usr/lib/python3.8/site-packages/tensorflow_core/python/keras/engine/training.py"", line 800, in fit
    return func.fit(
  File ""/usr/lib/python3.8/site-packages/tensorflow_core/python/keras/engine/training_v2.py"", line 331, in fit
    training_result = run_one_epoch(
  File ""/usr/lib/python3.8/site-packages/tensorflow_core/python/keras/engine/training_v2.py"", line 128, in run_one_epoch
    batch_outs = execution_function(iterator)
  File ""/usr/lib/python3.8/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py"", line 98, in execution_function
    distributed_function(input_fn))
  File ""/usr/lib/python3.8/site-packages/tensorflow_core/python/eager/def_function.py"", line 568, in __call__
    result = self._call(*args, **kwds)
  File ""/usr/lib/python3.8/site-packages/tensorflow_core/python/eager/def_function.py"", line 632, in _call
    return self._stateless_fn(*args, **kwds)
  File ""/usr/lib/python3.8/site-packages/tensorflow_core/python/eager/function.py"", line 2363, in __call__
    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access
  File ""/usr/lib/python3.8/site-packages/tensorflow_core/python/eager/function.py"", line 1607, in _filtered_call
    return self._call_flat(
  File ""/usr/lib/python3.8/site-packages/tensorflow_core/python/eager/function.py"", line 1691, in _call_flat
    return self._build_call_outputs(self._inference_function.call(
  File ""/usr/lib/python3.8/site-packages/tensorflow_core/python/eager/function.py"", line 540, in call
    outputs = execute.execute(
  File ""/usr/lib/python3.8/site-packages/tensorflow_core/python/eager/execute.py"", line 67, in quick_execute
    six.raise_from(core._status_to_exception(e.code, message), None)
  File ""<string>"", line 3, in raise_from
tensorflow.python.framework.errors_impl.InvalidArgumentError:  Input to reshape is a tensor with 1280 values, but the requested shape requires a multiple of 2560
         [[node model_1/flatten/Reshape (defined at home/me/Documents/projects/nowhere/src/trainer/testo.py:65) ]] [Op:__inference_distributed_function_1688]

Function call stack:
distributed_function
```

**Standalone code to reproduce the issue** 


``` py
from tensorflow.keras import layers
import tensorflow as tf
import numpy as np
from tensorflow.keras.layers.experimental.preprocessing import TextVectorization
from tensorflow.keras import layers

print(tf.__version__)

# Model constants.
embedding_dim = 128
CHAR_DICT = 'abcdefghijklmnopqrstuvwxyz0123456789 .!?:,\'%-\(\)/$|&;[]""'


@tf.keras.utils.register_keras_serializable(package='Custom', name='l1')
@tf.function
def split_text(text_list: list):
    joined = tf.strings.reduce_join(text_list)
    split = tf.strings.split(joined, sep="""")
    return tf.expand_dims(split, 0)


def vectorize_layers(factor, time_dims):
    embedding_dim = 128
    text_input = layers.Input(shape=(1,), dtype=tf.string)
    vectorize_layer = TextVectorization(
        split=split_text,
        max_tokens=len(CHAR_DICT) + 1,
        output_mode='int',
        output_sequence_length=128)

    vectorize_layer.set_vocabulary(list(CHAR_DICT))
    x = vectorize_layer(text_input)
    x = layers.Embedding(len(CHAR_DICT) + 1, embedding_dim)(x)
    x = layers.Dense(factor, activation='relu')(x)
    x = layers.Dropout(0.2)(x)
    model = tf.keras.Model(inputs=text_input, outputs=x)
    return model


def build_model(input_labels, factor):
    inputs = []
    mergers = []
    for label in input_labels:
        text_input = tf.keras.Input(shape=(1,), dtype=tf.string, name=label)
        inputs.append(text_input)
        mergers.append(text_input)

    x = layers.Concatenate()(mergers)
    x = tf.expand_dims(x, axis=-1)
    x = layers.TimeDistributed(vectorize_layers(factor, len(input_labels)))(x)
    x = layers.Flatten()(x)
    x = layers.Dense(factor)(x)
    x = layers.Dense(1, activation='sigmoid', name='predictions')(x)
    model = tf.keras.Model(inputs=inputs, outputs=x)
    return model


model = build_model([""a"", ""b""], 10)
# model.save(""/tmp/asd"")

# Compile the model with binary crossentropy loss and an adam optimizer.
model.compile(
    loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

model.fit({""a"": np.array([""heasdasdre"", ""is somdfas"", ""dfae "", ""mads d!"", ""asd dfa%# 12""]),
           ""b"": np.array([""asagda gdaasdfasd fgaewgasdg"", ""asd"", ""asdfasd,%#"", ""dasd"", ""asdasfg""])},
          np.array([0.1, 0.5, 0.4, 0.6, 0.3]))

print(model.predict({""a"": [""here is some mad dog shit right ere boiz!""], ""b"": [""asdagaewgasdg""]}))


```

**Describe the expected behavior**

The fit function should work

Here is the same code but without the `TextVectorize` layer using just floats and it works fine

``` py

from tensorflow.keras import layers
import tensorflow as tf
import numpy as np
from tensorflow.keras.layers.experimental.preprocessing import TextVectorization
from tensorflow.keras import layers

print(tf.__version__)

# Model constants.
embedding_dim = 128
CHAR_DICT = 'abcdefghijklmnopqrstuvwxyz0123456789 .!?:,\'%-\(\)/$|&;[]""'


@tf.keras.utils.register_keras_serializable(package='Custom', name='l1')
@tf.function
def split_text(text_list: list):
    joined = tf.strings.reduce_join(text_list)
    split = tf.strings.split(joined, sep="""")
    return tf.expand_dims(split, 0)


def vectorize_layers(factor, time_dims):
    embedding_dim = 128
    text_input = layers.Input(shape=(1))
    # text_input = layers.Input(shape=(1,), dtype=tf.string)
    # vectorize_layer = TextVectorization(
    #     split=split_text,
    #     max_tokens=len(CHAR_DICT) + 1,
    #     output_mode='int',
    #     output_sequence_length=128)

    # vectorize_layer.set_vocabulary(list(CHAR_DICT))
    # x = vectorize_layer(text_input)
    x = layers.Embedding(len(CHAR_DICT) + 1, embedding_dim)(text_input)
    x = layers.Dense(factor, activation='relu')(x)
    x = layers.Dropout(0.2)(x)
    model = tf.keras.Model(inputs=text_input, outputs=x)
    return model


def build_model(input_labels, factor):
    inputs = []
    mergers = []
    for label in input_labels:
        text_input = tf.keras.Input(shape=(1,), dtype=tf.float32, name=label)
        inputs.append(text_input)
        mergers.append(text_input)

    x = layers.Concatenate()(mergers)
    x = tf.expand_dims(x, axis=-1)
    x = layers.TimeDistributed(vectorize_layers(factor, len(input_labels)))(x)
    x = layers.Flatten()(x)
    x = layers.Dense(factor)(x)
    x = layers.Dense(1, activation='sigmoid', name='predictions')(x)
    model = tf.keras.Model(inputs=inputs, outputs=x)
    return model


model = build_model([""a"", ""b""], 10)
# model.save(""/tmp/asd"")

# Compile the model with binary crossentropy loss and an adam optimizer.
model.compile(
    loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

model.fit({""a"": np.array([4, 5, 6, 6, 7], dtype=np.float),
           ""b"": np.array([6, 4, 2, 1, 0], dtype=np.float)},
          np.array([0.1, 0.5, 0.4, 0.6, 0.3], dtype=np.float))

print(model.predict({""a"": np.array([2.5], dtype=np.float), ""b"": np.array([2.5], dtype=np.float)}))


```


**Other info / logs** 

Dockerfile

```

# FROM tensorflow/tensorflow:nightly-gpu-py3
FROM tensorflow/tensorflow:latest-gpu-py3
ENV DEBIAN_FRONTEND noninteractive 
RUN export DEBIAN_FRONTEND=""noninteractive""
# RUN apt-get update && apt-get install -y python3 python3-matplotlib python3-pandas python3-pip
RUN export PIP_DEFAULT_TIMEOUT=100 
RUN pip install --upgrade pip
RUN pip install psycopg2-binary
RUN pip install SQLAlchemy
RUN pip install pandas
RUN pip install matplotlib
RUN pip install keras
RUN pip install scikit-learn

WORKDIR /app
VOLUME /app


```
"
38589,AttributeError: module 'tensorflow.python.framework.ops' has no attribute '_TensorLike',"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:not applicable
- TensorFlow installed from (source or binary):binary (pip3 install tensorflow)
- TensorFlow version: 2.2.0-dev20200409
- Python version: 3.6.9
- Installed using virtualenv? pip? conda?: pip
- Bazel version (if compiling from source): na
- GCC/Compiler version (if compiling from source):7.5.0
- CUDA/cuDNN version: Cuda10.2/cuDNN 7.6.5
- GPU model and memory:GeForce GTX 1060/6GB



**Describe the problem**
Below is the issue with tensorflow when a specific model is executed. 

Using TensorFlow backend.
2020-04-16 10:54:20.595255: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
Patch extracted
Traceback (most recent call last):
  File ""train_retina.py"", line 38, in <module>
    model = M.BCDU_net_D3(input_size = (64,64,1))
  File ""/home/sandbox/vissu/image_segmentation/BCDU-Net/Retina Blood Vessel Segmentation/models.py"", line 17, in BCDU_net_D3
    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)
  File ""/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py"", line 76, in symbolic_fn_wrapper
    return func(*args, **kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/keras/engine/base_layer.py"", line 446, in __call__
    self.assert_input_compatibility(inputs)
  File ""/usr/local/lib/python3.6/dist-packages/keras/engine/base_layer.py"", line 310, in assert_input_compatibility
    K.is_keras_tensor(x)
  File ""/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py"", line 696, in is_keras_tensor
    if not is_tensor(x):
  File ""/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py"", line 704, in is_tensor
    return isinstance(x, tf_ops._TensorLike) or tf_ops.is_dense_tensor_like(x)
AttributeError: module 'tensorflow.python.framework.ops' has no attribute '_TensorLike'

Also referred   other open issues, but there is no solution out there. 

**Provide the exact sequence of commands / steps that you executed before running into the problem**
when running an example of BCDU-Net model. 

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
38588,TF API Feature transformation to saved model from checkpoint file ,"OS Platform and Distribution : macOS Catalina 10.15.3

TensorFlow installed from : binary

TensorFlow version : 1.15.0

Python version: 3.7.3


**Describe the current behavior**

I have general question , i have checkpoint file which was converted to  .pb file  using https://stackoverflow.com/questions/56766639/how-to-convert-ckpt-to-pb , however is there any way in the code in this link we can port feature transformation into saved model ?

I already have code to convert feature transformation to TF API  ? 

Also can we get example of this - https://cloud.google.com/ai-platform/prediction/docs/exporting-savedmodel-for-prediction#create_serving_graph_separately_from_training , its not very clear from docs

I basically have checkpoint file and what to convert that into .pb file with feature transformation part of it . I already have code for converting to feature using TF API .
"
38583,Tf.function raises TypeError,"**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04): Linux Ubuntu 16.04
- TensorFlow installed from (source or
binary): pip
- TensorFlow version (use command below): v2.1.0-rc2-17-ge5bf8de 2.1.0
- Python version: 3
- CUDA/cuDNN version: - GPU model and memory: Tesla v100

**Describe the current behavior**
When running the code attached below (it's from https://github.com/titu1994/keras-attention-augmented-convs) it crashes with the trace attached at the bottom. But When I remove the @tf.function annotation, it works.



**Describe the expected behavior**

I would expect that the annotation does not make the program crash.

**Standalone code to reproduce the issue** 
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.


```
import tensorflow as tf
from tensorflow.keras.layers import Layer
from tensorflow.keras.layers import Conv2D
from tensorflow.keras.layers import BatchNormalization
from tensorflow.keras.layers import concatenate
from tensorflow.keras import initializers
import tensorflow.keras.backend as K


def _conv_layer(filters, kernel_size, strides=(1, 1), padding='same', name=None):
    return Conv2D(filters, kernel_size, strides=strides, padding=padding,
                  use_bias=True, kernel_initializer='he_normal', name=name)


def _normalize_depth_vars(depth_k, depth_v, filters):


    if type(depth_k) == float:
        depth_k = int(filters * depth_k)
    else:
        depth_k = int(depth_k)

    if type(depth_v) == float:
        depth_v = int(filters * depth_v)
    else:
        depth_v = int(depth_v)

    return depth_k, depth_v


class AttentionAugmentation2D(Layer):

    def __init__(self, depth_k, depth_v, num_heads, relative=True, **kwargs):

        super(AttentionAugmentation2D, self).__init__(**kwargs)

        if depth_k % num_heads != 0:
            raise ValueError('`depth_k` (%d) is not divisible by `num_heads` (%d)' % (
                depth_k, num_heads))

        if depth_v % num_heads != 0:
            raise ValueError('`depth_v` (%d) is not divisible by `num_heads` (%d)' % (
                depth_v, num_heads))

        if depth_k // num_heads < 1.:
            raise ValueError('depth_k / num_heads cannot be less than 1 ! '
                             'Given depth_k = %d, num_heads = %d' % (
                             depth_k, num_heads))

        if depth_v // num_heads < 1.:
            raise ValueError('depth_v / num_heads cannot be less than 1 ! '
                             'Given depth_v = %d, num_heads = %d' % (
                                 depth_v, num_heads))

        self.depth_k = depth_k
        self.depth_v = depth_v
        self.num_heads = num_heads
        self.relative = relative

        self.axis = 1 if K.image_data_format() == 'channels_first' else -1

    def build(self, input_shape):
        self._shape = input_shape

        # normalize the format of depth_v and depth_k
        self.depth_k, self.depth_v = _normalize_depth_vars(self.depth_k, self.depth_v,
                                                           input_shape)

        if self.axis == 1:
            _, channels, height, width = input_shape
        else:
            _, height, width, channels = input_shape

        if self.relative:
            dk_per_head = self.depth_k // self.num_heads

            if dk_per_head == 0:
                print('dk per head', dk_per_head)

            self.key_relative_w = self.add_weight('key_rel_w',
                                                  shape=[2 * width - 1, dk_per_head],
                                                  initializer=initializers.RandomNormal(
                                                      stddev=dk_per_head ** -0.5))

            self.key_relative_h = self.add_weight('key_rel_h',
                                                  shape=[2 * height - 1, dk_per_head],
                                                  initializer=initializers.RandomNormal(
                                                      stddev=dk_per_head ** -0.5))

        else:
            self.key_relative_w = None
            self.key_relative_h = None

    def call(self, inputs, **kwargs):
        if self.axis == 1:
            # If channels first, force it to be channels last for these ops
            inputs = K.permute_dimensions(inputs, [0, 2, 3, 1])

        q, k, v = tf.split(inputs, [self.depth_k, self.depth_k, self.depth_v], axis=-1)

        q = self.split_heads_2d(q)
        k = self.split_heads_2d(k)
        v = self.split_heads_2d(v)

        # scale query
        depth_k_heads = self.depth_k / self.num_heads
        q *= (depth_k_heads ** -0.5)

        # [Batch, num_heads, height * width, depth_k or depth_v] if axis == -1
        qk_shape = [self._batch, self.num_heads, self._height * self._width, self.depth_k // self.num_heads]
        v_shape = [self._batch, self.num_heads, self._height * self._width, self.depth_v // self.num_heads]
        flat_q = K.reshape(q, K.stack(qk_shape))
        flat_k = K.reshape(k, K.stack(qk_shape))
        flat_v = K.reshape(v, K.stack(v_shape))

        # [Batch, num_heads, HW, HW]
        logits = tf.matmul(flat_q, flat_k, transpose_b=True)

        # Apply relative encodings
        if self.relative:
            h_rel_logits, w_rel_logits = self.relative_logits(q)
            logits += h_rel_logits
            logits += w_rel_logits

        weights = K.softmax(logits, axis=-1)
        attn_out = tf.matmul(weights, flat_v)

        attn_out_shape = [self._batch, self.num_heads, self._height, self._width, self.depth_v // self.num_heads]
        attn_out_shape = K.stack(attn_out_shape)
        attn_out = K.reshape(attn_out, attn_out_shape)
        attn_out = self.combine_heads_2d(attn_out)
        # [batch, height, width, depth_v]

        if self.axis == 1:
            # return to [batch, depth_v, height, width] for channels first
            attn_out = K.permute_dimensions(attn_out, [0, 3, 1, 2])

        attn_out.set_shape(self.compute_output_shape(self._shape))

        return attn_out

    def compute_output_shape(self, input_shape):
        output_shape = list(input_shape)
        output_shape[self.axis] = self.depth_v
        return tuple(output_shape)

    def split_heads_2d(self, ip):
        tensor_shape = K.shape(ip)

        # batch, height, width, channels for axis = -1
        tensor_shape = [tensor_shape[i] for i in range(len(self._shape))]

        batch = tensor_shape[0]
        height = tensor_shape[1]
        width = tensor_shape[2]
        channels = tensor_shape[3]

        # Save the spatial tensor dimensions
        self._batch = batch
        self._height = height
        self._width = width

        ret_shape = K.stack([batch, height, width,  self.num_heads, channels // self.num_heads])
        split = K.reshape(ip, ret_shape)
        transpose_axes = (0, 3, 1, 2, 4)
        split = K.permute_dimensions(split, transpose_axes)

        return split

    def relative_logits(self, q):
        shape = K.shape(q)
        # [batch, num_heads, H, W, depth_v]
        shape = [shape[i] for i in range(5)]

        height = shape[2]
        width = shape[3]

        rel_logits_w = self.relative_logits_1d(q, self.key_relative_w, height, width,
                                               transpose_mask=[0, 1, 2, 4, 3, 5])

        rel_logits_h = self.relative_logits_1d(
            K.permute_dimensions(q, [0, 1, 3, 2, 4]),
            self.key_relative_h, width, height,
            transpose_mask=[0, 1, 4, 2, 5, 3])

        return rel_logits_h, rel_logits_w

    def relative_logits_1d(self, q, rel_k, H, W, transpose_mask):
        rel_logits = tf.einsum('bhxyd,md->bhxym', q, rel_k)
        rel_logits = K.reshape(rel_logits, [-1, self.num_heads * H, W, 2 * W - 1])
        rel_logits = self.rel_to_abs(rel_logits)
        rel_logits = K.reshape(rel_logits, [-1, self.num_heads, H, W, W])
        rel_logits = K.expand_dims(rel_logits, axis=3)
        rel_logits = K.tile(rel_logits, [1, 1, 1, H, 1, 1])
        rel_logits = K.permute_dimensions(rel_logits, transpose_mask)
        rel_logits = K.reshape(rel_logits, [-1, self.num_heads, H * W, H * W])
        return rel_logits

    def rel_to_abs(self, x):
        shape = K.shape(x)
        shape = [shape[i] for i in range(3)]
        B, Nh, L, = shape
        col_pad = K.zeros(K.stack([B, Nh, L, 1]))
        x = K.concatenate([x, col_pad], axis=3)
        flat_x = K.reshape(x, [B, Nh, L * 2 * L])
        flat_pad = K.zeros(K.stack([B, Nh, L - 1]))
        flat_x_padded = K.concatenate([flat_x, flat_pad], axis=2)
        final_x = K.reshape(flat_x_padded, [B, Nh, L + 1, 2 * L - 1])
        final_x = final_x[:, :, :L, L - 1:]
        return final_x

    def combine_heads_2d(self, inputs):
        # [batch, num_heads, height, width, depth_v // num_heads]
        transposed = K.permute_dimensions(inputs, [0, 2, 3, 1, 4])
        # [batch, height, width, num_heads, depth_v // num_heads]
        shape = K.shape(transposed)
        shape = [shape[i] for i in range(5)]

        a, b = shape[-2:]
        ret_shape = K.stack(shape[:-2] + [a * b])
        # [batch, height, width, depth_v]
        return K.reshape(transposed, ret_shape)

    def get_config(self):
        config = {
            'depth_k': self.depth_k,
            'depth_v': self.depth_v,
            'num_heads': self.num_heads,
            'relative': self.relative,
        }
        base_config = super(AttentionAugmentation2D, self).get_config()
        return dict(list(base_config.items()) + list(config.items()))


def augmented_conv2d(ip, filters, kernel_size=(3, 3), strides=(1, 1),
                     depth_k=0.2, depth_v=0.2, num_heads=8, relative_encodings=True):


    channel_axis = 1 if K.image_data_format() == 'channels_first' else -1

    depth_k, depth_v = _normalize_depth_vars(depth_k, depth_v, filters)

    conv_out = _conv_layer(filters - depth_v, kernel_size, strides)(ip)

    # Augmented Attention Block
    qkv_conv = _conv_layer(2 * depth_k + depth_v, (1, 1), strides)(ip)
    attn_out = AttentionAugmentation2D(depth_k, depth_v, num_heads, relative_encodings)(qkv_conv)
    attn_out = _conv_layer(depth_v, kernel_size=(1, 1))(attn_out)

    output = concatenate([conv_out, attn_out], axis=channel_axis)
    output = BatchNormalization()(output)
    return output


@tf.function
def main():
    from tensorflow.keras.layers import Input
    from tensorflow.keras.models import Model

    ip = Input(shape=(32, 32, 3))
    x = augmented_conv2d(ip, filters=20, kernel_size=(3, 3),
                         depth_k=0.2, depth_v=0.2,  # dk/v (0.2) * f_out (20) = 4
                         num_heads=4, relative_encodings=True)

    model = Model(ip, x)
    model.summary()

    # Check if attention builds properly
    x = tf.zeros((1, 32, 32, 3))
    y = model(x)
    print(""Attention Augmented Conv out shape : "", y.shape)

if __name__ == '__main__':
    main()
```


**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

```

TypeError: in converted code:

    attn_aug_conv.py:318 main  *
        x = augmented_conv2d(ip, filters=20, kernel_size=(3, 3),
    attn_aug_conv.py:305 augmented_conv2d  *
        attn_out = AttentionAugmentation2D(depth_k, depth_v, num_heads, relative_encodings)(qkv_conv)
    /home/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py:778 __call__
        outputs = call_fn(cast_inputs, *args, **kwargs)
    attn_aug_conv.py:158 call  *
        h_rel_logits, w_rel_logits = self.relative_logits(q)
    attn_aug_conv.py:215 relative_logits  *
        rel_logits_w = self.relative_logits_1d(q, self.key_relative_w, height, width,
    attn_aug_conv.py:228 relative_logits_1d  *
        rel_logits = self.rel_to_abs(rel_logits)
    attn_aug_conv.py:240 rel_to_abs  *
        col_pad = K.zeros(K.stack([B, Nh, L, 1]))
    /home/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py:1300 zeros
        v = array_ops.zeros(shape=shape, dtype=tf_dtype, name=name)
    /home/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/array_ops.py:2446 zeros
        output = fill(shape, constant(zero, dtype=dtype), name=name)
    /home/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/array_ops.py:233 fill
        result = gen_array_ops.fill(dims, value, name=name)
    /home/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_array_ops.py:3240 fill
        dims, value, name=name, ctx=_ctx)
    /home/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_array_ops.py:3267 fill_eager_fallback
        ctx=ctx, name=name)
    /home/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py:76 quick_execute
        raise e
    /home/miniconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py:61 quick_execute
        num_outputs)

    TypeError: An op outside of the function building code is being passed
    a ""Graph"" tensor. It is possible to have Graph tensors
    leak out of the function building context by including a
    tf.init_scope in your function building code.
    For example, the following function will fail:
      @tf.function
      def has_init_scope():
        my_constant = tf.constant(1.)
        with tf.init_scope():
          added = my_constant * 2
    The graph tensor has name: attention_augmentation2d/stack_6:0
```
"
38581,Memory leak when validation generator is used,"
**System information** 
Tested in 2 environments: 

1. my computer with Linux Ubuntu 18.04.3 LTS, 
tensorflow GIT_VERSION and VERSION: v1.12.1-27410-g0f2c6e4a99 2.2.0-dev20200317,
CUDA release 10.1, V10.1.243, GeForce GTX 1060 6GB

2. colaboratory
tensorflow GIT_VERSION and VERSION: v2.2.0-rc2-0-ge6e5d6df2a 2.2.0-rc2


**Describe the current behavior**
When the validation generator is passed to the model `fit` function the memory is gradually filling until it is completely used up and the process is killed.

 The memory is filled faster when input is larger - the input vector in the example has length 500000 (in my real scenario, I use high-resolution images..). The memory is filled only once during the validation iteration, it does not matter how many validation_steps are taken (in the example is set to 2).

**Important observation**
The memory leak occurs only when keras is imported from tensorflow eg. `from tensorflow import keras`. It works fine when keras is imported separately eg. `import keras` with tensorflow backend.

**Describe the expected behavior**
The memory usage should not increase after validation iteration. 

**Standalone code to reproduce the issue** 
The issue is reproduced in this colab notebook:
https://colab.research.google.com/drive/1AyHgzv4JmN5iFBuMD-Cbey3Uj0WpKcka

or it can be reproduced with the following script. It prints the maximal memory usage. The memory does not have to increase in every iteration but with enough epochs it fills the whole memory.
```
import sys
import resource  # used for monitoring memory usage
import logging
import numpy as np

from tensorflow import keras
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras import callbacks

""""""In order to prevent the memory leak remove/comment out the tensorflow 
imports above and uncomment keras imports below""""""
# import keras
# from keras.models import Sequential
# from keras.layers import Dense
# from keras import callbacks


class MemoryLoggerCallback(callbacks.Callback):
    def __init__(self):
        self.memory_usage = []

    def on_epoch_end(self, epoch, logs=None):
        max_used_memory = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
        logging.info(f""\nmemory usage after end of epoch hook: {max_used_memory}"")
        if epoch % 10 == 0:
            self.memory_usage.append(max_used_memory)
            logging.info(""############"")
            logging.info(self.memory_usage)
            logging.info(""############"")


def dummy_gen_simple(input_dim: int, batch_size: int = 3):
    """"""random data and label generator""""""
    while True:
        x = np.random.random((batch_size, input_dim))
        y = keras.utils.to_categorical(np.random.randint(10, size=(batch_size, 1)), num_classes=10)
        yield (x, y, None)


def init_logger():
    """"""initialise logger which redirects to stderr,
    so it prints log messages during training""""""
    # set up global logger
    logger = logging.getLogger('')
    logger.setLevel(logging.INFO)
    logger.handlers = []  # remove default handlers
    # set up STDERR handler
    stderr_handler = logging.StreamHandler(sys.stderr)
    logger.addHandler(stderr_handler)


init_logger()

input_dim = 500000

# arbitrary simple model
model = Sequential()
model.add(Dense(64, activation='relu', input_dim=input_dim))
model.add(Dense(64, activation='relu'))
model.add(Dense(10, activation='softmax'))

model.compile(loss='categorical_crossentropy',
              optimizer='adam',
              metrics=['accuracy'])

memory_logger_callback = MemoryLoggerCallback()

model.fit(dummy_gen_simple(input_dim, batch_size=32),
          steps_per_epoch=10,
          epochs=252,
          validation_data=dummy_gen_simple(input_dim, batch_size=16),
          validation_steps=2,
          callbacks=[memory_logger_callback])

```


**Other info / logs** 
Always increasing maximum memory used, logged every 10th epoch (tensorflow.keras used):
[2994176, 2994972, 3560776, 4187488, 4813912, 5440976, 6067128, 6694228, 7352372, 7978688, 8605452, 9326704, 10061912, 10428392, 11055996, 11603124, 12187312]

It should look like:
Stabilized memory use, logged every 50th epoch (keras used): 
[2677340, 2864996, 2864996, 2864996, 2864996, 2864996, 2927704, 2990080, 2990080, 2990080, 2990080, 2990080, 2990080, 2990080, 2990080, 2990080, 2990344, 2990344, 2990344, 2990344, 2990344]
"
38578,Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory,"Debian 10.3
Python 3.8.2
Cuda 10.2
Quadro K5200d drivers 440.82
Tensorflow 2.2.0-rc2

import tensorflow as tf
tf.config.list_physical_devices('GPU')
2020-04-15 20:58:07.177217: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-04-15 20:58:07.205025: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: 
pciBusID: 0000:03:00.0 name: Quadro K5200 computeCapability: 3.5
coreClock: 0.771GHz coreCount: 12 deviceMemorySize: 7.94GiB deviceMemoryBandwidth: 179.05GiB/s
2020-04-15 20:58:07.205269: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory
2020-04-15 20:58:07.207704: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-04-15 20:58:07.210137: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-04-15 20:58:07.210533: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-04-15 20:58:07.213099: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-04-15 20:58:07.214498: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-04-15 20:58:07.219816: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-04-15 20:58:07.219842: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1598] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...

"
38576,[TFLITE] Modelmaker for (multi-class) custom text classification.,"**System information**
- TensorFlow version (you are using):
Nightly version of TensorFlow (2.2.0-dev20200415)
- Are you willing to contribute it (Yes/No):
Yes

**Describe the feature and the current behavior/state.**
Ability to use custom train data for text classification.
Currently on providing custom data instead of **aclImdb** [http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz](url)

`text_classifier.create(train_data, model_spec=model_spec, epochs=5)` functionality breaks with the following error :
`UnboundLocalError                         Traceback (most recent call last)
<ipython-input-48-391f7527d048> in <module>
----> 1 model = text_classifier.create(train_data, model_spec=model_spec, epochs=20)

~/anaconda3/envs/py3/lib/python3.7/site-packages/tensorflow_examples/lite/model_maker/core/task/text_classifier.py in create(train_data, model_export_format, model_spec, shuffle, batch_size, epochs, validation_data)
     60 
     61   tf.compat.v1.logging.info('Retraining the models...')
---> 62   text_classifier.train(train_data, validation_data, epochs, batch_size)
     63 
     64   return text_classifier

~/anaconda3/envs/py3/lib/python3.7/site-packages/tensorflow_examples/lite/model_maker/core/task/text_classifier.py in train(self, train_data, validation_data, epochs, batch_size)
    126                                                 steps_per_epoch,
    127                                                 validation_steps,
--> 128                                                 self.num_classes)
    129 
    130     return self.model

~/anaconda3/envs/py3/lib/python3.7/site-packages/tensorflow_examples/lite/model_maker/core/task/model_spec.py in run_classifier(self, train_input_fn, validation_input_fn, epochs, steps_per_epoch, validation_steps, num_classes)
    222         steps_per_epoch=steps_per_epoch,
    223         validation_data=validation_ds,
--> 224         validation_steps=validation_steps)
    225 
    226     return model

~/anaconda3/envs/py3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py in _method_wrapper(self, *args, **kwargs)
     69   def _method_wrapper(self, *args, **kwargs):
     70     if not self._in_multi_worker_mode():  # pylint: disable=protected-access
---> 71       return method(self, *args, **kwargs)
     72 
     73     # Running inside `run_distribute_coordinator` already.

~/anaconda3/envs/py3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)
    917               end_step = step + data_handler.step_increment
    918               callbacks.on_train_batch_end(end_step, logs)
--> 919         epoch_logs = copy.copy(logs)
    920 
    921         # Run validation.

UnboundLocalError: local variable 'logs' referenced before assignment
`
**Will this change the current api? How?**
Not sure.
**Who will benefit with this feature?**
End users
**Any Other info.**
Custom (multi-class) text classification support."
38574,"Custom keras/tensorflow layer, output-shape error","I wrote my own keras/tensorflow layer. Passing images into it works fine, but using it in combination with other layers, givesan error. Somehow the output shape of my custom layer should be wrong, or some kind of ""Nonetype"".

I posted my question on Stackoverflow, to reduce redundance,  just follow the underlying link to the code.

https://stackoverflow.com/questions/61231081/custom-keras-tensorflow-layer-output-shape-error"
38572,[TFLITE] Modelmaker and code generator for boundingRect/Cuboid + keypoints,"**System information**
- TensorFlow version (you are using):
Tensorflow-nightly
- Are you willing to contribute it (Yes/No):
No

**Describe the feature and the current behavior/state.**
In Tensorflow Hub at https://github.com/tensorflow/hub/issues/424 I've proposed to introduce one of the many single stage anchor-free models that adapt quite easily to keypoints tasks (face detection+ladmarks, people detection + pose, 3d cuboid + object keypoints etc.). 
It could be very useful if the new ModelMaker and the code generator could support generic object occupancy (2d/3d) + arbitrary target keypoints.

**Will this change the current api? How?**
Yes.
**Who will benefit with this feature?**
Many end2end task like face detection with landmakrs, people detection + pose, 3d object detection + specific object keypoints, hand detection + hand landmarks etc..)
**Any Other info.**
"
38571,Failed precondition: Error while reading resource variable block3a_se_expand/bias from Container: localhost. This could mean that the variable was uninitialized. Not found: Resource localhost/block3a_se_expand/bias/N10tensorflow3VarE does not exist. 	 [[{{node block3a_se_expand/BiasAdd/ReadVariableOp}}]] 	 [[dense_1/Softmax/_1903]],"I have three trained models which is using in one script . First model (.h5) is loaded using following piece of code

```
from keras_retinanet import models
def get_session():
    config = tf.compat.v1.ConfigProto()
    config.gpu_options.allow_growth = True
    return tf.compat.v1.Session(config=config)
keras.backend.tensorflow_backend.set_session(get_session()) 
first_model = models.load_model(first_model_path, backbone_name='resnet50')
```
The first model loaded and predicted successfully. After first model operation,  second model (.hdf5) loaded using following code block

```
from tensorflow.keras.models import load_model
second_model =load_model(second_model_path)
```
Second model loaded successfully and but while prediction , getting the following error.

`2020-04-15 12:01:36.207346: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2020-04-15 12:01:36.310985: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2020-04-15 12:01:43.026476: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10
Traceback (most recent call last):
  File ""ppe_detection.py"", line 105, in <module>
    predicted , x = predict_helmet(processed_roi,helmet_model)
  File ""/samjith/project/safety-monitoring/classify/helmet/helmet_classy.py"", line 17, in predict_helmet
    helmet_score = helmet_model.predict([x])[0][0]
  File ""/home/samjith/anaconda3/envs/keras-retina/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py"", line 1078, in predict
    callbacks=callbacks)
  File ""/home/samjith/anaconda3/envs/keras-retina/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_arrays.py"", line 363, in model_iteration
    batch_outs = f(ins_batch)
  File ""/home/samjith/anaconda3/envs/keras-retina/lib/python3.7/site-packages/tensorflow/python/keras/backend.py"", line 3292, in __call__
    run_metadata=self.run_metadata)
  File ""/home/samjith/anaconda3/envs/keras-retina/lib/python3.7/site-packages/tensorflow/python/client/session.py"", line 1458, in __call__
    run_metadata_ptr)
tensorflow.python.framework.errors_impl.FailedPreconditionError: 2 root error(s) found.
  (0) Failed precondition: Error while reading resource variable block3b_expand_conv/kernel from Container: localhost. This could mean that the variable was uninitialized. Not found: Resource localhost/block3b_expand_conv/kernel/N10tensorflow3VarE does not exist.
	 [[{{node block3b_expand_conv/Conv2D/ReadVariableOp}}]]
	 [[dense_1/Softmax/_1903]]
  (1) Failed precondition: Error while reading resource variable block3b_expand_conv/kernel from Container: localhost. This could mean that the variable was uninitialized. Not found: Resource localhost/block3b_expand_conv/kernel/N10tensorflow3VarE does not exist.
	 [[{{node block3b_expand_conv/Conv2D/ReadVariableOp}}]]
0 successful operations.
0 derived errors ignored.
`
I have gone through [this github  link](https://github.com/tensorflow/tensorflow/issues/28287#issuecomment-495005162). But the error still remains.
"
38570,Add new hyperparameter k in tf.compat.v1.train.polynomial_decay and other decay fuction,"Hey, according to [this paper](https://arxiv.org/abs/2004.05909) should be adding new hyperparameter k in the API of tf.compat.v1.train.polynomial_decay and other decay functions to simply improve performance. Thank you very much.
"
38569,Not coverting pb to tflite for using with microinterpreter for x86_64 platform,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 18.04):
- TensorFlow installed from (using pip):
- TensorFlow version (1.14.0):


**1) when I convert my model to pb using export_inference_graph.py using following command:

> python export_inference_graph.py --input_type image_tensor --pipeline_config_path ../training/ssd_mobilenet_v1_coco.config --trained_checkpoint_prefix ../training/model.ckpt-25 --output_directory ../inference_graph

**2) convert the above generated pb to tflite using tflite converter by below command:**

> tflite_convert   --output_file=""/home/ashwini/Object_detection_general/models/research/logs_text_detection/frozen_pb_using_export_inference_graph/aaa.tflite""   --graph_def_file=""/home/ashwini/Object_detection_general/models/research/logs_text_detection/frozen_pb_using_export_inference_graph/frozen_inference_graph.pb""   --inference_type=QUANTIZED_UINT8   --input_arrays=""image_tensor""   --output_arrays=""detection_boxes,detection_scores,detection_classes,num_detections""   --mean_values=128   --std_dev_values=128   --input_shapes=1,300,300,3   --change_concat_input_ranges=false --default_ranges_min=0 and --default_ranges_max=6
**
If possible, please share a link to Colab/Jupyter/any notebook.

```
# Copy and paste here the exact command
```

**2020-04-15 16:09:59.924340: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayGatherV3
2020-04-15 16:09:59.924359: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArraySizeV3
2020-04-15 16:09:59.924385: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TensorArrayGatherV3
2020-04-15 16:09:59.982759: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 1442 operators, 2553 arrays (0 quantized)
2020-04-15 16:10:00.074646: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After Removing unused ops pass 1: 1367 operators, 2399 arrays (0 quantized)
2020-04-15 16:10:00.186402: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 1367 operators, 2399 arrays (0 quantized)
2020-04-15 16:10:00.268372: F tensorflow/lite/toco/graph_transformations/resolve_constant_slice.cc:59] Check failed: dim_size >= 1 (0 vs. 1)
Fatal Python error: Aborted

Current thread 0x00007fb5e3e9e740 (most recent call first):
  File ""/home/ashwini/Object_detection_general/environment/obj_det/lib/python3.6/site-packages/tensorflow/lite/toco/python/toco_from_protos.py"", line 33 in execute
  File ""/home/ashwini/Object_detection_general/environment/obj_det/lib/python3.6/site-packages/absl/app.py"", line 250 in _run_main
  File ""/home/ashwini/Object_detection_general/environment/obj_det/lib/python3.6/site-packages/absl/app.py"", line 299 in run
  File ""/home/ashwini/Object_detection_general/environment/obj_det/lib/python3.6/site-packages/tensorflow/python/platform/app.py"", line 40 in run
  File ""/home/ashwini/Object_detection_general/environment/obj_det/lib/python3.6/site-packages/tensorflow/lite/toco/python/toco_from_protos.py"", line 59 in main
  File ""/home/ashwini/Object_detection_general/environment/obj_det/bin/toco_from_protos"", line 11 in <module>
Aborted (core dumped)**

```
# Copy and paste the output here.
```

**Also, please include a link to the saved model or GraphDef**

```
# Put link here or attach to the issue.
```

**Failure details**
If the conversion is successful, but the generated model is wrong,
state what is wrong:
- Producing wrong results and/or decrease in accuracy
- Producing correct results, but the model is slower than expected (model generated from old converter)


**Any other info / logs**

Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
38568,Error occurs when bazel building the example,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Windows 10
- TensorFlow installed from (source or binary):
- TensorFlow version:2.1.0
- Python version:3.7.7
- Installed using virtualenv? pip? conda?:pip
- Bazel version (if compiling from source):2.0.0



**Describe the problem**
Recently I'm studying tensorflow-lite. After cloning the repo and install Bazel2.0.0, I'm trying to build the tf-lite hello-world example. 
**Here's the command**
```shell
cd E:\tensorflow\tensorflow\lite\micro\examples\hello_world
bazel build :sine_model_data
```
**Here's the error message:**
```shell
INFO: Options provided by the client:
  Inherited 'common' options: --isatty=1 --terminal_columns=120
INFO: Reading rc options for 'build' from e:\tensorflow\.bazelrc:
  Inherited 'common' options: --experimental_repo_remote_exec
INFO: Options provided by the client:
  'build' options: --python_path=D:/Anaconda3/envs/tf2.0/python.exe
INFO: Reading rc options for 'build' from e:\tensorflow\.bazelrc:
  'build' options: --apple_platform_type=macos --define framework_shared_object=true --define open_source_build=true --java_toolchain=//third_party/toolchains/java:tf_java_toolchain --host_java_toolchain=//third_party/toolchains/java:tf_java_toolchain --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --noincompatible_prohibit_aapt1 --enable_platform_specific_config --config=v2
INFO: Found applicable config definition build:v2 in file e:\tensorflow\.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1
INFO: Found applicable config definition build:windows in file e:\tensorflow\.bazelrc: --copt=/w --copt=/D_USE_MATH_DEFINES --host_copt=/D_USE_MATH_DEFINES --cxxopt=/std:c++14 --host_cxxopt=/std:c++14 --config=monolithic --copt=-DWIN32_LEAN_AND_MEAN --host_copt=-DWIN32_LEAN_AND_MEAN --copt=-DNOGDI --host_copt=-DNOGDI --linkopt=/DEBUG --host_linkopt=/DEBUG --linkopt=/OPT:REF --host_linkopt=/OPT:REF --linkopt=/OPT:ICF --host_linkopt=/OPT:ICF --experimental_strict_action_env=true --verbose_failures --distinct_host_configuration=false
INFO: Found applicable config definition build:monolithic in file e:\tensorflow\.bazelrc: --define framework_shared_object=false
INFO: Call stack for the definition of repository 'flatbuffers' which is a third_party_http_archive (rule definition at E:/tensorflow/third_party/repo.bzl:219:28):
 - E:/tensorflow/third_party/flatbuffers/workspace.bzl:6:5
 - E:/tensorflow/tensorflow/workspace.bzl:53:5
 - E:/tensorflow/tensorflow/workspace.bzl:100:5
 - E:/tensorflow/WORKSPACE:19:1
INFO: Repository 'flatbuffers' used the following cache hits instead of downloading the corresponding file.
 * Hash '62f2223fb9181d1d6338451375628975775f7522185266cd5296571ac152bc45' for https://storage.googleapis.com/mirror.tensorflow.org/github.com/google/flatbuffers/archive/v1.12.0.tar.gz
If the definition of 'flatbuffers' was updated, verify that the hashes were also updated.
ERROR: An error occurred during the fetch of repository 'flatbuffers':
   java.io.IOException: Could not create symlink from E:/tensorflow/third_party/flatbuffers/build_defs.bzl to C:/users/chenhao/_bazel_chenhao/3rb265pl/external/flatbuffers/build_defs.bzl: C:/users/chenhao/_bazel_chenhao/3rb265pl/external/flatbuffers/build_defs.bzl (File exists)
DEBUG: Rule 'io_bazel_rules_docker' indicated that a canonical reproducible form can be obtained by modifying arguments shallow_since = ""1556410077 -0400""
DEBUG: Call stack for the definition of repository 'io_bazel_rules_docker' which is a git_repository (rule definition at C:/users/chenhao/_bazel_chenhao/3rb265pl/external/bazel_tools/tools/build_defs/repo/git.bzl:195:18):
 - C:/users/chenhao/_bazel_chenhao/3rb265pl/external/bazel_toolchains/repositories/repositories.bzl:37:9
 - E:/tensorflow/WORKSPACE:37:1
ERROR: Skipping ':sine_model_data': no such package '@flatbuffers//': java.io.IOException: Could not create symlink from E:/tensorflow/third_party/flatbuffers/build_defs.bzl to C:/users/chenhao/_bazel_chenhao/3rb265pl/external/flatbuffers/build_defs.bzl: C:/users/chenhao/_bazel_chenhao/3rb265pl/external/flatbuffers/build_defs.bzl (File exists)
WARNING: Target pattern parsing failed.
ERROR: no such package '@flatbuffers//': java.io.IOException: Could not create symlink from E:/tensorflow/third_party/flatbuffers/build_defs.bzl to C:/users/chenhao/_bazel_chenhao/3rb265pl/external/flatbuffers/build_defs.bzl: C:/users/chenhao/_bazel_chenhao/3rb265pl/external/flatbuffers/build_defs.bzl (File exists)
INFO: Elapsed time: 2.267s
INFO: 0 processes.
FAILED: Build did NOT complete successfully (0 packages loaded)
    currently loading: tensorflow/lite/micro/examples/hello_world
```

According to the Error, I try to build the flatbuffer first(I don't know whether it'll work, just have a try)
Here's the command
```shell
cd E:\tensorflow\third_party\flatbuffers
bazel build :flatbuffers
```
Here's the output
```shell
INFO: Options provided by the client:
  Inherited 'common' options: --isatty=1 --terminal_columns=120
INFO: Reading rc options for 'build' from e:\tensorflow\.bazelrc:
  Inherited 'common' options: --experimental_repo_remote_exec
INFO: Options provided by the client:
  'build' options: --python_path=D:/Anaconda3/envs/tf2.0/python.exe
INFO: Reading rc options for 'build' from e:\tensorflow\.bazelrc:
  'build' options: --apple_platform_type=macos --define framework_shared_object=true --define open_source_build=true --java_toolchain=//third_party/toolchains/java:tf_java_toolchain --host_java_toolchain=//third_party/toolchains/java:tf_java_toolchain --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --noincompatible_prohibit_aapt1 --enable_platform_specific_config --config=v2
INFO: Found applicable config definition build:v2 in file e:\tensorflow\.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1
INFO: Found applicable config definition build:windows in file e:\tensorflow\.bazelrc: --copt=/w --copt=/D_USE_MATH_DEFINES --host_copt=/D_USE_MATH_DEFINES --cxxopt=/std:c++14 --host_cxxopt=/std:c++14 --config=monolithic --copt=-DWIN32_LEAN_AND_MEAN --host_copt=-DWIN32_LEAN_AND_MEAN --copt=-DNOGDI --host_copt=-DNOGDI --linkopt=/DEBUG --host_linkopt=/DEBUG --linkopt=/OPT:REF --host_linkopt=/OPT:REF --linkopt=/OPT:ICF --host_linkopt=/OPT:ICF --experimental_strict_action_env=true --verbose_failures --distinct_host_configuration=false
INFO: Found applicable config definition build:monolithic in file e:\tensorflow\.bazelrc: --define framework_shared_object=false
DEBUG: Rule 'io_bazel_rules_docker' indicated that a canonical reproducible form can be obtained by modifying arguments shallow_since = ""1556410077 -0400""
DEBUG: Call stack for the definition of repository 'io_bazel_rules_docker' which is a git_repository (rule definition at C:/users/chenhao/_bazel_chenhao/3rb265pl/external/bazel_tools/tools/build_defs/repo/git.bzl:195:18):
 - C:/users/chenhao/_bazel_chenhao/3rb265pl/external/bazel_toolchains/repositories/repositories.bzl:37:9
 - E:/tensorflow/WORKSPACE:37:1
INFO: Call stack for the definition of repository 'local_config_python' which is a python_configure (rule definition at E:/tensorflow/third_party/py/python_configure.bzl:280:20):
 - E:/tensorflow/tensorflow/workspace.bzl:96:5
 - E:/tensorflow/WORKSPACE:19:1
ERROR: An error occurred during the fetch of repository 'local_config_python':
   Traceback (most recent call last):
        File ""E:/tensorflow/third_party/py/python_configure.bzl"", line 263
                _create_local_python_repository(<1 more arguments>)
        File ""E:/tensorflow/third_party/py/python_configure.bzl"", line 209, in _create_local_python_repository
                _check_python_bin(<2 more arguments>)
        File ""E:/tensorflow/third_party/py/python_configure.bzl"", line 145, in _check_python_bin
                auto_config_fail(<1 more arguments>)
        File ""E:/tensorflow/third_party/remote_config/common.bzl"", line 12, in auto_config_fail
                fail(<1 more arguments>)
Configuration Error: --define PYTHON_BIN_PATH='D:\Anaconda3\envs\tf2.0\python.exe
D:\Anaconda3\python.exe
C:\Users\ChenHao\AppData\Local\Microsoft\WindowsApps\python.exe' is not executable. Is it the python binary?
INFO: Call stack for the definition of repository 'rules_java' which is a http_archive (rule definition at C:/users/chenhao/_bazel_chenhao/3rb265pl/external/bazel_tools/tools/build_defs/repo/http.bzl:292:16):
 - C:/users/chenhao/_bazel_chenhao/3rb265pl/external/bazel_tools/tools/build_defs/repo/utils.bzl:205:9
 - /DEFAULT.WORKSPACE.SUFFIX:290:1
ERROR: While resolving toolchains for target //third_party/flatbuffers:flatbuffers: invalid registered toolchain '@local_config_python//:py_toolchain': no such package '@local_config_python//': Traceback (most recent call last):
        File ""E:/tensorflow/third_party/py/python_configure.bzl"", line 263
                _create_local_python_repository(<1 more arguments>)
        File ""E:/tensorflow/third_party/py/python_configure.bzl"", line 209, in _create_local_python_repository
                _check_python_bin(<2 more arguments>)
        File ""E:/tensorflow/third_party/py/python_configure.bzl"", line 145, in _check_python_bin
                auto_config_fail(<1 more arguments>)
        File ""E:/tensorflow/third_party/remote_config/common.bzl"", line 12, in auto_config_fail
                fail(<1 more arguments>)
Configuration Error: --define PYTHON_BIN_PATH='D:\Anaconda3\envs\tf2.0\python.exe
D:\Anaconda3\python.exe
C:\Users\ChenHao\AppData\Local\Microsoft\WindowsApps\python.exe' is not executable. Is it the python binary?
ERROR: Analysis of target '//third_party/flatbuffers:flatbuffers' failed; build aborted: invalid registered toolchain '@local_config_python//:py_toolchain': no such package '@local_config_python//': Traceback (most recent call last):
        File ""E:/tensorflow/third_party/py/python_configure.bzl"", line 263
                _create_local_python_repository(<1 more arguments>)
        File ""E:/tensorflow/third_party/py/python_configure.bzl"", line 209, in _create_local_python_repository
                _check_python_bin(<2 more arguments>)
        File ""E:/tensorflow/third_party/py/python_configure.bzl"", line 145, in _check_python_bin
                auto_config_fail(<1 more arguments>)
        File ""E:/tensorflow/third_party/remote_config/common.bzl"", line 12, in auto_config_fail
                fail(<1 more arguments>)
Configuration Error: --define PYTHON_BIN_PATH='D:\Anaconda3\envs\tf2.0\python.exe
D:\Anaconda3\python.exe
C:\Users\ChenHao\AppData\Local\Microsoft\WindowsApps\python.exe' is not executable. Is it the python binary?
INFO: Elapsed time: 20.577s
INFO: 0 processes.
FAILED: Build did NOT complete successfully (0 packages loaded, 0 targets configured)
    currently loading: @bazel_tools//tools/jdk

```
Why is there an Error about ""**PYTHON_BIN_PATH** which is the right path in the output. 

How can I build the example right?

"
38565,Could not create cudnn handle: CUDNN_STATUS_ALLOC_FAILED ,"**System information**
- windows 10 64
- TensorFlow installed from anaconda
- TensorFlow version: 2.1
- Python version: 3.7.6
- Installed using conda
- CUDA/cuDNN version: 
not sure what cuda version i use: conda list cudatoolkit gives 10.1.243 but nvidia-smi gives cuda 11
cudnn version: 7.6.5
- GPU model and memory:
nvidia gtx 1660Ti 6GB turing
keras version: 2.3.1, keras base 2.3.1, keras-application 1.0.8, keras prepossessing 1.1 




when I an trying to use the layer conv2Dtranspose in a keras model I get the error:
```
2020-04-15 11:26:57.432157: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_ALLOC_FAILED
2020-04-15 11:26:57.438997: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_ALLOC_FAILED
2020-04-15 11:26:57.443860: F tensorflow/core/kernels/conv_grad_input_ops.cc:1163] Check failed: stream->parent()->GetConvolveBackwardDataAlgorithms( conv_parameters.ShouldIncludeWinogradNonfusedAlgo<T>(stream->parent()), &algorithms)
```
my guess is that there is a compatablity issue with my cuda or cudnn version, that I dont know how to change in anaconda. changing the version of anything else does not seem to work. 

Provide the exact sequence of commands / steps that you executed before running into the problem:

```
import os
from PIL import Image
import matplotlib.pyplot as plt
import numpy as np
from keras.models import Model
from keras.optimizers import Adam
from keras.layers.advanced_activations import LeakyReLU
from keras.layers import Conv2D, Input,BatchNormalization, Flatten, Dense, Activation, Conv2DTranspose
from keras import backend as K
from sklearn.model_selection import train_test_split
from keras.callbacks.callbacks import EarlyStopping,Callback
from keras.backend.tensorflow_backend import set_session
import tensorflow as tf
gpus= tf.config.experimental.list_physical_devices('GPU')
tf.config.experimental.set_memory_growth(gpus[0], True)
from tensorflow.python.client import device_lib
print(device_lib.list_local_devices())

def adam_optimizer():
    return Adam(lr=0.000002, beta_1=0.5)

def build_generator(inputs, image_size):
    # network parameters
    layer_filters = [256, 128, 64, 32, 3]
    strides = 2
    x = inputs
    for filters in layer_filters:
        x = Conv2DTranspose(filters=filters,kernel_size=(3,3),strides=strides,padding='same')(x)
        shape = K.int_shape(x)
        x = Activation('relu')(x)
        x = BatchNormalization()(x)
    x = Activation('sigmoid')(x)
    generator = Model(inputs, x, name='generator')
    generator.compile(loss='binary_crossentropy',optimizer=adam_optimizer(),metrics=['accuracy'])
    return generator

inputs = Input(shape=(2,2,480))
g = build_generator(inputs, (64,64,3))

false_faces = g.predict(np.random.normal(size=(2,2,2,480)))
```
Any other info / logs:
logs from the notebook:
```
(base) C:\Users\Moran>jupyter notebook
[I 11:26:40.436 NotebookApp] Serving notebooks from local directory: C:\Users\Moran
[I 11:26:40.436 NotebookApp] The Jupyter Notebook is running at:
[I 11:26:40.436 NotebookApp] http://localhost:8888/?token=eeabd801c4c1b83aa79d704bf93c4465f305c688ebb846dc
[I 11:26:40.436 NotebookApp]  or http://127.0.0.1:8888/?token=eeabd801c4c1b83aa79d704bf93c4465f305c688ebb846dc
[I 11:26:40.436 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).
[C 11:26:40.508 NotebookApp]

    To access the notebook, open this file in a browser:
        file:///C:/Users/Moran/AppData/Roaming/jupyter/runtime/nbserver-14384-open.html
    Or copy and paste one of these URLs:
        http://localhost:8888/?token=eeabd801c4c1b83aa79d704bf93c4465f305c688ebb846dc
     or http://127.0.0.1:8888/?token=eeabd801c4c1b83aa79d704bf93c4465f305c688ebb846dc
[I 11:26:45.246 NotebookApp] Kernel started: 14241611-5379-485d-b99b-c51ef765ca55
2020-04-15 11:26:47.464197: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll
2020-04-15 11:26:50.655541: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library nvcuda.dll
2020-04-15 11:26:50.703563: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties:
pciBusID: 0000:01:00.0 name: GeForce GTX 1660 Ti computeCapability: 7.5
coreClock: 1.59GHz coreCount: 24 deviceMemorySize: 6.00GiB deviceMemoryBandwidth: 268.26GiB/s
2020-04-15 11:26:50.715262: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll
2020-04-15 11:26:50.726496: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll
2020-04-15 11:26:50.737190: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_10.dll
2020-04-15 11:26:50.747595: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_10.dll
2020-04-15 11:26:50.759230: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_10.dll
2020-04-15 11:26:50.768199: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_10.dll
2020-04-15 11:26:50.786405: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll
2020-04-15 11:26:50.794014: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-04-15 11:26:50.798597: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2
2020-04-15 11:26:50.811901: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties:
pciBusID: 0000:01:00.0 name: GeForce GTX 1660 Ti computeCapability: 7.5
coreClock: 1.59GHz coreCount: 24 deviceMemorySize: 6.00GiB deviceMemoryBandwidth: 268.26GiB/s
2020-04-15 11:26:50.823790: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll
2020-04-15 11:26:50.830518: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll
2020-04-15 11:26:50.837440: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_10.dll
2020-04-15 11:26:50.844229: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_10.dll
2020-04-15 11:26:50.851215: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_10.dll
2020-04-15 11:26:50.857471: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_10.dll
2020-04-15 11:26:50.864682: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll
2020-04-15 11:26:50.870630: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-04-15 11:26:51.694569: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-04-15 11:26:51.700712: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0
2020-04-15 11:26:51.705257: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N
2020-04-15 11:26:51.710677: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/device:GPU:0 with 4625 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1660 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5)
2020-04-15 11:26:52.683708: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties:
pciBusID: 0000:01:00.0 name: GeForce GTX 1660 Ti computeCapability: 7.5
coreClock: 1.59GHz coreCount: 24 deviceMemorySize: 6.00GiB deviceMemoryBandwidth: 268.26GiB/s
2020-04-15 11:26:52.696926: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll
2020-04-15 11:26:52.703966: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll
2020-04-15 11:26:52.710870: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_10.dll
2020-04-15 11:26:52.717898: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_10.dll
2020-04-15 11:26:52.726352: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_10.dll
2020-04-15 11:26:52.732807: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_10.dll
2020-04-15 11:26:52.738251: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll
2020-04-15 11:26:52.746009: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-04-15 11:26:52.750168: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-04-15 11:26:52.756798: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0
2020-04-15 11:26:52.760471: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N
2020-04-15 11:26:52.764642: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 4625 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1660 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5)
2020-04-15 11:26:55.502574: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll
2020-04-15 11:26:57.432157: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_ALLOC_FAILED
2020-04-15 11:26:57.438997: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_ALLOC_FAILED
2020-04-15 11:26:57.443860: F tensorflow/core/kernels/conv_grad_input_ops.cc:1163] Check failed: stream->parent()->GetConvolveBackwardDataAlgorithms( conv_parameters.ShouldIncludeWinogradNonfusedAlgo<T>(stream->parent()), &algorithms)
```
i am trying to solve this for days (!!) now - I looked at all similar problems but for no use  - the solutions there does not work or not apply to my case (for example, since I am using anaconda)"
38564,Wrong function in example for tensor_diag,"The examples in the documentations of `tf.linalg.tensor_diag_part` and `tf.linalg.tensor_diag`
are showing the non-tensor version of these functions, e.g.
```
# 'diagonal' is [1, 2, 3, 4]
tf.diag(diagonal) ==> [[1, 0, 0, 0]
                       [0, 2, 0, 0]
                       [0, 0, 3, 0]
                       [0, 0, 0, 4]]
```

See 
https://www.tensorflow.org/api_docs/python/tf/linalg/tensor_diag
https://www.tensorflow.org/api_docs/python/tf/linalg/tensor_diag_part"
38563,error: 'arm_convolve_1_x_n_s8_get_buffer_size' was not declared in this scope,"@tensorflow/micro

**System information**
- Host OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu18.04 under WSL
- TensorFlow installed from (source or binary): source
- Tensorflow version (commit SHA if source):  2ddbc3572cd10002cf4e74a9c7b4dbf3d5995d7b
- Target platform (e.g. Arm Mbed OS, Arduino Nano 33 etc.):   sparkfun_edge

when trying to build person detection app using the cmsis-nn libraries using this command:

`make -f tensorflow/lite/micro/tools/make/Makefile TAGS=cmsis-nn TARGET=sparkfun_edge person_detection_int8_bin`

I run into the following compile error:

`arm-none-eabi-g++ -std=c++11 -DTF_LITE_STATIC_MEMORY -O3 -DPART_apollo3 -DAM_PACKAGE_BGA -DAM_PART_APOLLO3 -DGEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK -DTF_LITE_STATIC_MEMORY -DNDEBUG -DTF_LITE_MCU_DEBUG_LOG -D __FPU_PRESENT=1 -DARM_MATH_CM4 -fno-rtti -fmessage-length=0 -fno-exceptions -fno-unwind-tables -fno-builtin -ffunction-sections -fdata-sections -funsigned-char -MMD -mcpu=cortex-m4 -mthumb -mfpu=fpv4-sp-d16 -mfloat-abi=hard -std=gnu++11 -Wvla -Wall -Wextra -Wsign-compare -Wdouble-promotion -Wunused-variable -Wshadow -Wmissing-field-initializers -Wno-unused-parameter -Wno-write-strings -fno-delete-null-pointer-checks -fno-threadsafe-statics -fomit-frame-pointer -fpermissive -fno-use-cxa-atexit -nostdlib -ggdb -O3 -I. -Itensorflow/lite/micro/tools/make/downloads/ -Itensorflow/lite/micro/tools/make/downloads/gemmlowp -Itensorflow/lite/micro/tools/make/downloads/flatbuffers/include -Itensorflow/lite/micro/tools/make/downloads/ruy -Itensorflow/lite/micro/tools/make/downloads/AmbiqSuite-Rel2.2.0/boards_sfe/common/third_party/hm01b0 -isystemtensorflow/lite/micro/tools/make/downloads/cmsis/CMSIS/Core/Include/ -isystemtensorflow/lite/micro/tools/make/downloads/cmsis/CMSIS/DSP/Include/ -Itensorflow/lite/micro/tools/make/downloads/gcc_embedded//arm-none-eabi/ -Itensorflow/lite/micro/tools/make/downloads/AmbiqSuite-Rel2.2.0/mcu/apollo3/ -Itensorflow/lite/micro/tools/make/downloads/AmbiqSuite-Rel2.2.0/CMSIS/AmbiqMicro/Include/ -Itensorflow/lite/micro/tools/make/downloads/AmbiqSuite-Rel2.2.0/boards_sfe/edge/bsp -Itensorflow/lite/micro/tools/make/downloads/AmbiqSuite-Rel2.2.0/devices/ -Itensorflow/lite/micro/tools/make/downloads/AmbiqSuite-Rel2.2.0/utils/ -Itensorflow/lite/micro/tools/make/downloads/cmsis//CMSIS/Core/Include -Itensorflow/lite/micro/tools/make/downloads/cmsis//CMSIS/NN/Include -Itensorflow/lite/micro/tools/make/downloads/cmsis//CMSIS/DSP/Include -Itensorflow/lite/micro/tools/make/downloads/kissfft -Itensorflow/lite/micro/tools/make/downloads/AmbiqSuite-Rel2.2.0/boards_sfe/common/third_party/lis2dh12/ -c tensorflow/lite/micro/kernels/cmsis-nn/conv.cc -o tensorflow/lite/micro/tools/make/gen/sparkfun_edge_cortex-m4/obj/tensorflow/lite/micro/kernels/cmsis-nn/conv.o
tensorflow/lite/micro/kernels/cmsis-nn/conv.cc: In function 'TfLiteStatus tflite::ops::micro::conv::EvalQuantizedPerChannel(TfLiteContext*, TfLiteNode*, TfLiteConvParams*, tflite::ops::micro::conv::OpData*, const TfLiteTensor*, const TfLiteTensor*, const TfLiteTensor*, TfLiteTensor*, TfLiteTensor*)':
tensorflow/lite/micro/kernels/cmsis-nn/conv.cc:269:30: error: 'arm_convolve_1_x_n_s8_get_buffer_size' was not declared in this scope
     const int32_t buf_size = arm_convolve_1_x_n_s8_get_buffer_size(
                              ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
tensorflow/lite/micro/kernels/cmsis-nn/conv.cc:269:30: note: suggested alternative: 'arm_convolve_s8_get_buffer_size'
     const int32_t buf_size = arm_convolve_1_x_n_s8_get_buffer_size(
                              ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
                              arm_convolve_s8_get_buffer_size
tensorflow/lite/micro/kernels/cmsis-nn/conv.cc:271:9: error: 'get_cmsis_scratch_buffer' was not declared in this scope
     if (get_cmsis_scratch_buffer(context, &buf, buf_size) != kTfLiteOk) {
         ^~~~~~~~~~~~~~~~~~~~~~~~
tensorflow/lite/micro/tools/make/Makefile:288: recipe for target 'tensorflow/lite/micro/tools/make/gen/sparkfun_edge_cortex-m4/obj/tensorflow/lite/micro/kernels/cmsis-nn/conv.o' failed
make: *** [tensorflow/lite/micro/tools/make/gen/sparkfun_edge_cortex-m4/obj/tensorflow/lite/micro/kernels/cmsis-nn/conv.o] Error 1`


without the TAGS=cmsis-nn flags, the code builds without trouble ...

Best Regards




"
38561,Unwanted tf.function retracing when using variable-length inputs,"**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04
- TensorFlow installed from (source or binary): pip
- TensorFlow version (use command below): 2.2.0rc2
- Python version: 3.6.8

**Describe the current behavior**

A lot of warnings saying that there is a tf.function retracing are happening when using a keras model in a loop with variable length inputs.

**Describe the expected behavior**

I would like not to have retracing if there is no need (for example a fully convolutionnal model).

**Standalone code to reproduce the issue** 

```python
from random import randint

import tensorflow as tf
from tensorflow.keras.layers import Conv1D
from tensorflow.keras.models import Sequential

model = Sequential()
model.add(Conv1D(8, 3))
model.build([None, 12, 1])

predict_tensors = [
    tf.random.normal([randint(1, 8), randint(4, 40), 1])
    for _ in range(10)
]
for t in predict_tensors:
    _ = model.predict(t)
```

**Other info / logs** 

Logs:
```
WARNING: Logging before flag parsing goes to stderr.
W0406 09:22:52.525994 139643050075904 def_function.py:598] 5 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f00a7fc1268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.
W0406 09:22:52.615050 139643050075904 def_function.py:598] 6 out of the last 7 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f00a7fc1268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.
W0406 09:22:52.653312 139643050075904 def_function.py:598] 7 out of the last 8 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f00a7fc1268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.
W0406 09:22:52.706550 139643050075904 def_function.py:598] 8 out of the last 10 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f00a7fc1268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.
```

This issue was originally described [here](https://github.com/tensorflow/tensorflow/issues/34025#issuecomment-609612284), and some other people have had trouble with [training as well](https://github.com/tensorflow/tensorflow/issues/34025#issuecomment-609186763).

When switching back to 2.1, the problem is gone."
38560,Memory leak when try to use Metal delegate with “TFLGpuDelegateWaitTypeAggressive” option,"**System information** 
- Mobile device ：iPhone XR
- OS version：13.3.1

**Describe the current behavior**
I encountered a memory leak problem when trying  to deploy metal delegate backend on iPhone.

**Describe the expected behavior**
There is no memory leak in tflite lib

**Standalone code to reproduce the issue** 
1)	Modify the source code in metal_delegate.mm as follows
At line 109, add “alarm_thread_ = 0; “ during the init of “alarm_thread_”;
### 
      device_ = [command_queue_ device];
      total_alarms_ = 1;
      alarm_thread_ = 0;
      NSString* error;

> Note:
This change is to allow the “alarm_thread” thread to run normally when metal delegate option is set to “TFLGpuDelegateWaitTypeAggressive”. 

2)	Recompile the modified source code, generate tflite framework lib and metal delegate library
3)	Use the IOS project located in lite/examples/ios/camera to test the new lib generated by step 2)
Modify the source code in CameraExampleViewController.mm as follows
> TFLGpuDelegateOptions options; 
  options.allow_precision_loss = true; 
  // options.wait_type = TFLGpuDelegateWaitTypeActive; 
  options.wait_type = TFLGpuDelegateWaitTypeAggressive; 
  delegate = TFLGpuDelegateCreate(&options); 
  interpreter->ModifyGraphWithDelegate(delegate);

4)	Use Xcode IDE to recompile the camera project, it can be seen that when the APP is running on iPhone, the memory keeps growing.


**Other info / logs** Include any logs or source code that would be helpful to

"
38559,Failed to use vectorizing mapping for tf.data,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information** 
- OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04):  ubuntu18.04
- TensorFlow installed from (source or
binary): - TensorFlow version (use command below):  pip, tf2.1.0
- CUDA/cuDNN version: - GPU model and memory: cuda10.1, cudnn7.6.5

**Describe the current behavior**
Failed to apply vectorizing mapping for tf.data

**Describe the expected behavior**
Apply vectorizing mapping for tf.data and speed up as described in https://www.tensorflow.org/guide/data_performance#vectorizing_mapping

**Standalone code to reproduce the issue** 
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

    import tensorflow as tf

    data = tf.data.TFRecordDataset(['images.tfrecord'])

    image_feature_description = {
        'height': tf.io.FixedLenFeature([], tf.int64),
        'width': tf.io.FixedLenFeature([], tf.int64),
        'depth': tf.io.FixedLenFeature([], tf.int64),
        'bboxes': tf.io.VarLenFeature(tf.int64),
        'image_raw': tf.io.FixedLenFeature([], tf.string),
    }

    def parse_example(example):
        data = tf.io.parse_single_example(example, image_feature_description)
        
        img = tf.io.decode_jpeg(data['image_raw'])
        
        img = tf.image.resize(img, (416, 416))

        bboxes = data['bboxes']
        bboxes = tf.sparse.to_dense(bboxes)
        bboxes = tf.reshape(bboxes, [-1, 5])

        return img, bboxes


    #data = data.map(parse_example).batch(1)  # this works
    data = data.batch(1).map(parse_example)  # I tried to apply vectorizing mapping but errors raised

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

    Traceback (most recent call last):
    File ""test_tfrecord.py"", line 28, in <module>
        data = data.batch(1).map(parse_example)
    File ""/home/wilson/venv/lib/python3.6/site-packages/tensorflow_core/python/data/ops/dataset_ops.py"", line 1588, in map
        return MapDataset(self, map_func, preserve_cardinality=True)
    File ""/home/wilson/venv/lib/python3.6/site-packages/tensorflow_core/python/data/ops/dataset_ops.py"", line 3888, in __init__
        use_legacy_function=use_legacy_function)
    File ""/home/wilson/venv/lib/python3.6/site-packages/tensorflow_core/python/data/ops/dataset_ops.py"", line 3147, in __init__
        self._function = wrapper_fn._get_concrete_function_internal()
    File ""/home/wilson/venv/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py"", line 2395, in _get_concrete_function_internal
        *args, **kwargs)
    File ""/home/wilson/venv/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py"", line 2389, in _get_concrete_function_internal_garbage_collected
        graph_function, _, _ = self._maybe_define_function(args, kwargs)
    File ""/home/wilson/venv/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py"", line 2703, in _maybe_define_function
        graph_function = self._create_graph_function(args, kwargs)
    File ""/home/wilson/venv/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py"", line 2593, in _create_graph_function
        capture_by_value=self._capture_by_value),
    File ""/home/wilson/venv/lib/python3.6/site-packages/tensorflow_core/python/framework/func_graph.py"", line 978, in func_graph_from_py_func
        func_outputs = python_func(*func_args, **func_kwargs)
    File ""/home/wilson/venv/lib/python3.6/site-packages/tensorflow_core/python/data/ops/dataset_ops.py"", line 3140, in wrapper_fn
        ret = _wrapper_helper(*args)
    File ""/home/wilson/venv/lib/python3.6/site-packages/tensorflow_core/python/data/ops/dataset_ops.py"", line 3082, in _wrapper_helper
        ret = autograph.tf_convert(func, ag_ctx)(*nested_args)
    File ""/home/wilson/venv/lib/python3.6/site-packages/tensorflow_core/python/autograph/impl/api.py"", line 237, in wrapper
        raise e.ag_error_metadata.to_exception(e)
    ValueError: in converted code:

        test_tfrecord.py:14 parse_example  *
            data = tf.io.parse_single_example(example, image_feature_description)
        /home/wilson/venv/lib/python3.6/site-packages/tensorflow_core/python/ops/parsing_ops.py:472 parse_single_example_v2_unoptimized
            serialized = _assert_scalar(serialized, ""serialized"")
        /home/wilson/venv/lib/python3.6/site-packages/tensorflow_core/python/ops/parsing_ops.py:1319 _assert_scalar
            raise ValueError(""Input %s must be a scalar"" % name)

        ValueError: Input serialized must be a scalar

How should I fix it, thanks"
38558,"ValueError: None is only supported in the 1st dimension. Tensor 'image_tensor' has invalid shape '[None, None, None, 3]'.","**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Linux Ubuntu 18.04
- TensorFlow installed from (source or binary): pip install 
- TensorFlow version (or github SHA if from source): 2.1.0


**Command used to run the converter or code if you’re using the Python API**
If possible, please share a link to Colab/Jupyter/any notebook.

```
tflite_convert --saved_model_dir=/path/to/automl/efficientdet/ssd_mobilenet_v1_fpn_shared_box_predictor_640x640_coco14_sync_2018_07_03/saved_model/ --output_file=/path/to/automl/efficientdet/ssd_mobilenet_v1_fpn_shared_box_predictor_640x640_coco14_sync_2018_07_03/
```

**The output from the converter invocation**

```
Traceback (most recent call last):

  File ""/home/hulining/.local/bin/tflite_convert"", line 11, in <module>
    sys.exit(main())

  File ""/home/hulining/.local/lib/python3.6/site-packages/tensorflow/lite/python/tflite_convert.py"", line 503, in main

    app.run(main=run_main, argv=sys.argv[:1])

  File ""/home/hulining/.local/lib/python3.6/site-packages/tensorflow/python/platform/app.py"", line 40, in run

    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)

  File ""/home/hulining/.local/lib/python3.6/site-packages/absl/app.py"", line 299, in run
    _run_main(main, args)

  File ""/home/hulining/.local/lib/python3.6/site-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))

  File ""/home/hulining/.local/lib/python3.6/site-packages/tensorflow/lite/python/tflite_convert.py"", line 499, in run_main

    _convert_tf1_model(tflite_flags)

  File ""/home/hulining/.local/lib/python3.6/site-packages/tensorflow/lite/python/tflite_convert.py"", line 193, in _convert_tf1_model

    output_data = converter.convert()

  File ""/home/hulining/.local/lib/python3.6/site-packages/tensorflow/lite/python/lite.py"", line 811, in convert

    _get_tensor_name(tensor), shape_list))

ValueError: None is only supported in the 1st dimension. Tensor 'image_tensor' has invalid shape '[None, None, None, 3]'.

```

**Also, please include a link to the saved model or GraphDef**

```
https://github.com/google/automl/tree/master/efficientdet

http://download.tensorflow.org/models/object_detection/ssd_resnet50_v1_fpn_shared_box_predictor_640x640_coco14_sync_2018_07_03.tar.gz

http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v1_fpn_shared_box_predictor_640x640_coco14_sync_2018_07_03.tar.gz
```

**Failure details**
I tried  several ways like Python API and command line and several models above to convert a .pb file to a tflite file. Both of them failed with the error above.
don't know how to slove the error.


"
38557,TF 1.13 with TRT 6.0,"Is it possible to modify tensorrt submodule from tensorflow 1.13 to support it with TRT 6.0? Can it support TRT 6.0?
I have seen performance drop for only tensorflow models from TF 1.13 to  TF 1.15. So I want to stick to 1.13 with TRT 6.0."
38556,Can not create control inputs with tf.control_dependencies ,"I was expecting to get some control inputs with `tf.control_dependencies()`, but the following test code did not give back what I expected.
    
    import tensorflow as tf

    a = tf.get_variable('a', shape = [2, 3])
    b = tf.get_variable('b', shape = [2, 3])
    c = tf.scalar_mul(2, a)
    d = tf.scalar_mul(3, b)

    with tf.control_dependencies([d, c]):
      f = d-c

    print (f.op.control_inputs)

It returned `[]`. If I did the other way

    f = d-c
    f.op._add_control_inputs([c.op, d.op])
    print (f.op.control_inputs)

I got `[<tf.Operation 'Mul' type=Mul>, <tf.Operation 'Mul_1' type=Mul>]`, which seems good. 

So does `tf.control_dependencies()` create control dependencies? Or does `op.control_inputs` reflect all the control inputs? Could this be a bug?"
38555,[tf.function] tf.Variable converted to tf.Tensor automatically in second loop,"
**System information** 
- Have I written custom code :  Yes
- OS Platform and Distribution (e.g.,Linux Ubuntu 16.04):   MacOS Mojave 10.14.5
- TensorFlow installed from (source or binary): - TensorFlow version (use command below):  pip
- Python version: - 3.6.5

**Describe the current behavior**
tf.Variable converted to tf.Tensor automatically after second loop in function decorated by tf.function.

**Describe the expected behavior**
It should not convert automatically.

**Standalone code to reproduce the issue** 

```python
@tf.function
def foo(a):
    print(a)
    for i in range(10):
        if a[0] > 3:
            print(f'True: a_{i}: {a}')
            a = a[0].assign(1)
        else:
            print(f'False: a_{i}: {a}')
            a = a[0].assign(2)
a = tf.Variable(np.array([1,2,3]))
foo(a)
```

**Other info / logs** 

```
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
<ipython-input-25-9c589be6e6c6> in <module>
----> 1 foo(a)

~/.pyenv/versions/3.6.5/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py in __call__(self, *args, **kwds)
    566         xla_context.Exit()
    567     else:
--> 568       result = self._call(*args, **kwds)
    569 
    570     if tracing_count == self._get_tracing_count():

~/.pyenv/versions/3.6.5/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py in _call(self, *args, **kwds)
    613       # This is the first call of __call__, so we have to initialize.
    614       initializers = []
--> 615       self._initialize(args, kwds, add_initializers_to=initializers)
    616     finally:
    617       # At this point we know that the initialization is complete (or less

~/.pyenv/versions/3.6.5/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py in _initialize(self, args, kwds, add_initializers_to)
    495     self._concrete_stateful_fn = (
    496         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access
--> 497             *args, **kwds))
    498 
    499     def invalid_creator_scope(*unused_args, **unused_kwds):

~/.pyenv/versions/3.6.5/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py in _get_concrete_function_internal_garbage_collected(self, *args, **kwargs)
   2387       args, kwargs = None, None
   2388     with self._lock:
-> 2389       graph_function, _, _ = self._maybe_define_function(args, kwargs)
   2390     return graph_function
   2391 

~/.pyenv/versions/3.6.5/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py in _maybe_define_function(self, args, kwargs)
   2701 
   2702       self._function_cache.missed.add(call_context_key)
-> 2703       graph_function = self._create_graph_function(args, kwargs)
   2704       self._function_cache.primary[cache_key] = graph_function
   2705       return graph_function, args, kwargs

~/.pyenv/versions/3.6.5/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py in _create_graph_function(self, args, kwargs, override_flat_arg_shapes)
   2591             arg_names=arg_names,
   2592             override_flat_arg_shapes=override_flat_arg_shapes,
-> 2593             capture_by_value=self._capture_by_value),
   2594         self._function_attributes,
   2595         # Tell the ConcreteFunction to clean up its graph once it goes out of

~/.pyenv/versions/3.6.5/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/framework/func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)
    976                                           converted_func)
    977 
--> 978       func_outputs = python_func(*func_args, **func_kwargs)
    979 
    980       # invariant: `func_outputs` contains only Tensors, CompositeTensors,

~/.pyenv/versions/3.6.5/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py in wrapped_fn(*args, **kwds)
    437         # __wrapped__ allows AutoGraph to swap in a converted function. We give
    438         # the function a weak reference to itself to avoid a reference cycle.
--> 439         return weak_wrapped_fn().__wrapped__(*args, **kwds)
    440     weak_wrapped_fn = weakref.ref(wrapped_fn)
    441 

~/.pyenv/versions/3.6.5/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/framework/func_graph.py in wrapper(*args, **kwargs)
    966           except Exception as e:  # pylint:disable=broad-except
    967             if hasattr(e, ""ag_error_metadata""):
--> 968               raise e.ag_error_metadata.to_exception(e)
    969             else:
    970               raise

ValueError: in converted code:

    <ipython-input-23-3a2d4adc4a09>:7 foo  *
        a = a[0].assign(1)
    /Users/mac/.pyenv/versions/3.6.5/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/ops/array_ops.py:1074 assign
        raise ValueError(""Sliced assignment is only supported for variables"")

    ValueError: Sliced assignment is only supported for variables
```"
38552,Failed to load the Native tensorflow routine,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04 LTS 
- TensorFlow installed from (source or binary):  https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-1.5.0-py3-none-any.whl
- TensorFlow version: Tensorflow 1.5.0
- Python version: Python 2.7.12
- Installed using virtualenv? pip? conda?: pip




**Describe the problem**
I tried running : 

```
import tensorflow as tf
print(tf.reduce_sum(tf.random.normal([1000, 1000])))
```


**Any other info / logs**
The following is the error I get.

```
Traceback (most recent call last):
  File ""/home/sarva/.local/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""/home/sarva/.local/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""/home/sarva/.local/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""/usr/lib/python3.5/imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""/usr/lib/python3.5/imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: /home/sarva/.local/lib/python3.5/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so: invalid ELF header

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""wtf.py"", line 2, in <module>
    import tensorflow as tf
  File ""/home/sarva/.local/lib/python3.5/site-packages/tensorflow/__init__.py"", line 24, in <module>
    from tensorflow.python import *
  File ""/home/sarva/.local/lib/python3.5/site-packages/tensorflow/python/__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""/home/sarva/.local/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""/home/sarva/.local/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""/home/sarva/.local/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""/home/sarva/.local/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""/usr/lib/python3.5/imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""/usr/lib/python3.5/imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: /home/sarva/.local/lib/python3.5/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so: invalid ELF header


Failed to load the native TensorFlow runtime.
```

**additional info**
 Can someone please guide on how to properly install tensorflow for my system. I am running ubuntu in VirtualBox on Windows 10 if that helps.

On typing uname -a: the system info returned is Linux ubuntu 4.4.0-177-generic #207-Ubuntu SMP Mon Mar 16 01:15:50 UTC 2020 i686 i686 i686 GNU/Linux
"
38551,Linking of tensorflowlite_c.so throws multiple undefined reference errors,"**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04): GNU/Linux aarch64
- TensorFlow installed from (source or
binary): source
- TensorFlow version (use command below): 2.2.0
- Python version: 3.6
- Bazel version (if compiling from source): 2.0.0
- GCC/Compiler version (if compiling from
source): gcc version 7.4.0 (Ubuntu/Linaro 7.4.0-1ubuntu1~18.04.1) 

**Describe the current behavior**
Built the extended TF lite runtime with enable tf ops (complete process found in issue #38077). Compilation of the minimal.cc example succeeds, but the linker throws mulitple errors afterwards.

**Describe the expected behavior**
Build should complete, as the shared object is found.

**Standalone code to reproduce the issue** 
make executes the commands:
```
g++ -Iinclude -I/workspace/tensorflow -I/workspace/abseil-cpp -Wall  -c src/minimal.c -o obj/minimal.o
g++ -Llib obj/minimal.o -ltensorflowlite_c -lflatbuffers -o test
```

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
```
obj/minimal.o: In function `main':
minimal.c:(.text+0x6c): undefined reference to `tflite::DefaultErrorReporter()'
minimal.c:(.text+0x80): undefined reference to `tflite::FlatBufferModel::BuildFromFile(char const*, tflite::ErrorReporter*)'
minimal.c:(.text+0xe0): undefined reference to `tflite::ops::builtin::BuiltinOpResolver::BuiltinOpResolver()'
minimal.c:(.text+0x100): undefined reference to `tflite::impl::InterpreterBuilder::InterpreterBuilder(tflite::FlatBufferModel const&, tflite::OpResolver const&)'
minimal.c:(.text+0x110): undefined reference to `tflite::impl::InterpreterBuilder::operator()(std::unique_ptr<tflite::impl::Interpreter, std::default_delete<tflite::impl::Interpreter> >*)'
minimal.c:(.text+0x174): undefined reference to `tflite::impl::Interpreter::AllocateTensors()'
minimal.c:(.text+0x1d8): undefined reference to `tflite::PrintInterpreterState(tflite::impl::Interpreter*)'
minimal.c:(.text+0x1e4): undefined reference to `tflite::impl::Interpreter::Invoke()'
minimal.c:(.text+0x248): undefined reference to `tflite::PrintInterpreterState(tflite::impl::Interpreter*)'
minimal.c:(.text+0x25c): undefined reference to `tflite::impl::InterpreterBuilder::~InterpreterBuilder()'
minimal.c:(.text+0x2a4): undefined reference to `tflite::impl::InterpreterBuilder::~InterpreterBuilder()'
obj/minimal.o: In function `std::default_delete<tflite::FlatBufferModel>::operator()(tflite::FlatBufferModel*) const':
minimal.c:(.text._ZNKSt14default_deleteIN6tflite15FlatBufferModelEEclEPS1_[_ZNKSt14default_deleteIN6tflite15FlatBufferModelEEclEPS1_]+0x24): undefined reference to `tflite::FlatBufferModel::~FlatBufferModel()'
obj/minimal.o: In function `std::default_delete<tflite::impl::Interpreter>::operator()(tflite::impl::Interpreter*) const':
minimal.c:(.text._ZNKSt14default_deleteIN6tflite4impl11InterpreterEEclEPS2_[_ZNKSt14default_deleteIN6tflite4impl11InterpreterEEclEPS2_]+0x24): undefined reference to `tflite::impl::Interpreter::~Interpreter()'
obj/minimal.o:(.data.rel.ro._ZTVN6tflite3ops7builtin17BuiltinOpResolverE[_ZTVN6tflite3ops7builtin17BuiltinOpResolverE]+0x10): undefined reference to `tflite::MutableOpResolver::FindOp(tflite::BuiltinOperator, int) const'
obj/minimal.o:(.data.rel.ro._ZTVN6tflite3ops7builtin17BuiltinOpResolverE[_ZTVN6tflite3ops7builtin17BuiltinOpResolverE]+0x18): undefined reference to `tflite::MutableOpResolver::FindOp(char const*, int) const'
obj/minimal.o:(.data.rel.ro._ZTIN6tflite3ops7builtin17BuiltinOpResolverE[_ZTIN6tflite3ops7builtin17BuiltinOpResolverE]+0x10): undefined reference to `typeinfo for tflite::MutableOpResolver'
obj/minimal.o: In function `tflite::MutableOpResolver::~MutableOpResolver()':
minimal.c:(.text._ZN6tflite17MutableOpResolverD2Ev[_ZN6tflite17MutableOpResolverD5Ev]+0xc): undefined reference to `vtable for tflite::MutableOpResolver'
minimal.c:(.text._ZN6tflite17MutableOpResolverD2Ev[_ZN6tflite17MutableOpResolverD5Ev]+0x10): undefined reference to `vtable for tflite::MutableOpResolver'
collect2: error: ld returned 1 exit status
makefile:20: recipe for target 'test' failed
make: *** [test] Error 1
```
"
38550,Keras Model in SavedModel format Errors on Loading -ValueError('Model inputs are already set.'),"**System information**

Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
No
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): ProductName:	Mac OS X, ProductVersion:	10.15.2, BuildVersion:	19C57
TensorFlow installed from (source or binary): pip
TensorFlow version (use command below): 2.1.0
Python version: 3.6.8
CUDA/cuDNN version: None
GPU model and memory: None

**Describe the current behavior**

When trying to load one of my SavedModel format models (saved using 1.15.0) using` tf.keras.models.load_model `an error is thrown at the following location:

```
  File ""/Users/saurabh/.pyenv/versions/emotion-python/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py"", line 2671, in _set_input_attrs
    raise ValueError('Model inputs are already set.')
```
**I can successfully load and run this model using TensorFlow versions 2.0.0, 1.15.0 and 1.14.0.**


**Describe the expected behavior**

Can successfully load a model from a SMB(SavedModel format) file.

**Code to reproduce the issue:**

```
import tensorflow as tf

model_smb = tf.keras.models.load_model('smbnew', compile=False)
```

**Other info / logs:**

**_I am also attaching a dummy SavedModel model below which can be used to test.**



Complete Stacktrace of the error:

```
Traceback (most recent call last):
  File ""setup.py"", line 9, in <module>
    model_smb = tf.keras.models.load_model('smbnew', compile=False)
  File ""python3.6/site-packages/tensorflow_core/python/keras/saving/save.py"", line 150, in load_model
    return saved_model_load.load(filepath, compile)
  File ""python3.6/site-packages/tensorflow_core/python/keras/saving/saved_model/load.py"", line 89, in load
    model = tf_load.load_internal(path, loader_cls=KerasObjectLoader)
  File ""python3.6/site-packages/tensorflow_core/python/saved_model/load.py"", line 552, in load_internal
    export_dir)
  File ""python3.6/site-packages/tensorflow_core/python/keras/saving/saved_model/load.py"", line 119, in __init__
    self._finalize()
  File ""python3.6/site-packages/tensorflow_core/python/keras/saving/saved_model/load.py"", line 165, in _finalize
    node._set_inputs(inputs)
  File ""python3.6/site-packages/tensorflow_core/python/keras/engine/training.py"", line 2647, in _set_inputs
    inputs = self._set_input_attrs(inputs)
  File ""python3.6/site-packages/tensorflow_core/python/training/tracking/base.py"", line 457, in _method_wrapper
    result = method(self, *args, **kwargs)
  File ""python3.6/site-packages/tensorflow_core/python/keras/engine/training.py"", line 2671, in _set_input_attrs
    raise ValueError('Model inputs are already set.')
ValueError: Model inputs are already set.

```
When loaded with tf.keras in v2.0.0 the layers, model config, inputs, outputs, summary etc. are all parsed correctly, as well as being able to run data through the model."
38548,Beam search for Transformer example,Hi! I have been following the Transformer tutorial here https://github.com/tensorflow/docs/blob/master/site/en/tutorials/text/transformer.ipynb and I am wondering how can beam search be implemented to work with the current code? Thanks!
38547,TimeDistributed fails with GlobalAveragePooling1D layer. ,"I am trying to use Bert to encode chunks of text. I get the 3D output from Bert, and trying to apply GlobalAveragePooling1D. I get list index out of range. Problem seems to be when applying timedistributed layer to globalaveragepooling1d layer. See below.

`   def bert_model(self, max_seq_len, number_of_labels=130, adapter_size=64, bert_config_file=None, bert_ckpt_file=None, bert_model_name=None):

        with tf.io.gfile.GFile(bert_config_file, ""r"") as reader:
            bc = StockBertConfig.from_json_string(reader.read())
            bert_params = map_stock_config_to_params(bc)
            bert_params.adapter_size = adapter_size
            bert = BertModelLayer.from_params(bert_params, name=""bert"")

        sentence_input = Input(shape=(max_seq_len,), dtype='float32', name=""sentence_input_ids"")
        subtitles_input = Input(shape=(self.max_shape[1], max_seq_len), dtype='int32', name=""SubtitlesInput"")

        bert_output = bert(sentence_input)
        bert_output = GlobalAveragePooling1D()(bert_output)

        self.bert_sentence_model = Model(sentence_input, bert_output)

        segment_time_distributed = TimeDistributed(self.bert_sentence_model, name=""TimeDistributedSegment"")
        segment_cnn = Conv1D(256, 2, padding=""same"", strides=1, activation=""relu"", name=""Segment2Conv1D"")
        segment_max_pool_2 = MaxPooling1D(pool_size=3, name=""Segment2MaxPool1D"")

        subtitles_timedistributed = segment_time_distributed(subtitles_input)
        subtitles_cnn = segment_cnn(subtitles_timedistributed)
        subtitles_maxpool = segment_max_pool_2(subtitles_cnn)

        subtitles_dropout = SpatialDropout1D(0.30, name=""SubtitlesDropout"")(subtitles_maxpool)
        subtitles_pre_attention_output = Dense(256, name=""SubtitlesPreAttnOutput"")(subtitles_dropout)

        attention_subtitles = Attention(name=""SubtitlesAttention"")([subtitles_pre_attention_output, subtitles_maxpool])

        subtitles_max_output = GlobalMaxPool1D(name=""GlobalMaxPoolSubitles"")(attention_subtitles)
        subtitles_avg_output = GlobalAveragePooling1D(name=""GlobalAvgPoolSubitles"")(attention_subtitles)

        concat_output = Concatenate(axis=-1, name=""OutputConcatenate"")([subtitles_max_output, subtitles_avg_output])
        dropput = Dropout(0.40)(concat_output)
        output = Dense(number_of_labels, activation=""sigmoid"", name=""Output"")(dropput)

        # model = keras.Model(inputs=[sentence_input_ids, token_type_ids], outputs=logits)
        # model.build(input_shape=[(None, max_seq_len), (None, max_seq_len)])
        self.model = Model(inputs=subtitles_input, outputs=output)
        #self.model.build(input_shape=(None, max_seq_len))

        # load the pre-trained model weights
        load_stock_weights(bert, bert_ckpt_file)

        # freeze weights if adapter-BERT is used
        if adapter_size is not None:
            self.freeze_bert_layers(bert)

        self.model.compile(optimizer=""adam"",
                      loss=""binary_crossentropy"")

        self.bert_sentence_model.summary()
        self.model.summary()`

Traceback (most recent call last):
  File ""C:/Development/Projects/GenrePrediction/GenrePredictionModel.py"", line 765, in <module>
    validation_labels=genre_prediction.validation_labels, epochs=1000, batch_size=1)
  File ""C:/Development/Projects/GenrePrediction/GenrePredictionModel.py"", line 468, in fit_bert
    self.sentence_model, self.model = self.bert_model(max_sentence_length, bert_ckpt_file=""D:/Development/Projects/bert_models/""+self.bert_model_name+""/bert_model.ckpt"", bert_config_file=""D:/Development/Projects/bert_models/""+self.bert_model_name+""/bert_config.json"", number_of_labels=len(self.genres))
  **File ""C:/Development/Projects/GenrePrediction/GenrePredictionModel.py"", line 336, in bert_model
    subtitles_timedistributed = segment_time_distributed(subtitles_input)**
  File ""C:\Program Files\Python37\lib\site-packages\tensorflow_core\python\keras\engine\base_layer.py"", line 773, in __call__
    outputs = call_fn(cast_inputs, *args, **kwargs)
  File ""C:\Program Files\Python37\lib\site-packages\tensorflow_core\python\keras\layers\wrappers.py"", line 270, in call
    output_shape = self.compute_output_shape(input_shape).as_list()
  File ""C:\Program Files\Python37\lib\site-packages\tensorflow_core\python\keras\layers\wrappers.py"", line 212, in compute_output_shape
    child_output_shape = self.layer.compute_output_shape(child_input_shape)
  File ""C:\Program Files\Python37\lib\site-packages\tensorflow_core\python\keras\engine\network.py"", line 768, in compute_output_shape
    layer_output_shapes = layer.compute_output_shape(layer_input_shapes)
  File ""C:\Program Files\Python37\lib\site-packages\tensorflow_core\python\keras\layers\pooling.py"", line 591, in compute_output_shape
    return tensor_shape.TensorShape([input_shape[0], input_shape[2]])
IndexError: list index out of range


<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow): 
- OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04): 
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if
the issue happens on mobile device: 
- TensorFlow installed from (source or
binary): - TensorFlow version (use command below): 
- Python version: - Bazel
version (if compiling from source):
- GCC/Compiler version (if compiling from
source): 
- CUDA/cuDNN version: - GPU model and memory: 10.1, 7,65

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

**Describe the expected behavior**

**Standalone code to reproduce the issue** 
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
38546,FTRL maths displayed messy,"In this doc https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Ftrl the math is messed up

see https://snipboard.io/my0uSb.jpg

using chrome browser"
38545,tf.image.extract_glimpse does not work as it should (tensorflow 2.1),"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10 64 bit
- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: No
- **TensorFlow installed from (source or binary)**: NVIDIA (https://docs.nvidia.com/deeplearning/frameworks/tensorflow-release-notes)
- **TensorFlow version (use command below)**: 2.1
- **Python version**: 3.6.9



### Describe the problem
Hello, I am trying to use tf.image.extract_glimpse and I realised that It does not work as it should.
The issue was the same than 4 year ago #7681 and it was solved. But It seems like that in the new version of tensorflow 2.1 it is not fixed.

### Source code / logs
You can try to reproduce this code:


BATCH_SIZE = 1
IMAGE_HEIGHT = 7
IMAGE_WIDTH = 7
CHANNELS = 1
GLIMPSE_SIZE = (3,3)

image = tf.reshape(tf.range(49, delta=1, dtype=tf.float32),
  shape=(BATCH_SIZE, IMAGE_HEIGHT, IMAGE_WIDTH, CHANNELS))

output1 = tf.image.extract_glimpse(image, size=GLIMPSE_SIZE,
  offsets=[[1,1]], centered=False, normalized=False)

output2 = tf.image.extract_glimpse(image, size=GLIMPSE_SIZE,
  offsets=[[2,2]], centered=False, normalized=False)

output1 = [[  0.   1.   2.]
                 [  5.   6.   7.]
                 [ 10.  11.  12.]]

output2 =  [[  0.   1.   2.]
                 [  5.   6.   7.]
                 [ 10.  11.  12.]]

The results are the same, that we got in issue #7681."
38542,Macro pollution (Is it called like this) on windows,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
windows 10 x64
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
binary
- TensorFlow version:
2.1
- Python version:
3.7
- Installed using virtualenv? pip? conda?:
- Bazel version (if compiling from source):
0.27.1
- GCC/Compiler version (if compiling from source):
visual studio 2019
- CUDA/cuDNN version:
10.2/7
- GPU model and memory:
Turing


**Describe the problem**
Use compiled tensorflow to compile an empty project like this:
`#include <tensorflow/core/framework/tensor.h>

int main(int argc, char const* argv[])
{
    return 0;
}`
I got some errors like this:
warning C4003: not enough arguments for function-like macro invocation 'min'
error C2589: '(': illegal token on right side of '::'
error C2062: type 'unknown-type' unexpected
error C3805: 'type': unexpected token, expected either '}' or a ','.
Then I write `#undef max
#undef min`  on third_party\eigen3\unsupported\Eigen\CXX11\Tensor,it passed compile.

**Provide the exact sequence of commands / steps that you executed before running into the problem**
Compile tensorflow to get .dll .lib and header files.
Create an empty vs project,config and use those files.
Write ""#include <tensorflow/core/framework/tensor.h>"" and compile it.

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
38541,Issues of Adam Optimizer on Complex domain,"**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow):  Yes
- OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04):  Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if
the issue happens on mobile device: 
- TensorFlow installed from (source or
binary): `conda install -c conda-forge tensorflow-gpu=2.1`
- TensorFlow version (use command below):  2.1.0
- Python version: - 3.7.7
version (if compiling from source):
- GCC/Compiler version (if compiling from
source): 
- CUDA/cuDNN version: - GPU model and memory: 10.1.243/7.6.5

**Describe the current behavior**

I'm building a custom model that does computation in Complex value domain, we find the performance in accuracy sense by using Adam is worse than that by translating the whole model into a real domain counterpart (2 times network parameters, real and imag parts ), and use same Adam optimizer.

I dig into the sources codes of [Adam](https://github.com/tensorflow/tensorflow/blob/f270180a6caa8693f2b2888ac7e6b8e69c4feaa8/tensorflow/core/kernels/training_ops_gpu.cu.cc#L57), line 57: 

`v_i += one_minus_beta2 * (g_i * g_i - v_i);`

for real numbers, it is correct as g_i * g_i standards for 2nd order moments, while g_i * g_i in the Complex domain is pseudo-variance. Andy M. Sarrof also discuss this behavior in his [thesis](https://andysarroff.com/papers/sarroff2018a.pdf) (page 35, equation 3.56)

However, it is expected that this behavior does not throw errors because it's valid operation.

**Describe the expected behavior**

I suppose in [line 57](https://github.com/tensorflow/tensorflow/blob/f270180a6caa8693f2b2888ac7e6b8e69c4feaa8/tensorflow/core/kernels/training_ops_gpu.cu.cc#L57),  `g_i * g_i` should be replace by `g_i * {conjugate function}(g_i)` as pointed out by Andy M. Sarrof in this thesis [https://andysarroff.com/papers/sarroff2018a.pdf] (page 35, equation 3.56)

"
38540,Building a vocabulary from text data for classification,"I am following this [tutorial](https://www.tensorflow.org/tutorials/load_data/text) and [here](https://www.tensorflow.org/tutorials/load_data/text#build_vocabulary) the documentation says `There are a few ways to do this in both TensorFlow and Python.`. I am wondering what could be other ways of building a vocabulary. The way defined after this is slow for me since it is a loop and my dataset consists over 900,000 text docs."
38539,tf.function decorated functions fail in graph mode if any of the branches of conditionals would be invalid at runtime,"**System information** 
- Have I written custom code: yes
- OS Platform and Distribution: Ubuntu 18.04
- TensorFlow installed from: binary
- TensorFlow version: 2.1.0 
- Python version: 3.7.6

**Describe the current behavior**
As far as I followed the development of TF's @tf.function-decoration/autotracing, the aim is to mostly write ideomatic Python and have TF take care of building a corresponding TF op graph, with this feature being a highlight of TF2.

The simple function below, where one branch can only be properly executed when the conditional is met, albeit ideomatic Python, fails in graph mode, albeit it works in eager mode.

(I am aware that I can work around the situation; but I guess it not working as-is is a bug?)

**Describe the expected behavior**

The function working identically in both eager or graph mode.

**Standalone code to reproduce the issue** 
```python
import tensorflow as tf


@tf.function
def test_function(tensor):
    if tf.size(tensor) == 2:
        return tensor[1]
    else:
        return tensor[0]


tf.config.experimental_run_functions_eagerly(True)

print(test_function(tf.constant([1])))
print(test_function(tf.constant([1, 2])))
print(test_function(tf.constant([1, 2, 3])))

tf.config.experimental_run_functions_eagerly(False)

print(test_function(tf.constant([1])))
print(test_function(tf.constant([1, 2])))
print(test_function(tf.constant([1, 2, 3])))
```
```
> TF_CPP_MIN_LOG_LEVEL=2 python test.py
tf.Tensor(1, shape=(), dtype=int32)
tf.Tensor(2, shape=(), dtype=int32)
tf.Tensor(1, shape=(), dtype=int32)
Traceback (most recent call last):
  File ""test.py"", line 20, in <module>
    print(test_function(tf.constant([1])))
  File ""…/tensorflow_core/python/eager/def_function.py"", line 568, in __call__
    result = self._call(*args, **kwds)
  File ""…/tensorflow_core/python/eager/def_function.py"", line 615, in _call
    self._initialize(args, kwds, add_initializers_to=initializers)
  File ""…/tensorflow_core/python/eager/def_function.py"", line 497, in _initialize
    *args, **kwds))
  File ""…/tensorflow_core/python/eager/function.py"", line 2389, in _get_concrete_function_internal_garbage_collected
    graph_function, _, _ = self._maybe_define_function(args, kwargs)
  File ""…/tensorflow_core/python/eager/function.py"", line 2703, in _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)
  File ""…/tensorflow_core/python/eager/function.py"", line 2593, in _create_graph_function
    capture_by_value=self._capture_by_value),
  File ""…/tensorflow_core/python/framework/func_graph.py"", line 978, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File ""…/tensorflow_core/python/eager/def_function.py"", line 439, in wrapped_fn
    return weak_wrapped_fn().__wrapped__(*args, **kwds)
  File ""…/tensorflow_core/python/framework/func_graph.py"", line 968, in wrapper
    raise e.ag_error_metadata.to_exception(e)
ValueError: in converted code:

    test.py:7 test_function  *
        return tensor[1]
    …/tensorflow_core/python/ops/array_ops.py:898 _slice_helper
        name=name)
    …/tensorflow_core/python/ops/array_ops.py:1064 strided_slice
        shrink_axis_mask=shrink_axis_mask)
    …/tensorflow_core/python/ops/gen_array_ops.py:9535 strided_slice
        shrink_axis_mask=shrink_axis_mask, name=name)
    …/tensorflow_core/python/framework/op_def_library.py:742 _apply_op_helper
        attrs=attr_protos, op_def=op_def)
    …/tensorflow_core/python/framework/func_graph.py:595 _create_op_internal
        compute_device)
    …/tensorflow_core/python/framework/ops.py:3322 _create_op_internal
        op_def=op_def)
    …/tensorflow_core/python/framework/ops.py:1786 __init__
        control_input_ops)
    …/tensorflow_core/python/framework/ops.py:1622 _create_c_op
        raise ValueError(str(e))

    ValueError: slice index 1 of dimension 0 out of bounds. for 'strided_slice' (op: 'StridedSlice') with input shapes: [1], [1], [1], [1] and with computed input tensors: input[1] = <1>, input[2] = <2>, input[3] = <1>.
```"
38538,"kaggle tpu kernel(tf 2.2.0) ""Socket closed"" when using subclassing api ","When doing model.fit, will always got socket lost/closed error using tpu kernel V3-8 if using subclassing api while functional api is ok. code like below


    class Model(keras.Model):
        def __init__(self):
            super(Model, self).__init__() 

            bert_layer = hub.load(BERT_GCS_PATH_SAVEDMODEL)
            bert_layer = hub.KerasLayer(bert_layer, trainable=True)
            self.bert_layer = bert_layer
            self.dense = keras.layers.Dense(1)

       def call(self, input):
            input_word_ids = input['input_word_ids']
            input_mask = input['input_mask']
            segment_ids = input['all_segment_id']
  
            x, _ = self.bert_layer([input_word_ids, input_mask, segment_ids])
            x = self.dense(x)
            self.logit = x
            x = tf.math.sigmoid(x)
            return x"
38537,can not restore adagrad Variable,"for fixed_size_partitioner trainningVariable, adagrad Variable in  tf.GraphKeys.GLOBAL_VARIABLES is：<tf.Variable 'title_rank/title_rank/concat_projection/part_2/Adagrad:0' shape=(15, 1) dtype=float32_ref>
but in saved checkpoint: 'title_rank/concat_projection/ion/part_0/Adagrad', [75, 1]
shape is not right and restore adagrad Variable failed"
38536,C API for TensorFlow Lite for Microcontrollers (micro)?,"Hi,

I'm porting TF micro for my custom micro-controller. I also saw TF distribute C API (not C++) for general TF (not micro). Is it possible to add the C API to the micro package?"
38535,installation issue-ImportError: DLL load failed while importing _pywrap_tensorflow_internal: The specified module could not be found.,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:NO
- TensorFlow installed from (source or binary):source
- TensorFlow version:2.0
- Python version:3.8.2
- Installed using virtualenv? pip? conda?:pip
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:



**Describe the problem**

**Provide the exact sequence of commands / steps that you executed before running into the problem**


ImportError: Traceback (most recent call last):
  File ""C:\Users\Abhishek Sharma\anaconda3\envs\tfp3.8\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\Abhishek Sharma\anaconda3\envs\tfp3.8\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\Abhishek Sharma\anaconda3\envs\tfp3.8\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\Abhishek Sharma\anaconda3\envs\tfp3.8\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\Abhishek Sharma\anaconda3\envs\tfp3.8\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed while importing _pywrap_tensorflow_internal: The specified module could not be found.


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/errors

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.



**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
38534,Longer latency after both post quantization and aware-quantization training ,"**System information**

OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04.4
Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: None
TensorFlow installed from (source or binary): source
TensorFlow version: 1.15.2
Python version: 3.7.7
Installed using virtualenv? pip? conda?: pip
Bazel version (if compiling from source) : 0.26.1
GCC/Compiler version (if compiling from source): None
CUDA/cuDNN version: None
GPU model and memory: None
**Describe the problem

Provide the exact sequence of commands / steps that you executed before running into the problem**

I try to evaluate my TensorFlow Lite model using the tool in https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/tools/evaluation/tasks/coco_object_detection I evaluate 3 models: original model, model after full integer quantization and model after aware-quantization training. The model I use is SSD MobileNetV2 in object detection TensorFlow API and trained with another dataset. 

For the data I get, the original model has latency 151954, full interger quantized model's latency: 2970549, aware quantized model's: 945065

My code for running :
  -- \

  //tensorflow/lite/tools/evaluation/tasks/coco_object_detection:run_eval \

  --model_file=/home/sicong/Documents/model_zoo/ssd_mobilenet_v2_coco_2018_03_29/Udacity/Udacity_300_247705/full_integer_quantization_247705_200_dev01_with_input_inference.tflite \

  --ground_truth_images_path=/home/sicong/Documents/datasets/udacity/for_evaluation/images \

  --ground_truth_proto=/home/sicong/Documents/datasets/udacity/for_evaluation/ground_truth_change_id.pbtxt \

  --model_output_labels=/home/sicong/Documents/datasets/udacity/for_evaluation/udacity_label_map_edge_TPU.pbtxt \

  --output_file_path=/home/sicong/Documents/datasets/udacity/for_evaluation/full_integer_quantization_247705_200_dev01_with_input_inference.txt

Thank you for help!"
38532,TensorFlow Object Detection API with Keras model,"<em>Please make sure that this is an issue related to performance of TensorFlow.
As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:performance_template</em>

**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow): partially
- OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if
the issue happens on mobile device:  Desktop
- TensorFlow installed from (source or
binary): - TensorFlow version (use command below): 1.15
- Python version: - Bazel
version (if compiling from source): 3.6.9
- GCC/Compiler version (if compiling from
source): 
- CUDA/cuDNN version: 10.0/7.6.5
- GPU model and memory: GTX970 4GB

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
I feed custom trained model with a video stream. I would like to use output's bounding boxes to feed 6 different models trained in for example Keras. I use webcam tutorial from Object Detection API. Only way it works for now is to set session by Keras and load model from the beggining. It ruins the performance very much. 

**Describe the expected behavior**
I would like to have more than 1 fps with passing the detected objects to CNN Keras model.

**Standalone code to reproduce the issue** 
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

[Google Colab code](https://colab.research.google.com/drive/1O-FkQg6PGJ6EtCYzBE4oZeMKS5gbJSsa)


**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
38529,TFLite_Convertor cannot convert atrous_conv PB to tflite file,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow): 
- OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04): Linux Redhat 7
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if
the issue happens on mobile device: Desktop
- TensorFlow installed from (source or
binary): - TensorFlow version (use command below):  1.13.1
- Python version: - Bazel
version (if compiling from source): 3.6.5
- GCC/Compiler version (if compiling from
source): 
- CUDA/cuDNN version: - GPU model and memory: CPU

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
write a simple artous_conv model to convert like below:

input = tf.compat.v1.placeholder(tf.float32, shape=(1, 244, 244, 3))
    filter = [11, 11, 3, 64]

    filter_weight = tf.compat.v1.get_variable(
        ""weights"", filter,
        initializer=tf.truncated_normal_initializer(stddev=0.1)
    )
    tf.nn.atrous_conv2d(value=input, filters=filter_weight, rate=2,
                        padding='VALID')

Convert this PB to tflite by TFlite_convertor with below cmd:

tflite_convert --output_file=test.tflite --graph_def_file=frozen.pb --input_arrays=Placeholder --output_arrays=convolution/BatchToSpaceND

Error happened:

 ""TOCO failed. See console for info.\n%s\n%s\n"" % (stdout, stderr))
tensorflow.lite.python.convert.ConverterError: TOCO failed. See console for info.
2020-04-14 18:35:43.409903: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 5 operators, 11 arrays (0 quantized)
2020-04-14 18:35:43.410080: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 5 operators, 11 arrays (0 quantized)


**Describe the expected behavior**
Should be converted without error

**Standalone code to reproduce the issue** 
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
38528,tf.function does not transform nested class methods,"System information

Have I written custom code (as opposed to using a stock
example script provided in TensorFlow): true
OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04): OSX 10.14.5
TensorFlow installed from (source or
binary): pip
TensorFlow version (use command below): v2.1.0
Describe the current behavior
When trying to  call a tf.function decorated class method, it raises an OperatorNotAllowedError:

OperatorNotAllowedInGraphError: using a tf.Tensor as a Python bool is not allowed: AutoGraph did not convert this function. Try decorating it directly with @tf.function.

Describe the expected behavior
It should work.

code structure

```python
class Foo:
        def __init__:
              .....
        @tf.function
         def myfun(y):
               # some computation
               t = 0
               while tf.math.reduce_max(pinf_t) > 1e-8:
                       # some computation
                       if t==0:
                          # some computation
                       else:
                          # some computation
               # do some computation
       return value
``` 



Full traceback:

 ---------------------------------------------------------------------------

```
Traceback (most recent call last):
  File ""/Users/mac/Documents/bishe/DeepStateCount/DeepStateCount/countdssm.py"", line 168, in <module>
    dssm.run()
  File ""/Users/mac/Documents/bishe/DeepStateCount/DeepStateCount/countdssm.py"", line 142, in run
    epochs=epochs)
  File ""/Users/mac/.pyenv/versions/3.6.5/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py"", line 819, in fit
    use_multiprocessing=use_multiprocessing)
  File ""/Users/mac/.pyenv/versions/3.6.5/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py"", line 235, in fit
    use_multiprocessing=use_multiprocessing)
  File ""/Users/mac/.pyenv/versions/3.6.5/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py"", line 593, in _process_training_inputs
    use_multiprocessing=use_multiprocessing)
  File ""/Users/mac/.pyenv/versions/3.6.5/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py"", line 706, in _process_inputs
    use_multiprocessing=use_multiprocessing)
  File ""/Users/mac/.pyenv/versions/3.6.5/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/data_adapter.py"", line 702, in __init__
    x = standardize_function(x)
  File ""/Users/mac/.pyenv/versions/3.6.5/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py"", line 660, in standardize_function
    standardize(dataset, extract_tensors_from_dataset=False)
  File ""/Users/mac/.pyenv/versions/3.6.5/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py"", line 2360, in _standardize_user_data
    self._compile_from_inputs(all_inputs, y_input, x, y)
  File ""/Users/mac/.pyenv/versions/3.6.5/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py"", line 2618, in _compile_from_inputs
    experimental_run_tf_function=self._experimental_run_tf_function)
  File ""/Users/mac/.pyenv/versions/3.6.5/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/training/tracking/base.py"", line 457, in _method_wrapper
    result = method(self, *args, **kwargs)
  File ""/Users/mac/.pyenv/versions/3.6.5/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py"", line 446, in compile
    self._compile_weights_loss_and_weighted_metrics()
  File ""/Users/mac/.pyenv/versions/3.6.5/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/training/tracking/base.py"", line 457, in _method_wrapper
    result = method(self, *args, **kwargs)
  File ""/Users/mac/.pyenv/versions/3.6.5/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py"", line 1592, in _compile_weights_loss_and_weighted_metrics
    self.total_loss = self._prepare_total_loss(masks)
  File ""/Users/mac/.pyenv/versions/3.6.5/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py"", line 1652, in _prepare_total_loss
    per_sample_losses = loss_fn.call(y_true, y_pred)
  File ""/Users/mac/Documents/bishe/DeepStateCount/DeepStateCount/countdssm.py"", line 24, in call
    likes = tf.map_fn(self.loss_fun, tf.concat([y_true, y_pred], axis=2))
  File ""/Users/mac/.pyenv/versions/3.6.5/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/ops/map_fn.py"", line 268, in map_fn
    maximum_iterations=n)
  File ""/Users/mac/.pyenv/versions/3.6.5/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/ops/control_flow_ops.py"", line 2675, in while_loop
    back_prop=back_prop)
  File ""/Users/mac/.pyenv/versions/3.6.5/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/ops/while_v2.py"", line 194, in while_loop
    add_control_dependencies=add_control_dependencies)
  File ""/Users/mac/.pyenv/versions/3.6.5/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/framework/func_graph.py"", line 978, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File ""/Users/mac/.pyenv/versions/3.6.5/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/ops/while_v2.py"", line 172, in wrapped_body
    outputs = body(*_pack_sequence_as(orig_loop_vars, args))
  File ""/Users/mac/.pyenv/versions/3.6.5/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/ops/map_fn.py"", line 257, in compute
    packed_fn_values = fn(packed_values)
  File ""/Users/mac/Documents/bishe/DeepStateCount/DeepStateCount/countdssm.py"", line 31, in loss_fun
    like = count_ssm.loglike()
  File ""/Users/mac/Documents/bishe/DeepStateCount/DeepStateCount/NLSSMforDeep.py"", line 33, in loglike
    linear_ssm = self.approx_gaussian(max_iter=50)
  File ""/Users/mac/.pyenv/versions/3.6.5/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py"", line 568, in __call__
    result = self._call(*args, **kwds)
  File ""/Users/mac/.pyenv/versions/3.6.5/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py"", line 615, in _call
    self._initialize(args, kwds, add_initializers_to=initializers)
  File ""/Users/mac/.pyenv/versions/3.6.5/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py"", line 497, in _initialize
    *args, **kwds))
  File ""/Users/mac/.pyenv/versions/3.6.5/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py"", line 2389, in _get_concrete_function_internal_garbage_collected
    graph_function, _, _ = self._maybe_define_function(args, kwargs)
  File ""/Users/mac/.pyenv/versions/3.6.5/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py"", line 2703, in _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)
  File ""/Users/mac/.pyenv/versions/3.6.5/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py"", line 2593, in _create_graph_function
    capture_by_value=self._capture_by_value),
  File ""/Users/mac/.pyenv/versions/3.6.5/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/framework/func_graph.py"", line 978, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File ""/Users/mac/.pyenv/versions/3.6.5/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py"", line 439, in wrapped_fn
    return weak_wrapped_fn().__wrapped__(*args, **kwds)
  File ""/Users/mac/.pyenv/versions/3.6.5/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py"", line 3211, in bound_method_wrapper
    return wrapped_fn(*args, **kwargs)
  File ""/Users/mac/.pyenv/versions/3.6.5/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/framework/func_graph.py"", line 964, in wrapper
    user_requested=True,
  File ""/Users/mac/.pyenv/versions/3.6.5/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/autograph/impl/api.py"", line 560, in converted_call
    return _call_unconverted(f, args, kwargs, options)
  File ""/Users/mac/.pyenv/versions/3.6.5/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/autograph/impl/api.py"", line 326, in _call_unconverted
    return f.__self__.call(args, kwargs)
  File ""/Users/mac/.pyenv/versions/3.6.5/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py"", line 3173, in call
    return wrapped_fn(self.weakrefself_target__(), *args, **kwargs)
  File ""/Users/mac/Documents/bishe/DeepStateCount/DeepStateCount/NLSSMforDeep.py"", line 123, in approx_gaussian
    var=False)['alpha']
  File ""/Users/mac/Documents/bishe/DeepStateCount/DeepStateCount/LSSMforDeep.py"", line 317, in exact_kalman_smoothing
    filtered = self.exact_kalman_filtering()
  File ""/Users/mac/.pyenv/versions/3.6.5/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py"", line 568, in __call__
    result = self._call(*args, **kwds)
  File ""/Users/mac/.pyenv/versions/3.6.5/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py"", line 615, in _call
    self._initialize(args, kwds, add_initializers_to=initializers)
  File ""/Users/mac/.pyenv/versions/3.6.5/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py"", line 497, in _initialize
    *args, **kwds))
  File ""/Users/mac/.pyenv/versions/3.6.5/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py"", line 2389, in _get_concrete_function_internal_garbage_collected
    graph_function, _, _ = self._maybe_define_function(args, kwargs)
  File ""/Users/mac/.pyenv/versions/3.6.5/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py"", line 2703, in _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)
  File ""/Users/mac/.pyenv/versions/3.6.5/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py"", line 2593, in _create_graph_function
    capture_by_value=self._capture_by_value),
  File ""/Users/mac/.pyenv/versions/3.6.5/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/framework/func_graph.py"", line 978, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File ""/Users/mac/.pyenv/versions/3.6.5/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py"", line 439, in wrapped_fn
    return weak_wrapped_fn().__wrapped__(*args, **kwds)
  File ""/Users/mac/.pyenv/versions/3.6.5/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py"", line 3211, in bound_method_wrapper
    return wrapped_fn(*args, **kwargs)
  File ""/Users/mac/.pyenv/versions/3.6.5/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/framework/func_graph.py"", line 964, in wrapper
    user_requested=True,
  File ""/Users/mac/.pyenv/versions/3.6.5/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/autograph/impl/api.py"", line 560, in converted_call
    return _call_unconverted(f, args, kwargs, options)
  File ""/Users/mac/.pyenv/versions/3.6.5/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/autograph/impl/api.py"", line 326, in _call_unconverted
    return f.__self__.call(args, kwargs)
  File ""/Users/mac/.pyenv/versions/3.6.5/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py"", line 3173, in call
    return wrapped_fn(self.weakrefself_target__(), *args, **kwargs)
  File ""/Users/mac/Documents/bishe/DeepStateCount/DeepStateCount/LSSMforDeep.py"", line 139, in exact_kalman_filtering
    while tf.math.reduce_max(pinf_t) > 1e-8:
  File ""/Users/mac/.pyenv/versions/3.6.5/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py"", line 757, in __bool__
    self._disallow_bool_casting()
  File ""/Users/mac/.pyenv/versions/3.6.5/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py"", line 523, in _disallow_bool_casting
    ""using a `tf.Tensor` as a Python `bool`"")
  File ""/Users/mac/.pyenv/versions/3.6.5/envs/tensorflow/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py"", line 510, in _disallow_when_autograph_enabled
    "" decorating it directly with @tf.function."".format(task))
tensorflow.python.framework.errors_impl.OperatorNotAllowedInGraphError: using a `tf.Tensor` as a Python `bool` is not allowed: AutoGraph did not convert this function. Try decorating it directly with @tf.functio
```"
38526,"ModuleNotFoundError: No module named 'tensorflow.python._pywrap_tfe',how to due with it?","This template is for miscellaneous issues not covered by the other issue categories.

For questions on how to work with TensorFlow, or support for problems that are not verified bugs in TensorFlow, please go to [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).

If you are reporting a vulnerability, please use the [dedicated reporting process](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md).

For high-level discussions about TensorFlow, please post to discuss@tensorflow.org, for questions about the development or internal workings of TensorFlow, or if you would like to know how to contribute to TensorFlow, please post to developers@tensorflow.org.
"
38525,ERROR: C:/users/alex/_bazel_alex/xv6zejqw/external/flatbuffers/src/BUILD:40:1: C++ compilation of rule '@flatbuffers//src:flatc' failed (Exit -1).,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: -
- TensorFlow installed from (source or binary): source
- TensorFlow version: r2.1
- Python version: 3.6.0
- Installed using virtualenv? pip? conda?: pip
- Bazel version (if compiling from source): 0.29.1
- GCC/Compiler version (if compiling from source): VS2019
- CUDA/cuDNN version: n
- GPU model and memory: n



**Describe the problem**
I'm trying to compile tensorflow lite for android use. But I failed.

**Provide the exact sequence of commands / steps that you executed before running into the problem**
1. setup environment according to
https://www.tensorflow.org/install/source_windows

2. git checkout r2.1 (I tried the master but same error)

3. configure
C:\tensorflow>configure
WARNING: Running Bazel server needs to be killed, because the startup options are different.
WARNING: Waiting for server process to terminate (waited 5 seconds, waiting at most 60)
WARNING: Waiting for server process to terminate (waited 10 seconds, waiting at most 60)
WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command ""bazel shutdown"".
You have bazel 0.29.1 installed.
Please specify the location of python. [Default is D:\Program Files\Python\Python36\python.exe]:


Found possible Python library paths:
  D:\Program Files\Python\Python36\lib\site-packages
Please input the desired Python library path to use.  Default is [D:\Program Files\Python\Python36\lib\site-packages]

Do you wish to build TensorFlow with XLA JIT support? [y/N]: n
No XLA JIT support will be enabled for TensorFlow.

Do you wish to build TensorFlow with ROCm support? [y/N]: n
No ROCm support will be enabled for TensorFlow.

Do you wish to build TensorFlow with CUDA support? [y/N]: n
No CUDA support will be enabled for TensorFlow.

Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is /arch:AVX]:


Would you like to override eigen strong inline for some C++ compilation to reduce the compilation time? [Y/n]: y
Eigen strong inline overridden.

Preconfigured Bazel build configs. You can use any of the below by adding ""--config=<>"" to your build command. See .bazelrc for more details.
        --config=mkl            # Build with MKL support.
        --config=monolithic     # Config for mostly static monolithic build.
        --config=ngraph         # Build with Intel nGraph support.
        --config=numa           # Build with NUMA support.
        --config=dynamic_kernels        # (Experimental) Build kernels into separate shared objects.
        --config=v2             # Build TensorFlow 2.x instead of 1.x.
Preconfigured Bazel build configs to DISABLE default on features:
        --config=noaws          # Disable AWS S3 filesystem support.
        --config=nogcp          # Disable GCP support.
        --config=nohdfs         # Disable HDFS support.
        --config=nonccl         # Disable NVIDIA NCCL support.
Configuration finished

4. Build with
bazel build -c opt --cxxopt=--std=c++11 --config=android_arm //tensorflow/lite/c:libtensorflowlite_c.so


**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

C:\tensorflow>bazel build -c opt --cxxopt=--std=c++11 --config=android_arm //tensorflow/lite/c:libtensorflowlite_c.so
Starting local Bazel server and connecting to it...
INFO: Options provided by the client:
  Inherited 'common' options: --isatty=1 --terminal_columns=120
INFO: Options provided by the client:
  'build' options: --python_path=D:/Program Files/Python/Python36/python.exe
INFO: Reading rc options for 'build' from c:\tensorflow\.bazelrc:
  'build' options: --apple_platform_type=macos --define framework_shared_object=true --define open_source_build=true --java_toolchain=//third_party/toolchains/java:tf_java_toolchain --host_java_toolchain=//third_party/toolchains/java:tf_java_toolchain --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone --strategy=Genrule=standalone -c opt --cxxopt=-std=c++14 --host_cxxopt=-std=c++14 --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --config=v2
INFO: Reading rc options for 'build' from c:\tensorflow\.tf_configure.bazelrc:
  'build' options: --action_env PYTHON_BIN_PATH=D:/Program Files/Python/Python36/python.exe --action_env PYTHON_LIB_PATH=D:/Program Files/Python/Python36/lib/site-packages --python_path=D:/Program Files/Python/Python36/python.exe --config monolithic --copt=-w --host_copt=-w --copt=-DWIN32_LEAN_AND_MEAN --host_copt=-DWIN32_LEAN_AND_MEAN --copt=-DNOGDI --host_copt=-DNOGDI --copt=-D_USE_MATH_DEFINES --verbose_failures --distinct_host_configuration=false --define=override_eigen_strong_inline=true --action_env TF_CONFIGURE_IOS=0
INFO: Found applicable config definition build:v2 in file c:\tensorflow\.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1
INFO: Found applicable config definition build:monolithic in file c:\tensorflow\.bazelrc: --define framework_shared_object=false
INFO: Found applicable config definition build:android_arm in file c:\tensorflow\.bazelrc: --config=android --cpu=armeabi-v7a --fat_apk_cpu=armeabi-v7a
INFO: Found applicable config definition build:android in file c:\tensorflow\.bazelrc: --crosstool_top=//external:android/crosstool --host_crosstool_top=@bazel_tools//tools/cpp:toolchain
DEBUG: Rule 'io_bazel_rules_docker' indicated that a canonical reproducible form can be obtained by modifying arguments shallow_since = ""1556410077 -0400""
DEBUG: Call stack for the definition of repository 'io_bazel_rules_docker' which is a git_repository (rule definition at C:/users/alex/_bazel_alex/xv6zejqw/external/bazel_tools/tools/build_defs/repo/git.bzl:195:18):
 - C:/users/alex/_bazel_alex/xv6zejqw/external/bazel_toolchains/repositories/repositories.bzl:37:9
 - C:/tensorflow/WORKSPACE:37:1
ERROR: Skipping '//tensorflow/lite/c:libtensorflowlite_c.so': no such target '//tensorflow/lite/c:libtensorflowlite_c.so': target 'libtensorflowlite_c.so' not declared in package 'tensorflow/lite/c' defined by C:/tensorflow/tensorflow/lite/c/BUILD
WARNING: Target pattern parsing failed.
ERROR: no such target '//tensorflow/lite/c:libtensorflowlite_c.so': target 'libtensorflowlite_c.so' not declared in package 'tensorflow/lite/c' defined by C:/tensorflow/tensorflow/lite/c/BUILD
INFO: Elapsed time: 13.103s
INFO: 0 processes.
FAILED: Build did NOT complete successfully (1 packages loaded)

Thanks in advance."
38524,problem with nested tf.function in tensorflow 2,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow): 

- OS Platform and Distribution 

NAME=""Ubuntu""
VERSION=""18.04.3 LTS (Bionic Beaver)""
ID=ubuntu
ID_LIKE=debian
PRETTY_NAME=""Ubuntu 18.04.3 LTS""
VERSION_ID=""18.04""
HOME_URL=""https://www.ubuntu.com/""
SUPPORT_URL=""https://help.ubuntu.com/""
BUG_REPORT_URL=""https://bugs.launchpad.net/ubuntu/""
PRIVACY_POLICY_URL=""https://www.ubuntu.com/legal/terms-and-policies/privacy-policy""
VERSION_CODENAME=bionic
UBUNTU_CODENAME=bionic

- Mobile device

Not tested on mobile

- TensorFlow installed from (source or
binary): 

tensorflow and tf-nightly installed with pip

- TensorFlow version (use command below): 

Tensorflow version: treid with 2.1.0 and tf-nigthly (tf 2.2.0)

- Python version: 

python3.6

 - Bazel
version (if compiling from source):
- GCC/Compiler version (if compiling from
source): 

- CUDA/cuDNN version: - GPU model and memory:

Problem persists on CPU and GPU, 

CPU:
processor       : 3                                                                                                                                                                            
vendor_id       : GenuineIntel                                                                                                                                                                 
cpu family      : 6                                                                                                                                                                            
model           : 142                                                                                                                                                                          
model name      : Intel(R) Core(TM) i7-8565U CPU @ 1.80GHz                                                                                                                                     


GPU:

description: VGA compatible controller
product: GP102 [GeForce GTX 1080 Ti]
vendor: NVIDIA Corporation



**Describe the current behavior**

It throws a ValueError 


**Describe the expected behavior**

Does not throw ValueError

**Standalone code to reproduce the issue** 

I made a small example that reproduces the error here

https://colab.research.google.com/drive/1yWowuoHCjuBHckHnS9sRBwnx9i8NtIxW

If running that code as is it throws an error, see the ""constraint"" function. If i just copy the contents of the fem function into constraint then it works (as described in the comment in the constraint function).


**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

Here's the traceback of the error

```bash
InvalidArgumentError                      Traceback (most recent call last)
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py in get_attr(self, name)
   2327       with c_api_util.tf_buffer() as buf:
-> 2328         pywrap_tf_session.TF_OperationGetAttrValueProto(self._c_op, name, buf)
   2329         data = pywrap_tf_session.TF_GetBuffer(buf)

InvalidArgumentError: Operation 'StatefulPartitionedCall' has no attr named '_XlaCompile'.

During handling of the above exception, another exception occurred:

ValueError                                Traceback (most recent call last)
15 frames
ValueError: Operation 'StatefulPartitionedCall' has no attr named '_XlaCompile'.

During handling of the above exception, another exception occurred:

ValueError                                Traceback (most recent call last)
/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py in _call_flat(self, args, captured_inputs, cancellation_manager)
   1736         raise ValueError(""All inputs to `ConcreteFunction`s must be Tensors; ""
   1737                          ""on invocation of %s, the %d-th input (%s) was not a ""
-> 1738                          ""Tensor."" % (self._func_graph.name, i, str(arg)))
   1739     args = tensor_inputs + captured_inputs
   1740     possible_gradient_type = (

ValueError: All inputs to `ConcreteFunction`s must be Tensors; on invocation of __backward_fem_664, the 0-th input (IndexedSlices(indices=Tensor(""gradients/PartitionedCall_grad/PartitionedCall_4:1"", shape=(3200,), dtype=int64), values=Tensor(""gradients/PartitionedCall_grad/PartitionedCall_4:0"", shape=(3200,), dtype=float64), dense_shape=Tensor(""gradients/PartitionedCall_grad/PartitionedCall_4:2"", shape=(1,), dtype=int32))) was not a Tensor.
```
"
38523,https://www.tensorflow.org/api_docs/python/tf/saved_model/tag_constants is broken,"## URL(s) with the issue: 
https://www.tensorflow.org/api_docs/python/tf/saved_model/tag_constants

Please provide a link to the documentation entry, for example:
https://www.tensorflow.org/tfx/serving/serving_basic#train_and_export_tensorflow_model

## Description of issue (what needs changing):
In the explanation corresponding to **`tags`** in [this link](https://www.tensorflow.org/tfx/serving/serving_basic#train_and_export_tensorflow_model), the Hyperlink corresponding to the Text, related [TensorFlow API documentation](https://www.tensorflow.org/api_docs/python/tf/saved_model/tag_constants) is broken.

### Clear description

This link is useful for the community to understand the purpose of different Tags used while Saving a Model.

### Parameters defined

Are all parameters defined and formatted correctly? : Yes

### Returns defined

Are return values defined? : N/A"
38522,"When imports tensorflow, there is an error.","```python
>>> import tensorflow as tf
2020-04-14 16:10:32.366842: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'cudart64_101.dll'; dlerror: cudart64_101.dll not found
2020-04-14 16:10:32.385198: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\__init__.py"", line 41, in <module>
    from tensorflow.python.tools import module_util as _module_util
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\__init__.py"", line 84, in <module>
    from tensorflow.python import keras
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\keras\__init__.py"", line 27, in <module>
    from tensorflow.python.keras import models
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\keras\models.py"", line 24, in <module>
    from tensorflow.python.keras import metrics as metrics_module
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\keras\metrics.py"", line 37, in <module>
    from tensorflow.python.keras.engine import base_layer
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\keras\engine\base_layer.py"", line 51, in <module>
    from tensorflow.python.keras import initializers
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\keras\initializers\__init__.py"", line 127, in <module>
    populate_deserializable_objects()
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\keras\initializers\__init__.py"", line 85, in populate_deserializable_objects
    generic_utils.populate_dict_with_module_objects(
AttributeError: module 'tensorflow.python.keras.utils.generic_utils' has no attribute 'populate_dict_with_module_objects'
```
How can I fix the ploblem? Can you fix it?I'm using the newest version of tensorflow, 2.2.0rc3."
38521,Installation on Android with armv8,"**System information**
- Xiaomi Redmi 5 plus, Redmi Note 8 Pro, Samsung Galaxy A50


i m clone just now project from https://github.com/tensorflow/examples/tree/master/lite/examples/speech_commands/android
build and tried install to the phones and at the end of insall i m getting error - ""App not Installed"""
38520,MonitoredTrainingSession/Parameter server with large embedding table,"i want to train a model with MonitoredTrainingSession, and here is a large embedding table(K*D, K is almost 100 millions, D is 16), and i have to put the tensor(embedding_table) to one parameter server(ps.0), which will make a bottleneck.

So, i want to know is there any method to solve this problem. For example, put the large embedding table to be parted and each PS have one of them. "
38519,"ClusterSpec propagation propagates ""localhost"" to remote","**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow): No
- OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04): CentOS
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if
the issue happens on mobile device: 
- TensorFlow installed from (source orbinary): source
- TensorFlow version (use command below): latest master
- Python version: python3.6
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source): gcc8
- CUDA/cuDNN version: - GPU model and memory:

TensorFlow propagates ""localhost"" instead of real ip address to remote.

Demo code:
one is ps
```python
import tensorflow.compat.v1 as tf                                                                                                                                       
tf.disable_v2_behavior()
server = tf.distribute.Server(tf.train.ClusterSpec({""ps"" : [""ps_ip_address:5333""]}), job_name=""ps"", task_index=0, protocol='grpc')                                          
print(""start ps"")
server.join() 
```

one worker
```python
import tensorflow.compat.v1 as tf
from tensorflow.core.protobuf import config_pb2
from tensorflow.python.training import server_lib
from tensorflow.core.protobuf import cluster_pb2
import time
tf.disable_v2_behavior()

with tf.device(""/job:ps/replica:0/task:0""):
    a = tf.get_variable(""param"", [10], tf.float32, initializer=tf.zeros_initializer)

with tf.device(""/job:worker/replica:0/task:0""):
    update = tf.get_variable(""update"", [10], tf.float32, initializer=tf.ones_initializer)
    add_op = a.assign_add(update)

init_op = tf.initialize_all_variables()

server = tf.distribute.Server({""localhost"": [""worker_ip_address:0""]}, protocol=""grpc"")
cluster_def = cluster_pb2.ClusterDef()
worker_job = cluster_def.job.add()
worker_job.name = 'worker'
worker_job.tasks[0] = server.target[len('grpc://'):]
ps_job = cluster_def.job.add()
ps_job.name = ""ps""
ps_job.tasks[0] = ""ps_ip_address:5333""
config = config_pb2.ConfigProto(cluster_def=cluster_def, 
 experimental=config_pb2.ConfigProto.Experimental(share_session_state_in_clusterspec_propagation=True))

with tf.Session(server.target, config=config) as sess:
    sess.run(init_op)
    print(sess.run(add_op))

```
ps and server starts on different machines. The ps starts without worker device information and relies cluster spec propagation to propagates worker device information to ps.
However, from ps log, worker device is propagated as ""localhost"" to ps.
```console
2020-04-14 13:30:21.673766: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:300] Initialize GrpcChannelCache for job ps -> {0 -> localhost:5333}
2020-04-14 13:30:21.676047: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:390] Started server with target: grpc://localhost:5333
start ps
2020-04-14 13:36:33.582439: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:300] Initialize GrpcChannelCache for job worker -> {0 -> localhost:51798}
2020-04-14 13:36:33.582471: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:300] Initialize GrpcChannelCache for job ps -> {0 -> localhost:5333}
```
So ps server tries to create grpc channel to the wrong worker device `localhost:51798` and the session run hangs forever.

I tried to replace `worker_job.tasks[0] = server.target[len('grpc://'):]` with `worker_job.tasks[0] = server.target[len('grpc://'):].replace(""localhost"", ""worker_ip_address"")`, but TF failed to create session with following error:
```console
tensorflow.python.framework.errors_impl.InvalidArgumentError: The master (current machine) is not included in the provided cluster_def.  job {
  name: ""worker""
  tasks {
    key: 0
    value: ""worker_ip_address:43479""
  }
}
job {
  name: ""ps""
  tasks {
    key: 0
    value: ""ps_ip_address:5333""
  } 
}
```

I changed the code of https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/distributed_runtime/master_session.cc#L1355 and replaced all localhost with real ip address, it works. I'm not sure if this change will cause other issues.

Any idea how to fix this generally?

"
38518,InvalidArgumentError: assertion failed: [0] [Op:Assert] name: EagerVariableNameReuse,"when i use tensorflow2.1 .I trained my model custom,yesterday，the code can run correctly. But torday is error, I debug my code , I found this code is error ,
```python
self.train_accuracy = tf.keras.metrics.CategoricalAccuracy('train_accuracy')
```
but this code is actually correct,
Now I assert a variable using this in jupyter notebook, it's wrong !
the error is :
```
InvalidArgumentError: assertion failed: [0] [Op:Assert] name: EagerVariableNameReuse
```
 who can tell me the reason and some solutions,thanks.

the whole code is:
```python
import os
import numpy as np
import cv2
import tensorflow as tf



class ModelTrain():
    def __init__(self):
        self.loss_object = tf.keras.losses.CategoricalCrossentropy()
        self.optimizer = tf.keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999)
        self.train_loss = tf.keras.metrics.CategoricalCrossentropy('train_loss', dtype=tf.float32)
        self.train_accuracy = tf.keras.metrics.CategoricalAccuracy('train_accuracy')
        self.validation_loss = tf.keras.metrics.CategoricalCrossentropy('validation_loss', dtype=tf.float32)
        self.validation_accuracy = tf.keras.metrics.CategoricalAccuracy('validation_accuracy')
        
if __name__ == ""__main__"":
    model_train = ModelTrain()
```

the error is :

```
Traceback (most recent call last):
  File ""/media/huaxin/tcl3/facepro/hand-gesture-recognition/jester-data-preprocessing_v0.2/test.py"", line 18, in <module>
    model_train = ModelTrain()
  File ""/media/huaxin/tcl3/facepro/hand-gesture-recognition/jester-data-preprocessing_v0.2/test.py"", line 12, in __init__
    self.train_loss = tf.keras.metrics.CategoricalCrossentropy('train_loss', dtype=tf.float32)
  File ""/media/huaxin/tcl3/facepro/anaconda3/envs/python3.7.4/lib/python3.7/site-packages/tensorflow_core/python/keras/metrics.py"", line 2818, in __init__
    label_smoothing=label_smoothing)
  File ""/media/huaxin/tcl3/facepro/anaconda3/envs/python3.7.4/lib/python3.7/site-packages/tensorflow_core/python/keras/metrics.py"", line 560, in __init__
    super(MeanMetricWrapper, self).__init__(name=name, dtype=dtype)
  File ""/media/huaxin/tcl3/facepro/anaconda3/envs/python3.7.4/lib/python3.7/site-packages/tensorflow_core/python/keras/metrics.py"", line 460, in __init__
    reduction=metrics_utils.Reduction.WEIGHTED_MEAN, name=name, dtype=dtype)
  File ""/media/huaxin/tcl3/facepro/anaconda3/envs/python3.7.4/lib/python3.7/site-packages/tensorflow_core/python/keras/metrics.py"", line 296, in __init__
    'total', initializer=init_ops.zeros_initializer)
  File ""/media/huaxin/tcl3/facepro/anaconda3/envs/python3.7.4/lib/python3.7/site-packages/tensorflow_core/python/keras/metrics.py"", line 276, in add_weight
    aggregation=aggregation)
  File ""/media/huaxin/tcl3/facepro/anaconda3/envs/python3.7.4/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 446, in add_weight
    caching_device=caching_device)
  File ""/media/huaxin/tcl3/facepro/anaconda3/envs/python3.7.4/lib/python3.7/site-packages/tensorflow_core/python/training/tracking/base.py"", line 744, in _add_variable_with_custom_getter
    **kwargs_for_getter)
  File ""/media/huaxin/tcl3/facepro/anaconda3/envs/python3.7.4/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer_utils.py"", line 142, in make_variable
    shape=variable_shape if variable_shape else None)
  File ""/media/huaxin/tcl3/facepro/anaconda3/envs/python3.7.4/lib/python3.7/site-packages/tensorflow_core/python/ops/variables.py"", line 258, in __call__
    return cls._variable_v1_call(*args, **kwargs)
  File ""/media/huaxin/tcl3/facepro/anaconda3/envs/python3.7.4/lib/python3.7/site-packages/tensorflow_core/python/ops/variables.py"", line 219, in _variable_v1_call
    shape=shape)
  File ""/media/huaxin/tcl3/facepro/anaconda3/envs/python3.7.4/lib/python3.7/site-packages/tensorflow_core/python/ops/variables.py"", line 197, in <lambda>
    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)
  File ""/media/huaxin/tcl3/facepro/anaconda3/envs/python3.7.4/lib/python3.7/site-packages/tensorflow_core/python/ops/variable_scope.py"", line 2596, in default_variable_creator
    shape=shape)
  File ""/media/huaxin/tcl3/facepro/anaconda3/envs/python3.7.4/lib/python3.7/site-packages/tensorflow_core/python/ops/variables.py"", line 262, in __call__
    return super(VariableMetaclass, cls).__call__(*args, **kwargs)
  File ""/media/huaxin/tcl3/facepro/anaconda3/envs/python3.7.4/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py"", line 1411, in __init__
    distribute_strategy=distribute_strategy)
  File ""/media/huaxin/tcl3/facepro/anaconda3/envs/python3.7.4/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py"", line 1557, in _init_from_args
    graph_mode=self._in_graph_mode)
  File ""/media/huaxin/tcl3/facepro/anaconda3/envs/python3.7.4/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py"", line 232, in eager_safe_variable_handle
    shape, dtype, shared_name, name, graph_mode, initial_value)
  File ""/media/huaxin/tcl3/facepro/anaconda3/envs/python3.7.4/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py"", line 164, in _variable_handle_from_shape_and_dtype
    math_ops.logical_not(exists), [exists], name=""EagerVariableNameReuse"")
  File ""/media/huaxin/tcl3/facepro/anaconda3/envs/python3.7.4/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_logging_ops.py"", line 55, in _assert
    _ops.raise_from_not_ok_status(e, name)
  File ""/media/huaxin/tcl3/facepro/anaconda3/envs/python3.7.4/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py"", line 6606, in raise_from_not_ok_status
    six.raise_from(core._status_to_exception(e.code, message), None)
  File ""<string>"", line 3, in raise_from
tensorflow.python.framework.errors_impl.InvalidArgumentError: assertion failed: [0] [Op:Assert] name: EagerVariableNameReuse
```

the same situation existed yesterday,I uninstall tensorflow2.1 and re-install,the problemis solved,but today same problem exist again,what's the reason, and how can solve this.

"
38517,mkl-dnn sha256sum not match since two available link has different sha256sum,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Utuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version: 2.1.0
- Python version: 3.6.8
- Installed using virtualenv? pip? conda?:
- Bazel version (if compiling from source): 0.24.1
- GCC/Compiler version (if compiling from source): 5.5.0
- CUDA/cuDNN version:
- GPU model and memory:



**Describe the problem**

Bazel build fails since mkl-dnn sha256sum doesn't match.

In tensorflow/workspace.bzl, there are two links:

urls = [
            ""https://storage.googleapis.com/mirror.tensorflow.org/github.com/intel/mkl-dnn/archive/v0.21.3.tar.gz"",
            ""https://github.com/intel/mkl-dnn/archive/v0.21.3.tar.gz"",
        ],

However the sha256sum of the two links is not the same. The sha256sum of the first url is given in workspace. Due to some connect issue in China, we don't have access to the first url and can only use the second. Then sha256sum not match is met.

**Provide the exact sequence of commands / steps that you executed before running into the problem**


**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
38516,Cannot use set_visible_devices with mixed_precision,"**System information** 
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): kind of. Combination of 2 example scripts
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux - Fedora 31
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: 
- TensorFlow installed from (source or
binary): source
- TensorFlow version (use command below): v2.2.0-rc3-0-gaad398b5e9 2.2.0-rc3
- Python version: 3.7.6
- Bazel version (if compiling from source): 2.0.0
- GCC/Compiler version (if compiling from source): gcc (GCC) 9.2.1 20190827 (Red Hat 9.2.1-1)
- CUDA/cuDNN version: CUDA 10.2, cuDNN 7.6.5.33
- GPU model and memory: 2x GeForce RTX 2080 Ti 12gb

**Describe the current behavior**
When attempting to use `tf.config.set_visible_devices()` in conjunction with `tf.python.keras.mixed_precision.experimental.policy.set_policy()`, the Tensorflow errors with:
```
RuntimeError: TensorFlow device (GPU:0) is being mapped to multiple CUDA devices (0 now, and 1 previously), which is not supported. This may be the result of providing different GPU configurations (ConfigProto.gpu_options, for example different visible_device_list) when creating multiple Sessions in the same process. This is not  currently supported, see https://github.com/tensorflow/tensorflow/issues/19083
```

**Describe the expected behavior**
No error

**Standalone code to reproduce the issue** 
```
import tensorflow as tf
devices = tf.config.list_physical_devices('GPU')
tf.config.set_visible_devices(devices[1:], 'GPU')

from tensorflow.python.keras.mixed_precision.experimental import policy as mixed_precision
mixed_precision.set_policy(mixed_precision.Policy('mixed_float16'))
```"
38515,macosx py38 invalid wheel,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macosx 10.15.4
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): binary
- TensorFlow version: 2.2.0-rc.3 py38
- Python version: 3.8.1
- Installed using virtualenv? pip? conda?: pip
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A



**Describe the problem**
invalid wheel for tensorflow 2.2.0-rc.3 for macosx python 3.8
**Provide the exact sequence of commands / steps that you executed before running into the problem**
pip install tensorflow-cpu

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
```
ERROR: tensorflow-cpu has an invalid wheel, .dist-info directory 'tensorflow-2.2.0rc3.dist-info' does not start with 'tensorflow-cpu'
```"
38514,tf.keras.callbacks.ModelCheckpoint fails in distributed Parameter Server Strategy,"**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04): Linux RHEL 7
- TensorFlow installed from (source or
binary): - TensorFlow version (use command below): 2.1

**Describe the current behavior**
`tf.keras.callbacks.ModelCheckpoint` callback fails to save the model if the parameter server doesn't have access to the checkpoint location of other workers. And the location for workers other than chief worker, cannot be configured to a remote filesystem (e.g., hdfs)

**Describe the expected behavior**
The callback should be able to save the model if running on different machines using shared storage. I am not sure if the shared storage should be a requirement either.

**Standalone code to reproduce the issue** 
1. Create model.py provided below
2. Run the model.py in two terminals.
    - Terminal 1: Simply execute the model.py with the shown args.
    - Terminal 2: Run the unshare command to separate the mount namespace.
optional:
  Instead of running on the same machine, you can also run the given script on two separate machines. All you'd have to do this is change TF_CONFIG in the model.py. Then you wouldn't need to separate the mount namespace.


model.py
```py
import os
import pprint
import sys
import json
import tensorflow as tf
import tensorflow_datasets as tfds

tf.compat.v1.disable_eager_execution()

node_attr = sys.argv[1]
name = node_attr[:-1]
index = node_attr[-1]
os.environ['CUDA_VISIBLE_DEVICES']='-1'

os.environ['TF_CONFIG'] = json.dumps({""cluster"": {""worker"": [""localhost:5773""], ""ps"": [""localhost:5711""]}, ""task"": {""type"": name, ""index"": int(index)}})
strategy = tf.distribute.experimental.ParameterServerStrategy()

# Uncomment below for multi worker mirror strategy.
#os.environ['TF_CONFIG'] = json.dumps({""cluster"": {""worker"": [""localhost:5773"", ""localhost:6778""]}, ""task"": {""type"": name, ""index"": int(index)}})
#strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()

mnist = tf.keras.datasets.mnist

(x_train, y_train), (x_test, y_test) = mnist.load_data()
x_train, x_test = x_train / 255.0, x_test / 255.0

def input_fn(mode):
    datasets, info = tfds.load(name='mnist', with_info=True, as_supervised=True)
    mnist_dataset = (
        datasets['train'] if mode == 'train' else datasets['test']
    )
    def scale(image, label):
        image = tf.cast(image, tf.float32)
        image /= 255
        return image, label

    return mnist_dataset.map(scale).cache().repeat(2).shuffle(10000).batch(4)

def build_and_compile_cnn_model():
    model = tf.keras.Sequential([
        tf.keras.layers.Conv2D(32, 3, activation='relu', input_shape=(28, 28, 1)),
        tf.keras.layers.MaxPooling2D(),
        tf.keras.layers.Flatten(),
        tf.keras.layers.Dense(64, activation='relu'),
        tf.keras.layers.Dense(10)
    ])
    model.compile(
        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
        optimizer=tf.keras.optimizers.SGD(learning_rate=0.001),
        metrics=['accuracy'])
    return model

def main():
    tf_config = json.loads(os.environ['TF_CONFIG'])
    job_name = tf_config['task']['type']
    job_index = tf_config['task']['index']

    if job_name == 'ps':
        server = tf.distribute.Server(
            tf_config['cluster'], job_name=job_name, task_index=job_index
        )
        server.join()
    else:
      train_dataset = input_fn('train')
      ckpt_full_path = os.path.join(sys.argv[2], 'model.ckpt-{epoch:04d}')
      callbacks = [
          tf.keras.callbacks.ModelCheckpoint(ckpt_full_path, save_weights_only=True, verbose=1, save_freq=1),
      ]

      options = tf.data.Options()
      options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.OFF
      train_datasets_no_auto_shard = train_dataset.with_options(options)

      with strategy.scope():
        model = build_and_compile_cnn_model()
      model.fit(x=train_datasets_no_auto_shard, epochs=3,steps_per_epoch=3, callbacks=callbacks)

if __name__ == '__main__':
    main()
```

Steps to reproduce:
1st terminal
```
$ python model.py worker0 /tmp
WARNING:tensorflow:`eval_fn` is not passed in. The `worker_fn` will be used if an ""evaluator"" task exists in the cluster.
WARNING:tensorflow:`eval_fn` is not passed in. The `worker_fn` will be used if an ""evaluator"" task exists in the cluster.
WARNING:tensorflow:`eval_strategy` is not passed in. No distribution strategy will be used for evaluation.
WARNING:tensorflow:`eval_strategy` is not passed in. No distribution strategy will be used for evaluation.
2020-04-13 18:11:00.844880: I tensorflow/core/distributed_runtime/worker.cc:204] Cancellation requested for RunGraph.
Train on 3 steps
Epoch 1/3

Epoch 00001: saving model to /tmp/checkpoints/model.ckpt-0001
Traceback (most recent call last):
  File ""/home/angoyal/ws/scratch/myvenv/lib/python3.7/site-packages/tensorflow_core/python/client/session.py"", line 1367, in _do_call
    return fn(*args)
  File ""/home/angoyal/ws/scratch/myvenv/lib/python3.7/site-packages/tensorflow_core/python/client/session.py"", line 1352, in _run_fn
    target_list, run_metadata)
  File ""/home/angoyal/ws/scratch/myvenv/lib/python3.7/site-packages/tensorflow_core/python/client/session.py"", line 1445, in _call_tf_sessionrun
    run_metadata)
tensorflow.python.framework.errors_impl.NotFoundError: From /job:ps/replica:0/task:0:
/tmp/checkpoints/model.ckpt-0001_temp_8b7417c3f79f449f87c2218bde68999d; No such file or directory
	 [[{{node SaveV2}}]]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""model.py"", line 87, in <module>
    main()
  File ""model.py"", line 83, in main
    model.fit(x=train_datasets_no_auto_shard, epochs=3,steps_per_epoch=3, callbacks=callbacks)
  File ""/home/angoyal/ws/scratch/myvenv/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py"", line 819, in fit
    use_multiprocessing=use_multiprocessing)
  File ""/home/angoyal/ws/scratch/myvenv/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_distributed.py"", line 790, in fit
    *args, **kwargs)
  File ""/home/angoyal/ws/scratch/myvenv/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_distributed.py"", line 777, in wrapper
    mode=dc.CoordinatorMode.INDEPENDENT_WORKER)
  File ""/home/angoyal/ws/scratch/myvenv/lib/python3.7/site-packages/tensorflow_core/python/distribute/distribute_coordinator.py"", line 853, in run_distribute_coordinator
    task_id, session_config, rpc_layer)
  File ""/home/angoyal/ws/scratch/myvenv/lib/python3.7/site-packages/tensorflow_core/python/distribute/distribute_coordinator.py"", line 360, in _run_single_worker
    return worker_fn(strategy)
  File ""/home/angoyal/ws/scratch/myvenv/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_distributed.py"", line 772, in _worker_fn
    return method(model, **kwargs)
  File ""/home/angoyal/ws/scratch/myvenv/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_distributed.py"", line 685, in fit
    steps_name='steps_per_epoch')
  File ""/home/angoyal/ws/scratch/myvenv/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_arrays.py"", line 352, in model_iteration
    callbacks._call_batch_hook(mode, 'end', step, batch_logs)
  File ""/home/angoyal/ws/scratch/myvenv/lib/python3.7/site-packages/tensorflow_core/python/keras/callbacks.py"", line 239, in _call_batch_hook
    batch_hook(batch, logs)
  File ""/home/angoyal/ws/scratch/myvenv/lib/python3.7/site-packages/tensorflow_core/python/keras/callbacks.py"", line 528, in on_train_batch_end
    self.on_batch_end(batch, logs=logs)
  File ""/home/angoyal/ws/scratch/myvenv/lib/python3.7/site-packages/tensorflow_core/python/keras/callbacks.py"", line 977, in on_batch_end
    self._save_model(epoch=self._current_epoch, logs=logs)
  File ""/home/angoyal/ws/scratch/myvenv/lib/python3.7/site-packages/tensorflow_core/python/keras/callbacks.py"", line 1038, in _save_model
    self.model.save_weights(filepath, overwrite=True)
  File ""/home/angoyal/ws/scratch/myvenv/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py"", line 1123, in save_weights
    self._trackable_saver.save(filepath, session=session)
  File ""/home/angoyal/ws/scratch/myvenv/lib/python3.7/site-packages/tensorflow_core/python/training/tracking/util.py"", line 1177, in save
    return session.run(save_path, feed_dict=feed_dict)
  File ""/home/angoyal/ws/scratch/myvenv/lib/python3.7/site-packages/tensorflow_core/python/client/session.py"", line 960, in run
    run_metadata_ptr)
  File ""/home/angoyal/ws/scratch/myvenv/lib/python3.7/site-packages/tensorflow_core/python/client/session.py"", line 1183, in _run
    feed_dict_tensor, options, run_metadata)
  File ""/home/angoyal/ws/scratch/myvenv/lib/python3.7/site-packages/tensorflow_core/python/client/session.py"", line 1361, in _do_run
    run_metadata)
  File ""/home/angoyal/ws/scratch/myvenv/lib/python3.7/site-packages/tensorflow_core/python/client/session.py"", line 1386, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.NotFoundError: From /job:ps/replica:0/task:0:
/tmp/checkpoints/model.ckpt-0001_temp_8b7417c3f79f449f87c2218bde68999d; No such file or directory
	 [[node SaveV2 (defined at model.py:83) ]]

Errors may have originated from an input operation.
Input Source operations connected to node SaveV2:
 dense/kernel/Read/ReadVariableOp (defined at model.py:48)	
 training/SGD/decay/Read/ReadVariableOp (defined at /export/apps/python/3.7/lib/python3.7/threading.py:926)

Original stack trace for 'SaveV2':
  File ""model.py"", line 87, in <module>
    main()
  File ""model.py"", line 83, in main
    model.fit(x=train_datasets_no_auto_shard, epochs=3,steps_per_epoch=3, callbacks=callbacks)
  File ""/home/angoyal/ws/scratch/myvenv/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py"", line 819, in fit
    use_multiprocessing=use_multiprocessing)
  File ""/home/angoyal/ws/scratch/myvenv/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_distributed.py"", line 790, in fit
    *args, **kwargs)
  File ""/home/angoyal/ws/scratch/myvenv/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_distributed.py"", line 777, in wrapper
    mode=dc.CoordinatorMode.INDEPENDENT_WORKER)
  File ""/home/angoyal/ws/scratch/myvenv/lib/python3.7/site-packages/tensorflow_core/python/distribute/distribute_coordinator.py"", line 853, in run_distribute_coordinator
    task_id, session_config, rpc_layer)
  File ""/home/angoyal/ws/scratch/myvenv/lib/python3.7/site-packages/tensorflow_core/python/distribute/distribute_coordinator.py"", line 360, in _run_single_worker
    return worker_fn(strategy)
  File ""/home/angoyal/ws/scratch/myvenv/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_distributed.py"", line 772, in _worker_fn
    return method(model, **kwargs)
  File ""/home/angoyal/ws/scratch/myvenv/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_distributed.py"", line 685, in fit
    steps_name='steps_per_epoch')
  File ""/home/angoyal/ws/scratch/myvenv/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_arrays.py"", line 352, in model_iteration
    callbacks._call_batch_hook(mode, 'end', step, batch_logs)
  File ""/home/angoyal/ws/scratch/myvenv/lib/python3.7/site-packages/tensorflow_core/python/keras/callbacks.py"", line 239, in _call_batch_hook
    batch_hook(batch, logs)
  File ""/home/angoyal/ws/scratch/myvenv/lib/python3.7/site-packages/tensorflow_core/python/keras/callbacks.py"", line 528, in on_train_batch_end
    self.on_batch_end(batch, logs=logs)
  File ""/home/angoyal/ws/scratch/myvenv/lib/python3.7/site-packages/tensorflow_core/python/keras/callbacks.py"", line 977, in on_batch_end
    self._save_model(epoch=self._current_epoch, logs=logs)
  File ""/home/angoyal/ws/scratch/myvenv/lib/python3.7/site-packages/tensorflow_core/python/keras/callbacks.py"", line 1038, in _save_model
    self.model.save_weights(filepath, overwrite=True)
  File ""/home/angoyal/ws/scratch/myvenv/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py"", line 1123, in save_weights
    self._trackable_saver.save(filepath, session=session)
  File ""/home/angoyal/ws/scratch/myvenv/lib/python3.7/site-packages/tensorflow_core/python/training/tracking/util.py"", line 1168, in save
    file_prefix=file_prefix_tensor, object_graph_tensor=object_graph_tensor)
  File ""/home/angoyal/ws/scratch/myvenv/lib/python3.7/site-packages/tensorflow_core/python/training/tracking/util.py"", line 1116, in _save_cached_when_graph_building
    save_op = saver.save(file_prefix)
  File ""/home/angoyal/ws/scratch/myvenv/lib/python3.7/site-packages/tensorflow_core/python/training/saving/functional_saver.py"", line 230, in save
    sharded_saves.append(saver.save(shard_prefix))
  File ""/home/angoyal/ws/scratch/myvenv/lib/python3.7/site-packages/tensorflow_core/python/training/saving/functional_saver.py"", line 72, in save
    return io_ops.save_v2(file_prefix, tensor_names, tensor_slices, tensors)
  File ""/home/angoyal/ws/scratch/myvenv/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_io_ops.py"", line 1717, in save_v2
    name=name)
  File ""/home/angoyal/ws/scratch/myvenv/lib/python3.7/site-packages/tensorflow_core/python/framework/op_def_library.py"", line 742, in _apply_op_helper
    attrs=attr_protos, op_def=op_def)
  File ""/home/angoyal/ws/scratch/myvenv/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py"", line 3322, in _create_op_internal
    op_def=op_def)
  File ""/home/angoyal/ws/scratch/myvenv/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py"", line 1756, in __init__
    self._traceback = tf_stack.extract_stack()

Exception ignored in: <function Server.__del__ at 0x7f4457191320>
Traceback (most recent call last):
  File ""/home/angoyal/ws/scratch/myvenv/lib/python3.7/site-packages/tensorflow_core/python/training/server_lib.py"", line 158, in __del__
AttributeError: 'NoneType' object has no attribute 'UnimplementedError'
```

2nd terminal
```
# isolate the mount namespace
$ unshare --mount
$ mkdir newtmp; mount --bind ./newtmp /tmp
$ python model.py ps0 /tmp
...
...
2020-04-13 18:04:37.871417: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:300] Initialize GrpcChannelCache for job ps -> {0 -> localhost:5711}
2020-04-13 18:04:37.871485: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:300] Initialize GrpcChannelCache for job worker -> {0 -> localhost:5773}
2020-04-13 18:04:37.872330: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:390] Started server with target: grpc://localhost:5711
2020-04-13 18:09:31.762295: W tensorflow/core/framework/op_kernel.cc:1655] OP_REQUIRES failed at save_restore_v2_ops.cc:109 : Not found: /tmp/checkpoints/model.ckpt-0001_temp_64dd8f8a454a4a28b378ce888c66219e; No such file or directory
```
**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

- It works fine with MultiWorkerMirrorStrategy
- Even if we wanted to give shared access through HDFS, It doesn't work. It tries to write to a /tmp location on workers other than chief.
- It does work if all the workers and ps are running on the same machine with local filesystem access.
"
38513,Tflite GPU Delegate for Jetson TK1 Platform 32bit K1 GPU,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>

**System information**
- TensorFlow version (you are using):

v2.1.0

- Are you willing to contribute it (Yes/No):

yes, I'm barely looking into it, and would appreciate help, as the issues ( inevitably ) occur. 

**Describe the feature and the current behavior/state.**

Just getting started, and completely un-optimistic ( but worth a shot right? )

**Will this change the current api? How?**

Hardly,
Will merely require build instructions on how to get openGL ES 3.1 compiled with jetson tk1

**Who will benefit with this feature?**

Anyone who has a aging 32bit TK1 dev board or Nyan-Big Chromebook

**Any Other info.**

OpenGL ES support since Jetpack v1.2
https://developer.nvidia.com/jetson-tk1-development-pack-1_2"
38512,Keras Callbacks `params` API change,"In the current nightly there were changes to the `params` attribute in the Callbacks that is affecting custom callbacks code.

**System information** 
- Yes
- Colab

**Describe the current behavior**

The minimal example is:

```
import tensorflow as tf
model = tf.keras.Sequential([tf.keras.layers.Dense(1)])
model.compile(loss = ""mse"", optimizer = ""sgd"")
callback = tf.keras.callbacks.Callback()
model.fit(
    [1,2,3],
    [5,6,7],
    callbacks = [callback]
)
callback.params
```

With current 2.2-rc3 we see:

```
{'epochs': 1, 'steps': 1, 'verbose': 1}
```

**Describe the expected behavior**

The expected behavior is a dict with the following parameters:

```
{'batch_size': 32,
 'do_validation': False,
 'epochs': 1,
 'metrics': ['loss'],
 'samples': 3,
 'steps': 1,
 'verbose': 1}
```

Here are colab links for:

2.1: https://colab.research.google.com/drive/1D0o-1J9StBPqnrgnOBH5NuqbxoLHodN4
2.2-rc2: https://colab.research.google.com/drive/15c6gJSCL19xrx68fmgUtFsbXFDDYpg3_


"
38511,RuntimeError while trying to run with Parameter Server Strategy in Eager mode,"**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow): **No**
- OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04): **RHEL 7**
- TensorFlow installed from (source or
binary): - TensorFlow version (use command below): **2.0, 2.1**

**Describe the current behavior**
The model fails to instantiate and fails with the following error:
```
  File ""model.py"", line 10, in <module>
    tf.keras.layers.Conv2D(32, 3, activation='relu', input_shape=(28, 28, 1)),
  File ""/home/angoyal/ws/scratch/myvenv/lib/python3.7/site-packages/tensorflow_core/python/training/tracking/base.py"", line 457, in _method_wrapper
    result = method(self, *args, **kwargs)
  File ""/home/angoyal/ws/scratch/myvenv/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/sequential.py"", line 116, in __init__
    self.add(layer)
  File ""/home/angoyal/ws/scratch/myvenv/lib/python3.7/site-packages/tensorflow_core/python/training/tracking/base.py"", line 457, in _method_wrapper
    result = method(self, *args, **kwargs)
  File ""/home/angoyal/ws/scratch/myvenv/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/sequential.py"", line 185, in add
    layer(x)
  File ""/home/angoyal/ws/scratch/myvenv/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 748, in __call__
    self._maybe_build(inputs)
  File ""/home/angoyal/ws/scratch/myvenv/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 2116, in _maybe_build
    self.build(input_shapes)
  File ""/home/angoyal/ws/scratch/myvenv/lib/python3.7/site-packages/tensorflow_core/python/keras/layers/convolutional.py"", line 158, in build
    dtype=self.dtype)
  File ""/home/angoyal/ws/scratch/myvenv/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 446, in add_weight
    caching_device=caching_device)
  File ""/home/angoyal/ws/scratch/myvenv/lib/python3.7/site-packages/tensorflow_core/python/training/tracking/base.py"", line 744, in _add_variable_with_custom_getter
    **kwargs_for_getter)
  File ""/home/angoyal/ws/scratch/myvenv/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer_utils.py"", line 142, in make_variable
    shape=variable_shape if variable_shape else None)
  File ""/home/angoyal/ws/scratch/myvenv/lib/python3.7/site-packages/tensorflow_core/python/ops/variables.py"", line 258, in __call__
    return cls._variable_v1_call(*args, **kwargs)
  File ""/home/angoyal/ws/scratch/myvenv/lib/python3.7/site-packages/tensorflow_core/python/ops/variables.py"", line 219, in _variable_v1_call
    shape=shape)
  File ""/home/angoyal/ws/scratch/myvenv/lib/python3.7/site-packages/tensorflow_core/python/ops/variables.py"", line 65, in getter
    return captured_getter(captured_previous, **kwargs)
  File ""/home/angoyal/ws/scratch/myvenv/lib/python3.7/site-packages/tensorflow_core/python/distribute/distribute_lib.py"", line 1330, in creator_with_resource_vars
    return self._create_variable(*args, **kwargs)
  File ""/home/angoyal/ws/scratch/myvenv/lib/python3.7/site-packages/tensorflow_core/python/distribute/parameter_server_strategy.py"", line 446, in _create_variable
    with ops.device(self._variable_device):
  File ""/home/angoyal/ws/scratch/myvenv/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py"", line 5032, in device
    ""tf.device does not support functions when eager execution ""
RuntimeError: tf.device does not support functions when eager execution is enabled.
```
**Describe the expected behavior**
The model should instantiate

**Standalone code to reproduce the issue** 
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

```
(myvenv) [angoyal@angoyal-ld2 scratch]$ cat model.py
import os
import tensorflow as tf

os.environ['TF_CONFIG'] = '{""cluster"": {""worker"": [""localhost:5773""], ""ps"": [""localhost:5711""]}, ""task"": {""type"": ""worker"", ""index"": 0}}'

strategy = tf.distribute.experimental.ParameterServerStrategy()

with strategy.scope():
    model = tf.keras.Sequential([
        tf.keras.layers.Conv2D(32, 3, activation='relu', input_shape=(28, 28, 1)),
    ])
````

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
38510,Cannot find dependencies to use in bazel BUILD to compile tensorflow lite,"Thank you for submitting a TensorFlow documentation issue. Per our GitHub
policy, we only address code/doc bugs, performance issues, feature requests, and
build/installation issues on GitHub.

The TensorFlow docs are open source! To get involved, read the documentation
contributor guide: https://www.tensorflow.org/community/contribute/docs

## URL(s) with the issue:

Please provide a link to the documentation entry, for example:
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/MyMethod

## Description of issue (what needs changing):

Unable to find documentation to compile a .cc file that will load and run the interpreter on a tflite model.  I have created a test folder which contains test.cc and BUILD  the build file is shown as below.  I have attempted to list deps but it fails to compile each time i run bazel build :test from within the test directory

cc_binary(
    name = ""catlite"",
    srcs = [""catlite.cc""],
    deps = []

)

### Clear description

For example, why should someone use this method? How is it useful?

### Correct links

Is the link to the source code correct?

### Parameters defined

Are all parameters defined and formatted correctly?

### Returns defined

Are return values defined?

### Raises listed and defined

Are the errors defined? For example,
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises

### Usage example

Is there a usage example?

See the API guide: https://www.tensorflow.org/community/contribute/docs_ref
on how to write testable usage examples.

### Request visuals, if applicable

Are there currently visuals? If not, will it clarify the content?

### Submit a pull request?

Are you planning to also submit a pull request to fix the issue? See the docs
contributor guide: https://www.tensorflow.org/community/contribute/docs,
docs API guide: https://www.tensorflow.org/community/contribute/docs_ref and the
docs style guide: https://www.tensorflow.org/community/contribute/docs_style
"
38508,Tensorboard exception with non-ascii character username on windows,"When there are non-ascii characters in the user name, tensorboard will have problems.

```
2020-04-14 04:28:35.993085: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1441] function cupti_interface_->EnableCallback( 0 , subscriber_, CUPTI_CB_DOMAIN_DRIVER_API, cbid)failed with error CUPTI could not be loaded or symbol could not be found.
2020-04-14 04:28:35.996519: I tensorflow/core/profiler/internal/gpu/device_tracer.cc:217]  GpuTracer has collected 0 callback api events and 0 activity events.
2020-04-14 04:28:36.013131: I tensorflow/core/profiler/rpc/client/save_profile.cc:168] Creating directory: logs\train\plugins\profile\2020_04_13_20_28_35
2020-04-14 04:28:36.027295: I tensorflow/core/profiler/rpc/client/save_profile.cc:174] Dumped gzipped tool data for trace.json.gz to logs\train\plugins\profile\2020_04_13_20_28_35\���Ǳ���ļ���.trace.json.gz
2020-04-14 04:28:36.031216: I tensorflow/core/profiler/utils/event_span.cc:288] Generation of step-events took 0 ms

2020-04-14 04:28:36.039011: I tensorflow/python/profiler/internal/profiler_wrapper.cc:91] Creating directory: logs\train\plugins\profile\2020_04_13_20_28_35Dumped tool data for overview_page.pb to logs\train\plugins\profile\2020_04_13_20_28_35\���Ǳ���ļ���.overview_page.pb
Dumped tool data for input_pipeline.pb to logs\train\plugins\profile\2020_04_13_20_28_35\���Ǳ���ļ���.input_pipeline.pb
Dumped tool data for tensorflow_stats.pb to logs\train\plugins\profile\2020_04_13_20_28_35\���Ǳ���ļ���.tensorflow_stats.pb
Dumped tool data for kernel_stats.pb to logs\train\plugins\profile\2020_04_13_20_28_35\���Ǳ���ļ���.kernel_stats.pb
```"
38507,building tfcompile.exe debug mode with Windows failed,"I want to use the debug mode tfcompile to trace into one problem that XLA/AOT cannot compile my model. But I found problem in building the debug mode tfcompile file.

I followed https://www.tensorflow.org/install/source (for windows part), installed msys2.With all nvidia drivers Cuda, cudnn installed.

Tensorflow 2.2.0 (latest on branch r2.2 on Apr 13, 2020), 
Win10 Pro, 
Python 3.6, 
Bazel 2.0.0 (or 2.2.0) 
Cuda 10.2 + Cudnn
nvidia 1060

VS2019 native console:
cd d:/w/Git/tensorflowDebugpython configure.py
`python configure.py`

I can successfully build release mode tfcompile, using command
`bazel build --config=opt --config=cuda //tensorflow/compiler/aot:tfcompile` 

But never succeed for debug mode, with the following command under VS2019 native console:
`bazel build -s --config=opt -c dbg --strip=never --config=cuda //tensorflow/compiler/aot:tfcompile` 

There were some bugs  I had to fix before going to the following symbol link errors, basically the return value empty error. I have no idea why they did not affect the release version. I can't find any clue in C++ codes to differentiate the release and debug modes. Only bazel --config=opt -c dbg seems the switch to turn debug on. I traced into bazel files, but not found any suspicious errors.

Another bug I have to work around is I saw:
C:/Users/yuefe/AppData/Local/Temp/nvcc_inter_files_tmp_dir/tmpdiauwif_/fill_functor.cu.compute_70.cudafe1.cpp: fatal error C1041: cannot open program database 'C:\users\yuefe\_bazel_yuefe\p5ggus4g\execroot\org_tensorflow\vc140.pdb'; if multiple CL.EXE write to the same .PDB file, please use /FS

I cannot find the root. My solution is to add --job 1 to the command line:
`bazel build --jobs 1 -s --config=opt -c dbg --strip=never --config=cuda //tensorflow/compiler/aot:tfcompile` 

Finally, compiling can reach the following point:

When failing, I observed:
libconcat_op.lo(concat_op.o) : error LNK2019: unresolved external symbol ""void __cdecl tensorflow::ConcatGPU<unsigned __int64>(class tensorflow::OpKernelContext *,class std::vector<class std::unique_ptr<class Eigen::TensorMap<class Eigen::Tensor<unsigned __int64 const ,2,1,__int64>,16,struct Eigen::MakePointer>,struct std::default_delete<class Eigen::TensorMap<class Eigen::Tensor<unsigned __int64 const ,2,1,__int64>,16,struct Eigen::MakePointer> > >,class std::allocator<class std::unique_ptr<class Eigen::TensorMap<class Eigen::Tensor<unsigned __int64 const ,2,1,__int64>,16,struct Eigen::MakePointer>,struct std::default_delete<class Eigen::TensorMap<class Eigen::Tensor<unsigned __int64 const ,2,1,__int64>,16,struct Eigen::MakePointer> > > > > const &,class tensorflow::Tensor *,class Eigen::TensorMap<class Eigen::Tensor<unsigned __int64,2,1,__int64>,16,struct Eigen::MakePointer> *)"" (??$ConcatGPU@_K@tensorflow@@YAXPEAVOpKernelContext@0@AEBV?$vector@V?$unique_ptr@V?$TensorMap@V?$Tensor@$$CB_K$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@U?$default_delete@V?$TensorMap@V?$Tensor@$$CB_K$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@std@@@std@@V?$allocator@V?$unique_ptr@V?$TensorMap@V?$Tensor@$$CB_K$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@U?$default_delete@V?$TensorMap@V?$Tensor@$$CB_K$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@std@@@std@@@2@@std@@PEAVTensor@0@PEAV?$TensorMap@V?$Tensor@_K$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@Z) referenced in function ""public: virtual void __cdecl tensorflow::ConcatBaseOp<struct Eigen::ThreadPoolDevice,unsigned __int64,1>::Compute(class tensorflow::OpKernelContext *)"" (?Compute@?$ConcatBaseOp@UThreadPoolDevice@Eigen@@_K$00@tensorflow@@UEAAXPEAVOpKernelContext@2@@Z)
libconcat_op.lo(concat_op.o) : error LNK2019: unresolved external symbol ""void __cdecl tensorflow::ConcatGPU<unsigned int>(class tensorflow::OpKernelContext *,class std::vector<class std::unique_ptr<class Eigen::TensorMap<class Eigen::Tensor<unsigned int const ,2,1,__int64>,16,struct Eigen::MakePointer>,struct std::default_delete<class Eigen::TensorMap<class Eigen::Tensor<unsigned int const ,2,1,__int64>,16,struct Eigen::MakePointer> > >,class std::allocator<class std::unique_ptr<class Eigen::TensorMap<class Eigen::Tensor<unsigned int const ,2,1,__int64>,16,struct Eigen::MakePointer>,struct std::default_delete<class Eigen::TensorMap<class Eigen::Tensor<unsigned int const ,2,1,__int64>,16,struct Eigen::MakePointer> > > > > const &,class tensorflow::Tensor *,class Eigen::TensorMap<class Eigen::Tensor<unsigned int,2,1,__int64>,16,struct Eigen::MakePointer> *)"" (??$ConcatGPU@I@tensorflow@@YAXPEAVOpKernelContext@0@AEBV?$vector@V?$unique_ptr@V?$TensorMap@V?$Tensor@$$CBI$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@U?$default_delete@V?$TensorMap@V?$Tensor@$$CBI$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@std@@@std@@V?$allocator@V?$unique_ptr@V?$TensorMap@V?$Tensor@$$CBI$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@U?$default_delete@V?$TensorMap@V?$Tensor@$$CBI$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@std@@@std@@@2@@std@@PEAVTensor@0@PEAV?$TensorMap@V?$Tensor@I$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@Z) referenced in function ""public: virtual void __cdecl tensorflow::ConcatBaseOp<struct Eigen::ThreadPoolDevice,unsigned int,1>::Compute(class tensorflow::OpKernelContext *)"" (?Compute@?$ConcatBaseOp@UThreadPoolDevice@Eigen@@I$00@tensorflow@@UEAAXPEAVOpKernelContext@2@@Z)
libconcat_op.lo(concat_op.o) : error LNK2019: unresolved external symbol ""void __cdecl tensorflow::ConcatGPU<struct Eigen::QInt32>(class tensorflow::OpKernelContext *,class std::vector<class std::unique_ptr<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QInt32 const ,2,1,__int64>,16,struct Eigen::MakePointer>,struct std::default_delete<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QInt32 const ,2,1,__int64>,16,struct Eigen::MakePointer> > >,class std::allocator<class std::unique_ptr<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QInt32 const ,2,1,__int64>,16,struct Eigen::MakePointer>,struct std::default_delete<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QInt32 const ,2,1,__int64>,16,struct Eigen::MakePointer> > > > > const &,class tensorflow::Tensor *,class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QInt32,2,1,__int64>,16,struct Eigen::MakePointer> *)"" (??$ConcatGPU@UQInt32@Eigen@@@tensorflow@@YAXPEAVOpKernelContext@0@AEBV?$vector@V?$unique_ptr@V?$TensorMap@V?$Tensor@$$CBUQInt32@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@U?$default_delete@V?$TensorMap@V?$Tensor@$$CBUQInt32@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@std@@@std@@V?$allocator@V?$unique_ptr@V?$TensorMap@V?$Tensor@$$CBUQInt32@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@U?$default_delete@V?$TensorMap@V?$Tensor@$$CBUQInt32@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@std@@@std@@@2@@std@@PEAVTensor@0@PEAV?$TensorMap@V?$Tensor@UQInt32@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@Z) referenced in function ""public: virtual void __cdecl tensorflow::ConcatBaseOp<struct Eigen::ThreadPoolDevice,struct Eigen::QInt32,1>::Compute(class tensorflow::OpKernelContext *)"" (?Compute@?$ConcatBaseOp@UThreadPoolDevice@Eigen@@UQInt32@2@$00@tensorflow@@UEAAXPEAVOpKernelContext@2@@Z)
libpack_op.lo(pack_op.o) : error LNK2001: unresolved external symbol ""void __cdecl tensorflow::ConcatGPU<struct Eigen::QInt32>(class tensorflow::OpKernelContext *,class std::vector<class std::unique_ptr<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QInt32 const ,2,1,__int64>,16,struct Eigen::MakePointer>,struct std::default_delete<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QInt32 const ,2,1,__int64>,16,struct Eigen::MakePointer> > >,class std::allocator<class std::unique_ptr<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QInt32 const ,2,1,__int64>,16,struct Eigen::MakePointer>,struct std::default_delete<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QInt32 const ,2,1,__int64>,16,struct Eigen::MakePointer> > > > > const &,class tensorflow::Tensor *,class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QInt32,2,1,__int64>,16,struct Eigen::MakePointer> *)"" (??$ConcatGPU@UQInt32@Eigen@@@tensorflow@@YAXPEAVOpKernelContext@0@AEBV?$vector@V?$unique_ptr@V?$TensorMap@V?$Tensor@$$CBUQInt32@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@U?$default_delete@V?$TensorMap@V?$Tensor@$$CBUQInt32@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@std@@@std@@V?$allocator@V?$unique_ptr@V?$TensorMap@V?$Tensor@$$CBUQInt32@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@U?$default_delete@V?$TensorMap@V?$Tensor@$$CBUQInt32@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@std@@@std@@@2@@std@@PEAVTensor@0@PEAV?$TensorMap@V?$Tensor@UQInt32@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@Z)
libtensor_array_ops.lo(tensor_array_ops.o) : error LNK2001: unresolved external symbol ""void __cdecl tensorflow::ConcatGPU<struct Eigen::QInt32>(class tensorflow::OpKernelContext *,class std::vector<class std::unique_ptr<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QInt32 const ,2,1,__int64>,16,struct Eigen::MakePointer>,struct std::default_delete<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QInt32 const ,2,1,__int64>,16,struct Eigen::MakePointer> > >,class std::allocator<class std::unique_ptr<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QInt32 const ,2,1,__int64>,16,struct Eigen::MakePointer>,struct std::default_delete<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QInt32 const ,2,1,__int64>,16,struct Eigen::MakePointer> > > > > const &,class tensorflow::Tensor *,class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QInt32,2,1,__int64>,16,struct Eigen::MakePointer> *)"" (??$ConcatGPU@UQInt32@Eigen@@@tensorflow@@YAXPEAVOpKernelContext@0@AEBV?$vector@V?$unique_ptr@V?$TensorMap@V?$Tensor@$$CBUQInt32@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@U?$default_delete@V?$TensorMap@V?$Tensor@$$CBUQInt32@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@std@@@std@@V?$allocator@V?$unique_ptr@V?$TensorMap@V?$Tensor@$$CBUQInt32@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@U?$default_delete@V?$TensorMap@V?$Tensor@$$CBUQInt32@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@std@@@std@@@2@@std@@PEAVTensor@0@PEAV?$TensorMap@V?$Tensor@UQInt32@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@Z)
liblist_kernels.lo(list_kernels.o) : error LNK2001: unresolved external symbol ""void __cdecl tensorflow::ConcatGPU<struct Eigen::QInt32>(class tensorflow::OpKernelContext *,class std::vector<class std::unique_ptr<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QInt32 const ,2,1,__int64>,16,struct Eigen::MakePointer>,struct std::default_delete<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QInt32 const ,2,1,__int64>,16,struct Eigen::MakePointer> > >,class std::allocator<class std::unique_ptr<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QInt32 const ,2,1,__int64>,16,struct Eigen::MakePointer>,struct std::default_delete<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QInt32 const ,2,1,__int64>,16,struct Eigen::MakePointer> > > > > const &,class tensorflow::Tensor *,class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QInt32,2,1,__int64>,16,struct Eigen::MakePointer> *)"" (??$ConcatGPU@UQInt32@Eigen@@@tensorflow@@YAXPEAVOpKernelContext@0@AEBV?$vector@V?$unique_ptr@V?$TensorMap@V?$Tensor@$$CBUQInt32@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@U?$default_delete@V?$TensorMap@V?$Tensor@$$CBUQInt32@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@std@@@std@@V?$allocator@V?$unique_ptr@V?$TensorMap@V?$Tensor@$$CBUQInt32@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@U?$default_delete@V?$TensorMap@V?$Tensor@$$CBUQInt32@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@std@@@std@@@2@@std@@PEAVTensor@0@PEAV?$TensorMap@V?$Tensor@UQInt32@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@Z)
libconcat_op.lo(concat_op.o) : error LNK2019: unresolved external symbol ""void __cdecl tensorflow::ConcatGPU<struct Eigen::QInt16>(class tensorflow::OpKernelContext *,class std::vector<class std::unique_ptr<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QInt16 const ,2,1,__int64>,16,struct Eigen::MakePointer>,struct std::default_delete<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QInt16 const ,2,1,__int64>,16,struct Eigen::MakePointer> > >,class std::allocator<class std::unique_ptr<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QInt16 const ,2,1,__int64>,16,struct Eigen::MakePointer>,struct std::default_delete<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QInt16 const ,2,1,__int64>,16,struct Eigen::MakePointer> > > > > const &,class tensorflow::Tensor *,class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QInt16,2,1,__int64>,16,struct Eigen::MakePointer> *)"" (??$ConcatGPU@UQInt16@Eigen@@@tensorflow@@YAXPEAVOpKernelContext@0@AEBV?$vector@V?$unique_ptr@V?$TensorMap@V?$Tensor@$$CBUQInt16@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@U?$default_delete@V?$TensorMap@V?$Tensor@$$CBUQInt16@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@std@@@std@@V?$allocator@V?$unique_ptr@V?$TensorMap@V?$Tensor@$$CBUQInt16@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@U?$default_delete@V?$TensorMap@V?$Tensor@$$CBUQInt16@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@std@@@std@@@2@@std@@PEAVTensor@0@PEAV?$TensorMap@V?$Tensor@UQInt16@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@Z) referenced in function ""public: virtual void __cdecl tensorflow::ConcatBaseOp<struct Eigen::ThreadPoolDevice,struct Eigen::QInt16,1>::Compute(class tensorflow::OpKernelContext *)"" (?Compute@?$ConcatBaseOp@UThreadPoolDevice@Eigen@@UQInt16@2@$00@tensorflow@@UEAAXPEAVOpKernelContext@2@@Z)
liblist_kernels.lo(list_kernels.o) : error LNK2001: unresolved external symbol ""void __cdecl tensorflow::ConcatGPU<struct Eigen::QInt16>(class tensorflow::OpKernelContext *,class std::vector<class std::unique_ptr<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QInt16 const ,2,1,__int64>,16,struct Eigen::MakePointer>,struct std::default_delete<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QInt16 const ,2,1,__int64>,16,struct Eigen::MakePointer> > >,class std::allocator<class std::unique_ptr<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QInt16 const ,2,1,__int64>,16,struct Eigen::MakePointer>,struct std::default_delete<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QInt16 const ,2,1,__int64>,16,struct Eigen::MakePointer> > > > > const &,class tensorflow::Tensor *,class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QInt16,2,1,__int64>,16,struct Eigen::MakePointer> *)"" (??$ConcatGPU@UQInt16@Eigen@@@tensorflow@@YAXPEAVOpKernelContext@0@AEBV?$vector@V?$unique_ptr@V?$TensorMap@V?$Tensor@$$CBUQInt16@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@U?$default_delete@V?$TensorMap@V?$Tensor@$$CBUQInt16@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@std@@@std@@V?$allocator@V?$unique_ptr@V?$TensorMap@V?$Tensor@$$CBUQInt16@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@U?$default_delete@V?$TensorMap@V?$Tensor@$$CBUQInt16@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@std@@@std@@@2@@std@@PEAVTensor@0@PEAV?$TensorMap@V?$Tensor@UQInt16@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@Z)
libconcat_op.lo(concat_op.o) : error LNK2019: unresolved external symbol ""void __cdecl tensorflow::ConcatGPU<struct Eigen::QUInt16>(class tensorflow::OpKernelContext *,class std::vector<class std::unique_ptr<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QUInt16 const ,2,1,__int64>,16,struct Eigen::MakePointer>,struct std::default_delete<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QUInt16 const ,2,1,__int64>,16,struct Eigen::MakePointer> > >,class std::allocator<class std::unique_ptr<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QUInt16 const ,2,1,__int64>,16,struct Eigen::MakePointer>,struct std::default_delete<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QUInt16 const ,2,1,__int64>,16,struct Eigen::MakePointer> > > > > const &,class tensorflow::Tensor *,class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QUInt16,2,1,__int64>,16,struct Eigen::MakePointer> *)"" (??$ConcatGPU@UQUInt16@Eigen@@@tensorflow@@YAXPEAVOpKernelContext@0@AEBV?$vector@V?$unique_ptr@V?$TensorMap@V?$Tensor@$$CBUQUInt16@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@U?$default_delete@V?$TensorMap@V?$Tensor@$$CBUQUInt16@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@std@@@std@@V?$allocator@V?$unique_ptr@V?$TensorMap@V?$Tensor@$$CBUQUInt16@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@U?$default_delete@V?$TensorMap@V?$Tensor@$$CBUQUInt16@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@std@@@std@@@2@@std@@PEAVTensor@0@PEAV?$TensorMap@V?$Tensor@UQUInt16@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@Z) referenced in function ""public: virtual void __cdecl tensorflow::ConcatBaseOp<struct Eigen::ThreadPoolDevice,struct Eigen::QUInt16,1>::Compute(class tensorflow::OpKernelContext *)"" (?Compute@?$ConcatBaseOp@UThreadPoolDevice@Eigen@@UQUInt16@2@$00@tensorflow@@UEAAXPEAVOpKernelContext@2@@Z)
liblist_kernels.lo(list_kernels.o) : error LNK2001: unresolved external symbol ""void __cdecl tensorflow::ConcatGPU<struct Eigen::QUInt16>(class tensorflow::OpKernelContext *,class std::vector<class std::unique_ptr<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QUInt16 const ,2,1,__int64>,16,struct Eigen::MakePointer>,struct std::default_delete<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QUInt16 const ,2,1,__int64>,16,struct Eigen::MakePointer> > >,class std::allocator<class std::unique_ptr<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QUInt16 const ,2,1,__int64>,16,struct Eigen::MakePointer>,struct std::default_delete<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QUInt16 const ,2,1,__int64>,16,struct Eigen::MakePointer> > > > > const &,class tensorflow::Tensor *,class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QUInt16,2,1,__int64>,16,struct Eigen::MakePointer> *)"" (??$ConcatGPU@UQUInt16@Eigen@@@tensorflow@@YAXPEAVOpKernelContext@0@AEBV?$vector@V?$unique_ptr@V?$TensorMap@V?$Tensor@$$CBUQUInt16@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@U?$default_delete@V?$TensorMap@V?$Tensor@$$CBUQUInt16@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@std@@@std@@V?$allocator@V?$unique_ptr@V?$TensorMap@V?$Tensor@$$CBUQUInt16@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@U?$default_delete@V?$TensorMap@V?$Tensor@$$CBUQUInt16@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@std@@@std@@@2@@std@@PEAVTensor@0@PEAV?$TensorMap@V?$Tensor@UQUInt16@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@Z)
libconcat_op.lo(concat_op.o) : error LNK2019: unresolved external symbol ""void __cdecl tensorflow::ConcatGPU<struct Eigen::QInt8>(class tensorflow::OpKernelContext *,class std::vector<class std::unique_ptr<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QInt8 const ,2,1,__int64>,16,struct Eigen::MakePointer>,struct std::default_delete<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QInt8 const ,2,1,__int64>,16,struct Eigen::MakePointer> > >,class std::allocator<class std::unique_ptr<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QInt8 const ,2,1,__int64>,16,struct Eigen::MakePointer>,struct std::default_delete<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QInt8 const ,2,1,__int64>,16,struct Eigen::MakePointer> > > > > const &,class tensorflow::Tensor *,class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QInt8,2,1,__int64>,16,struct Eigen::MakePointer> *)"" (??$ConcatGPU@UQInt8@Eigen@@@tensorflow@@YAXPEAVOpKernelContext@0@AEBV?$vector@V?$unique_ptr@V?$TensorMap@V?$Tensor@$$CBUQInt8@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@U?$default_delete@V?$TensorMap@V?$Tensor@$$CBUQInt8@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@std@@@std@@V?$allocator@V?$unique_ptr@V?$TensorMap@V?$Tensor@$$CBUQInt8@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@U?$default_delete@V?$TensorMap@V?$Tensor@$$CBUQInt8@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@std@@@std@@@2@@std@@PEAVTensor@0@PEAV?$TensorMap@V?$Tensor@UQInt8@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@Z) referenced in function ""public: virtual void __cdecl tensorflow::ConcatBaseOp<struct Eigen::ThreadPoolDevice,struct Eigen::QInt8,1>::Compute(class tensorflow::OpKernelContext *)"" (?Compute@?$ConcatBaseOp@UThreadPoolDevice@Eigen@@UQInt8@2@$00@tensorflow@@UEAAXPEAVOpKernelContext@2@@Z)
libpack_op.lo(pack_op.o) : error LNK2001: unresolved external symbol ""void __cdecl tensorflow::ConcatGPU<struct Eigen::QInt8>(class tensorflow::OpKernelContext *,class std::vector<class std::unique_ptr<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QInt8 const ,2,1,__int64>,16,struct Eigen::MakePointer>,struct std::default_delete<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QInt8 const ,2,1,__int64>,16,struct Eigen::MakePointer> > >,class std::allocator<class std::unique_ptr<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QInt8 const ,2,1,__int64>,16,struct Eigen::MakePointer>,struct std::default_delete<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QInt8 const ,2,1,__int64>,16,struct Eigen::MakePointer> > > > > const &,class tensorflow::Tensor *,class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QInt8,2,1,__int64>,16,struct Eigen::MakePointer> *)"" (??$ConcatGPU@UQInt8@Eigen@@@tensorflow@@YAXPEAVOpKernelContext@0@AEBV?$vector@V?$unique_ptr@V?$TensorMap@V?$Tensor@$$CBUQInt8@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@U?$default_delete@V?$TensorMap@V?$Tensor@$$CBUQInt8@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@std@@@std@@V?$allocator@V?$unique_ptr@V?$TensorMap@V?$Tensor@$$CBUQInt8@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@U?$default_delete@V?$TensorMap@V?$Tensor@$$CBUQInt8@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@std@@@std@@@2@@std@@PEAVTensor@0@PEAV?$TensorMap@V?$Tensor@UQInt8@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@Z)
libtensor_array_ops.lo(tensor_array_ops.o) : error LNK2001: unresolved external symbol ""void __cdecl tensorflow::ConcatGPU<struct Eigen::QInt8>(class tensorflow::OpKernelContext *,class std::vector<class std::unique_ptr<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QInt8 const ,2,1,__int64>,16,struct Eigen::MakePointer>,struct std::default_delete<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QInt8 const ,2,1,__int64>,16,struct Eigen::MakePointer> > >,class std::allocator<class std::unique_ptr<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QInt8 const ,2,1,__int64>,16,struct Eigen::MakePointer>,struct std::default_delete<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QInt8 const ,2,1,__int64>,16,struct Eigen::MakePointer> > > > > const &,class tensorflow::Tensor *,class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QInt8,2,1,__int64>,16,struct Eigen::MakePointer> *)"" (??$ConcatGPU@UQInt8@Eigen@@@tensorflow@@YAXPEAVOpKernelContext@0@AEBV?$vector@V?$unique_ptr@V?$TensorMap@V?$Tensor@$$CBUQInt8@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@U?$default_delete@V?$TensorMap@V?$Tensor@$$CBUQInt8@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@std@@@std@@V?$allocator@V?$unique_ptr@V?$TensorMap@V?$Tensor@$$CBUQInt8@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@U?$default_delete@V?$TensorMap@V?$Tensor@$$CBUQInt8@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@std@@@std@@@2@@std@@PEAVTensor@0@PEAV?$TensorMap@V?$Tensor@UQInt8@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@Z)
liblist_kernels.lo(list_kernels.o) : error LNK2001: unresolved external symbol ""void __cdecl tensorflow::ConcatGPU<struct Eigen::QInt8>(class tensorflow::OpKernelContext *,class std::vector<class std::unique_ptr<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QInt8 const ,2,1,__int64>,16,struct Eigen::MakePointer>,struct std::default_delete<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QInt8 const ,2,1,__int64>,16,struct Eigen::MakePointer> > >,class std::allocator<class std::unique_ptr<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QInt8 const ,2,1,__int64>,16,struct Eigen::MakePointer>,struct std::default_delete<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QInt8 const ,2,1,__int64>,16,struct Eigen::MakePointer> > > > > const &,class tensorflow::Tensor *,class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QInt8,2,1,__int64>,16,struct Eigen::MakePointer> *)"" (??$ConcatGPU@UQInt8@Eigen@@@tensorflow@@YAXPEAVOpKernelContext@0@AEBV?$vector@V?$unique_ptr@V?$TensorMap@V?$Tensor@$$CBUQInt8@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@U?$default_delete@V?$TensorMap@V?$Tensor@$$CBUQInt8@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@std@@@std@@V?$allocator@V?$unique_ptr@V?$TensorMap@V?$Tensor@$$CBUQInt8@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@U?$default_delete@V?$TensorMap@V?$Tensor@$$CBUQInt8@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@std@@@std@@@2@@std@@PEAVTensor@0@PEAV?$TensorMap@V?$Tensor@UQInt8@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@Z)
libconcat_op.lo(concat_op.o) : error LNK2019: unresolved external symbol ""void __cdecl tensorflow::ConcatGPU<struct Eigen::QUInt8>(class tensorflow::OpKernelContext *,class std::vector<class std::unique_ptr<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QUInt8 const ,2,1,__int64>,16,struct Eigen::MakePointer>,struct std::default_delete<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QUInt8 const ,2,1,__int64>,16,struct Eigen::MakePointer> > >,class std::allocator<class std::unique_ptr<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QUInt8 const ,2,1,__int64>,16,struct Eigen::MakePointer>,struct std::default_delete<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QUInt8 const ,2,1,__int64>,16,struct Eigen::MakePointer> > > > > const &,class tensorflow::Tensor *,class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QUInt8,2,1,__int64>,16,struct Eigen::MakePointer> *)"" (??$ConcatGPU@UQUInt8@Eigen@@@tensorflow@@YAXPEAVOpKernelContext@0@AEBV?$vector@V?$unique_ptr@V?$TensorMap@V?$Tensor@$$CBUQUInt8@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@U?$default_delete@V?$TensorMap@V?$Tensor@$$CBUQUInt8@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@std@@@std@@V?$allocator@V?$unique_ptr@V?$TensorMap@V?$Tensor@$$CBUQUInt8@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@U?$default_delete@V?$TensorMap@V?$Tensor@$$CBUQUInt8@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@std@@@std@@@2@@std@@PEAVTensor@0@PEAV?$TensorMap@V?$Tensor@UQUInt8@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@Z) referenced in function ""public: virtual void __cdecl tensorflow::ConcatBaseOp<struct Eigen::ThreadPoolDevice,struct Eigen::QUInt8,1>::Compute(class tensorflow::OpKernelContext *)"" (?Compute@?$ConcatBaseOp@UThreadPoolDevice@Eigen@@UQUInt8@2@$00@tensorflow@@UEAAXPEAVOpKernelContext@2@@Z)
libpack_op.lo(pack_op.o) : error LNK2001: unresolved external symbol ""void __cdecl tensorflow::ConcatGPU<struct Eigen::QUInt8>(class tensorflow::OpKernelContext *,class std::vector<class std::unique_ptr<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QUInt8 const ,2,1,__int64>,16,struct Eigen::MakePointer>,struct std::default_delete<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QUInt8 const ,2,1,__int64>,16,struct Eigen::MakePointer> > >,class std::allocator<class std::unique_ptr<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QUInt8 const ,2,1,__int64>,16,struct Eigen::MakePointer>,struct std::default_delete<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QUInt8 const ,2,1,__int64>,16,struct Eigen::MakePointer> > > > > const &,class tensorflow::Tensor *,class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QUInt8,2,1,__int64>,16,struct Eigen::MakePointer> *)"" (??$ConcatGPU@UQUInt8@Eigen@@@tensorflow@@YAXPEAVOpKernelContext@0@AEBV?$vector@V?$unique_ptr@V?$TensorMap@V?$Tensor@$$CBUQUInt8@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@U?$default_delete@V?$TensorMap@V?$Tensor@$$CBUQUInt8@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@std@@@std@@V?$allocator@V?$unique_ptr@V?$TensorMap@V?$Tensor@$$CBUQUInt8@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@U?$default_delete@V?$TensorMap@V?$Tensor@$$CBUQUInt8@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@std@@@std@@@2@@std@@PEAVTensor@0@PEAV?$TensorMap@V?$Tensor@UQUInt8@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@Z)
libtensor_array_ops.lo(tensor_array_ops.o) : error LNK2001: unresolved external symbol ""void __cdecl tensorflow::ConcatGPU<struct Eigen::QUInt8>(class tensorflow::OpKernelContext *,class std::vector<class std::unique_ptr<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QUInt8 const ,2,1,__int64>,16,struct Eigen::MakePointer>,struct std::default_delete<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QUInt8 const ,2,1,__int64>,16,struct Eigen::MakePointer> > >,class std::allocator<class std::unique_ptr<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QUInt8 const ,2,1,__int64>,16,struct Eigen::MakePointer>,struct std::default_delete<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QUInt8 const ,2,1,__int64>,16,struct Eigen::MakePointer> > > > > const &,class tensorflow::Tensor *,class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QUInt8,2,1,__int64>,16,struct Eigen::MakePointer> *)"" (??$ConcatGPU@UQUInt8@Eigen@@@tensorflow@@YAXPEAVOpKernelContext@0@AEBV?$vector@V?$unique_ptr@V?$TensorMap@V?$Tensor@$$CBUQUInt8@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@U?$default_delete@V?$TensorMap@V?$Tensor@$$CBUQUInt8@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@std@@@std@@V?$allocator@V?$unique_ptr@V?$TensorMap@V?$Tensor@$$CBUQUInt8@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@U?$default_delete@V?$TensorMap@V?$Tensor@$$CBUQUInt8@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@std@@@std@@@2@@std@@PEAVTensor@0@PEAV?$TensorMap@V?$Tensor@UQUInt8@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@Z)
liblist_kernels.lo(list_kernels.o) : error LNK2001: unresolved external symbol ""void __cdecl tensorflow::ConcatGPU<struct Eigen::QUInt8>(class tensorflow::OpKernelContext *,class std::vector<class std::unique_ptr<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QUInt8 const ,2,1,__int64>,16,struct Eigen::MakePointer>,struct std::default_delete<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QUInt8 const ,2,1,__int64>,16,struct Eigen::MakePointer> > >,class std::allocator<class std::unique_ptr<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QUInt8 const ,2,1,__int64>,16,struct Eigen::MakePointer>,struct std::default_delete<class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QUInt8 const ,2,1,__int64>,16,struct Eigen::MakePointer> > > > > const &,class tensorflow::Tensor *,class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QUInt8,2,1,__int64>,16,struct Eigen::MakePointer> *)"" (??$ConcatGPU@UQUInt8@Eigen@@@tensorflow@@YAXPEAVOpKernelContext@0@AEBV?$vector@V?$unique_ptr@V?$TensorMap@V?$Tensor@$$CBUQUInt8@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@U?$default_delete@V?$TensorMap@V?$Tensor@$$CBUQUInt8@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@std@@@std@@V?$allocator@V?$unique_ptr@V?$TensorMap@V?$Tensor@$$CBUQUInt8@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@U?$default_delete@V?$TensorMap@V?$Tensor@$$CBUQUInt8@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@std@@@std@@@2@@std@@PEAVTensor@0@PEAV?$TensorMap@V?$Tensor@UQUInt8@Eigen@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@Z)
libconcat_op.lo(concat_op.o) : error LNK2019: unresolved external symbol ""void __cdecl tensorflow::ConcatGPU<class tensorflow::tstring>(class tensorflow::OpKernelContext *,class std::vector<class std::unique_ptr<class Eigen::TensorMap<class Eigen::Tensor<class tensorflow::tstring const ,2,1,__int64>,16,struct Eigen::MakePointer>,struct std::default_delete<class Eigen::TensorMap<class Eigen::Tensor<class tensorflow::tstring const ,2,1,__int64>,16,struct Eigen::MakePointer> > >,class std::allocator<class std::unique_ptr<class Eigen::TensorMap<class Eigen::Tensor<class tensorflow::tstring const ,2,1,__int64>,16,struct Eigen::MakePointer>,struct std::default_delete<class Eigen::TensorMap<class Eigen::Tensor<class tensorflow::tstring const ,2,1,__int64>,16,struct Eigen::MakePointer> > > > > const &,class tensorflow::Tensor *,class Eigen::TensorMap<class Eigen::Tensor<class tensorflow::tstring,2,1,__int64>,16,struct Eigen::MakePointer> *)"" (??$ConcatGPU@Vtstring@tensorflow@@@tensorflow@@YAXPEAVOpKernelContext@0@AEBV?$vector@V?$unique_ptr@V?$TensorMap@V?$Tensor@$$CBVtstring@tensorflow@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@U?$default_delete@V?$TensorMap@V?$Tensor@$$CBVtstring@tensorflow@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@std@@@std@@V?$allocator@V?$unique_ptr@V?$TensorMap@V?$Tensor@$$CBVtstring@tensorflow@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@U?$default_delete@V?$TensorMap@V?$Tensor@$$CBVtstring@tensorflow@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@std@@@std@@@2@@std@@PEAVTensor@0@PEAV?$TensorMap@V?$Tensor@Vtstring@tensorflow@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@Z) referenced in function ""public: virtual void __cdecl tensorflow::ConcatBaseOp<struct Eigen::ThreadPoolDevice,class tensorflow::tstring,1>::Compute(class tensorflow::OpKernelContext *)"" (?Compute@?$ConcatBaseOp@UThreadPoolDevice@Eigen@@Vtstring@tensorflow@@$00@tensorflow@@UEAAXPEAVOpKernelContext@2@@Z)
libpack_op.lo(pack_op.o) : error LNK2001: unresolved external symbol ""void __cdecl tensorflow::ConcatGPU<class tensorflow::tstring>(class tensorflow::OpKernelContext *,class std::vector<class std::unique_ptr<class Eigen::TensorMap<class Eigen::Tensor<class tensorflow::tstring const ,2,1,__int64>,16,struct Eigen::MakePointer>,struct std::default_delete<class Eigen::TensorMap<class Eigen::Tensor<class tensorflow::tstring const ,2,1,__int64>,16,struct Eigen::MakePointer> > >,class std::allocator<class std::unique_ptr<class Eigen::TensorMap<class Eigen::Tensor<class tensorflow::tstring const ,2,1,__int64>,16,struct Eigen::MakePointer>,struct std::default_delete<class Eigen::TensorMap<class Eigen::Tensor<class tensorflow::tstring const ,2,1,__int64>,16,struct Eigen::MakePointer> > > > > const &,class tensorflow::Tensor *,class Eigen::TensorMap<class Eigen::Tensor<class tensorflow::tstring,2,1,__int64>,16,struct Eigen::MakePointer> *)"" (??$ConcatGPU@Vtstring@tensorflow@@@tensorflow@@YAXPEAVOpKernelContext@0@AEBV?$vector@V?$unique_ptr@V?$TensorMap@V?$Tensor@$$CBVtstring@tensorflow@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@U?$default_delete@V?$TensorMap@V?$Tensor@$$CBVtstring@tensorflow@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@std@@@std@@V?$allocator@V?$unique_ptr@V?$TensorMap@V?$Tensor@$$CBVtstring@tensorflow@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@U?$default_delete@V?$TensorMap@V?$Tensor@$$CBVtstring@tensorflow@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@std@@@std@@@2@@std@@PEAVTensor@0@PEAV?$TensorMap@V?$Tensor@Vtstring@tensorflow@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@Z)
libtensor_array_ops.lo(tensor_array_ops.o) : error LNK2001: unresolved external symbol ""void __cdecl tensorflow::ConcatGPU<class tensorflow::tstring>(class tensorflow::OpKernelContext *,class std::vector<class std::unique_ptr<class Eigen::TensorMap<class Eigen::Tensor<class tensorflow::tstring const ,2,1,__int64>,16,struct Eigen::MakePointer>,struct std::default_delete<class Eigen::TensorMap<class Eigen::Tensor<class tensorflow::tstring const ,2,1,__int64>,16,struct Eigen::MakePointer> > >,class std::allocator<class std::unique_ptr<class Eigen::TensorMap<class Eigen::Tensor<class tensorflow::tstring const ,2,1,__int64>,16,struct Eigen::MakePointer>,struct std::default_delete<class Eigen::TensorMap<class Eigen::Tensor<class tensorflow::tstring const ,2,1,__int64>,16,struct Eigen::MakePointer> > > > > const &,class tensorflow::Tensor *,class Eigen::TensorMap<class Eigen::Tensor<class tensorflow::tstring,2,1,__int64>,16,struct Eigen::MakePointer> *)"" (??$ConcatGPU@Vtstring@tensorflow@@@tensorflow@@YAXPEAVOpKernelContext@0@AEBV?$vector@V?$unique_ptr@V?$TensorMap@V?$Tensor@$$CBVtstring@tensorflow@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@U?$default_delete@V?$TensorMap@V?$Tensor@$$CBVtstring@tensorflow@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@std@@@std@@V?$allocator@V?$unique_ptr@V?$TensorMap@V?$Tensor@$$CBVtstring@tensorflow@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@U?$default_delete@V?$TensorMap@V?$Tensor@$$CBVtstring@tensorflow@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@std@@@std@@@2@@std@@PEAVTensor@0@PEAV?$TensorMap@V?$Tensor@Vtstring@tensorflow@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@Z)
liblist_kernels.lo(list_kernels.o) : error LNK2001: unresolved external symbol ""void __cdecl tensorflow::ConcatGPU<class tensorflow::tstring>(class tensorflow::OpKernelContext *,class std::vector<class std::unique_ptr<class Eigen::TensorMap<class Eigen::Tensor<class tensorflow::tstring const ,2,1,__int64>,16,struct Eigen::MakePointer>,struct std::default_delete<class Eigen::TensorMap<class Eigen::Tensor<class tensorflow::tstring const ,2,1,__int64>,16,struct Eigen::MakePointer> > >,class std::allocator<class std::unique_ptr<class Eigen::TensorMap<class Eigen::Tensor<class tensorflow::tstring const ,2,1,__int64>,16,struct Eigen::MakePointer>,struct std::default_delete<class Eigen::TensorMap<class Eigen::Tensor<class tensorflow::tstring const ,2,1,__int64>,16,struct Eigen::MakePointer> > > > > const &,class tensorflow::Tensor *,class Eigen::TensorMap<class Eigen::Tensor<class tensorflow::tstring,2,1,__int64>,16,struct Eigen::MakePointer> *)"" (??$ConcatGPU@Vtstring@tensorflow@@@tensorflow@@YAXPEAVOpKernelContext@0@AEBV?$vector@V?$unique_ptr@V?$TensorMap@V?$Tensor@$$CBVtstring@tensorflow@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@U?$default_delete@V?$TensorMap@V?$Tensor@$$CBVtstring@tensorflow@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@std@@@std@@V?$allocator@V?$unique_ptr@V?$TensorMap@V?$Tensor@$$CBVtstring@tensorflow@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@U?$default_delete@V?$TensorMap@V?$Tensor@$$CBVtstring@tensorflow@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@std@@@std@@@2@@std@@PEAVTensor@0@PEAV?$TensorMap@V?$Tensor@Vtstring@tensorflow@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@Z)
libconcat_op.lo(concat_op.o) : error LNK2019: unresolved external symbol ""void __cdecl tensorflow::ConcatGPU<signed char>(class tensorflow::OpKernelContext *,class std::vector<class std::unique_ptr<class Eigen::TensorMap<class Eigen::Tensor<signed char const ,2,1,__int64>,16,struct Eigen::MakePointer>,struct std::default_delete<class Eigen::TensorMap<class Eigen::Tensor<signed char const ,2,1,__int64>,16,struct Eigen::MakePointer> > >,class std::allocator<class std::unique_ptr<class Eigen::TensorMap<class Eigen::Tensor<signed char const ,2,1,__int64>,16,struct Eigen::MakePointer>,struct std::default_delete<class Eigen::TensorMap<class Eigen::Tensor<signed char const ,2,1,__int64>,16,struct Eigen::MakePointer> > > > > const &,class tensorflow::Tensor *,class Eigen::TensorMap<class Eigen::Tensor<signed char,2,1,__int64>,16,struct Eigen::MakePointer> *)"" (??$ConcatGPU@C@tensorflow@@YAXPEAVOpKernelContext@0@AEBV?$vector@V?$unique_ptr@V?$TensorMap@V?$Tensor@$$CBC$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@U?$default_delete@V?$TensorMap@V?$Tensor@$$CBC$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@std@@@std@@V?$allocator@V?$unique_ptr@V?$TensorMap@V?$Tensor@$$CBC$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@U?$default_delete@V?$TensorMap@V?$Tensor@$$CBC$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@std@@@std@@@2@@std@@PEAVTensor@0@PEAV?$TensorMap@V?$Tensor@C$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@Z) referenced in function ""public: virtual void __cdecl tensorflow::ConcatBaseOp<struct Eigen::ThreadPoolDevice,signed char,1>::Compute(class tensorflow::OpKernelContext *)"" (?Compute@?$ConcatBaseOp@UThreadPoolDevice@Eigen@@C$00@tensorflow@@UEAAXPEAVOpKernelContext@2@@Z)
libpack_op.lo(pack_op.o) : error LNK2001: unresolved external symbol ""void __cdecl tensorflow::ConcatGPU<signed char>(class tensorflow::OpKernelContext *,class std::vector<class std::unique_ptr<class Eigen::TensorMap<class Eigen::Tensor<signed char const ,2,1,__int64>,16,struct Eigen::MakePointer>,struct std::default_delete<class Eigen::TensorMap<class Eigen::Tensor<signed char const ,2,1,__int64>,16,struct Eigen::MakePointer> > >,class std::allocator<class std::unique_ptr<class Eigen::TensorMap<class Eigen::Tensor<signed char const ,2,1,__int64>,16,struct Eigen::MakePointer>,struct std::default_delete<class Eigen::TensorMap<class Eigen::Tensor<signed char const ,2,1,__int64>,16,struct Eigen::MakePointer> > > > > const &,class tensorflow::Tensor *,class Eigen::TensorMap<class Eigen::Tensor<signed char,2,1,__int64>,16,struct Eigen::MakePointer> *)"" (??$ConcatGPU@C@tensorflow@@YAXPEAVOpKernelContext@0@AEBV?$vector@V?$unique_ptr@V?$TensorMap@V?$Tensor@$$CBC$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@U?$default_delete@V?$TensorMap@V?$Tensor@$$CBC$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@std@@@std@@V?$allocator@V?$unique_ptr@V?$TensorMap@V?$Tensor@$$CBC$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@U?$default_delete@V?$TensorMap@V?$Tensor@$$CBC$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@std@@@std@@@2@@std@@PEAVTensor@0@PEAV?$TensorMap@V?$Tensor@C$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@Z)
libtensor_array_ops.lo(tensor_array_ops.o) : error LNK2001: unresolved external symbol ""void __cdecl tensorflow::ConcatGPU<signed char>(class tensorflow::OpKernelContext *,class std::vector<class std::unique_ptr<class Eigen::TensorMap<class Eigen::Tensor<signed char const ,2,1,__int64>,16,struct Eigen::MakePointer>,struct std::default_delete<class Eigen::TensorMap<class Eigen::Tensor<signed char const ,2,1,__int64>,16,struct Eigen::MakePointer> > >,class std::allocator<class std::unique_ptr<class Eigen::TensorMap<class Eigen::Tensor<signed char const ,2,1,__int64>,16,struct Eigen::MakePointer>,struct std::default_delete<class Eigen::TensorMap<class Eigen::Tensor<signed char const ,2,1,__int64>,16,struct Eigen::MakePointer> > > > > const &,class tensorflow::Tensor *,class Eigen::TensorMap<class Eigen::Tensor<signed char,2,1,__int64>,16,struct Eigen::MakePointer> *)"" (??$ConcatGPU@C@tensorflow@@YAXPEAVOpKernelContext@0@AEBV?$vector@V?$unique_ptr@V?$TensorMap@V?$Tensor@$$CBC$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@U?$default_delete@V?$TensorMap@V?$Tensor@$$CBC$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@std@@@std@@V?$allocator@V?$unique_ptr@V?$TensorMap@V?$Tensor@$$CBC$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@U?$default_delete@V?$TensorMap@V?$Tensor@$$CBC$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@std@@@std@@@2@@std@@PEAVTensor@0@PEAV?$TensorMap@V?$Tensor@C$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@Z)
liblist_kernels.lo(list_kernels.o) : error LNK2001: unresolved external symbol ""void __cdecl tensorflow::ConcatGPU<signed char>(class tensorflow::OpKernelContext *,class std::vector<class std::unique_ptr<class Eigen::TensorMap<class Eigen::Tensor<signed char const ,2,1,__int64>,16,struct Eigen::MakePointer>,struct std::default_delete<class Eigen::TensorMap<class Eigen::Tensor<signed char const ,2,1,__int64>,16,struct Eigen::MakePointer> > >,class std::allocator<class std::unique_ptr<class Eigen::TensorMap<class Eigen::Tensor<signed char const ,2,1,__int64>,16,struct Eigen::MakePointer>,struct std::default_delete<class Eigen::TensorMap<class Eigen::Tensor<signed char const ,2,1,__int64>,16,struct Eigen::MakePointer> > > > > const &,class tensorflow::Tensor *,class Eigen::TensorMap<class Eigen::Tensor<signed char,2,1,__int64>,16,struct Eigen::MakePointer> *)"" (??$ConcatGPU@C@tensorflow@@YAXPEAVOpKernelContext@0@AEBV?$vector@V?$unique_ptr@V?$TensorMap@V?$Tensor@$$CBC$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@U?$default_delete@V?$TensorMap@V?$Tensor@$$CBC$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@std@@@std@@V?$allocator@V?$unique_ptr@V?$TensorMap@V?$Tensor@$$CBC$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@U?$default_delete@V?$TensorMap@V?$Tensor@$$CBC$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@std@@@std@@@2@@std@@PEAVTensor@0@PEAV?$TensorMap@V?$Tensor@C$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@Z)
libconcat_op.lo(concat_op.o) : error LNK2019: unresolved external symbol ""void __cdecl tensorflow::ConcatGPU<unsigned short>(class tensorflow::OpKernelContext *,class std::vector<class std::unique_ptr<class Eigen::TensorMap<class Eigen::Tensor<unsigned short const ,2,1,__int64>,16,struct Eigen::MakePointer>,struct std::default_delete<class Eigen::TensorMap<class Eigen::Tensor<unsigned short const ,2,1,__int64>,16,struct Eigen::MakePointer> > >,class std::allocator<class std::unique_ptr<class Eigen::TensorMap<class Eigen::Tensor<unsigned short const ,2,1,__int64>,16,struct Eigen::MakePointer>,struct std::default_delete<class Eigen::TensorMap<class Eigen::Tensor<unsigned short const ,2,1,__int64>,16,struct Eigen::MakePointer> > > > > const &,class tensorflow::Tensor *,class Eigen::TensorMap<class Eigen::Tensor<unsigned short,2,1,__int64>,16,struct Eigen::MakePointer> *)"" (??$ConcatGPU@G@tensorflow@@YAXPEAVOpKernelContext@0@AEBV?$vector@V?$unique_ptr@V?$TensorMap@V?$Tensor@$$CBG$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@U?$default_delete@V?$TensorMap@V?$Tensor@$$CBG$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@std@@@std@@V?$allocator@V?$unique_ptr@V?$TensorMap@V?$Tensor@$$CBG$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@U?$default_delete@V?$TensorMap@V?$Tensor@$$CBG$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@std@@@std@@@2@@std@@PEAVTensor@0@PEAV?$TensorMap@V?$Tensor@G$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@Z) referenced in function ""public: virtual void __cdecl tensorflow::ConcatBaseOp<struct Eigen::ThreadPoolDevice,unsigned short,1>::Compute(class tensorflow::OpKernelContext *)"" (?Compute@?$ConcatBaseOp@UThreadPoolDevice@Eigen@@G$00@tensorflow@@UEAAXPEAVOpKernelContext@2@@Z)
libpack_op.lo(pack_op.o) : error LNK2001: unresolved external symbol ""void __cdecl tensorflow::ConcatGPU<unsigned short>(class tensorflow::OpKernelContext *,class std::vector<class std::unique_ptr<class Eigen::TensorMap<class Eigen::Tensor<unsigned short const ,2,1,__int64>,16,struct Eigen::MakePointer>,struct std::default_delete<class Eigen::TensorMap<class Eigen::Tensor<unsigned short const ,2,1,__int64>,16,struct Eigen::MakePointer> > >,class std::allocator<class std::unique_ptr<class Eigen::TensorMap<class Eigen::Tensor<unsigned short const ,2,1,__int64>,16,struct Eigen::MakePointer>,struct std::default_delete<class Eigen::TensorMap<class Eigen::Tensor<unsigned short const ,2,1,__int64>,16,struct Eigen::MakePointer> > > > > const &,class tensorflow::Tensor *,class Eigen::TensorMap<class Eigen::Tensor<unsigned short,2,1,__int64>,16,struct Eigen::MakePointer> *)"" (??$ConcatGPU@G@tensorflow@@YAXPEAVOpKernelContext@0@AEBV?$vector@V?$unique_ptr@V?$TensorMap@V?$Tensor@$$CBG$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@U?$default_delete@V?$TensorMap@V?$Tensor@$$CBG$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@std@@@std@@V?$allocator@V?$unique_ptr@V?$TensorMap@V?$Tensor@$$CBG$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@U?$default_delete@V?$TensorMap@V?$Tensor@$$CBG$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@std@@@std@@@2@@std@@PEAVTensor@0@PEAV?$TensorMap@V?$Tensor@G$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@Z)
libtensor_array_ops.lo(tensor_array_ops.o) : error LNK2001: unresolved external symbol ""void __cdecl tensorflow::ConcatGPU<unsigned short>(class tensorflow::OpKernelContext *,class std::vector<class std::unique_ptr<class Eigen::TensorMap<class Eigen::Tensor<unsigned short const ,2,1,__int64>,16,struct Eigen::MakePointer>,struct std::default_delete<class Eigen::TensorMap<class Eigen::Tensor<unsigned short const ,2,1,__int64>,16,struct Eigen::MakePointer> > >,class std::allocator<class std::unique_ptr<class Eigen::TensorMap<class Eigen::Tensor<unsigned short const ,2,1,__int64>,16,struct Eigen::MakePointer>,struct std::default_delete<class Eigen::TensorMap<class Eigen::Tensor<unsigned short const ,2,1,__int64>,16,struct Eigen::MakePointer> > > > > const &,class tensorflow::Tensor *,class Eigen::TensorMap<class Eigen::Tensor<unsigned short,2,1,__int64>,16,struct Eigen::MakePointer> *)"" (??$ConcatGPU@G@tensorflow@@YAXPEAVOpKernelContext@0@AEBV?$vector@V?$unique_ptr@V?$TensorMap@V?$Tensor@$$CBG$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@U?$default_delete@V?$TensorMap@V?$Tensor@$$CBG$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@std@@@std@@V?$allocator@V?$unique_ptr@V?$TensorMap@V?$Tensor@$$CBG$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@U?$default_delete@V?$TensorMap@V?$Tensor@$$CBG$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@std@@@std@@@2@@std@@PEAVTensor@0@PEAV?$TensorMap@V?$Tensor@G$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@Z)
liblist_kernels.lo(list_kernels.o) : error LNK2001: unresolved external symbol ""void __cdecl tensorflow::ConcatGPU<unsigned short>(class tensorflow::OpKernelContext *,class std::vector<class std::unique_ptr<class Eigen::TensorMap<class Eigen::Tensor<unsigned short const ,2,1,__int64>,16,struct Eigen::MakePointer>,struct std::default_delete<class Eigen::TensorMap<class Eigen::Tensor<unsigned short const ,2,1,__int64>,16,struct Eigen::MakePointer> > >,class std::allocator<class std::unique_ptr<class Eigen::TensorMap<class Eigen::Tensor<unsigned short const ,2,1,__int64>,16,struct Eigen::MakePointer>,struct std::default_delete<class Eigen::TensorMap<class Eigen::Tensor<unsigned short const ,2,1,__int64>,16,struct Eigen::MakePointer> > > > > const &,class tensorflow::Tensor *,class Eigen::TensorMap<class Eigen::Tensor<unsigned short,2,1,__int64>,16,struct Eigen::MakePointer> *)"" (??$ConcatGPU@G@tensorflow@@YAXPEAVOpKernelContext@0@AEBV?$vector@V?$unique_ptr@V?$TensorMap@V?$Tensor@$$CBG$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@U?$default_delete@V?$TensorMap@V?$Tensor@$$CBG$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@std@@@std@@V?$allocator@V?$unique_ptr@V?$TensorMap@V?$Tensor@$$CBG$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@U?$default_delete@V?$TensorMap@V?$Tensor@$$CBG$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@std@@@std@@@2@@std@@PEAVTensor@0@PEAV?$TensorMap@V?$Tensor@G$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@Z)
libdepth_space_ops.lo(spacetodepth_op.o) : error LNK2019: unresolved external symbol ""public: void __cdecl tensorflow::functor::SpaceToDepthOpFunctor<struct Eigen::GpuDevice,struct Eigen::QInt8,0>::operator()(struct Eigen::GpuDevice const &,class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QInt8 const ,4,1,__int64>,16,struct Eigen::MakePointer>,int,class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QInt8,4,1,__int64>,16,struct Eigen::MakePointer>)"" (??R?$SpaceToDepthOpFunctor@UGpuDevice@Eigen@@UQInt8@2@$0A@@functor@tensorflow@@QEAAXAEBUGpuDevice@Eigen@@V?$TensorMap@V?$Tensor@$$CBUQInt8@Eigen@@$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@HV?$TensorMap@V?$Tensor@UQInt8@Eigen@@$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@@Z) referenced in function ""public: virtual void __cdecl tensorflow::SpaceToDepthOp<struct Eigen::GpuDevice,struct Eigen::QInt8>::Compute(class tensorflow::OpKernelContext *)"" (?Compute@?$SpaceToDepthOp@UGpuDevice@Eigen@@UQInt8@2@@tensorflow@@UEAAXPEAVOpKernelContext@2@@Z)
libdepth_space_ops.lo(spacetodepth_op.o) : error LNK2019: unresolved external symbol ""public: void __cdecl tensorflow::functor::SpaceToDepthOpFunctor<struct Eigen::GpuDevice,class tensorflow::Variant,1>::operator()(struct Eigen::GpuDevice const &,class Eigen::TensorMap<class Eigen::Tensor<class tensorflow::Variant const ,4,1,__int64>,16,struct Eigen::MakePointer>,int,class Eigen::TensorMap<class Eigen::Tensor<class tensorflow::Variant,4,1,__int64>,16,struct Eigen::MakePointer>)"" (??R?$SpaceToDepthOpFunctor@UGpuDevice@Eigen@@VVariant@tensorflow@@$00@functor@tensorflow@@QEAAXAEBUGpuDevice@Eigen@@V?$TensorMap@V?$Tensor@$$CBVVariant@tensorflow@@$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@HV?$TensorMap@V?$Tensor@VVariant@tensorflow@@$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@@Z) referenced in function ""public: virtual void __cdecl tensorflow::SpaceToDepthOp<struct Eigen::ThreadPoolDevice,class tensorflow::Variant>::Compute(class tensorflow::OpKernelContext *)"" (?Compute@?$SpaceToDepthOp@UThreadPoolDevice@Eigen@@VVariant@tensorflow@@@tensorflow@@UEAAXPEAVOpKernelContext@2@@Z)
libdepth_space_ops.lo(spacetodepth_op.o) : error LNK2019: unresolved external symbol ""public: void __cdecl tensorflow::functor::SpaceToDepthOpFunctor<struct Eigen::GpuDevice,class tensorflow::Variant,0>::operator()(struct Eigen::GpuDevice const &,class Eigen::TensorMap<class Eigen::Tensor<class tensorflow::Variant const ,4,1,__int64>,16,struct Eigen::MakePointer>,int,class Eigen::TensorMap<class Eigen::Tensor<class tensorflow::Variant,4,1,__int64>,16,struct Eigen::MakePointer>)"" (??R?$SpaceToDepthOpFunctor@UGpuDevice@Eigen@@VVariant@tensorflow@@$0A@@functor@tensorflow@@QEAAXAEBUGpuDevice@Eigen@@V?$TensorMap@V?$Tensor@$$CBVVariant@tensorflow@@$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@HV?$TensorMap@V?$Tensor@VVariant@tensorflow@@$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@@Z) referenced in function ""public: virtual void __cdecl tensorflow::SpaceToDepthOp<struct Eigen::ThreadPoolDevice,class tensorflow::Variant>::Compute(class tensorflow::OpKernelContext *)"" (?Compute@?$SpaceToDepthOp@UThreadPoolDevice@Eigen@@VVariant@tensorflow@@@tensorflow@@UEAAXPEAVOpKernelContext@2@@Z)
libdepth_space_ops.lo(spacetodepth_op.o) : error LNK2019: unresolved external symbol ""public: void __cdecl tensorflow::functor::SpaceToDepthOpFunctor<struct Eigen::GpuDevice,class tensorflow::ResourceHandle,1>::operator()(struct Eigen::GpuDevice const &,class Eigen::TensorMap<class Eigen::Tensor<class tensorflow::ResourceHandle const ,4,1,__int64>,16,struct Eigen::MakePointer>,int,class Eigen::TensorMap<class Eigen::Tensor<class tensorflow::ResourceHandle,4,1,__int64>,16,struct Eigen::MakePointer>)"" (??R?$SpaceToDepthOpFunctor@UGpuDevice@Eigen@@VResourceHandle@tensorflow@@$00@functor@tensorflow@@QEAAXAEBUGpuDevice@Eigen@@V?$TensorMap@V?$Tensor@$$CBVResourceHandle@tensorflow@@$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@HV?$TensorMap@V?$Tensor@VResourceHandle@tensorflow@@$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@@Z) referenced in function ""public: virtual void __cdecl tensorflow::SpaceToDepthOp<struct Eigen::ThreadPoolDevice,class tensorflow::ResourceHandle>::Compute(class tensorflow::OpKernelContext *)"" (?Compute@?$SpaceToDepthOp@UThreadPoolDevice@Eigen@@VResourceHandle@tensorflow@@@tensorflow@@UEAAXPEAVOpKernelContext@2@@Z)
libdepth_space_ops.lo(spacetodepth_op.o) : error LNK2019: unresolved external symbol ""public: void __cdecl tensorflow::functor::SpaceToDepthOpFunctor<struct Eigen::GpuDevice,class tensorflow::ResourceHandle,0>::operator()(struct Eigen::GpuDevice const &,class Eigen::TensorMap<class Eigen::Tensor<class tensorflow::ResourceHandle const ,4,1,__int64>,16,struct Eigen::MakePointer>,int,class Eigen::TensorMap<class Eigen::Tensor<class tensorflow::ResourceHandle,4,1,__int64>,16,struct Eigen::MakePointer>)"" (??R?$SpaceToDepthOpFunctor@UGpuDevice@Eigen@@VResourceHandle@tensorflow@@$0A@@functor@tensorflow@@QEAAXAEBUGpuDevice@Eigen@@V?$TensorMap@V?$Tensor@$$CBVResourceHandle@tensorflow@@$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@HV?$TensorMap@V?$Tensor@VResourceHandle@tensorflow@@$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@@Z) referenced in function ""public: virtual void __cdecl tensorflow::SpaceToDepthOp<struct Eigen::ThreadPoolDevice,class tensorflow::ResourceHandle>::Compute(class tensorflow::OpKernelContext *)"" (?Compute@?$SpaceToDepthOp@UThreadPoolDevice@Eigen@@VResourceHandle@tensorflow@@@tensorflow@@UEAAXPEAVOpKernelContext@2@@Z)
libdepth_space_ops.lo(spacetodepth_op.o) : error LNK2019: unresolved external symbol ""public: void __cdecl tensorflow::functor::SpaceToDepthOpFunctor<struct Eigen::GpuDevice,class tensorflow::tstring,1>::operator()(struct Eigen::GpuDevice const &,class Eigen::TensorMap<class Eigen::Tensor<class tensorflow::tstring const ,4,1,__int64>,16,struct Eigen::MakePointer>,int,class Eigen::TensorMap<class Eigen::Tensor<class tensorflow::tstring,4,1,__int64>,16,struct Eigen::MakePointer>)"" (??R?$SpaceToDepthOpFunctor@UGpuDevice@Eigen@@Vtstring@tensorflow@@$00@functor@tensorflow@@QEAAXAEBUGpuDevice@Eigen@@V?$TensorMap@V?$Tensor@$$CBVtstring@tensorflow@@$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@HV?$TensorMap@V?$Tensor@Vtstring@tensorflow@@$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@@Z) referenced in function ""public: virtual void __cdecl tensorflow::SpaceToDepthOp<struct Eigen::ThreadPoolDevice,class tensorflow::tstring>::Compute(class tensorflow::OpKernelContext *)"" (?Compute@?$SpaceToDepthOp@UThreadPoolDevice@Eigen@@Vtstring@tensorflow@@@tensorflow@@UEAAXPEAVOpKernelContext@2@@Z)
libdepth_space_ops.lo(spacetodepth_op.o) : error LNK2019: unresolved external symbol ""public: void __cdecl tensorflow::functor::SpaceToDepthOpFunctor<struct Eigen::GpuDevice,class tensorflow::tstring,0>::operator()(struct Eigen::GpuDevice const &,class Eigen::TensorMap<class Eigen::Tensor<class tensorflow::tstring const ,4,1,__int64>,16,struct Eigen::MakePointer>,int,class Eigen::TensorMap<class Eigen::Tensor<class tensorflow::tstring,4,1,__int64>,16,struct Eigen::MakePointer>)"" (??R?$SpaceToDepthOpFunctor@UGpuDevice@Eigen@@Vtstring@tensorflow@@$0A@@functor@tensorflow@@QEAAXAEBUGpuDevice@Eigen@@V?$TensorMap@V?$Tensor@$$CBVtstring@tensorflow@@$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@HV?$TensorMap@V?$Tensor@Vtstring@tensorflow@@$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@@Z) referenced in function ""public: virtual void __cdecl tensorflow::SpaceToDepthOp<struct Eigen::ThreadPoolDevice,class tensorflow::tstring>::Compute(class tensorflow::OpKernelContext *)"" (?Compute@?$SpaceToDepthOp@UThreadPoolDevice@Eigen@@Vtstring@tensorflow@@@tensorflow@@UEAAXPEAVOpKernelContext@2@@Z)
libdepth_space_ops.lo(spacetodepth_op.o) : error LNK2019: unresolved external symbol ""public: void __cdecl tensorflow::functor::SpaceToDepthOpFunctor<struct Eigen::GpuDevice,bool,1>::operator()(struct Eigen::GpuDevice const &,class Eigen::TensorMap<class Eigen::Tensor<bool const ,4,1,__int64>,16,struct Eigen::MakePointer>,int,class Eigen::TensorMap<class Eigen::Tensor<bool,4,1,__int64>,16,struct Eigen::MakePointer>)"" (??R?$SpaceToDepthOpFunctor@UGpuDevice@Eigen@@_N$00@functor@tensorflow@@QEAAXAEBUGpuDevice@Eigen@@V?$TensorMap@V?$Tensor@$$CB_N$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@HV?$TensorMap@V?$Tensor@_N$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@@Z) referenced in function ""public: virtual void __cdecl tensorflow::SpaceToDepthOp<struct Eigen::ThreadPoolDevice,bool>::Compute(class tensorflow::OpKernelContext *)"" (?Compute@?$SpaceToDepthOp@UThreadPoolDevice@Eigen@@_N@tensorflow@@UEAAXPEAVOpKernelContext@2@@Z)
libdepth_space_ops.lo(spacetodepth_op.o) : error LNK2019: unresolved external symbol ""public: void __cdecl tensorflow::functor::SpaceToDepthOpFunctor<struct Eigen::GpuDevice,bool,0>::operator()(struct Eigen::GpuDevice const &,class Eigen::TensorMap<class Eigen::Tensor<bool const ,4,1,__int64>,16,struct Eigen::MakePointer>,int,class Eigen::TensorMap<class Eigen::Tensor<bool,4,1,__int64>,16,struct Eigen::MakePointer>)"" (??R?$SpaceToDepthOpFunctor@UGpuDevice@Eigen@@_N$0A@@functor@tensorflow@@QEAAXAEBUGpuDevice@Eigen@@V?$TensorMap@V?$Tensor@$$CB_N$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@HV?$TensorMap@V?$Tensor@_N$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@@Z) referenced in function ""public: virtual void __cdecl tensorflow::SpaceToDepthOp<struct Eigen::ThreadPoolDevice,bool>::Compute(class tensorflow::OpKernelContext *)"" (?Compute@?$SpaceToDepthOp@UThreadPoolDevice@Eigen@@_N@tensorflow@@UEAAXPEAVOpKernelContext@2@@Z)
libdepth_space_ops.lo(spacetodepth_op.o) : error LNK2019: unresolved external symbol ""public: void __cdecl tensorflow::functor::SpaceToDepthOpFunctor<struct Eigen::GpuDevice,class std::complex<double>,1>::operator()(struct Eigen::GpuDevice const &,class Eigen::TensorMap<class Eigen::Tensor<class std::complex<double> const ,4,1,__int64>,16,struct Eigen::MakePointer>,int,class Eigen::TensorMap<class Eigen::Tensor<class std::complex<double>,4,1,__int64>,16,struct Eigen::MakePointer>)"" (??R?$SpaceToDepthOpFunctor@UGpuDevice@Eigen@@V?$complex@N@std@@$00@functor@tensorflow@@QEAAXAEBUGpuDevice@Eigen@@V?$TensorMap@V?$Tensor@$$CBV?$complex@N@std@@$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@HV?$TensorMap@V?$Tensor@V?$complex@N@std@@$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@@Z) referenced in function ""public: virtual void __cdecl tensorflow::SpaceToDepthOp<struct Eigen::ThreadPoolDevice,class std::complex<double> >::Compute(class tensorflow::OpKernelContext *)"" (?Compute@?$SpaceToDepthOp@UThreadPoolDevice@Eigen@@V?$complex@N@std@@@tensorflow@@UEAAXPEAVOpKernelContext@2@@Z)
libdepth_space_ops.lo(spacetodepth_op.o) : error LNK2019: unresolved external symbol ""public: void __cdecl tensorflow::functor::SpaceToDepthOpFunctor<struct Eigen::GpuDevice,class std::complex<double>,0>::operator()(struct Eigen::GpuDevice const &,class Eigen::TensorMap<class Eigen::Tensor<class std::complex<double> const ,4,1,__int64>,16,struct Eigen::MakePointer>,int,class Eigen::TensorMap<class Eigen::Tensor<class std::complex<double>,4,1,__int64>,16,struct Eigen::MakePointer>)"" (??R?$SpaceToDepthOpFunctor@UGpuDevice@Eigen@@V?$complex@N@std@@$0A@@functor@tensorflow@@QEAAXAEBUGpuDevice@Eigen@@V?$TensorMap@V?$Tensor@$$CBV?$complex@N@std@@$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@HV?$TensorMap@V?$Tensor@V?$complex@N@std@@$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@@Z) referenced in function ""public: virtual void __cdecl tensorflow::SpaceToDepthOp<struct Eigen::ThreadPoolDevice,class std::complex<double> >::Compute(class tensorflow::OpKernelContext *)"" (?Compute@?$SpaceToDepthOp@UThreadPoolDevice@Eigen@@V?$complex@N@std@@@tensorflow@@UEAAXPEAVOpKernelContext@2@@Z)
libdepth_space_ops.lo(spacetodepth_op.o) : error LNK2019: unresolved external symbol ""public: void __cdecl tensorflow::functor::SpaceToDepthOpFunctor<struct Eigen::GpuDevice,class std::complex<float>,1>::operator()(struct Eigen::GpuDevice const &,class Eigen::TensorMap<class Eigen::Tensor<class std::complex<float> const ,4,1,__int64>,16,struct Eigen::MakePointer>,int,class Eigen::TensorMap<class Eigen::Tensor<class std::complex<float>,4,1,__int64>,16,struct Eigen::MakePointer>)"" (??R?$SpaceToDepthOpFunctor@UGpuDevice@Eigen@@V?$complex@M@std@@$00@functor@tensorflow@@QEAAXAEBUGpuDevice@Eigen@@V?$TensorMap@V?$Tensor@$$CBV?$complex@M@std@@$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@HV?$TensorMap@V?$Tensor@V?$complex@M@std@@$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@@Z) referenced in function ""public: virtual void __cdecl tensorflow::SpaceToDepthOp<struct Eigen::ThreadPoolDevice,class std::complex<float> >::Compute(class tensorflow::OpKernelContext *)"" (?Compute@?$SpaceToDepthOp@UThreadPoolDevice@Eigen@@V?$complex@M@std@@@tensorflow@@UEAAXPEAVOpKernelContext@2@@Z)
libdepth_space_ops.lo(spacetodepth_op.o) : error LNK2019: unresolved external symbol ""public: void __cdecl tensorflow::functor::SpaceToDepthOpFunctor<struct Eigen::GpuDevice,class std::complex<float>,0>::operator()(struct Eigen::GpuDevice const &,class Eigen::TensorMap<class Eigen::Tensor<class std::complex<float> const ,4,1,__int64>,16,struct Eigen::MakePointer>,int,class Eigen::TensorMap<class Eigen::Tensor<class std::complex<float>,4,1,__int64>,16,struct Eigen::MakePointer>)"" (??R?$SpaceToDepthOpFunctor@UGpuDevice@Eigen@@V?$complex@M@std@@$0A@@functor@tensorflow@@QEAAXAEBUGpuDevice@Eigen@@V?$TensorMap@V?$Tensor@$$CBV?$complex@M@std@@$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@HV?$TensorMap@V?$Tensor@V?$complex@M@std@@$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@@Z) referenced in function ""public: virtual void __cdecl tensorflow::SpaceToDepthOp<struct Eigen::ThreadPoolDevice,class std::complex<float> >::Compute(class tensorflow::OpKernelContext *)"" (?Compute@?$SpaceToDepthOp@UThreadPoolDevice@Eigen@@V?$complex@M@std@@@tensorflow@@UEAAXPEAVOpKernelContext@2@@Z)
libdepth_space_ops.lo(spacetodepth_op.o) : error LNK2019: unresolved external symbol ""public: void __cdecl tensorflow::functor::SpaceToDepthOpFunctor<struct Eigen::GpuDevice,double,1>::operator()(struct Eigen::GpuDevice const &,class Eigen::TensorMap<class Eigen::Tensor<double const ,4,1,__int64>,16,struct Eigen::MakePointer>,int,class Eigen::TensorMap<class Eigen::Tensor<double,4,1,__int64>,16,struct Eigen::MakePointer>)"" (??R?$SpaceToDepthOpFunctor@UGpuDevice@Eigen@@N$00@functor@tensorflow@@QEAAXAEBUGpuDevice@Eigen@@V?$TensorMap@V?$Tensor@$$CBN$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@HV?$TensorMap@V?$Tensor@N$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@@Z) referenced in function ""public: virtual void __cdecl tensorflow::SpaceToDepthOp<struct Eigen::ThreadPoolDevice,double>::Compute(class tensorflow::OpKernelContext *)"" (?Compute@?$SpaceToDepthOp@UThreadPoolDevice@Eigen@@N@tensorflow@@UEAAXPEAVOpKernelContext@2@@Z)
libdepth_space_ops.lo(spacetodepth_op.o) : error LNK2019: unresolved external symbol ""public: void __cdecl tensorflow::functor::SpaceToDepthOpFunctor<struct Eigen::GpuDevice,double,0>::operator()(struct Eigen::GpuDevice const &,class Eigen::TensorMap<class Eigen::Tensor<double const ,4,1,__int64>,16,struct Eigen::MakePointer>,int,class Eigen::TensorMap<class Eigen::Tensor<double,4,1,__int64>,16,struct Eigen::MakePointer>)"" (??R?$SpaceToDepthOpFunctor@UGpuDevice@Eigen@@N$0A@@functor@tensorflow@@QEAAXAEBUGpuDevice@Eigen@@V?$TensorMap@V?$Tensor@$$CBN$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@HV?$TensorMap@V?$Tensor@N$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@@Z) referenced in function ""public: virtual void __cdecl tensorflow::SpaceToDepthOp<struct Eigen::ThreadPoolDevice,double>::Compute(class tensorflow::OpKernelContext *)"" (?Compute@?$SpaceToDepthOp@UThreadPoolDevice@Eigen@@N@tensorflow@@UEAAXPEAVOpKernelContext@2@@Z)
libdepth_space_ops.lo(spacetodepth_op.o) : error LNK2019: unresolved external symbol ""public: void __cdecl tensorflow::functor::SpaceToDepthOpFunctor<struct Eigen::GpuDevice,struct tensorflow::bfloat16,1>::operator()(struct Eigen::GpuDevice const &,class Eigen::TensorMap<class Eigen::Tensor<struct tensorflow::bfloat16 const ,4,1,__int64>,16,struct Eigen::MakePointer>,int,class Eigen::TensorMap<class Eigen::Tensor<struct tensorflow::bfloat16,4,1,__int64>,16,struct Eigen::MakePointer>)"" (??R?$SpaceToDepthOpFunctor@UGpuDevice@Eigen@@Ubfloat16@tensorflow@@$00@functor@tensorflow@@QEAAXAEBUGpuDevice@Eigen@@V?$TensorMap@V?$Tensor@$$CBUbfloat16@tensorflow@@$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@HV?$TensorMap@V?$Tensor@Ubfloat16@tensorflow@@$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@@Z) referenced in function ""public: virtual void __cdecl tensorflow::SpaceToDepthOp<struct Eigen::ThreadPoolDevice,struct tensorflow::bfloat16>::Compute(class tensorflow::OpKernelContext *)"" (?Compute@?$SpaceToDepthOp@UThreadPoolDevice@Eigen@@Ubfloat16@tensorflow@@@tensorflow@@UEAAXPEAVOpKernelContext@2@@Z)
libdepth_space_ops.lo(spacetodepth_op.o) : error LNK2019: unresolved external symbol ""public: void __cdecl tensorflow::functor::SpaceToDepthOpFunctor<struct Eigen::GpuDevice,struct tensorflow::bfloat16,0>::operator()(struct Eigen::GpuDevice const &,class Eigen::TensorMap<class Eigen::Tensor<struct tensorflow::bfloat16 const ,4,1,__int64>,16,struct Eigen::MakePointer>,int,class Eigen::TensorMap<class Eigen::Tensor<struct tensorflow::bfloat16,4,1,__int64>,16,struct Eigen::MakePointer>)"" (??R?$SpaceToDepthOpFunctor@UGpuDevice@Eigen@@Ubfloat16@tensorflow@@$0A@@functor@tensorflow@@QEAAXAEBUGpuDevice@Eigen@@V?$TensorMap@V?$Tensor@$$CBUbfloat16@tensorflow@@$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@HV?$TensorMap@V?$Tensor@Ubfloat16@tensorflow@@$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@@Z) referenced in function ""public: virtual void __cdecl tensorflow::SpaceToDepthOp<struct Eigen::ThreadPoolDevice,struct tensorflow::bfloat16>::Compute(class tensorflow::OpKernelContext *)"" (?Compute@?$SpaceToDepthOp@UThreadPoolDevice@Eigen@@Ubfloat16@tensorflow@@@tensorflow@@UEAAXPEAVOpKernelContext@2@@Z)
libdepth_space_ops.lo(spacetodepth_op.o) : error LNK2019: unresolved external symbol ""public: void __cdecl tensorflow::functor::SpaceToDepthOpFunctor<struct Eigen::GpuDevice,signed char,1>::operator()(struct Eigen::GpuDevice const &,class Eigen::TensorMap<class Eigen::Tensor<signed char const ,4,1,__int64>,16,struct Eigen::MakePointer>,int,class Eigen::TensorMap<class Eigen::Tensor<signed char,4,1,__int64>,16,struct Eigen::MakePointer>)"" (??R?$SpaceToDepthOpFunctor@UGpuDevice@Eigen@@C$00@functor@tensorflow@@QEAAXAEBUGpuDevice@Eigen@@V?$TensorMap@V?$Tensor@$$CBC$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@HV?$TensorMap@V?$Tensor@C$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@@Z) referenced in function ""public: virtual void __cdecl tensorflow::SpaceToDepthOp<struct Eigen::ThreadPoolDevice,signed char>::Compute(class tensorflow::OpKernelContext *)"" (?Compute@?$SpaceToDepthOp@UThreadPoolDevice@Eigen@@C@tensorflow@@UEAAXPEAVOpKernelContext@2@@Z)
libdepth_space_ops.lo(spacetodepth_op.o) : error LNK2019: unresolved external symbol ""public: void __cdecl tensorflow::functor::SpaceToDepthOpFunctor<struct Eigen::GpuDevice,signed char,0>::operator()(struct Eigen::GpuDevice const &,class Eigen::TensorMap<class Eigen::Tensor<signed char const ,4,1,__int64>,16,struct Eigen::MakePointer>,int,class Eigen::TensorMap<class Eigen::Tensor<signed char,4,1,__int64>,16,struct Eigen::MakePointer>)"" (??R?$SpaceToDepthOpFunctor@UGpuDevice@Eigen@@C$0A@@functor@tensorflow@@QEAAXAEBUGpuDevice@Eigen@@V?$TensorMap@V?$Tensor@$$CBC$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@HV?$TensorMap@V?$Tensor@C$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@@Z) referenced in function ""public: virtual void __cdecl tensorflow::SpaceToDepthOp<struct Eigen::ThreadPoolDevice,signed char>::Compute(class tensorflow::OpKernelContext *)"" (?Compute@?$SpaceToDepthOp@UThreadPoolDevice@Eigen@@C@tensorflow@@UEAAXPEAVOpKernelContext@2@@Z)
libdepth_space_ops.lo(spacetodepth_op.o) : error LNK2019: unresolved external symbol ""public: void __cdecl tensorflow::functor::SpaceToDepthOpFunctor<struct Eigen::GpuDevice,short,1>::operator()(struct Eigen::GpuDevice const &,class Eigen::TensorMap<class Eigen::Tensor<short const ,4,1,__int64>,16,struct Eigen::MakePointer>,int,class Eigen::TensorMap<class Eigen::Tensor<short,4,1,__int64>,16,struct Eigen::MakePointer>)"" (??R?$SpaceToDepthOpFunctor@UGpuDevice@Eigen@@F$00@functor@tensorflow@@QEAAXAEBUGpuDevice@Eigen@@V?$TensorMap@V?$Tensor@$$CBF$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@HV?$TensorMap@V?$Tensor@F$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@@Z) referenced in function ""public: virtual void __cdecl tensorflow::SpaceToDepthOp<struct Eigen::ThreadPoolDevice,short>::Compute(class tensorflow::OpKernelContext *)"" (?Compute@?$SpaceToDepthOp@UThreadPoolDevice@Eigen@@F@tensorflow@@UEAAXPEAVOpKernelContext@2@@Z)
libdepth_space_ops.lo(spacetodepth_op.o) : error LNK2019: unresolved external symbol ""public: void __cdecl tensorflow::functor::SpaceToDepthOpFunctor<struct Eigen::GpuDevice,short,0>::operator()(struct Eigen::GpuDevice const &,class Eigen::TensorMap<class Eigen::Tensor<short const ,4,1,__int64>,16,struct Eigen::MakePointer>,int,class Eigen::TensorMap<class Eigen::Tensor<short,4,1,__int64>,16,struct Eigen::MakePointer>)"" (??R?$SpaceToDepthOpFunctor@UGpuDevice@Eigen@@F$0A@@functor@tensorflow@@QEAAXAEBUGpuDevice@Eigen@@V?$TensorMap@V?$Tensor@$$CBF$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@HV?$TensorMap@V?$Tensor@F$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@@Z) referenced in function ""public: virtual void __cdecl tensorflow::SpaceToDepthOp<struct Eigen::ThreadPoolDevice,short>::Compute(class tensorflow::OpKernelContext *)"" (?Compute@?$SpaceToDepthOp@UThreadPoolDevice@Eigen@@F@tensorflow@@UEAAXPEAVOpKernelContext@2@@Z)
libdepth_space_ops.lo(spacetodepth_op.o) : error LNK2019: unresolved external symbol ""public: void __cdecl tensorflow::functor::SpaceToDepthOpFunctor<struct Eigen::GpuDevice,unsigned short,1>::operator()(struct Eigen::GpuDevice const &,class Eigen::TensorMap<class Eigen::Tensor<unsigned short const ,4,1,__int64>,16,struct Eigen::MakePointer>,int,class Eigen::TensorMap<class Eigen::Tensor<unsigned short,4,1,__int64>,16,struct Eigen::MakePointer>)"" (??R?$SpaceToDepthOpFunctor@UGpuDevice@Eigen@@G$00@functor@tensorflow@@QEAAXAEBUGpuDevice@Eigen@@V?$TensorMap@V?$Tensor@$$CBG$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@HV?$TensorMap@V?$Tensor@G$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@@Z) referenced in function ""public: virtual void __cdecl tensorflow::SpaceToDepthOp<struct Eigen::ThreadPoolDevice,unsigned short>::Compute(class tensorflow::OpKernelContext *)"" (?Compute@?$SpaceToDepthOp@UThreadPoolDevice@Eigen@@G@tensorflow@@UEAAXPEAVOpKernelContext@2@@Z)
libdepth_space_ops.lo(spacetodepth_op.o) : error LNK2019: unresolved external symbol ""public: void __cdecl tensorflow::functor::SpaceToDepthOpFunctor<struct Eigen::GpuDevice,unsigned short,0>::operator()(struct Eigen::GpuDevice const &,class Eigen::TensorMap<class Eigen::Tensor<unsigned short const ,4,1,__int64>,16,struct Eigen::MakePointer>,int,class Eigen::TensorMap<class Eigen::Tensor<unsigned short,4,1,__int64>,16,struct Eigen::MakePointer>)"" (??R?$SpaceToDepthOpFunctor@UGpuDevice@Eigen@@G$0A@@functor@tensorflow@@QEAAXAEBUGpuDevice@Eigen@@V?$TensorMap@V?$Tensor@$$CBG$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@HV?$TensorMap@V?$Tensor@G$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@@Z) referenced in function ""public: virtual void __cdecl tensorflow::SpaceToDepthOp<struct Eigen::ThreadPoolDevice,unsigned short>::Compute(class tensorflow::OpKernelContext *)"" (?Compute@?$SpaceToDepthOp@UThreadPoolDevice@Eigen@@G@tensorflow@@UEAAXPEAVOpKernelContext@2@@Z)
libdepth_space_ops.lo(spacetodepth_op.o) : error LNK2019: unresolved external symbol ""public: void __cdecl tensorflow::functor::SpaceToDepthOpFunctor<struct Eigen::GpuDevice,int,0>::operator()(struct Eigen::GpuDevice const &,class Eigen::TensorMap<class Eigen::Tensor<int const ,4,1,__int64>,16,struct Eigen::MakePointer>,int,class Eigen::TensorMap<class Eigen::Tensor<int,4,1,__int64>,16,struct Eigen::MakePointer>)"" (??R?$SpaceToDepthOpFunctor@UGpuDevice@Eigen@@H$0A@@functor@tensorflow@@QEAAXAEBUGpuDevice@Eigen@@V?$TensorMap@V?$Tensor@$$CBH$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@HV?$TensorMap@V?$Tensor@H$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@@Z) referenced in function ""public: virtual void __cdecl tensorflow::SpaceToDepthOp<struct Eigen::ThreadPoolDevice,int>::Compute(class tensorflow::OpKernelContext *)"" (?Compute@?$SpaceToDepthOp@UThreadPoolDevice@Eigen@@H@tensorflow@@UEAAXPEAVOpKernelContext@2@@Z)
libdepth_space_ops.lo(spacetodepth_op.o) : error LNK2019: unresolved external symbol ""public: void __cdecl tensorflow::functor::SpaceToDepthOpFunctor<struct Eigen::GpuDevice,__int64,1>::operator()(struct Eigen::GpuDevice const &,class Eigen::TensorMap<class Eigen::Tensor<__int64 const ,4,1,__int64>,16,struct Eigen::MakePointer>,int,class Eigen::TensorMap<class Eigen::Tensor<__int64,4,1,__int64>,16,struct Eigen::MakePointer>)"" (??R?$SpaceToDepthOpFunctor@UGpuDevice@Eigen@@_J$00@functor@tensorflow@@QEAAXAEBUGpuDevice@Eigen@@V?$TensorMap@V?$Tensor@$$CB_J$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@HV?$TensorMap@V?$Tensor@_J$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@@Z) referenced in function ""public: virtual void __cdecl tensorflow::SpaceToDepthOp<struct Eigen::ThreadPoolDevice,__int64>::Compute(class tensorflow::OpKernelContext *)"" (?Compute@?$SpaceToDepthOp@UThreadPoolDevice@Eigen@@_J@tensorflow@@UEAAXPEAVOpKernelContext@2@@Z)
libdepth_space_ops.lo(spacetodepth_op.o) : error LNK2019: unresolved external symbol ""public: void __cdecl tensorflow::functor::SpaceToDepthOpFunctor<struct Eigen::GpuDevice,__int64,0>::operator()(struct Eigen::GpuDevice const &,class Eigen::TensorMap<class Eigen::Tensor<__int64 const ,4,1,__int64>,16,struct Eigen::MakePointer>,int,class Eigen::TensorMap<class Eigen::Tensor<__int64,4,1,__int64>,16,struct Eigen::MakePointer>)"" (??R?$SpaceToDepthOpFunctor@UGpuDevice@Eigen@@_J$0A@@functor@tensorflow@@QEAAXAEBUGpuDevice@Eigen@@V?$TensorMap@V?$Tensor@$$CB_J$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@HV?$TensorMap@V?$Tensor@_J$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@@Z) referenced in function ""public: virtual void __cdecl tensorflow::SpaceToDepthOp<struct Eigen::ThreadPoolDevice,__int64>::Compute(class tensorflow::OpKernelContext *)"" (?Compute@?$SpaceToDepthOp@UThreadPoolDevice@Eigen@@_J@tensorflow@@UEAAXPEAVOpKernelContext@2@@Z)
libdepth_space_ops.lo(depthtospace_op.o) : error LNK2019: unresolved external symbol ""public: void __cdecl tensorflow::functor::DepthToSpaceOpFunctor<struct Eigen::GpuDevice,struct Eigen::QInt8,1>::operator()(struct Eigen::GpuDevice const &,class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QInt8 const ,5,1,__int64>,16,struct Eigen::MakePointer>,int,class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QInt8,5,1,__int64>,16,struct Eigen::MakePointer>)"" (??R?$DepthToSpaceOpFunctor@UGpuDevice@Eigen@@UQInt8@2@$00@functor@tensorflow@@QEAAXAEBUGpuDevice@Eigen@@V?$TensorMap@V?$Tensor@$$CBUQInt8@Eigen@@$04$00_J@Eigen@@$0BA@UMakePointer@2@@4@HV?$TensorMap@V?$Tensor@UQInt8@Eigen@@$04$00_J@Eigen@@$0BA@UMakePointer@2@@4@@Z) referenced in function ""public: virtual void __cdecl tensorflow::DepthToSpaceOp<struct Eigen::GpuDevice,struct Eigen::QInt8>::Compute(class tensorflow::OpKernelContext *)"" (?Compute@?$DepthToSpaceOp@UGpuDevice@Eigen@@UQInt8@2@@tensorflow@@UEAAXPEAVOpKernelContext@2@@Z)
libdepth_space_ops.lo(depthtospace_op.o) : error LNK2019: unresolved external symbol ""public: void __cdecl tensorflow::functor::DepthToSpaceOpFunctor<struct Eigen::GpuDevice,struct Eigen::QInt8,0>::operator()(struct Eigen::GpuDevice const &,class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QInt8 const ,5,1,__int64>,16,struct Eigen::MakePointer>,int,class Eigen::TensorMap<class Eigen::Tensor<struct Eigen::QInt8,5,1,__int64>,16,struct Eigen::MakePointer>)"" (??R?$DepthToSpaceOpFunctor@UGpuDevice@Eigen@@UQInt8@2@$0A@@functor@tensorflow@@QEAAXAEBUGpuDevice@Eigen@@V?$TensorMap@V?$Tensor@$$CBUQInt8@Eigen@@$04$00_J@Eigen@@$0BA@UMakePointer@2@@4@HV?$TensorMap@V?$Tensor@UQInt8@Eigen@@$04$00_J@Eigen@@$0BA@UMakePointer@2@@4@@Z) referenced in function ""public: virtual void __cdecl tensorflow::DepthToSpaceOp<struct Eigen::GpuDevice,struct Eigen::QInt8>::Compute(class tensorflow::OpKernelContext *)"" (?Compute@?$DepthToSpaceOp@UGpuDevice@Eigen@@UQInt8@2@@tensorflow@@UEAAXPEAVOpKernelContext@2@@Z)
libdepth_space_ops.lo(depthtospace_op.o) : error LNK2019: unresolved external symbol ""public: void __cdecl tensorflow::functor::DepthToSpaceOpFunctor<struct Eigen::GpuDevice,class tensorflow::Variant,1>::operator()(struct Eigen::GpuDevice const &,class Eigen::TensorMap<class Eigen::Tensor<class tensorflow::Variant const ,4,1,__int64>,16,struct Eigen::MakePointer>,int,class Eigen::TensorMap<class Eigen::Tensor<class tensorflow::Variant,4,1,__int64>,16,struct Eigen::MakePointer>)"" (??R?$DepthToSpaceOpFunctor@UGpuDevice@Eigen@@VVariant@tensorflow@@$00@functor@tensorflow@@QEAAXAEBUGpuDevice@Eigen@@V?$TensorMap@V?$Tensor@$$CBVVariant@tensorflow@@$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@HV?$TensorMap@V?$Tensor@VVariant@tensorflow@@$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@@Z) referenced in function ""public: virtual void __cdecl tensorflow::DepthToSpaceOp<struct Eigen::ThreadPoolDevice,class tensorflow::Variant>::Compute(class tensorflow::OpKernelContext *)"" (?Compute@?$DepthToSpaceOp@UThreadPoolDevice@Eigen@@VVariant@tensorflow@@@tensorflow@@UEAAXPEAVOpKernelContext@2@@Z)
libdepth_space_ops.lo(depthtospace_op.o) : error LNK2019: unresolved external symbol ""public: void __cdecl tensorflow::functor::DepthToSpaceOpFunctor<struct Eigen::GpuDevice,class tensorflow::ResourceHandle,1>::operator()(struct Eigen::GpuDevice const &,class Eigen::TensorMap<class Eigen::Tensor<class tensorflow::ResourceHandle const ,4,1,__int64>,16,struct Eigen::MakePointer>,int,class Eigen::TensorMap<class Eigen::Tensor<class tensorflow::ResourceHandle,4,1,__int64>,16,struct Eigen::MakePointer>)"" (??R?$DepthToSpaceOpFunctor@UGpuDevice@Eigen@@VResourceHandle@tensorflow@@$00@functor@tensorflow@@QEAAXAEBUGpuDevice@Eigen@@V?$TensorMap@V?$Tensor@$$CBVResourceHandle@tensorflow@@$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@HV?$TensorMap@V?$Tensor@VResourceHandle@tensorflow@@$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@@Z) referenced in function ""public: virtual void __cdecl tensorflow::DepthToSpaceOp<struct Eigen::ThreadPoolDevice,class tensorflow::ResourceHandle>::Compute(class tensorflow::OpKernelContext *)"" (?Compute@?$DepthToSpaceOp@UThreadPoolDevice@Eigen@@VResourceHandle@tensorflow@@@tensorflow@@UEAAXPEAVOpKernelContext@2@@Z)
libdepth_space_ops.lo(depthtospace_op.o) : error LNK2019: unresolved external symbol ""public: void __cdecl tensorflow::functor::DepthToSpaceOpFunctor<struct Eigen::GpuDevice,class tensorflow::tstring,1>::operator()(struct Eigen::GpuDevice const &,class Eigen::TensorMap<class Eigen::Tensor<class tensorflow::tstring const ,4,1,__int64>,16,struct Eigen::MakePointer>,int,class Eigen::TensorMap<class Eigen::Tensor<class tensorflow::tstring,4,1,__int64>,16,struct Eigen::MakePointer>)"" (??R?$DepthToSpaceOpFunctor@UGpuDevice@Eigen@@Vtstring@tensorflow@@$00@functor@tensorflow@@QEAAXAEBUGpuDevice@Eigen@@V?$TensorMap@V?$Tensor@$$CBVtstring@tensorflow@@$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@HV?$TensorMap@V?$Tensor@Vtstring@tensorflow@@$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@@Z) referenced in function ""public: virtual void __cdecl tensorflow::DepthToSpaceOp<struct Eigen::ThreadPoolDevice,class tensorflow::tstring>::Compute(class tensorflow::OpKernelContext *)"" (?Compute@?$DepthToSpaceOp@UThreadPoolDevice@Eigen@@Vtstring@tensorflow@@@tensorflow@@UEAAXPEAVOpKernelContext@2@@Z)
libdepth_space_ops.lo(depthtospace_op.o) : error LNK2019: unresolved external symbol ""public: void __cdecl tensorflow::functor::DepthToSpaceOpFunctor<struct Eigen::GpuDevice,bool,1>::operator()(struct Eigen::GpuDevice const &,class Eigen::TensorMap<class Eigen::Tensor<bool const ,4,1,__int64>,16,struct Eigen::MakePointer>,int,class Eigen::TensorMap<class Eigen::Tensor<bool,4,1,__int64>,16,struct Eigen::MakePointer>)"" (??R?$DepthToSpaceOpFunctor@UGpuDevice@Eigen@@_N$00@functor@tensorflow@@QEAAXAEBUGpuDevice@Eigen@@V?$TensorMap@V?$Tensor@$$CB_N$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@HV?$TensorMap@V?$Tensor@_N$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@@Z) referenced in function ""public: virtual void __cdecl tensorflow::DepthToSpaceOp<struct Eigen::ThreadPoolDevice,bool>::Compute(class tensorflow::OpKernelContext *)"" (?Compute@?$DepthToSpaceOp@UThreadPoolDevice@Eigen@@_N@tensorflow@@UEAAXPEAVOpKernelContext@2@@Z)
libdepth_space_ops.lo(depthtospace_op.o) : error LNK2019: unresolved external symbol ""public: void __cdecl tensorflow::functor::DepthToSpaceOpFunctor<struct Eigen::GpuDevice,class std::complex<double>,1>::operator()(struct Eigen::GpuDevice const &,class Eigen::TensorMap<class Eigen::Tensor<class std::complex<double> const ,4,1,__int64>,16,struct Eigen::MakePointer>,int,class Eigen::TensorMap<class Eigen::Tensor<class std::complex<double>,4,1,__int64>,16,struct Eigen::MakePointer>)"" (??R?$DepthToSpaceOpFunctor@UGpuDevice@Eigen@@V?$complex@N@std@@$00@functor@tensorflow@@QEAAXAEBUGpuDevice@Eigen@@V?$TensorMap@V?$Tensor@$$CBV?$complex@N@std@@$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@HV?$TensorMap@V?$Tensor@V?$complex@N@std@@$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@@Z) referenced in function ""public: virtual void __cdecl tensorflow::DepthToSpaceOp<struct Eigen::ThreadPoolDevice,class std::complex<double> >::Compute(class tensorflow::OpKernelContext *)"" (?Compute@?$DepthToSpaceOp@UThreadPoolDevice@Eigen@@V?$complex@N@std@@@tensorflow@@UEAAXPEAVOpKernelContext@2@@Z)
libdepth_space_ops.lo(depthtospace_op.o) : error LNK2019: unresolved external symbol ""public: void __cdecl tensorflow::functor::DepthToSpaceOpFunctor<struct Eigen::GpuDevice,class std::complex<float>,1>::operator()(struct Eigen::GpuDevice const &,class Eigen::TensorMap<class Eigen::Tensor<class std::complex<float> const ,4,1,__int64>,16,struct Eigen::MakePointer>,int,class Eigen::TensorMap<class Eigen::Tensor<class std::complex<float>,4,1,__int64>,16,struct Eigen::MakePointer>)"" (??R?$DepthToSpaceOpFunctor@UGpuDevice@Eigen@@V?$complex@M@std@@$00@functor@tensorflow@@QEAAXAEBUGpuDevice@Eigen@@V?$TensorMap@V?$Tensor@$$CBV?$complex@M@std@@$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@HV?$TensorMap@V?$Tensor@V?$complex@M@std@@$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@@Z) referenced in function ""public: virtual void __cdecl tensorflow::DepthToSpaceOp<struct Eigen::ThreadPoolDevice,class std::complex<float> >::Compute(class tensorflow::OpKernelContext *)"" (?Compute@?$DepthToSpaceOp@UThreadPoolDevice@Eigen@@V?$complex@M@std@@@tensorflow@@UEAAXPEAVOpKernelContext@2@@Z)
libdepth_space_ops.lo(depthtospace_op.o) : error LNK2019: unresolved external symbol ""public: void __cdecl tensorflow::functor::DepthToSpaceOpFunctor<struct Eigen::GpuDevice,double,1>::operator()(struct Eigen::GpuDevice const &,class Eigen::TensorMap<class Eigen::Tensor<double const ,4,1,__int64>,16,struct Eigen::MakePointer>,int,class Eigen::TensorMap<class Eigen::Tensor<double,4,1,__int64>,16,struct Eigen::MakePointer>)"" (??R?$DepthToSpaceOpFunctor@UGpuDevice@Eigen@@N$00@functor@tensorflow@@QEAAXAEBUGpuDevice@Eigen@@V?$TensorMap@V?$Tensor@$$CBN$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@HV?$TensorMap@V?$Tensor@N$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@@Z) referenced in function ""public: virtual void __cdecl tensorflow::DepthToSpaceOp<struct Eigen::ThreadPoolDevice,double>::Compute(class tensorflow::OpKernelContext *)"" (?Compute@?$DepthToSpaceOp@UThreadPoolDevice@Eigen@@N@tensorflow@@UEAAXPEAVOpKernelContext@2@@Z)
libdepth_space_ops.lo(depthtospace_op.o) : error LNK2019: unresolved external symbol ""public: void __cdecl tensorflow::functor::DepthToSpaceOpFunctor<struct Eigen::GpuDevice,struct tensorflow::bfloat16,1>::operator()(struct Eigen::GpuDevice const &,class Eigen::TensorMap<class Eigen::Tensor<struct tensorflow::bfloat16 const ,4,1,__int64>,16,struct Eigen::MakePointer>,int,class Eigen::TensorMap<class Eigen::Tensor<struct tensorflow::bfloat16,4,1,__int64>,16,struct Eigen::MakePointer>)"" (??R?$DepthToSpaceOpFunctor@UGpuDevice@Eigen@@Ubfloat16@tensorflow@@$00@functor@tensorflow@@QEAAXAEBUGpuDevice@Eigen@@V?$TensorMap@V?$Tensor@$$CBUbfloat16@tensorflow@@$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@HV?$TensorMap@V?$Tensor@Ubfloat16@tensorflow@@$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@@Z) referenced in function ""public: virtual void __cdecl tensorflow::DepthToSpaceOp<struct Eigen::ThreadPoolDevice,struct tensorflow::bfloat16>::Compute(class tensorflow::OpKernelContext *)"" (?Compute@?$DepthToSpaceOp@UThreadPoolDevice@Eigen@@Ubfloat16@tensorflow@@@tensorflow@@UEAAXPEAVOpKernelContext@2@@Z)
libdepth_space_ops.lo(depthtospace_op.o) : error LNK2019: unresolved external symbol ""public: void __cdecl tensorflow::functor::DepthToSpaceOpFunctor<struct Eigen::GpuDevice,signed char,1>::operator()(struct Eigen::GpuDevice const &,class Eigen::TensorMap<class Eigen::Tensor<signed char const ,4,1,__int64>,16,struct Eigen::MakePointer>,int,class Eigen::TensorMap<class Eigen::Tensor<signed char,4,1,__int64>,16,struct Eigen::MakePointer>)"" (??R?$DepthToSpaceOpFunctor@UGpuDevice@Eigen@@C$00@functor@tensorflow@@QEAAXAEBUGpuDevice@Eigen@@V?$TensorMap@V?$Tensor@$$CBC$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@HV?$TensorMap@V?$Tensor@C$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@@Z) referenced in function ""public: virtual void __cdecl tensorflow::DepthToSpaceOp<struct Eigen::ThreadPoolDevice,signed char>::Compute(class tensorflow::OpKernelContext *)"" (?Compute@?$DepthToSpaceOp@UThreadPoolDevice@Eigen@@C@tensorflow@@UEAAXPEAVOpKernelContext@2@@Z)
libdepth_space_ops.lo(depthtospace_op.o) : error LNK2019: unresolved external symbol ""public: void __cdecl tensorflow::functor::DepthToSpaceOpFunctor<struct Eigen::GpuDevice,unsigned char,1>::operator()(struct Eigen::GpuDevice const &,class Eigen::TensorMap<class Eigen::Tensor<unsigned char const ,4,1,__int64>,16,struct Eigen::MakePointer>,int,class Eigen::TensorMap<class Eigen::Tensor<unsigned char,4,1,__int64>,16,struct Eigen::MakePointer>)"" (??R?$DepthToSpaceOpFunctor@UGpuDevice@Eigen@@E$00@functor@tensorflow@@QEAAXAEBUGpuDevice@Eigen@@V?$TensorMap@V?$Tensor@$$CBE$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@HV?$TensorMap@V?$Tensor@E$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@@Z) referenced in function ""public: virtual void __cdecl tensorflow::DepthToSpaceOp<struct Eigen::ThreadPoolDevice,unsigned char>::Compute(class tensorflow::OpKernelContext *)"" (?Compute@?$DepthToSpaceOp@UThreadPoolDevice@Eigen@@E@tensorflow@@UEAAXPEAVOpKernelContext@2@@Z)
libdepth_space_ops.lo(depthtospace_op.o) : error LNK2019: unresolved external symbol ""public: void __cdecl tensorflow::functor::DepthToSpaceOpFunctor<struct Eigen::GpuDevice,short,1>::operator()(struct Eigen::GpuDevice const &,class Eigen::TensorMap<class Eigen::Tensor<short const ,4,1,__int64>,16,struct Eigen::MakePointer>,int,class Eigen::TensorMap<class Eigen::Tensor<short,4,1,__int64>,16,struct Eigen::MakePointer>)"" (??R?$DepthToSpaceOpFunctor@UGpuDevice@Eigen@@F$00@functor@tensorflow@@QEAAXAEBUGpuDevice@Eigen@@V?$TensorMap@V?$Tensor@$$CBF$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@HV?$TensorMap@V?$Tensor@F$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@@Z) referenced in function ""public: virtual void __cdecl tensorflow::DepthToSpaceOp<struct Eigen::ThreadPoolDevice,short>::Compute(class tensorflow::OpKernelContext *)"" (?Compute@?$DepthToSpaceOp@UThreadPoolDevice@Eigen@@F@tensorflow@@UEAAXPEAVOpKernelContext@2@@Z)
libdepth_space_ops.lo(depthtospace_op.o) : error LNK2019: unresolved external symbol ""public: void __cdecl tensorflow::functor::DepthToSpaceOpFunctor<struct Eigen::GpuDevice,unsigned short,1>::operator()(struct Eigen::GpuDevice const &,class Eigen::TensorMap<class Eigen::Tensor<unsigned short const ,4,1,__int64>,16,struct Eigen::MakePointer>,int,class Eigen::TensorMap<class Eigen::Tensor<unsigned short,4,1,__int64>,16,struct Eigen::MakePointer>)"" (??R?$DepthToSpaceOpFunctor@UGpuDevice@Eigen@@G$00@functor@tensorflow@@QEAAXAEBUGpuDevice@Eigen@@V?$TensorMap@V?$Tensor@$$CBG$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@HV?$TensorMap@V?$Tensor@G$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@@Z) referenced in function ""public: virtual void __cdecl tensorflow::DepthToSpaceOp<struct Eigen::ThreadPoolDevice,unsigned short>::Compute(class tensorflow::OpKernelContext *)"" (?Compute@?$DepthToSpaceOp@UThreadPoolDevice@Eigen@@G@tensorflow@@UEAAXPEAVOpKernelContext@2@@Z)
libdepth_space_ops.lo(depthtospace_op.o) : error LNK2019: unresolved external symbol ""public: void __cdecl tensorflow::functor::DepthToSpaceOpFunctor<struct Eigen::GpuDevice,__int64,1>::operator()(struct Eigen::GpuDevice const &,class Eigen::TensorMap<class Eigen::Tensor<__int64 const ,4,1,__int64>,16,struct Eigen::MakePointer>,int,class Eigen::TensorMap<class Eigen::Tensor<__int64,4,1,__int64>,16,struct Eigen::MakePointer>)"" (??R?$DepthToSpaceOpFunctor@UGpuDevice@Eigen@@_J$00@functor@tensorflow@@QEAAXAEBUGpuDevice@Eigen@@V?$TensorMap@V?$Tensor@$$CB_J$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@HV?$TensorMap@V?$Tensor@_J$03$00_J@Eigen@@$0BA@UMakePointer@2@@4@@Z) referenced in function ""public: virtual void __cdecl tensorflow::DepthToSpaceOp<struct Eigen::ThreadPoolDevice,__int64>::Compute(class tensorflow::OpKernelContext *)"" (?Compute@?$DepthToSpaceOp@UThreadPoolDevice@Eigen@@_J@tensorflow@@UEAAXPEAVOpKernelContext@2@@Z)
libpack_op.lo(pack_op.o) : error LNK2019: unresolved external symbol ""void __cdecl tensorflow::ConcatGPU<class tensorflow::Variant>(class tensorflow::OpKernelContext *,class std::vector<class std::unique_ptr<class Eigen::TensorMap<class Eigen::Tensor<class tensorflow::Variant const ,2,1,__int64>,16,struct Eigen::MakePointer>,struct std::default_delete<class Eigen::TensorMap<class Eigen::Tensor<class tensorflow::Variant const ,2,1,__int64>,16,struct Eigen::MakePointer> > >,class std::allocator<class std::unique_ptr<class Eigen::TensorMap<class Eigen::Tensor<class tensorflow::Variant const ,2,1,__int64>,16,struct Eigen::MakePointer>,struct std::default_delete<class Eigen::TensorMap<class Eigen::Tensor<class tensorflow::Variant const ,2,1,__int64>,16,struct Eigen::MakePointer> > > > > const &,class tensorflow::Tensor *,class Eigen::TensorMap<class Eigen::Tensor<class tensorflow::Variant,2,1,__int64>,16,struct Eigen::MakePointer> *)"" (??$ConcatGPU@VVariant@tensorflow@@@tensorflow@@YAXPEAVOpKernelContext@0@AEBV?$vector@V?$unique_ptr@V?$TensorMap@V?$Tensor@$$CBVVariant@tensorflow@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@U?$default_delete@V?$TensorMap@V?$Tensor@$$CBVVariant@tensorflow@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@std@@@std@@V?$allocator@V?$unique_ptr@V?$TensorMap@V?$Tensor@$$CBVVariant@tensorflow@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@U?$default_delete@V?$TensorMap@V?$Tensor@$$CBVVariant@tensorflow@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@std@@@std@@@2@@std@@PEAVTensor@0@PEAV?$TensorMap@V?$Tensor@VVariant@tensorflow@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@Z) referenced in function ""public: virtual void __cdecl tensorflow::PackOp<struct Eigen::ThreadPoolDevice,class tensorflow::Variant>::Compute(class tensorflow::OpKernelContext *)"" (?Compute@?$PackOp@UThreadPoolDevice@Eigen@@VVariant@tensorflow@@@tensorflow@@UEAAXPEAVOpKernelContext@2@@Z)
libtensor_array_ops.lo(tensor_array_ops.o) : error LNK2001: unresolved external symbol ""void __cdecl tensorflow::ConcatGPU<class tensorflow::Variant>(class tensorflow::OpKernelContext *,class std::vector<class std::unique_ptr<class Eigen::TensorMap<class Eigen::Tensor<class tensorflow::Variant const ,2,1,__int64>,16,struct Eigen::MakePointer>,struct std::default_delete<class Eigen::TensorMap<class Eigen::Tensor<class tensorflow::Variant const ,2,1,__int64>,16,struct Eigen::MakePointer> > >,class std::allocator<class std::unique_ptr<class Eigen::TensorMap<class Eigen::Tensor<class tensorflow::Variant const ,2,1,__int64>,16,struct Eigen::MakePointer>,struct std::default_delete<class Eigen::TensorMap<class Eigen::Tensor<class tensorflow::Variant const ,2,1,__int64>,16,struct Eigen::MakePointer> > > > > const &,class tensorflow::Tensor *,class Eigen::TensorMap<class Eigen::Tensor<class tensorflow::Variant,2,1,__int64>,16,struct Eigen::MakePointer> *)"" (??$ConcatGPU@VVariant@tensorflow@@@tensorflow@@YAXPEAVOpKernelContext@0@AEBV?$vector@V?$unique_ptr@V?$TensorMap@V?$Tensor@$$CBVVariant@tensorflow@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@U?$default_delete@V?$TensorMap@V?$Tensor@$$CBVVariant@tensorflow@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@std@@@std@@V?$allocator@V?$unique_ptr@V?$TensorMap@V?$Tensor@$$CBVVariant@tensorflow@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@U?$default_delete@V?$TensorMap@V?$Tensor@$$CBVVariant@tensorflow@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@std@@@std@@@2@@std@@PEAVTensor@0@PEAV?$TensorMap@V?$Tensor@VVariant@tensorflow@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@Z)
liblist_kernels.lo(list_kernels.o) : error LNK2001: unresolved external symbol ""void __cdecl tensorflow::ConcatGPU<class tensorflow::Variant>(class tensorflow::OpKernelContext *,class std::vector<class std::unique_ptr<class Eigen::TensorMap<class Eigen::Tensor<class tensorflow::Variant const ,2,1,__int64>,16,struct Eigen::MakePointer>,struct std::default_delete<class Eigen::TensorMap<class Eigen::Tensor<class tensorflow::Variant const ,2,1,__int64>,16,struct Eigen::MakePointer> > >,class std::allocator<class std::unique_ptr<class Eigen::TensorMap<class Eigen::Tensor<class tensorflow::Variant const ,2,1,__int64>,16,struct Eigen::MakePointer>,struct std::default_delete<class Eigen::TensorMap<class Eigen::Tensor<class tensorflow::Variant const ,2,1,__int64>,16,struct Eigen::MakePointer> > > > > const &,class tensorflow::Tensor *,class Eigen::TensorMap<class Eigen::Tensor<class tensorflow::Variant,2,1,__int64>,16,struct Eigen::MakePointer> *)"" (??$ConcatGPU@VVariant@tensorflow@@@tensorflow@@YAXPEAVOpKernelContext@0@AEBV?$vector@V?$unique_ptr@V?$TensorMap@V?$Tensor@$$CBVVariant@tensorflow@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@U?$default_delete@V?$TensorMap@V?$Tensor@$$CBVVariant@tensorflow@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@std@@@std@@V?$allocator@V?$unique_ptr@V?$TensorMap@V?$Tensor@$$CBVVariant@tensorflow@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@U?$default_delete@V?$TensorMap@V?$Tensor@$$CBVVariant@tensorflow@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@std@@@std@@@2@@std@@PEAVTensor@0@PEAV?$TensorMap@V?$Tensor@VVariant@tensorflow@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@Z)
libpack_op.lo(pack_op.o) : error LNK2019: unresolved external symbol ""void __cdecl tensorflow::ConcatGPU<class tensorflow::ResourceHandle>(class tensorflow::OpKernelContext *,class std::vector<class std::unique_ptr<class Eigen::TensorMap<class Eigen::Tensor<class tensorflow::ResourceHandle const ,2,1,__int64>,16,struct Eigen::MakePointer>,struct std::default_delete<class Eigen::TensorMap<class Eigen::Tensor<class tensorflow::ResourceHandle const ,2,1,__int64>,16,struct Eigen::MakePointer> > >,class std::allocator<class std::unique_ptr<class Eigen::TensorMap<class Eigen::Tensor<class tensorflow::ResourceHandle const ,2,1,__int64>,16,struct Eigen::MakePointer>,struct std::default_delete<class Eigen::TensorMap<class Eigen::Tensor<class tensorflow::ResourceHandle const ,2,1,__int64>,16,struct Eigen::MakePointer> > > > > const &,class tensorflow::Tensor *,class Eigen::TensorMap<class Eigen::Tensor<class tensorflow::ResourceHandle,2,1,__int64>,16,struct Eigen::MakePointer> *)"" (??$ConcatGPU@VResourceHandle@tensorflow@@@tensorflow@@YAXPEAVOpKernelContext@0@AEBV?$vector@V?$unique_ptr@V?$TensorMap@V?$Tensor@$$CBVResourceHandle@tensorflow@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@U?$default_delete@V?$TensorMap@V?$Tensor@$$CBVResourceHandle@tensorflow@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@std@@@std@@V?$allocator@V?$unique_ptr@V?$TensorMap@V?$Tensor@$$CBVResourceHandle@tensorflow@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@U?$default_delete@V?$TensorMap@V?$Tensor@$$CBVResourceHandle@tensorflow@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@std@@@std@@@2@@std@@PEAVTensor@0@PEAV?$TensorMap@V?$Tensor@VResourceHandle@tensorflow@@$01$00_J@Eigen@@$0BA@UMakePointer@2@@Eigen@@@Z) referenced in function ""public: virtual void __cdecl tensorflow::PackOp<struct Eigen::ThreadPoolDevice,class tensorflow::ResourceHandle>::Compute(class tensorflow::OpKernelContext *)"" (?Compute@?$PackOp@UThreadPoolDevice@Eigen@@VResourceHandle@tensorflow@@@tensorflow@@UEAAXPEAVOpKernelContext@2@@Z)
libself_adjoint_eig_v2_op.lo(self_adjoint_eig_v2_op_gpu.o) : error LNK2019: unresolved external symbol ""public: void __cdecl tensorflow::functor::UnaryFunctor<struct Eigen::GpuDevice,struct tensorflow::functor::conj<double> >::operator()(struct Eigen::GpuDevice const &,class Eigen::TensorMap<class Eigen::Tensor<double,1,1,__int64>,16,struct Eigen::MakePointer>,class Eigen::TensorMap<class Eigen::Tensor<double const ,1,1,__int64>,16,struct Eigen::MakePointer>)"" (??R?$UnaryFunctor@UGpuDevice@Eigen@@U?$conj@N@functor@tensorflow@@@functor@tensorflow@@QEAAXAEBUGpuDevice@Eigen@@V?$TensorMap@V?$Tensor@N$00$00_J@Eigen@@$0BA@UMakePointer@2@@4@V?$TensorMap@V?$Tensor@$$CBN$00$00_J@Eigen@@$0BA@UMakePointer@2@@4@@Z) referenced in function ""public: virtual void __cdecl tensorflow::SelfAdjointEigV2OpGpu<double>::ComputeAsync(class tensorflow::OpKernelContext *,class std::function<void __cdecl(void)>)"" (?ComputeAsync@?$SelfAdjointEigV2OpGpu@N@tensorflow@@UEAAXPEAVOpKernelContext@2@V?$function@$$A6AXXZ@std@@@Z)
libself_adjoint_eig_v2_op.lo(self_adjoint_eig_v2_op_gpu.o) : error LNK2019: unresolved external symbol ""public: void __cdecl tensorflow::functor::UnaryFunctor<struct Eigen::GpuDevice,struct tensorflow::functor::conj<float> >::operator()(struct Eigen::GpuDevice const &,class Eigen::TensorMap<class Eigen::Tensor<float,1,1,__int64>,16,struct Eigen::MakePointer>,class Eigen::TensorMap<class Eigen::Tensor<float const ,1,1,__int64>,16,struct Eigen::MakePointer>)"" (??R?$UnaryFunctor@UGpuDevice@Eigen@@U?$conj@M@functor@tensorflow@@@functor@tensorflow@@QEAAXAEBUGpuDevice@Eigen@@V?$TensorMap@V?$Tensor@M$00$00_J@Eigen@@$0BA@UMakePointer@2@@4@V?$TensorMap@V?$Tensor@$$CBM$00$00_J@Eigen@@$0BA@UMakePointer@2@@4@@Z) referenced in function ""public: virtual void __cdecl tensorflow::SelfAdjointEigV2OpGpu<float>::ComputeAsync(class tensorflow::OpKernelContext *,class std::function<void __cdecl(void)>)"" (?ComputeAsync@?$SelfAdjointEigV2OpGpu@M@tensorflow@@UEAAXPEAVOpKernelContext@2@V?$function@$$A6AXXZ@std@@@Z)
libresource_variable_ops.lo(resource_variable_ops.o) : error LNK2019: unresolved external symbol ""public: void __cdecl tensorflow::functor::DenseUpdate<struct Eigen::GpuDevice,class tensorflow::Variant,2>::operator()(struct Eigen::GpuDevice const &,class Eigen::TensorMap<class Eigen::Tensor<class tensorflow::Variant,1,1,__int64>,16,struct Eigen::MakePointer>,class Eigen::TensorMap<class Eigen::Tensor<class tensorflow::Variant const ,1,1,__int64>,16,struct Eigen::MakePointer>)"" (??R?$DenseUpdate@UGpuDevice@Eigen@@VVariant@tensorflow@@$01@functor@tensorflow@@QEAAXAEBUGpuDevice@Eigen@@V?$TensorMap@V?$Tensor@VVariant@tensorflow@@$00$00_J@Eigen@@$0BA@UMakePointer@2@@4@V?$TensorMap@V?$Tensor@$$CBVVariant@tensorflow@@$00$00_J@Eigen@@$0BA@UMakePointer@2@@4@@Z) referenced in function ""class tensorflow::Status __cdecl tensorflow::EnsureSparseVariableAccess<struct Eigen::GpuDevice,class tensorflow::Variant>(class tensorflow::OpKernelContext *,class tensorflow::Var *)"" (??$EnsureSparseVariableAccess@UGpuDevice@Eigen@@VVariant@tensorflow@@@tensorflow@@YA?AVStatus@0@PEAVOpKernelContext@0@PEAVVar@0@@Z)
bazel-out\x64_windows-dbg\bin\tensorflow\compiler\aot\tfcompile : fatal error LNK1120: 56 unresolved externals
Target //tensorflow/compiler/aot:tfcompile failed to build
INFO: Elapsed time: 18423.485s, Critical Path: 947.85s
INFO: 2594 processes: 2594 local.
FAILED: Build did NOT complete successfully
"
38506,Keras Assertion Error for TPU Strategy ,"I get the following assertion error at .fit() when trying to use TPU distributed strategy. 

```
Model: ""my_model_final""
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
my_model (MyModel)           multiple                  2098016   
_________________________________________________________________
dense_2 (Dense)              multiple                  3120      
_________________________________________________________________
layer_normalization_9 (Layer multiple                  96        
_________________________________________________________________
dense_3 (Dense)              multiple                  4160      
_________________________________________________________________
output_2 (Dense)             multiple                  65        
_________________________________________________________________
output_1 (EmbeddingSimilarit multiple                  32000     
=================================================================
Total params: 2,137,457
Trainable params: 2,137,457
Non-trainable params: 0
_________________________________________________________________
None
Traceback (most recent call last):
  File ""copy_train_lm.py"", line 91, in <module>
    model.fit(x=gen(all_files,128), epochs=100, steps_per_epoch=100)#,
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/engine/training.py"", line 819, in fit
    use_multiprocessing=use_multiprocessing)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/engine/training_distributed.py"", line 619, in fit
    epochs=epochs)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/engine/training.py"", line 2242, in _distribution_standardize_user_data
    assert isinstance(x, dataset_ops.DatasetV2)
AssertionError
```
This is my code to reproduce the results:

```
import numpy as np 
import tensorflow as tf 
from keras_model import MyModelFinal
from tensorflow import keras
tf.compat.v1.disable_eager_execution()
resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='rakshanda-agarwal')
tf.config.experimental_connect_to_host(resolver.master())tf.tpu.experimental.initialize_tpu_system(resolver)
strategy = tf.distribute.experimental.TPUStrategy(resolver)

def gen(all_files, batch_size):
    while True:
        for file in all_files:
            with np.load(file) as data:
                for i in range(0,len(data[""input_ids""]),batch_size):

                    input_ids = data[""input_ids""][i:(i+batch_size)] 
                    input_mask = data['input_mask'][i:(i+batch_size)]
                    segment_ids = data[""segment_ids""][i:(i+batch_size)]
                    masked_lm_positions = data[""masked_lm_positions""][i:(i+batch_size)]
                    masked_lm_ids = data[""masked_lm_ids""][i:(i+batch_size)]
                    masked_lm_weights = data[""masked_lm_weights""][i:(i+batch_size)]
                    next_sentence_labels = data[""next_sentence_labels""][i:(i+batch_size)]

                    # masked_lm_weights=tf.reshape(masked_lm_weights,[128*20])
                    # masked_lm_ids=tf.reshape(masked_lm_ids, [128,20,1])
                    yield ([input_ids, segment_ids, input_mask, masked_lm_positions],
                        [[masked_lm_ids,masked_lm_weights], next_sentence_labels])
                        # {'output_1':masked_lm_ids, 'output_2':next_sentence_labels}, 
                        # {'output_1':masked_lm_weights, 'output_2':np.ones(batch_size)})
                        # [masked_lm_ids, next_sentence_labels],[masked_lm_weights,1])

                        # [masked_lm_ids, next_sentence_labels],[masked_lm_weights,np.ones(batch_size)])


all_files=[""data1/train/1.npz""]
# val_files=[""LM1/train/1.npz""]

batch_size = 128
out_filters = 64
num_layers = 4

def loss1(logits, y, vocab_size=32000):
    print(y)
    masked_lm_ids = y[0]
    masked_lm_weights = y[1]
    logits = tf.reshape(logits, [2560,32000])
    log_probs = tf.nn.log_softmax(logits, axis=-1)
    masked_lm_ids = tf.reshape(masked_lm_ids, [-1])
    masked_lm_weights = tf.reshape(masked_lm_weights, [-1])
    one_hot_labels = tf.one_hot(masked_lm_ids, depth=vocab_size, dtype=tf.float32)
    per_example_loss = -tf.reduce_sum(log_probs * one_hot_labels, axis=[-1])
    numerator = tf.reduce_sum(masked_lm_weights * per_example_loss)
    denominator = tf.reduce_sum(masked_lm_weights) + 1e-5
    loss=numerator / denominator
    return loss

with strategy.scope():
    model=MyModelFinal(out_filters=64, is_training=True, emb_size=48, 
        vocab_size=32000, max_seq_length=128, num_layers=4) 

    
    with np.load(all_files[0]) as data:
        for i in range(0,len(data[""input_ids""]),batch_size):

            input_ids = data[""input_ids""][i:(i+batch_size)] 
            input_mask = data['input_mask'][i:(i+batch_size)]
            segment_ids = data[""segment_ids""][i:(i+batch_size)]
            masked_lm_positions = data[""masked_lm_positions""][i:(i+batch_size)]
            # masked_lm_ids = data[""masked_lm_ids""][i:(i+batch_size)]
            # masked_lm_weights = data[""masked_lm_weights""][i:(i+batch_size)]
            # next_sentence_labels = data[""next_sentence_labels""][i:(i+batch_size)]

            model([input_ids, segment_ids, input_mask, masked_lm_positions])
            break


    print(model.summary())

    optimizer = keras.optimizers.Adam(lr=0.0002)
    losses={'output_1':loss1,
        'output_2':'binary_crossentropy'}

    # lossWeights = {""output_1"": 1.0, ""output_2"": 1.0}

    model.compile(optimizer=optimizer, loss=losses)
    # ,
    #     sample_weight_mode={'output_1' : 'temporal', 'output_2':None})

model.fit(x=gen(all_files,128), epochs=100, steps_per_epoch=100)#,
    # validation_data=gen(val_files,128),
    # 
    # validation_steps=100, validation_freq=1)
```
"
38505,ImportError: DLL load failed: The specified module could not be found. Failed to load the native TensorFlow runtime.,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): pip install
- TensorFlow version: 2
- Python version: 3.7
- Installed using virtualenv? pip? conda?: pip
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N?A
- CUDA/cuDNN version: CUDA 10.2,  cuDNN 7.6.5 
- GPU model and memory: Nvidia Quadro M1200, 16 GB RAM

I cannot import tensorflow
This is what I got:
Exception has occurred: ImportError
Traceback (most recent call last): File ""C:\Users\khiteliv\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module> from tensorflow.python.pywrap_tensorflow_internal import * File ""C:\Users\khiteliv\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module> _pywrap_tensorflow_internal = swig_import_helper() File ""C:\Users\khiteliv\AppData\Local\Continuum\anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description) File ""C:\Users\khiteliv\AppData\Local\Continuum\anaconda3\lib\imp.py"", line 242, in load_module return load_dynamic(name, filename, file) File ""C:\Users\khiteliv\AppData\Local\Continuum\anaconda3\lib\imp.py"", line 342, in load_dynamic return _load(spec) ImportError: DLL load failed: The specified module could not be found. Failed to load the native TensorFlow runtime. 


Thank you for your help!"
38503, AttributeError: 'tuple' object has no attribute 'shape' error while using Google colab,"Based on research and understanding of the issue its looks to me as a bug as i tried different things suggested by other users for similar issues. but it doesn't resolve.

------------------------

### System information
Using google colab
access to the notebook: https://colab.research.google.com/drive/1sDg-5lDnUKYLQUbSkBiZsYK4ZBof3ZQZ#scrollTo=mopYecQ-eIJk&uniqifier=1



You can obtain the TensorFlow version with:
Using goolge colab

### Describe the problem
I am able to run the same code on a normal jupyter notebook on my uni server. but it throws me an error while trying to run it on google colab.
I checked if there are any references to keras instaed of tensoflw.keras and corrected them. I also converted the datagenerator output to a tuple instead of list

### Source code / logs
WARNING:tensorflow:From <ipython-input-10-1ae13c8462de>:9: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
Please use Model.fit, which supports generators.
Epoch 1/5
---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
<ipython-input-10-1ae13c8462de> in <module>()
      7                   epochs=nb_epoch,
      8                   steps_per_epoch=nb_train_samples,
----> 9                   validation_data=gen_valid)

12 frames
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py in wrapper(*args, **kwargs)
    966           except Exception as e:  # pylint:disable=broad-except
    967             if hasattr(e, ""ag_error_metadata""):
--> 968               raise e.ag_error_metadata.to_exception(e)
    969             else:
    970               raise

AttributeError: in user code:

    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:505 train_function  *
        outputs = self.distribute_strategy.run(
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:951 run  **
        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2290 call_for_each_replica
        return self._call_for_each_replica(fn, args, kwargs)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2649 _call_for_each_replica
        return fn(*args, **kwargs)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:477 train_step  **
        self.compiled_metrics.update_state(y, y_pred, sample_weight)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/compile_utils.py:386 update_state
        self._build(y_pred, y_true)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/compile_utils.py:317 _build
        self._metrics, y_true, y_pred)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py:1118 map_structure_up_to
        **kwargs)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py:1214 map_structure_with_tuple_paths_up_to
        *flat_value_lists)]
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py:1213 <listcomp>
        results = [func(*args, **kwargs) for args in zip(flat_path_list,
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py:1116 <lambda>
        lambda _, *values: func(*values),  # Discards the path arg.
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/compile_utils.py:416 _get_metric_objects
        return [self._get_metric_object(m, y_t, y_p) for m in metrics]
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/compile_utils.py:416 <listcomp>
        return [self._get_metric_object(m, y_t, y_p) for m in metrics]
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/compile_utils.py:437 _get_metric_object
        y_t_rank = len(y_t.shape.as_list())

    AttributeError: 'tuple' object has no attribute 'shape'
"
38502,tf-trt converted deep models int8 inference crashes,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow):  NO
- OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04):  
Version: tf-gpu.1-15.m45 (dlvm)
Based on: Debian GNU/Linux 9.12 (stretch) (GNU/Linux 4.9.0-12-amd64 x86_64\n)
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if
the issue happens on mobile device: 
- TensorFlow installed from (source or
binary): - TensorFlow version (use command below):  v1.15.2-1-g61ff2cb 1.15.2
- Python version: - Bazel
version (if compiling from source): n/a
- GCC/Compiler version (if compiling from
source): n/a
- CUDA/cuDNN version: - GPU model and memory:
Cuda compilation tools, release 10.0, V10.0.130
#define CUDNN_MAJOR 7
#define CUDNN_MINOR 6
#define CUDNN_PATCHLEVEL 5

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
I am using tf-trt to convert some of the models to different precision mode.
it works fine for fp32 and fp16  (gets converted and inference runs fine)
but int8  only get converted but on inference gives the following error
2020-04-12 10:20:31.123734: I tensorflow/compiler/tf2tensorrt/kernels/trt_engine_op.cc:812] Starting calibration thread on device 0, Calibration Resource @ 0x7fd990004ea0
2020-04-12 10:20:31.123883: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libnvinfer.so.5
2020-04-12 10:20:31.124498: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libnvinfer_plugin.so.5
2020-04-12 10:20:58.770669: I tensorflow/compiler/tf2tensorrt/kernels/trt_engine_op.cc:812] Starting calibration thread on device 0, Calibration Resource @ 0x7fd96c004e80
2020-04-12 10:21:20.543550: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2020-04-12 10:29:21.108202: F tensorflow/compiler/tf2tensorrt/kernels/trt_engine_op.cc:349] Check failed: t.TotalBytes() == device_tensor->TotalBytes() (1832000 vs. 21467376)
Aborted

**Describe the expected behavior**
model should run faster with int8 ?

**Standalone code to reproduce the issue** 
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.
n/a

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
already attached
"
38501,tf.estimator graph_saver.restore() error when calling train_and_evalute method,"**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow): **yes**
- OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04): **Google Colab**
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if
the issue happens on mobile device: **no**
- TensorFlow installed from (source or
binary): **Provided by Colab**
- TensorFlow version (use command below): **2.1.0**
- Python version: **Python 3.6**
- Bazel version (if compiling from source): **not relevant**
- GCC/Compiler version (if compiling from
source): **not relevant**
- CUDA/cuDNN version: **CUDA V10.1.243**
- GPU model and memory: **GPU deactivated**

**Describe the current behavior**
After evaluation, the `train_and_evaluate` method of the tf.estimator API throws an error when the Saver restores the checkpoints after exporting the model using tf.estimator.Exporter. It seems that the estimator calls the restore() method with too many arguments. See logs for details.

**Describe the expected behavior**
Until a few days ago, my (unchanged) code worked without any errors. So I guess some change in tensorflow/tf.estimator within the last days caused the issue to come up. Back then, the estimator was able to train, evaluate, export and then continue training without problems.

**Standalone code to reproduce the issue** 
Here is a link to a [Colab Notebook]( https://colab.research.google.com/drive/1KHqAMZGqngMvQntyTqnj7boa4OZPPoi1) to reproduce the issue

**Other info / logs** 
```
INFO:tensorflow:Finished evaluation at 2020-04-13-14:15:37
INFO:tensorflow:Saving dict for global step 2821: accuracy = 1.0, global_step = 2821, loss = 0.2742786
INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2821: /content/simple/model.ckpt-2821
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Signatures INCLUDED in export for Classify: None
INFO:tensorflow:Signatures INCLUDED in export for Regress: None
INFO:tensorflow:Signatures INCLUDED in export for Predict: ['serving_default']
INFO:tensorflow:Signatures INCLUDED in export for Train: None
INFO:tensorflow:Signatures INCLUDED in export for Eval: None
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
<ipython-input-128-30df9d6a3d21> in <module>()
----> 1 tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)

23 frames
/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py in train_and_evaluate(estimator, train_spec, eval_spec)
    471         '(with task id 0).  Given task id {}'.format(config.task_id))
    472 
--> 473   return executor.run()
    474 
    475 

/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py in run(self)
    611         config.task_type != run_config_lib.TaskType.EVALUATOR):
    612       logging.info('Running training and evaluation locally (non-distributed).')
--> 613       return self.run_local()
    614 
    615     # Distributed case.

/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py in run_local(self)
    712         max_steps=self._train_spec.max_steps,
    713         hooks=train_hooks,
--> 714         saving_listeners=saving_listeners)
    715 
    716     eval_result = listener_for_eval.eval_result or _EvalResult(

/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py in train(self, input_fn, hooks, steps, max_steps, saving_listeners)
    372 
    373       saving_listeners = _check_listeners_type(saving_listeners)
--> 374       loss = self._train_model(input_fn, hooks, saving_listeners)
    375       logging.info('Loss for final step: %s.', loss)
    376       return self

/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py in _train_model(self, input_fn, hooks, saving_listeners)
   1162       return self._train_model_distributed(input_fn, hooks, saving_listeners)
   1163     else:
-> 1164       return self._train_model_default(input_fn, hooks, saving_listeners)
   1165 
   1166   def _train_model_default(self, input_fn, hooks, saving_listeners):

/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py in _train_model_default(self, input_fn, hooks, saving_listeners)
   1196       return self._train_with_estimator_spec(estimator_spec, worker_hooks,
   1197                                              hooks, global_step_tensor,
-> 1198                                              saving_listeners)
   1199 
   1200   def _train_model_distributed(self, input_fn, hooks, saving_listeners):

/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py in _train_with_estimator_spec(self, estimator_spec, worker_hooks, hooks, global_step_tensor, saving_listeners)
   1495       any_step_done = False
   1496       while not mon_sess.should_stop():
-> 1497         _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])
   1498         any_step_done = True
   1499     if not any_step_done:

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py in run(self, fetches, feed_dict, options, run_metadata)
    776         feed_dict=feed_dict,
    777         options=options,
--> 778         run_metadata=run_metadata)
    779 
    780   def run_step_fn(self, step_fn):

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py in run(self, fetches, feed_dict, options, run_metadata)
   1281             feed_dict=feed_dict,
   1282             options=options,
-> 1283             run_metadata=run_metadata)
   1284       except _PREEMPTION_ERRORS as e:
   1285         logging.info(

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py in run(self, *args, **kwargs)
   1382         raise six.reraise(*original_exc_info)
   1383       else:
-> 1384         raise six.reraise(*original_exc_info)
   1385 
   1386 

/usr/local/lib/python3.6/dist-packages/six.py in reraise(tp, value, tb)
    691             if value.__traceback__ is not tb:
    692                 raise value.with_traceback(tb)
--> 693             raise value
    694         finally:
    695             value = None

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py in run(self, *args, **kwargs)
   1367   def run(self, *args, **kwargs):
   1368     try:
-> 1369       return self._sess.run(*args, **kwargs)
   1370     except _PREEMPTION_ERRORS:
   1371       raise

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/monitored_session.py in run(self, fetches, feed_dict, options, run_metadata)
   1448               results=outputs[hook] if hook in outputs else None,
   1449               options=options,
-> 1450               run_metadata=run_metadata))
   1451     self._should_stop = self._should_stop or run_context.stop_requested
   1452 

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/basic_session_run_hooks.py in after_run(self, run_context, run_values)
    599       if self._timer.should_trigger_for_step(global_step):
    600         self._timer.update_last_triggered_step(global_step)
--> 601         if self._save(run_context.session, global_step):
    602           run_context.request_stop()
    603 

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/basic_session_run_hooks.py in _save(self, session, step)
    625     should_stop = False
    626     for l in self._listeners:
--> 627       if l.after_save(session, step):
    628         logging.info(
    629             ""A CheckpointSaverListener requested that training be stopped. ""

/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py in after_save(***failed resolving arguments***)
    517       return True
    518     if self._timer.should_trigger_for_step(global_step_value):
--> 519       self._evaluate(global_step_value)  # updates self.eval_result
    520       if not self._continuous_eval_listener.after_eval(self.eval_result):
    521         logging.info('Exiting evaluation, as requested by '

/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py in _evaluate(self, global_step_value)
    537     self._timer.update_last_triggered_step(global_step_value)
    538     self.eval_result, self.export_results = (
--> 539         self._evaluator.evaluate_and_export())
    540     if self.eval_result.status != _EvalStatus.EVALUATED:
    541       #  This is unexpected; should never happen.

/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py in evaluate_and_export(self)
    930           self._max_training_steps if self._max_training_steps else False)
    931       export_results = self._export_eval_result(eval_result,
--> 932                                                 is_the_final_export)
    933 
    934       if is_the_final_export:

/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py in _export_eval_result(self, eval_result, is_the_final_export)
    963                 checkpoint_path=eval_result.checkpoint_path,
    964                 eval_result=eval_result.metrics,
--> 965                 is_the_final_export=is_the_final_export))
    966       return export_results
    967 

/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/exporter.py in export(self, estimator, export_path, checkpoint_path, eval_result, is_the_final_export)
    466     export_result = self._saved_model_exporter.export(
    467         estimator, export_path, checkpoint_path, eval_result,
--> 468         is_the_final_export)
    469 
    470     self._garbage_collect_exports(export_path)

/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/exporter.py in export(***failed resolving arguments***)
    118         assets_extra=self._assets_extra,
    119         as_text=self._as_text,
--> 120         checkpoint_path=checkpoint_path)
    121 
    122     return export_result

/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py in export_saved_model(self, export_dir_base, serving_input_receiver_fn, assets_extra, as_text, checkpoint_path, experimental_mode)
    737         as_text=as_text,
    738         checkpoint_path=checkpoint_path,
--> 739         strip_default_attrs=True)
    740 
    741   def experimental_export_all_saved_models(

/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py in _export_all_saved_models(self, export_dir_base, input_receiver_fn_map, assets_extra, as_text, checkpoint_path, strip_default_attrs)
    860             builder, input_receiver_fn_map, checkpoint_path,
    861             save_variables, mode=ModeKeys.PREDICT,
--> 862             strip_default_attrs=strip_default_attrs)
    863         save_variables = False
    864 

/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py in _add_meta_graph_for_mode(self, builder, input_receiver_fn_map, checkpoint_path, save_variables, mode, export_tags, check_variables, strip_default_attrs)
    967         if check_variables:
    968           try:
--> 969             graph_saver.restore(session, checkpoint_path)
    970           except errors.NotFoundError as e:
    971             msg = ('Could not load all requested variables from checkpoint. '

TypeError: restore() takes 2 positional arguments but 3 were given
```
"
38500,BatchNormalization with renorm=True doesn't work with TPU,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Colab
- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:
- **TensorFlow installed from (source or binary)**: Colab
- **TensorFlow version (use command below)**: Colab
- **Python version**: Colab
- **Bazel version (if compiling from source)**: Colab
- **GCC/Compiler version (if compiling from source)**: Colab
- **CUDA/cuDNN version**: Colab
- **GPU model and memory**: -
- **Exact command to reproduce**: See below

### Describe the problem
BatchNormalization with the argument renorm=True using TPUs in Colab produces an error. It seems to be a bug since the code below works with CPUs and GPUs.

### Source code / logs

# ----------------------- Full code to reproduce the error: -----------------------
import tensorflow as tf

# TPU stuff
tpu = tf.distribute.cluster_resolver.TPUClusterResolver()
tf.config.experimental_connect_to_cluster(tpu)
tf.tpu.experimental.initialize_tpu_system(tpu)
strategy = tf.distribute.experimental.TPUStrategy(tpu)

# Build the network
def build_model():
  from tensorflow.keras import Model
  from tensorflow.keras.layers import Dense, Input, BatchNormalization
  inputs = Input(1)
  x = inputs
  x = Dense(1)(x)
  x = BatchNormalization(renorm=True)(x)
  x = Dense(1, 'relu')(x)
  model = Model(inputs, x)
  return model

with strategy.scope():
  model = build_model()
  model.compile(loss='mse', optimizer='adam')


# --------------------------- Error log:
TypeError                                 Traceback (most recent call last)
<ipython-input-3-abb50f72a18a> in <module>()
     21 
     22 with strategy.scope():
---> 23   model = build_model()
     24   model.compile(loss='mse', optimizer='adam')

12 frames
<ipython-input-3-abb50f72a18a> in build_model()
     14   x = inputs
     15   x = Dense(1)(x)
---> 16   x = BatchNormalization(renorm=True)(x)
     17   x = Dense(1, 'relu')(x)
     18   model = Model(inputs, x)

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py in __call__(self, *args, **kwargs)
    920                     not base_layer_utils.is_in_eager_or_tf_function()):
    921                   with auto_control_deps.AutomaticControlDependencies() as acd:
--> 922                     outputs = call_fn(cast_inputs, *args, **kwargs)
    923                     # Wrap Tensors in `outputs` in `tf.identity` to avoid
    924                     # circular dependencies.

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/normalization.py in call(self, inputs, training)
    817       if self.renorm:
    818         r, d, new_mean, new_variance = self._renorm_correction_and_moments(
--> 819             new_mean, new_variance, training, inputs_size)
    820         # When training, the normalized values (say, x) will be transformed as
    821         # x * gamma + beta without renorm, and (x * r + d) * gamma + beta

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/normalization.py in _renorm_correction_and_moments(self, mean, variance, training, inputs_size)
    676     # TODO(yuefengz): colocate the operations
    677     update_new_mean = _update_renorm_variable(self.renorm_mean, mean,
--> 678                                               inputs_size)
    679     update_new_stddev = _update_renorm_variable(self.renorm_stddev, stddev,
    680                                                 inputs_size)

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/normalization.py in _update_renorm_variable(var, value, inputs_size)
    672       def _fake_update():
    673         return array_ops.identity(var)
--> 674       return tf_utils.smart_cond(training, _do_update, _fake_update)
    675 
    676     # TODO(yuefengz): colocate the operations

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/tf_utils.py in smart_cond(pred, true_fn, false_fn, name)
     63         pred, true_fn=true_fn, false_fn=false_fn, name=name)
     64   return smart_module.smart_cond(
---> 65       pred, true_fn=true_fn, false_fn=false_fn, name=name)
     66 
     67 

/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/smart_cond.py in smart_cond(pred, true_fn, false_fn, name)
     57   else:
     58     return control_flow_ops.cond(pred, true_fn=true_fn, false_fn=false_fn,
---> 59                                  name=name)
     60 
     61 

/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py in new_func(*args, **kwargs)
    505                 'in a future version' if date is None else ('after %s' % date),
    506                 instructions)
--> 507       return func(*args, **kwargs)
    508 
    509     doc = _add_deprecated_arg_notice_to_docstring(

/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_ops.py in cond(pred, true_fn, false_fn, strict, name, fn1, fn2)
   1175   if (util.EnableControlFlowV2(ops.get_default_graph()) and
   1176       not context.executing_eagerly()):
-> 1177     return cond_v2.cond_v2(pred, true_fn, false_fn, name)
   1178 
   1179   # We needed to make true_fn/false_fn keyword arguments for

/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/cond_v2.py in cond_v2(pred, true_fn, false_fn, name)
     99         false_graph.external_captures,
    100         building_gradient=False,
--> 101         name=scope)
    102 
    103 

/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/cond_v2.py in _build_cond(pred, true_graph, false_graph, true_inputs, false_inputs, building_gradient, name)
    219   """"""
    220   _make_indexed_slices_indices_types_match(_COND, [true_graph, false_graph])
--> 221   _check_same_outputs(_COND, [true_graph, false_graph])
    222 
    223   # Add inputs to true_graph and false_graph to make them match. Note that

/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/cond_v2.py in _check_same_outputs(op_type, graphs)
    799     for b0_out, bn_out in zip(graphs[0].outputs, graphs[b].outputs):
    800       if b0_out.dtype != bn_out.dtype:
--> 801         error(b, ""%s and %s have different types"" % (b0_out, bn_out))
    802 
    803 

/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/cond_v2.py in error(branch_idx, error_detail)
    777             b0_out=graphs[0].structured_outputs,
    778             bn_out=graphs[branch_idx].structured_outputs,
--> 779             detail=error_detail))
    780 
    781   for b in range(1, len(graphs)):

TypeError: true_fn and false_fn arguments to tf.cond must have the same number, type, and overall structure of return values.

true_fn output: Tensor(""Identity_1:0"", dtype=bool)
false_fn output: Tensor(""Identity_1:0"", shape=(1,), dtype=float32)

Error details:
Tensor(""Identity_1:0"", dtype=bool) and Tensor(""Identity_1:0"", shape=(1,), dtype=float32) have different types



"
38498,Currently logs param is None for on_train_end() and on_test_end(),"You can see the current implementation of `fit()` ([here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/engine/training.py#L950)) and `evaluate()` ([here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/engine/training.py#L1180)) methods that the logs passed to the methods `on_train_end()` and `on_test_end()` are None which is as per the documentation can be changed in future.  
In tensorflow/addons, There is addition of `TQDMProgressBar()` callback. And recently I have raised PR [#1649](https://github.com/tensorflow/addons/pull/1649) to add code to make progress bar work in case of `evaluate()` too.  
Here, we came across the problem that there are `logs` passed to `on_test_batch_end()` method to update the progress bar. But after the epoch is complete and when `on_test_end()` method is called, there are no `logs` passed to that. Because of this, there is no metrics results passed to the method. But in my opinion and also from @shun-lin's [#1649 (comment)](https://github.com/tensorflow/addons/pull/1649#issuecomment-612785521), it is good to pass logs which are output from the last call to `on_test_batch_end()` method. Currenly in tqdm callback, we are storing the `on_test_batch_end()` logs in class variable and using them in `on_test_end()`, which we think is temporary fix. 

cc @shun-lin, @gabrieldemarmiesse."
38496,hard_swish(x) layer in TFLM app crash,"@tensorflow/micro

**System information**
- Host OS Platform: Windows 10
- TensorFlow installed from pip
- Tensorflow version 2.1.0
- Target platform: Windows 10 (I debug this way)

**Describe the problem**
I converted mobilenet_v3to .tflite -> converted to .cc using xxd -i -> compiled app with cl.exe and got nullptr exception tflite::MicroInterpreter constructor.
If I replace hard_swish(x) layer with relu(x) - no error occurs
```
def relu(x):
    return layers.ReLU()(x)
def hard_sigmoid(x):
    return layers.ReLU(6.)(x + 3.) * (1. / 6.)
def hard_swish(x):
    return layers.Multiply()([layers.Activation(hard_sigmoid)(x), x])
    # return relu(x)
```


**Please provide the exact sequence of commands/steps when you ran into the problem**
I use this mobilenet_v3.py:  
https://drive.google.com/open?id=1FOj2p4mj-0VxWC-79uUlZExyrV9OHRJ2

this code to convert: 
```
def convertTFL(name, model):
    converter = tf.lite.TFLiteConverter.from_keras_model(model)
    converter.optimizations = [tf.lite.Optimize.DEFAULT]
    converter.representative_dataset = quantizationDataGenerator
    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]
    converter.inference_input_type = tf.int8
    converter.inference_output_type = tf.int8
    quantModel = converter.convert()

    with open(""{}.tflite"".format(name), ""wb"") as f:
        f.write(quantModel)

import mobilenet_v3
model = mobilenet_v3.MobileNetV3Small(
             input_shape=(IMAGE_SIDE, IMAGE_SIDE, 3),
             alpha=1.0,
             minimalistic=False,
             include_top=None, weights='imagenet', pooling=None
        )
convertTFL('mobilenetv3', model)
```


and this code for main.cc for TFLM app:
```
#include ""tensorflow/lite/micro/kernels/micro_ops.h""
#include ""tensorflow/lite/micro/micro_error_reporter.h""
#include ""tensorflow/lite/micro/micro_interpreter.h""
//#include ""tensorflow/lite/micro/micro_mutable_op_resolver.h""
#include ""tensorflow/lite/micro/kernels/all_ops_resolver.h""
#include ""tensorflow/lite/schema/schema_generated.h""
#include ""tensorflow/lite/version.h""

#define IMAGE_SIDE 224
#define IMAGE_SIZE ( 3 * IMAGE_SIDE * IMAGE_SIDE )
#define NUM_TEST_IMAGES 1 // 10 // 100

extern unsigned char modelBuffer[];

namespace {
    constexpr int kTensorArenaSize = 5000 * 1024;
    #pragma Bss("".tensor_arena"")
    static uint8_t tensor_arena[kTensorArenaSize];
    #pragma Bss()
}  // namespace


int main(){
     printf(""entered main()\n"");
    static tflite::MicroErrorReporter micro_error_reporter;
    tflite::ErrorReporter& error_reporter = micro_error_reporter;

    const tflite::Model* model = tflite::GetModel(modelBuffer);
    if (model->version() != TFLITE_SCHEMA_VERSION) {
        printf(""wrong version!!!\n"");
        return -1;
    }
    printf(""got model\n"");

    static tflite::MicroMutableOpResolver micro_mutable_op_resolver;
     printf(""after  MicroMutableOpResolver()\n"");

    micro_mutable_op_resolver.AddBuiltin(
        tflite::BuiltinOperator_DEPTHWISE_CONV_2D,
        tflite::ops::micro::Register_DEPTHWISE_CONV_2D(), 1, 3);

    micro_mutable_op_resolver.AddBuiltin(tflite::BuiltinOperator_CONV_2D,
                                        tflite::ops::micro::Register_CONV_2D(),
                                        1, 3);
                                        

    micro_mutable_op_resolver.AddBuiltin(tflite::BuiltinOperator_QUANTIZE,
                                        tflite::ops::micro::Register_QUANTIZE());


    micro_mutable_op_resolver.AddBuiltin(tflite::BuiltinOperator_DEQUANTIZE, tflite::ops::micro::Register_DEQUANTIZE(), 1, 2);

                                    
    micro_mutable_op_resolver.AddBuiltin(tflite::BuiltinOperator_PAD, tflite::ops::micro::Register_PAD(), 1, 2 );

    micro_mutable_op_resolver.AddBuiltin(tflite::BuiltinOperator_ADD, tflite::ops::micro::Register_ADD(), 1, 2 );


 printf(""before MicroInterpreter\n"");
    // Build an interpreter to run the model with.
    // NOLINTNEXTLINE(runtime-global-variables)
    static tflite::MicroInterpreter interpreter = tflite::MicroInterpreter(
        model, micro_mutable_op_resolver, tensor_arena, kTensorArenaSize,
        &error_reporter);
        printf(""after MicroInterpreter\n"");

    // Allocate memory from the tensor_arena for the model's tensors.
     printf(""before AllocateTensors()\n"");
    TfLiteStatus allocate_status = interpreter.AllocateTensors();
    if (allocate_status != kTfLiteOk) {
        error_reporter.Report(""AllocateTensors() failed"");
        return -1;
    }
    printf(""after AllocateTensors()\n"");

    TfLiteTensor* input = interpreter.input(0);
    TfLiteTensor* output = interpreter.output(0);
    return 0;
}

```
"
38495,Outputs Nan of inf with auto mixed precision,"I use a three-tier full connection network to train a DQN (reinforcement learning) agent. The code like this

```
def observation_to_action(states):
    # define policy neural network
    W1 = tf.get_variable(""W1"", [state_dim, 300], initializer=tf.random_normal_initializer())
    b1 = tf.get_variable(""b1"", [300], initializer=tf.constant_initializer(0))
    h1 = tf.nn.relu(tf.matmul(states, W1) + b1)

    W2 = tf.get_variable(""W2"", [300, 300], initializer=tf.random_normal_initializer())
    b2 = tf.get_variable(""b2"", [300], initializer=tf.constant_initializer(0))
    h2 = tf.nn.relu(tf.matmul(h1, W2) + b2)

    W3 = tf.get_variable(""W3"", [300, 300], initializer=tf.random_normal_initializer())
    b3 = tf.get_variable(""b3"", [300], initializer=tf.constant_initializer(0))
    h3 = tf.nn.relu(tf.matmul(h2, W3) + b3)

    Wn = tf.get_variable(""Wn"", [300, num_actions], initializer=tf.random_normal_initializer())
    bn = tf.get_variable(""bn"", [num_actions], initializer=tf.constant_initializer(0))
    q = tf.matmul(h3, Wn) + bn
    return q
```

Then automatic mixed precision can be enabled by this 

```
opt = tf.train.AdamOptimizer()
opt = tf.train.experimental.enable_mixed_precision_graph_rewrite(opt)
train_op = opt.minimize(loss)
```

The log indicates that the mixed precision has been used

```
2020-04-13 09:56:57.471656: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1816] Running auto_mixed_precision graph optimizer
2020-04-13 09:56:57.472372: I tensorflow/core/grappler/optimizers/auto_mixed_precision.cc:1772] Converted 16/44 nodes to float16 precision using 1 cast(s) to float16 (excluding Const and Variable casts)
```

But the output of the network, q, is Nan or inf. Is this normal? I want to train a DQN agent, if the output Q-value is nan or inf, it can't choose a best action to act. As a result, it can't be trained. I think the output may overflow the range of FP16( $ 2^{-24} $ ~65504). How can I train a reinforcement learning agent with auto mixed precision. Besides this, I also try to use mix precision manually by following codes

```
def observation_to_action(states):
    # define policy neural network
    W1 = tf.get_variable(""W1"", [state_dim, 256], initializer=tf.random_normal_initializer())
    b1 = tf.get_variable(""b1"", [256], initializer=tf.constant_initializer(0))
    h1 = tf.nn.relu(tf.cast(tf.matmul(tf.cast(states, tf.float16), tf.cast(W1, tf.float16)), tf.float32) + tf.cast(b1, tf.float32))

    W2 = tf.get_variable(""W2"", [256, 256], initializer=tf.random_normal_initializer())
    b2 = tf.get_variable(""b2"", [256], initializer=tf.constant_initializer(0))
    h2 = tf.nn.relu(tf.cast(tf.matmul(tf.cast(h1, tf.float16), tf.cast(W2, tf.float16)), tf.float32) + tf.cast(b2, tf.float32))

    W3 = tf.get_variable(""W3"", [256, 256], initializer=tf.random_normal_initializer())
    b3 = tf.get_variable(""b3"", [256], initializer=tf.constant_initializer(0))
    h3 = tf.nn.relu(tf.cast(tf.matmul(tf.cast(h2, tf.float16), tf.cast(W3, tf.float16)), tf.float32) + tf.cast(b3, tf.float32))


    Wn = tf.get_variable(""Wn"", [256, num_actions], initializer=tf.random_normal_initializer())
    bn = tf.get_variable(""bn"", [num_actions], initializer=tf.constant_initializer(0))
    q = tf.cast(tf.matmul(tf.cast(h3, tf.float16), tf.cast(Wn, tf.float16)), tf.float32) + tf.cast(bn, tf.float32)

    return q
```

But it's outputs are Nan or inf too. Thank you very much.





Ubuntu 18.04.3 LTS x86_64

Tesla V100    Driver Version: 435.21       CUDA Version: 10.0"
38494,Coredump in tensorflow 1.12.0,"```
Corefile information as follow:
#0  0x00007fb46bf905f7 in raise () from /lib64/libc.so.6
#1  0x00007fb46bf91ce8 in abort () from /lib64/libc.so.6
#2  0x00007fb46bfd0317 in __libc_message () from /lib64/libc.so.6
#3  0x00007fb46bfd8023 in _int_free () from /lib64/libc.so.6
#4  0x00007fb3dd81616b in std::_Function_base::_Base_manager<std::_Bind<std::_Mem_fn<void (tensorflow::(anonymous namespace)::ExecutorState::*)(tensorflow::(anonymous namespace)::ExecutorState::TaggedNode, long long)> (tensorflow::(anonymous namespace)::ExecutorState*, tensorflow::(anonymous namespace)::ExecutorState::TaggedNode, long long)> >::_M_manager(std::_Any_data&, std::_Any_data const&, std::_Manager_operation) () from /opt/anaconda2/lib/python2.7/site-packages/tensorflow/python/../libtensorflow_framework.so
#5  0x00007fb3dd89254d in Eigen::NonBlockingThreadPoolTempl<tensorflow::thread::EigenEnvironment>::WorkerLoop(int) () from /opt/anaconda2/lib/python2.7/site-packages/tensorflow/python/../libtensorflow_framework.so
#6  0x00007fb3dd891582 in std::_Function_handler<void (), tensorflow::thread::EigenEnvironment::CreateThread(std::function<void ()>)::{lambda()#1}>::_M_invoke(std::_Any_data const&) () from /opt/anaconda2/lib/python2.7/site-packages/tensorflow/python/../libtensorflow_framework.so
#7  0x00007fb3dcdaf220 in ?? () from /lib64/libstdc++.so.6
#8  0x00007fb46ca2cdc5 in start_thread () from /lib64/libpthread.so.0
#9  0x00007fb46c05129d in clone () from /lib64/libc.so.6
```

**System information** 
- Python 2.7
- CentOS 
- Tensorflow 1.12.0
- TensorFlow installed from: tensorflow-1.12.0-cp27-cp27mu-manylinux1_x86_64.whl
- GCC 4.8.5

Has anyone ever been faced with same issue?
"
38492,depends on @local_config_cc//:cc-compiler-x64_windows in repository @local_config_cc which failed to fetch. no such package ,"bazel build :hello_main
INFO: Call stack for the definition of repository 'local_config_cc' which is a cc_autoconf (rule definition at C:/users/administrator/_bazel_administrator/gtw4qbxk/external/bazel_tools/tools/cpp/cc_configure.bzl:143:15):
 - <builtin>
 - C:/users/administrator/_bazel_administrator/gtw4qbxk/external/bazel_tools/tools/cpp/cc_configure.bzl:179:5
 - /DEFAULT.WORKSPACE.SUFFIX:317:1
ERROR: An error occurred during the fetch of repository 'local_config_cc':
   Traceback (most recent call last):
        File ""C:/users/administrator/_bazel_administrator/gtw4qbxk/external/bazel_tools/tools/cpp/cc_configure.bzl"", line 120
                configure_windows_toolchain(<1 more arguments>)
        File ""C:/users/administrator/_bazel_administrator/gtw4qbxk/external/bazel_tools/tools/cpp/windows_cc_configure.bzl"", line 690, in configure_windows_toolchain
                _get_msvc_vars(repository_ctx, <1 more arguments>)
        File ""C:/users/administrator/_bazel_administrator/gtw4qbxk/external/bazel_tools/tools/cpp/windows_cc_configure.bzl"", line 503, in _get_msvc_vars
                _find_missing_vc_tools(<2 more arguments>)
        File ""C:/users/administrator/_bazel_administrator/gtw4qbxk/external/bazel_tools/tools/cpp/windows_cc_configure.bzl"", line 387, in _find_missing_vc_tools
                find_msvc_tool(repository_ctx, <2 more arguments>)
        File ""C:/users/administrator/_bazel_administrator/gtw4qbxk/external/bazel_tools/tools/cpp/windows_cc_configure.bzl"", line 367, in find_msvc_tool
                _get_vc_full_version(<2 more arguments>)
        File ""C:/users/administrator/_bazel_administrator/gtw4qbxk/external/bazel_tools/tools/cpp/windows_cc_configure.bzl"", line 357, in _get_vc_full_version
                _get_latest_subversion(<2 more arguments>)
        File ""C:/users/administrator/_bazel_administrator/gtw4qbxk/external/bazel_tools/tools/cpp/windows_cc_configure.bzl"", line 336, in _get_latest_subversion
                repository_ctx.path((vc_path + ""\\Tools\\MSVC"")).readdir()
C:/Program Files (x86)/Microsoft Visual Studio/2019/Professional/VC/Tools/MSVC (No such file or directory)
ERROR: E:/tensorflow/02/BUILD:8:1: //:hello_main depends on @local_config_cc//:cc-compiler-x64_windows in repository @local_config_cc which failed to fetch. no such package '@local_config_cc//': Traceback (most recent call last):
        File ""C:/users/administrator/_bazel_administrator/gtw4qbxk/external/bazel_tools/tools/cpp/cc_configure.bzl"", line 120
                configure_windows_toolchain(<1 more arguments>)
        File ""C:/users/administrator/_bazel_administrator/gtw4qbxk/external/bazel_tools/tools/cpp/windows_cc_configure.bzl"", line 690, in configure_windows_toolchain
                _get_msvc_vars(repository_ctx, <1 more arguments>)
        File ""C:/users/administrator/_bazel_administrator/gtw4qbxk/external/bazel_tools/tools/cpp/windows_cc_configure.bzl"", line 503, in _get_msvc_vars
                _find_missing_vc_tools(<2 more arguments>)
        File ""C:/users/administrator/_bazel_administrator/gtw4qbxk/external/bazel_tools/tools/cpp/windows_cc_configure.bzl"", line 387, in _find_missing_vc_tools
                find_msvc_tool(repository_ctx, <2 more arguments>)
        File ""C:/users/administrator/_bazel_administrator/gtw4qbxk/external/bazel_tools/tools/cpp/windows_cc_configure.bzl"", line 367, in find_msvc_tool
                _get_vc_full_version(<2 more arguments>)
        File ""C:/users/administrator/_bazel_administrator/gtw4qbxk/external/bazel_tools/tools/cpp/windows_cc_configure.bzl"", line 357, in _get_vc_full_version
                _get_latest_subversion(<2 more arguments>)
        File ""C:/users/administrator/_bazel_administrator/gtw4qbxk/external/bazel_tools/tools/cpp/windows_cc_configure.bzl"", line 336, in _get_latest_subversion
                repository_ctx.path((vc_path + ""\\Tools\\MSVC"")).readdir()
C:/Program Files (x86)/Microsoft Visual Studio/2019/Professional/VC/Tools/MSVC (No such file or directory)
ERROR: Analysis of target '//:hello_main' failed; build aborted: no such package '@local_config_cc//': Traceback (most recent call last):  
        File ""C:/users/administrator/_bazel_administrator/gtw4qbxk/external/bazel_tools/tools/cpp/cc_configure.bzl"", line 120
                configure_windows_toolchain(<1 more arguments>)
        File ""C:/users/administrator/_bazel_administrator/gtw4qbxk/external/bazel_tools/tools/cpp/windows_cc_configure.bzl"", line 690, in configure_windows_toolchain
        File ""C:/users/administrator/_bazel_administrator/gtw4qbxk/external/bazel_tools/tools/cpp/windows_cc_configure.bzl"", line 503, in _                _find_missing_vc_tools(<2 more arguments>)
        File ""C:/users/administrator/_bazel_administrator/gtw4qbxk/external/bazel_tools/tools/cpp/windows_cc_configure.bzl"", line 387, in _find_missing_vc_tools
                find_msvc_tool(repository_ctx, <2 more arguments>)
        File ""C:/users/administrator/_bazel_administrator/gtw4qbxk/external/bazel_tools/tools/cpp/windows_cc_configure.bzl"", line 367, in find_msvc_tool
                _get_vc_full_version(<2 more arguments>)
        File ""C:/users/administrator/_bazel_administrator/gtw4qbxk/external/bazel_tools/tools/cpp/windows_cc_configure.bzl"", line 357, in _get_vc_full_version
                _get_latest_subversion(<2 more arguments>)
        File ""C:/users/administrator/_bazel_administrator/gtw4qbxk/external/bazel_tools/tools/cpp/windows_cc_configure.bzl"", line 336, in _get_latest_subversion
                repository_ctx.path((vc_path + ""\\Tools\\MSVC"")).readdir()
C:/Program Files (x86)/Microsoft Visual Studio/2019/Professional/VC/Tools/MSVC (No such file or directory)
INFO: Elapsed time: 1.231s
INFO: 0 processes.
FAILED: Build did NOT complete successfully (0 packages loaded, 0 targets configured)
PS E:\TensorFlow\02> bazel clean --expunge
INFO: Starting clean.
PS E:\TensorFlow\02> bazel build :hello_main
Starting local Bazel server and connecting to it...
INFO: Call stack for the definition of repository 'local_config_cc' which is a cc_autoconf (rule definition at C:/users/administrator/_bazel_administrator/gtw4qbxk/external/bazel_tools/tools/cpp/cc_configure.bzl:143:15):
 - <builtin>
 - C:/users/administrator/_bazel_administrator/gtw4qbxk/external/bazel_tools/tools/cpp/cc_configure.bzl:179:5
 - /DEFAULT.WORKSPACE.SUFFIX:317:1
ERROR: An error occurred during the fetch of repository 'local_config_cc':
   Traceback (most recent call last):
        File ""C:/users/administrator/_bazel_administrator/gtw4qbxk/external/bazel_tools/tools/cpp/cc_configure.bzl"", line 120
                configure_windows_toolchain(<1 more arguments>)
        File ""C:/users/administrator/_bazel_administrator/gtw4qbxk/external/bazel_tools/tools/cpp/windows_cc_configure.bzl"", line 690, in configure_windows_toolchain
                _get_msvc_vars(repository_ctx, <1 more arguments>)
        File ""C:/users/administrator/_bazel_administrator/gtw4qbxk/external/bazel_tools/tools/cpp/windows_cc_configure.bzl"", line 503, in _get_msvc_vars
                _find_missing_vc_tools(<2 more arguments>)
        File ""C:/users/administrator/_bazel_administrator/gtw4qbxk/external/bazel_tools/tools/cpp/windows_cc_configure.bzl"", line 387, in _find_missing_vc_tools
                find_msvc_tool(repository_ctx, <2 more arguments>)
        File ""C:/users/administrator/_bazel_administrator/gtw4qbxk/external/bazel_tools/tools/cpp/windows_cc_configure.bzl"", line 367, in find_msvc_tool
                _get_vc_full_version(<2 more arguments>)
        File ""C:/users/administrator/_bazel_administrator/gtw4qbxk/external/bazel_tools/tools/cpp/windows_cc_configure.bzl"", line 357, in _get_vc_full_version
                _get_latest_subversion(<2 more arguments>)
        File ""C:/users/administrator/_bazel_administrator/gtw4qbxk/external/bazel_tools/tools/cpp/windows_cc_configure.bzl"", line 336, in _get_latest_subversion
                repository_ctx.path((vc_path + ""\\Tools\\MSVC"")).readdir()
C:/Program Files (x86)/Microsoft Visual Studio/2019/Professional/VC/Tools/MSVC (No such file or directory)
ERROR: E:/tensorflow/02/BUILD:8:1: //:hello_main depends on @local_config_cc//:cc-compiler-x64_windows in repository @local_config_cc which failed to fetch. no such package '@local_config_cc//': Traceback (most recent call last):
        File ""C:/users/administrator/_bazel_administrator/gtw4qbxk/external/bazel_tools/tools/cpp/cc_configure.bzl"", line 120
                configure_windows_toolchain(<1 more arguments>)
        File ""C:/users/administrator/_bazel_administrator/gtw4qbxk/external/bazel_tools/tools/cpp/windows_cc_configure.bzl"", line 690, in configure_windows_toolchain
                _get_msvc_vars(repository_ctx, <1 more arguments>)
        File ""C:/users/administrator/_bazel_administrator/gtw4qbxk/external/bazel_tools/tools/cpp/windows_cc_configure.bzl"", line 503, in _get_msvc_vars
                _find_missing_vc_tools(<2 more arguments>)
        File ""C:/users/administrator/_bazel_administrator/gtw4qbxk/external/bazel_tools/tools/cpp/windows_cc_configure.bzl"", line 387, in _find_missing_vc_tools
                find_msvc_tool(repository_ctx, <2 more arguments>)
        File ""C:/users/administrator/_bazel_administrator/gtw4qbxk/external/bazel_tools/tools/cpp/windows_cc_configure.bzl"", line 367, in find_msvc_tool
                _get_vc_full_version(<2 more arguments>)
        File ""C:/users/administrator/_bazel_administrator/gtw4qbxk/external/bazel_tools/tools/cpp/windows_cc_configure.bzl"", line 357, in _get_vc_full_version
                _get_latest_subversion(<2 more arguments>)
        File ""C:/users/administrator/_bazel_administrator/gtw4qbxk/external/bazel_tools/tools/cpp/windows_cc_configure.bzl"", line 336, in _get_latest_subversion
                repository_ctx.path((vc_path + ""\\Tools\\MSVC"")).readdir()
C:/Program Files (x86)/Microsoft Visual Studio/2019/Professional/VC/Tools/MSVC (No such file or directory)
ERROR: Analysis of target '//:hello_main' failed; build aborted: no such package '@local_config_cc//': Traceback (most recent call last):  
        File ""C:/users/administrator/_bazel_administrator/gtw4qbxk/external/bazel_tools/tools/cpp/cc_configure.bzl"", line 120
                configure_windows_toolchain(<1 more arguments>)
        File ""C:/users/administrator/_bazel_administrator/gtw4qbxk/external/bazel_tools/tools/cpp/windows_cc_configure.bzl"", line 690, in configure_windows_toolchain
        File ""C:/users/administrator/_bazel_administrator/gtw4qbxk/external/bazel_tools/tools/cpp/windows_cc_configure.bzl"", line 503, in _get_msvc_vars
                _find_missing_vc_tools(<2 more arguments>)
        File ""C:/users/administrator/_bazel_administrator/gtw4qbxk/external/bazel_tools/tools/cpp/windows_cc_configure.bzl"", line 387, in _find_missing_vc_tools
                find_msvc_tool(repository_ctx, <2 more arguments>)
        File ""C:/users/administrator/_bazel_administrator/gtw4qbxk/external/bazel_tools/tools/cpp/windows_cc_configure.bzl"", line 367, in find_msvc_tool
                _get_vc_full_version(<2 more arguments>)
        File ""C:/users/administrator/_bazel_administrator/gtw4qbxk/external/bazel_tools/tools/cpp/windows_cc_configure.bzl"", line 357, in _get_vc_full_version
                _get_latest_subversion(<2 more arguments>)
        File ""C:/users/administrator/_bazel_administrator/gtw4qbxk/external/bazel_tools/tools/cpp/windows_cc_configure.bzl"", line 336, in _get_latest_subversion
                repository_ctx.path((vc_path + ""\\Tools\\MSVC"")).readdir()
C:/Program Files (x86)/Microsoft Visual Studio/2019/Professional/VC/Tools/MSVC (No such file or directory)
INFO: Elapsed time: 7.744s
INFO: 0 processes.
FAILED: Build did NOT complete successfully (12 packages loaded, 18 targets configured)
PS E:\TensorFlow\02> bazel
                                                           [bazel release 3.0.0]
Usage: bazel <command> <options> ...

Available commands:
  analyze-profile     Analyzes build profile data.
  aquery              Analyzes the given targets and queries the action graph.
  build               Builds the specified targets.
  canonicalize-flags  Canonicalizes a list of bazel options.
  clean               Removes output files and optionally stops the server.
  coverage            Generates code coverage report for specified test targets.
  cquery              Loads, analyzes, and queries the specified targets w/ configurations.
  dump                Dumps the internal state of the bazel server process.
  fetch               Fetches external repositories that are prerequisites to the targets.
  help                Prints help for commands, or the index.
  license             Prints the license of this software.
  mobile-install      Installs targets to mobile devices.
  print_action        Prints the command line args for compiling a file.
  query               Executes a dependency graph query.
  run                 Runs the specified target.
  shutdown            Stops the bazel server.
  sync                Syncs all repositories specified in the workspace file
  test                Builds and runs the specified test targets.
  version             Prints version information for bazel.

Getting more help:
  bazel help <command>
                   Prints help and options for <command>.
  bazel help startup_options
                   Options for the JVM hosting bazel.
  bazel help target-syntax
                   Explains the syntax for specifying targets.
  bazel help info-keys
                   Displays a list of keys used by the info command.
PS E:\TensorFlow\02> bazel version
Build label: 3.0.0
Build target: bazel-out/x64_windows-opt/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Mon Apr 6 12:56:01 2020 (1586177761)
Build timestamp: 1586177761
Build timestamp as int: 1586177761
PS E:\TensorFlow\02> "
38491,ERROR: Config value download_clang is not defined in any .rc file,"tensorflow：r2.2
bazel         ：2.0.0

ERROR: Config value download_clang is not defined in any .rc file

print info：
`bazel build -c opt //tensorflow/contrib/android:libtensorflow_inference.so  --crosstool_top=//external:android/crosstool  --host_crosstool_top=@bazel_tools//tools/cpp:toolchain  --cpu=armeabi-v7a
INFO: Options provided by the client:
  Inherited 'common' options: --isatty=1 --terminal_columns=80
INFO: Reading rc options for 'build' from /home/wushengqi/ai/tensorflow/.bazelrc:
  Inherited 'common' options: --experimental_repo_remote_exec
INFO: Reading rc options for 'build' from /home/wushengqi/ai/tensorflow/.bazelrc:
  'build' options: --apple_platform_type=macos --define framework_shared_object=true --define open_source_build=true --java_toolchain=//third_party/toolchains/java:tf_java_toolchain --host_java_toolchain=//third_party/toolchains/java:tf_java_toolchain --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --noincompatible_prohibit_aapt1 --enable_platform_specific_config --config=v2
INFO: Reading rc options for 'build' from /home/wushengqi/ai/tensorflow/.tf_configure.bazelrc:
  'build' options: --action_env PYTHON_BIN_PATH=/home/wushengqi/anaconda3/bin/python --action_env PYTHON_LIB_PATH=/home/wushengqi/anaconda3/lib/python3.7/site-packages --python_path=/home/wushengqi/anaconda3/bin/python --config=xla --config=rocm --config=download_clang --action_env ANDROID_NDK_HOME=/home/wushengqi/android/android-ndk-r14b --action_env ANDROID_NDK_API_LEVEL=19 --action_env ANDROID_BUILD_TOOLS_VERSION=29.0.2 --action_env ANDROID_SDK_API_LEVEL=29 --action_env ANDROID_SDK_HOME=/home/wushengqi/android/Sdk --action_env TF_CONFIGURE_IOS=0
INFO: Found applicable config definition build:v2 in file /home/wushengqi/ai/tensorflow/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1
INFO: Found applicable config definition build:xla in file /home/wushengqi/ai/tensorflow/.bazelrc: --action_env=TF_ENABLE_XLA=1 --define=with_xla_support=true
INFO: Found applicable config definition build:rocm in file /home/wushengqi/ai/tensorflow/.bazelrc: --crosstool_top=@local_config_rocm//crosstool:toolchain --define=using_rocm=true --define=using_rocm_hipcc=true --action_env TF_NEED_ROCM=1
ERROR: Config value download_clang is not defined in any .rc file
`

If I'm using a lower version of bazel（1.2.1）：
`bazel build -c opt //tensorflow/contrib/android:libtensorflow_inference.so  --crosstool_top=//external:android/crosstool  --host_crosstool_top=@bazel_tools//tools/cpp:toolchain  --cpu=armeabi-v7a
INFO: Options provided by the client:
  Inherited 'common' options: --isatty=1 --terminal_columns=80
INFO: Reading rc options for 'build' from /home/wushengqi/ai/tensorflow/.bazelrc:
  Inherited 'common' options: --experimental_repo_remote_exec
ERROR: Unrecognized option: --experimental_repo_remote_exec
`"
38490,problem with keras.applications models if pooling != None,"@tensorflow/micro

**System information**
- Host OS Platform: Windows 10
- TensorFlow installed from pip
- Tensorflow version: 2.1.0
- Target platform: windows 10 ( I debug this way)

**Describe the problem**
I want to convert following model:
```
        model = tf.keras.applications.mobilenet_v2.MobileNetV2(
            input_shape=(IMAGE_SIDE, IMAGE_SIDE, 3), alpha=0.35,
            include_top=False, weights='imagenet', pooling=None
        )
```
If I use If I use `pooling=None` - no problems 
If I use `pooling='avg'` I got problems when compiling app with TFLM kernels:
Didn't find op for builtin opcode 'MEAN' version '2'
If I use  `pooling='max'` I got problem with conversion: 
RuntimeError: Quantization not yet supported for op: REDUCE_MAX


**Please provide the exact sequence of commands/steps when you ran into the problem**
I use this conversion code:
```
def convertTFL(name, model):
    converter = tf.lite.TFLiteConverter.from_keras_model(model)
    converter.optimizations = [tf.lite.Optimize.DEFAULT]
    converter.representative_dataset = quantizationDataGenerator
    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]
    converter.inference_input_type = tf.int8
    converter.inference_output_type = tf.int8
    quantModel = converter.convert()

    with open(""{}.tflite"".format(name), ""wb"") as f:
        f.write(quantModel)
```
After that I got .cc file by using 'xxd -i' and compile following main.cc  with cl.exe 
```
#include ""tensorflow/lite/micro/kernels/micro_ops.h""
#include ""tensorflow/lite/micro/micro_error_reporter.h""
#include ""tensorflow/lite/micro/micro_interpreter.h""
//#include ""tensorflow/lite/micro/micro_mutable_op_resolver.h""
#include ""tensorflow/lite/micro/kernels/all_ops_resolver.h""
#include ""tensorflow/lite/schema/schema_generated.h""
#include ""tensorflow/lite/version.h""

#define IMAGE_SIDE 224
#define IMAGE_SIZE ( 3 * IMAGE_SIDE * IMAGE_SIDE )
#define NUM_TEST_IMAGES 1 // 10 // 100

extern unsigned char modelBuffer[];

namespace {
    constexpr int kTensorArenaSize = 5000 * 1024;
    #pragma Bss("".tensor_arena"")
    static uint8_t tensor_arena[kTensorArenaSize];
    #pragma Bss()
}  // namespace

int main(){
     printf(""entered main()\n"");
    static tflite::MicroErrorReporter micro_error_reporter;
    tflite::ErrorReporter& error_reporter = micro_error_reporter;

    const tflite::Model* model = tflite::GetModel(modelBuffer);
    if (model->version() != TFLITE_SCHEMA_VERSION) {
        printf(""wrong version!!!\n"");
        return -1;
    }
    printf(""got model\n"");

    static tflite::MicroMutableOpResolver micro_mutable_op_resolver;
     printf(""after  MicroMutableOpResolver()\n"");

    micro_mutable_op_resolver.AddBuiltin(
        tflite::BuiltinOperator_DEPTHWISE_CONV_2D,
        tflite::ops::micro::Register_DEPTHWISE_CONV_2D(), 1, 3);

    micro_mutable_op_resolver.AddBuiltin(tflite::BuiltinOperator_CONV_2D,
                                        tflite::ops::micro::Register_CONV_2D(),
                                        1, 3);
                                        

    micro_mutable_op_resolver.AddBuiltin(tflite::BuiltinOperator_QUANTIZE,
                                        tflite::ops::micro::Register_QUANTIZE());


    micro_mutable_op_resolver.AddBuiltin(tflite::BuiltinOperator_DEQUANTIZE, tflite::ops::micro::Register_DEQUANTIZE(), 1, 2);

                                    
    micro_mutable_op_resolver.AddBuiltin(tflite::BuiltinOperator_PAD, tflite::ops::micro::Register_PAD(), 1, 2 );

    micro_mutable_op_resolver.AddBuiltin(tflite::BuiltinOperator_ADD, tflite::ops::micro::Register_ADD(), 1, 2 );


 printf(""before MicroInterpreter\n"");
    // Build an interpreter to run the model with.
    // NOLINTNEXTLINE(runtime-global-variables)
    static tflite::MicroInterpreter interpreter = tflite::MicroInterpreter(
        model, micro_mutable_op_resolver, tensor_arena, kTensorArenaSize,
        &error_reporter);
        printf(""after MicroInterpreter\n"");

    // Allocate memory from the tensor_arena for the model's tensors.
     printf(""before AllocateTensors()\n"");
    TfLiteStatus allocate_status = interpreter.AllocateTensors();
    if (allocate_status != kTfLiteOk) {
        error_reporter.Report(""AllocateTensors() failed"");
        return -1;
    }
    printf(""after AllocateTensors()\n"");


    TfLiteTensor* input = interpreter.input(0);
    TfLiteTensor* output = interpreter.output(0);

    return 0;
}
```
"
38489,How to explain the result of tf.map_fn?,"```
item_map = {223368: 2, 227300: 3}
i =tf.reshape([223368,223368], [-1, ])
o1 = tf.map_fn(lambda x: item_map.get(x, 0),i)
o2 = tf.map_fn(lambda x: item_map.get(223368, 0), i)
o3 = tf.map_fn(lambda x:x, i)
with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())
    print(i.eval())  #输出[223368 223368]
    print(o1.eval()) #输出[0 0]
    print(o2.eval()) #输出[2 2]
    print(o3.eval()) #输出[223368 223368]
```
why o1 is [0,0]?"
38488,Didn't find op for builtin opcode 'QUANTIZE' version '2',"@tensorflow/micro

**System information**
- Windows 10
- tensorflow install from pip
- tensorflow:  2.1.0
- traget platform : I run simply on windows

**Describe the problem**
I made app like one in examples and during call interpreter.AllocateTensors() I got this:
Didn't   find op for builtin opcode 'QUANTIZE' version '2'

**Please provide the exact sequence of commands/steps when you ran into the problem**
I got this message for two models:
NASNet-A
```
model = tf.keras.applications.nasnet.NASNetMobile(
            input_shape=(224, 224, 3), 
            include_top=None, weights='imagenet', pooling=None
        )
```
SquezeNetv1.1
https://drive.google.com/open?id=1_A87NVmu_jRJ1ltSTR2iKffEgBGhargS
( I shared heras h5 saved model)

I convert with following code:
```
    converter = tf.lite.TFLiteConverter.from_keras_model(model)
    converter.optimizations = [tf.lite.Optimize.DEFAULT]
    converter.representative_dataset = quantizationDataGenerator
    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]
    converter.inference_input_type = tf.int8
    converter.inference_output_type = tf.int8
    quantModel = converter.convert()
```

get cc file with 'xxd -i ' and make application with following main.cpp.
I use cl.exe compiler and run under windows 10.

```
#include ""tensorflow/lite/micro/kernels/micro_ops.h""
#include ""tensorflow/lite/micro/micro_error_reporter.h""
#include ""tensorflow/lite/micro/micro_interpreter.h""
//#include ""tensorflow/lite/micro/micro_mutable_op_resolver.h""
#include ""tensorflow/lite/micro/kernels/all_ops_resolver.h""
#include ""tensorflow/lite/schema/schema_generated.h""
#include ""tensorflow/lite/version.h""

#define IMAGE_SIDE 224
#define IMAGE_SIZE ( 3 * IMAGE_SIDE * IMAGE_SIDE )
#define NUM_TEST_IMAGES 1 // 10 // 100

extern unsigned char modelBuffer[];

namespace {
    constexpr int kTensorArenaSize = 5000 * 1024;
    #pragma Bss("".tensor_arena"")
    static uint8_t tensor_arena[kTensorArenaSize];
    #pragma Bss()
}  // namespace

int main(){
     printf(""entered main()\n"");
    static tflite::MicroErrorReporter micro_error_reporter;
    tflite::ErrorReporter& error_reporter = micro_error_reporter;

    const tflite::Model* model = tflite::GetModel(modelBuffer);
    if (model->version() != TFLITE_SCHEMA_VERSION) {
        printf(""wrong version!!!\n"");
        return -1;
    }
    printf(""got model\n"");

    static tflite::MicroMutableOpResolver micro_mutable_op_resolver;
     printf(""after  MicroMutableOpResolver()\n"");

    micro_mutable_op_resolver.AddBuiltin(
        tflite::BuiltinOperator_DEPTHWISE_CONV_2D,
        tflite::ops::micro::Register_DEPTHWISE_CONV_2D(), 1, 3);

    micro_mutable_op_resolver.AddBuiltin(tflite::BuiltinOperator_CONV_2D,
                                        tflite::ops::micro::Register_CONV_2D(),
                                        1, 3);
                                        

    micro_mutable_op_resolver.AddBuiltin(tflite::BuiltinOperator_QUANTIZE,
                                        tflite::ops::micro::Register_QUANTIZE());


    micro_mutable_op_resolver.AddBuiltin(tflite::BuiltinOperator_DEQUANTIZE, tflite::ops::micro::Register_DEQUANTIZE(), 1, 2);

                                    
    micro_mutable_op_resolver.AddBuiltin(tflite::BuiltinOperator_PAD, tflite::ops::micro::Register_PAD(), 1, 2 );

    micro_mutable_op_resolver.AddBuiltin(tflite::BuiltinOperator_ADD, tflite::ops::micro::Register_ADD(), 1, 2 );


 printf(""before MicroInterpreter\n"");
    // Build an interpreter to run the model with.
    // NOLINTNEXTLINE(runtime-global-variables)
    static tflite::MicroInterpreter interpreter = tflite::MicroInterpreter(
        model, micro_mutable_op_resolver, tensor_arena, kTensorArenaSize,
        &error_reporter);
        printf(""after MicroInterpreter\n"");

    // Allocate memory from the tensor_arena for the model's tensors.
     printf(""before AllocateTensors()\n"");
    TfLiteStatus allocate_status = interpreter.AllocateTensors();
    if (allocate_status != kTfLiteOk) {
        error_reporter.Report(""AllocateTensors() failed"");
        return -1;
    }
    printf(""after AllocateTensors()\n"");

    TfLiteTensor* input = interpreter.input(0);
    TfLiteTensor* output = interpreter.output(0);

    FILE * xfd = fopen( ""x-cifar-nasnet-100.cc"",""rb"");
    for (int i = 0; i < NUM_TEST_IMAGES; i++){
        fread(input->data.f, sizeof(float), IMAGE_SIZE, xfd);
        for (int i = 0; i < 100; i++) printf(""%.3f "", input->data.f[i]);

        if (kTfLiteOk != interpreter.Invoke()) {
            error_reporter.Report(""Invoke failed."");
            return -1;
        } 
        printf(""--------------\n"");
        for (int i = 0; i < 100; i++) printf(""%.3f "", output->data.f[i]);
        printf(""==============\n"");
    }
    fclose(xfd);

    return 0;
}


"
38487,cannot install tensorflow 1.14.0 using pip,"trying to install tensorflow==1.14.0 using pip but it is showing this error
ERROR: Could not find a version that satisfies the requirement tensorflow==1.14 (from versions: 2.2.0rc1, 2.2.0rc2)                                                                                                 
ERROR: No matching distribution found for tensorflow==1.14"
38486,tf/keras model.fit training accuracy doesn't match model.predict() accuracy on training data despite having only one training batch,"**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04): Mac OS Catalina
- TensorFlow installed from (source or
binary): I tried both - The issue persists regardless
- TensorFlow version (use command below):'2.1.0'
keras version '2.2.4-tf'
- Python version: 3.7.7

**Describe the current behavior**
When I fine tune a pre-trained resnet using tensorflow.keras.applications.ResNet50, the accuracy shown in training does not match the accuracy of using predict on the same training data, despite the batch size being the size of the entire training set (i.e. only one batch per epoch).

I did my due diligence researching this problem and apparently it has something to do with the batch normalization - but surely this is an error that needs to be fixed?

**Describe the expected behavior**
I expect the training accuracy during training after calling model.fit to be the same as the accuracy using model.predict on the same data, given that the batch size is the size of the entire training set.

**Standalone code to reproduce the issue** 
Here's the data https://www.icloud.com/iclouddrive/0xyiKQ2D7CuucbbQ-M8NSPilQ#tf
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

```
from tensorflow.keras.layers import Conv2D, Input, MaxPool2D, add, Flatten, Dense
import tensorflow.keras as keras
import tensorflow as tf
import numpy as np
from sklearn.preprocessing import OneHotEncoder
from sklearn.metrics import confusion_matrix
from seaborn import heatmap
tf.keras.backend.clear_session()from tensorflow.keras.applications import ResNet50
from tensorflow.keras.models import Sequential
import os


os.chdir('/users/justusmulli/bayer')
resnet_weights_path = 'resnet50/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'
os.chdir('/users/jm')


def classification_sampler(x, y, distribution = 'balanced'):
    counts = np.unique(y, return_counts = True)
    class_size = {}
    s = np.argmin(counts[1])
    if distribution == 'balanced':
        for i in range(len(counts[0])):
            class_size[counts[0][i]] = counts[1][s]
    else:
        for class_name in distribution:
            if distribution[class_name]>1:
                class_size[class_name] = distribution[class_name]
            else:
                class_size[class_name] = counts[1][s]*(distribution[class_name]/class_size[counts[0][s]])
    x_sample = []
    y_sample = []
    for i in range(len(class_size)):
        class_name = counts[0][i]
        x_sample.extend(x[y==class_name][:class_size[class_name]])
        y_sample.extend(y[y==class_name][:class_size[class_name]])
    return np.array(x_sample), np.array(y_sample)


x_train = np.load('x_train.npy')
y_train = np.load('y_train.npy')
x_val = np.load('x_test.npy')
y_val = np.load('y_test.npy')
x_train, y_train = classification_sampler(x_train, y_train)
x_val, y_val = classification_sampler(x_val, y_val)
encoder = OneHotEncoder()
encoder.fit(y_train.reshape(-1,1))
y_train = encoder.transform(y_train.reshape(-1,1)).toarray()
y_val = encoder.transform(y_val.reshape(-1,1)).toarray()

model = Sequential()


model.add(ResNet50(include_top = False, pooling = 'avg'))

model.add(Dense(512, activation = 'relu'))
model.add(Dense(128, activation = 'relu'))

model.add(Dense(3, activation = 'softmax'))

model.layers[0].trainable = False

from tensorflow.python.keras import optimizers
optimizer = keras.optimizers.Adam(learning_rate = 0.00000005)
model.compile(optimizer = optimizer, loss = 'categorical_crossentropy', metrics = ['accuracy'])
es = keras.callbacks.EarlyStopping(monitor='val_accuracy',
                                  min_delta=0,
                                  patience=100,
                                  verbose=0, mode='max')
hist = model.fit(x_train, y_train, validation_data = (x_val, y_val), batch_size = 267, epochs = 1000, callbacks = [es])
b = hist.model.predict(x_train)
accuracy_score(np.argmax(b, axis = 1), np.argmax(y_train, axis = 1))
```

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
Epoch 101/1000
267/267 [==============================] - 14s 52ms/sample - loss: 1.1680 - accuracy: 0.3708 - val_loss: 1.1356 - val_accuracy: 0.3333

b = hist.model.predict(x_train)
accuracy_score(np.argmax(b, axis = 1), np.argmax(y_train, axis = 1))
0.3333333333333333"
38485,How to obtain the activation value of neural network in Tensorflow 2.0?,"I used a simple data set mnist to train the neural network, but I want to get the activation value (output) of the last layer of the neural network, how should I do it?

The structure of my neural network is as follows
```
inputs = tf.keras.Input(shape=(28, 28), name='mnist_input')
h1 = tf.keras.layers.Flatten()(inputs)
h2 = tf.keras.layers.Dense(128, activation='relu')(h1)
h3 = tf.keras.layers.Dense(64, activation='relu')(h2)
outputs = tf.keras.layers.Dense(10, activation='softmax', name='outputs')(h3)
model = tf.keras.Model(inputs, outputs)
```

I try to use the callback function `on_epoch_end` to do this. Use `eval()` method on `model.outputs [0]` in the `on_epoch_end` method to get the activation value. But I got an error message: 
> {InvalidArgumentError} You must feed a value for placeholder tensor 'outputs/MatMul/ReadVariableOp/resource' with dtype resource

It seems that what is saved in model is only the framework of the neural network and does not fill in the data. How do I get the activation value after filling in the data?"
38483,How to store tf dataset object to file?,"## URL(s) with the issue:
https://www.tensorflow.org/guide/data

## Description of issue (what needs changing):
How to store tf.dataset object to file?
For instance,
```
dataset1 = tf.data.Dataset.from_tensor_slices(
    tf.random.uniform([4, 10], minval=1, maxval=10, dtype=tf.int32))
dataset1
```
How to store the dataset1 to file?

### Clear description

For me, a saved copy of tokenized dataset saves lot of training time.
```python
from transformers import AlbertTokenizer
import tensorflow as tf
import DataReader
import Tokenizer


def encode(type, dataPath='./qgdata/nq-train-sample.json'):
    entries = DataReader.read(dataPath)
    encoding = []
    for entry in entries:
        if type == 'context':
            context = Tokenizer.encode(
                entry['passage'], entry['answer'], entry['question'], True)
            encoding.append(context)
        else:
            question = Tokenizer.encode(
                entry['passage'], entry['answer'], entry['question'], False)
            encoding.append(question)
    data = tf.data.Dataset.from_generator(
        lambda: encoding, tf.int64, output_shapes=512)
    return data


def make_dataset(dataPath='./qgdata/nq-train-sample.json', batch_size=1):
    contextData = encode('context', dataPath)
    questionData = encode('question', dataPath)
    dataset = tf.data.Dataset.zip((contextData, questionData))
    return dataset.batch(batch_size)
```
Instead of running this batching script before each training, it would be very efficient to store the tokenzied dataset object to file and avoid retokenizing.

### Usage example
Maybe like:
```python
dataset1 = tf.data.Dataset.from_tensor_slices(
    tf.random.uniform([4, 10], minval=1, maxval=10, dtype=tf.int32))
dataset1.save_dataset(path_to_store)
```
"
38482,"Install the TensorFlow-GPU and CUDA and CUDnn, but GPU not work when test.","**System information**
- OS Platform and Distribution: Win10, X64
- TensorFlow version: 1.15
- Python version: 3.5
- Installed using virtualenv? pip? conda?: pip install tensorflow_gpu-1.15.0-cp35-cp35m-win_amd64
- CUDA/cuDNN version: 10.2/7.6.5
- GPU model and memory: GTX1050



**problem details**
i use the Anaconda, the first i create a new environment which python version is 3.7 and TensorFlow-GPU is 2.1. and then i install the CUDA 10.2and CUDNN, 7.6.5, but when i test it, there is a error said can't find the cudart64_101.dll file, when i changed that file(cudart64_102.dll) its name to cudart64_101.dll, no error again, and when i run the follow code showing true
`#code 1`
`import tensorflow as tf`
`print(tf.test.is_gpu_available())`
and running that below code also show the GPU device log
`#code 2`
`import tensorflow as tf`
`sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(log_device_placement=True))`
all is going well on tensorflow 2.1 with GPU

but when i wanna to use tf-gpu 1.X, i install the tensorflow-gpu 1.15, with the same CUDA, CUDNN version, i made a copy of cudart64_101.dll and rename cudart_100.dll, when i run the above test code, the console shows no error, but show false in the code 1 and did not show GPU device info in code 2. i was wondering that if the CUDA/CUDNN version isn't fit the tensorflow-gpu version, is any error will show? i think there must be some error will be report. The problem is i don't know how to fix it **because it didn't report error** .


should i uninstall the CUDA 10.2 and CUDNN and install CUDA 10.0/10.1 but...


**Any other info / logs**
and when i import tensorflow in anaconda prompt , there is no warning or error, just shows 
`tensorflow/stream_executor/platform/default/http://dso_loader.cc:44] Successfully opened dynamic library cudart64_100.dll`
"
38478,[tflite] FlexAddV2,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- TensorFlow installed from (source or binary):
- TensorFlow version (or github SHA if from source):


**Provide the text output from tflite_convert**

```
# Copy and paste here
```

**Standalone code to reproduce the issue** 
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

Also, please include a link to a GraphDef or the model if possible.

**Any other info / logs**

Include any logs or source code that would be helpful to diagnose the problem.
If including tracebacks, please include the full traceback. Large logs and files
should be attached.
"
38477,tensorflow.python.framework.errors_impl.UnimplementedError: File system scheme 'gs' not implemented (file: 'gs://tfds-data/datasets/mnist'),"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: It is an example script (for distributed training) provided in TensorFlow
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 18.04
- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: N/A
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: v2.2.0-rc2-77-gaad398b5e9 2.2.0-rc3
- **Python version**: 3.6.9
- **Bazel version (if compiling from source)**: 2.0.0
- **GCC/Compiler version (if compiling from source)**: 7.5.0
- **CUDA/cuDNN version**: 10.2 / 7.6.5.32-1
- **GPU model and memory**: NVIDIA GeForce 940MX with 2 GB Dedicated VRAM
- **Exact command to reproduce**: python3 distributed_training.py

### Describe the problem
I have built TensorFlow 2.2 from source (using r2.2 branch) with support of CUDA 10.2 and CUDNN 7.6.5 on Ubuntu 18.04 for python3.
During the configuration of the build there was no question like ""Do you wish to build TensorFlow with Google Cloud Platform support? [y/N]""
After I installed this built whl and tried to use it with the script that requires to access the gs://tfds-data/datasets/mnist data, I got the following error:
tensorflow.python.framework.errors_impl.UnimplementedError: File system scheme 'gs' not implemented (file: 'gs://tfds-data/datasets/mnist')
Please advise.
I am using tensorflow-datasets 2.1.0, not sure if this can be the cause of the problem (this version agains tensroflow 2.2 version).

### Source code / logs
Source code of the script:
```
from __future__ import absolute_import, division, print_function, unicode_literals
import os

import tensorflow_datasets as tfds
import tensorflow as tf

tfds.disable_progress_bar()


def evaluate_and_get_model(pth):
    mdl = tf.keras.models.load_model(pth, compile=False)
    mdl.compile(loss='sparse_categorical_crossentropy',
                optimizer=tf.keras.optimizers.Adam(),
                metrics=['accuracy'])
    evl_loss, evl_acc = mdl.evaluate(eval_dataset)
    print('Eval loss: {}, Eval Accuracy: {}'.format(evl_loss, evl_acc))
    return mdl


# Function for decaying the learning rate.
# You can define any decay function you need.
def decay(epoch):
    if epoch < 3:
        return 1e-3
    elif 3 <= epoch < 7:
        return 1e-4
    else:
        return 1e-5


def scale(image, label):
    image = tf.cast(image, tf.float32)
    image /= 255

    return image, label


# Callback for printing the LR at the end of each epoch.
class PrintLR(tf.keras.callbacks.Callback):
    def on_epoch_end(self, epoch, logs=None):
        print('\nLearning rate for epoch {} is {}'.format(epoch + 1, model.optimizer.lr.numpy()))


print(tf.__version__)

datasets, info = tfds.load(name='mnist', with_info=True, as_supervised=True, data_dir='gs://tfds-data/datasets')

mnist_train, mnist_test = datasets['train'], datasets['test']

strategy = tf.distribute.MirroredStrategy()

print('Number of devices: {}'.format(strategy.num_replicas_in_sync))

# You can also do info.splits.total_num_examples to get the total
# number of examples in the dataset.

num_train_examples = info.splits['train'].num_examples
num_test_examples = info.splits['test'].num_examples

BUFFER_SIZE = 10000

BATCH_SIZE_PER_REPLICA = 64
BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync

train_dataset = mnist_train.map(scale).cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE)
eval_dataset = mnist_test.map(scale).batch(BATCH_SIZE)

with strategy.scope():
    model = tf.keras.Sequential([
        tf.keras.layers.Conv2D(32, 3, activation='relu', input_shape=(28, 28, 1)),
        tf.keras.layers.MaxPooling2D(),
        tf.keras.layers.Flatten(),
        tf.keras.layers.Dense(64, activation='relu'),
        tf.keras.layers.Dense(10, activation='softmax')
    ])

    model.compile(loss='sparse_categorical_crossentropy',
                  optimizer=tf.keras.optimizers.Adam(),
                  metrics=['accuracy'])

# Define the checkpoint directory to store the checkpoints

checkpoint_dir = './training_checkpoints'
# Name of the checkpoint files
checkpoint_prefix = os.path.join(checkpoint_dir, 'ckpt_{epoch}')

callbacks = [
    tf.keras.callbacks.TensorBoard(log_dir='./logs'),
    tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_prefix,
                                       save_weights_only=True),
    tf.keras.callbacks.LearningRateScheduler(decay),
    PrintLR()
]

model.fit(train_dataset, epochs=12, callbacks=callbacks)

model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))

eval_loss, eval_acc = model.evaluate(eval_dataset)

print('Eval loss: {}, Eval Accuracy: {}'.format(eval_loss, eval_acc))

path = 'saved_model/'

model.save(path, save_format='tf')

unreplicated_model = evaluate_and_get_model(path)

unreplicated_model.save(path, save_format='tf')

with strategy.scope():
    evaluate_and_get_model(path)
```

Command line output of running the ""python3 distributed_training.py"" command:
```
2.2.0-rc3
ERROR:absl:Failed to construct dataset mnist
Traceback (most recent call last):
  File ""distributed_training.py"", line 48, in <module>
    datasets, info = tfds.load(name='mnist', with_info=True, as_supervised=True, data_dir='gs://tfds-data/datasets')
  File ""/home/vyepishov/.local/lib/python3.6/site-packages/tensorflow_datasets/core/api_utils.py"", line 52, in disallow_positional_args_dec
    return fn(*args, **kwargs)
  File ""/home/vyepishov/.local/lib/python3.6/site-packages/tensorflow_datasets/core/registered.py"", line 302, in load
    dbuilder = builder(name, data_dir=data_dir, **builder_kwargs)
  File ""/home/vyepishov/.local/lib/python3.6/site-packages/tensorflow_datasets/core/registered.py"", line 172, in builder
    return _DATASET_REGISTRY[name](**builder_kwargs)
  File ""/home/vyepishov/.local/lib/python3.6/site-packages/tensorflow_datasets/core/api_utils.py"", line 52, in disallow_positional_args_dec
    return fn(*args, **kwargs)
  File ""/home/vyepishov/.local/lib/python3.6/site-packages/tensorflow_datasets/core/dataset_builder.py"", line 197, in __init__
    self._data_dir = self._build_data_dir()
  File ""/home/vyepishov/.local/lib/python3.6/site-packages/tensorflow_datasets/core/dataset_builder.py"", line 661, in _build_data_dir
    version_dirs = _other_versions_on_disk()
  File ""/home/vyepishov/.local/lib/python3.6/site-packages/tensorflow_datasets/core/dataset_builder.py"", line 648, in _other_versions_on_disk
    if not tf.io.gfile.exists(builder_data_dir):
  File ""/home/vyepishov/.local/lib/python3.6/site-packages/tensorflow/python/lib/io/file_io.py"", line 267, in file_exists_v2
    _pywrap_file_io.FileExists(compat.as_bytes(path))
tensorflow.python.framework.errors_impl.UnimplementedError: File system scheme 'gs' not implemented (file: 'gs://tfds-data/datasets/mnist')
```"
38476,ValueError: trainable_variables cannot be None. Given None,"when i use model_fn and tf2.1，
my_head = tf.estimator.BinaryClassHead()
  return my_head.EstimatorSpec(
      features=features,
      mode=mode,
      labels=labels,
      optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),
      logits=logits)

i get: 
File ""/usr/local/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/head/base_head.py"", line 278, in create_estimator_spec
    regularization_losses=regularization_losses))
  File ""/usr/local/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/head/binary_class_head.py"", line 513, in _create_tpu_estimator_spec
    loss_reduction=self._loss_reduction)
  File ""/usr/local/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/head/base_head.py"", line 870, in create_estimator_spec_train_op
    validate_trainable_variables(trainable_variables)
  File ""/usr/local/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/head/base_head.py"", line 636, in validate_trainable_variables
    trainable_variables))
ValueError: trainable_variables cannot be None. Given None
"
38475,tf.train.Server E0413...SO_REUSEPORT unavailable on compiling system,"**System information** 
- OS Platform and Distribution:
Linux Ubuntu 18.04.3 LTS
Node0: Linux version 5.3.0-46-generic (buildd@lcy01-amd64-013) (gcc version 7.5.0 (Ubuntu 7.5.0-3ubuntu1~18.04))
Node1:Linux version 5.6.3-050603-generic (kernel@kathleen) (gcc version 9.3.0 (Ubuntu 9.3.0-10ubuntu1))
- TensorFlow installed from (source or
binary): 2.1.0  installed from conda
- Python version: - Anaconda python 3.6.12
- CUDA/cuDNN version: 10.2 
- GPU model and memory: RTX 2080TI 11GB

**Standalone code to reproduce the issue** 
```
#Both Node0 & Node1:
os.environ[""TF_CPP_MIN_LOG_LEVEL""] = ""3""
import tensorflow.compat.v1 as tf
tf.disable_v2_behavior()
cluster_def = {'worker':['192.168.1.5:4448','192.168.1.2:4449']}

#Node0-192.168.1.5:4448:
server = tf.train.Server(cluster_def, job_name='worker', task_index=0)

#Node1-192.168.1.2:4449:
server = tf.train.Server(cluster_def, job_name='worker', task_index=1)
```

**Describe the expected behavior**
On Node1-192.168.1.2:4449, return:
E0413 00:11:52.803623615    2266 socket_utils_common_posix.cc:198] check for SO_REUSEPORT: {""created"":""@1586707912.803602543"",""description"":""SO_REUSEPORT unavailable on compiling system"",""file"":""external/grpc/src/core/lib/iomgr/socket_utils_common_posix.cc"",""file_line"":166}

Could somebody give me a helping hand?
Thanks in advance."
38474,Embedding a preprocessing function inside a tf.keras model for serving,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04): **Colab**
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if
the issue happens on mobile device: 
- TensorFlow installed from (source or
binary): - TensorFlow version (use command below): 
- Python version: - Bazel
version (if compiling from source):
- GCC/Compiler version (if compiling from
source): 
- CUDA/cuDNN version: - GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

I am trying to embed a simple image preprocessing function inside an already trained `tf.keras` model. This is a useful feature to have because it can help us reduce a lot of boilerplate code needed while using any model for serving purposes. With this capability, you get a lot more flexibility and modularity to your model.

So after training my model, I am first defining a preprocessing function like so - 

```python
def preprocess_image_cv2(image_path):
    img = cv2.imread(image_path)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    img = cv2.resize(img, (28, 28)).astype(""float32"")
    img = img / 255
    img = np.expand_dims(img, 0)
    img = tf.convert_to_tensor(img)
    return img
```

I am then using it to create another model class along with the trained model - 

```python
# Define the model for predcition purpose
class ExportModel(tf.keras.Model):
    def __init__(self, preproc_func, model):
        super().__init__(self)
        self.preproc_func = preproc_func
        self.model = model

    @tf.function
    def my_serve(self, image_path):
        print(""Inside"")
        preprocessed_image = self.preproc_func(image_path) # Preprocessing
        probabilities = self.model(preprocessed_image, training=False) # Model prediction
        class_id = tf.argmax(probabilities[0], axis=-1) # Postprocessing
        return {""class_index"": class_id}
```

I am then able to run inference on a sample image with this setting:

```python
# Now initialize a dummy model and fill its parameters with that of
# the model we trained
restored_model = get_training_model()
restored_model.set_weights(apparel_model.get_weights())

# Now use this model, preprocessing function, and the same image
# for checking if everything is working
serving_model = ExportModel(preprocess_image_cv2, restored_model)
class_index = serving_model.my_serve(""sample_image.png"")
CLASSES[class_index[""class_index""].numpy()] # prints Dress
```

But I am unable to export this model for serving. I am doing the following for exporting - 

```python
# Make sure we are *not* letting the model to train
tf.keras.backend.set_learning_phase(0)

# Serialize model
export_path = ""model_preprocessing_func""
tf.saved_model.save(serving_model, export_path, signatures={""serving_default"": serving_model.my_serve})
```

This yields - 

```
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
<ipython-input-97-9e2616e04da9> in <module>()
      1 export_path = ""model_preprocessing_func""
----> 2 tf.saved_model.save(serving_model, export_path, signatures={""serving_default"": serving_model.my_serve})

2 frames
/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/save.py in save(obj, export_dir, signatures, options)
    949 
    950   _, exported_graph, object_saver, asset_info = _build_meta_graph(
--> 951       obj, export_dir, signatures, options, meta_graph_def)
    952   saved_model.saved_model_schema_version = constants.SAVED_MODEL_SCHEMA_VERSION
    953 

/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/save.py in _build_meta_graph(obj, export_dir, signatures, options, meta_graph_def)
   1009 
   1010   signatures, wrapped_functions = (
-> 1011       signature_serialization.canonicalize_signatures(signatures))
   1012   signature_serialization.validate_saveable_view(checkpoint_graph_view)
   1013   signature_map = signature_serialization.create_signature_map(signatures)

/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/signature_serialization.py in canonicalize_signatures(signatures)
    110           (""Expected a TensorFlow function to generate a signature for, but ""
    111            ""got {}. Only `tf.functions` with an input signature or ""
--> 112            ""concrete functions can be used as a signature."").format(function))
    113 
    114     wrapped_functions[original_function] = signature_function = (

ValueError: Expected a TensorFlow function to generate a signature for, but got <tensorflow.python.eager.def_function.Function object at 0x7fd5b646ea58>. Only `tf.functions` with an input signature or concrete functions can be used as a signature.
```

I am able to interpret the last part of the error but I am unable to figure out what steps should I take to resolve it.

**Describe the expected behavior**

**Standalone code to reproduce the issue** 
One can reproduce the issue with this [Colab Notebook][1]. Help is appreciated. 


  [1]: https://colab.research.google.com/drive/1QuJ7MLgtgNtJ7E_r4gpCokNxukNxay1O

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
38473,tf.data.Dataset.map() uses only 1 cpu,"**System information** 
- Have I written custom code: No
- OS Platform and Distribution: Linux Ubuntu 16.04
- TensorFlow installed from: binary
- TensorFlow version: v2.2.0-rc1-34-ge6e5d6df2a 2.2.0-rc2
- Python version: 3.7.5
- CUDA/cuDNN version: 10.1.1/7.6.5
- GPU model and memory: GTX 1080 Ti.

**Describe the current behavior**
When checking with the `top` command during training, only 1 CPU is used.

**Describe the expected behavior**
Multiple CPUs should be used.

**Standalone code to reproduce the issue** 

You can take the code from the [official TensorFlow tutorial on image segmentation](https://www.tensorflow.org/tutorials/images/segmentation).

For a more convincing experiment, replace the two lines:

```python
train = dataset['train'].map(load_image_train, num_parallel_calls=tf.data.experimental.AUTOTUNE)
test = dataset['test'].map(load_image_test)
```

with e.g.

```python
train = dataset['train'].map(load_image_train, num_parallel_calls=4)
test = dataset['test'].map(load_image_test, num_parallel_calls=4)
```
"
38471,How can one apply an arbitrary function to a dataset?,"Is there anything similar to pandas' `.apply()` or `.map()` that could apply arbitrary functions on TensorFlow datasets in an efficient (i.e., vectorized) manner? 

## Minimum working example

Consider the following code.

```
import tensorflow as tf

def compute_length(x): 
    return tf.strings.length(x)

def check_substring(x, substring):
    return substring in x

def compute_palindrome(x):
    return ''.join([x[-i] for i in range(-len(x)+1, 1)])
    
ds = tf.data.Dataset.from_tensor_slices([""Ottawa"", ""Stockholm"", ""Rabat""])

ds = ds.map(
    lambda city: (city, 
                  compute_length(city), 
#                  check_substring(city, ""lm""),
#                  compute_palindrome(city),
                  ),
        )

num_elems = len(ds.element_spec)
for elem in ds:
    print(''.join([f""{elem[i]}"" for i in range(num_elems)]))
```

## Issues

`compute_length()` works fine and returns
```
b'Ottawa'6
b'Stockholm'9
b'Rabat'5
```

However, commenting out `check_subsring()` returns 

> OperatorNotAllowedInGraphError: iterating over `tf.Tensor` is not allowed: AutoGraph is disabled in this function. Try decorating it directly with @tf.function.

and commenting out `compute_palindrome()` returns 

> TypeError: len is not well defined for symbolic Tensors. (args_0:0) Please call `x.shape` rather than `len(x)` for shape information.

Unlike a simple `apply()` or `map()` in pandas, there is clearly some extra steps needed to apply such operations on Tensors. The documentation for what those steps are isn't easy to find. 

PS: The use of TensorFlow's `map()` isn't required. Whatever does the job is welcome.

## URL(s) with the issue:

This pertains to either 
https://www.tensorflow.org/api_docs/python/tf/data/Dataset#map or
https://www.tensorflow.org/api_docs/python/tf/map_fn"
38470,"WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f70dfc46840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.","I have a problem while trying to do prediction by using LSTM...
Here is a error code: 
WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f70dfc46840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.
However, anyway I have a prediction even though there is error code above.
Is there any solution with this problem? I used Colab gpu for this test. Here is my code.... 
<img width=""1178"" alt=""스크린샷 2020-04-12 오후 10 17 56"" src=""https://user-images.githubusercontent.com/48937254/79069726-776d8580-7d0b-11ea-8fc2-e9749755d9fc.png"">
<img width=""1295"" alt=""스크린샷 2020-04-12 오후 10 18 15"" src=""https://user-images.githubusercontent.com/48937254/79069733-82c0b100-7d0b-11ea-8eaf-18bd45886f37.png"">
"
38469,tflite buffer from GPU,"This template is for miscellaneous issues not covered by the other issue categories.

For questions on how to work with TensorFlow, or support for problems that are not verified bugs in TensorFlow, please go to [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).

If you are reporting a vulnerability, please use the [dedicated reporting process](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md).

For high-level discussions about TensorFlow, please post to discuss@tensorflow.org, for questions about the development or internal workings of TensorFlow, or if you would like to know how to contribute to TensorFlow, please post to developers@tensorflow.org.


template <typename T>
Status GlBuffer::MappedRead(
    const std::function<Status(absl::Span<const T> d)>& reader) const {
  if (bytes_size_ % sizeof(T) != 0) {
    return InvalidArgumentError(""Buffer is not aligned"");
  }
  gl_buffer_internal::BufferBinder binder(target_, id_);
  gl_buffer_internal::BufferMapper mapper(target_, offset_, bytes_size_,
                                          GL_MAP_READ_BIT);
  if (!mapper.data()) {
    return GetOpenGlErrors();
  }
  float *data = (float *)mapper.data();
  for (int i = 0; i < 30; i++) {
    __android_log_print(ANDROID_LOG_WARN, ""jni-tflite"", ""value=%f"", data[i]);
  }
  return reader(absl::MakeSpan(reinterpret_cast<const T*>(mapper.data()),
                               bytes_size_ / sizeof(T)));
}

Above code is in gl_buffer.h for read data from gpu to cpu, printed value is all zero for input node as i want to inpect the result is as expected. but output node has non zero values. why ?

Status Invoke(TfLiteContext* context) {
    const EGLContext egl_context_at_delegate_init = env_->context().context();
    const EGLContext egl_context_at_delegate_invoke = eglGetCurrentContext();
    if (egl_context_at_delegate_init != egl_context_at_delegate_invoke) {
      return FailedPreconditionError(
          ""Delegate should run on the same thread where it was initialized."");
    }

    // Push input data from a tensor to GPU.
    for (ValueId id : inputs_) {
      const ValueRef& ref = tensors_[id];
      auto external_object = bhwc_objects_.FindBuffer(ref.tensor_index);
      if (external_object) {
        // Use input from GPU.
        // Conversion is needed only when external object is not phwc4.
        if (!IsPHWC4(tensors_[id].shape)) {
          RETURN_IF_ERROR(bhwc_to_phwc4_.Convert(
              ref.shape, *external_object, command_queue_.get(), external_object   ""Note:read data to cpu all is zero!!!?""
              phwc4_objects_.FindBuffer(id)));
        }
      } else {
        // Copy from CPU to GPU
        TfLiteTensor& tensor = context->tensors[ref.tensor_index];
        RETURN_IF_ERROR(CopyToBufferHandle(id, &tensor));
      }
    }

    // Run inference.
    RETURN_IF_ERROR(inference_context_->Reset());
    RETURN_IF_ERROR(inference_context_->Execute());

    // Push output data from GPU to a tensor.
    bool finished_gpu_processing = false;
    for (ValueId id : outputs_) {
      const ValueRef& ref = tensors_[id];
      auto external_object = bhwc_objects_.FindBuffer(ref.tensor_index);
      if (external_object) {
        // Convert data from PHWC4 to BHWC and leave it in GPU object.
        // Conversion is needed only when external object is not phwc4.
        if (!IsPHWC4(tensors_[id].shape)) {
          RETURN_IF_ERROR(
              phwc4_to_bhwc_.Convert(ref.shape, *phwc4_objects_.FindBuffer(id),
                                     command_queue_.get(), external_object));
        }
      } else {
        // Wait until all GPU command are completed. This call leads to a lower
        // processing latency because a buffer reading below will not stall if
        // data is not yet ready.
        if (!finished_gpu_processing) {
          RETURN_IF_ERROR(command_queue_->WaitForCompletion());
          finished_gpu_processing = true;
        }
        // Copy from GPU to CPU.
        TfLiteTensor& tensor = context->tensors[ref.tensor_index];
        RETURN_IF_ERROR(CopyFromBufferHandle(id, &tensor));          ""#Note:this is output node to print value has non zero value"" 
      }
    }
    return OkStatus();
  }


"
38468,tensorflow problems,"System Information:
- Windows 7
- TensorFlow installed via pip
- Python version: 3.8.2

Code:
from keras.models import Sequential

Error: 
Using TensorFlow backend.
Traceback (most recent call last):
  File ""C:\Users\HP\Desktop\chatbot\train_chatbot.py"", line 8, in <module>
    from keras.models import Sequential
  File ""C:\Users\HP\AppData\Local\Programs\Python\Python38\lib\site-packages\keras\__init__.py"", line 3, in <module>
    from . import utils
  File ""C:\Users\HP\AppData\Local\Programs\Python\Python38\lib\site-packages\keras\utils\__init__.py"", line 6, in <module>
    from . import conv_utils
  File ""C:\Users\HP\AppData\Local\Programs\Python\Python38\lib\site-packages\keras\utils\conv_utils.py"", line 9, in <module>
    from .. import backend as K
  File ""C:\Users\HP\AppData\Local\Programs\Python\Python38\lib\site-packages\keras\backend\__init__.py"", line 1, in <module>
    from .load_backend import epsilon
  File ""C:\Users\HP\AppData\Local\Programs\Python\Python38\lib\site-packages\keras\backend\load_backend.py"", line 90, in <module>
    from .tensorflow_backend import *
  File ""C:\Users\HP\AppData\Local\Programs\Python\Python38\lib\site-packages\keras\backend\tensorflow_backend.py"", line 5, in <module>
    import tensorflow as tf
  File ""C:\Users\HP\AppData\Local\Programs\Python\Python38\lib\site-packages\tensorflow\__init__.py"", line 41, in <module>
    from tensorflow.python.tools import module_util as _module_util
  File ""C:\Users\HP\AppData\Local\Programs\Python\Python38\lib\site-packages\tensorflow\python\__init__.py"", line 50, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\Users\HP\AppData\Local\Programs\Python\Python38\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 30, in <module>
    self_check.preload_check()
  File ""C:\Users\HP\AppData\Local\Programs\Python\Python38\lib\site-packages\tensorflow\python\platform\self_check.py"", line 53, in preload_check
    raise ImportError(
ImportError: Could not find the DLL(s) 'msvcp140_1.dll'. TensorFlow requires that these DLLs be installed in a directory that is named in your %PATH% environment variable. You may install these DLLs by downloading ""Microsoft C++ Redistributable for Visual Studio 2015, 2017 and 2019"" for your platform from this URL: https://support.microsoft.com/help/2977003/the-latest-supported-visual-c-downloads
"
38465,ValueError specifying TensorSpec names while using model.save,"**System information** 
- Custom code has been written to define the model, and is given
- OS Platform and Distribution: Linux Ubuntu 19.10: 
- TensorFlow installed via pip
- TensorFlow versions 2.1.0 & 2.2.0.dev20200411 trialed
- Python version: 3.7

**Describe the current behavior**
Attempting to use model.save() to save a trained model, raises the eventual error 
`ValueError: If specifying TensorSpec names for nested structures, either zero or all names have to be specified.`
Code also raises the error while failing to save
`WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7efb5076e0e0> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: Bad argument number for Name: 4, expecting 3`
Another error that visible in the output is the failed conversion to JSON of a tf_graphics layer. This has been raised in the tensorflow_graphics repository

**Describe the expected behaviour**
Unsure - error was asked to be raised to TensorFlow team by the error text.

**Standalone code to reproduce the issue** 
In comment below

**Current Code output**
```
WARNING:tensorflow:AutoGraph could not transform <bound method FeatureSteeredConvolutionKerasLayer.call of <tensorflow_graphics.nn.layer.graph_convolution.FeatureSteeredConvolutionKerasLayer object at 0x7efb9617c790>> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: module 'gast' has no attribute 'Constant'
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
Model: ""MyFirstGraphModel""
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, 100, 3)]     0                                            
__________________________________________________________________________________________________
conv1d (Conv1D)                 (None, 100, 2)       8           input_1[0][0]                    
__________________________________________________________________________________________________
input_2 (InputLayer)            [(None, 100, 100)]   0                                            
__________________________________________________________________________________________________
input_3 (InputLayer)            [(None,)]            0                                            
__________________________________________________________________________________________________
feature_steered_convolution_ker (None, 100, 32)      584         conv1d[0][0]                     
                                                                 input_2[0][0]                    
__________________________________________________________________________________________________
re_lu (ReLU)                    (None, 100, 32)      0           feature_steered_convolution_keras
__________________________________________________________________________________________________
feature_steered_convolution_ker (None, 100, 64)      16968       re_lu[0][0]                      
                                                                 input_2[0][0]                    
__________________________________________________________________________________________________
re_lu_1 (ReLU)                  (None, 100, 64)      0           feature_steered_convolution_keras
__________________________________________________________________________________________________
feature_steered_convolution_ker (None, 100, 128)     66696       re_lu_1[0][0]                    
                                                                 input_2[0][0]                    
__________________________________________________________________________________________________
re_lu_2 (ReLU)                  (None, 100, 128)     0           feature_steered_convolution_keras
__________________________________________________________________________________________________
conv1d_1 (Conv1D)               (None, 100, 256)     33024       re_lu_2[0][0]                    
__________________________________________________________________________________________________
conv1d_2 (Conv1D)               (None, 100, 1)       257         conv1d_1[0][0]                   
==================================================================================================
Total params: 117,537
Trainable params: 117,537
Non-trainable params: 0
__________________________________________________________________________________________________
WARNING:tensorflow:AutoGraph could not transform <function tf_record_to_dataset.<locals>.<lambda> at 0x7efb9450be60> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: module 'gast' has no attribute 'Constant'
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
WARNING:tensorflow:AutoGraph could not transform <function tf_record_to_dataset.<locals>.<lambda> at 0x7efb9448ab00> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: module 'gast' has no attribute 'Constant'
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
2020-04-12 15:51:25.362023: I tensorflow/core/profiler/lib/profiler_session.cc:154] Profiler session started.
2020-04-12 15:51:25.362060: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1372] Profiler found 1 GPUs
2020-04-12 15:51:25.362157: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcupti.so.10.1'; dlerror: libcupti.so.10.1: cannot open shared object file: No such file or directory
2020-04-12 15:51:25.362163: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1419] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI could not be loaded or symbol could not be found.
2020-04-12 15:51:25.362167: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1458] function cupti_interface_->ActivityRegisterCallbacks( AllocCuptiActivityBuffer, FreeCuptiActivityBuffer)failed with error CUPTI could not be loaded or symbol could not be found.
2020-04-12 15:51:25.362175: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1441] function cupti_interface_->EnableCallback( 0 , subscriber_, CUPTI_CB_DOMAIN_DRIVER_API, cbid)failed with error CUPTI could not be loaded or symbol could not be found.
2020-04-12 15:51:25.362203: I tensorflow/core/profiler/lib/profiler_session.cc:154] Profiler session started.
2020-04-12 15:51:25.362208: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1419] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI could not be loaded or symbol could not be found.
2020-04-12 15:51:25.362211: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1458] function cupti_interface_->ActivityRegisterCallbacks( AllocCuptiActivityBuffer, FreeCuptiActivityBuffer)failed with error CUPTI could not be loaded or symbol could not be found.
2020-04-12 15:51:25.362216: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1441] function cupti_interface_->EnableCallback( 0 , subscriber_, CUPTI_CB_DOMAIN_DRIVER_API, cbid)failed with error CUPTI could not be loaded or symbol could not be found.
WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... Layer FeatureSteeredConvolutionKerasLayer has arguments in `__init__` and therefore must override `get_config`.
WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7efb944d2560> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: Bad argument number for Name: 4, expecting 3
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
/home/robin/anaconda3/envs/Robin-Graph-NN-Pose-from-Model/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:430: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.
  ""Converting sparse IndexedSlices to a dense Tensor of unknown shape. ""
2020-04-12 15:51:27.041239: I tensorflow/core/profiler/lib/profiler_session.cc:154] Profiler session started.
2020-04-12 15:51:27.041279: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1419] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI could not be loaded or symbol could not be found.
2020-04-12 15:51:27.041288: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1458] function cupti_interface_->ActivityRegisterCallbacks( AllocCuptiActivityBuffer, FreeCuptiActivityBuffer)failed with error CUPTI could not be loaded or symbol could not be found.
WARNING:tensorflow:From /home/robin/anaconda3/envs/Robin-Graph-NN-Pose-from-Model/lib/python3.7/site-packages/tensorflow/python/ops/summary_ops_v2.py:1271: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.
Instructions for updating:
use `tf.profiler.experimental.stop` instead.
2020-04-12 15:51:27.046579: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1441] function cupti_interface_->EnableCallback( 0 , subscriber_, CUPTI_CB_DOMAIN_DRIVER_API, cbid)failed with error CUPTI could not be loaded or symbol could not be found.
2020-04-12 15:51:27.049348: I tensorflow/core/profiler/internal/gpu/device_tracer.cc:217]  GpuTracer has collected 0 callback api events and 0 activity events.
2020-04-12 15:51:27.054982: I tensorflow/core/profiler/rpc/client/save_profile.cc:168] Creating directory: logs/fit/20200412-155125/train/plugins/profile/2020_04_12_15_51_27
      1/Unknown - 0s 81us/step - loss: 0.3479 - acc: 0.69002020-04-12 15:51:27.059084: I tensorflow/core/profiler/rpc/client/save_profile.cc:174] Dumped gzipped tool data for trace.json.gz to logs/fit/20200412-155125/train/plugins/profile/2020_04_12_15_51_27/robin-System-Product-Name.trace.json.gz
2020-04-12 15:51:27.061354: I tensorflow/core/profiler/utils/event_span.cc:288] Generation of step-events took 0 ms

2020-04-12 15:51:27.063255: I tensorflow/python/profiler/internal/profiler_wrapper.cc:91] Creating directory: logs/fit/20200412-155125/train/plugins/profile/2020_04_12_15_51_27Dumped tool data for overview_page.pb to logs/fit/20200412-155125/train/plugins/profile/2020_04_12_15_51_27/robin-System-Product-Name.overview_page.pb
Dumped tool data for input_pipeline.pb to logs/fit/20200412-155125/train/plugins/profile/2020_04_12_15_51_27/robin-System-Product-Name.input_pipeline.pb
Dumped tool data for tensorflow_stats.pb to logs/fit/20200412-155125/train/plugins/profile/2020_04_12_15_51_27/robin-System-Product-Name.tensorflow_stats.pb
Dumped tool data for kernel_stats.pb to logs/fit/20200412-155125/train/plugins/profile/2020_04_12_15_51_27/robin-System-Product-Name.kernel_stats.pb

    628/Unknown - 2s 3ms/step - loss: 0.3358 - acc: 0.6680WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7efb602a50e0> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: Bad argument number for Name: 4, expecting 3
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
640/640 [==============================] - 2s 4ms/step - loss: 0.3356 - acc: 0.6681 - val_loss: 0.3316 - val_acc: 0.6689
2020-04-12 15:51:30.035679: W tensorflow/python/util/util.cc:329] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7efb5076e0e0> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: Bad argument number for Name: 4, expecting 3
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
Traceback (most recent call last):
  File ""/home/robin/Masters/Robin-Graph-NN-Pose-from-Model/Examples/graph_network_model.py"", line 68, in <module>
    model.save('./test/model_dir')
  File ""/home/robin/anaconda3/envs/Robin-Graph-NN-Pose-from-Model/lib/python3.7/site-packages/tensorflow/python/keras/engine/network.py"", line 1062, in save
    signatures, options)
  File ""/home/robin/anaconda3/envs/Robin-Graph-NN-Pose-from-Model/lib/python3.7/site-packages/tensorflow/python/keras/saving/save.py"", line 134, in save_model
    signatures, options)
  File ""/home/robin/anaconda3/envs/Robin-Graph-NN-Pose-from-Model/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model/save.py"", line 78, in save
    save_lib.save(model, filepath, signatures, options)
  File ""/home/robin/anaconda3/envs/Robin-Graph-NN-Pose-from-Model/lib/python3.7/site-packages/tensorflow/python/saved_model/save.py"", line 951, in save
    obj, export_dir, signatures, options, meta_graph_def)
  File ""/home/robin/anaconda3/envs/Robin-Graph-NN-Pose-from-Model/lib/python3.7/site-packages/tensorflow/python/saved_model/save.py"", line 1024, in _build_meta_graph
    _ = _SaveableView(checkpoint_graph_view)
  File ""/home/robin/anaconda3/envs/Robin-Graph-NN-Pose-from-Model/lib/python3.7/site-packages/tensorflow/python/saved_model/save.py"", line 204, in __init__
    function._list_all_concrete_functions_for_serialization())  # pylint: disable=protected-access
  File ""/home/robin/anaconda3/envs/Robin-Graph-NN-Pose-from-Model/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py"", line 882, in _list_all_concrete_functions_for_serialization
    concrete_functions.append(self.get_concrete_function(*args, **kwargs))
  File ""/home/robin/anaconda3/envs/Robin-Graph-NN-Pose-from-Model/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model/save_impl.py"", line 546, in get_concrete_function
    self.call_collection.add_trace(*args, **kwargs)
  File ""/home/robin/anaconda3/envs/Robin-Graph-NN-Pose-from-Model/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model/save_impl.py"", line 418, in add_trace
    trace_with_training(True)
  File ""/home/robin/anaconda3/envs/Robin-Graph-NN-Pose-from-Model/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model/save_impl.py"", line 416, in trace_with_training
    fn.get_concrete_function(*args, **kwargs)
  File ""/home/robin/anaconda3/envs/Robin-Graph-NN-Pose-from-Model/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model/save_impl.py"", line 547, in get_concrete_function
    return super(LayerCall, self).get_concrete_function(*args, **kwargs)
  File ""/home/robin/anaconda3/envs/Robin-Graph-NN-Pose-from-Model/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py"", line 1000, in get_concrete_function
    concrete = self._get_concrete_function_garbage_collected(*args, **kwargs)
  File ""/home/robin/anaconda3/envs/Robin-Graph-NN-Pose-from-Model/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py"", line 918, in _get_concrete_function_garbage_collected
    *args, **kwargs)
  File ""/home/robin/anaconda3/envs/Robin-Graph-NN-Pose-from-Model/lib/python3.7/site-packages/tensorflow/python/eager/function.py"", line 2497, in _get_concrete_function_garbage_collected
    graph_function, args, kwargs = self._maybe_define_function(args, kwargs)
  File ""/home/robin/anaconda3/envs/Robin-Graph-NN-Pose-from-Model/lib/python3.7/site-packages/tensorflow/python/eager/function.py"", line 2775, in _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)
  File ""/home/robin/anaconda3/envs/Robin-Graph-NN-Pose-from-Model/lib/python3.7/site-packages/tensorflow/python/eager/function.py"", line 2665, in _create_graph_function
    capture_by_value=self._capture_by_value),
  File ""/home/robin/anaconda3/envs/Robin-Graph-NN-Pose-from-Model/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py"", line 898, in func_graph_from_py_func
    args, arg_names, flat_shapes=arg_shapes)
  File ""/home/robin/anaconda3/envs/Robin-Graph-NN-Pose-from-Model/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py"", line 1134, in _get_defun_inputs_from_args
    args, names, structure=args, flat_shapes=flat_shapes)
  File ""/home/robin/anaconda3/envs/Robin-Graph-NN-Pose-from-Model/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py"", line 1198, in _get_defun_inputs
    raise ValueError(""If specifying TensorSpec names for nested structures, ""
ValueError: If specifying TensorSpec names for nested structures, either zero or all names have to be specified.

```
"
38463,cannot set tf.Variable as model input,"Tensorflow: 2.1.0

I intend to utilize a pre-trained model and input a trainable input noise. but it is not allowed in tensorflow 2.0. want to find out whether it is a bug or by design.

```python
init_value = tf.random.normal((1, 512, 512, 3))
noise_input = tf.Variable(init_value, trainable=True)

pretrained_vgg19 = tf.keras.applications.VGG19(include_top=False, input_shape=(512, 512, 3))
pretrained_vgg19.predict(noise_input)
```
![image](https://user-images.githubusercontent.com/731496/79059341-60974680-7cab-11ea-957c-6e57f5fc237c.png)
"
38462,More clarity on TFLite + GPU,"## URL(s) with the issue:

https://www.tensorflow.org/lite/performance/gpu_advanced

## Description of issue (what needs changing):

After a couple of days digging through documentation and source code, I'm still very confused about the current state of GPU support in tensorflow/lite.

1. https://www.tensorflow.org/lite/performance/gpu_advanced#android_cc : talks about C/C++, which gives the illusion that one might use the lite/c API. But as far as I can see, the `ModifyGraphWithDelegate` function is not present in lite/c (why? It would be very helpful), even though it has the concept of delegates;
2. https://www.tensorflow.org/lite/performance/gpu_advanced#android_cc : suggests a build command that generates a 60MB shared library... I don't see any benefit in giving such suggestion, since other commands listed in other pages will generate properly optimized binaries;
3. https://www.tensorflow.org/lite/performance/gpu_advanced#android_cc : building on (2.), I'm also under the impression that building the delegate as a separate shared lib would not be the best option for minimizing the overall size - in this case, a target for building the delegate + libtensorflowlite together would be highly appreciated, at least as a documentation snippet (not to mention prebuilt binaries, which are referred by the team as ""coming soon"" in several not-so-recent issue comments);
3. https://www.tensorflow.org/lite/performance/gpu_advanced#inputoutput_buffers : suggests the use of `GpuDelegate` which, as far as I understand comes from `lite/delegates/gpu/gl_delegate.h` and as such is deprecated. A big notice in the source code warns to migrate to the new implementation before the end of 2019, so it probably shouldn't be in documentation;
4. https://www.tensorflow.org/lite/performance/gpu_advanced#inputoutput_buffers : 
While a replacement exists (`lite/delegates/gpu/delegate.h`), it does not have any `bindGlBufferToTensor()` function, and it is not clear how to achieve the same thing with the new delegate. There are several unanswered questions on SO about this;
5. https://www.tensorflow.org/lite/performance/gpu_advanced#inputoutput_buffers : the example uses a SSBO, however the delegate seems to support [textures as well?](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/delegates/gpu/gl_delegate.h#L53-L57) If this can be a different way to send initial input, it would be nice to have it documented;

It is hard for us to plan the adoption of TFLite without a clear view over what you have, or at least where you're heading. For example, I'm especially interested in using GL buffers as input (sounds like a game changer), but I have no clue about what's the state of this in TFLite. Same with using delegates in lite/c, the abstraction is there but `ModifyGraphWithDelegate` is not. So doc fixes apart, could we have a very brief description of where TFLite + GPU/delegates is headed and what's coming in the next couple of months, so that people can decide if it meets their needs and plan accordingly? 

I understand that some of these APIs are marked as experimental and I really appreciate your work. Thanks!
"
38461, AttributeError: module 'tensorflow' has no attribute 'variable_scope',"When I put this line of code in:

mlpr = ANNR([input], layers, batchSize = 256, maxIter = 20000, tol = 0.2, reg = 1e-4, verbose = True)

I get the following error:  AttributeError: module 'tensorflow' has no attribute 'variable_scope'

I am using tensorflow version 2.1

How do I fix this?

Thanks in advance."
38460,[1.14/1.15] TensorRT ConvertGraphDefToEngine SIGSEGV,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04): NixOS
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if
the issue happens on mobile device:  N/A
- TensorFlow installed from (source or
binary): Source
- TensorFlow version (use command below): 1.14
- Python version: 3.6.10
- Bazel: v0.26.0
version (if compiling from source):
- GCC/Compiler version (if compiling from
source): 0.9.2
- CUDA/cuDNN version: 10.0.130/7.6.5.32
- GPU model and memory: No GPU in the system/sandboxed environment

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

When making `tensorflow` to invoke TensorRT graph optimiser on the system without a GPU/inside a sandbox, `tensorflow` will segfault with a null dereference.

<details>
<summary>Log</summary>

```
2020-04-11 19:39:35.067438: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2020-04-11 19:39:35.069624: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2020-04-11 19:39:35.069654: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (shirobox): /proc/driver/nvidia/version does not exist
2020-04-11 19:39:35.088189: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2999610000 Hz
2020-04-11 19:39:35.089136: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x40682b0 executing computations on platform Host. Devices:
2020-04-11 19:39:35.089190: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2020-04-11 19:39:35.829560: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
[2020-04-11 19:39:35,858][WARNING][tensorflow][deprecation new_func] From test_tensorrt_enabled.py:26: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.graph_util.convert_variables_to_constants`
[2020-04-11 19:39:35,858][WARNING][tensorflow][deprecation new_func] From /nix/store/w7dqhlrb6qv0im8hnwl309f13q86pnb4-python3-3.6.10-env/lib/python3.6/site-packages/tensorflow/python/framework/graph_util_impl.py:270: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.graph_util.extract_sub_graph`
[2020-04-11 19:39:35,876][INFO][tensorflow][graph_util_impl convert_variables_to_constants] Froze 11 variables.
[2020-04-11 19:39:35,890][INFO][tensorflow][graph_util_impl convert_variables_to_constants] Converted 11 variables to const ops.
[2020-04-11 19:39:35,891][INFO][tensorflow][trt_convert _check_trt_version_compatibility] Linked TensorRT version: (7, 0, 0)
[2020-04-11 19:39:35,891][INFO][tensorflow][trt_convert _check_trt_version_compatibility] Loaded TensorRT version: (7, 0, 0)
[2020-04-11 19:39:35,891][INFO][tensorflow][trt_convert _check_trt_version_compatibility] Running against TensorRT version 7.0.0
2020-04-11 19:39:35.948446: I tensorflow/core/grappler/devices.cc:55] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0
2020-04-11 19:39:35.948611: I tensorflow/core/grappler/clusters/single_machine.cc:359] Starting new session
2020-04-11 19:39:35.997673: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:460] There are 5 ops of 4 different types in the graph that are not converted to TensorRT: Identity, FusedBatchNorm, NoOp, Placeholder, (For more information see https://docs.nvidia.com/deeplearning/dgx/tf-trt-user-guide/index.html#supported-ops).
2020-04-11 19:39:35.997810: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:733] Number of TensorRT candidate segments: 1
2020-04-11 19:39:36.003553: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2020-04-11 19:39:36.006215: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:797] Couldn't get current device: no CUDA-capable device is detected
2020-04-11 19:39:36.006242: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 0 does not exist Not found: TensorFlow device GPU:0 was not registered
2020-04-11 19:39:36.006267: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 1 does not exist Not found: TensorFlow device GPU:1 was not registered
2020-04-11 19:39:36.006279: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 2 does not exist Not found: TensorFlow device GPU:2 was not registered
2020-04-11 19:39:36.006289: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 3 does not exist Not found: TensorFlow device GPU:3 was not registered
2020-04-11 19:39:36.006300: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 4 does not exist Not found: TensorFlow device GPU:4 was not registered
2020-04-11 19:39:36.006311: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 5 does not exist Not found: TensorFlow device GPU:5 was not registered
2020-04-11 19:39:36.006321: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 6 does not exist Not found: TensorFlow device GPU:6 was not registered
2020-04-11 19:39:36.006332: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 7 does not exist Not found: TensorFlow device GPU:7 was not registered
2020-04-11 19:39:36.006342: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 8 does not exist Not found: TensorFlow device GPU:8 was not registered
2020-04-11 19:39:36.006352: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 9 does not exist Not found: TensorFlow device GPU:9 was not registered
2020-04-11 19:39:36.006363: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 10 does not exist Not found: TensorFlow device GPU:10 was not registered
2020-04-11 19:39:36.006373: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 11 does not exist Not found: TensorFlow device GPU:11 was not registered
2020-04-11 19:39:36.006384: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 12 does not exist Not found: TensorFlow device GPU:12 was not registered
2020-04-11 19:39:36.006395: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 13 does not exist Not found: TensorFlow device GPU:13 was not registered
2020-04-11 19:39:36.006406: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 14 does not exist Not found: TensorFlow device GPU:14 was not registered
2020-04-11 19:39:36.006416: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 15 does not exist Not found: TensorFlow device GPU:15 was not registered
2020-04-11 19:39:36.006426: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 16 does not exist Not found: TensorFlow device GPU:16 was not registered
2020-04-11 19:39:36.006436: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 17 does not exist Not found: TensorFlow device GPU:17 was not registered
2020-04-11 19:39:36.006447: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 18 does not exist Not found: TensorFlow device GPU:18 was not registered
2020-04-11 19:39:36.006457: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 19 does not exist Not found: TensorFlow device GPU:19 was not registered
2020-04-11 19:39:36.006467: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 20 does not exist Not found: TensorFlow device GPU:20 was not registered
2020-04-11 19:39:36.006478: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 21 does not exist Not found: TensorFlow device GPU:21 was not registered
2020-04-11 19:39:36.006488: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 22 does not exist Not found: TensorFlow device GPU:22 was not registered
2020-04-11 19:39:36.006498: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 23 does not exist Not found: TensorFlow device GPU:23 was not registered
2020-04-11 19:39:36.006509: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 24 does not exist Not found: TensorFlow device GPU:24 was not registered
2020-04-11 19:39:36.006519: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 25 does not exist Not found: TensorFlow device GPU:25 was not registered
2020-04-11 19:39:36.006529: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 26 does not exist Not found: TensorFlow device GPU:26 was not registered
2020-04-11 19:39:36.006540: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 27 does not exist Not found: TensorFlow device GPU:27 was not registered
2020-04-11 19:39:36.006550: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 28 does not exist Not found: TensorFlow device GPU:28 was not registered
2020-04-11 19:39:36.006561: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 29 does not exist Not found: TensorFlow device GPU:29 was not registered
2020-04-11 19:39:36.006571: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 30 does not exist Not found: TensorFlow device GPU:30 was not registered
2020-04-11 19:39:36.006582: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 31 does not exist Not found: TensorFlow device GPU:31 was not registered
2020-04-11 19:39:36.006592: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 32 does not exist Not found: TensorFlow device GPU:32 was not registered
2020-04-11 19:39:36.006602: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 33 does not exist Not found: TensorFlow device GPU:33 was not registered
2020-04-11 19:39:36.006613: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 34 does not exist Not found: TensorFlow device GPU:34 was not registered
2020-04-11 19:39:36.006625: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 35 does not exist Not found: TensorFlow device GPU:35 was not registered
2020-04-11 19:39:36.006636: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 36 does not exist Not found: TensorFlow device GPU:36 was not registered
2020-04-11 19:39:36.006647: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 37 does not exist Not found: TensorFlow device GPU:37 was not registered
2020-04-11 19:39:36.006659: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 38 does not exist Not found: TensorFlow device GPU:38 was not registered
2020-04-11 19:39:36.006670: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 39 does not exist Not found: TensorFlow device GPU:39 was not registered
2020-04-11 19:39:36.006682: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 40 does not exist Not found: TensorFlow device GPU:40 was not registered
2020-04-11 19:39:36.006693: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 41 does not exist Not found: TensorFlow device GPU:41 was not registered
2020-04-11 19:39:36.006705: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 42 does not exist Not found: TensorFlow device GPU:42 was not registered
2020-04-11 19:39:36.006717: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 43 does not exist Not found: TensorFlow device GPU:43 was not registered
2020-04-11 19:39:36.006728: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 44 does not exist Not found: TensorFlow device GPU:44 was not registered
2020-04-11 19:39:36.006738: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 45 does not exist Not found: TensorFlow device GPU:45 was not registered
2020-04-11 19:39:36.006749: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 46 does not exist Not found: TensorFlow device GPU:46 was not registered
2020-04-11 19:39:36.006761: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 47 does not exist Not found: TensorFlow device GPU:47 was not registered
2020-04-11 19:39:36.006772: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 48 does not exist Not found: TensorFlow device GPU:48 was not registered
2020-04-11 19:39:36.006784: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 49 does not exist Not found: TensorFlow device GPU:49 was not registered
2020-04-11 19:39:36.006794: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 50 does not exist Not found: TensorFlow device GPU:50 was not registered
2020-04-11 19:39:36.006805: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 51 does not exist Not found: TensorFlow device GPU:51 was not registered
2020-04-11 19:39:36.006817: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 52 does not exist Not found: TensorFlow device GPU:52 was not registered
2020-04-11 19:39:36.006828: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 53 does not exist Not found: TensorFlow device GPU:53 was not registered
2020-04-11 19:39:36.006838: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 54 does not exist Not found: TensorFlow device GPU:54 was not registered
2020-04-11 19:39:36.006849: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 55 does not exist Not found: TensorFlow device GPU:55 was not registered
2020-04-11 19:39:36.006860: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 56 does not exist Not found: TensorFlow device GPU:56 was not registered
2020-04-11 19:39:36.006872: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 57 does not exist Not found: TensorFlow device GPU:57 was not registered
2020-04-11 19:39:36.006883: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 58 does not exist Not found: TensorFlow device GPU:58 was not registered
2020-04-11 19:39:36.006894: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 59 does not exist Not found: TensorFlow device GPU:59 was not registered
2020-04-11 19:39:36.006905: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 60 does not exist Not found: TensorFlow device GPU:60 was not registered
2020-04-11 19:39:36.006917: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 61 does not exist Not found: TensorFlow device GPU:61 was not registered
2020-04-11 19:39:36.006928: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 62 does not exist Not found: TensorFlow device GPU:62 was not registered
2020-04-11 19:39:36.006939: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 63 does not exist Not found: TensorFlow device GPU:63 was not registered
2020-04-11 19:39:36.006950: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 64 does not exist Not found: TensorFlow device GPU:64 was not registered
2020-04-11 19:39:36.006962: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 65 does not exist Not found: TensorFlow device GPU:65 was not registered
2020-04-11 19:39:36.006972: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 66 does not exist Not found: TensorFlow device GPU:66 was not registered
2020-04-11 19:39:36.006983: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 67 does not exist Not found: TensorFlow device GPU:67 was not registered
2020-04-11 19:39:36.006994: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 68 does not exist Not found: TensorFlow device GPU:68 was not registered
2020-04-11 19:39:36.007011: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 69 does not exist Not found: TensorFlow device GPU:69 was not registered
2020-04-11 19:39:36.007024: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 70 does not exist Not found: TensorFlow device GPU:70 was not registered
2020-04-11 19:39:36.007035: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 71 does not exist Not found: TensorFlow device GPU:71 was not registered
2020-04-11 19:39:36.007045: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 72 does not exist Not found: TensorFlow device GPU:72 was not registered
2020-04-11 19:39:36.007056: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 73 does not exist Not found: TensorFlow device GPU:73 was not registered
2020-04-11 19:39:36.007067: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 74 does not exist Not found: TensorFlow device GPU:74 was not registered
2020-04-11 19:39:36.007078: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 75 does not exist Not found: TensorFlow device GPU:75 was not registered
2020-04-11 19:39:36.007089: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 76 does not exist Not found: TensorFlow device GPU:76 was not registered
2020-04-11 19:39:36.007100: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 77 does not exist Not found: TensorFlow device GPU:77 was not registered
2020-04-11 19:39:36.007110: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 78 does not exist Not found: TensorFlow device GPU:78 was not registered
2020-04-11 19:39:36.007121: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 79 does not exist Not found: TensorFlow device GPU:79 was not registered
2020-04-11 19:39:36.007132: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 80 does not exist Not found: TensorFlow device GPU:80 was not registered
2020-04-11 19:39:36.007142: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 81 does not exist Not found: TensorFlow device GPU:81 was not registered
2020-04-11 19:39:36.007153: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 82 does not exist Not found: TensorFlow device GPU:82 was not registered
2020-04-11 19:39:36.007164: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 83 does not exist Not found: TensorFlow device GPU:83 was not registered
2020-04-11 19:39:36.007175: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 84 does not exist Not found: TensorFlow device GPU:84 was not registered
2020-04-11 19:39:36.007185: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 85 does not exist Not found: TensorFlow device GPU:85 was not registered
2020-04-11 19:39:36.007195: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 86 does not exist Not found: TensorFlow device GPU:86 was not registered
2020-04-11 19:39:36.007206: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 87 does not exist Not found: TensorFlow device GPU:87 was not registered
2020-04-11 19:39:36.007217: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 88 does not exist Not found: TensorFlow device GPU:88 was not registered
2020-04-11 19:39:36.007228: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 89 does not exist Not found: TensorFlow device GPU:89 was not registered
2020-04-11 19:39:36.007240: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 90 does not exist Not found: TensorFlow device GPU:90 was not registered
2020-04-11 19:39:36.007251: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 91 does not exist Not found: TensorFlow device GPU:91 was not registered
2020-04-11 19:39:36.007260: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 92 does not exist Not found: TensorFlow device GPU:92 was not registered
2020-04-11 19:39:36.007272: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 93 does not exist Not found: TensorFlow device GPU:93 was not registered
2020-04-11 19:39:36.007282: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 94 does not exist Not found: TensorFlow device GPU:94 was not registered
2020-04-11 19:39:36.007293: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 95 does not exist Not found: TensorFlow device GPU:95 was not registered
2020-04-11 19:39:36.007304: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 96 does not exist Not found: TensorFlow device GPU:96 was not registered
2020-04-11 19:39:36.007315: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 97 does not exist Not found: TensorFlow device GPU:97 was not registered
2020-04-11 19:39:36.007326: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 98 does not exist Not found: TensorFlow device GPU:98 was not registered
2020-04-11 19:39:36.007338: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 99 does not exist Not found: TensorFlow device GPU:99 was not registered
2020-04-11 19:39:36.007348: W tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:824] Can't identify the cuda device. Running on device 0
2020-04-11 19:39:36.007394: E tensorflow/compiler/tf2tensorrt/utils/trt_logger.cc:41] DefaultLogger CUDA initialization failure with error 38. Please check your CUDA installation:  http://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html
Fatal Python error: Segmentation fault

Current thread 0x00007f02020e7f40 (most recent call first):
  File ""/nix/store/w7dqhlrb6qv0im8hnwl309f13q86pnb4-python3-3.6.10-env/lib/python3.6/site-packages/tensorflow/python/grappler/tf_optimizer.py"", line 41 in OptimizeGraph
  File ""/nix/store/w7dqhlrb6qv0im8hnwl309f13q86pnb4-python3-3.6.10-env/lib/python3.6/site-packages/tensorflow/python/compiler/tensorrt/trt_convert.py"", line 204 in _run_conversion
  File ""/nix/store/w7dqhlrb6qv0im8hnwl309f13q86pnb4-python3-3.6.10-env/lib/python3.6/site-packages/tensorflow/python/compiler/tensorrt/trt_convert.py"", line 226 in _convert_graph_def
  File ""/nix/store/w7dqhlrb6qv0im8hnwl309f13q86pnb4-python3-3.6.10-env/lib/python3.6/site-packages/tensorflow/python/compiler/tensorrt/trt_convert.py"", line 298 in convert
  File ""/nix/store/w7dqhlrb6qv0im8hnwl309f13q86pnb4-python3-3.6.10-env/lib/python3.6/site-packages/tensorflow/python/compiler/tensorrt/trt_convert.py"", line 1146 in create_inference_graph
  File ""/nix/store/w7dqhlrb6qv0im8hnwl309f13q86pnb4-python3-3.6.10-env/lib/python3.6/site-packages/tensorflow/contrib/tensorrt/python/trt_convert.py"", line 51 in create_inference_graph
  File ""test_tensorrt_enabled.py"", line 38 in test_tensorrt_enabled
  File ""/nix/store/w7dqhlrb6qv0im8hnwl309f13q86pnb4-python3-3.6.10-env/lib/python3.6/site-packages/_pytest/python.py"", line 167 in pytest_pyfunc_call
  File ""/nix/store/w7dqhlrb6qv0im8hnwl309f13q86pnb4-python3-3.6.10-env/lib/python3.6/site-packages/pluggy/callers.py"", line 187 in _multicall
  File ""/nix/store/w7dqhlrb6qv0im8hnwl309f13q86pnb4-python3-3.6.10-env/lib/python3.6/site-packages/pluggy/manager.py"", line 87 in <lambda>
  File ""/nix/store/w7dqhlrb6qv0im8hnwl309f13q86pnb4-python3-3.6.10-env/lib/python3.6/site-packages/pluggy/manager.py"", line 93 in _hookexec
  File ""/nix/store/w7dqhlrb6qv0im8hnwl309f13q86pnb4-python3-3.6.10-env/lib/python3.6/site-packages/pluggy/hooks.py"", line 286 in __call__
  File ""/nix/store/w7dqhlrb6qv0im8hnwl309f13q86pnb4-python3-3.6.10-env/lib/python3.6/site-packages/_pytest/python.py"", line 1445 in runtest
  File ""/nix/store/w7dqhlrb6qv0im8hnwl309f13q86pnb4-python3-3.6.10-env/lib/python3.6/site-packages/_pytest/runner.py"", line 134 in pytest_runtest_call
  File ""/nix/store/w7dqhlrb6qv0im8hnwl309f13q86pnb4-python3-3.6.10-env/lib/python3.6/site-packages/pluggy/callers.py"", line 187 in _multicall
  File ""/nix/store/w7dqhlrb6qv0im8hnwl309f13q86pnb4-python3-3.6.10-env/lib/python3.6/site-packages/pluggy/manager.py"", line 87 in <lambda>
  File ""/nix/store/w7dqhlrb6qv0im8hnwl309f13q86pnb4-python3-3.6.10-env/lib/python3.6/site-packages/pluggy/manager.py"", line 93 in _hookexec
  File ""/nix/store/w7dqhlrb6qv0im8hnwl309f13q86pnb4-python3-3.6.10-env/lib/python3.6/site-packages/pluggy/hooks.py"", line 286 in __call__
  File ""/nix/store/w7dqhlrb6qv0im8hnwl309f13q86pnb4-python3-3.6.10-env/lib/python3.6/site-packages/_pytest/runner.py"", line 210 in <lambda>
  File ""/nix/store/w7dqhlrb6qv0im8hnwl309f13q86pnb4-python3-3.6.10-env/lib/python3.6/site-packages/_pytest/runner.py"", line 237 in from_call
  File ""/nix/store/w7dqhlrb6qv0im8hnwl309f13q86pnb4-python3-3.6.10-env/lib/python3.6/site-packages/_pytest/runner.py"", line 210 in call_runtest_hook
  File ""/nix/store/w7dqhlrb6qv0im8hnwl309f13q86pnb4-python3-3.6.10-env/lib/python3.6/site-packages/_pytest/runner.py"", line 185 in call_and_report
  File ""/nix/store/w7dqhlrb6qv0im8hnwl309f13q86pnb4-python3-3.6.10-env/lib/python3.6/site-packages/_pytest/runner.py"", line 99 in runtestprotocol
  File ""/nix/store/w7dqhlrb6qv0im8hnwl309f13q86pnb4-python3-3.6.10-env/lib/python3.6/site-packages/_pytest/runner.py"", line 84 in pytest_runtest_protocol
  File ""/nix/store/w7dqhlrb6qv0im8hnwl309f13q86pnb4-python3-3.6.10-env/lib/python3.6/site-packages/pluggy/callers.py"", line 187 in _multicall
  File ""/nix/store/w7dqhlrb6qv0im8hnwl309f13q86pnb4-python3-3.6.10-env/lib/python3.6/site-packages/pluggy/manager.py"", line 87 in <lambda>
  File ""/nix/store/w7dqhlrb6qv0im8hnwl309f13q86pnb4-python3-3.6.10-env/lib/python3.6/site-packages/pluggy/manager.py"", line 93 in _hookexec
  File ""/nix/store/w7dqhlrb6qv0im8hnwl309f13q86pnb4-python3-3.6.10-env/lib/python3.6/site-packages/pluggy/hooks.py"", line 286 in __call__
  File ""/nix/store/w7dqhlrb6qv0im8hnwl309f13q86pnb4-python3-3.6.10-env/lib/python3.6/site-packages/_pytest/main.py"", line 271 in pytest_runtestloop
  File ""/nix/store/w7dqhlrb6qv0im8hnwl309f13q86pnb4-python3-3.6.10-env/lib/python3.6/site-packages/pluggy/callers.py"", line 187 in _multicall
  File ""/nix/store/w7dqhlrb6qv0im8hnwl309f13q86pnb4-python3-3.6.10-env/lib/python3.6/site-packages/pluggy/manager.py"", line 87 in <lambda>
  File ""/nix/store/w7dqhlrb6qv0im8hnwl309f13q86pnb4-python3-3.6.10-env/lib/python3.6/site-packages/pluggy/manager.py"", line 93 in _hookexec
  File ""/nix/store/w7dqhlrb6qv0im8hnwl309f13q86pnb4-python3-3.6.10-env/lib/python3.6/site-packages/pluggy/hooks.py"", line 286 in __call__
  File ""/nix/store/w7dqhlrb6qv0im8hnwl309f13q86pnb4-python3-3.6.10-env/lib/python3.6/site-packages/_pytest/main.py"", line 247 in _main
  File ""/nix/store/w7dqhlrb6qv0im8hnwl309f13q86pnb4-python3-3.6.10-env/lib/python3.6/site-packages/_pytest/main.py"", line 197 in wrap_session
  File ""/nix/store/w7dqhlrb6qv0im8hnwl309f13q86pnb4-python3-3.6.10-env/lib/python3.6/site-packages/_pytest/main.py"", line 240 in pytest_cmdline_main
  File ""/nix/store/w7dqhlrb6qv0im8hnwl309f13q86pnb4-python3-3.6.10-env/lib/python3.6/site-packages/pluggy/callers.py"", line 187 in _multicall
  File ""/nix/store/w7dqhlrb6qv0im8hnwl309f13q86pnb4-python3-3.6.10-env/lib/python3.6/site-packages/pluggy/manager.py"", line 87 in <lambda>
  File ""/nix/store/w7dqhlrb6qv0im8hnwl309f13q86pnb4-python3-3.6.10-env/lib/python3.6/site-packages/pluggy/manager.py"", line 93 in _hookexec
  File ""/nix/store/w7dqhlrb6qv0im8hnwl309f13q86pnb4-python3-3.6.10-env/lib/python3.6/site-packages/pluggy/hooks.py"", line 286 in __call__
  File ""/nix/store/w7dqhlrb6qv0im8hnwl309f13q86pnb4-python3-3.6.10-env/lib/python3.6/site-packages/_pytest/config/__init__.py"", line 93 in main
  File ""/nix/store/w7dqhlrb6qv0im8hnwl309f13q86pnb4-python3-3.6.10-env/lib/python3.6/site-packages/pytest/__main__.py"", line 7 in <module>
  File ""/nix/store/2ard4hsnrajrxdwvp20kgql2r5j2fl82-python3-3.6.10/lib/python3.6/runpy.py"", line 85 in _run_code
  File ""/nix/store/2ard4hsnrajrxdwvp20kgql2r5j2fl82-python3-3.6.10/lib/python3.6/runpy.py"", line 193 in _run_module_as_main
```

</details>

<details>
<summary>gdb backtrace</summary>

```
#0  0x00007fff359762f7 in tensorflow::tensorrt::convert::ConvertGraphDefToEngine(tensorflow::GraphDef const&, tensorflow::tensorrt::TrtPrecisionMode, int, unsigned long, std::vector<tensorflow::PartialTensorShape, std::allocator<tensorflow::PartialTensorShape> > const&, tensorflow::tensorrt::Logger*, nvinfer1::IGpuAllocator*, tensorflow::tensorrt::TRTInt8Calibrator*, std::unique_ptr<nvinfer1::ICudaEngine, tensorflow::tensorrt::TrtDestroyer<nvinfer1::ICudaEngine> >*, bool, bool*) () from /nix/store/w7dqhlrb6qv0im8hnwl309f13q86pnb4-python3-3.6.10-env/lib/python3.6/site-packages/tensorflow/compiler/tf2tensorrt/python/ops/libtftrt.so
#1  0x00007fff3593f8e0 in tensorflow::tensorrt::convert::CreateTRTNode(tensorflow::tensorrt::convert::ConversionParams const&, std::vector<tensorflow::tensorrt::convert::EngineInfo, std::allocator<tensorflow::tensorrt::convert::EngineInfo> > const&, int, int, tensorflow::Graph*, nvinfer1::IGpuAllocator*, std::vector<tensorflow::Node*, std::allocator<tensorflow::Node*> >*) ()
   from /nix/store/w7dqhlrb6qv0im8hnwl309f13q86pnb4-python3-3.6.10-env/lib/python3.6/site-packages/tensorflow/compiler/tf2tensorrt/python/ops/libtftrt.so
#2  0x00007fff35947551 in tensorflow::tensorrt::convert::ConvertAfterShapes(tensorflow::tensorrt::convert::ConversionParams const&) ()
   from /nix/store/w7dqhlrb6qv0im8hnwl309f13q86pnb4-python3-3.6.10-env/lib/python3.6/site-packages/tensorflow/compiler/tf2tensorrt/python/ops/libtftrt.so
#3  0x00007fff3597ff50 in tensorflow::tensorrt::convert::TRTOptimizationPass::Optimize(tensorflow::grappler::Cluster*, tensorflow::grappler::GrapplerItem const&, tensorflow::GraphDef*) ()
   from /nix/store/w7dqhlrb6qv0im8hnwl309f13q86pnb4-python3-3.6.10-env/lib/python3.6/site-packages/tensorflow/compiler/tf2tensorrt/python/ops/libtftrt.so
#4  0x00007fff9c7d2105 in tensorflow::grappler::MetaOptimizer::RunOptimizer(tensorflow::grappler::GraphOptimizer*, tensorflow::grappler::Cluster*, tensorflow::grappler::GrapplerItem*, tensorflow::GraphDef*, tensorflow::grappler::MetaOptimizer::GraphOptimizationResult*) () from /nix/store/w7dqhlrb6qv0im8hnwl309f13q86pnb4-python3-3.6.10-env/lib/python3.6/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#5  0x00007fff9c7d3631 in tensorflow::grappler::MetaOptimizer::OptimizeGraph(tensorflow::grappler::Cluster*, tensorflow::grappler::GrapplerItem const&, tensorflow::GraphDef*) ()
   from /nix/store/w7dqhlrb6qv0im8hnwl309f13q86pnb4-python3-3.6.10-env/lib/python3.6/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#6  0x00007fff9c7d51fe in tensorflow::grappler::MetaOptimizer::Optimize(tensorflow::grappler::Cluster*, tensorflow::grappler::GrapplerItem const&, tensorflow::GraphDef*) ()
   from /nix/store/w7dqhlrb6qv0im8hnwl309f13q86pnb4-python3-3.6.10-env/lib/python3.6/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#7  0x00007fff94cfaa43 in TF_OptimizeGraph(GCluster, tensorflow::ConfigProto const&, tensorflow::MetaGraphDef const&, bool, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, TF_Status*) ()
   from /nix/store/w7dqhlrb6qv0im8hnwl309f13q86pnb4-python3-3.6.10-env/lib/python3.6/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#8  0x00007fff94d024fa in _wrap_TF_OptimizeGraph () from /nix/store/w7dqhlrb6qv0im8hnwl309f13q86pnb4-python3-3.6.10-env/lib/python3.6/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#9  0x00007ffff7d76cf3 in _PyCFunction_FastCallDict () from /nix/store/2ard4hsnrajrxdwvp20kgql2r5j2fl82-python3-3.6.10/lib/libpython3.6m.so.1.0
#10 0x00007ffff7dfb4c4 in call_function () from /nix/store/2ard4hsnrajrxdwvp20kgql2r5j2fl82-python3-3.6.10/lib/libpython3.6m.so.1.0
#11 0x00007ffff7e0032a in _PyEval_EvalFrameDefault () from /nix/store/2ard4hsnrajrxdwvp20kgql2r5j2fl82-python3-3.6.10/lib/libpython3.6m.so.1.0
#12 0x00007ffff7dfafda in _PyEval_EvalCodeWithName () from /nix/store/2ard4hsnrajrxdwvp20kgql2r5j2fl82-python3-3.6.10/lib/libpython3.6m.so.1.0
#13 0x00007ffff7dfb3d4 in call_function () from /nix/store/2ard4hsnrajrxdwvp20kgql2r5j2fl82-python3-3.6.10/lib/libpython3.6m.so.1.0
#14 0x00007ffff7e00a8f in _PyEval_EvalFrameDefault () from /nix/store/2ard4hsnrajrxdwvp20kgql2r5j2fl82-python3-3.6.10/lib/libpython3.6m.so.1.0
#15 0x00007ffff7dfa5d3 in _PyFunction_FastCall () from /nix/store/2ard4hsnrajrxdwvp20kgql2r5j2fl82-python3-3.6.10/lib/libpython3.6m.so.1.0
#16 0x00007ffff7dfb59c in call_function () from /nix/store/2ard4hsnrajrxdwvp20kgql2r5j2fl82-python3-3.6.10/lib/libpython3.6m.so.1.0
#17 0x00007ffff7e0032a in _PyEval_EvalFrameDefault () from /nix/store/2ard4hsnrajrxdwvp20kgql2r5j2fl82-python3-3.6.10/lib/libpython3.6m.so.1.0
#18 0x00007ffff7dfa5d3 in _PyFunction_FastCall () from /nix/store/2ard4hsnrajrxdwvp20kgql2r5j2fl82-python3-3.6.10/lib/libpython3.6m.so.1.0
#19 0x00007ffff7dfb59c in call_function () from /nix/store/2ard4hsnrajrxdwvp20kgql2r5j2fl82-python3-3.6.10/lib/libpython3.6m.so.1.0
#20 0x00007ffff7e0032a in _PyEval_EvalFrameDefault () from /nix/store/2ard4hsnrajrxdwvp20kgql2r5j2fl82-python3-3.6.10/lib/libpython3.6m.so.1.0
#21 0x00007ffff7dfa5d3 in _PyFunction_FastCall () from /nix/store/2ard4hsnrajrxdwvp20kgql2r5j2fl82-python3-3.6.10/lib/libpython3.6m.so.1.0
#22 0x00007ffff7dfb59c in call_function () from /nix/store/2ard4hsnrajrxdwvp20kgql2r5j2fl82-python3-3.6.10/lib/libpython3.6m.so.1.0
#23 0x00007ffff7e0032a in _PyEval_EvalFrameDefault () from /nix/store/2ard4hsnrajrxdwvp20kgql2r5j2fl82-python3-3.6.10/lib/libpython3.6m.so.1.0
#24 0x00007ffff7dfafda in _PyEval_EvalCodeWithName () from /nix/store/2ard4hsnrajrxdwvp20kgql2r5j2fl82-python3-3.6.10/lib/libpython3.6m.so.1.0
#25 0x00007ffff7dfb3d4 in call_function () from /nix/store/2ard4hsnrajrxdwvp20kgql2r5j2fl82-python3-3.6.10/lib/libpython3.6m.so.1.0
#26 0x00007ffff7e00a8f in _PyEval_EvalFrameDefault () from /nix/store/2ard4hsnrajrxdwvp20kgql2r5j2fl82-python3-3.6.10/lib/libpython3.6m.so.1.0
#27 0x00007ffff7dfafda in _PyEval_EvalCodeWithName () from /nix/store/2ard4hsnrajrxdwvp20kgql2r5j2fl82-python3-3.6.10/lib/libpython3.6m.so.1.0
#28 0x00007ffff7dfb3d4 in call_function () from /nix/store/2ard4hsnrajrxdwvp20kgql2r5j2fl82-python3-3.6.10/lib/libpython3.6m.so.1.0
#29 0x00007ffff7e00a8f in _PyEval_EvalFrameDefault () from /nix/store/2ard4hsnrajrxdwvp20kgql2r5j2fl82-python3-3.6.10/lib/libpython3.6m.so.1.0
#30 0x00007ffff7dfafda in _PyEval_EvalCodeWithName () from /nix/store/2ard4hsnrajrxdwvp20kgql2r5j2fl82-python3-3.6.10/lib/libpython3.6m.so.1.0
#31 0x00007ffff7dfb5ee in PyEval_EvalCodeEx () from /nix/store/2ard4hsnrajrxdwvp20kgql2r5j2fl82-python3-3.6.10/lib/libpython3.6m.so.1.0
#32 0x00007ffff7d4f60e in function_call () from /nix/store/2ard4hsnrajrxdwvp20kgql2r5j2fl82-python3-3.6.10/lib/libpython3.6m.so.1.0
#33 0x00007ffff7d21087 in PyObject_Call () from /nix/store/2ard4hsnrajrxdwvp20kgql2r5j2fl82-python3-3.6.10/lib/libpython3.6m.so.1.0
#34 0x00007ffff7e0084c in _PyEval_EvalFrameDefault () from /nix/store/2ard4hsnrajrxdwvp20kgql2r5j2fl82-python3-3.6.10/lib/libpython3.6m.so.1.0
#35 0x00007ffff7dfafda in _PyEval_EvalCodeWithName () from /nix/store/2ard4hsnrajrxdwvp20kgql2r5j2fl82-python3-3.6.10/lib/libpython3.6m.so.1.0
#36 0x00007ffff7dfb5ee in PyEval_EvalCodeEx () from /nix/store/2ard4hsnrajrxdwvp20kgql2r5j2fl82-python3-3.6.10/lib/libpython3.6m.so.1.0
#37 0x00007ffff7d4f52e in function_call () from /nix/store/2ard4hsnrajrxdwvp20kgql2r5j2fl82-python3-3.6.10/lib/libpython3.6m.so.1.0
#38 0x00007ffff7d21087 in PyObject_Call () from /nix/store/2ard4hsnrajrxdwvp20kgql2r5j2fl82-python3-3.6.10/lib/libpython3.6m.so.1.0
#39 0x00007ffff7e0084c in _PyEval_EvalFrameDefault () from /nix/store/2ard4hsnrajrxdwvp20kgql2r5j2fl82-python3-3.6.10/lib/libpython3.6m.so.1.0
#40 0x00007ffff7dfafda in _PyEval_EvalCodeWithName () from /nix/store/2ard4hsnrajrxdwvp20kgql2r5j2fl82-python3-3.6.10/lib/libpython3.6m.so.1.0
#41 0x00007ffff7dfb3d4 in call_function () from /nix/store/2ard4hsnrajrxdwvp20kgql2r5j2fl82-python3-3.6.10/lib/libpython3.6m.so.1.0
#42 0x00007ffff7e00a8f in _PyEval_EvalFrameDefault () from /nix/store/2ard4hsnrajrxdwvp20kgql2r5j2fl82-python3-3.6.10/lib/libpython3.6m.so.1.0
#43 0x00007ffff7dfafda in _PyEval_EvalCodeWithName () from /nix/store/2ard4hsnrajrxdwvp20kgql2r5j2fl82-python3-3.6.10/lib/libpython3.6m.so.1.0
#44 0x00007ffff7dfb3d4 in call_function () from /nix/store/2ard4hsnrajrxdwvp20kgql2r5j2fl82-python3-3.6.10/lib/libpython3.6m.so.1.0
#45 0x00007ffff7e0032a in _PyEval_EvalFrameDefault () from /nix/store/2ard4hsnrajrxdwvp20kgql2r5j2fl82-python3-3.6.10/lib/libpython3.6m.so.1.0
#46 0x00007ffff7dfa5d3 in _PyFunction_FastCall () from /nix/store/2ard4hsnrajrxdwvp20kgql2r5j2fl82-python3-3.6.10/lib/libpython3.6m.so.1.0
#47 0x00007ffff7dfb59c in call_function () from /nix/store/2ard4hsnrajrxdwvp20kgql2r5j2fl82-python3-3.6.10/lib/libpython3.6m.so.1.0
#48 0x00007ffff7e0032a in _PyEval_EvalFrameDefault () from /nix/store/2ard4hsnrajrxdwvp20kgql2r5j2fl82-python3-3.6.10/lib/libpython3.6m.so.1.0
#49 0x00007ffff7dfafda in _PyEval_EvalCodeWithName () from /nix/store/2ard4hsnrajrxdwvp20kgql2r5j2fl82-python3-3.6.10/lib/libpython3.6m.so.1.0
#50 0x00007ffff7e03c37 in _PyFunction_FastCallDict () from /nix/store/2ard4hsnrajrxdwvp20kgql2r5j2fl82-python3-3.6.10/lib/libpython3.6m.so.1.0
#51 0x00007ffff7d212a1 in _PyObject_FastCallDict () from /nix/store/2ard4hsnrajrxdwvp20kgql2r5j2fl82-python3-3.6.10/lib/libpython3.6m.so.1.0
```

</details>

<details>
<summary>disassembly/registers</summary>

```
...
   0x00007fff359762db <+155>:	je     0x7fff359762e0 <_ZN10tensorflow8tensorrt7convert23ConvertGraphDefToEngineERKNS_8GraphDefENS0_16TrtPrecisionModeEimRKSt6vectorINS_18PartialTensorShapeESaIS7_EEPNS0_6LoggerEPN8nvinfer113IGpuAllocatorEPNS0_17TRTInt8CalibratorEPSt10unique_ptrINSE_11ICudaEngineENS0_12TrtDestroyerISK_EEEbPb+160>
   0x00007fff359762dd <+157>:	movb   $0x0,(%rcx)
   0x00007fff359762e0 <+160>:	mov    $0x1b58,%esi
   0x00007fff359762e5 <+165>:	mov    %rax,%rdi
   0x00007fff359762e8 <+168>:	callq  0x7fff35923510 <createInferBuilder_INTERNAL@plt>
   0x00007fff359762ed <+173>:	mov    %rax,%rdi
   0x00007fff359762f0 <+176>:	mov    %rax,-0x440(%rbp)
=> 0x00007fff359762f7 <+183>:	mov    (%rax),%rax
   0x00007fff359762fa <+186>:	mov    %r15d,%esi
   0x00007fff359762fd <+189>:	mov    %rdi,%r15
   0x00007fff35976300 <+192>:	callq  *0x8(%rax)
   0x00007fff35976303 <+195>:	mov    (%r15),%rax
...

(gdb) info registers
rax            0x0                 0
....
```

</details>

I suspect that what’s happening is that `nvinfer1::createInferBuilder` [here](https://github.com/tensorflow/tensorflow/blob/00fad90125b18b80fe054de1055770cfb8fe4ba3/tensorflow/compiler/tf2tensorrt/convert/convert_nodes.cc#L4917) returns a nullptr (becaue of missing GPU) and then tensorflow dereferences it without checking the return value.

From what I can see this issue is still present [in master](https://github.com/tensorflow/tensorflow/blob/20a26f65d08ed37232a5adb19d9762bf65b6d761/tensorflow/compiler/tf2tensorrt/convert/convert_nodes.cc#L1204) – the `trt_builder_` is never checked for nullptr before it is dereferenced with `->` a couple lines below. 

**Describe the expected behavior**

Tensorflow should return an error/raise an exception instead of trying to dereference a nullptr.

**Standalone code to reproduce the issue** 

```python
import tensorflow as tf
import tensorflow.contrib.slim as slim
import tensorflow.contrib.tensorrt as trt

with tf.Session() as sess:
    input0 = tf.placeholder(tf.float32, [10, 3, 224, 224])
    out = input0

    out = slim.batch_norm(out, data_format=""NHWC"", scope=""bn2"")
    with slim.arg_scope([slim.conv2d, slim.batch_norm], data_format=""NCHW""), slim.arg_scope(
        [slim.batch_norm]
    ):
        out = slim.conv2d(
            out, 64, [3, 3], normalizer_fn=slim.batch_norm, activation_fn=tf.nn.relu
        )
        out = slim.conv2d(out, 64, [3, 3], normalizer_fn=slim.batch_norm)
        out = tf.identity(out)
    out = tf.identity(out)
    out_name = out.name[:-2]

    init = tf.global_variables_initializer()
    sess.run(init)

    frozen_graph = tf.graph_util.convert_variables_to_constants(
        sess, tf.get_default_graph().as_graph_def(), output_node_names=[out_name]
    )

    trt_graph = trt.create_inference_graph(
        frozen_graph,
        [out_name],
        max_batch_size=10,
        is_dynamic_op=False,
    )
```"
38459,Both 'mean' and 'variance' must be None when is_training is True and exponential_avg_factor == 1.0,"**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04): Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if
the issue happens on mobile device:  No
- TensorFlow installed from (source or
binary): - TensorFlow version (use command below): 2.2.0-dev20200411
- Python version: 3.6.3
- Bazel
version (if compiling from source): 
- GCC/Compiler version (if compiling from
source): 
- CUDA/cuDNN version: 10.1- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
When instantiating a batch norm layer like this:
tf.keras.layers.BatchNormalization(momentum=0.0, center=True, scale=False, name='bn1')
I get the error:
Both 'mean' and 'variance' must be None when is_training is True and exponential_avg_factor == 1.0
**Describe the expected behavior**
It is not always the expected behavior. Consider meta-learning for example. We are going to see just one batch of training data and we want to adapt all means and variances to this batch, this means the momentum should be zero.
Then after applying a few training iterations, we evaluate on the same batch norm layer with training=False and that also should work fine.
**Standalone code to reproduce the issue** 
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.
```
import tensorflow as tf
import numpy as np

inp = tf.keras.layers.Input(shape=(84, 84, 3))
dense = tf.keras.layers.Conv2D(10, 3, activation=None)(inp)
bn = tf.keras.layers.BatchNormalization(momentum=0.0, center=True, scale=False, name='bn1')(dense)
rel = tf.keras.layers.ReLU()(bn)
flat = tf.keras.layers.Flatten()(rel)
out = tf.keras.layers.Dense(1, )(flat)
model = tf.keras.models.Model(inputs=inp, outputs=out)

model.compile(loss=tf.keras.losses.MeanSquaredError(), optimizer=tf.keras.optimizers.Adam())
model.fit(x=np.random.uniform(size=(4, 84, 84, 3)), y=np.random.uniform(size=(4, 1)), epochs=1)
model.evaluate(x=np.random.uniform(size=(3, 84, 84, 3)), y=np.random.uniform(size=(3, 1)))
model.predict(x=np.random.uniform(size=(1, 84, 84, 3)))
```

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached."
38458,Uncertain training and validation generators behaviour,"**System information** 
- Have I written custom code: Yes
- OS Platform and Distribution: Windows 10 Home N 1909 
- TensorFlow installed from: Anaconda
- Python version: 3.7
- CUDA/cuDNN version: 10.0
- GPU model and memory: GeForce RTX 2060

**Describe the current behavior**

The generator function for images datasets that I'm using is as follow:

```python
def generator(batchsize, epochs, epoch_steps, train=False, val=False, test=False, shuffle=False):
    with tf.Session() as sess:      
        if (train):
            dataset = tf.data.Dataset.from_generator(lambda: image_gen(train_paths, train_scores),
                                                      output_types=(tf.float32, tf.float32))
        elif(val):
            dataset = tf.data.Dataset.from_generator(lambda: image_gen(val_paths, val_scores),
                                                      output_types=(tf.float32, tf.float32))
        else:
            dataset = tf.data.Dataset.from_generator(lambda: image_gen(test_paths),
                                                      output_types=(tf.float32))       

        if (shuffle and train):
            dataset = dataset.shuffle(buffer_size=dataset_size(train=True)) 
        elif (shuffle and val):
                dataset = dataset.shuffle(buffer_size=dataset_size(val=True)) 
        elif (shuffle and test):
                dataset = dataset.shuffle(buffer_size=dataset_size(test=True)) 
            
        dataset = dataset.batch(batchsize)
        dataset = dataset.map(pre_processing_image,
                              num_parallel_calls=tf.data.experimental.AUTOTUNE)
        dataset = dataset.prefetch(1)
        dataset = dataset.repeat(count = -1)
        
        iterable = tf.data.make_initializable_iterator(dataset)
        batch = iterable.get_next()
        sess.run(iterable.initializer)
        
        while True:
            try:
                data = sess.run(batch)
                yield data
            except:
                break
```

How the training script uses these generators is:

```python
training_steps = math.ceil(dataset_training_size / batchsize)
val_steps = math.ceil(dataset_val_size / batchsize)    
    
# Training and validation generator functions
train_generator = generator(batchsize=batchsize,
                            epochs = epochs_to_train,
                            epoch_steps = training_steps, 
                            train=True, 
                            shuffle=True)
val_generator = generator(batchsize=batchsize,
                          epochs = epochs_to_train,
                          epoch_steps = val_steps,
                          val=True)

model.fit_generator(generator=train_generator,
                    steps_per_epoch=training_steps,
                    epochs=epochs_to_train+loaded_epoch,
                    verbose=1,
                    callbacks=callBacks,
                    initial_epoch=loaded_epoch,
                    validation_data=val_generator,
                    validation_steps=val_steps)
```

Both training and validation datasets are very large while the batch size is a lot smaller, also the last step of each epoch has less images compared to the previous (dataset_size%batch_size != 0). What I want to accomplish during each epoch, for both generators, is to use all images one time only, possibly with randomness in their order during the training and not during the validation.
I made some tests with the following code and they the results are what I expect them to be

```python
a = []
b = []

try:
    for i in range(training_steps * epochs_to_train):
        a.append(next(train_generator))
except:
    pass

try:    
    for el in range(val_steps * epochs_to_train):
        b.append(next(val_generator))
except:
    pass
```

The current main problem with my code is that at the end of the last epoch I get this error:

```
IndexError: pop from empty list
Exception ignored in: <generator object generator at 0x00000226437494C8>
Traceback (most recent call last):
  File ""..."", line 448, in generator
    break
  File ""..."", line 1621, in __exit__
    self._default_graph_context_manager.__exit__(exec_type, exec_value, exec_tb)
  File ""...\Anaconda3\envs\tensorflow\lib\contextlib.py"", line 119, in __exit__
    next(self.gen)
  File ""...\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow_core\python\framework\ops.py"", line 5484, in get_controller
    context.context().context_switches.pop()
  File ""...\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow_core\python\eager\context.py"", line 237, in pop
    self.stack.pop()
IndexError: pop from empty list
```

This error is present for both generators but I think it isn't a complete issue, the training seems to end anyway and all models are correctly saved. I just don't know how to remove that exception and I don't want to publish the code with it.
I tried to mess with everything regarding mostly

```python
while True:
     try:
         data = sess.run(batch)
         yield data
     except:
         break
```

but I couldn't find a setup that ended the training without any exception.

The only similar issue that I could find online was https://stackoverflow.com/questions/52303130/keras-generator-with-tensorflow-dataset-api-indexerror-pop-from-empty-list/52304848 but the solution isn't working for me.

Also, during my various attempts I tried to change the generators as follow 

```python
#dataset = dataset.repeat(count = -1)
dataset = dataset.repeat(count = epochs)
```

```python
cnt = 0
#while True:
while cnt < epochs * epoch_steps
            try:
                data = sess.run(batch)
                cnt+=1
                yield data
            except:
                break
```
but in both cases I get the following error after some epochs:

```
  File ""...\train_model.py"", line 325, in <module>
    main()

  File ""...\train_model.py"", line 305, in main
    validation_steps=val_steps)

  File ""...\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow_core\python\keras\engine\training.py"", line 1296, in fit_generator
    steps_name='steps_per_epoch')

  File ""...\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow_core\python\keras\engine\training_generator.py"", line 323, in model_iteration
    steps_name='validation_steps')

  File ""...\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow_core\python\keras\engine\training_generator.py"", line 221, in model_iteration
    batch_data = _get_next_batch(generator)

  File ""...\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow_core\python\keras\engine\training_generator.py"", line 363, in _get_next_batch
    generator_output = next(generator)

  File ""...\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow_core\python\keras\utils\data_utils.py"", line 922, in get
    six.reraise(*sys.exc_info())

  File ""...\Anaconda3\envs\tensorflow\lib\site-packages\six.py"", line 703, in reraise
    raise value

  File ""...\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow_core\python\keras\utils\data_utils.py"", line 898, in get
    inputs = self.queue.get(block=True).get()

  File ""...\Anaconda3\envs\tensorflow\lib\multiprocessing\pool.py"", line 657, in get
    raise self._value

  File ""...\Anaconda3\envs\tensorflow\lib\multiprocessing\pool.py"", line 121, in worker
    result = (True, func(*args, **kwds))

  File ""...\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow_core\python\keras\utils\data_utils.py"", line 832, in next_sample
    return six.next(_SHARED_SEQUENCES[uid])

  File ""..."", line 448, in generator
    break

  File ""...\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow_core\python\client\session.py"", line 1621, in __exit__
    self._default_graph_context_manager.__exit__(exec_type, exec_value, exec_tb)

  File ""...\Anaconda3\envs\tensorflow\lib\contextlib.py"", line 119, in __exit__
    next(self.gen)

  File ""...\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow_core\python\framework\ops.py"", line 5484, in get_controller
    context.context().context_switches.pop()

  File ""...\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow_core\python\eager\context.py"", line 237, in pop
    self.stack.pop()

IndexError: pop from empty list

```

To my understanding if epochs and epoch_steps are set as the # of epochs and the steps for each epoch there shouldn't have been any problem..

I wrote here on GitHub because I'm not sure this is me not understanding what is wrong with my generators or if there is a bug. I didn't provide a complete code because it is very long and I think the important parts are present, if you need more informations I can provide them"
38457,Random NaN loss when using float16 dtype and batch size of 1,"__System information__ 
- Platform: Ubuntu Linux (Kernel 5.3) with Python 3.6.9 **OR** Google Colab
- Tested on TensorFlow: TF v2.1.0 and TF v2.2.0rc2

__Background__
I came across the following bug in one of my Tensorflow projects and was able to successfully reproduce the bug with minimal code in a Google colab. Please see the link to this colab below. The execution of this colab also shows the bug occuring in iteration 248.

__Reproducing Code__
see: [https://colab.research.google.com/drive/1ZzeqGSOKL5qw9j7XPqdlkHQvFAZETU5O](https://colab.research.google.com/drive/1ZzeqGSOKL5qw9j7XPqdlkHQvFAZETU5O)

```
import math
import numpy as np
import tensorflow as tf


if __name__ == '__main__':

    x = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])
    y = np.array([[0], [1], [1], [0]])

    loss_function = tf.keras.losses.BinaryCrossentropy()

    for i in range(2000):
        if i % 100 == 0:
            print(""Iteration {}"".format(i))

        model = tf.keras.Sequential([
            tf.keras.layers.Dense(units=1, activation='tanh', dtype=tf.float16)])

        model.compile(optimizer='sgd', loss=loss_function)
        model.fit(x=x, y=y, epochs=1, batch_size=1)

        loss_result = loss_function(y, model(x))

        if math.isnan(loss_result):
            raise RuntimeError('NAN Error in iteration {}'.format(i))
```

__Behaviour Description__
Seemingly non-deterministic occurence of a NaN result when calculating loss of a very simple Dense Model. The NaN loss seems to happen randomly and can occur on the 60th or 600th iteration. In the supplied Google colab code it happened in the 248th iteration. The bug only seems to occur using a dtype of float16 and batch_size of 1. Debugging the error lead me to see that the models producing a NaN loss seem to have been initialized with a NaN bias and kernel, though I couldn't get to the bottom of why.
"
38456,apply_gradients() return error unexpected keyword argument 'all_reduce_sum_gradients' using official.nlp.optimization,"System information
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Google Colab
TensorFlow version and how it was installed (source or binary): tf-nightly 2.2.0-dev20200408 (pip install) and 2.1 stable version
TensorFlow-Addons version and how it was installed (source or binary):
Python version:
Is GPU used? (yes/no): TPU
Describe the bug

A clear and concise description of what the bug is.

Code to reproduce the issue
////start code
optimizer = optimization.create_optimizer(
init_lr=INIT_LR,
num_train_steps=NB_BATCHES_TRAIN, # per epochs
num_warmup_steps=WARMUP_STEPS)

def squad_loss_fn(labels, model_outputs):
start_positions = labels['start_positions']
end_positions = labels['end_positions']
start_logits, end_logits = model_outputs

start_loss = tf.keras.backend.sparse_categorical_crossentropy(
    start_positions, start_logits, from_logits=True)

end_loss = tf.keras.backend.sparse_categorical_crossentropy(
    end_positions, end_logits, from_logits=True)

total_loss = (tf.reduce_mean(start_loss) + tf.reduce_mean(end_loss)) / 2
return total_loss
train_loss = tf.keras.metrics.Mean(name=""train_loss"")

bert_squad.compile(optimizer,
squad_loss_fn)

Training loop
NB_EPOCHS = 3
for epoch in range(NB_EPOCHS):
print(""Start of epoch {}"".format(epoch+1))
start = time.time()

train_loss.reset_states() 

for (batch, (inputs, targets)) in enumerate(train_dataset_light):
    with tf.GradientTape() as tape:
      model_outputs = bert_squad(inputs)
      loss = squad_loss_fn(targets, model_outputs)
    grads = tape.gradient(loss, bert_squad.trainable_variables) 
    optimizer.apply_gradients(zip(grads, bert_squad.trainable_variables))
    #optimizer.apply_gradients(zip(grads, bert_squad.trainable_variables), name=None, all_reduce_sum_gradients=True))
    
    train_loss(loss)
///// end code

Other info / logs

same issue here : Missing argument in apply_gradients() in AdamW optimizer #1267"
38455,SIGSEGV in  gemmlowp::PackSideBlockImpl tflite/C++ on Jetson Nano,"I have been trying to build and use tflite on Jetson Nano. However, I am always running into SIGSEGV somewhere in the framework. E.g. with v.1.15.0:

TF lite is built by cd'ing into the tools/make, calling the script for getting the dependencies and for building the generic aarch64_armv8-a.

Any help or ideas for the reason would be appreciated.

Regards

#0  0x0000005555a46e4c in gemmlowp::PackSideBlockImpl<gemmlowp::SideMap<unsigned char const, (gemmlowp::SideMapOrder)0>, gemmlowp::PackedSideBlock<gemmlowp::KernelSideFormatInt8<gemmlowp::CellFormat<4, 16, (gemmlowp::CellOrder)1>, 1> > >::PackL2() ()
#1  0x0000005555a52be0 in void gemmlowp::SingleThreadGemm<gemmlowp::KernelFormat<gemmlowp::KernelSideFormatInt8<gemmlowp::CellFormat<4, 16, (gemmlowp::CellOrder)1>, 1>, gemmlowp::KernelSideFormatInt8<gemmlowp::CellFormat<4, 16, (gemmlowp::CellOrder)1>, 1> >, unsigned char, unsigned char, gemmlowp::BitDepthParams<gemmlowp::OperandRange<1, 255>, gemmlowp::OperandRange<0, 255> >, (gemmlowp::MapOrder)1, (gemmlowp::MapOrder)0, (gemmlowp::MapOrder)1, gemmlowp::VectorDup<int const, (gemmlowp::VectorShape)1>, gemmlowp::VectorDup<int const, (gemmlowp::VectorShape)0>, std::tuple<gemmlowp::OutputStageBiasAddition<gemmlowp::VectorMap<int const, (gemmlowp::VectorShape)1> >, gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent, gemmlowp::OutputStageClamp, gemmlowp::OutputStageSaturatingCastToUint8> >(gemmlowp::SingleThreadGemmContext*, gemmlowp::KernelBase const&, gemmlowp::MatrixMap<unsigned char const, (gemmlowp::MapOrder)1> const&, gemmlowp::MatrixMap<unsigned char const, (gemmlowp::MapOrder)0> const&, gemmlowp::MatrixMap<unsigned char, (gemmlowp::MapOrder)1>*, gemmlowp::VectorDup<int const, (gemmlowp::VectorShape)1> const&, gemmlowp::VectorDup<int const, (gemmlowp::VectorShape)0> const&, std::tuple<gemmlowp::OutputStageBiasAddition<gemmlowp::VectorMap<int const, (gemmlowp::VectorShape)1> >, gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent, gemmlowp::OutputStageClamp, gemmlowp::OutputStageSaturatingCastToUint8> const&) ()
#2  0x0000005555a53384 in void gemmlowp::MultiThreadGemm<gemmlowp::KernelFormat<gemmlowp::KernelSideFormatInt8<gemmlowp::CellFormat<4, 16, (gemmlowp::CellOrder)1>, 1>, gemmlowp::KernelSideFormatInt8<gemmlowp::CellFormat<4, 16, (gemmlowp::CellOrder)1>, 1> >, unsigned char, unsigned char, gemmlowp::BitDepthParams<gemmlowp::OperandRange<1, 255>, gemmlowp::OperandRange<0, 255> >, (gemmlowp::MapOrder)1, (gemmlowp::MapOrder)0, (gemmlowp::MapOrder)1, gemmlowp::VectorDup<int const, (gemmlowp::VectorShape)1>, gemmlowp::VectorDup<int const, (gemmlowp::VectorShape)0>, std::tuple<gemmlowp::OutputStageBiasAddition<gemmlowp::VectorMap<int const, (gemmlowp::VectorShape)1> >, gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent, gemmlowp::OutputStageClamp, gemmlowp::OutputStageSaturatingCastToUint8>, gemmlowp::GemmContext>(gemmlowp::GemmContext*, gemmlowp::KernelBase const&, gemmlowp::MatrixMap<unsigned char const, (gemmlowp::MapOrder)1> const&, gemmlowp::MatrixMap<unsigned char const, (gemmlowp::MapOrder)0> const&, gemmlowp::MatrixMap<unsigned char, (gemmlowp::MapOrder)1>*, gemmlowp::VectorDup<int const, (gemmlowp::VectorShape)1> const&, gemmlowp::VectorDup<int const, (gemmlowp::VectorShape)0> const&, std::tuple<gemmlowp::OutputStageBiasAddition<gemmlowp::VectorMap<int const, (gemmlowp::VectorShape)1> >, gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent, gemmlowp::OutputStageClamp, gemmlowp::OutputStageSaturatingCastToUint8> const&) ()
#3  0x0000005555a54ad0 in void gemmlowp::DispatchGemmShape<unsigned char, unsigned char, gemmlowp::BitDepthParams<gemmlowp::OperandRange<1, 255>, gemmlowp::OperandRange<0, 255> >, (gemmlowp::MapOrder)1, (gemmlowp::MapOrder)0, (gemmlowp::MapOrder)0, gemmlowp::VectorDup<int const, (gemmlowp::VectorShape)0>, gemmlowp::VectorDup<int const, (gemmlowp::VectorShape)1>, std::tuple<gemmlowp::OutputStageBiasAddition<gemmlowp::VectorMap<int const, (gemmlowp::VectorShape)0> >, gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent, gemmlowp::OutputStageClamp, gemmlowp::OutputStageSaturatingCastToUint8>, gemmlowp::GemmContext>(gemmlowp::GemmContext*, gemmlowp::MatrixMap<unsigned char const, (gemmlowp::MapOrder)1> const&, gemmlowp::MatrixMap<unsigned char const, (gemmlowp::MapOrder)0> const&, gemmlowp::MatrixMap<unsigned char, (gemmlowp::MapOrder)0>*, gemmlowp::VectorDup<int const, (gemmlowp::VectorShape)0> const&, gemmlowp::VectorDup<int const, (gemmlowp::VectorShape)1> const&, std::tuple<gemmlowp::OutputStageBiasAddition<gemmlowp::VectorMap<int const, (gemmlowp::VectorShape)0> >, gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent, gemmlowp::OutputStageClamp, gemmlowp::OutputStageSaturatingCastToUint8> const&) ()
#4  0x0000005555a54d0c in tflite::optimized_ops::Conv(tflite::ConvParams const&, tflite::RuntimeShape const&, unsigned char const*, tflite::RuntimeShape const&, unsigned char const*, tflite::RuntimeShape const&, int const*, tflite::RuntimeShape const&, unsigned char*, tflite::RuntimeShape const&, unsigned char*, tflite::CpuBackendContext*) ()
#5  0x0000005555a554d8 in void tflite::ops::builtin::conv::EvalQuantized<(tflite::ops::builtin::conv::KernelType)2>(TfLiteContext*, TfLiteNode*, TfLiteConvParams*, tflite::ops::builtin::conv::OpData*, TfLiteTensor*, TfLiteTensor*, TfLiteTensor*, TfLiteTensor*, TfLiteTensor*, TfLiteTensor*) ()
#6  0x0000005555a6541c in TfLiteStatus tflite::ops::builtin::conv::Eval<(tflite::ops::builtin::conv::KernelType)2>(TfLiteContext*, TfLiteNode*) ()
#7  0x00000055559d73a0 in tflite::Subgraph::Invoke() ()
#8  0x00000055559647dc in tflite::Interpreter::Invoke() ()
#9  0x0000005555960cc4 in ObjectDetector::infer(cv::Mat&) (this=0x7fffffe7d0, img=...)"
38454,Tensor array can't be read when passed as argument of tf.function decorated functions,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow): true
- OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04): Windows 10
- TensorFlow installed from (source or
binary): pip
- TensorFlow version (use command below): v2.1.0-rc2-17-ge5bf8de410 2.1.0

**Describe the current behavior**
When trying to read from a tensor array _passed as an argument_ to a tf.function decorated function, it raises an OperatorNotAllowedError:

> OperatorNotAllowedInGraphError: using a `tf.Tensor` as a Python `bool` is not allowed: AutoGraph did not convert this function. Try decorating it directly with @tf.function.

**Describe the expected behavior**
It should work the same way in autograph and eager mode

**Standalone code to reproduce the issue** 
```python
def fun(a, tensor_array):
    loss = tf.constant(0.)
    x, y = tf.constant(0.), tf.constant(0.)
    size = tensor_array.size()
    for i in tf.range(size):
        x, y = tensor_array.read(i)
        loss += a * tf.abs(y - x) # Some dummy computation.
    return loss

decorated_fun = tf.function(fun)

data = [(1., 1.)] * 10
a_tensor_array = tf.TensorArray(dtype=tf.float32, element_shape=[2,], size=0, dynamic_size=True)
a_tensor_array = a_tensor_array.unstack(data)

a_tensor = tf.constant(1.)

print(fun(a_tensor, a_tensor_array))
print(decorated_fun(a_tensor, a_tensor_array))
```

Full traceback:

```
 ---------------------------------------------------------------------------
OperatorNotAllowedInGraphError            Traceback (most recent call last)
<ipython-input-36-fafbbc1bd984> in <module>
     17 
     18 print(fun(a_tensor, a_tensor_array))
---> 19 print(decorated_fun(a_tensor, a_tensor_array))
     20 

C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\eager\def_function.py in __call__(self, *args, **kwds)
    566         xla_context.Exit()
    567     else:
--> 568       result = self._call(*args, **kwds)
    569 
    570     if tracing_count == self._get_tracing_count():

C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\eager\def_function.py in _call(self, *args, **kwds)
    613       # This is the first call of __call__, so we have to initialize.
    614       initializers = []
--> 615       self._initialize(args, kwds, add_initializers_to=initializers)
    616     finally:
    617       # At this point we know that the initialization is complete (or less

C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\eager\def_function.py in _initialize(self, args, kwds, add_initializers_to)
    495     self._concrete_stateful_fn = (
    496         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access
--> 497             *args, **kwds))
    498 
    499     def invalid_creator_scope(*unused_args, **unused_kwds):

C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\eager\function.py in _get_concrete_function_internal_garbage_collected(self, *args, **kwargs)
   2387       args, kwargs = None, None
   2388     with self._lock:
-> 2389       graph_function, _, _ = self._maybe_define_function(args, kwargs)
   2390     return graph_function
   2391 

C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\eager\function.py in _maybe_define_function(self, args, kwargs)
   2701 
   2702       self._function_cache.missed.add(call_context_key)
-> 2703       graph_function = self._create_graph_function(args, kwargs)
   2704       self._function_cache.primary[cache_key] = graph_function
   2705       return graph_function, args, kwargs

C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\eager\function.py in _create_graph_function(self, args, kwargs, override_flat_arg_shapes)
   2591             arg_names=arg_names,
   2592             override_flat_arg_shapes=override_flat_arg_shapes,
-> 2593             capture_by_value=self._capture_by_value),
   2594         self._function_attributes,
   2595         # Tell the ConcreteFunction to clean up its graph once it goes out of

C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\framework\func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)
    976                                           converted_func)
    977 
--> 978       func_outputs = python_func(*func_args, **func_kwargs)
    979 
    980       # invariant: `func_outputs` contains only Tensors, CompositeTensors,

C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\eager\def_function.py in wrapped_fn(*args, **kwds)
    437         # __wrapped__ allows AutoGraph to swap in a converted function. We give
    438         # the function a weak reference to itself to avoid a reference cycle.
--> 439         return weak_wrapped_fn().__wrapped__(*args, **kwds)
    440     weak_wrapped_fn = weakref.ref(wrapped_fn)
    441 

C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\framework\func_graph.py in wrapper(*args, **kwargs)
    966           except Exception as e:  # pylint:disable=broad-except
    967             if hasattr(e, ""ag_error_metadata""):
--> 968               raise e.ag_error_metadata.to_exception(e)
    969             else:
    970               raise

OperatorNotAllowedInGraphError: in converted code:

    <ipython-input-34-fafbbc1bd984>:6 fun  *
        x, y = tensor_array.read(i)
    C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\ops\tensor_array_ops.py:1137 read
        return self._implementation.read(index, name=name)
    C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\ops\tensor_array_ops.py:753 read
        if index < 0:
    C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\framework\ops.py:757 __bool__
        self._disallow_bool_casting()
    C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\framework\ops.py:523 _disallow_bool_casting
        ""using a `tf.Tensor` as a Python `bool`"")
    C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\framework\ops.py:510 _disallow_when_autograph_enabled
        "" decorating it directly with @tf.function."".format(task))

    OperatorNotAllowedInGraphError: using a `tf.Tensor` as a Python `bool` is not allowed: AutoGraph did not convert this function. Try decorating it directly with @tf.function.
```"
38453,Gradient not registered in autograph mode with tf.data.Dataset loop,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow): True
- OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04): Windows 10
- TensorFlow installed from (source or
binary): PIP
- TensorFlow version (use command below): v2.1.0-rc2-17-ge5bf8de410 2.1.0


**Describe the current behavior**
In autograph mode, gradient is not registered properly (propagates None) if function value depends on dataset values

**Describe the expected behavior**
Gradient in autograph should match gradient in eager mode

**Standalone code to reproduce the issue** 
```python
import tensorflow as tf

dataset = tf.data.Dataset.from_tensor_slices([2., 3.])

def fun(x):
    for data in dataset:
        x = x * data
    return x

decorated_fun = tf.function(fun)

a = tf.constant(1.)
with tf.GradientTape(persistent=True) as tape:
    tape.watch(a)
    b = fun(a)
    c = decorated_fun(a)
print(tape.gradient(b, a)) # prints 6. as expected
print(tape.gradient(c, a)) # prints None

```

"
38452,tf.train.Checkpoint complain that tf.train.ExponentialMovingAverage instance is not a trackable object,"My tensorflow versiong is 2.1.0, I built a model in the standard way of keras subclassing and saved it with tf.train.Checkpoint. It works fine in the following code:
```
model = ... # a subclassing model instance
ckpt = tf.train.Checkpoint(model=model)
for epoch in range(total_epochs):
    ...   
    ckpt.save(path)
```
When add the code of moving average as following:
```
model = ... # a subclassing model instance
ema = tf.train.ExponentialMovingAverage(decay=0.999, zero_debias=True)
ckpt = tf.train.Checkpoint(model=model, ema=ema)
for epoch in range(total_epochs):
    ...   
    ckpt.save(path)
```
cause this error:
```
ValueError: `Checkpoint` was expecting a trackable object (an object derived from `TrackableBase`), 
got <tensorflow.python.training.moving_averages.ExponentialMovingAverage object at 0x7f63c8070a58>.
If you believe this object should be trackable (i.e. it is part of the TensorFlow Python API and manages state), please open an issue.
```

Is that `tf.train.ExponentialMovingAverage` incompatible with tf2? What's the best practice to do moving average in tf2?"
38451,The saved preview image is a green image (tensorflow lite object detection android demo),"I try to deploy the [tensorflow lite object detection android demo](https://github.com/tensorflow/examples/tree/master/lite/examples/object_detection/android) on streaming media rearview mirror,it is something like this:
![image](https://user-images.githubusercontent.com/43233772/79041066-72cba300-7c1f-11ea-983f-488ee4bdb7f8.png)
and it is android 5.1(API 22) OS, it use android.hardware.Camera API instead of Camera2 API.
The result is the app can preview, but doesn't show any prediction box. 
Afterwards, i set SAVE_PREVIEW_BITMAP = true, and found the cause is the input image is not correct, the saved preview bitmap is just a green image:
![croppedBitmap-300300-1586578626229](https://user-images.githubusercontent.com/43233772/79041173-3c425800-7c20-11ea-9a95-a881c5de2a1d.jpg)
So how to debug it ? thanks !
"
38450,XLA without autoclustering?,"https://www.tensorflow.org/xla/#explicit_compilation_with_tffunction seems to imply that it is possible to enable XLA for parts of the graph without involving autoclustering.

I am attempting to do this for the Gelu op in BERT https://github.com/google-research/bert/blob/master/modeling.py#L264 as suggested here https://github.com/tensorflow/tensorflow/pull/37937 and the observed behavior does not match my expectation.

I'm adding the tf.function tag to a function 'gelu' that contains tf.tanh and some cwise arithmetics, but not touching global jit options, etc. My expectation is to produce a number of identical clusters implementing this 'gelu', and possibly a number of clusters implementing its gradients.

What I'm actually seeing instead, is a number of clusters that seem to be greedily constructed around 'gelu's, but are also sweeping everything in the neighborhood, up to and including GEMMs:

```
2020-04-11 09:17:46.357008: I tensorflow/compiler/jit/mark_for_compilation_pass.cc:888] Assigning node gradients/AddN_149 to cluster cluster_1
2020-04-11 09:17:46.372574: I tensorflow/compiler/jit/mark_for_compilation_pass.cc:1471] *** Clustering info for graph of size 14527
2020-04-11 09:17:46.372603: I tensorflow/compiler/jit/mark_for_compilation_pass.cc:1472]  Built 50 clusters, size 4788 / 14527 (32.96%)
2020-04-11 09:17:46.372622: I tensorflow/compiler/jit/mark_for_compilation_pass.cc:1481]   cluster_0 114 / 14527 (0.78%)
2020-04-11 09:17:46.372630: I tensorflow/compiler/jit/mark_for_compilation_pass.cc:1485]    AddN: 2 instances
2020-04-11 09:17:46.372636: I tensorflow/compiler/jit/mark_for_compilation_pass.cc:1485]    AddV2: 4 instances
2020-04-11 09:17:46.372642: I tensorflow/compiler/jit/mark_for_compilation_pass.cc:1485]    BiasAdd: 3 instances
2020-04-11 09:17:46.372648: I tensorflow/compiler/jit/mark_for_compilation_pass.cc:1485]    BiasAddGrad: 2 instances
2020-04-11 09:17:46.372654: I tensorflow/compiler/jit/mark_for_compilation_pass.cc:1485]    Const: 24 instances
2020-04-11 09:17:46.372660: I tensorflow/compiler/jit/mark_for_compilation_pass.cc:1485]    Exp: 1 instances
2020-04-11 09:17:46.372666: I tensorflow/compiler/jit/mark_for_compilation_pass.cc:1485]    LogSoftmax: 2 instances
2020-04-11 09:17:46.372671: I tensorflow/compiler/jit/mark_for_compilation_pass.cc:1485]    MatMul: 5 instances
2020-04-11 09:17:46.372677: I tensorflow/compiler/jit/mark_for_compilation_pass.cc:1485]    Mean: 3 instances
2020-04-11 09:17:46.372683: I tensorflow/compiler/jit/mark_for_compilation_pass.cc:1485]    Mul: 19 instances
2020-04-11 09:17:46.372688: I tensorflow/compiler/jit/mark_for_compilation_pass.cc:1485]    Neg: 4 instances
2020-04-11 09:17:46.372695: I tensorflow/compiler/jit/mark_for_compilation_pass.cc:1485]    OneHot: 2 instances
2020-04-11 09:17:46.372701: I tensorflow/compiler/jit/mark_for_compilation_pass.cc:1485]    PartitionedCall: 1 instances
2020-04-11 09:17:46.372706: I tensorflow/compiler/jit/mark_for_compilation_pass.cc:1485]    ReadVariableOp: 8 instances
2020-04-11 09:17:46.372712: I tensorflow/compiler/jit/mark_for_compilation_pass.cc:1485]    RealDiv: 1 instances
2020-04-11 09:17:46.372717: I tensorflow/compiler/jit/mark_for_compilation_pass.cc:1485]    Reciprocal: 1 instances
2020-04-11 09:17:46.372723: I tensorflow/compiler/jit/mark_for_compilation_pass.cc:1485]    Reshape: 10 instances
2020-04-11 09:17:46.372729: I tensorflow/compiler/jit/mark_for_compilation_pass.cc:1485]    Rsqrt: 1 instances
2020-04-11 09:17:46.372734: I tensorflow/compiler/jit/mark_for_compilation_pass.cc:1485]    RsqrtGrad: 1 instances
2020-04-11 09:17:46.372742: I tensorflow/compiler/jit/mark_for_compilation_pass.cc:1485]    SquaredDifference: 1 instances
2020-04-11 09:17:46.372750: I tensorflow/compiler/jit/mark_for_compilation_pass.cc:1485]    Squeeze: 1 instances
2020-04-11 09:17:46.372759: I tensorflow/compiler/jit/mark_for_compilation_pass.cc:1485]    StridedSlice: 1 instances
2020-04-11 09:17:46.372767: I tensorflow/compiler/jit/mark_for_compilation_pass.cc:1485]    Sub: 3 instances
2020-04-11 09:17:46.372775: I tensorflow/compiler/jit/mark_for_compilation_pass.cc:1485]    Sum: 9 instances
2020-04-11 09:17:46.372783: I tensorflow/compiler/jit/mark_for_compilation_pass.cc:1485]    Tanh: 1 instances
2020-04-11 09:17:46.372792: I tensorflow/compiler/jit/mark_for_compilation_pass.cc:1485]    Tile: 4 instances
2020-04-11 09:17:46.372810: I tensorflow/compiler/jit/mark_for_compilation_pass.cc:1481]   cluster_1 232 / 14527 (1.60%)
2020-04-11 09:17:46.372840: I tensorflow/compiler/jit/mark_for_compilation_pass.cc:1485]    AddN: 13 instances
2020-04-11 09:17:46.372849: I tensorflow/compiler/jit/mark_for_compilation_pass.cc:1485]    BatchMatMulV2: 8 instances
2020-04-11 09:17:46.372859: I tensorflow/compiler/jit/mark_for_compilation_pass.cc:1485]    BiasAddGrad: 10 instances
2020-04-11 09:17:46.372868: I tensorflow/compiler/jit/mark_for_compilation_pass.cc:1485]    Const: 50 instances
2020-04-11 09:17:46.372877: I tensorflow/compiler/jit/mark_for_compilation_pass.cc:1485]    MatMul: 23 instances
2020-04-11 09:17:46.372885: I tensorflow/compiler/jit/mark_for_compilation_pass.cc:1485]    Mul: 58 instances
2020-04-11 09:17:46.372895: I tensorflow/compiler/jit/mark_for_compilation_pass.cc:1485]    Neg: 4 instances
2020-04-11 09:17:46.372904: I tensorflow/compiler/jit/mark_for_compilation_pass.cc:1485]    PartitionedCall: 1 instances
2020-04-11 09:17:46.372913: I tensorflow/compiler/jit/mark_for_compilation_pass.cc:1485]    Reshape: 19 instances
2020-04-11 09:17:46.372927: I tensorflow/compiler/jit/mark_for_compilation_pass.cc:1485]    RsqrtGrad: 4 instances
2020-04-11 09:17:46.372936: I tensorflow/compiler/jit/mark_for_compilation_pass.cc:1485]    Sub: 6 instances
2020-04-11 09:17:46.372945: I tensorflow/compiler/jit/mark_for_compilation_pass.cc:1485]    Sum: 19 instances
2020-04-11 09:17:46.372958: I tensorflow/compiler/jit/mark_for_compilation_pass.cc:1485]    Tile: 8 instances
2020-04-11 09:17:46.372967: I tensorflow/compiler/jit/mark_for_compilation_pass.cc:1485]    Transpose: 8 instances
2020-04-11 09:17:46.372976: I tensorflow/compiler/jit/mark_for_compilation_pass.cc:1485]    UnsortedSegmentSum: 1 instances
2020-04-11 09:17:46.372995: I tensorflow/compiler/jit/mark_for_compilation_pass.cc:1481]   cluster_10 113 / 14527 (0.78%)
2020-04-11 09:17:46.373006: I tensorflow/compiler/jit/mark_for_compilation_pass.cc:1485]    AddN: 6 instances
2020-04-11 09:17:46.373016: I tensorflow/compiler/jit/mark_for_compilation_pass.cc:1485]    BatchMatMulV2: 4 instances
2020-04-11 09:17:46.373024: I tensorflow/compiler/jit/mark_for_compilation_pass.cc:1485]    BiasAddGrad: 6 instances
2020-04-11 09:17:46.373032: I tensorflow/compiler/jit/mark_for_compilation_pass.cc:1485]    Const: 23 instances
2020-04-11 09:17:46.373040: I tensorflow/compiler/jit/mark_for_compilation_pass.cc:1485]    MatMul: 12 instances
2020-04-11 09:17:46.373049: I tensorflow/compiler/jit/mark_for_compilation_pass.cc:1485]    Mul: 29 instances
2020-04-11 09:17:46.373059: I tensorflow/compiler/jit/mark_for_compilation_pass.cc:1485]    Neg: 2 instances
2020-04-11 09:17:46.373068: I tensorflow/compiler/jit/mark_for_compilation_pass.cc:1485]    PartitionedCall: 1 instances
2020-04-11 09:17:46.373077: I tensorflow/compiler/jit/mark_for_compilation_pass.cc:1485]    Reshape: 8 instances
2020-04-11 09:17:46.373087: I tensorflow/compiler/jit/mark_for_compilation_pass.cc:1485]    RsqrtGrad: 2 instances
2020-04-11 09:17:46.373111: I tensorflow/compiler/jit/mark_for_compilation_pass.cc:1485]    Sub: 3 instances
2020-04-11 09:17:46.373119: I tensorflow/compiler/jit/mark_for_compilation_pass.cc:1485]    Sum: 9 instances
2020-04-11 09:17:46.373128: I tensorflow/compiler/jit/mark_for_compilation_pass.cc:1485]    Tile: 4 instances
2020-04-11 09:17:46.373136: I tensorflow/compiler/jit/mark_for_compilation_pass.cc:1485]    Transpose: 4 instances
2020-04-11 09:17:46.373151: I tensorflow/compiler/jit/mark_for_compilation_pass.cc:1481]   cluster_11 113 / 14527 (0.78%)

```
This presents reliability problems (if XLA is going to drag random operations from the graph into the cluster, I can never be sure that it won't end up with something it can't compile correctly) and also performance problems (instead of compiling 1 or 2 relatively short kernels, it ends up trying to compile 100 large kernels and that takes several minutes.)

Is this the intended behavior, and can this be avoided?"
38449,"ValueError: Error when checking : expected input_1 to have shape (608, 608, 3) but got array with shape (416, 416, 3)","please give me suggestions ? how to solve this error

if __name__ == '__main__':
    yolo = YOLO(0.6, 0.5)
    file = 'data/coco_classes.txt'
    all_classes = get_classes(file)
 
    # detect images in test floder.
    for (root, dirs, files) in os.walk('images/test'):
        if files:

            for f in files:
                print(f)
                
                path = os.path.join(root, f)
                image = cv2.imread(path)
                image = np.array(image)
                image = detect_image(image, yolo, all_classes)
                cv2.imwrite('images/res/' + f, image)
                

def process_image(img):
    """"""Resize, reduce and expand image.

    # Argument:
        img: original image.

    # Returns
        image: ndarray(64, 64, 3), processed image.
    """"""
    
    image = cv2.resize(img, (416, 416),
                       interpolation=cv2.INTER_CUBIC)
    image = np.array(image, dtype='float32')
    image /= 255.
    image = np.expand_dims(image, axis=0)

    return image

ValueError: Error when checking : expected input_1 to have shape (608, 608, 3) but got array with shape (416, 416, 3)"
38448,"ValueError: Cannot infer num from shape (None, None) when unstacking dense tensor converted from sparse tensor","Hello,

Iam trying to create a Keras compatible model using Tensorflow to use the CTC loss and I just found a problem : after decoding the output of the neural network using ``tf.nn.ctc_greedy_decoder``, it returns an array with a sparse tensor, and in order to be able to use GPUs and TPUs to calculate the loss with ``tf.nn.ctc_loss`` we need to convert the sparse tensor to a dense tensor, so I used ``tf.sparse.to_dense``, but when I try to get the ``logit_length`` requested by the loss function using ``tf.unstack`` I get the following error : ``ValueError: Cannot infer num from shape (None, None)``. The thing is when I use ``tf.unstack`` on a dense tensor converted from a sparse tensor I don't have any issues.

Here is the part of code that raised this issue  (both ``batch_inputs`` and ``batch_targets`` are dense tensors): 

```
@tf.function
def train_step(self, batch_inputs, batch_targets):
    with tf.GradientTape(persistent = True) as tape:
        # Doing a manual prediction because calling Keras's predict method inside a tensorflow function is not supported
        X = batch_inputs
        for layer in self.neural_network.layers:
            X = layer(X)

        logits = tf.transpose(X, [1, 0, 2]) 
        logits_sequence_length = [logit.shape[0] for logit in tf.unstack(logits)] 
        decoded, neg_sum_logits = self.ctc_decoder(X, logits_sequence_length) 
        decoded_logits = decoded[0] 
        dense_decoded_logits = tf.sparse.to_dense(decoded_logits) 
        decoded_logits_sequence_length = [decoded_logit.shape[0] for decoded_logit in tf.unstack(dense_decoded_logits)]
        batch_target_sequence_length = [target.shape[0] for target in tf.unstack(batch_targets)] 
        batch_loss, average_batch_loss = self.calculate_loss(batch_targets, dense_decoded_logits, batch_target_sequence_length, decoded_logits_sequence_length) 
        with tape.stop_recording():
            gradients = tape.gradient(batch_loss, self.neural_network.trainable_variables) 
            self.optimizer.apply_gradients(zip(gradients, self.neural_network.trainable_variables)) 
            decoded_logits = tf.transpose(decoded_logits, [1, 0, 2]) 
            sparse_batch_targets = tf.math.dense_to_sparse(batch_targets, ignore_values = 0) 
            batch_ler, average_batch_ler = self.calculate_ler(sparse_batch_targets, decoded_logits) 
            return average_batch_loss.numpy(), average_batch_ler.numpy()
```

More specifically, this line :  `` decoded_logits_sequence_length = [decoded_logit.shape[0] for decoded_logit in tf.unstack(dense_decoded_logits)]``

And this is the full error : 
```
---------------------------------------------------------------------------

ValueError                                Traceback (most recent call last)

<ipython-input-44-88cbf7d06e0e> in <module>()
      5           val_inputs = dev_spectrograms,
      6           val_targets = dense_dev_targets,
----> 7           val_batch_size = 32)

10 frames

/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py in wrapper(*args, **kwargs)
    966           except Exception as e:  # pylint:disable=broad-except
    967             if hasattr(e, ""ag_error_metadata""):
--> 968               raise e.ag_error_metadata.to_exception(e)
    969             else:
    970               raise

ValueError: in user code:

    <ipython-input-42-c1dfc702e50f>:173 train_step  *
        decoded_logits_sequence_length = [decoded_logit.shape[0] for decoded_logit in tf.unstack(dense_decoded_logits)]
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py:1510 unstack  **
        raise ValueError(""Cannot infer num from shape %s"" % value_shape)

    ValueError: Cannot infer num from shape (None, None)
```

After trying a few things, I noticed that this works perfectly if I return ``dense_decoded_logits`` and unstack it outside the function, but for some reason it won't work inside.

I'm using Google Colab high-RAM runtime with GPU running Tensorflow version 2.2.0rc2"
38446,Incorrect zero recognition,"- Tensorflow 2.2.0rc2
- Windows 10
- Python 3.8.2

I have an image with zeros that tensorflow recognizes as eights, can this be fixed somehow?

Image:
![Screenshot_2](https://user-images.githubusercontent.com/9198186/79034675-b17e4080-7bc0-11ea-94fd-448af68fde28.png)
Result:
8,88
8,88
"
38445,Why does work_group_launch_order in TFLite Metal matter?,"https://github.com/tensorflow/tensorflow/blob/9a9a4bfec64cec8a12d31809404ece94a4f55771/tensorflow/lite/delegates/gpu/metal/kernels/conv.cc#L59

I'm a beginner of Metal and trying to understand the Metal implementation of convolution in TFLite. After having read this line of code and found all usages, I'm really confused that why the `work_group_launch_order` matters. How does this machenism work indeed? Is it related to the way GPU linearizes the 3D work group?

Thanks for your reply."
38443,"Simple graph invoking tf.complex() doesn't work on GPU, but works on CPU","**Environment**: Windows 10, Python 3.6, Tensorflow 2.1.0-rc2

The code below demonstrates a minimal working example of the  bug.  This code results in CUDA_ERROR_LAUNCH_FAILED when run on the GPU.  But, if you run on the CPU, the code has no issues.  I suspect the problem lies in the tensor coming out of tf.complex() as if I do not use that function, the issues seems to go away.

A small working example shows the error I get along with working code to reproduce on Windows 10.

```
2020-04-10 16:19:43.846387: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll
2020-04-10 16:19:44.860247: W tensorflow/stream_executor/gpu/redzone_allocator.cc:312] Internal: Invoking GPU asm compilation is supported on Cuda non-Windows platforms only
Relying on driver to perform ptx compilation. This message will be only logged once.
2020-04-10 16:19:44.879431: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll
2020-04-10 16:19:45.231402: E tensorflow/stream_executor/cuda/cuda_driver.cc:948] failed to synchronize the stop event: CUDA_ERROR_LAUNCH_FAILED: unspecified launch failure
2020-04-10 16:19:45.231880: E tensorflow/stream_executor/gpu/gpu_timer.cc:55] Internal: Error destroying CUDA event: CUDA_ERROR_LAUNCH_FAILED: unspecified launch failure
2020-04-10 16:19:45.232665: E tensorflow/stream_executor/gpu/gpu_timer.cc:60] Internal: Error destroying CUDA event: CUDA_ERROR_LAUNCH_FAILED: unspecified launch failure
2020-04-10 16:19:45.233121: I tensorflow/stream_executor/cuda/cuda_driver.cc:801] failed to allocate 8B (8 bytes) from device: CUDA_ERROR_LAUNCH_FAILED: unspecified launch failure
2020-04-10 16:19:45.233532: E tensorflow/stream_executor/stream.cc:5452] Internal: Failed to enqueue async memset operation: CUDA_ERROR_LAUNCH_FAILED: unspecified launch failure
2020-04-10 16:19:45.233951: E tensorflow/stream_executor/cuda/cuda_driver.cc:613] failed to load PTX text as a module: CUDA_ERROR_LAUNCH_FAILED: unspecified launch failure
2020-04-10 16:19:45.234331: E tensorflow/stream_executor/cuda/cuda_driver.cc:618] error log buffer (1024 bytes): 
2020-04-10 16:19:45.234634: W tensorflow/core/kernels/gpu_utils.cc:68] Failed to check cudnn convolutions for out-of-bounds reads and writes with an error message: 'Failed to load PTX text as a module: CUDA_ERROR_LAUNCH_FAILED: unspecified launch failure'; skipping this check. This only means that we won't check cudnn for out-of-bounds reads and writes. This message will only be printed once.
2020-04-10 16:19:45.235499: I tensorflow/stream_executor/cuda/cuda_driver.cc:801] failed to allocate 8B (8 bytes) from device: CUDA_ERROR_LAUNCH_FAILED: unspecified launch failure
2020-04-10 16:19:45.235957: I tensorflow/stream_executor/stream.cc:4963] [stream=000001EA81FD2D60,impl=000001EA92405DC0] did not memzero GPU location; source: 0000008AE2D3C858
2020-04-10 16:19:45.236342: E tensorflow/stream_executor/cuda/cuda_driver.cc:613] failed to load PTX text as a module: CUDA_ERROR_LAUNCH_FAILED: unspecified launch failure
2020-04-10 16:19:45.236834: E tensorflow/stream_executor/cuda/cuda_driver.cc:618] error log buffer (1024 bytes): 
2020-04-10 16:19:45.237205: W tensorflow/core/common_runtime/base_collective_executor.cc:217] BaseCollectiveExecutor::StartAbort Internal: cuDNN launch failure : input shape([5,16,256,256]) filter shape([1,1,16,1])
	 [[{{node model/conv2d_1/Conv2D}}]]
```

```
import numpy as np
import tensorflow as tf
print(tf.__version__)

input_size = (256,256,1)
input_real = tf.keras.layers.Input(input_size)
input_imag = tf.keras.layers.Input(input_size)

# Get input into mag and phase 
cpx_input = tf.keras.layers.Lambda(lambda x: tf.complex(x[0], x[1]))([input_real, input_imag])    
abs_of_input = tf.math.abs(cpx_input)
phase_of_input =  tf.math.angle(cpx_input) 

# Add some trainiable weights
conv1 = tf.keras.layers.Conv2D(16, 5, padding = 'same')(abs_of_input)
mask = tf.keras.layers.Conv2D(1, 1)(conv1) 
filtered_freq = mask * abs_of_input
reconstructedFreq_dc_centered = tf.complex(mask, 0.0) * tf.math.exp(tf.complex(0.0,1.0)*tf.complex(phase_of_input, 0.0))  # I believe this is the offending line
tmp = tf.math.abs(reconstructedFreq_dc_centered)

model = tf.keras.models.Model([input_real, input_imag], tmp)

model.summary()

model.compile(optimizer='SGD', loss = 'mse')

x_real = np.random.randn(5, 256, 256, 1)
x_imag = np.random.randn(5, 256, 256, 1)

model.train_on_batch(x = [x_real, x_imag], y = x_real)

```
EDIT 1: Simplified code more."
38442,PySpark Deep Learning Pipeline - ClassNotFoundException: org.tensorframes.ShapeDescription,"I am getting the following exception while running Deep Learning Pipeline in Spark.
Versions of 

tensorflow and tensorframes : 2.0.0
conda : 4.8.3
pip : 20.0.2
python: 3.6

The exception comes while calling fit method of the pipeline:

    p = Pipeline(stages=[featurizer, lr])
    p_model = p.fit(train_df)

**Stack Trace**

   ```
 Traceback (most recent call last):
      File ""<stdin>"", line 1, in <module>
      File ""/opt/spark/python/pyspark/ml/base.py"", line 132, in fit
        return self._fit(dataset)
      File ""/opt/spark/python/pyspark/ml/pipeline.py"", line 107, in _fit
        dataset = stage.transform(dataset)
      File ""/opt/spark/python/pyspark/ml/base.py"", line 173, in transform
        return self._transform(dataset)
      File ""/opt/spark/python/pyspark/ml/wrapper.py"", line 312, in _transform
        return DataFrame(self._java_obj.transform(dataset._jdf), dataset.sql_ctx)
      File ""/opt/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py"", line 1257, in __call__
      File ""/opt/spark/python/pyspark/sql/utils.py"", line 63, in deco
        return f(*a, **kw)
      File ""/opt/spark/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py"", line 328, in get_return_value
    py4j.protocol.Py4JJavaError: An error occurred while calling o56.transform.
    : java.lang.NoClassDefFoundError: org/tensorframes/ShapeDescription
            at com.databricks.sparkdl.DeepImageFeaturizer.transform(DeepImageFeaturizer.scala:124)
            at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
            at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
            at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
            at java.lang.reflect.Method.invoke(Method.java:498)
            at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
            at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
            at py4j.Gateway.invoke(Gateway.java:282)
            at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
            at py4j.commands.CallCommand.execute(CallCommand.java:79)
            at py4j.GatewayConnection.run(GatewayConnection.java:238)
            at java.lang.Thread.run(Thread.java:748)
    Caused by: java.lang.ClassNotFoundException: org.tensorframes.ShapeDescription
            at java.net.URLClassLoader.findClass(URLClassLoader.java:382)
            at java.lang.ClassLoader.loadClass(ClassLoader.java:419)
            at java.lang.ClassLoader.loadClass(ClassLoader.java:352)
            ... 12 more

```
Any suggestions to solve this?"
42799,[ko] Notebooks out of sync,"Hello,

Please sync the ko notebooks to the source of truth notebooks using the nb_code_sync tool here( https://github.com/tensorflow/docs-l10n/blob/master/tools/nb_code_sync.py).

Currently, many of them are failing."
38438,"shape_invariants ""None"" for all loop variables for tf 1.15.x","OS Platform and Distribution : macOS Catalina 10.15.3

TensorFlow installed from : binary

TensorFlow version : 1.15.0

Python version: 3.7.3

When I try below 

```
import tensorflow as tf

tf.enable_eager_execution()

def tile_nd_ragged2(a, b):
  # Need a sentinel, otherwise it's hard to give it the initial shape we need.
  # We'll drop the sentinel at the end.
  acc = tf.ragged.constant([[[]]], dtype=a.dtype)

  # Work one row at a time...
  for i1 in range(len(a.nested_row_lengths()[0])):    # Should be able to write `for a1, b1 in zip(a, b)` soon.
    a1 = a[i1]
    b1 = b[i1]
    # If the components have variable length, we can't use a TensorArray anymore,
    # so use a RaggedTensor instead.
    acc1 = tf.ragged.constant([[]], dtype=a.dtype)
    def loop_test(i2, _):
      return i2 < tf.cast(a1.nested_row_lengths()[0][i1], tf.int32)
    def loop_body(i2, acc1):
      a2 = a1[i2]
      b2 = b1[i2]
      for _ in range(len(b2)):
        acc1 = tf.concat([acc1, tf.expand_dims(a2, 0)], axis=0)
      return i2 + 1, acc1

    _, acc1 = tf.while_loop(loop_test, loop_body, [0, acc1],shape_invariants=[None, tf.TensorShape([None, None])])
    acc1 = acc1[1:]  # Drop the sentinel.
    acc = tf.concat([acc, tf.expand_dims(acc1, 0)], axis=0)    # Add the row to the final result.

  acc = acc[1:]  # Drop the sentinel.
  return acc


x = tf.ragged.constant([[[b'a1', b'a2', b'a3'], [b'b1', b'b2', b'b3'], [b'c1', b'c2','c3']], [[b'd1'], [b'e1', b'e2']]])
y = tf.ragged.constant([[[b't1', b't2', b't3'], [b'u1', b'u2'], [b'v1', b'v2']], [[b'w1'], [b'x1', b'x2', b'x3']]])
print(x)
print(y)
print(tile_nd_ragged2(x, y))
```
I get below output  
```
input 
a = <tf.RaggedTensor [[[b'a1', b'a2', b'a3'], [b'b1', b'b2', b'b3'], [b'c1', b'c2', b'c3']], [[b'd1'], [b'e1', b'e2']]]>
b = <tf.RaggedTensor [[[b't1', b't2', b't3'], [b'u1', b'u2'], [b'v1', b'v2']], [[b'w1'], [b'x1', b'x2', b'x3']]]>
output = <tf.RaggedTensor [[[b'a1', b'a2', b'a3'], [b'a1', b'a2', b'a3'], [b'a1', b'a2', b'a3'], [b'b1', b'b2', b'b3'], [b'b1', b'b2', b'b3'], [b'c1', b'c2', b'c3'], [b'c1', b'c2', b'c3']], [[b'd1'], [b'e1', b'e2'], [b'e1', b'e2'], [b'e1', b'e2']]]>
```

But when i try to put `@tf.function` above the function and run exactly same way it gives below error 

 ```
 File ""tf_3.py"", line 101, in <module>
    print(tile_nd_ragged2(x, y))
  File ""/<path>/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py"", line 449, in __call__
    self._initialize(args, kwds, add_initializers_to=initializer_map)
  File ""/<path>/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py"", line 392, in _initialize
    *args, **kwds))
  File ""/<path>/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py"", line 1847, in _get_concrete_function_internal_garbage_collected
    graph_function, _, _ = self._maybe_define_function(args, kwargs)
  File ""/<path>/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py"", line 2147, in _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)
  File ""/<path>/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py"", line 2038, in _create_graph_function
    capture_by_value=self._capture_by_value),
  File ""/<path>/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py"", line 915, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File ""/<path>/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py"", line 335, in wrapped_fn
    return weak_wrapped_fn().__wrapped__(*args, **kwds)
  File ""/<path>/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py"", line 905, in wrapper
    raise e.ag_error_metadata.to_exception(e)
TypeError: in converted code:

    tf_3.py:88 tile_nd_ragged2  *
        _, acc1 = tf.while_loop(loop_test, loop_body, [0, acc1],shape_invariants=[None, tf.TensorShape([None, None])])
    /<path>/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/control_flow_ops.py:2675 while_loop
        back_prop=back_prop)
    /<path>/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/while_v2.py:87 while_loop
        list(shape_invariants), expand_composites=False)
    /<path>/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/util/nest.py:536 map_structure
        structure[0], [func(*x) for x in entries],
    /<path>/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/util/nest.py:536 <listcomp>
        structure[0], [func(*x) for x in entries],
    /<path>/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/control_flow_ops.py:512 _shape_invariant_to_type_spec
        % shape)

    TypeError: Expected shape to be a TypeSpec or TensorShape, got None
```
Opening a feature request as per discussion in ticket - [https://github.com/tensorflow/tensorflow/issues/38375](https://github.com/tensorflow/tensorflow/issues/38375)

Feature :
support for ""None"" in shape_invariants for tf 1.15.x "
38437,xla_build CMakeLists.txt - multi platforms,"Hello,

0663149 added CMake support for the upcoming standalone XLA AOT build in TensorFlow 2.2.

However some of the compile options defined in there seem to be for Linux only. When using cmake to build the `xla_aot_runtime_src` from the installed pip package and with the default CMakeLists.txt, I get the following behaviour:
- Linux, everything works;
- MacOS, build succeeds but with a warning of an unknown option (-Wno-deprecated-copy)
- Windows with MSVC, it fails.

In all cases I have used tf-nightly, Python 3.7, pip, cpu only. Platform specific configs:
- MacOS: cmake 3.17.0, AppleClang 11.0.3.11030032
- Linux: cmake 3.10.2, GNU 7.5.0
- Windows:  cmake 3.16.5, MSVC 19.25.28612.0

Wouldn't be better to have something along those lines?
```
cmake_minimum_required(VERSION 3.4.3)

file(GLOB_RECURSE TF_RUNTIME_SRC ""*.cc"")
add_library(tf_xla_runtime_objects OBJECT
	${TF_RUNTIME_SRC}
)

target_include_directories(tf_xla_runtime_objects PRIVATE ../include)
target_compile_options(tf_xla_runtime_objects PRIVATE
  -ftemplate-backtrace-limit=0
  $<$<OR:$<CXX_COMPILER_ID:GNU>,$<CXX_COMPILER_ID:Clang>>:-Wno-ignored-attributes>  
  $<$<CXX_COMPILER_ID:GNU>:-Wno-deprecated-copy>  
  $<$<OR:$<CXX_COMPILER_ID:GNU>,$<CXX_COMPILER_ID:Clang>>:-Wno-cast-qual>  
  $<$<OR:$<CXX_COMPILER_ID:GNU>,$<CXX_COMPILER_ID:Clang>>:-Wno-sign-compare>  
)

add_library(tf_xla_runtime STATIC
  $<TARGET_OBJECTS:tf_xla_runtime_objects>
)
```

Also, apart from managing the warning flags, do you have any view on shipping predefined MSVC compiler options required to make the build succeed? The build does eventually work, but the list of flags is quite lengthy and it's certainly not something that I would have dreamt of (I copied it from bazel).

As a side note, on all three platforms I have tried building the bazel target `//tensorflow/compiler/tf2xla:xla_compiled_cpu_runtime_standalone` and thanks to the fact that all options are pre-configured and managed by bazel the experience has been much smoother.

Best Regards,

Marco"
38435,tf.ragged - tf.tile like operation for each dimension ,"**System information** 

     OS Platform and Distribution : macOS Catalina 10.15.3

    TensorFlow installed from : binary

    TensorFlow version : 1.15.2

    Python version: 3.7.3


I have a1 and a2 ragged tensor 

`a1 = tf.ragged.constant([[[b'a1', b'a2', b'a3'], [b'b1', b'b2', b'b3'], [b'c1', b'c2','c3']], [[b'd1'], [b'e1', b'e2']]])`


`b1 = tf.ragged.constant([[[b't1', b't2', b't3'], [b'u1', b'u2'], [b'v1', b'v2']], [[b'w1'], [b'x1', b'x2', b'x3']]])`


I have a1 , b1 as above , i want c as below 

`c1 = tf.ragged.constant([[[b'a1', b'a2', b'a3'],[b'a1', b'a2', b'a3'],[b'a1', b'a2', b'a3'],[b'b1', b'b2', b'b3'],[b'b1', b'b2', b'b3'],[b'c1', b'c2','c3'],[b'c1', b'c2','c3']], [[b'd1'], [b'e1', b'e2'],[b'e1', b'e2'],[b'e1', b'e2']]])`

ie [b'a1', b'a2', b'a3'] is repeated equal to number of elements in  [b't1', b't2', b't3'] ie 3 so in c1 we will have [b'a1', b'a2', b'a3'],[b'a1', b'a2', b'a3'],[b'a1', b'a2', b'a3'],

similarly [b'b1', b'b2', b'b3'] is repeated equal to number of elements in  [b'u1', b'u2'] ie 2 so in c 1we will more have [b'b1', b'b2', b'b3'],[b'b1', b'b2', b'b3'],

similarly [b'c1', b'c2','c3'] is repeated equal to number of elements in  [[b'v1', b'v2'] ie 2 so in c1 we will more have [b'c1', b'c2','c3'],[b'c1', b'c2','c3']

till here all will be past of first tensor  ie `[[b'a1', b'a2', b'a3'],[b'a1', b'a2', b'a3'],[b'a1', b'a2', b'a3'],[b'b1', b'b2', b'b3'],[b'b1', b'b2', b'b3'],[b'c1', b'c2','c3'],[b'c1', b'c2','c3']]` now for second ragged tensor 

same process as above where [b'd1'] should be repeated 1 times as number of elements in [b'w1'] ..... 

 i am using this to convert raw signal to feature as part of my savedModel . 
"
42798,[ru] Failing notebooks.,"https://github.com/tensorflow/docs-l10n/blob/master/site/ru/guide/migrate.ipynb

```
nbconvert.preprocessors.execute.CellExecutionError: An error occurred while executing the following cell:
------------------
  import tensorflow.compat.v2 as tf
except Exception:
  pass
tf.enable_v2_behavior()


import tensorflow_datasets as tfds
------------------

  File ""<ipython-input-2-affb36bccd73>"", line 2
    except Exception:
         ^
SyntaxError: invalid syntax

SyntaxError: invalid syntax (<ipython-input-2-affb36bccd73>, line 2)
```

https://github.com/tensorflow/docs-l10n/blob/master/site/ru/tutorials/keras/save_and_load.ipynb
```
nbconvert.preprocessors.execute.CellExecutionError: An error occurred while executing the following cell:
------------------
import time
saved_model_path = ""./saved_models/{}"".format(int(time.time()))

tf.keras.experimental.export_saved_model(model, saved_model_path)
saved_model_path
------------------

---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
<ipython-input-20-9d5aff309515> in <module>
      2 saved_model_path = ""./saved_models/{}"".format(int(time.time()))
      3 
----> 4 tf.keras.experimental.export_saved_model(model, saved_model_path)
      5 saved_model_path

AttributeError: module 'tensorflow_core.python.keras.api._v2.keras.experimental' has no attribute 'export_saved_model'
AttributeError: module 'tensorflow_core.python.keras.api._v2.keras.experimental' has no attribute 'export_saved_model'
```

https://github.com/tensorflow/docs-l10n/blob/master/site/ru/tutorials/keras/text_classification_with_hub.ipynb
```
nbconvert.preprocessors.execute.CellExecutionError: An error occurred while executing the following cell:
------------------
# Разобьем обучающую выборку в пропорции 60% на 40%, и у нас будет 15,000 примеров
# для обучения, 10,000 примеров для валидации и 25,000 примеров для проверки.
train_validation_split = tfds.Split.TRAIN.subsplit([6, 4])

(train_data, validation_data), test_data = tfds.load(
    name=""imdb_reviews"", 
    split=(train_validation_split, tfds.Split.TEST),
    as_supervised=True)
------------------

---------------------------------------------------------------------------
AssertionError                            Traceback (most recent call last)
<ipython-input-3-ecc6d6ac73cf> in <module>
      6     name=""imdb_reviews"",
      7     split=(train_validation_split, tfds.Split.TEST),
----> 8     as_supervised=True)

~/.local/lib/python3.6/site-packages/tensorflow_datasets/core/api_utils.py in disallow_positional_args_dec(fn, instance, args, kwargs)
     50     _check_no_positional(fn, args, ismethod, allowed=allowed)
     51     _check_required(fn, kwargs)
---> 52     return fn(*args, **kwargs)
     53 
     54   return disallow_positional_args_dec(wrapped)  # pylint: disable=no-value-for-parameter

...

~/.local/lib/python3.6/site-packages/tensorflow_datasets/core/tfrecords_reader.py in _str_to_relative_instruction(spec)
    354   res = _SUB_SPEC_RE.match(spec)
    355   if not res:
--> 356     raise AssertionError('Unrecognized instruction format: %s' % spec)
    357   unit = '%' if res.group('from_pct') or res.group('to_pct') else 'abs'
    358   return ReadInstruction(

AssertionError: Unrecognized instruction format: NamedSplit('train')(tfds.percent[0:60])
AssertionError: Unrecognized instruction format: NamedSplit('train')(tfds.percent[0:60])
```

https://github.com/tensorflow/docs-l10n/blob/master/site/ru/tutorials/load_data/text.ipynb
```
nbconvert.preprocessors.execute.CellExecutionError: An error occurred while executing the following cell:
------------------
train_data = all_encoded_data.skip(TAKE_SIZE).shuffle(BUFFER_SIZE)
train_data = train_data.padded_batch(BATCH_SIZE)

test_data = all_encoded_data.take(TAKE_SIZE)
test_data = test_data.padded_batch(BATCH_SIZE)
------------------

---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
<ipython-input-13-be2cd799459e> in <module>
      1 train_data = all_encoded_data.skip(TAKE_SIZE).shuffle(BUFFER_SIZE)
----> 2 train_data = train_data.padded_batch(BATCH_SIZE)
      3 
      4 test_data = all_encoded_data.take(TAKE_SIZE)
      5 test_data = test_data.padded_batch(BATCH_SIZE)

TypeError: padded_batch() missing 1 required positional argument: 'padded_shapes'
TypeError: padded_batch() missing 1 required positional argument: 'padded_shapes'
```
"
38434,diag_part doesn't work for sub/super diagonals,"**System information** 
- Have I written custom code: no, see https://www.tensorflow.org/api_docs/python/tf/linalg/diag_part
- OS Platform and Distribution: 
  - Windows 10, Anaconda Python 3.7.6, tensorflow 2.1.0
  - Debian GNU/Linux 8.11 (jessie), Anaconda Python 3.7.3, tensorflow 2.0.0

**Describe the current behavior**
If I ran the example code:
```python
import numpy as np
import tensorflow as tf
input = np.array([[[1, 2, 3, 4], [5, 6, 7, 8], [9, 8, 7, 6]], [[5, 4, 3, 2], [1, 2, 3, 4], [5, 6, 7, 8]]])
print(tf.linalg.diag_part(input))
print(tf.linalg.diag_part(input, k=1))
```
***result***
```
[[1 6 7]
 [5 2 7]]
[[1 6 7]
 [5 2 7]]
```
***expected***
```
[[1 6 7]
 [5 2 7]]
[[2, 7, 6],
 [4, 3, 8]]
```
I think that the keyword arguments are just neglected."
38433,No specific error when import keras,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): win10 Enterprise
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): source
- TensorFlow version: 
```
# packages in environment at C:\ProgramData\Anaconda3:
# Name                    Version                   Build  Channel
tensorflow                2.1.0                    pypi_0    pypi
tensorflow-estimator      2.1.0                    pypi_0    pypi
```

- Python version: 3.7
- Installed using virtualenv? pip? conda?: pip
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:



**Describe the problem**
Can not import tensorflow

**Provide the exact sequence of commands / steps that you executed before running into the problem**
1. use `pip install tensorflow` to install it and report success
2. use `from tensorflow import keras` and run into error below

I have no idea what is happening, no specific error code


**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
```
ERROR:root:Internal Python error in the inspect module.
Below is the traceback from this internal error.

ERROR:root:Internal Python error in the inspect module.
Below is the traceback from this internal error.

Traceback (most recent call last):
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\ProgramData\Anaconda3\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\ProgramData\Anaconda3\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: The specified module could not be found.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\ProgramData\Anaconda3\lib\site-packages\IPython\core\interactiveshell.py"", line 3331, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File ""<ipython-input-1-1d80d955c0d6>"", line 5, in <module>
    from tensorflow import keras
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\__init__.py"", line 101, in <module>
    from tensorflow_core import *
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\__init__.py"", line 40, in <module>
    from tensorflow.python.tools import module_util as _module_util
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\__init__.py"", line 50, in __getattr__
    module = self._load()
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\__init__.py"", line 44, in _load
    module = _importlib.import_module(self.__name__)
  File ""C:\ProgramData\Anaconda3\lib\importlib\__init__.py"", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 74, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\ProgramData\Anaconda3\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\ProgramData\Anaconda3\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: The specified module could not be found.


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/errors

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\ProgramData\Anaconda3\lib\site-packages\IPython\core\interactiveshell.py"", line 2044, in showtraceback
    stb = value._render_traceback_()
AttributeError: 'ImportError' object has no attribute '_render_traceback_'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\ProgramData\Anaconda3\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\ProgramData\Anaconda3\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: The specified module could not be found.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\ProgramData\Anaconda3\lib\site-packages\IPython\core\ultratb.py"", line 1151, in get_records
    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\IPython\core\ultratb.py"", line 319, in wrapped
    return f(*args, **kwargs)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\IPython\core\ultratb.py"", line 353, in _fixed_getinnerframes
    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))
  File ""C:\ProgramData\Anaconda3\lib\inspect.py"", line 1502, in getinnerframes
    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)
  File ""C:\ProgramData\Anaconda3\lib\inspect.py"", line 1460, in getframeinfo
    filename = getsourcefile(frame) or getfile(frame)
  File ""C:\ProgramData\Anaconda3\lib\inspect.py"", line 696, in getsourcefile
    if getattr(getmodule(object, filename), '__loader__', None) is not None:
  File ""C:\ProgramData\Anaconda3\lib\inspect.py"", line 733, in getmodule
    if ismodule(module) and hasattr(module, '__file__'):
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\__init__.py"", line 50, in __getattr__
    module = self._load()
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\__init__.py"", line 44, in _load
    module = _importlib.import_module(self.__name__)
  File ""C:\ProgramData\Anaconda3\lib\importlib\__init__.py"", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""<frozen importlib._bootstrap>"", line 1006, in _gcd_import
  File ""<frozen importlib._bootstrap>"", line 983, in _find_and_load
  File ""<frozen importlib._bootstrap>"", line 953, in _find_and_load_unlocked
  File ""<frozen importlib._bootstrap>"", line 219, in _call_with_frames_removed
  File ""<frozen importlib._bootstrap>"", line 1006, in _gcd_import
  File ""<frozen importlib._bootstrap>"", line 983, in _find_and_load
  File ""<frozen importlib._bootstrap>"", line 967, in _find_and_load_unlocked
  File ""<frozen importlib._bootstrap>"", line 677, in _load_unlocked
  File ""<frozen importlib._bootstrap_external>"", line 728, in exec_module
  File ""<frozen importlib._bootstrap>"", line 219, in _call_with_frames_removed
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\__init__.py"", line 42, in <module>
    from . _api.v2 import audio
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\_api\v2\audio\__init__.py"", line 10, in <module>
    from tensorflow.python.ops.gen_audio_ops import decode_wav
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\ops\gen_audio_ops.py"", line 9, in <module>
    from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\__init__.py"", line 50, in __getattr__
    module = self._load()
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\__init__.py"", line 44, in _load
    module = _importlib.import_module(self.__name__)
  File ""C:\ProgramData\Anaconda3\lib\importlib\__init__.py"", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 74, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\ProgramData\Anaconda3\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\ProgramData\Anaconda3\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: The specified module could not be found.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\ProgramData\Anaconda3\lib\site-packages\IPython\core\interactiveshell.py"", line 3331, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File ""<ipython-input-1-1d80d955c0d6>"", line 5, in <module>
    from tensorflow import keras
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\__init__.py"", line 101, in <module>
    from tensorflow_core import *
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\__init__.py"", line 40, in <module>
    from tensorflow.python.tools import module_util as _module_util
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\__init__.py"", line 50, in __getattr__
    module = self._load()
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\__init__.py"", line 44, in _load
    module = _importlib.import_module(self.__name__)
  File ""C:\ProgramData\Anaconda3\lib\importlib\__init__.py"", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 74, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\ProgramData\Anaconda3\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\ProgramData\Anaconda3\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: The specified module could not be found.


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/errors

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\ProgramData\Anaconda3\lib\site-packages\IPython\core\interactiveshell.py"", line 2044, in showtraceback
    stb = value._render_traceback_()
AttributeError: 'ImportError' object has no attribute '_render_traceback_'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\ProgramData\Anaconda3\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\ProgramData\Anaconda3\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: The specified module could not be found.


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/errors

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.
Traceback (most recent call last):
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\ProgramData\Anaconda3\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\ProgramData\Anaconda3\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: The specified module could not be found.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\ProgramData\Anaconda3\lib\site-packages\IPython\core\interactiveshell.py"", line 3331, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File ""<ipython-input-1-1d80d955c0d6>"", line 5, in <module>
    from tensorflow import keras
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\__init__.py"", line 101, in <module>
    from tensorflow_core import *
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\__init__.py"", line 40, in <module>
    from tensorflow.python.tools import module_util as _module_util
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\__init__.py"", line 50, in __getattr__
    module = self._load()
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\__init__.py"", line 44, in _load
    module = _importlib.import_module(self.__name__)
  File ""C:\ProgramData\Anaconda3\lib\importlib\__init__.py"", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 74, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\ProgramData\Anaconda3\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\ProgramData\Anaconda3\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: The specified module could not be found.


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/errors

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\ProgramData\Anaconda3\lib\site-packages\IPython\core\interactiveshell.py"", line 2044, in showtraceback
    stb = value._render_traceback_()
AttributeError: 'ImportError' object has no attribute '_render_traceback_'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\ProgramData\Anaconda3\lib\site-packages\IPython\core\interactiveshell.py"", line 3254, in run_ast_nodes
    if (await self.run_code(code, result,  async_=asy)):
  File ""C:\ProgramData\Anaconda3\lib\site-packages\IPython\core\interactiveshell.py"", line 3348, in run_code
    self.showtraceback(running_compiled_code=True)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\IPython\core\interactiveshell.py"", line 2047, in showtraceback
    value, tb, tb_offset=tb_offset)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\IPython\core\ultratb.py"", line 1418, in structured_traceback
    self, etype, value, tb, tb_offset, number_of_lines_of_context)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\IPython\core\ultratb.py"", line 1318, in structured_traceback
    self, etype, value, tb, tb_offset, number_of_lines_of_context
  File ""C:\ProgramData\Anaconda3\lib\site-packages\IPython\core\ultratb.py"", line 1186, in structured_traceback
    formatted_exceptions += self.prepare_chained_exception_message(evalue.__cause__)
TypeError: can only concatenate str (not ""list"") to str

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\ProgramData\Anaconda3\lib\site-packages\IPython\core\interactiveshell.py"", line 2044, in showtraceback
    stb = value._render_traceback_()
AttributeError: 'TypeError' object has no attribute '_render_traceback_'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\ProgramData\Anaconda3\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\ProgramData\Anaconda3\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: The specified module could not be found.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\ProgramData\Anaconda3\lib\site-packages\IPython\core\ultratb.py"", line 1151, in get_records
    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\IPython\core\ultratb.py"", line 319, in wrapped
    return f(*args, **kwargs)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\IPython\core\ultratb.py"", line 353, in _fixed_getinnerframes
    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))
  File ""C:\ProgramData\Anaconda3\lib\inspect.py"", line 1502, in getinnerframes
    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)
  File ""C:\ProgramData\Anaconda3\lib\inspect.py"", line 1460, in getframeinfo
    filename = getsourcefile(frame) or getfile(frame)
  File ""C:\ProgramData\Anaconda3\lib\inspect.py"", line 696, in getsourcefile
    if getattr(getmodule(object, filename), '__loader__', None) is not None:
  File ""C:\ProgramData\Anaconda3\lib\inspect.py"", line 733, in getmodule
    if ismodule(module) and hasattr(module, '__file__'):
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\__init__.py"", line 50, in __getattr__
    module = self._load()
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\__init__.py"", line 44, in _load
    module = _importlib.import_module(self.__name__)
  File ""C:\ProgramData\Anaconda3\lib\importlib\__init__.py"", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""<frozen importlib._bootstrap>"", line 1006, in _gcd_import
  File ""<frozen importlib._bootstrap>"", line 983, in _find_and_load
  File ""<frozen importlib._bootstrap>"", line 953, in _find_and_load_unlocked
  File ""<frozen importlib._bootstrap>"", line 219, in _call_with_frames_removed
  File ""<frozen importlib._bootstrap>"", line 1006, in _gcd_import
  File ""<frozen importlib._bootstrap>"", line 983, in _find_and_load
  File ""<frozen importlib._bootstrap>"", line 967, in _find_and_load_unlocked
  File ""<frozen importlib._bootstrap>"", line 677, in _load_unlocked
  File ""<frozen importlib._bootstrap_external>"", line 728, in exec_module
  File ""<frozen importlib._bootstrap>"", line 219, in _call_with_frames_removed
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\__init__.py"", line 42, in <module>
    from . _api.v2 import audio
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\_api\v2\audio\__init__.py"", line 10, in <module>
    from tensorflow.python.ops.gen_audio_ops import decode_wav
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\ops\gen_audio_ops.py"", line 9, in <module>
    from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\__init__.py"", line 50, in __getattr__
    module = self._load()
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\__init__.py"", line 44, in _load
    module = _importlib.import_module(self.__name__)
  File ""C:\ProgramData\Anaconda3\lib\importlib\__init__.py"", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 74, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\ProgramData\Anaconda3\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\ProgramData\Anaconda3\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: The specified module could not be found.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\ProgramData\Anaconda3\lib\site-packages\IPython\core\interactiveshell.py"", line 3331, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File ""<ipython-input-1-1d80d955c0d6>"", line 5, in <module>
    from tensorflow import keras
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\__init__.py"", line 101, in <module>
    from tensorflow_core import *
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\__init__.py"", line 40, in <module>
    from tensorflow.python.tools import module_util as _module_util
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\__init__.py"", line 50, in __getattr__
    module = self._load()
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\__init__.py"", line 44, in _load
    module = _importlib.import_module(self.__name__)
  File ""C:\ProgramData\Anaconda3\lib\importlib\__init__.py"", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 74, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\ProgramData\Anaconda3\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\ProgramData\Anaconda3\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: The specified module could not be found.


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/errors

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\ProgramData\Anaconda3\lib\site-packages\IPython\core\interactiveshell.py"", line 2044, in showtraceback
    stb = value._render_traceback_()
AttributeError: 'ImportError' object has no attribute '_render_traceback_'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\ProgramData\Anaconda3\lib\site-packages\IPython\core\interactiveshell.py"", line 3254, in run_ast_nodes
    if (await self.run_code(code, result,  async_=asy)):
  File ""C:\ProgramData\Anaconda3\lib\site-packages\IPython\core\interactiveshell.py"", line 3348, in run_code
    self.showtraceback(running_compiled_code=True)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\IPython\core\interactiveshell.py"", line 2047, in showtraceback
    value, tb, tb_offset=tb_offset)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\IPython\core\ultratb.py"", line 1418, in structured_traceback
    self, etype, value, tb, tb_offset, number_of_lines_of_context)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\IPython\core\ultratb.py"", line 1318, in structured_traceback
    self, etype, value, tb, tb_offset, number_of_lines_of_context
  File ""C:\ProgramData\Anaconda3\lib\site-packages\IPython\core\ultratb.py"", line 1186, in structured_traceback
    formatted_exceptions += self.prepare_chained_exception_message(evalue.__cause__)
TypeError: can only concatenate str (not ""list"") to str

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\ProgramData\Anaconda3\lib\site-packages\IPython\core\interactiveshell.py"", line 2044, in showtraceback
    stb = value._render_traceback_()
AttributeError: 'TypeError' object has no attribute '_render_traceback_'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\ProgramData\Anaconda3\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\ProgramData\Anaconda3\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: The specified module could not be found.


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/errors

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.
---------------------------------------------------------------------------
ImportError                               Traceback (most recent call last)
C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py in <module>
     57 
---> 58   from tensorflow.python.pywrap_tensorflow_internal import *
     59   from tensorflow.python.pywrap_tensorflow_internal import __version__

C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py in <module>
     27             return _mod
---> 28     _pywrap_tensorflow_internal = swig_import_helper()
     29     del swig_import_helper

C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py in swig_import_helper()
     23             try:
---> 24                 _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
     25             finally:

C:\ProgramData\Anaconda3\lib\imp.py in load_module(name, file, filename, details)
    241         else:
--> 242             return load_dynamic(name, filename, file)
    243     elif type_ == PKG_DIRECTORY:

C:\ProgramData\Anaconda3\lib\imp.py in load_dynamic(name, path, file)
    341             name=name, loader=loader, origin=path)
--> 342         return _load(spec)
    343 

ImportError: DLL load failed: The specified module could not be found.

During handling of the above exception, another exception occurred:


During handling of the above exception, another exception occurred:

AttributeError                            Traceback (most recent call last)
C:\ProgramData\Anaconda3\lib\site-packages\IPython\core\interactiveshell.py in showtraceback(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)
   2043                         # in the engines. This should return a list of strings.
-> 2044                         stb = value._render_traceback_()
   2045                     except Exception:

AttributeError: 'ImportError' object has no attribute '_render_traceback_'

During handling of the above exception, another exception occurred:

TypeError                                 Traceback (most recent call last)
C:\ProgramData\Anaconda3\lib\site-packages\IPython\core\interactiveshell.py in run_code(self, code_obj, result, async_)
   3346             if result is not None:
   3347                 result.error_in_exec = sys.exc_info()[1]
-> 3348             self.showtraceback(running_compiled_code=True)
   3349         else:
   3350             outflag = False

C:\ProgramData\Anaconda3\lib\site-packages\IPython\core\interactiveshell.py in showtraceback(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)
   2045                     except Exception:
   2046                         stb = self.InteractiveTB.structured_traceback(etype,
-> 2047                                             value, tb, tb_offset=tb_offset)
   2048 
   2049                     self._showtraceback(etype, value, stb)

C:\ProgramData\Anaconda3\lib\site-packages\IPython\core\ultratb.py in structured_traceback(self, etype, value, tb, tb_offset, number_of_lines_of_context)
   1416             self.tb = tb
   1417         return FormattedTB.structured_traceback(
-> 1418             self, etype, value, tb, tb_offset, number_of_lines_of_context)
   1419 
   1420 

C:\ProgramData\Anaconda3\lib\site-packages\IPython\core\ultratb.py in structured_traceback(self, etype, value, tb, tb_offset, number_of_lines_of_context)
   1316             # Verbose modes need a full traceback
   1317             return VerboseTB.structured_traceback(
-> 1318                 self, etype, value, tb, tb_offset, number_of_lines_of_context
   1319             )
   1320         elif mode == 'Minimal':

C:\ProgramData\Anaconda3\lib\site-packages\IPython\core\ultratb.py in structured_traceback(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)
   1184         exception = self.get_parts_of_chained_exception(evalue)
   1185         if exception:
-> 1186             formatted_exceptions += self.prepare_chained_exception_message(evalue.__cause__)
   1187             etype, evalue, etb = exception
   1188         else:

TypeError: can only concatenate str (not ""list"") to str
```"
38432,Converting retrained ssd_resnet50_v1 object detection model to TFLite for use on Coral USB Accelerator,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **Linux Ubuntu 16.04**
- TensorFlow installed from (source or binary): **tf-nightly installed through pip**
- TensorFlow version (or github SHA if from source): **2.2.0.dev20200401**
- **Nvidia GeForce GTX 1050 Ti Driver Version: 440.64.00**
- **Cuda compilation tools, release 9.0, V9.0.176**
- **CUDNN_MAJOR 7 CUDNN_MINOR 0 CUDNN_PATCHLEVEL 5**
- **Edge TPU Compiler version 2.1.302470888**

**Provide the text output from tflite_convert**

```
TensorFlow Lite currently doesn't support control flow ops: Merge, Switch. 
We are working on supporting control flow ops, 
please see github issue at https://github.com/tensorflow/tensorflow/issues/28485. 
Some of the operators in the model are not supported by the 
standard TensorFlow Lite runtime and are not recognized by TensorFlow. 
If you have a custom implementation 
for them you can disable this error with --allow_custom_ops, or by setting 
allow_custom_ops=True when calling tf.lite.TFLiteConverter(). 
Here is a list of builtin operators you 
are using: ADD, CAST, CONCATENATION, CONV_2D, EQUAL, EXP, EXPAND_DIMS, FILL, 
GATHER, GREATER, GREATER_EQUAL,
LESS, LOGICAL_OR, LOGISTIC, MAXIMUM, MAX_POOL_2D, MINIMUM, MUL, PACK, PAD, 
RANGE, RESHAPE, RESIZE_BILINEAR, SELECT, 
SHAPE, SLICE, SPLIT, SQUEEZE, STRIDED_SLICE, SUB, SUM, TOPK_V2, TRANSPOSE, UNPACK, 
WHERE.Here is a list of operators for which you will need custom implementations: 
DecodeGif, DecodeJpeg, DecodePng, DecodeRaw, NonMaxSuppressionV5, Substr.
```

**Standalone code to reproduce the issue** 
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.
```
import tensorflow as tf

BATCH_SIZE = 32
IMG_HEIGHT = 320
IMG_WIDTH = 320
physical_devices = tf.config.list_physical_devices('GPU')
tf.config.set_logical_device_configuration(physical_devices[0],[tf.config.LogicalDeviceConfiguration(memory_limit=500)])
logical_devices = tf.config.list_logical_devices('GPU')

list_ds_Dianthus = tf.data.Dataset.list_files(str('/home/afayed/coral/detection_ag/ag/Dianthus''*/*/*'))
list_ds_DustyMiller = tf.data.Dataset.list_files(str('/home/afayed/coral/detection_ag/ag/DustyMiller''*/*/*'))
list_ds_Pansy = tf.data.Dataset.list_files(str('/home/afayed/coral/detection_ag/ag/Pansy''*/*/*'))
list_all = list_ds_Dianthus.concatenate(list_ds_DustyMiller).concatenate(list_ds_Pansy)
#len(list(list_all))

def get_label(file_path):
  parts = tf.strings.split(file_path, '/')
  class_name = tf.strings.split(parts[-3], '1')
  class_name = tf.strings.split(class_name, '2')
  class_name = tf.strings.split(class_name, '3')
  class_name = tf.strings.split(class_name, '4')
  return class_name

def decode_img(img):
	img = tf.image.decode_jpeg(img, channels=3) #color images
	img = tf.image.convert_image_dtype(img, tf.float32) 
	#convert unit8 tensor to floats in the [0,1]range
	return tf.image.resize(img, [IMG_WIDTH, IMG_HEIGHT]) 

def process_path(file_path):
  label = get_label(file_path)
  img = tf.io.read_file(file_path)
  img = decode_img(img)
  return img, label

num_calibration_steps= 1000

def representative_dataset_gen():
	for _ in range(num_calibration_steps):
	# Get sample input data as a numpy array in a method of your choosing.
		image = list_all.take(1)
		yield [decode_img(image)]

saved_model_obj = tf.saved_model.load(export_dir='/home/afayed/coral/detection_ag/train/export/Servo/1586490086/')
concrete_func = saved_model_obj.signatures['serving_default']
concrete_func.inputs[0].set_shape([])
converter =  tf.lite.TFLiteConverter.from_concrete_functions([concrete_func])
converter.experimental_new_converter = False
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS,
                                       tf.lite.OpsSet.SELECT_TF_OPS]
converter.optimizations =  [tf.lite.Optimize.DEFAULT]
converter.representative_dataset = representative_dataset_gen
tflite_quant_model = converter.convert()

open(""/home/afayed/Desktop/output_tflite_graph.tflite"", ""wb"").write(tflite_quant_model)
```

Also, please include a link to a GraphDef or the model if possible.
#### Model ckpt 5 used [here](https://drive.google.com/file/d/1ssqvHDMh1Knh1QU05HjBLdUmkNihi_Ks/view?usp=sharing) as a .tar.
#### Frozen graph generated [here](https://drive.google.com/file/d/1dWspjmCtX_qscYH5jRFwR0Niw9HdY2Pb/view?usp=sharing)
#### saved_model.pb used [here](https://drive.google.com/file/d/10vPKG_49a8Smlv_CRhI5a0XH4Iskd6gZ/view?usp=sharing)



**Any other info / logs**
# Detailed explanation
**I am trying to use custom training data to retrain 'ssd_resnet50_v1_fpn_shared_box_predictor_640x640_coco14_sync_2018_07_03' (model obtained from model zoo [here](http://download.tensorflow.org/models/object_detection/ssd_resnet50_v1_fpn_shared_box_predictor_640x640_coco14_sync_2018_07_03.tar.gz) ) following [Google's Retrain an object detection model tutorial](hhttps://coral.ai/docs/edgetpu/retrain-detection/#prerequisites)**
 
**I retrained it on custom training data using TensorFlow with GPU devel version 1.12.0-rc2 on a docker container built with this [Dockerfile](https://drive.google.com/open?id=1q7CTyAweZCRSsYcwOODkDSgQkWabyYac). 
I also tried retraining with TensorFlow with GPU version 1.15.2. The pipeline config file I am using is available [here](https://drive.google.com/file/d/1oGPdg5wK6tQOLVkMCcJz5f-pMLMVzqGf/view?usp=sharing). 
I have made sure I used a fixed_shape_resizer and included ""max_number_of_boxes: 200"" in train_input_reader and eval_input_reader and all of that. 
My image dimensions as found in pipeline_v2.config are 320,320. 
I found the new Experimental Converter [here](https://groups.google.com/a/tensorflow.org/forum/#!topic/tflite/C7Ag0sUrLYg)**

## **So, my process is as such:**

**I start the docker container and start retraining from ckpt 0 that is given by downloading the model from the model zoo:**

```
sudo docker run --gpus all --name edgetpu-detect \
--rm -it --privileged -p 6006:6006 \
--mount type=bind,src=${DETECT_DIR},dst=/tensorflow/models/research/learn_pet \
detect-tutorial
```


**For the sake of testing lets only retrain 5 steps (I've tried up to 20,000 giving the same results):**

```
./retrain_detection_model.sh --num_training_steps 5 --num_eval_steps 100
```

retrain_detection_model.sh found [here](https://drive.google.com/open?id=1mMErPY2j68cNGDS_pmh9gbdAKOAvWmLB)


**I then use 'saved_model_cli.py' to get any info I need about the model. Text file generated [here]**(https://drive.google.com/open?id=1nDNSpEyjExg-_L_wpaDJaNlbVrRvfbp8):

```
python /tensorflow/tensorflow/python/tools/saved_model_cli.py show 
--dir /tensorflow/models/research/learn_pet/train/export/Servo/1586336368/ 
--all > /tensorflow/models/research/learn_pet/train/saved_model_cli_output.txt
```

I then export a frozen graph using export_tflite_ssd_graph.py (unedited) both through 1.12.0-rc2 and 1.15.2 *code shown here is using TF 1.15.2*:

```
python object_detection/export_tflite_ssd_graph.py 
--pipeline_config_path=""/tensorflow/models/research/learn_pet/ckpt/pipeline_v2.config"" 
--trained_checkpoint_prefix=""/tensorflow/models/research/learn_pet/train/model.ckpt-5"" 
--output_directory=""/tensorflow/models/research/learn_pet/models"" 
```
**And then I use the converter invocation (stated up above + its output) that causes this issue.**



*I limit memory growth using*
`physical_devices = tf.config.list_physical_devices('GPU')
tf.config.set_logical_device_configuration(physical_devices[0],[tf.config.LogicalDeviceConfiguration(memory_limit=500)])
logical_devices = tf.config.list_logical_devices('GPU')`


**Please help, I am also trying to do this with faster_rcnn_inception_resnet_v2_atrous_coco_2018_01_28 and that is where I found about the Experimental Converter working for RCNNs. My goal is to run either of these models on the Coral USB Accelerator after retraining with my own custom training data. I did not edit any scripts generating either of these models. Thanks in advanced**

"
38431,Converting retrained ssd_resnet50_v1 object detection model to TFLite for use on Coral USB Accelerator,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **Linux Ubuntu 16.04**
- TensorFlow installed from (source or binary): **tf-nightly installed through pip**
- TensorFlow version (or github SHA if from source): **2.2.0.dev20200401**
- **Nvidia GeForce GTX 1050 Ti Driver Version: 440.64.00**
- **Cuda compilation tools, release 9.0, V9.0.176**
- **CUDNN_MAJOR 7 CUDNN_MINOR 0 CUDNN_PATCHLEVEL 5**
- **Edge TPU Compiler version 2.1.302470888**

**Command used to run the converter or code if you’re using the Python API**
If possible, please share a link to Colab/Jupyter/any notebook.

```
import tensorflow as tf

BATCH_SIZE = 32
IMG_HEIGHT = 320
IMG_WIDTH = 320
physical_devices = tf.config.list_physical_devices('GPU')
tf.config.set_logical_device_configuration(physical_devices[0],[tf.config.LogicalDeviceConfiguration(memory_limit=500)])
logical_devices = tf.config.list_logical_devices('GPU')

list_ds_Dianthus = tf.data.Dataset.list_files(str('/home/afayed/coral/detection_ag/ag/Dianthus''*/*/*'))
list_ds_DustyMiller = tf.data.Dataset.list_files(str('/home/afayed/coral/detection_ag/ag/DustyMiller''*/*/*'))
list_ds_Pansy = tf.data.Dataset.list_files(str('/home/afayed/coral/detection_ag/ag/Pansy''*/*/*'))
list_all = list_ds_Dianthus.concatenate(list_ds_DustyMiller).concatenate(list_ds_Pansy)
#len(list(list_all))

def get_label(file_path):
  parts = tf.strings.split(file_path, '/')
  class_name = tf.strings.split(parts[-3], '1')
  class_name = tf.strings.split(class_name, '2')
  class_name = tf.strings.split(class_name, '3')
  class_name = tf.strings.split(class_name, '4')
  return class_name

def decode_img(img):
	img = tf.image.decode_jpeg(img, channels=3) #color images
	img = tf.image.convert_image_dtype(img, tf.float32) 
	#convert unit8 tensor to floats in the [0,1]range
	return tf.image.resize(img, [IMG_WIDTH, IMG_HEIGHT]) 

def process_path(file_path):
  label = get_label(file_path)
  img = tf.io.read_file(file_path)
  img = decode_img(img)
  return img, label

num_calibration_steps= 1000

def representative_dataset_gen():
	for _ in range(num_calibration_steps):
	# Get sample input data as a numpy array in a method of your choosing.
		image = list_all.take(1)
		yield [decode_img(image)]

saved_model_obj = tf.saved_model.load(export_dir='/home/afayed/coral/detection_ag/train/export/Servo/1586490086/')
concrete_func = saved_model_obj.signatures['serving_default']
concrete_func.inputs[0].set_shape([])
converter =  tf.lite.TFLiteConverter.from_concrete_functions([concrete_func])
converter.experimental_new_converter = False
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS,
                                       tf.lite.OpsSet.SELECT_TF_OPS]
converter.optimizations =  [tf.lite.Optimize.DEFAULT]
converter.representative_dataset = representative_dataset_gen
tflite_quant_model = converter.convert()

open(""/home/afayed/Desktop/output_tflite_graph.tflite"", ""wb"").write(tflite_quant_model)
```

**The output from the converter invocation**

```
TensorFlow Lite currently doesn't support control flow ops: Merge, Switch. 
We are working on supporting control flow ops, 
please see github issue at https://github.com/tensorflow/tensorflow/issues/28485. 
Some of the operators in the model are not supported by the 
standard TensorFlow Lite runtime and are not recognized by TensorFlow. 
If you have a custom implementation 
for them you can disable this error with --allow_custom_ops, or by setting 
allow_custom_ops=True when calling tf.lite.TFLiteConverter(). 
Here is a list of builtin operators you 
are using: ADD, CAST, CONCATENATION, CONV_2D, EQUAL, EXP, EXPAND_DIMS, FILL, 
GATHER, GREATER, GREATER_EQUAL,
LESS, LOGICAL_OR, LOGISTIC, MAXIMUM, MAX_POOL_2D, MINIMUM, MUL, PACK, PAD, 
RANGE, RESHAPE, RESIZE_BILINEAR, SELECT, 
SHAPE, SLICE, SPLIT, SQUEEZE, STRIDED_SLICE, SUB, SUM, TOPK_V2, TRANSPOSE, UNPACK, 
WHERE.Here is a list of operators for which you will need custom implementations: 
DecodeGif, DecodeJpeg, DecodePng, DecodeRaw, NonMaxSuppressionV5, Substr.
```

**Also, please include a link to the saved model or GraphDef**

#### Model ckpt 5 used [here](https://drive.google.com/file/d/1ssqvHDMh1Knh1QU05HjBLdUmkNihi_Ks/view?usp=sharing) as a .tar.
#### Frozen graph generated [here](https://drive.google.com/file/d/1dWspjmCtX_qscYH5jRFwR0Niw9HdY2Pb/view?usp=sharing)
#### saved_model.pb used [here](https://drive.google.com/file/d/10vPKG_49a8Smlv_CRhI5a0XH4Iskd6gZ/view?usp=sharing)

**Failure details**
Conversion not successful... 

**Any other info / logs**
# Detailed explanation
**I am trying to use custom training data to retrain 'ssd_resnet50_v1_fpn_shared_box_predictor_640x640_coco14_sync_2018_07_03' (model obtained from model zoo [here](http://download.tensorflow.org/models/object_detection/ssd_resnet50_v1_fpn_shared_box_predictor_640x640_coco14_sync_2018_07_03.tar.gz) ) following [Google's Retrain an object detection model tutorial](hhttps://coral.ai/docs/edgetpu/retrain-detection/#prerequisites)**
 
**I retrained it on custom training data using TensorFlow with GPU devel version 1.12.0-rc2 on a docker container built with this [Dockerfile](https://drive.google.com/open?id=1q7CTyAweZCRSsYcwOODkDSgQkWabyYac). 
I also tried retraining with TensorFlow with GPU version 1.15.2. The pipeline config file I am using is available [here](https://drive.google.com/file/d/1oGPdg5wK6tQOLVkMCcJz5f-pMLMVzqGf/view?usp=sharing). 
I have made sure I used a fixed_shape_resizer and included ""max_number_of_boxes: 200"" in train_input_reader and eval_input_reader and all of that. 
My image dimensions as found in pipeline_v2.config are 320,320. 
I found the new Experimental Converter [here](https://groups.google.com/a/tensorflow.org/forum/#!topic/tflite/C7Ag0sUrLYg)**

## **So, my process is as such:**

**I start the docker container and start retraining from ckpt 0 that is given by downloading the model from the model zoo:**

```
sudo docker run --gpus all --name edgetpu-detect \
--rm -it --privileged -p 6006:6006 \
--mount type=bind,src=${DETECT_DIR},dst=/tensorflow/models/research/learn_pet \
detect-tutorial
```


**For the sake of testing lets only retrain 5 steps (I've tried up to 20,000 giving the same results):**

```
./retrain_detection_model.sh --num_training_steps 5 --num_eval_steps 100
```

retrain_detection_model.sh found [here](https://drive.google.com/open?id=1mMErPY2j68cNGDS_pmh9gbdAKOAvWmLB)


**I then use 'saved_model_cli.py' to get any info I need about the model. Text file generated [here]**(https://drive.google.com/open?id=1nDNSpEyjExg-_L_wpaDJaNlbVrRvfbp8):

```
python /tensorflow/tensorflow/python/tools/saved_model_cli.py show --dir /tensorflow/models/research/learn_pet/train/export/Servo/1586336368/ --all > /tensorflow/models/research/learn_pet/train/saved_model_cli_output.txt```
```

I then export a frozen graph using export_tflite_ssd_graph.py (unedited) both through 1.12.0-rc2 and 1.15.2 *code shown here is using TF 1.15.2*:

```
python object_detection/export_tflite_ssd_graph.py --pipeline_config_path=""/tensorflow/models/research/learn_pet/ckpt/pipeline_v2.config"" --trained_checkpoint_prefix=""/tensorflow/models/research/learn_pet/train/model.ckpt-5"" --output_directory=""/tensorflow/models/research/learn_pet/models"" 
```
**Output:**
```
root@d97ce87cb12f:/tensorflow/models/research# python object_detection/export_tflite_ssd_graph.py --pipeline_config_path=""/tensorflow/learn_pet/ckpt/pipeline_v2.config"" --trained_checkpoint_prefix=""/tensorflow/learn_pet/train/model.ckpt-5"" --output_directory=""/tensorflow/learn_pet/models""
WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:From object_detection/export_tflite_ssd_graph.py:143: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.

WARNING:tensorflow:From object_detection/export_tflite_ssd_graph.py:133: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.

W0410 12:39:17.462405 140155277027136 module_wrapper.py:139] From object_detection/export_tflite_ssd_graph.py:133: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.

WARNING:tensorflow:From /tensorflow/models/research/object_detection/export_tflite_ssd_graph_lib.py:193: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.

W0410 12:39:17.465477 140155277027136 module_wrapper.py:139] From /tensorflow/models/research/object_detection/export_tflite_ssd_graph_lib.py:193: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.

WARNING:tensorflow:From /tensorflow/models/research/object_detection/export_tflite_ssd_graph_lib.py:237: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

W0410 12:39:17.465742 140155277027136 module_wrapper.py:139] From /tensorflow/models/research/object_detection/export_tflite_ssd_graph_lib.py:237: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From /tensorflow/models/research/object_detection/meta_architectures/ssd_meta_arch.py:597: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

W0410 12:39:17.468422 140155277027136 module_wrapper.py:139] From /tensorflow/models/research/object_detection/meta_architectures/ssd_meta_arch.py:597: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
Please use `layer.__call__` method instead.
W0410 12:39:17.471358 140155277027136 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
Please use `layer.__call__` method instead.
WARNING:tensorflow:From /tensorflow/models/research/object_detection/core/anchor_generator.py:171: The name tf.assert_equal is deprecated. Please use tf.compat.v1.assert_equal instead.

W0410 12:39:18.826324 140155277027136 module_wrapper.py:139] From /tensorflow/models/research/object_detection/core/anchor_generator.py:171: The name tf.assert_equal is deprecated. Please use tf.compat.v1.assert_equal instead.

WARNING:tensorflow:From /tensorflow/models/research/object_detection/predictors/convolutional_box_predictor.py:380: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.

W0410 12:39:19.233271 140155277027136 module_wrapper.py:139] From /tensorflow/models/research/object_detection/predictors/convolutional_box_predictor.py:380: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.

WARNING:tensorflow:From /tensorflow/models/research/object_detection/export_tflite_ssd_graph_lib.py:52: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

W0410 12:39:19.890158 140155277027136 module_wrapper.py:139] From /tensorflow/models/research/object_detection/export_tflite_ssd_graph_lib.py:52: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2020-04-10 12:39:19.891180: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-04-10 12:39:19.908694: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 12:39:19.909025: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: 
name: GeForce GTX 1050 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.62
pciBusID: 0000:01:00.0
2020-04-10 12:39:19.909296: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2020-04-10 12:39:19.910343: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2020-04-10 12:39:19.911197: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2020-04-10 12:39:19.911425: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2020-04-10 12:39:19.912640: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2020-04-10 12:39:19.913612: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2020-04-10 12:39:19.916425: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-04-10 12:39:19.916589: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 12:39:19.916980: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 12:39:19.917217: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0
2020-04-10 12:39:19.917530: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-04-10 12:39:19.941192: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2808000000 Hz
2020-04-10 12:39:19.941657: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7efacc0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-04-10 12:39:19.941674: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-04-10 12:39:19.987579: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 12:39:19.987958: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7905220 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-04-10 12:39:19.987995: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce GTX 1050 Ti, Compute Capability 6.1
2020-04-10 12:39:19.988151: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 12:39:19.988386: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: 
name: GeForce GTX 1050 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.62
pciBusID: 0000:01:00.0
2020-04-10 12:39:19.988425: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2020-04-10 12:39:19.988441: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2020-04-10 12:39:19.988454: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2020-04-10 12:39:19.988469: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2020-04-10 12:39:19.988485: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2020-04-10 12:39:19.988499: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2020-04-10 12:39:19.988516: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-04-10 12:39:19.988588: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 12:39:19.988915: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 12:39:19.989197: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0
2020-04-10 12:39:19.989246: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2020-04-10 12:39:19.989760: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-04-10 12:39:19.989773: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 
2020-04-10 12:39:19.989782: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N 
2020-04-10 12:39:19.989861: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 12:39:19.990093: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 12:39:19.990307: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 2888 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
WARNING:tensorflow:From /tensorflow/models/research/object_detection/export_tflite_ssd_graph_lib.py:267: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.

W0410 12:39:20.492587 140155277027136 module_wrapper.py:139] From /tensorflow/models/research/object_detection/export_tflite_ssd_graph_lib.py:267: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.

WARNING:tensorflow:From /tensorflow/models/research/object_detection/builders/graph_rewriter_builder.py:41: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

W0410 12:39:20.495462 140155277027136 module_wrapper.py:139] From /tensorflow/models/research/object_detection/builders/graph_rewriter_builder.py:41: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

INFO:tensorflow:Skipping quantizing WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_0/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
I0410 12:39:20.895448 140155277027136 quantize.py:588] Skipping quantizing WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_0/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
INFO:tensorflow:Skipping quantizing WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_1/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
I0410 12:39:20.895938 140155277027136 quantize.py:588] Skipping quantizing WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_1/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
INFO:tensorflow:Skipping quantizing WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_2/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
I0410 12:39:20.896350 140155277027136 quantize.py:588] Skipping quantizing WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_2/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
INFO:tensorflow:Skipping quantizing WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_3/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
I0410 12:39:20.896607 140155277027136 quantize.py:588] Skipping quantizing WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_3/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
INFO:tensorflow:Skipping quantizing WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_0/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
I0410 12:39:20.896919 140155277027136 quantize.py:588] Skipping quantizing WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_0/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
INFO:tensorflow:Skipping quantizing WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_1/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
I0410 12:39:20.897162 140155277027136 quantize.py:588] Skipping quantizing WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_1/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
INFO:tensorflow:Skipping quantizing WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_2/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
I0410 12:39:20.897400 140155277027136 quantize.py:588] Skipping quantizing WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_2/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
INFO:tensorflow:Skipping quantizing WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_3/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
I0410 12:39:20.897668 140155277027136 quantize.py:588] Skipping quantizing WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_3/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
INFO:tensorflow:Skipping quantizing WeightSharedConvolutionalBoxPredictor_1/BoxPredictionTower/conv2d_0/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
I0410 12:39:20.897969 140155277027136 quantize.py:588] Skipping quantizing WeightSharedConvolutionalBoxPredictor_1/BoxPredictionTower/conv2d_0/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
INFO:tensorflow:Skipping quantizing WeightSharedConvolutionalBoxPredictor_1/BoxPredictionTower/conv2d_1/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
I0410 12:39:20.898177 140155277027136 quantize.py:588] Skipping quantizing WeightSharedConvolutionalBoxPredictor_1/BoxPredictionTower/conv2d_1/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
INFO:tensorflow:Skipping quantizing WeightSharedConvolutionalBoxPredictor_1/BoxPredictionTower/conv2d_2/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
I0410 12:39:20.898397 140155277027136 quantize.py:588] Skipping quantizing WeightSharedConvolutionalBoxPredictor_1/BoxPredictionTower/conv2d_2/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
INFO:tensorflow:Skipping quantizing WeightSharedConvolutionalBoxPredictor_1/BoxPredictionTower/conv2d_3/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
I0410 12:39:20.898632 140155277027136 quantize.py:588] Skipping quantizing WeightSharedConvolutionalBoxPredictor_1/BoxPredictionTower/conv2d_3/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
INFO:tensorflow:Skipping quantizing WeightSharedConvolutionalBoxPredictor_1/ClassPredictionTower/conv2d_0/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
I0410 12:39:20.898874 140155277027136 quantize.py:588] Skipping quantizing WeightSharedConvolutionalBoxPredictor_1/ClassPredictionTower/conv2d_0/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
INFO:tensorflow:Skipping quantizing WeightSharedConvolutionalBoxPredictor_1/ClassPredictionTower/conv2d_1/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
I0410 12:39:20.899109 140155277027136 quantize.py:588] Skipping quantizing WeightSharedConvolutionalBoxPredictor_1/ClassPredictionTower/conv2d_1/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
INFO:tensorflow:Skipping quantizing WeightSharedConvolutionalBoxPredictor_1/ClassPredictionTower/conv2d_2/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
I0410 12:39:20.899347 140155277027136 quantize.py:588] Skipping quantizing WeightSharedConvolutionalBoxPredictor_1/ClassPredictionTower/conv2d_2/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
INFO:tensorflow:Skipping quantizing WeightSharedConvolutionalBoxPredictor_1/ClassPredictionTower/conv2d_3/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
I0410 12:39:20.899583 140155277027136 quantize.py:588] Skipping quantizing WeightSharedConvolutionalBoxPredictor_1/ClassPredictionTower/conv2d_3/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
INFO:tensorflow:Skipping quantizing WeightSharedConvolutionalBoxPredictor_2/BoxPredictionTower/conv2d_0/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
I0410 12:39:20.899877 140155277027136 quantize.py:588] Skipping quantizing WeightSharedConvolutionalBoxPredictor_2/BoxPredictionTower/conv2d_0/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
INFO:tensorflow:Skipping quantizing WeightSharedConvolutionalBoxPredictor_2/BoxPredictionTower/conv2d_1/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
I0410 12:39:20.900119 140155277027136 quantize.py:588] Skipping quantizing WeightSharedConvolutionalBoxPredictor_2/BoxPredictionTower/conv2d_1/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
INFO:tensorflow:Skipping quantizing WeightSharedConvolutionalBoxPredictor_2/BoxPredictionTower/conv2d_2/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
I0410 12:39:20.900363 140155277027136 quantize.py:588] Skipping quantizing WeightSharedConvolutionalBoxPredictor_2/BoxPredictionTower/conv2d_2/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
INFO:tensorflow:Skipping quantizing WeightSharedConvolutionalBoxPredictor_2/BoxPredictionTower/conv2d_3/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
I0410 12:39:20.900600 140155277027136 quantize.py:588] Skipping quantizing WeightSharedConvolutionalBoxPredictor_2/BoxPredictionTower/conv2d_3/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
INFO:tensorflow:Skipping quantizing WeightSharedConvolutionalBoxPredictor_2/ClassPredictionTower/conv2d_0/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
I0410 12:39:20.900838 140155277027136 quantize.py:588] Skipping quantizing WeightSharedConvolutionalBoxPredictor_2/ClassPredictionTower/conv2d_0/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
INFO:tensorflow:Skipping quantizing WeightSharedConvolutionalBoxPredictor_2/ClassPredictionTower/conv2d_1/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
I0410 12:39:20.901076 140155277027136 quantize.py:588] Skipping quantizing WeightSharedConvolutionalBoxPredictor_2/ClassPredictionTower/conv2d_1/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
INFO:tensorflow:Skipping quantizing WeightSharedConvolutionalBoxPredictor_2/ClassPredictionTower/conv2d_2/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
I0410 12:39:20.901296 140155277027136 quantize.py:588] Skipping quantizing WeightSharedConvolutionalBoxPredictor_2/ClassPredictionTower/conv2d_2/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
INFO:tensorflow:Skipping quantizing WeightSharedConvolutionalBoxPredictor_2/ClassPredictionTower/conv2d_3/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
I0410 12:39:20.901502 140155277027136 quantize.py:588] Skipping quantizing WeightSharedConvolutionalBoxPredictor_2/ClassPredictionTower/conv2d_3/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
INFO:tensorflow:Skipping quantizing WeightSharedConvolutionalBoxPredictor_3/BoxPredictionTower/conv2d_0/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
I0410 12:39:20.901758 140155277027136 quantize.py:588] Skipping quantizing WeightSharedConvolutionalBoxPredictor_3/BoxPredictionTower/conv2d_0/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
INFO:tensorflow:Skipping quantizing WeightSharedConvolutionalBoxPredictor_3/BoxPredictionTower/conv2d_1/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
I0410 12:39:20.901966 140155277027136 quantize.py:588] Skipping quantizing WeightSharedConvolutionalBoxPredictor_3/BoxPredictionTower/conv2d_1/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
INFO:tensorflow:Skipping quantizing WeightSharedConvolutionalBoxPredictor_3/BoxPredictionTower/conv2d_2/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
I0410 12:39:20.902171 140155277027136 quantize.py:588] Skipping quantizing WeightSharedConvolutionalBoxPredictor_3/BoxPredictionTower/conv2d_2/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
INFO:tensorflow:Skipping quantizing WeightSharedConvolutionalBoxPredictor_3/BoxPredictionTower/conv2d_3/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
I0410 12:39:20.902374 140155277027136 quantize.py:588] Skipping quantizing WeightSharedConvolutionalBoxPredictor_3/BoxPredictionTower/conv2d_3/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
INFO:tensorflow:Skipping quantizing WeightSharedConvolutionalBoxPredictor_3/ClassPredictionTower/conv2d_0/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
I0410 12:39:20.902588 140155277027136 quantize.py:588] Skipping quantizing WeightSharedConvolutionalBoxPredictor_3/ClassPredictionTower/conv2d_0/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
INFO:tensorflow:Skipping quantizing WeightSharedConvolutionalBoxPredictor_3/ClassPredictionTower/conv2d_1/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
I0410 12:39:20.902798 140155277027136 quantize.py:588] Skipping quantizing WeightSharedConvolutionalBoxPredictor_3/ClassPredictionTower/conv2d_1/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
INFO:tensorflow:Skipping quantizing WeightSharedConvolutionalBoxPredictor_3/ClassPredictionTower/conv2d_2/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
I0410 12:39:20.903002 140155277027136 quantize.py:588] Skipping quantizing WeightSharedConvolutionalBoxPredictor_3/ClassPredictionTower/conv2d_2/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
INFO:tensorflow:Skipping quantizing WeightSharedConvolutionalBoxPredictor_3/ClassPredictionTower/conv2d_3/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
I0410 12:39:20.903205 140155277027136 quantize.py:588] Skipping quantizing WeightSharedConvolutionalBoxPredictor_3/ClassPredictionTower/conv2d_3/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
INFO:tensorflow:Skipping quantizing WeightSharedConvolutionalBoxPredictor_4/BoxPredictionTower/conv2d_0/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
I0410 12:39:20.903466 140155277027136 quantize.py:588] Skipping quantizing WeightSharedConvolutionalBoxPredictor_4/BoxPredictionTower/conv2d_0/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
INFO:tensorflow:Skipping quantizing WeightSharedConvolutionalBoxPredictor_4/BoxPredictionTower/conv2d_1/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
I0410 12:39:20.903675 140155277027136 quantize.py:588] Skipping quantizing WeightSharedConvolutionalBoxPredictor_4/BoxPredictionTower/conv2d_1/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
INFO:tensorflow:Skipping quantizing WeightSharedConvolutionalBoxPredictor_4/BoxPredictionTower/conv2d_2/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
I0410 12:39:20.903881 140155277027136 quantize.py:588] Skipping quantizing WeightSharedConvolutionalBoxPredictor_4/BoxPredictionTower/conv2d_2/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
INFO:tensorflow:Skipping quantizing WeightSharedConvolutionalBoxPredictor_4/BoxPredictionTower/conv2d_3/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
I0410 12:39:20.904086 140155277027136 quantize.py:588] Skipping quantizing WeightSharedConvolutionalBoxPredictor_4/BoxPredictionTower/conv2d_3/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
INFO:tensorflow:Skipping quantizing WeightSharedConvolutionalBoxPredictor_4/ClassPredictionTower/conv2d_0/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
I0410 12:39:20.904299 140155277027136 quantize.py:588] Skipping quantizing WeightSharedConvolutionalBoxPredictor_4/ClassPredictionTower/conv2d_0/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
INFO:tensorflow:Skipping quantizing WeightSharedConvolutionalBoxPredictor_4/ClassPredictionTower/conv2d_1/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
I0410 12:39:20.904532 140155277027136 quantize.py:588] Skipping quantizing WeightSharedConvolutionalBoxPredictor_4/ClassPredictionTower/conv2d_1/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
INFO:tensorflow:Skipping quantizing WeightSharedConvolutionalBoxPredictor_4/ClassPredictionTower/conv2d_2/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
I0410 12:39:20.904742 140155277027136 quantize.py:588] Skipping quantizing WeightSharedConvolutionalBoxPredictor_4/ClassPredictionTower/conv2d_2/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
INFO:tensorflow:Skipping quantizing WeightSharedConvolutionalBoxPredictor_4/ClassPredictionTower/conv2d_3/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
I0410 12:39:20.904950 140155277027136 quantize.py:588] Skipping quantizing WeightSharedConvolutionalBoxPredictor_4/ClassPredictionTower/conv2d_3/Identity, because it is the output of a conv/fc followed by a identity, feeding a fused batch norm.
INFO:tensorflow:Skipping FeatureExtractor/resnet_v1_50/resnet_v1_50/block1/unit_1/bottleneck_v1/add, because its followed by an activation.
I0410 12:39:20.949430 140155277027136 quantize.py:166] Skipping FeatureExtractor/resnet_v1_50/resnet_v1_50/block1/unit_1/bottleneck_v1/add, because its followed by an activation.
INFO:tensorflow:Skipping FeatureExtractor/resnet_v1_50/resnet_v1_50/block1/unit_2/bottleneck_v1/add, because its followed by an activation.
I0410 12:39:20.949680 140155277027136 quantize.py:201] Skipping FeatureExtractor/resnet_v1_50/resnet_v1_50/block1/unit_2/bottleneck_v1/add, because its followed by an activation.
INFO:tensorflow:Skipping FeatureExtractor/resnet_v1_50/resnet_v1_50/block1/unit_2/bottleneck_v1/add, because its followed by an activation.
I0410 12:39:20.964820 140155277027136 quantize.py:166] Skipping FeatureExtractor/resnet_v1_50/resnet_v1_50/block1/unit_2/bottleneck_v1/add, because its followed by an activation.
INFO:tensorflow:Skipping FeatureExtractor/resnet_v1_50/resnet_v1_50/block1/unit_3/bottleneck_v1/add, because its followed by an activation.
I0410 12:39:20.965119 140155277027136 quantize.py:201] Skipping FeatureExtractor/resnet_v1_50/resnet_v1_50/block1/unit_3/bottleneck_v1/add, because its followed by an activation.
INFO:tensorflow:Skipping FeatureExtractor/resnet_v1_50/resnet_v1_50/block2/unit_1/bottleneck_v1/add, because its followed by an activation.
I0410 12:39:20.980214 140155277027136 quantize.py:166] Skipping FeatureExtractor/resnet_v1_50/resnet_v1_50/block2/unit_1/bottleneck_v1/add, because its followed by an activation.
INFO:tensorflow:Skipping FeatureExtractor/resnet_v1_50/resnet_v1_50/block2/unit_2/bottleneck_v1/add, because its followed by an activation.
I0410 12:39:20.980386 140155277027136 quantize.py:201] Skipping FeatureExtractor/resnet_v1_50/resnet_v1_50/block2/unit_2/bottleneck_v1/add, because its followed by an activation.
INFO:tensorflow:Skipping FeatureExtractor/resnet_v1_50/resnet_v1_50/block2/unit_2/bottleneck_v1/add, because its followed by an activation.
I0410 12:39:20.996045 140155277027136 quantize.py:166] Skipping FeatureExtractor/resnet_v1_50/resnet_v1_50/block2/unit_2/bottleneck_v1/add, because its followed by an activation.
INFO:tensorflow:Skipping FeatureExtractor/resnet_v1_50/resnet_v1_50/block2/unit_3/bottleneck_v1/add, because its followed by an activation.
I0410 12:39:20.996264 140155277027136 quantize.py:201] Skipping FeatureExtractor/resnet_v1_50/resnet_v1_50/block2/unit_3/bottleneck_v1/add, because its followed by an activation.
INFO:tensorflow:Skipping FeatureExtractor/resnet_v1_50/resnet_v1_50/block2/unit_3/bottleneck_v1/add, because its followed by an activation.
I0410 12:39:21.011528 140155277027136 quantize.py:166] Skipping FeatureExtractor/resnet_v1_50/resnet_v1_50/block2/unit_3/bottleneck_v1/add, because its followed by an activation.
INFO:tensorflow:Skipping FeatureExtractor/resnet_v1_50/resnet_v1_50/block2/unit_4/bottleneck_v1/add, because its followed by an activation.
I0410 12:39:21.011718 140155277027136 quantize.py:201] Skipping FeatureExtractor/resnet_v1_50/resnet_v1_50/block2/unit_4/bottleneck_v1/add, because its followed by an activation.
INFO:tensorflow:Skipping FeatureExtractor/resnet_v1_50/resnet_v1_50/block3/unit_1/bottleneck_v1/add, because its followed by an activation.
I0410 12:39:21.027328 140155277027136 quantize.py:166] Skipping FeatureExtractor/resnet_v1_50/resnet_v1_50/block3/unit_1/bottleneck_v1/add, because its followed by an activation.
INFO:tensorflow:Skipping FeatureExtractor/resnet_v1_50/resnet_v1_50/block3/unit_2/bottleneck_v1/add, because its followed by an activation.
I0410 12:39:21.027498 140155277027136 quantize.py:201] Skipping FeatureExtractor/resnet_v1_50/resnet_v1_50/block3/unit_2/bottleneck_v1/add, because its followed by an activation.
INFO:tensorflow:Skipping FeatureExtractor/resnet_v1_50/resnet_v1_50/block3/unit_2/bottleneck_v1/add, because its followed by an activation.
I0410 12:39:21.044524 140155277027136 quantize.py:166] Skipping FeatureExtractor/resnet_v1_50/resnet_v1_50/block3/unit_2/bottleneck_v1/add, because its followed by an activation.
INFO:tensorflow:Skipping FeatureExtractor/resnet_v1_50/resnet_v1_50/block3/unit_3/bottleneck_v1/add, because its followed by an activation.
I0410 12:39:21.044679 140155277027136 quantize.py:201] Skipping FeatureExtractor/resnet_v1_50/resnet_v1_50/block3/unit_3/bottleneck_v1/add, because its followed by an activation.
INFO:tensorflow:Skipping FeatureExtractor/resnet_v1_50/resnet_v1_50/block3/unit_3/bottleneck_v1/add, because its followed by an activation.
I0410 12:39:21.061121 140155277027136 quantize.py:166] Skipping FeatureExtractor/resnet_v1_50/resnet_v1_50/block3/unit_3/bottleneck_v1/add, because its followed by an activation.
INFO:tensorflow:Skipping FeatureExtractor/resnet_v1_50/resnet_v1_50/block3/unit_4/bottleneck_v1/add, because its followed by an activation.
I0410 12:39:21.061372 140155277027136 quantize.py:201] Skipping FeatureExtractor/resnet_v1_50/resnet_v1_50/block3/unit_4/bottleneck_v1/add, because its followed by an activation.
INFO:tensorflow:Skipping FeatureExtractor/resnet_v1_50/resnet_v1_50/block3/unit_4/bottleneck_v1/add, because its followed by an activation.
I0410 12:39:21.076568 140155277027136 quantize.py:166] Skipping FeatureExtractor/resnet_v1_50/resnet_v1_50/block3/unit_4/bottleneck_v1/add, because its followed by an activation.
INFO:tensorflow:Skipping FeatureExtractor/resnet_v1_50/resnet_v1_50/block3/unit_5/bottleneck_v1/add, because its followed by an activation.
I0410 12:39:21.076805 140155277027136 quantize.py:201] Skipping FeatureExtractor/resnet_v1_50/resnet_v1_50/block3/unit_5/bottleneck_v1/add, because its followed by an activation.
INFO:tensorflow:Skipping FeatureExtractor/resnet_v1_50/resnet_v1_50/block3/unit_5/bottleneck_v1/add, because its followed by an activation.
I0410 12:39:21.092691 140155277027136 quantize.py:166] Skipping FeatureExtractor/resnet_v1_50/resnet_v1_50/block3/unit_5/bottleneck_v1/add, because its followed by an activation.
INFO:tensorflow:Skipping FeatureExtractor/resnet_v1_50/resnet_v1_50/block3/unit_6/bottleneck_v1/add, because its followed by an activation.
I0410 12:39:21.092893 140155277027136 quantize.py:201] Skipping FeatureExtractor/resnet_v1_50/resnet_v1_50/block3/unit_6/bottleneck_v1/add, because its followed by an activation.
INFO:tensorflow:Skipping FeatureExtractor/resnet_v1_50/resnet_v1_50/block4/unit_1/bottleneck_v1/add, because its followed by an activation.
I0410 12:39:21.107756 140155277027136 quantize.py:166] Skipping FeatureExtractor/resnet_v1_50/resnet_v1_50/block4/unit_1/bottleneck_v1/add, because its followed by an activation.
INFO:tensorflow:Skipping FeatureExtractor/resnet_v1_50/resnet_v1_50/block4/unit_2/bottleneck_v1/add, because its followed by an activation.
I0410 12:39:21.107955 140155277027136 quantize.py:201] Skipping FeatureExtractor/resnet_v1_50/resnet_v1_50/block4/unit_2/bottleneck_v1/add, because its followed by an activation.
INFO:tensorflow:Skipping FeatureExtractor/resnet_v1_50/resnet_v1_50/block4/unit_2/bottleneck_v1/add, because its followed by an activation.
I0410 12:39:21.123640 140155277027136 quantize.py:166] Skipping FeatureExtractor/resnet_v1_50/resnet_v1_50/block4/unit_2/bottleneck_v1/add, because its followed by an activation.
INFO:tensorflow:Skipping FeatureExtractor/resnet_v1_50/resnet_v1_50/block4/unit_3/bottleneck_v1/add, because its followed by an activation.
I0410 12:39:21.123864 140155277027136 quantize.py:201] Skipping FeatureExtractor/resnet_v1_50/resnet_v1_50/block4/unit_3/bottleneck_v1/add, because its followed by an activation.
INFO:tensorflow:Skipping FeatureExtractor/resnet_v1_50/resnet_v1_50/block1/unit_3/bottleneck_v1/add, because its followed by an activation.
I0410 12:39:21.206912 140155277027136 quantize.py:166] Skipping FeatureExtractor/resnet_v1_50/resnet_v1_50/block1/unit_3/bottleneck_v1/add, because its followed by an activation.
INFO:tensorflow:Skipping FeatureExtractor/resnet_v1_50/resnet_v1_50/block2/unit_4/bottleneck_v1/add, because its followed by an activation.
I0410 12:39:21.297351 140155277027136 quantize.py:166] Skipping FeatureExtractor/resnet_v1_50/resnet_v1_50/block2/unit_4/bottleneck_v1/add, because its followed by an activation.
INFO:tensorflow:Skipping FeatureExtractor/resnet_v1_50/resnet_v1_50/block3/unit_6/bottleneck_v1/add, because its followed by an activation.
I0410 12:39:21.426005 140155277027136 quantize.py:166] Skipping FeatureExtractor/resnet_v1_50/resnet_v1_50/block3/unit_6/bottleneck_v1/add, because its followed by an activation.
INFO:tensorflow:Skipping FeatureExtractor/resnet_v1_50/resnet_v1_50/block4/unit_3/bottleneck_v1/add, because its followed by an activation.
I0410 12:39:21.500694 140155277027136 quantize.py:166] Skipping FeatureExtractor/resnet_v1_50/resnet_v1_50/block4/unit_3/bottleneck_v1/add, because its followed by an activation.
INFO:tensorflow:Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block1/unit_1/bottleneck_v1/add
I0410 12:39:22.099278 140155277027136 quantize.py:299] Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block1/unit_1/bottleneck_v1/add
INFO:tensorflow:Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block1/unit_2/bottleneck_v1/add
I0410 12:39:22.099895 140155277027136 quantize.py:299] Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block1/unit_2/bottleneck_v1/add
INFO:tensorflow:Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block1/unit_3/bottleneck_v1/add
I0410 12:39:22.100310 140155277027136 quantize.py:299] Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block1/unit_3/bottleneck_v1/add
INFO:tensorflow:Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block2/unit_1/bottleneck_v1/add
I0410 12:39:22.100712 140155277027136 quantize.py:299] Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block2/unit_1/bottleneck_v1/add
INFO:tensorflow:Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block2/unit_2/bottleneck_v1/add
I0410 12:39:22.101081 140155277027136 quantize.py:299] Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block2/unit_2/bottleneck_v1/add
INFO:tensorflow:Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block2/unit_3/bottleneck_v1/add
I0410 12:39:22.101440 140155277027136 quantize.py:299] Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block2/unit_3/bottleneck_v1/add
INFO:tensorflow:Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block2/unit_4/bottleneck_v1/add
I0410 12:39:22.101804 140155277027136 quantize.py:299] Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block2/unit_4/bottleneck_v1/add
INFO:tensorflow:Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block3/unit_1/bottleneck_v1/add
I0410 12:39:22.102235 140155277027136 quantize.py:299] Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block3/unit_1/bottleneck_v1/add
INFO:tensorflow:Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block3/unit_2/bottleneck_v1/add
I0410 12:39:22.102601 140155277027136 quantize.py:299] Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block3/unit_2/bottleneck_v1/add
INFO:tensorflow:Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block3/unit_3/bottleneck_v1/add
I0410 12:39:22.103026 140155277027136 quantize.py:299] Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block3/unit_3/bottleneck_v1/add
INFO:tensorflow:Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block3/unit_4/bottleneck_v1/add
I0410 12:39:22.103431 140155277027136 quantize.py:299] Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block3/unit_4/bottleneck_v1/add
INFO:tensorflow:Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block3/unit_5/bottleneck_v1/add
I0410 12:39:22.103817 140155277027136 quantize.py:299] Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block3/unit_5/bottleneck_v1/add
INFO:tensorflow:Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block3/unit_6/bottleneck_v1/add
I0410 12:39:22.104173 140155277027136 quantize.py:299] Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block3/unit_6/bottleneck_v1/add
INFO:tensorflow:Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block4/unit_1/bottleneck_v1/add
I0410 12:39:22.104722 140155277027136 quantize.py:299] Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block4/unit_1/bottleneck_v1/add
INFO:tensorflow:Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block4/unit_2/bottleneck_v1/add
I0410 12:39:22.105071 140155277027136 quantize.py:299] Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block4/unit_2/bottleneck_v1/add
INFO:tensorflow:Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block4/unit_3/bottleneck_v1/add
I0410 12:39:22.105430 140155277027136 quantize.py:299] Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block4/unit_3/bottleneck_v1/add
INFO:tensorflow:Inserting fake quant op activation_AddV2_quant after FeatureExtractor/resnet_v1_50/fpn/top_down/add
I0410 12:39:22.105675 140155277027136 quantize.py:262] Inserting fake quant op activation_AddV2_quant after FeatureExtractor/resnet_v1_50/fpn/top_down/add
INFO:tensorflow:Inserting fake quant op activation_AddV2_quant after FeatureExtractor/resnet_v1_50/fpn/top_down/add_1
I0410 12:39:22.111881 140155277027136 quantize.py:262] Inserting fake quant op activation_AddV2_quant after FeatureExtractor/resnet_v1_50/fpn/top_down/add_1
INFO:tensorflow:Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/conv1/add_fold
I0410 12:39:22.121784 140155277027136 quantize.py:299] Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/conv1/add_fold
INFO:tensorflow:Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block1/unit_1/bottleneck_v1/conv1/add_fold
I0410 12:39:22.122250 140155277027136 quantize.py:299] Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block1/unit_1/bottleneck_v1/conv1/add_fold
INFO:tensorflow:Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block1/unit_1/bottleneck_v1/conv2/add_fold
I0410 12:39:22.122534 140155277027136 quantize.py:299] Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block1/unit_1/bottleneck_v1/conv2/add_fold
INFO:tensorflow:Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block1/unit_2/bottleneck_v1/conv1/add_fold
I0410 12:39:22.122827 140155277027136 quantize.py:299] Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block1/unit_2/bottleneck_v1/conv1/add_fold
INFO:tensorflow:Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block1/unit_2/bottleneck_v1/conv2/add_fold
I0410 12:39:22.123043 140155277027136 quantize.py:299] Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block1/unit_2/bottleneck_v1/conv2/add_fold
INFO:tensorflow:Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block1/unit_3/bottleneck_v1/conv1/add_fold
I0410 12:39:22.123297 140155277027136 quantize.py:299] Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block1/unit_3/bottleneck_v1/conv1/add_fold
INFO:tensorflow:Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block1/unit_3/bottleneck_v1/conv2/add_fold
I0410 12:39:22.123489 140155277027136 quantize.py:299] Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block1/unit_3/bottleneck_v1/conv2/add_fold
INFO:tensorflow:Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block2/unit_1/bottleneck_v1/conv1/add_fold
I0410 12:39:22.123872 140155277027136 quantize.py:299] Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block2/unit_1/bottleneck_v1/conv1/add_fold
INFO:tensorflow:Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block2/unit_1/bottleneck_v1/conv2/add_fold
I0410 12:39:22.124067 140155277027136 quantize.py:299] Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block2/unit_1/bottleneck_v1/conv2/add_fold
INFO:tensorflow:Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block2/unit_2/bottleneck_v1/conv1/add_fold
I0410 12:39:22.124314 140155277027136 quantize.py:299] Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block2/unit_2/bottleneck_v1/conv1/add_fold
INFO:tensorflow:Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block2/unit_2/bottleneck_v1/conv2/add_fold
I0410 12:39:22.124595 140155277027136 quantize.py:299] Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block2/unit_2/bottleneck_v1/conv2/add_fold
INFO:tensorflow:Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block2/unit_3/bottleneck_v1/conv1/add_fold
I0410 12:39:22.124916 140155277027136 quantize.py:299] Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block2/unit_3/bottleneck_v1/conv1/add_fold
INFO:tensorflow:Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block2/unit_3/bottleneck_v1/conv2/add_fold
I0410 12:39:22.125163 140155277027136 quantize.py:299] Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block2/unit_3/bottleneck_v1/conv2/add_fold
INFO:tensorflow:Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block2/unit_4/bottleneck_v1/conv1/add_fold
I0410 12:39:22.125458 140155277027136 quantize.py:299] Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block2/unit_4/bottleneck_v1/conv1/add_fold
INFO:tensorflow:Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block2/unit_4/bottleneck_v1/conv2/add_fold
I0410 12:39:22.125700 140155277027136 quantize.py:299] Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block2/unit_4/bottleneck_v1/conv2/add_fold
INFO:tensorflow:Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block3/unit_1/bottleneck_v1/conv1/add_fold
I0410 12:39:22.126079 140155277027136 quantize.py:299] Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block3/unit_1/bottleneck_v1/conv1/add_fold
INFO:tensorflow:Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block3/unit_1/bottleneck_v1/conv2/add_fold
I0410 12:39:22.126330 140155277027136 quantize.py:299] Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block3/unit_1/bottleneck_v1/conv2/add_fold
INFO:tensorflow:Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block3/unit_2/bottleneck_v1/conv1/add_fold
I0410 12:39:22.126605 140155277027136 quantize.py:299] Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block3/unit_2/bottleneck_v1/conv1/add_fold
INFO:tensorflow:Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block3/unit_2/bottleneck_v1/conv2/add_fold
I0410 12:39:22.126782 140155277027136 quantize.py:299] Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block3/unit_2/bottleneck_v1/conv2/add_fold
INFO:tensorflow:Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block3/unit_3/bottleneck_v1/conv1/add_fold
I0410 12:39:22.127025 140155277027136 quantize.py:299] Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block3/unit_3/bottleneck_v1/conv1/add_fold
INFO:tensorflow:Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block3/unit_3/bottleneck_v1/conv2/add_fold
I0410 12:39:22.127182 140155277027136 quantize.py:299] Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block3/unit_3/bottleneck_v1/conv2/add_fold
INFO:tensorflow:Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block3/unit_4/bottleneck_v1/conv1/add_fold
I0410 12:39:22.127393 140155277027136 quantize.py:299] Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block3/unit_4/bottleneck_v1/conv1/add_fold
INFO:tensorflow:Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block3/unit_4/bottleneck_v1/conv2/add_fold
I0410 12:39:22.127542 140155277027136 quantize.py:299] Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block3/unit_4/bottleneck_v1/conv2/add_fold
INFO:tensorflow:Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block3/unit_5/bottleneck_v1/conv1/add_fold
I0410 12:39:22.127753 140155277027136 quantize.py:299] Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block3/unit_5/bottleneck_v1/conv1/add_fold
INFO:tensorflow:Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block3/unit_5/bottleneck_v1/conv2/add_fold
I0410 12:39:22.127903 140155277027136 quantize.py:299] Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block3/unit_5/bottleneck_v1/conv2/add_fold
INFO:tensorflow:Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block3/unit_6/bottleneck_v1/conv1/add_fold
I0410 12:39:22.128112 140155277027136 quantize.py:299] Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block3/unit_6/bottleneck_v1/conv1/add_fold
INFO:tensorflow:Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block3/unit_6/bottleneck_v1/conv2/add_fold
I0410 12:39:22.128261 140155277027136 quantize.py:299] Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block3/unit_6/bottleneck_v1/conv2/add_fold
INFO:tensorflow:Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block4/unit_1/bottleneck_v1/conv1/add_fold
I0410 12:39:22.128529 140155277027136 quantize.py:299] Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block4/unit_1/bottleneck_v1/conv1/add_fold
INFO:tensorflow:Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block4/unit_1/bottleneck_v1/conv2/add_fold
I0410 12:39:22.128677 140155277027136 quantize.py:299] Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block4/unit_1/bottleneck_v1/conv2/add_fold
INFO:tensorflow:Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block4/unit_2/bottleneck_v1/conv1/add_fold
I0410 12:39:22.128887 140155277027136 quantize.py:299] Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block4/unit_2/bottleneck_v1/conv1/add_fold
INFO:tensorflow:Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block4/unit_2/bottleneck_v1/conv2/add_fold
I0410 12:39:22.129033 140155277027136 quantize.py:299] Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block4/unit_2/bottleneck_v1/conv2/add_fold
INFO:tensorflow:Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block4/unit_3/bottleneck_v1/conv1/add_fold
I0410 12:39:22.129251 140155277027136 quantize.py:299] Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block4/unit_3/bottleneck_v1/conv1/add_fold
INFO:tensorflow:Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block4/unit_3/bottleneck_v1/conv2/add_fold
I0410 12:39:22.129395 140155277027136 quantize.py:299] Skipping quant after FeatureExtractor/resnet_v1_50/resnet_v1_50/block4/unit_3/bottleneck_v1/conv2/add_fold
INFO:tensorflow:Skipping quant after FeatureExtractor/resnet_v1_50/fpn/top_down/smoothing_2/add_fold
I0410 12:39:22.129603 140155277027136 quantize.py:299] Skipping quant after FeatureExtractor/resnet_v1_50/fpn/top_down/smoothing_2/add_fold
INFO:tensorflow:Skipping quant after FeatureExtractor/resnet_v1_50/fpn/top_down/smoothing_1/add_fold
I0410 12:39:22.129747 140155277027136 quantize.py:299] Skipping quant after FeatureExtractor/resnet_v1_50/fpn/top_down/smoothing_1/add_fold
INFO:tensorflow:Skipping quant after FeatureExtractor/resnet_v1_50/fpn/bottom_up_block5/add_fold
I0410 12:39:22.129896 140155277027136 quantize.py:299] Skipping quant after FeatureExtractor/resnet_v1_50/fpn/bottom_up_block5/add_fold
INFO:tensorflow:Skipping quant after FeatureExtractor/resnet_v1_50/fpn/bottom_up_block6/add_fold
I0410 12:39:22.130037 140155277027136 quantize.py:299] Skipping quant after FeatureExtractor/resnet_v1_50/fpn/bottom_up_block6/add_fold
INFO:tensorflow:Skipping quant after WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_0/add_fold
I0410 12:39:22.130177 140155277027136 quantize.py:299] Skipping quant after WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_0/add_fold
INFO:tensorflow:Skipping quant after WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_1/add_fold
I0410 12:39:22.130314 140155277027136 quantize.py:299] Skipping quant after WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_1/add_fold
INFO:tensorflow:Skipping quant after WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_2/add_fold
I0410 12:39:22.130451 140155277027136 quantize.py:299] Skipping quant after WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_2/add_fold
INFO:tensorflow:Skipping quant after WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_3/add_fold
I0410 12:39:22.130587 140155277027136 quantize.py:299] Skipping quant after WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_3/add_fold
INFO:tensorflow:Skipping quant after WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_0/add_fold
I0410 12:39:22.130723 140155277027136 quantize.py:299] Skipping quant after WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_0/add_fold
INFO:tensorflow:Skipping quant after WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_1/add_fold
I0410 12:39:22.130858 140155277027136 quantize.py:299] Skipping quant after WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_1/add_fold
INFO:tensorflow:Skipping quant after WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_2/add_fold
I0410 12:39:22.130995 140155277027136 quantize.py:299] Skipping quant after WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_2/add_fold
INFO:tensorflow:Skipping quant after WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_3/add_fold
I0410 12:39:22.131131 140155277027136 quantize.py:299] Skipping quant after WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_3/add_fold
INFO:tensorflow:Skipping quant after WeightSharedConvolutionalBoxPredictor_1/BoxPredictionTower/conv2d_0/add_fold
I0410 12:39:22.131264 140155277027136 quantize.py:299] Skipping quant after WeightSharedConvolutionalBoxPredictor_1/BoxPredictionTower/conv2d_0/add_fold
INFO:tensorflow:Skipping quant after WeightSharedConvolutionalBoxPredictor_1/BoxPredictionTower/conv2d_1/add_fold
I0410 12:39:22.131427 140155277027136 quantize.py:299] Skipping quant after WeightSharedConvolutionalBoxPredictor_1/BoxPredictionTower/conv2d_1/add_fold
INFO:tensorflow:Skipping quant after WeightSharedConvolutionalBoxPredictor_1/BoxPredictionTower/conv2d_2/add_fold
I0410 12:39:22.131577 140155277027136 quantize.py:299] Skipping quant after WeightSharedConvolutionalBoxPredictor_1/BoxPredictionTower/conv2d_2/add_fold
INFO:tensorflow:Skipping quant after WeightSharedConvolutionalBoxPredictor_1/BoxPredictionTower/conv2d_3/add_fold
I0410 12:39:22.131731 140155277027136 quantize.py:299] Skipping quant after WeightSharedConvolutionalBoxPredictor_1/BoxPredictionTower/conv2d_3/add_fold
INFO:tensorflow:Skipping quant after WeightSharedConvolutionalBoxPredictor_1/ClassPredictionTower/conv2d_0/add_fold
I0410 12:39:22.131886 140155277027136 quantize.py:299] Skipping quant after WeightSharedConvolutionalBoxPredictor_1/ClassPredictionTower/conv2d_0/add_fold
INFO:tensorflow:Skipping quant after WeightSharedConvolutionalBoxPredictor_1/ClassPredictionTower/conv2d_1/add_fold
I0410 12:39:22.132046 140155277027136 quantize.py:299] Skipping quant after WeightSharedConvolutionalBoxPredictor_1/ClassPredictionTower/conv2d_1/add_fold
INFO:tensorflow:Skipping quant after WeightSharedConvolutionalBoxPredictor_1/ClassPredictionTower/conv2d_2/add_fold
I0410 12:39:22.132216 140155277027136 quantize.py:299] Skipping quant after WeightSharedConvolutionalBoxPredictor_1/ClassPredictionTower/conv2d_2/add_fold
INFO:tensorflow:Skipping quant after WeightSharedConvolutionalBoxPredictor_1/ClassPredictionTower/conv2d_3/add_fold
I0410 12:39:22.132382 140155277027136 quantize.py:299] Skipping quant after WeightSharedConvolutionalBoxPredictor_1/ClassPredictionTower/conv2d_3/add_fold
INFO:tensorflow:Skipping quant after WeightSharedConvolutionalBoxPredictor_2/BoxPredictionTower/conv2d_0/add_fold
I0410 12:39:22.132542 140155277027136 quantize.py:299] Skipping quant after WeightSharedConvolutionalBoxPredictor_2/BoxPredictionTower/conv2d_0/add_fold
INFO:tensorflow:Skipping quant after WeightSharedConvolutionalBoxPredictor_2/BoxPredictionTower/conv2d_1/add_fold
I0410 12:39:22.132689 140155277027136 quantize.py:299] Skipping quant after WeightSharedConvolutionalBoxPredictor_2/BoxPredictionTower/conv2d_1/add_fold
INFO:tensorflow:Skipping quant after WeightSharedConvolutionalBoxPredictor_2/BoxPredictionTower/conv2d_2/add_fold
I0410 12:39:22.132832 140155277027136 quantize.py:299] Skipping quant after WeightSharedConvolutionalBoxPredictor_2/BoxPredictionTower/conv2d_2/add_fold
INFO:tensorflow:Skipping quant after WeightSharedConvolutionalBoxPredictor_2/BoxPredictionTower/conv2d_3/add_fold
I0410 12:39:22.132973 140155277027136 quantize.py:299] Skipping quant after WeightSharedConvolutionalBoxPredictor_2/BoxPredictionTower/conv2d_3/add_fold
INFO:tensorflow:Skipping quant after WeightSharedConvolutionalBoxPredictor_2/ClassPredictionTower/conv2d_0/add_fold
I0410 12:39:22.133126 140155277027136 quantize.py:299] Skipping quant after WeightSharedConvolutionalBoxPredictor_2/ClassPredictionTower/conv2d_0/add_fold
INFO:tensorflow:Skipping quant after WeightSharedConvolutionalBoxPredictor_2/ClassPredictionTower/conv2d_1/add_fold
I0410 12:39:22.133264 140155277027136 quantize.py:299] Skipping quant after WeightSharedConvolutionalBoxPredictor_2/ClassPredictionTower/conv2d_1/add_fold
INFO:tensorflow:Skipping quant after WeightSharedConvolutionalBoxPredictor_2/ClassPredictionTower/conv2d_2/add_fold
I0410 12:39:22.133402 140155277027136 quantize.py:299] Skipping quant after WeightSharedConvolutionalBoxPredictor_2/ClassPredictionTower/conv2d_2/add_fold
INFO:tensorflow:Skipping quant after WeightSharedConvolutionalBoxPredictor_2/ClassPredictionTower/conv2d_3/add_fold
I0410 12:39:22.133538 140155277027136 quantize.py:299] Skipping quant after WeightSharedConvolutionalBoxPredictor_2/ClassPredictionTower/conv2d_3/add_fold
INFO:tensorflow:Skipping quant after WeightSharedConvolutionalBoxPredictor_3/BoxPredictionTower/conv2d_0/add_fold
I0410 12:39:22.133684 140155277027136 quantize.py:299] Skipping quant after WeightSharedConvolutionalBoxPredictor_3/BoxPredictionTower/conv2d_0/add_fold
INFO:tensorflow:Skipping quant after WeightSharedConvolutionalBoxPredictor_3/BoxPredictionTower/conv2d_1/add_fold
I0410 12:39:22.133875 140155277027136 quantize.py:299] Skipping quant after WeightSharedConvolutionalBoxPredictor_3/BoxPredictionTower/conv2d_1/add_fold
INFO:tensorflow:Skipping quant after WeightSharedConvolutionalBoxPredictor_3/BoxPredictionTower/conv2d_2/add_fold
I0410 12:39:22.134034 140155277027136 quantize.py:299] Skipping quant after WeightSharedConvolutionalBoxPredictor_3/BoxPredictionTower/conv2d_2/add_fold
INFO:tensorflow:Skipping quant after WeightSharedConvolutionalBoxPredictor_3/BoxPredictionTower/conv2d_3/add_fold
I0410 12:39:22.134214 140155277027136 quantize.py:299] Skipping quant after WeightSharedConvolutionalBoxPredictor_3/BoxPredictionTower/conv2d_3/add_fold
INFO:tensorflow:Skipping quant after WeightSharedConvolutionalBoxPredictor_3/ClassPredictionTower/conv2d_0/add_fold
I0410 12:39:22.134354 140155277027136 quantize.py:299] Skipping quant after WeightSharedConvolutionalBoxPredictor_3/ClassPredictionTower/conv2d_0/add_fold
INFO:tensorflow:Skipping quant after WeightSharedConvolutionalBoxPredictor_3/ClassPredictionTower/conv2d_1/add_fold
I0410 12:39:22.134491 140155277027136 quantize.py:299] Skipping quant after WeightSharedConvolutionalBoxPredictor_3/ClassPredictionTower/conv2d_1/add_fold
INFO:tensorflow:Skipping quant after WeightSharedConvolutionalBoxPredictor_3/ClassPredictionTower/conv2d_2/add_fold
I0410 12:39:22.134625 140155277027136 quantize.py:299] Skipping quant after WeightSharedConvolutionalBoxPredictor_3/ClassPredictionTower/conv2d_2/add_fold
INFO:tensorflow:Skipping quant after WeightSharedConvolutionalBoxPredictor_3/ClassPredictionTower/conv2d_3/add_fold
I0410 12:39:22.134763 140155277027136 quantize.py:299] Skipping quant after WeightSharedConvolutionalBoxPredictor_3/ClassPredictionTower/conv2d_3/add_fold
INFO:tensorflow:Skipping quant after WeightSharedConvolutionalBoxPredictor_4/BoxPredictionTower/conv2d_0/add_fold
I0410 12:39:22.134897 140155277027136 quantize.py:299] Skipping quant after WeightSharedConvolutionalBoxPredictor_4/BoxPredictionTower/conv2d_0/add_fold
INFO:tensorflow:Skipping quant after WeightSharedConvolutionalBoxPredictor_4/BoxPredictionTower/conv2d_1/add_fold
I0410 12:39:22.135031 140155277027136 quantize.py:299] Skipping quant after WeightSharedConvolutionalBoxPredictor_4/BoxPredictionTower/conv2d_1/add_fold
INFO:tensorflow:Skipping quant after WeightSharedConvolutionalBoxPredictor_4/BoxPredictionTower/conv2d_2/add_fold
I0410 12:39:22.135166 140155277027136 quantize.py:299] Skipping quant after WeightSharedConvolutionalBoxPredictor_4/BoxPredictionTower/conv2d_2/add_fold
INFO:tensorflow:Skipping quant after WeightSharedConvolutionalBoxPredictor_4/BoxPredictionTower/conv2d_3/add_fold
I0410 12:39:22.135301 140155277027136 quantize.py:299] Skipping quant after WeightSharedConvolutionalBoxPredictor_4/BoxPredictionTower/conv2d_3/add_fold
INFO:tensorflow:Skipping quant after WeightSharedConvolutionalBoxPredictor_4/ClassPredictionTower/conv2d_0/add_fold
I0410 12:39:22.135435 140155277027136 quantize.py:299] Skipping quant after WeightSharedConvolutionalBoxPredictor_4/ClassPredictionTower/conv2d_0/add_fold
INFO:tensorflow:Skipping quant after WeightSharedConvolutionalBoxPredictor_4/ClassPredictionTower/conv2d_1/add_fold
I0410 12:39:22.135572 140155277027136 quantize.py:299] Skipping quant after WeightSharedConvolutionalBoxPredictor_4/ClassPredictionTower/conv2d_1/add_fold
INFO:tensorflow:Skipping quant after WeightSharedConvolutionalBoxPredictor_4/ClassPredictionTower/conv2d_2/add_fold
I0410 12:39:22.135709 140155277027136 quantize.py:299] Skipping quant after WeightSharedConvolutionalBoxPredictor_4/ClassPredictionTower/conv2d_2/add_fold
INFO:tensorflow:Skipping quant after WeightSharedConvolutionalBoxPredictor_4/ClassPredictionTower/conv2d_3/add_fold
I0410 12:39:22.135844 140155277027136 quantize.py:299] Skipping quant after WeightSharedConvolutionalBoxPredictor_4/ClassPredictionTower/conv2d_3/add_fold
WARNING:tensorflow:From /tensorflow/models/research/object_detection/export_tflite_ssd_graph_lib.py:292: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

W0410 12:39:22.138879 140155277027136 module_wrapper.py:139] From /tensorflow/models/research/object_detection/export_tflite_ssd_graph_lib.py:292: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to check for files with this prefix.
W0410 12:39:22.693765 140155277027136 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to check for files with this prefix.
2020-04-10 12:39:23.471555: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 12:39:23.471913: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: 
name: GeForce GTX 1050 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.62
pciBusID: 0000:01:00.0
2020-04-10 12:39:23.471967: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2020-04-10 12:39:23.471993: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2020-04-10 12:39:23.472027: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2020-04-10 12:39:23.472041: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2020-04-10 12:39:23.472053: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2020-04-10 12:39:23.472066: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2020-04-10 12:39:23.472083: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-04-10 12:39:23.472137: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 12:39:23.472323: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 12:39:23.472471: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0
2020-04-10 12:39:23.472493: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-04-10 12:39:23.472501: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 
2020-04-10 12:39:23.472508: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N 
2020-04-10 12:39:23.472571: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 12:39:23.472756: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 12:39:23.472915: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 2888 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
INFO:tensorflow:Restoring parameters from /tensorflow/learn_pet/train/model.ckpt-5
I0410 12:39:23.473652 140155277027136 saver.py:1284] Restoring parameters from /tensorflow/learn_pet/train/model.ckpt-5
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.graph_util.convert_variables_to_constants`
W0410 12:39:25.057172 140155277027136 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.graph_util.convert_variables_to_constants`
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.graph_util.extract_sub_graph`
W0410 12:39:25.057349 140155277027136 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.graph_util.extract_sub_graph`
INFO:tensorflow:Froze 923 variables.
I0410 12:39:25.800305 140155277027136 graph_util_impl.py:334] Froze 923 variables.
INFO:tensorflow:Converted 923 variables to const ops.
I0410 12:39:25.936274 140155277027136 graph_util_impl.py:394] Converted 923 variables to const ops.
2020-04-10 12:39:26.212524: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes
root@d97ce87cb12f:/tensorflow/models/research# 

```

**Now up until here everything goes relatively fine. However, converting this frozen graph or the resulting saved_model.pb from retraining causes issues.**

### Method 1: converting a frozen using TFLite Converter (typically following the tutorial)
```
tflite_convert  --output_file=""/tensorflow/models/research/learn_pet/models/output_tflite_graph.tflite""   --graph_def_file=""/tensorflow/models/research/learn_pet/models/tflite_graph.pb""   --inference_type=QUANTIZED_UINT8  --input_arrays='normalized_input_image_tensor'   --output_arrays=""TFLite_Detection_PostProcess,TFLite_Detection_PostProcess:1,TFLite_Detection_PostProcess:2,TFLite_Detection_PostProcess:3"" --mean_values=128 --std_dev_values=128 --input_shapes=1,320,320,3  --change_concat_input_ranges=false --allow_nudging_weights_to_use_fast_gemm_kernel=true --allow_custom_ops
```

**I get this output message:**

```
root@fe9c39ea1f8e:/tensorflow/models/research# tflite_convert  --output_file=""/tensorflow/models/research/learn_pet/models/output_tflite_graph.tflite""   --graph_def_file=""/tensorflow/models/research/learn_pet/models/tflite_graph.pb""   --inference_type=QUANTIZED_UINT8  --input_arrays='normalized_input_image_tensor'   --output_arrays=""TFLite_Detection_PostProcess,TFLite_Detection_PostProcess:1,TFLite_Detection_PostProcess:2,TFLite_Detection_PostProcess:3"" --mean_values=128 --std_dev_values=128 --input_shapes=1,320,320,3 \--change_concat_input_ranges=false --allow_nudging_weights_to_use_fast_gemm_kernel=true --allow_custom_ops        
2020-04-10 11:05:40.265936: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-04-10 11:05:40.330137: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 11:05:40.330537: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: GeForce GTX 1050 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.62
pciBusID: 0000:01:00.0
totalMemory: 3.95GiB freeMemory: 3.11GiB
2020-04-10 11:05:40.330577: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2020-04-10 11:05:40.571784: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-04-10 11:05:40.571846: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2020-04-10 11:05:40.571855: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2020-04-10 11:05:40.571999: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 2822 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
Traceback (most recent call last):
  File ""/usr/local/bin/tflite_convert"", line 11, in <module>
    sys.exit(main())
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/lite/python/tflite_convert.py"", line 412, in main
    app.run(main=run_main, argv=sys.argv[:1])
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 125, in run
    _sys.exit(main(argv))
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/lite/python/tflite_convert.py"", line 408, in run_main
    _convert_model(tflite_flags)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/lite/python/tflite_convert.py"", line 162, in _convert_model
    output_data = converter.convert()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/lite/python/lite.py"", line 464, in convert
    **converter_kwargs)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/lite/python/convert.py"", line 311, in toco_convert_graph_def
    input_data.SerializeToString())
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/lite/python/convert.py"", line 135, in toco_convert_protos
    (stdout, stderr))
RuntimeError: TOCO failed see console for info.
2020-04-10 11:05:43.184443: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1080] Converting unsupported operation: TFLite_Detection_PostProcess
2020-04-10 11:05:43.418899: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 1987 operators, 2964 arrays (0 quantized)
2020-04-10 11:05:43.488337: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 1987 operators, 2964 arrays (0 quantized)
2020-04-10 11:05:46.741187: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 360 operators, 642 arrays (1 quantized)
2020-04-10 11:05:46.750968: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before pre-quantization graph transformations: 360 operators, 642 arrays (1 quantized)
2020-04-10 11:05:46.755164: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After pre-quantization graph transformations pass 1: 234 operators, 516 arrays (1 quantized)
2020-04-10 11:05:46.758687: F tensorflow/contrib/lite/toco/tooling_util.cc:1634] Array FeatureExtractor/resnet_v1_50/fpn/top_down/nearest_neighbor_upsampling/mul, which is an input to the Reshape operator producing the output array FeatureExtractor/resnet_v1_50/fpn/top_down/nearest_neighbor_upsampling/Reshape_1, is lacking min/max data, which is necessary for quantization. If accuracy matters, either target a non-quantized output format, or run quantized training with your model from a floating point checkpoint to change the input graph to contain min/max information. If you don't care about accuracy, you can pass --default_ranges_min= and --default_ranges_max= for easy experimentation.
Aborted

None
root@fe9c39ea1f8e:/tensorflow/models/research#
```


**So I try adding  --default_ranges_min=0 and --default_ranges_max=6 following a Relu6 similar issue and it works, but fails at the edgetpu_compiler with:**
**Code used:**
```
afayed@metecs-0497:~/coral/detection_ag/models$ sudo edgetpu_compiler output_tflite_graph.tflite
Edge TPU Compiler version 2.1.302470888 
ERROR: :79 input->params.zero_point != output->params.zero_point (107 != 0)
ERROR: Node number 77 (PACK) failed to prepare.

Internal compiler error. Aborting!
afayed@metecs-0497:~/coral/detection_ag/models$
```

**Trying to convert the saved_model.pb route becomes a lot more interesting! This file gets generated after retraining in dir:**
`/tensorflow/models/research/learn_pet/train/export/Servo/1586490086/saved_model.pb`

**There are a few scripts I have found and stitched together. I will paste them each with their respective output: (The following is being run outside the docker container on my tf-nightly 2.2.0.dev20200401 pip install)**

### Method 2 try 1: (converting a saved_model.pb using TFLite Converter)
```
import tensorflow as tf
converter = tf.lite.TFLiteConverter.from_saved_model('/home/afayed/coral/detection_ag/train/export/Servo/1586490086/')
converter.experimental_new_converter = **True or False**
converter.optimizations = [tf.lite.Optimize.DEFAULT]
converter.target_spec.supported_types = [tf.float16]
tflite_quant_model = converter.convert()
```
*I know the above used tf.float16 I was trying to get something... anything out of the converter. I might try GPU inference and drop the Coral USB Accelerator at this point with all this hassle or if its not even possible to use these more powerful models.*

**Output:**

```
afayed@metecs-0497:~$ python3 ~/Desktop/test.py 
2020-04-10 04:52:09.463558: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-9.0/lib64:/home/afayed/torch/install/lib:/home/afayed/kinova-demo/devel/lib:/opt/ros/kinetic/lib::/usr/local/lib:/usr/lib:/usr/aarch64-linux-gnu/lib
2020-04-10 04:52:09.463687: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-9.0/lib64:/home/afayed/torch/install/lib:/home/afayed/kinova-demo/devel/lib:/opt/ros/kinetic/lib::/usr/local/lib:/usr/lib:/usr/aarch64-linux-gnu/lib
2020-04-10 04:52:09.463710: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2020-04-10 04:52:11.015862: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-04-10 04:52:11.033075: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:52:11.033430: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce GTX 1050 Ti computeCapability: 6.1
coreClock: 1.62GHz coreCount: 6 deviceMemorySize: 3.95GiB deviceMemoryBandwidth: 104.43GiB/s
2020-04-10 04:52:11.033684: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-04-10 04:52:11.035302: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-04-10 04:52:11.036590: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-04-10 04:52:11.036867: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-04-10 04:52:11.038115: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-04-10 04:52:11.038672: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-04-10 04:52:11.040090: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-04-10 04:52:11.040214: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:52:11.040514: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:52:11.040744: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-04-10 04:52:11.041008: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-04-10 04:52:11.065286: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2808000000 Hz
2020-04-10 04:52:11.065997: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0xaf50e40 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-04-10 04:52:11.066016: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-04-10 04:52:11.105688: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:52:11.106075: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0xaf740d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-04-10 04:52:11.106093: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce GTX 1050 Ti, Compute Capability 6.1
2020-04-10 04:52:11.106271: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:52:11.106524: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce GTX 1050 Ti computeCapability: 6.1
coreClock: 1.62GHz coreCount: 6 deviceMemorySize: 3.95GiB deviceMemoryBandwidth: 104.43GiB/s
2020-04-10 04:52:11.106575: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-04-10 04:52:11.106590: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-04-10 04:52:11.106604: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-04-10 04:52:11.106618: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-04-10 04:52:11.106632: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-04-10 04:52:11.106646: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-04-10 04:52:11.106659: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-04-10 04:52:11.106705: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:52:11.107028: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:52:11.107216: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-04-10 04:52:11.107242: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-04-10 04:52:11.107840: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-04-10 04:52:11.107853: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 
2020-04-10 04:52:11.107862: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N 
2020-04-10 04:52:11.107946: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:52:11.108196: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:52:11.108428: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 2889 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
WARNING: Logging before flag parsing goes to stderr.
W0410 04:52:11.142004 139754160563968 wrap_function.py:214] Unable to create a python object for variable <tf.Variable 'global_step:0' shape=() dtype=int64_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:52:11.142286 139754160563968 wrap_function.py:214] Unable to create a python object for variable <tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/weights:0' shape=(7, 7, 3, 64) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:52:11.142424 139754160563968 wrap_function.py:214] Unable to create a python object for variable <tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/gamma:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:52:11.142553 139754160563968 wrap_function.py:214] Unable to create a python object for variable <tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/beta:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:52:11.142632 139754160563968 wrap_function.py:214] Unable to create a python object for variable <tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/moving_mean:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:52:11.659588 139754160563968 wrap_function.py:214] Unable to create a python object for variable <tf.Variable 'global_step:0' shape=() dtype=int64_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:52:11.659760 139754160563968 wrap_function.py:214] Unable to create a python object for variable <tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/weights:0' shape=(7, 7, 3, 64) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:52:11.659844 139754160563968 wrap_function.py:214] Unable to create a python object for variable <tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/gamma:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:52:11.659930 139754160563968 wrap_function.py:214] Unable to create a python object for variable <tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/beta:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:52:11.660046 139754160563968 wrap_function.py:214] Unable to create a python object for variable <tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/moving_mean:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:52:12.539669 139754160563968 wrap_function.py:214] Unable to create a python object for variable <tf.Variable 'global_step:0' shape=() dtype=int64_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:52:12.539836 139754160563968 wrap_function.py:214] Unable to create a python object for variable <tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/weights:0' shape=(7, 7, 3, 64) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:52:12.539940 139754160563968 wrap_function.py:214] Unable to create a python object for variable <tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/gamma:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:52:12.540039 139754160563968 wrap_function.py:214] Unable to create a python object for variable <tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/beta:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:52:12.540147 139754160563968 wrap_function.py:214] Unable to create a python object for variable <tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/moving_mean:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:52:13.977087 139754160563968 wrap_function.py:214] Unable to create a python object for variable <tf.Variable 'global_step:0' shape=() dtype=int64_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:52:13.977231 139754160563968 wrap_function.py:214] Unable to create a python object for variable <tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/weights:0' shape=(7, 7, 3, 64) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:52:13.977302 139754160563968 wrap_function.py:214] Unable to create a python object for variable <tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/gamma:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:52:13.977363 139754160563968 wrap_function.py:214] Unable to create a python object for variable <tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/beta:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:52:13.977421 139754160563968 wrap_function.py:214] Unable to create a python object for variable <tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/moving_mean:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
Traceback (most recent call last):
  File ""/home/afayed/Desktop/test.py"", line 6, in <module>
    tflite_quant_model = converter.convert()
  File ""/home/afayed/.local/lib/python3.5/site-packages/tensorflow_core/lite/python/lite.py"", line 418, in convert
    raise ValueError(""This converter can only convert a single ""
ValueError: This converter can only convert a single ConcreteFunction. Converting multiple functions is under development.
afayed@metecs-0497:~$ 
```
### Method 2 try 2:
**Here I try the 'tf.lite.OpsSet.TFLITE_BUILTINS' and  'tf.lite.OpsSet.SELECT_TF_OPS'**
```
import tensorflow as tf
saved_model_obj = tf.saved_model.load(export_dir='/home/afayed/coral/detection_ag/train/export/Servo/1586490086/')
concrete_func = saved_model_obj.signatures['serving_default']
concrete_func.inputs[0].set_shape([1,320,320,3])
converter =  tf.lite.TFLiteConverter.from_concrete_functions([concrete_func])
converter.experimental_new_converter = True
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS,
                                       tf.lite.OpsSet.SELECT_TF_OPS]
converter.optimizations =  [tf.lite.Optimize.DEFAULT]
tflite_model = converter.convert()
```

**Output:**
```
afayed@metecs-0497:~$ python3 ~/Desktop/test.py 
2020-04-10 04:54:40.829681: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-9.0/lib64:/home/afayed/torch/install/lib:/home/afayed/kinova-demo/devel/lib:/opt/ros/kinetic/lib::/usr/local/lib:/usr/lib:/usr/aarch64-linux-gnu/lib
2020-04-10 04:54:40.829826: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-9.0/lib64:/home/afayed/torch/install/lib:/home/afayed/kinova-demo/devel/lib:/opt/ros/kinetic/lib::/usr/local/lib:/usr/lib:/usr/aarch64-linux-gnu/lib
2020-04-10 04:54:40.829836: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2020-04-10 04:54:42.415761: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-04-10 04:54:42.433531: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:54:42.433764: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce GTX 1050 Ti computeCapability: 6.1
coreClock: 1.62GHz coreCount: 6 deviceMemorySize: 3.95GiB deviceMemoryBandwidth: 104.43GiB/s
2020-04-10 04:54:42.433970: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-04-10 04:54:42.435321: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-04-10 04:54:42.436558: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-04-10 04:54:42.436804: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-04-10 04:54:42.438298: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-04-10 04:54:42.438873: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-04-10 04:54:42.440300: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-04-10 04:54:42.440422: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:54:42.440706: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:54:42.440901: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-04-10 04:54:42.441211: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-04-10 04:54:42.465540: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2808000000 Hz
2020-04-10 04:54:42.466703: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0xb492f10 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-04-10 04:54:42.466747: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-04-10 04:54:42.513942: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:54:42.514292: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0xb4b61a0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-04-10 04:54:42.514310: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce GTX 1050 Ti, Compute Capability 6.1
2020-04-10 04:54:42.514512: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:54:42.514784: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce GTX 1050 Ti computeCapability: 6.1
coreClock: 1.62GHz coreCount: 6 deviceMemorySize: 3.95GiB deviceMemoryBandwidth: 104.43GiB/s
2020-04-10 04:54:42.514855: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-04-10 04:54:42.514901: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-04-10 04:54:42.514913: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-04-10 04:54:42.514940: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-04-10 04:54:42.514950: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-04-10 04:54:42.514960: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-04-10 04:54:42.514990: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-04-10 04:54:42.515094: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:54:42.515367: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:54:42.515614: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-04-10 04:54:42.515671: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-04-10 04:54:42.516305: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-04-10 04:54:42.516329: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 
2020-04-10 04:54:42.516336: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N 
2020-04-10 04:54:42.516450: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:54:42.516728: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:54:42.516989: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 2889 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
WARNING: Logging before flag parsing goes to stderr.
W0410 04:54:42.553511 139909104785152 wrap_function.py:214] Unable to create a python object for variable <tf.Variable 'global_step:0' shape=() dtype=int64_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:54:42.553783 139909104785152 wrap_function.py:214] Unable to create a python object for variable <tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/weights:0' shape=(7, 7, 3, 64) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:54:42.553906 139909104785152 wrap_function.py:214] Unable to create a python object for variable <tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/gamma:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:54:42.554021 139909104785152 wrap_function.py:214] Unable to create a python object for variable <tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/beta:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:54:42.554129 139909104785152 wrap_function.py:214] Unable to create a python object for variable <tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/moving_mean:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:54:43.084858 139909104785152 wrap_function.py:214] Unable to create a python object for variable <tf.Variable 'global_step:0' shape=() dtype=int64_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:54:43.085023 139909104785152 wrap_function.py:214] Unable to create a python object for variable <tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/weights:0' shape=(7, 7, 3, 64) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:54:43.085146 139909104785152 wrap_function.py:214] Unable to create a python object for variable <tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/gamma:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:54:43.085255 139909104785152 wrap_function.py:214] Unable to create a python object for variable <tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/beta:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:54:43.085352 139909104785152 wrap_function.py:214] Unable to create a python object for variable <tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/moving_mean:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:54:44.004590 139909104785152 wrap_function.py:214] Unable to create a python object for variable <tf.Variable 'global_step:0' shape=() dtype=int64_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:54:44.004742 139909104785152 wrap_function.py:214] Unable to create a python object for variable <tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/weights:0' shape=(7, 7, 3, 64) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:54:44.004844 139909104785152 wrap_function.py:214] Unable to create a python object for variable <tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/gamma:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:54:44.004932 139909104785152 wrap_function.py:214] Unable to create a python object for variable <tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/beta:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:54:44.004984 139909104785152 wrap_function.py:214] Unable to create a python object for variable <tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/moving_mean:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:54:45.414238 139909104785152 wrap_function.py:214] Unable to create a python object for variable <tf.Variable 'global_step:0' shape=() dtype=int64_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:54:45.414433 139909104785152 wrap_function.py:214] Unable to create a python object for variable <tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/weights:0' shape=(7, 7, 3, 64) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:54:45.414536 139909104785152 wrap_function.py:214] Unable to create a python object for variable <tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/gamma:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:54:45.414678 139909104785152 wrap_function.py:214] Unable to create a python object for variable <tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/beta:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:54:45.414774 139909104785152 wrap_function.py:214] Unable to create a python object for variable <tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/moving_mean:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
Traceback (most recent call last):
  File ""/home/afayed/.local/lib/python3.5/site-packages/tensorflow_core/python/framework/ops.py"", line 634, in set_shape
    unknown_shape)
tensorflow.python.framework.errors_impl.InvalidArgumentError: Shapes must be equal rank, but are 0 and 4

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/home/afayed/Desktop/test.py"", line 4, in <module>
    concrete_func.inputs[0].set_shape([1,320,320,3])
  File ""/home/afayed/.local/lib/python3.5/site-packages/tensorflow_core/python/framework/ops.py"", line 637, in set_shape
    raise ValueError(str(e))
ValueError: Shapes must be equal rank, but are 0 and 4
afayed@metecs-0497:~$ 
```
### Method 2 try 3 fixing set_shape() to an empty array:
```
import tensorflow as tf
physical_devices = tf.config.list_physical_devices('GPU')
tf.config.set_logical_device_configuration(physical_devices[0],[tf.config.LogicalDeviceConfiguration(memory_limit=500)])
logical_devices = tf.config.list_logical_devices('GPU')

saved_model_obj = tf.saved_model.load(export_dir='/home/afayed/coral/detection_ag/train/export/Servo/1586490086/')
concrete_func = saved_model_obj.signatures['serving_default']
concrete_func.inputs[0].set_shape([])
converter =  tf.lite.TFLiteConverter.from_concrete_functions([concrete_func])
converter.experimental_new_converter = True
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS,
                                       tf.lite.OpsSet.SELECT_TF_OPS]
converter.optimizations =  [tf.lite.Optimize.DEFAULT]
tflite_model = converter.convert()
```
*Output:*
```
afayed@metecs-0497:~$ python3 ~/Desktop/test.py 
2020-04-10 04:56:49.944995: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-9.0/lib64:/home/afayed/torch/install/lib:/home/afayed/kinova-demo/devel/lib:/opt/ros/kinetic/lib::/usr/local/lib:/usr/lib:/usr/aarch64-linux-gnu/lib
2020-04-10 04:56:49.945132: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-9.0/lib64:/home/afayed/torch/install/lib:/home/afayed/kinova-demo/devel/lib:/opt/ros/kinetic/lib::/usr/local/lib:/usr/lib:/usr/aarch64-linux-gnu/lib
2020-04-10 04:56:49.945157: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2020-04-10 04:56:50.596387: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-04-10 04:56:50.613734: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:56:50.613967: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce GTX 1050 Ti computeCapability: 6.1
coreClock: 1.62GHz coreCount: 6 deviceMemorySize: 3.95GiB deviceMemoryBandwidth: 104.43GiB/s
2020-04-10 04:56:50.614179: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-04-10 04:56:50.615449: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-04-10 04:56:50.616734: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-04-10 04:56:50.617019: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-04-10 04:56:50.618337: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-04-10 04:56:50.619126: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-04-10 04:56:50.620796: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-04-10 04:56:50.620927: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:56:50.621282: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:56:50.621526: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-04-10 04:56:50.621866: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-04-10 04:56:50.645443: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2808000000 Hz
2020-04-10 04:56:50.646094: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x6ca8e80 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-04-10 04:56:50.646140: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-04-10 04:56:50.686690: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:56:50.687029: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x6ccc110 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-04-10 04:56:50.687046: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce GTX 1050 Ti, Compute Capability 6.1
2020-04-10 04:56:50.687214: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:56:50.687461: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce GTX 1050 Ti computeCapability: 6.1
coreClock: 1.62GHz coreCount: 6 deviceMemorySize: 3.95GiB deviceMemoryBandwidth: 104.43GiB/s
2020-04-10 04:56:50.687508: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-04-10 04:56:50.687520: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-04-10 04:56:50.687531: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-04-10 04:56:50.687541: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-04-10 04:56:50.687551: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-04-10 04:56:50.687561: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-04-10 04:56:50.687571: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-04-10 04:56:50.687658: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:56:50.687918: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:56:50.688156: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-04-10 04:56:50.688198: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-04-10 04:56:50.688912: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-04-10 04:56:50.688923: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 
2020-04-10 04:56:50.688947: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N 
2020-04-10 04:56:50.689028: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:56:50.689310: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:56:50.689592: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 500 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
WARNING: Logging before flag parsing goes to stderr.
W0410 04:56:51.706341 139958945724160 wrap_function.py:214] Unable to create a python object for variable <tf.Variable 'global_step:0' shape=() dtype=int64_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:56:51.706622 139958945724160 wrap_function.py:214] Unable to create a python object for variable <tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/weights:0' shape=(7, 7, 3, 64) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:56:51.706747 139958945724160 wrap_function.py:214] Unable to create a python object for variable <tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/gamma:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:56:51.706877 139958945724160 wrap_function.py:214] Unable to create a python object for variable <tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/beta:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:56:51.707004 139958945724160 wrap_function.py:214] Unable to create a python object for variable <tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/moving_mean:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:56:52.241864 139958945724160 wrap_function.py:214] Unable to create a python object for variable <tf.Variable 'global_step:0' shape=() dtype=int64_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:56:52.242060 139958945724160 wrap_function.py:214] Unable to create a python object for variable <tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/weights:0' shape=(7, 7, 3, 64) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:56:52.242195 139958945724160 wrap_function.py:214] Unable to create a python object for variable <tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/gamma:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:56:52.242302 139958945724160 wrap_function.py:214] Unable to create a python object for variable <tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/beta:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:56:52.242417 139958945724160 wrap_function.py:214] Unable to create a python object for variable <tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/moving_mean:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:56:53.198438 139958945724160 wrap_function.py:214] Unable to create a python object for variable <tf.Variable 'global_step:0' shape=() dtype=int64_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:56:53.198575 139958945724160 wrap_function.py:214] Unable to create a python object for variable <tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/weights:0' shape=(7, 7, 3, 64) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:56:53.198707 139958945724160 wrap_function.py:214] Unable to create a python object for variable <tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/gamma:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:56:53.198782 139958945724160 wrap_function.py:214] Unable to create a python object for variable <tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/beta:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:56:53.198846 139958945724160 wrap_function.py:214] Unable to create a python object for variable <tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/moving_mean:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:56:54.791184 139958945724160 wrap_function.py:214] Unable to create a python object for variable <tf.Variable 'global_step:0' shape=() dtype=int64_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:56:54.791393 139958945724160 wrap_function.py:214] Unable to create a python object for variable <tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/weights:0' shape=(7, 7, 3, 64) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:56:54.791527 139958945724160 wrap_function.py:214] Unable to create a python object for variable <tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/gamma:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:56:54.791616 139958945724160 wrap_function.py:214] Unable to create a python object for variable <tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/beta:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:56:54.791716 139958945724160 wrap_function.py:214] Unable to create a python object for variable <tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/moving_mean:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
2020-04-10 04:56:56.510059: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:56:56.510283: I tensorflow/core/grappler/devices.cc:55] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0
2020-04-10 04:56:56.510477: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session
2020-04-10 04:56:56.510978: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:56:56.511179: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce GTX 1050 Ti computeCapability: 6.1
coreClock: 1.62GHz coreCount: 6 deviceMemorySize: 3.95GiB deviceMemoryBandwidth: 104.43GiB/s
2020-04-10 04:56:56.511212: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-04-10 04:56:56.511225: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-04-10 04:56:56.511237: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-04-10 04:56:56.511248: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-04-10 04:56:56.511259: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-04-10 04:56:56.511269: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-04-10 04:56:56.511281: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-04-10 04:56:56.511320: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:56:56.511527: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:56:56.511755: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-04-10 04:56:56.511774: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-04-10 04:56:56.511780: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 
2020-04-10 04:56:56.511784: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N 
2020-04-10 04:56:56.511879: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:56:56.512118: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:56:56.512332: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 500 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
2020-04-10 04:56:56.562991: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: graph_to_optimize
2020-04-10 04:56:56.563023: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0.003ms.
2020-04-10 04:56:56.563028: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.
W0410 04:56:56.611888 139958945724160 wrap_function.py:214] Unable to create a python object for variable <tf.Variable 'global_step:0' shape=() dtype=int64_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:56:56.612050 139958945724160 wrap_function.py:214] Unable to create a python object for variable <tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/weights:0' shape=(7, 7, 3, 64) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:56:56.612152 139958945724160 wrap_function.py:214] Unable to create a python object for variable <tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/gamma:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:56:56.612239 139958945724160 wrap_function.py:214] Unable to create a python object for variable <tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/beta:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:56:56.612321 139958945724160 wrap_function.py:214] Unable to create a python object for variable <tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/moving_mean:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
2020-04-10 04:57:04.038498: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:57:04.038786: I tensorflow/core/grappler/devices.cc:55] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0
2020-04-10 04:57:04.038887: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session
2020-04-10 04:57:04.039420: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:57:04.039698: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce GTX 1050 Ti computeCapability: 6.1
coreClock: 1.62GHz coreCount: 6 deviceMemorySize: 3.95GiB deviceMemoryBandwidth: 104.43GiB/s
2020-04-10 04:57:04.039781: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-04-10 04:57:04.039814: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-04-10 04:57:04.039826: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-04-10 04:57:04.039851: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-04-10 04:57:04.039862: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-04-10 04:57:04.039872: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-04-10 04:57:04.039902: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-04-10 04:57:04.039942: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:57:04.040221: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:57:04.040421: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-04-10 04:57:04.040460: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-04-10 04:57:04.040467: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 
2020-04-10 04:57:04.040472: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N 
2020-04-10 04:57:04.040530: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:57:04.040749: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:57:04.040945: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 500 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
2020-04-10 04:57:05.077944: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: graph_to_optimize
2020-04-10 04:57:05.077966: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   constant_folding: Graph size after: 1572 nodes (-1774), 1874 edges (-1970), time = 572.089ms.
2020-04-10 04:57:05.078096: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   constant_folding: Graph size after: 1572 nodes (0), 1874 edges (0), time = 197.05ms.
Traceback (most recent call last):
  File ""/home/afayed/Desktop/test.py"", line 14, in <module>
    tflite_model = converter.convert()
  File ""/home/afayed/.local/lib/python3.5/site-packages/tensorflow_core/lite/python/lite.py"", line 464, in convert
    **converter_kwargs)
  File ""/home/afayed/.local/lib/python3.5/site-packages/tensorflow_core/lite/python/convert.py"", line 457, in toco_convert_impl
    enable_mlir_converter=enable_mlir_converter)
  File ""/home/afayed/.local/lib/python3.5/site-packages/tensorflow_core/lite/python/convert.py"", line 203, in toco_convert_protos
    raise ConverterError(""See console for info.\n%s\n%s\n"" % (stdout, stderr))
tensorflow.lite.python.convert.ConverterError: See console for info.
2020-04-10 04:57:06.359298: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-9.0/lib64:/home/afayed/torch/install/lib:/home/afayed/kinova-demo/devel/lib:/opt/ros/kinetic/lib::/usr/local/lib:/usr/lib:/usr/aarch64-linux-gnu/lib
2020-04-10 04:57:06.359375: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-9.0/lib64:/home/afayed/torch/install/lib:/home/afayed/kinova-demo/devel/lib:/opt/ros/kinetic/lib::/usr/local/lib:/usr/lib:/usr/aarch64-linux-gnu/lib
2020-04-10 04:57:06.359384: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2020-04-10 04:57:07.195543: W tensorflow/compiler/mlir/lite/python/graphdef_to_tfl_flatbuffer.cc:89] Ignored output_format.
2020-04-10 04:57:07.195587: W tensorflow/compiler/mlir/lite/python/graphdef_to_tfl_flatbuffer.cc:95] Ignored drop_control_dependency.
2020-04-10 04:57:07.626685: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-04-10 04:57:07.653251: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2808000000 Hz
2020-04-10 04:57:07.653736: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fd39c1ec330 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-04-10 04:57:07.653752: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-04-10 04:57:07.655781: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-04-10 04:57:07.701689: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:57:07.701992: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fd39c2d6980 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-04-10 04:57:07.702007: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce GTX 1050 Ti, Compute Capability 6.1
2020-04-10 04:57:07.702163: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:57:07.702387: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce GTX 1050 Ti computeCapability: 6.1
coreClock: 1.62GHz coreCount: 6 deviceMemorySize: 3.95GiB deviceMemoryBandwidth: 104.43GiB/s
2020-04-10 04:57:07.702674: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-04-10 04:57:07.704034: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-04-10 04:57:07.705345: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-04-10 04:57:07.705605: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-04-10 04:57:07.706943: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-04-10 04:57:07.707795: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-04-10 04:57:07.709657: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-04-10 04:57:07.709776: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:57:07.710048: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:57:07.710245: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-04-10 04:57:07.710290: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-04-10 04:57:07.710886: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-04-10 04:57:07.710895: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 
2020-04-10 04:57:07.710919: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N 
2020-04-10 04:57:07.711001: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:57:07.711232: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:57:07.711447: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 2250 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
loc(callsite(""Equal""(""/home/afayed/.local/lib/python3.5/site-packages/tensorflow_core/python/saved_model/load.py"":559:0) at callsite(""/home/afayed/.local/lib/python3.5/site-packages/tensorflow_core/python/saved_model/load.py"":528:0 at ""/home/afayed/Desktop/test.py"":6:0))): error: 'tfl.equal' op operand #0 must be tensor of 1-bit integer or 32-bit float or 32-bit integer or 64-bit integer or 8-bit integer or QI8 type or QUI8 type or TFLite uint8 type values, but got 'tensor<!tf.string>'
loc(""case/cond/is_jpeg/Equal@_functionalize_if_else_branch_5""): error: 'tfl.equal' op operand #0 must be tensor of 1-bit integer or 32-bit float or 32-bit integer or 64-bit integer or 8-bit integer or QI8 type or QUI8 type or TFLite uint8 type values, but got 'tensor<*x!tf.string>'
loc(""case/cond/cond_jpeg/decode_image/is_jpeg/Equal@_functionalize_if_else_branch_3""): error: 'tfl.equal' op operand #0 must be tensor of 1-bit integer or 32-bit float or 32-bit integer or 64-bit integer or 8-bit integer or QI8 type or QUI8 type or TFLite uint8 type values, but got 'tensor<*x!tf.string>'
loc(""case/cond/cond_jpeg/decode_image/cond_jpeg/is_png/Equal@_functionalize_if_else_branch_2""): error: 'tfl.equal' op operand #0 must be tensor of 1-bit integer or 32-bit float or 32-bit integer or 64-bit integer or 8-bit integer or QI8 type or QUI8 type or TFLite uint8 type values, but got 'tensor<*x!tf.string>'
loc(""case/cond/cond_jpeg/decode_image/cond_jpeg/cond_png/is_gif@_functionalize_if_else_branch_1""): error: 'tfl.equal' op operand #0 must be tensor of 1-bit integer or 32-bit float or 32-bit integer or 64-bit integer or 8-bit integer or QI8 type or QUI8 type or TFLite uint8 type values, but got 'tensor<*x!tf.string>'
loc(""case/cond/cond_jpeg/decode_image/cond_jpeg/cond_png/cond_gif/is_bmp@_functionalize_if_else_branch_0""): error: 'tfl.equal' op operand #0 must be tensor of 1-bit integer or 32-bit float or 32-bit integer or 64-bit integer or 8-bit integer or QI8 type or QUI8 type or TFLite uint8 type values, but got 'tensor<*x!tf.string>'
Traceback (most recent call last):
  File ""/home/afayed/.local/bin/toco_from_protos"", line 8, in <module>
    sys.exit(main())
  File ""/home/afayed/.local/lib/python3.5/site-packages/tensorflow_core/lite/toco/python/toco_from_protos.py"", line 93, in main
    app.run(main=execute, argv=[sys.argv[0]] + unparsed)
  File ""/home/afayed/.local/lib/python3.5/site-packages/tensorflow_core/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/home/afayed/.local/lib/python3.5/site-packages/absl/app.py"", line 300, in run
    _run_main(main, args)
  File ""/home/afayed/.local/lib/python3.5/site-packages/absl/app.py"", line 251, in _run_main
    sys.exit(main(argv))
  File ""/home/afayed/.local/lib/python3.5/site-packages/tensorflow_core/lite/toco/python/toco_from_protos.py"", line 56, in execute
    enable_mlir_converter)
Exception: /home/afayed/.local/lib/python3.5/site-packages/tensorflow_core/python/saved_model/load.py:559:7: error: 'tfl.equal' op operand #0 must be tensor of 1-bit integer or 32-bit float or 32-bit integer or 64-bit integer or 8-bit integer or QI8 type or QUI8 type or TFLite uint8 type values, but got 'tensor<!tf.string>'
      root = load_v1_in_v2.load(export_dir, tags)
      ^
/home/afayed/.local/lib/python3.5/site-packages/tensorflow_core/python/saved_model/load.py:528:3: note: called from
  return load_internal(export_dir, tags)
  ^
/home/afayed/Desktop/test.py:6:1: note: called from
saved_model_obj = tf.saved_model.load(export_dir='/home/afayed/coral/detection_ag/train/export/Servo/1586490086/')
^
<unknown>:0: error: loc(""case/cond/is_jpeg/Equal@_functionalize_if_else_branch_5""): 'tfl.equal' op operand #0 must be tensor of 1-bit integer or 32-bit float or 32-bit integer or 64-bit integer or 8-bit integer or QI8 type or QUI8 type or TFLite uint8 type values, but got 'tensor<*x!tf.string>'
<unknown>:0: error: loc(""case/cond/cond_jpeg/decode_image/is_jpeg/Equal@_functionalize_if_else_branch_3""): 'tfl.equal' op operand #0 must be tensor of 1-bit integer or 32-bit float or 32-bit integer or 64-bit integer or 8-bit integer or QI8 type or QUI8 type or TFLite uint8 type values, but got 'tensor<*x!tf.string>'
<unknown>:0: error: loc(""case/cond/cond_jpeg/decode_image/cond_jpeg/is_png/Equal@_functionalize_if_else_branch_2""): 'tfl.equal' op operand #0 must be tensor of 1-bit integer or 32-bit float or 32-bit integer or 64-bit integer or 8-bit integer or QI8 type or QUI8 type or TFLite uint8 type values, but got 'tensor<*x!tf.string>'
<unknown>:0: error: loc(""case/cond/cond_jpeg/decode_image/cond_jpeg/cond_png/is_gif@_functionalize_if_else_branch_1""): 'tfl.equal' op operand #0 must be tensor of 1-bit integer or 32-bit float or 32-bit integer or 64-bit integer or 8-bit integer or QI8 type or QUI8 type or TFLite uint8 type values, but got 'tensor<*x!tf.string>'
<unknown>:0: error: loc(""case/cond/cond_jpeg/decode_image/cond_jpeg/cond_png/cond_gif/is_bmp@_functionalize_if_else_branch_0""): 'tfl.equal' op operand #0 must be tensor of 1-bit integer or 32-bit float or 32-bit integer or 64-bit integer or 8-bit integer or QI8 type or QUI8 type or TFLite uint8 type values, but got 'tensor<*x!tf.string>'




afayed@metecs-0497:~$ 
```
### Method 2 try 4 with a representative dataset (Experimental Conv set to True):
```
import tensorflow as tf
BATCH_SIZE = 32
IMG_HEIGHT = 320
IMG_WIDTH = 320
physical_devices = tf.config.list_physical_devices('GPU')
tf.config.set_logical_device_configuration(physical_devices[0],[tf.config.LogicalDeviceConfiguration(memory_limit=500)])
logical_devices = tf.config.list_logical_devices('GPU')

def decode_img(img):
	img = tf.image.decode_jpeg(img, channels=3) #color images
	img = tf.image.convert_image_dtype(img, tf.float32) 
	#convert unit8 tensor to floats in the [0,1]range
	return tf.image.resize(img, [IMG_WIDTH, IMG_HEIGHT]) 

def representative_dataset_gen():
	for _ in range(num_calibration_steps):
	# Get sample input data as a numpy array in a method of your choosing.
		image = list_all.take(1)
		yield [decode_img(image)]

saved_model_obj = tf.saved_model.load(export_dir='/home/afayed/coral/detection_ag/train/export/Servo/1586490086/')
concrete_func = saved_model_obj.signatures['serving_default']
concrete_func.inputs[0].set_shape([])
converter =  tf.lite.TFLiteConverter.from_concrete_functions([concrete_func])
converter.experimental_new_converter = True
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS,
                                       tf.lite.OpsSet.SELECT_TF_OPS]
converter.optimizations =  [tf.lite.Optimize.DEFAULT]
converter.representative_dataset = representative_dataset_gen
tflite_quant_model = converter.convert()

open(""/home/afayed/Desktop/output_tflite_graph.tflite"", ""wb"").write(tflite_quant_model)
```

**Output:**
```
afayed@metecs-0497:~$ python3 ~/Desktop/test.py 
2020-04-10 04:59:25.945004: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-9.0/lib64:/home/afayed/torch/install/lib:/home/afayed/kinova-demo/devel/lib:/opt/ros/kinetic/lib::/usr/local/lib:/usr/lib:/usr/aarch64-linux-gnu/lib
2020-04-10 04:59:25.945179: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-9.0/lib64:/home/afayed/torch/install/lib:/home/afayed/kinova-demo/devel/lib:/opt/ros/kinetic/lib::/usr/local/lib:/usr/lib:/usr/aarch64-linux-gnu/lib
2020-04-10 04:59:25.945191: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2020-04-10 04:59:26.606701: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-04-10 04:59:26.624591: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:59:26.624832: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce GTX 1050 Ti computeCapability: 6.1
coreClock: 1.62GHz coreCount: 6 deviceMemorySize: 3.95GiB deviceMemoryBandwidth: 104.43GiB/s
2020-04-10 04:59:26.625073: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-04-10 04:59:26.626365: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-04-10 04:59:26.627619: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-04-10 04:59:26.627865: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-04-10 04:59:26.629198: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-04-10 04:59:26.629971: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-04-10 04:59:26.631630: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-04-10 04:59:26.631723: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:59:26.631985: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:59:26.632169: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-04-10 04:59:26.632490: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-04-10 04:59:26.657430: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2808000000 Hz
2020-04-10 04:59:26.658056: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x54cf5b0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-04-10 04:59:26.658127: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-04-10 04:59:26.698387: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:59:26.698734: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x54f2840 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-04-10 04:59:26.698751: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce GTX 1050 Ti, Compute Capability 6.1
2020-04-10 04:59:26.698947: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:59:26.699219: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce GTX 1050 Ti computeCapability: 6.1
coreClock: 1.62GHz coreCount: 6 deviceMemorySize: 3.95GiB deviceMemoryBandwidth: 104.43GiB/s
2020-04-10 04:59:26.699285: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-04-10 04:59:26.699298: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-04-10 04:59:26.699339: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-04-10 04:59:26.699362: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-04-10 04:59:26.699390: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-04-10 04:59:26.699400: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-04-10 04:59:26.699411: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-04-10 04:59:26.699463: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:59:26.699745: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:59:26.699964: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-04-10 04:59:26.700007: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-04-10 04:59:26.700625: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-04-10 04:59:26.700635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 
2020-04-10 04:59:26.700660: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N 
2020-04-10 04:59:26.700750: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:59:26.701018: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:59:26.701311: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 500 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
WARNING: Logging before flag parsing goes to stderr.
W0410 04:59:27.646008 140401577404160 wrap_function.py:214] Unable to create a python object for variable <tf.Variable 'global_step:0' shape=() dtype=int64_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:59:27.646277 140401577404160 wrap_function.py:214] Unable to create a python object for variable <tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/weights:0' shape=(7, 7, 3, 64) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:59:27.646404 140401577404160 wrap_function.py:214] Unable to create a python object for variable <tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/gamma:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:59:27.646530 140401577404160 wrap_function.py:214] Unable to create a python object for variable <tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/beta:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:59:27.646658 140401577404160 wrap_function.py:214] Unable to create a python object for variable <tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/moving_mean:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:59:28.166036 140401577404160 wrap_function.py:214] Unable to create a python object for variable <tf.Variable 'global_step:0' shape=() dtype=int64_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:59:28.166230 140401577404160 wrap_function.py:214] Unable to create a python object for variable <tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/weights:0' shape=(7, 7, 3, 64) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:59:28.166350 140401577404160 wrap_function.py:214] Unable to create a python object for variable <tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/gamma:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:59:28.166450 140401577404160 wrap_function.py:214] Unable to create a python object for variable <tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/beta:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:59:28.166565 140401577404160 wrap_function.py:214] Unable to create a python object for variable <tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/moving_mean:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:59:29.039237 140401577404160 wrap_function.py:214] Unable to create a python object for variable <tf.Variable 'global_step:0' shape=() dtype=int64_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:59:29.039395 140401577404160 wrap_function.py:214] Unable to create a python object for variable <tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/weights:0' shape=(7, 7, 3, 64) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:59:29.039500 140401577404160 wrap_function.py:214] Unable to create a python object for variable <tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/gamma:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:59:29.039588 140401577404160 wrap_function.py:214] Unable to create a python object for variable <tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/beta:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:59:29.039674 140401577404160 wrap_function.py:214] Unable to create a python object for variable <tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/moving_mean:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:59:30.453517 140401577404160 wrap_function.py:214] Unable to create a python object for variable <tf.Variable 'global_step:0' shape=() dtype=int64_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:59:30.453718 140401577404160 wrap_function.py:214] Unable to create a python object for variable <tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/weights:0' shape=(7, 7, 3, 64) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:59:30.453832 140401577404160 wrap_function.py:214] Unable to create a python object for variable <tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/gamma:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:59:30.453950 140401577404160 wrap_function.py:214] Unable to create a python object for variable <tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/beta:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:59:30.454065 140401577404160 wrap_function.py:214] Unable to create a python object for variable <tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/moving_mean:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
2020-04-10 04:59:32.095622: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:59:32.095855: I tensorflow/core/grappler/devices.cc:55] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0
2020-04-10 04:59:32.096054: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session
2020-04-10 04:59:32.096504: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:59:32.096702: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce GTX 1050 Ti computeCapability: 6.1
coreClock: 1.62GHz coreCount: 6 deviceMemorySize: 3.95GiB deviceMemoryBandwidth: 104.43GiB/s
2020-04-10 04:59:32.096732: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-04-10 04:59:32.096744: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-04-10 04:59:32.096755: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-04-10 04:59:32.096765: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-04-10 04:59:32.096774: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-04-10 04:59:32.096784: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-04-10 04:59:32.096794: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-04-10 04:59:32.096834: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:59:32.097122: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:59:32.097353: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-04-10 04:59:32.097391: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-04-10 04:59:32.097416: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 
2020-04-10 04:59:32.097422: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N 
2020-04-10 04:59:32.097561: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:59:32.097814: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:59:32.098006: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 500 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
2020-04-10 04:59:32.149381: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: graph_to_optimize
2020-04-10 04:59:32.149406: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0.003ms.
2020-04-10 04:59:32.149411: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0ms.
W0410 04:59:32.196574 140401577404160 wrap_function.py:214] Unable to create a python object for variable <tf.Variable 'global_step:0' shape=() dtype=int64_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:59:32.196784 140401577404160 wrap_function.py:214] Unable to create a python object for variable <tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/weights:0' shape=(7, 7, 3, 64) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:59:32.196887 140401577404160 wrap_function.py:214] Unable to create a python object for variable <tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/gamma:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:59:32.196958 140401577404160 wrap_function.py:214] Unable to create a python object for variable <tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/beta:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 04:59:32.197010 140401577404160 wrap_function.py:214] Unable to create a python object for variable <tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/moving_mean:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
2020-04-10 04:59:39.254102: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:59:39.254359: I tensorflow/core/grappler/devices.cc:55] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0
2020-04-10 04:59:39.254457: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session
2020-04-10 04:59:39.254974: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:59:39.255226: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce GTX 1050 Ti computeCapability: 6.1
coreClock: 1.62GHz coreCount: 6 deviceMemorySize: 3.95GiB deviceMemoryBandwidth: 104.43GiB/s
2020-04-10 04:59:39.255293: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-04-10 04:59:39.255337: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-04-10 04:59:39.255349: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-04-10 04:59:39.255372: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-04-10 04:59:39.255381: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-04-10 04:59:39.255416: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-04-10 04:59:39.255426: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-04-10 04:59:39.255477: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:59:39.255710: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:59:39.255921: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-04-10 04:59:39.255979: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-04-10 04:59:39.255986: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 
2020-04-10 04:59:39.256003: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N 
2020-04-10 04:59:39.256090: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:59:39.256326: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:59:39.256558: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 500 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
2020-04-10 04:59:40.209379: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: graph_to_optimize
2020-04-10 04:59:40.209410: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   constant_folding: Graph size after: 1572 nodes (-1774), 1874 edges (-1970), time = 522.985ms.
2020-04-10 04:59:40.209481: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   constant_folding: Graph size after: 1572 nodes (0), 1874 edges (0), time = 186.768ms.
Traceback (most recent call last):
  File ""/home/afayed/Desktop/test.py"", line 32, in <module>
    tflite_quant_model = converter.convert()
  File ""/home/afayed/.local/lib/python3.5/site-packages/tensorflow_core/lite/python/lite.py"", line 464, in convert
    **converter_kwargs)
  File ""/home/afayed/.local/lib/python3.5/site-packages/tensorflow_core/lite/python/convert.py"", line 457, in toco_convert_impl
    enable_mlir_converter=enable_mlir_converter)
  File ""/home/afayed/.local/lib/python3.5/site-packages/tensorflow_core/lite/python/convert.py"", line 203, in toco_convert_protos
    raise ConverterError(""See console for info.\n%s\n%s\n"" % (stdout, stderr))
tensorflow.lite.python.convert.ConverterError: See console for info.
2020-04-10 04:59:41.441981: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-9.0/lib64:/home/afayed/torch/install/lib:/home/afayed/kinova-demo/devel/lib:/opt/ros/kinetic/lib::/usr/local/lib:/usr/lib:/usr/aarch64-linux-gnu/lib
2020-04-10 04:59:41.442083: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-9.0/lib64:/home/afayed/torch/install/lib:/home/afayed/kinova-demo/devel/lib:/opt/ros/kinetic/lib::/usr/local/lib:/usr/lib:/usr/aarch64-linux-gnu/lib
2020-04-10 04:59:41.442091: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2020-04-10 04:59:42.242273: W tensorflow/compiler/mlir/lite/python/graphdef_to_tfl_flatbuffer.cc:89] Ignored output_format.
2020-04-10 04:59:42.242303: W tensorflow/compiler/mlir/lite/python/graphdef_to_tfl_flatbuffer.cc:95] Ignored drop_control_dependency.
2020-04-10 04:59:42.652620: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-04-10 04:59:42.677332: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2808000000 Hz
2020-04-10 04:59:42.678004: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ff2cc1ec790 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-04-10 04:59:42.678035: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-04-10 04:59:42.680364: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-04-10 04:59:42.720113: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:59:42.720401: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ff2cc2d6f80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-04-10 04:59:42.720417: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce GTX 1050 Ti, Compute Capability 6.1
2020-04-10 04:59:42.720579: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:59:42.720802: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce GTX 1050 Ti computeCapability: 6.1
coreClock: 1.62GHz coreCount: 6 deviceMemorySize: 3.95GiB deviceMemoryBandwidth: 104.43GiB/s
2020-04-10 04:59:42.721080: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-04-10 04:59:42.722453: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-04-10 04:59:42.723755: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-04-10 04:59:42.724027: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-04-10 04:59:42.725595: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-04-10 04:59:42.726508: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-04-10 04:59:42.728483: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-04-10 04:59:42.728633: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:59:42.728920: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:59:42.729150: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-04-10 04:59:42.729198: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-04-10 04:59:42.729846: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-04-10 04:59:42.729856: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 
2020-04-10 04:59:42.729881: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N 
2020-04-10 04:59:42.729971: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:59:42.730223: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 04:59:42.730515: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 2250 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
loc(callsite(""Equal""(""/home/afayed/.local/lib/python3.5/site-packages/tensorflow_core/python/saved_model/load.py"":559:0) at callsite(""/home/afayed/.local/lib/python3.5/site-packages/tensorflow_core/python/saved_model/load.py"":528:0 at ""/home/afayed/Desktop/test.py"":23:0))): error: 'tfl.equal' op operand #0 must be tensor of 1-bit integer or 32-bit float or 32-bit integer or 64-bit integer or 8-bit integer or QI8 type or QUI8 type or TFLite uint8 type values, but got 'tensor<!tf.string>'
loc(""case/cond/is_jpeg/Equal@_functionalize_if_else_branch_5""): error: 'tfl.equal' op operand #0 must be tensor of 1-bit integer or 32-bit float or 32-bit integer or 64-bit integer or 8-bit integer or QI8 type or QUI8 type or TFLite uint8 type values, but got 'tensor<*x!tf.string>'
loc(""case/cond/cond_jpeg/decode_image/is_jpeg/Equal@_functionalize_if_else_branch_3""): error: 'tfl.equal' op operand #0 must be tensor of 1-bit integer or 32-bit float or 32-bit integer or 64-bit integer or 8-bit integer or QI8 type or QUI8 type or TFLite uint8 type values, but got 'tensor<*x!tf.string>'
loc(""case/cond/cond_jpeg/decode_image/cond_jpeg/is_png/Equal@_functionalize_if_else_branch_2""): error: 'tfl.equal' op operand #0 must be tensor of 1-bit integer or 32-bit float or 32-bit integer or 64-bit integer or 8-bit integer or QI8 type or QUI8 type or TFLite uint8 type values, but got 'tensor<*x!tf.string>'
loc(""case/cond/cond_jpeg/decode_image/cond_jpeg/cond_png/is_gif@_functionalize_if_else_branch_1""): error: 'tfl.equal' op operand #0 must be tensor of 1-bit integer or 32-bit float or 32-bit integer or 64-bit integer or 8-bit integer or QI8 type or QUI8 type or TFLite uint8 type values, but got 'tensor<*x!tf.string>'
loc(""case/cond/cond_jpeg/decode_image/cond_jpeg/cond_png/cond_gif/is_bmp@_functionalize_if_else_branch_0""): error: 'tfl.equal' op operand #0 must be tensor of 1-bit integer or 32-bit float or 32-bit integer or 64-bit integer or 8-bit integer or QI8 type or QUI8 type or TFLite uint8 type values, but got 'tensor<*x!tf.string>'
Traceback (most recent call last):
  File ""/home/afayed/.local/bin/toco_from_protos"", line 8, in <module>
    sys.exit(main())
  File ""/home/afayed/.local/lib/python3.5/site-packages/tensorflow_core/lite/toco/python/toco_from_protos.py"", line 93, in main
    app.run(main=execute, argv=[sys.argv[0]] + unparsed)
  File ""/home/afayed/.local/lib/python3.5/site-packages/tensorflow_core/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/home/afayed/.local/lib/python3.5/site-packages/absl/app.py"", line 300, in run
    _run_main(main, args)
  File ""/home/afayed/.local/lib/python3.5/site-packages/absl/app.py"", line 251, in _run_main
    sys.exit(main(argv))
  File ""/home/afayed/.local/lib/python3.5/site-packages/tensorflow_core/lite/toco/python/toco_from_protos.py"", line 56, in execute
    enable_mlir_converter)
Exception: /home/afayed/.local/lib/python3.5/site-packages/tensorflow_core/python/saved_model/load.py:559:7: error: 'tfl.equal' op operand #0 must be tensor of 1-bit integer or 32-bit float or 32-bit integer or 64-bit integer or 8-bit integer or QI8 type or QUI8 type or TFLite uint8 type values, but got 'tensor<!tf.string>'
      root = load_v1_in_v2.load(export_dir, tags)
      ^
/home/afayed/.local/lib/python3.5/site-packages/tensorflow_core/python/saved_model/load.py:528:3: note: called from
  return load_internal(export_dir, tags)
  ^
/home/afayed/Desktop/test.py:23:1: note: called from
saved_model_obj = tf.saved_model.load(export_dir='/home/afayed/coral/detection_ag/train/export/Servo/1586490086/')
^
<unknown>:0: error: loc(""case/cond/is_jpeg/Equal@_functionalize_if_else_branch_5""): 'tfl.equal' op operand #0 must be tensor of 1-bit integer or 32-bit float or 32-bit integer or 64-bit integer or 8-bit integer or QI8 type or QUI8 type or TFLite uint8 type values, but got 'tensor<*x!tf.string>'
<unknown>:0: error: loc(""case/cond/cond_jpeg/decode_image/is_jpeg/Equal@_functionalize_if_else_branch_3""): 'tfl.equal' op operand #0 must be tensor of 1-bit integer or 32-bit float or 32-bit integer or 64-bit integer or 8-bit integer or QI8 type or QUI8 type or TFLite uint8 type values, but got 'tensor<*x!tf.string>'
<unknown>:0: error: loc(""case/cond/cond_jpeg/decode_image/cond_jpeg/is_png/Equal@_functionalize_if_else_branch_2""): 'tfl.equal' op operand #0 must be tensor of 1-bit integer or 32-bit float or 32-bit integer or 64-bit integer or 8-bit integer or QI8 type or QUI8 type or TFLite uint8 type values, but got 'tensor<*x!tf.string>'
<unknown>:0: error: loc(""case/cond/cond_jpeg/decode_image/cond_jpeg/cond_png/is_gif@_functionalize_if_else_branch_1""): 'tfl.equal' op operand #0 must be tensor of 1-bit integer or 32-bit float or 32-bit integer or 64-bit integer or 8-bit integer or QI8 type or QUI8 type or TFLite uint8 type values, but got 'tensor<*x!tf.string>'
<unknown>:0: error: loc(""case/cond/cond_jpeg/decode_image/cond_jpeg/cond_png/cond_gif/is_bmp@_functionalize_if_else_branch_0""): 'tfl.equal' op operand #0 must be tensor of 1-bit integer or 32-bit float or 32-bit integer or 64-bit integer or 8-bit integer or QI8 type or QUI8 type or TFLite uint8 type values, but got 'tensor<*x!tf.string>'




afayed@metecs-0497:~$ 
```
### Method 2 try 5 with a representative dataset (Experimental Conv set to False):
**And finally, this try is what headed this issue**
**Code:**
```
import tensorflow as tf

BATCH_SIZE = 32
IMG_HEIGHT = 320
IMG_WIDTH = 320
physical_devices = tf.config.list_physical_devices('GPU')
tf.config.set_logical_device_configuration(physical_devices[0],[tf.config.LogicalDeviceConfiguration(memory_limit=500)])
logical_devices = tf.config.list_logical_devices('GPU')

list_ds_Dianthus = tf.data.Dataset.list_files(str('/home/afayed/coral/detection_ag/ag/Dianthus''*/*/*'))
list_ds_DustyMiller = tf.data.Dataset.list_files(str('/home/afayed/coral/detection_ag/ag/DustyMiller''*/*/*'))
list_ds_Pansy = tf.data.Dataset.list_files(str('/home/afayed/coral/detection_ag/ag/Pansy''*/*/*'))
list_all = list_ds_Dianthus.concatenate(list_ds_DustyMiller).concatenate(list_ds_Pansy)
#len(list(list_all))

def get_label(file_path):
  parts = tf.strings.split(file_path, '/')
  class_name = tf.strings.split(parts[-3], '1')
  class_name = tf.strings.split(class_name, '2')
  class_name = tf.strings.split(class_name, '3')
  class_name = tf.strings.split(class_name, '4')
  return class_name

def decode_img(img):
	img = tf.image.decode_jpeg(img, channels=3) #color images
	img = tf.image.convert_image_dtype(img, tf.float32) 
	#convert unit8 tensor to floats in the [0,1]range
	return tf.image.resize(img, [IMG_WIDTH, IMG_HEIGHT]) 
	#resize the image into 224*224 

def process_path(file_path):
  label = get_label(file_path)
  img = tf.io.read_file(file_path)
  img = decode_img(img)
  return img, label

num_calibration_steps= 1000

def representative_dataset_gen():
	for _ in range(num_calibration_steps):
	# Get sample input data as a numpy array in a method of your choosing.
		image = list_all.take(1)
		yield [decode_img(image)]

saved_model_obj = tf.saved_model.load(export_dir='/home/afayed/coral/detection_ag/train/export/Servo/1586490086/')
concrete_func = saved_model_obj.signatures['serving_default']
concrete_func.inputs[0].set_shape([])
converter =  tf.lite.TFLiteConverter.from_concrete_functions([concrete_func])
converter.experimental_new_converter = False
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS,
                                       tf.lite.OpsSet.SELECT_TF_OPS]
converter.optimizations =  [tf.lite.Optimize.DEFAULT]
converter.representative_dataset = representative_dataset_gen
tflite_quant_model = converter.convert()

open(""/home/afayed/Desktop/output_tflite_graph.tflite"", ""wb"").write(tflite_quant_model)
```
Output:
```
afayed@metecs-0497:~$ python3 ~/Desktop/Metecs\ Work/quant_aware_training.py 
2020-04-10 06:06:04.479099: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-9.0/lib64:/home/afayed/torch/install/lib:/home/afayed/kinova-demo/devel/lib:/opt/ros/kinetic/lib::/usr/local/lib:/usr/lib:/usr/aarch64-linux-gnu/lib
2020-04-10 06:06:04.479217: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-9.0/lib64:/home/afayed/torch/install/lib:/home/afayed/kinova-demo/devel/lib:/opt/ros/kinetic/lib::/usr/local/lib:/usr/lib:/usr/aarch64-linux-gnu/lib
2020-04-10 06:06:04.479231: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2020-04-10 06:06:05.141022: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-04-10 06:06:05.159643: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 06:06:05.159956: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce GTX 1050 Ti computeCapability: 6.1
coreClock: 1.62GHz coreCount: 6 deviceMemorySize: 3.95GiB deviceMemoryBandwidth: 104.43GiB/s
2020-04-10 06:06:05.160224: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-04-10 06:06:05.161735: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-04-10 06:06:05.163092: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-04-10 06:06:05.163399: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-04-10 06:06:05.164713: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-04-10 06:06:05.165613: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-04-10 06:06:05.167462: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-04-10 06:06:05.167624: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 06:06:05.168101: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 06:06:05.168436: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-04-10 06:06:05.168831: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-04-10 06:06:05.193418: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2808000000 Hz
2020-04-10 06:06:05.194356: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x62f8550 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-04-10 06:06:05.194381: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-04-10 06:06:05.234776: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 06:06:05.235127: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x631b7e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-04-10 06:06:05.235144: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce GTX 1050 Ti, Compute Capability 6.1
2020-04-10 06:06:05.235310: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 06:06:05.235556: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce GTX 1050 Ti computeCapability: 6.1
coreClock: 1.62GHz coreCount: 6 deviceMemorySize: 3.95GiB deviceMemoryBandwidth: 104.43GiB/s
2020-04-10 06:06:05.235612: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-04-10 06:06:05.235650: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-04-10 06:06:05.235670: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-04-10 06:06:05.235706: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-04-10 06:06:05.235727: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-04-10 06:06:05.235750: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-04-10 06:06:05.235771: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-04-10 06:06:05.235826: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 06:06:05.236058: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 06:06:05.236253: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-04-10 06:06:05.236304: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-04-10 06:06:05.236934: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-04-10 06:06:05.236945: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 
2020-04-10 06:06:05.236969: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N 
2020-04-10 06:06:05.237066: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 06:06:05.237329: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 06:06:05.237577: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 500 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
WARNING: Logging before flag parsing goes to stderr.
W0410 06:06:06.524962 140508644669184 wrap_function.py:214] Unable to create a python object for variable <tf.Variable 'global_step:0' shape=() dtype=int64_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 06:06:06.525167 140508644669184 wrap_function.py:214] Unable to create a python object for variable <tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/weights:0' shape=(7, 7, 3, 64) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 06:06:06.525248 140508644669184 wrap_function.py:214] Unable to create a python object for variable <tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/gamma:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 06:06:06.525318 140508644669184 wrap_function.py:214] Unable to create a python object for variable <tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/beta:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 06:06:06.525382 140508644669184 wrap_function.py:214] Unable to create a python object for variable <tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/moving_mean:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 06:06:07.102755 140508644669184 wrap_function.py:214] Unable to create a python object for variable <tf.Variable 'global_step:0' shape=() dtype=int64_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 06:06:07.102902 140508644669184 wrap_function.py:214] Unable to create a python object for variable <tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/weights:0' shape=(7, 7, 3, 64) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 06:06:07.102976 140508644669184 wrap_function.py:214] Unable to create a python object for variable <tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/gamma:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 06:06:07.103037 140508644669184 wrap_function.py:214] Unable to create a python object for variable <tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/beta:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 06:06:07.103093 140508644669184 wrap_function.py:214] Unable to create a python object for variable <tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/moving_mean:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 06:06:07.689994 140508644669184 wrap_function.py:214] Unable to create a python object for variable <tf.Variable 'global_step:0' shape=() dtype=int64_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 06:06:07.690133 140508644669184 wrap_function.py:214] Unable to create a python object for variable <tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/weights:0' shape=(7, 7, 3, 64) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 06:06:07.690204 140508644669184 wrap_function.py:214] Unable to create a python object for variable <tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/gamma:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 06:06:07.690261 140508644669184 wrap_function.py:214] Unable to create a python object for variable <tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/beta:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 06:06:07.690316 140508644669184 wrap_function.py:214] Unable to create a python object for variable <tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/moving_mean:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 06:06:09.211912 140508644669184 wrap_function.py:214] Unable to create a python object for variable <tf.Variable 'global_step:0' shape=() dtype=int64_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 06:06:09.212095 140508644669184 wrap_function.py:214] Unable to create a python object for variable <tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/weights:0' shape=(7, 7, 3, 64) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 06:06:09.212220 140508644669184 wrap_function.py:214] Unable to create a python object for variable <tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/gamma:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 06:06:09.212320 140508644669184 wrap_function.py:214] Unable to create a python object for variable <tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/beta:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 06:06:09.212404 140508644669184 wrap_function.py:214] Unable to create a python object for variable <tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/moving_mean:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
2020-04-10 06:06:11.022645: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 06:06:11.022909: I tensorflow/core/grappler/devices.cc:55] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0
2020-04-10 06:06:11.023001: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session
2020-04-10 06:06:11.023880: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 06:06:11.024138: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce GTX 1050 Ti computeCapability: 6.1
coreClock: 1.62GHz coreCount: 6 deviceMemorySize: 3.95GiB deviceMemoryBandwidth: 104.43GiB/s
2020-04-10 06:06:11.024205: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-04-10 06:06:11.024249: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-04-10 06:06:11.024261: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-04-10 06:06:11.024283: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-04-10 06:06:11.024293: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-04-10 06:06:11.024324: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-04-10 06:06:11.024357: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-04-10 06:06:11.024423: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 06:06:11.024695: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 06:06:11.024925: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-04-10 06:06:11.024962: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-04-10 06:06:11.024988: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 
2020-04-10 06:06:11.024993: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N 
2020-04-10 06:06:11.025169: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 06:06:11.025432: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 06:06:11.025671: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 500 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
2020-04-10 06:06:11.074813: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: graph_to_optimize
2020-04-10 06:06:11.074848: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0.003ms.
2020-04-10 06:06:11.074853: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
W0410 06:06:11.121850 140508644669184 wrap_function.py:214] Unable to create a python object for variable <tf.Variable 'global_step:0' shape=() dtype=int64_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 06:06:11.122043 140508644669184 wrap_function.py:214] Unable to create a python object for variable <tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/weights:0' shape=(7, 7, 3, 64) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 06:06:11.122144 140508644669184 wrap_function.py:214] Unable to create a python object for variable <tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/gamma:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 06:06:11.122252 140508644669184 wrap_function.py:214] Unable to create a python object for variable <tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/beta:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
W0410 06:06:11.122336 140508644669184 wrap_function.py:214] Unable to create a python object for variable <tf.Variable 'FeatureExtractor/resnet_v1_50/conv1/BatchNorm/moving_mean:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
2020-04-10 06:06:18.903261: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 06:06:18.903541: I tensorflow/core/grappler/devices.cc:55] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0
2020-04-10 06:06:18.903687: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session
2020-04-10 06:06:18.904242: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 06:06:18.904630: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce GTX 1050 Ti computeCapability: 6.1
coreClock: 1.62GHz coreCount: 6 deviceMemorySize: 3.95GiB deviceMemoryBandwidth: 104.43GiB/s
2020-04-10 06:06:18.904684: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-04-10 06:06:18.904706: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-04-10 06:06:18.904729: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-04-10 06:06:18.904750: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-04-10 06:06:18.904772: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-04-10 06:06:18.904794: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-04-10 06:06:18.904817: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-04-10 06:06:18.904878: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 06:06:18.905197: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 06:06:18.905387: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-04-10 06:06:18.905414: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-04-10 06:06:18.905426: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 
2020-04-10 06:06:18.905435: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N 
2020-04-10 06:06:18.905511: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 06:06:18.905903: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-10 06:06:18.906185: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 500 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
2020-04-10 06:06:19.968587: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:814] Optimization results for grappler item: graph_to_optimize
2020-04-10 06:06:19.968617: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   constant_folding: Graph size after: 1572 nodes (-1774), 1874 edges (-1970), time = 595.545ms.
2020-04-10 06:06:19.968697: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816]   constant_folding: Graph size after: 1572 nodes (0), 1874 edges (0), time = 203.882ms.
Traceback (most recent call last):
  File ""/home/afayed/Desktop/Metecs Work/quant_aware_training.py"", line 65, in <module>
    tflite_quant_model = converter.convert()
  File ""/home/afayed/.local/lib/python3.5/site-packages/tensorflow_core/lite/python/lite.py"", line 464, in convert
    **converter_kwargs)
  File ""/home/afayed/.local/lib/python3.5/site-packages/tensorflow_core/lite/python/convert.py"", line 457, in toco_convert_impl
    enable_mlir_converter=enable_mlir_converter)
  File ""/home/afayed/.local/lib/python3.5/site-packages/tensorflow_core/lite/python/convert.py"", line 203, in toco_convert_protos
    raise ConverterError(""See console for info.\n%s\n%s\n"" % (stdout, stderr))
tensorflow.lite.python.convert.ConverterError: See console for info.
2020-04-10 06:06:21.294618: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-9.0/lib64:/home/afayed/torch/install/lib:/home/afayed/kinova-demo/devel/lib:/opt/ros/kinetic/lib::/usr/local/lib:/usr/lib:/usr/aarch64-linux-gnu/lib
2020-04-10 06:06:21.294725: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-9.0/lib64:/home/afayed/torch/install/lib:/home/afayed/kinova-demo/devel/lib:/opt/ros/kinetic/lib::/usr/local/lib:/usr/lib:/usr/aarch64-linux-gnu/lib
2020-04-10 06:06:21.294733: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2020-04-10 06:06:22.409963: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: ParseSingleExample
2020-04-10 06:06:22.410302: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: DecodeRaw
2020-04-10 06:06:22.410346: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Substr
2020-04-10 06:06:22.410366: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: DecodeJpeg
2020-04-10 06:06:22.410433: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Substr
2020-04-10 06:06:22.410442: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Substr
2020-04-10 06:06:22.410488: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Substr
2020-04-10 06:06:22.410520: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: DecodeJpeg
2020-04-10 06:06:22.410540: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: DecodePng
2020-04-10 06:06:22.410627: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Substr
2020-04-10 06:06:22.410660: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: DecodeGif
2020-04-10 06:06:22.410673: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: DecodeBmp
2020-04-10 06:06:22.412680: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: NonMaxSuppressionV5
2020-04-10 06:06:22.412718: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: NonMaxSuppressionV5
2020-04-10 06:06:22.412730: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: NonMaxSuppressionV5
2020-04-10 06:06:22.412929: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Size
2020-04-10 06:06:22.465849: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 1111 operators, 2079 arrays (0 quantized)
2020-04-10 06:06:22.514192: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After Removing unused ops pass 1: 1070 operators, 1975 arrays (0 quantized)
2020-04-10 06:06:22.568968: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 1070 operators, 1975 arrays (0 quantized)
2020-04-10 06:06:22.789451: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 502 operators, 1067 arrays (0 quantized)
2020-04-10 06:06:22.811142: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Group bidirectional sequence lstm/rnn: 502 operators, 1067 arrays (0 quantized)
2020-04-10 06:06:22.825665: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before dequantization graph transformations: 502 operators, 1067 arrays (0 quantized)
2020-04-10 06:06:22.836283: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Identify nearest upsample.: 502 operators, 1067 arrays (0 quantized)
2020-04-10 06:06:22.867522: I tensorflow/lite/toco/allocate_transient_arrays.cc:345] Total transient array allocated size: 0 bytes, theoretical optimal value: 0 bytes.
2020-04-10 06:06:22.870222: I tensorflow/lite/toco/toco_tooling.cc:471] Number of parameters: 31687618
2020-04-10 06:06:22.871172: W tensorflow/lite/toco/tflite/operator.cc:2024] Op DecodeRaw is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.
2020-04-10 06:06:22.871184: W tensorflow/lite/toco/tflite/operator.cc:2024] Op Substr is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.
2020-04-10 06:06:22.871211: W tensorflow/lite/toco/tflite/operator.cc:2024] Op DecodeJpeg is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.
2020-04-10 06:06:22.871217: W tensorflow/lite/toco/tflite/operator.cc:2024] Op Substr is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.
2020-04-10 06:06:22.871222: W tensorflow/lite/toco/tflite/operator.cc:2024] Op Substr is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.
2020-04-10 06:06:22.871230: W tensorflow/lite/toco/tflite/operator.cc:2024] Op Substr is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.
2020-04-10 06:06:22.871236: W tensorflow/lite/toco/tflite/operator.cc:2024] Op DecodeJpeg is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.
2020-04-10 06:06:22.871242: W tensorflow/lite/toco/tflite/operator.cc:2024] Op DecodePng is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.
2020-04-10 06:06:22.871249: W tensorflow/lite/toco/tflite/operator.cc:2024] Op DecodeGif is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.
2020-04-10 06:06:22.872020: W tensorflow/lite/toco/tflite/operator.cc:2024] Op NonMaxSuppressionV5 is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.
2020-04-10 06:06:22.872027: W tensorflow/lite/toco/tflite/operator.cc:2024] Op NonMaxSuppressionV5 is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.
2020-04-10 06:06:22.872031: W tensorflow/lite/toco/tflite/operator.cc:2024] Op NonMaxSuppressionV5 is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.
2020-04-10 06:06:22.872663: W tensorflow/lite/toco/tflite/operator.cc:2024] Op DecodeRaw is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.
2020-04-10 06:06:22.872672: W tensorflow/lite/toco/tflite/operator.cc:2024] Op Substr is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.
2020-04-10 06:06:22.872698: W tensorflow/lite/toco/tflite/operator.cc:2024] Op DecodeJpeg is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.
2020-04-10 06:06:22.872704: W tensorflow/lite/toco/tflite/operator.cc:2024] Op Substr is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.
2020-04-10 06:06:22.872708: W tensorflow/lite/toco/tflite/operator.cc:2024] Op Substr is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.
2020-04-10 06:06:22.872716: W tensorflow/lite/toco/tflite/operator.cc:2024] Op Substr is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.
2020-04-10 06:06:22.872724: W tensorflow/lite/toco/tflite/operator.cc:2024] Op DecodeJpeg is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.
2020-04-10 06:06:22.872728: W tensorflow/lite/toco/tflite/operator.cc:2024] Op DecodePng is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.
2020-04-10 06:06:22.872748: W tensorflow/lite/toco/tflite/operator.cc:2024] Op DecodeGif is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.
2020-04-10 06:06:22.873543: W tensorflow/lite/toco/tflite/operator.cc:2024] Op NonMaxSuppressionV5 is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.
2020-04-10 06:06:22.873551: W tensorflow/lite/toco/tflite/operator.cc:2024] Op NonMaxSuppressionV5 is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.
2020-04-10 06:06:22.873556: W tensorflow/lite/toco/tflite/operator.cc:2024] Op NonMaxSuppressionV5 is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.
2020-04-10 06:06:22.874173: E tensorflow/lite/toco/toco_tooling.cc:498] We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md
 and pasting the following:

TensorFlow Lite currently doesn't support control flow ops: Merge, Switch. We are working on supporting control flow ops, please see github issue at https://github.com/tensorflow/tensorflow/issues/28485. Some of the operators in the model are not supported by the standard TensorFlow Lite runtime and are not recognized by TensorFlow. If you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: ADD, CAST, CONCATENATION, CONV_2D, EQUAL, EXP, EXPAND_DIMS, FILL, GATHER, GREATER, GREATER_EQUAL, LESS, LOGICAL_OR, LOGISTIC, MAXIMUM, MAX_POOL_2D, MINIMUM, MUL, PACK, PAD, RANGE, RESHAPE, RESIZE_BILINEAR, SELECT, SHAPE, SLICE, SPLIT, SQUEEZE, STRIDED_SLICE, SUB, SUM, TOPK_V2, TRANSPOSE, UNPACK, WHERE. Here is a list of operators for which you will need custom implementations: DecodeGif, DecodeJpeg, DecodePng, DecodeRaw, NonMaxSuppressionV5, Substr.
Traceback (most recent call last):
  File ""/home/afayed/.local/bin/toco_from_protos"", line 8, in <module>
    sys.exit(main())
  File ""/home/afayed/.local/lib/python3.5/site-packages/tensorflow_core/lite/toco/python/toco_from_protos.py"", line 93, in main
    app.run(main=execute, argv=[sys.argv[0]] + unparsed)
  File ""/home/afayed/.local/lib/python3.5/site-packages/tensorflow_core/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/home/afayed/.local/lib/python3.5/site-packages/absl/app.py"", line 300, in run
    _run_main(main, args)
  File ""/home/afayed/.local/lib/python3.5/site-packages/absl/app.py"", line 251, in _run_main
    sys.exit(main(argv))
  File ""/home/afayed/.local/lib/python3.5/site-packages/tensorflow_core/lite/toco/python/toco_from_protos.py"", line 56, in execute
    enable_mlir_converter)
Exception: We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md
 and pasting the following:

TensorFlow Lite currently doesn't support control flow ops: Merge, Switch. We are working on supporting control flow ops, please see github issue at https://github.com/tensorflow/tensorflow/issues/28485. Some of the operators in the model are not supported by the standard TensorFlow Lite runtime and are not recognized by TensorFlow. If you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: ADD, CAST, CONCATENATION, CONV_2D, EQUAL, EXP, EXPAND_DIMS, FILL, GATHER, GREATER, GREATER_EQUAL, LESS, LOGICAL_OR, LOGISTIC, MAXIMUM, MAX_POOL_2D, MINIMUM, MUL, PACK, PAD, RANGE, RESHAPE, RESIZE_BILINEAR, SELECT, SHAPE, SLICE, SPLIT, SQUEEZE, STRIDED_SLICE, SUB, SUM, TOPK_V2, TRANSPOSE, UNPACK, WHERE. Here is a list of operators for which you will need custom implementations: DecodeGif, DecodeJpeg, DecodePng, DecodeRaw, NonMaxSuppressionV5, Substr.



afayed@metecs-0497:~$ 

```
*I limit memory growth using*
`physical_devices = tf.config.list_physical_devices('GPU')
tf.config.set_logical_device_configuration(physical_devices[0],[tf.config.LogicalDeviceConfiguration(memory_limit=500)])
logical_devices = tf.config.list_logical_devices('GPU')`


**Please help, I am also trying to do this with faster_rcnn_inception_resnet_v2_atrous_coco_2018_01_28 and thats where I found about the Experimental Converter working for RCNNs. My goal is to run either of these models on the Coral USB Accelerator after retraining with my own custom training data. I did not edit any scripts generating either of these models. Thanks in advanced**
"
38430,flow_from_dataframe() doesn't shuffle data properly when splitting in subsets,"**System information** 
- Google Colab
- Tensorflow 2.2.0-rc2

**Describe the current behavior**
When `validation_split` is set to some value in `ImageDataGenerator` in order to split the data in two subsets to train and validate, and then shuffle is set to true in `flow_from_dataframe`, the shuffling occurs after this division. This makes the two subsets have different distributions, with a big impact in training stats.

**Describe the expected behavior**
The data should be shuffled BEFORE the division in subsets instead of after.

**Standalone code to reproduce the issue** 
Full code is available here: https://colab.research.google.com/drive/1gpiRZMHpp09nftzl909OG-9JJgTrhkO3 

```
def check_iterator_distribution(iterator):
  # Checks category distribution in the given iterator

  iterator.reset()
  nCat=[0,0,0,0,0,0,0,0,0] # number of images in each category (there are 9 categories)

  step_size = iterator.n//iterator.batch_size

  for i in range(step_size):
    a,b = next(iterator)

    for f in range(iterator.batch_size):
      index = np.where(b[f]==1.)[0][0]

      if index==0:
        nCat[0]+=1
      elif index==1:
        nCat[1]+=1
      elif index==2:
        nCat[2]+=1
      elif index==3:
        nCat[3]+=1
      elif index==4:
        nCat[4]+=1
      elif index==5:
        nCat[5]+=1
      elif index==6:
        nCat[6]+=1
      elif index==7:
        nCat[7]+=1
      elif index==8:
        nCat[8]+=1

  distribution = [x/iterator.n for x in nCat]

  print('Number of images per category', nCat)
  print('Distribution:',distribution)

datagen_train = ImageDataGenerator(preprocessing_function = efn.preprocess_input,
                                   rotation_range = 40,
                                   zoom_range = 0.2,
                                   horizontal_flip = True,
                                   vertical_flip = True,
                                   validation_split=0.2
                                   )

train_iterator = datagen_train.flow_from_dataframe(
    dataframe = df_train,
    directory = path,
    x_col = ""image"",
    y_col = ['MEL','NV','BCC','AK','BKL','DF','VASC','SCC','UNK'],
    batch_size = 32,
    shuffle = True,
    class_mode = ""raw"",
    target_size = (224,224),
    subset = ""training""
)

val_iterator = datagen_train.flow_from_dataframe(
    dataframe = df_train,
    directory = path,
    x_col = ""image"",
    y_col = ['MEL','NV','BCC','AK','BKL','DF','VASC','SCC','UNK'],
    batch_size = 32,
    shuffle = True,
    class_mode = ""raw"",
    target_size = (224,224),
    subset = ""validation""
)

check_iterator_distribution(train_iterator)
check_iterator_distribution(val_iterator)
```
The distribution of both iterators is as follows:

- `train_iterator`: Number of images per category [3789, 9417, 3214, 839, 1995, 214, 216, 572, 0]
Distribution: [0.1869, 0.4646, 0.1585, 0.0414, 0.0984, 0.0105, 0.0106, 0.0282, 0.0]
- `val_iterator`: Number of images per category [731, 3445, 108, 27, 627, 25, 37, 56, 0]
Distribution: [0.1442, 0.6800, 0.0213, 0.0053, 0.1237, 0.0049, 0.0073, 0.0110, 0.0]

In contrast, when the dataframe is shuffled (through `df_train.sample(frac=1)`) before being passed to `flow_from_dataframe()`, the distribution is almost the same in both:

- `train iterator`: Number of images per category [3596, 10290, 2699, 711, 2064, 192, 210, 494, 0]
Distribution: [0.1774, 0.5077, 0.1331, 0.0350, 0.1018, 0.0094, 0.0103, 0.0243, 0.0]
- `val_iterator`: Number of images per category [925, 2574, 621, 155, 558, 47, 43, 133, 0]
Distribution: [0.1825, 0.5080, 0.1225, 0.0305, 0.1101, 0.0092, 0.0084, 0.0262, 0.0]

"
38429,Broadcasting sparse indices,"**System information**
- TensorFlow version (you are using): 2.1
- Are you willing to contribute it (Yes/No): Yes (partially, what can be done on the python side, and maybe CPU kernels)

**Will this change the current api? How?**
Add an operation to `tf.sparse.broadcast_indices` (feel free to suggest a beter name), doing the following:
```
tf.sparse.broadcast_indices(a, b, default_value): Given two sparse tensors of same dense shape, inserts `default_value` at positions such that a.indices == b.indices.
```
This would provide a basic building block for arbitrary pointwise-binary operations on SparseTensors. Therefore I would also suggest adding a function like
```
tf.sparse.map_binary_op(a, b, op, def_value=0):
   a, b = broadcast_indices(a, b, def_value)
   return SparseTensor(a.indices, op(a.values, b.values), a.shape) 
```

This would then allow for more efficient implementations e.g. of binary metrics when both labels and predictions are sparse, e.g. when calculating P@k statistics.

I think I can provide an initial, sub-optimal implementation that builds this on top of `tf.sparse.add` for default values of zero. Would you be interested in a PR like that (maybe putting it into experimental namespace at first)? 
"
38428,batch_jacobian incorrect,"**System information** 
- Have I written custom code: yes
- OS Platform and Distribution
   - Windows 10, Anaconda Python 3.7.6, tensorflow 2.1.0
   - Debian GNU/Linux 8.11 (jessie), Anaconda Python 3.7.3, tensorflow 2.0.0

**Standalone code to reproduce the issue** 
```python
import numpy, tensorflow
x = tensorflow.Variable([[1], [1]], dtype=""float64"")
with tensorflow.GradientTape(persistent=True) as t:
    with tensorflow.GradientTape() as tt:
        obj = x[0]**2 + x[1]**2 + x[0]*x[1]
    dx = tt.gradient(obj, x)
print(t.batch_jacobian(dx, x).numpy())
```
output is 
```python
[[[3.]]

 [[3.]]]
```
which is not `[jacobian(y[i], x[i]) for i in range(x.shape[0])]` as [stated here](https://www.tensorflow.org/api_docs/python/tf/GradientTape#batch_jacobian).

It is more like `[gradient(sum(y), x[i]) for i in range(x.shape[0])]`, same as gradient of gradient:
```python
import numpy, tensorflow
x = tensorflow.Variable([1, 1], dtype=""float64"")
with tensorflow.GradientTape(persistent=True) as t:
    with tensorflow.GradientTape() as tt:
        obj = x[0]**2 + x[1]**2 + x[0]*x[1]
    dx = tt.gradient(obj, x)
print(t.jacobian(dx, x).numpy())
print(t.gradient(dx, x).numpy())
```
output is 
```python
[[2. 1.]
 [1. 2.]]
[3. 3.]
```
which is perfectly fine

**Other info / logs**
* f(x,y) = x^2+y^2+x y
* df/dx = 2x+y
* df/dy = 2y+x
* ddf/dxdx = 2
* ddf/dxdy = 1
* ddf/dydy = 2

What I want is the _diag(Hessian)_ without calculating full Hessian."
38427,Image Classification not working in Local System,"**System information**
**### - OS Platform and Distribution (MacOs Catalina):**
### **- TensorFlow version:2.1.0**
### **- Python version: 3.6.9**
### **- Platform - docker with jupyter notebook**

### **During The Image Classification, I got An error like this, 
It working properly in google colab notebook**

```
import os
import zipfile
local_zip = '/tf/tmp/horse-or-human.zip'
zip_ref = zipfile.ZipFile(local_zip, 'r')
zip_ref.extractall('/tf/tmp/horse-or-human')
zip_ref.close()
train_horse_dir = os.path.join('/tf/tmp/horse-or-human/horses')
train_human_dir = os.path.join('/tf/tmp/horse-or-human/humans')
train_horse_names = os.listdir(train_horse_dir)
print(train_horse_names[:10])
train_human_names = os.listdir(train_human_dir)
print(train_human_names[:10])
print('total training horse images:', len(os.listdir(train_horse_dir)))
print('total training human images:', len(os.listdir(train_human_dir)))
get_ipython().run_line_magic('matplotlib', 'inline')
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
nrows = 4
ncols = 4
pic_index = 0
# Set up matplotlib fig, and size it to fit 4x4 pics
fig = plt.gcf()
fig.set_size_inches(ncols * 4, nrows * 4)

pic_index += 8
next_horse_pix = [os.path.join(train_horse_dir, fname) 
                for fname in train_horse_names[pic_index-8:pic_index]]
next_human_pix = [os.path.join(train_human_dir, fname) 
                for fname in train_human_names[pic_index-8:pic_index]]

for i, img_path in enumerate(next_horse_pix+next_human_pix):
  # Set up subplot; subplot indices start at 1
  sp = plt.subplot(nrows, ncols, i + 1)
  sp.axis('Off') # Don't show axes (or gridlines)

  img = mpimg.imread(img_path)
  plt.imshow(img)

plt.show()










import tensorflow as tf
print(tf.__version__)



model = tf.keras.models.Sequential([
    # Note the input shape is the desired size of the image 300x300 with 3 bytes color
    # This is the first convolution
    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(300, 300, 3)),
    tf.keras.layers.MaxPooling2D(2, 2),
    # The second convolution
    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    # The third convolution
    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    # The fourth convolution
    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    # The fifth convolution
    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    # Flatten the results to feed into a DNN
    tf.keras.layers.Flatten(),
    # 512 neuron hidden layer
    tf.keras.layers.Dense(512, activation='relu'),
    # Only 1 output neuron. It will contain a value from 0-1 where 0 for 1 class ('horses') and 1 for the other ('humans')
    tf.keras.layers.Dense(1, activation='sigmoid')
])



model.summary()



from tensorflow.keras.optimizers import RMSprop

model.compile(loss='binary_crossentropy',
              optimizer=RMSprop(lr=0.001),
              metrics=['accuracy'])



from tensorflow.keras.preprocessing.image import ImageDataGenerator




from tensorflow.keras.preprocessing.image import ImageDataGenerator

# All images will be rescaled by 1./255
train_datagen = ImageDataGenerator(rescale=1/255)

# Flow training images in batches of 128 using train_datagen generator
train_generator = train_datagen.flow_from_directory(
        '/tf/tmp/horse-or-human/',  # This is the source directory for training images
        target_size=(300, 300),  # All images will be resized to 150x150
        batch_size=128,
        # Since we use binary_crossentropy loss, we need binary labels
        class_mode='binary')


# In[18]:


history = model.fit(train_generator,epochs=15,steps_per_epoch=8,verbose=1)
```

`
and got an error 
### **ImportErrorTraceback (most recent call last)
<ipython-input-18-8d2593ec774f> in <module>
----> 1 history = model.fit(train_generator,epochs=15,steps_per_epoch=8,verbose=1)

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)
    817         max_queue_size=max_queue_size,
    818         workers=workers,
--> 819         use_multiprocessing=use_multiprocessing)
    820 
    821   def evaluate(self,

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py in fit(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)
    233           max_queue_size=max_queue_size,
    234           workers=workers,
--> 235           use_multiprocessing=use_multiprocessing)
    236 
    237       total_samples = _get_total_number_of_samples(training_data_adapter)

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py in _process_training_inputs(model, x, y, batch_size, epochs, sample_weights, class_weights, steps_per_epoch, validation_split, validation_data, validation_steps, shuffle, distribution_strategy, max_queue_size, workers, use_multiprocessing)
    591         max_queue_size=max_queue_size,
    592         workers=workers,
--> 593         use_multiprocessing=use_multiprocessing)
    594     val_adapter = None
    595     if validation_data:

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py in _process_inputs(model, mode, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing)
    704       max_queue_size=max_queue_size,
    705       workers=workers,
--> 706       use_multiprocessing=use_multiprocessing)
    707 
    708   return adapter

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/data_adapter.py in __init__(self, x, y, sample_weights, standardize_function, shuffle, workers, use_multiprocessing, max_queue_size, **kwargs)
    950         use_multiprocessing=use_multiprocessing,
    951         max_queue_size=max_queue_size,
--> 952         **kwargs)
    953 
    954   @staticmethod

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/data_adapter.py in __init__(self, x, y, sample_weights, standardize_function, workers, use_multiprocessing, max_queue_size, **kwargs)
    745     # Since we have to know the dtype of the python generator when we build the
    746     # dataset, we have to look at a batch to infer the structure.
--> 747     peek, x = self._peek_and_restore(x)
    748     assert_not_namedtuple(peek)
    749 

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/data_adapter.py in _peek_and_restore(x)
    954   @staticmethod
    955   def _peek_and_restore(x):
--> 956     return x[0], x
    957 
    958   def _make_callable(self, x, workers, use_multiprocessing, max_queue_size):

/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/iterator.py in __getitem__(self, idx)
     63         index_array = self.index_array[self.batch_size * idx:
     64                                        self.batch_size * (idx + 1)]
---> 65         return self._get_batches_of_transformed_samples(index_array)
     66 
     67     def __len__(self):

/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/iterator.py in _get_batches_of_transformed_samples(self, index_array)
    228                            color_mode=self.color_mode,
    229                            target_size=self.target_size,
--> 230                            interpolation=self.interpolation)
    231             x = img_to_array(img, data_format=self.data_format)
    232             # Pillow images should be closed after `load_img`,

/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/utils.py in load_img(path, grayscale, color_mode, target_size, interpolation)
    106         color_mode = 'grayscale'
    107     if pil_image is None:
--> 108         raise ImportError('Could not import PIL.Image. '
    109                           'The use of `load_img` requires PIL.')
    110     img = pil_image.open(path)

ImportError: Could not import PIL.Image. The use of `load_img` requires PIL.**






"
38426,Not converting pb to tflite using tflite_convert with some custom ops,"**System information**
- OS Platform and Distribution = Linux Ubuntu 18.04
- TensorFlow installed from source
- TensorFlow version (or github SHA if from source):


**Provide the text output from tflite_convert**
/home/ashwini/Object_detection_general/environment/obj_det/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([(""qint8"", np.int8, 1)])
/home/ashwini/Object_detection_general/environment/obj_det/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([(""quint8"", np.uint8, 1)])
/home/ashwini/Object_detection_general/environment/obj_det/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([(""qint16"", np.int16, 1)])
/home/ashwini/Object_detection_general/environment/obj_det/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([(""quint16"", np.uint16, 1)])
/home/ashwini/Object_detection_general/environment/obj_det/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([(""qint32"", np.int32, 1)])
/home/ashwini/Object_detection_general/environment/obj_det/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([(""resource"", np.ubyte, 1)])
/home/ashwini/Object_detection_general/environment/obj_det/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([(""qint8"", np.int8, 1)])
/home/ashwini/Object_detection_general/environment/obj_det/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([(""quint8"", np.uint8, 1)])
/home/ashwini/Object_detection_general/environment/obj_det/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([(""qint16"", np.int16, 1)])
/home/ashwini/Object_detection_general/environment/obj_det/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([(""quint16"", np.uint16, 1)])
/home/ashwini/Object_detection_general/environment/obj_det/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([(""qint32"", np.int32, 1)])
/home/ashwini/Object_detection_general/environment/obj_det/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([(""resource"", np.ubyte, 1)])
2020-04-10 14:43:22.397713: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-04-10 14:43:22.426081: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2194720000 Hz
2020-04-10 14:43:22.426553: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x40c04e0 executing computations on platform Host. Devices:
2020-04-10 14:43:22.426614: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
Traceback (most recent call last):
  File ""/home/ashwini/Object_detection_general/environment/obj_det/bin/tflite_convert"", line 11, in <module>
    sys.exit(main())
  File ""/home/ashwini/Object_detection_general/environment/obj_det/lib/python3.6/site-packages/tensorflow/lite/python/tflite_convert.py"", line 504, in main
    app.run(main=run_main, argv=sys.argv[:1])
  File ""/home/ashwini/Object_detection_general/environment/obj_det/lib/python3.6/site-packages/tensorflow/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/home/ashwini/Object_detection_general/environment/obj_det/lib/python3.6/site-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/home/ashwini/Object_detection_general/environment/obj_det/lib/python3.6/site-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""/home/ashwini/Object_detection_general/environment/obj_det/lib/python3.6/site-packages/tensorflow/lite/python/tflite_convert.py"", line 500, in run_main
    _convert_tf1_model(tflite_flags)
  File ""/home/ashwini/Object_detection_general/environment/obj_det/lib/python3.6/site-packages/tensorflow/lite/python/tflite_convert.py"", line 193, in _convert_tf1_model
    output_data = converter.convert()
  File ""/home/ashwini/Object_detection_general/environment/obj_det/lib/python3.6/site-packages/tensorflow/lite/python/lite.py"", line 904, in convert
    **converter_kwargs)
  File ""/home/ashwini/Object_detection_general/environment/obj_det/lib/python3.6/site-packages/tensorflow/lite/python/convert.py"", line 373, in toco_convert_graph_def
    input_data.SerializeToString())
  File ""/home/ashwini/Object_detection_general/environment/obj_det/lib/python3.6/site-packages/tensorflow/lite/python/convert.py"", line 172, in toco_convert_protos
    ""TOCO failed. See console for info.\n%s\n%s\n"" % (stdout, stderr))
tensorflow.lite.python.convert.ConverterError: TOCO failed. See console for info.
/home/ashwini/Object_detection_general/environment/obj_det/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([(""qint8"", np.int8, 1)])
/home/ashwini/Object_detection_general/environment/obj_det/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([(""quint8"", np.uint8, 1)])
/home/ashwini/Object_detection_general/environment/obj_det/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([(""qint16"", np.int16, 1)])
/home/ashwini/Object_detection_general/environment/obj_det/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([(""quint16"", np.uint16, 1)])
/home/ashwini/Object_detection_general/environment/obj_det/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([(""qint32"", np.int32, 1)])
/home/ashwini/Object_detection_general/environment/obj_det/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([(""resource"", np.ubyte, 1)])
/home/ashwini/Object_detection_general/environment/obj_det/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([(""qint8"", np.int8, 1)])
/home/ashwini/Object_detection_general/environment/obj_det/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([(""quint8"", np.uint8, 1)])
/home/ashwini/Object_detection_general/environment/obj_det/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([(""qint16"", np.int16, 1)])
/home/ashwini/Object_detection_general/environment/obj_det/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([(""quint16"", np.uint16, 1)])
/home/ashwini/Object_detection_general/environment/obj_det/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([(""qint32"", np.int32, 1)])
/home/ashwini/Object_detection_general/environment/obj_det/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([(""resource"", np.ubyte, 1)])
2020-04-10 14:43:24.007856: I tensorflow/lite/toco/import_tensorflow.cc:1336] Converting unsupported operation: TFLite_Detection_PostProcess
2020-04-10 14:43:24.034443: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 500 operators, 754 arrays (0 quantized)
2020-04-10 14:43:24.050893: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 500 operators, 754 arrays (0 quantized)
2020-04-10 14:43:24.100022: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 64 operators, 176 arrays (0 quantized)
2020-04-10 14:43:24.101499: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Group bidirectional sequence lstm/rnn: 64 operators, 176 arrays (0 quantized)
2020-04-10 14:43:24.102515: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before dequantization graph transformations: 64 operators, 176 arrays (0 quantized)
2020-04-10 14:43:24.104827: I tensorflow/lite/toco/allocate_transient_arrays.cc:345] Total transient array allocated size: 11520000 bytes, theoretical optimal value: 8640000 bytes.
2020-04-10 14:43:24.105140: I tensorflow/lite/toco/toco_tooling.cc:433] Estimated count of arithmetic ops: 2.25832 billion (note that a multiply-add is counted as 2 ops).
2020-04-10 14:43:24.105533: E tensorflow/lite/toco/toco_tooling.cc:456] We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md
 and pasting the following:

Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: CONCATENATION, CONV_2D, DEPTHWISE_CONV_2D, LOGISTIC, RESHAPE. Here is a list of operators for which you will need custom implementations: TFLite_Detection_PostProcess.
Traceback (most recent call last):
  File ""/home/ashwini/Object_detection_general/environment/obj_det/bin/toco_from_protos"", line 11, in <module>
    sys.exit(main())
  File ""/home/ashwini/Object_detection_general/environment/obj_det/lib/python3.6/site-packages/tensorflow/lite/toco/python/toco_from_protos.py"", line 59, in main
    app.run(main=execute, argv=[sys.argv[0]] + unparsed)
  File ""/home/ashwini/Object_detection_general/environment/obj_det/lib/python3.6/site-packages/tensorflow/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/home/ashwini/Object_detection_general/environment/obj_det/lib/python3.6/site-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/home/ashwini/Object_detection_general/environment/obj_det/lib/python3.6/site-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""/home/ashwini/Object_detection_general/environment/obj_det/lib/python3.6/site-packages/tensorflow/lite/toco/python/toco_from_protos.py"", line 33, in execute
    output_str = tensorflow_wrap_toco.TocoConvert(model_str, toco_str, input_str)
Exception: We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md
 and pasting the following:

Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: CONCATENATION, CONV_2D, DEPTHWISE_CONV_2D, LOGISTIC, RESHAPE. Here is a list of operators for which you will need custom implementations: TFLite_Detection_PostProcess.


```
Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: CONCATENATION, CONV_2D, DEPTHWISE_CONV_2D, LOGISTIC, RESHAPE. Here is a list of operators for which you will need custom implementations: TFLite_Detection_PostProcess.

```

**Standalone code to reproduce the issue** 
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

Also, please include a link to a GraphDef or the model if possible.

when I try to execute following command:
tflite_convert   --output_file=""/home/ashwini/Object_detection_general/models/research/logs_text_detection/frozen_pb_using_tflite_ssd_script/pb_without_custom_ops/temp.tflite""   --graph_def_file=""/home/ashwini/Object_detection_general/models/research/logs_text_detection/frozen_pb_using_tflite_ssd_script/pb_with_custom_ops/tflite_graph_46100.pb""   --inference_type=FLOAT   --input_arrays=""normalized_input_image_tensor""   --output_arrays=""TFLite_Detection_PostProcess,TFLite_Detection_PostProcess:1,TFLite_Detection_PostProcess:2,TFLite_Detection_PostProcess:3""   --mean_values=128   --std_dev_values=128   --input_shapes=1,300,300,3   --change_concat_input_ranges=false --default_ranges_min=0 and --default_ranges_max=6

Include any logs or source code that would be helpful to diagnose the problem.
If including tracebacks, please include the full traceback. Large logs and files
should be attached.

Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: CONCATENATION, CONV_2D, DEPTHWISE_CONV_2D, LOGISTIC, RESHAPE. Here is a list of operators for which you will need custom implementations: TFLite_Detection_PostProcess.
Traceback (most recent call last):
  File ""/home/ashwini/Object_detection_general/environment/obj_det/bin/toco_from_protos"", line 11, in <module>
    sys.exit(main())
  File ""/home/ashwini/Object_detection_general/environment/obj_det/lib/python3.6/site-packages/tensorflow/lite/toco/python/toco_from_protos.py"", line 59, in main
    app.run(main=execute, argv=[sys.argv[0]] + unparsed)
  File ""/home/ashwini/Object_detection_general/environment/obj_det/lib/python3.6/site-packages/tensorflow/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/home/ashwini/Object_detection_general/environment/obj_det/lib/python3.6/site-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/home/ashwini/Object_detection_general/environment/obj_det/lib/python3.6/site-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""/home/ashwini/Object_detection_general/environment/obj_det/lib/python3.6/site-packages/tensorflow/lite/toco/python/toco_from_protos.py"", line 33, in execute

"
38425,TF2.x eager mode can not support ParameterServerStrategy now ?,"TF version: latest master ,  b083ceafd48b3c8e4d9dfcc40a6b743bed7b371a

Below is a simple example using TF2.0 eager mode, and it ran successful with `MirroredStrategy`, but error with `ParameterServerStrategy`.

```
from __future__ import absolute_import, division, print_function, unicode_literals
import tensorflow as tf
import tensorflow_datasets as tfds
import os, json

datasets, info = tfds.load(name='mnist', with_info=True, as_supervised=True)
mnist_train, mnist_test = datasets['train'], datasets['test']

os.environ['TF_CONFIG'] = json.dumps({
    ""cluster"": {
        ""worker"": [""localhost:12345""],
        ""ps"": [""localhost:12346""]
    },
    ""task"": {""type"": ""worker"", ""index"": 0}
})

strategy = tf.distribute.experimental.ParameterServerStrategy()
#strategy = tf.distribute.MirroredStrategy()

print('Number of devices: {}'.format(strategy.num_replicas_in_sync))
num_train_examples = info.splits['train'].num_examples
num_test_examples = info.splits['test'].num_examples
BUFFER_SIZE = 10000
BATCH_SIZE_PER_REPLICA = 64
BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync

def scale(image, label):
  image = tf.cast(image, tf.float32)
  image /= 255
  return image, label

train_dataset = mnist_train.map(scale).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)
eval_dataset = mnist_test.map(scale).batch(BATCH_SIZE)

with strategy.scope():
  model = tf.keras.Sequential([
      tf.keras.layers.Conv2D(32, 3, activation='relu', input_shape=(28, 28, 1)),
      tf.keras.layers.MaxPooling2D(),
      tf.keras.layers.Flatten(),
      tf.keras.layers.Dense(64, activation='relu'),
      tf.keras.layers.Dense(10, activation='softmax')
  ])

  model.compile(loss='sparse_categorical_crossentropy',
                optimizer=tf.keras.optimizers.Adam(),
                metrics=['accuracy'])

checkpoint_dir = './training_checkpoints'
# Name of the checkpoint files
checkpoint_prefix = os.path.join(checkpoint_dir, ""ckpt_{epoch}"")

# Function for decaying the learning rate.
# You can define any decay function you need.
def decay(epoch):
  if epoch < 3:
    return 1e-3
  elif epoch >= 3 and epoch < 7:
    return 1e-4
  else:
    return 1e-5

# Callback for printing the LR at the end of each epoch.
class PrintLR(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epoch, logs=None):
    print('\nLearning rate for epoch {} is {}'.format(epoch + 1,
                                                      model.optimizer.lr.numpy()))
callbacks = [
    tf.keras.callbacks.TensorBoard(log_dir='./logs'),
    tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_prefix,
                                       save_weights_only=True),
    tf.keras.callbacks.LearningRateScheduler(decay),
    PrintLR()
]

model.fit(train_dataset, epochs=12, callbacks=callbacks)
model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))
eval_loss, eval_acc = model.evaluate(eval_dataset)
print('Eval loss: {}, Eval Accuracy: {}'.format(eval_loss, eval_acc))
```

**error message** 

```
    tf.keras.layers.Dense(10, activation='softmax')
  File ""/usr/local/lib/python3.7/site-packages/tensorflow/python/training/tracking/base.py"", line 456, in _method_wrapper
    result = method(self, *args, **kwargs)
  File ""/usr/local/lib/python3.7/site-packages/tensorflow/python/keras/engine/sequential.py"", line 116, in __init__
    super(Sequential, self).__init__(name=name, autocast=False)
  File ""/usr/local/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py"", line 199, in __init__
    self._init_batch_counters()
  File ""/usr/local/lib/python3.7/site-packages/tensorflow/python/training/tracking/base.py"", line 456, in _method_wrapper
    result = method(self, *args, **kwargs)
  File ""/usr/local/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py"", line 206, in _init_batch_counters
    self._train_counter = variables.Variable(0, dtype='int64', aggregation=agg)
  File ""/usr/local/lib/python3.7/site-packages/tensorflow/python/ops/variables.py"", line 261, in __call__
    return cls._variable_v2_call(*args, **kwargs)
  File ""/usr/local/lib/python3.7/site-packages/tensorflow/python/ops/variables.py"", line 255, in _variable_v2_call
    shape=shape)
  File ""/usr/local/lib/python3.7/site-packages/tensorflow/python/ops/variables.py"", line 66, in getter
    return captured_getter(captured_previous, **kwargs)
  File ""/usr/local/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py"", line 1769, in creator_with_resource_vars
    return self._create_variable(next_creator, **kwargs)
  File ""/usr/local/lib/python3.7/site-packages/tensorflow/python/distribute/parameter_server_strategy.py"", line 455, in _create_variable
    with ops.device(self._variable_device):
  File ""/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/ops.py"", line 5183, in device
    ""tf.device does not support functions when eager execution ""
RuntimeError: tf.device does not support functions when eager execution is enabled.

```
"
38424,UnicodeDecodeError,"**System information** 
- csv2TFrecords
- Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if
the issue happens on mobile device: 
- TensorFlow installed from: pip install tensorflow==2.2.0rc2
- TensorFlow version : 2.2.0-rc2
- Python version: 3.8.2
 - GPU model: AMD HD 7950

**Traceback (most recent call last):
  File ""tf.py"", line 100, in <module>
    tf.app.run()
  File ""C:\Users\Mostalk\AppData\Roaming\Python\Python38\site-packages\tensorflow\python\platform\app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""C:\Users\Mostalk\AppData\Roaming\Python\Python38\site-packages\absl\app.py"", line 299, in run
    _run_main(main, args)
  File ""C:\Users\Mostalk\AppData\Roaming\Python\Python38\site-packages\absl\app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""tf.py"", line 91, in main
    tf_example = create_tf_example(group, path)
  File ""tf.py"", line 46, in create_tf_example
    encoded_jpg = fid.read()
  File ""C:\Users\Mostalk\AppData\Roaming\Python\Python38\site-packages\tensorflow\python\lib\io\file_io.py"", line 116, in read
    self._preread_check()
  File ""C:\Users\Mostalk\AppData\Roaming\Python\Python38\site-packages\tensorflow\python\lib\io\file_io.py"", line 78, in _preread_check
    self._read_buf = _pywrap_file_io.BufferedInputStream(
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xcd in position 123: invalid continuation byte**

"
38423,Error when loading h5 model inside strategy scope,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow): **No**
- OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04): **Windows 10 and Ubuntu 16.04.6 LTS**
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if
the issue happens on mobile device: 
- TensorFlow installed from (source or
binary): **binary**
- TensorFlow version (use command below): **2.1.0**
- Python version: **Python 3.7.5**
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source): 
- CUDA/cuDNN version: **CUDA 10.1.243, CuDNN 7.6.4**
- GPU model and memory: **error with CPU and GPU**

**Describe the current behavior**
Cannot load a model from a h5 file inside a strategy context (either CPU, GPU or mirrored) whereas load_model works without strategy context.
Inside a strategy context, it gives error :  

> c:\program files\python37\lib\site-packages\tensorflow_core\python\keras\optimizer_v2\optimizer_v2.py in apply_gradients(self, grads_and_vars, name)
>     439         return control_flow_ops.no_op()
>     440       apply_state = self._prepare(var_list)
> --> 441       return distribute_ctx.get_replica_context().merge_call(
>     442           functools.partial(self._distributed_apply, apply_state=apply_state),
>     443           args=(grads_and_vars,),
> 
> AttributeError: 'NoneType' object has no attribute 'merge_call'

This issue is linked to https://github.com/tensorflow/tensorflow/issues/32359 

**Describe the expected behavior**
load_model call should work in both cases : with or without the use of a strategy context.

**Standalone code to reproduce the issue** 
The zip archive containing the h5 file of the model is attached : 
[dummy_model.zip](https://github.com/tensorflow/tensorflow/files/4460828/dummy_model.zip)

  
Here is the code to reproduce the issue : 
```python
import tensorflow as tf

model_path = ""dummy_model.h5""

##### WORKING CASE #####
model = tf.keras.models.load_model(model_path)
model.summary()
########################

##### NON WORKING CASE #####
strategy_context = tf.distribute.OneDeviceStrategy(device=""/cpu:0"")  # not working also with ""/gpu:0"" and MirroredStrategy
with strategy_context.scope():
    model = tf.keras.models.load_model(model_path)
    model.summary()
############################
```
"
38422,"Better documentation for the Embeddings Projector, especially graphs/edges?","Apparently it is possible to render edges between data points in the embeddings projector but I cannot find the documentation for this anywhere. It is also not clear what other things might be possible which are not obvious or documented.
A column called `__next__` may have special meaning, judging from one of the examples, but it is not clear what exactly it can be used for, what the requirements on the input are or what other special meaning column names there may exist.
Or am I missing some obvious documentation here?"
38421,How to generate schema_generaed.h,"I try to add a builtin op for tflite, could you please tell me how to generate tensorflow/lite/schema/schema_generated.h
Thanks for your  help!"
38420,predict result with SavedModel are not same in Python Api and Java Api,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information** 
- OS Platform and Distribution (windows 7): 
- TensorFlow installed from (binary): 
- TensorFlow version (cpu, 1.15.0): 
- Python version: - 3.6.3


**Describe the current behavior**
 I saved model with Estimator.export_saved_model()

**I load the model with Python:**

`
from tensorflow.contrib import predictor
self.model = predictor.from_saved_model(self.mode_dir)

\\# predict 
a_input_ids, a_input_mask, a_segment_ids = self._build_input(a_input)
output = self.model({'a_input_ids': [a_input_ids],
                             'a_input_mask': [a_input_mask],
                             'a_segment_ids': [a_segment_ids]})
 a_output = output['a_output_layer']
`
a_output = [[-0.05960074  0.03045687 -0.20487925  0.36802548  0.07898629 -0.35250664
   0.21251363 -0.23284832 -0.30972436 -0.20010747 -0.00487598  0.48967522
   0.1831991  -0.28579575  0.15075627  0.2821794  -0.02628851 -0.05371238
   0.06514908 -0.38573033 -0.34205046  0.3108538  -0.01758813  0.59596956
   0.5169708  -0.46524945 -0.6804516  -0.32393196  0.36948654 -0.46160206
  -0.15634336  0.44929808 -0.39321676 -0.18401513 -0.3726705   0.19476992
   0.33169916 -0.11876976 -0.36055735  0.19275247  0.12676252  0.10232886
   0.63154477 -0.07467962 -0.17044203 -0.47212833  0.26961723 -0.33468968
   0.22710937  0.05272907 -0.6149754  -0.02799183  0.10492884  0.23291017
  -0.20572647 -0.13610545 -0.05362191  0.44776174  0.4095006  -0.43816873
   0.22285426  0.33557323  0.31537503  0.07024186 -0.38216737 -0.12280162
  -0.27534372 -0.41657594 -0.05565406 -0.33100575 -0.29913923  0.00283101
   0.10702493 -0.31459734 -0.2403451   0.42180565 -0.03365724  0.3264306
   0.5190079   0.21016245 -0.3...


**I load the model with Java:**

`
SavedModelBundle bundle = SavedModelBundle.load(exportDir, ""serve"");
\\# predict :
ThreeTuple<long[][], long[][], long[][]> input = buildInput(sentenceList);

Tensor<?> aInputIdsTensor = Tensor.create(input.param1);
Tensor<?> aInputMaskTensor = Tensor.create(input.param2);
Tensor<?> aSegmentIdsTensor = Tensor.create(input.param3);
List<Tensor<?>> tensors = this.bundle.session().runner()
                .feed(""a_input_ids"", aInputIdsTensor)
                .feed(""a_input_mask"", aInputMaskTensor)
                .feed(""a_segment_ids"", aSegmentIdsTensor)
                .fetch(""a_output"").run();
Tensor<?> result = tensors.get(0);
float[][] outResult = new float[1][dim];
 result.copyTo(outResult);
float[] a_output = outResult[0]
`
a_output = [[-0.018384377, -0.06955972, 0.051764473, 0.015454082, 0.06722302, -0.07839473, 0.02793679, -0.072589695, -0.051289488, -0.039070662, 0.049129114, 0.11508791, 0.0076964055, -0.042025223, 0.05569571, 0.05739251, -0.04230939, -0.05749864, 0.10970076, -0.15183078, -0.08809995, 0.07375819, 0.08044808, 0.12184837, 0.043990605, -0.12923256, -0.056834757, 0.056434825, 0.033050016, -0.022836037, -0.09641873, 0.029169578, -0.0059487675, -0.084053494, -0.095500425, -0.009507669, 0.032067284, -0.026453126, -0.070464775, 0.058229186, 0.016397119, 0.0129444385, 0.07648615, -0.014742567, -0.01920672, -0.10167458, -0.040589973, -0.037671003, -0.02273454, ...

I use the same version of Tensorflow, same SavedModel, same vocab,same everything but the code language。Apparently, the two result above is not same.


**Describe the expected behavior**

expected same predict result.

**Standalone code to reproduce the issue** 
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
38419,tf.python.keras.layers.preprocessing.index_lookup.IndexLookup cannot be saved and loaded,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information** 
Please check this Colab using tf-nightly.
Also reproduced in 2.2.0rc2
https://colab.research.google.com/drive/1QFmqgiGLsHN3shnEuhakAWLrqjT0nD6B
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow): 
- OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04): 
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if
the issue happens on mobile device: 
- TensorFlow installed from (source or
binary): - TensorFlow version (use command below): 
- Python version: - Bazel
version (if compiling from source):
- GCC/Compiler version (if compiling from
source): 
- CUDA/cuDNN version: - GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
After saving and loading the model the output of the layer is different.

**Describe the expected behavior**
The output should be the same

**Standalone code to reproduce the issue** 
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.
https://colab.research.google.com/drive/1QFmqgiGLsHN3shnEuhakAWLrqjT0nD6B

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
38418,save_weight/load_weight,"python 3.7/tensorflow 2.1

When I setup inception resnet v2 model and do training/validation, the accuracy is very high, already reaches 97%, while when I do save_weight, and load_weight to do testing, seems classification doesn't work properly(Cannot classified). Who can tell me what happens?

Hyper-parameter settings:
Adam learning rate = 0.0001
Adam decay =1e-4
L1_REGULIZER(kernel_regularizer) = 0.01
L2_REGULIZER(activity_regularizer) = 0.01
CLASS_NUM = 3

Test Result
All Images classified to 0 class

Main Function
`from __future__ import absolute_import, division, print_function
import tensorflow as tf
import math
import os
import datetime
import sys

# User defined packages
from configuration import IMAGE_HEIGHT, IMAGE_WIDTH, CHANNELS, \
    EPOCHS, BATCH_SIZE, save_model_root_dir, log_root_dir,  GLOBAL_LEARNING_RATE, \
    WEIGHT_DECAY, THRESHOLD
from prepare_data import generate_datasets, load_and_preprocess_image
from models import mobilenet_v1, mobilenet_v2, mobilenet_v3_large, mobilenet_v3_small, \
    efficientnet, resnext, inception_v4, inception_resnet_v1, inception_resnet_v2, \
    se_resnet, squeezenet, densenet, shufflenet_v2, resnet
from models.model_selection import get_model


def print_model_summary(network):
    network.build(input_shape=(None, IMAGE_HEIGHT, IMAGE_WIDTH, CHANNELS))
    network.summary()


def process_features(features, data_augmentation):
    image_raw = features['image_raw'].numpy()
    image_tensor_list = []
    for image in image_raw:
        image_tensor = load_and_preprocess_image(image, data_augmentation=data_augmentation)
        image_tensor_list.append(image_tensor)
    images = tf.stack(image_tensor_list, axis=0)
    labels = features['label'].numpy()

    return images, labels

def folder_preparation(job_id, product_id):
    # Genearte log file path and precreate log file header
    log_dir = log_root_dir + job_id + ""/"" + product_id  + ""/""
    if not os.path.exists(log_dir):
        os.makedirs(log_dir)
    file = open(log_dir +""training_result_step"" + "".log"", ""w"")
    file.write(""type\t"")
    file.write(""timestamp\t"")
    file.write(""epoch\t"")
    file.write(""step\t"")
    file.write(""train_accuracy\t"")
    file.write(""predict_labels\t"")
    file.write(""actual_labels\n"")
    file.close()
    
    file = open(log_dir +""training_result"" + "".log"",""w"")
    file.write(""timestamp\t"")
    file.write(""epoch\t"")
    file.write(""valid accuracy\n"")
    file.close()
            
    # Generate save model path
    save_model_dir = save_model_root_dir + job_id + ""/"" + product_id + ""/""
    if not os.path.exists(save_model_dir):
        os.makedirs(save_model_dir)
        
    return log_dir, save_model_dir

def main(argv):
    # Need the user to provide system argv for job_id and product_id, it is prepared for frontend calling
    if len(argv) < 2 or len(argv) > 3:
        print(""ERROR: Format error, refer to the usage: python test.py job_id product_id"")
    elif not argv[1].isdigit():
        print(""ERROR: Format error, job_id must be in int format"")
    elif not argv[1].isalnum():
        print(""ERROR: Format error, product_id must be consistent by character or number, without special character"")
    else:
        print(""INFO: Start training model "" + datetime.datetime.now().strftime(""%Y%m%d%H%M%S"")) 
        # GPU settings
        gpus = tf.config.list_physical_devices(""GPU"")
        if gpus:
            for gpu in gpus:
                tf.config.experimental.set_memory_growth(gpu, True)

        # Folder generate for log file and model saving
        log_dir, save_model_dir = folder_preparation(argv[1], argv[2])                
             
        # get the dataset
        train_dataset, valid_dataset, test_dataset, train_count, valid_count, test_count = generate_datasets()

        # create model
        model = get_model()
        print_model_summary(network=model)
    
        # Setup target for validation dataset accuracy, only when the valid_accuracy reachs the threshold the weight can be saved
        threshold = THRESHOLD

        # define loss calculation
        loss_object = tf.keras.losses.SparseCategoricalCrossentropy()
    
        # Tried RMSprop for optimizer, the result is not so good, finetune the optimizer to Adam or Momentum
        #optimizer = tf.keras.optimizers.RMSprop(learning_rate = GLOBAL_LEARNING_RATE,
        #                                        momentum = MOMENTUM,
        #                                        name = 'rms_optimizer')
        optimizer = tf.keras.optimizers.Adam(lr = GLOBAL_LEARNING_RATE, decay = WEIGHT_DECAY, name = 'adam_optimizer')

        # Define training KPI
        train_loss = tf.keras.metrics.Mean(name='train_loss')
        train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')

        # Define valid KPI
        valid_loss = tf.keras.metrics.Mean(name='valid_loss')
        valid_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='valid_accuracy')

        # @tf.function
        def train(image_batch, label_batch):
            with tf.GradientTape() as tape:
                predictions = model(image_batch, training=True)
                loss = loss_object(y_true=label_batch, y_pred=predictions)
            gradients = tape.gradient(loss, model.trainable_variables)
            optimizer.apply_gradients(grads_and_vars=zip(gradients, model.trainable_variables))

            train_loss.update_state(values=loss)
            train_accuracy.update_state(y_true=label_batch, y_pred=predictions)
        
            return predictions.numpy(), tf.math.argmax(predictions, axis =1).numpy()

        # @tf.function
        def valid(image_batch, label_batch):
            predictions = model(image_batch, training=True)
            v_loss = loss_object(label_batch, predictions)

            valid_loss.update_state(values=v_loss)
            valid_accuracy.update_state(y_true=label_batch, y_pred=predictions)
        
            return tf.math.argmax(predictions, axis =1).numpy()

        # start training
        for epoch in range(EPOCHS):
            train_step = 0
            #valid_step = 0
            for features in train_dataset:
                train_step += 1
                images, labels = process_features(features, data_augmentation=False)
                predictions, predict_labels = train(images, labels)
                
                # Print the info on the screen for developer to monitor training detail
                print(""Epoch: {}/{}, step: {}/{}, loss: {:.5f}, accuracy: {:.5f}, softmax(logits):{}, ""
                      ""predict_label:{}, target_label:{}"".format(epoch,
                                                                EPOCHS,
                                                                train_step,
                                                                math.ceil(train_count / BATCH_SIZE),
                                                                train_loss.result().numpy(),
                                                                train_accuracy.result().numpy(),
                                                                predictions,
                                                                predict_labels,
                                                                labels))
                
                # Record information into the log file
                file = open(log_dir +""training_result_step"" + "".log"", ""a"")
                file.write(""train\t"")
                file.write(datetime.datetime.now().strftime(""%Y%m%d%H%M%S"") + ""\t"")
                file.write(str(epoch) + ""\t"")
                file.write(str(train_step) + ""\t"")
                file.write(str(train_accuracy.result().numpy()) + ""\t"")
                file.write(str(predict_labels) + ""\t"")
                file.write(str(labels) + ""\n"")
                file.close()

            for features in valid_dataset:
                #valid_step += 1
                valid_images, valid_labels = process_features(features, data_augmentation=False)
                predict_labels = valid(valid_images, valid_labels)
                
                #file = open(log_dir +""training_result_step"" + "".log"", ""a"")
                #file.write(""validation\t"")
                #file.write(datetime.datetime.now().strftime(""%Y%m%d%H%M%S"") + ""\t"")
                #file.write(str(epoch) + ""\t"")
                #file.write(str(valid_step) + ""\t"")
                #file.write(str(valid_accuracy.result().numpy()) + ""\t"")
                #file.write(str(predict_labels) + ""\t"")
                #file.write(str(labels) + ""\n"")
                #file.close()
                
            # Print the info on the screen for developer to monitor validation result
            print(""Epoch: {}/{}, train loss: {:.5f}, train accuracy: {:.5f}, ""
                  ""valid loss: {:.5f}, valid accuracy: {:.5f}"".format(epoch,
                                                                      EPOCHS,
                                                                      train_loss.result().numpy(),
                                                                      train_accuracy.result().numpy(),
                                                                      valid_loss.result().numpy(),
                                                                      valid_accuracy.result().numpy()))
            # Create log file in txt format, easy for pandas to analysis and for best model selection
            file = open(log_dir +""training_result"" + "".log"",""a"")
            file.write(datetime.datetime.now().strftime(""%Y%m%d%H%M%S"") + ""\t"")
            file.write(str(epoch) + ""\t"")
            file.write(str(valid_accuracy.result().numpy()) + ""\n"")
            file.close()
            
            valid_accuracy_result = valid_accuracy.result().numpy()
        
            train_loss.reset_states()
            train_accuracy.reset_states()
            valid_loss.reset_states()
            valid_accuracy.reset_states()
            
            # Save the weights for evaluation and prediction only when the valid accuracy is higher than threshold and best ever result
            if valid_accuracy_result >= threshold:
                #model.save_weights(filepath=save_model_dir + str(epoch) + ""/model"", save_format='tf')
                model.save_weights(filepath=save_model_dir+""model"", save_format='tf')
                # model._set_inputs(inputs=tf.random.normal(shape=(1, IMAGE_HEIGHT, IMAGE_WIDTH, CHANNELS)))
                # tf.keras.models.save_model(model, save_model_dir + str(epoch), save_format='tf')
                
                # Threshold update
                threshold = valid_accuracy_result
            
        # save the whole model
        # tf.saved_model.save(model, save_model_dir)

        # convert to tensorflow lite format
        # model._set_inputs(inputs=tf.random.normal(shape=(1, IMAGE_HEIGHT, IMAGE_WIDTH, CHANNELS)))
        # converter = tf.lite.TFLiteConverter.from_keras_model(model)
        # tflite_model = converter.convert()
        # open(""converted_model.tflite"", ""wb"").write(tflite_model)
    

if __name__ == '__main__':
    main(sys.argv)
    

`

Model Definition
`import tensorflow as tf
from models.inception_modules import Stem, ReductionA, BasicConv2D, Conv2DLinear
from configuration import NUM_CLASSES, DROPOUT_RATIO, L1_REGULIZER, L2_REGULIZER


class InceptionResNetA(tf.keras.layers.Layer):
    def __init__(self):
        super(InceptionResNetA, self).__init__()
        self.b1_conv = BasicConv2D(filters=32,
                                   kernel_size=(1, 1),
                                   strides=1,
                                   padding=""same"")
        self.b2_conv1 = BasicConv2D(filters=32,
                                    kernel_size=(1, 1),
                                    strides=1,
                                    padding=""same"")
        self.b2_conv2 = BasicConv2D(filters=32,
                                    kernel_size=(3, 3),
                                    strides=1,
                                    padding=""same"")
        self.b3_conv1 = BasicConv2D(filters=32,
                                    kernel_size=(1, 1),
                                    strides=1,
                                    padding=""same"")
        self.b3_conv2 = BasicConv2D(filters=48,
                                    kernel_size=(3, 3),
                                    strides=1,
                                    padding=""same"")
        self.b3_conv3 = BasicConv2D(filters=64,
                                    kernel_size=(3, 3),
                                    strides=1,
                                    padding=""same"")
        self.conv = Conv2DLinear(filters=384,
                                 kernel_size=(1, 1),
                                 strides=1,
                                 padding=""same"")

    def call(self, inputs, training=None, **kwargs):
        b1 = self.b1_conv(inputs, training=training)
        b2 = self.b2_conv1(inputs, training=training)
        b2 = self.b2_conv2(b2, training=training)
        b3 = self.b3_conv1(inputs, training=training)
        b3 = self.b3_conv2(b3, training=training)
        b3 = self.b3_conv3(b3, training=training)

        x = tf.concat(values=[b1, b2, b3], axis=-1)
        x = self.conv(x, training=training)

        output = tf.keras.layers.add([x, inputs])
        return tf.nn.relu(output)


class InceptionResNetB(tf.keras.layers.Layer):
    def __init__(self):
        super(InceptionResNetB, self).__init__()
        self.b1_conv = BasicConv2D(filters=192,
                                   kernel_size=(1, 1),
                                   strides=1,
                                   padding=""same"")
        self.b2_conv1 = BasicConv2D(filters=128,
                                    kernel_size=(1, 1),
                                    strides=1,
                                    padding=""same"")
        self.b2_conv2 = BasicConv2D(filters=160,
                                    kernel_size=(1, 7),
                                    strides=1,
                                    padding=""same"")
        self.b2_conv3 = BasicConv2D(filters=192,
                                    kernel_size=(7, 1),
                                    strides=1,
                                    padding=""same"")
        self.conv = Conv2DLinear(filters=1152,
                                 kernel_size=(1, 1),
                                 strides=1,
                                 padding=""same"")

    def call(self, inputs, training=None, **kwargs):
        b1 = self.b1_conv(inputs, training=training)
        b2 = self.b2_conv1(inputs, training=training)
        b2 = self.b2_conv2(b2, training=training)
        b2 = self.b2_conv3(b2, training=training)

        x = tf.concat(values=[b1, b2], axis=-1)
        x = self.conv(x, training=training)

        output = tf.keras.layers.add([x, inputs])

        return tf.nn.relu(output)


class InceptionResNetC(tf.keras.layers.Layer):
    def __init__(self):
        super(InceptionResNetC, self).__init__()
        self.b1_conv = BasicConv2D(filters=192,
                                   kernel_size=(1, 1),
                                   strides=1,
                                   padding=""same"")
        self.b2_conv1 = BasicConv2D(filters=192,
                                    kernel_size=(1, 1),
                                    strides=1,
                                    padding=""same"")
        self.b2_conv2 = BasicConv2D(filters=224,
                                    kernel_size=(1, 3),
                                    strides=1,
                                    padding=""same"")
        self.b2_conv3 = BasicConv2D(filters=256,
                                    kernel_size=(3, 1),
                                    strides=1,
                                    padding=""same"")
        self.conv = Conv2DLinear(filters=2144,
                                 kernel_size=(1, 1),
                                 strides=1,
                                 padding=""same"")

    def call(self, inputs, training=None, **kwargs):
        b1 = self.b1_conv(inputs, training=training)
        b2 = self.b2_conv1(inputs, training=training)
        b2 = self.b2_conv2(b2, training=training)
        b2 = self.b2_conv3(b2, training=training)

        x = tf.concat(values=[b1, b2], axis=-1)
        x = self.conv(x, training=training)

        output = tf.keras.layers.add([x, inputs])

        return tf.nn.relu(output)


class ReductionB(tf.keras.layers.Layer):
    def __init__(self):
        super(ReductionB, self).__init__()
        self.b1_maxpool = tf.keras.layers.MaxPool2D(pool_size=(3, 3),
                                                    strides=2,
                                                    padding=""valid"")
        self.b2_conv1 = BasicConv2D(filters=256,
                                    kernel_size=(1, 1),
                                    strides=1,
                                    padding=""same"")
        self.b2_conv2 = BasicConv2D(filters=384,
                                    kernel_size=(3, 3),
                                    strides=2,
                                    padding=""valid"")
        self.b3_conv1 = BasicConv2D(filters=256,
                                    kernel_size=(1, 1),
                                    strides=1,
                                    padding=""same"")
        self.b3_conv2 = BasicConv2D(filters=288,
                                    kernel_size=(3, 3),
                                    strides=2,
                                    padding=""valid"")
        self.b4_conv1 = BasicConv2D(filters=256,
                                    kernel_size=(1, 1),
                                    strides=1,
                                    padding=""same"")
        self.b4_conv2 = BasicConv2D(filters=288,
                                    kernel_size=(3, 3),
                                    strides=1,
                                    padding=""same"")
        self.b4_conv3 = BasicConv2D(filters=320,
                                    kernel_size=(3, 3),
                                    strides=2,
                                    padding=""valid"")

    def call(self, inputs, training=None, **kwargs):
        b1 = self.b1_maxpool(inputs)

        b2 = self.b2_conv1(inputs, training=training)
        b2 = self.b2_conv2(b2, training=training)

        b3 = self.b3_conv1(inputs, training=training)
        b3 = self.b3_conv2(b3, training=training)

        b4 = self.b4_conv1(inputs, training=training)
        b4 = self.b4_conv2(b4, training=training)
        b4 = self.b4_conv3(b4, training=training)

        return tf.concat(values=[b1, b2, b3, b4], axis=-1)


def build_inception_resnet_a(n):
    block = tf.keras.Sequential()
    for _ in range(n):
        block.add(InceptionResNetA())
    return block


def build_inception_resnet_b(n):
    block = tf.keras.Sequential()
    for _ in range(n):
        block.add(InceptionResNetB())
    return block


def build_inception_resnet_c(n):
    block = tf.keras.Sequential()
    for _ in range(n):
        block.add(InceptionResNetC())
    return block


class InceptionResNetV2(tf.keras.Model):
    def __init__(self):
        super(InceptionResNetV2, self).__init__()
        self.stem = Stem()
        self.inception_resnet_a = build_inception_resnet_a(5)
        self.reduction_a = ReductionA(k=256, l=256, m=384, n=384)
        self.inception_resnet_b = build_inception_resnet_b(10)
        self.reduction_b = ReductionB()
        self.inception_resnet_c = build_inception_resnet_c(5)
        self.avgpool = tf.keras.layers.AveragePooling2D(pool_size=(8, 8))
        self.dropout = tf.keras.layers.Dropout(rate=DROPOUT_RATIO)
        self.flat = tf.keras.layers.Flatten()
        self.fc = tf.keras.layers.Dense(units=NUM_CLASSES,
                                        activation=tf.keras.activations.softmax,
                                        kernel_regularizer=tf.keras.regularizers.l1(L1_REGULIZER),
                                        activity_regularizer=tf.keras.regularizers.l2(L2_REGULIZER)
                                       )

    def call(self, inputs, training=None, mask=None):
        x = self.stem(inputs, training=training)
        x = self.inception_resnet_a(x, training=training)
        x = self.reduction_a(x, training=training)
        x = self.inception_resnet_b(x, training=training)
        x = self.reduction_b(x, training=training)
        x = self.inception_resnet_c(x, training=training)
        x = self.avgpool(x)
        x = self.dropout(x, training=training)
        x = self.flat(x)
        x = self.fc(x)

        return x`"
38416,tf.keras: Model parameters suddenly updated to 'nan' during back propagation when training,"**System information** 
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):  Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: 
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.1.0
- Python version: 3.7.4
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source): 
- CUDA/cuDNN version: 10.1/7.6.5
- GPU model and memory: Nvidia 1080Ti

**Describe the current behavior**
I was trying to train a small net similar to PNet of MTCNN and I wrote a custom loss to test if it is working. During the training, after several epochs the model weights and loss became 'nan'. 
I test the training procedure one epoch by one and found that the last epoch that gives a normal loss (0.0814), also outputs a model with all parameters of 'nan'. Thus I think when giving a normal loss, the backward propagation has something wrong and gives the model a 'nan' update.

What I have done to rule out some other possibilities:
(1) Check & clean the data: 
My data set is:
X: images of shape (12, 12, 3);
Y: label, box regression coords & 6-landmark regression coords concatenated together of shape (17, ).
For the label, it could be 1, -1, 0, -2 where only labels 1 and 0 will participate in calculating the custom loss I wrote myself.
For the roi & landmark coords, they all belong to [-1, 1].
For the image data, it will be processed as: (x - 127.5) / 128. before being sent into the training stream. 
I tried both the TFRecords dataflow & numpy array as the input for training.

(2) Add BatchNormalization layer, add L2-Norm to the weights, use Xavier initialization and pick a smaller learning rate (from 0.001 to 0.0001) to avoid problems like gradient exploding. 

(3) Replace the custom loss I wrote myself with 'mse'.

All the three changes made did not fix the 'nan' loss thing.

**Describe the expected behavior**
The training procedure should work well.

**Standalone code to reproduce the issue** 
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.
```
def pnet_train1(train_with_landmark = False):
    
    X = Input(shape = (12, 12, 3), name = 'Pnet_input')
    
    M = Conv2D(10, 3, strides = 1, padding = 'valid', kernel_initializer = glorot_normal, kernel_regularizer = l2(0.00001), name = 'Pnet_conv1')(X)
    M = PReLU(shared_axes = [1, 2], name = 'Pnet_prelu1')(M)
    M = MaxPooling2D(pool_size = 2, name = 'Pnet_maxpool1')(M) # default 'pool_size' is 2!!! 
    
    M = Conv2D(16, 3, strides = 1, padding = 'valid', kernel_initializer = glorot_normal, kernel_regularizer = l2(0.00001), name = 'Pnet_conv2')(M)
    M = PReLU(shared_axes= [1, 2], name = 'Pnet_prelu2')(M)
    
    M = Conv2D(32, 3, strides = 1, padding = 'valid', kernel_initializer = glorot_normal, kernel_regularizer = l2(0.00001), name = 'Pnet_conv3')(M)
    M = PReLU(shared_axes= [1, 2], name = 'Pnet_prelu3')(M)
    
    Classifier_conv = Conv2D(1, 1, activation = 'sigmoid', name = 'Pnet_classifier_conv', kernel_initializer = glorot_normal)(M)
    Bbox_regressor_conv = Conv2D(4, 1, name = 'Pnet_bbox_regressor_conv', kernel_initializer = glorot_normal)(M)
    Landmark_regressor_conv = Conv2D(12, 1, name = 'Pnet_landmark_regressor_conv', kernel_initializer = glorot_normal)(M)
    
    Classifier = Reshape((1, ), name = 'Pnet_classifier')(Classifier_conv)
    Bbox_regressor = Reshape((4, ), name = 'Pnet_bbox_regressor')(Bbox_regressor_conv) 
    if train_with_landmark: 
        Landmark_regressor = Reshape((12, ), name = 'Pnet_landmark_regressor')(Landmark_regressor_conv)
        Pnet_output = Concatenate()([Classifier, Bbox_regressor, Landmark_regressor]) 
        model = Model(X, Pnet_output) 
    else:
        Pnet_output = Concatenate()([Classifier, Bbox_regressor])
        model = Model(X, Pnet_output)
    
    return model

def pnet_train2(train_with_landmark = False):

    X = Input(shape = (12, 12, 3), name = 'Pnet_input')

    M = Conv2D(10, 3, strides = 1, padding = 'valid', use_bias = False, kernel_initializer = glorot_normal, kernel_regularizer = l2(0.00001), name = 'Pnet_conv1')(X)
    M = BatchNormalization(axis = -1, name = 'Pnet_bn1')(M)
    M = PReLU(shared_axes = [1, 2], name = 'Pnet_prelu1')(M)
    M = MaxPooling2D(pool_size = 2, name = 'Pnet_maxpool1')(M) # default 'pool_size' is 2!!! 

    M = Conv2D(16, 3, strides = 1, padding = 'valid', use_bias = False, kernel_initializer = glorot_normal, kernel_regularizer = l2(0.00001), name = 'Pnet_conv2')(M)
    M = BatchNormalization(axis = -1, name = 'Pnet_bn2')(M)
    M = PReLU(shared_axes= [1, 2], name = 'Pnet_prelu2')(M)

    M = Conv2D(32, 3, strides = 1, padding = 'valid', use_bias = False, kernel_initializer = glorot_normal, kernel_regularizer = l2(0.00001), name = 'Pnet_conv3')(M)
    M = BatchNormalization(axis = -1, name = 'Pnet_bn3')(M)
    M = PReLU(shared_axes= [1, 2], name = 'Pnet_prelu3')(M)

    Classifier_conv = Conv2D(1, 1, activation = 'sigmoid', name = 'Pnet_classifier_conv', kernel_initializer = glorot_normal)(M)
    Bbox_regressor_conv = Conv2D(4, 1, name = 'Pnet_bbox_regressor_conv', kernel_initializer = glorot_normal)(M)
    Landmark_regressor_conv = Conv2D(12, 1, name = 'Pnet_landmark_regressor_conv', kernel_initializer = glorot_normal)(M)

    Classifier = Reshape((1, ), name = 'Pnet_classifier')(Classifier_conv)
    Bbox_regressor = Reshape((4, ), name = 'Pnet_bbox_regressor')(Bbox_regressor_conv) 
    if train_with_landmark: 
        Landmark_regressor = Reshape((12, ), name = 'Pnet_landmark_regressor')(Landmark_regressor_conv)
        Pnet_output = Concatenate()([Classifier, Bbox_regressor, Landmark_regressor]) 
        model = Model(X, Pnet_output) 
    else:
        Pnet_output = Concatenate()([Classifier, Bbox_regressor])
        model = Model(X, Pnet_output)

    return model

# Here just check the the first classify loss. 
def custom_loss(y_true, y_pred):
        
    zero_index = K.zeros_like(y_true[:, 0]) 
    ones_index = K.ones_like(y_true[:, 0]) 
    
    labels = y_true[:, 0] 
    class_preds = y_pred[:, 0] 
    bi_crossentropy_loss = -labels * K.log(class_preds) - (1 - labels) * K.log(1 - class_preds) 
    
    classify_valid_index = tf.where(K.less(y_true[:, 0], 0), zero_index, ones_index) 
    classify_keep_num = K.cast(tf.cast(tf.reduce_sum(classify_valid_index), tf.float32) * 0.7, dtype = tf.int32) 
    
    classify_loss_sum = bi_crossentropy_loss * tf.cast(classify_valid_index, bi_crossentropy_loss.dtype) 
    classify_loss_sum_filtered, _ = tf.nn.top_k(classify_loss_sum, k = classify_keep_num) 
    classify_loss = tf.where(K.equal(classify_keep_num, 0), tf.constant(0, dtype = tf.float32), K.mean(classify_loss_sum_filtered)) 
    
    loss = classify_loss 
    
    return loss
```

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

![1](https://user-images.githubusercontent.com/31966022/78958654-4d557100-7b1b-11ea-8f5b-52406fb76111.png)"
38415,"In v2.1.0, conversion of ""tensorflow.python.framework.ops.Tensor"" to array ","I have used **tf.nn.softmax_cross_entropy_with_logits(logits,labels)** , which as an output gives a tensor of type ""tensorflow.python.framework.ops.Tensor"". 
I need to convert it into numpy array which by any means i am not able to do.
I have even tried to create tf.Session() but that to not working in this case.
Please help me out in it. 
 
"
38414,Resource exhausted:  MemoryError: Unable to allocate,"Hi, I'm getting a `ResourceExhaustedError` in the middle of a training and I'm assuming that shouldn't be possible. I.e., either it happens in the very first iteration, showing me my GPU doesn't have enough memory to train my model or it works until the end.
In my case, it ran fine for 46 epochs (batch size = 8, image size = (720, 1280)), then I got the error.
I'm running the code from a Jupyter notebook.

Any help is appreciated, thank you.

**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow): Yes

- OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04): Windows 10

- TensorFlow installed from (source or
binary): intalled from pip inside Anaconda environment

- TensorFlow version (use command below): 2.2.0-dev20200401

- Python version: 3.7.6

- CUDA/cuDNN version:
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2019 NVIDIA Corporation
Built on Sun_Jul_28_19:12:52_Pacific_Daylight_Time_2019
Cuda compilation tools, release 10.1, V10.1.243

- GPU model and memory: GeForce RTX 2080 Ti

**Describe the current behavior**
Getting a `ResourceExhaustedError` in the middle of the training (46 epochs in).

**Describe the expected behavior**
Expected to finish the training normally, or not work from the very first epoch.

**Standalone code to reproduce the issue** 
Since it's not that small, I'm attaching a file.
Feel free to update my report with the code inline if more appropriate.
[minimal_breaking_code.txt](https://github.com/tensorflow/tensorflow/files/4477650/minimal_breaking_code.txt)

Those are the entry variables:
![2020-04-14 17_33_59-Window](https://user-images.githubusercontent.com/764094/79271798-c8e65380-7e76-11ea-8c4f-1986d62e935b.png)

Also, the images are 1080x1920.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

---------------------------------------------------------------------------
ResourceExhaustedError                    Traceback (most recent call last)
C:/Users/Gamer/Dropbox/Projetos/MLPython/Imports.py in <module>
     31             'balanced_training_data': False,
     32             'data_augmentation': True,
---> 33             'training_data_samples': None
     34         }
     35     }

~\Dropbox\Projetos\Ecotrace\NewImages\Model.py in run_experiment(data_path, images_data_path, training_data, balanced_training_data, validation_data, parameters)
    338             keras.callbacks.ModelCheckpoint(filepath = last_model_filepath, save_best_only = True),
    339             keras.callbacks.ModelCheckpoint(filepath = best_model_filepath, save_best_only = True),
--> 340             keras.callbacks.CSVLogger(experiment_folder + '/history.csv')
    341         ]
    342     )

~\Anaconda3\envs\TensorFlow-nightly\lib\site-packages\tensorflow\python\keras\engine\training.py in _method_wrapper(self, *args, **kwargs)
     69   def _method_wrapper(self, *args, **kwargs):
     70     if not self._in_multi_worker_mode():  # pylint: disable=protected-access
---> 71       return method(self, *args, **kwargs)
     72 
     73     # Running inside `run_distribute_coordinator` already.

~\Anaconda3\envs\TensorFlow-nightly\lib\site-packages\tensorflow\python\keras\engine\training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)
    940               workers=workers,
    941               use_multiprocessing=use_multiprocessing,
--> 942               return_dict=True)
    943           val_logs = {'val_' + name: val for name, val in val_logs.items()}
    944           epoch_logs.update(val_logs)

~\Anaconda3\envs\TensorFlow-nightly\lib\site-packages\tensorflow\python\keras\engine\training.py in _method_wrapper(self, *args, **kwargs)
     69   def _method_wrapper(self, *args, **kwargs):
     70     if not self._in_multi_worker_mode():  # pylint: disable=protected-access
---> 71       return method(self, *args, **kwargs)
     72 
     73     # Running inside `run_distribute_coordinator` already.

~\Anaconda3\envs\TensorFlow-nightly\lib\site-packages\tensorflow\python\keras\engine\training.py in evaluate(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)
   1171             with trace.Trace('TraceContext', graph_type='test', step_num=step):
   1172               callbacks.on_test_batch_begin(step)
-> 1173               tmp_logs = test_function(iterator)
   1174               if data_handler.should_sync:
   1175                 context.async_wait()

~\Anaconda3\envs\TensorFlow-nightly\lib\site-packages\tensorflow\python\eager\def_function.py in __call__(self, *args, **kwds)
    606         xla_context.Exit()
    607     else:
--> 608       result = self._call(*args, **kwds)
    609 
    610     if tracing_count == self._get_tracing_count():

~\Anaconda3\envs\TensorFlow-nightly\lib\site-packages\tensorflow\python\eager\def_function.py in _call(self, *args, **kwds)
    644       # In this case we have not created variables on the first call. So we can
    645       # run the first trace but we should fail if variables are created.
--> 646       results = self._stateful_fn(*args, **kwds)
    647       if self._created_variables:
    648         raise ValueError(""Creating variables on a non-first call to a function""

~\Anaconda3\envs\TensorFlow-nightly\lib\site-packages\tensorflow\python\eager\function.py in __call__(self, *args, **kwargs)
   2418     with self._lock:
   2419       graph_function, args, kwargs = self._maybe_define_function(args, kwargs)
-> 2420     return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access
   2421 
   2422   @property

~\Anaconda3\envs\TensorFlow-nightly\lib\site-packages\tensorflow\python\eager\function.py in _filtered_call(self, args, kwargs)
   1663          if isinstance(t, (ops.Tensor,
   1664                            resource_variable_ops.BaseResourceVariable))),
-> 1665         self.captured_inputs)
   1666 
   1667   def _call_flat(self, args, captured_inputs, cancellation_manager=None):

~\Anaconda3\envs\TensorFlow-nightly\lib\site-packages\tensorflow\python\eager\function.py in _call_flat(self, args, captured_inputs, cancellation_manager)
   1744       # No tape is watching; skip to running the function.
   1745       return self._build_call_outputs(self._inference_function.call(
-> 1746           ctx, args, cancellation_manager=cancellation_manager))
   1747     forward_backward = self._select_forward_and_backward_functions(
   1748         args,

~\Anaconda3\envs\TensorFlow-nightly\lib\site-packages\tensorflow\python\eager\function.py in call(self, ctx, args, cancellation_manager)
    596               inputs=args,
    597               attrs=attrs,
--> 598               ctx=ctx)
    599         else:
    600           outputs = execute.execute_with_cancellation(

~\Anaconda3\envs\TensorFlow-nightly\lib\site-packages\tensorflow\python\eager\execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)
     58     ctx.ensure_initialized()
     59     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
---> 60                                         inputs, attrs, num_outputs)
     61   except core._NotOkStatusException as e:
     62     if name is not None:

ResourceExhaustedError: 2 root error(s) found.
  (0) Resource exhausted:  MemoryError: Unable to allocate 10.5 MiB for an array with shape (720, 1280, 3) and data type float32
Traceback (most recent call last):

  File ""C:\Users\Gamer\Anaconda3\envs\TensorFlow-nightly\lib\site-packages\tensorflow\python\ops\script_ops.py"", line 243, in __call__
    ret = func(*args)

  File ""C:\Users\Gamer\Anaconda3\envs\TensorFlow-nightly\lib\site-packages\tensorflow\python\autograph\impl\api.py"", line 309, in wrapper
    return func(*args, **kwargs)

  File ""C:\Users\Gamer\Anaconda3\envs\TensorFlow-nightly\lib\site-packages\tensorflow\python\data\ops\dataset_ops.py"", line 784, in generator_py_func
    values = next(generator_state.get_iterator(iterator_id))

  File ""C:\Users\Gamer\Anaconda3\envs\TensorFlow-nightly\lib\site-packages\tensorflow\python\keras\engine\data_adapter.py"", line 816, in wrapped_generator
    for data in generator_fn():

  File ""C:\Users\Gamer\Anaconda3\envs\TensorFlow-nightly\lib\site-packages\tensorflow\python\keras\utils\data_utils.py"", line 1022, in get
    six.reraise(*sys.exc_info())

  File ""C:\Users\Gamer\AppData\Roaming\Python\Python37\site-packages\six.py"", line 693, in reraise
    raise value

  File ""C:\Users\Gamer\Anaconda3\envs\TensorFlow-nightly\lib\site-packages\tensorflow\python\keras\utils\data_utils.py"", line 998, in get
    inputs = self.queue.get(block=True).get()

  File ""C:\Users\Gamer\Anaconda3\envs\TensorFlow-nightly\lib\multiprocessing\pool.py"", line 657, in get
    raise self._value

  File ""C:\Users\Gamer\Anaconda3\envs\TensorFlow-nightly\lib\multiprocessing\pool.py"", line 121, in worker
    result = (True, func(*args, **kwds))

  File ""C:\Users\Gamer\Anaconda3\envs\TensorFlow-nightly\lib\site-packages\tensorflow\python\keras\utils\data_utils.py"", line 932, in next_sample
    return six.next(_SHARED_SEQUENCES[uid])

  File ""C:\Users\Gamer\Anaconda3\envs\TensorFlow-nightly\lib\site-packages\keras_preprocessing\image\iterator.py"", line 104, in __next__
    return self.next(*args, **kwargs)

  File ""C:\Users\Gamer\Anaconda3\envs\TensorFlow-nightly\lib\site-packages\keras_preprocessing\image\iterator.py"", line 116, in next
    return self._get_batches_of_transformed_samples(index_array)

  File ""C:\Users\Gamer\Anaconda3\envs\TensorFlow-nightly\lib\site-packages\keras_preprocessing\image\iterator.py"", line 231, in _get_batches_of_transformed_samples
    x = img_to_array(img, data_format=self.data_format)

  File ""C:\Users\Gamer\Anaconda3\envs\TensorFlow-nightly\lib\site-packages\keras_preprocessing\image\utils.py"", line 299, in img_to_array
    x = np.asarray(img, dtype=dtype)

  File ""C:\Users\Gamer\Anaconda3\envs\TensorFlow-nightly\lib\site-packages\numpy\core\_asarray.py"", line 85, in asarray
    return array(a, dtype, copy=False, order=order)

MemoryError: Unable to allocate 10.5 MiB for an array with shape (720, 1280, 3) and data type float32


	 [[{{node PyFunc}}]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.

	 [[IteratorGetNext]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.

  (1) Resource exhausted:  MemoryError: Unable to allocate 10.5 MiB for an array with shape (720, 1280, 3) and data type float32
Traceback (most recent call last):

  File ""C:\Users\Gamer\Anaconda3\envs\TensorFlow-nightly\lib\site-packages\tensorflow\python\ops\script_ops.py"", line 243, in __call__
    ret = func(*args)

  File ""C:\Users\Gamer\Anaconda3\envs\TensorFlow-nightly\lib\site-packages\tensorflow\python\autograph\impl\api.py"", line 309, in wrapper
    return func(*args, **kwargs)

  File ""C:\Users\Gamer\Anaconda3\envs\TensorFlow-nightly\lib\site-packages\tensorflow\python\data\ops\dataset_ops.py"", line 784, in generator_py_func
    values = next(generator_state.get_iterator(iterator_id))

  File ""C:\Users\Gamer\Anaconda3\envs\TensorFlow-nightly\lib\site-packages\tensorflow\python\keras\engine\data_adapter.py"", line 816, in wrapped_generator
    for data in generator_fn():

  File ""C:\Users\Gamer\Anaconda3\envs\TensorFlow-nightly\lib\site-packages\tensorflow\python\keras\utils\data_utils.py"", line 1022, in get
    six.reraise(*sys.exc_info())

  File ""C:\Users\Gamer\AppData\Roaming\Python\Python37\site-packages\six.py"", line 693, in reraise
    raise value

  File ""C:\Users\Gamer\Anaconda3\envs\TensorFlow-nightly\lib\site-packages\tensorflow\python\keras\utils\data_utils.py"", line 998, in get
    inputs = self.queue.get(block=True).get()

  File ""C:\Users\Gamer\Anaconda3\envs\TensorFlow-nightly\lib\multiprocessing\pool.py"", line 657, in get
    raise self._value

  File ""C:\Users\Gamer\Anaconda3\envs\TensorFlow-nightly\lib\multiprocessing\pool.py"", line 121, in worker
    result = (True, func(*args, **kwds))

  File ""C:\Users\Gamer\Anaconda3\envs\TensorFlow-nightly\lib\site-packages\tensorflow\python\keras\utils\data_utils.py"", line 932, in next_sample
    return six.next(_SHARED_SEQUENCES[uid])

  File ""C:\Users\Gamer\Anaconda3\envs\TensorFlow-nightly\lib\site-packages\keras_preprocessing\image\iterator.py"", line 104, in __next__
    return self.next(*args, **kwargs)

  File ""C:\Users\Gamer\Anaconda3\envs\TensorFlow-nightly\lib\site-packages\keras_preprocessing\image\iterator.py"", line 116, in next
    return self._get_batches_of_transformed_samples(index_array)

  File ""C:\Users\Gamer\Anaconda3\envs\TensorFlow-nightly\lib\site-packages\keras_preprocessing\image\iterator.py"", line 231, in _get_batches_of_transformed_samples
    x = img_to_array(img, data_format=self.data_format)

  File ""C:\Users\Gamer\Anaconda3\envs\TensorFlow-nightly\lib\site-packages\keras_preprocessing\image\utils.py"", line 299, in img_to_array
    x = np.asarray(img, dtype=dtype)

  File ""C:\Users\Gamer\Anaconda3\envs\TensorFlow-nightly\lib\site-packages\numpy\core\_asarray.py"", line 85, in asarray
    return array(a, dtype, copy=False, order=order)

MemoryError: Unable to allocate 10.5 MiB for an array with shape (720, 1280, 3) and data type float32


	 [[{{node PyFunc}}]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.

	 [[IteratorGetNext]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.

	 [[IteratorGetNext/_4]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.

0 successful operations.
0 derived errors ignored. [Op:__inference_test_function_16419]

Function call stack:
test_function -> test_function
"
38413,r2.1 windows libtensorflow build failed,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows10 (1909) x64
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: None
- TensorFlow installed from (source or binary): Source
- TensorFlow version: r2.1
- Python version: 3.6.8
- Installed using virtualenv? pip? conda?: pip
- Bazel version (if compiling from source): 0.29.1
- GCC/Compiler version (if compiling from source): MSVC 2019 Build Tool
- CUDA/cuDNN version: None
- GPU model and memory: None



**Describe the problem**

I can't build tensorflow r2.1 as libtensorflow.
When I build source code it always failed with ProtoCompile ERROR. (Exit -1073741795)

**Provide the exact sequence of commands / steps that you executed before running into the problem**

First, installed msys and MSVC 2019 build tool. (Described in https://tensorflow.google.cn/install/source_windows)

And then, run bazel with following command.
.\bazel.exe build --config=opt //tensorflow/tools/lib_package:libtensorflow

**Build Error**
ERROR: D:/work/tensorflow/source/tensorflow/tensorflow/core/BUILD:2045:1: ProtoCompile tensorflow/core/protobuf/autotuning.pb.h failed (Exit -1073741795)
Target //tensorflow/tools/lib_package:libtensorflow failed to build
INFO: Elapsed time: 6.115s, Critical Path: 3.44s
INFO: 2 processes: 2 local.
FAILED: Build did NOT complete successfully"
38412,shape_invariants in tf.while_loop,"**System information** 
OS Platform and Distribution : macOS Catalina 10.15.3

TensorFlow installed from : binary

TensorFlow version : 1.15.2

Python version: 3.7.3

So basically i have 
`matrix = tf.constant([[[16,15,16,15,87],[3,4,3,4,87]],[[ 3,4,3,41,87],[0,0,0,0,0]]]) `

`b = tf.constant([[[1],[2]],[[1],[1]]])`

I want to 

I want vector c such that

[ 16 15 16 15 87] is repeated [1] times ,
[ 3 4 3 4 87] is repeated [2] times ,
[ 3 4 14 95 87] is repeated [2] times,
[ 3 7 9 250 87] is repated [2] times and so on ............

I am writing following code 

`import tensorflow as tf`

`tf.enable_eager_execution()`

`def repeatOperation2(t1,t2):`
  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`xShape = tf.shape(t1)[0]`
    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`reshaped  = tf.reshape(t1, [1, xShape])`
    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`repeat = tf.repeat(reshaped, repeats=t2, axis=0)`
    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`ta = tf.TensorArray(dtype=tf.int32, size=1)`
    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`ta.write(0, repeat)`
    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`ta_final_result = ta.stack()`
    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`return ta_final_result`

`def repeatOperation1(t1,t2):`
   &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`matrix_rows = tf.shape(t1)[0]`
    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`ta = tf.TensorArray(dtype=tf.int32, size=10)`
    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`i0 = tf.constant(0)`
    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`init_state = (i0, ta)`
    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`condition = lambda i, _: i < matrix_rows`
    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`body = lambda i, ta: (i + 1, ta.write(i, repeatOperation2(t1[i,:],t2[i,:])))`
    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`n, ta_final = tf.while_loop(condition, body,init_state,shape_invariants=[i0.get_shape(), tf.TensorShape((None,None,5))])`
    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`ta_final_result = ta_final.stack()`
    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;`return ta_final_result`


`matrix = tf.constant([[[16,15,16,15,87],[3,4,3,4,87]],[[ 3,4,3,41,87],[0,0,0,0,0]]]) `
`b = tf.constant([[[1],[2]],[[1],[1]]])`

`matrix_rows = tf.shape(matrix)[0]`
`ta = tf.TensorArray(dtype=tf.int32, size=matrix_rows)`
`init_state = (0, ta)`
`condition = lambda i, _: i < matrix_rows`
`body = lambda i, ta: (i + 1, ta.write(i, repeatOperation1(matrix[i,:,:],b[i,:,:])))`
`n, ta_final = tf.while_loop(condition, body, init_state)`
`ta_final_result = ta_final.stack()`
`print(ta_final_result)`



basically for each iteration multiplication i am using `shape_invariants=[i0.get_shape(), tf.TensorShape((None,None,5))])` since repeating matrix tensor equal to b tensor the number in first two dimension changes  but i am getting below error 

Error:

Traceback (most recent call last):
  File ""tf_2.py"", line 52, in <module>
    n, ta_final = tf.while_loop(condition, body, init_state)
  File ""<path>/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/control_flow_ops.py"", line 2714, in while_loop
    loop_vars = body(*loop_vars)
  File ""tf_2.py"", line 51, in <lambda>
    body = lambda i, ta: (i + 1, ta.write(i, repeatOperation1(matrix[i,:,:],b[i,:,:])))
  File ""tf_2.py"", line 37, in repeatOperation1
    n, ta_final = tf.while_loop(condition, body, init_state,shape_invariants=[i0.get_shape(), tf.TensorShape((None,None,5))])
  File ""<path>/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/control_flow_ops.py"", line 2714, in while_loop
    loop_vars = body(*loop_vars)
  File ""tf_2.py"", line 36, in <lambda>
    body = lambda i, ta: (i + 1, ta.write(i, repeatOperation2(t1[i,:],t2[i,:])))
  File ""<path>/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/tensor_array_ops.py"", line 1084, in write
    return self._implementation.write(index, value, name=name)
  File ""<path>/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/tensor_array_ops.py"", line 815, in write
    self._write(index, value)
  File ""<path>/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/tensor_array_ops.py"", line 805, in _write
    (value.shape, self._element_shape))
ValueError: Incompatible shape for value ((1, 2, 5)), expected ((1, 1, 5))"
38411,Tensorflow-gpu not interacting with gpu after fresh install,"
**System information**
- Windows 10
- pip install
- TensorFlow-gpu==1.15.2
-python 3.7.6
- using conda and trying to run through spyder and ubuntu for windows
- Bazel version (if compiling from source): idk
- GCC/Compiler version (if compiling from source): idk
- CUDA/cuDNN version: cuda 10.1 cuDNN 7.6.5 driver 436.3
- GPU model and memory: geforce 1660 ti

tensorflow can't see my gpu's I just need it to see it. I am trying to run magenta with gpu and I have been travelling in circles. I did have tensorflow working with gpu support and now I have messed with it too much that it must be broken. I have done a full uninstall of conda and then installed it all again. 
nvcc works and nvidia-smi works so I have it. But it isn't showing up in tensorflow-gpu. 

from running:
import tensorflow as tf
from tensorflow.python.client import device_lib
print(device_lib.list_local_devices())
print(tf.test.is_gpu_available(
    cuda_only=False,
    min_cuda_compute_capability=None
))

import tensorflow as tf
print(tf.test.gpu_device_name())

[name: ""/device:CPU:0""
device_type: ""CPU""
memory_limit: 268435456
locality {
}
incarnation: 172585563774038155
]
False

+-----------------------------------------------------------------------------+
| NVIDIA-SMI 436.30       Driver Version: 436.30       CUDA Version: 10.1     |
|-------------------------------+----------------------+----------------------+
| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  GeForce GTX 166... WDDM  | 00000000:01:00.0 Off |                  N/A |
| N/A   56C    P0    24W /  N/A |    614MiB /  6144MiB |      6%      Default |
+-------------------------------+----------------------+----------------------+

"
38409,Tensorflow Datasets with string inputs do not preserve data type,"All **reproducible** code below is run at **Google Colab** with **TF 2.2.0-rc2**.

Adapting the simple example from the [documentation][1] for creating a dataset from a simple Python list:

    import numpy as np
    import tensorflow as tf
    tf.__version__
    # '2.2.0-rc2'
    np.version.version
    # '1.18.2'

    dataset1 = tf.data.Dataset.from_tensor_slices([1, 2, 3]) 
    for element in dataset1: 
      print(element) 
      print(type(element.numpy()))

we get the result

    tf.Tensor(1, shape=(), dtype=int32)
    <class 'numpy.int32'>
    tf.Tensor(2, shape=(), dtype=int32)
    <class 'numpy.int32'>
    tf.Tensor(3, shape=(), dtype=int32)
    <class 'numpy.int32'>

where all data types are `int32`, as expected.

But changing this simple example to feed a list of strings instead of integers:

    dataset2 = tf.data.Dataset.from_tensor_slices(['1', '2', '3']) 
    for element in dataset2: 
      print(element) 
      print(type(element.numpy()))

gives the result

    tf.Tensor(b'1', shape=(), dtype=string)
    <class 'bytes'>
    tf.Tensor(b'2', shape=(), dtype=string)
    <class 'bytes'>
    tf.Tensor(b'3', shape=(), dtype=string)
    <class 'bytes'>

where, surprisingly, and despite the tensors themselves being of `dtype=string`, their evaluations are of type `bytes`.

This behavior is not confined to the `.from_tensor_slices` method; here is the situation with [`.list_files`][2] (the following snippet runs straightforward in a fresh Colab notebook):

    disc_data = tf.data.Dataset.list_files('sample_data/*.csv') # 4 csv files
    for element in disc_data: 
      print(element) 
      print(type(element.numpy()))

the result being:

    tf.Tensor(b'sample_data/california_housing_test.csv', shape=(), dtype=string)
    <class 'bytes'>
    tf.Tensor(b'sample_data/mnist_train_small.csv', shape=(), dtype=string)
    <class 'bytes'>
    tf.Tensor(b'sample_data/california_housing_train.csv', shape=(), dtype=string)
    <class 'bytes'>
    tf.Tensor(b'sample_data/mnist_test.csv', shape=(), dtype=string)
    <class 'bytes'>

where again, the file names in the evaluated tensors are returned as `bytes`, instead of `string`, despite that the tensors themselves are of `dtype=string`.

Similar behavior is observed also with the `.from_generator` method (not shown here).

A final demonstration: as shown in the `.as_numpy_iterator` method [documentation][3], the following equality condition is evaluated as `True`:

    dataset3 = tf.data.Dataset.from_tensor_slices({'a': ([1, 2], [3, 4]), 
                                                   'b': [5, 6]}) 

    list(dataset3.as_numpy_iterator()) == [{'a': (1, 3), 'b': 5}, 
                                           {'a': (2, 4), 'b': 6}] 
    # True

but if we change the elements of `b` to be strings, the equality condition is now surprisingly evaluated as `False`!

    dataset4 = tf.data.Dataset.from_tensor_slices({'a': ([1, 2], [3, 4]), 
                                                   'b': ['5', '6']})   # change elements of b to strings
    
    list(dataset4.as_numpy_iterator()) == [{'a': (1, 3), 'b': '5'},   # here
                                           {'a': (2, 4), 'b': '6'}]   # also
    # False

probably due to the different data types, since the values themselves are evidently identical.

---

I didn't stumble upon this behavior by academic experimentation; I am trying to pass my data to TF Datasets using custom functions that read pairs of files from the disk of the form

    f = ['filename1', 'filename2']

which custom functions work perfectly well on their own, but mapped through TF Datasets give

    RuntimeError: not a string

which, after this digging, seems at least not unexplained, if the returned data types are indeed `bytes` and not `string`.

So, is this a bug (as it seems), or am I missing something here?



  [1]: https://www.tensorflow.org/api_docs/python/tf/data/Dataset
  [2]: https://www.tensorflow.org/api_docs/python/tf/data/Dataset#list_files
  [3]: https://www.tensorflow.org/api_docs/python/tf/data/Dataset#as_numpy_iterator"
38404,CollectiveBcastRecv error for Tensorflow 2.0 Distributed training with MultiWorkerMirrored strategy using estimator API ,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04): Red Hat Enterprise Linux Server release 7.4 (Maipo)
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if
the issue happens on mobile device: 
- TensorFlow installed from (source or
binary): - TensorFlow version (use command below): 2.0
- Python version: 3.7 - Bazel 
version (if compiling from source): 0.26.1
- GCC/Compiler version (if compiling from
source): GCC 7.3.1
- CUDA/cuDNN version: - GPU model and memory: 10.1

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
I'm migrating a model for TF 1.14 to TF 2. I used the tf_upgrade_v2 script to change the model.  The upgraded model used `tf.compat.v1.get_variable()`  and and ` tf.compat.v1.train.AdagradOptimizer()`. It successfully ran on TF 2.0 using parameter server strategy. We used the estimator api for the distributed training. But when I changed the strategy to multi-worker mirrored strategy, it didn't work for me. There is some issue with Adagrad Initializer. Please see the error below. Are those calls compatible (`tf.compat.v1.get_variable()`  and tf.compat.v1.train.AdagradOptimize()) with multi-worker mirrored strategy using estimator API?
**Describe the expected behavior**
It should work by changing the strategy to multi-worker mirrored strategy in estimator RunConfig.

**Standalone code to reproduce the issue** 
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
API calls:

x = tf.compat.v1.get_variable(
                    name=x,
                    initializer=tf.random.truncated_normal([tensor_len, num_classes],
                                                           stddev=1.0 / math.sqrt(float(tensor_len))),
                    regularizer=tf.keras.regularizers.l2(l2_reg_weight)

 optimizer = tf.compat.v1.train.AdagradOptimizer(0.01)


Error Log:

2020-04-09 01:57:51.499271: W tensorflow/core/framework/op_kernel.cc:1622] OP_REQUIRES failed at collective_ops.cc:365 : Internal: RecvBufResponse returned 2408 bytes where to_tensor expected 8082020-04-09 01:57:51.499305: W tensorflow/core/framework/op_kernel.cc:1622] OP_REQUIRES failed at collective_ops.cc:365 : Internal: RecvBufResponse returned 808 bytes where to_tensor expected 24082020-04-09 01:57:51.499272: W tensorflow/core/framework/op_kernel.cc:1622] OP_REQUIRES failed at collective_ops.cc:365 : Internal: RecvBufResponse returned 2408 bytes where to_tensor expected 8082020-04-09 01:57:51.499371: W tensorflow/core/framework/op_kernel.cc:1622] OP_REQUIRES failed at collective_ops.cc:365 : Internal: RecvBufResponse returned 808 bytes where to_tensor expected 24082020-04-09 01:57:51.499365: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Internal: RecvBufResponse returned 2408 bytes where to_tensor expected 808	 [[{{node memberFeatures_geoRegion_weights/Adagrad/Initializer/CollectiveBcastRecv}}]]2020-04-09 01:57:51.500466: W tensorflow/core/framework/op_kernel.cc:1622] OP_REQUIRES failed at collective_ops.cc:365 : Cancelled: [_Derived_]CancelledAdditional GRPC error information:{""created"":""@1586397471.499604492"",""description"":""Error received from peer"",""file"":""external/grpc/src/core/lib/surface/call.cc"",""file_line"":1039,""grpc_message"":""Cancelled"",""grpc_status"":1}2020-04-09 01:57:51.501131: W tensorflow/core/framework/op_kernel.cc:1622] OP_REQUIRES failed at collective_ops.cc:365 : Internal: [_Derived_]RecvBufResponse returned 2408 bytes where to_tensor expected 808	 [[{{node memberFeatures_geoRegion_weights/Adagrad/Initializer/CollectiveBcastRecv}}]]2020-04-09 01:57:51.501135: W tensorflow/core/framework/op_kernel.cc:1622] OP_REQUIRES failed at collective_ops.cc:365 : Internal: [_Derived_]RecvBufResponse returned 2408 bytes where to_tensor expected 808	 [[{{node memberFeatures_geoRegion_weights/Adagrad/Initializer/CollectiveBcastRecv}}]]2020-04-09 01:57:51.501170: W tensorflow/core/framework/op_kernel.cc:1622] OP_REQUIRES failed at collective_ops.cc:365 : Internal: [_Derived_]RecvBufResponse returned 2408 bytes where to_tensor expected 808	 [[{{node memberFeatures_geoRegion_weights/Adagrad/Initializer/CollectiveBcastRecv}}]]2020-04-09 01:57:51.501175: W tensorflow/core/framework/op_kernel.cc:1622] OP_REQUIRES failed at collective_ops.cc:365 : Internal: [_Derived_]RecvBufResponse returned 2408 bytes where to_tensor expected 808	 [[{{node memberFeatures_geoRegion_weights/Adagrad/Initializer/CollectiveBcastRecv}}]]2020-04-09 01:57:51.501192: W tensorflow/core/framework/op_kernel.cc:1622] OP_REQUIRES failed at collective_ops.cc:365 : Internal: [_Derived_]RecvBufResponse returned 2408 bytes where to_tensor expected 808	 [[{{node memberFeatures_geoRegion_weights/Adagrad/Initializer/CollectiveBcastRecv}}]]2020-04-09 01:57:51.501223: W tensorflow/core/framework/op_kernel.cc:1622] OP_REQUIRES failed at collective_ops.cc:365 : Internal: [_Derived_]RecvBufResponse returned 2408 bytes where to_tensor expected 808	 [[{{node memberFeatures_geoRegion_weights/Adagrad/Initializer/CollectiveBcastRecv}}]]Traceback (most recent call last): File ""<>/site-packages/tensorflow_core/python/client/session.py"", line 1365, in _do_call return fn(*args) File ""<>/site-packages/tensorflow_core/python/client/session.py"", line 1350, in _run_fn target_list, run_metadata) File ""<>/site-packages/tensorflow_core/python/client/session.py"", line 1443, in _call_tf_sessionrun run_metadata)tensorflow.python.framework.errors_impl.InternalError: From /job:worker/replica:0/task:1:RecvBufResponse returned 2408 bytes where to_tensor expected 808	 [[{{node memberFeatures_geoRegion_weights/Adagrad/Initializer/CollectiveBcastRecv}}]]During handling of the above exception, another exception occurred:

"
