Issue Number,Issue Title,Issue Body
36936,Does passing 'training' flag to tf.keras.Sequential do anything?,"## URL(s) with the issue:
https://www.tensorflow.org/tutorials/customization/custom_training_walkthrough#define_the_loss_and_gradient_function

Please provide a link to the documentation entry, for example:
https://www.tensorflow.org/api_docs/python/tf/keras/Sequential

https://www.tensorflow.org/api_docs/python/tf/keras/Model
## Description of issue (what needs changing):
It is unclear whether the Sequential class makes use a 'training' flag fed into it during training/inference, as the tutorial above implies. 

### Clear description
When building a custom model subclassing from tf.keras.Model, the standard signature for writing the `call` is as follows: `def call(self, inputs, training=None, mask=None):`

If my class includes submodels of the form Sequential, I am able to pass this flag forward but I'm unaware whether it's doing anything, as documentation from the class doesn't mention this flag.
Looking at the customization tutorial above, however, the flag is passed into a Sequential model that does not include layers whose behavior change during training/inference. So I don't know if that flag is doing anything.

### Correct links

Is the link to the source code correct?

### Parameters defined

Are all parameters defined and formatted correctly?

### Returns defined

Are return values defined?

### Raises listed and defined

Are the errors defined? For example,
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises

### Usage example

Is there a usage example?

See the API guide: https://www.tensorflow.org/community/contribute/docs_ref
on how to write testable usage examples.

### Request visuals, if applicable

Are there currently visuals? If not, will it clarify the content?

### Submit a pull request?

Are you planning to also submit a pull request to fix the issue? See the docs
contributor guide: https://www.tensorflow.org/community/contribute/docs,
docs API guide: https://www.tensorflow.org/community/contribute/docs_ref and the
docs style guide: https://www.tensorflow.org/community/contribute/docs_style
"
36935,"DepthwiseConv1D: implementation, check and warning message","**System information** 
- Have I written custom code:
- OS Platform and Distribution: Windows 10 Enterprise 1803 (build 17134.1246)
- TensorFlow backend: yes
- TensorFlow version: 2.0.0
- Keras version: '2.2.4-tf' (called from tensorflow.keras)
- Python version: 3.7
- CUDA/cuDNN version: -
- GPU model and memory: -

For a project I'm working on, I needed a Depthwise Convolutional Layer 1D.
Unfortunately, keras at the moment does not include this layer (despite including `Conv1D`, `SeparableConv1D` and `DepthwiseConv2D`). Merging the codes of these three layers, I developed a version of `DepthwiseConv1D` that you can see below.

1. I think that keras should have this layer available in its standard library since `DepthwiseConv` is the only convolutional layer missing a 1D version. I'm quite sure of what I did, but I don't know keras code well enough to guarantee this to be 100% bug-free. How can I check this and would someone help me making a pull request with this code?

2. When using this layer I get the following warning:
```
WARNING:tensorflow:Entity <bound method DepthwiseConv1D.call of <__main__.DepthwiseConv1D object at 0x0000028580FB0D08>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: 
WARNING: Entity <bound method DepthwiseConv1D.call of <__main__.DepthwiseConv1D object at 0x0000028580FB0D08>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause:
```
looking at #32377 and #32319, but I already have `gast` 0.2.2 installed. Should I be concerned? Does ""will be executed as-is"" means that the layer won't be trained?

3.  `SeparableConv1D` at lines [1681-1684](https://github.com/tensorflow/tensorflow/blob/v2.1.0/tensorflow/python/keras/layers/convolutional.py#L1555-L1702) does
```
    if self.data_format == 'channels_last':
      strides = (1,) + self.strides + (1,)
    else:
      strides = (1, 1) + self.strides
```
since `self.strides` is a 2-elements tuple, this cause `strides` to be a 4-elements tuple. This was causing me an error in `nn.separable_conv2d` so I changed this to simply `strides = self.strides*2` (note that in a 1D conv, `strides` is a 1-element tuple).
Was this a bug in `SeparableConv1D`? Or is there a reason for this? Or what I did is wrong?

```
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

from tensorflow.python.framework import tensor_shape
from tensorflow.python.keras import backend
from tensorflow.python.keras import constraints
from tensorflow.python.keras import initializers
from tensorflow.python.keras import regularizers
from tensorflow.python.keras.engine.input_spec import InputSpec
from tensorflow.python.keras.layers.convolutional import Conv1D
# imports for backwards namespace compatibility
# pylint: disable=unused-import
# pylint: enable=unused-import
from tensorflow.python.keras.utils import conv_utils
from tensorflow.python.keras.utils import tf_utils
from tensorflow.python.ops import array_ops
from tensorflow.python.util.tf_export import keras_export


@keras_export('keras.layers.DepthwiseConv1D')
class DepthwiseConv1D(Conv1D):
  """"""Depthwise separable 1D convolution.
  Depthwise Separable convolutions consist of performing
  just the first step in a depthwise spatial convolution
  (which acts on each input channel separately).
  The `depth_multiplier` argument controls how many
  output channels are generated per input channel in the depthwise step.
  Arguments:
    kernel_size: A single integer specifying the spatial
      dimensions of the filters.
    strides: A single integer specifying the strides
      of the convolution.
      Specifying any `stride` value != 1 is incompatible with specifying
      any `dilation_rate` value != 1.
    padding: one of `'valid'` or `'same'` (case-insensitive).
    depth_multiplier: The number of depthwise convolution output channels
      for each input channel.
      The total number of depthwise convolution output
      channels will be equal to `filters_in * depth_multiplier`.
    data_format: A string,
      one of `channels_last` (default) or `channels_first`.
      The ordering of the dimensions in the inputs.
      `channels_last` corresponds to inputs with shape
      `(batch, length, channels)` while `channels_first`
      corresponds to inputs with shape
      `(batch, channels, length)`.
      The default is 'channels_last'.
    activation: Activation function to use.
      If you don't specify anything, no activation is applied
      (ie. 'linear' activation: `a(x) = x`).
    use_bias: Boolean, whether the layer uses a bias vector.
    depthwise_initializer: Initializer for the depthwise kernel matrix.
    bias_initializer: Initializer for the bias vector.
    depthwise_regularizer: Regularizer function applied to
      the depthwise kernel matrix.
    bias_regularizer: Regularizer function applied to the bias vector.
    activity_regularizer: Regularizer function applied to
      the output of the layer (its 'activation').
    depthwise_constraint: Constraint function applied to
      the depthwise kernel matrix.
    bias_constraint: Constraint function applied to the bias vector.
  Input shape:
    3D tensor with shape:
    `[batch, channels, length]` if data_format='channels_first'
    or 4D tensor with shape:
    `[batch, length, channels]` if data_format='channels_last'.
  Output shape:
    3D tensor with shape:
    `[batch, filters, new_length]` if data_format='channels_first'
    or 3D tensor with shape:
    `[batch, new_length, filters]` if data_format='channels_last'.
    `length` values might have changed due to padding.
  """"""

  def __init__(self,
               kernel_size,
               strides=1,
               padding='valid',
               depth_multiplier=1,
               data_format=None,
               activation=None,
               use_bias=True,
               depthwise_initializer='glorot_uniform',
               bias_initializer='zeros',
               depthwise_regularizer=None,
               bias_regularizer=None,
               activity_regularizer=None,
               depthwise_constraint=None,
               bias_constraint=None,
               **kwargs):
    super(DepthwiseConv1D, self).__init__(
        filters=None,
        kernel_size=kernel_size,
        strides=strides,
        padding=padding,
        data_format=data_format,
        activation=activation,
        use_bias=use_bias,
        bias_regularizer=bias_regularizer,
        activity_regularizer=activity_regularizer,
        bias_constraint=bias_constraint,
        # autocast=False,
        **kwargs)
    self.depth_multiplier = depth_multiplier
    self.depthwise_initializer = initializers.get(depthwise_initializer)
    self.depthwise_regularizer = regularizers.get(depthwise_regularizer)
    self.depthwise_constraint = constraints.get(depthwise_constraint)
    self.bias_initializer = initializers.get(bias_initializer)

  def build(self, input_shape):
    if len(input_shape) < 3:
      raise ValueError('Inputs to `DepthwiseConv1D` should have rank 3. '
                       'Received input shape:', str(input_shape))
    input_shape = tensor_shape.TensorShape(input_shape)

    #TODO(pj1989): replace with channel_axis = self._get_channel_axis()
    if self.data_format == 'channels_last':
        channel_axis = -1
    elif self.data_format == 'channels_first':
        channel_axis = 1

    if input_shape.dims[channel_axis].value is None:
      raise ValueError('The channel dimension of the inputs to '
                       '`DepthwiseConv1D` '
                       'should be defined. Found `None`.')
    input_dim = int(input_shape[channel_axis])
    depthwise_kernel_shape = (self.kernel_size[0],
                              input_dim,
                              self.depth_multiplier)

    self.depthwise_kernel = self.add_weight(
        shape=depthwise_kernel_shape,
        initializer=self.depthwise_initializer,
        name='depthwise_kernel',
        regularizer=self.depthwise_regularizer,
        constraint=self.depthwise_constraint)

    if self.use_bias:
      self.bias = self.add_weight(shape=(input_dim * self.depth_multiplier,),
                                  initializer=self.bias_initializer,
                                  name='bias',
                                  regularizer=self.bias_regularizer,
                                  constraint=self.bias_constraint)
    else:
      self.bias = None
    # Set input spec.
    self.input_spec = InputSpec(ndim=3, axes={channel_axis: input_dim})
    self.built = True

  def call(self, inputs):
    if self.padding == 'causal':
      inputs = array_ops.pad(inputs, self._compute_causal_padding())
    if self.data_format == 'channels_last':
      spatial_start_dim = 1
    else:
      spatial_start_dim = 2

    # Explicitly broadcast inputs and kernels to 4D.
    # TODO(fchollet): refactor when a native depthwise_conv2d op is available.
    strides = self.strides * 2
    inputs = array_ops.expand_dims(inputs, spatial_start_dim)
    depthwise_kernel = array_ops.expand_dims(self.depthwise_kernel, 0)
    dilation_rate = (1,) + self.dilation_rate

    outputs = backend.depthwise_conv2d(
        inputs,
        depthwise_kernel,
        strides=strides,
        padding=self.padding,
        dilation_rate=dilation_rate,
        data_format=self.data_format)

    if self.use_bias:
      outputs = backend.bias_add(
          outputs,
          self.bias,
          data_format=self.data_format)

    outputs = array_ops.squeeze(outputs, [spatial_start_dim])

    if self.activation is not None:
      return self.activation(outputs)

    return outputs

  @tf_utils.shape_type_conversion
  def compute_output_shape(self, input_shape):
    if self.data_format == 'channels_first':
      length = input_shape[2]
      out_filters = input_shape[1] * self.depth_multiplier
    elif self.data_format == 'channels_last':
      length = input_shape[1]
      out_filters = input_shape[2] * self.depth_multiplier

    length = conv_utils.conv_output_length(length, self.kernel_size,
                                           self.padding,
                                           self.strides)
    if self.data_format == 'channels_first':
      return (input_shape[0], out_filters, length)
    elif self.data_format == 'channels_last':
      return (input_shape[0], length, out_filters)

  def get_config(self):
    config = super(DepthwiseConv1D, self).get_config()
    config.pop('filters')
    config.pop('kernel_initializer')
    config.pop('kernel_regularizer')
    config.pop('kernel_constraint')
    config['depth_multiplier'] = self.depth_multiplier
    config['depthwise_initializer'] = initializers.serialize(
        self.depthwise_initializer)
    config['depthwise_regularizer'] = regularizers.serialize(
        self.depthwise_regularizer)
    config['depthwise_constraint'] = constraints.serialize(
        self.depthwise_constraint)
    return config
```
"
36934,For loop variable 'tensor_value' is not used in the loop body,"Hello, I'm curious about this. The for loop I mentioned is using variable `tensor_values`, but the variable `tensor_value` is never be used in the loop itself. Is it necessary?

https://github.com/tensorflow/tensorflow/blob/aadf705c858014a168d1a582accc81b7cc774d68/tensorflow/python/debug/lib/dumping_callback_test.py#L1131-L1136"
36933,API break between TF2.0.0 and TF2.1.0 on simple Keras code,"- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS 10.13.6
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): v2.1.0-rc2-17-ge5bf8de410 2.1.0
- Python version: v3.6.7:6ec5cf24b7, Oct 20 2018, 03:02:14

**Describe the current behavior**
I have written a piece of code to answer [this stackoverflow question](https://stackoverflow.com/questions/48309322/keras-multiply-layer-in-functional-api) (the code of `make_model`), and it worked well with tf2.0.0. But today I tested it coincidentally on tf2.1.0 and it raised an error. From the error message, the root cause seems to be that I didn't provide a `name` argument on my `tf.keras.Input` calls.

Note that the second piece of code that I wrote in my stackoverflow answer, `make_model_2`, works with both tf2.0.0 and tf2.1.0.

**Describe the expected behavior**
There shouldn't be any backward incompatibility between tf2.1.0 and tf2.0.0.

**Standalone code to reproduce the issue** 
```
import tensorflow as tf

print(tf.version.VERSION)

toy_data = {'movie': [[0], [1], [0], [1]], 'user': [[10], [12], [12], [10]]}
dataset = tf.data.Dataset.from_tensor_slices(toy_data).batch(2)

for x in dataset:
    print(x)

def make_model():
    inp_movie = tf.keras.Input(shape=(1,))
    inp_user = tf.keras.Input(shape=(1,))
    movie_embedding = tf.keras.layers.Dense(
            units=40, activation=tf.keras.layers.Activation(""relu""))(inp_movie)
    user_embedding = tf.keras.layers.Dense(
            units=40, activation=tf.keras.layers.Activation(""relu""))(inp_user)
    combined = tf.concat([movie_embedding, user_embedding], 1)
    output = tf.keras.layers.Dense(
            units=1, activation=tf.keras.layers.Activation(""sigmoid""))(combined)
    model = tf.keras.Model(inputs=[inp_movie, inp_user], outputs=output)
    return model

model = make_model()

for x in dataset:
    print(model(x))
```

**Other info / logs** 
```
---------------------------------------------------------------------------
KeyError                                  Traceback (most recent call last)
<ipython-input-1-cf28ddc4e239> in <module>
     25 
     26 for x in dataset:
---> 27     print(model(x))

~/path/to/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py in __call__(self, inputs, *args, **kwargs)
    820           with base_layer_utils.autocast_context_manager(
    821               self._compute_dtype):
--> 822             outputs = self.call(cast_inputs, *args, **kwargs)
    823           self._handle_activity_regularization(inputs, outputs)
    824           self._set_mask_metadata(inputs, outputs, input_masks)

~/path/to/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py in call(self, inputs, training, mask)
    715     return self._run_internal_graph(
    716         inputs, training=training, mask=mask,
--> 717         convert_kwargs_to_constants=base_layer_utils.call_context().saving)
    718 
    719   def compute_output_shape(self, input_shape):

~/path/to/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py in _run_internal_graph(self, inputs, training, mask, convert_kwargs_to_constants)
    820       # list. Matches dict keys to input names.
    821       inputs = [
--> 822           inputs[inp._keras_history.layer.name] for inp in self._nested_inputs
    823       ]
    824     else:

~/path/to/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py in <listcomp>(.0)
    820       # list. Matches dict keys to input names.
    821       inputs = [
--> 822           inputs[inp._keras_history.layer.name] for inp in self._nested_inputs
    823       ]
    824     else:

KeyError: 'input_1'
```"
36932,"Issue while using ""drop_remainder=True"" on validation set with TPU","**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow): Yes
- Tensorflow version: `2.1.0`

About hardware and software system information I'm using Kaggle kernels so more information can be found here: https://github.com/Kaggle/docker-python

**Describe the current behavior**
I'm getting errors like the ones below, when I use the argument `drop_remainder=True` on the `dataset.batch()` function, but this happens only with the validation set:
![tpu erros](https://user-images.githubusercontent.com/16668746/74946458-18a92100-53d8-11ea-85ad-d9a2aaa1d0bc.PNG)

The issue was further discussed in [this thread on the Kaggle forum](https://www.kaggle.com/c/flower-classification-with-tpus/discussion/130717)

**Describe the expected behavior**
The model was supposed to train normally like when I don't use the `drop_remainder=True` argument.

**Standalone code to reproduce the issue** 
Link for the Kaggle kernel: https://www.kaggle.com/dimitreoliveira/flower-classification-with-tpus-eda-and-baseline

**Other info / logs** 
Here is a quick summary of the experiments:
- [Version 32](https://www.kaggle.com/dimitreoliveira/flower-classification-with-tpus-eda-and-baseline?scriptVersionId=28912464): I've not used `drop_remainder=True` on any set and got no error.
- [Version 33](https://www.kaggle.com/dimitreoliveira/flower-classification-with-tpus-eda-and-baseline?scriptVersionId=28930091): I've used `drop_remainder=True` on train and validation sets and got error.
- [Version 34](https://www.kaggle.com/dimitreoliveira/flower-classification-with-tpus-eda-and-baseline?scriptVersionId=28931447): I've used `drop_remainder=True` only on train and got no error.
- [Version 35](https://www.kaggle.com/dimitreoliveira/flower-classification-with-tpus-eda-and-baseline/notebook?scriptVersionId=28932681): I've used `drop_remainder=True` only on validation and got error.

So it seems the errors are related to using `drop_remainder=True` on the validation set.
"
36931,Bazel build cannot access private member.. windows,"Im trying to build tensorflow from source on windows 10
I cant use pip install tensorflow coz i want to add user_ops in the build.
(Please let me know if that is possible any other way than source build)

------------------------------------------------------------------------

So I'm using these for build:
      Python = 3.7.6
      TF = Currently On Github (2/20/20)
      Bazel = 2.0.0
      MSVC = 14.15.26726 (VS 2017)
      Windows 10
      AMD Ryzen 1700
      CPU Build

During configuration, I selected:
      JIT = Yes
      ROCM = No
      CUDA = No
      Eigen overrides = No

------------------------------------------------------------------------

I get different errors every single time I run this build.
I did follow every single step on the https://www.tensorflow.org/install/source_windows#configure_the_build

Everytime, it says it cant access some private member from some class.
Here I got class ThreadPool, sometimes its TraceMe, sometimes something else I dont remember.
Its different everytime.
This is after 5-10min into build so the entire trace is huge.
I'll just put the ERROR part in here.

HELPPPPPPPPP........ I need user_ops....

```
**ERROR: D:/production/tensorflow-master/tensorflow/compiler/xla/BUILD:411:1: C++ compilation of rule '//tensorflow/compiler/xla:literal' failed (Exit 2)
external/com_google_absl\absl/meta/type_traits.h(121): error C2248: 'tensorflow::thread::ThreadPool::operator =': cannot access private member declared in class 'tensorflow::thread::ThreadPool'**

.\tensorflow/core/platform/threadpool.h(237): note: see declaration of 'tensorflow::thread::ThreadPool::operator ='
.\tensorflow/core/platform/threadpool.h(42): note: see declaration of 'tensorflow::thread::ThreadPool'
external/com_google_absl\absl/meta/type_traits.h(150): note: see reference to class template instantiation 'absl::type_traits_internal::is_detected<absl::type_traits_internal::IsCopyAssignableImpl,T>' being compiled
        with
        [
            T=tensorflow::thread::ThreadPool
        ]
external/com_google_absl\absl/meta/type_traits.h(430): note: see reference to class template instantiation 'absl::is_copy_assignable<T>' being compiled
        with
        [
            T=tensorflow::thread::ThreadPool
        ]

..
..
..

Target //tensorflow/tools/pip_package:build_pip_package failed to build
INFO: Elapsed time: 1058.548s, Critical Path: 969.86s
INFO: 2855 processes: 2855 local.
FAILED: Build did NOT complete successfully
```"
36929,(Solved and Not BUG)No module named 'tensorflow_core.compat' when import tensorflow_datasets in VSCode,"Sorry, I think I should check my code again, this problem may be caused by my mistakenly import other dependent files. Don't spend your precious time on my issue.
The problem is that when I downloaded the .py file from the tensorflow website, the default file name is csv.py which contradicted with other files in packages.

System: Window10 Pro 1909 zh-cn
Python version: 3.7.6
Tensorflow version: 2.1
CUDA version: 10.01
Visual Studio Code version: 1.42.1 with extension of zh-cn

I'm a beginner in Tensorflow studying. And now I'm studying with the tutorial from tensorflow official website, https://www.tensorflow.org/tutorials/load_data/csv.

I tried to test the code from the tutotial above line by line and had a strange phenonmenon at start.

When I tried the order of importing dependent files in the document, I got an error ""No module named 'tensorflow_core.compat' "".

The code ""import_bug.py"": 
import tensorflow
import tensorflow_datasets

The error information:

Failed to import TensorFlow. Please note that TensorFlow is not installed by default when you install TensorFlow Datasets. This is so that users can decide whether to install the GPU-enabled TensorFlow package. To use TensorFlow Datasets, please install the most recent version of TensorFlow, by following instructions at https://tensorflow.org/install.

Traceback (most recent call last):
  File ""~/Tensorflow/import_bug.py"", line 1, in <module>
    import tensorflow
  File ""~\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow\__init__.py"", line 101, in <module>
    from tensorflow_core import *
  File ""~\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow_core\__init__.py"", line 40, in <module>
    from tensorflow.python.tools import module_util as _module_util
  File ""~\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow\__init__.py"", line 50, in __getattr__
    module = self._load()
  File ""~\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow\__init__.py"", line 44, in _load
    module = _importlib.import_module(self.__name__)
  File ""~\AppData\Local\Programs\Python\Python37\lib\importlib\__init__.py"", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""~\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow_core\python\__init__.py"", line 75, in <module>
    from tensorflow.python.framework.framework_lib import *  # pylint: disable=redefined-builtin
  File ""~\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow_core\python\framework\framework_lib.py"", line 25, in <module>
    from tensorflow.python.framework.ops import Graph
  File ""~\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow_core\python\framework\ops.py"", line 41, in <module>
    from tensorflow.python.eager import context
  File ""~\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow_core\python\eager\context.py"", line 25, in <module>
    from absl import logging
  File ""~\AppData\Local\Programs\Python\Python37\lib\site-packages\absl\logging\__init__.py"", line 91, in <module>
    from absl import flags
  File ""~\AppData\Local\Programs\Python\Python37\lib\site-packages\absl\flags\__init__.py"", line 40, in <module>
    from absl.flags import _argument_parser
  File ""~\AppData\Local\Programs\Python\Python37\lib\site-packages\absl\flags\_argument_parser.py"", line 25, in <module>
    import csv
  File ""~\Tensorflow\csv.py"", line 8, in <module>
    import tensorflow_datasets as tfds
  File ""~\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow_datasets\__init__.py"", line 46, in <module>
    from tensorflow_datasets.core import tf_compat
  File ""~\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow_datasets\core\__init__.py"", line 21, in <module>
    tf_compat.ensure_tf_install()
  File ""~\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow_datasets\core\tf_compat.py"", line 46, in ensure_tf_install
    import tensorflow.compat.v2 as tf
  File ""~\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow\__init__.py"", line 50, in __getattr__
    module = self._load()
  File ""~\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow\__init__.py"", line 44, in _load
    module = _importlib.import_module(self.__name__)
  File ""~\AppData\Local\Programs\Python\Python37\lib\importlib\__init__.py"", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
ModuleNotFoundError: No module named 'tensorflow_core.compat'

But interestingly, when I tried the second line code of ""import_bug.py"" only (""import tensorflow_datasets) or the reverse order of the two-line code(""import tensorflow_datasets \n import tensorflow), there was no warning about the error above.

I want to know whether there is some setup mistakes in my computer environment or this is a common problem. I guess there maybe some dated ""import"" statementss in the related packages."
36928,"if GPU available, raise Exception ""Cholesky decomposition was not successful. The input might not be valid"" ,otherwise, in CPU mode, The Official Unittest is ok","**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow):  No
- OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04): Linux Ubuntu 16.04
- TensorFlow installed from (source or
binary):  pip install tensorflow-gpu==1.15.0

[tf_env.txt](https://github.com/tensorflow/tensorflow/files/4230518/tf_env.txt)

```
python -c ""import tensorflow as tf ;print (tf.__version__)""
1.15.0
```
```
python -c ""import tensorflow as tf ;print ( tf.test.gpu_device_name())""  

 Found device 0 with properties: 
name: Tesla V100-SXM2-32GB major: 7 minor: 0 memoryClockRate(GHz): 1.53

Created TensorFlow device (/device:GPU:0 with 30555 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:8a:00.0, compute capability: 7.0)
```

**Describe the current behavior**
```
CUDA_VISIBLE_DEVICES=-1 python gmm_test.py  GMMTest.test_fit
ok!
```
```
CUDA_VISIBLE_DEVICES=0 python gmm_test.py  GMMTest.test_fit

error:Original stack trace for 'Cholesky': 
```

**Describe the expected behavior**
expect  The Official code([gem_test.py](https://github.com/tensorflow/tensorflow/blob/r1.15/tensorflow/contrib/factorization/python/ops/gmm_test.py)) should  pass  the Unit-test in GPU mode
```
CUDA_VISIBLE_DEVICES=0 python gmm_test.py  GMMTest.test_fit
ok!
```
**Standalone code to reproduce the issue** 
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.
```
wget https://raw.githubusercontent.com/tensorflow/tensorflow/r1.15/tensorflow/contrib/factorization/python/ops/gmm_test.py -O ""gmm_test.py""

CUDA_VISIBLE_DEVICES=0 python gmm_test.py  GMMTest.test_fit

```


**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
[python_trace_err.log ](https://github.com/tensorflow/tensorflow/files/4230533/python_trace_err.log), which is python back_trace info
"
36927,Invalid output for MobileNet SSD with Hexagon Delegate and QCS605,"Hi there!

I have been using Tensorflow Lite and Coco SSD MobileNet for some time now in my Android (API 27) application and I decided to add a Hexagon Delegate. There is an unprecedented improvement in prediction time but prediction itself is full of false positives. I am using custom board with QCS605 on it. 

![Prediction without Hexagon delegate](https://user-images.githubusercontent.com/19536019/74928964-d208f600-53da-11ea-8594-ba3ce491402d.png)
Prediction without Hexagon delegate
![Prediction with Hexagon Delegate](https://user-images.githubusercontent.com/19536019/74928969-d59c7d00-53da-11ea-9b63-24623a560ee2.png)
Prediction with Hexagon Delegate

You can notice that with Hexagon Delegate there is the same confidence score for every box and some boxes are invalid (negative coordinates etc...)

The difference between these two interpreters is only in the delegate:
`       

        try {
            HexagonDelegate hexagonDelegate = new HexagonDelegate(c);
            options.addDelegate(hexagonDelegate);
        } catch (UnsupportedOperationException e) {
            Log.e(""TFLITE DELEGATE"", ""Hexagon delegate is not supported on this device"");
        }

         mModel = new Interpreter(ResourceHelper.loadModelFile(c.getAssets(), modelFileName), 

`
I get info ""Hexagon delegate: 61 nodes delegated out of 64 nodes.""
Any suggestions as what might be happening here? At first I thought that maybe my input is invalid but I guess delegate should not have any impact on that.... Difference in prediction time is  huge - 300ms/40ms as for CPU/DSP

I would really appreciate your help :) 

Thank you!


"
36926,"Array Relu, which is an input to the Conv operator producing the output array conv2d_1/BiasAdd, is lacking min/max data, which is necessary for quantization","Hi,
I am facing the following issue while converting my Frozen graph(.pb) to tflite 

Array Relu, which is an input to the Conv operator producing the output array conv2d_1/BiasAdd, is lacking min/max data, which is necessary for quantization. If accuracy matters, either target a non-quantized output format, or run quantized training with your model from a floating point checkpoint to change the input graph to contain min/max information. If you don't care about accuracy, you can pass --default_ranges_min= and --default_ranges_max= for easy experimentation.
Fatal Python error: Aborted

Current thread 0x00007f637125f740 (most recent call first):
  File ""/home/shubhamsingh/miniconda3/lib/python3.7/site-packages/tensorflow/lite/toco/python/toco_from_protos.py"", line 33 in execute
  File ""/home/shubhamsingh/miniconda3/lib/python3.7/site-packages/absl/app.py"", line 250 in _run_main
  File ""/home/shubhamsingh/miniconda3/lib/python3.7/site-packages/absl/app.py"", line 299 in run
  File ""/home/shubhamsingh/miniconda3/lib/python3.7/site-packages/tensorflow/python/platform/app.py"", line 40 in run
  File ""/home/shubhamsingh/miniconda3/lib/python3.7/site-packages/tensorflow/lite/toco/python/toco_from_protos.py"", line 59 in main
  File ""/home/shubhamsingh/miniconda3/bin/toco_from_protos"", line 8 in <module>
Aborted (core dumped)


I have used following script to convert the model
tflite_convert --output_file=mode_new_yoyo1.tflite --graph_def_file=frozen_model.pb --inference_type=QUANTIZED_UINT8 --input_arrays=input_1 --output_arrays=Dense1/Softmax,Dense2/Softmax --mean_values=0 --std_dev_values=255


I have used WideResnet model with two output node."
36925,Import module as -- gives error,"I am experiencing some strange behavior:

```
import tensorflow as tf
from tensorflow import keras
print(tf.__version__)
print(tf.keras.__version__)

from tf.keras.utils import to_categorical
```
gives the following output:

```
2.1.0
2.2.4-tf
---------------------------------------------------------------------------
ModuleNotFoundError                       Traceback (most recent call last)
<ipython-input-12-45d6753a0084> in <module>
      5 print(tf.keras.__version__)
      6 
----> 7 from tf.keras.utils import to_categorical
      8 
      9 one_hot_train_labels = to_categorical(train_labels)

ModuleNotFoundError: No module named 'tf'
```

However, if I changes it to

```from tensorflow.keras.utils import to_categorical```

it works fine. 

With other modules it works fine. For example, no problem with:

```from matplotlib import pyplot
pyplot.plot()```

"
36924,How collect gradients with two and more losses?,"```py
@tf.function
def train(dataset, epochs=5):
    for i in range(epochs):
        dataset = dataset.shuffle(1000)
        for images, boxes, labels in tqdm(dataset, desc='Epoch {} of {}'.format(i + 1, epochs)):
            with tf.GradientTape() as tape:
                localization, classification = model(images, training=True)
                loss_smooth = smooth_l1(boxes, localization)
                loss_focal  = focal(labels, classification)
            gradients = tape.gradient([loss_smooth, loss_focal], model.trainable_variables)
            optimizer.apply_gradients(zip(gradients, model.trainable_variables))
        print('Localization loss: {}, classification loss: {}'.format(loss_smooth, loss_focal))
```
How to can train model with two and more losses? Help?"
36923,how to install tensorflow in python 3.7.2 in 32 bit system,"hi....
 im trying to install tensorflow and keras for my project execution. Im able to install keras. But im unable to install tensorflow. 
can any one please tell me? 
"
36921,tensorflow:AutoGraph could not transform,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information** 
Downloading and preparing dataset imdb_reviews (80.23 MiB) to /root/tensorflow_datasets/imdb_reviews/subwords8k/1.0.0...
Shuffling and writing examples to /root/tensorflow_datasets/imdb_reviews/subwords8k/1.0.0.incomplete7ZTMSY/imdb_reviews-train.tfrecord
Shuffling and writing examples to /root/tensorflow_datasets/imdb_reviews/subwords8k/1.0.0.incomplete7ZTMSY/imdb_reviews-test.tfrecord
Shuffling and writing examples to /root/tensorflow_datasets/imdb_reviews/subwords8k/1.0.0.incomplete7ZTMSY/imdb_reviews-unsupervised.tfrecord
Dataset imdb_reviews downloaded and prepared to /root/tensorflow_datasets/imdb_reviews/subwords8k/1.0.0. Subsequent calls will reuse this data.
WARNING:tensorflow:AutoGraph could not transform <function _get_dataset_from_filename at 0x7f9503308d08> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: module 'gast' has no attribute 'Num'
WARNING:tensorflow:AutoGraph could not transform <function _get_dataset_from_filename at 0x7f9503308d08> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: module 'gast' has no attribute 'Num'
WARNING: AutoGraph could not transform <function _get_dataset_from_filename at 0x7f9503308d08> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: module 'gast' has no attribute 'Num'
WARNING:tensorflow:AutoGraph could not transform <bound method TopLevelFeature.decode_example of FeaturesDict({
    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=2),
    'text': Text(shape=(None,), dtype=tf.int64, encoder=<SubwordTextEncoder vocab_size=8185>),
})> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:AutoGraph could not transform <bound method TopLevelFeature.decode_example of FeaturesDict({
    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=2),
    'text': Text(shape=(None,), dtype=tf.int64, encoder=<SubwordTextEncoder vocab_size=8185>),
})> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: Bad argument number for Name: 3, expecting 4
WARNING: AutoGraph could not transform <bound method TopLevelFeature.decode_example of FeaturesDict({
    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=2),
    'text': Text(shape=(None,), dtype=tf.int64, encoder=<SubwordTextEncoder vocab_size=8185>),
})> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:AutoGraph could not transform <function _get_dataset_from_filename at 0x7f9503308d08> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: module 'gast' has no attribute 'Num'
WARNING:tensorflow:AutoGraph could not transform <function _get_dataset_from_filename at 0x7f9503308d08> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: module 'gast' has no attribute 'Num'
WARNING: AutoGraph could not transform <function _get_dataset_from_filename at 0x7f9503308d08> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: module 'gast' has no attribute 'Num'
WARNING:tensorflow:AutoGraph could not transform <bound method TopLevelFeature.decode_example of FeaturesDict({
    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=2),
    'text': Text(shape=(None,), dtype=tf.int64, encoder=<SubwordTextEncoder vocab_size=8185>),
})> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: Bad argument number for Name: 3, expecting 4
WARNING:tensorflow:AutoGraph could not transform <bound method TopLevelFeature.decode_example of FeaturesDict({
    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=2),
    'text': Text(shape=(None,), dtype=tf.int64, encoder=<SubwordTextEncoder vocab_size=8185>),
})> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: Bad argument number for Name: 3, expecting 4
WARNING: AutoGraph could not transform <bound method TopLevelFeature.decode_example of FeaturesDict({
    'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=2),
    'text': Text(shape=(None,), dtype=tf.int64, encoder=<SubwordTextEncoder vocab_size=8185>),
})> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: Bad argument number for Name: 3, expecting 4"
36919,Memory leak in finalizing GeneratorDataset iterator,"**System information**
- OS Linux Ubuntu 18.04  
- TensorFlow installed from `pipenv install tensorflow~=2.1  
- TensorFlow version 2.1.0
- Python version: 3.6
- CUDA/cuDNN version: 10.1
- GPU model and memory: 2 x (RTX 2080 Ti 11GB) 


**Describe the current behavior**

`tf.keras.preprocessing.image.ImageDataGenerator` output warning message `Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was canceled` when I am using `tf.keras.model.fit(..., worker = 10)` start to train to next epoch. The warning is gone when `worker = 1`. However, the warning does not seem to affect the result. 

In #35100, people tend to mean the warning is superfluous and spurious and the warning has been removed in tf-nightly. But after my usage case, I believe the warning is correct. I have infinite models to be trained one by one (generated by a genetic algorithm). When `tf.keras.model.fit(..., worker = 10)` the error message print out and the memory does not get freed in the next epoch. After training a few models.  All the memory is occupied and the process gets killed. It does not happen when `worker=1` the memory gets freed for each epoch.

I have try tf-nightly, The error message is removed but the memory problem is still there. 

**Describe the expected behavior**
It should free the memory for every epoch. 

**Code to reproduce the issue** 
I prepare my data in the following way.
`samples` is NumPy array with shape (n, 90, 90, 3). n'th image withe 90 by 90 RGB image.
`labels` is NumPy array with shape (n, 2), which is yes and no. [1, 0] is yes and [0, 1] is no.

I have to make a pipenv file, data set and small script for you to demonstrate the memory problem. 
[Download link from google drive](https://drive.google.com/file/d/1oQ1wQkY1ZXimQNBQljlMbNB4VNYjDAp7/view?usp=sharing)
(300 MB)

Unzip the link above and run
`pipenv install`
`pipenv shell`
`python main.py`
Then you see the warning


``` python
train_generator = data_aug.flow(samples, labels, batch_size = 64)
self.model.fit(train_generator, epochs=70, max_queue_size = 64, workers = 10)
```

**Other info / logs**
During these 70 epochs, you can see the memory go up for each epoch and print the error message every time between the epoch. 
"
36918,"Using trademarked word ""TensorFlow"" in the name of a C# binding","My company is developing a proprietary TensorFlow binding for .NET called [Gradient](https://losttech.software/gradient.html). We are considering to rename it to clearly indicate, that it is designed to work with TensorFlow: into `CompanyName.TensorFlow`. I could not find any information if it is OK to use `TensorFlow` as part of the name in such manner. We will correctly only refer to Google as the owner of the trademark as requested in the [Brand Guidelines](https://www.tensorflow.org/extras/tensorflow_brand_guidelines.pdf)."
36917,input_details shape is mismatching when converting Estimator to tflite,"**System information**
- OS Platform and Distribution :Ubuntu 18.04
- TensorFlow installed from : pip
- TensorFlow version : '2.2.0-dev20200218'


**Command used to run the converter or code if you’re using the Python API**
If possible, please share a link to Colab/Jupyter/any notebook.
```python
import pandas as pd
import tensorflow as tf
import numpy as np

dftrain = pd.read_csv('https://storage.googleapis.com/tf-datasets/titanic/train.csv')
dfeval = pd.read_csv('https://storage.googleapis.com/tf-datasets/titanic/eval.csv')
y_train = dftrain.pop('survived')
y_eval = dfeval.pop('survived')

#create feature columns. For testing I am using only numeric ones
NUMERIC_COLUMNS = ['age', 'fare']
feature_columns = []
for feature_name in NUMERIC_COLUMNS:
    feature_columns.append(tf.feature_column.numeric_column(key=feature_name))

# Use entire batch since this is such a small dataset.
NUM_EXAMPLES = len(y_train)

def make_input_fn(X, y, n_epochs=None, shuffle=False):
    def input_fn():
        dataset = tf.data.Dataset.from_tensor_slices((dict(X), y))
        
        if shuffle:
            dataset = dataset.shuffle(NUM_EXAMPLES)
        
        # For training, cycle thru dataset as many times as need (n_epochs=None).
        dataset = dataset.repeat(n_epochs)
        # In memory training doesn't use batching.
        dataset = dataset.batch(NUM_EXAMPLES)
        return dataset
    return input_fn

# Training and evaluation input functions.
train_input_fn = make_input_fn(dftrain[NUMERIC_COLUMNS], y_train)
eval_input_fn = make_input_fn(dfeval[NUMERIC_COLUMNS], y_eval, shuffle=False, n_epochs=1)

linear_est = tf.estimator.LinearClassifier(feature_columns)

# Train model.
linear_est.train(train_input_fn, max_steps=100)

# Evaluation.
result = linear_est.evaluate(eval_input_fn)

serving_input_fn = tf.estimator.export.build_parsing_serving_input_receiver_fn(
  tf.feature_column.make_parse_example_spec(feature_columns))

model_dir = 'model_data'
path = linear_est.export_saved_model(model_dir, serving_input_fn)

saved_model_obj = tf.saved_model.load(export_dir=path)
print(saved_model_obj.signatures.keys())

# Load the specific concrete function from the SavedModel.
concrete_func = saved_model_obj.signatures['serving_default']


# Convert the model to a TFLite model.
converter = tf.lite.TFLiteConverter.from_concrete_functions([concrete_func])
converter.optimizations = [tf.lite.Optimize.DEFAULT]
converter.experimental_new_converter = True
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS,
                               tf.lite.OpsSet.SELECT_TF_OPS]
tflite_model = converter.convert()

open(""converted.tflite"", ""wb"").write(tflite_model)
# Load TFLite model and allocate tensors.
interpreter = tf.lite.Interpreter(model_path=""converted.tflite"")

# Get input and output tensors.
input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()

print(input_details)
```
**Output is**
```
[{'name': 'input_example_tensor',
  'index': 0,
  'shape': array([1], dtype=int32),
  'shape_signature': array([], dtype=int32),
  'dtype': numpy.bytes_,
  'quantization': (0.0, 0),
  'quantization_parameters': {'scales': array([], dtype=float32),
   'zero_points': array([], dtype=int32),
   'quantized_dimension': 0},
  'sparsity_parameters': {}}]
```
why shape is [1] if I am passing 2 feature column to train. And if it is correct, how can I predict the loaded model

"
36916,ValueError: Unable to save the object ListWrapper(...) (a list wrapper constructed to track trackable TensorFlow objects) when calling the method tf.keras.Model.save_weights,"**System information** 
- Have I written custom code:  yes
- OS Platform and Distribution: macOS Catalina Version 10.15.3 
- TensorFlow installed from: binary (using pip in conda)
- TensorFlow version (use command below): v2.1.0-rc2-17-ge5bf8de410 2.1.0
- Python version: Python 3.6.10 :: Anaconda, Inc.

Note: probably related to this closed issue https://github.com/tensorflow/tensorflow/issues/35075

**Describe the current behavior**
While saving a model `tf.keras.Model` with the function `save_weights`, the program raises the following error (full trace in the log section):

> ValueError: Unable to save the object ListWrapper([ListWrapper([<tf.Variable 'model_32/dense_4/kernel:0' ...)>,  ...]), ListWrapper([<tf.Variable 'model_32/dense_6/kernel:0' ...)>, ...])]) (a list wrapper constructed to track trackable TensorFlow objects). A list element was replaced (\_\_setitem__, \_\_setslice__), deleted (\_\_delitem__, \_\_delslice__), or moved (sort). In order to support restoration on object creation, tracking is exclusively for append-only data structures.
>
>If you don't need this list checkpointed, wrap it in a tf.contrib.checkpoint.NoDependency object; it will be automatically un-wrapped and subsequently ignored.

Note that the model can be saved before updating the model's variables and the update works as expected. However once updated, if I try to save the model, it will crash.

**Describe the expected behavior**

1. The model should be saved without raising error
2. There shouldn't be any reference to `tf.contrib.checkpoint.NoDependency` as contrib is not available in TF2.

**Standalone code to reproduce the issue** 

```python
import tensorflow as tf

class Model(tf.keras.Model):
    
    @property
    def groupedVariables(self):
        if self._var is None:
            self._var = []
            for denses in self._denses:
                self._var.append([])
                for d in denses:
                    self._var[-1] = self._var[-1] + d.trainable_variables                    
        return self._var
    ## ------------------------------------------------------------------------
    def __init__(self, ** kwargs):
        super(Model, self).__init__(** kwargs)

        self._optimizers = []
        self._denses     = []
        self._var        = None
        for copy in range(2):
            self._optimizers.append(tf.keras.optimizers.Adam())
            self._denses    .append([ tf.keras.layers.Dense(s) for s in [2,1]])
    ## ------------------------------------------------------------------------
    def call(self, x):
        y = []    
        for denses in self._denses:
            yy = x
            for d in denses: yy = d(yy)
            y.append(yy) 
        return y
    ## ------------------------------------------------------------------------
    def update(self, x, t):
        loss = []
        with tf.GradientTape() as tape:
            yy   = self(x)
            for y in zip(yy):
                y = y[0]
                l = tf.reduce_mean((t - y) ** 2)
                loss.append(l)

        var  = self.groupedVariables
        grad = tape.gradient(loss, var) 
        for g,v,o in zip(grad, var, self._optimizers):
            o.apply_gradients(zip(g,v))
## ----------------------------------------------------------------------------
m = Model()        
x = tf.zeros(shape = [1, 2], dtype = tf.float32)

print(""Simple run then save ... "", end = """")
m(x)
m.save_weights(""TMP/model"") ## <== This works
print(""done"")

print(""Update then save ....... "", end = """")
m.update(x, 0)
m.save_weights(""TMP/model"") ## <== This craches
print(""done"")
```

**Other info / logs**
```
The full error trace
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
<ipython-input-62-6d7f6f1860e7> in <module>
     60 print(""Update then save ....... "", end = """")
     61 m.update(x, 0)
---> 62 m.save_weights(""TMP/model"") ## <== This craches
     63 print(""done"")

~usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/network.py in save_weights(self, filepath, overwrite, save_format)
   1121              'saved.\n\nConsider using a TensorFlow optimizer from `tf.train`.')
   1122             % (optimizer,))
-> 1123       self._trackable_saver.save(filepath, session=session)
   1124       # Record this checkpoint so it's visible from tf.train.latest_checkpoint.
   1125       checkpoint_management.update_checkpoint_state_internal(

~usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/tracking/util.py in save(self, file_prefix, checkpoint_number, session)
   1166     file_io.recursive_create_dir(os.path.dirname(file_prefix))
   1167     save_path, new_feed_additions = self._save_cached_when_graph_building(
-> 1168         file_prefix=file_prefix_tensor, object_graph_tensor=object_graph_tensor)
   1169     if new_feed_additions:
   1170       feed_dict.update(new_feed_additions)

~usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/tracking/util.py in _save_cached_when_graph_building(self, file_prefix, object_graph_tensor)
   1106     (named_saveable_objects, graph_proto,
   1107      feed_additions) = self._gather_saveables(
-> 1108          object_graph_tensor=object_graph_tensor)
   1109     if (self._last_save_object_graph != graph_proto
   1110         # When executing eagerly, we need to re-create SaveableObjects each time

~usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/tracking/util.py in _gather_saveables(self, object_graph_tensor)
   1074     """"""Wraps _serialize_object_graph to include the object graph proto.""""""
   1075     (named_saveable_objects, graph_proto,
-> 1076      feed_additions) = self._graph_view.serialize_object_graph()
   1077     if object_graph_tensor is None:
   1078       with ops.device(""/cpu:0""):

~usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/tracking/graph_view.py in serialize_object_graph(self)
    377       ValueError: If there are invalid characters in an optimizer's slot names.
    378     """"""
--> 379     trackable_objects, path_to_root = self._breadth_first_traversal()
    380     return self._serialize_gathered_objects(
    381         trackable_objects, path_to_root)

~usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/tracking/graph_view.py in _breadth_first_traversal(self)
    197             % (current_trackable,))
    198       bfs_sorted.append(current_trackable)
--> 199       for name, dependency in self.list_dependencies(current_trackable):
    200         if dependency not in path_to_root:
    201           path_to_root[dependency] = (

~usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/tracking/graph_view.py in list_dependencies(self, obj)
    157     # pylint: disable=protected-access
    158     obj._maybe_initialize_trackable()
--> 159     return obj._checkpoint_dependencies
    160     # pylint: enable=protected-access
    161 

~usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/tracking/data_structures.py in _checkpoint_dependencies(self)
    507            ""\n\nIf you don't need this list checkpointed, wrap it in a ""
    508            ""tf.contrib.checkpoint.NoDependency object; it will be ""
--> 509            ""automatically un-wrapped and subsequently ignored."" % (self,)))
    510     if self._external_modification:
    511       raise ValueError(

ValueError: Unable to save the object ListWrapper([ListWrapper([<tf.Variable 'model_34/dense_12/kernel:0' shape=(2, 2) dtype=float32, numpy=
array([[ 0.4429444,  1.1044892],
       [ 0.515365 , -1.0957527]], dtype=float32)>, <tf.Variable 'model_34/dense_12/bias:0' shape=(2,) dtype=float32, numpy=array([0., 0.], dtype=float32)>, <tf.Variable 'model_34/dense_13/kernel:0' shape=(2, 1) dtype=float32, numpy=
array([[0.5423187 ],
       [0.27255356]], dtype=float32)>, <tf.Variable 'model_34/dense_13/bias:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>]), ListWrapper([<tf.Variable 'model_34/dense_14/kernel:0' shape=(2, 2) dtype=float32, numpy=
array([[-0.85178864,  1.0104183 ],
       [ 1.1649271 ,  1.1087018 ]], dtype=float32)>, <tf.Variable 'model_34/dense_14/bias:0' shape=(2,) dtype=float32, numpy=array([0., 0.], dtype=float32)>, <tf.Variable 'model_34/dense_15/kernel:0' shape=(2, 1) dtype=float32, numpy=
array([[-0.2449851 ],
       [ 0.84787834]], dtype=float32)>, <tf.Variable 'model_34/dense_15/bias:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>])]) (a list wrapper constructed to track trackable TensorFlow objects). A list element was replaced (__setitem__, __setslice__), deleted (__delitem__, __delslice__), or moved (sort). In order to support restoration on object creation, tracking is exclusively for append-only data structures.

If you don't need this list checkpointed, wrap it in a tf.contrib.checkpoint.NoDependency object; it will be automatically un-wrapped and subsequently ignored.
```"
36915,tf.keras.applications.ResNet50 is not working,"<em>I am working on transfer learning and used the ResNet50 model to predict 10 classes of my dataset. The losss went to 0.7 and acc=99% during training phase, but when i evaluate the model on test dataset, it gave me acc=10% and loss=2.275. The most panicking thing was that model was predicting only one class during test phase.  I tried every solution , even for over fitting but in vain. Then, i used ResNet50V2 model instead. This model is predicting every class now and acc=88% during test phase. </em>

**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04): Ubuntu 16.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if
the issue happens on mobile device:  No
- TensorFlow installed from (source or
binary): - TensorFlow version (use command below):  Command version
- Python version: - Bazel
version (if compiling from source):
- GCC/Compiler version (if compiling from
source): 
- CUDA/cuDNN version: - GPU model and memory: 10.1 and cuDNN 7.6


 Please can you check the ResNet50 code as i think there is some problem in it as same code of mine is working with tf.keras.application.ResNet50V2?

Thank you"
36914,Models with tf.lite.Optimize cause abort() when interpreter->Invoke(),"@tensorflow/micro

**System information**
- Host OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS Catalina 10.15.2
- TensorFlow installed from (source or binary): Installed with pip `pip install --upgrade tensorflow`
- Tensorflow version (commit SHA if source): Version 2.1.0 and TFLITE_SCHEMA_VERSION (3)
- Target platform (e.g. Arm Mbed OS, Arduino Nano 33 etc.): ESP32

**Describe the problem**

When using a Tensorflow Lite converted model with `tf.lite.Optimize` the ESP32 will reboot (abort()) if `interpreter->Invoke()` is called for inference. 

However if we convert the exact same model without using `tf.lite.Optimize` the inference will run just fine.

**Please provide the exact sequence of commands/steps when you ran into the problem**

Training and converting a model:

```python
#Converting a simple model.
model = Sequential()
model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(10,6)))
model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))
model.add(Dropout(0.5))
model.add(MaxPooling1D(pool_size=2))
model.add(Flatten())
model.add(Dense(100, activation='relu'))
model.add(Dense(y_train.shape[1], activation='softmax'))
model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
model.fit(X_train, y_train, epochs=5, batch_size=32, verbose=2)

converter = lite.TFLiteConverter.from_keras_model(model)

#The problem is caused by the following line
converter.optimizations = [lite.Optimize.DEFAULT]

tfmodel = converter.convert()
open(PATH+'/model.tflite',""wb"").write(tfmodel)
```

Converting to C array:
`xxd -i converted_model.tflite > model_data.cc`

In ESP32:

```c
//abort() when:
if(interpreter->Invoke() != kTfLiteOk) {
        Serial.println(""There was an error invoking the interpreter!"");
        return;
        }
```

The inference will run just fine if we convert the same model without `converter.optimizations = [lite.Optimize.DEFAULT]`

I tried 'DEFAULT', 'OPTIMIZE_FOR_SIZE', and 'OPTIMIZE_FOR_LATENCY' same problem every time.
I also tried using `converter.experimental_new_converter = True` but it did not work.

Here is the trace from the ESP32:
```
abort() was called at PC 0x400ddd39 on core 1

Backtrace: 0x4008c49c:0x3ffb1e00 0x4008c6cd:0x3ffb1e20 0x400ddd39:0x3ffb1e40 0x400de09d:0x3ffb1e90 0x400e60ca:0x3ffb1f70 0x400d2a0d:0x3ffb1f90 0x400edf0d:0x3ffb1fb0 0x40088bd9:0x3ffb1fd0

Rebooting...
ets Jun  8 2016 00:22:57

rst:0xc (SW_CPU_RESET),boot:0x13 (SPI_FAST_FLASH_BOOT)
configsip: 0, SPIWP:0xee
clk_drv:0x00,q_drv:0x00,d_drv:0x00,cs0_drv:0x00,hd_drv:0x00,wp_drv:0x00
mode:DIO, clock div:1
load:0x3fff0018,len:4
load:0x3fff001c,len:1216
ho 0 tail 12 room 4
load:0x40078000,len:9720
ho 0 tail 12 room 4
load:0x40080400,len:6352
entry 0x400806b8
```
Edit: Adding decoded stack result

```
Decoding stack results
0x4008c49c: invoke_abort at /home/runner/work/esp32-arduino-lib-builder/esp32-arduino-lib-builder/esp-idf/components/esp32/panic.c line 155
0x4008c6cd: abort at /home/runner/work/esp32-arduino-lib-builder/esp32-arduino-lib-builder/esp-idf/components/esp32/panic.c line 170

# Error comes from here:
0x400ddd39: tflite::reference_integer_ops::FullyConnected(tflite::FullyConnectedParams const&, tflite::RuntimeShape const&, signed char const*, tflite::RuntimeShape const&, signed char const*, tflite::RuntimeShape const&, int const*, tflite::RuntimeShape const&, signed char*) at lib/tfmicro/tensorflow/lite/kernels/internal/reference/integer_ops/fully_connected.h line 35
0x400de09d: tflite::ops::micro::fully_connected::Eval(TfLiteContext*, TfLiteNode*) at lib/tfmicro/tensorflow/lite/micro/kernels/fully_connected.cc line 102
0x400e60ca: tflite::MicroInterpreter::Invoke() at lib/tfmicro/tensorflow/lite/micro/micro_interpreter.cc line 190

0x400d2a0d: loop() at /Users/vdouet/Deep Learning/HAR_ESP32_Tensorflow/Firmware/src/main.ino line 560
0x400edf0d: loopTask(void*) at /Users/vdouet/.platformio/packages/framework-arduinoespressif32/cores/esp32/main.cpp line 17
0x40088bd9: vPortTaskWrapper at /home/runner/work/esp32-arduino-lib-builder/esp32-arduino-lib-builder/esp-idf/components/freertos/port.c line 143
```

I tried using different models with different input shapes, even the same one from `examples/magic_wand` but every time the ESP32 will abort() when it reaches `interpreter->Invoke()`.

Edit for completeness:

The optimized converted models work absolutely fine using Tensorflow Lite with Python3:
```python
interpreter = tf.lite.Interpreter(model_path=PATH+""/model.tflite"")
interpreter.allocate_tensors()

input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()

input_shape = input_details[0]['shape']
input_data = np.array(np.random.random_sample(input_shape), dtype=np.float32)

interpreter.set_tensor(input_details[0]['index'], input_data)
interpreter.invoke()
```

Best regards,
Victor"
36912,lower accuracy when model.compile() inside strategy.scope() (TPU),"**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if
the issue happens on mobile device: N/A
- TensorFlow installed from (source or
binary): - TensorFlow version (use command below): TF 2.1.0
- Python version: - Bazel
version (if compiling from source): N/A
- GCC/Compiler version (if compiling from
source): N/A
- CUDA/cuDNN version: - GPU model and memory: N/A

**Describe the current behavior**

I am running model training in a GCP VM by using TPU v3-8.

When compiling a model outside `strategy.scope()`, during training, the validation 'sparse_categorical_accuracy' is always about 2 ~ 3 % higher than compiling the model inside `strategy.scope()`.

The log provided below is for sequential models (created along with some pre-trained image classification models). However, I also tried to use subclassed model of `tf.keras.models.Model `.
This time, compiling inside / outside `strategy.scope()` gives almost the same results, which is equivalent to sequential models with compiling inside `strategy.scope()` --> That means, a lower accuracy than sequential models with compiling outside `strategy.scope()`.

For subclassed model, I also tried to use custom distributed training loop, which also gives the lower accuracy.

I can provide the logs for using `subclassed class`, if you think it's helpful. (I need to re-run the test for this part.)

**Describe the expected behavior**

I expect both compiling inside or outside `strategy.scope()` having the same performance.

**Standalone code to reproduce the issue** 
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

(If necessary, I can provide the whole script. It's some python code for the Kaggle competition [https://www.kaggle.com/c/flower-classification-with-tpus](https://www.kaggle.com/c/flower-classification-with-tpus).

For compiling outside `strategy.scope()`

    from tensorflow.keras.applications import Xception
    from tensorflow.keras.applications import DenseNet201
    from tensorflow.keras.applications import ResNet152V2

    tpu = tf.distribute.cluster_resolver.TPUClusterResolver(tpu=TPU_WORKER, zone=ZONE, project=PROJECT)  # TPU detection. No parameters necessary if TPU_NAME environment variable is set. On Kaggle this is always the case.
    print('Running on TPU ', tpu.master())

    tf.config.experimental_connect_to_cluster(tpu)
    tf.tpu.experimental.initialize_tpu_system(tpu)
    strategy = tf.distribute.experimental.TPUStrategy(tpu)

    backend_model_name = ""ResNet152V2""

    with strategy.scope():

        flower_classifier = tf.keras.Sequential(
            [
                backend_model(weights='imagenet', include_top=False ,input_shape=(*IMAGE_SIZE, 3)),
                tf.keras.layers.GlobalAveragePooling2D(),
                tf.keras.layers.Dense(len(CLASSES), activation='softmax', name='prob_dist')
            ]
        )

    flower_classifier.compile(
        optimizer=tf.keras.optimizers.Adam(lr=0.00001),
        loss = 'sparse_categorical_crossentropy',
        metrics=['sparse_categorical_accuracy']
    )

    history = flower_classifier.fit(
        get_training_dataset(),
        steps_per_epoch=STEPS_PER_EPOCH,
        epochs=epochs,
        validation_data=get_validation_dataset(ordered=True),
        validation_steps=eval_steps
    )

For compiling inside `strategy.scope()`

    with strategy.scope():

        flower_classifier = tf.keras.Sequential(
            [
                backend_model(weights='imagenet', include_top=False ,input_shape=(*IMAGE_SIZE, 3)),
                tf.keras.layers.GlobalAveragePooling2D(),
                tf.keras.layers.Dense(len(CLASSES), activation='softmax', name='prob_dist')
            ]
        )

        flower_classifier.compile(
            optimizer=tf.keras.optimizers.Adam(lr=0.00001),
            loss = 'sparse_categorical_crossentropy',
            metrics=['sparse_categorical_accuracy']
        )

For subclassed model, it's like

class Flower_Classifier(tf.keras.models.Model):

    def __init__(self, backend_model):

        super(Flower_Classifier, self).__init__()

        self.image_embedding_layer = backend_model(weights='imagenet', include_top=False ,input_shape=(*IMAGE_SIZE, 3))
        self.pooling_layer = tf.keras.layers.GlobalAveragePooling2D()
        self.prob_dist_layer = tf.keras.layers.Dense(len(CLASSES), activation='softmax', name='prob_dist')

    def call(self, inputs, training=False):

        embedding = self.image_embedding_layer(inputs, training=training)
        pooling = self.pooling_layer(embedding)
        prob_dist = self.prob_dist_layer(pooling)

        return prob_dist

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

I run test on 3 models (DenseNet201, Xception, ResNet152V2). Each is model run 3 times for both compiling inside/outside `strategy.scope()`.
Each run is a training of 30 epochs. The following are the best 10 validation accuracy for each run.

    DenseNet201:

        compile inside strategy.scope():

            run 1: val_acc = [0.9094828, 0.90921336, 0.90921336, 0.90894395, 0.90867454, 0.9081358, 0.9059806, 0.90113145, 0.90005386, 0.89897627]
            run 2: val_acc = [0.90894395, 0.90894395, 0.90678877, 0.9040948, 0.9038254, 0.9038254, 0.9016703, 0.9016703, 0.9005927, 0.90005386]
            run 3: val_acc = [0.907597, 0.9073276, 0.9070582, 0.90678877, 0.9065194, 0.904903, 0.9038254, 0.90328664, 0.90005386, 0.8981681]

        compile outside strategy.scope():

            run 1: val_acc = [0.9288793, 0.92672414, 0.92672414, 0.92672414, 0.92456895, 0.92456895, 0.92456895, 0.92456895, 0.92241377, 0.92241377]
            run 2: val_acc = [0.92672414, 0.92456895, 0.92456895, 0.92456895, 0.92241377, 0.92241377, 0.92025864, 0.92025864, 0.91810346, 0.91810346]
            run 3: val_acc = [0.93318963, 0.93318963, 0.9288793, 0.9288793, 0.92672414, 0.92672414, 0.92456895, 0.92241377, 0.92241377, 0.92025864]

    ResNet152V2:

        compile inside strategy.scope():

            run 1: val_acc = [0.828125, 0.8270474, 0.8248922, 0.82435346, 0.82408404, 0.82408404, 0.82300645, 0.82300645, 0.8211207, 0.8200431]
            run 2: val_acc = [0.8278556, 0.8273168, 0.8257004, 0.8235453, 0.82327586, 0.82327586, 0.82192886, 0.8213901, 0.8189655, 0.8184267]
            run 3: val_acc = [0.828125, 0.8262392, 0.82543105, 0.82516164, 0.82462287, 0.8224677, 0.8221983, 0.81977373, 0.81869614, 0.8146552]

        compile outside strategy.scope():

            run 1: [0.85775864, 0.85775864, 0.8512931, 0.8491379, 0.8469828, 0.8448276, 0.8426724, 0.8405172, 0.8405172, 0.83836204]
            run 2: [0.8448276, 0.8426724, 0.8405172, 0.83836204, 0.8362069, 0.8340517, 0.8340517, 0.8340517, 0.83189654, 0.8275862]
            run 3: [0.86422414, 0.86206895, 0.86206895, 0.85991377, 0.85775864, 0.85560346, 0.85560346, 0.85560346, 0.85560346, 0.8534483]

    Xception:

        compile inside strategy.scope():

            run 1: val_acc = [0.8445582, 0.8418642, 0.83943963, 0.83432114, 0.83162713, 0.83081895, 0.82327586, 0.81869614, 0.8125, 0.80630386]
            run 2: val_acc = [0.8504849, 0.84886855, 0.8448276, 0.8445582, 0.83943963, 0.8356681, 0.8313578, 0.8213901, 0.81977373, 0.8127694]
            run 3: val_acc = [0.8507543, 0.8483297, 0.84428877, 0.83863145, 0.8370151, 0.8292026, 0.82273704, 0.8170797, 0.80953664, 0.8036099]

        compile outside strategy.scope():

            run 1: val_acc = [0.8836207, 0.8771552, 0.8728448, 0.8685345, 0.8663793, 0.86206895, 0.85991377, 0.8491379, 0.83836204, 0.8362069]
            run 2: val_acc = [0.8814655, 0.8771552, 0.875, 0.8728448, 0.8663793, 0.85991377, 0.85560346, 0.8491379, 0.8405172, 0.82974136]
            run 3: val_acc = [0.87068963, 0.86422414, 0.86206895, 0.85775864, 0.8512931, 0.8426724, 0.8426724, 0.8426724, 0.83189654, 0.8125]
"
36911,"tensorflow.python.ops.linalg.sparse.matmul crashes when inputs have different rank, but only if either is a CSRSparseMatrix","**System information** 
- Have I written custom code: yes
- OS Platform and Distribution: Linux Ubuntu 16.04 
- TensorFlow installed from: binary
- TensorFlow version (use command below): v2.1.0-rc2-17-ge5bf8de 2.1.0
- Python version: 3.7.5
- CUDA/cuDNN version: 10.2/7.6.4
- GPU model and memory: Nvidia GeForce GTX 1050 4GB

**Describe the current behavior**
`tensorflow.python.ops.linalg.sparse.matmul` works for dense inputs of rank 2 and 3, or 3 and 2, but crashes if either of the inputs is a `CSRSparseMatrix`.

**Describe the expected behavior**
`tensorflow.python.ops.linalg.sparse.matmul` works for inputs of rank 2/3, or 3/2, and for any combination of dense/sparse inputs.

**Code to reproduce the issue**

```python
import numpy as np
from tensorflow.python.ops.linalg.sparse import sparse as tfsp

a = np.ones((3, 3))
b = np.ones((5, 3, 3))
a_sp = tfsp.CSRSparseMatrix(a)
b_sp = tfsp.CSRSparseMatrix(b)

# This works fine
output = tfsp.matmul(a, b)
print(output.shape)

# These crash
output_sp = tfsp.matmul(a_sp, b)
output_sp = tfsp.matmul(a, b_sp)
output_sp = tfsp.matmul(a_sp, b_sp)
```

**Other info / logs** 

If only one of the two inputs is sparse, the stack trace looks like this: 

```
2020-02-19 18:51:52.547579: W tensorflow/core/framework/op_kernel.cc:1655] OP_REQUIRES failed at mat_mul_op.cc:507 : Invalid argument: Ranks of a and b must match, saw: 0x7ffc085957fc vs. 3.
---------------------------------------------------------------------------
InvalidArgumentError                      Traceback (most recent call last)
<ipython-input-5-256f5bb49d4d> in <module>
----> 1 output_sp = tfsp.matmul(a_sp, b)

~/dev/tf2/lib/python3.7/site-packages/tensorflow_core/python/ops/linalg/sparse/sparse_csr_matrix_ops.py in matmul(a, b, transpose_a, transpose_b, adjoint_a, adjoint_b, name)
    220           transpose_b=transpose_b,
    221           adjoint_a=adjoint_a,
--> 222           adjoint_b=adjoint_b)
    223     else:
    224       # opA(A) . opB(B) = t(nopB(B) . nopA(A))

~/dev/tf2/lib/python3.7/site-packages/tensorflow_core/python/ops/linalg/sparse/gen_sparse_csr_matrix_ops.py in sparse_matrix_mat_mul(a, b, transpose_a, transpose_b, adjoint_a, adjoint_b, transpose_output, conjugate_output, name)
    480         raise
    481     except _core._NotOkStatusException as e:
--> 482       _ops.raise_from_not_ok_status(e, name)
    483   # Add nodes to the TensorFlow graph.
    484   if transpose_a is None:

~/dev/tf2/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py in raise_from_not_ok_status(e, name)
   6604   message = e.message + ("" name: "" + name if name is not None else """")
   6605   # pylint: disable=protected-access
-> 6606   six.raise_from(core._status_to_exception(e.code, message), None)
   6607   # pylint: enable=protected-access
   6608 

~/dev/tf2/lib/python3.7/site-packages/six.py in raise_from(value, from_value)

InvalidArgumentError: Ranks of a and b must match, saw: 0x7ffc085957fc vs. 3. [Op:SparseMatrixMatMul]

```

If both inputs are sparse:

```
---------------------------------------------------------------------------
InvalidArgumentError                      Traceback (most recent call last)
<ipython-input-4-9a25f9aa5868> in <module>
----> 1 output_sp = tfsp.matmul(a_sp, b_sp)

~/dev/tf2/lib/python3.7/site-packages/tensorflow_core/python/ops/linalg/sparse/sparse_csr_matrix_ops.py in matmul(a, b, transpose_a, transpose_b, adjoint_a, adjoint_b, name)
    204           adjoint_a=adjoint_a,
    205           adjoint_b=adjoint_b,
--> 206           type=a.dtype)
    207 
    208       # In eager mode, shape inference functions are not called, and the output

~/dev/tf2/lib/python3.7/site-packages/tensorflow_core/python/ops/linalg/sparse/gen_sparse_csr_matrix_ops.py in sparse_matrix_sparse_mat_mul(a, b, type, transpose_a, transpose_b, adjoint_a, adjoint_b, name)
   1281         raise
   1282     except _core._NotOkStatusException as e:
-> 1283       _ops.raise_from_not_ok_status(e, name)
   1284   # Add nodes to the TensorFlow graph.
   1285   type = _execute.make_type(type, ""type"")

~/dev/tf2/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py in raise_from_not_ok_status(e, name)
   6604   message = e.message + ("" name: "" + name if name is not None else """")
   6605   # pylint: disable=protected-access
-> 6606   six.raise_from(core._status_to_exception(e.code, message), None)
   6607   # pylint: enable=protected-access
   6608 

~/dev/tf2/lib/python3.7/site-packages/six.py in raise_from(value, from_value)

InvalidArgumentError: Inner product dimensions of A and B do not agree.  Shapes are: [3,3] vs. [5,3,3] [Op:SparseMatrixSparseMatMul]

```
"
36910,Cannot Convert Tensor Object to Numpy Array,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information** - 
Have I written custom code - YES 
 OS Platform and Distribution - macOS Catalina 10.15.2 
 TensorFlow installed from - Conda 
TensorFlow version (use command below): 2.0.0
 - Python version: 3.6.7
CPU

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
I am writing a custom layer where I need a kernel to be element-wise multiplied on the input. I am trying to convert the input tensor into a Numpy array using K.eval(input) but I get the following error: 

AttributeError: 'Tensor' object has no attribute '_numpy'

**Describe the expected behavior**

**Code to reproduce the issue** Provide a reproducible test case that is the
bare minimum necessary to generate the problem.

Here is the custom layer that I am trying to implement: 

```python
import numpy as np
import tensorflow
from tensorflow.keras import backend as K
from tensorflow.keras.layers import InputSpec, Layer, Dense, Conv2D, Lambda, Multiply
from tensorflow.keras import constraints
from tensorflow.keras import initializers

from binary_ops import binarize


class BinaryConv2D(Conv2D):
    '''Binarized Convolution2D layer
    References: 
    ""BinaryNet: Training Deep Neural Networks with Weights and Activations Constrained to +1 or -1"" [http://arxiv.org/abs/1602.02830]
    '''

    def __init__(self, filters, kernel_lr_multiplier='Glorot',
                 bias_lr_multiplier=None, H=1., **kwargs):
        super(BinaryConv2D, self).__init__(filters, **kwargs)
        self.H = H
        self.kernel_lr_multiplier = kernel_lr_multiplier
        self.bias_lr_multiplier = bias_lr_multiplier

    def build(self, input_shape):
        if self.data_format == 'channels_first':
            channel_axis = 1
        else:
            channel_axis = -1
        if input_shape[channel_axis] is None:
            raise ValueError('The channel dimension of the inputs '
                             'should be defined. Found `None`.')

        input_dim = input_shape[channel_axis]
        kernel_shape = self.kernel_size + (input_dim, self.filters)

        base = self.kernel_size[0] * self.kernel_size[1]
        if self.H == 'Glorot':
            nb_input = int(input_dim * base)
            nb_output = int(self.filters * base)
            self.H = np.float32(np.sqrt(1.5 / (nb_input + nb_output)))
            # print('Glorot H: {}'.format(self.H))

        if self.kernel_lr_multiplier == 'Glorot':
            nb_input = int(input_dim * base)
            nb_output = int(self.filters * base)
            self.kernel_lr_multiplier = np.float32(1. / np.sqrt(1.5 / (nb_input + nb_output)))
            # print('Glorot learning rate multiplier: {}'.format(self.lr_multiplier))

        self.kernel_constraint = Clip(-self.H, self.H)
        self.kernel_initializer = initializers.RandomUniform(-self.H, self.H)
        self.kernel = self.add_weight(shape=kernel_shape,
                                      initializer=self.kernel_initializer,
                                      name='kernel',
                                      regularizer=self.kernel_regularizer,
                                      constraint=self.kernel_constraint)

        if self.use_bias:
            self.lr_multipliers = [self.kernel_lr_multiplier, self.bias_lr_multiplier]
            self.bias = self.add_weight((self.output_dim,),
                                        initializer=self.bias_initializers,
                                        name='bias',
                                        regularizer=self.bias_regularizer,
                                        constraint=self.bias_constraint)

        else:
            self.lr_multipliers = [self.kernel_lr_multiplier]
            self.bias = None

        # Set input spec.
        self.input_spec = InputSpec(ndim=4, axes={channel_axis: input_dim})
        self.built = True

    def call(self, inputs):
        binary_kernel = binarize(self.kernel, H=self.H)

        print(type(K.eval(binary_kernel)))
        
        bk_temp = np.reshape(K.eval(binary_kernel[:,:,:,0]), (-1,self.kernel_size[0],self.kernel_size[0],1))
        bk_cube = np.zeros((30,30,30,1))
        bk_cube[:] = bk_temp
        outputs = inputs * bk_cube
       

        if self.use_bias:
            outputs = K.bias_add(
                outputs,
                self.bias,
                data_format=self.data_format)

        
        if self.activation is not None:
            return self.activation(outputs) 
        return outputs

    def get_config(self):
        config = {'H': self.H,
                  'kernel_lr_multiplier': self.kernel_lr_multiplier,
                  'bias_lr_multiplier': self.bias_lr_multiplier}
        base_config = super(BinaryConv2D, self).get_config()
        return dict(list(base_config.items()) + list(config.items()))

```

I should add that this error comes up only when I try to compile this into a model. If I just call build then it works fine

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
36909,Source build of TensorFlow 2.0 with 0.26.1 bazel fails at C++ compilation of rule '@nccl_archive//:device_lib'.,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): centos6
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA
- TensorFlow installed from (source or binary): source
- TensorFlow version: r2.0
- Python version: py3.6
- Installed using virtualenv? pip? conda?: pip 
- Bazel version (if compiling from source): 0.26.1
- GCC/Compiler version (if compiling from source): 7.3.1 (devtoolset-7) 
- CUDA/cuDNN version: 10.0 / cudnn 7
- GPU model and memory:

**Describe the problem**
I m trying to build TensorFlow from source, with TF_CUDA_NEED=1 and TF_CUDA_PATHS set to the `/usr/local/cuda` which points to Cuda 10.0, NO environment variable for nccl were set TF_NCCL_VERSION, NCCL_INSTALL_PATHS. when the bazel build command is run is fails with * C++ compilation of rule '@nccl_archive//:device_lib' failed* error output.

**Provide the exact sequence of commands / steps that you executed before running into the problem**

- Install packages centos-release-scl 
- Install devtoolset and python
`yum install -y rh-python36 devtoolset-7`
- install pip packages
- build bazel 0.26.1 from source.
- clone TensorFlow from branch r2.0 and run configure script.
- execute bazel build.

**Any other info / logs**
```
ERROR: /home/default/.cache/bazel/_bazel_root/2c92b5569ddded7b3a6bd5e139451b60/external/nccl_archive/BUILD.bazel:53:1: C++ compilation of rule '@nccl_archive//:device_lib' failed (Exit 1) gcc failed: error executing command 
  (cd /home/default/.cache/bazel/_bazel_root/2c92b5569ddded7b3a6bd5e139451b60/sandbox/processwrapper-sandbox/2437/execroot/org_tensorflow && \
  exec env - \
    LD_LIBRARY_PATH=/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64/stubs:/opt/rh/rh-python36/root/usr/lib64/:/opt/rh/rh-python36/root/usr/include:/opt/rh/rh-python36/root/usr/include/python3.6m/:/usr/local/lib:/opt/rh/devtoolset-7/root/usr/lib64:/opt/rh/devtoolset-7/root/usr/lib:/opt/rh/devtoolset-7/root/usr/lib64/dyninst:/opt/rh/devtoolset-7/root/usr/lib/dyninst:/opt/rh/devtoolset-7/root/usr/lib64:/opt/rh/devtoolset-7/root/usr/lib:/usr/local/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \
    PATH=/opt/app-root/output/:/home/default/bin:/opt/rh/rh-python36/root/usr/bin:/opt/rh/devtoolset-7/root/usr/bin:/opt/app-root/bin:/usr/local/bin:/opt/app-root/src/.local/bin/:/usr/local/nvidia/bin:/usr/local/cuda/bin:/opt/app-root/src/bin:/opt/app-root/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/home/default/.local/bin \
    PWD=/proc/self/cwd \
  /opt/rh/devtoolset-7/root/usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections -fdata-sections '-std=c++0x' -MD -MF bazel-out/k8-opt/bin/external/nccl_archive/_objs/device_lib/max_f16_all_gather.cu.d '-frandom-seed=bazel-out/k8-opt/bin/external/nccl_archive/_objs/device_lib/max_f16_all_gather.cu.o' -iquote external/nccl_archive -iquote bazel-out/k8-opt/bin/external/nccl_archive -iquote external/local_config_cuda -iquote bazel-out/k8-opt/bin/external/local_config_cuda -Ibazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs -Ibazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/include_hdrs -Ibazel-out/k8-opt/bin/external/local_config_cuda/cuda/_virtual_includes/cuda_headers_virtual -Ibazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/src_hdrs -isystem external/local_config_cuda/cuda -isystem bazel-out/k8-opt/bin/external/local_config_cuda/cuda -isystem external/local_config_cuda/cuda/cuda/include -isystem bazel-out/k8-opt/bin/external/local_config_cuda/cuda/cuda/include -mavx -mavx512f -mavx2 -mfma '-mfpmath=both' -msse4.2 '-D_GLIBCXX_USE_CXX11_ABI=0' -fno-canonical-system-headers -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' -c bazel-out/k8-opt/bin/external/nccl_archive/src/collectives/device/max_f16_all_gather.cu.cc -o bazel-out/k8-opt/bin/external/nccl_archive/_objs/device_lib/max_f16_all_gather.cu.o)
Execution platform: @bazel_tools//platforms:host_platform

Use --sandbox_debug to see verbose messages from the sandbox: gcc failed: error executing command 
  (cd /home/default/.cache/bazel/_bazel_root/2c92b5569ddded7b3a6bd5e139451b60/sandbox/processwrapper-sandbox/2437/execroot/org_tensorflow && \
  exec env - \
    LD_LIBRARY_PATH=/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64/stubs:/opt/rh/rh-python36/root/usr/lib64/:/opt/rh/rh-python36/root/usr/include:/opt/rh/rh-python36/root/usr/include/python3.6m/:/usr/local/lib:/opt/rh/devtoolset-7/root/usr/lib64:/opt/rh/devtoolset-7/root/usr/lib:/opt/rh/devtoolset-7/root/usr/lib64/dyninst:/opt/rh/devtoolset-7/root/usr/lib/dyninst:/opt/rh/devtoolset-7/root/usr/lib64:/opt/rh/devtoolset-7/root/usr/lib:/usr/local/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \
    PATH=/opt/app-root/output/:/home/default/bin:/opt/rh/rh-python36/root/usr/bin:/opt/rh/devtoolset-7/root/usr/bin:/opt/app-root/bin:/usr/local/bin:/opt/app-root/src/.local/bin/:/usr/local/nvidia/bin:/usr/local/cuda/bin:/opt/app-root/src/bin:/opt/app-root/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/home/default/.local/bin \
    PWD=/proc/self/cwd \
  /opt/rh/devtoolset-7/root/usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections -fdata-sections '-std=c++0x' -MD -MF bazel-out/k8-opt/bin/external/nccl_archive/_objs/device_lib/max_f16_all_gather.cu.d '-frandom-seed=bazel-out/k8-opt/bin/external/nccl_archive/_objs/device_lib/max_f16_all_gather.cu.o' -iquote external/nccl_archive -iquote bazel-out/k8-opt/bin/external/nccl_archive -iquote external/local_config_cuda -iquote bazel-out/k8-opt/bin/external/local_config_cuda -Ibazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs -Ibazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/include_hdrs -Ibazel-out/k8-opt/bin/external/local_config_cuda/cuda/_virtual_includes/cuda_headers_virtual -Ibazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/src_hdrs -isystem external/local_config_cuda/cuda -isystem bazel-out/k8-opt/bin/external/local_config_cuda/cuda -isystem external/local_config_cuda/cuda/cuda/include -isystem bazel-out/k8-opt/bin/external/local_config_cuda/cuda/cuda/include -mavx -mavx512f -mavx2 -mfma '-mfpmath=both' -msse4.2 '-D_GLIBCXX_USE_CXX11_ABI=0' -fno-canonical-system-headers -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' -c bazel-out/k8-opt/bin/external/nccl_archive/src/collectives/device/max_f16_all_gather.cu.cc -o bazel-out/k8-opt/bin/external/nccl_archive/_objs/device_lib/max_f16_all_gather.cu.o)
Execution platform: @bazel_tools//platforms:host_platform

Use --sandbox_debug to see verbose messages from the sandbox
In file included from bazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/reduce_kernel.h:11:0,
                 from bazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/primitives.h:11,
                 from bazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/all_gather.h:8,
                 from bazel-out/k8-opt/bin/external/nccl_archive/src/collectives/device/max_f16_all_gather.cu.cc:10:
bazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/common_kernel.h:254:0: warning: ignoring #pragma unroll  [-Wunknown-pragmas]
     #pragma unroll
 
bazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/common_kernel.h:256:0: warning: ignoring #pragma unroll  [-Wunknown-pragmas]
     #pragma unroll 1
 
bazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/common_kernel.h:259:0: warning: ignoring #pragma unroll  [-Wunknown-pragmas]
     #pragma unroll
 
bazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/common_kernel.h:261:0: warning: ignoring #pragma unroll  [-Wunknown-pragmas]
     #pragma unroll 1
 
bazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/common_kernel.h:290:0: warning: ignoring #pragma unroll  [-Wunknown-pragmas]
     #pragma unroll 1
 
bazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/common_kernel.h:301:0: warning: ignoring #pragma unroll  [-Wunknown-pragmas]
     #pragma unroll 1
 
bazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/common_kernel.h:327:0: warning: ignoring #pragma unroll  [-Wunknown-pragmas]
   #pragma unroll
 
bazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/common_kernel.h:330:0: warning: ignoring #pragma unroll  [-Wunknown-pragmas]
   #pragma unroll
 
In file included from bazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/all_gather.h:8:0,
                 from bazel-out/k8-opt/bin/external/nccl_archive/src/collectives/device/max_f16_all_gather.cu.cc:10:
bazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/primitives.h:154:0: warning: ignoring #pragma unroll  [-Wunknown-pragmas]
     #pragma unroll 1
 
bazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/primitives.h:456:0: warning: ignoring #pragma unroll  [-Wunknown-pragmas]
     #pragma unroll 2
 
In file included from bazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/reduce_kernel.h:11:0,
                 from bazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/primitives.h:11,
                 from bazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/all_gather.h:8,
                 from bazel-out/k8-opt/bin/external/nccl_archive/src/collectives/device/max_f16_all_gather.cu.cc:10:
bazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/common_kernel.h: In member function 'PackType MULTI<FUNC, double>::operator()(PackType, PackType) const':
bazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/common_kernel.h:170:24: error: there are no arguments to '__longlong_as_double' that depend on a template parameter, so a declaration of '__longlong_as_double' must be available [-fpermissive]
     double rv = FUNC()(__longlong_as_double(x), __longlong_as_double(y));
                        ^~~~~~~~~~~~~~~~~~~~
bazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/common_kernel.h:170:24: note: (if you use '-fpermissive', G++ will accept your code, but allowing the use of an undeclared name is deprecated)
bazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/common_kernel.h:170:49: error: there are no arguments to '__longlong_as_double' that depend on a template parameter, so a declaration of '__longlong_as_double' must be available [-fpermissive]
     double rv = FUNC()(__longlong_as_double(x), __longlong_as_double(y));
                                                 ^~~~~~~~~~~~~~~~~~~~
bazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/common_kernel.h:171:12: error: there are no arguments to '__double_as_longlong' that depend on a template parameter, so a declaration of '__double_as_longlong' must be available [-fpermissive]
     return __double_as_longlong(rv);
            ^~~~~~~~~~~~~~~~~~~~
In file included from bazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/primitives.h:11:0,
                 from bazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/all_gather.h:8,
                 from bazel-out/k8-opt/bin/external/nccl_archive/src/collectives/device/max_f16_all_gather.cu.cc:10:
bazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/reduce_kernel.h: In member function 'uint32_t FuncMax<signed char>::operator()(uint32_t, uint32_t) const':
bazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/reduce_kernel.h:137:14: error: 'max' was not declared in this scope
     cr.a.x = max(cx.a.x, cy.a.x);
              ^~~
bazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/reduce_kernel.h: In member function 'uint32_t FuncMax<unsigned char>::operator()(uint32_t, uint32_t) const':
bazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/reduce_kernel.h:160:14: error: 'max' was not declared in this scope
     cr.a.x = max(cx.a.x, cy.a.x);
              ^~~
bazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/reduce_kernel.h: In member function 'half2 FuncSum<__half>::operator()(half2, half2) const':
bazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/reduce_kernel.h:226:10: error: '__half22float2' was not declared in this scope
     fx = __half22float2(x);
          ^~~~~~~~~~~~~~
bazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/reduce_kernel.h:226:10: note: suggested alternative: '__half2float'
     fx = __half22float2(x);
          ^~~~~~~~~~~~~~
          __half2float
bazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/reduce_kernel.h:230:12: error: '__float22half2_rn' was not declared in this scope
     return __float22half2_rn(fr);
            ^~~~~~~~~~~~~~~~~
bazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/reduce_kernel.h:230:12: note: suggested alternative: '__floats2half2_rn'
     return __float22half2_rn(fr);
            ^~~~~~~~~~~~~~~~~
            __floats2half2_rn
bazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/reduce_kernel.h: In member function 'half2 FuncProd<__half>::operator()(half2, half2) const':
bazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/reduce_kernel.h:249:10: error: '__half22float2' was not declared in this scope
     fx = __half22float2(x);
          ^~~~~~~~~~~~~~
bazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/reduce_kernel.h:249:10: note: suggested alternative: '__half2float'
     fx = __half22float2(x);
          ^~~~~~~~~~~~~~
          __half2float
bazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/reduce_kernel.h:253:12: error: '__float22half2_rn' was not declared in this scope
     return __float22half2_rn(fr);
            ^~~~~~~~~~~~~~~~~
bazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/reduce_kernel.h:253:12: note: suggested alternative: '__floats2half2_rn'
     return __float22half2_rn(fr);
            ^~~~~~~~~~~~~~~~~
            __floats2half2_rn
bazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/reduce_kernel.h: In member function 'half2 FuncMax<__half>::operator()(half2, half2) const':
bazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/reduce_kernel.h:269:10: error: '__half22float2' was not declared in this scope
     fx = __half22float2(x);
          ^~~~~~~~~~~~~~
bazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/reduce_kernel.h:269:10: note: suggested alternative: '__half2float'
     fx = __half22float2(x);
          ^~~~~~~~~~~~~~
          __half2float
bazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/reduce_kernel.h:271:12: error: 'fmaxf' was not declared in this scope
     fr.x = fmaxf(fx.x, fy.x);
            ^~~~~
bazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/reduce_kernel.h:273:12: error: '__float22half2_rn' was not declared in this scope
     return __float22half2_rn(fr);
            ^~~~~~~~~~~~~~~~~
bazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/reduce_kernel.h:273:12: note: suggested alternative: '__floats2half2_rn'
     return __float22half2_rn(fr);
            ^~~~~~~~~~~~~~~~~
            __floats2half2_rn
bazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/reduce_kernel.h: In member function 'half FuncMax<__half>::operator()(half, half) const':
bazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/reduce_kernel.h:279:10: error: 'fmaxf' was not declared in this scope
     fm = fmaxf(fx, fy);
          ^~~~~
bazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/reduce_kernel.h: In member function 'half2 FuncMin<__half>::operator()(half2, half2) const':
bazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/reduce_kernel.h:288:10: error: '__half22float2' was not declared in this scope
     fx = __half22float2(x);
          ^~~~~~~~~~~~~~
bazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/reduce_kernel.h:288:10: note: suggested alternative: '__half2float'
     fx = __half22float2(x);
          ^~~~~~~~~~~~~~
          __half2float
bazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/reduce_kernel.h:290:12: error: 'fminf' was not declared in this scope
     fr.x = fminf(fx.x, fy.x);
            ^~~~~
bazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/reduce_kernel.h:290:12: note: suggested alternative: 'min'
     fr.x = fminf(fx.x, fy.x);
            ^~~~~
            min
bazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/reduce_kernel.h:292:12: error: '__float22half2_rn' was not declared in this scope
     return __float22half2_rn(fr);
            ^~~~~~~~~~~~~~~~~
bazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/reduce_kernel.h:292:12: note: suggested alternative: '__floats2half2_rn'
     return __float22half2_rn(fr);
            ^~~~~~~~~~~~~~~~~
            __floats2half2_rn
bazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/reduce_kernel.h: In member function 'half FuncMin<__half>::operator()(half, half) const':
bazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/reduce_kernel.h:298:10: error: 'fminf' was not declared in this scope
     fm = fminf(fx, fy);
          ^~~~~
bazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/reduce_kernel.h:298:10: note: suggested alternative: 'min'
     fm = fminf(fx, fy);
          ^~~~~
          min
In file included from bazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/primitives.h:12:0,
                 from bazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/all_gather.h:8,
                 from bazel-out/k8-opt/bin/external/nccl_archive/src/collectives/device/max_f16_all_gather.cu.cc:10:
bazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/common.h: In function 'void load_parallel(void*, void*, size_t, int)':
bazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/common.h:37:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]
   for (int o = tid; o < (size/sizeof(int)); o += blockDim.x) d[o] = s[o];
                     ~~^~~~~~~~~~~~~~~~~~~~
bazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/common.h:37:50: error: 'blockDim' was not declared in this scope
   for (int o = tid; o < (size/sizeof(int)); o += blockDim.x) d[o] = s[o];
                                                  ^~~~~~~~
bazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/common.h:37:50: note: suggested alternative: 'flockfile'
   for (int o = tid; o < (size/sizeof(int)); o += blockDim.x) d[o] = s[o];
                                                  ^~~~~~~~
                                                  flockfile
bazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/common.h:38:3: error: '__syncthreads' was not declared in this scope
   __syncthreads();
   ^~~~~~~~~~~~~
bazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/common.h:38:3: note: suggested alternative: '__thread__'
   __syncthreads();
   ^~~~~~~~~~~~~
   __thread__
In file included from bazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/all_gather.h:8:0,
                 from bazel-out/k8-opt/bin/external/nccl_archive/src/collectives/device/max_f16_all_gather.cu.cc:10:
bazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/primitives.h: In member function 'void ncclPrimitives<UNROLL, SLICESPERCHUNK, SLICESTEPS, T, NRECV, NSEND, FUNC>::GenericOp(const T*, T*, int, int)':
bazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/primitives.h:156:22: error: there are no arguments to 'max' that depend on a template parameter, so a declaration of 'max' must be available [-fpermissive]
       int realSize = max(0, min(sliceSize, nelem-offset));
                      ^~~
bazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/primitives.h:175:19: error: there are no arguments to '__threadfence_system' that depend on a template parameter, so a declaration of '__threadfence_system' must be available [-fpermissive]
         if (SEND) __threadfence_system();
                   ^~~~~~~~~~~~~~~~~~~~
bazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/primitives.h: In member function 'void ncclPrimitives<UNROLL, SLICESPERCHUNK, SLICESTEPS, T, NRECV, NSEND, FUNC>::loadSendConn(ncclConnInfo*, int, T*)':
bazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/primitives.h:218:7: error: there are no arguments to '__syncthreads' that depend on a template parameter, so a declaration of '__syncthreads' must be available [-fpermissive]
       __syncthreads();
       ^~~~~~~~~~~~~
bazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/primitives.h: In member function 'void ncclPrimitives<UNROLL, SLICESPERCHUNK, SLICESTEPS, T, NRECV, NSEND, FUNC>::saveRecvConn(int)':
bazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/primitives.h:227:7: error: there are no arguments to '__threadfence_system' that depend on a template parameter, so a declaration of '__threadfence_system' must be available [-fpermissive]
       __threadfence_system();
       ^~~~~~~~~~~~~~~~~~~~
bazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/primitives.h: In member function 'void ncclPrimitives<UNROLL, SLICESPERCHUNK, SLICESTEPS, T, NRECV, NSEND, FUNC>::saveSendConn(int)':
bazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/primitives.h:235:7: error: there are no arguments to '__threadfence_system' that depend on a template parameter, so a declaration of '__threadfence_system' must be available [-fpermissive]
       __threadfence_system();
       ^~~~~~~~~~~~~~~~~~~~
bazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/primitives.h: In constructor 'ncclPrimitives<UNROLL, SLICESPERCHUNK, SLICESTEPS, T, NRECV, NSEND, FUNC>::ncclPrimitives(int, int, int*, int*, T*, int, ncclChannel*, ncclDevComm*, uint64_t)':
bazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/primitives.h:245:5: error: there are no arguments to '__syncthreads' that depend on a template parameter, so a declaration of '__syncthreads' must be available [-fpermissive]
     __syncthreads();
     ^~~~~~~~~~~~~
bazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/primitives.h: In member function 'void ncclLLPrimitives<T, FUNC, NRECV, NSEND>::saveRecvConn(int)':
bazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/primitives.h:514:7: error: there are no arguments to '__threadfence_block' that depend on a template parameter, so a declaration of '__threadfence_block' must be available [-fpermissive]
       __threadfence_block();
       ^~~~~~~~~~~~~~~~~~~
bazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/primitives.h: In member function 'void ncclLLPrimitives<T, FUNC, NRECV, NSEND>::saveSendConn(int)':
bazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/primitives.h:522:7: error: there are no arguments to '__threadfence_block' that depend on a template parameter, so a declaration of '__threadfence_block' must be available [-fpermissive]
       __threadfence_block();
       ^~~~~~~~~~~~~~~~~~~
In file included from bazel-out/k8-opt/bin/external/nccl_archive/src/collectives/device/max_f16_all_gather.cu.cc:10:0:
bazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/all_gather.h: In function 'void ncclAllGatherRingKernel(CollectiveArgs*)':
bazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/all_gather.h:13:19: error: 'threadIdx' was not declared in this scope
   const int tid = threadIdx.x;
                   ^~~~~~~~~
bazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/all_gather.h:14:24: error: 'blockDim' was not declared in this scope
   const int nthreads = blockDim.x - 1;
                        ^~~~~~~~
bazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/all_gather.h:14:24: note: suggested alternative: 'flockfile'
   const int nthreads = blockDim.x - 1;
                        ^~~~~~~~
                        flockfile
bazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/all_gather.h:17:48: error: 'blockIdx' was not declared in this scope
   struct ncclChannel* channel = comm->channels+blockIdx.x;
                                                ^~~~~~~~
bazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/all_gather.h: In function 'void ncclAllGatherRingLLKernel(CollectiveArgs*)':
bazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/all_gather.h:74:19: error: 'threadIdx' was not declared in this scope
   const int tid = threadIdx.x;
                   ^~~~~~~~~
bazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/all_gather.h:78:48: error: 'blockIdx' was not declared in this scope
   struct ncclChannel* channel = comm->channels+blockIdx.x;
                                                ^~~~~~~~
In file included from bazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/primitives.h:12:0,
                 from bazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/all_gather.h:8,
                 from bazel-out/k8-opt/bin/external/nccl_archive/src/collectives/device/max_f16_all_gather.cu.cc:10:
bazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/common.h: At global scope:
bazel-out/k8-opt/bin/external/nccl_archive/_virtual_includes/device_hdrs/common.h:40:24: warning: 'void load_coll(ncclColl*, ncclColl*, int)' defined but not used [-Wunused-function]
 static __device__ void load_coll(struct ncclColl* localColl, struct ncclColl* hostColl, int tid) {
```"
36903,Executing genrule //tensorflow/python/keras/api:keras_python_api_gen failed ,"**System information**
- Dockerimage: nvidia/cuda-ppc64le:10.1-cudnn7-devel-ubuntu18.04
- TensorFlow installed from (source or binary): source
- TensorFlow version: r2.1 (branch)
- Python version: Python 3.6.9 (also setted /usr/bin/python3 while ./configure)
- Installed using virtualenv? pip? conda?: no, github repository and build
- Bazel version (if compiling from source): 0.27
- GCC/Compiler version (if compiling from source): gcc (Ubuntu 7.4.0-1ubuntu1~18.04.1) 7.4.0
- CUDA/cuDNN version: 10.1, 7.0 
- GPU model and memory: compute capability 6.0 nvidia tesla P100, GPU Memory 12GB, RAM 256GB



While building it throws a error.
```bash
 bazel build --config=opt --config=cuda --discard_analysis_cache --nokeep_state_after_build --notrack_incremental_state //tensorflow/tools/pip_package:build_pip_package
```
Error:
```bash
ERROR: /root/tensorflow/tensorflow/python/keras/api/BUILD:102:1: Executing genrule //tensorflow/python/keras/api:keras_python_api_gen failed (Exit 1)
Traceback (most recent call last):
  File ""/root/.cache/bazel/_bazel_root/efb88f6336d9c4a18216fb94287b8d97/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_1_keras_python_api_gen.runfiles/org_tensorflow/tensorflow/python/tools/api/generator/create_python_api.py"", line 777, in <module>
    main()
  File ""/root/.cache/bazel/_bazel_root/efb88f6336d9c4a18216fb94287b8d97/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_1_keras_python_api_gen.runfiles/org_tensorflow/tensorflow/python/tools/api/generator/create_python_api.py"", line 756, in main
    importlib.import_module(package)
  File ""/usr/lib/python3.6/importlib/__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""<frozen importlib._bootstrap>"", line 994, in _gcd_import
  File ""<frozen importlib._bootstrap>"", line 971, in _find_and_load
  File ""<frozen importlib._bootstrap>"", line 955, in _find_and_load_unlocked
  File ""<frozen importlib._bootstrap>"", line 665, in _load_unlocked
  File ""<frozen importlib._bootstrap_external>"", line 678, in exec_module
  File ""<frozen importlib._bootstrap>"", line 219, in _call_with_frames_removed
  File ""/root/.cache/bazel/_bazel_root/efb88f6336d9c4a18216fb94287b8d97/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_1_keras_python_api_gen.runfiles/org_tensorflow/tensorflow/python/keras/datasets/imdb.py"", line 25, in <module>
    from tensorflow.python.keras.preprocessing.sequence import _remove_long_seq
  File ""/root/.cache/bazel/_bazel_root/efb88f6336d9c4a18216fb94287b8d97/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_1_keras_python_api_gen.runfiles/org_tensorflow/tensorflow/python/keras/preprocessing/__init__.py"", line 23, in <module>
    import keras_preprocessing
ModuleNotFoundError: No module named 'keras_preprocessing'
----------------
Note: The failure of target //tensorflow/python/keras/api:create_tensorflow.python_api_1_keras_python_api_gen (with exit code 1) may have been caused by the fact that it is a Python 2 program that was built in the host configuration, which uses Python 3. You can change the host configuration (for the entire build) to instead use Python 2 by setting --host_force_python=PY2.

If this error started occurring in Bazel 0.27 and later, it may be because the Python toolchain now enforces that targets analyzed as PY2 and PY3 run under a Python 2 and Python 3 interpreter, respectively. See https://github.com/bazelbuild/bazel/issues/7899 for more information.
----------------
Target //tensorflow/tools/pip_package:build_pip_package failed to build
Use --verbose_failures to see the command lines of failed build steps.
ERROR: /root/tensorflow/tensorflow/tools/pip_package/BUILD:49:1 Executing genrule //tensorflow/python/keras/api:keras_python_api_gen failed (Exit 1)
INFO: Elapsed time: 480.332s, Critical Path: 366.40s
INFO: 2627 processes: 2627 local.
FAILED: Build did NOT complete successfully
```


"
36901,tensorflow/core/grappler/optimizers/meta_optimizer.cc:561] layout failed: Invalid argument: MutableGraphView::SortTopologically error:,"Hi! I have the following message whenever I train a ConvLSTM with attention, after the samples are loaded in the buffer. The training goes on, but I haven't found anything on the internet related to this. I am not sure if its a bug, or I've made a mistake. 

The complete code I am using is from [here](https://github.com/dtransposed/Paper-Implementation/tree/master/action_recognition_using_visual_attention). I suspect one of the last 3 lines of the function leads to this error. I tried debugging, but it didn't helped much.

**System information**
OS: Ubuntu 16.04
Tensorflow 2.1 installed from pip
Python 3.6
CUDA 10.2
GPU Tesla K80, 12GB memory


    `@tf.function

    def train_step(self, images, labels):

        loss = 0

        with tf.GradientTape() as tape:

            if self.network_name == 'ALSTM':
                batch_feature_cube_sequence = self.network.get_batch_feature_cube_sequence(images)
                hidden_state, cell_state = self.network.reset_hidden_and_cell_state(batch_feature_cube_sequence)
                self.network.lstm1.initial_state = cell_state
                all_attention_weights = tf.zeros((0,
                                                  self.batch_size,
                                                  batch_feature_cube_sequence.shape[2],
                                                  batch_feature_cube_sequence.shape[2]))

                for i in range(0, images.shape[1]):
                    input_image = images[:, i, :, :, :]
                    predictions, hidden_state, attention_weights = self.network(input_image, hidden_state)

                    self.train_accuracy.update_state(labels, predictions)
                    self.train_precision.update_state(labels, predictions)
                    self.train_recall.update_state(labels, predictions)

                    loss = loss + self.loss_object(labels, predictions)
                    attention_weights = tf.expand_dims(attention_weights, 0)
                    all_attention_weights = tf.concat([all_attention_weights, attention_weights], 0)

                classification_loss = loss / int(images.shape[1])
                attention_loss = self.attention_penalty(all_attention_weights)/ int(images.shape[1])*self.batch_size
                regularization_term = tf.add_n([tf.nn.l2_loss(v) for v in self.network.trainable_variables if 'bias' not in v.name])

                total_loss = classification_loss + self.penalty_coefficient*attention_loss + self.weight_decay*regularization_term

            elif self.network_name == 'ConvALSTM':

                hidden_state = self.network.get_initial_hidden_state(self.batch_size)
                for i in range(0, images.shape[1]):
                    input_image = images[:, i, :, :, :]
                    predictions, hidden_state, attention_weights = self.network(input_image, hidden_state)

                    self.train_accuracy.update_state(labels, predictions)
                    self.train_precision.update_state(labels, predictions)
                    self.train_recall.update_state(labels, predictions)

                    loss = loss + self.loss_object(labels, predictions)

                classification_loss = loss / int(images.shape[1])
                total_loss = classification_loss

        gradients = tape.gradient(total_loss, self.network.trainable_variables)
        self.optimizer.apply_gradients(zip(gradients, self.network.trainable_variables))
        self.train_loss.update_state(total_loss)
        return total_loss`


`2020-02-19 14:50:31.311596: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:150] Filling up shuffle buffer (this may take a while): 464 of 1000
2020-02-19 14:50:41.318354: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:150] Filling up shuffle buffer (this may take a while): 926 of 1000
2020-02-19 14:50:42.932254: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:199] Shuffle buffer filled.
2020-02-19 14:52:10.425158: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:561] layout failed: Invalid argument: MutableGraphView::SortTopologically error: detected edge(s) creating cycle(s) {'Func/conv_alstm_7/conv_lst_m2d/while_grad/body/_15513/input/_27997' -> 'conv_alstm_7/conv_lst_m2d/while_grad/body/_15513/gradients/AddN', 'Func/conv_alstm_6/conv_lst_m2d/while_grad/body/_15704/input/_28113' -> 'conv_alstm_6/conv_lst_m2d/while_grad/body/_15704/gradients/AddN', 'Func/conv_alstm_5/conv_lst_m2d/while_grad/body/_15895/input/_28229' -> 'conv_alstm_5/conv_lst_m2d/while_grad/body/_15895/gradients/AddN', 'Func/conv_alstm_4/conv_lst_m2d/while_grad/body/_16086/input/_28345' -> 'conv_alstm_4/conv_lst_m2d/while_grad/body/_16086/gradients/AddN', 'Func/conv_alstm_3/conv_lst_m2d/while_grad/body/_16277/input/_28461' -> 'conv_alstm_3/conv_lst_m2d/while_grad/body/_16277/gradients/AddN', 'Func/conv_alstm_2/conv_lst_m2d/while_grad/body/_16468/input/_28577' -> 'conv_alstm_2/conv_lst_m2d/while_grad/body/_16468/gradients/AddN', 'Func/conv_alstm_1/conv_lst_m2d/while_grad/body/_16659/input/_28693' -> 'conv_alstm_1/conv_lst_m2d/while_grad/body/_16659/gradients/AddN', 'conv_alstm/conv_lst_m2d/while_grad/body/_16850/gradients/AddN_2' -> 'conv_alstm/conv_lst_m2d/while_grad/next_iteration/_17007', 'Func/conv_alstm_33/conv_lst_m2d/while_grad/body/_10547/input/_24981' -> 'conv_alstm_33/conv_lst_m2d/while_grad/body/_10547/gradients/AddN', 'Func/conv_alstm_32/conv_lst_m2d/while_grad/body/_10738/input/_25097' -> 'conv_alstm_32/conv_lst_m2d/while_grad/body/_10738/gradients/AddN', 'Func/conv_alstm_31/conv_lst_m2d/while_grad/body/_10929/input/_25213' -> 'conv_alstm_31/conv_lst_m2d/while_grad/body/_10929/gradients/AddN', 'Func/conv_alstm_30/conv_lst_m2d/while_grad/body/_11120/input/_25329' -> 'conv_alstm_30/conv_lst_m2d/while_grad/body/_11120/gradients/AddN', 'Func/conv_alstm_29/conv_lst_m2d/while_grad/body/_11311/input/_25445' -> 'conv_alstm_29/conv_lst_m2d/while_grad/body/_11311/gradients/AddN', 'Func/conv_alstm_28/conv_lst_m2d/while_grad/body/_11502/input/_25561' -> 'conv_alstm_28/conv_lst_m2d/while_grad/body/_11502/gradients/AddN', 'Func/conv_alstm_27/conv_lst_m2d/while_grad/body/_11693/input/_25677' -> 'conv_alstm_27/conv_lst_m2d/while_grad/body/_11693/gradients/AddN', 'Func/conv_alstm_26/conv_lst_m2d/while_grad/body/_11884/input/_25793' -> 'conv_alstm_26/conv_lst_m2d/while_grad/body/_11884/gradients/AddN', 'Func/conv_alstm_25/conv_lst_m2d/while_grad/body/_12075/input/_25909' -> 'conv_alstm_25/conv_lst_m2d/while_grad/body/_12075/gradients/AddN', 'Func/conv_alstm_24/conv_lst_m2d/while_grad/body/_12266/input/_26025' -> 'conv_alstm_24/conv_lst_m2d/while_grad/body/_12266/gradients/AddN', 'Func/conv_alstm_23/conv_lst_m2d/while_grad/body/_12457/input/_26141' -> 'conv_alstm_23/conv_lst_m2d/while_grad/body/_12457/gradients/AddN', 'Func/conv_alstm_21/conv_lst_m2d/while_grad/body/_12839/input/_26373' -> 'conv_alstm_21/conv_lst_m2d/while_grad/body/_12839/gradients/AddN', 'Func/conv_alstm_20/conv_lst_m2d/while_grad/body/_13030/input/_26489' -> 'conv_alstm_20/conv_lst_m2d/while_grad/body/_13030/gradients/AddN', 'Func/conv_alstm_19/conv_lst_m2d/while_grad/body/_13221/input/_26605' -> 'conv_alstm_19/conv_lst_m2d/while_grad/body/_13221/gradients/AddN', 'Func/conv_alstm_18/conv_lst_m2d/while_grad/body/_13412/input/_26721' -> 'conv_alstm_18/conv_lst_m2d/while_grad/body/_13412/gradients/AddN', 'Func/conv_alstm_17/conv_lst_m2d/while_grad/body/_13603/input/_26837' -> 'conv_alstm_17/conv_lst_m2d/while_grad/body/_13603/gradients/AddN', 'Func/conv_alstm_16/conv_lst_m2d/while_grad/body/_13794/input/_26953' -> 'conv_alstm_16/conv_lst_m2d/while_grad/body/_13794/gradients/AddN', 'Func/conv_alstm_15/conv_lst_m2d/while_grad/body/_13985/input/_27069' -> 'conv_alstm_15/conv_lst_m2d/while_grad/body/_13985/gradients/AddN', 'Func/conv_alstm_14/conv_lst_m2d/while_grad/body/_14176/input/_27185' -> 'conv_alstm_14/conv_lst_m2d/while_grad/body/_14176/gradients/AddN', 'Func/conv_alstm_13/conv_lst_m2d/while_grad/body/_14367/input/_27301' -> 'conv_alstm_13/conv_lst_m2d/while_grad/body/_14367/gradients/AddN', 'Func/conv_alstm_12/conv_lst_m2d/while_grad/body/_14558/input/_27417' -> 'conv_alstm_12/conv_lst_m2d/while_grad/body/_14558/gradients/AddN', 'Func/conv_alstm_11/conv_lst_m2d/while_grad/body/_14749/input/_27533' -> 'conv_alstm_11/conv_lst_m2d/while_grad/body/_14749/gradients/AddN', 'Func/conv_alstm_10/conv_lst_m2d/while_grad/body/_14940/input/_27649' -> 'conv_alstm_10/conv_lst_m2d/while_grad/body/_14940/gradients/AddN', 'Func/conv_alstm_9/conv_lst_m2d/while_grad/body/_15131/input/_27765' -> 'conv_alstm_9/conv_lst_m2d/while_grad/body/_15131/gradients/AddN', 'Func/conv_alstm_8/conv_lst_m2d/while_grad/body/_15322/input/_27881' -> 'conv_alstm_8/conv_lst_m2d/while_grad/body/_15322/gradients/AddN', 'conv_alstm_22/conv_lst_m2d/while_grad/body/_12648/gradients/convolution_4_grad/Conv2DBackpropInput' -> 'conv_alstm_22/conv_lst_m2d/while_grad/body/_12648/gradients/AddN_2', 'conv_alstm_22/conv_lst_m2d/while_grad/body/_12648/gradients/convolution_5_grad/Conv2DBackpropInput' -> 'conv_alstm_22/conv_lst_m2d/while_grad/body/_12648/gradients/AddN_2', 'conv_alstm_22/conv_lst_m2d/while_grad/body/_12648/gradients/convolution_6_grad/Conv2DBackpropInput' -> 'conv_alstm_22/conv_lst_m2d/while_grad/body/_12648/gradients/AddN_2', 'conv_alstm_22/conv_lst_m2d/while_grad/body/_12648/gradients/convolution_7_grad/Conv2DBackpropInput-2-TransposeNHWCToNCHW-LayoutOptimizer' -> 'conv_alstm_22/conv_lst_m2d/while_grad/body/_12648/gradients/convolution_7_grad/Conv2DBackpropInput', 'Func/conv_alstm_34/conv_lst_m2d/while_grad/body/_10356/input/_24865' -> 'conv_alstm_34/conv_lst_m2d/while_grad/body/_10356/gradients/AddN', 'Func/conv_alstm_35/conv_lst_m2d/while_grad/body/_10165/input/_24749' -> 'conv_alstm_35/conv_lst_m2d/while_grad/body/_10165/gradients/AddN', 'Func/conv_alstm_36/conv_lst_m2d/while_grad/body/_9974/input/_24633' -> 'conv_alstm_36/conv_lst_m2d/while_grad/body/_9974/gradients/AddN', 'conv_alstm_21/conv_lst_m2d/while/body/_5240/clip_by_value' -> 'conv_alstm_21/conv_lst_m2d/while/body/_5240/mul_3', 'conv_alstm_21/conv_lst_m2d/while/body/_5240/mul_2' -> 'conv_alstm_21/conv_lst_m2d/while/body/_5240/add_5', 'conv_alstm_21/conv_lst_m2d/while/body/_5240/clip_by_value_2' -> 'conv_alstm_21/conv_lst_m2d/while/body/_5240/mul_5', 'conv_alstm_21/conv_lst_m2d/while/body/_5240/convolution_6' -> 'conv_alstm_21/conv_lst_m2d/while/body/_5240/add_4', 'conv_alstm_22/conv_lst_m2d/while/body/_5459/clip_by_value_2' -> 'conv_alstm_22/conv_lst_m2d/while/body/_5459/mul_5', 'conv_alstm_22/conv_lst_m2d/while/body/_5459/convolution_6' -> 'conv_alstm_22/conv_lst_m2d/while/body/_5459/add_4', 'conv_alstm_22/conv_lst_m2d/while/body/_5459/clip_by_value' -> 'conv_alstm_22/conv_lst_m2d/while/body/_5459/mul_3', 'conv_alstm_22/conv_lst_m2d/while/body/_5459/mul_2' -> 'conv_alstm_22/conv_lst_m2d/while/body/_5459/add_5', 'conv_alstm_23/conv_lst_m2d/while/body/_5678/clip_by_value_2' -> 'conv_alstm_23/conv_lst_m2d/while/body/_5678/mul_5', 'conv_alstm_23/conv_lst_m2d/while/body/_5678/convolution_6' -> 'conv_alstm_23/conv_lst_m2d/while/body/_5678/add_4', 'conv_alstm_23/conv_lst_m2d/while/body/_5678/clip_by_value' -> 'conv_alstm_23/conv_lst_m2d/while/body/_5678/mul_3', 'conv_alstm_23/conv_lst_m2d/while/body/_5678/mul_2' -> 'conv_alstm_23/conv_lst_m2d/while/body/_5678/add_5', 'conv_alstm_24/conv_lst_m2d/while/body/_5897/clip_by_value_2' -> 'conv_alstm_24/conv_lst_m2d/while/body/_5897/mul_5', 'conv_alstm_24/conv_lst_m2d/while/body/_5897/convolution_6' -> 'conv_alstm_24/conv_lst_m2d/while/body/_5897/add_4', 'conv_alstm_24/conv_lst_m2d/while/body/_5897/clip_by_value' -> 'conv_alstm_24/conv_lst_m2d/while/body/_5897/mul_3', 'conv_alstm_24/conv_lst_m2d/while/body/_5897/mul_2' -> 'conv_alstm_24/conv_lst_m2d/while/body/_5897/add_5', 'conv_alstm_25/conv_lst_m2d/while/body/_6116/clip_by_value_2' -> 'conv_alstm_25/conv_lst_m2d/while/body/_6116/mul_5', 'conv_alstm_25/conv_lst_m2d/while/body/_6116/convolution_6' -> 'conv_alstm_25/conv_lst_m2d/while/body/_6116/add_4', 'conv_alstm_25/conv_lst_m2d/while/body/_6116/clip_by_value' -> 'conv_alstm_25/conv_lst_m2d/while/body/_6116/mul_3', 'conv_alstm_25/conv_lst_m2d/while/body/_6116/mul_2' -> 'conv_alstm_25/conv_lst_m2d/while/body/_6116/add_5', 'conv_alstm_26/conv_lst_m2d/while/body/_6335/clip_by_value' -> 'conv_alstm_26/conv_lst_m2d/while/body/_6335/mul_3', 'conv_alstm_26/conv_lst_m2d/while/body/_6335/mul_2' -> 'conv_alstm_26/conv_lst_m2d/while/body/_6335/add_5', 'conv_alstm_26/conv_lst_m2d/while/body/_6335/clip_by_value_2' -> 'conv_alstm_26/conv_lst_m2d/while/body/_6335/mul_5', 'conv_alstm_26/conv_lst_m2d/while/body/_6335/convolution_6' -> 'conv_alstm_26/conv_lst_m2d/while/body/_6335/add_4', 'conv_alstm_27/conv_lst_m2d/while/body/_6554/convolution_6' -> 'conv_alstm_27/conv_lst_m2d/while/body/_6554/add_4', 'conv_alstm_27/conv_lst_m2d/while/body/_6554/clip_by_value' -> 'conv_alstm_27/conv_lst_m2d/while/body/_6554/mul_3', 'conv_alstm_27/conv_lst_m2d/while/body/_6554/mul_2' -> 'conv_alstm_27/conv_lst_m2d/while/body/_6554/add_5', 'conv_alstm_27/conv_lst_m2d/while/body/_6554/clip_by_value_2' -> 'conv_alstm_27/conv_lst_m2d/while/body/_6554/mul_5', 'conv_alstm_28/conv_lst_m2d/while/body/_6773/mul_2' -> 'conv_alstm_28/conv_lst_m2d/while/body/_6773/add_5', 'conv_alstm_29/conv_lst_m2d/while/body/_6992/clip_by_value_2' -> 'conv_alstm_29/conv_lst_m2d/while/body/_6992/mul_5', 'conv_alstm_29/conv_lst_m2d/while/body/_6992/convolution_6' -> 'conv_alstm_29/conv_lst_m2d/while/body/_6992/add_4', 'conv_alstm_29/conv_lst_m2d/while/body/_6992/clip_by_value' -> 'conv_alstm_29/conv_lst_m2d/while/body/_6992/mul_3', 'conv_alstm_29/conv_lst_m2d/while/body/_6992/mul_2' -> 'conv_alstm_29/conv_lst_m2d/while/body/_6992/add_5', 'conv_alstm_30/conv_lst_m2d/while/body/_7211/clip_by_value_2' -> 'conv_alstm_30/conv_lst_m2d/while/body/_7211/mul_5', 'conv_alstm_30/conv_lst_m2d/while/body/_7211/convolution_6' -> 'conv_alstm_30/conv_lst_m2d/while/body/_7211/add_4', 'conv_alstm_30/conv_lst_m2d/while/body/_7211/clip_by_value' -> 'conv_alstm_30/conv_lst_m2d/while/body/_7211/mul_3', 'conv_alstm_30/conv_lst_m2d/while/body/_7211/mul_2' -> 'conv_alstm_30/conv_lst_m2d/while/body/_7211/add_5', 'conv_alstm_31/conv_lst_m2d/while/body/_7430/mul_2' -> 'conv_alstm_31/conv_lst_m2d/while/body/_7430/add_5', 'conv_alstm_32/conv_lst_m2d/while/body/_7649/mul_2' -> 'conv_alstm_32/conv_lst_m2d/while/body/_7649/add_5', 'conv_alstm_33/conv_lst_m2d/while/body/_7868/clip_by_value' -> 'conv_alstm_33/conv_lst_m2d/while/body/_7868/mul_3', 'conv_alstm_33/conv_lst_m2d/while/body/_7868/mul_2' -> 'conv_alstm_33/conv_lst_m2d/while/body/_7868/add_5', 'conv_alstm_33/conv_lst_m2d/while/body/_7868/clip_by_value_2' -> 'conv_alstm_33/conv_lst_m2d/while/body/_7868/mul_5', 'conv_alstm_33/conv_lst_m2d/while/body/_7868/convolution_6' -> 'conv_alstm_33/conv_lst_m2d/while/body/_7868/add_4', 'conv_alstm_34/conv_lst_m2d/while/body/_8087/mul_2' -> 'conv_alstm_34/conv_lst_m2d/while/body/_8087/add_5', 'conv_alstm_35/conv_lst_m2d/while/body/_8306/clip_by_value' -> 'conv_alstm_35/conv_lst_m2d/while/body/_8306/mul_3', 'conv_alstm_35/conv_lst_m2d/while/body/_8306/mul_2' -> 'conv_alstm_35/conv_lst_m2d/while/body/_8306/add_5', 'conv_alstm_35/conv_lst_m2d/while/body/_8306/clip_by_value_2' -> 'conv_alstm_35/conv_lst_m2d/while/body/_8306/mul_5', 'conv_alstm_35/conv_lst_m2d/while/body/_8306/convolution_6' -> 'conv_alstm_35/conv_lst_m2d/while/body/_8306/add_4', 'conv_alstm_36/conv_lst_m2d/while/body/_8525/convolution_6' -> 'conv_alstm_36/conv_lst_m2d/while/body/_8525/add_4', 'conv_alstm_36/conv_lst_m2d/while/body/_8525/clip_by_value' -> 'conv_alstm_36/conv_lst_m2d/while/body/_8525/mul_3', 'conv_alstm_36/conv_lst_m2d/while/body/_8525/mul_2' -> 'conv_alstm_36/conv_lst_m2d/while/body/_8525/add_5', 'conv_alstm_36/conv_lst_m2d/while/body/_8525/clip_by_value_2' -> 'conv_alstm_36/conv_lst_m2d/while/body/_8525/mul_5', 'conv_alstm_37/conv_lst_m2d/while/body/_8744/convolution_6' -> 'conv_alstm_37/conv_lst_m2d/while/body/_8744/add_4', 'conv_alstm_37/conv_lst_m2d/while/body/_8744/clip_by_value' -> 'conv_alstm_37/conv_lst_m2d/while/body/_8744/mul_3', 'conv_alstm_37/conv_lst_m2d/while/body/_8744/mul_2' -> 'conv_alstm_37/conv_lst_m2d/while/body/_8744/add_5', 'conv_alstm_37/conv_lst_m2d/while/body/_8744/clip_by_value_2' -> 'conv_alstm_37/conv_lst_m2d/while/body/_8744/mul_5', 'conv_alstm_38/conv_lst_m2d/while/body/_8963/clip_by_value_2' -> 'conv_alstm_38/conv_lst_m2d/while/body/_8963/mul_5', 'conv_alstm_38/conv_lst_m2d/while/body/_8963/convolution_6' -> 'conv_alstm_38/conv_lst_m2d/while/body/_8963/add_4', 'conv_alstm_38/conv_lst_m2d/while/body/_8963/clip_by_value' -> 'conv_alstm_38/conv_lst_m2d/while/body/_8963/mul_3', 'conv_alstm_38/conv_lst_m2d/while/body/_8963/mul_2' -> 'conv_alstm_38/conv_lst_m2d/while/body/_8963/add_5', 'conv_alstm_39/conv_lst_m2d/while/body/_9182/mul_2' -> 'conv_alstm_39/conv_lst_m2d/while/body/_9182/add_5', 'conv_alstm_39/conv_lst_m2d/while/body/_9182/convolution_6' -> 'conv_alstm_39/conv_lst_m2d/while/body/_9182/add_4', 'conv_alstm_39/conv_lst_m2d/while/body/_9182/clip_by_value' -> 'conv_alstm_39/conv_lst_m2d/while/body/_9182/mul_3', 'conv_alstm_39/conv_lst_m2d/while/body/_9182/clip_by_value_2' -> 'conv_alstm_39/conv_lst_m2d/while/body/_9182/mul_5', 'Func/conv_alstm_38/conv_lst_m2d/while_grad/body/_9592/input/_24401' -> 'conv_alstm_38/conv_lst_m2d/while_grad/body/_9592/gradients/AddN', 'Func/conv_alstm_37/conv_lst_m2d/while_grad/body/_9783/input/_24517' -> 'conv_alstm_37/conv_lst_m2d/while_grad/body/_9783/gradients/AddN', 'conv_alstm_39/conv_lst_m2d/while_grad/body/_9401/gradients/AddN_2' -> 'conv_alstm_39/conv_lst_m2d/while_grad/next_iteration/_9558', 'conv_alstm_34/conv_lst_m2d/while/body/_8087/convolution_6' -> 'conv_alstm_34/conv_lst_m2d/while/body/_8087/add_4', 'conv_alstm_34/conv_lst_m2d/while/body/_8087/clip_by_value' -> 'conv_alstm_34/conv_lst_m2d/while/body/_8087/mul_3', 'conv_alstm_34/conv_lst_m2d/while/body/_8087/clip_by_value_2' -> 'conv_alstm_34/conv_lst_m2d/while/body/_8087/mul_5', 'conv_alstm_32/conv_lst_m2d/while/body/_7649/clip_by_value_2' -> 'conv_alstm_32/conv_lst_m2d/while/body/_7649/mul_5', 'conv_alstm_32/conv_lst_m2d/while/body/_7649/convolution_6' -> 'conv_alstm_32/conv_lst_m2d/while/body/_7649/add_4', 'conv_alstm_32/conv_lst_m2d/while/body/_7649/clip_by_value' -> 'conv_alstm_32/conv_lst_m2d/while/body/_7649/mul_3', 'conv_alstm_31/conv_lst_m2d/while/body/_7430/clip_by_value_2' -> 'conv_alstm_31/conv_lst_m2d/while/body/_7430/mul_5', 'conv_alstm_31/conv_lst_m2d/while/body/_7430/convolution_6' -> 'conv_alstm_31/conv_lst_m2d/while/body/_7430/add_4', 'conv_alstm_31/conv_lst_m2d/while/body/_7430/clip_by_value' -> 'conv_alstm_31/conv_lst_m2d/while/body/_7430/mul_3', 'conv_alstm_28/conv_lst_m2d/while/body/_6773/clip_by_value' -> 'conv_alstm_28/conv_lst_m2d/while/body/_6773/mul_3', 'conv_alstm_28/conv_lst_m2d/while/body/_6773/clip_by_value_2' -> 'conv_alstm_28/conv_lst_m2d/while/body/_6773/mul_5', 'conv_alstm_28/conv_lst_m2d/while/body/_6773/convolution_6' -> 'conv_alstm_28/conv_lst_m2d/while/body/_6773/add_4', 'conv_alstm_3/conv_lst_m2d/while/body/_1298/clip_by_value' -> 'conv_alstm_3/conv_lst_m2d/while/body/_1298/mul_3', 'conv_alstm_3/conv_lst_m2d/while/body/_1298/mul_2' -> 'conv_alstm_3/conv_lst_m2d/while/body/_1298/add_5', 'conv_alstm_3/conv_lst_m2d/while/body/_1298/clip_by_value_2' -> 'conv_alstm_3/conv_lst_m2d/while/body/_1298/mul_5', 'conv_alstm_3/conv_lst_m2d/while/body/_1298/convolution_6' -> 'conv_alstm_3/conv_lst_m2d/while/body/_1298/add_4', 'conv_alstm_4/conv_lst_m2d/while/body/_1517/mul_2' -> 'conv_alstm_4/conv_lst_m2d/while/body/_1517/add_5', 'conv_alstm_5/conv_lst_m2d/while/body/_1736/clip_by_value' -> 'conv_alstm_5/conv_lst_m2d/while/body/_1736/mul_3', 'conv_alstm_5/conv_lst_m2d/while/body/_1736/mul_2' -> 'conv_alstm_5/conv_lst_m2d/while/body/_1736/add_5', 'conv_alstm_5/conv_lst_m2d/while/body/_1736/clip_by_value_2' -> 'conv_alstm_5/conv_lst_m2d/while/body/_1736/mul_5', 'conv_alstm_5/conv_lst_m2d/while/body/_1736/convolution_6' -> 'conv_alstm_5/conv_lst_m2d/while/body/_1736/add_4', 'conv_alstm_6/conv_lst_m2d/while/body/_1955/convolution_6' -> 'conv_alstm_6/conv_lst_m2d/while/body/_1955/add_4', 'conv_alstm_6/conv_lst_m2d/while/body/_1955/clip_by_value' -> 'conv_alstm_6/conv_lst_m2d/while/body/_1955/mul_3', 'conv_alstm_6/conv_lst_m2d/while/body/_1955/mul_2' -> 'conv_alstm_6/conv_lst_m2d/while/body/_1955/add_5', 'conv_alstm_6/conv_lst_m2d/while/body/_1955/clip_by_value_2' -> 'conv_alstm_6/conv_lst_m2d/while/body/_1955/mul_5', 'conv_alstm_7/conv_lst_m2d/while/body/_2174/mul_2' -> 'conv_alstm_7/conv_lst_m2d/while/body/_2174/add_5', 'conv_alstm_8/conv_lst_m2d/while/body/_2393/mul_2' -> 'conv_alstm_8/conv_lst_m2d/while/body/_2393/add_5', 'conv_alstm_9/conv_lst_m2d/while/body/_2612/clip_by_value' -> 'conv_alstm_9/conv_lst_m2d/while/body/_2612/mul_3', 'conv_alstm_9/conv_lst_m2d/while/body/_2612/mul_2' -> 'conv_alstm_9/conv_lst_m2d/while/body/_2612/add_5', 'conv_alstm_9/conv_lst_m2d/while/body/_2612/clip_by_value_2' -> 'conv_alstm_9/conv_lst_m2d/while/body/_2612/mul_5', 'conv_alstm_9/conv_lst_m2d/while/body/_2612/convolution_6' -> 'conv_alstm_9/conv_lst_m2d/while/body/_2612/add_4', 'conv_alstm_10/conv_lst_m2d/while/body/_2831/clip_by_value_2' -> 'conv_alstm_10/conv_lst_m2d/while/body/_2831/mul_5', 'conv_alstm_10/conv_lst_m2d/while/body/_2831/convolution_6' -> 'conv_alstm_10/conv_lst_m2d/while/body/_2831/add_4', 'conv_alstm_10/conv_lst_m2d/while/body/_2831/clip_by_value' -> 'conv_alstm_10/conv_lst_m2d/while/body/_2831/mul_3', 'conv_alstm_10/conv_lst_m2d/while/body/_2831/mul_2' -> 'conv_alstm_10/conv_lst_m2d/while/body/_2831/add_5', 'conv_alstm_11/conv_lst_m2d/while/body/_3050/mul_2' -> 'conv_alstm_11/conv_lst_m2d/while/body/_3050/add_5', 'conv_alstm_11/conv_lst_m2d/while/body/_3050/clip_by_value_2' -> 'conv_alstm_11/conv_lst_m2d/while/body/_3050/mul_5', 'conv_alstm_11/conv_lst_m2d/while/body/_3050/convolution_6' -> 'conv_alstm_11/conv_lst_m2d/while/body/_3050/add_4', 'conv_alstm_11/conv_lst_m2d/while/body/_3050/clip_by_value' -> 'conv_alstm_11/conv_lst_m2d/while/body/_3050/mul_3', 'conv_alstm_12/conv_lst_m2d/while/body/_3269/clip_by_value' -> 'conv_alstm_12/conv_lst_m2d/while/body/_3269/mul_3', 'conv_alstm_12/conv_lst_m2d/while/body/_3269/mul_2' -> 'conv_alstm_12/conv_lst_m2d/while/body/_3269/add_5', 'conv_alstm_12/conv_lst_m2d/while/body/_3269/clip_by_value_2' -> 'conv_alstm_12/conv_lst_m2d/while/body/_3269/mul_5', 'conv_alstm_12/conv_lst_m2d/while/body/_3269/convolution_6' -> 'conv_alstm_12/conv_lst_m2d/while/body/_3269/add_4', 'conv_alstm_13/conv_lst_m2d/while/body/_3488/clip_by_value' -> 'conv_alstm_13/conv_lst_m2d/while/body/_3488/mul_3', 'conv_alstm_13/conv_lst_m2d/while/body/_3488/mul_2' -> 'conv_alstm_13/conv_lst_m2d/while/body/_3488/add_5', 'conv_alstm_13/conv_lst_m2d/while/body/_3488/clip_by_value_2' -> 'conv_alstm_13/conv_lst_m2d/while/body/_3488/mul_5', 'conv_alstm_13/conv_lst_m2d/while/body/_3488/convolution_6' -> 'conv_alstm_13/conv_lst_m2d/while/body/_3488/add_4', 'conv_alstm_14/conv_lst_m2d/while/body/_3707/clip_by_value' -> 'conv_alstm_14/conv_lst_m2d/while/body/_3707/mul_3', 'conv_alstm_14/conv_lst_m2d/while/body/_3707/mul_2' -> 'conv_alstm_14/conv_lst_m2d/while/body/_3707/add_5', 'conv_alstm_14/conv_lst_m2d/while/body/_3707/clip_by_value_2' -> 'conv_alstm_14/conv_lst_m2d/while/body/_3707/mul_5', 'conv_alstm_14/conv_lst_m2d/while/body/_3707/convolution_6' -> 'conv_alstm_14/conv_lst_m2d/while/body/_3707/add_4', 'conv_alstm_15/conv_lst_m2d/while/body/_3926/convolution_6' -> 'conv_alstm_15/conv_lst_m2d/while/body/_3926/add_4', 'conv_alstm_15/conv_lst_m2d/while/body/_3926/clip_by_value' -> 'conv_alstm_15/conv_lst_m2d/while/body/_3926/mul_3', 'conv_alstm_15/conv_lst_m2d/while/body/_3926/mul_2' -> 'conv_alstm_15/conv_lst_m2d/while/body/_3926/add_5', 'conv_alstm_15/conv_lst_m2d/while/body/_3926/clip_by_value_2' -> 'conv_alstm_15/conv_lst_m2d/while/body/_3926/mul_5', 'conv_alstm_16/conv_lst_m2d/while/body/_4145/clip_by_value_2' -> 'conv_alstm_16/conv_lst_m2d/while/body/_4145/mul_5', 'conv_alstm_16/conv_lst_m2d/while/body/_4145/convolution_6' -> 'conv_alstm_16/conv_lst_m2d/while/body/_4145/add_4', 'conv_alstm_16/conv_lst_m2d/while/body/_4145/clip_by_value' -> 'conv_alstm_16/conv_lst_m2d/while/body/_4145/mul_3', 'conv_alstm_16/conv_lst_m2d/while/body/_4145/mul_2' -> 'conv_alstm_16/conv_lst_m2d/while/body/_4145/add_5', 'conv_alstm_17/conv_lst_m2d/while/body/_4364/clip_by_value_2' -> 'conv_alstm_17/conv_lst_m2d/while/body/_4364/mul_5', 'conv_alstm_17/conv_lst_m2d/while/body/_4364/convolution_6' -> 'conv_alstm_17/conv_lst_m2d/while/body/_4364/add_4', 'conv_alstm_17/conv_lst_m2d/while/body/_4364/clip_by_value' -> 'conv_alstm_17/conv_lst_m2d/while/body/_4364/mul_3', 'conv_alstm_17/conv_lst_m2d/while/body/_4364/mul_2' -> 'conv_alstm_17/conv_lst_m2d/while/body/_4364/add_5', 'conv_alstm_18/conv_lst_m2d/while/body/_4583/clip_by_value_2' -> 'conv_alstm_18/conv_lst_m2d/while/body/_4583/mul_5', 'conv_alstm_18/conv_lst_m2d/while/body/_4583/convolution_6' -> 'conv_alstm_18/conv_lst_m2d/while/body/_4583/add_4', 'conv_alstm_18/conv_lst_m2d/while/body/_4583/clip_by_value' -> 'conv_alstm_18/conv_lst_m2d/while/body/_4583/mul_3', 'conv_alstm_18/conv_lst_m2d/while/body/_4583/mul_2' -> 'conv_alstm_18/conv_lst_m2d/while/body/_4583/add_5', 'conv_alstm_19/conv_lst_m2d/while/body/_4802/mul_2' -> 'conv_alstm_19/conv_lst_m2d/while/body/_4802/add_5', 'conv_alstm_20/conv_lst_m2d/while/body/_5021/mul_2' -> 'conv_alstm_20/conv_lst_m2d/while/body/_5021/add_5', 'conv_alstm_20/conv_lst_m2d/while/body/_5021/clip_by_value_2' -> 'conv_alstm_20/conv_lst_m2d/while/body/_5021/mul_5', 'conv_alstm_20/conv_lst_m2d/while/body/_5021/convolution_6' -> 'conv_alstm_20/conv_lst_m2d/while/body/_5021/add_4', 'conv_alstm_20/conv_lst_m2d/while/body/_5021/clip_by_value' -> 'conv_alstm_20/conv_lst_m2d/while/body/_5021/mul_3', 'conv_alstm_19/conv_lst_m2d/while/body/_4802/clip_by_value_2' -> 'conv_alstm_19/conv_lst_m2d/while/body/_4802/mul_5', 'conv_alstm_19/conv_lst_m2d/while/body/_4802/convolution_6' -> 'conv_alstm_19/conv_lst_m2d/while/body/_4802/add_4', 'conv_alstm_19/conv_lst_m2d/while/body/_4802/clip_by_value' -> 'conv_alstm_19/conv_lst_m2d/while/body/_4802/mul_3', 'conv_alstm_8/conv_lst_m2d/while/body/_2393/clip_by_value_2' -> 'conv_alstm_8/conv_lst_m2d/while/body/_2393/mul_5', 'conv_alstm_8/conv_lst_m2d/while/body/_2393/convolution_6' -> 'conv_alstm_8/conv_lst_m2d/while/body/_2393/add_4', 'conv_alstm_8/conv_lst_m2d/while/body/_2393/clip_by_value' -> 'conv_alstm_8/conv_lst_m2d/while/body/_2393/mul_3', 'conv_alstm_7/conv_lst_m2d/while/body/_2174/clip_by_value_2' -> 'conv_alstm_7/conv_lst_m2d/while/body/_2174/mul_5', 'conv_alstm_7/conv_lst_m2d/while/body/_2174/convolution_6' -> 'conv_alstm_7/conv_lst_m2d/while/body/_2174/add_4', 'conv_alstm_7/conv_lst_m2d/while/body/_2174/clip_by_value' -> 'conv_alstm_7/conv_lst_m2d/while/body/_2174/mul_3', 'conv_alstm_4/conv_lst_m2d/while/body/_1517/convolution_6' -> 'conv_alstm_4/conv_lst_m2d/while/body/_1517/add_4', 'conv_alstm_4/conv_lst_m2d/while/body/_1517/clip_by_value' -> 'conv_alstm_4/conv_lst_m2d/while/body/_1517/mul_3', 'conv_alstm_4/conv_lst_m2d/while/body/_1517/clip_bdy/_3488/mul_3', 'conv_alstm_13/conv_lst_m2d/while/body/_3488/mul_2' -> 'conv_alstm_13/conv_lst_m2d/while/body/_3488/add_5', 'conv_alstm_13/conv_lst_m2d/while/body/_3488/clip_by_value_2' -> 'conv_alstm_13/conv_lst_m2d/while/body/_3488/mul_5', 'conv_alstm_13/conv_lst_m2d/while/body/_3488/convolution_6' -> 'conv_alstm_13/conv_lst_m2d/while/body/_3488/add_4', 'conv_alstm_14/conv_lst_m2d/while/body/_3707/clip_by_value' -> 'conv_alstm_14/conv_lst_m2d/while/body/_3707/mul_3', 'conv_alstm_14/conv_lst_m2d/while/body/_3707/mul_2' -> 'conv_alstm_14/conv_lst_m2d/while/body/_3707/add_5', 'conv_alstm_14/conv_lst_m2d/while/body/_3707/clip_by_value_2' -> 'conv_alstm_14/conv_lst_m2d/while/body/_3707/mul_5', 'conv_alstm_14/conv_lst_m2d/while/body/_3707/convolution_6' -> 'conv_alstm_14/conv_lst_m2d/while/body/_3707/add_4', 'conv_alstm_15/conv_lst_m2d/while/body/_3926/convolution_6' -> 'conv_alstm_15/conv_lst_m2d/while/body/_3926/add_4', 'conv_alstm_15/conv_lst_m2d/while/body/_3926/clip_by_value' -> 'conv_alstm_15/conv_lst_m2d/while/body/_3926/mul_3', 'conv_alstm_15/conv_lst_m2d/while/body/_3926/mul_2' -> 'conv_alstm_15/conv_lst_m2d/while/body/_3926/add_5', 'conv_alstm_15/conv_lst_m2d/while/body/_3926/clip_by_value_2' -> 'conv_alstm_15/conv_lst_m2d/while/body/_3926/mul_5', 'conv_alstm_16/conv_lst_m2d/while/body/_4145/clip_by_value_2' -> 'conv_alstm_16/conv_lst_m2d/while/body/_4145/mul_5', 'conv_alstm_16/conv_lst_m2d/while/body/_4145/convolution_6' -> 'conv_alstm_16/conv_lst_m2d/while/body/_4145/add_4', 'conv_alstm_16/conv_lst_m2d/while/body/_4145/clip_by_value' -> 'con
v_alstm_16/conv_lst_m2d/while/body/_4145/mul_3', 'conv_alstm_16/conv_lst_m2d/while/body/_4145/mul_2' -> 'conv_alstm_16/conv_lst_m2d/while/body/_4145/add_5', 'conv_alstm_17/conv_lst_m2d/while/body/_
4364/clip_by_value_2' -> 'conv_alstm_17/conv_lst_m2d/while/body/_4364/mul_5', 'conv_alstm_17/conv_lst_m2d/while/body/_4364/convolution_6' -> 'conv_alstm_17/conv_lst_m2d/while/body/_4364/add_4', 'co
nv_alstm_17/conv_lst_m2d/while/body/_4364/clip_by_value' -> 'conv_alstm_17/conv_lst_m2d/while/body/_4364/mul_3', 'conv_alstm_17/conv_lst_m2d/while/body/_4364/mul_2' -> 'conv_alstm_17/conv_lst_m2d/w
hile/body/_4364/add_5', 'conv_alstm_18/conv_lst_m2d/while/body/_4583/clip_by_value_2' -> 'conv_alstm_18/conv_lst_m2d/while/body/_4583/mul_5', 'conv_alstm_18/conv_lst_m2d/while/body/_4583/convolutio
n_6' -> 'conv_alstm_18/conv_lst_m2d/while/body/_4583/add_4', 'conv_alstm_18/conv_lst_m2d/while/body/_4583/clip_by_value' -> 'conv_alstm_18/conv_lst_m2d/while/body/_4583/mul_3', 'conv_alstm_18/conv_
lst_m2d/while/body/_4583/mul_2' -> 'conv_alstm_18/conv_lst_m2d/while/body/_4583/add_5', 'conv_alstm_19/conv_lst_m2d/while/body/_4802/mul_2' -> 'conv_alstm_19/conv_lst_m2d/while/body/_4802/add_5', '
conv_alstm_20/conv_lst_m2d/while/body/_5021/mul_2' -> 'conv_alstm_20/conv_lst_m2d/while/body/_5021/add_5', 'conv_alstm_20/conv_lst_m2d/while/body/_5021/clip_by_value_2' -> 'conv_alstm_20/conv_lst_m
2d/while/body/_5021/mul_5', 'conv_alstm_20/conv_lst_m2d/while/body/_5021/convolution_6' -> 'conv_alstm_20/conv_lst_m2d/while/body/_5021/add_4', 'conv_alstm_20/conv_lst_m2d/while/body/_5021/clip_by_
value' -> 'conv_alstm_20/conv_lst_m2d/while/body/_5021/mul_3', 'conv_alstm_19/conv_lst_m2d/while/body/_4802/clip_by_value_2' -> 'conv_alstm_19/conv_lst_m2d/while/body/_4802/mul_5', 'conv_alstm_19/c
onv_lst_m2d/while/body/_4802/convolution_6' -> 'conv_alstm_19/conv_lst_m2d/while/body/_4802/add_4', 'conv_alstm_19/conv_lst_m2d/while/body/_4802/clip_by_value' -> 'conv_alstm_19/conv_lst_m2d/while/
body/_4802/mul_3', 'conv_alstm_8/conv_lst_m2d/while/body/_2393/clip_by_value_2' -> 'conv_alstm_8/conv_lst_m2d/while/body/_2393/mul_5', 'conv_alstm_8/conv_lst_m2d/while/body/_2393/convolution_6' -> 
'conv_alstm_8/conv_lst_m2d/while/body/_2393/add_4', 'conv_alstm_8/conv_lst_m2d/while/body/_2393/clip_by_value' -> 'conv_alstm_8/conv_lst_m2d/while/body/_2393/mul_3', 'conv_alstm_7/conv_lst_m2d/whil
e/body/_2174/clip_by_value_2' -> 'conv_alstm_7/conv_lst_m2d/while/body/_2174/mul_5', 'conv_alstm_7/conv_lst_m2d/while/body/_2174/convolution_6' -> 'conv_alstm_7/conv_lst_m2d/while/body/_2174/add_4'
, 'conv_alstm_7/conv_lst_m2d/while/body/_2174/clip_by_value' -> 'conv_alstm_7/conv_lst_m2d/while/body/_2174/mul_3', 'conv_alstm_4/conv_lst_m2d/while/body/_1517/convolution_6' -> 'conv_alstm_4/conv_
lst_m2d/while/body/_1517/add_4', 'conv_alstm_4/conv_lst_m2d/while/body/_1517/clip_by_value' -> 'conv_alstm_4/conv_lst_m2d/while/body/_1517/mul_3', 'conv_alstm_4/conv_lst_m2d/while/body/_1517/clip_b
y_value_2' -> 'conv_alstm_4/conv_lst_m2d/while/body/_1517/mul_5', 'conv_alstm_1/conv_lst_m2d/while/body/_860/clip_by_value' -> 'conv_alstm_1/conv_lst_m2d/while/body/_860/mul_3', 'conv_alstm_1/conv_
lst_m2d/while/body/_860/mul_2' -> 'conv_alstm_1/conv_lst_m2d/while/body/_860/add_5', 'conv_alstm_1/conv_lst_m2d/while/body/_860/clip_by_value_2' -> 'conv_alstm_1/conv_lst_m2d/while/body/_860/mul_5'
, 'conv_alstm_1/conv_lst_m2d/while/body/_860/convolution_6' -> 'conv_alstm_1/conv_lst_m2d/while/body/_860/add_4', 'conv_alstm_2/conv_lst_m2d/while/body/_1079/clip_by_value' -> 'conv_alstm_2/conv_ls
t_m2d/while/body/_1079/mul_3', 'conv_alstm_2/conv_lst_m2d/while/body/_1079/mul_2' -> 'conv_alstm_2/conv_lst_m2d/while/body/_1079/add_5', 'conv_alstm_2/conv_lst_m2d/while/body/_1079/clip_by_value_2'
 -> 'conv_alstm_2/conv_lst_m2d/while/body/_1079/mul_5', 'conv_alstm_2/conv_lst_m2d/while/body/_1079/convolution_6' -> 'conv_alstm_2/conv_lst_m2d/while/body/_1079/add_4', 'conv_alstm/conv_lst_m2d/wh
ile/body/_641/mul_2' -> 'conv_alstm/conv_lst_m2d/while/body/_641/add_5', 'conv_alstm/conv_lst_m2d/while/body/_641/clip_by_value' -> 'conv_alstm/conv_lst_m2d/while/body/_641/mul_3', 'conv_alstm/conv
_lst_m2d/while/body/_641/clip_by_value_2' -> 'conv_alstm/conv_lst_m2d/while/body/_641/mul_5', 'conv_alstm/conv_lst_m2d/while/body/_641/convolution_6' -> 'conv_alstm/conv_lst_m2d/while/body/_641/add
_4'}.`



"
36900,"when using mixed_precision.Policy('mixed_float16'), training is stuck at saving checkpoints for 0 ","<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04): Debian GNU/Linux 9 (stretch) 
- TensorFlow installed from (source or
binary): binary
- TensorFlow version (use command below): 2.1
- Python version: 3.5.3
- Bazel
version (if compiling from source): 
- GCC/Compiler version (if compiling from
source): 
- CUDA/cuDNN version: 
- GPU model and memory:

**Describe the current behavior**
When using tpu estimator in cpu mode and setting the precision policy to 'mixed_float16' training hangs at saving checkpoints for 0
**Describe the expected behavior**
Continue training using mixed precision, with default policy training is successfull

**Code to reproduce the issue** Provide a reproducible test case that is the
bare minimum necessary to generate the problem.
Use an example tpu_estimator from one of the tensorflow examples and set precision policy:
```
policy = mixed_precision.Policy('mixed_float16')
mixed_precision.set_policy(policy)
```

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

with TF_CPP_MIN_VLOG_LEVEL=2:
this message is getting repeated periodically:
2020-02-19 13:54:50.181246: I tensorflow/core/framework/model.cc:892] Starting optimization of tunable parameters with HillClimb
2020-02-19 13:54:50.181532: I tensorflow/core/framework/model.cc:943] Number of tunable parameters: 1
2020-02-19 13:54:50.181634: I tensorflow/core/framework/model.cc:946] Setting tunable parameter MapAndBatch(id:1) to 4
2020-02-19 13:54:50.181729: I tensorflow/core/kernels/data/model_dataset_op.cc:192] Waiting for 60000 ms.


"
36899,Autograd cannot handle if conditions with line brakes when accessing fields,"### System information
- custom code:
- Linux Ubuntu 18.04
- TensorFlow installed from binary:
-  tensorflow-gpu 2.1.0:
-  3.6.8:
- cuda 10.0:
- Nvidia Geforce 1080ti 11Gb:


### Describe the problem
BUG: Autograd cannot handle if conditions with line brakes when accessing fields.

### Source code / logs
This works:

import tensorflow as tf
class Test:
    a = tf.Variable(1.0)

    @tf.function
    def test_function(self):
        if False or self.a < 1.0:
            pass
t = Test()
t.test_function()

But this does not:

import tensorflow as tf
class Test:
    a = tf.Variable(1.0)

    @tf.function
    def test_function(self):
        if False or\
                self.a < 1.0:
            pass
t = Test()
t.test_function()

Error Message: 
tensorflow.python.framework.errors_impl.OperatorNotAllowedInGraphError: using a `tf.Tensor` as a Python `bool` is not allowed: AutoGraph did not convert this function. Try decorating it directly with @tf.function.



"
36897,Feature Request: Pickle an entire model.,"**System information** 
TensorFlow version 2.0.0

**Describe the current behavior**
This request follows the issue [#33204](https://github.com/tensorflow/tensorflow/issues/33283).
When trying to pickle a model to save its current state I get the error: `TypeError: can't pickle _thread._local objects`. Even when doing a low-level code and just trying to save keras layers it gets the same error message.

**Describe the expected behavior**
It would be nice to be able to save models with pickle.
Pickling the entire model object is easier than saving just the weights. Especially for complex models with multiple networks involved. It is very convenient as long as it does not introduce performance issues.

A potential current fix can be [this](https://github.com/tensorflow/tensorflow/issues/33283#issuecomment-561772070) for the moment.

**Code to reproduce the issue** 
The problem can be reproduced with this [gist](https://colab.research.google.com/gist/gadagashwini/079ecb24dcfb0130a41c4cc8f7a69aba/untitled209.ipynb).
"
36896,Use bazel crosstool to compile other arch wheel file raise lots of undefined reference error,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Debian GNU/Linux 9 (stretch)
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary):  N/A
- TensorFlow version: v2.0.0 tag
- Python version: Python 3.5.3
- Installed using virtualenv? pip? conda?: N/A
- Bazel version (if compiling from source): 0.24.1
- GCC/Compiler version (if compiling from source): 6.3.0
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A

**Describe the problem**

I'm trying to compile MIPS tensorflow wheel file with bazel crosstool, refer to `tensorflow/tensorflow/tools/ci_build/pi/build_raspberry_pi.sh and tensorflow/third_party/toolchains/cpus/arm/*`

My related CROSSTOOL refers to: https://paste.ubuntu.com/p/JRgnfkVrPw/ And then, I build it:
```
root@container:~/tensorflow# git diff --unified=0
diff --git a/.bazelrc b/.bazelrc
index 4b673d3fcf..caa301c8eb 100644
--- a/.bazelrc
+++ b/.bazelrc
@@ -113,0 +114,3 @@ build -c opt
+build --show_timestamps --verbose_failures --subcommands --color=yes --cpu mips64 --crosstool_top //tools/linux_mips64:linuxmips64

root@container:~/tensorflow# cat .tf_configure.bazelrc 
build --action_env PYTHON_BIN_PATH=""/usr/bin/python""
build --action_env PYTHON_LIB_PATH=""/usr/local/lib/python3.5/dist-packages""
build --python_path=""/usr/bin/python""
build:xla --define with_xla_support=true
build:opt --copt=-march=mips64
build:opt --host_copt=-march=native
build:opt --define with_default_optimizations=true
test --flaky_test_attempts=3
test --test_size_filters=small,medium
test --test_tag_filters=-benchmark-test,-no_oss,-oss_serial
test --build_tag_filters=-benchmark-test,-no_oss
test --test_tag_filters=-gpu
test --build_tag_filters=-gpu
build --action_env TF_CONFIGURE_IOS=""0""

root@container:~/tensorflow# bazel build -c opt --config=v1 --config=noaws --config=nonccl --cpu mips64 //tensorflow/tools/pip_package:build_pip_package
... ...
(12:36:27) ERROR: /root/.cache/bazel/_bazel_root/efb88f6336d9c4a18216fb94287b8d97/external/com_google_protobuf/BUILD:405:1: Linking of rule '@com_google_protobuf//:protoc' failed (Exit 1): gcc failed: error executing command 
  (cd /root/.cache/bazel/_bazel_root/efb88f6336d9c4a18216fb94287b8d97/execroot/org_tensorflow && \
  exec env - \
    PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \
    PWD=/proc/self/cwd \
  /usr/bin/gcc -o bazel-out/host/bin/external/com_google_protobuf/protoc -Wl,-z,relro,-z,now -no-canonical-prefixes -pass-exit-codes '-Wl,--build-id=md5' '-Wl,--hash-style=gnu' -Wl,--gc-sections -Wl,-S -Wl,@bazel-out/host/bin/external/com_google_protobuf/protoc-2.params)
Execution platform: @bazel_tools//platforms:host_platform
bazel-out/host/bin/external/com_google_protobuf/libprotobuf.a(descriptor.o): In function `void std::call_once<void (*)(google::protobuf::FileDescriptorTables const*), google::protobuf::FileDescriptorTables const*>(std::once_flag&, void (*&&)(google::protobuf::FileDescriptorTables const*), google::protobuf::FileDescriptorTables const*&&)::{lambda()#2}::_FUN()':
descriptor.cc:(.text._ZZSt9call_onceIPFvPKN6google8protobuf20FileDescriptorTablesEEJS4_EEvRSt9once_flagOT_DpOT0_ENUlvE0_4_FUNEv[_ZZSt9call_onceIPFvPKN6google8protobuf20FileDescriptorTablesEEJS4_EEvRSt9once_flagOT_DpOT0_ENKUlvE0_clEv]+0x3): undefined reference to `std::__once_callable'
... ...
```

I have tried google and then add/comment different gcc compile flag to try again, but undefined reference similar error happened always. So, I ask for help

Since undefined reference similar error is too long, I redirect to file and paste it, see: https://paste.ubuntu.com/p/V7ccND89nZ/

**Provide the exact sequence of commands / steps that you executed before running into the problem**

Use debian:stretch image to build it, and container has installed `binutils-mips64el-linux-gnuabi64 gcc-mips64el-linux-gnuabi64 gfortran-mips64el-linux-gnuabi64 g++-mips64el-linux-gnuabi64 libpython3-all-dev:mips64el` toolchains

Prepare related env and then  bazel build, lots of undefined reference errors will raise

Any help will be appreciate, thanks!"
36895,"Custom implementations for AvgPool3D, Conv3D, MaxPool3D","**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Debian 9
- TensorFlow installed from (source or binary): Binary
- TensorFlow version (or github SHA if from source): 2.1.0


**Provide the text output from tflite_convert**

```
Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: ADD, CONCATENATION, FULLY_CONNECTED, MUL, RELU6, SOFTMAX. Here is a list of operators for which you will need custom implementations: AvgPool3D, Conv3D, MaxPool3D.

```

Also, please include a link to a GraphDef or the model if possible.

**Any other info / logs**

Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
36894,tf.keras.layers.ReLU() drops tensor._keras_mask (sample_weight) unintentionally.,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information** 
Windows 10 1903, TF 2.0 or 2.1, Python 3.7, CUDA10.1, cuDNN 7.6, GTX 1070 8G

**Describe the current behavior**
tf.keras.layers.ReLU()(x) sets `x._keras_mask` to None.

`tf.keras.layers.Embedding(mask_zero=True)(x)` and `tf.keras.layers.GRU(mask=self_defined_mask)(x)` set a bool Tensor `mask` to `x._keras_mask`. This mask will be passed on to Loss and Metrics and serves as `sample_weight` when calculating the cross_entropy_loss and metrics.accuracy etc. However, it just disappeared after a ReLU layer.

I found tf.keras.layers.ReLU() call K.relu() which in turn calls tf.nn.relu(). `tf.nn.relu()`, a legacy of TF 1.x which doesn't support `_keras_mask`, seems to be the cause of the unintentional drop of the mask.

**Describe the expected behavior**
tf.keras.layers.ReLU()(x) just leaves `x._keras_mask` as it was.

**Code to reproduce the issue** Provide a reproducible test case that is the
bare minimum necessary to generate the problem.

```
class GRU4REC(tf.keras.Model):
    def __init__(self, vocabulary_size, embedding_dim, hidden_units):
        super(GRU4REC, self).__init__()
        self.Embedding = tf.keras.layers.Embedding(vocabulary_size, embedding_dim, mask_zero=True)
        self.FC1 = tf.keras.layers.Dense(hidden_units * 3, tf.nn.relu)
        self.BN1 = tf.keras.layers.BatchNormalization()
        self.RELU = tf.keras.layers.ReLU()
        self.GRU = tf.keras.layers.GRU(hidden_units, return_sequences=True)
        self.FC2 = tf.keras.layers.Dense(vocabulary_size)
        self.BN2 = tf.keras.layers.BatchNormalization()

    def call(self, inputs, training=None, mask=None):
        x = self.Embedding(inputs)
        x = self.FC1(x)
        x = self.BN1(x)
        print(f'before relu: {x._keras_mask}') # print a Tensor
        x = self.RELU(x)
        print(f'after relu: {x._keras_mask}') # print None
        x = self.GRU(x)
        x = self.FC2(x)
        x = self.BN2(x)
        x = self.RELU(x)
        # pred = tf.argmax(x, -1)
        # tf.print('++++++++++')
        # tf.print(tf.shape(pred))
        # eq = tf.equal(inputs, tf.cast(pred, tf.int32))
        # tf.print(tf.reduce_sum(tf.cast(eq, tf.float32)))
        # tf.print('---------')
        return x
```

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

On TF 2.0

```
2020-02-19 20:24:05.261124: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library nvcuda.dll
2020-02-19 20:24:05.292473: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce GTX 1070 computeCapability: 6.1
coreClock: 1.7845GHz coreCount: 15 deviceMemorySize: 8.00GiB deviceMemoryBandwidth: 238.66GiB/s
2020-02-19 20:24:05.292814: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll
2020-02-19 20:24:05.425947: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll
2020-02-19 20:24:05.503908: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_10.dll
2020-02-19 20:24:05.538431: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_10.dll
2020-02-19 20:24:05.660730: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_10.dll
2020-02-19 20:24:05.738706: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_10.dll
2020-02-19 20:24:05.944062: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll
2020-02-19 20:24:05.945225: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-02-19 20:24:05.947055: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce GTX 1070 computeCapability: 6.1
coreClock: 1.7845GHz coreCount: 15 deviceMemorySize: 8.00GiB deviceMemoryBandwidth: 238.66GiB/s
2020-02-19 20:24:05.947607: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll
2020-02-19 20:24:05.947889: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll
2020-02-19 20:24:05.948150: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_10.dll
2020-02-19 20:24:05.948418: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_10.dll
2020-02-19 20:24:05.948677: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_10.dll
2020-02-19 20:24:05.948922: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_10.dll
2020-02-19 20:24:05.949206: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll
2020-02-19 20:24:05.950821: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-02-19 20:24:06.889483: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-02-19 20:24:06.889680: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 
2020-02-19 20:24:06.889787: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N 
2020-02-19 20:24:06.891077: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6376 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1)
before relu: Tensor(""gr_u4rec/embedding/NotEqual:0"", shape=(None, None), dtype=bool)
after relu: None
before relu: Tensor(""model/gr_u4rec/embedding/NotEqual:0"", shape=(None, None), dtype=bool)
after relu: None
2020-02-19 20:24:08.567321: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll

Process finished with exit code -1
```

When I was training a lots-of-zero-padded sequences, the loss went down smoothly as expected while the accuracy soared dramatically. However, everything went just right when I removed ReLU. Hope fix it or help point it out if I was wrong. Thanks~
"
36893,tf.io.gfile.listdir does not with with S3 buckets,"**System information** - MacOS, Tensorflow 2.1, Python 3.7.6

**Describe the current behavior**

Executing `tf.io.gfile.listdir(""s3://bucket-name/"")` results in:

```
/private/var/folders/bn/36k9myl51_v23yyxm629ly4w0000gn/T/tmp.PygT1otw/lib/python3.7/site-packages/tensorflow_core/python/lib/io/file_io.py in list_directory_v2(path)
    644   return [
    645       compat.as_str_any(filename)
--> 646       for filename in pywrap_tensorflow.GetChildren(compat.as_bytes(path))
    647   ]
    648

InvalidArgumentError: S3 path doesn't contain an object name: s3://bucket-name/
```

**Describe the expected behavior**

It should return a list of objects within the bucket.

S3 is quite limited in features for searching/globbing S3 objects but simple operations like listing objects under a given key (in the case above, `/`), are well supported and it would be good to include in Tensorflow.

The error message is also somewhat confusing."
36892,Unable to build r1.15 using gcc 4.8.5-39 because of -std=c++14 argument.,"The crux of this issue is **Does tensorflow r1.15 compile with gcc 4.8.5** when I check out r1.15, I cannot compile due to an invalid argument ""-std=c++14"" similar to #31760 but I do not understand the resolution from that. 

I am preparing to migrate to version 2.X so I tried to build r1.15. I get two errors. 

The first error is resolved in #28824

The second error I have not gotten around. Everthing seems to build fine then I get.

>ERROR: /home/username/.cache/bazel/_bazel_smithm3/6bda0689d89415301f8ee7c16fbd66e8/external/local_config_mlir/BUILD:418:1: C++ compilation of rule '@local_config_mlir//:Support' failed (Exit 1)  
>gcc: error: unrecognized command line option '-std=c++14'


**System information**
- Centos7
- checkout r1.15 and v1.15.1
- Python 3.8.1
- Bazel version 0.25.2
- GCC/Compiler version 4.8.5-039
- CUDA/cuDNN version 10.1/7
- GPU model and memory Nvidia 1080Ti

This appears to be caused by mlir requiring a newer version of gcc, since it requires `-std=c++14` and if you replace it with it with '-std=c++1y' you'lll get an error about `std::make_unique`

Is tensorflow r1.15 supposed to be compatible with gcc 4.8.5 (default on centos 7)?

 **Reproducing the problem.**

git clone https://github.com/tensorflow/tensorflow.git
cd tensorflow
git checkout r1.15
./configure
**Select default options + CUDA**
bazel build //tensorflow/tools/pip_package:build_pip_package
"
36890,How does the frozen model for speech recognition has been created?,"After following the steps train.py and freeze.py from ""https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/sequences/audio_recognition.md"", The inputs of my frozen model(https://imgur.com/a/JtNVkHw) is quite different from the actual frozen model conv_actions_frozen.pb(https://imgur.com/a/KJXExbV). What changes should I make to get the original frozen model for speech recognition?. 
My Python version is 3.7.3 and Tensor flow version is 2.1.0"
36889,"ValueError: We need at least 1 word to plot a word cloud, got 0.","<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information** - Have I written custom code (as opposed to using a stock
example script provided in TensorFlow): - OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04): - Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if
the issue happens on mobile device: - TensorFlow installed from (source or
binary): - TensorFlow version (use command below): - Python version: - Bazel
version (if compiling from source): - GCC/Compiler version (if compiling from
source): - CUDA/cuDNN version: - GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

**Describe the expected behavior**

**Code to reproduce the issue** Provide a reproducible test case that is the
bare minimum necessary to generate the problem.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

normal_words =' '.join([text for text in combi['tidy_tweet'][combi['label'] == 0]]) 
wordcloud = WordCloud(width=800, height=500, random_state=21, max_font_size=110).generate(normal_words) 
plt.figure(figsize=(10, 7)) 
plt.imshow(wordcloud, interpolation=""bilinear"") 
plt.axis('off') 
plt.show()
ValueError: We need at least 1 word to plot a word cloud, got 0.







"
36887,ImportError: DLL load failed: The specified module could not be found.,"C:\Users\ravikumarm\AppData\Local\Programs\Python\Python37\python.exe C:/AI/imageClassification.py
Using TensorFlow backend.
Traceback (most recent call last):
  File ""C:\Users\ravikumarm\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\ravikumarm\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\ravikumarm\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\ravikumarm\AppData\Local\Programs\Python\Python37\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\ravikumarm\AppData\Local\Programs\Python\Python37\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: The specified module could not be found.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:/AI/imageClassification.py"", line 1, in <module>
    from keras.preprocessing.image import ImageDataGenerator
  File ""C:\Users\ravikumarm\AppData\Local\Programs\Python\Python37\lib\site-packages\keras\__init__.py"", line 3, in <module>
    from . import utils
  File ""C:\Users\ravikumarm\AppData\Local\Programs\Python\Python37\lib\site-packages\keras\utils\__init__.py"", line 6, in <module>
    from . import conv_utils
  File ""C:\Users\ravikumarm\AppData\Local\Programs\Python\Python37\lib\site-packages\keras\utils\conv_utils.py"", line 9, in <module>
    from .. import backend as K
  File ""C:\Users\ravikumarm\AppData\Local\Programs\Python\Python37\lib\site-packages\keras\backend\__init__.py"", line 1, in <module>
    from .load_backend import epsilon
  File ""C:\Users\ravikumarm\AppData\Local\Programs\Python\Python37\lib\site-packages\keras\backend\load_backend.py"", line 90, in <module>
    from .tensorflow_backend import *
  File ""C:\Users\ravikumarm\AppData\Local\Programs\Python\Python37\lib\site-packages\keras\backend\tensorflow_backend.py"", line 5, in <module>
    import tensorflow as tf
  File ""C:\Users\ravikumarm\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow\__init__.py"", line 101, in <module>
    from tensorflow_core import *
  File ""C:\Users\ravikumarm\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow_core\__init__.py"", line 40, in <module>
    from tensorflow.python.tools import module_util as _module_util
  File ""C:\Users\ravikumarm\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow\__init__.py"", line 50, in __getattr__
    module = self._load()
  File ""C:\Users\ravikumarm\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow\__init__.py"", line 44, in _load
    module = _importlib.import_module(self.__name__)
  File ""C:\Users\ravikumarm\AppData\Local\Programs\Python\Python37\lib\importlib\__init__.py"", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""C:\Users\ravikumarm\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow_core\python\__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\Users\ravikumarm\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 74, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""C:\Users\ravikumarm\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\ravikumarm\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\ravikumarm\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\ravikumarm\AppData\Local\Programs\Python\Python37\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\ravikumarm\AppData\Local\Programs\Python\Python37\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: The specified module could not be found.


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/errors

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.

Process finished with exit code 1
"
36885,protobuf error when saving model,"**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow):  yes
- OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04): Ubuntu 18.04.3 
- TensorFlow installed from: pip
- TensorFlow version: v2.1.0-rc2-17-ge5bf8de
- Python version: 3.7.0 from anaconda
- CUDA/cuDNN version: 10.1.243
- GPU model and memory: GTX 2080 Ti, 11091 MB

**Describe the current behavior**

when save the model by
```
saver = tf.compat.v1.train.Saver(tf.compat.v1.global_variables(), max_to_keep=3)
path = saver.save(sess, checkpoint_prefix, global_step=current_step)
                            print(""Saved model checkpoint to {}"".format(path))
```
error occurs:

```
[libprotobuf ERROR google/protobuf/wire_format_lite.cc:577] String field 'tensorflow.TensorShapeProto.Dim.name' contains invalid UTF-8 data when parsing a protocol buffer. Use the 'bytes' type if you intend to send raw bytes.
Traceback (most recent call last):
  File ""cnn.py"", line 374, in <module>
    train(args, x_train, y_train, vocab_size, x_dev, y_dev)
  File ""cnn.py"", line 279, in train
    path = saver.save(sess, checkpoint_prefix, global_step=current_step)
  File ""xxx/anaconda3/envs/li/lib/python3.7/site-packages/tensorflow_core/python/training/saver.py"", line 1203, in save
    save_debug_info=save_debug_info)
  File ""xxx/anaconda3/envs/li/lib/python3.7/site-packages/tensorflow_core/python/training/saver.py"", line 1246, in export_meta_graph
    graph_def=ops.get_default_graph().as_graph_def(add_shapes=True),
  File ""xxx/anaconda3/envs/li/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py"", line 3134, in as_graph_def
    result, _ = self._as_graph_def(from_version, add_shapes)
  File ""xxx/anaconda3/envs/li/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py"", line 3051, in _as_graph_def
    graph.ParseFromString(compat.as_bytes(data))
google.protobuf.message.DecodeError: Error parsing message
```

"
36884,sue: Build/Installation Issue,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version:
- Python version:
- Installed using virtualenv? pip? conda?:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:



**Describe the problem**

**Provide the exact sequence of commands / steps that you executed before running into the problem**


**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
36883,Not able to load a saved model with custom layer,"Please make sure that this is a bug. As per our

**System information** - Have I written custom code (as opposed to using a stock
example script provided in TensorFlow): - OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04): - Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if
the issue happens on mobile device: - TensorFlow installed from (source or
binary): - TensorFlow version (use command below): - Python version: - Bazel
version (if compiling from source): - GCC/Compiler version (if compiling from
source): - CUDA/cuDNN version: - GPU model and memory:


OS - CentOs
tensorflow-gpu = 2.1.0
tensorflow = 2.0.0
installed in the conda version - conda version : 4.8.1
using cuda - CUDA Version: 10.1
Gpu - Tesla K80
python - 3.6


You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
I have created a custom Layer and trained the model using that layer, but when I load the model back, it is not able to load all the weight values.
**Describe the expected behavior**
It should be able to load the weight values.
**Code to reproduce the issue** Provide a reproducible test case that is the
bare minimum necessary to generate the problem.
```python
from __future__ import absolute_import, division, print_function, unicode_literals
from tensorflow.keras import initializers
from tensorflow.keras import layers
from tensorflow.keras.models import load_model
from tensorflow.keras.layers import Input, Dense
from tensorflow.python.keras import backend as K
from tensorflow.python.keras.utils import tf_utils
from tensorflow.keras.layers import LeakyReLU
import tensorflow as tf
import tensorflow as tf
import tensorflow.keras
from tensorflow.keras.callbacks import *
from tensorflow.keras.losses import mse

### create a custom layer

class CustomBatchNormalization(layers.Layer):
    def __init__(self, momentum=0.99, epsilon=1e-3,beta_initializer='zeros',
                 gamma_initializer='ones', moving_mean_initializer='zeros',
                 moving_range_initializer='ones',**kwargs):
        super(CustomBatchNormalization, self).__init__(**kwargs)
        self.supports_masking = True
        self.momentum = momentum
        self.epsilon = epsilon
        self.beta_initializer = initializers.get(beta_initializer)
        self.gamma_initializer = initializers.get(gamma_initializer)
        self.moving_mean_initializer = initializers.get(moving_mean_initializer)
        self.moving_range_initializer = (
            initializers.get(moving_range_initializer))

    
    def build(self,input_shape):
        dim = input_shape[-1]
        shape = (dim,)
        self.gamma = self.add_weight(shape=shape,
                             name='gamma',
                             initializer=self.gamma_initializer,trainable=True)
        self.beta = self.add_weight(shape=shape,
                            name='beta',
                            initializer=self.beta_initializer,
                                   trainable=True)
        
        self.moving_mean = self.add_weight(
            shape=shape,
            name='moving_mean',
            initializer=self.moving_mean_initializer,
            trainable=False)
        
        self.moving_range = self.add_weight(
            shape=shape,
            name='moving_range',
            initializer=self.moving_range_initializer,
            trainable=False)



    def call(self, inputs,training=None):
        input_shape = inputs.shape
        
        if training == False:
            scaled = (inputs-self.moving_mean)/(self.moving_range+self.epsilon)
            return self.gamma*scaled + self.beta
        
        mean = tf.math.reduce_mean(inputs,axis=0)
        maxr = tf.math.reduce_max(inputs,axis=0)
        minr = tf.math.reduce_min(inputs,axis=0)
        
        range_diff = tf.math.subtract(maxr,minr)
        self.moving_mean = tf.math.add(self.momentum*self.moving_mean, (1-self.momentum)*mean)
        self.moving_range = tf.math.add(self.momentum*self.moving_range,(1-self.momentum)*range_diff)
        scaled = tf.math.divide(tf.math.subtract(inputs,mean),(range_diff+self.epsilon))
        return tf.math.add(tf.math.multiply(self.gamma,scaled),self.beta)
    
    def get_config(self):
        config = {
            'momentum': self.momentum,
            'epsilon': self.epsilon,
            'beta_initializer': initializers.serialize(self.beta_initializer),
            'gamma_initializer': initializers.serialize(self.gamma_initializer),
            'moving_mean_initializer':
                initializers.serialize(self.moving_mean_initializer),
            'moving_range_initializer':
                initializers.serialize(self.moving_range_initializer)
        }
        base_config = super(CustomBatchNormalization, self).get_config()
        return dict(list(base_config.items()) + list(config.items()))
    
    def compute_output_shape(self, input_shape):
        return input_shape


### create your model
inp = Input(shape=(4,))
batch_norm_1 = CustomBatchNormalization(dynamic=True)(inp)
densout = Dense(24, activation='linear')(batch_norm_1)
densout = LeakyReLU(alpha=0.3)(densout)
batch_norm_2 = CustomBatchNormalization(dynamic=True)(densout)
densout = Dense(128, activation='linear')(batch_norm_2)
densout = LeakyReLU(alpha=0.3)(densout)
batch_norm_out = CustomBatchNormalization(dynamic=True)(densout)
out = Dense(5, activation='linear')(batch_norm_out)
test_nw = tf.keras.models.Model(inp, out)

##compile it
test_nw.compile(tf.keras.optimizers.Adam(), loss=mse,experimental_run_tf_function=False)

path_HDF5 = 'PATH_TO_SAVE_THIS_MODEL'
earlyStopping = EarlyStopping(monitor='val_loss', patience=10, verbose=0, mode='min')
mcp_save_RH = ModelCheckpoint(path_HDF5,save_best_only=True, monitor='val_loss', mode='min')

X = np.random.randn(4,4)
y = np.random.randn(4,5)
X_val = np.random.randn(4,4)
y_val = np.random.randn(4,5)
test_nw.fit(X,y,batch_size=4, epochs=10,validation_data = (X_val,y_val),callbacks=[earlyStopping, mcp_save_RH] )

######## Now restart the kernel and load the model
dict_lay = {'CustomBatchNormalization':CustomBatchNormalization}
mod = load_model(path_HDF5,custom_objects=dict_lay)
```

I get an error saying that
 ```
ValueError                                Traceback (most recent call last)
<ipython-input-9-8655e6764114> in <module>
----> 1 mod = load_model(path_HDF5+'CI01_RH_CBN_test.hdf5',custom_objects=dict_lay)

~/miniconda3/envs/CbrainCustomLayer/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py in load_model(filepath, custom_objects, compile)
    144   if (h5py is not None and (
    145       isinstance(filepath, h5py.File) or h5py.is_hdf5(filepath))):
--> 146     return hdf5_format.load_model_from_hdf5(filepath, custom_objects, compile)
    147 
    148   if isinstance(filepath, six.string_types):

~/miniconda3/envs/CbrainCustomLayer/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py in load_model_from_hdf5(filepath, custom_objects, compile)
    169 
    170     # set weights
--> 171     load_weights_from_hdf5_group(f['model_weights'], model.layers)
    172 
    173     if compile:

~/miniconda3/envs/CbrainCustomLayer/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py in load_weights_from_hdf5_group(f, layers)
    695                        str(len(symbolic_weights)) +
    696                        ' weights, but the saved weights have ' +
--> 697                        str(len(weight_values)) + ' elements.')
    698     weight_value_tuples += zip(symbolic_weights, weight_values)
    699   K.batch_set_value(weight_value_tuples)

ValueError: Layer #0 (named ""custom_batch_normalization_17"" in the current model) was found to correspond to layer custom_batch_normalization_17 in the save file. However the new layer custom_batch_normalization_17 expects 4 weights, but the saved weights have 2 elements.

```
**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
36882,Is NonMaxSuppressionV4 supported？,"**System information**
- Linux Ubuntu 16.04
- TensorFlow 2.1.0


**Provide the text output from tflite_convert**
```
Here is a list of operators for which you will need custom implementations: NonMaxSuppressionV4.
```

**Code**
```
selected_indices_padded,  num_valid = tf.image.non_max_suppression(boxes=boxes_squeezed,
                                                  scores=scores,
                                                  max_output_size=20,
                                                  score_threshold=0.7,
                                                  iou_threshold=0.5,
                                                  pad_to_max_output_size=True,
                                                  )
```

According to https://www.tensorflow.org/lite/guide/ops_compatibility,  `NON_MAX_SUPPRESSION_V4` was already supported.
However,  when I use it to build my model and try to convert it into tflite, the error came out.

I tried a solution with `tf.lite.OpsSet.SELECT_TF_OPS`, and the error gone.
```
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS,
                                       tf.lite.OpsSet.SELECT_TF_OPS]
```

But I cannot run it properly with native TFLite intepreter... Another error showed as below:

```
RuntimeError: Regular TensorFlow ops are not supported by this interpreter. Make sure you apply/link the Flex delegate before inference.Node number 92 (FlexNonMaxSuppressionV4) failed to prepare.
```






"
36881,"How could I can add a new OS on the support on the ""tested and supported"" list?","## URL(s) with the issue:
https://www.tensorflow.org/install

## Description of issue (what needs changing):
Could someone instruct me how to add a new OS on the support on the ""tested and supported"" list, I would like to make some efforts for Opensuse and SLE. 

There might have some steps to make sure an OS is ""tested and supported"", right?

"
36880,No gradients for bias and kernels in Dense layer. ,"**System information** - Have I written custom code (as opposed to using a stock
example script provided in TensorFlow): - Yes
OS: Mac OS Catalina 
TensorFlow installed from: pip
TensorFlow version:  2.1 
 Python version: - 3.7


I'm getting this error, 

`**WARNING:tensorflow:Gradients do not exist for variables ['flight_2/layer1/kernel:0', 'flight_2/layer1/bias:0', 'flight_2/layer2/kernel:0', 'flight_2/layer2/bias:0', 'flight_2/layer3/kernel:0', 'flight_2/layer3/bias:0'] when minimizing the loss.
WARNING:tensorflow:Gradients do not exist for variables ['flight_2/layer1/kernel:0', 'flight_2/layer1/bias:0', 'flight_2/layer2/kernel:0', 'flight_2/layer2/bias:0', 'flight_2/layer3/kernel:0', 'flight_2/layer3/bias:0'] when minimizing the loss.**


Here's my full code, which is enough for re-producing problem
```

import dask.dataframe as dd
import numpy as np
import tensorflow as tf
tf.compat.v1.enable_eager_execution()
tf.keras.backend.set_floatx('float64')
import time
pd.options.display.float_format = '{:,.2f}'.format
from scipy import stats
import matplotlib as mpl
mpl.rcParams['agg.path.chunksize'] = 10000
import os




from tensorflow.keras.layers import LSTM, GRU



from sklearn.preprocessing import LabelEncoder, StandardScaler


%matplotlib inline

tf.__version__

# data = dd.read_csv(""s3://search-curated-sec/bom_pat_6e_aberogate_new.csv/*.csv"")
data = pd.read_csv('../data/bom_pat_6e_abrogate.csv')

data.dropna(inplace=True)

data['deptime'] = data['deptime'].astype(str).str.pad(4, fillchar='0')
data['depinf'] = data['depdate'].astype(str) + data['deptime'].astype(str)
for i in ['booktime','changeDateTime_1', 'changeDateTime_2',
       'changeDateTime_3', 'changeDateTime_4', 'changeDateTime_5',
       'changeDateTime_6', 'changeDateTime_7', 'changeDateTime_8',
       'changeDateTime_9', 'changeDateTime_10', 'aberogateTime']:
    data[i] = pd.to_datetime(data[i], format = '%Y%m%d%H')

data['depinf'] = pd.to_datetime(data['depinf'], format='%Y%m%d%H%M')

data.drop(['bookdate', 'depdate', 'deptime'], axis=1, inplace=True)

data.head()

data['diff_book_3'] = data.apply(lambda x: (x['changeDateTime_3'] - x['booktime']).total_seconds(), axis=1)

data.to_csv('../data/bom_pat_6e_abrogate.csv', index=False)

data[data['diff_book_3']>=0].shape

data.shape

data['diff_book_3'] = (pd.to_datetime(data['changeDateTime_3']) - pd.to_datetime(data['booktime'])).dt.total_seconds() // 3600

### Features

data.columns

lbl1 = LabelEncoder()
std = StandardScaler()

data['trans_fno'] = lbl1.fit_transform(data['fno'])

features = np.array([data['duration'], data['htg'], data['fare'],  data['trans_fno'], pd.to_datetime(data['booktime']).dt.month, pd.to_datetime(data['booktime']).dt.day, pd.to_datetime(data['depinf']).dt.month, pd.to_datetime(data['depinf']).dt.day]).T

target = data['diff_book_3'].values

#Standardizing all features
features = std.fit_transform(features)

# Starting Model

class Flight(tf.keras.Model):
    def __init__(self, layer1_units = 512, layer2_units = 256, layer3_units = 128):
        super(Flight, self).__init__()
        self.layer1 = layer1_units
        self.layer2 = layer2_units
        self.layer3 = layer3_units

        
        self.linear1 = tf.keras.layers.Dense(self.layer1, activation='relu', input_shape = (9, ), kernel_regularizer=tf.keras.regularizers.l2(1e-3), name='layer1')
        self.linear2 = tf.keras.layers.Dense(self.layer2, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(1e-3), name='layer2')
        self.linear3 = tf.keras.layers.Dense(self.layer3, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(1e-3), name='layer3')
        self.linear4 = tf.keras.layers.Dense(1, activation='linear', kernel_regularizer=tf.keras.regularizers.l2(1e-3), name='layer4')


    def call(self, x):
        output = self.linear1(x)
        output = self.linear2(x)
        output = self.linear3(x)
        output = self.linear4(x)
        return output

#### Creating a tf.data dataset 

batch_size = 10000


data_size = len(features)
steps_per_epoch = len(features)//batch_size

dataset = tf.data.Dataset.from_tensor_slices((features, target))
dataset = dataset.batch(batch_size, drop_remainder=True)

#Checking sample data size
example_input_batch, example_target_batch = next(iter(dataset))
print(""This is sample input_batch shape and target_batch shape: "",example_input_batch.shape, example_target_batch.shape)

flight = Flight()
sample_output = flight(example_input_batch)

for l in flight.layers:
    print(l.name, l.trainable)

sample_output = flight(example_input_batch)

optimizer = tf.keras.optimizers.Adam()
loss_calc = tf.keras.losses.MeanAbsoluteError()

# Saving checkpoints
checkpoint_dir = './training_checkpoints'
checkpoint_prefix = os.path.join(checkpoint_dir, ""ckpt"")
checkpoint = tf.train.Checkpoint(optimizer=optimizer,
                                flight = flight)

@tf.function
def train_step(inp, targ):
    loss = 0

    with tf.GradientTape() as tape:
        predicted = flight(inp)

        loss = loss_calc(targ, predicted)
        
        variables = flight.variables

        gradients = tape.gradient(loss, variables)

        optimizer.apply_gradients(zip(gradients, variables))

    return loss

epochs = 5
for epoch in range(epochs):
        start = time.time()

#         flight_hidden = flight.initialize_hidden_state()
        total_loss = 0

        for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):
            batch_loss = train_step(inp, targ)
            total_loss += batch_loss

        # saving (checkpoint) the model every 2 epochs
        checkpoint.save(file_prefix = checkpoint_prefix)

        print('Epoch {} Loss {:.4f}'.format(epoch + 1,
                                        total_loss / steps_per_epoch))
        print('Time taken for 1 epoch {} sec\n'.format(time.time() - start))

```


I've added a sample dataset for reproducing the problem. 
[tensorflow_issue.csv.zip](https://github.com/tensorflow/tensorflow/files/4223717/tensorflow_issue.csv.zip)


"
36879,Basic LSTM TFLite model created with new experimental converter results in model with incorrect output shape,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Google Colab
- TensorFlow installed from (source or binary): binary
- TensorFlow version (or github SHA if from source): 2.2.0-dev20200218


**Command used to run the converter or code if you’re using the Python API**

```
converter = tf.lite.TFLiteConverter.from_keras_model(model)
converter.experimental_new_converter = True
tflite_model = converter.convert()
open(""mnist_lstm_f32.tflite"", ""wb"").write(tflite_model)
```

**The output from the converter invocation**

```
Conversion is successful
```

**Failure details**
I am creating a basic MNIST classification model which includes a single LSTM layer. Using the new experimental converter option, the model can be converted to TFLite format successfully and inferring from the TFLite model using the Python Interpreter API gives correct results.

However, the model's output shape is just an empty array and running the model on Android required the output buffer size to be specified so the model crashes. I expect the output shape to be ```[1, 10]``` however that is not the case as shown below.
```
[{'name': 'Identity', 'index': 52, 'shape': array([], dtype=int32), 'shape_signature': array([], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]
```


**Any other info / logs**
[Colab notebook](https://colab.research.google.com/drive/1X5B2O2aF9HlVX0GHl1IAASPqrz45ujff)
"
36878,"Tflearn import error in Tensorflow 2.1: ""ModuleNotFoundError: No module named 'tensorflow.contrib'""","So, basically, I am trying to migrate the entire code to TF 2.1.0. However, it seems that **tensorflow.contrib** has been deprecated. Due to this, importing tflearn always throws an error of the missing module of tf.contrib. So, how am I supposed to implement this code without using tflearn?
```python
def get_vocab_processor(model_dir):
    vocab_path = os.path.join(model_dir, "".."", ""vocab"")
    #vocab_processor = tf.contrib.learn.preprocessing.VocabularyProcessor.restore(vocab_path)
    #tflearn import error. tflearn support removed from Tensorflow 2.1.0
    import tflearn
    vocab_processor = tflearn.data_utils.VocabularyProcessor.restore(filename=vocab_path)
    return vocab_processor
```

And then, I use this method like this:
```python
def process(FLAGS, dataset):
    x_raw, y_test = data_helpers.load_data_labels(dataset)
    y_test = np.argmax(y_test, axis=1)

    vocab_processor = get_vocab_processor(FLAGS.model_dir)
    x_test = np.array(list(vocab_processor.transform(x_raw)))

    model_file = tf.train.latest_checkpoint(FLAGS.model_dir)
```
**Edit:**
**This is the error I get after execution:**
```
Traceback (most recent call last):
  File ""c:\Users\koustubh.p\Downloads\multiple-signal-detection\multiple-signal-detection\churn_updated.py"", line 179, in <module>
    process(FLAGS, dataset)
  File ""c:\Users\koustubh.p\Downloads\multiple-signal-detection\multiple-signal-detection\churn_updated.py"", line 110, in process
    vocab_processor = get_vocab_processor(FLAGS.model_dir)
  File ""c:\Users\koustubh.p\Downloads\multiple-signal-detection\multiple-signal-detection\churn_updated.py"", line 102, in get_vocab_processor
    import tflearn
  File ""c:\Users\koustubh.p\Downloads\multiple-signal-detection\multiple-signal-detection\venv\lib\site-packages\tflearn\__init__.py"", line 4, in <module>
    from . import config
  File ""c:\Users\koustubh.p\Downloads\multiple-signal-detection\multiple-signal-detection\venv\lib\site-packages\tflearn\config.py"", line 5, in <module>
    from .variables import variable
  File ""c:\Users\koustubh.p\Downloads\multiple-signal-detection\multiple-signal-detection\venv\lib\site-packages\tflearn\variables.py"", line 7, in <module>
    from tensorflow.contrib.framework.python.ops import add_arg_scope as contrib_add_arg_scope
ModuleNotFoundError: No module named 'tensorflow.contrib'
```"
36877,Memory leak in TensorFlow 2.0 DataSet when using group_by_window.,"**System information**
- OS Platform: - Google Cloud Linux Ubuntu 16.04 
- TensorFlow installed from (source or binary): binary
- TensorFlow version: 2.0.0
- Python version: 3.7
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10.01
- GPU model and memory: Tesla P100, 16GB
- Running on GRAPH MODE:- YES

This is creating memory leak.
```
def pairwise_batch_iterator(tf_records,
                           no_threads=14,
                           batch_size=64,
                           num_epochs=50):
    
    dataset = make_dataset(tf_records, no_threads)
    dataset = dataset.repeat(num_epochs)
    
    dataset = dataset.apply(tf.data.experimental.group_by_window(
        key_func=lambda elem, *args: elem,
        reduce_func=lambda _, window: window.batch(batch_size),
        window_size=batch_size))
    
    dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)
    
    return dataset
```

This works fine
```
def pairwise_batch_iterator(tf_records,
                           no_threads=14,
                           batch_size=64,
                           num_epochs=50):
    
    dataset = make_dataset(tf_records, no_threads)
    dataset = dataset.repeat(num_epochs)
    
    dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)
    
    return dataset
```
***
I am training a pairwise ranking model where I have to group by query id that's why I am using tf.data.experimental.group_by_window and this is creating a memory leak. If I use the second version of code I don't face any issue but I have to group by query id.
***
"
36875,Add a Model.fit-like API for seq2seq models,"Many models can be trained by `tf.keras.Model.fit` API, which is very convenient. But for seq2seq models, we have to use a custom training loop. As we know, seq2seq Models are used very often, so why not build a API to train these models in a convenient way?"
36874,time of tensorflow1.14 built from source perfroms worse than tensorflow1.14 from pypi,"**System information**
- OS Platform and Distribution : Linux Ubuntu 16.04
- TensorFlow installed from: source
- TensorFlow version:1.14.0
- Python version:3.6.2
- Installed using :pip
- Bazel version: 0.25.2
- GCC/Compiler version: 5.4.0
- CPU: Intel Core i9-9900K


I want to speed up CPU inference on trained Mask R-CNN pb model.  So, I followed instructions on tensorflow webpage [here](https://www.tensorflow.org/install/source) and method from intel [here](https://software.intel.com/en-us/articles/intel-optimization-for-tensorflow-installation-guide#linux_B_S).  

**Here is .tf_configure.bazelrc after running ./configure**
- build --action_env PYTHON_BIN_PATH=""/home/allen/miniconda3/envs/tf1_mkl/bin/python""
- build --action_env PYTHON_LIB_PATH=""/home/allen/miniconda3/envs/tf1_mkl/lib/python3.6/site-packages""
- build --python_path=""/home/allen/miniconda3/envs/tf1_mkl/bin/python""
- build:xla --define with_xla_support=true
- build --config=xla
- build --action_env TF_NEED_OPENCL_SYCL=""0""
- build --action_env TF_NEED_ROCM=""0""
- build --action_env TF_NEED_CUDA=""0""
- build --action_env TF_DOWNLOAD_CLANG=""0""
- build:opt --copt=-march=native
- build:opt --copt=-Wno-sign-compare
- build:opt --host_copt=-march=native
- build:opt --define with_default_optimizations=true
- build:v2 --define=tf_api_version=2
- test --flaky_test_attempts=3
- test --test_size_filters=small,medium
- test --test_tag_filters=-benchmark-test,-no_oss,-oss_serial
- test --build_tag_filters=-benchmark-test,-no_oss
- test --test_tag_filters=-gpu
- test --build_tag_filters=-gpu
- build --action_env TF_CONFIGURE_IOS=""0""

**Here is my bazel build command:**
`bazel build --config=mkl --cxxopt=-D_GLIBCXX_USE_CXX11_ABI=0 --copt=-march=sandybridge --copt=-mtune=ivybridge --copt=-O3 //tensorflow/tools/pip_package:build_pip_package
`
**Next, I generated whl and installed successfully.**
But time of sess.run of Mask R-CNN is about 1s per image, which is worse than tf1.14 installed from pypi.
**Here is the output using tensorflow installed from source **

> WARNING:tensorflow:
> The TensorFlow contrib module will not be included in TensorFlow 2.0.
> For more information, please see:
>   * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
>   * https://github.com/tensorflow/addons
>   * https://github.com/tensorflow/io (for I/O related ops)
> If you depend on functionality not listed there, please file an issue.
> 
> WARNING:tensorflow:From time_compare.py:314: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.
> 
> WARNING:tensorflow:From time_compare.py:43: FastGFile.__init__ (from tensorflow.python.platform.gfile) is deprecated and will be removed in a future version.
> Instructions for updating:
> Use tf.gfile.GFile.
> W0219 12:14:37.498566 140296832321280 deprecation.py:323] From time_compare.py:43: FastGFile.__init__ (from tensorflow.python.platform.gfile) is deprecated and will be removed in a future version.
> Instructions for updating:
> Use tf.gfile.GFile.
> WARNING:tensorflow:From time_compare.py:44: The name tf.GraphDef is deprecated. Please use tf.compat.v1.GraphDef instead.
> 
> W0219 12:14:37.498702 140296832321280 module_wrapper.py:139] From time_compare.py:44: The name tf.GraphDef is deprecated. Please use tf.compat.v1.GraphDef instead.
> 
> Graph loaded.
> WARNING:tensorflow:From time_compare.py:50: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.
> 
> W0219 12:14:38.048038 140296832321280 module_wrapper.py:139] From time_compare.py:50: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.
> 
> 2020-02-19 12:14:38.048334: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  AVX2 FMA
> To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.
> 2020-02-19 12:14:38.070567: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3600000000 Hz
> 2020-02-19 12:14:38.071554: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55ed8c786280 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
> 2020-02-19 12:14:38.071582: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
> 2020-02-19 12:14:38.072303: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.
> Image No.0 time cost:2.7566s/home/allen/ytzx/dataset/cwfp/v4/val2014/001002_r180_81445.jpg, time:2.756582736968994
> Image No.1 time cost:0.9806s/home/allen/ytzx/dataset/cwfp/v4/val2014/001006_r270_80042.jpg, average time:0.9805862903594971

**And here is inference output using tensorflow installed from pypi**

> WARNING:tensorflow:From time_compare.py:314: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.
> 
> WARNING:tensorflow:From time_compare.py:43: FastGFile.__init__ (from tensorflow.python.platform.gfile) is deprecated and will be removed in a future version.
> Instructions for updating:
> Use tf.gfile.GFile.
> W0219 12:15:57.491406 139925355824896 deprecation.py:323] From time_compare.py:43: FastGFile.__init__ (from tensorflow.python.platform.gfile) is deprecated and will be removed in a future version.
> Instructions for updating:
> Use tf.gfile.GFile.
> WARNING:tensorflow:From time_compare.py:44: The name tf.GraphDef is deprecated. Please use tf.compat.v1.GraphDef instead.
> 
> W0219 12:15:57.491531 139925355824896 deprecation_wrapper.py:119] From time_compare.py:44: The name tf.GraphDef is deprecated. Please use tf.compat.v1.GraphDef instead.
> 
> Graph loaded.
> WARNING:tensorflow:From time_compare.py:50: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.
> 
> W0219 12:15:58.086142 139925355824896 deprecation_wrapper.py:119] From time_compare.py:50: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.
> 
> 2020-02-19 12:15:58.086468: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
> 2020-02-19 12:15:58.110562: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3600000000 Hz
> 2020-02-19 12:15:58.111640: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56350f20bfb0 executing computations on platform Host. Devices:
> 2020-02-19 12:15:58.111652: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
> 2020-02-19 12:15:58.891970: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
> Image No.0 time cost:1.2104s/home/allen/ytzx/dataset/cwfp/v4/val2014/001002_r180_81445.jpg, time:1.2104294300079346
> Image No.1 time cost:0.376s/home/allen/ytzx/dataset/cwfp/v4/val2014/001006_r270_80042.jpg, average time:0.3759894371032715
> 
Any suggestions or thoughts would be appreciated.
"
36872,How to quant TFLite model in int8 format,"@tensorflow/micro

**System information**
- Host OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
   -- x86 Linux Ubuntu 16.04
- TensorFlow installed from (source or binary):
   -- binary
- Tensorflow version (commit SHA if source):
   -- 2.1.0
- Target platform (e.g. Arm Mbed OS, Arduino Nano 33 etc.):
   -- x86 Linux

**Describe the problem**
   -- How to quant TF model to int8 format so that I can use CMSIS-NN int8 APIs
**Please provide the exact sequence of commands/steps when you ran into the problem**
   -- I try the toco command:
       toco --saved_model_dir /home/swai01/tfl-m_speech_model --output_file=./conv_int8.tflite --input_shapes=1,49,40,1 --input_arrays=Reshape_2 --output_arrays='labels_softmax' --inference_type=QUANTIZED_INT8 --mean_values=0 --std_dev_values=9.8077
      but got the error message:
          ValueError: This converter can only convert a single ConcreteFunction. Converting multiple functions is under development.
   Thanks for your time.

ruey-an
"
36871,whether the netwrok code is needed to run the prediction procedure,"Hi,

I have the trained .pb model, and I would like to load it and then run the prediction procedure.

Is the network code needed to run the prediction?, or I only need the following code but don't need the network code?



```cpp
Model model(""../ssd_inception/frozen_inference_graph.pb"");
    auto outNames1 = new Tensor(model, ""num_detections"");
    auto outNames2 = new Tensor(model, ""detection_scores"");
    auto outNames3 = new Tensor(model, ""detection_boxes"");
    auto outNames4 = new Tensor(model, ""detection_classes"");

    auto inpName = new Tensor(model, ""image_tensor"");

    // Read image
    cv::Mat img, inp;
    img = cv::imread(""../test.jpg"", CV_LOAD_IMAGE_COLOR);

    int rows = img.rows;
    int cols = img.cols;

    cv::resize(img, inp, cv::Size(300, 300));
    cv::cvtColor(inp, inp, CV_BGR2RGB);

    // Put image in Tensor
    std::vector<uint8_t > img_data;
    img_data.assign(inp.data, inp.data + inp.total() * inp.channels());
    inpName->set_data(img_data, {1, 300, 300, 3});

    model.run(inpName, {outNames1, outNames2, outNames3, outNames4});

```


Thanks,
Ardeal

"
36870,How to override gradient in a FuncGraph created by tf.function,"With tensorflow 1.x API, I can override gradients with a gradient_override_map during building a graph as follows

```    
@tf.RegisterGradient('CustZero')
def _custom_grad(op, grad):
    return tf.zeros_like(op.inputs[0])
    
with tf.compat.v1.Session() as sess:
    with sess.graph.as_default() as g:
        x = tf.convert_to_tensor([-1.0, 0.0, 1.0, 2.0])
        with g.gradient_override_map({'Relu': 'CustZero'}):
            y = tf.nn.relu(x)
    dy = tf.gradients(y, x)

# dy: [0., 0., 0., 0.]
```

As we are moving to TF2, I'd like to use native TF2 API to do the same task with `tf.function` and `tf.GradientTape`. As I have learnt, `tf.function` creates a FuncGraph for each different `input_signature`, and I can use `get_concrete_function` to create one ConcreteFunction with a specific `input_signature`. Then I can get the `FuncGraph` associated with the `ConcreteFunction`. This is what I have tried, which failed to override gradients.

```
# create a concrete function with the specified input signatures
@tf.function(input_signature=(tf.TensorSpec(shape=(None,), dtype=tf.float32),))
def my_relu(x):
    return tf.nn.relu(x)
my_relu_conc = my_relu.get_concrete_function()

x = tf.constant([-1.0, 0.0, 1.0, 2.0], dtype=tf.float32)
with tf.GradientTape() as tape:
    with my_relu_conc.graph.gradient_override_map({'Relu': 'CustZero'}):
        tape.watch(x)
        y = my_relu_conc(x)
dy = tape.gradient(y, x).numpy()

# dy: [0., 0., 1., 1.]
```

From my understanding, since the FuncGraph is already traced, the graph cannot be changed and I cannot override with custom gradients. 

My question is: are there any methods to override gradient using native TF2 APIs?

If not, could we add an additional parameter named `gradient_override_map` to `tf.function` or `get_concrete_function` such that we can override gradients in the process where a FuncGraph is created? 

```
@tf.function(
    input_signature=(tf.TensorSpec(shape=(None,), dtype=tf.float32),), 
    gradient_override_map={'Relu': 'CustZero'})
def my_relu(x):
    return tf.nn.relu(x)
my_relu_conc = my_relu.get_concrete_function()
```
or 

```
@tf.function()
def my_relu(x):
    return tf.nn.relu(x)
my_relu_conc = my_relu.get_concrete_function(
    input_signature=(tf.TensorSpec(shape=(None,), dtype=tf.float32),), 
    gradient_override_map={'Relu': 'CustZero'})
```"
36867,Why i have same value in confusion matrix always 12% even after 17000 lerning rate?,"Model after train don,t work and Confusion matrix have one column value other column 0
"
36866,missing ops,"**System information**
- MacOS Mojave: 10.14.6
- TensorFlow installed from binary
- TensorFlow version: 2.1.0


**Provide the text output from tflite_convert**

```
Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: CONV_2D, FULLY_CONNECTED, RESHAPE, SOFTMAX, STRIDED_SLICE, TANH. Here is a list of operators for which you will need custom implementations: TensorListFromTensor, TensorListReserve, TensorListStack, While.
```

Also, please include a link to a GraphDef or the model if possible.

**Any other info / logs**

Full output:
```
2020-02-18 12:08:47.613890: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-02-18 12:08:47.641459: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fb45f7d55d0 executing computations on platform Host. Devices:
2020-02-18 12:08:47.641499: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version
WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.
W0218 12:08:48.275663 4679718336 hdf5_format.py:198] Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.
2020-02-18 12:08:48.596718: I tensorflow/core/grappler/devices.cc:60] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA support)
2020-02-18 12:08:48.596828: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session
2020-02-18 12:08:48.620729: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:716] Optimization results for grappler item: graph_to_optimize
2020-02-18 12:08:48.620755: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718]   function_optimizer: Graph size after: 125 nodes (0), 151 edges (0), time = 7.053ms.
2020-02-18 12:08:48.620760: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718]   function_optimizer: Graph size after: 125 nodes (0), 151 edges (0), time = 3.511ms.
2020-02-18 12:08:48.620765: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:716] Optimization results for grappler item: sequential_gru_while_cond_1874
2020-02-18 12:08:48.620769: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718]   function_optimizer: function_optimizer did nothing. time = 0.005ms.
2020-02-18 12:08:48.620773: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-02-18 12:08:48.620778: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:716] Optimization results for grappler item: sequential_gru_while_body_1875
2020-02-18 12:08:48.620871: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-02-18 12:08:48.620884: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-02-18 12:08:48.704099: I tensorflow/core/grappler/devices.cc:60] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA support)
2020-02-18 12:08:48.704194: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session
2020-02-18 12:08:48.742007: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:716] Optimization results for grappler item: graph_to_optimize
2020-02-18 12:08:48.742026: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718]   constant folding: Graph size after: 60 nodes (-5), 70 edges (-9), time = 19.624ms.
2020-02-18 12:08:48.742030: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718]   constant folding: Graph size after: 60 nodes (0), 70 edges (0), time = 4.102ms.
2020-02-18 12:08:48.742033: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:716] Optimization results for grappler item: sequential_gru_while_body_1875_frozen
2020-02-18 12:08:48.742035: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718]   constant folding: Graph size after: 79 nodes (0), 98 edges (0), time = 1.601ms.
2020-02-18 12:08:48.742038: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718]   constant folding: Graph size after: 79 nodes (0), 98 edges (0), time = 1.559ms.
2020-02-18 12:08:48.742040: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:716] Optimization results for grappler item: sequential_gru_while_cond_1874_frozen
2020-02-18 12:08:48.742144: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718]   constant folding: Graph size after: 14 nodes (0), 4 edges (0), time = 0.29ms.
2020-02-18 12:08:48.742148: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718]   constant folding: Graph size after: 14 nodes (0), 4 edges (0), time = 0.202ms.
Traceback (most recent call last):
  File ""/usr/local/bin/tflite_convert"", line 10, in <module>
    sys.exit(main())
  File ""/usr/local/lib/python3.7/site-packages/tensorflow_core/lite/python/tflite_convert.py"", line 515, in main
    app.run(main=run_main, argv=sys.argv[:1])
  File ""/usr/local/lib/python3.7/site-packages/tensorflow_core/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/usr/local/lib/python3.7/site-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/usr/local/lib/python3.7/site-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""/usr/local/lib/python3.7/site-packages/tensorflow_core/lite/python/tflite_convert.py"", line 502, in run_main
    _convert_tf2_model(tflite_flags)
  File ""/usr/local/lib/python3.7/site-packages/tensorflow_core/lite/python/tflite_convert.py"", line 221, in _convert_tf2_model
    tflite_model = converter.convert()
  File ""/usr/local/lib/python3.7/site-packages/tensorflow_core/lite/python/lite.py"", line 446, in convert
    **converter_kwargs)
  File ""/usr/local/lib/python3.7/site-packages/tensorflow_core/lite/python/convert.py"", line 449, in toco_convert_impl
    enable_mlir_converter=enable_mlir_converter)
  File ""/usr/local/lib/python3.7/site-packages/tensorflow_core/lite/python/convert.py"", line 200, in toco_convert_protos
    raise ConverterError(""See console for info.\n%s\n%s\n"" % (stdout, stderr))
tensorflow.lite.python.convert.ConverterError: See console for info.
2020-02-18 12:08:52.222650: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-02-18 12:08:52.242018: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fd921cfa1b0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-02-18 12:08:52.242031: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-02-18 12:08:52.271859: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorListFromTensor
2020-02-18 12:08:52.271902: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 21
2020-02-18 12:08:52.271961: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorListReserve
2020-02-18 12:08:52.271971: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 21
2020-02-18 12:08:52.272009: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: While
2020-02-18 12:08:52.272030: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 21
2020-02-18 12:08:52.272035: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 21
2020-02-18 12:08:52.272059: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorListStack
2020-02-18 12:08:52.274986: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 26 operators, 67 arrays (0 quantized)
2020-02-18 12:08:52.279519: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 26 operators, 67 arrays (0 quantized)
2020-02-18 12:08:52.281200: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 22 operators, 65 arrays (0 quantized)
2020-02-18 12:08:52.281569: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 2: 21 operators, 63 arrays (0 quantized)
2020-02-18 12:08:52.282014: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 3: 12 operators, 45 arrays (0 quantized)
2020-02-18 12:08:52.282246: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 4: 11 operators, 43 arrays (0 quantized)
2020-02-18 12:08:52.282451: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Group bidirectional sequence lstm/rnn: 11 operators, 43 arrays (0 quantized)
2020-02-18 12:08:52.282591: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before dequantization graph transformations: 11 operators, 43 arrays (0 quantized)
2020-02-18 12:08:52.282698: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Identify nearest upsample.: 11 operators, 43 arrays (0 quantized)
2020-02-18 12:08:52.282938: I tensorflow/lite/toco/allocate_transient_arrays.cc:345] Total transient array allocated size: 2304 bytes, theoretical optimal value: 1920 bytes.
2020-02-18 12:08:52.283040: I tensorflow/lite/toco/toco_tooling.cc:471] Number of parameters: 401825
2020-02-18 12:08:52.287920: E tensorflow/lite/toco/toco_tooling.cc:498] We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md
 and pasting the following:

Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: CONV_2D, FULLY_CONNECTED, RESHAPE, SOFTMAX, STRIDED_SLICE, TANH. Here is a list of operators for which you will need custom implementations: TensorListFromTensor, TensorListReserve, TensorListStack, While.
Traceback (most recent call last):
  File ""/Users/grady/work/tensorflow/venv/bin/toco_from_protos"", line 8, in <module>
    sys.exit(main())
  File ""/Users/grady/work/tensorflow/venv/lib/python3.7/site-packages/tensorflow_core/lite/toco/python/toco_from_protos.py"", line 93, in main
    app.run(main=execute, argv=[sys.argv[0]] + unparsed)
  File ""/Users/grady/work/tensorflow/venv/lib/python3.7/site-packages/tensorflow_core/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/usr/local/lib/python3.7/site-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/usr/local/lib/python3.7/site-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""/Users/grady/work/tensorflow/venv/lib/python3.7/site-packages/tensorflow_core/lite/toco/python/toco_from_protos.py"", line 56, in execute
    enable_mlir_converter)
Exception: We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md
 and pasting the following:

Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: CONV_2D, FULLY_CONNECTED, RESHAPE, SOFTMAX, STRIDED_SLICE, TANH. Here is a list of operators for which you will need custom implementations: TensorListFromTensor, TensorListReserve, TensorListStack, While.
```

"
36865,TensorFlow Lite Op Request,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- TensorFlow installed from (source or binary): binary
- TensorFlow version (or github SHA if from source): 2.1.0

**Code** (https://www.tensorflow.org/lite/performance/post_training_quantization#weight_quantization)
```python
import tensorflow as tf
saved_model_dir = '/opt/model/my_model'
converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)
converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]
tflite_quant_model = converter.convert()
```

**Provide the text output from tflite_convert**

```
2020-02-18 19:24:22.977058: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libnvinfer.so.6
2020-02-18 19:24:22.978737: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libnvinfer_plugin.so.6
2020-02-18 19:24:24.105775: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-02-18 19:24:24.128869: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300070000 Hz
2020-02-18 19:24:24.129146: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5567cc4fa770 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-02-18 19:24:24.129174: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-02-18 19:24:24.131587: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-02-18 19:24:24.187720: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-02-18 19:24:24.188106: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5567cc57c4f0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-02-18 19:24:24.188130: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla M60, Compute Capability 5.2
2020-02-18 19:24:24.188279: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-02-18 19:24:24.188558: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:00:1e.0 name: Tesla M60 computeCapability: 5.2
coreClock: 1.1775GHz coreCount: 16 deviceMemorySize: 7.44GiB deviceMemoryBandwidth: 149.31GiB/s
2020-02-18 19:24:24.188610: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-02-18 19:24:24.188649: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-02-18 19:24:24.189979: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-02-18 19:24:24.190280: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-02-18 19:24:24.192086: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-02-18 19:24:24.193471: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-02-18 19:24:24.193524: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-02-18 19:24:24.193599: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-02-18 19:24:24.193921: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-02-18 19:24:24.194179: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-02-18 19:24:24.194214: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-02-18 19:24:24.541245: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-02-18 19:24:24.541292: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 
2020-02-18 19:24:24.541301: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N 
2020-02-18 19:24:24.541515: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-02-18 19:24:24.541855: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-02-18 19:24:24.542145: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 159 MB memory) -> physical GPU (device: 0, name: Tesla M60, pci bus id: 0000:00:1e.0, compute capability: 5.2)
2020-02-18 19:24:24.589548: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorListFromTensor
2020-02-18 19:24:24.589614: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 21
2020-02-18 19:24:24.589679: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorListFromTensor
2020-02-18 19:24:24.589696: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 21
2020-02-18 19:24:24.589715: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorListReserve
2020-02-18 19:24:24.589729: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 21
2020-02-18 19:24:24.589746: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorListReserve
2020-02-18 19:24:24.589759: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 21
2020-02-18 19:24:24.589789: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: While
2020-02-18 19:24:24.589820: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 21
2020-02-18 19:24:24.589832: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 21
2020-02-18 19:24:24.589853: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: While
2020-02-18 19:24:24.589876: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 21
2020-02-18 19:24:24.589888: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 21
2020-02-18 19:24:24.589899: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorListStack
2020-02-18 19:24:24.589916: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorListStack
2020-02-18 19:24:24.592612: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 79 operators, 169 arrays (0 quantized)
2020-02-18 19:24:24.593771: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 79 operators, 169 arrays (0 quantized)
2020-02-18 19:24:24.595059: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 44 operators, 121 arrays (0 quantized)
2020-02-18 19:24:24.595863: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Group bidirectional sequence lstm/rnn: 44 operators, 121 arrays (0 quantized)
2020-02-18 19:24:24.596433: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before dequantization graph transformations: 44 operators, 121 arrays (0 quantized)
2020-02-18 19:24:24.596939: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Identify nearest upsample.: 44 operators, 121 arrays (0 quantized)
2020-02-18 19:24:24.597844: I tensorflow/lite/toco/allocate_transient_arrays.cc:345] Total transient array allocated size: 18048 bytes, theoretical optimal value: 12032 bytes.
2020-02-18 19:24:24.598043: I tensorflow/lite/toco/toco_tooling.cc:471] Number of parameters: 5372617
2020-02-18 19:24:24.598566: E tensorflow/lite/toco/toco_tooling.cc:498] We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md
 and pasting the following:

Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. 
If those are native TensorFlow operators, you might be able to use the extended runtime by 
passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS 
when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them 
you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True 
when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: 
ADD, CONCATENATION, CONV_2D, EXPAND_DIMS, FULLY_CONNECTED, GATHER, 
MAX_POOL_2D, MUL, REDUCE_MAX, RESHAPE, REVERSE_V2, SOFTMAX, SQUEEZE, 
TRANSPOSE. Here is a list of operators for which you will need custom implementations:
TensorListFromTensor, TensorListReserve, TensorListStack, While.

Traceback (most recent call last):
  File ""/opt/anaconda3/bin/toco_from_protos"", line 8, in <module>
    sys.exit(main())
  File ""/opt/anaconda3/lib/python3.6/site-packages/tensorflow_core/lite/toco/python/toco_from_protos.py"", line 93, in main
    app.run(main=execute, argv=[sys.argv[0]] + unparsed)
  File ""/opt/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/opt/anaconda3/lib/python3.6/site-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/opt/anaconda3/lib/python3.6/site-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""/opt/anaconda3/lib/python3.6/site-packages/tensorflow_core/lite/toco/python/toco_from_protos.py"", line 56, in execute
    enable_mlir_converter)
```
"
36864,Tensorflow 2.1.0 is not using GPU,"**System information**
- OS Platform: - Google Cloud Linux Ubuntu 16.04 
- TensorFlow installed from (source or binary): binary
- TensorFlow version: 2.1
- Python version: 3.7
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10.01
- GPU model and memory: Tesla P100, 16GB

When I train any model using TensorFlow using 2.1 it runs on CPU only even it shows on GPU, but GPU utilization becomes always 0% and CPU utilization is very high. 

"
36863,trouble importing tensorflow_hub,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Microsoft Windows 10 pro
- TensorFlow installed from (source or binary): binary (?) pip install
- TensorFlow version: tensorflow - 2.1.0,   tensorflow-hub       0.7.0 
- Python version: 3.7.6
- Installed using virtualenv? pip? conda?: Installed using pip within virtualenv.


**Describe the problem**
Cannot import tensorflow_hub due to the error in the output below. tensorflow_hub is installed successfully and tensorflow is able to import.

**Provide the exact sequence of commands / steps that you executed before running into the problem**
import tensorflow_hub as hub

**Any other info / logs**

Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.


```ImportError                               Traceback (most recent call last)
~\AppData\Local\Continuum\miniconda3\envs\pya\lib\site-packages\tensorflow\python\pywrap_tensorflow.py in <module>
     57 
---> 58   from tensorflow.python.pywrap_tensorflow_internal import *
     59 

~\AppData\Local\Continuum\miniconda3\envs\pya\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py in <module>
     27             return _mod
---> 28     _pywrap_tensorflow_internal = swig_import_helper()
     29     del swig_import_helper

~\AppData\Local\Continuum\miniconda3\envs\pya\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py in swig_import_helper()
     23             try:
---> 24                 _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
     25             finally:

~\AppData\Local\Continuum\miniconda3\envs\pya\lib\imp.py in load_module(name, file, filename, details)
    241         else:
--> 242             return load_dynamic(name, filename, file)
    243     elif type_ == PKG_DIRECTORY:

~\AppData\Local\Continuum\miniconda3\envs\pya\lib\imp.py in load_dynamic(name, path, file)
    341             name=name, loader=loader, origin=path)
--> 342         return _load(spec)
    343 

ImportError: DLL load failed: The specified module could not be found.

During handling of the above exception, another exception occurred:

ImportError                               Traceback (most recent call last)
<ipython-input-22-85533c25c7ee> in <module>
----> 1 import tensorflow_hub as hub
      2 #import tensorflow as tf
      3 
      4 #elmo = hub.Module(""https://tfhub.dev/google/elmo/2"", trainable=True)

~\AppData\Local\Continuum\miniconda3\envs\pya\lib\site-packages\tensorflow_hub\__init__.py in <module>
     21 from absl import logging
     22 from distutils.version import LooseVersion
---> 23 import tensorflow as tf
     24 
     25 # pylint: disable=g-import-not-at-top

~\AppData\Local\Continuum\miniconda3\envs\pya\lib\site-packages\tensorflow\__init__.py in <module>
     39 import sys as _sys
     40 
---> 41 from tensorflow.python.tools import module_util as _module_util
     42 from tensorflow.python.util.lazy_loader import LazyLoader as _LazyLoader
     43 

~\AppData\Local\Continuum\miniconda3\envs\pya\lib\site-packages\tensorflow\python\__init__.py in <module>
     48 import numpy as np
     49 
---> 50 from tensorflow.python import pywrap_tensorflow
     51 from tensorflow.python import _pywrap_utils
     52 from tensorflow.python import _pywrap_tfprof

~\AppData\Local\Continuum\miniconda3\envs\pya\lib\site-packages\tensorflow\python\pywrap_tensorflow.py in <module>
     67 for some common reasons and solutions.  Include the entire stack trace
     68 above this error message when asking for help."""""" % traceback.format_exc()
---> 69   raise ImportError(msg)
     70 
     71 # pylint: enable=wildcard-import,g-import-not-at-top,unused-import,line-too-long

ImportError: Traceback (most recent call last):
  File ""C:\Users\myname\AppData\Local\Continuum\miniconda3\envs\pya\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\myname\AppData\Local\Continuum\miniconda3\envs\pya\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\myname\AppData\Local\Continuum\miniconda3\envs\pya\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\myname\AppData\Local\Continuum\miniconda3\envs\pya\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\myname\AppData\Local\Continuum\miniconda3\envs\pya\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: The specified module could not be found.


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/errors

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.```


"
36861,saves everything: The optimizer configuration... it is not able to save TensorFlow optimizers,"
## URL(s) with the issue: 
https://www.tensorflow.org/tutorials/keras/save_and_load

## Description of issue (what needs changing):

The first reference to ""optimizer configuration"" is unqualified.
The second reference to ""optimizers"" is kind of qualified with ""(from tf.train)"".
Does this mean, tf.keras.optimizer states are stored but not tf.optimizer or does this mean no optimizer states are stored?

full text as follows:

```
This technique saves everything:

- The weight values
- The model's configuration(architecture)
- The optimizer configuration

Keras saves models by inspecting the architecture. Currently, it is not able to save TensorFlow optimizers (from tf.train). When using those you will need to re-compile the model after loading, and you will lose the state of the optimizer.
```"
36860,Tensorflow 2.0.0 - DLL load failed - windows cpu,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 64 bit
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:  n/a
- TensorFlow installed from (source or binary): binary
- TensorFlow version: 2.0.0
- Python version: 3.7.6
- Installed using virtualenv? pip? conda?:  pip and conda
- Bazel version (if compiling from source): n/a
- GCC/Compiler version (if compiling from source):  n/a
- CUDA/cuDNN version:  n/a
- GPU model and memory:  n/a



**Describe the problem**

Installation of TensorFlow 2.0.0 using pip was successful, but TensorFlow import failed.
On the contrary, installation of TensorFlow 2.0.0 using conda was successful and in addition TensorFlow import was successful.
**Why does conda env work fine but pip env don't?**

**Provide the exact sequence of commands / steps that you executed before running into the problem**
I created 2 conda environments: one for conda release and the other for pip release, both dedicated to tensorflow 2.0.0. 

1. tensorflow2_0_conda environment:
conda installation using
`conda install python=3.7 tensorflow=2.0`

2. tensorflow2_0_pip environment:
pip installation using
`conda install python=3.7`
`pip install tensorflow==2.0.0`

Both installations completed without any error.

Import test:
`python -c ""import tensorflow as tf""`

ad 1) conda env works fine
ad 2) pip env failed with error message (detail see logs entry)
`ImportError: DLL load failed ...`


**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

```
(tensorflow2_0_pip)>python -c ""import tensorflow as tf""
Traceback (most recent call last):
  File ""C:\Anaconda3\envs\tensorflow2_0_pip\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Anaconda3\envs\tensorflow2_0_pip\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Anaconda3\envs\tensorflow2_0_pip\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Anaconda3\envs\tensorflow2_0_pip\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Anaconda3\envs\tensorflow2_0_pip\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: A dynamic link library (DLL) initialization routine failed.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""<string>"", line 1, in <module>
  File ""C:\Anaconda3\envs\tensorflow2_0_pip\lib\site-packages\tensorflow\__init__.py"", line 98, in <module>
    from tensorflow_core import *
  File ""C:\Anaconda3\envs\tensorflow2_0_pip\lib\site-packages\tensorflow_core\__init__.py"", line 40, in <module>
    from tensorflow.python.tools import module_util as _module_util
  File ""C:\Anaconda3\envs\tensorflow2_0_pip\lib\site-packages\tensorflow\__init__.py"", line 50, in __getattr__
    module = self._load()
  File ""C:\Anaconda3\envs\tensorflow2_0_pip\lib\site-packages\tensorflow\__init__.py"", line 44, in _load
    module = _importlib.import_module(self.__name__)
  File ""C:\Anaconda3\envs\tensorflow2_0_pip\lib\importlib\__init__.py"", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""C:\Anaconda3\envs\tensorflow2_0_pip\lib\site-packages\tensorflow_core\python\__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\Anaconda3\envs\tensorflow2_0_pip\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 74, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""C:\Anaconda3\envs\tensorflow2_0_pip\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Anaconda3\envs\tensorflow2_0_pip\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Anaconda3\envs\tensorflow2_0_pip\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Anaconda3\envs\tensorflow2_0_pip\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Anaconda3\envs\tensorflow2_0_pip\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: A dynamic link library (DLL) initialization routine failed.


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/errors

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.

(tensorflow2_0_pip)>
```"
36859,"Tensorflow-gpu 2.1 Cuda 10.2, ImportError: DLL load failed: The specified module could not be found.","**System information**
- OS Platform and Distribution: Windows 10
- TensorFlow installed from: pip install tensorflow-gpu
- TensorFlow version: tensorflow-gpu-2.1.0
- Python version: python 3.7.6
- Visual_Studio_Community 2019
- CUDA/cuDNN version: Cuda 10.2.89, cudnn-10.2-windows10-x64-v7.6.5.32
- GPU model and memory: NVIDIA GeForce 940MX 2GB



**Describe the problem**

I followed all the steps to install tensroflow-gpu today.
I downloaded Visual Studio 2019 and installed it.
Then I downloaded and installed NVIDIA CUDA 10.2 Toolkit and NVIDIA cuDNN 7.6.5.32 following compatibilities recommendations.
CUDA and CUDANN are in my environment variables, so no problems with that.
I installed today python 3.7.6 and tensorflow-gpu with pip inside a virtual environment, which took automatically version 2.1.
Pip install tensorflow-gpu runs smoothly but I get an error when I try to import it.
I open a new post because, in the opened one, the proposed solutions are:
* Downloading and installing visual studio 2015-2019 x86 and x64: it wouldn't work for me as I have already installed it.
* Downgrade to tensorflow 2.0: I would like to keep tensorflow 2.1, on top of this, even downgrading I get another run-time error, which is solvable by downgrading to CUDA 10.1, which I don't want to do.


**Any other info / logs**

This is the errror message: 
```
>>> import tensorflow as tf
Traceback (most recent call last):
  File ""C:\Users\apaladini\OneDrive - Amadeus Workplace\Desktop\Work\2020\Tensorflow-gpu\venvs\py37\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\apaladini\OneDrive - Amadeus Workplace\Desktop\Work\2020\Tensorflow-gpu\venvs\py37\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\apaladini\OneDrive - Amadeus Workplace\Desktop\Work\2020\Tensorflow-gpu\venvs\py37\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\apaladini\AppData\Local\Programs\Python\Python37\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\apaladini\AppData\Local\Programs\Python\Python37\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: The specified module could not be found.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""C:\Users\apaladini\OneDrive - Amadeus Workplace\Desktop\Work\2020\Tensorflow-gpu\venvs\py37\lib\site-packages\tensorflow\__init__.py"", line 101, in <module>
    from tensorflow_core import *
  File ""C:\Users\apaladini\OneDrive - Amadeus Workplace\Desktop\Work\2020\Tensorflow-gpu\venvs\py37\lib\site-packages\tensorflow_core\__init__.py"", line 40, in <module>
    from tensorflow.python.tools import module_util as _module_util
  File ""C:\Users\apaladini\OneDrive - Amadeus Workplace\Desktop\Work\2020\Tensorflow-gpu\venvs\py37\lib\site-packages\tensorflow\__init__.py"", line 50, in __getattr__
    module = self._load()
  File ""C:\Users\apaladini\OneDrive - Amadeus Workplace\Desktop\Work\2020\Tensorflow-gpu\venvs\py37\lib\site-packages\tensorflow\__init__.py"", line 44, in _load
    module = _importlib.import_module(self.__name__)
  File ""C:\Users\apaladini\AppData\Local\Programs\Python\Python37\lib\importlib\__init__.py"", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""C:\Users\apaladini\OneDrive - Amadeus Workplace\Desktop\Work\2020\Tensorflow-gpu\venvs\py37\lib\site-packages\tensorflow_core\python\__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\Users\apaladini\OneDrive - Amadeus Workplace\Desktop\Work\2020\Tensorflow-gpu\venvs\py37\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 74, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""C:\Users\apaladini\OneDrive - Amadeus Workplace\Desktop\Work\2020\Tensorflow-gpu\venvs\py37\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\apaladini\OneDrive - Amadeus Workplace\Desktop\Work\2020\Tensorflow-gpu\venvs\py37\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\apaladini\OneDrive - Amadeus Workplace\Desktop\Work\2020\Tensorflow-gpu\venvs\py37\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\apaladini\AppData\Local\Programs\Python\Python37\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\apaladini\AppData\Local\Programs\Python\Python37\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: The specified module could not be found.


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/errors

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.
```
I didn't find a way to find out what dll file the error is referring to.

How can I make this work?
Thanks in advance!"
36858,Securing models before sending it to client for inference,"We have Tensorflow Saved model format (.pb file  )that we want to ship in an offline application. 
Is there a way to secure the model such that, it is not exposed to the client?

We understand that any logic that is running on the client-side is exposed by definition but wondering whether there are best practices to mitigate this risk? "
36857,Key error message doesn't print the new line in Estimator,"output in the concole:
```
KeyError: ""The dictionary passed into features does not have the expected inputs keys defined in 
the keras model.\n\tExpected keys: {'input_1', 'input_2'}\n\tfeatures keys: {'feat_ids', 
'feat_vals'}\n\tDifference: {'input_1', 'feat_ids', 'feat_vals', 'input_2'}""
```
The link to the code snippet:
https://github.com/tensorflow/estimator/blob/6915557cef8bfc86f29f87e4467d601e4553b957/tensorflow_estimator/python/estimator/keras.py#L119-L129

The key error message doesn't print the new line, we should update it.
It's related to https://stackoverflow.com/questions/46892261/new-line-on-error-message-in-keyerror-python-3-3"
36855,How the Frozen model from tensorflow audio recognition is made and converted to tensorflow lite model?,"After following the steps train.py and freeze.py from the [tutorial](https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/sequences/audio_recognition.md) ,the structure of my frozen model looks like(https://imgur.com/a/JtNVkHw) which is different from the official frozen model conv_actions_frozen.pb(https://imgur.com/a/KJXExbV).

When I Converted Frozen model to Tensorflow lite using the steps:

```
import tensorflow as tf
converter = tf.compat.v1.lite.TFLiteConverter.from_frozen_graph(""./my_frozen_graph.pb"", input_arrays=['decoded_sample_data', 'decoded_sample_data:1'], output_arrays=['labels_softmax'])
converter.allow_custom_ops=True
tflite_model = converter.convert()
open(""output.tflite"", ""wb"").write(tflite_model)
```

The structure of my tflite model (https://imgur.com/a/uceoHlo) is also different from the original speech commands tflite model(https://imgur.com/a/lWmxl9d). Also, When i am testing my tflite model on android studio, it is getting crashed.

I suspect something went wrong in the creation of frozen model from the [tutorial](https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/sequences/audio_recognition.md). Could someone kindly help in generating the frozen model for speech commands.

Tensorflow version-2.1.0

python version - 3.7.3"
36853,The minimum required Cuda capability is 6.0 for the binary C-API releases 1.14.0 and 1.15.0,"**System information**
- OS Platform and Distribution: Ubuntu 18.04
- TensorFlow installed from: binary C-API release (https://storage.googleapis.com/tensorflow/libtensorflow/libtensorflow-gpu-linux-x86_64-1.14.0.tar.gz)
- TensorFlow version: `1.14.0`
- Docker image: `tensorflow/tensorflow:1.14.0-gpu-py3`
- GPU model and memory:

```
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 440.59       Driver Version: 440.59       CUDA Version: 10.2     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  GeForce GTX 960M    Off  | 00000000:01:00.0 Off |                  N/A |
| N/A   36C    P8    N/A /  N/A |      0MiB /  2004MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
```


**Describe the problem**
Using the C-API, the following error occurs when attempting to run inferences with the above GPU setup. 

```
2020-02-18 09:42:51.504548: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-02-18 09:42:51.529888: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2599990000 Hz
2020-02-18 09:42:51.530480: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x555dbf23f760 executing computations on platform Host. Devices:
2020-02-18 09:42:51.530508: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2020-02-18 09:42:51.531487: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2020-02-18 09:42:51.541446: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-02-18 09:42:51.542021: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: GeForce GTX 960M major: 5 minor: 0 memoryClockRate(GHz): 1.0975
pciBusID: 0000:01:00.0
2020-02-18 09:42:51.542289: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0
2020-02-18 09:42:51.543592: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10.0
2020-02-18 09:42:51.544681: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcufft.so.10.0
2020-02-18 09:42:51.545006: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcurand.so.10.0
2020-02-18 09:42:51.546594: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusolver.so.10.0
2020-02-18 09:42:51.547771: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcusparse.so.10.0
2020-02-18 09:42:51.551039: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2020-02-18 09:42:51.551147: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-02-18 09:42:51.552024: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-02-18 09:42:51.552531: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1717] Ignoring visible gpu device (device: 0, name: GeForce GTX 960M, pci bus id: 0000:01:00.0, compute capability: 5.0) with Cuda compute capability 5.0. The minimum required Cuda capability is 6.0.
2020-02-18 09:42:51.585097: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-02-18 09:42:51.585122: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 
2020-02-18 09:42:51.585128: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N 
```

This issue has previously been raised and fixed in https://github.com/tensorflow/tensorflow/issues/25329 for another setup, but the error remains when using the C-API.

I have also confirmed the same issue when using the `1.15.0` binary release.
"
36851,"TypeError: Tensor is unhashable if Tensor equality is enabled. Instead, use tensor.experimental_ref() as the key. in colab","When tryig to build the following model, I get error Tensor is unhashable (see figure)
input_data = Input(name='the_input', shape=(208, 224,224, 3), dtype=dtype)
 layer1 =        TimeDistributed(
            MobileNet(weights='imagenet',include_top=False))(input_data)
    
layer2 =  TimeDistributed(GlobalAveragePooling2D())(layer1)
##********************************* Create Bidirectional LSTM*************************************
for i in range(0, n_layers):
     x = Bidirectional(CuDNNLSTM(20, kernel_initializer=kernel_init_rnn, bias_initializer=bias_init_rnn,
                                        unit_forget_bias=True, return_sequences=True),
                              merge_mode='sum', name='CuDNN_bi_lstm'+str(i+1))(layer2)

x = TimeDistributed(Dense(units=20, kernel_initializer=kernel_init_dense, bias_initializer=bias_init_dense,
                              activation='relu'), name='fc_4')(x)
x = TimeDistributed(Dropout(dropout), name='dropout_4')(x)
    # Output layer with softmax
y_pred = TimeDistributed(Dense(units=30, kernel_initializer=kernel_init_dense,
                                   bias_initializer=bias_init_dense, activation='softmax'), name='softmax')(x)
Model(inputs=input_data, outputs=y_pred).summary()
![colab issue](https://user-images.githubusercontent.com/17008416/74722702-63ebf400-525f-11ea-804d-283b4016d6fe.JPG)

"
36848,Not able to use 'training' argument in the call method for a custom layer.,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information** :

OS - CentOs
tensorflow-gpu = 2.1.0
tensorflow = 2.0.0
installed in the conda version - conda version : 4.8.1
using cuda - CUDA Version: 10.1
Gpu - Tesla K80
python - 3.6


**Describe the current behavior**
Not able to use the 'training' flag when designing a custom layer. Getting error saying that 
```
operatorNotAllowedInGraphError            Traceback (most recent call last)
~/miniconda3/envs/CbrainCustomLayer/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py in __call__(self, inputs, *args, **kwargs)
    841                   with auto_control_deps.AutomaticControlDependencies() as acd:
--> 842                     outputs = call_fn(cast_inputs, *args, **kwargs)
    843                     # Wrap Tensors in `outputs` in `tf.identity` to avoid

~/miniconda3/envs/CbrainCustomLayer/lib/python3.6/site-packages/tensorflow_core/python/autograph/impl/api.py in wrapper(*args, **kwargs)
    236         if hasattr(e, 'ag_error_metadata'):
--> 237           raise e.ag_error_metadata.to_exception(e)
    238         else:

OperatorNotAllowedInGraphError: in converted code:

    <ipython-input-26-3ff47d389914>:43 call
        if not training:
    /home/ankitesh/miniconda3/envs/CbrainCustomLayer/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py:765 __bool__
        self._disallow_bool_casting()
    /home/ankitesh/miniconda3/envs/CbrainCustomLayer/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py:534 _disallow_bool_casting
        self._disallow_in_graph_mode(""using a `tf.Tensor` as a Python `bool`"")
    /home/ankitesh/miniconda3/envs/CbrainCustomLayer/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py:523 _disallow_in_graph_mode
        "" this function with @tf.function."".format(task))

    OperatorNotAllowedInGraphError: using a `tf.Tensor` as a Python `bool` is not allowed in Graph execution. Use Eager execution or decorate this function with @tf.function.
```
**Describe the expected behavior**
It should not give an error

**Code to reproduce the issue** Provide a reproducible test case that is the
bare minimum necessary to generate the problem.

This is the class that I made

```python
from tensorflow.keras import initializers
from tensorflow.keras import layers


class CustomBatchNormalization(layers.Layer):
    def __init__(self, momentum=0.99, epsilon=1e-3,beta_initializer='zeros',
                 gamma_initializer='ones', moving_mean_initializer='zeros',
                 moving_range_initializer='ones',**kwargs):
        self.momentum = momentum
        self.epsilon = epsilon
        self.beta_initializer = initializers.get(beta_initializer)
        self.gamma_initializer = initializers.get(gamma_initializer)
        self.moving_mean_initializer = initializers.get(moving_mean_initializer)
        self.moving_range_initializer = (
            initializers.get(moving_range_initializer))
        
        super().__init__(**kwargs)
    
    def build(self,input_shape):
        dim = input_shape[-1]
        shape = (dim,)
        self.gamma = self.add_weight(shape=shape,
                             name='gamma',
                             initializer=self.gamma_initializer,trainable=True)
        self.beta = self.add_weight(shape=shape,
                            name='beta',
                            initializer=self.beta_initializer,
                                   trainable=True)
        
        self.moving_mean = self.add_weight(
            shape=shape,
            name='moving_mean',
            initializer=self.moving_mean_initializer,
            trainable=False)
        
        self.moving_range = self.add_weight(
            shape=shape,
            name='moving_range',
            initializer=self.moving_range_initializer,
            trainable=False)



    def call(self, inputs, training=None):
        input_shape = inputs.shape
        
        if not training:
            scaled = (inputs-self.moving_mean)/(self.moving_range+self.epsilon)
            return self.gamma*scaled + self.beta
        
        mean = tf.math.reduce_mean(inputs,axis=0)
        maxr = tf.math.reduce_max(inputs,axis=0)
        minr = tf.math.reduce_min(inputs,axis=0)
        
        range_diff = tf.math.subtract(maxr,minr)
        self.moving_mean = tf.math.add(self.momentum*self.moving_mean, (1-self.momentum)*mean)
        self.moving_range = tf.math.add(self.momentum*self.moving_range,(1-self.momentum)*range_diff)
        scaled = tf.math.divide(tf.math.subtract(inputs,mean),(range_diff+self.epsilon))
        return tf.math.add(tf.math.multiply(self.gamma,scaled),self.beta)
    
    def get_config(self):
        config = {
            'momentum': self.momentum,
            'epsilon': self.epsilon,
            'beta_initializer': initializers.serialize(self.beta_initializer),
            'gamma_initializer': initializers.serialize(self.gamma_initializer),
            'moving_mean_initializer':
                initializers.serialize(self.moving_mean_initializer),
            'moving_range_initializer':
                initializers.serialize(self.moving_range_initializer)
        }
        base_config = super(CustomBatchNormalization, self).get_config()
        return dict(list(base_config.items()) + list(config.items()))
    
    def compute_output_shape(self, input_shape):
        return input_shape




##Below is the network 

inp = Input(shape=(64,))
batch_norm_1 = CustomBatchNormalization()(inp)
densout = Dense(128, activation='linear')(batch_norm_1)
densout = LeakyReLU(alpha=0.3)(densout)
for i in range (6):
    batch_norm_i = CustomBatchNormalization()(densout)
    densout = Dense(128, activation='linear')(batch_norm_i)
    densout = LeakyReLU(alpha=0.3)(densout)
batch_norm_out = CustomBatchNormalization()(densout)
out = Dense(64, activation='linear')(batch_norm_out)
Inp_RH_CBN = tf.keras.models.Model(inp, out)
```
**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.


Here is the full log error
```
OperatorNotAllowedInGraphError            Traceback (most recent call last)
~/miniconda3/envs/CbrainCustomLayer/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py in __call__(self, inputs, *args, **kwargs)
    841                   with auto_control_deps.AutomaticControlDependencies() as acd:
--> 842                     outputs = call_fn(cast_inputs, *args, **kwargs)
    843                     # Wrap Tensors in `outputs` in `tf.identity` to avoid

~/miniconda3/envs/CbrainCustomLayer/lib/python3.6/site-packages/tensorflow_core/python/autograph/impl/api.py in wrapper(*args, **kwargs)
    236         if hasattr(e, 'ag_error_metadata'):
--> 237           raise e.ag_error_metadata.to_exception(e)
    238         else:

OperatorNotAllowedInGraphError: in converted code:

    <ipython-input-26-3ff47d389914>:43 call
        if not training:
    /home/ankitesh/miniconda3/envs/CbrainCustomLayer/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py:765 __bool__
        self._disallow_bool_casting()
    /home/ankitesh/miniconda3/envs/CbrainCustomLayer/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py:534 _disallow_bool_casting
        self._disallow_in_graph_mode(""using a `tf.Tensor` as a Python `bool`"")
    /home/ankitesh/miniconda3/envs/CbrainCustomLayer/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py:523 _disallow_in_graph_mode
        "" this function with @tf.function."".format(task))

    OperatorNotAllowedInGraphError: using a `tf.Tensor` as a Python `bool` is not allowed in Graph execution. Use Eager execution or decorate this function with @tf.function.


During handling of the above exception, another exception occurred:

TypeError                                 Traceback (most recent call last)
<ipython-input-27-3d2d9055924b> in <module>
      1 inp = Input(shape=(64,))
----> 2 batch_norm_1 = CustomBatchNormalization()(inp)
      3 densout = Dense(128, activation='linear')(batch_norm_1)
      4 densout = LeakyReLU(alpha=0.3)(densout)
      5 for i in range (6):

~/miniconda3/envs/CbrainCustomLayer/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py in __call__(self, inputs, *args, **kwargs)
    852                               'dynamic. Pass `dynamic=True` to the class '
    853                               'constructor.\nEncountered error:\n""""""\n' +
--> 854                               str(e) + '\n""""""')
    855           else:
    856             # We will use static shape inference to return symbolic tensors

TypeError: You are attempting to use Python control flow in a layer that was not declared to be dynamic. Pass `dynamic=True` to the class constructor.
Encountered error:
""""""
in converted code:

    <ipython-input-26-3ff47d389914>:43 call
        if not training:
    /home/ankitesh/miniconda3/envs/CbrainCustomLayer/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py:765 __bool__
        self._disallow_bool_casting()
    /home/ankitesh/miniconda3/envs/CbrainCustomLayer/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py:534 _disallow_bool_casting
        self._disallow_in_graph_mode(""using a `tf.Tensor` as a Python `bool`"")
    /home/ankitesh/miniconda3/envs/CbrainCustomLayer/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py:523 _disallow_in_graph_mode
        "" this function with @tf.function."".format(task))

    OperatorNotAllowedInGraphError: using a `tf.Tensor` as a Python `bool` is not allowed in Graph execution. Use Eager execution or decorate this function with @tf.function.
```


"
36847,"Unable to run ""Classifying CIFAR-10 with XLA"" Experiment: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.          [[{{node conv2d/Conv2D}}]]","Hi All,
I am trying to run an example from [https://www.tensorflow.org/xla/tutorials/autoclustering_xla](https://www.tensorflow.org/xla/tutorials/autoclustering_xla) in my local. 

Configuration is: Conda End, TF2.1, cuDNN 7.6, cuda 10.1 and I have tried out various combination from [https://www.tensorflow.org/install/source#tested_build_configurations](https://www.tensorflow.org/install/source#tested_build_configurations) like for TF1.14, TF1.11 but it is throwing the same error as below:


I have followed solutions from [Stack Overflow](https://stackoverflow.com/questions/50622525/which-tensorflow-and-cuda-version-combinations-are-compatible); [https://www.tensorflow.org/install/gpu](https://www.tensorflow.org/install/gpu) and numerous other sources. Can someone please help me with this? I am using GeForce RTX 2080.


![image](https://user-images.githubusercontent.com/48321602/74702298-96520e80-51d7-11ea-89b7-43acabff54e7.png)"
36846,"There aren't enough elements in this dataset for each shard to have at least one element (# elems = 1, # shards = 2)","**Environment**
Python 3.7.3 (default, Dec 20 2019, 18:57:59)
[GCC 8.3.0] on linux
tensorflow(cpu) 2.1.0
tensorflow_datasets 2.0.0
Description:    Raspbian GNU/Linux 10 (buster)

**Using code the example from**
https://www.tensorflow.org/tutorials/distribute/multi_worker_with_keras

**TFConfig below**

`
{'cluster': {'worker': ['RpiCluster1:2222', 'RpiCluster2:2222']}, 'task': {'type': 'worker', 'index': 0}}
{'cluster': {'worker': ['RpiCluster1:2222', 'RpiCluster2:2222']}, 'task': {'type': 'worker', 'index': 1}}
`

**Error below seems to suggest sharding is not working**
2020-02-18 03:41:12.788327: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:300] Initialize GrpcChannelCache for job worker -> {0 -> RpiCluster1:2222, 1 -> localhost:2222}
2020-02-18 03:41:12.789117: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:390] Started server with target: grpc://localhost:2222
2020-02-18 03:41:21.023441: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:300] Initialize GrpcChannelCache for job worker -> {0 -> localhost:2222, 1 -> RpiCluster2:2222}
2020-02-18 03:41:21.024802: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:390] Started server with target: grpc://localhost:2222
WARNING:tensorflow:`eval_fn` is not passed in. The `worker_fn` will be used if an ""evaluator"" task exists in the cluster.
WARNING:tensorflow:`eval_fn` is not passed in. The `worker_fn` will be used if an ""evaluator"" task exists in the cluster.
WARNING:tensorflow:`eval_strategy` is not passed in. No distribution strategy will be used for evaluation.
WARNING:tensorflow:`eval_strategy` is not passed in. No distribution strategy will be used for evaluation.
WARNING:tensorflow:`eval_fn` is not passed in. The `worker_fn` will be used if an ""evaluator"" task exists in the cluster.
WARNING:tensorflow:`eval_fn` is not passed in. The `worker_fn` will be used if an ""evaluator"" task exists in the cluster.
WARNING:tensorflow:`eval_strategy` is not passed in. No distribution strategy will be used for evaluation.
WARNING:tensorflow:`eval_strategy` is not passed in. No distribution strategy will be used for evaluation.
2020-02-18 03:41:34.450011: W tensorflow/core/common_runtime/base_collective_executor.cc:217] BaseCollectiveExecutor::StartAbort Out of range: End of sequence
         [[{{node IteratorGetNext}}]]
WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 15 batches). You may need to use the repeat() function when building your dataset.
WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 15 batches). You may need to use the repeat() function when building your dataset.
2020-02-18 03:41:35.775198: W tensorflow/core/common_runtime/base_collective_executor.cc:217] BaseCollectiveExecutor::StartAbort Invalid argument: There aren't enough elements in this dataset for each shard to have at least one element (# elems = 1, # shards = 2). If you are using datasets with distribution strategy, considering setting the auto sharding policy to either DATA or OFF using the `experimental_distribute.auto_shard_policy` optionof `tf.data.Options()`.
         [[{{node MultiDeviceIteratorGetNextFromShard}}]]
         [[RemoteCall]]
         [[IteratorGetNext]]
2020-02-18 03:41:35.795862: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.
Found Cluster spec  {'worker': ['RpiCluster1:2222', 'RpiCluster2:2222']}
Found TFConfig {'cluster': {'worker': ['RpiCluster1:2222', 'RpiCluster2:2222']}, 'task': {'type': 'worker', 'index': 0}}
Created strategy  <tensorflow.python.distribute.collective_all_reduce_strategy.CollectiveAllReduceStrategy object at 0x66fb7e70>
Number of workers  2
Creating datasets inside scope...
Creating model inside scope...
Starting to fit model....
Train for 5 steps
Epoch 1/3
2020-02-18 03:41:36.589112: W tensorflow/python/util/util.cc:319] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
2020-02-18 03:41:39.502892: W tensorflow/python/util/util.cc:319] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
2020-02-18 03:41:39.615315: E tensorflow/core/common_runtime/ring_alg.cc:279] Aborting RingReduce with Cancelled: RPC Request was cancelled
2020-02-18 03:41:39.615446: W tensorflow/core/common_runtime/base_collective_executor.cc:217] BaseCollectiveExecutor::StartAbort Cancelled: RPC Request was cancelled
2020-02-18 03:41:39.615763: W tensorflow/core/framework/op_kernel.cc:1655] OP_REQUIRES failed at collective_ops.cc:253 : Cancelled: RPC Request was cancelled
2020-02-18 03:41:39.615850: W tensorflow/core/common_runtime/base_collective_executor.cc:217] BaseCollectiveExecutor::StartAbort Cancelled: RPC Request was cancelled
         [[{{node CollectiveReduce}}]]
Found Cluster spec  {'worker': ['RpiCluster1:2222', 'RpiCluster2:2222']}
Found TFConfig {'cluster': {'worker': ['RpiCluster1:2222', 'RpiCluster2:2222']}, 'task': {'type': 'worker', 'index': 1}}
Created strategy  <tensorflow.python.distribute.collective_all_reduce_strategy.CollectiveAllReduceStrategy object at 0x670a3c10>
Number of workers  2
Creating datasets inside scope...
Creating model inside scope...
Starting to fit model....
Train for 5 steps
Epoch 1/3
Traceback (most recent call last):
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/engine/training_v2.py"", line 753, in on_start
    yield
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/engine/training_v2.py"", line 397, in fit
    prefix='val_')
  File ""/usr/lib/python3.7/contextlib.py"", line 130, in __exit__
    self.gen.throw(type, value, traceback)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/engine/training_v2.py"", line 771, in on_epoch
    self.callbacks.on_epoch_end(epoch, epoch_logs)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/callbacks.py"", line 302, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/callbacks.py"", line 990, in on_epoch_end
    self._save_model(epoch=epoch, logs=logs)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/callbacks.py"", line 1040, in _save_model
    self.model.save(filepath, overwrite=True)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/engine/network.py"", line 1008, in save
    signatures, options)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/saving/save.py"", line 115, in save_model
    signatures, options)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/saving/saved_model/save.py"", line 78, in save
    save_lib.save(model, filepath, signatures, options)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/saved_model/save.py"", line 916, in save
    object_saver.save(utils_impl.get_variables_path(export_dir))
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/training/tracking/util.py"", line 1168, in save
    file_prefix=file_prefix_tensor, object_graph_tensor=object_graph_tensor)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/training/tracking/util.py"", line 1116, in _save_cached_when_graph_building
    save_op = saver.save(file_prefix)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/training/saving/functional_saver.py"", line 230, in save
    sharded_saves.append(saver.save(shard_prefix))
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/training/saving/functional_saver.py"", line 69, in save
    tensors.append(spec.tensor)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/training/saving/saveable_object.py"", line 52, in tensor
    return self._tensor() if callable(self._tensor) else self._tensor
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/distribute/values.py"", line 1252, in tensor
    return strategy.extended.read_var(sync_on_read_variable)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/distribute/mirrored_strategy.py"", line 769, in read_var
    return replica_local_var._get_cross_replica()  # pylint: disable=protected-access
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/distribute/values.py"", line 1347, in _get_cross_replica
    self, axis=None)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/distribute/distribute_lib.py"", line 808, in reduce
    return self._extended._reduce(reduce_op, value)  # pylint: disable=protected-access
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/distribute/distribute_lib.py"", line 1449, in _reduce
    device_util.current() or ""/device:CPU:0""))[0]
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/distribute/collective_all_reduce_strategy.py"", line 528, in _reduce_to
    reduce_op, value, destinations=destinations)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/distribute/cross_device_ops.py"", line 282, in reduce
    destinations)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/distribute/cross_device_ops.py"", line 1038, in reduce_implementation
    all_reduced = self._batch_all_reduce(reduce_op, [per_replica_value])[0]
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/distribute/cross_device_ops.py"", line 1118, in _batch_all_reduce
    dense_results = self._do_batch_all_reduce_dense(reduce_op, dense_values)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/distribute/cross_device_ops.py"", line 1160, in _do_batch_all_reduce_dense
    ""Id"", communication_hint)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/distribute/cross_device_utils.py"", line 368, in build_collective_reduce
    return collective_all_reduce()
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/eager/def_function.py"", line 568, in __call__
    result = self._call(*args, **kwds)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/eager/def_function.py"", line 638, in _call
    return self._concrete_stateful_fn._filtered_call(canon_args, canon_kwds)  # pylint: disable=protected-access
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/eager/function.py"", line 1611, in _filtered_call
    self.captured_inputs)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/eager/function.py"", line 1692, in _call_flat
    ctx, args, cancellation_manager=cancellation_manager))
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/eager/function.py"", line 545, in call
    ctx=ctx)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/eager/execute.py"", line 67, in quick_execute
    six.raise_from(core._status_to_exception(e.code, message), None)
  File ""<string>"", line 3, in raise_from
tensorflow.python.framework.errors_impl.CancelledError:  RPC Request was cancelled
         [[node CollectiveReduce (defined at /usr/lib/python3.7/contextlib.py:130) ]] [Op:__inference_collective_all_reduce_1457]

Function call stack:
collective_all_reduce


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""main_2.py"", line 98, in <module>
    multi_worker_model.fit(x=train_datasets, epochs=3, steps_per_epoch=5, callbacks = callbacks)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/engine/training.py"", line 819, in fit
    use_multiprocessing=use_multiprocessing)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/engine/training_distributed.py"", line 790, in fit
    *args, **kwargs)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/engine/training_distributed.py"", line 777, in wrapper
    mode=dc.CoordinatorMode.INDEPENDENT_WORKER)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/distribute/distribute_coordinator.py"", line 853, in run_distribute_coordinator
    task_id, session_config, rpc_layer)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/distribute/distribute_coordinator.py"", line 360, in _run_single_worker
    return worker_fn(strategy)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/engine/training_distributed.py"", line 772, in _worker_fn
    return method(model, **kwargs)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/engine/training_v2.py"", line 397, in fit
    prefix='val_')
  File ""/usr/lib/python3.7/contextlib.py"", line 130, in __exit__
    self.gen.throw(type, value, traceback)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/engine/training_v2.py"", line 757, in on_start
    self.callbacks._call_end_hook(mode)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/callbacks.py"", line 262, in _call_end_hook
    self.on_train_end()
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/callbacks.py"", line 379, in on_train_end
    callback.on_train_end(logs)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/callbacks.py"", line 966, in on_train_end
    self._training_state.delete_backup()
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/distribute/multi_worker_training_state.py"", line 173, in delete_backup
    tracking.AutoTrackable.__delattr__(self._model, CKPT_SAVED_EPOCH)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/training/tracking/tracking.py"", line 94, in __delattr__
    super(AutoTrackable, self).__delattr__(name)
AttributeError: _ckpt_saved_epoch
WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
2020-02-18 03:41:41.376299: W tensorflow/core/common_runtime/eager/context.cc:349] Unable to destroy server_ object, so releasing instead. Servers don't support clean shutdown.
srun: error: RpiCluster2: task 1: Exited with exit code 1
2020-02-18 03:41:45.023032: E tensorflow/core/common_runtime/ring_alg.cc:279] Aborting RingReduce with Invalid argument: [_Derived_]There aren't enough elements in this dataset for each shard to have at least one element (# elems = 1, # shards = 2). If you are using datasets with distribution strategy, considering setting the auto sharding policy to either DATA or OFF using the `experimental_distribute.auto_shard_policy` optionof `tf.data.Options()`.
         [[{{node MultiDeviceIteratorGetNextFromShard}}]]
         [[RemoteCall]]
         [[IteratorGetNext]]
2020-02-18 03:41:45.023246: W tensorflow/core/common_runtime/base_collective_executor.cc:217] BaseCollectiveExecutor::StartAbort Invalid argument: [_Derived_]There aren't enough elements in this dataset for each shard to have at least one element (# elems = 1, # shards = 2). If you are using datasets with distribution strategy, considering setting the auto sharding policy to either DATA or OFF using the `experimental_distribute.auto_shard_policy` optionof `tf.data.Options()`.
         [[{{node MultiDeviceIteratorGetNextFromShard}}]]
         [[RemoteCall]]
         [[IteratorGetNext]]
2020-02-18 03:41:45.023715: W tensorflow/core/framework/op_kernel.cc:1655] OP_REQUIRES failed at collective_ops.cc:253 : Invalid argument: [_Derived_]There aren't enough elements in this dataset for each shard to have at least one element (# elems = 1, # shards = 2). If you are using datasets with distribution strategy, considering setting the auto sharding policy to either DATA or OFF using the `experimental_distribute.auto_shard_policy` optionof `tf.data.Options()`.
         [[{{node MultiDeviceIteratorGetNextFromShard}}]]
         [[RemoteCall]]
         [[IteratorGetNext]]
2020-02-18 03:41:45.024006: W tensorflow/core/common_runtime/base_collective_executor.cc:217] BaseCollectiveExecutor::StartAbort Invalid argument: [_Derived_]There aren't enough elements in this dataset for each shard to have at least one element (# elems = 1, # shards = 2). If you are using datasets with distribution strategy, considering setting the auto sharding policy to either DATA or OFF using the `experimental_distribute.auto_shard_policy` optionof `tf.data.Options()`.
         [[{{node MultiDeviceIteratorGetNextFromShard}}]]
         [[RemoteCall]]
         [[IteratorGetNext]]
         [[CollectiveReduce]]
Traceback (most recent call last):
  File ""main_2.py"", line 98, in <module>
    multi_worker_model.fit(x=train_datasets, epochs=3, steps_per_epoch=5, callbacks = callbacks)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/engine/training.py"", line 819, in fit
    use_multiprocessing=use_multiprocessing)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/engine/training_distributed.py"", line 790, in fit
    *args, **kwargs)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/engine/training_distributed.py"", line 777, in wrapper
    mode=dc.CoordinatorMode.INDEPENDENT_WORKER)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/distribute/distribute_coordinator.py"", line 853, in run_distribute_coordinator
    task_id, session_config, rpc_layer)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/distribute/distribute_coordinator.py"", line 360, in _run_single_worker
    return worker_fn(strategy)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/engine/training_distributed.py"", line 772, in _worker_fn
    return method(model, **kwargs)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/engine/training_v2.py"", line 397, in fit
    prefix='val_')
  File ""/usr/lib/python3.7/contextlib.py"", line 130, in __exit__
    self.gen.throw(type, value, traceback)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/engine/training_v2.py"", line 771, in on_epoch
    self.callbacks.on_epoch_end(epoch, epoch_logs)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/callbacks.py"", line 302, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/callbacks.py"", line 990, in on_epoch_end
    self._save_model(epoch=epoch, logs=logs)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/callbacks.py"", line 1040, in _save_model
    self.model.save(filepath, overwrite=True)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/engine/network.py"", line 1008, in save
    signatures, options)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/saving/save.py"", line 115, in save_model
    signatures, options)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/saving/saved_model/save.py"", line 78, in save
    save_lib.save(model, filepath, signatures, options)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/saved_model/save.py"", line 916, in save
    object_saver.save(utils_impl.get_variables_path(export_dir))
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/training/tracking/util.py"", line 1168, in save
    file_prefix=file_prefix_tensor, object_graph_tensor=object_graph_tensor)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/training/tracking/util.py"", line 1116, in _save_cached_when_graph_building
    save_op = saver.save(file_prefix)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/training/saving/functional_saver.py"", line 230, in save
    sharded_saves.append(saver.save(shard_prefix))
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/training/saving/functional_saver.py"", line 69, in save
    tensors.append(spec.tensor)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/training/saving/saveable_object.py"", line 52, in tensor
    return self._tensor() if callable(self._tensor) else self._tensor
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/distribute/values.py"", line 1252, in tensor
    return strategy.extended.read_var(sync_on_read_variable)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/distribute/mirrored_strategy.py"", line 769, in read_var
    return replica_local_var._get_cross_replica()  # pylint: disable=protected-access
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/distribute/values.py"", line 1347, in _get_cross_replica
    self, axis=None)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/distribute/distribute_lib.py"", line 808, in reduce
    return self._extended._reduce(reduce_op, value)  # pylint: disable=protected-access
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/distribute/distribute_lib.py"", line 1449, in _reduce
    device_util.current() or ""/device:CPU:0""))[0]
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/distribute/collective_all_reduce_strategy.py"", line 528, in _reduce_to
    reduce_op, value, destinations=destinations)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/distribute/cross_device_ops.py"", line 282, in reduce
    destinations)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/distribute/cross_device_ops.py"", line 1038, in reduce_implementation
    all_reduced = self._batch_all_reduce(reduce_op, [per_replica_value])[0]
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/distribute/cross_device_ops.py"", line 1118, in _batch_all_reduce
    dense_results = self._do_batch_all_reduce_dense(reduce_op, dense_values)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/distribute/cross_device_ops.py"", line 1160, in _do_batch_all_reduce_dense
    ""Id"", communication_hint)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/distribute/cross_device_utils.py"", line 368, in build_collective_reduce
    return collective_all_reduce()
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/eager/def_function.py"", line 568, in __call__
    result = self._call(*args, **kwds)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/eager/def_function.py"", line 638, in _call
    return self._concrete_stateful_fn._filtered_call(canon_args, canon_kwds)  # pylint: disable=protected-access
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/eager/function.py"", line 1611, in _filtered_call
    self.captured_inputs)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/eager/function.py"", line 1692, in _call_flat
    ctx, args, cancellation_manager=cancellation_manager))
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/eager/function.py"", line 545, in call
    ctx=ctx)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/eager/execute.py"", line 67, in quick_execute
    six.raise_from(core._status_to_exception(e.code, message), None)
  File ""<string>"", line 3, in raise_from
tensorflow.python.framework.errors_impl.InvalidArgumentError:  [_Derived_]There aren't enough elements in this dataset for each shard to have at least one element (# elems = 1, # shards = 2). If you are using datasets with distribution strategy, considering setting the auto sharding policy to either DATA or OFF using the `experimental_distribute.auto_shard_policy` optionof `tf.data.Options()`.
         [[{{node MultiDeviceIteratorGetNextFromShard}}]]
         [[RemoteCall]]
         [[IteratorGetNext]]
         [[CollectiveReduce]] [Op:__inference_collective_all_reduce_1477]

Function call stack:
collective_all_reduce

2020-02-18 03:41:47.749541: W tensorflow/core/common_runtime/eager/context.cc:349] Unable to destroy server_ object, so releasing instead. Servers don't support clean shutdown.
1/5 [=====>........................] - ETA: 22ssrun: error: RpiCluster1: task 0: Exited with exit code 1

"
36845,tf.keras.losses.SparseCategoricalCrossentropy within the multi-GPU strategy.scope() generates NAN value,
36844,Documentation is very unclear. It lacks formulas in many APIs.,"For example, in SparseCategoricalAccuracy(), the words in this API does not help to give a clear picture to understand what it is doing. Why not give a formula. A formula, associated with an example, is clear enough for this API."
36842,Tensorlfow with Pycharm,"

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- TensorFlow installed from (source or binary): Source
- TensorFlow version: Latest to today
- Python version:3.7
- Installed using virtualenv? pip? conda?:Conda
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: idk
- GPU model and memory: 16gb intel core i5


Conda create -n tensor python=3.7
y
activate tensor
pip install tensorflow
pip install keras

logs
C:\Users\HP\Anaconda3\envs\tensor\pythonw.exe C:/Users/HP/PycharmProjects/TensorENV/Test.py
Traceback (most recent call last):
  File ""C:\Users\HP\Anaconda3\envs\tensor\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\HP\Anaconda3\envs\tensor\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\HP\Anaconda3\envs\tensor\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\HP\Anaconda3\envs\tensor\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\HP\Anaconda3\envs\tensor\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: The specified module could not be found.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:/Users/HP/PycharmProjects/TensorENV/Test.py"", line 1, in <module>
    import tensorflow
  File ""C:\Users\HP\Anaconda3\envs\tensor\lib\site-packages\tensorflow\__init__.py"", line 101, in <module>
    from tensorflow_core import *
  File ""C:\Users\HP\Anaconda3\envs\tensor\lib\site-packages\tensorflow_core\__init__.py"", line 40, in <module>
    from tensorflow.python.tools import module_util as _module_util
  File ""C:\Users\HP\Anaconda3\envs\tensor\lib\site-packages\tensorflow\__init__.py"", line 50, in __getattr__
    module = self._load()
  File ""C:\Users\HP\Anaconda3\envs\tensor\lib\site-packages\tensorflow\__init__.py"", line 44, in _load
    module = _importlib.import_module(self.__name__)
  File ""C:\Users\HP\Anaconda3\envs\tensor\lib\importlib\__init__.py"", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""C:\Users\HP\Anaconda3\envs\tensor\lib\site-packages\tensorflow_core\python\__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\Users\HP\Anaconda3\envs\tensor\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 74, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""C:\Users\HP\Anaconda3\envs\tensor\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\HP\Anaconda3\envs\tensor\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\HP\Anaconda3\envs\tensor\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\HP\Anaconda3\envs\tensor\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\HP\Anaconda3\envs\tensor\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: The specified module could not be found.


Failed to load the native TensorFlow runtime.
"
36841,DockerHub tag 2.1.0-py3 includes GPU support,"**System information**

DockerHub: [tensorflow/tensorflow:2.1.0-py3](https://hub.docker.com/layers/tensorflow/tensorflow/2.1.0-py3/images/sha256-14ec674cefd622aa9d45f07485500da254acaf8adfef80bd0f279db03c735689?context=explore)

**Describe the problem**

This Docker image seems to have the pip `tensorflow` package installed, rather than the `tensorflow-cpu` package. As of version 2.1.0, the `tensorflow` package includes GPU support (see the first bullet point in the [changelog](https://github.com/tensorflow/tensorflow/releases/tag/v2.1.0)).

Since [tensorflow/tensorflow:2.1.0-gpu-py3](https://hub.docker.com/layers/tensorflow/tensorflow/2.1.0-gpu-py3/images/sha256-1010e051dde4a9b62532a80f4a9a619013eafc78491542d5ef5da796cc2697ae?context=explore) is also provided, it seems to me like [tensorflow/tensorflow:2.1.0-py3](https://hub.docker.com/layers/tensorflow/tensorflow/2.1.0-py3/images/sha256-14ec674cefd622aa9d45f07485500da254acaf8adfef80bd0f279db03c735689?context=explore) should not include GPU support. If you believe that it should, would it be possible to publish e.g. tensorflow/tensorflow:2.1.0-cpu-py3 to DockerHub?

**Additional context**

The reason I noticed this is because I started seeing these warnings when running on CPU: 

```
W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory
W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory
W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
```

In addition to removing these warnings, having a cpu-only version would reduce the image size."
36840,Connecting to invalid output X of source node Y which has Z outputs [TF2.1-nightly],"Occurs in Graph execution (not Eager) with a `return_sequences=True` followed by `return_sequences=False` (but not either on its own) custom RNN layer; the layer involves `nn.moments` and `nn.batch_normalization` ops in `call`, as described [here](https://github.com/tensorflow/tensorflow/issues/36797). The error occurs upon:

 - `model.train_on_batch()` -- `.fit()` -- `.save_weights()` -- `.save()`

I tried `tf.compat.v1.experimental.output_all_intermediates(True)` and `False`, didn't help. Doesn't occur with built-in `LSTM` layer. 

Any resolution?

<hr>

**Error trace**:

```python
File ""C:\DL_code\dev_bn_indrnn\main2.py"", line 29, in <module>
  model.train_on_batch(x, y)
File ""D:\Anaconda\envs\tf2n_env\lib\site-packages\tensorflow\python\keras\engine\training_v1.py"", line 1083, in train_on_batch
  outputs = self.train_function(ins)  # pylint: disable=not-callable
File ""D:\Anaconda\envs\tf2n_env\lib\site-packages\tensorflow\python\keras\backend.py"", line 3597, in __call__
  session = get_session(inputs)
File ""D:\Anaconda\envs\tf2n_env\lib\site-packages\tensorflow\python\keras\backend.py"", line 528, in get_session
  _initialize_variables(session)
File ""D:\Anaconda\envs\tf2n_env\lib\site-packages\tensorflow\python\keras\backend.py"", line 943, in _initialize_variables
  [variables_module.is_variable_initialized(v) for v in candidate_vars])
File ""D:\Anaconda\envs\tf2n_env\lib\site-packages\tensorflow\python\client\session.py"", line 958, in run
  run_metadata_ptr)
File ""D:\Anaconda\envs\tf2n_env\lib\site-packages\tensorflow\python\client\session.py"", line 1181, in _run
  feed_dict_tensor, options, run_metadata)
File ""D:\Anaconda\envs\tf2n_env\lib\site-packages\tensorflow\python\client\session.py"", line 1359, in _do_run
  run_metadata)
File ""D:\Anaconda\envs\tf2n_env\lib\site-packages\tensorflow\python\client\session.py"", line 1384, in _do_call
  raise type(e)(node_def, op, message)

InvalidArgumentError: Node 'training/Nadam/gradients/gradients/ind_rnn/while_grad/ind_rnn/while_grad': 
Connecting to invalid output 46 of source node ind_rnn/while which has 46 outputs. 
Try using tf.compat.v1.experimental.output_all_intermediates(True).
```

<hr>

**Update**: while there aren't errors in Eager, the gradients are extremely small: `1e-9` to `1e-19`, whereas usually the same layers have `1e-6` to `1e-2`. This may or may not be a design rather than a bug problem."
36837,Tensorflow Lite Build Problem - Specialization for Eigen::internal::scalar_logistic_op<float> Removed,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Lunux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): source, branch r2.1
- TensorFlow version: 2.1.0
- Python version: 3.6
- Installed using virtualenv? pip? conda?: No
- Bazel version (if compiling from source): ./tensorflow/tools/ci_build/install/install_bazel.sh
- GCC/Compiler version (if compiling from source): arm-linux-gnueabihf-gcc (Ubuntu/Linaro 7.4.0-1ubuntu1~18.04.1) 7.4.0
- CUDA/cuDNN version:
- GPU model and memory:



**Describe the problem**

Cross-compiling Tensorflow Lite for Raspberry PI following published instructions.

Multiple failures to find `Eigen::internal::scalar_logistic_op`:

```In file included from tensorflow/lite/kernels/activations.cc:28:0:
./tensorflow/lite/kernels/internal/optimized/optimized_ops.h: In function 'void tflite::optimized_ops::LstmCell(const tflite::LstmCellParams&, const tflite::RuntimeShape&, const float*, const tflite::RuntimeShape&, const float*, const tflite::RuntimeShape&, const float*, const tflite::RuntimeShape&, const float*, const tflite::RuntimeShape&, const float*, const tflite::RuntimeShape&, float*, const tflite::RuntimeShape&, float*, const tflite::RuntimeShape&, float*, const tflite::RuntimeShape&, float*, tflite::CpuBackendContext*)':
./tensorflow/lite/kernels/internal/optimized/optimized_ops.h:2938:48: error: 'scalar_logistic_op' is not a member of 'Eigen::internal'
       input_gate_sm.unaryExpr(Eigen::internal::scalar_logistic_op<float>()) *
                                                ^~~~~~~~~~~~~~~~~~
```

**Provide the exact sequence of commands / steps that you executed before running into the problem**

```
git clone git@github.com:tensorflow/tensorflow.git
cd tensorflow && git checkout r2.1
./tensorflow/tools/ci_build/install/install_bazel.sh
./tensorflow/lite/tools/make/download_dependencies.sh
./tensorflow/lite/tools/make/build_rpi_lib.sh
```

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

Eigen has moved to GitLab. The release for 2.1.0 has an error in `download_dependencies.sh` - the BitBucket repository URL is not found since `curl` is called with `-s`. I cloned the repository and found this using `git log`:

```
commit 0f288e2ae6d343a978c4d5f6a951e20d7b69d96e
Author: Rasmus Munk Larsen <rmlarsen@google.com>
Date:   Mon Dec 2 17:00:58 2019 -0800

    Revert the specialization for scalar_logistic_op<float> introduced in:
    
    https://bitbucket.org/eigen/eigen/commits/5ce45e1849c9c8352266830f6f8e628f26b99a9a
    
    While providing a 50% speedup on Haswell+ processors, the large relative error outside [-18, 18] in this approximation causes problems, e.g., when computing gradients of activation functions like softplus in neural networks.
```

I tried other releases of Eigen with the same problem."
36835,graph_transforms not found when running export_tflite_ssd_graph.py to convert ssd model,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- TensorFlow installed from (source or binary): binary
- TensorFlow version (or github SHA if from source): 2.1.0


**Command used to run the converter or code if you’re using the Python API**
From issue #31015 I'm trying to run:

python ../models/research/object_detection/export_tflite_ssd_graph.py --pipeline_config_path pipeline.config --trained_checkpoint_prefix model.ckpt --output_directory my_frozen_graph --add_postprocessing_op True

The output is as follows:

Traceback (most recent call last):
  File ""../models/research/object_detection/export_tflite_ssd_graph.py"", line 96, in <module>
    from object_detection import export_tflite_ssd_graph_lib
  File ""/home/mello/venv36/lib/python3.6/site-packages/object_detection/export_tflite_ssd_graph_lib.py"", line 26, in <module>
    from tensorflow.tools.graph_transforms import TransformGraph
ModuleNotFoundError: No module named 'tensorflow.tools.graph_transforms'

The section in export_tflite_ssd_graph_lib.py where the error occurs:

import tensorflow as tf
from tensorflow.core.framework import attr_value_pb2
from tensorflow.core.framework import types_pb2
from tensorflow.core.protobuf import saver_pb2
from tensorflow.tools.graph_transforms import TransformGraph

I have tried binary install of tensorflow, both on ubuntu and on raspbian buster, have tried it with python 3.7 and 3.6, virtualenv or without.
Also have tried with tensorflow compiled using bazel.

Regardless, I alwas get that tensorflow.tools.graph_transforms are missing.

Model I'm using is ssd_mobilenet_v2_coco_2018_03_29

I don't believe it has the to do with the model, but probably with the tensorflow install (but not at all sure...)

Thanks for your help!"
36833,[tf2.1.0] model.save() throws TypeError when using tf.debugging.enable_check_numerics(),"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Redhat 8.1 (in Docker)
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): TF2.1.0
- Python version: 3.6.8
- CUDA/cuDNN version: 10.1
- GPU model and memory: V100, 32GB

**Describe the current behavior**
when using `tf.debugging.enable_check_numerics()`, model.save(...) will throw some TypeError as below:
```
TypeError: Input 'resource' of 'AssignVariableOp' Op has type float32 that does not match expected type of resource.
```

**Code to reproduce the issue** 
```python
import tensorflow as tf
tf.debugging.enable_check_numerics()

def build_and_compile_model():
    
    input = tf.keras.Input((20,))
    y = tf.keras.layers.Dense(2)
    model = tf.keras.Model(inputs=input, outputs=y)
    
    model.compile(
        loss=tf.keras.losses.sparse_categorical_crossentropy,
        optimizer=tf.keras.optimizers.SGD(learning_rate=0.001),
        metrics=['accuracy'])
    
    return model

model = build_and_compile_model()
model.save('test', save_format='tf')
```

**Other info / logs** 
Traceback logs as follows:
```
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
/tmp/site-packages/tensorflow_core/python/framework/op_def_library.py in _apply_op_helper(op_type_name, name, **keywords)
    467               as_ref=input_arg.is_ref,
--> 468               preferred_dtype=default_dtype)
    469         except TypeError as err:

/tmp/site-packages/tensorflow_core/python/framework/ops.py in convert_to_tensor(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)
   1289           ""Tensor conversion requested dtype %s for Tensor with dtype %s: %r"" %
-> 1290           (dtype.name, value.dtype.name, value))
   1291     return value

ValueError: Tensor conversion requested dtype resource for Tensor with dtype float32: <tf.Tensor 'dense/kernel/Read/ReadVariableOp:0' shape=(20, 2) dtype=float32>

During handling of the above exception, another exception occurred:

TypeError                                 Traceback (most recent call last)
<ipython-input-3-597a577ec9b0> in <module>()
      3 model = build_and_compile_model()
      4 
----> 5 model.save('test', save_format='tf')

/tmp/site-packages/tensorflow_core/python/keras/engine/network.py in save(self, filepath, overwrite, include_optimizer, save_format, signatures, options)
   1006     """"""
   1007     save.save_model(self, filepath, overwrite, include_optimizer, save_format,
-> 1008                     signatures, options)
   1009 
   1010   def save_weights(self, filepath, overwrite=True, save_format=None):

/tmp/site-packages/tensorflow_core/python/keras/saving/save.py in save_model(model, filepath, overwrite, include_optimizer, save_format, signatures, options)
    113   else:
    114     saved_model_save.save(model, filepath, overwrite, include_optimizer,
--> 115                           signatures, options)
    116 
    117 

/tmp/site-packages/tensorflow_core/python/keras/saving/saved_model/save.py in save(model, filepath, overwrite, include_optimizer, signatures, options)
     76     # we use the default replica context here.
     77     with distribution_strategy_context._get_default_replica_context():  # pylint: disable=protected-access
---> 78       save_lib.save(model, filepath, signatures, options)
     79 
     80   if not include_optimizer:

/tmp/site-packages/tensorflow_core/python/saved_model/save.py in save(obj, export_dir, signatures, options)
    907   object_saver = util.TrackableSaver(checkpoint_graph_view)
    908   asset_info, exported_graph = _fill_meta_graph_def(
--> 909       meta_graph_def, saveable_view, signatures, options.namespace_whitelist)
    910   saved_model.saved_model_schema_version = (
    911       constants.SAVED_MODEL_SCHEMA_VERSION)

/tmp/site-packages/tensorflow_core/python/saved_model/save.py in _fill_meta_graph_def(meta_graph_def, saveable_view, signature_functions, namespace_whitelist)
    588     for concrete_function in saveable_view.concrete_functions:
    589       concrete_function.add_to_graph()
--> 590     saver_def = saver.to_proto()
    591     meta_graph_def.saver_def.CopyFrom(saver_def)
    592   graph_def = exported_graph.as_graph_def(add_shapes=True)

/tmp/site-packages/tensorflow_core/python/training/saving/functional_saver.py in to_proto(self)
    149         shape=[], dtype=dtypes.string, name=""saver_filename"")
    150     save_tensor = self._traced_save(filename_tensor)
--> 151     restore_op = self._traced_restore(filename_tensor).op
    152     return saver_pb2.SaverDef(
    153         filename_tensor_name=filename_tensor.name,

/tmp/site-packages/tensorflow_core/python/eager/def_function.py in __call__(self, *args, **kwds)
    566         xla_context.Exit()
    567     else:
--> 568       result = self._call(*args, **kwds)
    569 
    570     if tracing_count == self._get_tracing_count():

/tmp/site-packages/tensorflow_core/python/eager/def_function.py in _call(self, *args, **kwds)
    613       # This is the first call of __call__, so we have to initialize.
    614       initializers = []
--> 615       self._initialize(args, kwds, add_initializers_to=initializers)
    616     finally:
    617       # At this point we know that the initialization is complete (or less

/tmp/site-packages/tensorflow_core/python/eager/def_function.py in _initialize(self, args, kwds, add_initializers_to)
    495     self._concrete_stateful_fn = (
    496         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access
--> 497             *args, **kwds))
    498 
    499     def invalid_creator_scope(*unused_args, **unused_kwds):

/tmp/site-packages/tensorflow_core/python/eager/function.py in _get_concrete_function_internal_garbage_collected(self, *args, **kwargs)
   2387       args, kwargs = None, None
   2388     with self._lock:
-> 2389       graph_function, _, _ = self._maybe_define_function(args, kwargs)
   2390     return graph_function
   2391 

/tmp/site-packages/tensorflow_core/python/eager/function.py in _maybe_define_function(self, args, kwargs)
   2701 
   2702       self._function_cache.missed.add(call_context_key)
-> 2703       graph_function = self._create_graph_function(args, kwargs)
   2704       self._function_cache.primary[cache_key] = graph_function
   2705       return graph_function, args, kwargs

/tmp/site-packages/tensorflow_core/python/eager/function.py in _create_graph_function(self, args, kwargs, override_flat_arg_shapes)
   2591             arg_names=arg_names,
   2592             override_flat_arg_shapes=override_flat_arg_shapes,
-> 2593             capture_by_value=self._capture_by_value),
   2594         self._function_attributes,
   2595         # Tell the ConcreteFunction to clean up its graph once it goes out of

/tmp/site-packages/tensorflow_core/python/framework/func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)
    976                                           converted_func)
    977 
--> 978       func_outputs = python_func(*func_args, **func_kwargs)
    979 
    980       # invariant: `func_outputs` contains only Tensors, CompositeTensors,

/tmp/site-packages/tensorflow_core/python/eager/def_function.py in wrapped_fn(*args, **kwds)
    437         # __wrapped__ allows AutoGraph to swap in a converted function. We give
    438         # the function a weak reference to itself to avoid a reference cycle.
--> 439         return weak_wrapped_fn().__wrapped__(*args, **kwds)
    440     weak_wrapped_fn = weakref.ref(wrapped_fn)
    441 

/tmp/site-packages/tensorflow_core/python/eager/function.py in bound_method_wrapper(*args, **kwargs)
   3204       if tf_inspect.ismethod(wrapped_fn):
   3205         wrapped_fn = six.get_unbound_function(wrapped_fn)
-> 3206       return wrapped_fn(weak_instance(), *args, **kwargs)
   3207 
   3208     # If __wrapped__ was replaced, then it is always an unbound function.

/tmp/site-packages/tensorflow_core/python/training/saving/functional_saver.py in _traced_restore(self, file_prefix)
    169       autograph=False)
    170   def _traced_restore(self, file_prefix):
--> 171     restore_ops = self.restore(file_prefix)
    172     with ops.device(""cpu:0""):
    173       with ops.control_dependencies(restore_ops.values()):

/tmp/site-packages/tensorflow_core/python/training/saving/functional_saver.py in restore(self, file_prefix)
    253     for device, saver in sorted(self._single_device_savers.items()):
    254       with ops.device(device):
--> 255         restore_ops.update(saver.restore(file_prefix))
    256     return restore_ops

/tmp/site-packages/tensorflow_core/python/training/saving/functional_saver.py in restore(self, file_prefix)
    100                                           structured_restored_tensors):
    101       restore_ops[saveable.name] = saveable.restore(
--> 102           restored_tensors, restored_shapes=None)
    103     return restore_ops
    104 

/tmp/site-packages/tensorflow_core/python/training/saving/saveable_object_util.py in restore(self, restored_tensors, restored_shapes)
    114       restored_tensor = array_ops.identity(restored_tensor)
    115       return resource_variable_ops.shape_safe_assign_variable_handle(
--> 116           self.handle_op, self._var_shape, restored_tensor)
    117 
    118 

/tmp/site-packages/tensorflow_core/python/ops/resource_variable_ops.py in shape_safe_assign_variable_handle(handle, shape, value, name)
    298   return gen_resource_variable_ops.assign_variable_op(handle,
    299                                                       value_tensor,
--> 300                                                       name=name)
    301 
    302 

/tmp/site-packages/tensorflow_core/python/ops/gen_resource_variable_ops.py in assign_variable_op(resource, value, name)
    152   # Add nodes to the TensorFlow graph.
    153   _, _, _op, _outputs = _op_def_library._apply_op_helper(
--> 154         ""AssignVariableOp"", resource=resource, value=value, name=name)
    155   return _op
    156 AssignVariableOp = tf_export(""raw_ops.AssignVariableOp"")(_ops.to_raw_op(assign_variable_op))

/tmp/site-packages/tensorflow_core/python/framework/op_def_library.py in _apply_op_helper(op_type_name, name, **keywords)
    489           if input_arg.type != types_pb2.DT_INVALID:
    490             raise TypeError(""%s expected type of %s."" %
--> 491                             (prefix, dtypes.as_dtype(input_arg.type).name))
    492           else:
    493             # Update the maps with the default, if needed.

TypeError: Input 'resource' of 'AssignVariableOp' Op has type float32 that does not match expected type of resource.
```
"
36831,"""ValueError: No gradients provided for any variable"" in TF2.1 custom models","**System information** 
- OS Platform and Distribution: Arch Linux
- TensorFlow version: v2.1.0-rc2-17-ge5bf8de 2.1.0 


I'm trying to train a custom model with tf.GradientTape, but it gives me this error:

```
ValueError: No gradients provided for any variable: ['MyModel/conv2d/kernel:0', 'MyModel/conv2d/bias:0'].
```

I don't see anything wrong in my code, can you point out where is the problem?

```python
train_dir = config.TRAIN_DIR
train_ds = tf.data.Dataset.list_files(str(train_dir / ""*""))
train_ds = (
    train_ds.map(load_frames, num_parallel_calls=12)
    .batch(batch_size)
    .prefetch(buffer_size=batch_size)
)

model = MyModel()
# Keep results for plotting
train_loss_results = []
optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)
mse_loss_fn = tf.keras.losses.MeanSquaredError()
for epoch in epochs:
    epoch_loss_avg = tf.keras.metrics.Mean()
    for inputs in train_ds:
        with tf.GradientTape() as tape:
            input_1, input_2, input_3 = inputs
            predictions, warping_output = model(inputs, training=True)
            rec_loss = mse_loss_fn(input_3, predictions)
            
        grads = tape.gradient(rec_loss, model.trainable_weights)
        optimizer.apply_gradients(zip(grads, model.trainable_weights))
        epoch_loss_avg(grads)  # Add current batch loss

    train_loss_results.append(epoch_loss_avg.result())
    if epoch % 50 == 0:
        print(""Epoch {:03d}: Loss: {:.3f}"".format(epoch, epoch_loss_avg.result()))

```

where `MyModel` is for example

```python
class MyModel(tf.keras.Model):
    def __init__(self, name=""MyModel"", **kwargs):
        super(MyModel, self).__init__(name=name, **kwargs)
        self.conv = tf.keras.layers.Conv2D(
            filters=32, kernel_size=7, strides=1, padding=""same""
        )

    def call(self, inputs, training=True, **kwargs):
        input_1, input_2, input_3 = inputs
        out = self.conv(input_1)
        return out
```
"
36829,[Keras] Fatal exception training a model with more outputs than targets from the generator,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
 - Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Arch Linux
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: 
- TensorFlow installed from (source or binary): Binary
- TensorFlow version (use command below): 2.1.0
- Python version: 3.8
- Bazel version (if compiling from source): 
- GCC/Compiler version (if compiling from source): 
- CUDA/cuDNN version: NA
- GPU model and memory: NA

**Describe the current behavior**

With eager execution enabled, the number of targets generated by the generator and the number of outputs produced by the model have to be the same. If there is a difference between the two, training fails with the following error:

```shell
ValueError: Unable to match target structure and sample_weight_modes structure:
  ...
    to  
  ['...', '...']
```

**Describe the expected behavior**

The example below should work whether using eager or non-eager execution.

**Code to reproduce the issue** Provide a reproducible test case that is the
bare minimum necessary to generate the problem.


```python
import tensorflow as tf
import numpy as np

# This script works if v2 is disabled, but fails if v2 is enabled.
tf.compat.v1.disable_v2_behavior()

# Create a very simple generator.
class Generator(tf.keras.utils.Sequence):
	def __len__(self):
		return 1

	def __getitem__(self, index):
		return np.zeros((1, 100, 100)), np.zeros((1, 2))
generator = Generator()

# Create a simple model with two outputs, one has a loss attached to it the other does not.
inputs = tf.keras.Input((100, 100))
flattened = tf.keras.layers.Flatten()(inputs)
output_1 = tf.keras.layers.Dense(2, name='output_for_loss')(flattened)
output_2 = tf.keras.layers.Reshape((2, -1), name='some_other_output')(flattened)
model = tf.keras.Model(inputs=inputs, outputs=[output_1, output_2])
model.compile(loss={'output_for_loss': tf.keras.losses.binary_crossentropy})

# Train using the generator.
model.fit(generator)
```

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

Complete traceback:

```shell
Traceback (most recent call last):
  File ""/usr/lib/python3.8/site-packages/tensorflow_core/python/util/nest.py"", line 329, in assert_same_structure
    _pywrap_utils.AssertSameStructure(nest1, nest2, check_types,
ValueError: The two structures don't have the same nested structure.

First structure: type=ndarray str=[[0. 0.]]

Second structure: type=tuple str=(None, None)

More specifically: Substructure ""type=tuple str=(None, None)"" is a sequence, while substructure ""type=ndarray str=[[0. 0.]]"" is not

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/usr/lib/python3.8/site-packages/tensorflow_core/python/keras/engine/data_adapter.py"", line 1076, in broadcast_sample_weight_modes
    nest.assert_same_structure(
  File ""/usr/lib/python3.8/site-packages/tensorflow_core/python/util/nest.py"", line 334, in assert_same_structure
    raise type(e)(""%s\n""
ValueError: The two structures don't have the same nested structure.

First structure: type=ndarray str=[[0. 0.]]

Second structure: type=tuple str=(None, None)

More specifically: Substructure ""type=tuple str=(None, None)"" is a sequence, while substructure ""type=ndarray str=[[0. 0.]]"" is not
Entire first structure:
.
Entire second structure:
(., .)

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/usr/lib/python3.8/site-packages/tensorflow_core/python/keras/engine/data_adapter.py"", line 1087, in broadcast_sample_weight_modes
    sample_weight_modes = nest.pack_sequence_as(
  File ""/usr/lib/python3.8/site-packages/tensorflow_core/python/util/nest.py"", line 504, in pack_sequence_as
    return _pack_sequence_as(structure, flat_sequence, expand_composites)
  File ""/usr/lib/python3.8/site-packages/tensorflow_core/python/util/nest.py"", line 448, in _pack_sequence_as
    raise ValueError(
ValueError: The target structure is of type `<class 'numpy.ndarray'>`
  [[0. 0.]]
However the input structure is a sequence (<class 'list'>) of length 2.
  [None, None]
nest cannot guarantee that it is safe to map one to the other.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""test.py"", line 25, in <module>
    model.fit(generator)
  File ""/usr/lib/python3.8/site-packages/tensorflow_core/python/keras/engine/training.py"", line 800, in fit
    return func.fit(
  File ""/usr/lib/python3.8/site-packages/tensorflow_core/python/keras/engine/training_v2.py"", line 219, in fit
    training_data_adapter, validation_adapter = _process_training_inputs(
  File ""/usr/lib/python3.8/site-packages/tensorflow_core/python/keras/engine/training_v2.py"", line 579, in _process_training_inputs
    train_adapter = _process_inputs(
  File ""/usr/lib/python3.8/site-packages/tensorflow_core/python/keras/engine/training_v2.py"", line 693, in _process_inputs
    adapter = adapter_cls(
  File ""/usr/lib/python3.8/site-packages/tensorflow_core/python/keras/engine/data_adapter.py"", line 945, in __init__
    super(KerasSequenceAdapter, self).__init__(
  File ""/usr/lib/python3.8/site-packages/tensorflow_core/python/keras/engine/data_adapter.py"", line 752, in __init__
    ) = self._canonicalize_peek(peek, kwargs.get(""sample_weight_modes""))
  File ""/usr/lib/python3.8/site-packages/tensorflow_core/python/keras/engine/data_adapter.py"", line 806, in _canonicalize_peek
    sample_weight_modes = broadcast_sample_weight_modes(
  File ""/usr/lib/python3.8/site-packages/tensorflow_core/python/keras/engine/data_adapter.py"", line 1093, in broadcast_sample_weight_modes
    raise ValueError(
ValueError: Unable to match target structure and sample_weight_modes structure:
  ...
    to  
  ['...', '...']
```

This issue seems to be introduced in https://github.com/tensorflow/tensorflow/commit/ac20030c96d37e980333b604402ef6dba48ef5e2 ."
36828,Build from Source Failure (Ubuntu 18.04 CUDA/cuDNN 10.1/7.6.5 Py 3.6 no AVX),"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Ubuntu 18.04
- TensorFlow installed from (source or binary):
Source
- TensorFlow version:
GPU 2.1
- Python version:
3.6
- Installed using virtualenv? pip? conda?:
NA - PIP3
- Bazel version (if compiling from source):
0.29.1
- GCC/Compiler version (if compiling from source):
7.4.0
- CUDA/cuDNN version:
10.1/7.6.5
- GPU model and memory:
GTX 1080 / 8GB


**Describe the problem**
The build process fails with:
ERROR: /home/greg/tensorflow/tensorflow/core/kernels/BUILD:4843:1: output 'tensorflow/core/kernels/_objs/depth_space_ops_gpu/depthtospace_op_gpu.cu.pic.o' was not created
ERROR: /home/greg/tensorflow/tensorflow/core/kernels/BUILD:4843:1: not all outputs were created or valid
Target //tensorflow/tools/pip_package:build_pip_package failed to build
ERROR: /home/greg/tensorflow/tensorflow/python/tools/BUILD:311:1 not all outputs were created or valid
INFO: Elapsed time: 248.378s, Critical Path: 97.82s
INFO: 853 processes: 853 local.
FAILED: Build did NOT complete successfully

**Provide the exact sequence of commands / steps that you executed before running into the problem**
I have tried both of the following with similar results:
bazel build --config=cuda //tensorflow/tools/pip_package:build_pip_package
bazel build  //tensorflow/tools/pip_package:build_pip_package

**Any other info / logs**
No other errors show in logs, can upload more of a snippet if needed, but no other reference to 'depthtospace_op_gpu.cu.pic' found leading to the failure for any hints.

I tried running the docker install as we from the install page, trying to avoid all the setup:
https://www.tensorflow.org/install/source

I got this error from the docker system on the 2nd docker command:
docker run --runtime=nvidia -it -w /tensorflow -v $PWD:/mnt -e HOST_PERMS=""$(id -u):$(id -g)"" tensorflow/tensorflow:devel-gpu-py3 bash
docker: Error response from daemon: Unknown runtime specified nvidia.
See 'docker run --help'.

I have build TensorFlow from source in the past, build 2.0b6 (no GPU) shortly after it was released and have no problems with GPU compiling of TensorFlow 1.X versions.  I have an old server without AVX support so I can't use the pre-compiled PIPs and haven't found one for my configuration with 2.1 yet.

Thanks.
"
36827,Keras with multiple outputs: cannot evaluate a metric without associated loss,"- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS 10.13.6
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): v2.1.0-rc2-17-ge5bf8de410 2.1.0
- Python version: v3.6.7:6ec5cf24b7, Oct 20 2018, 03:02:14

**Describe the current behavior**

I am training a model which has two outputs, but I only want to train it with respect to a loss function on the first output. Nervertheless, I want to calculate a metric based on the second output. So, I pass this kind of argument to `compile`: 
`loss={'main_output': tf.keras.losses.MeanSquaredError(),}, metrics={'second_output': tf.keras.losses.MeanSquaredError()}` or `loss={'main_output': tf.keras.losses.MeanSquaredError(), 'second_output': None}, metrics={'second_output': tf.keras.losses.MeanSquaredError()}`. This does not work as intendend as the metric on `second_output`is not computed when I call the `fit` method. The first try raises a Warning which explains why:
```
WARNING:tensorflow:Output second_output missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to second_output.
```
I don't get why the API is done that way, for what reason no data could be passed to `second_output`just because I didn't associate a loss.

**Workaround**
I had to write a custom loss functions returning always `0.` to make things work:
```
def zero_loss(y_true, y_pred):
    return 0.
model.compile(optimizer=tf.keras.optimizers.Adam(), 
              loss={'main_output': tf.keras.losses.MeanSquaredError(), 'second_output': zero_loss}, 
              metrics={'second_output': tf.keras.losses.MeanSquaredError()})
```
But this prints a lot of useless stuff when calling `model.fit`: this prints `second_output_loss: 0.0000e+00` on each epoch.

**Describe the expected behavior**
I think that metrics on outputs without losses should be able to be computed when calling `fit`or `evaluate`.

**Code to reproduce the issue** 

```
import tensorflow as tf
import numpy as np

print('Using Tensorflow version {} (git version {})'.format(tf.version.VERSION, tf.version.GIT_VERSION))

input_data = np.random.normal(size=(1024, 5))
target_data = {'main_output' : np.random.normal(size=(1024,)), 'second_output': np.random.normal(size=(1024,))}
input_dataset = tf.data.Dataset.from_tensor_slices(input_data)
target_dataset = tf.data.Dataset.from_tensor_slices(target_data)
dataset = tf.data.Dataset.zip((input_dataset, target_dataset)).batch(16)

def make_model():
    inp = tf.keras.Input(shape=(5))
    hidden = tf.keras.layers.Dense(24, activation='relu')(inp)
    out = tf.keras.layers.Dense(1, name='main_output')(hidden)
    out2 = tf.keras.layers.Lambda(lambda x: x ** 2, name='second_output')(out)
    model = tf.keras.Model(inputs=inp, outputs=[out, out2])
    return model

epochs = 2

model = make_model()
model.compile(optimizer=tf.keras.optimizers.Adam(), 
              loss={'main_output': tf.keras.losses.MeanSquaredError(),}, 
              metrics={'second_output': tf.keras.losses.MeanSquaredError()})
model.fit(x=dataset, epochs=epochs)

model = make_model()
model.compile(optimizer=tf.keras.optimizers.Adam(), 
              loss={'main_output': tf.keras.losses.MeanSquaredError(), 'second_output': None}, 
              metrics={'second_output': tf.keras.losses.MeanSquaredError()})
model.fit(x=dataset, epochs=epochs)

model = make_model()
def zero_loss(y_true, y_pred):
    return 0.
model.compile(optimizer=tf.keras.optimizers.Adam(), 
              loss={'main_output': tf.keras.losses.MeanSquaredError(), 'second_output': zero_loss}, 
              metrics={'second_output': tf.keras.losses.MeanSquaredError()})
model.fit(x=dataset, epochs=epochs)
```"
36826,tf.lite.TFLiteConverter error when I trying to convert keras .h5 Yolov3 model.,"**System information**
google colab
tf ver. '2.1.0'


**Command used to run the converter or code if you’re using the Python API**

```
yolo_keras_model= tf.keras.models.load_model(filepath=""yolo.h5"", compile=False)
converter = tf.lite.TFLiteConverter.from_keras_model(yolo_keras_model)
tflite_model = converter.convert()
```

**The output from the converter invocation**

```
ValueError: None is only supported in the 1st dimension. Tensor 'input_1' has invalid shape '[None, None, None, 3]'.
```

**Also, please include a link to the saved model or GraphDef**

```
# my .h5 file
# https://drive.google.com/open?id=1R8PAoeYtkUyiN8XBUohLmmJYxR97p14o.
```

**Failure details**
I read #22564, bit this decision is not clear to me. 
Also, i try to use TFLiteConverter.from_concrete_functions()
```
yolo_model= tf.keras.models.load_model(filepath=""yolo.h5"", compile=False)
export_dir = ""/saved_model""
tf.saved_model.save(yolo_model, export_dir)
model = tf.saved_model.load(export_dir)
concrete_func = model.signatures[
  tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY]
concrete_func.inputs[0].set_shape([1, 416, 416, 3])
coverter = tf.lite.TFLiteConverter.from_concrete_functions([concrete_func])
tflite_model = coverter .convert()
```
Error
```
/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/func_graph.py in deref(weak_v)
    482       if v is None:
    483         raise AssertionError(
--> 484             ""Called a function referencing variables which have been deleted. ""
    485             ""This likely means that function-local variables were created and ""
    486             ""not referenced elsewhere in the program. This is generally a ""
AssertionError: Called a function referencing variables which have been deleted. This likely means that function-local variables were created and not referenced elsewhere in the program. This is generally a mistake; consider storing variables in an object attribute on first call.
```
What i should do?  As i understand, this steps are necessary for quantization. "
36823,"decode_wav_op.cc:55 : Invalid argument: Bad file size for WAV: Expected 16 or 18, but got 40","**System information** 

- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Fedora 31
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
 - TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.1
- Python version: 3.7
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A

**Describe the current behavior**

```
import tensorflow as tf

# from https://github.com/Athospd/wavesurfer/blob/master/data-raw/Glaucidium-minutissimum-22180.wav
file = tf.io.read_file(""/tmp/Glaucidium-minutissimum-22180.wav"")
tf.audio.decode_wav(file)
```

error:

```
2020-02-17 14:20:35.070542: W tensorflow/core/framework/op_kernel.cc:1675] OP_REQUIRES failed at decode_wav_op.cc:55 : Invalid argument: Bad file size for WAV: Expected 16 or 18, but got40
```

**Describe the expected behavior**

No error

**Code to reproduce the issue** 

See above.

**Other info / logs**

File is played without problems by e.g. `sox`.

File info:

```
Input File     : 'Glaucidium-minutissimum-22180.wav'
Channels       : 1
Sample Rate    : 16000
Precision      : 16-bit
Duration       : 00:00:46.29 = 740624 samples ~ 3471.68 CDDA sectors
File Size      : 1.48M
Bit Rate       : 256k
Sample Encoding: 16-bit Signed Integer PCM
```

Also, the number of samples dòes not seem to be the problem, as after a simple resampling 

```
sox Glaucidium-minutissimum-22180.wav -r 16000 o5.wav
```

the new output is decoded without error.

Source location is

https://github.com/tensorflow/tensorflow/blob/e4c9dedb31df127aa6f52050f70f0084fd3e4c93/tensorflow/core/lib/wav/wav_io.cc#L238

but it is not clear to me what exactly is going on, so it would be great if this could be investigated. Thanks!"
36822,exception in gradient computation for losses when combining Tensor and EagerTensor,"**System information** - Have I written custom code (as opposed to using a stock
example script provided in TensorFlow): yes 
- OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04): - Linux Mint 19 
- TensorFlow installed from (source or binary): binary (pip)
- TensorFlow version (use command below): v2.1.0-rc2-17-ge5bf8de 2.1.0
- Python version: 3.6

**Describe the current behavior**
The following minimal example works when using the second implementation alternative, but raises an error for the first:
```python
ip = layers.Input(10)
with tf.GradientTape() as tape:
    t = tf.zeros((10, 10))
    tape.watch(t)
    # this line throws an error 
    result = keras.losses.MeanSquaredError()(t, ip)
    # but this one works
    # result = (t - ip)**2 / tf.cast(tf.reduce_prod(tf.shape(t)), tf.float32)
tape.gradient(result, t)
```

The error is
```
  File ""~/wrapper.py"", line 101, in <module>
    print(tape.gradient(result, t))
  File ""~/venv/lib/python3.6/site-packages/tensorflow_core/python/eager/backprop.py"", line 1029, in gradient
    unconnected_gradients=unconnected_gradients)
  File ""~/venv/lib/python3.6/site-packages/tensorflow_core/python/eager/imperative_grad.py"", line 77, in imperative_grad
    compat.as_str(unconnected_gradients.value))
  File ""~/venv/lib/python3.6/site-packages/tensorflow_core/python/eager/backprop.py"", line 141, in _gradient_function
    return grad_fn(mock_op, *out_grads)
  File ""~/venv/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py"", line 258, in _MeanGrad
    sum_grad = _SumGrad(op, grad)[0]
  File ""~/venv/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py"", line 213, in _SumGrad
    op.inputs[1])
  File ""~/venv/lib/python3.6/site-packages/tensorflow_core/python/ops/math_ops.py"", line 3502, in reduced_shape
    input_shape = input_shape.numpy()
AttributeError: 'Tensor' object has no attribute 'numpy'
```
**Describe the expected behavior**
As the second implementation works, i would also expect the first to work.

I have not done exhaustive testing of different loss functions, but the same problem also occurs when replacing the `MeanSquaredError` by `CategoricalCrossEntropy`. The problem seems to be caused by the fact that only one of the arguments to the loss function is an `EagerTensor`."
36821,Memory leak using generators with tf.data.experimental.AUTOTUNE,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information** - Have I written custom code (as opposed to using a stock
example script provided in TensorFlow): - OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04): - Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if
the issue happens on mobile device: - TensorFlow installed from (source or
binary): - TensorFlow version (use command below): - Python version: - Bazel
version (if compiling from source): - GCC/Compiler version (if compiling from
source): - CUDA/cuDNN version: - GPU model and memory:

Windows 10
Tensorflow 2.0
RTX 2060

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

Read images from a generator using ""num_parallel_calls=AUTOTUNE"" is eating all memory

**Describe the expected behavior**

Don't use up all memory

**Code to reproduce the issue** Provide a reproducible test case that is the
bare minimum necessary to generate the problem.

```
def my_generator(data_dir):
    def my_func():
        paths = pathlib.Path(data_dir).rglob('*.png')
        for path in paths:
            yield str(path)
    return my_func

def process_path_test(file_path):
    """"""Read a tensorflow image from a png file and return the
    image and filepath for writing out during test time""""""
    img_file = tf.io.read_file(file_path)
    img = tf.io.decode_png(img_file, channels=1, dtype=tf.uint16)
    return img, file_path

def some_func(img, file_path):
    return img, file_path

p_dir = '//Some_path_to_images'
AUTOTUNE = tf.data.experimental.AUTOTUNE
test_imgs = tf.data.Dataset.from_generator(my_generator(p_dir), tf.string).map(process_path_test)
test_imgs = test_imgs.map(some_func, num_parallel_calls=AUTOTUNE)
my_iter = iter(test_imgs)
next(my_iter)
```

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
36819,Keras fit generator - ValueError: Failed to find data adapter that can handle input,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information** - Have I written custom code (as opposed to using a stock
example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04): Linux Ubuntu 18.04
- TensorFlow installed from (source or
binary): source
- TensorFlow version (use command below): 2.1.0
- Python version: 3.6
- Keras Version: 2.3.1

When i fit the model, it shows me this error:
`      Traceback (most recent call last):
  File ""/home/castilho/PycharmProjects/Chargrid/Chargrid/main.py"", line 201, in <module>
    target_path=target_path, prefix=prefix_splits, make_new_representation=False, train=True)
  File ""/home/castilho/PycharmProjects/Chargrid/Chargrid/main.py"", line 117, in main
    nn.train(representations_path=representations_path, target_path=target_path, training_filenames = data['train_imgs'], validation_filenames=data['val_imgs'])
  File ""/home/castilho/PycharmProjects/Chargrid/Chargrid/neural_network.py"", line 150, in train
    validation_steps=int(len(validation_filenames) // batch_size))
  File ""/home/castilho/PycharmProjects/Chargrid/venv/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py"", line 819, in fit
    use_multiprocessing=use_multiprocessing)
  File ""/home/castilho/PycharmProjects/Chargrid/venv/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py"", line 235, in fit
    use_multiprocessing=use_multiprocessing)
  File ""/home/castilho/PycharmProjects/Chargrid/venv/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py"", line 533, in _process_training_inputs
    adapter_cls = data_adapter.select_data_adapter(x, y)
  File ""/home/castilho/PycharmProjects/Chargrid/venv/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/data_adapter.py"", line 998, in select_data_adapter
    _type_name(x), _type_name(y)))
ValueError: Failed to find data adapter that can handle input: <class 'Chargrid.dataset_generator.RepresentationGenerator'>, <class 'NoneType'>

Process finished with exit code 1`



I think this a bug in Keras. Below, is a part of the code when i fit the model.
`       def train(self, representations_path: str, target_path: str, training_filenames: list, validation_filenames: list,
              batch_size: int = 7):
        
        train_generator = RepresentationGenerator(representation_path=representations_path, target_path=target_path,
                                                  filenames=training_filenames, batch_size=batch_size)
        val_generator = RepresentationGenerator(representation_path=representations_path, target_path=target_path,
                                                filenames=validation_filenames, batch_size=batch_size)
        self.model_semantic.fit(x=train_generator, batch_size=7,
                                steps_per_epoch=int(len(training_filenames) // batch_size),
                                epochs=10,
                                verbose=1,
                                validation_data=val_generator,
                                validation_steps=int(len(validation_filenames) // batch_size))
        return 0`


My class RepresentationGenerator is:

`from tensorflow_core.python.keras.utils.data_utils import Sequence


class RepresentationGenerator(Sequence):

    def __init__(self, representation_path, target_path, filenames, batch_size):
        self.filenames = np.array(filenames)
        self.batch_size = batch_size
        self.representation_path = representation_path
        self.target_path = target_path

    def __len__(self):
        return (np.ceil(len(self.filenames) / float(self.batch_size))).astype(np.int)

    def __getitem__(self, idx):
        files_to_batch = self.filenames[idx * self.batch_size: (idx + 1) * self.batch_size]
        batch_x, batch_y = [], []
        for file in files_to_batch:
            batch_x.append(np.load(self.representation_path + file + "".npy"", allow_pickle=True))
            batch_y.append(np.load(self.target_path + file + "".npy"", allow_pickle=True))

        return np.array(batch_x), np.array(batch_y)
`


When i fit the model with a generator, the variable Y assume as None and it shows the error above. How can i fix that?

**System information**  
- Have I written custom code (as opposed to using example directory):  Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Linux Ubuntu 18.04
- TensorFlow backend (yes / no):  Yes
- TensorFlow version:  2.1.0
- Keras version:  2.3.1
- Python version:  3.6
- GPU model and memory:  NVIDIA Corporation GP108M [GeForce MX250]
"
36818,How the Frozen model from tensor flow audio recognition is made and converted to tensor flow lite model?,"Thank you for submitting a TensorFlow documentation issue. Per our GitHub
policy, we only address code/doc bugs, performance issues, feature requests, and
build/installation issues on GitHub.

The TensorFlow docs are open source! To get involved, read the documentation
contributor guide: https://www.tensorflow.org/community/contribute/docs

## URL(s) with the issue:

Please provide a link to the documentation entry, for example:
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/MyMethod

## Description of issue (what needs changing):

### Clear description

For example, why should someone use this method? How is it useful?

### Correct links

Is the link to the source code correct?

### Parameters defined

Are all parameters defined and formatted correctly?

### Returns defined

Are return values defined?

### Raises listed and defined

Are the errors defined? For example,
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises

### Usage example

Is there a usage example?

See the API guide: https://www.tensorflow.org/community/contribute/docs_ref
on how to write testable usage examples.

### Request visuals, if applicable

Are there currently visuals? If not, will it clarify the content?

### Submit a pull request?

Are you planning to also submit a pull request to fix the issue? See the docs
contributor guide: https://www.tensorflow.org/community/contribute/docs,
docs API guide: https://www.tensorflow.org/community/contribute/docs_ref and the
docs style guide: https://www.tensorflow.org/community/contribute/docs_style
After following the steps train.py and freeze.py from the tutorial ,the structure of my frozen model looks like(https://imgur.com/a/JtNVkHw) which is different from the official frozen model conv_actions_frozen.pb(https://imgur.com/a/KJXExbV).

When I Converted Frozen model to Tensorflow lite using the steps:

import tensorflow as tf
converter = tf.compat.v1.lite.TFLiteConverter.from_frozen_graph(""./my_frozen_graph.pb"", input_arrays=['decoded_sample_data', 'decoded_sample_data:1'], output_arrays=['labels_softmax'])
converter.allow_custom_ops=True
tflite_model = converter.convert()
open(""output.tflite"", ""wb"").write(tflite_model)
The Tflite model obtained is getting crashed when tested in android studio and the structure of my tflite model (https://imgur.com/a/uceoHlo) is also different from the original speech commands tflite model(https://imgur.com/a/lWmxl9d).

I suspect something went wrong in the creation of frozen model from the tutorial. Could someone kindly help in generating the frozen model for speech commands.

Tensorflow version-2.1.0

python version - 3.7.3"
36816,Can tensorflow use multiple ps servers to store an embedding variable? ,"Thank you for reading. 
Can tensorflow use multiple parameter servers to store an embedding variable? 
My embedding is too big, the bandwidth of a server is not enough. 
Which module should I use?

Looking forward to your reply！
Thanks！"
36815,2GB Protobuf limit,"Greetings,

I am training some deep learning models using Ubuntu Server 18.04 along with the following nvidia docker: nvcr.io/nvidia/tensorflow:20.01-tf1-py3

Tensorflow-gpu 1.15.2
CUDA 10.2
GPU TITAN RTX 24GB

Everything is working very well and with a solid performance boost compared to my windows setup.
However, it is limited to having a set window size of 328,328,328 - once I go with any larger window size the following happens:

File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py"", line 3166, in _as_graph_def
graph.ParseFromString(compat.as_bytes(data))

As far as I understand this has to do with the protbuf limit set at 2GB as default. If I print the length of the data being serialized it is just under 2GB at the working window_size and just over when it is not working.

If I run the same script in windows10 (with pip install of tensorflow-gpu==1.15.2), the protobuf error is not present. But it is running out of memory with higher resolutions as windows is using significant amounts of VRAM in background.

My question is: How do I raise the limit of the protobuf while using the dockerfile in question. I am not interested in simply lowerering the window size because the higher windowsize we choose, the better is the quality of the output in the end.

I have tried looking into the ops.py and also the coded_stream.h - without knowing exactly what to change"
36814,Can't import Layer from tensorflow.python.keras.engine.base_layer,"I'm getting an error that says `from tensorflow.python.keras.engine.base_layer import Layer` while importing tensorflow in my app.

**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04): MacOS
- TensorFlow installed from (source or
binary): binary
- TensorFlow version (use command below): 1.15.0
- Python version: 3.7

**Describe the current behavior**
On packaging an app using tensorflow with py2app, I get the following error while running the app: 
```
File ""/Users/harshitdwivedi/Desktop/aftershootscripts/dist/aftershoot.app/Contents/Resources/lib/python3.7/tensorflow_core/__init__.py"", line 36, in <module>
    from tensorflow._api.v1 import compat
  File ""/Users/harshitdwivedi/Desktop/aftershootscripts/dist/aftershoot.app/Contents/Resources/lib/python3.7/tensorflow_core/_api/v1/compat/__init__.py"", line 23, in <module>
    from tensorflow._api.v1.compat import v1
  File ""/Users/harshitdwivedi/Desktop/aftershootscripts/dist/aftershoot.app/Contents/Resources/lib/python3.7/tensorflow_core/_api/v1/compat/v1/__init__.py"", line 40, in <module>
    from tensorflow._api.v1.compat.v1 import experimental
  File ""/Users/harshitdwivedi/Desktop/aftershootscripts/dist/aftershoot.app/Contents/Resources/lib/python3.7/tensorflow_core/_api/v1/compat/v1/experimental/__init__.py"", line 11, in <module>
    from tensorflow.python.ops.control_flow_v2_toggles import output_all_intermediates
  File ""/Users/harshitdwivedi/Desktop/aftershootscripts/dist/aftershoot.app/Contents/Resources/lib/python3.7/tensorflow_core/python/ops/control_flow_v2_toggles.py"", line 24, in <module>
    from tensorflow.python.ops import control_flow_util_v2
  File ""/Users/harshitdwivedi/Desktop/aftershootscripts/dist/aftershoot.app/Contents/Resources/lib/python3.7/tensorflow_core/python/ops/control_flow_util_v2.py"", line 28, in <module>
    from tensorflow.python.keras.engine import base_layer_utils
  File ""/Users/harshitdwivedi/Desktop/aftershootscripts/dist/aftershoot.app/Contents/Resources/lib/python3.7/tensorflow_core/python/keras/__init__.py"", line 27, in <module>
    from tensorflow.python.keras import applications
  File ""/Users/harshitdwivedi/Desktop/aftershootscripts/dist/aftershoot.app/Contents/Resources/lib/python3.7/tensorflow_core/python/keras/applications/__init__.py"", line 25, in <module>
    from tensorflow.python.keras import engine
  File ""/Users/harshitdwivedi/Desktop/aftershootscripts/dist/aftershoot.app/Contents/Resources/lib/python3.7/tensorflow_core/python/keras/engine/__init__.py"", line 23, in <module>
    from tensorflow.python.keras.engine.base_layer import Layer
  File ""/Users/harshitdwivedi/Desktop/aftershootscripts/dist/aftershoot.app/Contents/Resources/lib/python3.7/tensorflow_core/python/keras/engine/base_layer.py"", line 58, in <module>
    from tensorflow.python.keras.saving.saved_model import save as saved_model
  File ""/Users/harshitdwivedi/Desktop/aftershootscripts/dist/aftershoot.app/Contents/Resources/lib/python3.7/tensorflow_core/python/keras/saving/saved_model/save.py"", line 30, in <module>
    from tensorflow.python.keras.saving import saving_utils
  File ""/Users/harshitdwivedi/Desktop/aftershootscripts/dist/aftershoot.app/Contents/Resources/lib/python3.7/tensorflow_core/python/keras/saving/__init__.py"", line 33, in <module>
    from tensorflow.python.keras.saving.saved_model_experimental import export_saved_model
  File ""/Users/harshitdwivedi/Desktop/aftershootscripts/dist/aftershoot.app/Contents/Resources/lib/python3.7/tensorflow_core/python/keras/saving/saved_model_experimental.py"", line 30, in <module>
    from tensorflow.python.keras.utils import mode_keys
  File ""/Users/harshitdwivedi/Desktop/aftershootscripts/dist/aftershoot.app/Contents/Resources/lib/python3.7/tensorflow_core/python/keras/utils/__init__.py"", line 38, in <module>
    from tensorflow.python.keras.utils.multi_gpu_utils import multi_gpu_model
  File ""/Users/harshitdwivedi/Desktop/aftershootscripts/dist/aftershoot.app/Contents/Resources/lib/python3.7/tensorflow_core/python/keras/utils/multi_gpu_utils.py"", line 22, in <module>
    from tensorflow.python.keras.engine.training import Model
  File ""/Users/harshitdwivedi/Desktop/aftershootscripts/dist/aftershoot.app/Contents/Resources/lib/python3.7/tensorflow_core/python/keras/engine/training.py"", line 42, in <module>
    from tensorflow.python.keras import metrics as metrics_module
  File ""/Users/harshitdwivedi/Desktop/aftershootscripts/dist/aftershoot.app/Contents/Resources/lib/python3.7/tensorflow_core/python/keras/metrics.py"", line 34, in <module>
    from tensorflow.python.keras.engine.base_layer import Layer
ImportError: cannot import name 'Layer' from 'tensorflow.python.keras.engine.base_layer' (/Users/harshitdwivedi/Desktop/aftershootscripts/dist/aftershoot.app/Contents/Resources/lib/python3.7/tensorflow_core/python/keras/engine/base_layer.py)
```

**Describe the expected behavior**
The packaged app should work as expected.

**Code to reproduce the issue** Provide a reproducible test case that is the
bare minimum necessary to generate the problem.

```
import tensorflow as tf

self.model_path = r""{}"".format(
            pathlib.Path(os.getcwd()).joinpath('model'))
        self.session = tf.Session(graph=tf.Graph())
        tf.saved_model.loader.load(self.session, ['serve'], self.model_path)
```

here's the setup.py that I've used with py2app: 

```
""""""
This is a setup.py script generated by py2applet

Usage:
    python setup.py py2app
""""""

from setuptools import setup

APP = ['aftershoot.py']
DATA_FILES = []
OPTIONS = {
        'packages' : ['PySide2', 'shiboken2', 'tensorflow_core', 'astor'],
        'resources' : ['exposure/']
        # 'optimize' : 1,
        }

setup(
    app=APP,
    data_files=DATA_FILES,
    options={'py2app': OPTIONS},
    setup_requires=['py2app']
)
```"
36813,utils,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Python version**:
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with:

```bash
python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""
```

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
36810,Gradient Support for Unique operator,"I am trying to run a custom graph with only Unique op for a debugging.

`with tf.GradientTape() as g:
y = tf.unique(x)
dy_dx = g.gradient(y, x)`

The Forward pass runs fine, but getting this error during Backward pass:

> LookupError: gradient registry has no entry for: Unique

Gradient yet to be supported for Unique (or) there is no gradient for Unique ? Please help me understand why incase if its the second one.
"
36809,import_graph_def  with cond nodes fails in eager/tf.function contexts,"*Have I written custom code*: Yes
*OS Platform and Distribution*: Ubuntu 16.04
*Tensorflow installed from*: binary
*Tensorflow version*: v2.1.0-rc2-17-ge5bf8de 2.1.0 (cpu)

**Describe the current behavior**
`import_graph_def` fails to rebuild graphs containing `tf.cond` nodes in eager mode/`tf.function`ed calls.

**Describe the expected behavior**
Work as it does using tf 1.x-style session calls, or eager mode/`tf.function`ed calls on graph defs containing similar nodes like `tf.where`.

**Code to reproduce the issue**
```python
import tensorflow as tf

graph = tf.Graph()
with graph.as_default():
    x = tf.keras.backend.placeholder(shape=(), dtype=tf.float32)
    y = tf.keras.backend.placeholder(shape=(), dtype=tf.float32)
    training = tf.keras.backend.placeholder(shape=(), dtype=tf.bool)
    z = tf.cond(training, lambda: x * 10, lambda: y * 2)

graph_def = graph.as_graph_def()


def fn(*args):
    x_value, y_value, training_value = args
    return tf.graph_util.import_graph_def(graph_def,
                                          input_map={
                                              x.op.name: x_value,
                                              y.op.name: y_value,
                                              training.op.name: training_value,
                                          },
                                          return_elements=[z.name])


class ImportedCondTest(tf.test.TestCase):

    def test_in_graph_mode(self):
        with tf.Graph().as_default():
            out = tf.graph_util.import_graph_def(graph_def,
                                                 input_map={
                                                     x.op.name: 0.,
                                                     y.op.name: 1.0,
                                                     training.op.name: True,
                                                 },
                                                 return_elements=[z.name])
            with tf.compat.v1.Session() as sess:
                sess.run(out)

    def test_fn(self):
        fn(0., 1., True)

    def test_tf_function_fn(self):
        tf.function(fn)(0., 1., True)

    def test_map(self):
        dataset = tf.data.Dataset.from_tensor_slices(([0.], [1.], [True]))
        mapped = dataset.map(fn)
        for _ in mapped:
            pass


if __name__ == '__main__':
    tf.test.main()
```

**Other info / logs**
```
Running tests under Python 3.6.8: ...anaconda2/envs/tf-2.0-cpu/bin/python
[ RUN      ] ImportedCondTest.test_in_graph_mode
2020-02-17 15:13:40.567294: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-02-17 15:13:40.587856: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3491630000 Hz
2020-02-17 15:13:40.588472: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55f5c5ffbd30 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-02-17 15:13:40.588510: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[       OK ] ImportedCondTest.test_in_graph_mode
[ RUN      ] ImportedCondTest.test_map
2020-02-17 15:13:40.733678: W tensorflow/core/framework/op_kernel.cc:1655] OP_REQUIRES failed at optimize_dataset_op.cc:60 : Invalid argument: Unable to find FunctionDef for cond_true_4 in the registry.
[  FAILED  ] ImportedCondTest.test_map
[ RUN      ] ImportedCondTest.test_normal
[  FAILED  ] ImportedCondTest.test_normal
[ RUN      ] ImportedCondTest.test_session
[  SKIPPED ] ImportedCondTest.test_session
[ RUN      ] ImportedCondTest.test_tf_function
[  FAILED  ] ImportedCondTest.test_tf_function
======================================================================
ERROR: test_map (__main__.ImportedCondTest)
test_map (__main__.ImportedCondTest)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""cond_fail.py"", line 47, in test_map
    for _ in mapped:
  File ""...anaconda2/envs/tf-2.0-cpu/lib/python3.6/site-packages/tensorflow_core/python/data/ops/dataset_ops.py"", line 418, in __iter__
    return iterator_ops.OwnedIterator(self)
  File ""...anaconda2/envs/tf-2.0-cpu/lib/python3.6/site-packages/tensorflow_core/python/data/ops/iterator_ops.py"", line 594, in __init__
    self._create_iterator(dataset)
  File ""...anaconda2/envs/tf-2.0-cpu/lib/python3.6/site-packages/tensorflow_core/python/data/ops/iterator_ops.py"", line 600, in _create_iterator
    dataset = dataset._apply_options()
  File ""...anaconda2/envs/tf-2.0-cpu/lib/python3.6/site-packages/tensorflow_core/python/data/ops/dataset_ops.py"", line 381, in _apply_options
    static_optimization_configs)
  File ""...anaconda2/envs/tf-2.0-cpu/lib/python3.6/site-packages/tensorflow_core/python/data/ops/dataset_ops.py"", line 4213, in __init__
    **self._flat_structure)
  File ""...anaconda2/envs/tf-2.0-cpu/lib/python3.6/site-packages/tensorflow_core/python/ops/gen_dataset_ops.py"", line 3638, in optimize_dataset
    _ops.raise_from_not_ok_status(e, name)
  File ""...anaconda2/envs/tf-2.0-cpu/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py"", line 6606, in raise_from_not_ok_status
    six.raise_from(core._status_to_exception(e.code, message), None)
  File ""<string>"", line 3, in raise_from
tensorflow.python.framework.errors_impl.InvalidArgumentError: Unable to find FunctionDef for cond_true_4 in the registry. [Op:OptimizeDataset]

======================================================================
ERROR: test_normal (__main__.ImportedCondTest)
test_normal (__main__.ImportedCondTest)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""cond_fail.py"", line 39, in test_normal
    fn(0., 1., True)
  File ""cond_fail.py"", line 21, in fn
    return_elements=[z.name])
  File ""...anaconda2/envs/tf-2.0-cpu/lib/python3.6/site-packages/tensorflow_core/python/util/deprecation.py"", line 507, in new_func
    return func(*args, **kwargs)
  File ""...anaconda2/envs/tf-2.0-cpu/lib/python3.6/site-packages/tensorflow_core/python/framework/importer.py"", line 405, in import_graph_def
    producer_op_list=producer_op_list)
  File ""...anaconda2/envs/tf-2.0-cpu/lib/python3.6/site-packages/tensorflow_core/python/framework/importer.py"", line 487, in _import_graph_def_internal
    validate_colocation_constraints)
  File ""...anaconda2/envs/tf-2.0-cpu/lib/python3.6/site-packages/tensorflow_core/python/framework/importer.py"", line 221, in _PopulateTFImportGraphDefOptions
    dst_output = input_dst._as_tf_output()  # pylint: disable=protected-access
  File ""...anaconda2/envs/tf-2.0-cpu/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py"", line 1125, in _as_tf_output
    ""_as_tf_output not supported when eager execution is enabled."")
NotImplementedError: _as_tf_output not supported when eager execution is enabled.

======================================================================
ERROR: test_tf_function (__main__.ImportedCondTest)
test_tf_function (__main__.ImportedCondTest)
----------------------------------------------------------------------
Traceback (most recent call last):
  File ""cond_fail.py"", line 42, in test_tf_function
    tf.function(fn)(0., 1., True)
  File ""...anaconda2/envs/tf-2.0-cpu/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py"", line 568, in __call__
    result = self._call(*args, **kwds)
  File ""...anaconda2/envs/tf-2.0-cpu/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py"", line 638, in _call
    return self._concrete_stateful_fn._filtered_call(canon_args, canon_kwds)  # pylint: disable=protected-access
  File ""...anaconda2/envs/tf-2.0-cpu/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py"", line 1611, in _filtered_call
    self.captured_inputs)
  File ""...anaconda2/envs/tf-2.0-cpu/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py"", line 1692, in _call_flat
    ctx, args, cancellation_manager=cancellation_manager))
  File ""...anaconda2/envs/tf-2.0-cpu/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py"", line 545, in call
    ctx=ctx)
  File ""...anaconda2/envs/tf-2.0-cpu/lib/python3.6/site-packages/tensorflow_core/python/eager/execute.py"", line 67, in quick_execute
    six.raise_from(core._status_to_exception(e.code, message), None)
  File ""<string>"", line 3, in raise_from
tensorflow.python.framework.errors_impl.InvalidArgumentError: Op type not registered 'cond_true_4' in binary running on jackd-5810. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed. while building NodeDef 'import/cond/then/_0' [Op:__inference_fn_61]

----------------------------------------------------------------------
Ran 5 tests in 0.243s

FAILED (errors=3, skipped=1)
```"
36808,Is Tensorflow impossible to predict multiple steps?,"Thank you for reading. I'm not good at English. 

I am wondering how to predict and get future time series data after model training. I would like to get the values after N steps.

So, I used the time series in the Tensorflow tutorial to practice predicting the model.

```
a = y_val[-look_back:] 
for i in range(N-step prediction): #predict a new value n times.
    tmp = model.predict(a.reshape(-1, look_back, num_feature)) #predicted value     
    a = a[1:] #remove first     
    a = np.append(a, tmp) #insert predicted value
```
The results are predicted by linear graphs from nonlinear graphs as shown below.

![1](https://imgur.com/7tenqRd.png)

How can I get the actual, right solution? or Is Tessorflow impossible to predict multiple steps?

[full source](https://gist.github.com/Lay4U/96e0ba8d8c251046e89eae4bc5d40510)  (After the 25th line is my code.)

[epoch=100](https://gist.github.com/Lay4U/3c530649934af39a6c6e9884a8eb14fd)"
36807,wrong doc for categorical_hinge loss ,"## Description of issue (what needs changing):

document for tensorflow.keras.losses.categorical_hinge is wrong

### Clear description

```python
@keras_export('keras.losses.categorical_hinge')
def categorical_hinge(y_true, y_pred):
  """"""Computes the categorical hinge loss between `y_true` and `y_pred`.
  `loss = maximum(neg - pos + 1, 0)`
  where `neg = sum(y_true * y_pred)` and `pos = maximum(1 - y_true)`
  Args:
    y_true: The ground truth values. `y_true` values are expected to be -1 or 1.
      If binary (0 or 1) labels are provided they will be converted to -1 or 1.
    y_pred: The predicted values.
  Returns:
    Categorical hinge loss values.
  """"""
  y_pred = ops.convert_to_tensor_v2(y_pred)
  y_true = math_ops.cast(y_true, y_pred.dtype)
  pos = math_ops.reduce_sum(y_true * y_pred, axis=-1)
  neg = math_ops.reduce_max((1. - y_true) * y_pred, axis=-1)
  return math_ops.maximum(0., neg - pos + 1.)
```

Should be: `neg=maximum((1-y_true)*y_pred)` and `pos=sum(y_true*y_pred)`
"
36806,how to use pretrain weight,"This template is for miscellaneous issues not covered by the other issue categories.

For questions on how to work with TensorFlow, or support for problems that are not verified bugs in TensorFlow, please go to [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).

If you are reporting a vulnerability, please use the [dedicated reporting process](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md).

For high-level discussions about TensorFlow, please post to discuss@tensorflow.org, for questions about the development or internal workings of TensorFlow, or if you would like to know how to contribute to TensorFlow, please post to developers@tensorflow.org.

-----------------------------------------------------------------------------------------------------------

Hi, can somenoe guide me how to use quantization aware with a pretrain weight(32bit)?
I have already trained a 32bit weight. Can I make it be a pretrain weight and train by quantization aware(tf.contrib.quantize.create_training_graph(quant_delay=300000))?

Thank you."
36805,Convert `std::vector<tensorflow::Tensor>` into `std::vector<float>`,"How to convert Tensor `<type: float shae: [1, 512, 800, 1] >` into `std::vector<float>` ?

I've tried [stackoverflow](https://stackoverflow.com/questions/44843368/convert-tensorflow-tensor-of-variable-size-to-stdvector-in-c) and some others  also, but failed
Thank you beforehand."
36804,TFlite got error output when enable hexagon delegate,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information** - Have I written custom code (as opposed to using a stock
example script provided in TensorFlow): - OS Platform and Distribution (
Linux Ubuntu 16.04): - Mobile device (OPPO reno ace) if
the issue happens on mobile device: - TensorFlow installed from (source or
binary): - TensorFlow version (use command below): - Python version: - Bazel
version (if compiling from source): - GCC/Compiler version (if compiling from
source): - CUDA/cuDNN version: - GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
I use this model for testing: https://storage.googleapis.com/mirror.tensorflow.org/storage.googleapis.com/download.tensorflow.org/models/tflite/coco_ssd_mobilenet_v1_0.75_quant_2018_06_29.zip
I set all input values as 1(just for tesing), then print the first 50 values of output[0], see below picture, on the left is the values when running on CPU, on the right is the values when enable hexagon delegate, 
![cpu_dsp](https://user-images.githubusercontent.com/29744812/74617424-eee9c300-5167-11ea-9061-53225444a7b7.png)

CPU and DSP got diffrent output


**Describe the expected behavior**
CPU and DSP should get the same output values


**Code to reproduce the issue** Provide a reproducible test case that is the
bare minimum necessary to generate the problem.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
36803,"Start the thread in Hook, resulting in failure to exit when train_step fails","<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information** - Have I written custom code (as opposed to using a stock
example script provided in TensorFlow): - OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04): - Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if
the issue happens on mobile device: - TensorFlow installed from (source or
binary): - TensorFlow version (use command below): - Python version: - Bazel
version (if compiling from source): - GCC/Compiler version (if compiling from
source): - CUDA/cuDNN version: - GPU model and memory:

Ubuntu16.04 x86_64 GNU/Linux

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

Tensorflow@v1.12.0

**Describe the current behavior**

I use the Estimator for training, and implements a hook (I'm sorry, but for some reason I can't show the source code), in the hook's’ `after_create_session` method, I started a python thread (a bit like TPUInfeedOutfeedSessionHook) which sess.run a block type op(eg. `dequeue`). Also, I implemented the end method,which will run an op(eg. `enqueue`) to prevent the thread from getting stuck.But Estimator explicitly describes the behavior of the hooks: if sess.run on in train step return failure, it will not call the end (and after_run) method. In the code, MonitorSession call the _close_internal method (it will invoke the Session.close()) which will wait for all the work thread ends, but obviously, the thread executing sess.run in my hook's after_create_session will not be able to exit )

**Describe the expected behavior**

I feel my usage is not strange, also the realization of the reference part TPUEstimator (TPUInfeedOutfeedSessionHook is similar to my hook). Does tensorflow not allowed to start a thread in the hook?As once it's started, when something goes wrong in the training step, the next call is session.close()，Eventually the Tensorflow process got stuck.

**Code to reproduce the issue** Provide a reproducible test case that is the
bare minimum necessary to generate the problem.
```PYTHON
def my_thread_task:
 while True:
        try:
          session.run(self._dequeue_ops)
        except tf.errors.OutOfRangeError: # this signal will send by end() method
          break
        except Exception as e:
          # raise runtime error
def after_create_session:
  threading.Thread(target=my_thread_task)
```
**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
36802,DataLoss error on TFRecords - Randomly when accessing the dataset on S3 like storage,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information** 
- OS Platform and Distribution (e.g.,Linux Ubuntu 16.04): CentOS Linux 7.7
- TensorFlow installed from (source or
binary): binary
- TensorFlow version (use command below): 1.14.0
- Python version: 3.6.8
- Bazel
- CUDA/cuDNN version: 410.79/V10.0.130
- GPU model and memory: V100 8 GPUs /16130MiB

**Describe the current behavior**

I'm running tensorflow benchmark ResNet50 on Fuse of cloud storage(Alibaba Cloud Storage: oss). It succeed many times, or failed at the beginning of training. And when it passed the beginning,  it never failed during the training. And the speed is also good.

 The workload is 4 V100 GPU instances and each has 8 GPUs: 32 GPUs in total. 

```
  (0) Data loss: corrupted record at 0
	 [[{{node MultiDeviceIteratorGetNextFromShard}}]]
	 [[RemoteCall]]
	 [[input_processing/IteratorGetNext]]
	 [[cluster_5_1/merge_oidx_1/_951]]
  (1) Data loss: corrupted record at 0
	 [[{{node MultiDeviceIteratorGetNextFromShard}}]]
	 [[RemoteCall]]
	 [[input_processing/IteratorGetNext]]
0 successful operations.
0 derived errors ignored.
Traceback (most recent call last):
  File ""/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1356, in _do_call
    return fn(*args)
  File ""/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1341, in _run_fn
    options, feed_dict, fetch_list, target_list, run_metadata)
  File ""/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1429, in _call_tf_sessionrun
    run_metadata)
tensorflow.python.framework.errors_impl.DataLossError: 2 root error(s) found.
  (0) Data loss: corrupted record at 0
	 [[{{node MultiDeviceIteratorGetNextFromShard}}]]
	 [[RemoteCall]]
	 [[input_processing/IteratorGetNext]]
	 [[cluster_5_1/merge_oidx_1/_951]]
  (1) Data loss: corrupted record at 0
	 [[{{node MultiDeviceIteratorGetNextFromShard}}]]
	 [[RemoteCall]]
	 [[input_processing/IteratorGetNext]]
```

I can make sure the tfrecords are correct, because we have checked it one by one.
The logs of fuse and Cloud storage system doesn't have any hint.
Could your guys suggest what may cause this issue? Is there any latency requirement? Or could we set timeout in somewhere? Thanks very much for your help!


Here is the full log:
[test.log](https://github.com/tensorflow/tensorflow/files/4211351/test.log)


**Describe the expected behavior**

**Code to reproduce the issue** Provide a reproducible test case that is the
bare minimum necessary to generate the problem.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
36801,TypeError: Object of type float32 is not JSON serializable,"**System information**
- Have I written custom code: Yes
- OS Platform and Distribution: Mac OS Catalina (Version: 10.15.3)
- TensorFlow installed from: binary
- TensorFlow version: 2.1
- Python version: 3.7.5
- GPU model and memory: Intel Iris Pro 1536 MB

**Describe the current behavior**

I get the following error

> TypeError: Object of type float32 is not JSON serializable

when I try to save the state of the optimizer **after** having trained the model. Before training the model, I can save the state of the optimizer without getting any error.

**Describe the expected behavior**

No error.

**Code to reproduce the issue** 

```
import json

import tensorflow as tf


def get_model(input_shape=(1,)):
    model = tf.keras.Sequential()
    model.add(tf.keras.layers.Input(shape=input_shape))
    model.add(tf.keras.layers.Dense(8, activation=""relu""))
    model.add(tf.keras.layers.Dense(1))
    model.summary()
    model.compile(loss=""mse"", optimizer=""adam"")
    return model


def write_config(model, optimizer_file_path=""optimizer.json""):
    with open(optimizer_file_path, ""w"") as f:
        json.dump(model.optimizer.get_config(), f, indent=4, sort_keys=True)


def get_data(n=100):
    import numpy as np
    data_x = np.random.rand(n, 1)
    data_y = np.asarray([1 if x > 0.5 else 0 for x in data_x]).reshape(data_x.shape)
    return data_x, data_y


if __name__ == '__main__':
    model = get_model()

    x, y = get_data()

    # No error before fitting.
    # write_config(model)

    model.fit(x, y, epochs=2)

    # Error after fitting.
    write_config(model)
```

**Other**

Note that [the documentation of `model.optimizer.get_config()` says that the returned value is serializable](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Optimizer#get_config)

> An optimizer config is a Python dictionary (serializable) containing the configuration of an optimizer."
36800,Pip package building fail on third party NASM linking ,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 Pro (version 1903 ; 18362.657)
- TensorFlow installed from (source or binary): source
- TensorFlow version: 2.0.1
- Python version: 3.7.3
- Bazel version (if compiling from source): 0.26.1
- GCC/Compiler version (if compiling from source): MSVC 16 (VS2019)
- CUDA/cuDNN version: 10.2 + 7
- GPU model and memory: NVIDIA Titan RTX

**Describe the problem**

Building from source the pip package fails due to a failing linking to a third-party library (NASM)
**NOTE**: During the first building try, my antivirus (Avira) put a nasm-related generated file in quarantine, so I disabled it before doing a clean new build.

**Provide the exact sequence of commands / steps that you executed before running into the problem**

- Preamble : Installed all prerequisites as given by https://www.tensorflow.org/install/source_windows
- Run the configuration script (`python ./configure.py`) with following options: python 3.7 ; XLA support ; no ROCm ; CUDA 10.2 + cuDNN 7 ; AVX2 instruction set ; Eigen inline override
- Fix the WORKSPACE file by adding:
~~~~
http_archive(
    name = ""io_bazel_rules_docker"",
    sha256 = ""dc97fccceacd4c6be14e800b2a00693d5e8d07f69ee187babfd04a80a9f8e250"",
    strip_prefix = ""rules_docker-0.14.1"",
    urls = [""https://github.com/bazelbuild/rules_docker/releases/download/v0.14.1/rules_docker-v0.14.1.tar.gz""],
)
~~~~
after the http_archive for closure rules (otherwise build fails when trying to execute `git reset --hard [...]` on @io_bazel_rules_docker)
- Run the bazel build (`bazel build //tensorflow/tools/pip_package:build_pip_package`)
The build fail during the linking of the 3rd party NASM library (see error log under)

**Any other info / logs**

python configure.py
~~~~
Please specify the location of python. [Default is C:\Program Files\Python_3.7.3\python.exe]:


Found possible Python library paths:
  C:\Program Files\Python_3.7.3\lib\site-packages
Please input the desired Python library path to use.  Default is [C:\Program Files\Python_3.7.3\lib\site-packages]

Do you wish to build TensorFlow with XLA JIT support? [y/N]: y
XLA JIT support will be enabled for TensorFlow.

Do you wish to build TensorFlow with ROCm support? [y/N]: n
No ROCm support will be enabled for TensorFlow.

Do you wish to build TensorFlow with CUDA support? [y/N]: y
CUDA support will be enabled for TensorFlow.

Found CUDA 10.2 in:
    C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v10.2/lib/x64
    C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v10.2/include
Found cuDNN 7 in:
    C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v10.2/lib/x64
    C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v10.2/include


Please specify a list of comma-separated CUDA compute capabilities you want to build with.
You can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.
Please note that each additional compute capability significantly increases your build time and binary size, and that TensorFlow only supports compute capabilities >= 3.5 [Default is: 3.5,7.0]: 7.5


Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is /arch:AVX]: /arch:AVX2


Would you like to override eigen strong inline for some C++ compilation to reduce the compilation time? [Y/n]: y
Eigen strong inline overridden.

Preconfigured Bazel build configs. You can use any of the below by adding ""--config=<>"" to your build command. See .bazelrc for more details.
        --config=mkl            # Build with MKL support.
        --config=monolithic     # Config for mostly static monolithic build.
        --config=gdr            # Build with GDR support.
        --config=verbs          # Build with libverbs support.
        --config=ngraph         # Build with Intel nGraph support.
        --config=numa           # Build with NUMA support.
        --config=dynamic_kernels        # (Experimental) Build kernels into separate shared objects.
        --config=v2             # Build TensorFlow 2.x instead of 1.x.
Preconfigured Bazel build configs to DISABLE default on features:
        --config=noaws          # Disable AWS S3 filesystem support.
        --config=nogcp          # Disable GCP support.
        --config=nohdfs         # Disable HDFS support.
        --config=noignite       # Disable Apache Ignite support.
        --config=nokafka        # Disable Apache Kafka support.
        --config=nonccl         # Disable NVIDIA NCCL support.
~~~~

Build error
~~~~
ERROR: C:/users/tyrmalion/_bazel_tyrmalion/mrkkanxp/external/nasm/BUILD.bazel:8:1: Linking of rule '@nasm//:nasm' failed (Exit 1104): link.exe failed: error executing command
  cd C:/users/tyrmalion/_bazel_tyrmalion/mrkkanxp/execroot/org_tensorflow
  SET CUDA_TOOLKIT_PATH=C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v10.2
    SET INCLUDE=C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.24.28314\ATLMFC\include;C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.24.28314\include;C:\Program Files (x86)\Windows Kits\NETFXSDK\4.6.1\include\um;C:\Program Files (x86)\Windows Kits\10\include\10.0.17763.0\ucrt;C:\Program Files (x86)\Windows Kits\10\include\10.0.17763.0\shared;C:\Program Files (x86)\Windows Kits\10\include\10.0.17763.0\um;C:\Program Files (x86)\Windows Kits\10\include\10.0.17763.0\winrt;C:\Program Files (x86)\Windows Kits\10\include\10.0.17763.0\cppwinrt
    SET LIB=C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.24.28314\ATLMFC\lib\x64;C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.24.28314\lib\x64;C:\Program Files (x86)\Windows Kits\NETFXSDK\4.6.1\lib\um\x64;C:\Program Files (x86)\Windows Kits\10\lib\10.0.17763.0\ucrt\x64;C:\Program Files (x86)\Windows Kits\10\lib\10.0.17763.0\um\x64;
    SET PATH=C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\VC\Tools\MSVC\14.24.28314\bin\HostX64\x64;C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\Common7\IDE\VC\VCPackages;C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\Common7\IDE\CommonExtensions\Microsoft\TestWindow;C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\Common7\IDE\CommonExtensions\Microsoft\TeamFoundation\Team Explorer;C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\MSBuild\Current\bin\Roslyn;C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\Team Tools\Performance Tools\x64;C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\Team Tools\Performance Tools;C:\Program Files (x86)\Microsoft Visual Studio\Shared\Common\VSPerfCollectionTools\vs2019\\x64;C:\Program Files (x86)\Microsoft Visual Studio\Shared\Common\VSPerfCollectionTools\vs2019\;C:\Program Files (x86)\Microsoft SDKs\Windows\v10.0A\bin\NETFX 4.6.1 Tools\x64\;C:\Program Files (x86)\Windows Kits\10\bin\10.0.17763.0\x64;C:\Program Files (x86)\Windows Kits\10\bin\x64;C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\\MSBuild\Current\Bin;C:\WINDOWS\Microsoft.NET\Framework64\v4.0.30319;C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\Common7\IDE\;C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\Common7\Tools\;;C:\WINDOWS\system32;C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\Common7\IDE\CommonExtensions\Microsoft\CMake\CMake\bin;C:\Program Files (x86)\Microsoft Visual Studio\2019\Community\Common7\IDE\CommonExtensions\Microsoft\CMake\Ninja
    SET PWD=/proc/self/cwd
    SET PYTHON_BIN_PATH=C:/Program Files/Python_3.7.3/python.exe
    SET PYTHON_LIB_PATH=C:/Program Files/Python_3.7.3/lib/site-packages
    SET RUNFILES_MANIFEST_ONLY=1
    SET TEMP=C:\Users\TYRMAL~1\AppData\Local\Temp
    SET TF2_BEHAVIOR=1
    SET TF_CONFIGURE_IOS=0
    SET TF_CUDA_COMPUTE_CAPABILITIES=7.5
    SET TF_ENABLE_XLA=1
    SET TF_NEED_CUDA=1
    SET TMP=C:\Users\TYRMAL~1\AppData\Local\Temp
  C:/Program Files (x86)/Microsoft Visual Studio/2019/Community/VC/Tools/MSVC/14.24.28314/bin/HostX64/x64/link.exe /nologo /OUT:bazel-out/x64_windows-opt/bin/external/nasm/nasm /SUBSYSTEM:CONSOLE /MACHINE:X64 @bazel-out/x64_windows-opt/bin/external/nasm/nasm-2.params
Execution platform: @bazel_tools//platforms:host_platform
LINK : fatal error LNK1104: cannot open file 'bazel-out\x64_windows-opt\bin\external\nasm\nasm'
Target //tensorflow/tools/pip_package:build_pip_package failed to build
INFO: Elapsed time: 478.038s, Critical Path: 27.71s
INFO: 563 processes: 563 local.
FAILED: Build did NOT complete successfully
~~~~"
36799,Feature Request: General Purpose Metrics Callback,"# Background
I am coming from tensorflow addons and have been send here by @pavithrasv and @seanpmorgan to start this discussion. The root of this is that we have great problems to implement a clean and bugfree F1 metric for keras. See here: https://github.com/tensorflow/addons/issues/825

# Feature Request Description
For keras / tensorflow it is possible to implement custom metrics. These metrics are basicaly keras layers and have to be implemented with tensorflow itself. For many reasons it is not easy to implement certain metrics. This is the reason why some metrics like F1 are still not available in TF and have a history of ugly bugs. This is why I think that it would be good to implement a callback to plug in any metric without having to use TF. So you could plug in all sklearn metrics you want to use.
This is the case with other tools like LightGBM and XGBoost. See `feval` parameter of `lightgbm.train`: https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.train.html#lightgbm.train

# First Idea of Implementation
A first implementation version could look like this (but has some limitations - see below):

``` python
class MetricsCallback(keras.callbacks.Callback):
    def __init__(self, val_data, val_labels, fmetrics):
        super().__init__()
        self.val_data = val_data
        self.val_labels = val_labels
        self.fmetrics = fmetrics
        # TODO: more checks

    def on_epoch_end(self, epoch, logs=None):
        logs = logs or {}
        predict_results = self.model.predict(self.val_data)

        for fm in self.fmetrics:
            metric_name, value = fm(self.val_labels, predict_results)
            logs[metric_name] = value
```

## Limitations
You have to give validation data to this callback and not to the fit function of keras. Otherwise the validation data will be predicted twice - once from keras fit and once from this callback. 

And if you want to use the EarlyStopping callback you have to provide this callback before the EarlyStopping callback.

# Next Steps
What are the next steps? I would like to start a discussion on how to implement the first version in a way that integrates with keras and does not feel like a hack."
36798,TF 2.0: Spyder auto complete and go to definition not working. Please fix it!,"Due to the nature of the ""lazy import"" spyder IDE is not able to resolve the package tree and fails both ""auto complete"" and ""go to function definition"". 

Spyder guys told me TF should implemeny .pyi files to overcome this.

https://github.com/spyder-ide/spyder/issues/11553"
36797,Severe slowdown with 1 BN step in while_v2,"I'm developing recurrent batch normalization for LSTM, and am seeing a best-case scenario of **8x slowdown** relative to base implementation (worst-case can **exceed 20x**). `tf.function` helps notably, but not nearly enough - and the behavior is unreasonable; applying the operation on _1 out of 150 steps_ yields a 6.7x slowdown, and on 150/150 steps, 8x. I suspect [`while_v2.while_loop()`](https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/ops/control_flow_ops.py#L2666)'s gradient handling is responsible.

The problem's exacerbated by TF 2.1's [broken profiler](https://github.com/tensorflow/tensorboard/issues/3256) - my IDE (Spyder 4) is also unable to capture the call details in Eager or Graph, unlike in TF2. I also cannot develop in 2.0 per bug fixes and significant performance improvements. I don't think `while_v2` was designed to handle whatever I'm doing.

What can I do to circumvent such a severe slowdown? Also, is this the best place to ask, or is there a dev forum somewhere to avoid a month-long back & forth? Help is appreciated.

<hr>

**DETAILS**: a part of the full code:

```python
def recurrent_bn(self, inputs_t, op_name, step, training=None):
    training = self._get_training_value(training)
    beta, gamma, moving_mean, moving_variance = self._get_bn_vars(op_name)

    @tf.function
    def outs(inputs_t, step, beta, gamma, moving_mean, moving_variance, training):
        if tf.math.less(step, self.max_inference_step) and (training != False):
            mean_t, variance_t = self._get_stats_and_maybe_update(
                inputs_t, step, moving_mean, moving_variance, training)
        else:
            mean_t, variance_t = moving_mean[-1], moving_variance[-1]
        return nn.batch_normalization(inputs_t, mean_t, variance_t,
                                      beta, gamma, self.bn_epsilon)

    outputs = outs(inputs_t, step, beta, gamma, moving_mean,
                   moving_variance, training)
    outputs.set_shape(inputs_t.shape)
    return outputs

def _get_bn_vars(self, op_name):
    return [getattr(self, op_name + '_' + var_name) for var_name in
            ('gamma', 'beta', 'moving_mean', 'moving_variance')]  # these were built
```

`recurrent_bn` is applied 9 times in `call` - 4 times for each of `i, f, c, o` of `kernel, recurrent`, and once on `c`. `_get_stats_and_maybe_update` returns `nn.moments` applied on `moving_...[step:step+1]` slice, and calls [`_assign_moving_average`](https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/keras/layers/normalization.py#L503) (added method to `LSTMCell`) when `training` is truthy. `LSTM` and `LSTMCell` are also inherited by `recurrent_v2` classes, which yielded a speedup.

 - `gamma, beta` have shape `(1, self.units)`
 - `moving_mean, moving_variance` have shape `(self.max_inference_steps, self.units)`
 - There are 9 of each -> 36 total
 - Example call: `x_i = self.recurrent_bn(x_i, 'kernel_i', step, training)`

<hr>

**Possible culprits**:

 1. Gradients, **main culprit**, via T2-T5: T3 yielded significant speedup relative to every other test, including T4 - and T5 was negligible. It appears that updating the BN variables just _once_ triggers some gradient operations for _every timestep_ - hence the slowdown. 
 2. `_get_bn_vars`, **unknown**; the variables are being fetched from a Python dictionary in `tf.function`, and though there are no retracing warnings, it's still a suspect
 3. `nn.batch_normalization` + `nn.moments`, **ruled out** via T2; only a 12% speedup is granted.
 4. `step`, **ruled out** via T6 + T7; no noted performance difference
 5. `CuDNNLSTM`, **ruled out**; I set `implementation = 1` and `recurrent_dropout = .05`

**Tests**:

 - **T1**: replace `self.max_inference_steps` (`.numpy() == 150`) with `tf.constant(1, dtype='int64')
 - **T2**: T1 + move `nn.batch_normalization` under `if`, replace `else` with `return inputs_t`
 - **T3**: wrap `gamma, beta` with `K.stop_gradient()` _before_ `if`, and `mean_t, variance_t` _after_ `else` (otherwise cannot slice wrapped tensor)
 - **T4**: T3, but wrap everything _after_ `else`.
 - **T5**: `K.stop_gradient` on `inputs_t, training`
 - **T6**: immediately `return inputs_t` in `recurrent_bn`
 - **T7**: remove hidden state `step`, don't return `step + 1` in `call`

**Bugs**:

  1. Wrapping `self._assign_moving_average` with `self.add_update` fails [`_assert_same_graph()`](https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/framework/ops.py#L5816):

```
original_item == updates[0], item == updates[1]
updates[0] == <tf.Operation 'training/Adam/Adam/AssignAddVariableOp' type=AssignAddVariableOp>
updates[1] == <tf.Operation 'AssignMovingAvg' type=ResourceStridedSliceAssign>
updates[0].graph == <tensorflow.python.framework.ops.Graph object at 0x000002A3473AF788>
updates[1].graph == <tensorflow.python.ops.control_flow_v2_func_graphs.CondBranchFuncGraph
                     object at 0x000002A35C7F2548>
```
   -  [`updates`](https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/keras/engine/training.py#L2059); `len(updates) == 37` = 9*4 + 1; so 4 per each of 9 calls to `recurrent_bn`, +1 default
   - [`self.add_update`](https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/keras/layers/recurrent_v2.py#L1158) is used in `LSTM` right _after_ `K.rnn` - so it appears that `while_v2` is responsible for `updates[1].graph` being different
   - `self.add_update` compiles, and yields a 10% speedup in Eager

 2. As noted [here](https://github.com/tensorflow/tensorflow/issues/36840): while there aren't errors in Eager, the gradients are extremely small: `1e-9` to `1e-19`, whereas usually the same layers have `1e-6` to `1e-2`. This may or may not be a design rather than a bug problem.

<hr>

**IDE Profiler encapsulation**:

<img src=""https://user-images.githubusercontent.com/16495490/74617169-49255c80-5145-11ea-9aba-b5cca922e97c.png"" width=""550"">


"
36794,a bug about tf.function,"WARNING:tensorflow:AutoGraph could not transform <function converge_to_2 at 0x7f6e047dae50> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: invalid value for ""node"": expected ""ast.AST"", got ""<class 'NoneType'>""; to visit lists of nodes, use ""visit_block"" instead
WARNING: AutoGraph could not transform <function converge_to_2 at 0x7f6e047dae50> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: invalid value for ""node"": expected ""ast.AST"", got ""<class 'NoneType'>""; to visit lists of nodes, use ""visit_block"" instead
tf.Tensor(1.9999981, shape=(), dtype=float32)"
36793,Same input - different output,"I have written a small code, and notice that I get a different result dependent on if I use Numpy or not. 

This code should give the same result for both df_dy and df_dy_p, but it does not. It does not matter if I change the order of the calculations. 

`from math import e
import numpy as np

def calc_sigma(y):
    return 1 / (1 + e**-y)

def get_derivative(x, y):
    with tf.GradientTape(persistent=True) as tape:
        tape.watch(x)
        sigma = cal_sigma(-y)
        f = (x + sigma) / np.power((x - y), 2)
        p = (x + sigma) / ((x -y)**2)
    print(x, y, f, p)
    df_dy = tape.gradient(f, x) 
    df_dy_p = tape.gradient(p, x)
    print(df_dy)
    print(df_dy_p)

x = tf.constant (1.)
y = tf.constant (-3.)
get_derivative(x, y)`

The output is:

tf.Tensor(1.0, shape=(), dtype=float32) tf.Tensor(-3.0, shape=(), dtype=float32) tf.Tensor(0.12203588, shape=(), dtype=float32) tf.Tensor(0.12203588, shape=(), dtype=float32)
tf.Tensor(0.0625, shape=(), dtype=float32)
tf.Tensor(0.0014820583, shape=(), dtype=float32)

As one can see, the input is the same, but the output differs. "
36792,Cannot convert a symbolic Tensor (Neg_1:0) to a numpy array,"Hello.

I am trying to derive with Tensorflow, and get an error telling me to report the behavior to the TensorFlow team. Hence this post. 

My code:
```python
from math import e

def cal_sigma(y):
    return 1 / (1 + np.power(e, -y) )

@tf.function
def get_derivative(x, y):
    with tf.GradientTape(persistent=True) as tape:
        tape.watch(x)
        tape.watch(y)
        y_sigma = cal_sigma(-y)
        f = (x + y_sigma) / np.power((x -y), 2)
    df_dy = tape.gradient(f, y) 
    return df_dy

x = tf.constant (1.)
y = tf.constant (-3.)
print(get_derivative(x, y))

If I derive with respect to x (df_dy = tape.gradient(f, x) in second to last line; it works. However, with y, I get the following error:

WARNING:tensorflow:AutoGraph could not transform <method-wrapper '__call__' of numpy.ufunc object at 0x110a96950> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: Cannot convert a symbolic Tensor (Neg_1:0) to a numpy array.
WARNING: AutoGraph could not transform <method-wrapper '__call__' of numpy.ufunc object at 0x110a96950> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: Cannot convert a symbolic Tensor (Neg_1:0) to a numpy array.
---------------------------------------------------------------------------
NotImplementedError                       Traceback (most recent call last)
<ipython-input-11-a4cdc628e4ad> in <module>
      2 y = tf.constant (-3.)
      3 #print(get_derivative(x, y))
----> 4 print(get_derivative2(x, y))

/opt/anaconda3/envs/DeepLearning/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py in __call__(self, *args, **kwds)
    566         xla_context.Exit()
    567     else:
--> 568       result = self._call(*args, **kwds)
    569 
    570     if tracing_count == self._get_tracing_count():

/opt/anaconda3/envs/DeepLearning/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py in _call(self, *args, **kwds)
    604       # In this case we have not created variables on the first call. So we can
    605       # run the first trace but we should fail if variables are created.
--> 606       results = self._stateful_fn(*args, **kwds)
    607       if self._created_variables:
    608         raise ValueError(""Creating variables on a non-first call to a function""

/opt/anaconda3/envs/DeepLearning/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py in __call__(self, *args, **kwargs)
   2360     """"""Calls a graph function specialized to the inputs.""""""
   2361     with self._lock:
-> 2362       graph_function, args, kwargs = self._maybe_define_function(args, kwargs)
   2363     return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access
   2364 

/opt/anaconda3/envs/DeepLearning/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py in _maybe_define_function(self, args, kwargs)
   2701 
   2702       self._function_cache.missed.add(call_context_key)
-> 2703       graph_function = self._create_graph_function(args, kwargs)
   2704       self._function_cache.primary[cache_key] = graph_function
   2705       return graph_function, args, kwargs

/opt/anaconda3/envs/DeepLearning/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py in _create_graph_function(self, args, kwargs, override_flat_arg_shapes)
   2591             arg_names=arg_names,
   2592             override_flat_arg_shapes=override_flat_arg_shapes,
-> 2593             capture_by_value=self._capture_by_value),
   2594         self._function_attributes,
   2595         # Tell the ConcreteFunction to clean up its graph once it goes out of

/opt/anaconda3/envs/DeepLearning/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)
    976                                           converted_func)
    977 
--> 978       func_outputs = python_func(*func_args, **func_kwargs)
    979 
    980       # invariant: `func_outputs` contains only Tensors, CompositeTensors,

/opt/anaconda3/envs/DeepLearning/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py in wrapped_fn(*args, **kwds)
    437         # __wrapped__ allows AutoGraph to swap in a converted function. We give
    438         # the function a weak reference to itself to avoid a reference cycle.
--> 439         return weak_wrapped_fn().__wrapped__(*args, **kwds)
    440     weak_wrapped_fn = weakref.ref(wrapped_fn)
    441 

/opt/anaconda3/envs/DeepLearning/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py in wrapper(*args, **kwargs)
    966           except Exception as e:  # pylint:disable=broad-except
    967             if hasattr(e, ""ag_error_metadata""):
--> 968               raise e.ag_error_metadata.to_exception(e)
    969             else:
    970               raise

NotImplementedError: in converted code:

    <ipython-input-9-af8fccc461fb>:20 get_derivative2  *
        y_sigma = cal_sigma(-y)
    <ipython-input-9-af8fccc461fb>:4 cal_sigma  *
        return 1 / (1 + np.power(e, -y) )
    /opt/anaconda3/envs/DeepLearning/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:728 __array__
        "" array."".format(self.name))

    NotImplementedError: Cannot convert a symbolic Tensor (Neg_1:0) to a numpy array.
```"
36791,tflite save issue,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- TensorFlow installed from (source or binary):
- TensorFlow version (or github SHA if from source):


**Provide the text output from tflite_convert**

```
2020-02-16 21:52:52.869005: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory
2020-02-16 21:52:52.869341: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory
2020-02-16 21:52:52.869351: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
2020-02-16 21:52:55.481557: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Size
2020-02-16 21:52:55.497984: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Size
2020-02-16 21:52:55.498578: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Size
2020-02-16 21:52:55.498607: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Size
2020-02-16 21:52:55.499028: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Size
2020-02-16 21:52:55.499052: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Size
2020-02-16 21:52:55.499231: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: CombinedNonMaxSuppression
2020-02-16 21:52:55.535714: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 735 operators, 1368 arrays (0 quantized)
2020-02-16 21:52:55.561395: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 735 operators, 1368 arrays (0 quantized)
2020-02-16 21:52:56.057040: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 284 operators, 533 arrays (0 quantized)
2020-02-16 21:52:56.062129: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 2: 284 operators, 533 arrays (0 quantized)
2020-02-16 21:52:56.067209: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Group bidirectional sequence lstm/rnn: 284 operators, 533 arrays (0 quantized)
2020-02-16 21:52:56.071019: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before dequantization graph transformations: 284 operators, 533 arrays (0 quantized)
2020-02-16 21:52:56.073859: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Identify nearest upsample.: 284 operators, 533 arrays (0 quantized)
2020-02-16 21:52:56.083033: I tensorflow/lite/toco/allocate_transient_arrays.cc:345] Total transient array allocated size: 66560128 bytes, theoretical optimal value: 44408960 bytes.
2020-02-16 21:52:56.083962: I tensorflow/lite/toco/toco_tooling.cc:471] Number of parameters: 61503185
2020-02-16 21:52:56.091894: E tensorflow/lite/toco/toco_tooling.cc:498] We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md
 and pasting the following:

Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: ADD, CAST, CONCATENATION, CONV_2D, DIV, EXP, EXPAND_DIMS, FILL, LEAKY_RELU, LOGISTIC, MUL, PACK, PAD, RESHAPE, RESIZE_NEAREST_NEIGHBOR, SHAPE, SPLIT_V, STRIDED_SLICE, SUB. Here is a list of operators for which you will need custom implementations: CombinedNonMaxSuppression, Size.
Traceback (most recent call last):
  File ""/home/kji/anaconda3/envs/py37_tf/bin/toco_from_protos"", line 8, in <module>
    sys.exit(main())
  File ""/home/kji/anaconda3/envs/py37_tf/lib/python3.7/site-packages/tensorflow_core/lite/toco/python/toco_from_protos.py"", line 93, in main
    app.run(main=execute, argv=[sys.argv[0]] + unparsed)
  File ""/home/kji/anaconda3/envs/py37_tf/lib/python3.7/site-packages/tensorflow_core/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/home/kji/anaconda3/envs/py37_tf/lib/python3.7/site-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/home/kji/anaconda3/envs/py37_tf/lib/python3.7/site-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""/home/kji/anaconda3/envs/py37_tf/lib/python3.7/site-packages/tensorflow_core/lite/toco/python/toco_from_protos.py"", line 56, in execute
    enable_mlir_converter)
Exception: We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md
 and pasting the following:

Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: ADD, CAST, CONCATENATION, CONV_2D, DIV, EXP, EXPAND_DIMS, FILL, LEAKY_RELU, LOGISTIC, MUL, PACK, PAD, RESHAPE, RESIZE_NEAREST_NEIGHBOR, SHAPE, SPLIT_V, STRIDED_SLICE, SUB. Here is a list of operators for which you will need custom implementations: CombinedNonMaxSuppression, Size.```

Also, please include a link to a GraphDef or the model if possible.

**Any other info / logs**

Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

I don't know changing input size in tensorflow 2.1 tflite"
36790,tf.keras.backend.set_floatx() causing ValueError (dtype conversion error) while computing tf.keras.metrics.*,"**System information** - Have I written custom code on **Google Colab**: - 
**Code:**
```
tf.keras.backend.set_floatx('float64')

model.compile(optimizer= Adam(learning_rate= 0.001, clipnorm=1.0, clipvalue=0.5),
              loss={
                  'class_output': BinaryCrossentropy(),
                  'decoder_output': BinaryCrossentropy()
              },
              loss_weights=[0.5, 1.0],
               metrics = {
                  'class_output':[tf.metrics.Recall(), tf.metrics.Precision()],
                  'decoder_output':[tf.metrics.Recall(), tf.metrics.Precision()],
              }
             ) 
```
**Error:**
```
/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py in convert_to_tensor(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)
   1288       raise ValueError(
   1289           ""Tensor conversion requested dtype %s for Tensor with dtype %s: %r"" %
-> 1290           (dtype.name, value.dtype.name, value))
   1291     return value
   1292 

ValueError: Tensor conversion requested dtype float64 for Tensor with dtype float32: <tf.Tensor 'metrics_6/class_output_recall_8/Sum:0' shape=(1,) dtype=float32>
```

OS Platform and Distribution : - 
```
os.uname()
>>> posix.uname_result(sysname='Linux', nodename='ed841897617b', release='4.14.137+', version='#1 SMP Thu Aug 8 02:47:02 PDT 2019', machine='x86_64')
```
TensorFlow installed from : - 
```!pip install tensorflow==2.10```
TensorFlow version : - 
```
tf.__version__
>>> '2.1.0'
```
Python version: - 
```
!python -V
>>> Python 3.6.9
```
~~Bazel version :-  NA~~
~~GCC/Compiler version : - NA~~  
~~CUDA/cuDNN version: -  NA~~

GPU model and memory:
```
from psutil import virtual_memory
mem = virtual_memory()
print(mem.total / 1024**3, 'GB') # total physical memory available
>>>12.717426300048828 GB
````
~~You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`~~

**Describe the current behavior**
When using `tf.keras.backend.set_floatx('float64')` , whole tf should be set to float64, right ?
But the tf.metrics are not getting set as shown in the code above

**Describe the expected behavior**
All of tf including tf.metrics should be calculated on the basis of tf.keras.backend.set_floatx('float64')

**Code to reproduce the issue** 
```
import tensorflow as tf 

tf.keras.backend.set_floatx('float64')

m = tf.keras.metrics.Recall()
m.update_state([0, 1, 1, 1], [1, 0, 1, 1])
print('Final result: ', m.result().numpy())
```

**Other info / logs** ~~Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.~~
StackTrace:
```
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
<ipython-input-30-86f79f751766> in <module>()
      6               loss_weights=[0.5, 1.0],
      7                metrics = {
----> 8                   'class_output':[tf.metrics.Recall(), tf.metrics.Precision()],
      9                 #  'decoder_output':[tf.metrics.Recall(), tf.metrics.Precision()],
     10               }

13 frames
/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/tracking/base.py in _method_wrapper(self, *args, **kwargs)
    455     self._self_setattr_tracking = False  # pylint: disable=protected-access
    456     try:
--> 457       result = method(self, *args, **kwargs)
    458     finally:
    459       self._self_setattr_tracking = previous_value  # pylint: disable=protected-access

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py in compile(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, target_tensors, distribute, **kwargs)
    437           targets=self._targets,
    438           skip_target_masks=self._prepare_skip_target_masks(),
--> 439           masks=self._prepare_output_masks())
    440 
    441       # Prepare sample weight modes. List with the same length as model outputs.

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py in _handle_metrics(self, outputs, targets, skip_target_masks, sample_weights, masks, return_weighted_metrics, return_weighted_and_unweighted_metrics)
   2002           metric_results.extend(
   2003               self._handle_per_output_metrics(self._per_output_metrics[i],
-> 2004                                               target, output, output_mask))
   2005         if return_weighted_and_unweighted_metrics or return_weighted_metrics:
   2006           metric_results.extend(

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py in _handle_per_output_metrics(self, metrics_dict, y_true, y_pred, mask, weights)
   1953       with K.name_scope(metric_name):
   1954         metric_result = training_utils.call_metric_function(
-> 1955             metric_fn, y_true, y_pred, weights=weights, mask=mask)
   1956         metric_results.append(metric_result)
   1957     return metric_results

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_utils.py in call_metric_function(metric_fn, y_true, y_pred, weights, mask)
   1153 
   1154   if y_pred is not None:
-> 1155     return metric_fn(y_true, y_pred, sample_weight=weights)
   1156   # `Mean` metric only takes a single value.
   1157   return metric_fn(y_true, sample_weight=weights)

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/metrics.py in __call__(self, *args, **kwargs)
    194     from tensorflow.python.keras.distribute import distributed_training_utils  # pylint:disable=g-import-not-at-top
    195     return distributed_training_utils.call_replica_local_fn(
--> 196         replica_local_fn, *args, **kwargs)
    197 
    198   @property

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/distribute/distributed_training_utils.py in call_replica_local_fn(fn, *args, **kwargs)
   1133     with strategy.scope():
   1134       return strategy.extended.call_for_each_replica(fn, args, kwargs)
-> 1135   return fn(*args, **kwargs)
   1136 
   1137 

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/metrics.py in replica_local_fn(*args, **kwargs)
    177     def replica_local_fn(*args, **kwargs):
    178       """"""Updates the state of the metric in a replica-local context.""""""
--> 179       update_op = self.update_state(*args, **kwargs)  # pylint: disable=not-callable
    180       with ops.control_dependencies([update_op]):
    181         result_t = self.result()  # pylint: disable=not-callable

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/utils/metrics_utils.py in decorated(metric_obj, *args, **kwargs)
     74 
     75     with tf_utils.graph_context_for_symbolic_tensors(*args, **kwargs):
---> 76       update_op = update_state_fn(*args, **kwargs)
     77     if update_op is not None:  # update_op will be None in eager execution.
     78       metric_obj.add_update(update_op)

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/metrics.py in update_state(self, y_true, y_pred, sample_weight)
   1340         top_k=self.top_k,
   1341         class_id=self.class_id,
-> 1342         sample_weight=sample_weight)
   1343 
   1344   def result(self):

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/utils/metrics_utils.py in update_confusion_matrix_variables(variables_to_update, y_true, y_pred, thresholds, top_k, class_id, sample_weight, multi_label, label_weights)
    438       update_ops.append(
    439           weighted_assign_add(label, pred, weights_tiled,
--> 440                               variables_to_update[matrix_cond]))
    441 
    442   return control_flow_ops.group(update_ops)

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/utils/metrics_utils.py in weighted_assign_add(label, pred, weights, var)
    414     if weights is not None:
    415       label_and_pred *= weights
--> 416     return var.assign_add(math_ops.reduce_sum(label_and_pred, 1))
    417 
    418   loop_vars = {

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py in assign_add(self, delta, use_locking, name, read_value)
    783     with _handle_graph(self.handle), self._assign_dependencies():
    784       assign_add_op = gen_resource_variable_ops.assign_add_variable_op(
--> 785           self.handle, ops.convert_to_tensor(delta, dtype=self.dtype),
    786           name=name)
    787     if read_value:

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py in convert_to_tensor(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)
   1288       raise ValueError(
   1289           ""Tensor conversion requested dtype %s for Tensor with dtype %s: %r"" %
-> 1290           (dtype.name, value.dtype.name, value))
   1291     return value
   1292 

ValueError: Tensor conversion requested dtype float64 for Tensor with dtype float32: <tf.Tensor 'metrics_6/class_output_recall_8/Sum:0' shape=(1,) dtype=float32>
```
"
36789,image-utils,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Python version**:
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with:

```bash
python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""
```

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
36788,How to use tensorflow js on a nodejs server?,"Hi everyone 👨‍💻, 
I would like to use the tensorflow js plugin with cocossd and mobilenet on the server side with nodejs.
I've already done a script on the client side that works where when the user submits a form I run tfjs:
```javascript

    const img = new Image(100, 100);
    img.src = //base64 encoded image
    
    // Load the model.
    mobilenet.load().then(async model => {
        const post_predictions = []; 
        model.classify(img).then(classify_predictions => {
            classify_predictions.forEach(function(element){
                const each_class = element[""className""].split("", "")
                each_class.forEach(function(this_element){
                    post_predictions.push([this_element, (element.probability*100)]);
                })
            })
            cocoSsd.load().then(model => {
                // detect objects in the image.
                model.detect(img).then(predictions => {
                    predictions.forEach(function(this_element){
                        post_predictions.unshift([this_element.class, (this_element.score*100)]);
                    });
                    post_predictions.sort(function(a, b) {
                        return b[1]-a[1];
                    });

                    console.log(post_predictions)
                });
            })
        });
    });
```

I would like to do the same on the server side but I have node idea what modules require or how to load an image from it's base 64.

I tried to download cocossd and mobilenet on my server with:

> npm i @tensorflow-models/mobilenet

> npm i @tensorflow-models/coco-ssd

And then i tried to install tensorflow js for node with:

> npm i @tensorflow/tfjs-node

But when i do :
> npm i tensorflow

I get this error :
>npm ERR! code EBADPLATFORM

>npm ERR! notsup Unsupported platform for tensorflow@0.7.0: wanted {""os"":""linux,darwin"",""arch"":""any""} (current: {""os"":""win32"",""arch"":""x64""})

>npm ERR! notsup Valid OS:    linux,darwin

>npm ERR! notsup Valid Arch:  any

>npm ERR! notsup Actual OS:   win32

>npm ERR! notsup Actual Arch: x64


>npm ERR! A complete log of this run can be found in:

>npm ERR!     C:\Users\johan\AppData\Roaming\npm-cache\_logs\2020-02-16T05_27_15_276Z-debug.log

Pls someone help me 🙏
Thanks"
36787,  AttributeError: 'module' object has no attribute 'random_normal' ,"
AttributeError                            Traceback (most recent call last)
<ipython-input-5-73592c5fe983> in <module>()
----> 1 W=tf.Variable(initial_value=tf.random_normal(shape=(1,4),mean=100,stddev=0.35),name=""W"")
      2 b=tf.Variable(tf.zeros([4]),name=""b"")

AttributeError: 'module' object has no attribute 'random_normal'


tf has no attribute 'random_normal' ?"
36786,"Add ""See also""  references","This is sort of a follow up to #33756. The TF docs have undergone huge improvements over the last couple months. However, one thing I really like about the PyTorch docs which is still (mostly) missing in the TF docs are ""**See also**""  references.

A lot of functions have similar or related functionality. Examples include:

1. `tf.split`, `tf.unstack`
2. `tf.size`, `tf.shape`
3. `tf.repeat`, `tf.concat`, `tf.tile`, `tf.stack`
4. `tf.exp`, `tf.math.log`
5. `tf.keras.layers.MaxPool2D`, `tf.nn.max_pool2d `
6. `tf.ones`, `tf.ones_like` and `tf.zeros`, `tf.zeros_like`

just to name a few.

Often people happen to find one and start using it regularly but remain unaware of the others for quite a while. Even if I do know about all of them, I often find myself wanting to compare the signature of similar functions to find the one most suitable to the current use case. In those cases, it takes way too many clicks to get from one to the other(s).

In short, would be great if the docs referenced related content. That should help guide people to use the best tool for the job right from the start."
36785,TF 2.1/tf.keras AdaDelta optimizer: default epsilon and learning rate values,"Hi @tanzhenyu @lamberta @dynamicwebpaige There are two param default values for AdaDelta that look different from the original implementation. It is probably explained in past discussions (and if it is the case pls let me know where I can find it so we can close this issue.) Cheers.

Similar issues: https://github.com/tensorflow/tensorflow/issues/31024 and https://github.com/tensorflow/tensorflow/pull/31025.

TF 2.1 [API docs for the Adadelta optimizer](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adadelta) come from [`/optimizer-v2/`](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/optimizer_v2/adadelta.py), where: 
- The learning rate is set to 0.001:
  - Keras' implementation states that learning rate is 1.
  - [`optimizer.py`](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/optimizers.py) (v1) sets it to 1 (synced with Keras, I suppose).
  - There's a Keras PR - https://github.com/keras-team/keras/pull/12841 - that proposed to change the LR from 1 to 0.001. It may have been reverted back to 1 (see commit https://github.com/keras-team/keras/pull/12888/commits/2009cab5217a57bfbb4dae88371640ce1bb4a0e9).
- The default epsilon does not match the one in the original AdaDelta [paper](https://arxiv.org/pdf/1212.5701.pdf) as well as Keras' implementation:
  - They use `1e-6` instead of `1e-7` (`""Setting the hyperparameters to ε = 1e − 6 and ρ = 0.95...""`).

Sources: 

- [TF 2.1 /optimizer_v2/](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/optimizer_v2/adadelta.py):

```python
@keras_export('keras.optimizers.Adadelta')
class Adadelta(optimizer_v2.OptimizerV2):
  ...
  def __init__(self,
               learning_rate=0.001,
               rho=0.95,
               epsilon=1e-7,
               name='Adadelta',
               **kwargs):
```

- [TF 2.1 optimizers.py - version 1](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/optimizers.py):

```python
class Adadelta(Optimizer):
...
  def __init__(self, lr=1.0, rho=0.95, epsilon=None, decay=0., **kwargs):
...
```

- [Keras optimizers.py](https://github.com/keras-team/keras/blob/master/keras/optimizers.py):
```python
class Adadelta(Optimizer):
...
    def __init__(self, learning_rate=1.0, rho=0.95, **kwargs):
...
```

Thanks for taking your time to look at this potential issue."
36784,Allow overriding `_validate_state_spec` in RNN [Feature Request],"We are allowed to define `get_initial_state()` for initializing custom states, but not for validating them; I have a scalar hidden state, which raises an exception per `flat_state_spec[i].shape[1:]` (it assumes a 2D+ tensor). Below modification resolves it, but isn't really a workaround since it [modifies](https://github.com/tensorflow/tensorflow/blob/r2.0/tensorflow/python/keras/layers/recurrent.py#L586) the parent class for all RNNs - so TF can either include such scalar handling, or enable method overriding.

```python
# ...
for i in range(len(flat_cell_state_size)):
  state_spec_shape = flat_state_spec[i].shape
  if len(state_spec_shape) == 1 and not (tensor_shape.TensorShape(
    # Check scalar case first
    state_spec_shape[0]).is_compatible_with(
        tensor_shape.TensorShape(flat_cell_state_size[i]))):
    raise validation_error
  elif not tensor_shape.TensorShape(
    # Ignore the first axis for init_state which is for batch
    state_spec_shape[1:]).is_compatible_with(
        tensor_shape.TensorShape(flat_cell_state_size[i])):
    raise validation_error
```"
36783,"tensorflow-1.14 and tensorflow1.15, avx512f does no performance improvements than avx2","HI :
    I run a model use tensorflow-1.14 compiled with avx2, avx512f , and found that: avx512 does no performance improvements than avx2. The timeline of avx2 or avx512f were the same as below. MatMul is most expensive op.

Machine A:
avx512 CPU: Intel(R) Xeon(R) Silver 4110 CPU @ 2.10GHz
avx512 compile command: 
bazel build tensorflow:libtensorflow_cc.so -c opt --copt=-march=native --copt=-mfpmath=both  --copt=-mfma --copt=-mavx --copt=-mavx2 --copt=-mavx512f --copt=-mavx512cd --copt=-mavx512dq --copt=-mavx512bw --copt=-mavx512vl . 
gcc version: 7.3.0

Machine B:
avx2 CPU: Intel(R) Xeon(R) CPU E5-2620 v4 @ 2.10GHz
avx2 compile command:
bazel build tensorflow:libtensorflow_cc.so -c opt --copt=-march=native --copt=-mfpmath=both  --copt=-mfma --copt=-mavx --copt=-mavx2 
gcc version: 4.8.5
    
![image](https://user-images.githubusercontent.com/10751631/74588331-6d464800-5036-11ea-80dc-dd26b71e0f25.png)


"
36782,Unable to package tensorflow with Py2App,"
**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS Catalina
- TensorFlow installed from (source or binary): Binary
- TensorFlow version: 2.1.0
- Python version: 3.7
- Installed using virtualenv? pip? conda?: Yes, installed in a virtualenv using pip
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A

**Describe the problem**
On running an executable that was packaged using Py2App, the executable throws the following error: 

```
File ""/Users/harshitdwivedi/Desktop/aftershootscripts/dist/aftershoot.app/Contents/Resources/aftershoot.py"", line 4, in <module>
    import asexposure.ASExposure as Exposure
  File ""asexposure/ASExposure.pyc"", line 1, in <module>
  File ""/Users/harshitdwivedi/Desktop/aftershootscripts/dist/aftershoot.app/Contents/Resources/lib/python3.7/tensorflow/__init__.py"", line 98, in <module>
    from tensorflow_core import *
  File ""/Users/harshitdwivedi/Desktop/aftershootscripts/dist/aftershoot.app/Contents/Resources/lib/python3.7/tensorflow_core/__init__.py"", line 40, in <module>
    from tensorflow.python.tools import module_util as _module_util
ModuleNotFoundError: No module named 'tensorflow.python.tools'; 'tensorflow.python' is not a package
```
Upon looking into the line of code causing this issue, it looks like `tensorflow_core`'s `init.py` is trying to import `module_util` from `tensorflow.python.tools`. However, isnide my site-packages,  there's northing inside the package named `tensorflow`. Instead the package above `python.tools` exists inside `tensorflow_core`.

Here's a screenshot showcasing this: 

<img width=""626"" alt=""Screenshot 2020-02-15 at 6 06 56 PM"" src=""https://user-images.githubusercontent.com/47669588/74587897-20567780-501e-11ea-9ff1-91b268c2a160.png"">

As you can see here, python folder is inside tensorflow_core, but the init.py tries to refer it from tensorflow.
<img width=""817"" alt=""Screenshot 2020-02-15 at 6 07 52 PM"" src=""https://user-images.githubusercontent.com/47669588/74587901-264c5880-501e-11ea-9814-63e8d9ded432.png"">

Is this a known issue? And if so, is there a way to fix this?"
36781,Blas GEMM launch failed,"- Have I written custom code: yes
- OS Platform and Distribution: ubuntu 18.04
- TensorFlow installed from binary
- TensorFlow version: 2.1.0 (TensorFlow-GPU)
- Keras version: 2.3.1
- Python version: 3.6.8
- CUDA/cuDNN version: Cuda 10.1 / cuDNN 7.6.4
- GPU model and memory: Tesla K80 with 11441MiB Memory

**Describe the current behavior**

On an AWS p2.xlarge instance, when calling `model.fit` on a TF model with GPU support activated, the process crashes with the following error message:

```
InternalError:  Blas GEMM launch failed : a.shape=(32, 116032), b.shape=(116032, 256), m=32, n=256, k=116032
	 [[node dense_1/MatMul (defined at /home/ubuntu/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3009) ]] [Op:__inference_keras_scratch_graph_1645]

Function call stack:
keras_scratch_graph
```

**Describe the expected behavior**

When calling `model.fit`, the model would simply train normally like it does when using a CPU.

**Code to reproduce the issue**

Run a p2.xlarge instance on AWS
Install all the GPU-related requirements as per https://www.tensorflow.org/install/gpu
Create a basic Sequential model with Keras (TF backend)
Compile the model (this runs fine)
Call `model.fit` on some training data

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

Logs of the error:
```
2020-02-15 11:07:22.795814: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10770 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:1e.0, compute capability: 3.7)
2020-02-15 11:07:27.168747: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-02-15 11:07:27.169206: E tensorflow/stream_executor/cuda/cuda_blas.cc:238] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED
2020-02-15 11:07:27.169297: E tensorflow/stream_executor/cuda/cuda_blas.cc:238] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED
2020-02-15 11:07:27.169377: E tensorflow/stream_executor/cuda/cuda_blas.cc:238] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED
2020-02-15 11:07:27.170036: E tensorflow/stream_executor/cuda/cuda_blas.cc:238] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED
2020-02-15 11:07:27.170106: E tensorflow/stream_executor/cuda/cuda_blas.cc:238] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED
2020-02-15 11:07:27.170242: E tensorflow/stream_executor/cuda/cuda_blas.cc:238] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED
2020-02-15 11:07:27.170302: E tensorflow/stream_executor/cuda/cuda_blas.cc:238] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED
2020-02-15 11:07:27.170533: E tensorflow/stream_executor/cuda/cuda_blas.cc:238] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED
2020-02-15 11:07:27.170593: E tensorflow/stream_executor/cuda/cuda_blas.cc:238] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED
2020-02-15 11:07:27.180263: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-02-15 11:07:28.554099: E tensorflow/stream_executor/cuda/cuda_blas.cc:238] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED
2020-02-15 11:07:28.709952: E tensorflow/stream_executor/cuda/cuda_blas.cc:238] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED
2020-02-15 11:07:28.808561: E tensorflow/stream_executor/cuda/cuda_blas.cc:238] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED
2020-02-15 11:07:28.820285: E tensorflow/stream_executor/cuda/cuda_blas.cc:238] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED
2020-02-15 11:07:28.820399: W tensorflow/stream_executor/stream.cc:2041] attempting to perform BLAS operation using StreamExecutor without BLAS support
2020-02-15 11:07:28.820463: W tensorflow/core/common_runtime/base_collective_executor.cc:217] BaseCollectiveExecutor::StartAbort Internal: Blas GEMM launch failed : a.shape=(32, 116032), b.shape=(116032, 256), m=32, n=256, k=116032
```

This is the output of `nvidia-smi` **before** calling `model.compile()`:

```
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 430.50       Driver Version: 430.50       CUDA Version: 10.1     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  Tesla K80           Off  | 00000000:00:1E.0 Off |                    0 |
| N/A   45C    P0    74W / 149W |      0MiB / 11441MiB |    100%      Default |   <<<--- 0% Memory usage
+-------------------------------+----------------------+----------------------+

+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|  No running processes found                                                 |   <<<--- nothing running
+-----------------------------------------------------------------------------+
```

And the output of `nvidia-smi` **after** calling `model.compile()` (and immediately before `model.fit()`):

```
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 430.50       Driver Version: 430.50       CUDA Version: 10.1     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  Tesla K80           Off  | 00000000:00:1E.0 Off |                    0 |
| N/A   45C    P0    72W / 149W |  10942MiB / 11441MiB |      0%      Default |   <<<--- 96% Memory usage
+-------------------------------+----------------------+----------------------+

+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|    0      1811      C   /usr/bin/python3                           10929MiB |   <<<--- TF model here
+-----------------------------------------------------------------------------+
```"
36780,GPU ran out of memory when run training,"<em>
from imageai.Detection.Custom import DetectionModelTrainer
trainer = DetectionModelTrainer()
trainer.setModelTypeAsYOLOv3()
trainer.setDataDirectory(data_directory=""dataset"")
trainer.setTrainConfig(object_names_array=[""bottle"", ""plastic""], batch_size=4, num_experiments=100, train_from_pretrained_model=""pretrained-yolov3.h5"")
trainer.trainModel()
</em>

**System information**
- OS Platform and Distribution Window 10 Pro 64bit
- TensorFlow installed from (source or binary): 
pip3 install tensorflow==1.15      # CPU
pip3 install tensorflow-gpu==1.15  # GPU
- TensorFlow version: 1.15
- Python version: 3.6.0
- Installed using pip3 
- Bazel version (if compiling from source): none
- GCC/Compiler version (if compiling from source): none
- CUDA/cuDNN version: 10.0/ 7.6.4.38
- GPU model and memory: NVIDIA GTX 1060 6gb

Problem:
After I set the code for running the Train Object Detection AI with pre-trained YOLOv3 model, i ran out with this error:  

2020-02-15 17:58:40.777296: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079B0C1800 next 2814 of size 256
2020-02-15 17:58:40.780241: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079B0C1900 next 678 of size 512
2020-02-15 17:58:40.782580: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079B0C1B00 next 2205 of size 4718592
2020-02-15 17:58:40.785012: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079B541B00 next 1697 of size 256
2020-02-15 17:58:40.787373: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079B541C00 next 1556 of size 256
2020-02-15 17:58:40.790582: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079B541D00 next 2196 of size 256
2020-02-15 17:58:40.793020: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079B541E00 next 2383 of size 256
2020-02-15 17:58:40.795391: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079B541F00 next 2190 of size 256
2020-02-15 17:58:40.798532: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079B542000 next 1369 of size 1179648
2020-02-15 17:58:40.801057: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079B662000 next 809 of size 256
2020-02-15 17:58:40.803499: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079B662100 next 1642 of size 256
2020-02-15 17:58:40.806536: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079B662200 next 2930 of size 256
2020-02-15 17:58:40.808913: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079B662300 next 878 of size 256
2020-02-15 17:58:40.811696: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079B662400 next 1558 of size 256
2020-02-15 17:58:40.814127: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079B662500 next 1954 of size 256
2020-02-15 17:58:40.817189: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079B662600 next 1943 of size 256
2020-02-15 17:58:40.819655: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079B662700 next 1672 of size 1024
2020-02-15 17:58:40.822389: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079B662B00 next 1521 of size 4718592
2020-02-15 17:58:40.825378: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079BAE2B00 next 1588 of size 256
2020-02-15 17:58:40.827745: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079BAE2C00 next 1907 of size 256
2020-02-15 17:58:40.830129: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079BAE2D00 next 417 of size 512
2020-02-15 17:58:40.832533: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079BAE2F00 next 1830 of size 1179648
2020-02-15 17:58:40.835571: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079BC02F00 next 1758 of size 256
2020-02-15 17:58:40.837951: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079BC03000 next 1594 of size 256
2020-02-15 17:58:40.840512: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079BC03100 next 1666 of size 256
2020-02-15 17:58:40.843507: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079BC03200 next 660 of size 2048
2020-02-15 17:58:40.845865: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079BC03A00 next 1300 of size 1024
2020-02-15 17:58:40.848297: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079BC03E00 next 2656 of size 256
2020-02-15 17:58:40.850647: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079BC03F00 next 1076 of size 294912
2020-02-15 17:58:40.853831: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079BC4BF00 next 2117 of size 32768
2020-02-15 17:58:40.856371: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079BC53F00 next 397 of size 294912
2020-02-15 17:58:40.858778: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079BC9BF00 next 2031 of size 1024
2020-02-15 17:58:40.861655: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079BC9C300 next 3033 of size 524288
2020-02-15 17:58:40.864087: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079BD1C300 next 2131 of size 256
2020-02-15 17:58:40.866517: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079BD1C400 next 1153 of size 1024
2020-02-15 17:58:40.868924: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079BD1C800 next 2046 of size 4096
2020-02-15 17:58:40.872127: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079BD1D800 next 1257 of size 4096
2020-02-15 17:58:40.874570: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079BD1E800 next 2437 of size 256
2020-02-15 17:58:40.876956: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079BD1E900 next 1338 of size 4096
2020-02-15 17:58:40.880136: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079BD1F900 next 2366 of size 524288
2020-02-15 17:58:40.882579: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079BD9F900 next 2002 of size 256
2020-02-15 17:58:40.884978: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079BD9FA00 next 1843 of size 256
2020-02-15 17:58:40.887920: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079BD9FB00 next 1676 of size 1024
2020-02-15 17:58:40.890800: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079BD9FF00 next 2630 of size 2048
2020-02-15 17:58:40.893214: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079BDA0700 next 1410 of size 256
2020-02-15 17:58:40.895593: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079BDA0800 next 3238 of size 256
2020-02-15 17:58:40.898808: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079BDA0900 next 610 of size 256
2020-02-15 17:58:40.901215: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079BDA0A00 next 493 of size 1179648
2020-02-15 17:58:40.903636: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079BEC0A00 next 2618 of size 256
2020-02-15 17:58:40.906728: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079BEC0B00 next 2224 of size 256
2020-02-15 17:58:40.909136: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079BEC0C00 next 2275 of size 512
2020-02-15 17:58:40.911535: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079BEC0E00 next 2534 of size 256
2020-02-15 17:58:40.913780: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079BEC0F00 next 1557 of size 2048
2020-02-15 17:58:40.917027: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079BEC1700 next 2737 of size 256
2020-02-15 17:58:40.919477: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079BEC1800 next 2972 of size 256
2020-02-15 17:58:40.921979: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079BEC1900 next 3166 of size 2048
2020-02-15 17:58:40.924925: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079BEC2100 next 2625 of size 131072
2020-02-15 17:58:40.927463: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079BEE2100 next 775 of size 256
2020-02-15 17:58:40.929845: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079BEE2200 next 3153 of size 256
2020-02-15 17:58:40.932791: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079BEE2300 next 3043 of size 256
2020-02-15 17:58:40.935236: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079BEE2400 next 2032 of size 786432
2020-02-15 17:58:40.938012: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079BFA2400 next 1761 of size 2048
2020-02-15 17:58:40.940588: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079BFA2C00 next 2285 of size 256
2020-02-15 17:58:40.943803: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079BFA2D00 next 914 of size 256
2020-02-15 17:58:40.946200: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079BFA2E00 next 1162 of size 131072
2020-02-15 17:58:40.948620: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079BFC2E00 next 1386 of size 1024
2020-02-15 17:58:40.951614: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079BFC3200 next 2160 of size 2048
2020-02-15 17:58:40.954028: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079BFC3A00 next 1553 of size 256
2020-02-15 17:58:40.956652: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079BFC3B00 next 1069 of size 32768
2020-02-15 17:58:40.959735: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079BFCBB00 next 1831 of size 256
2020-02-15 17:58:40.962109: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079BFCBC00 next 1460 of size 256
2020-02-15 17:58:40.964488: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079BFCBD00 next 593 of size 1024
2020-02-15 17:58:40.966847: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079BFCC100 next 3182 of size 256
2020-02-15 17:58:40.969843: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079BFCC200 next 2262 of size 2097152
2020-02-15 17:58:40.972330: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079C1CC200 next 1199 of size 256
2020-02-15 17:58:40.974758: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079C1CC300 next 724 of size 256
2020-02-15 17:58:40.977834: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079C1CC400 next 1524 of size 256
2020-02-15 17:58:40.980250: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079C1CC500 next 1395 of size 1024
2020-02-15 17:58:40.982642: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079C1CC900 next 923 of size 256
2020-02-15 17:58:40.984972: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079C1CCA00 next 481 of size 256
2020-02-15 17:58:40.987981: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079C1CCB00 next 2112 of size 4718592
2020-02-15 17:58:40.990616: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079C64CB00 next 2870 of size 256
2020-02-15 17:58:40.992968: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079C64CC00 next 2704 of size 18874368
2020-02-15 17:58:40.996329: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079D84CC00 next 2333 of size 256
2020-02-15 17:58:40.998776: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079D84CD00 next 1368 of size 256
2020-02-15 17:58:41.001143: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079D84CE00 next 1835 of size 4718592
2020-02-15 17:58:41.003596: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079DCCCE00 next 3272 of size 2048
2020-02-15 17:58:41.006686: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079DCCD600 next 3026 of size 256
2020-02-15 17:58:41.009001: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079DCCD700 next 2483 of size 524288
2020-02-15 17:58:41.011411: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079DD4D700 next 1259 of size 2048
2020-02-15 17:58:41.014383: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079DD4DF00 next 1530 of size 256
2020-02-15 17:58:41.016763: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079DD4E000 next 2089 of size 256
2020-02-15 17:58:41.019121: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079DD4E100 next 2655 of size 2048
2020-02-15 17:58:41.021508: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079DD4E900 next 1337 of size 4096
2020-02-15 17:58:41.024727: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079DD4F900 next 2173 of size 1179648
2020-02-15 17:58:41.027171: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079DE6F900 next 2593 of size 256
2020-02-15 17:58:41.029614: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079DE6FA00 next 1310 of size 256
2020-02-15 17:58:41.032548: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079DE6FB00 next 1832 of size 256
2020-02-15 17:58:41.035066: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079DE6FC00 next 1185 of size 4718592
2020-02-15 17:58:41.038111: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079E2EFC00 next 3209 of size 256
2020-02-15 17:58:41.041349: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079E2EFD00 next 706 of size 256
2020-02-15 17:58:41.043756: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079E2EFE00 next 596 of size 1024
2020-02-15 17:58:41.046180: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079E2F0200 next 2671 of size 524288
2020-02-15 17:58:41.048597: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079E370200 next 2706 of size 256
2020-02-15 17:58:41.051761: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079E370300 next 732 of size 256
2020-02-15 17:58:41.054156: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079E370400 next 950 of size 256
2020-02-15 17:58:41.056652: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079E370500 next 3163 of size 256
2020-02-15 17:58:41.059514: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079E370600 next 2668 of size 2048
2020-02-15 17:58:41.062021: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079E370E00 next 2047 of size 256
2020-02-15 17:58:41.064415: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079E370F00 next 462 of size 256
2020-02-15 17:58:41.066813: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079E371000 next 2494 of size 1024
2020-02-15 17:58:41.070152: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079E371400 next 1841 of size 256
2020-02-15 17:58:41.072626: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079E371500 next 2080 of size 256
2020-02-15 17:58:41.075187: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079E371600 next 999 of size 4096
2020-02-15 17:58:41.078354: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079E372600 next 2983 of size 256
2020-02-15 17:58:41.080727: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079E372700 next 2922 of size 2048
2020-02-15 17:58:41.083190: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079E372F00 next 1863 of size 256
2020-02-15 17:58:41.086185: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079E373000 next 2359 of size 512
2020-02-15 17:58:41.088645: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079E373200 next 1555 of size 256
2020-02-15 17:58:41.091062: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079E373300 next 3260 of size 1024
2020-02-15 17:58:41.093460: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079E373700 next 1679 of size 256
2020-02-15 17:58:41.096540: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079E373800 next 2248 of size 256
2020-02-15 17:58:41.098937: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079E373900 next 2026 of size 256
2020-02-15 17:58:41.101410: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079E373A00 next 2178 of size 18874368
2020-02-15 17:58:41.104438: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079F573A00 next 719 of size 1024
2020-02-15 17:58:41.106953: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079F573E00 next 3251 of size 1024
2020-02-15 17:58:41.109370: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079F574200 next 1465 of size 1024
2020-02-15 17:58:41.111759: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079F574600 next 2182 of size 1024
2020-02-15 17:58:41.114917: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079F574A00 next 2308 of size 256
2020-02-15 17:58:41.117627: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079F574B00 next 2007 of size 131072
2020-02-15 17:58:41.120103: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079F594B00 next 561 of size 1024
2020-02-15 17:58:41.123939: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079F594F00 next 2008 of size 256
2020-02-15 17:58:41.126341: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079F595000 next 3034 of size 2048
2020-02-15 17:58:41.128774: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079F595800 next 1354 of size 1024
2020-02-15 17:58:41.131750: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079F595C00 next 489 of size 512
2020-02-15 17:58:41.134168: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079F595E00 next 2811 of size 512
2020-02-15 17:58:41.136566: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079F596000 next 664 of size 256
2020-02-15 17:58:41.138991: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079F596100 next 2059 of size 1179648
2020-02-15 17:58:41.141980: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079F6B6100 next 2228 of size 256
2020-02-15 17:58:41.144370: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079F6B6200 next 3064 of size 4718592
2020-02-15 17:58:41.146829: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FB36200 next 1085 of size 256
2020-02-15 17:58:41.149925: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FB36300 next 2066 of size 524288
2020-02-15 17:58:41.152418: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FBB6300 next 2113 of size 256
2020-02-15 17:58:41.154847: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FBB6400 next 1277 of size 256
2020-02-15 17:58:41.157369: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FBB6500 next 2976 of size 256
2020-02-15 17:58:41.160431: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FBB6600 next 1688 of size 256
2020-02-15 17:58:41.162912: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FBB6700 next 2702 of size 73728
2020-02-15 17:58:41.165495: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FBC8700 next 1219 of size 256
2020-02-15 17:58:41.168809: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FBC8800 next 699 of size 256
2020-02-15 17:58:41.171469: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FBC8900 next 1389 of size 256
2020-02-15 17:58:41.174371: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FBC8A00 next 2586 of size 73728
2020-02-15 17:58:41.177705: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FBDAA00 next 752 of size 256
2020-02-15 17:58:41.180396: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FBDAB00 next 1165 of size 256
2020-02-15 17:58:41.182959: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FBDAC00 next 3020 of size 3584
2020-02-15 17:58:41.186178: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FBDBA00 next 2548 of size 256
2020-02-15 17:58:41.189193: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FBDBB00 next 1735 of size 256
2020-02-15 17:58:41.191923: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FBDBC00 next 1159 of size 256
2020-02-15 17:58:41.195381: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FBDBD00 next 680 of size 256
2020-02-15 17:58:41.197971: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FBDBE00 next 648 of size 256
2020-02-15 17:58:41.200653: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FBDBF00 next 2529 of size 256
2020-02-15 17:58:41.203891: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FBDC000 next 1273 of size 256
2020-02-15 17:58:41.206874: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FBDC100 next 3058 of size 256
2020-02-15 17:58:41.209513: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FBDC200 next 1770 of size 512
2020-02-15 17:58:41.213017: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FBDC400 next 2194 of size 256
2020-02-15 17:58:41.215632: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FBDC500 next 3095 of size 256
2020-02-15 17:58:41.218356: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FBDC600 next 1904 of size 256
2020-02-15 17:58:41.220851: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FBDC700 next 590 of size 256
2020-02-15 17:58:41.224289: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FBDC800 next 727 of size 256
2020-02-15 17:58:41.226964: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FBDC900 next 2871 of size 256
2020-02-15 17:58:41.229544: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FBDCA00 next 3218 of size 256
2020-02-15 17:58:41.232704: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FBDCB00 next 2227 of size 256
2020-02-15 17:58:41.235329: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FBDCC00 next 3177 of size 256
2020-02-15 17:58:41.237926: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FBDCD00 next 2867 of size 256
2020-02-15 17:58:41.241441: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FBDCE00 next 2799 of size 256
2020-02-15 17:58:41.244158: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FBDCF00 next 3028 of size 256
2020-02-15 17:58:41.246775: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FBDD000 next 1909 of size 256
2020-02-15 17:58:41.250085: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FBDD100 next 945 of size 294912
2020-02-15 17:58:41.252655: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FC25100 next 1009 of size 256
2020-02-15 17:58:41.255448: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FC25200 next 3111 of size 512
2020-02-15 17:58:41.258604: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FC25400 next 2824 of size 256
2020-02-15 17:58:41.261063: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FC25500 next 2456 of size 1179648
2020-02-15 17:58:41.263586: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FD45500 next 971 of size 512
2020-02-15 17:58:41.266049: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FD45700 next 2061 of size 256
2020-02-15 17:58:41.269139: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FD45800 next 2081 of size 32768
2020-02-15 17:58:41.271671: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FD4D800 next 1781 of size 256
2020-02-15 17:58:41.274198: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FD4D900 next 938 of size 256
2020-02-15 17:58:41.277204: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FD4DA00 next 2035 of size 256
2020-02-15 17:58:41.279583: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FD4DB00 next 870 of size 1024
2020-02-15 17:58:41.282031: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FD4DF00 next 3050 of size 256
2020-02-15 17:58:41.284972: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FD4E000 next 1322 of size 256
2020-02-15 17:58:41.287366: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FD4E100 next 1515 of size 1024
2020-02-15 17:58:41.289957: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FD4E500 next 1974 of size 256
2020-02-15 17:58:41.292400: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FD4E600 next 2401 of size 512
2020-02-15 17:58:41.295368: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FD4E800 next 2553 of size 256
2020-02-15 17:58:41.297768: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FD4E900 next 405 of size 256
2020-02-15 17:58:41.300128: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FD4EA00 next 1802 of size 256
2020-02-15 17:58:41.303077: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FD4EB00 next 1026 of size 512
2020-02-15 17:58:41.305517: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FD4ED00 next 1139 of size 256
2020-02-15 17:58:41.307917: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FD4EE00 next 3037 of size 1024
2020-02-15 17:58:41.310338: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FD4F200 next 2314 of size 512
2020-02-15 17:58:41.313322: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FD4F400 next 2344 of size 256
2020-02-15 17:58:41.315689: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FD4F500 next 1380 of size 256
2020-02-15 17:58:41.318074: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FD4F600 next 820 of size 1024
2020-02-15 17:58:41.321098: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FD4FA00 next 1101 of size 256
2020-02-15 17:58:41.323551: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FD4FB00 next 3036 of size 256
2020-02-15 17:58:41.325924: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FD4FC00 next 738 of size 512
2020-02-15 17:58:41.328267: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FD4FE00 next 2188 of size 256
2020-02-15 17:58:41.331362: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FD4FF00 next 2317 of size 256
2020-02-15 17:58:41.333726: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FD50000 next 1454 of size 131072
2020-02-15 17:58:41.336396: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FD70000 next 1187 of size 256
2020-02-15 17:58:41.339585: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FD70100 next 2360 of size 256
2020-02-15 17:58:41.341949: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FD70200 next 1093 of size 1024
2020-02-15 17:58:41.344371: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FD70600 next 1918 of size 256
2020-02-15 17:58:41.346847: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FD70700 next 609 of size 256
2020-02-15 17:58:41.350104: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FD70800 next 1889 of size 256
2020-02-15 17:58:41.352521: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FD70900 next 3059 of size 1024
2020-02-15 17:58:41.354921: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FD70D00 next 2820 of size 256
2020-02-15 17:58:41.357943: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FD70E00 next 3027 of size 1179648
2020-02-15 17:58:41.360483: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FE90E00 next 1467 of size 256
2020-02-15 17:58:41.363124: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FE90F00 next 3156 of size 512
2020-02-15 17:58:41.366368: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FE91100 next 1271 of size 256
2020-02-15 17:58:41.368933: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FE91200 next 1693 of size 256
2020-02-15 17:58:41.371463: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FE91300 next 1374 of size 256
2020-02-15 17:58:41.374963: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FE91400 next 1412 of size 1024
2020-02-15 17:58:41.377657: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FE91800 next 414 of size 256
2020-02-15 17:58:41.380364: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FE91900 next 1752 of size 256
2020-02-15 17:58:41.382835: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FE91A00 next 1926 of size 512
2020-02-15 17:58:41.386326: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FE91C00 next 3085 of size 2048
2020-02-15 17:58:41.389358: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FE92400 next 594 of size 256
2020-02-15 17:58:41.392043: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FE92500 next 750 of size 256
2020-02-15 17:58:41.395505: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FE92600 next 2982 of size 524288
2020-02-15 17:58:41.398441: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FF12600 next 1713 of size 256
2020-02-15 17:58:41.402286: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FF12700 next 2629 of size 256
2020-02-15 17:58:41.405092: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FF12800 next 1075 of size 1024
2020-02-15 17:58:41.407996: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FF12C00 next 482 of size 131072
2020-02-15 17:58:41.411444: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FF32C00 next 1240 of size 256
2020-02-15 17:58:41.414124: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FF32D00 next 1849 of size 256
2020-02-15 17:58:41.416909: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FF32E00 next 2782 of size 256
2020-02-15 17:58:41.420152: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000079FF32F00 next 1724 of size 1179648
2020-02-15 17:58:41.422957: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A0052F00 next 2628 of size 256
2020-02-15 17:58:41.425675: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A0053000 next 2463 of size 1179648
2020-02-15 17:58:41.428891: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A0173000 next 1919 of size 256
2020-02-15 17:58:41.431488: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A0173100 next 961 of size 2097152
2020-02-15 17:58:41.433938: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A0373100 next 2743 of size 256
2020-02-15 17:58:41.436452: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A0373200 next 1945 of size 256
2020-02-15 17:58:41.439669: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A0373300 next 615 of size 256
2020-02-15 17:58:41.442032: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A0373400 next 2454 of size 256
2020-02-15 17:58:41.444608: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A0373500 next 2779 of size 131072
2020-02-15 17:58:41.447620: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A0393500 next 1111 of size 256
2020-02-15 17:58:41.449985: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A0393600 next 1577 of size 512
2020-02-15 17:58:41.452369: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A0393800 next 3267 of size 131072
2020-02-15 17:58:41.454884: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A03B3800 next 1237 of size 2048
2020-02-15 17:58:41.457894: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A03B4000 next 2135 of size 256
2020-02-15 17:58:41.460374: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A03B4100 next 1870 of size 1024
2020-02-15 17:58:41.462765: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A03B4500 next 2599 of size 256
2020-02-15 17:58:41.465603: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A03B4600 next 2622 of size 1024
2020-02-15 17:58:41.468001: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A03B4A00 next 2550 of size 256
2020-02-15 17:58:41.470397: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A03B4B00 next 2807 of size 2048
2020-02-15 17:58:41.473079: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A03B5300 next 3071 of size 1024
2020-02-15 17:58:41.476163: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A03B5700 next 2685 of size 256
2020-02-15 17:58:41.478531: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A03B5800 next 1227 of size 1024
2020-02-15 17:58:41.480998: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A03B5C00 next 3216 of size 256
2020-02-15 17:58:41.484022: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A03B5D00 next 1071 of size 2048
2020-02-15 17:58:41.486416: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A03B6500 next 1838 of size 256
2020-02-15 17:58:41.488862: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A03B6600 next 2609 of size 256
2020-02-15 17:58:41.491821: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A03B6700 next 2521 of size 256
2020-02-15 17:58:41.494470: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A03B6800 next 2395 of size 256
2020-02-15 17:58:41.496856: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A03B6900 next 3002 of size 524288
2020-02-15 17:58:41.499487: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A0436900 next 2511 of size 1377280
2020-02-15 17:58:41.502460: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A0586D00 next 2144 of size 1024
2020-02-15 17:58:41.504995: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A0587100 next 2818 of size 4096
2020-02-15 17:58:41.507542: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A0588100 next 2619 of size 43008
2020-02-15 17:58:41.510509: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A0592900 next 918 of size 524288
2020-02-15 17:58:41.512958: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A0612900 next 785 of size 256
2020-02-15 17:58:41.515443: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A0612A00 next 921 of size 1024
2020-02-15 17:58:41.517795: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A0612E00 next 1379 of size 1024
2020-02-15 17:58:41.520913: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A0613200 next 2688 of size 256
2020-02-15 17:58:41.523625: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A0613300 next 1478 of size 256
2020-02-15 17:58:41.526149: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A0613400 next 1630 of size 256
2020-02-15 17:58:41.529156: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A0613500 next 2107 of size 512
2020-02-15 17:58:41.531725: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A0613700 next 2279 of size 1024
2020-02-15 17:58:41.534113: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A0613B00 next 740 of size 256
2020-02-15 17:58:41.537141: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A0613C00 next 1598 of size 256
2020-02-15 17:58:41.539785: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A0613D00 next 2270 of size 4718592
2020-02-15 17:58:41.542341: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A0A93D00 next 2162 of size 256
2020-02-15 17:58:41.544874: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A0A93E00 next 3233 of size 256
2020-02-15 17:58:41.547897: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A0A93F00 next 2109 of size 256
2020-02-15 17:58:41.550328: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A0A94000 next 534 of size 786432
2020-02-15 17:58:41.552727: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A0B54000 next 1791 of size 256
2020-02-15 17:58:41.555755: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A0B54100 next 1365 of size 1024
2020-02-15 17:58:41.558350: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A0B54500 next 1981 of size 256
2020-02-15 17:58:41.560941: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A0B54600 next 479 of size 4718592
2020-02-15 17:58:41.564039: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A0FD4600 next 2882 of size 524288
2020-02-15 17:58:41.566555: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A1054600 next 1779 of size 256
2020-02-15 17:58:41.569031: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A1054700 next 2496 of size 256
2020-02-15 17:58:41.571624: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A1054800 next 1003 of size 1024
2020-02-15 17:58:41.574794: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A1054C00 next 691 of size 256
2020-02-15 17:58:41.577270: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A1054D00 next 1661 of size 256
2020-02-15 17:58:41.579716: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A1054E00 next 2195 of size 256
2020-02-15 17:58:41.582670: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A1054F00 next 2883 of size 256
2020-02-15 17:58:41.585259: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A1055000 next 2017 of size 256
2020-02-15 17:58:41.587770: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A1055100 next 3128 of size 256
2020-02-15 17:58:41.591226: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A1055200 next 925 of size 2048
2020-02-15 17:58:41.593734: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A1055A00 next 2889 of size 1024
2020-02-15 17:58:41.596226: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A1055E00 next 2716 of size 256
2020-02-15 17:58:41.598621: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A1055F00 next 1854 of size 256
2020-02-15 17:58:41.601824: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A1056000 next 544 of size 1179648
2020-02-15 17:58:41.604294: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A1176000 next 2970 of size 512
2020-02-15 17:58:41.606820: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A1176200 next 484 of size 1024
2020-02-15 17:58:41.609950: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A1176600 next 2207 of size 4718592
2020-02-15 17:58:41.612454: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A15F6600 next 1350 of size 256
2020-02-15 17:58:41.614837: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A15F6700 next 2155 of size 2048
2020-02-15 17:58:41.618093: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A15F6F00 next 1751 of size 1024
2020-02-15 17:58:41.620497: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A15F7300 next 1820 of size 256
2020-02-15 17:58:41.623352: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A15F7400 next 3199 of size 256
2020-02-15 17:58:41.625727: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A15F7500 next 2969 of size 256
2020-02-15 17:58:41.628934: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A15F7600 next 1766 of size 1179648
2020-02-15 17:58:41.631486: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A1717600 next 1429 of size 256
2020-02-15 17:58:41.633950: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A1717700 next 948 of size 256
2020-02-15 17:58:41.636862: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A1717800 next 1956 of size 512
2020-02-15 17:58:41.639400: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A1717A00 next 1241 of size 256
2020-02-15 17:58:41.641784: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A1717B00 next 2924 of size 2048
2020-02-15 17:58:41.644711: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A1718300 next 629 of size 256
2020-02-15 17:58:41.647082: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A1718400 next 818 of size 256
2020-02-15 17:58:41.649497: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A1718500 next 1827 of size 256
2020-02-15 17:58:41.651907: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A1718600 next 2686 of size 524288
2020-02-15 17:58:41.654909: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A1798600 next 851 of size 256
2020-02-15 17:58:41.657330: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A1798700 next 1916 of size 256
2020-02-15 17:58:41.659713: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A1798800 next 2715 of size 1024
2020-02-15 17:58:41.662162: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A1798C00 next 1547 of size 256
2020-02-15 17:58:41.665208: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A1798D00 next 1415 of size 512
2020-02-15 17:58:41.667581: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A1798F00 next 3155 of size 131072
2020-02-15 17:58:41.669997: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A17B8F00 next 2507 of size 256
2020-02-15 17:58:41.672967: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A17B9000 next 839 of size 256
2020-02-15 17:58:41.675352: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A17B9100 next 676 of size 256
2020-02-15 17:58:41.678303: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A17B9200 next 1614 of size 256
2020-02-15 17:58:41.681599: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A17B9300 next 620 of size 2048
2020-02-15 17:58:41.684149: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A17B9B00 next 1635 of size 256
2020-02-15 17:58:41.686545: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A17B9C00 next 2219 of size 1024
2020-02-15 17:58:41.689022: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A17BA000 next 1109 of size 1179648
2020-02-15 17:58:41.692317: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A18DA000 next 3086 of size 256
2020-02-15 17:58:41.694788: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A18DA100 next 1320 of size 1024
2020-02-15 17:58:41.697189: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A18DA500 next 623 of size 256
2020-02-15 17:58:41.700086: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A18DA600 next 1569 of size 1024
2020-02-15 17:58:41.702512: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A18DAA00 next 3249 of size 1024
2020-02-15 17:58:41.704916: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A18DAE00 next 662 of size 256
2020-02-15 17:58:41.707876: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A18DAF00 next 1683 of size 4096
2020-02-15 17:58:41.710311: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A18DBF00 next 549 of size 2048
2020-02-15 17:58:41.712727: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A18DC700 next 1382 of size 256
2020-02-15 17:58:41.715100: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A18DC800 next 996 of size 256
2020-02-15 17:58:41.718035: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A18DC900 next 2051 of size 256
2020-02-15 17:58:41.720469: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A18DCA00 next 1675 of size 256
2020-02-15 17:58:41.722968: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A18DCB00 next 1252 of size 294912
2020-02-15 17:58:41.726110: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A1924B00 next 588 of size 512
2020-02-15 17:58:41.728527: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A1924D00 next 1012 of size 131072
2020-02-15 17:58:41.730972: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A1944D00 next 1488 of size 256
2020-02-15 17:58:41.733337: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A1944E00 next 1759 of size 512
2020-02-15 17:58:41.736365: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A1945000 next 1179 of size 524288
2020-02-15 17:58:41.738839: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19C5000 next 1928 of size 256
2020-02-15 17:58:41.741254: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19C5100 next 886 of size 256
2020-02-15 17:58:41.744203: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19C5200 next 641 of size 256
2020-02-15 17:58:41.746888: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19C5300 next 1006 of size 4096
2020-02-15 17:58:41.749305: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19C6300 next 958 of size 256
2020-02-15 17:58:41.751700: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19C6400 next 634 of size 256
2020-02-15 17:58:41.754738: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19C6500 next 475 of size 256
2020-02-15 17:58:41.757226: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19C6600 next 2062 of size 256
2020-02-15 17:58:41.759614: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19C6700 next 1148 of size 1024
2020-02-15 17:58:41.762565: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19C6B00 next 3240 of size 512
2020-02-15 17:58:41.764940: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19C6D00 next 2965 of size 512
2020-02-15 17:58:41.767310: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19C6F00 next 418 of size 256
2020-02-15 17:58:41.769658: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19C7000 next 1013 of size 256
2020-02-15 17:58:41.772774: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19C7100 next 2862 of size 4096
2020-02-15 17:58:41.775225: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19C8100 next 2399 of size 256
2020-02-15 17:58:41.777591: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19C8200 next 1542 of size 256
2020-02-15 17:58:41.780452: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19C8300 next 559 of size 2048
2020-02-15 17:58:41.782830: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19C8B00 next 2064 of size 4096
2020-02-15 17:58:41.785213: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19C9B00 next 1653 of size 2048
2020-02-15 17:58:41.787597: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19CA300 next 2611 of size 4096
2020-02-15 17:58:41.790689: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19CB300 next 1508 of size 1024
2020-02-15 17:58:41.793214: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19CB700 next 1411 of size 256
2020-02-15 17:58:41.795793: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19CB800 next 1383 of size 256
2020-02-15 17:58:41.798899: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19CB900 next 1497 of size 2048
2020-02-15 17:58:41.801281: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19CC100 next 1164 of size 256
2020-02-15 17:58:41.803699: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19CC200 next 3187 of size 1024
2020-02-15 17:58:41.806942: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19CC600 next 1266 of size 256
2020-02-15 17:58:41.809355: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19CC700 next 506 of size 256
2020-02-15 17:58:41.811706: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19CC800 next 3217 of size 256
2020-02-15 17:58:41.814178: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19CC900 next 1592 of size 256
2020-02-15 17:58:41.817066: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19CCA00 next 700 of size 2048
2020-02-15 17:58:41.819557: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19CD200 next 2410 of size 4096
2020-02-15 17:58:41.822007: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19CE200 next 2216 of size 256
2020-02-15 17:58:41.824908: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19CE300 next 3200 of size 256
2020-02-15 17:58:41.827313: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19CE400 next 710 of size 256
2020-02-15 17:58:41.829722: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19CE500 next 2264 of size 256
2020-02-15 17:58:41.832303: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19CE600 next 933 of size 256
2020-02-15 17:58:41.835313: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19CE700 next 1701 of size 256
2020-02-15 17:58:41.837740: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19CE800 next 2088 of size 2048
2020-02-15 17:58:41.840374: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19CF000 next 1192 of size 1024
2020-02-15 17:58:41.843569: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19CF400 next 2283 of size 256
2020-02-15 17:58:41.846126: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19CF500 next 960 of size 256
2020-02-15 17:58:41.848652: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19CF600 next 1025 of size 1024
2020-02-15 17:58:41.851968: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19CFA00 next 1527 of size 256
2020-02-15 17:58:41.855046: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19CFB00 next 2859 of size 256
2020-02-15 17:58:41.857760: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19CFC00 next 3270 of size 256
2020-02-15 17:58:41.861059: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19CFD00 next 1721 of size 4096
2020-02-15 17:58:41.863663: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19D0D00 next 2339 of size 2048
2020-02-15 17:58:41.866406: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19D1500 next 698 of size 256
2020-02-15 17:58:41.869176: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19D1600 next 1986 of size 2048
2020-02-15 17:58:41.873329: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19D1E00 next 1110 of size 256
2020-02-15 17:58:41.876011: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19D1F00 next 1804 of size 256
2020-02-15 17:58:41.879428: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19D2000 next 613 of size 256
2020-02-15 17:58:41.882171: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19D2100 next 2528 of size 256
2020-02-15 17:58:41.884814: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19D2200 next 3164 of size 512
2020-02-15 17:58:41.888455: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19D2400 next 389 of size 256
2020-02-15 17:58:41.891657: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19D2500 next 2723 of size 256
2020-02-15 17:58:41.894443: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19D2600 next 2263 of size 2048
2020-02-15 17:58:41.897994: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19D2E00 next 2640 of size 256
2020-02-15 17:58:41.900719: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19D2F00 next 421 of size 256
2020-02-15 17:58:41.903495: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19D3000 next 3099 of size 256
2020-02-15 17:58:41.907303: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19D3100 next 1221 of size 256
2020-02-15 17:58:41.910010: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19D3200 next 1180 of size 256
2020-02-15 17:58:41.912814: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19D3300 next 1707 of size 4096
2020-02-15 17:58:41.916139: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19D4300 next 1100 of size 256
2020-02-15 17:58:41.918765: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19D4400 next 2231 of size 2048
2020-02-15 17:58:41.921529: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19D4C00 next 2130 of size 86016
2020-02-15 17:58:41.925219: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19E9C00 next 837 of size 256
2020-02-15 17:58:41.927861: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19E9D00 next 756 of size 2048
2020-02-15 17:58:41.930718: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19EA500 next 2036 of size 256
2020-02-15 17:58:41.934014: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19EA600 next 491 of size 256
2020-02-15 17:58:41.936574: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19EA700 next 2830 of size 2048
2020-02-15 17:58:41.939506: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19EAF00 next 1760 of size 256
2020-02-15 17:58:41.942820: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19EB000 next 2808 of size 256
2020-02-15 17:58:41.945554: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19EB100 next 2100 of size 4096
2020-02-15 17:58:41.948217: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19EC100 next 2014 of size 2048
2020-02-15 17:58:41.951516: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19EC900 next 1955 of size 256
2020-02-15 17:58:41.954067: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19ECA00 next 911 of size 2048
2020-02-15 17:58:41.957010: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A19ED200 next 3112 of size 1545472
2020-02-15 17:58:41.960359: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A1B66700 next 1157 of size 256
2020-02-15 17:58:41.963079: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A1B66800 next 1078 of size 1024
2020-02-15 17:58:41.965789: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A1B66C00 next 2748 of size 2048
2020-02-15 17:58:41.968795: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A1B67400 next 1351 of size 131072
2020-02-15 17:58:41.971276: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A1B87400 next 1390 of size 196608
2020-02-15 17:58:41.974080: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A1BB7400 next 1596 of size 256
2020-02-15 17:58:41.976476: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A1BB7500 next 1275 of size 2048
2020-02-15 17:58:41.979545: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A1BB7D00 next 583 of size 256
2020-02-15 17:58:41.981923: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A1BB7E00 next 2846 of size 256
2020-02-15 17:58:41.984320: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A1BB7F00 next 2694 of size 256
2020-02-15 17:58:41.987246: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A1BB8000 next 2071 of size 256
2020-02-15 17:58:41.989842: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A1BB8100 next 2073 of size 1024
2020-02-15 17:58:41.992291: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A1BB8500 next 1551 of size 1024
2020-02-15 17:58:41.994685: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A1BB8900 next 861 of size 256
2020-02-15 17:58:41.997686: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A1BB8A00 next 903 of size 4718592
2020-02-15 17:58:42.000144: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A2038A00 next 2123 of size 524288
2020-02-15 17:58:42.002599: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A20B8A00 next 2363 of size 512
2020-02-15 17:58:42.005790: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A20B8C00 next 813 of size 512
2020-02-15 17:58:42.008154: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A20B8E00 next 2053 of size 256
2020-02-15 17:58:42.010531: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A20B8F00 next 2316 of size 512
2020-02-15 17:58:42.012886: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A20B9100 next 2145 of size 256
2020-02-15 17:58:42.015838: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A20B9200 next 2948 of size 2048
2020-02-15 17:58:42.018220: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A20B9A00 next 1214 of size 256
2020-02-15 17:58:42.020602: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A20B9B00 next 1210 of size 256
2020-02-15 17:58:42.023631: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A20B9C00 next 1317 of size 256
2020-02-15 17:58:42.026097: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A20B9D00 next 2326 of size 256
2020-02-15 17:58:42.028469: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A20B9E00 next 1744 of size 4718592
2020-02-15 17:58:42.030913: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A2539E00 next 3258 of size 2097152
2020-02-15 17:58:42.034037: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A2739E00 next 1464 of size 4718592
2020-02-15 17:58:42.036985: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A2BB9E00 next 2570 of size 18874368
2020-02-15 17:58:42.039692: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A3DB9E00 next 1560 of size 18874368
2020-02-15 17:58:42.042684: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A4FB9E00 next 894 of size 4718592
2020-02-15 17:58:42.045116: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A5439E00 next 2375 of size 2097152
2020-02-15 17:58:42.047651: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A5639E00 next 3145 of size 18874368
2020-02-15 17:58:42.050697: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A6839E00 next 2451 of size 2097152
2020-02-15 17:58:42.053278: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A6A39E00 next 1680 of size 4718592
2020-02-15 17:58:42.055815: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A6EB9E00 next 1501 of size 2097152
2020-02-15 17:58:42.058828: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A70B9E00 next 2522 of size 18874368
2020-02-15 17:58:42.061324: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A82B9E00 next 2575 of size 256
2020-02-15 17:58:42.063730: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A82B9F00 next 1308 of size 256
2020-02-15 17:58:42.066104: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A82BA000 next 1176 of size 256
2020-02-15 17:58:42.069059: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A82BA100 next 2097 of size 256
2020-02-15 17:58:42.071449: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A82BA200 next 3159 of size 1024
2020-02-15 17:58:42.073876: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A82BA600 next 1684 of size 18874368
2020-02-15 17:58:42.076897: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A94BA600 next 1794 of size 256
2020-02-15 17:58:42.079284: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A94BA700 next 1616 of size 256
2020-02-15 17:58:42.081676: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A94BA800 next 2320 of size 256
2020-02-15 17:58:42.084157: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A94BA900 next 659 of size 256
2020-02-15 17:58:42.087004: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A94BAA00 next 1535 of size 256
2020-02-15 17:58:42.089455: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A94BAB00 next 1269 of size 4096
2020-02-15 17:58:42.091850: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A94BBB00 next 2985 of size 256
2020-02-15 17:58:42.094258: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A94BBC00 next 614 of size 2048
2020-02-15 17:58:42.097483: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A94BC400 next 433 of size 256
2020-02-15 17:58:42.100725: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A94BC500 next 586 of size 2048
2020-02-15 17:58:42.103263: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A94BCD00 next 2309 of size 256
2020-02-15 17:58:42.106431: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A94BCE00 next 1104 of size 256
2020-02-15 17:58:42.108840: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A94BCF00 next 1130 of size 1024
2020-02-15 17:58:42.111231: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A94BD300 next 2412 of size 256
2020-02-15 17:58:42.114300: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A94BD400 next 2429 of size 256
2020-02-15 17:58:42.116684: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A94BD500 next 807 of size 256
2020-02-15 17:58:42.119256: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A94BD600 next 1929 of size 4096
2020-02-15 17:58:42.122225: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A94BE600 next 631 of size 2048
2020-02-15 17:58:42.124638: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A94BEE00 next 2257 of size 256
2020-02-15 17:58:42.127063: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A94BEF00 next 2453 of size 256
2020-02-15 17:58:42.129447: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A94BF000 next 2020 of size 256
2020-02-15 17:58:42.132624: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A94BF100 next 2256 of size 256
2020-02-15 17:58:42.135024: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A94BF200 next 3229 of size 256
2020-02-15 17:58:42.137397: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A94BF300 next 3256 of size 131072
2020-02-15 17:58:42.140594: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A94DF300 next 2695 of size 256
2020-02-15 17:58:42.142960: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A94DF400 next 2552 of size 256
2020-02-15 17:58:42.145368: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A94DF500 next 1209 of size 1179648
2020-02-15 17:58:42.147815: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A95FF500 next 788 of size 2048
2020-02-15 17:58:42.150859: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A95FFD00 next 2919 of size 256
2020-02-15 17:58:42.153288: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A95FFE00 next 1848 of size 21504
2020-02-15 17:58:42.155746: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A9605200 next 2209 of size 1024
2020-02-15 17:58:42.158628: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A9605600 next 1486 of size 512
2020-02-15 17:58:42.161036: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A9605800 next 760 of size 256
2020-02-15 17:58:42.163385: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A9605900 next 485 of size 256
2020-02-15 17:58:42.165800: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A9605A00 next 1321 of size 256
2020-02-15 17:58:42.168781: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A9605B00 next 2457 of size 256
2020-02-15 17:58:42.171161: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A9605C00 next 2018 of size 256
2020-02-15 17:58:42.173570: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A9605D00 next 2204 of size 4096
2020-02-15 17:58:42.177096: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A9606D00 next 632 of size 1024
2020-02-15 17:58:42.179622: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A9607100 next 2467 of size 256
2020-02-15 17:58:42.181989: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007A9607200 next 954 of size 18874368
2020-02-15 17:58:42.185071: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AA807200 next 2739 of size 256
2020-02-15 17:58:42.187495: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AA807300 next 774 of size 256
2020-02-15 17:58:42.190262: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AA807400 next 2169 of size 43008
2020-02-15 17:58:42.192863: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AA811C00 next 1385 of size 256
2020-02-15 17:58:42.196252: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AA811D00 next 2392 of size 4096
2020-02-15 17:58:42.198689: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AA812D00 next 2069 of size 1024
2020-02-15 17:58:42.201209: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AA813100 next 2708 of size 256
2020-02-15 17:58:42.204106: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AA813200 next 1163 of size 256
2020-02-15 17:58:42.206669: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AA813300 next 880 of size 256
2020-02-15 17:58:42.209020: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AA813400 next 992 of size 256
2020-02-15 17:58:42.212033: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AA813500 next 2651 of size 256
2020-02-15 17:58:42.214401: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AA813600 next 2562 of size 512
2020-02-15 17:58:42.216764: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AA813800 next 595 of size 524288
2020-02-15 17:58:42.219167: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AA893800 next 1950 of size 1024
2020-02-15 17:58:42.222102: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AA893C00 next 959 of size 524288
2020-02-15 17:58:42.224530: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AA913C00 next 2697 of size 4718592
2020-02-15 17:58:42.227012: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AAD93C00 next 1533 of size 4718592
2020-02-15 17:58:42.230086: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AB213C00 next 1852 of size 4096
2020-02-15 17:58:42.232510: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AB214C00 next 2767 of size 2097152
2020-02-15 17:58:42.234942: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AB414C00 next 2577 of size 4096
2020-02-15 17:58:42.237352: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AB415C00 next 1601 of size 1024
2020-02-15 17:58:42.240521: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AB416000 next 626 of size 1024
2020-02-15 17:58:42.242993: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AB416400 next 3039 of size 131072
2020-02-15 17:58:42.245452: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AB436400 next 1503 of size 256
2020-02-15 17:58:42.248301: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AB436500 next 419 of size 256
2020-02-15 17:58:42.250674: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AB436600 next 390 of size 294912
2020-02-15 17:58:42.253078: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AB47E600 next 1208 of size 512
2020-02-15 17:58:42.255556: I tensorflow/core/common_runtime/bfc_allocator.cc:905] Free  at 00000007AB47E800 next 1505 of size 256
2020-02-15 17:58:42.258735: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AB47E900 next 3125 of size 1024
2020-02-15 17:58:42.261142: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AB47ED00 next 3087 of size 4718592
2020-02-15 17:58:42.263592: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AB8FED00 next 1181 of size 2048
2020-02-15 17:58:42.266526: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AB8FF500 next 2627 of size 2048
2020-02-15 17:58:42.268983: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AB8FFD00 next 1117 of size 1024
2020-02-15 17:58:42.271450: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AB900100 next 1623 of size 2048
2020-02-15 17:58:42.273939: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AB900900 next 1120 of size 2048
2020-02-15 17:58:42.276912: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AB901100 next 1033 of size 4096
2020-02-15 17:58:42.279286: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AB902100 next 2260 of size 2048
2020-02-15 17:58:42.281700: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AB902900 next 1205 of size 2097152
2020-02-15 17:58:42.284600: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007ABB02900 next 1887 of size 512
2020-02-15 17:58:42.287021: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007ABB02B00 next 1949 of size 512
2020-02-15 17:58:42.289416: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007ABB02D00 next 2382 of size 21504
2020-02-15 17:58:42.291914: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007ABB08100 next 2006 of size 8192
2020-02-15 17:58:42.294862: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007ABB0A100 next 2165 of size 512
2020-02-15 17:58:42.297253: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007ABB0A300 next 2098 of size 32768
2020-02-15 17:58:42.299732: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007ABB12300 next 3141 of size 1024
2020-02-15 17:58:42.302706: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007ABB12700 next 523 of size 131072
2020-02-15 17:58:42.305148: I tensorflow/core/common_runtime/bfc_allocator.cc:905] Free  at 00000007ABB32700 next 3045 of size 256
2020-02-15 17:58:42.307584: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007ABB32800 next 2342 of size 524288
2020-02-15 17:58:42.310007: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007ABBB2800 next 1821 of size 1024
2020-02-15 17:58:42.313019: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007ABBB2C00 next 1260 of size 2048
2020-02-15 17:58:42.315296: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007ABBB3400 next 1937 of size 512
2020-02-15 17:58:42.317703: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007ABBB3600 next 574 of size 512
2020-02-15 17:58:42.320694: I tensorflow/core/common_runtime/bfc_allocator.cc:905] Free  at 00000007ABBB3800 next 2239 of size 256
2020-02-15 17:58:42.323159: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007ABBB3900 next 1049 of size 1024
2020-02-15 17:58:42.325849: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007ABBB3D00 next 617 of size 1179648
2020-02-15 17:58:42.329032: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007ABCD3D00 next 1629 of size 256
2020-02-15 17:58:42.331446: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007ABCD3E00 next 604 of size 131072
2020-02-15 17:58:42.333885: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007ABCF3E00 next 3146 of size 18874368
2020-02-15 17:58:42.336411: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007ACEF3E00 next 2850 of size 2048
2020-02-15 17:58:42.339367: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007ACEF4600 next 3178 of size 1024
2020-02-15 17:58:42.341772: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007ACEF4A00 next 1377 of size 2048
2020-02-15 17:58:42.344245: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007ACEF5200 next 1994 of size 1536
2020-02-15 17:58:42.347161: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007ACEF5800 next 1446 of size 18874368
2020-02-15 17:58:42.349634: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AE0F5800 next 802 of size 768
2020-02-15 17:58:42.352091: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AE0F5B00 next 889 of size 75264
2020-02-15 17:58:42.354538: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AE108100 next 542 of size 75264
2020-02-15 17:58:42.357580: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AE11A700 next 1604 of size 2048
2020-02-15 17:58:42.359987: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AE11AF00 next 2823 of size 2816
2020-02-15 17:58:42.362409: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AE11BA00 next 3212 of size 1024
2020-02-15 17:58:42.365409: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AE11BE00 next 2524 of size 2048
2020-02-15 17:58:42.367862: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AE11C600 next 2931 of size 1024
2020-02-15 17:58:42.370309: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AE11CA00 next 2994 of size 1024
2020-02-15 17:58:42.372801: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AE11CE00 next 3133 of size 1024
2020-02-15 17:58:42.375937: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AE11D200 next 1456 of size 1024
2020-02-15 17:58:42.378359: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AE11D600 next 447 of size 1024
2020-02-15 17:58:42.380748: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AE11DA00 next 2060 of size 1024
2020-02-15 17:58:42.384158: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AE11DE00 next 1290 of size 1024
2020-02-15 17:58:42.386606: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AE11E200 next 2909 of size 512
2020-02-15 17:58:42.389092: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AE11E400 next 2602 of size 1024
2020-02-15 17:58:42.392223: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AE11E800 next 2701 of size 1024
2020-02-15 17:58:42.394637: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AE11EC00 next 919 of size 1024
2020-02-15 17:58:42.397053: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AE11F000 next 2470 of size 1024
2020-02-15 17:58:42.399575: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AE11F400 next 1482 of size 1024
2020-02-15 17:58:42.402526: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AE11F800 next 3029 of size 1024
2020-02-15 17:58:42.405101: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AE11FC00 next 874 of size 1024
2020-02-15 17:58:42.407798: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AE120000 next 2004 of size 1024
2020-02-15 17:58:42.410996: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AE120400 next 2858 of size 1024
2020-02-15 17:58:42.413509: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AE120800 next 1235 of size 1024
2020-02-15 17:58:42.415902: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AE120C00 next 504 of size 1024
2020-02-15 17:58:42.418281: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AE121000 next 2124 of size 1024
2020-02-15 17:58:42.421294: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AE121400 next 957 of size 1024
2020-02-15 17:58:42.423772: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AE121800 next 1677 of size 2048
2020-02-15 17:58:42.426261: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AE122000 next 476 of size 2048
2020-02-15 17:58:42.429258: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AE122800 next 1959 of size 2048
2020-02-15 17:58:42.431762: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AE123000 next 381 of size 2048
2020-02-15 17:58:42.434158: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AE123800 next 2714 of size 2048
2020-02-15 17:58:42.437155: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AE124000 next 1660 of size 1024
2020-02-15 17:58:42.439616: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AE124400 next 2584 of size 3840
2020-02-15 17:58:42.442311: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AE125300 next 422 of size 2048
2020-02-15 17:58:42.444791: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AE125B00 next 1858 of size 2048
2020-02-15 17:58:42.448010: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AE126300 next 693 of size 2048
2020-02-15 17:58:42.450374: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AE126B00 next 846 of size 2048
2020-02-15 17:58:42.452749: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AE127300 next 2310 of size 2048
2020-02-15 17:58:42.456684: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AE127B00 next 600 of size 1024
2020-02-15 17:58:42.459352: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AE127F00 next 1397 of size 1024
2020-02-15 17:58:42.461817: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AE128300 next 446 of size 1024
2020-02-15 17:58:42.464171: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AE128700 next 2913 of size 2048
2020-02-15 17:58:42.467466: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AE128F00 next 2201 of size 2048
2020-02-15 17:58:42.469847: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AE129700 next 2662 of size 2048
2020-02-15 17:58:42.472355: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AE129F00 next 3206 of size 2048
2020-02-15 17:58:42.475568: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AE12A700 next 1805 of size 2048
2020-02-15 17:58:42.478035: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AE12AF00 next 1343 of size 2048
2020-02-15 17:58:42.480401: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AE12B700 next 3060 of size 2048
2020-02-15 17:58:42.483356: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AE12BF00 next 1792 of size 3584
2020-02-15 17:58:42.485810: I tensorflow/core/common_runtime/bfc_allocator.cc:905] Free  at 00000007AE12CD00 next 1968 of size 37632
2020-02-15 17:58:42.488283: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AE136000 next 437 of size 112896
2020-02-15 17:58:42.490877: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AE151900 next 1087 of size 150528
2020-02-15 17:58:42.493962: I tensorflow/core/common_runtime/bfc_allocator.cc:905] Free  at 00000007AE176500 next 1213 of size 150528
2020-02-15 17:58:42.496417: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AE19B100 next 1922 of size 150528
2020-02-15 17:58:42.498859: I tensorflow/core/common_runtime/bfc_allocator.cc:905] Free  at 00000007AE1BFD00 next 2881 of size 150528
2020-02-15 17:58:42.501969: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AE1E4900 next 387 of size 6422528
2020-02-15 17:58:42.504422: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AE804900 next 786 of size 11023872
2020-02-15 17:58:42.507126: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AF287F00 next 2598 of size 75264
2020-02-15 17:58:42.510202: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AF29A500 next 3162 of size 112896
2020-02-15 17:58:42.512655: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AF2B5E00 next 1728 of size 768
2020-02-15 17:58:42.515022: I tensorflow/core/common_runtime/bfc_allocator.cc:905] Free  at 00000007AF2B6100 next 2579 of size 23808
2020-02-15 17:58:42.517467: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AF2BBE00 next 645 of size 512
2020-02-15 17:58:42.520371: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AF2BC000 next 552 of size 512
2020-02-15 17:58:42.522888: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AF2BC200 next 386 of size 512
2020-02-15 17:58:42.525432: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AF2BC400 next 2274 of size 512
2020-02-15 17:58:42.528376: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AF2BC600 next 2154 of size 512
2020-02-15 17:58:42.530772: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AF2BC800 next 873 of size 512
2020-02-15 17:58:42.533137: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AF2BCA00 next 1925 of size 512
2020-02-15 17:58:42.535487: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AF2BCC00 next 3107 of size 512
2020-02-15 17:58:42.538700: I tensorflow/core/common_runtime/bfc_allocator.cc:905] Free  at 00000007AF2BCE00 next 1790 of size 256
2020-02-15 17:58:42.541358: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AF2BCF00 next 1957 of size 256
2020-02-15 17:58:42.543816: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AF2BD000 next 2015 of size 256
2020-02-15 17:58:42.546888: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AF2BD100 next 2074 of size 1024
2020-02-15 17:58:42.549292: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AF2BD500 next 1540 of size 1024
2020-02-15 17:58:42.551724: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AF2BD900 next 2307 of size 1024
2020-02-15 17:58:42.554160: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AF2BDD00 next 2832 of size 1024
2020-02-15 17:58:42.557498: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AF2BE100 next 764 of size 1024
2020-02-15 17:58:42.560016: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AF2BE500 next 3174 of size 1024
2020-02-15 17:58:42.562455: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AF2BE900 next 2966 of size 1024
2020-02-15 17:58:42.565410: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AF2BED00 next 520 of size 1024
2020-02-15 17:58:42.567840: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AF2BF100 next 1528 of size 512
2020-02-15 17:58:42.570273: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AF2BF300 next 1178 of size 512
2020-02-15 17:58:42.573301: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AF2BF500 next 1549 of size 1024
2020-02-15 17:58:42.575925: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AF2BF900 next 1030 of size 1024
2020-02-15 17:58:42.578328: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AF2BFD00 next 2356 of size 1024
2020-02-15 17:58:42.580809: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AF2C0100 next 2086 of size 512
2020-02-15 17:58:42.583877: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AF2C0300 next 2328 of size 512
2020-02-15 17:58:42.586288: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AF2C0500 next 2721 of size 1024
2020-02-15 17:58:42.588938: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AF2C0900 next 1525 of size 1024
2020-02-15 17:58:42.591999: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AF2C0D00 next 973 of size 512
2020-02-15 17:58:42.594349: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AF2C0F00 next 989 of size 512
2020-02-15 17:58:42.596717: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AF2C1100 next 1979 of size 1024
2020-02-15 17:58:42.599096: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AF2C1500 next 2354 of size 1536
2020-02-15 17:58:42.602223: I tensorflow/core/common_runtime/bfc_allocator.cc:905] Free  at 00000007AF2C1B00 next 2490 of size 18944
2020-02-15 17:58:42.604635: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AF2C6500 next 598 of size 75264
2020-02-15 17:58:42.607104: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AF2D8B00 next 1774 of size 150528
2020-02-15 17:58:42.610014: I tensorflow/core/common_runtime/bfc_allocator.cc:905] Free  at 00000007AF2FD700 next 2860 of size 75264
2020-02-15 17:58:42.612473: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AF30FD00 next 1996 of size 75264
2020-02-15 17:58:42.614873: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AF322300 next 2378 of size 6422528
2020-02-15 17:58:42.618048: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AF942300 next 1494 of size 6422528
2020-02-15 17:58:42.620533: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007AFF62300 next 2516 of size 9700352
2020-02-15 17:58:42.623082: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007B08A2700 next 666 of size 6422528
2020-02-15 17:58:42.625528: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007B0EC2700 next 404 of size 7076864
2020-02-15 17:58:42.628488: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007B1582300 next 845 of size 12845056
2020-02-15 17:58:42.630988: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007B21C2300 next 1963 of size 12845056
2020-02-15 17:58:42.633605: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007B2E02300 next 2918 of size 6422528
2020-02-15 17:58:42.636659: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007B3422300 next 424 of size 3211264
2020-02-15 17:58:42.639137: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007B3732300 next 2845 of size 3441664
2020-02-15 17:58:42.641808: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007B3A7A700 next 1253 of size 13075456
2020-02-15 17:58:42.644283: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007B46F2B00 next 3152 of size 6422528
2020-02-15 17:58:42.647474: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007B4D12B00 next 1910 of size 6422528
2020-02-15 17:58:42.649914: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007B5332B00 next 1408 of size 3211264
2020-02-15 17:58:42.652386: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007B5642B00 next 793 of size 3211264
2020-02-15 17:58:42.655377: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007B5952B00 next 2999 of size 6422528
2020-02-15 17:58:42.657857: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007B5F72B00 next 429 of size 6422528
2020-02-15 17:58:42.660271: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007B6592B00 next 2506 of size 6422528
2020-02-15 17:58:42.663338: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007B6BB2B00 next 1366 of size 10354688
2020-02-15 17:58:42.665800: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007B7592B00 next 1975 of size 3211264
2020-02-15 17:58:42.668248: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007B78A2B00 next 1246 of size 3211264
2020-02-15 17:58:42.670696: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007B7BB2B00 next 2752 of size 3211264
2020-02-15 17:58:42.673936: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007B7EC2B00 next 2856 of size 6422528
2020-02-15 17:58:42.676372: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007B84E2B00 next 2997 of size 3211264
2020-02-15 17:58:42.678933: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007B87F2B00 next 1798 of size 3211264
2020-02-15 17:58:42.682023: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007B8B02B00 next 687 of size 3211264
2020-02-15 17:58:42.684467: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007B8E12B00 next 1010 of size 3211264
2020-02-15 17:58:42.686932: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007B9122B00 next 877 of size 3211264
2020-02-15 17:58:42.689931: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007B9432B00 next 929 of size 3211264
2020-02-15 17:58:42.692354: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007B9742B00 next 963 of size 6422528
2020-02-15 17:58:42.694983: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007B9D62B00 next 1650 of size 6422528
2020-02-15 17:58:42.697433: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007BA382B00 next 2740 of size 3211264
2020-02-15 17:58:42.700376: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007BA692B00 next 1439 of size 6422528
2020-02-15 17:58:42.702818: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007BACB2B00 next 1444 of size 6422528
2020-02-15 17:58:42.705314: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007BB2D2B00 next 1899 of size 3211264
2020-02-15 17:58:42.708344: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007BB5E2B00 next 2841 of size 6422528
2020-02-15 17:58:42.710898: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007BBC02B00 next 1092 of size 3277824
2020-02-15 17:58:42.713343: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007BBF22F00 next 2499 of size 3211264
2020-02-15 17:58:42.715794: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007BC232F00 next 1113 of size 6422528
2020-02-15 17:58:42.718771: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007BC852F00 next 1923 of size 6422528
2020-02-15 17:58:42.721248: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007BCE72F00 next 1908 of size 6422528
2020-02-15 17:58:42.723808: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007BD492F00 next 443 of size 3211264
2020-02-15 17:58:42.726782: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007BD7A2F00 next 1740 of size 3211264
2020-02-15 17:58:42.729286: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007BDAB2F00 next 517 of size 3211264
2020-02-15 17:58:42.731781: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007BDDC2F00 next 2959 of size 6422528
2020-02-15 17:58:42.734263: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007BE3E2F00 next 432 of size 3277824
2020-02-15 17:58:42.737244: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007BE703300 next 2265 of size 1179648
2020-02-15 17:58:42.739826: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007BE823300 next 2772 of size 8454144
2020-02-15 17:58:42.742308: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007BF033300 next 881 of size 6422528
2020-02-15 17:58:42.745401: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007BF653300 next 1714 of size 6422528
2020-02-15 17:58:42.747860: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007BFC73300 next 1007 of size 3211264
2020-02-15 17:58:42.750321: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007BFF83300 next 1480 of size 6422528
2020-02-15 17:58:42.753366: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007C05A3300 next 865 of size 3211264
2020-02-15 17:58:42.755937: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007C08B3300 next 1967 of size 6422528
2020-02-15 17:58:42.758407: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007C0ED3300 next 2200 of size 3211264
2020-02-15 17:58:42.761063: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007C11E3300 next 2346 of size 6422528
2020-02-15 17:58:42.764351: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007C1803300 next 2159 of size 3211264
2020-02-15 17:58:42.766928: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007C1B13300 next 3263 of size 6422528
2020-02-15 17:58:42.769657: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007C2133300 next 997 of size 3211264
2020-02-15 17:58:42.773190: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007C2443300 next 2174 of size 3211264
2020-02-15 17:58:42.775834: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007C2753300 next 759 of size 3211264
2020-02-15 17:58:42.778582: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007C2A63300 next 1938 of size 6422528
2020-02-15 17:58:42.781845: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007C3083300 next 492 of size 6422528
2020-02-15 17:58:42.784663: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007C36A3300 next 2132 of size 3211264
2020-02-15 17:58:42.787532: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007C39B3300 next 1406 of size 3211264
2020-02-15 17:58:42.791548: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007C3CC3300 next 826 of size 6422528
2020-02-15 17:58:42.794368: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007C42E3300 next 2077 of size 6422528
2020-02-15 17:58:42.797158: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007C4903300 next 1689 of size 3211264
2020-02-15 17:58:42.800627: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007C4C13300 next 1881 of size 6422528
2020-02-15 17:58:42.803553: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007C5233300 next 2115 of size 6422528
2020-02-15 17:58:42.807207: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007C5853300 next 3115 of size 3211264
2020-02-15 17:58:42.809924: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007C5B63300 next 2573 of size 6422528
2020-02-15 17:58:42.812726: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007C6183300 next 3007 of size 3211264
2020-02-15 17:58:42.816216: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007C6493300 next 1810 of size 6422528
2020-02-15 17:58:42.819050: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007C6AB3300 next 2837 of size 3211264
2020-02-15 17:58:42.821758: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007C6DC3300 next 2903 of size 3211264
2020-02-15 17:58:42.825251: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007C70D3300 next 2411 of size 3211264
2020-02-15 17:58:42.828025: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007C73E3300 next 804 of size 6422528
2020-02-15 17:58:42.830761: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007C7A03300 next 1561 of size 6422528
2020-02-15 17:58:42.834200: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007C8023300 next 2582 of size 3211264
2020-02-15 17:58:42.836947: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007C8333300 next 373 of size 3211264
2020-02-15 17:58:42.840057: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007C8643300 next 1489 of size 6422528
2020-02-15 17:58:42.843389: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007C8C63300 next 1932 of size 6704640
2020-02-15 17:58:42.845866: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007C92C8100 next 2261 of size 18874368
2020-02-15 17:58:42.848598: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007CA4C8100 next 761 of size 3211264
2020-02-15 17:58:42.851261: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007CA7D8100 next 2365 of size 6422528
2020-02-15 17:58:42.854349: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007CADF8100 next 897 of size 9633792
2020-02-15 17:58:42.857239: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007CB728100 next 808 of size 9633792
2020-02-15 17:58:42.859672: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007CC058100 next 828 of size 6422528
2020-02-15 17:58:42.862798: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007CC678100 next 1809 of size 3211264
2020-02-15 17:58:42.865318: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007CC988100 next 1044 of size 3211264
2020-02-15 17:58:42.867927: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007CCC98100 next 3210 of size 3211264
2020-02-15 17:58:42.871046: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007CCFA8100 next 951 of size 3211264
2020-02-15 17:58:42.873618: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007CD2B8100 next 1326 of size 3211264
2020-02-15 17:58:42.876082: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007CD5C8100 next 1912 of size 3211264
2020-02-15 17:58:42.879076: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007CD8D8100 next 814 of size 3211264
2020-02-15 17:58:42.881589: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007CDBE8100 next 2167 of size 6422528
2020-02-15 17:58:42.884192: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007CE208100 next 1424 of size 6422528
2020-02-15 17:58:42.886756: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007CE828100 next 2099 of size 3211264
2020-02-15 17:58:42.890099: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007CEB38100 next 2282 of size 6422528
2020-02-15 17:58:42.892633: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007CF158100 next 1613 of size 9700352
2020-02-15 17:58:42.895079: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007CFA98500 next 1023 of size 6422528
2020-02-15 17:58:42.898152: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007D00B8500 next 1481 of size 6422528
2020-02-15 17:58:42.900623: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007D06D8500 next 1128 of size 6422528
2020-02-15 17:58:42.903058: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007D0CF8500 next 2234 of size 6422528
2020-02-15 17:58:42.906296: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007D1318500 next 1492 of size 3211264
2020-02-15 17:58:42.908766: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007D1628500 next 1876 of size 3211264
2020-02-15 17:58:42.911829: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007D1938500 next 1971 of size 3211264
2020-02-15 17:58:42.915207: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007D1C48500 next 1442 of size 3211264
2020-02-15 17:58:42.917741: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007D1F58500 next 1941 of size 3211264
2020-02-15 17:58:42.920177: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007D2268500 next 953 of size 3211264
2020-02-15 17:58:42.922687: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007D2578500 next 795 of size 3211264
2020-02-15 17:58:42.925679: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007D2888500 next 2900 of size 3211264
2020-02-15 17:58:42.928266: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007D2B98500 next 1143 of size 6422528
2020-02-15 17:58:42.930755: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007D31B8500 next 2709 of size 6422528
2020-02-15 17:58:42.933755: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007D37D8500 next 956 of size 6422528
2020-02-15 17:58:42.936209: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007D3DF8500 next 1244 of size 6422528
2020-02-15 17:58:42.938760: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007D4418500 next 782 of size 6422528
2020-02-15 17:58:42.941240: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007D4A38500 next 1874 of size 6422528
2020-02-15 17:58:42.944333: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007D5058500 next 1548 of size 6422528
2020-02-15 17:58:42.946854: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007D5678500 next 2398 of size 3211264
2020-02-15 17:58:42.949301: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007D5988500 next 2680 of size 6422528
2020-02-15 17:58:42.952425: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007D5FA8500 next 1183 of size 3211264
2020-02-15 17:58:42.954911: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007D62B8500 next 2840 of size 3211264
2020-02-15 17:58:42.957392: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007D65C8500 next 709 of size 3211264
2020-02-15 17:58:42.960285: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007D68D8500 next 2578 of size 3211264
2020-02-15 17:58:42.962861: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007D6BE8500 next 2386 of size 3211264
2020-02-15 17:58:42.965312: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007D6EF8500 next 726 of size 6422528
2020-02-15 17:58:42.967751: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007D7518500 next 1829 of size 3277824
2020-02-15 17:58:42.970762: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007D7838900 next 2766 of size 3211264
2020-02-15 17:58:42.973254: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007D7B48900 next 3129 of size 6422528
2020-02-15 17:58:42.975743: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007D8168900 next 576 of size 6422528
2020-02-15 17:58:42.978651: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007D8788900 next 1170 of size 6422528
2020-02-15 17:58:42.981116: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007D8DA8900 next 415 of size 3277824
2020-02-15 17:58:42.983528: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007D90C8D00 next 1432 of size 6422528
2020-02-15 17:58:42.985995: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007D96E8D00 next 1340 of size 3211264
2020-02-15 17:58:42.989178: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007D99F8D00 next 550 of size 3211264
2020-02-15 17:58:42.991963: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007D9D08D00 next 780 of size 1605632
2020-02-15 17:58:42.994511: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007D9E90D00 next 2827 of size 1605632
2020-02-15 17:58:42.997580: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007DA018D00 next 2012 of size 150528
2020-02-15 17:58:43.000033: I tensorflow/core/common_runtime/bfc_allocator.cc:905] Free  at 00000007DA03D900 next 1066 of size 18944
2020-02-15 17:58:43.002437: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007DA042300 next 887 of size 75264
2020-02-15 17:58:43.005687: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007DA054900 next 822 of size 150528
2020-02-15 17:58:43.008224: I tensorflow/core/common_runtime/bfc_allocator.cc:905] Free  at 00000007DA079500 next 1387 of size 75264
2020-02-15 17:58:43.010651: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007DA08BB00 next 1461 of size 150528
2020-02-15 17:58:43.013072: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007DA0B0700 next 1652 of size 165376
2020-02-15 17:58:43.016381: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007DA0D8D00 next 2753 of size 2656256
2020-02-15 17:58:43.018903: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007DA361500 next 2885 of size 6653952
2020-02-15 17:58:43.021679: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007DA9B9D00 next 864 of size 6422528
2020-02-15 17:58:43.024814: I tensorflow/core/common_runtime/bfc_allocator.cc:905] Free  at 00000007DAFD9D00 next 3173 of size 786432
2020-02-15 17:58:43.027594: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007DB099D00 next 557 of size 2424832
2020-02-15 17:58:43.030264: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007DB2E9D00 next 1824 of size 3211264
2020-02-15 17:58:43.033490: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007DB5F9D00 next 1189 of size 3211264
2020-02-15 17:58:43.036366: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007DB909D00 next 2048 of size 3211264
2020-02-15 17:58:43.039612: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007DBC19D00 next 2068 of size 1605632
2020-02-15 17:58:43.042869: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007DBDA1D00 next 3009 of size 3211264
2020-02-15 17:58:43.045666: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007DC0B1D00 next 3053 of size 1605632
2020-02-15 17:58:43.048348: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007DC239D00 next 1016 of size 1605632
2020-02-15 17:58:43.051663: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007DC3C1D00 next 1114 of size 1605632
2020-02-15 17:58:43.054445: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007DC549D00 next 2559 of size 1605632
2020-02-15 17:58:43.057498: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007DC6D1D00 next 1223 of size 2557952
2020-02-15 17:58:43.060945: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007DC942500 next 1585 of size 6653952
2020-02-15 17:58:43.063721: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007DCF9AD00 next 2133 of size 1605632
2020-02-15 17:58:43.066699: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007DD122D00 next 2954 of size 3211264
2020-02-15 17:58:43.070113: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007DD432D00 next 3081 of size 3211264
2020-02-15 17:58:43.073061: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007DD742D00 next 2939 of size 1605632
2020-02-15 17:58:43.075786: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007DD8CAD00 next 932 of size 1605632
2020-02-15 17:58:43.079078: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007DDA52D00 next 2491 of size 1605632
2020-02-15 17:58:43.081819: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007DDBDAD00 next 1812 of size 3211264
2020-02-15 17:58:43.084629: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007DDEEAD00 next 721 of size 1605632
2020-02-15 17:58:43.087926: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007DE072D00 next 1491 of size 3211264
2020-02-15 17:58:43.091489: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007DE382D00 next 1020 of size 3211264
2020-02-15 17:58:43.094232: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007DE692D00 next 1520 of size 1605632
2020-02-15 17:58:43.097666: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007DE81AD00 next 2839 of size 1605632
2020-02-15 17:58:43.100490: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007DE9A2D00 next 562 of size 2228224
2020-02-15 17:58:43.103259: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007DEBC2D00 next 628 of size 3211264
2020-02-15 17:58:43.106591: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007DEED2D00 next 2616 of size 3211264
2020-02-15 17:58:43.109249: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007DF1E2D00 next 985 of size 3211264
2020-02-15 17:58:43.111903: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007DF4F2D00 next 949 of size 3211264
2020-02-15 17:58:43.115126: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007DF802D00 next 1405 of size 3211264
2020-02-15 17:58:43.117733: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007DFB12D00 next 2273 of size 1605632
2020-02-15 17:58:43.120178: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007DFC9AD00 next 1015 of size 3211264
2020-02-15 17:58:43.123522: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007DFFAAD00 next 2258 of size 3211264
2020-02-15 17:58:43.126076: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E02BAD00 next 2797 of size 3211264
2020-02-15 17:58:43.128543: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E05CAD00 next 3244 of size 3211264
2020-02-15 17:58:43.131830: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E08DAD00 next 2449 of size 3211264
2020-02-15 17:58:43.134375: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E0BEAD00 next 1600 of size 3211264
2020-02-15 17:58:43.137073: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E0EFAD00 next 1138 of size 1605632
2020-02-15 17:58:43.140442: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E1082D00 next 1129 of size 1605632
2020-02-15 17:58:43.142990: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E120AD00 next 858 of size 1605632
2020-02-15 17:58:43.145630: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E1392D00 next 1669 of size 1605632
2020-02-15 17:58:43.148251: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E151AD00 next 1754 of size 1605632
2020-02-15 17:58:43.151495: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E16A2D00 next 2826 of size 1605632
2020-02-15 17:58:43.154300: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E182AD00 next 1090 of size 1605632
2020-02-15 17:58:43.157179: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E19B2D00 next 442 of size 1605632
2020-02-15 17:58:43.160359: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E1B3AD00 next 1058 of size 3211264
2020-02-15 17:58:43.163159: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E1E4AD00 next 2330 of size 3211264
2020-02-15 17:58:43.165842: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E215AD00 next 2774 of size 3211264
2020-02-15 17:58:43.169367: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E246AD00 next 1951 of size 3211264
2020-02-15 17:58:43.172273: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E277AD00 next 1341 of size 3211264
2020-02-15 17:58:43.175475: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E2A8AD00 next 975 of size 3211264
2020-02-15 17:58:43.178898: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E2D9AD00 next 3008 of size 3211264
2020-02-15 17:58:43.181592: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E30AAD00 next 1443 of size 1605632
2020-02-15 17:58:43.184311: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E3232D00 next 525 of size 1605632
2020-02-15 17:58:43.187466: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E33BAD00 next 2703 of size 1605632
2020-02-15 17:58:43.190594: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E3542D00 next 1479 of size 1605632
2020-02-15 17:58:43.193386: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E36CAD00 next 1328 of size 1771520
2020-02-15 17:58:43.196685: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E387B500 next 3121 of size 3211264
2020-02-15 17:58:43.199313: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E3B8B500 next 2172 of size 1605632
2020-02-15 17:58:43.201773: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E3D13500 next 1552 of size 3211264
2020-02-15 17:58:43.204885: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E4023500 next 1859 of size 3211264
2020-02-15 17:58:43.207990: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E4333500 next 1097 of size 1605632
2020-02-15 17:58:43.210610: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E44BB500 next 2168 of size 3211264
2020-02-15 17:58:43.213872: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E47CB500 next 859 of size 3211264
2020-02-15 17:58:43.216292: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E4ADB500 next 1171 of size 3211264
2020-02-15 17:58:43.218796: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E4DEB500 next 2134 of size 3377152
2020-02-15 17:58:43.221864: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E5123D00 next 703 of size 1605632
2020-02-15 17:58:43.224392: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E52ABD00 next 3110 of size 1605632
2020-02-15 17:58:43.226922: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E5433D00 next 1915 of size 3211264
2020-02-15 17:58:43.230142: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E5743D00 next 3189 of size 1605632
2020-02-15 17:58:43.232675: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E58CBD00 next 2019 of size 1605632
2020-02-15 17:58:43.235202: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E5A53D00 next 2947 of size 1605632
2020-02-15 17:58:43.237751: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E5BDBD00 next 2419 of size 1605632
2020-02-15 17:58:43.241111: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E5D63D00 next 2904 of size 1869824
2020-02-15 17:58:43.243850: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E5F2C500 next 1611 of size 3211264
2020-02-15 17:58:43.246298: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E623C500 next 539 of size 3211264
2020-02-15 17:58:43.249391: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E654C500 next 657 of size 3211264
2020-02-15 17:58:43.251857: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E685C500 next 875 of size 1605632
2020-02-15 17:58:43.254357: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E69E4500 next 1422 of size 3211264
2020-02-15 17:58:43.257955: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E6CF4500 next 1964 of size 3211264
2020-02-15 17:58:43.260400: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E7004500 next 3077 of size 1605632
2020-02-15 17:58:43.262833: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E718C500 next 1736 of size 3211264
2020-02-15 17:58:43.265261: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E749C500 next 3021 of size 3211264
2020-02-15 17:58:43.268474: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E77AC500 next 1445 of size 4816896
2020-02-15 17:58:43.271086: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E7C44500 next 630 of size 3211264
2020-02-15 17:58:43.274220: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E7F54500 next 2318 of size 1605632
2020-02-15 17:58:43.277491: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E80DC500 next 2551 of size 1605632
2020-02-15 17:58:43.280256: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E8264500 next 3051 of size 1605632
2020-02-15 17:58:43.282991: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E83EC500 next 644 of size 3211264
2020-02-15 17:58:43.286207: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E86FC500 next 2345 of size 1605632
2020-02-15 17:58:43.289291: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E8884500 next 2198 of size 3211264
2020-02-15 17:58:43.292015: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E8B94500 next 2836 of size 1605632
2020-02-15 17:58:43.295412: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E8D1C500 next 705 of size 3211264
2020-02-15 17:58:43.298256: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E902C500 next 2367 of size 3211264
2020-02-15 17:58:43.300970: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E933C500 next 3057 of size 1605632
2020-02-15 17:58:43.304318: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E94C4500 next 2298 of size 1605632
2020-02-15 17:58:43.307486: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E964C500 next 1112 of size 1605632
2020-02-15 17:58:43.310339: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E97D4500 next 1519 of size 1605632
2020-02-15 17:58:43.313832: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E995C500 next 1119 of size 3211264
2020-02-15 17:58:43.316518: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007E9C6C500 next 3172 of size 4816896
2020-02-15 17:58:43.319445: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007EA104500 next 625 of size 1605632
2020-02-15 17:58:43.322869: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007EA28C500 next 927 of size 1605632
2020-02-15 17:58:43.325621: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007EA414500 next 670 of size 1605632
2020-02-15 17:58:43.328422: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007EA59C500 next 1493 of size 3211264
2020-02-15 17:58:43.331675: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007EA8AC500 next 1934 of size 3211264
2020-02-15 17:58:43.334524: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007EABBC500 next 2778 of size 3211264
2020-02-15 17:58:43.337359: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007EAECC500 next 1124 of size 3211264
2020-02-15 17:58:43.340899: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007EB1DC500 next 3017 of size 1605632
2020-02-15 17:58:43.343699: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007EB364500 next 686 of size 3211264
2020-02-15 17:58:43.346480: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007EB674500 next 2434 of size 1605632
2020-02-15 17:58:43.349629: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007EB7FC500 next 2146 of size 3211264
2020-02-15 17:58:43.352306: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007EBB0C500 next 1414 of size 1605632
2020-02-15 17:58:43.355149: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007EBC94500 next 1038 of size 1605632
2020-02-15 17:58:43.358642: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007EBE1C500 next 2206 of size 1605632
2020-02-15 17:58:43.361179: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007EBFA4500 next 2955 of size 3211264
2020-02-15 17:58:43.363618: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007EC2B4500 next 1541 of size 3211264
2020-02-15 17:58:43.366764: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007EC5C4500 next 1054 of size 1605632
2020-02-15 17:58:43.369233: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007EC74C500 next 2464 of size 1605632
2020-02-15 17:58:43.371820: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007EC8D4500 next 1329 of size 3211264
2020-02-15 17:58:43.374890: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007ECBE4500 next 692 of size 3211264
2020-02-15 17:58:43.377375: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007ECEF4500 next 2825 of size 1605632
2020-02-15 17:58:43.379963: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007ED07C500 next 396 of size 3211264
2020-02-15 17:58:43.383314: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007ED38C500 next 1279 of size 4816896
2020-02-15 17:58:43.385987: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007ED824500 next 1571 of size 3211264
2020-02-15 17:58:43.388965: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007EDB34500 next 867 of size 3211264
2020-02-15 17:58:43.392315: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007EDE44500 next 464 of size 1605632
2020-02-15 17:58:43.395124: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007EDFCC500 next 2660 of size 1605632
2020-02-15 17:58:43.397985: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007EE154500 next 2968 of size 1605632
2020-02-15 17:58:43.401307: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007EE2DC500 next 2407 of size 1605632
2020-02-15 17:58:43.404088: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007EE464500 next 2531 of size 1839104
2020-02-15 17:58:43.407244: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007EE625500 next 527 of size 3444736
2020-02-15 17:58:43.410534: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007EE96E500 next 1216 of size 802816
2020-02-15 17:58:43.413326: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007EEA32500 next 2590 of size 802816
2020-02-15 17:58:43.416237: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007EEAF6500 next 1203 of size 1605632
2020-02-15 17:58:43.419552: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007EEC7E500 next 2795 of size 1605632
2020-02-15 17:58:43.422518: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007EEE06500 next 3245 of size 1605632
2020-02-15 17:58:43.425368: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007EEF8E500 next 3114 of size 1605632
2020-02-15 17:58:43.428716: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007EF116500 next 1254 of size 802816
2020-02-15 17:58:43.431499: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007EF1DA500 next 830 of size 1294336
2020-02-15 17:58:43.434300: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007EF316500 next 1330 of size 802816
2020-02-15 17:58:43.437555: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007EF3DA500 next 2563 of size 802816
2020-02-15 17:58:43.440595: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007EF49E500 next 983 of size 1605632
2020-02-15 17:58:43.443428: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007EF626500 next 647 of size 1605632
2020-02-15 17:58:43.446820: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007EF7AE500 next 1301 of size 1605632
2020-02-15 17:58:43.449614: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007EF936500 next 2829 of size 802816
2020-02-15 17:58:43.452397: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007EF9FA500 next 1513 of size 802816
2020-02-15 17:58:43.455910: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007EFABE500 next 991 of size 1605632
2020-02-15 17:58:43.458982: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007EFC46500 next 2079 of size 802816
2020-02-15 17:58:43.461861: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007EFD0A500 next 1627 of size 802816
2020-02-15 17:58:43.465400: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007EFDCE500 next 2396 of size 2228224
2020-02-15 17:58:43.468219: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007EFFEE500 next 1681 of size 3211264
2020-02-15 17:58:43.470923: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F02FE500 next 1063 of size 3211264
2020-02-15 17:58:43.474531: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F060E500 next 3092 of size 6686720
2020-02-15 17:58:43.477374: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F0C6ED00 next 1892 of size 1605632
2020-02-15 17:58:43.480242: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F0DF6D00 next 1671 of size 1605632
2020-02-15 17:58:43.483669: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F0F7ED00 next 3019 of size 1605632
2020-02-15 17:58:43.486513: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F1106D00 next 642 of size 1605632
2020-02-15 17:58:43.489684: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F128ED00 next 1247 of size 802816
2020-02-15 17:58:43.492886: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F1352D00 next 1409 of size 1605632
2020-02-15 17:58:43.495593: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F14DAD00 next 2244 of size 1605632
2020-02-15 17:58:43.498156: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F1662D00 next 689 of size 802816
2020-02-15 17:58:43.501219: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F1726D00 next 890 of size 802816
2020-02-15 17:58:43.503634: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F17EAD00 next 2863 of size 1294336
2020-02-15 17:58:43.506420: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F1926D00 next 2149 of size 802816
2020-02-15 17:58:43.509453: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F19EAD00 next 1906 of size 802816
2020-02-15 17:58:43.512061: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F1AAED00 next 3131 of size 802816
2020-02-15 17:58:43.514544: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F1B72D00 next 2854 of size 802816
2020-02-15 17:58:43.517020: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F1C36D00 next 2028 of size 1605632
2020-02-15 17:58:43.520164: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F1DBED00 next 1783 of size 1605632
2020-02-15 17:58:43.522859: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F1F46D00 next 1226 of size 1605632
2020-02-15 17:58:43.525566: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F20CED00 next 3271 of size 1605632
2020-02-15 17:58:43.528579: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F2256D00 next 3234 of size 1605632
2020-02-15 17:58:43.531137: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F23DED00 next 3042 of size 1605632
2020-02-15 17:58:43.533628: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F2566D00 next 1638 of size 802816
2020-02-15 17:58:43.536833: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F262AD00 next 2681 of size 1294336
2020-02-15 17:58:43.539738: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F2766D00 next 762 of size 1605632
2020-02-15 17:58:43.542265: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F28EED00 next 1980 of size 802816
2020-02-15 17:58:43.545557: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F29B2D00 next 3140 of size 802816
2020-02-15 17:58:43.548185: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F2A76D00 next 1022 of size 802816
2020-02-15 17:58:43.550887: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F2B3AD00 next 3123 of size 802816
2020-02-15 17:58:43.553541: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F2BFED00 next 1789 of size 1605632
2020-02-15 17:58:43.557272: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F2D86D00 next 720 of size 1605632
2020-02-15 17:58:43.559896: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F2F0ED00 next 829 of size 802816
2020-02-15 17:58:43.563192: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F2FD2D00 next 1242 of size 1605632
2020-02-15 17:58:43.565954: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F315AD00 next 2974 of size 1605632
2020-02-15 17:58:43.568885: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F32E2D00 next 568 of size 1605632
2020-02-15 17:58:43.572253: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F346AD00 next 679 of size 1605632
2020-02-15 17:58:43.575148: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F35F2D00 next 2720 of size 802816
2020-02-15 17:58:43.577870: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F36B6D00 next 2741 of size 1605632
2020-02-15 17:58:43.581283: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F383ED00 next 1634 of size 1605632
2020-02-15 17:58:43.583899: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F39C6D00 next 3013 of size 802816
2020-02-15 17:58:43.586741: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F3A8AD00 next 899 of size 802816
2020-02-15 17:58:43.590444: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F3B4ED00 next 1711 of size 802816
2020-02-15 17:58:43.593253: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F3C12D00 next 2665 of size 802816
2020-02-15 17:58:43.596038: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F3CD6D00 next 1989 of size 2818048
2020-02-15 17:58:43.599306: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F3F86D00 next 2468 of size 802816
2020-02-15 17:58:43.602061: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F404AD00 next 1036 of size 802816
2020-02-15 17:58:43.604744: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F410ED00 next 1720 of size 1605632
2020-02-15 17:58:43.608438: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F4296D00 next 1589 of size 802816
2020-02-15 17:58:43.611320: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F435AD00 next 3242 of size 1605632
2020-02-15 17:58:43.614166: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F44E2D00 next 1803 of size 1605632
2020-02-15 17:58:43.617514: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F466AD00 next 2781 of size 802816
2020-02-15 17:58:43.620334: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F472ED00 next 2422 of size 1605632
2020-02-15 17:58:43.623294: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F48B6D00 next 2210 of size 802816
2020-02-15 17:58:43.626605: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F497AD00 next 2783 of size 1605632
2020-02-15 17:58:43.629467: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F4B02D00 next 1145 of size 802816
2020-02-15 17:58:43.632313: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F4BC6D00 next 1879 of size 1605632
2020-02-15 17:58:43.635669: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F4D4ED00 next 685 of size 802816
2020-02-15 17:58:43.638623: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F4E12D00 next 2971 of size 802816
2020-02-15 17:58:43.641433: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F4ED6D00 next 1186 of size 802816
2020-02-15 17:58:43.644740: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F4F9AD00 next 2381 of size 1294336
2020-02-15 17:58:43.647496: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F50D6D00 next 2580 of size 1605632
2020-02-15 17:58:43.650330: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F525ED00 next 968 of size 802816
2020-02-15 17:58:43.653536: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F5322D00 next 1211 of size 1605632
2020-02-15 17:58:43.656720: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F54AAD00 next 3195 of size 1605632
2020-02-15 17:58:43.659589: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F5632D00 next 1587 of size 802816
2020-02-15 17:58:43.662876: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F56F6D00 next 1626 of size 1605632
2020-02-15 17:58:43.665782: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F587ED00 next 1370 of size 1605632
2020-02-15 17:58:43.668471: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F5A06D00 next 1296 of size 802816
2020-02-15 17:58:43.671641: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F5ACAD00 next 1775 of size 802816
2020-02-15 17:58:43.674501: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F5B8ED00 next 2576 of size 1605632
2020-02-15 17:58:43.677232: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F5D16D00 next 2536 of size 1605632
2020-02-15 17:58:43.680540: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F5E9ED00 next 1871 of size 802816
2020-02-15 17:58:43.683143: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F5F62D00 next 383 of size 1605632
2020-02-15 17:58:43.685702: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F60EAD00 next 1231 of size 802816
2020-02-15 17:58:43.688365: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F61AED00 next 584 of size 1605632
2020-02-15 17:58:43.691522: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F6336D00 next 1579 of size 802816
2020-02-15 17:58:43.694130: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F63FAD00 next 1976 of size 401408
2020-02-15 17:58:43.696795: I tensorflow/core/common_runtime/bfc_allocator.cc:905] Free  at 00000007F645CD00 next 375 of size 75264
2020-02-15 17:58:43.699998: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F646F300 next 2666 of size 150528
2020-02-15 17:58:43.702716: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F6493F00 next 2690 of size 175616
2020-02-15 17:58:43.705755: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F64BED00 next 2416 of size 802816
2020-02-15 17:58:43.709089: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F6582D00 next 1433 of size 872448
2020-02-15 17:58:43.711843: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F6657D00 next 2949 of size 1605632
2020-02-15 17:58:43.714795: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F67DFD00 next 1024 of size 1605632
2020-02-15 17:58:43.718164: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F6967D00 next 962 of size 1605632
2020-02-15 17:58:43.720897: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F6AEFD00 next 1413 of size 1605632
2020-02-15 17:58:43.724034: I tensorflow/core/common_runtime/bfc_allocator.cc:905] Free  at 00000007F6C77D00 next 1834 of size 150528
2020-02-15 17:58:43.727322: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F6C9C900 next 1346 of size 250880
2020-02-15 17:58:43.730251: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F6CD9D00 next 2513 of size 401408
2020-02-15 17:58:43.732949: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F6D3BD00 next 2093 of size 1605632
2020-02-15 17:58:43.736314: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F6EC3D00 next 2738 of size 1605632
2020-02-15 17:58:43.739398: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F704BD00 next 1692 of size 802816
2020-02-15 17:58:43.742327: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F710FD00 next 909 of size 802816
2020-02-15 17:58:43.745693: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F71D3D00 next 2809 of size 1605632
2020-02-15 17:58:43.748495: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F735BD00 next 1434 of size 802816
2020-02-15 17:58:43.751268: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F741FD00 next 3180 of size 3211264
2020-02-15 17:58:43.754553: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F772FD00 next 2027 of size 401408
2020-02-15 17:58:43.757715: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F7791D00 next 1202 of size 150528
2020-02-15 17:58:43.760568: I tensorflow/core/common_runtime/bfc_allocator.cc:905] Free  at 00000007F77B6900 next 627 of size 250880
2020-02-15 17:58:43.763784: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F77F3D00 next 603 of size 401408
2020-02-15 17:58:43.766549: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F7855D00 next 980 of size 401408
2020-02-15 17:58:43.769330: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F78B7D00 next 2267 of size 3211264
2020-02-15 17:58:43.772727: I tensorflow/core/common_runtime/bfc_allocator.cc:905] Free  at 00000007F7BC7D00 next 1305 of size 1605632
2020-02-15 17:58:43.775573: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F7D4FD00 next 1940 of size 1605632
2020-02-15 17:58:43.778331: I tensorflow/core/common_runtime/bfc_allocator.cc:905] Free  at 00000007F7ED7D00 next 2940 of size 802816
2020-02-15 17:58:43.781586: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F7F9BD00 next 3018 of size 802816
2020-02-15 17:58:43.784431: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F805FD00 next 2745 of size 4333568
2020-02-15 17:58:43.787204: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F8481D00 next 2679 of size 802816
2020-02-15 17:58:43.791588: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F8545D00 next 1182 of size 802816
2020-02-15 17:58:43.794373: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F8609D00 next 2455 of size 802816
2020-02-15 17:58:43.797156: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F86CDD00 next 2163 of size 1605632
2020-02-15 17:58:43.800505: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F8855D00 next 2357 of size 1605632
2020-02-15 17:58:43.803353: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F89DDD00 next 1757 of size 1605632
2020-02-15 17:58:43.806553: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F8B65D00 next 2425 of size 1605632
2020-02-15 17:58:43.809863: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F8CEDD00 next 876 of size 1605632
2020-02-15 17:58:43.812614: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F8E75D00 next 1554 of size 3211264
2020-02-15 17:58:43.815414: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F9185D00 next 1207 of size 3211264
2020-02-15 17:58:43.818762: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F9495D00 next 2085 of size 3211264
2020-02-15 17:58:43.821369: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F97A5D00 next 2300 of size 1605632
2020-02-15 17:58:43.824153: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F992DD00 next 2898 of size 1605632
2020-02-15 17:58:43.827353: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F9AB5D00 next 671 of size 1646592
2020-02-15 17:58:43.829862: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007F9C47D00 next 2906 of size 4816896
2020-02-15 17:58:43.832430: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007FA0DFD00 next 684 of size 1605632
2020-02-15 17:58:43.835374: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007FA267D00 next 1537 of size 1605632
2020-02-15 17:58:43.837834: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007FA3EFD00 next 2936 of size 1605632
2020-02-15 17:58:43.840436: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007FA577D00 next 1458 of size 4816896
2020-02-15 17:58:43.843433: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007FAA0FD00 next 2472 of size 3211264
2020-02-15 17:58:43.845933: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007FAD1FD00 next 2063 of size 1605632
2020-02-15 17:58:43.848381: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007FAEA7D00 next 2249 of size 1904640
2020-02-15 17:58:43.850960: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007FB078D00 next 3066 of size 1605632
2020-02-15 17:58:43.854084: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007FB200D00 next 2719 of size 3211264
2020-02-15 17:58:43.856645: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007FB510D00 next 753 of size 3211264
2020-02-15 17:58:43.859287: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007FB820D00 next 2861 of size 3211264
2020-02-15 17:58:43.862292: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007FBB30D00 next 1662 of size 3211264
2020-02-15 17:58:43.865138: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007FBE40D00 next 3192 of size 802816
2020-02-15 17:58:43.868507: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007FBF04D00 next 1155 of size 802816
2020-02-15 17:58:43.872102: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007FBFC8D00 next 460 of size 3211264
2020-02-15 17:58:43.874859: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007FC2D8D00 next 1121 of size 1605632
2020-02-15 17:58:43.877563: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007FC460D00 next 2757 of size 1605632
2020-02-15 17:58:43.880846: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007FC5E8D00 next 1499 of size 6422528
2020-02-15 17:58:43.883612: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007FCC08D00 next 2413 of size 6422528
2020-02-15 17:58:43.886388: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007FD228D00 next 2094 of size 3211264
2020-02-15 17:58:43.890350: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007FD538D00 next 1158 of size 3211264
2020-02-15 17:58:43.893175: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007FD848D00 next 2698 of size 3211264
2020-02-15 17:58:43.895959: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007FDB58D00 next 413 of size 2784768
2020-02-15 17:58:43.899421: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007FDE00B00 next 1645 of size 5178368
2020-02-15 17:58:43.902337: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007FE2F0F00 next 1722 of size 3211264
2020-02-15 17:58:43.905577: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007FE600F00 next 3084 of size 3211264
2020-02-15 17:58:43.909042: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007FE910F00 next 1233 of size 3211264
2020-02-15 17:58:43.911858: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007FEC20F00 next 1753 of size 1605632
2020-02-15 17:58:43.915187: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007FEDA8F00 next 1391 of size 1605632
2020-02-15 17:58:43.917930: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007FEF30F00 next 1570 of size 1605632
2020-02-15 17:58:43.920676: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007FF0B8F00 next 509 of size 3211264
2020-02-15 17:58:43.924208: I tensorflow/core/common_runtime/bfc_allocator.cc:905] Free  at 00000007FF3C8F00 next 1698 of size 802816
2020-02-15 17:58:43.927044: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007FF48CF00 next 924 of size 802816
2020-02-15 17:58:43.929812: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007FF550F00 next 1885 of size 1605632
2020-02-15 17:58:43.932576: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007FF6D8F00 next 503 of size 3211264
2020-02-15 17:58:43.935769: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007FF9E8F00 next 734 of size 3211264
2020-02-15 17:58:43.938790: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000007FFCF8F00 next 2372 of size 3211264
2020-02-15 17:58:43.942491: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000800008F00 next 3275 of size 1605632
2020-02-15 17:58:43.945575: I tensorflow/core/common_runtime/bfc_allocator.cc:905] Free  at 0000000800190F00 next 3171 of size 2408448
2020-02-15 17:58:43.948352: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000008003DCF00 next 2296 of size 802816
2020-02-15 17:58:43.951557: I tensorflow/core/common_runtime/bfc_allocator.cc:905] Free  at 00000008004A0F00 next 2884 of size 1605632
2020-02-15 17:58:43.954295: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000800628F00 next 2485 of size 3211264
2020-02-15 17:58:43.957480: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000800938F00 next 1134 of size 3211264
2020-02-15 17:58:43.960914: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000800C48F00 next 723 of size 3937024
2020-02-15 17:58:43.963687: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000080100A200 next 2321 of size 1605632
2020-02-15 17:58:43.966518: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000801192200 next 1743 of size 802816
2020-02-15 17:58:43.969709: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000801256200 next 1459 of size 802816
2020-02-15 17:58:43.972874: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000080131A200 next 982 of size 802816
2020-02-15 17:58:43.975648: I tensorflow/core/common_runtime/bfc_allocator.cc:905] Free  at 00000008013DE200 next 1014 of size 2408448
2020-02-15 17:58:43.978907: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000080162A200 next 1342 of size 3211264
2020-02-15 17:58:43.981678: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000080193A200 next 2319 of size 3211264
2020-02-15 17:58:43.984491: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000801C4A200 next 1295 of size 3211264
2020-02-15 17:58:43.987741: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000801F5A200 next 1451 of size 3211264
2020-02-15 17:58:43.991413: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000080226A200 next 2380 of size 3211264
2020-02-15 17:58:43.994248: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000080257A200 next 1352 of size 3211264
2020-02-15 17:58:43.997664: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000080288A200 next 2945 of size 3211264
2020-02-15 17:58:44.000462: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000802B9A200 next 2980 of size 3211264
2020-02-15 17:58:44.003204: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000802EAA200 next 2986 of size 3932160
2020-02-15 17:58:44.006573: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000080326A200 next 548 of size 6422528
2020-02-15 17:58:44.009162: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000080388A200 next 564 of size 6422528
2020-02-15 17:58:44.011663: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000803EAA200 next 673 of size 20881408
2020-02-15 17:58:44.014858: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000805294200 next 1419 of size 3211264
2020-02-15 17:58:44.017466: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000008055A4200 next 1801 of size 3211264
2020-02-15 17:58:44.019988: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000008058B4200 next 838 of size 3211264
2020-02-15 17:58:44.022644: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000805BC4200 next 1602 of size 16909056
2020-02-15 17:58:44.025798: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000806BE4500 next 987 of size 6422528
2020-02-15 17:58:44.028299: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000807204500 next 3073 of size 6422528
2020-02-15 17:58:44.030851: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000807824500 next 834 of size 3211264
2020-02-15 17:58:44.033795: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000807B34500 next 1371 of size 3211264
2020-02-15 17:58:44.036573: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000807E44500 next 815 of size 6422528
2020-02-15 17:58:44.039707: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000808464500 next 2404 of size 3211264
2020-02-15 17:58:44.043235: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000808774500 next 2632 of size 4003072
2020-02-15 17:58:44.046035: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000808B45A00 next 1531 of size 6422528
2020-02-15 17:58:44.048714: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000809165A00 next 426 of size 6422528
2020-02-15 17:58:44.051979: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000809785A00 next 2222 of size 6422528
2020-02-15 17:58:44.054708: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000809DA5A00 next 2076 of size 10358272
2020-02-15 17:58:44.057892: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000080A786800 next 2872 of size 6422528
2020-02-15 17:58:44.061166: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000080ADA6800 next 1011 of size 6422528
2020-02-15 17:58:44.063805: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000080B3C6800 next 1238 of size 6422528
2020-02-15 17:58:44.066486: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000080B9E6800 next 2139 of size 6422528
2020-02-15 17:58:44.069779: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000080C006800 next 898 of size 6422528
2020-02-15 17:58:44.072433: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000080C626800 next 2865 of size 6422528
2020-02-15 17:58:44.074914: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000080CC46800 next 2771 of size 6422528
2020-02-15 17:58:44.078099: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000080D266800 next 946 of size 6422528
2020-02-15 17:58:44.080645: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000080D886800 next 2379 of size 2784768
2020-02-15 17:58:44.083166: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000080DB2E600 next 1167 of size 2784768
2020-02-15 17:58:44.085663: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000080DDD6400 next 2118 of size 10348544
2020-02-15 17:58:44.088899: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000080E7B4C00 next 1029 of size 9633792
2020-02-15 17:58:44.091521: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000080F0E4C00 next 3094 of size 6422528
2020-02-15 17:58:44.093953: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000080F704C00 next 2055 of size 3211264
2020-02-15 17:58:44.096953: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000080FA14C00 next 428 of size 4928768
2020-02-15 17:58:44.099384: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000080FEC8100 next 3196 of size 25690112
2020-02-15 17:58:44.101968: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000811748100 next 3080 of size 42467328
2020-02-15 17:58:44.105092: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000813FC8100 next 832 of size 12845056
2020-02-15 17:58:44.107634: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000814C08100 next 1511 of size 12845056
2020-02-15 17:58:44.110095: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000815848100 next 2545 of size 25690112
2020-02-15 17:58:44.112604: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000008170C8100 next 558 of size 1179648
2020-02-15 17:58:44.115614: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000008171E8100 next 372 of size 524288
2020-02-15 17:58:44.118146: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000817268100 next 2591 of size 524288
2020-02-15 17:58:44.120681: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000008172E8100 next 1742 of size 131072
2020-02-15 17:58:44.123701: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000817308100 next 2313 of size 6422528
2020-02-15 17:58:44.126181: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000817928100 next 2920 of size 786432
2020-02-15 17:58:44.128643: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000008179E8100 next 1381 of size 7284480
2020-02-15 17:58:44.131653: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000008180DA800 next 941 of size 25614592
2020-02-15 17:58:44.134207: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000819948100 next 2596 of size 18874368
2020-02-15 17:58:44.136682: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000081AB48100 next 779 of size 1024
2020-02-15 17:58:44.139136: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000081AB48500 next 597 of size 27409408
2020-02-15 17:58:44.142277: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000081C56C100 next 824 of size 1024
2020-02-15 17:58:44.144663: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000081C56C500 next 1325 of size 512
2020-02-15 17:58:44.147110: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000081C56C700 next 1151 of size 2048
2020-02-15 17:58:44.150112: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000081C56CF00 next 2136 of size 1024
2020-02-15 17:58:44.152514: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000081C56D300 next 1364 of size 294912
2020-02-15 17:58:44.154988: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000081C5B5300 next 508 of size 25690112
2020-02-15 17:58:44.157540: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000081DE35300 next 1583 of size 27410432
2020-02-15 17:58:44.160595: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 000000081F859300 next 663 of size 25690112
2020-02-15 17:58:44.163091: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000008210D9300 next 2790 of size 2097152
2020-02-15 17:58:44.165596: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000008212D9300 next 2707 of size 18874368
2020-02-15 17:58:44.168542: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 00000008224D9300 next 1840 of size 6422528
2020-02-15 17:58:44.170969: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000822AF9300 next 1004 of size 6422528
2020-02-15 17:58:44.173484: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000823119300 next 1857 of size 21495808
2020-02-15 17:58:44.176466: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000824599300 next 3222 of size 25690112
2020-02-15 17:58:44.179031: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000825E19300 next 944 of size 25690112
2020-02-15 17:58:44.181487: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000827699300 next 2340 of size 6422528
2020-02-15 17:58:44.183965: I tensorflow/core/common_runtime/bfc_allocator.cc:905] InUse at 0000000827CB9300 next 18446744073709551615 of size 35430400
2020-02-15 17:58:44.187393: I tensorflow/core/common_runtime/bfc_allocator.cc:914]      Summary of in-use Chunks by size:
2020-02-15 17:58:44.189939: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 922 Chunks of size 256 totalling 230.5KiB
2020-02-15 17:58:44.192509: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 221 Chunks of size 512 totalling 110.5KiB
2020-02-15 17:58:44.195599: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 22 Chunks of size 768 totalling 16.5KiB
2020-02-15 17:58:44.198076: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 370 Chunks of size 1024 totalling 370.0KiB
2020-02-15 17:58:44.200615: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 5 Chunks of size 1280 totalling 6.3KiB
2020-02-15 17:58:44.203631: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 9 Chunks of size 1536 totalling 13.5KiB
2020-02-15 17:58:44.206586: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 2 Chunks of size 1792 totalling 3.5KiB
2020-02-15 17:58:44.209034: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 294 Chunks of size 2048 totalling 588.0KiB
2020-02-15 17:58:44.211667: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 2 Chunks of size 2304 totalling 4.5KiB
2020-02-15 17:58:44.214688: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 2560 totalling 2.5KiB
2020-02-15 17:58:44.217355: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 2816 totalling 2.8KiB
2020-02-15 17:58:44.219852: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 4 Chunks of size 3072 totalling 12.0KiB
2020-02-15 17:58:44.223013: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 7 Chunks of size 3584 totalling 24.5KiB
2020-02-15 17:58:44.225587: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 2 Chunks of size 3840 totalling 7.5KiB
2020-02-15 17:58:44.228201: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 119 Chunks of size 4096 totalling 476.0KiB
2020-02-15 17:58:44.231379: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 4352 totalling 4.3KiB
2020-02-15 17:58:44.233689: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 4864 totalling 4.8KiB
2020-02-15 17:58:44.236247: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 5632 totalling 5.5KiB
2020-02-15 17:58:44.239664: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 2 Chunks of size 6144 totalling 12.0KiB
2020-02-15 17:58:44.242382: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 7168 totalling 7.0KiB
2020-02-15 17:58:44.244920: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 7 Chunks of size 8192 totalling 56.0KiB
2020-02-15 17:58:44.247523: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 14592 totalling 14.3KiB
2020-02-15 17:58:44.250609: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 7 Chunks of size 21504 totalling 147.0KiB
2020-02-15 17:58:44.253276: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 15 Chunks of size 32768 totalling 480.0KiB
2020-02-15 17:58:44.256358: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 40960 totalling 40.0KiB
2020-02-15 17:58:44.259439: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 8 Chunks of size 43008 totalling 336.0KiB
2020-02-15 17:58:44.262080: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 56576 totalling 55.3KiB
2020-02-15 17:58:44.264551: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 15 Chunks of size 73728 totalling 1.05MiB
2020-02-15 17:58:44.267577: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 8 Chunks of size 75264 totalling 588.0KiB
2020-02-15 17:58:44.270239: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 6 Chunks of size 86016 totalling 504.0KiB
2020-02-15 17:58:44.273113: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 94464 totalling 92.3KiB
2020-02-15 17:58:44.276249: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 103424 totalling 101.0KiB
2020-02-15 17:58:44.278770: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 2 Chunks of size 112896 totalling 220.5KiB
2020-02-15 17:58:44.281437: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 124928 totalling 122.0KiB
2020-02-15 17:58:44.284520: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 75 Chunks of size 131072 totalling 9.38MiB
2020-02-15 17:58:44.287166: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 9 Chunks of size 150528 totalling 1.29MiB
2020-02-15 17:58:44.290431: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 163840 totalling 160.0KiB
2020-02-15 17:58:44.293622: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 165376 totalling 161.5KiB
2020-02-15 17:58:44.296174: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 175616 totalling 171.5KiB
2020-02-15 17:58:44.298785: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 8 Chunks of size 196608 totalling 1.50MiB
2020-02-15 17:58:44.301392: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 201984 totalling 197.3KiB
2020-02-15 17:58:44.304678: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 244224 totalling 238.5KiB
2020-02-15 17:58:44.307514: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 250880 totalling 245.0KiB
2020-02-15 17:58:44.310231: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 23 Chunks of size 294912 totalling 6.47MiB
2020-02-15 17:58:44.313381: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 5 Chunks of size 401408 totalling 1.91MiB
2020-02-15 17:58:44.315964: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 74 Chunks of size 524288 totalling 37.00MiB
2020-02-15 17:58:44.318679: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 586752 totalling 573.0KiB
2020-02-15 17:58:44.321701: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 657152 totalling 641.8KiB
2020-02-15 17:58:44.324460: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 677376 totalling 661.5KiB
2020-02-15 17:58:44.327104: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 8 Chunks of size 786432 totalling 6.00MiB
2020-02-15 17:58:44.330250: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 58 Chunks of size 802816 totalling 44.41MiB
2020-02-15 17:58:44.332809: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 872448 totalling 852.0KiB
2020-02-15 17:58:44.335442: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 979968 totalling 957.0KiB
2020-02-15 17:58:44.338907: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 1007872 totalling 984.3KiB
2020-02-15 17:58:44.341871: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 82 Chunks of size 1179648 totalling 92.25MiB
2020-02-15 17:58:44.344558: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 4 Chunks of size 1294336 totalling 4.94MiB
2020-02-15 17:58:44.347681: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 1377280 totalling 1.31MiB
2020-02-15 17:58:44.350298: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 1545472 totalling 1.47MiB
2020-02-15 17:58:44.352739: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 133 Chunks of size 1605632 totalling 203.66MiB
2020-02-15 17:58:44.355438: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 1646592 totalling 1.57MiB
2020-02-15 17:58:44.358654: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 1771520 totalling 1.69MiB
2020-02-15 17:58:44.360962: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 1839104 totalling 1.75MiB
2020-02-15 17:58:44.363428: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 1869824 totalling 1.78MiB
2020-02-15 17:58:44.366192: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 1904640 totalling 1.82MiB
2020-02-15 17:58:44.368592: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 49 Chunks of size 2097152 totalling 98.00MiB
2020-02-15 17:58:44.370963: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 2109440 totalling 2.01MiB
2020-02-15 17:58:44.373414: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 2162688 totalling 2.06MiB
2020-02-15 17:58:44.376322: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 2 Chunks of size 2228224 totalling 4.25MiB
2020-02-15 17:58:44.378717: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 2424832 totalling 2.31MiB
2020-02-15 17:58:44.381106: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 2557952 totalling 2.44MiB
2020-02-15 17:58:44.384003: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 2656256 totalling 2.53MiB
2020-02-15 17:58:44.386346: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 3 Chunks of size 2784768 totalling 7.97MiB
2020-02-15 17:58:44.388721: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 2818048 totalling 2.69MiB
2020-02-15 17:58:44.391058: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 168 Chunks of size 3211264 totalling 514.50MiB
2020-02-15 17:58:44.394068: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 4 Chunks of size 3277824 totalling 12.50MiB
2020-02-15 17:58:44.396498: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 3377152 totalling 3.22MiB
2020-02-15 17:58:44.398988: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 3441664 totalling 3.28MiB
2020-02-15 17:58:44.401939: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 3444736 totalling 3.29MiB
2020-02-15 17:58:44.404247: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 3637248 totalling 3.47MiB
2020-02-15 17:58:44.406887: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 3932160 totalling 3.75MiB
2020-02-15 17:58:44.409178: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 3937024 totalling 3.75MiB
2020-02-15 17:58:44.412272: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 4003072 totalling 3.82MiB
2020-02-15 17:58:44.414555: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 4333568 totalling 4.13MiB
2020-02-15 17:58:44.416888: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 81 Chunks of size 4718592 totalling 364.50MiB
2020-02-15 17:58:44.419783: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 7 Chunks of size 4816896 totalling 32.16MiB
2020-02-15 17:58:44.422109: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 4928768 totalling 4.70MiB
2020-02-15 17:58:44.424421: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 5178368 totalling 4.94MiB
2020-02-15 17:58:44.426714: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 5351680 totalling 5.10MiB
2020-02-15 17:58:44.429627: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 5505024 totalling 5.25MiB
2020-02-15 17:58:44.431785: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 6029312 totalling 5.75MiB
2020-02-15 17:58:44.434041: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 97 Chunks of size 6422528 totalling 594.13MiB
2020-02-15 17:58:44.436386: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 2 Chunks of size 6653952 totalling 12.69MiB
2020-02-15 17:58:44.439410: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 6686720 totalling 6.38MiB
2020-02-15 17:58:44.441740: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 6704640 totalling 6.39MiB
2020-02-15 17:58:44.444197: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 7076864 totalling 6.75MiB
2020-02-15 17:58:44.447101: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 7142656 totalling 6.81MiB
2020-02-15 17:58:44.449356: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 7284480 totalling 6.95MiB
2020-02-15 17:58:44.451676: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 8454144 totalling 8.06MiB
2020-02-15 17:58:44.453946: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 9240576 totalling 8.81MiB
2020-02-15 17:58:44.456789: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 3 Chunks of size 9633792 totalling 27.56MiB
2020-02-15 17:58:44.459086: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 2 Chunks of size 9700352 totalling 18.50MiB
2020-02-15 17:58:44.461487: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 10348544 totalling 9.87MiB
2020-02-15 17:58:44.463777: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 10354688 totalling 9.88MiB
2020-02-15 17:58:44.466719: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 10358272 totalling 9.88MiB
2020-02-15 17:58:44.469014: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 11023872 totalling 10.51MiB
2020-02-15 17:58:44.471332: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 12451840 totalling 11.88MiB
2020-02-15 17:58:44.474144: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 21 Chunks of size 12845056 totalling 257.25MiB
2020-02-15 17:58:44.476486: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 2 Chunks of size 13075456 totalling 24.94MiB
2020-02-15 17:58:44.478885: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 13664768 totalling 13.03MiB
2020-02-15 17:58:44.481274: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 15957504 totalling 15.22MiB
2020-02-15 17:58:44.484311: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 3 Chunks of size 16777216 totalling 48.00MiB
2020-02-15 17:58:44.486626: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 16909056 totalling 16.13MiB
2020-02-15 17:58:44.489046: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 48 Chunks of size 18874368 totalling 864.00MiB
2020-02-15 17:58:44.491885: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 20881408 totalling 19.91MiB
2020-02-15 17:58:44.494300: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 21495808 totalling 20.50MiB
2020-02-15 17:58:44.496657: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 21561856 totalling 20.56MiB
2020-02-15 17:58:44.498997: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 23199744 totalling 22.13MiB
2020-02-15 17:58:44.501873: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 23592960 totalling 22.50MiB
2020-02-15 17:58:44.504227: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 25459712 totalling 24.28MiB
2020-02-15 17:58:44.506917: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 25614592 totalling 24.43MiB
2020-02-15 17:58:44.509899: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 13 Chunks of size 25690112 totalling 318.50MiB
2020-02-15 17:58:44.512278: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 25920000 totalling 24.72MiB
2020-02-15 17:58:44.514599: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 27409408 totalling 26.14MiB
2020-02-15 17:58:44.516967: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 27410432 totalling 26.14MiB
2020-02-15 17:58:44.519942: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 30556928 totalling 29.14MiB
2020-02-15 17:58:44.522436: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 35430400 totalling 33.79MiB
2020-02-15 17:58:44.524830: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 37591296 totalling 35.85MiB
2020-02-15 17:58:44.527775: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 42467328 totalling 40.50MiB
2020-02-15 17:58:44.530087: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 45869824 totalling 43.74MiB
2020-02-15 17:58:44.532440: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 5 Chunks of size 51380224 totalling 245.00MiB
2020-02-15 17:58:44.534795: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 64685312 totalling 61.69MiB
2020-02-15 17:58:44.537692: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 68157440 totalling 65.00MiB
2020-02-15 17:58:44.540211: I tensorflow/core/common_runtime/bfc_allocator.cc:917] 1 Chunks of size 68161024 totalling 65.00MiB
2020-02-15 17:58:44.542593: I tensorflow/core/common_runtime/bfc_allocator.cc:921] Sum Total of in-use chunks: 4.59GiB
2020-02-15 17:58:44.544742: I tensorflow/core/common_runtime/bfc_allocator.cc:923] total_region_allocated_bytes_: 4937233152 memory_limit_: 4937233203 available bytes: 51 curr_region_allocation_bytes_: 9874466816
2020-02-15 17:58:44.549137: I tensorflow/core/common_runtime/bfc_allocator.cc:929] Stats:
Limit:                  4937233203
InUse:                  4925189888
MaxInUse:               4927248640
NumAllocs:                  403889
MaxAllocSize:           1742209024

2020-02-15 17:58:44.554733: W tensorflow/core/common_runtime/bfc_allocator.cc:424] ****************************************************************************************************
2020-02-15 17:58:44.558242: W tensorflow/core/framework/op_kernel.cc:1651] OP_REQUIRES failed at cwise_ops_common.cc:82 : Resource exhausted: OOM when allocating tensor with shape[2,56,56,3,37,2] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
Traceback (most recent call last):
  File ""C:\Python\AI.py"", line 7, in <module>
    trainer.trainModel()
  File ""C:\Python\lib\site-packages\imageai\Detection\Custom\__init__.py"", line 291, in trainModel
    max_queue_size=8
  File ""C:\Python\lib\site-packages\keras\legacy\interfaces.py"", line 91, in wrapper
    return func(*args, **kwargs)
  File ""C:\Python\lib\site-packages\keras\engine\training.py"", line 1732, in fit_generator
    initial_epoch=initial_epoch)
  File ""C:\Python\lib\site-packages\keras\engine\training_generator.py"", line 220, in fit_generator
    reset_metrics=False)
  File ""C:\Python\lib\site-packages\keras\engine\training.py"", line 1514, in train_on_batch
    outputs = self.train_function(ins)
  File ""C:\Python\lib\site-packages\tensorflow_core\python\keras\backend.py"", line 3476, in __call__
    run_metadata=self.run_metadata)
  File ""C:\Python\lib\site-packages\tensorflow_core\python\client\session.py"", line 1472, in __call__
    run_metadata_ptr)
tensorflow.python.framework.errors_impl.ResourceExhaustedError: 2 root error(s) found.
  (0) Resource exhausted: OOM when allocating tensor with shape[3,3,512,1024] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
         [[{{node training/Adam/Square_207}}]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.

         [[training/Adam/sub_646/_7481]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.

  (1) Resource exhausted: OOM when allocating tensor with shape[3,3,512,1024] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
         [[{{node training/Adam/Square_207}}]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.

0 successful operations.
0 derived errors ignored.


Anyone know this? please help






"
36779,Change in the Dimension (shape) because of np.hstack on tf.keras.preprocessing.text.Tokenizer.texts_to_sequences,"**System information** 

- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes

- OS Platform and Distribution (e.g.,Linux Ubuntu 16.04): - NA, as it can be replicated in Google Colab, irrespective of an OS

Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: - NA

TensorFlow installed from (source or binary): - pip install tensorflow==2.1

TensorFlow version (use command below): - 2.1

Python version: - Google Colab Python 3

Bazel version (if compiling from source): NA

GCC/Compiler version (if compiling from source): - CUDA/cuDNN version: NA

- GPU model and memory: NA

**Describe the current behavior**: TLDR, working properly for Testing (Validation) Labels but shape is changing for Training Labels.

I have applied np.hstack on `tensorflow.keras.preprocessing.text.Tokenizer.texts_to_sequences` for both Training Labels and for Validation (Testing) Labels.

Surprisingly and mystically, the Size of the Output, after I applied on Training Labels is different from that of before I have applied `np.hstack`. However, there is no Change in the Shape for Validation Labels, before and after the application of `tensorflow.keras.preprocessing.text.Tokenizer.texts_to_sequences` and `np.hstack`.

**Describe the expected behavior**: There should not be change in the Shape before and after application of above Methods and the behavior should be same for both Training Labels and Testing Labels.

**Code to reproduce the issue** :  This is the Link of the [Github Gist](https://colab.sandbox.google.com/gist/rmothukuru/fa586147ebefdc9f2eb9ff03206e5787/discrepancy_keras_tokenizer.ipynb), to reproduce the error easily.

Complete Code to reproduce the Error is given below (just in case if the link doesn't work):

```
!pip install tensorflow==2.1

# For Preprocessing the Text => To Tokenize the Text
from tensorflow.keras.preprocessing.text import Tokenizer
# If the Two Articles are of different length, pad_sequences will make the length equal
from tensorflow.keras.preprocessing.sequence import pad_sequences

# Package for performing Numerical Operations
import numpy as np

Unique_Labels_List = ['India', 'USA', 'Australia', 'Germany', 'Bhutan', 'Nepal', 'New Zealand', 'Israel', 'Canada', 'France', 'Ireland', 'Poland', 'Egypt', 'Greece', 'China', 'Spain', 'Mexico']


Train_Labels = Unique_Labels_List[0:14]
#print('Train Labels = {}'.format(Train_Labels))

Val_Labels =  Unique_Labels_List[14:]
#print('Val_Labels = {}'.format(Val_Labels))

No_Of_Train_Items = [248, 200, 200, 218, 248, 248, 249, 247, 220, 200, 200, 211, 224, 209]
No_Val_Items = [212, 200, 219]

T_L = []
for Each_Label, Item in zip(Train_Labels, No_Of_Train_Items):
    T_L.append([Each_Label] * Item)

T_L = [item for sublist in T_L for item in sublist]

V_L = []
for Each_Label, Item in zip(Val_Labels, No_Val_Items):
    V_L.append([Each_Label] * Item)

V_L = [item for sublist in V_L for item in sublist]


len(T_L)

len(V_L)

label_tokenizer = Tokenizer()

label_tokenizer.fit_on_texts(Unique_Labels_List)

# Since it should be a Numpy Array, we should Convert the Sequences to Numpy Array, for both Training and 
# Test Labels

training_label_list = label_tokenizer.texts_to_sequences(T_L)

validation_label_list = label_tokenizer.texts_to_sequences(V_L)

training_label_seq = np.hstack(training_label_list)

validation_label_seq = np.hstack(validation_label_list)

print('Actual Number of Train Labels before np.hstack are {}'.format(len(training_label_list)))
print('Change in the Number of Train Labels because of np.hstack are {}'.format(len(training_label_seq)))

print('-------------------------------------------------------------------------------------------------------')

print('Actual Number of Validation Labels before np.hstack are {}'.format(len(validation_label_list)))
print('However, there is no change in the Number of Validation Labels because of np.hstack {}'.format(len(validation_label_seq)))
```

**Other info / logs** :
"
36778,TFTRT Int8 calibrate cost all of memory and Fail,"**System information** 
Hardware : i7 + 1660ti 
TensorFlow installed from source using bazel
The tf_env.txt is shown :

== check python ===================================================
python version: 3.5.2
python branch: 
python build version: ('default', 'Oct  8 2019 13:06:37')
python compiler version: GCC 5.4.0 20160609
python implementation: CPython


== check os platform ===============================================
os: Linux
os kernel version: #30~18.04.1-Ubuntu SMP Fri Jan 17 06:14:09 UTC 2020
os release version: 5.3.0-28-generic
os platform: Linux-5.3.0-28-generic-x86_64-with-Ubuntu-16.04-xenial
linux distribution: ('Ubuntu', '16.04', 'xenial')
linux os distribution: ('Ubuntu', '16.04', 'xenial')
mac version: ('', ('', '', ''), '')
uname: uname_result(system='Linux', node='xuxin', release='5.3.0-28-generic', version='#30~18.04.1-Ubuntu SMP Fri Jan 17 06:14:09 UTC 2020', machine='x86_64', processor='x86_64')
architecture: ('64bit', 'ELF')
machine: x86_64


== are we in docker =============================================
Yes

== compiler =====================================================
c++ (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609
Copyright (C) 2015 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.


== check pips ===================================================
numpy                1.17.3                
protobuf             3.10.0                
tensorflow           1.15.0                
tensorflow-estimator 1.15.1                

== check for virtualenv =========================================
False
== env ==========================================================
LD_LIBRARY_PATH is unset
DYLD_LIBRARY_PATH is unset

== nvidia-smi ===================================================
Sat Feb 15 07:29:47 2020       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 440.59       Driver Version: 440.59       CUDA Version: 10.2     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  GeForce GTX 166...  Off  | 00000000:01:00.0 Off |                  N/A |
| N/A   41C    P0    28W /  N/A |    346MiB /  5944MiB |     13%      Default |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
+-----------------------------------------------------------------------------+

== cuda libs  ===================================================
/usr/local/lib/python3.5/dist-packages/torch/lib/libcudart-1b201d85.so.10.1
/usr/local/cuda-10.1/targets/x86_64-linux/lib/libcudart.so.10.1.243
/usr/local/cuda-10.1/targets/x86_64-linux/lib/libcudart_static.a

== tensorflow installed from info ==================
Name: tensorflow
Version: 1.15.0
Summary: TensorFlow is an open source machine learning framework for everyone.
Home-page: https://www.tensorflow.org/
Author-email: packages@tensorflow.org
License: Apache 2.0
Location: /usr/local/lib/python3.5/dist-packages
Required-by: 

== python version  ==============================================
(major, minor, micro, releaselevel, serial)
(2, 7, 12, 'final', 0)

== bazel version  ===============================================
Build label: 0.24.1
Build time: Tue Apr 2 16:29:26 2019 (1554222566)
Build timestamp: 1554222566
Build timestamp as int: 1554222566

**Describe the current behavior**

I use tftrt module to calibrate int8 model.
I can convert() the model successfully and cost a little memory.
But, as I do calibrate(), the memory increase crazily and use the whole memory.
I set config as following and send to init TrtGraphConverter:
        config = tf.ConfigProto()
        config.gpu_options.per_process_gpu_memory_fraction = 0.5
        config.gpu_options.allow_growth = True
        config.allow_soft_placement = True
        config.log_device_placement = False

But it is useless.
By the way, I can use my PC to infer the model normally but calibrate always fail. 


**Code to reproduce the issue**
```
        config = tf.ConfigProto()
        config.gpu_options.per_process_gpu_memory_fraction = 0.5
        config.gpu_options.allow_growth = True
        config.allow_soft_placement = True
        config.log_device_placement = False

        tftrt_graph = tftrt.TrtGraphConverter(
            input_graph_def=graph.frozen_graph,
            nodes_blacklist=graph.y_name,
            session_config=config,
            max_batch_size=1,
            max_workspace_size_bytes=1 << 32,
            precision_mode='INT8',
            is_dynamic_op=True,
            minimum_segment_size=5)

      engine_graph = tftrt_graph.convert()
      engine_graph = tftrt_graph.calibrate(
                fetch_names=[x + ':0' for x in graph.y_name],
                num_runs=1,
                feed_dict_fn=feed_dict_fn)
```

**Other info / logs** 

The TFTRT output :
2020-02-15 07:03:29.178998: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-02-15 07:03:29.179482: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: GeForce GTX 1660 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.59
pciBusID: 0000:01:00.0
2020-02-15 07:03:29.179549: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-02-15 07:03:29.179572: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-02-15 07:03:29.179608: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-02-15 07:03:29.179642: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-02-15 07:03:29.179652: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-02-15 07:03:29.179701: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-02-15 07:03:29.179715: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-02-15 07:03:29.179777: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-02-15 07:03:29.180161: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-02-15 07:03:29.180449: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2020-02-15 07:03:29.180472: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-02-15 07:03:29.180498: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 
2020-02-15 07:03:29.180525: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N 
2020-02-15 07:03:29.180604: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-02-15 07:03:29.180926: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-02-15 07:03:29.181202: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5214 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1660 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5)
2020-02-15 07:03:30.620789: I tensorflow/compiler/tf2tensorrt/kernels/trt_engine_op.cc:812] Starting calibration thread on device 0, Calibration Resource @ 0x7f1be40085e0
2020-02-15 07:03:30.621001: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libnvinfer.so.6
2020-02-15 07:03:30.621392: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libnvinfer_plugin.so.6
2020-02-15 07:03:36.767786: E tensorflow/compiler/tf2tensorrt/utils/trt_logger.cc:41] DefaultLogger ../rtSafe/safeContext.cpp (105) - Cudnn Error in initializeCommonContext: 4 (Could not initialize cudnn, please check cudnn installation.)
2020-02-15 07:03:36.768004: E tensorflow/compiler/tf2tensorrt/utils/trt_logger.cc:41] DefaultLogger ../rtSafe/safeContext.cpp (105) - Cudnn Error in initializeCommonContext: 4 (Could not initialize cudnn, please check cudnn installation.)
2020-02-15 07:03:36.768058: E tensorflow/compiler/tf2tensorrt/kernels/trt_engine_op.cc:838] Calibration failed: Internal: Failed to build TensorRT engine
terminate called without an active exception
Aborted (core dumped)



"
36776,tf.config.list_physical_devices() does not show GPU,"**System information** 
OS Platform and Distribution - Windows 10 home
TensorFlow installed using - pip install tensorflow-gpu
TensorFlow version - 2.1.0
Python version - 3.7.4
CUDA/cuDNN version - 10.1
GPU - NVIDIA GeForce GTX 1650

I can see the GPUs in my machine as shown below.
![image](https://user-images.githubusercontent.com/42920503/74582198-e4bc9e80-4f86-11ea-9626-70c844e87bdd.png)

I have installed, visual studio 2019 express, CUDA tool kit 10.1 with cuDNN. 

When I try to see all the physical devices detected by tensorflow, I can see only cpu is detcted.
![image](https://user-images.githubusercontent.com/42920503/74582236-5563bb00-4f87-11ea-9294-863b7a91e11f.png)

Kindly check the issue."
36775,First example on the Tensor page results in an error,"## URL(s) with the issue:

https://www.tensorflow.org/api_docs/python/tf/Tensor

The page has the breadcrumbs `TensorFlow > API > TensorFlow Core v2.1.0 > Python`.

## Description of issue (what needs changing):

Running the first example on the [Tensor](https://www.tensorflow.org/api_docs/python/tf/Tensor) page results in an error.

### Clear description

Here is the outcome of running the first example.
``` py
>>> # Build a dataflow graph.
... c = tf.constant([[1.0, 2.0], [3.0, 4.0]])
>>> d = tf.constant([[1.0, 1.0], [0.0, 1.0]])
>>> e = tf.matmul(c, d)
>>> # Construct a `Session` to execute the graph.
... sess = tf.compat.v1.Session()
>>> # Execute the graph and store the value that `e` represents in `result`.
... result = sess.run(e)
Traceback (most recent call last):
  File ""<stdin>"", line 2, in <module>
  File ""/usr/local/lib/python3.7/site-packages/tensorflow_core/python/client/session.py"", line 960, in run
    run_metadata_ptr)
  File ""/usr/local/lib/python3.7/site-packages/tensorflow_core/python/client/session.py"", line 1108, in _run
    raise RuntimeError('The Session graph is empty.  Add operations to the '
RuntimeError: The Session graph is empty.  Add operations to the graph before calling run().
```

I understand from [here](https://kodlogs.com/34085/runtimeerror-the-session-graph-is-empty-add-operations-to-the-graph-before-calling-run) that a session is no longer required in tf v2.

But the Tensor documentation starts off with multiple session references which appears to now be obsolete or not required.
"
36772,"Error converting GraphDef to tflite - Check failed: GetOpWithOutput(model, output_array) Specified output array ""'TFLite_Detection_PostProcess'"" is not produced by any op in this graph","**System information**
- OS Platform and Distribution = Win10
- TensorFlow installed from binary - pip
- TensorFlow version 1.13.1



**Command used to run the converter or code if you’re using the Python API**

```
# Copy and paste here the exact command
tflite_convert \
 --output_file=/tmp/detect.tflite \ 
 --graph_def_file=tflite2/tflite_graph.pb \ 
 --input_shapes=1,300,300,3 \
 --input_arrays=image_tensor \ 
--output_arrays='TFLite_Detection_PostProcess','TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3'

**The output from the converter invocation**

```
# Copy and paste the output here.
(tensorflow1) C:\tensorflow1\models\research\object_detection>tflite_convert \ --output_file=/tmp/fuck.tflite \ --graph_def_file=tflite2/tflite_graph.pb \ --input_shapes=1,300,300,3 \ --input_arrays=image_tensor \ --output_arrays='TFLite_Detection_PostProcess','TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3'
2020-02-15 00:33:22.884597: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_100.dll
2020-02-15 00:33:24.579223: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library nvcuda.dll
2020-02-15 00:33:24.608227: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties:
name: GeForce RTX 2080 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.845
pciBusID: 0000:2d:00.0
2020-02-15 00:33:24.611885: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_100.dll
2020-02-15 00:33:24.616006: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_100.dll
2020-02-15 00:33:24.621212: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_100.dll
2020-02-15 00:33:24.623686: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_100.dll
2020-02-15 00:33:24.628228: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_100.dll
2020-02-15 00:33:24.631880: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_100.dll
2020-02-15 00:33:24.640338: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll
2020-02-15 00:33:24.642489: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2020-02-15 00:33:24.644141: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2
2020-02-15 00:33:24.649750: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties:
name: GeForce RTX 2080 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.845
pciBusID: 0000:2d:00.0
2020-02-15 00:33:24.653135: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_100.dll
2020-02-15 00:33:24.656487: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_100.dll
2020-02-15 00:33:24.658613: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_100.dll
2020-02-15 00:33:24.660695: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_100.dll
2020-02-15 00:33:24.662859: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_100.dll
2020-02-15 00:33:24.665900: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_100.dll
2020-02-15 00:33:24.670329: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll
2020-02-15 00:33:24.672979: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2020-02-15 00:33:25.178111: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-02-15 00:33:25.179912: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0
2020-02-15 00:33:25.181515: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N
2020-02-15 00:33:25.184222: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6269 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 SUPER, pci bus id: 0000:2d:00.0, compute capability: 7.5)
Traceback (most recent call last):
  File ""C:\Users\jacks\Anaconda3\envs\tensorflow1\Scripts\tflite_convert-script.py"", line 10, in <module>
    sys.exit(main())
  File ""C:\Users\jacks\Anaconda3\envs\tensorflow1\lib\site-packages\tensorflow_core\lite\python\tflite_convert.py"", line 515, in main
    app.run(main=run_main, argv=sys.argv[:1])
  File ""C:\Users\jacks\Anaconda3\envs\tensorflow1\lib\site-packages\tensorflow_core\python\platform\app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""C:\Users\jacks\Anaconda3\envs\tensorflow1\lib\site-packages\absl\app.py"", line 299, in run
    _run_main(main, args)
  File ""C:\Users\jacks\Anaconda3\envs\tensorflow1\lib\site-packages\absl\app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""C:\Users\jacks\Anaconda3\envs\tensorflow1\lib\site-packages\tensorflow_core\lite\python\tflite_convert.py"", line 511, in run_main
    _convert_tf1_model(tflite_flags)
  File ""C:\Users\jacks\Anaconda3\envs\tensorflow1\lib\site-packages\tensorflow_core\lite\python\tflite_convert.py"", line 199, in _convert_tf1_model
    output_data = converter.convert()
  File ""C:\Users\jacks\Anaconda3\envs\tensorflow1\lib\site-packages\tensorflow_core\lite\python\lite.py"", line 989, in convert
    **converter_kwargs)
  File ""C:\Users\jacks\Anaconda3\envs\tensorflow1\lib\site-packages\tensorflow_core\lite\python\convert.py"", line 412, in toco_convert_graph_def
    enable_mlir_converter=enable_mlir_converter)
  File ""C:\Users\jacks\Anaconda3\envs\tensorflow1\lib\site-packages\tensorflow_core\lite\python\convert.py"", line 200, in toco_convert_protos
    raise ConverterError(""See console for info.\n%s\n%s\n"" % (stdout, stderr))
tensorflow.lite.python.convert.ConverterError: See console for info.
2020-02-15 00:33:25.515637: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_100.dll
2020-02-15 00:33:27.222702: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TFLite_Detection_PostProcess
2020-02-15 00:33:27.230047: F tensorflow/lite/toco/tooling_util.cc:935] Check failed: GetOpWithOutput(model, output_array) Specified output array ""'TFLite_Detection_PostProcess'"" is not produced by any op in this graph. Is it a typo? This should not happen. If you trigger this error please send a bug report (with code to reporduce this error), to the TensorFlow Lite team.
Fatal Python error: Aborted

Current thread 0x00002c24 (most recent call first):
  File ""C:\Users\jacks\Anaconda3\envs\tensorflow1\lib\site-packages\tensorflow_core\lite\toco\python\toco_from_protos.py"", line 52 in execute
  File ""C:\Users\jacks\Anaconda3\envs\tensorflow1\lib\site-packages\absl\app.py"", line 250 in _run_main
  File ""C:\Users\jacks\Anaconda3\envs\tensorflow1\lib\site-packages\absl\app.py"", line 299 in run
  File ""C:\Users\jacks\Anaconda3\envs\tensorflow1\lib\site-packages\tensorflow_core\python\platform\app.py"", line 40 in run
  File ""C:\Users\jacks\Anaconda3\envs\tensorflow1\lib\site-packages\tensorflow_core\lite\toco\python\toco_from_protos.py"", line 89 in main
  File ""C:\Users\jacks\Anaconda3\envs\tensorflow1\Scripts\toco_from_protos-script.py"", line 10 in <module>
"
36771,"Building libtensorflow for v2.1.0 fails on mac with unrecognized flag ""-fno-constant-cfstrings""","**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Mac OSX 10.15.3
- TensorFlow installed from (source or binary): source
- TensorFlow version: 2.1.0 (Version on branch git/r2.1)
- Python version: Python 3.7.4
- Installed using virtualenv? pip? conda?: conda
- Bazel version (if compiling from source): 0.29.1
- GCC/Compiler version (if compiling from source): CC=gcc-8, CXX=g++8, version 8.3.0, 
- CUDA/cuDNN version: N/A, not installing with GPU
- GPU model and memory: N/A, not installing with GPU



**Describe the problem**

At Airbnb we want to build by source the C++ API for tensorflow so we can integrate it with internal libraries. We want to use the latest C++ API and building for mac is a first step. 

**Provide the exact sequence of commands / steps that you executed before running into the problem**
Here are the minimal steps taken to reproduce the issue on my machine:

```
❯ echo $PWD
/Users/ray_zhang/home/tensorflow
❯ CXX=g++-8 CC=gcc-8 ./configure
... (chose all the default options)
❯ bazel clean --expunge
❯ BAZEL_USE_CPP_ONLY_TOOLCHAIN=1 bazel build --action_env CC=gcc-8 --action_env CXX=g++-8 //tensorflow:libtensorflow.so
```

And I get the error:

```
ERROR: /private/var/tmp/_bazel_ray_zhang/af5fde86ccd7201c52a3f430d09db563/external/curl/BUILD.bazel:32:1: C++ compilation of rule '@curl//:curl' failed (Exit 1)
gcc-8: error: unrecognized command line option '-fno-constant-cfstrings'; did you mean '-mno-constant-cfstrings'?
Target //tensorflow:libtensorflow.so failed to build
Use --verbose_failures to see the command lines of failed build steps.
INFO: Elapsed time: 244.628s, Critical Path: 53.75s
INFO: 754 processes: 754 local.
FAILED: Build did NOT complete successfully
```


**Any other info / logs**
Here's a larger trace with the WARNING messages shortened(I'm guessing that is redundant):

```
INFO: Options provided by the client:
  Inherited 'common' options: --isatty=1 --terminal_columns=188
INFO: Reading rc options for 'build' from /Users/ray_zhang/home/tensorflow/.bazelrc:
  'build' options: --apple_platform_type=macos --define framework_shared_object=true --define open_source_build=true --java_toolchain=//third_party/toolchains/java:tf_java_toolchain --host_java_toolchain=//third_party/toolchains/java:tf_java_toolchain --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone --strategy=Genrule=standalone -c opt --cxxopt=-std=c++14 --host_cxxopt=-std=c++14 --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --config=v2
INFO: Reading rc options for 'build' from /Users/ray_zhang/home/tensorflow/.tf_configure.bazelrc:
  'build' options: --action_env PYTHON_BIN_PATH=/Users/ray_zhang/anaconda/envs/bh/bin/python --action_env PYTHON_LIB_PATH=/Users/ray_zhang/anaconda/envs/bh/lib/python3.7/site-packages --python_path=/Users/ray_zhang/anaconda/envs/bh/bin/python --config=xla --action_env TF_CONFIGURE_IOS=0
INFO: Found applicable config definition build:v2 in file /Users/ray_zhang/home/tensorflow/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1
INFO: Found applicable config definition build:xla in file /Users/ray_zhang/home/tensorflow/.tf_configure.bazelrc: --define with_xla_support=true
WARNING: /Users/ray_zhang/home/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:abi.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /Users/ray_zhang/home/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:byte_order.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /Users/ray_zhang/home/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:context.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /Users/ray_zhang/home/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:cord.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /Users/ray_zhang/home/tensorflow/tensorflow/core/BUILD:2174:12: in srcs attribute of cc_library rule //tensorflow/core:lib_internal: please do not import '//tensorflow/core/platform:cpu_feature_guard.h' directly. You should either move the file to this package or depend on an appropriate rule there
...
'//tensorflow/core/platform:profile_utils/cpu_utils.cc' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /Users/ray_zhang/home/tensorflow/tensorflow/core/BUILD:2367:12: in srcs attribute of cc_library rule //tensorflow/core:jpeg_internal: please do not import '//tensorflow/core/platform:jpeg.h' directly. You should either move the file to this package or depend on an appropriate rule there
WARNING: /Users/ray_zhang/home/tensorflow/tensorflow/core/BUILD:2347:12: in srcs attribute of cc_library rule //tensorflow/core:gif_internal: please do not import '//tensorflow/core/platform:gif.h' directly. You should either move the file to this package or depend on an appropriate rule there
INFO: Analyzed target //tensorflow:libtensorflow.so (165 packages loaded, 15597 targets configured).
INFO: Found 1 target...
INFO: Deleting stale sandbox base /private/var/tmp/_bazel_ray_zhang/af5fde86ccd7201c52a3f430d09db563/sandbox
INFO: From Compiling external/llvm/lib/Support/UnicodeCaseFold.cpp [for host]:
external/llvm/lib/Support/UnicodeCaseFold.cpp:8:1: warning: multi-line comment [-Wcomment]
 //   utils/unicode-case-fold.py \
 ^
INFO: From Compiling external/llvm/lib/Support/VirtualFileSystem.cpp [for host]:
external/llvm/lib/Support/VirtualFileSystem.cpp: In member function 'std::unique_ptr<llvm::vfs::RedirectingFileSystem::Entry> llvm::vfs::RedirectingFileSystemParser::parseEntry(llvm::yaml::Node*, llvm::vfs::RedirectingFileSystem*, bool)':
external/llvm/lib/Support/VirtualFileSystem.cpp:1448:5: warning: 'Kind' may be used uninitialized in this function [-Wmaybe-uninitialized]
     switch (Kind) {
     ^~~~~~
INFO: From Compiling external/llvm/lib/MC/XCOFFObjectWriter.cpp [for host]:
external/llvm/lib/MC/XCOFFObjectWriter.cpp: In member function 'void {anonymous}::XCOFFObjectWriter::writeSymbolName(const llvm::StringRef&)':
external/llvm/lib/MC/XCOFFObjectWriter.cpp:349:17: warning: 'char* strncpy(char*, const char*, size_t)' specified bound 8 equals destination size [-Wstringop-truncation]
     std::strncpy(Name, SymbolName.data(), XCOFF::NameSize);
     ~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
INFO: From Compiling external/llvm/lib/MC/MachObjectWriter.cpp [for host]:
external/llvm/lib/MC/MachObjectWriter.cpp: In member function 'void llvm::MachObjectWriter::writeNlist(llvm::MachObjectWriter::MachSymbolData&, const llvm::MCAsmLayout&)':
external/llvm/lib/MC/MachObjectWriter.cpp:381:13: warning: 'AliaseeInfo' may be used uninitialized in this function [-Wmaybe-uninitialized]
     Address = AliaseeInfo->StringIndex;
     ~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~
INFO: From Compiling external/llvm/lib/MC/ELFObjectWriter.cpp [for host]:
external/llvm/lib/MC/ELFObjectWriter.cpp: In function 'uint64_t {anonymous}::ELFWriter::writeObject(llvm::MCAssembler&, const llvm::MCAsmLayout&)':
external/llvm/lib/MC/ELFObjectWriter.cpp:1216:36: warning: 'AddrsigSection' may be used uninitialized in this function [-Wmaybe-uninitialized]
       SectionOffsets[AddrsigSection] = std::make_pair(SecStart, SecEnd);
                                    ^
INFO: From Compiling external/nsync/internal/cv.c [for host]:
external/nsync/internal/cv.c: In function 'void nsync::nsync_cv_init(nsync::nsync_cv*)':
external/nsync/internal/cv.c:30:36: warning: 'void* memset(void*, int, size_t)' clearing an object of type 'nsync::nsync_cv' {aka 'struct nsync::nsync_cv_s_'} with no trivial copy-assignment; use value-initialization instead [-Wclass-memaccess]
         memset (cv, 0, sizeof (*cv));
                                    ^
In file included from external/nsync/public/nsync.h:20,
                 from external/nsync/internal/cv.c:19:
external/nsync/public/nsync_cv.h:86:16: note: 'nsync::nsync_cv' {aka 'struct nsync::nsync_cv_s_'} declared here
 typedef struct nsync_cv_s_ {
                ^~~~~~~~~~~
INFO: From Compiling external/nsync/internal/counter.c [for host]:
external/nsync/internal/counter.c: In function 'nsync::nsync_counter_s_* nsync::nsync_counter_new(uint32_t)':
external/nsync/internal/counter.c:39:28: warning: 'void* memset(void*, int, size_t)' clearing an object of type 'struct nsync::nsync_counter_s_' with no trivial copy-assignment; use value-initialization instead [-Wclass-memaccess]
   memset (c, 0, sizeof (*c));
                            ^
external/nsync/internal/counter.c:29:8: note: 'struct nsync::nsync_counter_s_' declared here
 struct nsync_counter_s_ {
        ^~~~~~~~~~~~~~~~
INFO: From Compiling tensorflow/core/platform/numbers.cc:
tensorflow/core/platform/numbers.cc: In instantiation of 'T tensorflow::{anonymous}::locale_independent_strtonum(const char*, const char**) [with T = double]':
tensorflow/core/platform/numbers.cc:197:60:   required from here
tensorflow/core/platform/numbers.cc:65:21: warning: comparison of integer expressions of different signedness: 'int' and 'std::__cxx11::basic_string<char>::size_type' {aka 'long unsigned int'} [-Wsign-compare]
   for (int i = 0; i < special_num_str.length(); ++i) {
                   ~~^~~~~~~~~~~~~~~~~~~~~~~~~~
INFO: From Compiling tensorflow/core/lib/strings/proto_serialization.cc:
tensorflow/core/lib/strings/proto_serialization.cc: In function 'bool tensorflow::SerializeToBufferDeterministic(const google::protobuf::MessageLite&, char*, size_t)':
tensorflow/core/lib/strings/proto_serialization.cc:75:44: warning: comparison of integer expressions of different signedness: 'size_t' {aka 'long unsigned int'} and 'int' [-Wsign-compare]
   return !output_stream.HadError() && size == output_stream.ByteCount();
                                       ~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~
INFO: From Compiling external/snappy/snappy-stubs-internal.cc [for host]:
cc1plus: warning: command line option '-Wno-implicit-function-declaration' is valid for C/ObjC but not for C++
INFO: From Compiling external/snappy/snappy.cc [for host]:
cc1plus: warning: command line option '-Wno-implicit-function-declaration' is valid for C/ObjC but not for C++
INFO: From Compiling external/snappy/snappy-sinksource.cc:
cc1plus: warning: command line option '-Wno-implicit-function-declaration' is valid for C/ObjC but not for C++
INFO: From Compiling external/snappy/snappy-stubs-internal.cc:
cc1plus: warning: command line option '-Wno-implicit-function-declaration' is valid for C/ObjC but not for C++
INFO: From Compiling external/snappy/snappy.cc:
cc1plus: warning: command line option '-Wno-implicit-function-declaration' is valid for C/ObjC but not for C++
ERROR: /private/var/tmp/_bazel_ray_zhang/af5fde86ccd7201c52a3f430d09db563/external/curl/BUILD.bazel:32:1: C++ compilation of rule '@curl//:curl' failed (Exit 1)
gcc-8: error: unrecognized command line option '-fno-constant-cfstrings'; did you mean '-mno-constant-cfstrings'?
Target //tensorflow:libtensorflow.so failed to build
Use --verbose_failures to see the command lines of failed build steps.
INFO: Elapsed time: 244.628s, Critical Path: 53.75s
INFO: 754 processes: 754 local.
FAILED: Build did NOT complete successfully
```"
36769,Tensorflow installation error,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Python version**:
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with:

```bash
python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""
```

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
36768,"Pix2Pix tutorial error: ""Cannot convert a symbolic Tensor (truediv:0) to a numpy array.""","## URL(s) with the issue: 

https://www.tensorflow.org/tutorials/generative/pix2pix#load_the_dataset

## Description of issue (what needs changing):

plt.imshow(inp/255.0) is not valid in latest TF. Instead you must call .eval() on the Tensor objects to convert them to numpy.

### Clear description

The existing code throws this error: ""Cannot convert a symbolic Tensor (truediv:0) to a numpy array.""
from this line: plt.imshow(inp/255.0)

I was able to fix this by calling inp.eval(). But in order to call eval, you also must set up a session, which has not yet been explained at that point in the tutorial.

There may be a better way to get around this error -- I am new to TensorFlow. 
I'm guessing the tutorial contains legacy code from 1.x ? I hope there isn't more because it took me quite a while to find a fix!"
36766,TensorFlowLiteC.framework in flutter : Undefined symbols for architecture & using TensorFlowLiteC directly for iOS,"**System information** - 
bazel --version 2.0.0
TensorFlowLiteC.framework built as per [these instructions](https://github.com/tensorflow/tensorflow/blob/2fc54c5eacd547ba2cd9a6acf61ff131bb5f1bfd/tensorflow/lite/g3doc/guide/build_ios.md) 

flutter doctor
```
Doctor summary (to see all details, run flutter doctor -v):
[✓] Flutter (Channel stable, v1.12.13+hotfix.8, on Mac OS X 10.15.3 19D76, locale en)
[✗] Android toolchain - develop for Android devices
    ✗ Unable to locate Android SDK.
      Install Android Studio from: https://developer.android.com/studio/index.html
      On first launch it will assist you in installing the Android SDK components.
      (or visit https://flutter.dev/setup/#android-setup for detailed instructions).
      If the Android SDK has been installed to a custom location, set ANDROID_HOME to that location.
      You may also want to add it to your PATH environment variable.

 
[✓] Xcode - develop for iOS and macOS (Xcode 11.1)
[!] Android Studio (not installed)
[✓] VS Code (version 1.42.1)
[✓] Connected device (1 available)

! Doctor found issues in 2 categories.
```

**Steps to reproduce:**

`git clone https://github.com/am15h/tflite_flutter_plugin`
`cd tflite_flutter_plugin`
`git checkout ios_support`
`flutter pub get`
`cd example/ios && pod install`
`cd .. && flutter run`


<details>
<summary><b>Error log when running on iOS simulator</b> similar error log with iPhone arm64 device</summary>
<pre>
MDGs-iMac:example amish$ flutter run
 
Launching lib/main.dart on iPhone 11 Pro Max in debug mode...
Warning: Missing build name (CFBundleShortVersionString).
Warning: Missing build number (CFBundleVersion).
Action Required: You must set a build name and number in the pubspec.yaml file version field before submitting to the App
Store.
 
Running pod install...                                              3.5s
Running Xcode build...                                                  
                                                   
 ├─Assembling Flutter resources...                           7.8s
 └─Compiling, linking and signing...                         6.0s
Xcode build done.                                           32.7s
Failed to build iOS app
Error output from Xcode build:
↳
    ** BUILD FAILED **


Xcode's output:
↳
    Undefined symbols for architecture x86_64:
      ""std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::assign(char const*, unsigned
      long)"", referenced from:
          absl::time_internal::cctz::TimeZoneInfo::Load(std::__1::basic_string<char, std::__1::char_traits<char>,
          std::__1::allocator<char> > const&, absl::time_internal::cctz::ZoneInfoSource*) in
          TensorFlowLiteC(time_zone_info_ac39a6fa55f13bccf521f748f28e02bd.o)
          absl::time_internal::cctz::ParsePosixSpec(std::__1::basic_string<char, std::__1::char_traits<char>,
          std::__1::allocator<char> > const&, absl::time_internal::cctz::PosixTimeZone*) in
          TensorFlowLiteC(time_zone_posix_69842208220ebf392e752081d8d0bbbb.o)
      ""std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::compare(unsigned long, unsigned
      long, char const*) const"", referenced from:
          absl::time_internal::cctz::TimeZoneIf::Load(std::__1::basic_string<char, std::__1::char_traits<char>,
          std::__1::allocator<char> > const&) in TensorFlowLiteC(time_zone_if_b1201e42997e5298e8b9b342eb441cd9.o)
          absl::time_internal::cctz::(anonymous namespace)::FileZoneInfoSource::Open(std::__1::basic_string<char,
          std::__1::char_traits<char>, std::__1::allocator<char> > const&) in
          TensorFlowLiteC(time_zone_info_ac39a6fa55f13bccf521f748f28e02bd.o)
          absl::time_internal::cctz::(anonymous namespace)::AndroidZoneInfoSource::Open(std::__1::basic_string<char,
          std::__1::char_traits<char>, std::__1::allocator<char> > const&) in
          TensorFlowLiteC(time_zone_info_ac39a6fa55f13bccf521f748f28e02bd.o)
      ""std::__1::mutex::~mutex()"", referenced from:
          __GLOBAL__sub_I_time_zone_impl.cc in TensorFlowLiteC(time_zone_impl_70088ae3adaade7bd54e47cd293b4fcc.o)
      ""typeinfo for std::__1::basic_streambuf<char, std::__1::char_traits<char> >"", referenced from:
          typeinfo for std::__1::basic_stringbuf<char, std::__1::char_traits<char>, std::__1::allocator<char> > in
          TensorFlowLiteC(int128_df0a637a93531d213521c15fc19bd7c1.o)
          typeinfo for std::__1::basic_stringbuf<char, std::__1::char_traits<char>, std::__1::allocator<char> > in
          TensorFlowLiteC(time_zone_info_ac39a6fa55f13bccf521f748f28e02bd.o)
      ""std::__1::basic_streambuf<char, std::__1::char_traits<char> >::imbue(std::__1::locale const&)"", referenced from:
          vtable for std::__1::basic_stringbuf<char, std::__1::char_traits<char>, std::__1::allocator<char> > in
          TensorFlowLiteC(int128_df0a637a93531d213521c15fc19bd7c1.o)
          vtable for std::__1::basic_stringbuf<char, std::__1::char_traits<char>, std::__1::allocator<char> > in
          TensorFlowLiteC(time_zone_info_ac39a6fa55f13bccf521f748f28e02bd.o)
      ""std::__1::mutex::lock()"", referenced from:
          absl::time_internal::cctz::time_zone::Impl::LoadTimeZone(std::__1::basic_string<char, std::__1::char_traits<char>,
          std::__1::allocator<char> > const&, absl::time_internal::cctz::time_zone*) in
          TensorFlowLiteC(time_zone_impl_70088ae3adaade7bd54e47cd293b4fcc.o)
          absl::time_internal::cctz::time_zone::Impl::ClearTimeZoneMapTestOnly() in
          TensorFlowLiteC(time_zone_impl_70088ae3adaade7bd54e47cd293b4fcc.o)
      ""std::__1::basic_streambuf<char, std::__1::char_traits<char> >::setbuf(char*, long)"", referenced from:
          vtable for std::__1::basic_stringbuf<char, std::__1::char_traits<char>, std::__1::allocator<char> > in
          TensorFlowLiteC(int128_df0a637a93531d213521c15fc19bd7c1.o)
          vtable for std::__1::basic_stringbuf<char, std::__1::char_traits<char>, std::__1::allocator<char> > in
          TensorFlowLiteC(time_zone_info_ac39a6fa55f13bccf521f748f28e02bd.o)
      ""vtable for __cxxabiv1::__class_type_info"", referenced from:
          typeinfo for absl::time_internal::cctz::TimeZoneIf in
          TensorFlowLiteC(time_zone_if_b1201e42997e5298e8b9b342eb441cd9.o)
          typeinfo for std::__1::__function::__base<std::__1::unique_ptr<absl::time_internal::cctz::ZoneInfoSource,
          std::__1::default_delete<absl::time_internal::cctz::ZoneInfoSource> > (std::__1::basic_string<char,
          std::__1::char_traits<char>, std::__1::allocator<char> > const&)> in
          TensorFlowLiteC(time_zone_info_ac39a6fa55f13bccf521f748f28e02bd.o)
          typeinfo for absl::time_internal::cctz::TimeZoneInfo::Load(std::__1::basic_string<char, std::__1::char_traits<char>,
          std::__1::allocator<char> > const&)::$_1 in TensorFlowLiteC(time_zone_info_ac39a6fa55f13bccf521f748f28e02bd.o)
          typeinfo for absl::time_internal::cctz::ZoneInfoSource in
          TensorFlowLiteC(zone_info_source_d0d641f6600cbc71bed9faf61afe560f.o)
      NOTE: a missing vtable usually means the first non-inline virtual member function has no definition.
      ""std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::erase(unsigned long, unsigned
      long)"", referenced from:
          absl::time_internal::cctz::FixedOffsetToAbbr(std::__1::chrono::duration<long long, std::__1::ratio<1l, 1l> > const&)
          in TensorFlowLiteC(time_zone_fixed_12d6eb8ff52945a37ee8f97c1ea02823.o)
      ""std::__1::basic_streambuf<char, std::__1::char_traits<char> >::sync()"", referenced from:
          vtable for std::__1::basic_stringbuf<char, std::__1::char_traits<char>, std::__1::allocator<char> > in
          TensorFlowLiteC(int128_df0a637a93531d213521c15fc19bd7c1.o)
          vtable for std::__1::basic_stringbuf<char, std::__1::char_traits<char>, std::__1::allocator<char> > in
          TensorFlowLiteC(time_zone_info_ac39a6fa55f13bccf521f748f28e02bd.o)
      ""std::__1::basic_streambuf<char, std::__1::char_traits<char> >::uflow()"", referenced from:
          vtable for std::__1::basic_stringbuf<char, std::__1::char_traits<char>, std::__1::allocator<char> > in
          TensorFlowLiteC(int128_df0a637a93531d213521c15fc19bd7c1.o)
          vtable for std::__1::basic_stringbuf<char, std::__1::char_traits<char>, std::__1::allocator<char> > in
          TensorFlowLiteC(time_zone_info_ac39a6fa55f13bccf521f748f28e02bd.o)
      ""std::__1::basic_ostream<char, std::__1::char_traits<char> >::operator<<(unsigned long)"", referenced from:
          absl::time_internal::cctz::TimeZoneInfo::Description() const in
          TensorFlowLiteC(time_zone_info_ac39a6fa55f13bccf521f748f28e02bd.o)
      ""std::__1::basic_streambuf<char, std::__1::char_traits<char> >::xsputn(char const*, long)"", referenced from:
          vtable for std::__1::basic_stringbuf<char, std::__1::char_traits<char>, std::__1::allocator<char> > in
          TensorFlowLiteC(int128_df0a637a93531d213521c15fc19bd7c1.o)
          vtable for std::__1::basic_stringbuf<char, std::__1::char_traits<char>, std::__1::allocator<char> > in
          TensorFlowLiteC(time_zone_info_ac39a6fa55f13bccf521f748f28e02bd.o)
      ""std::__1::basic_ostream<char, std::__1::char_traits<char> >::~basic_ostream()"", referenced from:
          construction vtable for std::__1::basic_ostream<char, std::__1::char_traits<char>
          >-in-std::__1::basic_ostringstream<char, std::__1::char_traits<char>, std::__1::allocator<char> > in
          TensorFlowLiteC(int128_df0a637a93531d213521c15fc19bd7c1.o)
          construction vtable for std::__1::basic_ostream<char, std::__1::char_traits<char>
          >-in-std::__1::basic_ostringstream<char, std::__1::char_traits<char>, std::__1::allocator<char> > in
          TensorFlowLiteC(time_zone_info_ac39a6fa55f13bccf521f748f28e02bd.o)
      ""std::__1::basic_ostream<char, std::__1::char_traits<char> >::~basic_ostream()"", referenced from:
          construction vtable for std::__1::basic_ostream<char, std::__1::char_traits<char>
          >-in-std::__1::basic_ostringstream<char, std::__1::char_traits<char>, std::__1::allocator<char> > in
          TensorFlowLiteC(int128_df0a637a93531d213521c15fc19bd7c1.o)
          construction vtable for std::__1::basic_ostream<char, std::__1::char_traits<char>
          >-in-std::__1::basic_ostringstream<char, std::__1::char_traits<char>, std::__1::allocator<char> > in
          TensorFlowLiteC(time_zone_info_ac39a6fa55f13bccf521f748f28e02bd.o)
      ""virtual thunk to std::__1::basic_ostream<char, std::__1::char_traits<char> >::~basic_ostream()"", referenced from:
          construction vtable for std::__1::basic_ostream<char, std::__1::char_traits<char>
          >-in-std::__1::basic_ostringstream<char, std::__1::char_traits<char>, std::__1::allocator<char> > in
          TensorFlowLiteC(int128_df0a637a93531d213521c15fc19bd7c1.o)
          construction vtable for std::__1::basic_ostream<char, std::__1::char_traits<char>
          >-in-std::__1::basic_ostringstream<char, std::__1::char_traits<char>, std::__1::allocator<char> > in
          TensorFlowLiteC(time_zone_info_ac39a6fa55f13bccf521f748f28e02bd.o)
      ""virtual thunk to std::__1::basic_ostream<char, std::__1::char_traits<char> >::~basic_ostream()"", referenced from:
          construction vtable for std::__1::basic_ostream<char, std::__1::char_traits<char>
          >-in-std::__1::basic_ostringstream<char, std::__1::char_traits<char>, std::__1::allocator<char> > in
          TensorFlowLiteC(int128_df0a637a93531d213521c15fc19bd7c1.o)
          construction vtable for std::__1::basic_ostream<char, std::__1::char_traits<char>
          >-in-std::__1::basic_ostringstream<char, std::__1::char_traits<char>, std::__1::allocator<char> > in
          TensorFlowLiteC(time_zone_info_ac39a6fa55f13bccf521f748f28e02bd.o)
      ""std::__1::basic_ostream<char, std::__1::char_traits<char> >::sentry::sentry(std::__1::basic_ostream<char,
      std::__1::char_traits<char> >&)"", referenced from:
          std::__1::basic_ostream<char, std::__1::char_traits<char> >& std::__1::__put_character_sequence<char,
          std::__1::char_traits<char> >(std::__1::basic_ostream<char, std::__1::char_traits<char> >&, char const*, unsigned
          long) in TensorFlowLiteC(int128_df0a637a93531d213521c15fc19bd7c1.o)
          std::__1::basic_ostream<char, std::__1::char_traits<char> >& std::__1::__put_character_sequence<char,
          std::__1::char_traits<char> >(std::__1::basic_ostream<char, std::__1::char_traits<char> >&, char const*, unsigned
          long) in TensorFlowLiteC(time_zone_info_ac39a6fa55f13bccf521f748f28e02bd.o)
      ""std::__1::ios_base::clear(unsigned int)"", referenced from:
          std::__1::basic_ostream<char, std::__1::char_traits<char> >& std::__1::__put_character_sequence<char,
          std::__1::char_traits<char> >(std::__1::basic_ostream<char, std::__1::char_traits<char> >&, char const*, unsigned
          long) in TensorFlowLiteC(int128_df0a637a93531d213521c15fc19bd7c1.o)
          std::__1::basic_ostream<char, std::__1::char_traits<char> >& std::__1::__put_character_sequence<char,
          std::__1::char_traits<char> >(std::__1::basic_ostream<char, std::__1::char_traits<char> >&, char const*, unsigned
          long) in TensorFlowLiteC(time_zone_info_ac39a6fa55f13bccf521f748f28e02bd.o)
      ""std::__1::basic_streambuf<char, std::__1::char_traits<char> >::xsgetn(char*, long)"", referenced from:
          vtable for std::__1::basic_stringbuf<char, std::__1::char_traits<char>, std::__1::allocator<char> > in
          TensorFlowLiteC(int128_df0a637a93531d213521c15fc19bd7c1.o)
          vtable for std::__1::basic_stringbuf<char, std::__1::char_traits<char>, std::__1::allocator<char> > in
          TensorFlowLiteC(time_zone_info_ac39a6fa55f13bccf521f748f28e02bd.o)
      ""std::__1::basic_ostream<char, std::__1::char_traits<char> >::sentry::~sentry()"", referenced from:
          std::__1::basic_ostream<char, std::__1::char_traits<char> >& std::__1::__put_character_sequence<char,
          std::__1::char_traits<char> >(std::__1::basic_ostream<char, std::__1::char_traits<char> >&, char const*, unsigned
          long) in TensorFlowLiteC(int128_df0a637a93531d213521c15fc19bd7c1.o)
          std::__1::basic_ostream<char, std::__1::char_traits<char> >& std::__1::__put_character_sequence<char,
          std::__1::char_traits<char> >(std::__1::basic_ostream<char, std::__1::char_traits<char> >&, char const*, unsigned
          long) in TensorFlowLiteC(time_zone_info_ac39a6fa55f13bccf521f748f28e02bd.o)
      ""std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::resize(unsigned long, char)"",
      referenced from:
          std::__1::basic_stringbuf<char, std::__1::char_traits<char>, std::__1::allocator<char> >::overflow(int) in
          TensorFlowLiteC(int128_df0a637a93531d213521c15fc19bd7c1.o)
          std::__1::basic_stringbuf<char, std::__1::char_traits<char>, std::__1::allocator<char> >::overflow(int) in
          TensorFlowLiteC(time_zone_info_ac39a6fa55f13bccf521f748f28e02bd.o)
      ""std::__1::clog"", referenced from:
          absl::time_internal::cctz::TimeZoneInfo::CheckTransition(std::__1::basic_string<char, std::__1::char_traits<char>,
          std::__1::allocator<char> > const&, absl::time_internal::cctz::TransitionType const&, int, bool,
          std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&) const in
          TensorFlowLiteC(time_zone_info_ac39a6fa55f13bccf521f748f28e02bd.o)
          absl::time_internal::cctz::TimeZoneInfo::ExtendTransitions(std::__1::basic_string<char, std::__1::char_traits<char>,
          std::__1::allocator<char> > const&, absl::time_internal::cctz::TimeZoneInfo::Header const&) in
          TensorFlowLiteC(time_zone_info_ac39a6fa55f13bccf521f748f28e02bd.o)
      ""std::__1::mutex::unlock()"", referenced from:
          absl::time_internal::cctz::time_zone::Impl::LoadTimeZone(std::__1::basic_string<char, std::__1::char_traits<char>,
          std::__1::allocator<char> > const&, absl::time_internal::cctz::time_zone*) in
          TensorFlowLiteC(time_zone_impl_70088ae3adaade7bd54e47cd293b4fcc.o)
          absl::time_internal::cctz::time_zone::Impl::ClearTimeZoneMapTestOnly() in
          TensorFlowLiteC(time_zone_impl_70088ae3adaade7bd54e47cd293b4fcc.o)
      ""___cxa_end_catch"", referenced from:
          std::__1::basic_stringbuf<char, std::__1::char_traits<char>, std::__1::allocator<char> >::overflow(int) in
          TensorFlowLiteC(int128_df0a637a93531d213521c15fc19bd7c1.o)
          std::__1::basic_ostream<char, std::__1::char_traits<char> >& std::__1::__put_character_sequence<char,
          std::__1::char_traits<char> >(std::__1::basic_ostream<char, std::__1::char_traits<char> >&, char const*, unsigned
          long) in TensorFlowLiteC(int128_df0a637a93531d213521c15fc19bd7c1.o)
          std::__1::vector<absl::time_internal::cctz::Transition, std::__1::allocator<absl::time_internal::cctz::Transition>
          >::shrink_to_fit() in TensorFlowLiteC(time_zone_info_ac39a6fa55f13bccf521f748f28e02bd.o)
          std::__1::basic_stringbuf<char, std::__1::char_traits<char>, std::__1::allocator<char> >::overflow(int) in
          TensorFlowLiteC(time_zone_info_ac39a6fa55f13bccf521f748f28e02bd.o)
          std::__1::basic_ostream<char, std::__1::char_traits<char> >& std::__1::__put_character_sequence<char,
          std::__1::char_traits<char> >(std::__1::basic_ostream<char, std::__1::char_traits<char> >&, char const*, unsigned
          long) in TensorFlowLiteC(time_zone_info_ac39a6fa55f13bccf521f748f28e02bd.o)
      ""std::__1::basic_ostream<char, std::__1::char_traits<char> >::operator<<(int)"", referenced from:
          absl::time_internal::cctz::TimeZoneInfo::CheckTransition(std::__1::basic_string<char, std::__1::char_traits<char>,
          std::__1::allocator<char> > const&, absl::time_internal::cctz::TransitionType const&, int, bool,
          std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&) const in
          TensorFlowLiteC(time_zone_info_ac39a6fa55f13bccf521f748f28e02bd.o)
      ""operator new(unsigned long)"", referenced from:
          -[TFLBufferConvert convertWithEncoder:shape:sourceBuffer:convertedBuffer:] in
          TensorFlowLiteC(buffer_convert_1d2d90cc5f78b8992cc785cc8c58fd0c.o)
          -[TFLInferenceContext setInputDimensions:outputDimensions:taskDescriptors:] in
          TensorFlowLiteC(inference_context_0de3088040d9569800f4171c1bc2996f.o)
          std::__1::vector<unsigned int, std::__1::allocator<unsigned int> >::__vallocate(unsigned long) in
          TensorFlowLiteC(inference_context_0de3088040d9569800f4171c1bc2996f.o)
          void std::__1::vector<TFLComputeTask* __strong, std::__1::allocator<TFLComputeTask* __strong>
          >::__emplace_back_slow_path<TFLComputeTask* __strong&>(TFLComputeTask* __strong&) in
          TensorFlowLiteC(inference_context_0de3088040d9569800f4171c1bc2996f.o)
          std::__1::__tree_iterator<std::__1::__value_type<unsigned int, tflite::gpu::StrongShape<(tflite::gpu::Layout)10> >,
          std::__1::__tree_node<std::__1::__value_type<unsigned int, tflite::gpu::StrongShape<(tflite::gpu::Layout)10> >,
          void*>*, long> std::__1::__tree<std::__1::__value_type<unsigned int,
          tflite::gpu::StrongShape<(tflite::gpu::Layout)10> >, std::__1::__map_value_compare<unsigned int,
          std::__1::__value_type<unsigned int, tflite::gpu::StrongShape<(tflite::gpu::Layout)10> >, std::__1::less<unsigned
          int>, true>, std::__1::allocator<std::__1::__value_type<unsigned int,
          tflite::gpu::StrongShape<(tflite::gpu::Layout)10> > > >::__emplace_hint_unique_key_args<unsigned int,
          std::__1::pair<unsigned int const, tflite::gpu::StrongShape<(tflite::gpu::Layout)10> >
          const&>(std::__1::__tree_const_iterator<std::__1::__value_type<unsigned int,
          tflite::gpu::StrongShape<(tflite::gpu::Layout)10> >, std::__1::__tree_node<std::__1::__value_type<unsigned int,
          tflite::gpu::StrongShape<(tflite::gpu::Layout)10> >, void*>*, long>, unsigned int const&, std::__1::pair<unsigned int
          const, tflite::gpu::StrongShape<(tflite::gpu::Layout)10> > const&) in
          TensorFlowLiteC(inference_context_0de3088040d9569800f4171c1bc2996f.o)
          std::__1::pair<std::__1::__tree_iterator<id<MTLBuffer> __strong, std::__1::__tree_node<id<MTLBuffer> __strong,
          void*>*, long>, bool> std::__1::__tree<std::__1::__value_type<unsigned int, id<MTLBuffer> __strong>,
          std::__1::__map_value_compare<unsigned int, id<MTLBuffer> __strong, std::__1::less<unsigned int>, true>,
          std::__1::allocator<id<MTLBuffer> __strong> >::__emplace_unique_key_args<unsigned int,
          std::__1::piecewise_construct_t const&, std::__1::tuple<unsigned int const&>, std::__1::piecewise_construct_t
          const&<> >(unsigned int const&, std::__1::piecewise_construct_t const&, std::__1::tuple<unsigned int const&>&&,
          std::__1::piecewise_construct_t const&<>&&) in TensorFlowLiteC(inference_context_0de3088040d9569800f4171c1bc2996f.o)
          std::__1::pair<std::__1::__tree_iterator<unsigned int, std::__1::__tree_node<unsigned int, void*>*, long>, bool>
          std::__1::__tree<unsigned int, std::__1::less<unsigned int>, std::__1::allocator<unsigned int>
          >::__emplace_unique_key_args<unsigned int, unsigned int const&>(unsigned int const&, unsigned int const&) in
          TensorFlowLiteC(inference_context_0de3088040d9569800f4171c1bc2996f.o)
          ...
      ""std::__1::ios_base::init(void*)"", referenced from:
          absl::operator<<(std::__1::basic_ostream<char, std::__1::char_traits<char> >&, absl::uint128) in
          TensorFlowLiteC(int128_df0a637a93531d213521c15fc19bd7c1.o)
          absl::time_internal::cctz::TimeZoneInfo::Description() const in
          TensorFlowLiteC(time_zone_info_ac39a6fa55f13bccf521f748f28e02bd.o)
      ""typeinfo for std::length_error"", referenced from:
          std::__1::__throw_length_error(char const*) in TensorFlowLiteC(inference_context_0de3088040d9569800f4171c1bc2996f.o)
          std::__1::__throw_length_error(char const*) in TensorFlowLiteC(compute_task_7d9740b6bb033cffaa24e4dcd6c98207.o)
          std::__1::__throw_length_error(char const*) in TensorFlowLiteC(memory_management_b2355fe02092d3e625e8a39708405196.o)
          std::__1::__throw_length_error(char const*) in TensorFlowLiteC(internal_177af47ac7f30482d4096214acf6ba06.o)
          std::__1::__throw_length_error(char const*) in
          TensorFlowLiteC(min_cost_flow_assignment_3433aed886ccf32d0ddc192b47dca509.o)
          std::__1::__throw_length_error(char const*) in
          TensorFlowLiteC(greedy_by_size_assignment_9fa33a720f1e8acb4a8f6c0d76110984.o)
          std::__1::__throw_length_error(char const*) in
          TensorFlowLiteC(greedy_by_breadth_assignment_9652ad845cf0f94df849627b34cc7bc4.o)
          ...
      ""std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::append(unsigned long, char)"",
      referenced from:
          absl::operator<<(std::__1::basic_ostream<char, std::__1::char_traits<char> >&, absl::uint128) in
          TensorFlowLiteC(int128_df0a637a93531d213521c15fc19bd7c1.o)
          absl::time_internal::cctz::TimeZoneInfo::ResetToBuiltinUTC(std::__1::chrono::duration<long long, std::__1::ratio<1l,
          1l> > const&) in TensorFlowLiteC(time_zone_info_ac39a6fa55f13bccf521f748f28e02bd.o)
      ""std::length_error::~length_error()"", referenced from:
          std::__1::__throw_length_error(char const*) in TensorFlowLiteC(inference_context_0de3088040d9569800f4171c1bc2996f.o)
          std::__1::__throw_length_error(char const*) in TensorFlowLiteC(compute_task_7d9740b6bb033cffaa24e4dcd6c98207.o)
          std::__1::__throw_length_error(char const*) in TensorFlowLiteC(memory_management_b2355fe02092d3e625e8a39708405196.o)
          std::__1::__throw_length_error(char const*) in TensorFlowLiteC(internal_177af47ac7f30482d4096214acf6ba06.o)
          std::__1::__throw_length_error(char const*) in
          TensorFlowLiteC(min_cost_flow_assignment_3433aed886ccf32d0ddc192b47dca509.o)
          std::__1::__throw_length_error(char const*) in
          TensorFlowLiteC(greedy_by_size_assignment_9fa33a720f1e8acb4a8f6c0d76110984.o)
          std::__1::__throw_length_error(char const*) in
          TensorFlowLiteC(greedy_by_breadth_assignment_9652ad845cf0f94df849627b34cc7bc4.o)
          ...
      ""std::__1::ios_base::getloc() const"", referenced from:
          absl::operator<<(std::__1::basic_ostream<char, std::__1::char_traits<char> >&, absl::uint128) in
          TensorFlowLiteC(int128_df0a637a93531d213521c15fc19bd7c1.o)
          std::__1::basic_ostream<char, std::__1::char_traits<char> >& std::__1::__put_character_sequence<char,
          std::__1::char_traits<char> >(std::__1::basic_ostream<char, std::__1::char_traits<char> >&, char const*, unsigned
          long) in TensorFlowLiteC(int128_df0a637a93531d213521c15fc19bd7c1.o)
          std::__1::basic_ostream<char, std::__1::char_traits<char> >& std::__1::__put_character_sequence<char,
          std::__1::char_traits<char> >(std::__1::basic_ostream<char, std::__1::char_traits<char> >&, char const*, unsigned
          long) in TensorFlowLiteC(time_zone_info_ac39a6fa55f13bccf521f748f28e02bd.o)
      ""std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>
      >::basic_string(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, unsigned
      long, unsigned long, std::__1::allocator<char> const&)"", referenced from:
          absl::time_internal::cctz::TimeZoneIf::Load(std::__1::basic_string<char, std::__1::char_traits<char>,
          std::__1::allocator<char> > const&) in TensorFlowLiteC(time_zone_if_b1201e42997e5298e8b9b342eb441cd9.o)
          absl::time_internal::cctz::(anonymous namespace)::FileZoneInfoSource::Open(std::__1::basic_string<char,
          std::__1::char_traits<char>, std::__1::allocator<char> > const&) in
          TensorFlowLiteC(time_zone_info_ac39a6fa55f13bccf521f748f28e02bd.o)
          absl::time_internal::cctz::(anonymous namespace)::AndroidZoneInfoSource::Open(std::__1::basic_string<char,
          std::__1::char_traits<char>, std::__1::allocator<char> > const&) in
          TensorFlowLiteC(time_zone_info_ac39a6fa55f13bccf521f748f28e02bd.o)
      ""___gxx_personality_v0"", referenced from:
          -[TFLBufferConvert initWithDevice:isFloat16:convertToPBHWC4:] in
          TensorFlowLiteC(buffer_convert_1d2d90cc5f78b8992cc785cc8c58fd0c.o)
          -[TFLBufferConvert convertWithEncoder:shape:sourceBuffer:convertedBuffer:] in
          TensorFlowLiteC(buffer_convert_1d2d90cc5f78b8992cc785cc8c58fd0c.o)
          -[TFLInferenceContext compileModelWithDevice:taskDescriptors:outputBufferIDs:runtimeOptions:] in
          TensorFlowLiteC(inference_context_0de3088040d9569800f4171c1bc2996f.o)
          -[TFLInferenceContext setInputDimensions:outputDimensions:taskDescriptors:] in
          TensorFlowLiteC(inference_context_0de3088040d9569800f4171c1bc2996f.o)
          -[TFLInferenceContext encodeWithEncoder:inputOutputBuffers:encoderBlock:] in
          TensorFlowLiteC(inference_context_0de3088040d9569800f4171c1bc2996f.o)
          std::__1::__throw_length_error(char const*) in TensorFlowLiteC(inference_context_0de3088040d9569800f4171c1bc2996f.o)
          std::__1::vector<id<MTLBuffer> __strong, std::__1::allocator<id<MTLBuffer> > >::vector(unsigned long) in
          TensorFlowLiteC(inference_context_0de3088040d9569800f4171c1bc2996f.o)
          ...
      ""std::__1::basic_streambuf<char, std::__1::char_traits<char> >::~basic_streambuf()"", referenced from:
          absl::operator<<(std::__1::basic_ostream<char, std::__1::char_traits<char> >&, absl::uint128) in
          TensorFlowLiteC(int128_df0a637a93531d213521c15fc19bd7c1.o)
          std::__1::basic_ostringstream<char, std::__1::char_traits<char>, std::__1::allocator<char> >::~basic_ostringstream()
          in TensorFlowLiteC(int128_df0a637a93531d213521c15fc19bd7c1.o)
          std::__1::basic_ostringstream<char, std::__1::char_traits<char>, std::__1::allocator<char> >::~basic_ostringstream()
          in TensorFlowLiteC(int128_df0a637a93531d213521c15fc19bd7c1.o)
          virtual thunk to std::__1::basic_ostringstream<char, std::__1::char_traits<char>, std::__1::allocator<char>
          >::~basic_ostringstream() in TensorFlowLiteC(int128_df0a637a93531d213521c15fc19bd7c1.o)
          virtual thunk to std::__1::basic_ostringstream<char, std::__1::char_traits<char>, std::__1::allocator<char>
          >::~basic_ostringstream() in TensorFlowLiteC(int128_df0a637a93531d213521c15fc19bd7c1.o)
          std::__1::basic_stringbuf<char, std::__1::char_traits<char>, std::__1::allocator<char> >::~basic_stringbuf() in
          TensorFlowLiteC(int128_df0a637a93531d213521c15fc19bd7c1.o)
          std::__1::basic_stringbuf<char, std::__1::char_traits<char>, std::__1::allocator<char> >::~basic_stringbuf() in
          TensorFlowLiteC(int128_df0a637a93531d213521c15fc19bd7c1.o)
          ...
      ""std::__1::basic_ostream<char, std::__1::char_traits<char> >::~basic_ostream()"", referenced from:
          absl::operator<<(std::__1::basic_ostream<char, std::__1::char_traits<char> >&, absl::uint128) in
          TensorFlowLiteC(int128_df0a637a93531d213521c15fc19bd7c1.o)
          std::__1::basic_ostringstream<char, std::__1::char_traits<char>, std::__1::allocator<char> >::~basic_ostringstream()
          in TensorFlowLiteC(int128_df0a637a93531d213521c15fc19bd7c1.o)
          std::__1::basic_ostringstream<char, std::__1::char_traits<char>, std::__1::allocator<char> >::~basic_ostringstream()
          in TensorFlowLiteC(int128_df0a637a93531d213521c15fc19bd7c1.o)
          virtual thunk to std::__1::basic_ostringstream<char, std::__1::char_traits<char>, std::__1::allocator<char>
          >::~basic_ostringstream() in TensorFlowLiteC(int128_df0a637a93531d213521c15fc19bd7c1.o)
          virtual thunk to std::__1::basic_ostringstream<char, std::__1::char_traits<char>, std::__1::allocator<char>
          >::~basic_ostringstream() in TensorFlowLiteC(int128_df0a637a93531d213521c15fc19bd7c1.o)
          absl::time_internal::cctz::TimeZoneInfo::Description() const in
          TensorFlowLiteC(time_zone_info_ac39a6fa55f13bccf521f748f28e02bd.o)
          std::__1::basic_ostringstream<char, std::__1::char_traits<char>, std::__1::allocator<char> >::~basic_ostringstream()
          in TensorFlowLiteC(time_zone_info_ac39a6fa55f13bccf521f748f28e02bd.o)
          ...
      ""std::__1::basic_ostream<char, std::__1::char_traits<char> >::operator<<(unsigned long long)"", referenced from:
          absl::operator<<(std::__1::basic_ostream<char, std::__1::char_traits<char> >&, absl::uint128) in
          TensorFlowLiteC(int128_df0a637a93531d213521c15fc19bd7c1.o)
      ""std::__1::thread::hardware_concurrency()"", referenced from:
          absl::base_internal::NumCPUs() in TensorFlowLiteC(sysinfo_7400a2bc43f21361805bc698a3f484fd.o)
          absl::base_internal::NominalCPUFrequency() in TensorFlowLiteC(sysinfo_7400a2bc43f21361805bc698a3f484fd.o)
      ""std::__1::ctype<char>::id"", referenced from:
          absl::operator<<(std::__1::basic_ostream<char, std::__1::char_traits<char> >&, absl::uint128) in
          TensorFlowLiteC(int128_df0a637a93531d213521c15fc19bd7c1.o)
          std::__1::basic_ostream<char, std::__1::char_traits<char> >& std::__1::__put_character_sequence<char,
          std::__1::char_traits<char> >(std::__1::basic_ostream<char, std::__1::char_traits<char> >&, char const*, unsigned
          long) in TensorFlowLiteC(int128_df0a637a93531d213521c15fc19bd7c1.o)
          std::__1::basic_ostream<char, std::__1::char_traits<char> >& std::__1::__put_character_sequence<char,
          std::__1::char_traits<char> >(std::__1::basic_ostream<char, std::__1::char_traits<char> >&, char const*, unsigned
          long) in TensorFlowLiteC(time_zone_info_ac39a6fa55f13bccf521f748f28e02bd.o)
      ""std::__1::chrono::steady_clock::now()"", referenced from:
          absl::base_internal::CycleClock::Now() in TensorFlowLiteC(cycleclock_5b17d6cd121f92a8007a903553fab797.o)
      ""___cxa_begin_catch"", referenced from:
          ___clang_call_terminate in TensorFlowLiteC(compute_task_7d9740b6bb033cffaa24e4dcd6c98207.o)
          std::__1::basic_stringbuf<char, std::__1::char_traits<char>, std::__1::allocator<char> >::overflow(int) in
          TensorFlowLiteC(int128_df0a637a93531d213521c15fc19bd7c1.o)
          std::__1::basic_ostream<char, std::__1::char_traits<char> >& std::__1::__put_character_sequence<char,
          std::__1::char_traits<char> >(std::__1::basic_ostream<char, std::__1::char_traits<char> >&, char const*, unsigned
          long) in TensorFlowLiteC(int128_df0a637a93531d213521c15fc19bd7c1.o)
          std::__1::vector<absl::time_internal::cctz::Transition, std::__1::allocator<absl::time_internal::cctz::Transition>
          >::shrink_to_fit() in TensorFlowLiteC(time_zone_info_ac39a6fa55f13bccf521f748f28e02bd.o)
          std::__1::basic_stringbuf<char, std::__1::char_traits<char>, std::__1::allocator<char> >::overflow(int) in
          TensorFlowLiteC(time_zone_info_ac39a6fa55f13bccf521f748f28e02bd.o)
          std::__1::basic_ostream<char, std::__1::char_traits<char> >& std::__1::__put_character_sequence<char,
          std::__1::char_traits<char> >(std::__1::basic_ostream<char, std::__1::char_traits<char> >&, char const*, unsigned
          long) in TensorFlowLiteC(time_zone_info_ac39a6fa55f13bccf521f748f28e02bd.o)
      ""std::__1::__vector_base_common<true>::__throw_length_error() const"", referenced from:
          std::__1::enable_if<(__is_forward_iterator<unsigned int*>::value) && (is_constructible<unsigned int,
          std::__1::iterator_traits<unsigned int*>::reference>::value), void>::type std::__1::vector<unsigned int,
          std::__1::allocator<unsigned int> >::assign<unsigned int*>(unsigned int*, unsigned int*) in
          TensorFlowLiteC(inference_context_0de3088040d9569800f4171c1bc2996f.o)
          std::__1::vector<unsigned int, std::__1::allocator<unsigned int> >::__vallocate(unsigned long) in
          TensorFlowLiteC(inference_context_0de3088040d9569800f4171c1bc2996f.o)
          void std::__1::vector<TFLComputeTask* __strong, std::__1::allocator<TFLComputeTask* __strong>
          >::__emplace_back_slow_path<TFLComputeTask* __strong&>(TFLComputeTask* __strong&) in
          TensorFlowLiteC(inference_context_0de3088040d9569800f4171c1bc2996f.o)
          void std::__1::vector<tflite::gpu::TensorUsageRecord<unsigned long>,
          std::__1::allocator<tflite::gpu::TensorUsageRecord<unsigned long> > >::__emplace_back_slow_path<int, unsigned int&,
          unsigned int&>(int&&, unsigned int&, unsigned int&) in
          TensorFlowLiteC(inference_context_0de3088040d9569800f4171c1bc2996f.o)
          std::__1::vector<id<MTLBuffer> __strong, std::__1::allocator<id<MTLBuffer> > >::__vallocate(unsigned long) in
          TensorFlowLiteC(inference_context_0de3088040d9569800f4171c1bc2996f.o)
          void std::__1::vector<InputBuffer, std::__1::allocator<InputBuffer>
          >::__emplace_back_slow_path<InputBuffer>(InputBuffer&&) in
          TensorFlowLiteC(compute_task_7d9740b6bb033cffaa24e4dcd6c98207.o)
          void std::__1::vector<UniformBuffer, std::__1::allocator<UniformBuffer>
          >::__emplace_back_slow_path<UniformBuffer>(UniformBuffer&&) in
          TensorFlowLiteC(compute_task_7d9740b6bb033cffaa24e4dcd6c98207.o)
          ...
      ""std::__1::locale::use_facet(std::__1::locale::id&) const"", referenced from:
          absl::operator<<(std::__1::basic_ostream<char, std::__1::char_traits<char> >&, absl::uint128) in
          TensorFlowLiteC(int128_df0a637a93531d213521c15fc19bd7c1.o)
          std::__1::basic_ostream<char, std::__1::char_traits<char> >& std::__1::__put_character_sequence<char,
          std::__1::char_traits<char> >(std::__1::basic_ostream<char, std::__1::char_traits<char> >&, char const*, unsigned
          long) in TensorFlowLiteC(int128_df0a637a93531d213521c15fc19bd7c1.o)
          std::__1::basic_ostream<char, std::__1::char_traits<char> >& std::__1::__put_character_sequence<char,
          std::__1::char_traits<char> >(std::__1::basic_ostream<char, std::__1::char_traits<char> >&, char const*, unsigned
          long) in TensorFlowLiteC(time_zone_info_ac39a6fa55f13bccf521f748f28e02bd.o)
      ""std::__1::__next_prime(unsigned long)"", referenced from:
          std::__1::__hash_table<std::__1::__hash_value_type<std::__1::basic_string<char, std::__1::char_traits<char>,
          std::__1::allocator<char> >, absl::time_internal::cctz::time_zone::Impl const*>,
          std::__1::__unordered_map_hasher<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>
          >, std::__1::__hash_value_type<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >,
          absl::time_internal::cctz::time_zone::Impl const*>, std::__1::hash<std::__1::basic_string<char,
          std::__1::char_traits<char>, std::__1::allocator<char> > >, true>,
          std::__1::__unordered_map_equal<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>
          >, std::__1::__hash_value_type<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >,
          absl::time_internal::cctz::time_zone::Impl const*>, std::__1::equal_to<std::__1::basic_string<char,
          std::__1::char_traits<char>, std::__1::allocator<char> > >, true>,
          std::__1::allocator<std::__1::__hash_value_type<std::__1::basic_string<char, std::__1::char_traits<char>,
          std::__1::allocator<char> >, absl::time_internal::cctz::time_zone::Impl const*> > >::rehash(unsigned long) in
          TensorFlowLiteC(time_zone_impl_70088ae3adaade7bd54e47cd293b4fcc.o)
      ""std::__1::chrono::system_clock::now()"", referenced from:
          absl::Now() in TensorFlowLiteC(clock_59d4d44bffb6d368cb7c779169be0652.o)
          absl::GetCurrentTimeNanos() in TensorFlowLiteC(clock_59d4d44bffb6d368cb7c779169be0652.o)
      ""std::__1::basic_streambuf<char, std::__1::char_traits<char> >::showmanyc()"", referenced from:
          vtable for std::__1::basic_stringbuf<char, std::__1::char_traits<char>, std::__1::allocator<char> > in
          TensorFlowLiteC(int128_df0a637a93531d213521c15fc19bd7c1.o)
          vtable for std::__1::basic_stringbuf<char, std::__1::char_traits<char>, std::__1::allocator<char> > in
          TensorFlowLiteC(time_zone_info_ac39a6fa55f13bccf521f748f28e02bd.o)
      ""std::__1::ios_base::__set_badbit_and_consider_rethrow()"", referenced from:
          std::__1::basic_ostream<char, std::__1::char_traits<char> >& std::__1::__put_character_sequence<char,
          std::__1::char_traits<char> >(std::__1::basic_ostream<char, std::__1::char_traits<char> >&, char const*, unsigned
          long) in TensorFlowLiteC(int128_df0a637a93531d213521c15fc19bd7c1.o)
          std::__1::basic_ostream<char, std::__1::char_traits<char> >& std::__1::__put_character_sequence<char,
          std::__1::char_traits<char> >(std::__1::basic_ostream<char, std::__1::char_traits<char> >&, char const*, unsigned
          long) in TensorFlowLiteC(time_zone_info_ac39a6fa55f13bccf521f748f28e02bd.o)
      ""___cxa_guard_acquire"", referenced from:
          absl::container_internal::Sample() in TensorFlowLiteC(memory_management_b2355fe02092d3e625e8a39708405196.o)
          absl::container_internal::HashtablezSampler::Global() in
          TensorFlowLiteC(hashtablez_sampler_f7a58fda31cdb479dd28749081bd30a1.o)
          absl::time_internal::cctz::time_zone::Impl::UTCImpl() in
          TensorFlowLiteC(time_zone_impl_70088ae3adaade7bd54e47cd293b4fcc.o)
          absl::time_internal::cctz::TimeZoneLibC::MakeTime(absl::time_internal::cctz::detail::civil_time<absl::time_internal::
          cctz::detail::second_tag> const&) const in TensorFlowLiteC(time_zone_libc_1c4053d35db44a839fcd158b0a3f97d5.o)
      ""std::__1::basic_ios<char, std::__1::char_traits<char> >::~basic_ios()"", referenced from:
          absl::operator<<(std::__1::basic_ostream<char, std::__1::char_traits<char> >&, absl::uint128) in
          TensorFlowLiteC(int128_df0a637a93531d213521c15fc19bd7c1.o)
          std::__1::basic_ostringstream<char, std::__1::char_traits<char>, std::__1::allocator<char> >::~basic_ostringstream()
          in TensorFlowLiteC(int128_df0a637a93531d213521c15fc19bd7c1.o)
          std::__1::basic_ostringstream<char, std::__1::char_traits<char>, std::__1::allocator<char> >::~basic_ostringstream()
          in TensorFlowLiteC(int128_df0a637a93531d213521c15fc19bd7c1.o)
          virtual thunk to std::__1::basic_ostringstream<char, std::__1::char_traits<char>, std::__1::allocator<char>
          >::~basic_ostringstream() in TensorFlowLiteC(int128_df0a637a93531d213521c15fc19bd7c1.o)
          virtual thunk to std::__1::basic_ostringstream<char, std::__1::char_traits<char>, std::__1::allocator<char>
          >::~basic_ostringstream() in TensorFlowLiteC(int128_df0a637a93531d213521c15fc19bd7c1.o)
          absl::time_internal::cctz::TimeZoneInfo::Description() const in
          TensorFlowLiteC(time_zone_info_ac39a6fa55f13bccf521f748f28e02bd.o)
          std::__1::basic_ostringstream<char, std::__1::char_traits<char>, std::__1::allocator<char> >::~basic_ostringstream()
          in TensorFlowLiteC(time_zone_info_ac39a6fa55f13bccf521f748f28e02bd.o)
          ...
      ""___cxa_guard_abort"", referenced from:
          absl::container_internal::Sample() in TensorFlowLiteC(memory_management_b2355fe02092d3e625e8a39708405196.o)
          absl::container_internal::HashtablezSampler::Global() in
          TensorFlowLiteC(hashtablez_sampler_f7a58fda31cdb479dd28749081bd30a1.o)
          absl::time_internal::cctz::time_zone::Impl::UTCImpl() in
          TensorFlowLiteC(time_zone_impl_70088ae3adaade7bd54e47cd293b4fcc.o)
      ""std::__1::__basic_string_common<true>::__throw_length_error() const"", referenced from:
          std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>
          >::basic_string<std::nullptr_t>(char const*) in TensorFlowLiteC(compute_task_7d9740b6bb033cffaa24e4dcd6c98207.o)
          std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>
          >::basic_string<std::nullptr_t>(char const*) in TensorFlowLiteC(common_cd6e0002c2cc438c490b1d8b3375cdd6.o)
          std::__1::basic_stringbuf<char, std::__1::char_traits<char>, std::__1::allocator<char> >::str() const in
          TensorFlowLiteC(int128_df0a637a93531d213521c15fc19bd7c1.o)
          absl::time_internal::cctz::local_time_zone() in TensorFlowLiteC(time_zone_lookup_1013b5b9ce7824eb44fb9b51c7e98f70.o)
          absl::time_internal::cctz::FixedOffsetToName(std::__1::chrono::duration<long long, std::__1::ratio<1l, 1l> > const&)
          in TensorFlowLiteC(time_zone_fixed_12d6eb8ff52945a37ee8f97c1ea02823.o)
          absl::time_internal::cctz::(anonymous namespace)::AndroidZoneInfoSource::Open(std::__1::basic_string<char,
          std::__1::char_traits<char>, std::__1::allocator<char> > const&) in
          TensorFlowLiteC(time_zone_info_ac39a6fa55f13bccf521f748f28e02bd.o)
          std::__1::basic_stringbuf<char, std::__1::char_traits<char>, std::__1::allocator<char> >::str() const in
          TensorFlowLiteC(time_zone_info_ac39a6fa55f13bccf521f748f28e02bd.o)
          ...
      ""std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::insert(unsigned long, unsigned
      long, char)"", referenced from:
          absl::operator<<(std::__1::basic_ostream<char, std::__1::char_traits<char> >&, absl::uint128) in
          TensorFlowLiteC(int128_df0a637a93531d213521c15fc19bd7c1.o)
      ""std::exception::what() const"", referenced from:
          vtable for std::__1::bad_function_call in TensorFlowLiteC(compute_task_7d9740b6bb033cffaa24e4dcd6c98207.o)
          vtable for std::__1::bad_function_call in TensorFlowLiteC(hashtablez_sampler_f7a58fda31cdb479dd28749081bd30a1.o)
          vtable for std::__1::bad_function_call in TensorFlowLiteC(zone_info_source_d0d641f6600cbc71bed9faf61afe560f.o)
      ""std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::assign(char const*)"", referenced
      from:
          -[TFLBufferConvert initWithDevice:isFloat16:convertToPBHWC4:] in
          TensorFlowLiteC(buffer_convert_1d2d90cc5f78b8992cc785cc8c58fd0c.o)
          absl::FormatDuration(absl::Duration) in TensorFlowLiteC(duration_23d5e2ad34b3d4e9d4db6be0369385c2.o)
      ""vtable for __cxxabiv1::__si_class_type_info"", referenced from:
          typeinfo for std::__1::bad_function_call in TensorFlowLiteC(compute_task_7d9740b6bb033cffaa24e4dcd6c98207.o)
          typeinfo for std::__1::bad_function_call in TensorFlowLiteC(hashtablez_sampler_f7a58fda31cdb479dd28749081bd30a1.o)
          typeinfo for std::__1::basic_ostringstream<char, std::__1::char_traits<char>, std::__1::allocator<char> > in
          TensorFlowLiteC(int128_df0a637a93531d213521c15fc19bd7c1.o)
          typeinfo for std::__1::basic_stringbuf<char, std::__1::char_traits<char>, std::__1::allocator<char> > in
          TensorFlowLiteC(int128_df0a637a93531d213521c15fc19bd7c1.o)
          typeinfo for absl::time_internal::cctz::TimeZoneInfo in
          TensorFlowLiteC(time_zone_info_ac39a6fa55f13bccf521f748f28e02bd.o)
          typeinfo for std::__1::basic_ostringstream<char, std::__1::char_traits<char>, std::__1::allocator<char> > in
          TensorFlowLiteC(time_zone_info_ac39a6fa55f13bccf521f748f28e02bd.o)
          typeinfo for std::__1::basic_stringbuf<char, std::__1::char_traits<char>, std::__1::allocator<char> > in
          TensorFlowLiteC(time_zone_info_ac39a6fa55f13bccf521f748f28e02bd.o)
          ...
      NOTE: a missing vtable usually means the first non-inline virtual member function has no definition.
      ""std::__1::__vector_base_common<true>::__throw_out_of_range() const"", referenced from:
          -[TFLComputeTask assignBuffers:outputIds:usageRecordIds:sharedBufferIds:sharedBuffers:] in
          TensorFlowLiteC(compute_task_7d9740b6bb033cffaa24e4dcd6c98207.o)
      ""std::exception::~exception()"", referenced from:
          std::__1::bad_function_call::~bad_function_call() in TensorFlowLiteC(compute_task_7d9740b6bb033cffaa24e4dcd6c98207.o)
          std::__1::bad_function_call::~bad_function_call() in TensorFlowLiteC(compute_task_7d9740b6bb033cffaa24e4dcd6c98207.o)
          std::__1::bad_function_call::~bad_function_call() in
          TensorFlowLiteC(hashtablez_sampler_f7a58fda31cdb479dd28749081bd30a1.o)
          std::__1::bad_function_call::~bad_function_call() in
          TensorFlowLiteC(hashtablez_sampler_f7a58fda31cdb479dd28749081bd30a1.o)
          std::__1::bad_function_call::~bad_function_call() in
          TensorFlowLiteC(zone_info_source_d0d641f6600cbc71bed9faf61afe560f.o)
          std::__1::bad_function_call::~bad_function_call() in
          TensorFlowLiteC(zone_info_source_d0d641f6600cbc71bed9faf61afe560f.o)
      ""std::__1::to_string(unsigned int)"", referenced from:
          -[TFLComputeTask setInputDimensionsWithDevice:dimensions:] in
          TensorFlowLiteC(compute_task_7d9740b6bb033cffaa24e4dcd6c98207.o)
      ""std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::append(char const*)"", referenced
      from:
          -[TFLComputeTask setInputDimensionsWithDevice:dimensions:] in
          TensorFlowLiteC(compute_task_7d9740b6bb033cffaa24e4dcd6c98207.o)
          absl::FormatDuration(absl::Duration) in TensorFlowLiteC(duration_23d5e2ad34b3d4e9d4db6be0369385c2.o)
          absl::(anonymous namespace)::AppendNumberUnit(std::__1::basic_string<char, std::__1::char_traits<char>,
          std::__1::allocator<char> >*, double, absl::(anonymous namespace)::DisplayUnit) in
          TensorFlowLiteC(duration_23d5e2ad34b3d4e9d4db6be0369385c2.o)
          absl::time_internal::cctz::(anonymous namespace)::FileZoneInfoSource::Open(std::__1::basic_string<char,
          std::__1::char_traits<char>, std::__1::allocator<char> > const&) in
          TensorFlowLiteC(time_zone_info_ac39a6fa55f13bccf521f748f28e02bd.o)
      ""std::__1::to_string(unsigned long)"", referenced from:
          -[TFLComputeTask setInputDimensionsWithDevice:dimensions:] in
          TensorFlowLiteC(compute_task_7d9740b6bb033cffaa24e4dcd6c98207.o)
      ""vtable for std::length_error"", referenced from:
          std::length_error::length_error(char const*) in TensorFlowLiteC(inference_context_0de3088040d9569800f4171c1bc2996f.o)
          std::length_error::length_error(char const*) in TensorFlowLiteC(compute_task_7d9740b6bb033cffaa24e4dcd6c98207.o)
          std::length_error::length_error(char const*) in TensorFlowLiteC(memory_management_b2355fe02092d3e625e8a39708405196.o)
          std::length_error::length_error(char const*) in TensorFlowLiteC(internal_177af47ac7f30482d4096214acf6ba06.o)
          std::length_error::length_error(char const*) in
          TensorFlowLiteC(min_cost_flow_assignment_3433aed886ccf32d0ddc192b47dca509.o)
          std::length_error::length_error(char const*) in
          TensorFlowLiteC(greedy_by_size_assignment_9fa33a720f1e8acb4a8f6c0d76110984.o)
          std::length_error::length_error(char const*) in
          TensorFlowLiteC(greedy_by_breadth_assignment_9652ad845cf0f94df849627b34cc7bc4.o)
          ...
      NOTE: a missing vtable usually means the first non-inline virtual member function has no definition.
      ""___cxa_allocate_exception"", referenced from:
          std::__1::__throw_length_error(char const*) in TensorFlowLiteC(inference_context_0de3088040d9569800f4171c1bc2996f.o)
          std::__1::__throw_length_error(char const*) in TensorFlowLiteC(compute_task_7d9740b6bb033cffaa24e4dcd6c98207.o)
          std::__1::__throw_bad_function_call() in TensorFlowLiteC(compute_task_7d9740b6bb033cffaa24e4dcd6c98207.o)
          std::__1::__throw_length_error(char const*) in TensorFlowLiteC(memory_management_b2355fe02092d3e625e8a39708405196.o)
          std::__1::__throw_bad_function_call() in TensorFlowLiteC(hashtablez_sampler_f7a58fda31cdb479dd28749081bd30a1.o)
          std::__1::__throw_length_error(char const*) in TensorFlowLiteC(internal_177af47ac7f30482d4096214acf6ba06.o)
          std::__1::__throw_length_error(char const*) in
          TensorFlowLiteC(min_cost_flow_assignment_3433aed886ccf32d0ddc192b47dca509.o)
          ...
      ""std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::compare(unsigned long, unsigned
      long, char const*, unsigned long) const"", referenced from:
          absl::FormatDuration(absl::Duration) in TensorFlowLiteC(duration_23d5e2ad34b3d4e9d4db6be0369385c2.o)
          absl::time_internal::cctz::FixedOffsetFromName(std::__1::basic_string<char, std::__1::char_traits<char>,
          std::__1::allocator<char> > const&, std::__1::chrono::duration<long long, std::__1::ratio<1l, 1l> >*) in
          TensorFlowLiteC(time_zone_fixed_12d6eb8ff52945a37ee8f97c1ea02823.o)
          absl::time_internal::cctz::TimeZoneInfo::CheckTransition(std::__1::basic_string<char, std::__1::char_traits<char>,
          std::__1::allocator<char> > const&, absl::time_internal::cctz::TransitionType const&, int, bool,
          std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&) const in
          TensorFlowLiteC(time_zone_info_ac39a6fa55f13bccf521f748f28e02bd.o)
          absl::time_internal::cctz::TimeZoneLibC::TimeZoneLibC(std::__1::basic_string<char, std::__1::char_traits<char>,
          std::__1::allocator<char> > const&) in TensorFlowLiteC(time_zone_libc_1c4053d35db44a839fcd158b0a3f97d5.o)
          absl::time_internal::cctz::TimeZoneLibC::TimeZoneLibC(std::__1::basic_string<char, std::__1::char_traits<char>,
          std::__1::allocator<char> > const&) in TensorFlowLiteC(time_zone_libc_1c4053d35db44a839fcd158b0a3f97d5.o)
      ""std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::push_back(char)"", referenced
      from:
          absl::(anonymous namespace)::AppendNumberUnit(std::__1::basic_string<char, std::__1::char_traits<char>,
          std::__1::allocator<char> >*, double, absl::(anonymous namespace)::DisplayUnit) in
          TensorFlowLiteC(duration_23d5e2ad34b3d4e9d4db6be0369385c2.o)
          std::__1::basic_stringbuf<char, std::__1::char_traits<char>, std::__1::allocator<char> >::overflow(int) in
          TensorFlowLiteC(int128_df0a637a93531d213521c15fc19bd7c1.o)
          absl::time_internal::cctz::TimeZoneInfo::Load(std::__1::basic_string<char, std::__1::char_traits<char>,
          std::__1::allocator<char> > const&, absl::time_internal::cctz::ZoneInfoSource*) in
          TensorFlowLiteC(time_zone_info_ac39a6fa55f13bccf521f748f28e02bd.o)
          std::__1::basic_stringbuf<char, std::__1::char_traits<char>, std::__1::allocator<char> >::overflow(int) in
          TensorFlowLiteC(time_zone_info_ac39a6fa55f13bccf521f748f28e02bd.o)
          absl::time_internal::cctz::(anonymous namespace)::FileZoneInfoSource::Open(std::__1::basic_string<char,
          std::__1::char_traits<char>, std::__1::allocator<char> > const&) in
          TensorFlowLiteC(time_zone_info_ac39a6fa55f13bccf521f748f28e02bd.o)
      ""std::terminate()"", referenced from:
          ___clang_call_terminate in TensorFlowLiteC(compute_task_7d9740b6bb033cffaa24e4dcd6c98207.o)
      ""std::__1::chrono::system_clock::from_time_t(long)"", referenced from:
          absl::Now() in TensorFlowLiteC(clock_59d4d44bffb6d368cb7c779169be0652.o)
          absl::GetCurrentTimeNanos() in TensorFlowLiteC(clock_59d4d44bffb6d368cb7c779169be0652.o)
          absl::Time::In(absl::TimeZone) const in TensorFlowLiteC(time_663724b99f08c35ff81d5280df9c0131.o)
          absl::FromChrono(std::__1::chrono::time_point<std::__1::chrono::system_clock, std::__1::chrono::duration<long long,
          std::__1::ratio<1l, 1000000l> > > const&) in TensorFlowLiteC(time_663724b99f08c35ff81d5280df9c0131.o)
          absl::ToChronoTime(absl::Time) in TensorFlowLiteC(time_663724b99f08c35ff81d5280df9c0131.o)
          absl::TimeZone::At(absl::Time) const in TensorFlowLiteC(time_663724b99f08c35ff81d5280df9c0131.o)
          absl::(anonymous namespace)::MakeTimeWithOverflow(std::__1::chrono::time_point<std::__1::chrono::system_clock,
          std::__1::chrono::duration<long long, std::__1::ratio<1l, 1l> > > const&,
          absl::time_internal::cctz::detail::civil_time<absl::time_internal::cctz::detail::second_tag> const&,
          absl::time_internal::cctz::time_zone const&, bool*) in TensorFlowLiteC(time_663724b99f08c35ff81d5280df9c0131.o)
          ...
      ""typeinfo for std::__1::basic_ostream<char, std::__1::char_traits<char> >"", referenced from:
          construction vtable for std::__1::basic_ostream<char, std::__1::char_traits<char>
          >-in-std::__1::basic_ostringstream<char, std::__1::char_traits<char>, std::__1::allocator<char> > in
          TensorFlowLiteC(int128_df0a637a93531d213521c15fc19bd7c1.o)
          typeinfo for std::__1::basic_ostringstream<char, std::__1::char_traits<char>, std::__1::allocator<char> > in
          TensorFlowLiteC(int128_df0a637a93531d213521c15fc19bd7c1.o)
          construction vtable for std::__1::basic_ostream<char, std::__1::char_traits<char>
          >-in-std::__1::basic_ostringstream<char, std::__1::char_traits<char>, std::__1::allocator<char> > in
          TensorFlowLiteC(time_zone_info_ac39a6fa55f13bccf521f748f28e02bd.o)
          typeinfo for std::__1::basic_ostringstream<char, std::__1::char_traits<char>, std::__1::allocator<char> > in
          TensorFlowLiteC(time_zone_info_ac39a6fa55f13bccf521f748f28e02bd.o)
      ""std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char>
      >::basic_string(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&)"",
      referenced from:
          -[TFLInferenceContext setInputDimensions:outputDimensions:taskDescriptors:] in
          TensorFlowLiteC(inference_context_0de3088040d9569800f4171c1bc2996f.o)
          -[TFLComputeTask compileWithDevice:taskDescriptor:runtimeOptions:] in
          TensorFlowLiteC(compute_task_7d9740b6bb033cffaa24e4dcd6c98207.o)
          -[TFLComputeTask setInputDimensionsWithDevice:dimensions:] in
          TensorFlowLiteC(compute_task_7d9740b6bb033cffaa24e4dcd6c98207.o)
          -[TFLComputeTask assignBuffers:outputIds:usageRecordIds:sharedBufferIds:sharedBuffers:] in
          TensorFlowLiteC(compute_task_7d9740b6bb033cffaa24e4dcd6c98207.o)
          tflite::gpu::Status tflite::gpu::AssignObjectsToTensors<unsigned
          long>(std::__1::vector<tflite::gpu::TensorUsageRecord<unsigned long>,
          std::__1::allocator<tflite::gpu::TensorUsageRecord<unsigned long> > > const&, tflite::gpu::MemoryStrategy,
          tflite::gpu::ObjectsAssignment<unsigned long>*, std::__1::vector<std::__1::vector<unsigned long,
          std::__1::allocator<unsigned long> >, std::__1::allocator<std::__1::vector<unsigned long,
          std::__1::allocator<unsigned long> > > > const*) in
          TensorFlowLiteC(memory_management_b2355fe02092d3e625e8a39708405196.o)
          tflite::gpu::Status tflite::gpu::GreedyInOrderAssignment<unsigned
          long>(std::__1::vector<tflite::gpu::TensorUsageRecord<unsigned long>,
          std::__1::allocator<tflite::gpu::TensorUsageRecord<unsigned long> > > const&, tflite::gpu::ObjectsAssignment<unsigned
          long>*, std::__1::vector<std::__1::vector<unsigned long, std::__1::allocator<unsigned long> >,
          std::__1::allocator<std::__1::vector<unsigned long, std::__1::allocator<unsigned long> > > > const*) in
          TensorFlowLiteC(memory_management_b2355fe02092d3e625e8a39708405196.o)
          tflite::gpu::Status tflite::gpu::AssignObjectsToTensors<tflite::gpu::StrongShape<(tflite::gpu::Layout)10>
          >(std::__1::vector<tflite::gpu::TensorUsageRecord<tflite::gpu::StrongShape<(tflite::gpu::Layout)10> >,
          std::__1::allocator<tflite::gpu::TensorUsageRecord<tflite::gpu::StrongShape<(tflite::gpu::Layout)10> > > > const&,
          tflite::gpu::MemoryStrategy, tflite::gpu::ObjectsAssignment<tflite::gpu::StrongShape<(tflite::gpu::Layout)10> >*,
          std::__1::vector<std::__1::vector<unsigned long, std::__1::allocator<unsigned long> >,
          std::__1::allocator<std::__1::vector<unsigned long, std::__1::allocator<unsigned long> > > > const*) in
          TensorFlowLiteC(memory_management_b2355fe02092d3e625e8a39708405196.o)
          ...
      ""std::__1::basic_streambuf<char, std::__1::char_traits<char> >::basic_streambuf()"", referenced from:
          absl::operator<<(std::__1::basic_ostream<char, std::__1::char_traits<char> >&, absl::uint128) in
          TensorFlowLiteC(int128_df0a637a93531d213521c15fc19bd7c1.o)
          absl::time_internal::cctz::TimeZoneInfo::Description() const in
          TensorFlowLiteC(time_zone_info_ac39a6fa55f13bccf521f748f28e02bd.o)
      ""___cxa_free_exception"", referenced from:
          std::__1::__throw_length_error(char const*) in TensorFlowLiteC(inference_context_0de3088040d9569800f4171c1bc2996f.o)
          std::__1::__throw_length_error(char const*) in TensorFlowLiteC(compute_task_7d9740b6bb033cffaa24e4dcd6c98207.o)
          std::__1::__throw_length_error(char const*) in TensorFlowLiteC(memory_management_b2355fe02092d3e625e8a39708405196.o)
          std::__1::__throw_length_error(char const*) in TensorFlowLiteC(internal_177af47ac7f30482d4096214acf6ba06.o)
          std::__1::__throw_length_error(char const*) in
          TensorFlowLiteC(min_cost_flow_assignment_3433aed886ccf32d0ddc192b47dca509.o)
          std::__1::__throw_length_error(char const*) in
          TensorFlowLiteC(greedy_by_size_assignment_9fa33a720f1e8acb4a8f6c0d76110984.o)
          std::__1::__throw_length_error(char const*) in
          TensorFlowLiteC(greedy_by_breadth_assignment_9652ad845cf0f94df849627b34cc7bc4.o)
          ...
      ""std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >::append(char const*, unsigned
      long)"", referenced from:
          -[TFLComputeTask setInputDimensionsWithDevice:dimensions:] in
          TensorFlowLiteC(compute_task_7d9740b6bb033cffaa24e4dcd6c98207.o)
          absl::FormatDuration(absl::Duration) in TensorFlowLiteC(duration_23d5e2ad34b3d4e9d4db6be0369385c2.o)
          absl::(anonymous namespace)::AppendNumberUnit(std::__1::basic_string<char, std::__1::char_traits<char>,
          std::__1::allocator<char> >*, double, absl::(anonymous namespace)::DisplayUnit) in
          TensorFlowLiteC(duration_23d5e2ad34b3d4e9d4db6be0369385c2.o)
          absl::time_internal::cctz::(anonymous namespace)::FileZoneInfoSource::Open(std::__1::basic_string<char,
          std::__1::char_traits<char>, std::__1::allocator<char> > const&) in
          TensorFlowLiteC(time_zone_info_ac39a6fa55f13bccf521f748f28e02bd.o)
      ""std::__1::__shared_weak_count::__release_weak()"", referenced from:
          -[TFLInferenceContext compileModelWithDevice:taskDescriptors:outputBufferIDs:runtimeOptions:] in
          TensorFlowLiteC(inference_context_0de3088040d9569800f4171c1bc2996f.o)
      ""___cxa_throw"", referenced from:
          std::__1::__throw_length_error(char const*) in TensorFlowLiteC(inference_context_0de3088040d9569800f4171c1bc2996f.o)
          std::__1::__throw_length_error(char const*) in TensorFlowLiteC(compute_task_7d9740b6bb033cffaa24e4dcd6c98207.o)
          std::__1::__throw_bad_function_call() in TensorFlowLiteC(compute_task_7d9740b6bb033cffaa24e4dcd6c98207.o)
          std::__1::__throw_length_error(char const*) in TensorFlowLiteC(memory_management_b2355fe02092d3e625e8a39708405196.o)
          std::__1::__throw_bad_function_call() in TensorFlowLiteC(hashtablez_sampler_f7a58fda31cdb479dd28749081bd30a1.o)
          std::__1::__throw_length_error(char const*) in TensorFlowLiteC(internal_177af47ac7f30482d4096214acf6ba06.o)
          std::__1::__throw_length_error(char const*) in
          TensorFlowLiteC(min_cost_flow_assignment_3433aed886ccf32d0ddc192b47dca509.o)
          ...
      ""std::__1::locale::~locale()"", referenced from:
          absl::operator<<(std::__1::basic_ostream<char, std::__1::char_traits<char> >&, absl::uint128) in
          TensorFlowLiteC(int128_df0a637a93531d213521c15fc19bd7c1.o)
          std::__1::basic_ostream<char, std::__1::char_traits<char> >& std::__1::__put_character_sequence<char,
          std::__1::char_traits<char> >(std::__1::basic_ostream<char, std::__1::char_traits<char> >&, char const*, unsigned
          long) in TensorFlowLiteC(int128_df0a637a93531d213521c15fc19bd7c1.o)
          std::__1::basic_ostream<char, std::__1::char_traits<char> >& std::__1::__put_character_sequence<char,
          std::__1::char_traits<char> >(std::__1::basic_ostream<char, std::__1::char_traits<char> >&, char const*, unsigned
          long) in TensorFlowLiteC(time_zone_info_ac39a6fa55f13bccf521f748f28e02bd.o)
      ""std::logic_error::logic_error(char const*)"", referenced from:
          std::length_error::length_error(char const*) in TensorFlowLiteC(inference_context_0de3088040d9569800f4171c1bc2996f.o)
          std::length_error::length_error(char const*) in TensorFlowLiteC(compute_task_7d9740b6bb033cffaa24e4dcd6c98207.o)
          std::length_error::length_error(char const*) in TensorFlowLiteC(memory_management_b2355fe02092d3e625e8a39708405196.o)
          std::length_error::length_error(char const*) in TensorFlowLiteC(internal_177af47ac7f30482d4096214acf6ba06.o)
          std::length_error::length_error(char const*) in
          TensorFlowLiteC(min_cost_flow_assignment_3433aed886ccf32d0ddc192b47dca509.o)
          std::length_error::length_error(char const*) in
          TensorFlowLiteC(greedy_by_size_assignment_9fa33a720f1e8acb4a8f6c0d76110984.o)
          std::length_error::length_error(char const*) in
          TensorFlowLiteC(greedy_by_breadth_assignment_9652ad845cf0f94df849627b34cc7bc4.o)
          ...
      ""typeinfo for std::exception"", referenced from:
          typeinfo for std::__1::bad_function_call in TensorFlowLiteC(compute_task_7d9740b6bb033cffaa24e4dcd6c98207.o)
          typeinfo for std::__1::bad_function_call in TensorFlowLiteC(hashtablez_sampler_f7a58fda31cdb479dd28749081bd30a1.o)
          typeinfo for std::__1::bad_function_call in TensorFlowLiteC(zone_info_source_d0d641f6600cbc71bed9faf61afe560f.o)
      ""___cxa_guard_release"", referenced from:
          absl::container_internal::Sample() in TensorFlowLiteC(memory_management_b2355fe02092d3e625e8a39708405196.o)
          absl::container_internal::HashtablezSampler::Global() in
          TensorFlowLiteC(hashtablez_sampler_f7a58fda31cdb479dd28749081bd30a1.o)
          absl::time_internal::cctz::time_zone::Impl::UTCImpl() in
          TensorFlowLiteC(time_zone_impl_70088ae3adaade7bd54e47cd293b4fcc.o)
          absl::time_internal::cctz::TimeZoneLibC::MakeTime(absl::time_internal::cctz::detail::civil_time<absl::time_internal::
          cctz::detail::second_tag> const&) const in TensorFlowLiteC(time_zone_libc_1c4053d35db44a839fcd158b0a3f97d5.o)
      ""___cxa_pure_virtual"", referenced from:
          vtable for absl::time_internal::cctz::TimeZoneIf in TensorFlowLiteC(time_zone_if_b1201e42997e5298e8b9b342eb441cd9.o)
          vtable for absl::time_internal::cctz::ZoneInfoSource in
          TensorFlowLiteC(zone_info_source_d0d641f6600cbc71bed9faf61afe560f.o)
      ""operator delete(void*)"", referenced from:
          -[TFLBufferConvert initWithDevice:isFloat16:convertToPBHWC4:] in
          TensorFlowLiteC(buffer_convert_1d2d90cc5f78b8992cc785cc8c58fd0c.o)
          -[TFLBufferConvert convertWithEncoder:shape:sourceBuffer:convertedBuffer:] in
          TensorFlowLiteC(buffer_convert_1d2d90cc5f78b8992cc785cc8c58fd0c.o)
          -[TFLInferenceContext compileModelWithDevice:taskDescriptors:outputBufferIDs:runtimeOptions:] in
          TensorFlowLiteC(inference_context_0de3088040d9569800f4171c1bc2996f.o)
          -[TFLInferenceContext setInputDimensions:outputDimensions:taskDescriptors:] in
          TensorFlowLiteC(inference_context_0de3088040d9569800f4171c1bc2996f.o)
          -[TFLInferenceContext .cxx_destruct] in TensorFlowLiteC(inference_context_0de3088040d9569800f4171c1bc2996f.o)
          std::__1::__tree<std::__1::__value_type<unsigned int, unsigned long>, std::__1::__map_value_compare<unsigned int,
          std::__1::__value_type<unsigned int, unsigned long>, std::__1::less<unsigned int>, true>,
          std::__1::allocator<std::__1::__value_type<unsigned int, unsigned long> >
          >::destroy(std::__1::__tree_node<std::__1::__value_type<unsigned int, unsigned long>, void*>*) in
          TensorFlowLiteC(inference_context_0de3088040d9569800f4171c1bc2996f.o)
          std::__1::__tree<unsigned int, std::__1::less<unsigned int>, std::__1::allocator<unsigned int>
          >::destroy(std::__1::__tree_node<unsigned int, void*>*) in
          TensorFlowLiteC(inference_context_0de3088040d9569800f4171c1bc2996f.o)
          ...
    ld: symbol(s) not found for architecture x86_64
    clang: error: linker command failed with exit code 1 (use -v to see invocation)
    note: Using new build systemnote: Planning buildnote: Constructing build description

Could not build the application for the simulator.
Error launching application on iPhone 11 Pro Max.
</pre>
</details>"
36764,tf.linalg.svd not supporting tf.half as dtype on Windows CPU with python3.5,"Hello!

I am currently writing a test file for an optimizer toward tensorflow_addons. I use tf.linalg.svd function in the test file and I test with the case of using tf.half as dtype. 

The test can pass the given CI test with Mac CPU python 3.5 and Ubuntu CPU python 3. But for the given CI test on Windows CPU with python3.5, it throws following error message: 

""
ERROR:tensorflow:No OpKernel was registered to support Op 'Svd' used by node Svd (defined at \\?\C:\Users\RUNNER~1\AppData\Local\Temp\Bazel.runfiles_pt5sug_g\runfiles\__main__\tensorflow_addons\optimizers\conditional_gradient_test.py:37) with these attrs: [full_matrices=false, compute_uv=true, T=DT_HALF]

Registered devices: [CPU]

Registered kernels:

  device='CPU'; T in [DT_FLOAT]

  device='CPU'; T in [DT_DOUBLE]

  device='CPU'; T in [DT_COMPLEX64]

  device='CPU'; T in [DT_COMPLEX128]

  device='GPU'; T in [DT_FLOAT]

  device='GPU'; T in [DT_DOUBLE]



	 [[Svd]]
""

The code I am running with is as following:
""
def top_singular_vector( m):
        # handle the case where m is a tensor of rank 0 or rank 1.
        n = tf.cond(
            tf.equal(tf.rank(m), 0),
            lambda: tf.expand_dims(tf.expand_dims(m, [0]), [0]),
            lambda: m,
        )
        n = tf.cond(tf.equal(tf.rank(m), 1), lambda: tf.expand_dims(m, [0]), lambda: n,)
        st, ut, vt = tf.linalg.svd(n, full_matrices=False)
        m_size = tf.shape(n)
        ut = tf.reshape(ut[:, 0], [m_size[0], 1])
        vt = tf.reshape(vt[:, 0], [m_size[1], 1])
        st = tf.matmul(ut, tf.transpose(vt))
        # when we return the top singular vector, we have to remove the
        # dimension we have added on
        st = tf.cond(
            tf.equal(tf.rank(m), 0),
            lambda: tf.squeeze(tf.squeeze(st, [0]), [0]),
            lambda: st,
        )
        st = tf.cond(tf.equal(tf.rank(m), 1), lambda: tf.squeeze(st, [0]), lambda: st,)
        return st

grads0 = tf.constant([0.1, 0.1], dtype=tf.half)
grads1 = tf.constant([0.01, 0.01], dtype=tf.half)
top_singular_vector0 = top_singular_vector(grads0)
top_singular_vector1 = top_singular_vector(grads1)
""

It will be great if tf.linalg.svd function can have more compatible or similar behavior on dtype over different systems.

Thank you!
"
36763,Missing dependencies in image_classification android example for instrumented test ClassifierTest,"**Describe the problem**

**Provide the exact sequence of commands / steps that you executed before running into the problem**

In the tensorflow lite image classification example for android; gradle dependencies for the instrumented test have to be added
 
https://github.com/tensorflow/examples/blob/master/lite/examples/image_classification/android/app/build.gradle

Fix:
needs to be added in the dependencies section: 

    androidTestImplementation 'androidx.test.ext:junit:1.1.1'
    androidTestImplementation 'com.android.support.test:rules:1.0.2'
    androidTestImplementation 'com.google.truth:truth:1.0.1'


 "
36759,posenet negative output scores,"@tensorflow/micro


**Describe the problem**
Hello,

I'm working on a C++ implementation for the posenet model. (using multi_person_mobilenet_v1_075_float.tflite).

I can't seem to find much documentation on how to interpret the outputs of the model, but I did come across [this medium post](https://medium.com/@prajwalsingh_48273/posenet-for-android-8b6dede9fa2f). My outputs adhere to the dimensions that the article outlines, however, I'm getting negative scores.

I've also tried with the starter model file from the [Tensorflow Pose estimation page](https://www.tensorflow.org/lite/models/pose_estimation/overview) with similar negative scores.

My question is regarding the range of values I can expect for each of these outputs (score, offsets, displacements). 

Probably a better question to ask: Is there updated models and comprehensive documentation somewhere for any pretrained posenet model?"
36758,Tensorflow-GPU 2.0 Docker Python script is just returning a message without executing,"I installed ""tensorflow:2.0.1-gpu-py3"" docker image on my Ubuntu 18.04 with nvidia-driver-435 and mx110 video card. It works and even runs the following code after few minutes of initialization
`python -c ""import tensorflow as tf;print(tf.reduce_sum(tf.random.normal([1000, 1000])))""`
but when I'm trying to execute this file 

https://github.com/vadimen/algorithms/blob/master/code.py

it just returns 

`python3 ssd_mobilenet_tf_for_video.py 
2020-02-14 17:56:28.801358: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-02-14 17:56:28.803092: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-02-14 17:56:28.803374: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: GeForce MX110 major: 5 minor: 0 memoryClockRate(GHz): 1.006
pciBusID: 0000:01:00.0
2020-02-14 17:56:28.803547: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2020-02-14 17:56:28.804471: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2020-02-14 17:56:28.805256: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2020-02-14 17:56:28.805476: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2020-02-14 17:56:28.806716: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2020-02-14 17:56:28.807675: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2020-02-14 17:56:28.810783: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-02-14 17:56:28.810947: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-02-14 17:56:28.811578: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-02-14 17:56:28.812142: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2020-02-14 17:56:30.518085: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-02-14 17:56:30.540075: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 1800000000 Hz
2020-02-14 17:56:30.540367: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4f31d60 executing computations on platform Host. Devices:
2020-02-14 17:56:30.540380: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version
2020-02-14 17:56:30.577626: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-02-14 17:56:30.577961: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4eda270 executing computations on platform CUDA. Devices:
2020-02-14 17:56:30.577977: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): GeForce MX110, Compute Capability 5.0
2020-02-14 17:56:30.578121: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-02-14 17:56:30.578356: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: GeForce MX110 major: 5 minor: 0 memoryClockRate(GHz): 1.006
pciBusID: 0000:01:00.0
2020-02-14 17:56:30.578399: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2020-02-14 17:56:30.578417: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2020-02-14 17:56:30.578431: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2020-02-14 17:56:30.578446: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2020-02-14 17:56:30.578462: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2020-02-14 17:56:30.578477: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2020-02-14 17:56:30.578489: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-02-14 17:56:30.578537: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-02-14 17:56:30.578769: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-02-14 17:56:30.578972: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2020-02-14 17:56:30.579001: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2020-02-14 17:56:30.579466: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-02-14 17:56:30.579477: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 
2020-02-14 17:56:30.579483: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N 
2020-02-14 17:56:30.579558: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-02-14 17:56:30.579815: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-02-14 17:56:30.580074: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 1535 MB memory) -> physical GPU (device: 0, name: GeForce MX110, pci bus id: 0000:01:00.0, compute capability: 5.0)
{'detection_classes': TensorShape([None, 100]), 'num_detections': TensorShape([None]), 'detection_boxes': TensorShape([None, 100, 4]), 'detection_scores': TensorShape([None, 100])}
`
"
36757,Add more information about eager/graph context for Keras layer.call(),"Thank you for submitting a TensorFlow documentation issue. Per our GitHub
policy, we only address code/doc bugs, performance issues, feature requests, and
build/installation issues on GitHub.

The TensorFlow docs are open source! To get involved, read the documentation
contributor guide: https://www.tensorflow.org/community/contribute/docs

## URL(s) with the issue:

https://www.tensorflow.org/api_docs/python/tf/keras/layers/Layer#call

## Description of issue (what needs changing):

### Clear description

This is a key function that user will implement with they custom layer. Currently it is poorly documented, especially w.r.t the execution context of eager/graph. In TF 2.0, we are advocating eager execution by default. However, the call() body in keras is executed with graph context by default unless configured otherwise. It will raise error if user try to add print/debug related to items into the call body, eg print(eager_tensor.numpy()), etc.

Some related question raised in  https://github.com/tensorflow/tensorflow/issues/27519.

### Correct links

Yes

### Parameters defined

Yes

### Returns defined

Yes

### Raises listed and defined

Yes

### Usage example

No

### Request visuals, if applicable

No

### Submit a pull request?
No
"
36755,Unify the code for GpuCompiler::OptimizeHloPostLayoutAssignment for AMD and NVidia in XLA,"The code in `GpuCompiler::OptimizeHloPostLayoutAssignment` subclasses is essentially duplicated for AMD and NVidia in XLA. This already leads to subtle bugs: TreeReductionRewriterPass is applied to NVidia, but not to AMD.

 Would it be possible to unify those, put the code in `gpu_compiler.cc`, and just check the platform to dynamically choose whether to apply NVidia-specific or AMD-specific passes?"
36751,Allocator (GPU_0_bfc) ran out of memory trying to allocate 32.0KiB (rounded to 32768),"**System information**
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): -  Windows 10 1909  
TensorFlow version (use command below): -  2.1.0 - gpu version  
Python version: -  3.6.9  
CUDA/cuDNN version: -  10.1.243  
GPU model and memory:  GTX 1660 Ti 6GB and 32GB (28GB available)  

**Describe the current behavior**  
Firstly it is some weighted model which I used for google-quest-challenge and since the contest date is out for submission I ran kaggle kernel not normal but with GPU. And then I got score, want to increase by chaning the model and few things and when I ran this in my computer, surprisingly I am getting this error. Please somebody help me how to rectify this error. I need it and I am so desperate. Because I work all day long with this computer on machine learning models. So, now that the error occurred I cannot do it.  

![1](https://user-images.githubusercontent.com/44919399/74539156-921dbb00-4f63-11ea-955d-2e46e171387d.jpg)
![2](https://user-images.githubusercontent.com/44919399/74539180-9944c900-4f63-11ea-9c08-6271c8f0e60e.jpg)

**Code to reproduce the issue** 
[google-quest-challenge.txt](https://github.com/tensorflow/tensorflow/files/4204830/google-quest-challenge.txt)
[data.zip](https://github.com/tensorflow/tensorflow/files/4204848/data.zip)


**Other info / logs**  
I uploaded the code as text file and datasets as zip file. Please find it and response as soon as possible. I am very desperate.

"
36750,Loading the in-memory loaded saved model ,"Hi all,
Can someone tell me a way to load an in-memory loaded tensorflow model (a protobuf file) into Tensorflow?

For example, the current code I have is as follows: 
```
model_path = 'path/to/the/model/'
session = tf.Session(graph=tf.Graph())
tf.saved_model.loader.load(session, ['serve'], model_path)
```

However, instead of loading the model by providing its path, I would like to load a model by providing a bytebuffer of the loaded model file.

Can anyone tell me how I can do this? Thanks!"
36748,"Ubuntu 18.04 with RTX 2070 SUPER with tensorflow 1.13, Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERRO","**System information**
- Have I written custom code : No
- OS: Linux 5.3.0-28 18.04.1-Ubuntu
- TensorFlow installed from pip3
- TensorFlow version: tried 13.1 and 13.2
- Python version: Python 3.6.9
- Bazel: /
- GCC/Compiler: gcc (Ubuntu 7.4.0-1ubuntu1~18.04.1) 7.4.0
- CUDA/cuDNN version: CUDA 10.0, cuDNN 7.4.2
- GPU model and memory: GeForce RTX 2070 SUPER, 8GB

**Describe the current behavior**
I downloaded the [MNIST ""tensorflow without a PhD example""](https://github.com/GoogleCloudPlatform/tensorflow-without-a-phd) from git and tried to run one of the examples with
`python3 mnist_3.1_convolutional_bigger_dropout.py`
after downloading tensorflow and tensorflow gpu with
`pip3 install tensorflow==1.13.2 tensorflow-gpu==1.13.2`.

**Describe the expected behavior**
I have not altered the code in any way and could successfully run it on the CPU. I assumed it would work without problems with the GPU, too, after I installed proprietary NVidia drivers (435) and the CUDA and cuDNN libraries.
There was a [workaround in a different issue relating to the same problem](https://github.com/tensorflow/tensorflow/issues/24496#issuecomment-464909727) but this did not fix the issue for me.

**Code to reproduce the issue**
Just clone the repository above and run the code from the ""tensorflow-mnist-tutorial"" directory.

**Other info / logs**
This is the output:
```
$ python3 mnist_3.1_convolutional_bigger_dropout.py 
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([(""qint8"", np.int8, 1)])
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([(""quint8"", np.uint8, 1)])
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([(""qint16"", np.int16, 1)])
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([(""quint16"", np.uint16, 1)])
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([(""qint32"", np.int32, 1)])
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([(""resource"", np.ubyte, 1)])
INFO:tensorflow:Tensorflow version 1.13.2
Tensorflow version 1.13.2
2020-02-14 11:56:04.391977: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x16d9470 executing computations on platform CUDA. Devices:
2020-02-14 11:56:04.392023: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): GeForce RTX 2070 SUPER, Compute Capability 7.5
2020-02-14 11:56:04.412696: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3600105000 Hz
2020-02-14 11:56:04.413472: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x1718880 executing computations on platform Host. Devices:
2020-02-14 11:56:04.413512: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
2020-02-14 11:56:04.413749: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: 
name: GeForce RTX 2070 SUPER major: 7 minor: 5 memoryClockRate(GHz): 1.815
pciBusID: 0000:03:00.0
totalMemory: 7.79GiB freeMemory: 7.56GiB
2020-02-14 11:56:04.413786: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0
2020-02-14 11:56:04.414980: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-02-14 11:56:04.415008: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 
2020-02-14 11:56:04.415022: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N 
2020-02-14 11:56:04.415176: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7350 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2070 SUPER, pci bus id: 0000:03:00.0, compute capability: 7.5)
2020-02-14 11:56:08.593018: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0
2020-02-14 11:56:08.593064: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-02-14 11:56:08.593075: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 
2020-02-14 11:56:08.593087: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N 
2020-02-14 11:56:08.593176: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7350 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2070 SUPER, pci bus id: 0000:03:00.0, compute capability: 7.5)
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
WARNING:tensorflow:From mnist_3.1_convolutional_bigger_dropout.py:88: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
WARNING:tensorflow:From mnist_3.1_convolutional_bigger_dropout.py:95: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.
Instructions for updating:

Future major versions of TensorFlow will allow gradients to flow
into the labels input on backprop by default.

See `tf.nn.softmax_cross_entropy_with_logits_v2`.

2020-02-14 11:56:10.165980: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0
2020-02-14 11:56:10.166030: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-02-14 11:56:10.166039: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 
2020-02-14 11:56:10.166049: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N 
2020-02-14 11:56:10.166133: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7350 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2070 SUPER, pci bus id: 0000:03:00.0, compute capability: 7.5)
2020-02-14 11:56:10.651240: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10.0 locally
2020-02-14 11:56:11.534908: E tensorflow/stream_executor/cuda/cuda_dnn.cc:334] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR
2020-02-14 11:56:11.581923: E tensorflow/stream_executor/cuda/cuda_dnn.cc:334] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR
Exception in Tkinter callback
Traceback (most recent call last):
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py"", line 1334, in _do_call
    return fn(*args)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py"", line 1319, in _run_fn
    options, feed_dict, fetch_list, target_list, run_metadata)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py"", line 1407, in _call_tf_sessionrun
    run_metadata)
tensorflow.python.framework.errors_impl.UnknownError: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.
         [[{{node Conv2D}}]]
         [[{{node convert_image}}]]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/usr/lib/python3.6/tkinter/__init__.py"", line 1705, in __call__
    return self.func(*args)
  File ""/usr/lib/python3.6/tkinter/__init__.py"", line 749, in callit
    func(*args)
  File ""/usr/lib/python3/dist-packages/matplotlib/backends/backend_tkagg.py"", line 95, in _on_timer
    TimerBase._on_timer(self)
  File ""/usr/lib/python3/dist-packages/matplotlib/backend_bases.py"", line 1383, in _on_timer
    ret = func(*args, **kwargs)
  File ""/usr/lib/python3/dist-packages/matplotlib/animation.py"", line 1542, in _step
    still_going = Animation._step(self, *args)
  File ""/usr/lib/python3/dist-packages/matplotlib/animation.py"", line 1277, in _step
    self._draw_next_frame(framedata, self._blit)
  File ""/usr/lib/python3/dist-packages/matplotlib/animation.py"", line 1296, in _draw_next_frame
    self._draw_frame(framedata)
  File ""/usr/lib/python3/dist-packages/matplotlib/animation.py"", line 1814, in _draw_frame
    self._drawn_artists = self._func(framedata, *self._args)
  File ""/home/myuser/repository/tensorflow-without-a-phd/tensorflow-mnist-tutorial/tensorflowvisu.py"", line 364, in animate_step
    compute_step(n, request_test_data_update, request_data_update)
  File ""mnist_3.1_convolutional_bigger_dropout.py"", line 131, in training_step
    feed_dict={X: batch_X, Y_: batch_Y, pkeep: 1.0, step: i})
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py"", line 929, in run
    run_metadata_ptr)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py"", line 1152, in _run
    feed_dict_tensor, options, run_metadata)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py"", line 1328, in _do_run
    run_metadata)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py"", line 1348, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.UnknownError: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.
         [[node Conv2D (defined at mnist_3.1_convolutional_bigger_dropout.py:78) ]]
         [[node convert_image (defined at /home/myuser/repository/tensorflow-without-a-phd/tensorflow-mnist-tutorial/tensorflowvisu.py:62) ]]

Caused by op 'Conv2D', defined at:
  File ""mnist_3.1_convolutional_bigger_dropout.py"", line 78, in <module>
    Y1 = tf.nn.relu(tf.nn.conv2d(X, W1, strides=[1, stride, stride, 1], padding='SAME') + B1)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_nn_ops.py"", line 1026, in conv2d
    data_format=data_format, dilations=dilations, name=name)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py"", line 788, in _apply_op_helper
    op_def=op_def)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py"", line 507, in new_func
    return func(*args, **kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py"", line 3300, in create_op
    op_def=op_def)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py"", line 1801, in __init__
    self._traceback = tf_stack.extract_stack()

UnknownError (see above for traceback): Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.
         [[node Conv2D (defined at mnist_3.1_convolutional_bigger_dropout.py:78) ]]
         [[node convert_image (defined at /home/myuser/repository/tensorflow-without-a-phd/tensorflow-mnist-tutorial/tensorflowvisu.py:62) ]]
```

By the way, there was a helpful table showing which tensorflow version required what python version, gcc compiler, bazel version and cuDNN/CUDA version. What happened to that?

Cheers"
36746,Best Method To import Multiple Tensorflow Models in Inference,"suppose i have 3 Models in Tensorflow each for a specific problem while inference with a web cam or in real time processing, my question is how can i import multiple models in one session with their frozen graph and labelpb files ? or what is the best method for doing running the 3 models at the same time ?

"
36740,Image Classification pretrained model breaks for batch size 1 with BaseCollectiveExecutor::StartAbort error,"**System information** 
- Have I written custom code (as opposed to using a stock
example script provided in TensorFlow): No, code used from https://github.com/tensorflow/tensorrt/tftrt/examples/image-classification
- OS Platform and Distribution (e.g.,
Linux Ubuntu 16.04): RHEL 7.6
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if
the issue happens on mobile device: 
- TensorFlow installed from (source or
binary): Binary
- TensorFlow version (use command below): 2.1
- Python version: - Bazel
version (if compiling from source): 
- GCC/Compiler version (if compiling from
source): 7.3.0
- CUDA/cuDNN version: 10.2/7.6.5
- GPU model and memory: Tesla T4

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
Related issue: https://github.com/tensorflow/tensorrt/issues/169: Link: https://github.com/tensorflow/tensorrt/issues/169#issuecomment-572383212 
This example uses a frozen graph that was downloaded from here: http://download.tensorflow.org/models/official/resnet_v1_imagenet_savedmodel.tar.gz

This issue happens for synthetic as well as a validation runs. I was making my runs using this call:
```
python image_classification.py --input_saved_model_dir data/resnet_v1_50/1523293981 --data_dir /home/mayroy13/Mayank/Mayank/test/imagenet --calib_data_dir /home/mayroy13/Mayank/Mayank/test/imagenet --minimum_segment_size 3 --output_saved_model_dir trt_engine --batch_size 1 --use_trt --num_iterations 100 --precision FP16 --mode validation --max_workspace_size $((2**32))
```
And it fails with the following error:
```
Benchmark arguments:
  batch_size: 1
  calib_data_dir: /home/mayroy13/Mayank/Mayank/test/imagenet
  data_dir: /home/mayroy13/Mayank/Mayank/test/imagenet
  display_every: 100
  gpu_mem_cap: 0
  input_saved_model_dir: data/resnet_v1_50/1523293981
  input_size: 224
  max_workspace_size: 4294967296
  minimum_segment_size: 3
  mode: validation
  num_calib_inputs: 50
  num_classes: 1001
  num_iterations: 100
  num_warmup_iterations: 50
  optimize_offline: False
  output_saved_model_dir: trt_engine
  precision: FP16
  preprocess_method: vgg
  target_duration: None
  use_synthetic: False
  use_trt: True
TensorRT Conversion Params:
  is_dynamic_op: True
  max_batch_size: 1
  max_workspace_size_bytes: 4294967296
  maximum_cached_engines: 100
  minimum_segment_size: 3
  precision_mode: FP16
  rewriter_config_template: None
  use_calibration: False
Conversion times:
  conversion: 40.5s
2020-02-13 22:40:45.510560: W tensorflow/core/common_runtime/base_collective_executor.cc:217] BaseCollectiveExecutor::StartAbort Invalid argument: Number of ways to split should evenly divide the split dimension, but got split_dim 0 (size = 1) and num_split 2
         [[{{node PartitionedCall/split_inputs/split}}]]
2020-02-13 22:40:45.510560: W tensorflow/core/common_runtime/base_collective_executor.cc:217] BaseCollectiveExecutor::StartAbort Invalid argument: Number of ways to split should evenly divide the split dimension, but got split_dim 0 (size = 1) and num_split 2
         [[{{node PartitionedCall/split_inputs/split}}]]
         [[PartitionedCall/split_inputs/split/_2]]
2020-02-13 22:40:45.511446: W tensorflow/core/common_runtime/base_collective_executor.cc:217] BaseCollectiveExecutor::StartAbort Invalid argument: Number of ways to split should evenly divide the split dimension, but got split_dim 0 (size = 1) and num_split 2
         [[{{node PartitionedCall/split_inputs/split}}]]
         [[PartitionedCall/TRTEngineOp_0/_6]]
Traceback (most recent call last):
  File ""image_classification.py"", line 464, in <module>
    target_duration=args.target_duration)
  File ""image_classification.py"", line 231, in run_inference
    batch_preds = graph_func(batch_images)[0].numpy()
  File ""/home/mayroy13/anaconda3/envs/wml17/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py"", line 1551, in __call__
    return self._call_impl(args, kwargs)
  File ""/home/mayroy13/anaconda3/envs/wml17/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py"", line 1591, in _call_impl
    return self._call_flat(args, self.captured_inputs, cancellation_manager)
  File ""/home/mayroy13/anaconda3/envs/wml17/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py"", line 1692, in _call_flat
    ctx, args, cancellation_manager=cancellation_manager))
  File ""/home/mayroy13/anaconda3/envs/wml17/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py"", line 545, in call
    ctx=ctx)
  File ""/home/mayroy13/anaconda3/envs/wml17/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py"", line 67, in quick_execute
    six.raise_from(core._status_to_exception(e.code, message), None)
  File ""<string>"", line 3, in raise_from
tensorflow.python.framework.errors_impl.InvalidArgumentError: 2 root error(s) found.
  (0) Invalid argument:  Number of ways to split should evenly divide the split dimension, but got split_dim 0 (size = 1) and num_split 2
         [[node PartitionedCall/split_inputs/split (defined at image_classification.py:134) ]]
         [[PartitionedCall/split_inputs/split/_2]]
  (1) Invalid argument:  Number of ways to split should evenly divide the split dimension, but got split_dim 0 (size = 1) and num_split 2
         [[node PartitionedCall/split_inputs/split (defined at image_classification.py:134) ]]
0 successful operations.
1 derived errors ignored. [Op:__inference_pruned_25839]

Function call stack:
pruned -> pruned
```
**Describe the expected behavior**
The expected behaviour would be for the code to complete and print metrics for the run.
"
36739,How to get original string data back from TFRecordData,"I followed TensorFlow guide to save my string data using:
```
def _create_string_feature(values):
    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[values.encode('utf-8')]))
```
I also used ```[""tf.string"", ""FixedLenFeature""]``` as my feature original type, and ```""tf.string""``` as my feature convert type.

However, during my training when I run my session and I create iterators, my string feature for a batch size of 2 (for example: ['food fruit', 'cupcake food' ]) would be like below. The problem is that this list is of size 1, and not 2 (batch_size=2), why instances in one batch are sticked (clubbed) together rather than being splitted?

```
[b'food fruit' b'cupcake food']
```
For my other features which are int or float, they are numpy arrays of shape (batch_size, feature_len) which are fine but not sure why string features are not separated in a single batch?

Any help would be appreciated."
36737,Updating TF to start using Bazel 2.0.0,"Updating TF to start using Bazel 2.0.0
"
36736,Sudden OOM error with Tensorflow after several successfully trained batches,"**System information** 
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution: Ubuntu 18.04.3 LTS 
- TensorFlow installed from (source or binary): tensorflow installed from docker image
- TensorFlow version (use command below): v2.1.0
- Python version: 3.6.9
- GCC/Compiler version (if compiling from source): 8.3.0
- CUDA/cuDNN version: V10.1.243
- GPU model and memory: NVIDIA Corporation GM200 [GeForce GTX TITAN X] [10de:1132] and 12 GB of memory

**Description**: I'm running an Encoder-Decoder architecture to do video captioning. For this I created three classes based on keras.Model. The first model has several 3D convolutional layers, normalization and 3D max pooling layers and I use it to describe the video, it is initialized and called inside the Encoder model. This encoder model is called once for each video and passes information to the decoder model which is called several times (as many as the number of words in the caption).

**Input shape**: The dimensions of the input video are (128,224,224,3) where 128 indicates the number of frames and the dimensions of the sentences are (1,55) where 55 indicates the number of tokens.

**Problem**: I'm using a batch of 1 (video) and the model trains well up to a certain number of videos and then throws an OOM error as seen in the picture. I have tried to lower the number of frames to 64 and 32 but the same error keeps coming up but, interestingly, the error takes longer to come up as I lower the frames, this makes me think that in a certain place the memory is being used in a cumulative way. From the error I can deduce that it appears in the backpropagation of the first layer maxpoling3d. However, I don't understand why the model runs well for some videos and then throws the error, if it was by memory, it should break in the first video, right? I attach the training function I'm using and the data generator.

![Selección_002](https://user-images.githubusercontent.com/18648306/74474042-b057be00-4e72-11ea-8de4-6cd0486ac4c0.png)
![Selección_003](https://user-images.githubusercontent.com/18648306/74474072-bcdc1680-4e72-11ea-961c-dd4532beda0c.png)
![Selección_001](https://user-images.githubusercontent.com/18648306/74473583-d7fa5680-4e71-11ea-8c86-f8f7420cd139.png)
"
36735,Re-compiling keras model causes save / load_model to fail,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: docker container running RHEL 7.7
- **TensorFlow installed from (source or binary)**: binary (pip)
- **TensorFlow version (use command below)**: 2.1
- **Python version**: 3.6
- **CUDA/cuDNN version**: running on CPU
- **Exact command to reproduce**:

```
import tensorflow as tf
from tensorflow.keras import optimizers
from tensorflow.keras import metrics
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout

model = Sequential()
model.add(Dense(64, activation='relu', input_shape=(13,)))
model.add(Dense(32, activation='relu'))
model.add(Dense(3, activation='relu'))
model.add(Dense(1, activation='sigmoid'))

model.compile(loss='binary_crossentropy', metrics=[""accuracy""], optimizer=""SGD"")

# Compiling again with the same loss, optimizer and metrics
model.compile(loss=model.loss, optimizer=model.optimizer, metrics=model.metrics)

model.save(""my_model.h5"")
loaded = tf.keras.models.load_model(""my_model.h5"")
```

### Describe the problem
Compiling keras model again and saving it as h5 file causes `load_model` to fail with `TypeError: __init__() missing 1 required positional argument: 'fn'`. 

This issue does not happen if the model is compile once.

Happening in both tensorflow 2.0 and 2.1

### Source code / logs

```
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
<ipython-input-4-a65550ed8fb1> in <module>
     15 
     16 model.save(""my_model.h5"")
---> 17 loaded = tf.keras.models.load_model(""my_model.h5"")

/opt/conda/envs/py-tensorflow_2_0_0/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/save.py in load_model(filepath, custom_objects, compile)
    144   if (h5py is not None and (
    145       isinstance(filepath, h5py.File) or h5py.is_hdf5(filepath))):
--> 146     return hdf5_format.load_model_from_hdf5(filepath, custom_objects, compile)
    147 
    148   if isinstance(filepath, six.string_types):

/opt/conda/envs/py-tensorflow_2_0_0/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py in load_model_from_hdf5(filepath, custom_objects, compile)
    182       # Compile model.
    183       model.compile(**saving_utils.compile_args_from_training_config(
--> 184           training_config, custom_objects))
    185 
    186       # Set optimizer weights.

/opt/conda/envs/py-tensorflow_2_0_0/lib/python3.6/site-packages/tensorflow_core/python/training/tracking/base.py in _method_wrapper(self, *args, **kwargs)
    455     self._self_setattr_tracking = False  # pylint: disable=protected-access
    456     try:
--> 457       result = method(self, *args, **kwargs)
    458     finally:
    459       self._self_setattr_tracking = previous_value  # pylint: disable=protected-access

/opt/conda/envs/py-tensorflow_2_0_0/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py in compile(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, target_tensors, distribute, **kwargs)
    427     with K.get_graph().as_default():
    428       # Save all metric attributes per output of the model.
--> 429       self._cache_output_metric_attributes(metrics, weighted_metrics)
    430 
    431       # Set metric attributes on model.

/opt/conda/envs/py-tensorflow_2_0_0/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py in _cache_output_metric_attributes(self, metrics, weighted_metrics)
   1840         output_shapes.append(output.shape.as_list())
   1841     self._per_output_metrics = training_utils.collect_per_output_metric_info(
-> 1842         metrics, self.output_names, output_shapes, self.loss_functions)
   1843     self._per_output_weighted_metrics = (
   1844         training_utils.collect_per_output_metric_info(

/opt/conda/envs/py-tensorflow_2_0_0/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_utils.py in collect_per_output_metric_info(metrics, output_names, output_shapes, loss_fns, is_weighted)
    878     metrics_dict = OrderedDict()
    879     for metric in metrics:
--> 880       metric_name = get_metric_name(metric, is_weighted)
    881       metric_fn = get_metric_function(
    882           metric, output_shape=output_shapes[i], loss_fn=loss_fns[i])

/opt/conda/envs/py-tensorflow_2_0_0/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_utils.py in get_metric_name(metric, weighted)
   1072       return metric
   1073 
-> 1074     metric = metrics_module.get(metric)
   1075     return metric.name if hasattr(metric, 'name') else metric.__name__
   1076   else:

/opt/conda/envs/py-tensorflow_2_0_0/lib/python3.6/site-packages/tensorflow_core/python/keras/metrics.py in get(identifier)
   3060 def get(identifier):
   3061   if isinstance(identifier, dict):
-> 3062     return deserialize(identifier)
   3063   elif isinstance(identifier, six.string_types):
   3064     return deserialize(str(identifier))

/opt/conda/envs/py-tensorflow_2_0_0/lib/python3.6/site-packages/tensorflow_core/python/keras/metrics.py in deserialize(config, custom_objects)
   3054       module_objects=globals(),
   3055       custom_objects=custom_objects,
-> 3056       printable_module_name='metric function')
   3057 
   3058 

/opt/conda/envs/py-tensorflow_2_0_0/lib/python3.6/site-packages/tensorflow_core/python/keras/utils/generic_utils.py in deserialize_keras_object(identifier, module_objects, custom_objects, printable_module_name)
    303                 list(custom_objects.items())))
    304       with CustomObjectScope(custom_objects):
--> 305         return cls.from_config(cls_config)
    306     else:
    307       # Then `cls` may be a function returning a class.

/opt/conda/envs/py-tensorflow_2_0_0/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py in from_config(cls, config)
    517         A layer instance.
    518     """"""
--> 519     return cls(**config)
    520 
    521   def compute_output_shape(self, input_shape):

TypeError: __init__() missing 1 required positional argument: 'fn'
```
"
36734,AttributeError: 'BatchGen' object has no attribute 'shape',"I am using TensorFlow version 1.15 for a project. I have converted a BioBert pre-trained model into a Keras layer following the code [here](https://towardsdatascience.com/fine-tuning-bert-with-keras-and-tf-module-ed24ea91cff2). However, when I run my code, I get the following error:

```
Traceback (most recent call last):
  File ""/home/jupyter-belona/.conda/envs/mimic-proj/lib/python3.7/runpy.py"", line 193, in _run_module_as_main
    ""__main__"", mod_spec)
  File ""/home/jupyter-belona/.conda/envs/mimic-proj/lib/python3.7/runpy.py"", line 85, in _run_code
    exec(code, run_globals)
  File ""/home/jupyter-belona/Untitled_Folder/deep-learning-clinical-forecast/mimic3newmodels/decompensation/main.py"", line
152, in <module>
    verbose=args.verbose)
  File ""/home/jupyter-belona/.conda/envs/mimic-proj/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/trainin
g.py"", line 1296, in fit_generator
    steps_name='steps_per_epoch')
  File ""/home/jupyter-belona/.conda/envs/mimic-proj/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/trainin
g_generator.py"", line 144, in model_iteration
    shuffle=shuffle)
  File ""/home/jupyter-belona/.conda/envs/mimic-proj/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/trainin
g_generator.py"", line 477, in convert_to_generator_like
    **num_samples = int(nest.flatten(data)[0].shape[0])**
AttributeError: 'BatchGen' object has no attribute 'shape'
```
Please, how do I fix this error? I really need your help."
36733,tf.split for unequal splits when num is odd and size_splits is not available,"**System information**
- TensorFlow version: 1.14.0



**Describe the feature and the current behavior/state.**
When I have a tensor of size say [99, 100, 100, 1] and want to split (batch size 99) it into 4 parts (because I have 4 GPUs). It can't be split with the existing function. I don't always know the batch size so I can't use size_splits as well.
"
36731,Entity <function pfor.<locals>.f at 0x644d84950> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: macOS 10.14.6 (18G2022)
- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: no
- **TensorFlow installed from (source or binary)**: binary, from Anaconda
- **TensorFlow version (use command below)**: unknown 1.14.0
- **Python version**: 3.7.4
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**: cudatoolkit-9.0
- **GPU model and memory**: not used
- **Exact command to reproduce**: run the attached script `get_partial_derivatives.py`.


### Describe the problem
I ran into a bug when I run the following small code:

```python
import tensorflow as tf
tf.enable_v2_behavior()

input = tf.Variable([[1.0, 2.0], [3.0, 4.0]])
w = tf.Variable([[1.0, 7.0], [3.0, 5.0]])

with tf.GradientTape(persistent=True) as t:
    f = tf.matmul(input, tf.transpose(w))

print(""f:"")
print(f)

print(""Derivative:"")
print(t.jacobian(f, input))
```


### Source code / logs
Log of the error:

```
WARNING:tensorflow:Entity <function pfor.<locals>.f at 0x644d84950> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function pfor.<locals>.f at 0x644d84950>: AssertionError: Bad argument number for Name: 3, expecting 4
```

The full log (with AUTOGRAPH_VERBOSITY=10) is attached.

[get_partial_derivatives.py.txt](https://github.com/tensorflow/tensorflow/files/4199640/get_partial_derivatives.py.txt)
[logfile.txt](https://github.com/tensorflow/tensorflow/files/4199641/logfile.txt)"
36730,tensorflow-gpu=2.1.0 AttributeError: module 'tensorflow' has no attribute 'placeholder',"when I used the tensorflow-gpu=2.1.0 to run in keras-python3.6 env, it said:

Using TensorFlow backend.
2020-02-13 21:47:27.592762: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_100.dll
WARNING:tensorflow:From D:\Anaconda3\envs\keras36\lib\site-packages\tensorflow_core\python\compat\v2_compat.py:65: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.
Instructions for updating:
non-resource variables are not supported in the long term
Traceback (most recent call last):
  File ""i:/Git_Lip/XWLip_lite/DC_kares_LipReading_P70_R18/code/network.py"", line 574, in <module>
    models=Lip_net(**params)
  File ""i:/Git_Lip/XWLip_lite/DC_kares_LipReading_P70_R18/code/network.py"", line 367, in Lip_net
    input_data = Input(name='the_input', shape=(24,112,112,3), dtype='float32')
  File ""D:\Anaconda3\envs\keras36\lib\site-packages\keras\engine\input_layer.py"", line 178, in Input
    input_tensor=tensor)
  File ""D:\Anaconda3\envs\keras36\lib\site-packages\keras\legacy\interfaces.py"", line 91, in wrapper
    return func(*args, **kwargs)
  File ""D:\Anaconda3\envs\keras36\lib\site-packages\keras\engine\input_layer.py"", line 87, in __init__
    name=self.name)
  File ""D:\Anaconda3\envs\keras36\lib\site-packages\keras\backend\tensorflow_backend.py"", line 517, in placeholder
    x = tf.placeholder(dtype, shape=shape, name=name)
AttributeError: module 'tensorflow' has no attribute 'placeholder'

how can I  sovle the problem?Thanks for replying."
36728,Iterator Resource Error ,"While running this code - [Link](https://github.com/cerlymarco/MEDIUM_NoteBook/blob/master/Time2Vec/Time2Vec2.ipynb)

Please help me with this.

```
NotFoundError                             Traceback (most recent call last)
<ipython-input-12-db1663a8e74a> in <module>()
      5 #nnT2V.summary()
      6 
----> 7 nnT2V.fit(X_train, y_train, epochs=1, batch_size=256, verbose=3, shuffle=True, validation_split=0.2)

~\AppData\Roaming\Python\Python36\site-packages\tensorflow_core\python\keras\engine\training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)
    726         max_queue_size=max_queue_size,
    727         workers=workers,
--> 728         use_multiprocessing=use_multiprocessing)
    729 
    730   def evaluate(self,

~\AppData\Roaming\Python\Python36\site-packages\tensorflow_core\python\keras\engine\training_v2.py in fit(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)
    322                 mode=ModeKeys.TRAIN,
    323                 training_context=training_context,
--> 324                 total_epochs=epochs)
    325             cbks.make_logs(model, epoch_logs, training_result, ModeKeys.TRAIN)
    326 

~\AppData\Roaming\Python\Python36\site-packages\tensorflow_core\python\keras\engine\training_v2.py in run_one_epoch(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)
    121         step=step, mode=mode, size=current_batch_size) as batch_logs:
    122       try:
--> 123         batch_outs = execution_function(iterator)
    124       except (StopIteration, errors.OutOfRangeError):
    125         # TODO(kaftan): File bug about tf function and errors.OutOfRangeError?

~\AppData\Roaming\Python\Python36\site-packages\tensorflow_core\python\keras\engine\training_v2_utils.py in execution_function(input_fn)
     84     # `numpy` translates Tensors to values in Eager mode.
     85     return nest.map_structure(_non_none_constant_value,
---> 86                               distributed_function(input_fn))
     87 
     88   return execution_function

~\AppData\Roaming\Python\Python36\site-packages\tensorflow_core\python\eager\def_function.py in __call__(self, *args, **kwds)
    455 
    456     tracing_count = self._get_tracing_count()
--> 457     result = self._call(*args, **kwds)
    458     if tracing_count == self._get_tracing_count():
    459       self._call_counter.called_without_tracing()

~\AppData\Roaming\Python\Python36\site-packages\tensorflow_core\python\eager\def_function.py in _call(self, *args, **kwds)
    485       # In this case we have created variables on the first call, so we run the
    486       # defunned version which is guaranteed to never create variables.
--> 487       return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable
    488     elif self._stateful_fn is not None:
    489       # Release the lock early so that multiple threads can perform the call

~\AppData\Roaming\Python\Python36\site-packages\tensorflow_core\python\eager\function.py in __call__(self, *args, **kwargs)
   1821     """"""Calls a graph function specialized to the inputs.""""""
   1822     graph_function, args, kwargs = self._maybe_define_function(args, kwargs)
-> 1823     return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access
   1824 
   1825   @property

~\AppData\Roaming\Python\Python36\site-packages\tensorflow_core\python\eager\function.py in _filtered_call(self, args, kwargs)
   1139          if isinstance(t, (ops.Tensor,
   1140                            resource_variable_ops.BaseResourceVariable))),
-> 1141         self.captured_inputs)
   1142 
   1143   def _call_flat(self, args, captured_inputs, cancellation_manager=None):

~\AppData\Roaming\Python\Python36\site-packages\tensorflow_core\python\eager\function.py in _call_flat(self, args, captured_inputs, cancellation_manager)
   1222     if executing_eagerly:
   1223       flat_outputs = forward_function.call(
-> 1224           ctx, args, cancellation_manager=cancellation_manager)
   1225     else:
   1226       gradient_name = self._delayed_rewrite_functions.register()

~\AppData\Roaming\Python\Python36\site-packages\tensorflow_core\python\eager\function.py in call(self, ctx, args, cancellation_manager)
    509               inputs=args,
    510               attrs=(""executor_type"", executor_type, ""config_proto"", config),
--> 511               ctx=ctx)
    512         else:
    513           outputs = execute.execute_with_cancellation(

~\AppData\Roaming\Python\Python36\site-packages\tensorflow_core\python\eager\execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)
     65     else:
     66       message = e.message
---> 67     six.raise_from(core._status_to_exception(e.code, message), None)
     68   except TypeError as e:
     69     keras_symbolic_tensors = [

~\Anaconda3\lib\site-packages\six.py in raise_from(value, from_value)

NotFoundError:  Resource AnonymousIterator/AnonymousIterator1/class tensorflow::data::IteratorResource does not exist.
	 [[node IteratorGetNext (defined at C:\Users\yogesh\AppData\Roaming\Python\Python36\site-packages\tensorflow_core\python\framework\ops.py:1751) ]] [Op:__inference_distributed_function_7034]

Function call stack:
distributed_function
```
"
36727,TFRecordDataset causes seg fault with parallel reads and parallel map of an empty file list,"== check python ===================================================
python version: 3.7.4
python branch:
python build version: ('default', 'Sep 7 2019 18:27:02')
python compiler version: Clang 10.0.1 (clang-1001.0.46.4)
python implementation: CPython

== check os platform ===============================================
os: Darwin
os kernel version: Darwin Kernel Version 19.0.0: Wed Sep 25 20:18:50 PDT 2019; root:xnu-6153.11.262/RELEASE_X86_64
os release version: 19.0.0
os platform: Darwin-19.0.0-x86_64-i386-64bit
linux distribution: ('', '', '')
linux os distribution: ('', '', '')
mac version: ('10.15', ('', '', ''), 'x86_64')
uname: uname_result(system='Darwin', node='Andrews-MacBook.local', release='19.0.0', version='Darwin Kernel Version 19.0.0: Wed Sep 25 20:18:50 PDT 2019; root:xnu-6153.11.262/RELEASE_X86_64', machine='x86_64', processor='i386')
architecture: ('64bit', '')
machine: x86_64

== are we in docker =============================================
No

== compiler =====================================================
xcrun: error: invalid active developer path (/Library/Developer/CommandLineTools), missing xcrun at: /Library/Developer/CommandLineTools/usr/bin/xcrun

== check pips ===================================================
numpy 1.17.4
protobuf 3.10.0
tensorflow 2.1.0
tensorflow-estimator 2.0.1

== check for virtualenv =========================================
True

== tensorflow import ============================================
tf.version.VERSION = 2.1.0
tf.version.GIT_VERSION = v2.0.0-rc2-26-g64c3d382ca
tf.version.COMPILER_VERSION = 4.2.1 Compatible Apple LLVM 10.0.0 (clang-1000.11.45.5)

== env ==========================================================
LD_LIBRARY_PATH is unset
DYLD_LIBRARY_PATH is unset

== nvidia-smi ===================================================
./tf_env_collect.sh: line 147: nvidia-smi: command not found

== cuda libs ===================================================

== tensorflow installed from info ==================
Name: tensorflow
Version: 2.1.0
Summary: TensorFlow is an open source machine learning framework for everyone.
Home-page: https://www.tensorflow.org/
Author-email: packages@tensorflow.org
License: Apache 2.0
Location: /Users/andrew/.local/share/virtualenvs/lib_andrew_scratch--yvJ8pLH/lib/python3.7/site-packages
Required-by:

== python version ==============================================
(major, minor, micro, releaselevel, serial)
(3, 7, 4, 'final', 0)

== bazel version ===============================================
Describe the current behavior
Segfault when next is called on the Itterable.

Describe the expected behavior
Crash/Error gracefully

Code to reproduce the issue

```
import tensorflow as tf

def _parse_function(example_proto):
    feature_description = {'features': tf.io.FixedLenFeature([], tf.string)}
    return tf.io.parse_single_example(example_proto, feature_description)

dataset = tf.data.TFRecordDataset([], num_parallel_reads = 2)
dataset = dataset.map(_parse_function, num_parallel_calls = tf.data.experimental.AUTOTUNE)

count = sum([1 for i in dataset])
```

I have reproduced this is Colab 
https://colab.research.google.com/drive/1C6sJ0BVjbK1h78LojPxp1DAuILJC_9e8
"
36725,Can't open the camera/webcam due to a tensorflow installation problem.,"Hello, i have some problems with the installation of tensorflow and the opening of the webcam. Now i am nowhere near experienced with tensorflow, let alone the anaconda prompt menu. I hope you guys could provide me with some help. Thank you in advanced.


(tfpose) C:\Users\gebruiker\Desktop\tf-pose-estimation>python run_webcam.py --model=mobilenet_thin --resize=432x368 --camera=0
Traceback (most recent call last):
  File ""C:\Users\gebruiker\Anaconda3\envs\tfpose\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\gebruiker\Anaconda3\envs\tfpose\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\gebruiker\Anaconda3\envs\tfpose\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\gebruiker\Anaconda3\envs\tfpose\lib\imp.py"", line 243, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\gebruiker\Anaconda3\envs\tfpose\lib\imp.py"", line 343, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: Kan opgegeven module niet vinden.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""run_webcam.py"", line 8, in <module>
    from tf_pose.estimator import TfPoseEstimator
  File ""C:\Users\gebruiker\Desktop\tf-pose-estimation\tf_pose\__init__.py"", line 5, in <module>
    from tf_pose.runner import infer, Estimator, get_estimator
  File ""C:\Users\gebruiker\Desktop\tf-pose-estimation\tf_pose\runner.py"", line 7, in <module>
    from tf_pose import common
  File ""C:\Users\gebruiker\Desktop\tf-pose-estimation\tf_pose\common.py"", line 3, in <module>
    import tensorflow as tf
  File ""C:\Users\gebruiker\Anaconda3\envs\tfpose\lib\site-packages\tensorflow\__init__.py"", line 101, in <module>
    from tensorflow_core import *
  File ""C:\Users\gebruiker\Anaconda3\envs\tfpose\lib\site-packages\tensorflow_core\__init__.py"", line 40, in <module>
    from tensorflow.python.tools import module_util as _module_util
  File ""C:\Users\gebruiker\Anaconda3\envs\tfpose\lib\site-packages\tensorflow\__init__.py"", line 50, in __getattr__
    module = self._load()
  File ""C:\Users\gebruiker\Anaconda3\envs\tfpose\lib\site-packages\tensorflow\__init__.py"", line 44, in _load
    module = _importlib.import_module(self.__name__)
  File ""C:\Users\gebruiker\Anaconda3\envs\tfpose\lib\importlib\__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""C:\Users\gebruiker\Anaconda3\envs\tfpose\lib\site-packages\tensorflow_core\python\__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\Users\gebruiker\Anaconda3\envs\tfpose\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 74, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""C:\Users\gebruiker\Anaconda3\envs\tfpose\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\gebruiker\Anaconda3\envs\tfpose\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\gebruiker\Anaconda3\envs\tfpose\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\gebruiker\Anaconda3\envs\tfpose\lib\imp.py"", line 243, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\gebruiker\Anaconda3\envs\tfpose\lib\imp.py"", line 343, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: Kan opgegeven module niet vinden.


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/errors

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help."
36724,Bug for TF2.x + TensorRT(7) failing when minimum_segment_size=2,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No, code used from https://github.com/tensorflow/tensorrt/blob/master/tftrt/examples/object_detection/object_detection.py and modified to remove logical errors
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: RHEL 7.6
- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:
- **TensorFlow installed from (source or binary)**: 
- **TensorFlow version (use command below)**: 2.1.0
- **Python version**: 3.7.6
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**: 7.3.0
- **CUDA/cuDNN version**: 10.2/7.6.5
- **GPU model and memory**: Tesla T4
- **Exact command to reproduce**: python object_detection.py  --input_saved_model_dir models/ssd_inception_v2_coco_2018_01_28/saved_model --output_saved_model_dir trt_engine --data_dir coco/val2017  --annotation_path coco/annotations/instances_val2017.json --input_size 640 --batch_size 1 --num_warmup_iterations 10  --minimum_segment_size 2 --num_iterations 20 --use_trt --precision FP16

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with:

```bash
python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""
```

### Describe the problem
Related issue: https://github.com/tensorflow/tensorrt/issues/178
When minimum_segment_size is set to 2 for TensorRT conversion, the code fails with this assertion error and the error log suggests this is a Tensorflow issue.
```
Benchmark arguments:
  annotation_path: coco/annotations/instances_val2017.json
  batch_size: 1
  calib_data_dir: None
  data_dir: coco/val2017
  display_every: 100
  gpu_mem_cap: 0
  input_saved_model_dir: models/ssd_inception_v2_coco_2018_01_28/saved_model
  input_size: 640
  max_workspace_size: 1073741824
  minimum_segment_size: 2
  mode: validation
  num_calib_inputs: 128
  num_iterations: 20
  num_warmup_iterations: 10
  optimize_offline: False
  output_saved_model_dir: trt_engine
  precision: FP16
  target_duration: None
  use_synthetic: False
  use_trt: True
TensorRT Conversion Params:
  is_dynamic_op: True
  max_batch_size: 1
  max_workspace_size_bytes: 1073741824
  maximum_cached_engines: 1
  minimum_segment_size: 2
  precision_mode: FP16
  rewriter_config_template: None
  use_calibration: False
Conversion times:
  conversion: 51.9s
loading annotations into memory...
Done (t=0.96s)
creating index...
index created!
2020-02-13 02:32:55.475297: I tensorflow/compiler/tf2tensorrt/kernels/trt_engine_op.cc:736] Building a new TensorRT engine for StatefulPartitionedCall/Preprocessor/map/while/ResizeImage/TRTEngineOp_293 with input shapes: [[1,640,640,3]]
2020-02-13 02:32:55.475382: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libnvinfer.so.7
2020-02-13 02:32:55.476308: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libnvinfer_plugin.so.7
2020-02-13 02:32:56.821045: W tensorflow/compiler/tf2tensorrt/utils/trt_logger.cc:38] DefaultLogger Current optimization profile is: 0. Please ensure there are no enqueued operations pending in this context prior to switching profiles
2020-02-13 02:32:56.821587: I tensorflow/compiler/tf2tensorrt/kernels/trt_engine_op.cc:736] Building a new TensorRT engine for StatefulPartitionedCall/TRTEngineOp_0 with input shapes: [[1,300,300,3]]
2020-02-13 02:33:40.565597: W tensorflow/compiler/tf2tensorrt/utils/trt_logger.cc:38] DefaultLogger Current optimization profile is: 0. Please ensure there are no enqueued operations pending in this context prior to switching profiles
2020-02-13 02:33:40.568191: I tensorflow/compiler/tf2tensorrt/kernels/trt_engine_op.cc:736] Building a new TensorRT engine for StatefulPartitionedCall/TRTEngineOp_292 with input shapes: [[1,1083,91], [1,600,91], [1,150,91], [1,54,91], [1,24,91], [1,6,91]]
2020-02-13 02:33:40.572484: I tensorflow/compiler/tf2tensorrt/kernels/trt_engine_op.cc:736] Building a new TensorRT engine for StatefulPartitionedCall/MultipleGridAnchorGenerator/TRTEngineOp_19 with input shapes: [[6,2]]
2020-02-13 02:33:40.633713: W tensorflow/compiler/tf2tensorrt/utils/trt_logger.cc:38] DefaultLogger Current optimization profile is: 0. Please ensure there are no enqueued operations pending in this context prior to switching profiles
2020-02-13 02:33:40.633784: I tensorflow/compiler/tf2tensorrt/kernels/trt_engine_op.cc:736] Building a new TensorRT engine for StatefulPartitionedCall/MultipleGridAnchorGenerator/TRTEngineOp_20 with input shapes: [[6,2]]
2020-02-13 02:33:40.662646: W tensorflow/compiler/tf2tensorrt/utils/trt_logger.cc:38] DefaultLogger Current optimization profile is: 0. Please ensure there are no enqueued operations pending in this context prior to switching profiles
2020-02-13 02:33:40.662798: I tensorflow/compiler/tf2tensorrt/kernels/trt_engine_op.cc:736] Building a new TensorRT engine for StatefulPartitionedCall/TRTEngineOp_294 with input shapes: [[1,1083,1,4], [1,600,1,4], [1,150,1,4], [1,54,1,4], [1,24,1,4], [1,6,1,4]]
2020-02-13 02:33:40.670319: W tensorflow/compiler/tf2tensorrt/utils/trt_logger.cc:38] DefaultLogger Current optimization profile is: 0. Please ensure there are no enqueued operations pending in this context prior to switching profiles
2020-02-13 02:33:40.670384: I tensorflow/compiler/tf2tensorrt/kernels/trt_engine_op.cc:736] Building a new TensorRT engine for StatefulPartitionedCall/MultipleGridAnchorGenerator/TRTEngineOp_9 with input shapes: [[1083,2]]
2020-02-13 02:33:40.670419: I tensorflow/compiler/tf2tensorrt/kernels/trt_engine_op.cc:736] Building a new TensorRT engine for StatefulPartitionedCall/MultipleGridAnchorGenerator/TRTEngineOp_8 with input shapes: [[6,2], [6,2]]
2020-02-13 02:33:40.711256: W tensorflow/compiler/tf2tensorrt/utils/trt_logger.cc:38] DefaultLogger Current optimization profile is: 0. Please ensure there are no enqueued operations pending in this context prior to switching profiles
2020-02-13 02:33:40.720622: W tensorflow/compiler/tf2tensorrt/utils/trt_logger.cc:38] DefaultLogger Current optimization profile is: 0. Please ensure there are no enqueued operations pending in this context prior to switching profiles
2020-02-13 02:33:40.720687: I tensorflow/compiler/tf2tensorrt/kernels/trt_engine_op.cc:736] Building a new TensorRT engine for StatefulPartitionedCall/MultipleGridAnchorGenerator/TRTEngineOp_10 with input shapes: [[1083,2]]
2020-02-13 02:33:40.726760: W tensorflow/compiler/tf2tensorrt/utils/trt_logger.cc:38] DefaultLogger Current optimization profile is: 0. Please ensure there are no enqueued operations pending in this context prior to switching profiles
2020-02-13 02:33:40.750769: W tensorflow/compiler/tf2tensorrt/utils/trt_logger.cc:38] DefaultLogger Current optimization profile is: 0. Please ensure there are no enqueued operations pending in this context prior to switching profiles
2020-02-13 02:33:40.750833: I tensorflow/compiler/tf2tensorrt/kernels/trt_engine_op.cc:736] Building a new TensorRT engine for StatefulPartitionedCall/MultipleGridAnchorGenerator/TRTEngineOp_11 with input shapes: [[600,2]]
2020-02-13 02:33:40.750850: I tensorflow/compiler/tf2tensorrt/kernels/trt_engine_op.cc:736] Building a new TensorRT engine for StatefulPartitionedCall/MultipleGridAnchorGenerator/TRTEngineOp_3 with input shapes: [[1083,2], [1083,2]]
2020-02-13 02:33:40.774449: W tensorflow/compiler/tf2tensorrt/utils/trt_logger.cc:38] DefaultLogger Current optimization profile is: 0. Please ensure there are no enqueued operations pending in this context prior to switching profiles
2020-02-13 02:33:40.782585: W tensorflow/compiler/tf2tensorrt/utils/trt_logger.cc:38] DefaultLogger Current optimization profile is: 0. Please ensure there are no enqueued operations pending in this context prior to switching profiles
2020-02-13 02:33:40.782647: I tensorflow/compiler/tf2tensorrt/kernels/trt_engine_op.cc:736] Building a new TensorRT engine for StatefulPartitionedCall/MultipleGridAnchorGenerator/TRTEngineOp_12 with input shapes: [[600,2]]
2020-02-13 02:33:40.808488: W tensorflow/compiler/tf2tensorrt/utils/trt_logger.cc:38] DefaultLogger Current optimization profile is: 0. Please ensure there are no enqueued operations pending in this context prior to switching profiles
2020-02-13 02:33:40.808552: I tensorflow/compiler/tf2tensorrt/kernels/trt_engine_op.cc:736] Building a new TensorRT engine for StatefulPartitionedCall/MultipleGridAnchorGenerator/TRTEngineOp_13 with input shapes: [[150,2]]
2020-02-13 02:33:40.808570: I tensorflow/compiler/tf2tensorrt/kernels/trt_engine_op.cc:736] Building a new TensorRT engine for StatefulPartitionedCall/MultipleGridAnchorGenerator/TRTEngineOp_4 with input shapes: [[600,2], [600,2]]
2020-02-13 02:33:40.831022: W tensorflow/compiler/tf2tensorrt/utils/trt_logger.cc:38] DefaultLogger Current optimization profile is: 0. Please ensure there are no enqueued operations pending in this context prior to switching profiles
2020-02-13 02:33:40.840426: W tensorflow/compiler/tf2tensorrt/utils/trt_logger.cc:38] DefaultLogger Current optimization profile is: 0. Please ensure there are no enqueued operations pending in this context prior to switching profiles
2020-02-13 02:33:40.840488: I tensorflow/compiler/tf2tensorrt/kernels/trt_engine_op.cc:736] Building a new TensorRT engine for StatefulPartitionedCall/MultipleGridAnchorGenerator/TRTEngineOp_14 with input shapes: [[150,2]]
2020-02-13 02:33:40.866507: W tensorflow/compiler/tf2tensorrt/utils/trt_logger.cc:38] DefaultLogger Current optimization profile is: 0. Please ensure there are no enqueued operations pending in this context prior to switching profiles
2020-02-13 02:33:40.866570: I tensorflow/compiler/tf2tensorrt/kernels/trt_engine_op.cc:736] Building a new TensorRT engine for StatefulPartitionedCall/MultipleGridAnchorGenerator/TRTEngineOp_15 with input shapes: [[54,2]]
2020-02-13 02:33:40.866587: I tensorflow/compiler/tf2tensorrt/kernels/trt_engine_op.cc:736] Building a new TensorRT engine for StatefulPartitionedCall/MultipleGridAnchorGenerator/TRTEngineOp_5 with input shapes: [[150,2], [150,2]]
2020-02-13 02:33:40.890943: W tensorflow/compiler/tf2tensorrt/utils/trt_logger.cc:38] DefaultLogger Current optimization profile is: 0. Please ensure there are no enqueued operations pending in this context prior to switching profiles
2020-02-13 02:33:40.899113: W tensorflow/compiler/tf2tensorrt/utils/trt_logger.cc:38] DefaultLogger Current optimization profile is: 0. Please ensure there are no enqueued operations pending in this context prior to switching profiles
2020-02-13 02:33:40.899176: I tensorflow/compiler/tf2tensorrt/kernels/trt_engine_op.cc:736] Building a new TensorRT engine for StatefulPartitionedCall/MultipleGridAnchorGenerator/TRTEngineOp_16 with input shapes: [[54,2]]
2020-02-13 02:33:40.925454: W tensorflow/compiler/tf2tensorrt/utils/trt_logger.cc:38] DefaultLogger Current optimization profile is: 0. Please ensure there are no enqueued operations pending in this context prior to switching profiles
2020-02-13 02:33:40.925518: I tensorflow/compiler/tf2tensorrt/kernels/trt_engine_op.cc:736] Building a new TensorRT engine for StatefulPartitionedCall/MultipleGridAnchorGenerator/TRTEngineOp_17 with input shapes: [[24,2]]
2020-02-13 02:33:40.925538: I tensorflow/compiler/tf2tensorrt/kernels/trt_engine_op.cc:736] Building a new TensorRT engine for StatefulPartitionedCall/MultipleGridAnchorGenerator/TRTEngineOp_6 with input shapes: [[54,2], [54,2]]
2020-02-13 02:33:40.950457: W tensorflow/compiler/tf2tensorrt/utils/trt_logger.cc:38] DefaultLogger Current optimization profile is: 0. Please ensure there are no enqueued operations pending in this context prior to switching profiles
2020-02-13 02:33:40.958686: W tensorflow/compiler/tf2tensorrt/utils/trt_logger.cc:38] DefaultLogger Current optimization profile is: 0. Please ensure there are no enqueued operations pending in this context prior to switching profiles
2020-02-13 02:33:40.958751: I tensorflow/compiler/tf2tensorrt/kernels/trt_engine_op.cc:736] Building a new TensorRT engine for StatefulPartitionedCall/MultipleGridAnchorGenerator/TRTEngineOp_18 with input shapes: [[24,2]]
2020-02-13 02:33:40.984527: W tensorflow/compiler/tf2tensorrt/utils/trt_logger.cc:38] DefaultLogger Current optimization profile is: 0. Please ensure there are no enqueued operations pending in this context prior to switching profiles
2020-02-13 02:33:40.984605: I tensorflow/compiler/tf2tensorrt/kernels/trt_engine_op.cc:736] Building a new TensorRT engine for StatefulPartitionedCall/MultipleGridAnchorGenerator/TRTEngineOp_7 with input shapes: [[24,2], [24,2]]
2020-02-13 02:33:40.998919: W tensorflow/compiler/tf2tensorrt/utils/trt_logger.cc:38] DefaultLogger Current optimization profile is: 0. Please ensure there are no enqueued operations pending in this context prior to switching profiles
2020-02-13 02:33:40.999116: I tensorflow/compiler/tf2tensorrt/kernels/trt_engine_op.cc:736] Building a new TensorRT engine for StatefulPartitionedCall/TRTEngineOp_2 with input shapes: [[1917], [1917], [1917], [1917]]
2020-02-13 02:33:41.113058: W tensorflow/compiler/tf2tensorrt/utils/trt_logger.cc:38] DefaultLogger Current optimization profile is: 0. Please ensure there are no enqueued operations pending in this context prior to switching profiles
2020-02-13 02:33:41.113152: I tensorflow/compiler/tf2tensorrt/kernels/trt_engine_op.cc:736] Building a new TensorRT engine for StatefulPartitionedCall/TRTEngineOp_1 with input shapes: [[1917], [1917], [1917], [1917]]
2020-02-13 02:33:41.229240: W tensorflow/compiler/tf2tensorrt/utils/trt_logger.cc:38] DefaultLogger Current optimization profile is: 0. Please ensure there are no enqueued operations pending in this context prior to switching profiles
2020-02-13 02:33:41.229401: I tensorflow/compiler/tf2tensorrt/kernels/trt_engine_op.cc:736] Building a new TensorRT engine for StatefulPartitionedCall/Postprocessor/TRTEngineOp_291 with input shapes: [[1,1917,4]]
2020-02-13 02:33:41.249654: W tensorflow/compiler/tf2tensorrt/utils/trt_logger.cc:38] DefaultLogger Current optimization profile is: 0. Please ensure there are no enqueued operations pending in this context prior to switching profiles
2020-02-13 02:33:41.252100: I tensorflow/compiler/tf2tensorrt/kernels/trt_engine_op.cc:736] Building a new TensorRT engine for StatefulPartitionedCall/Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/TRTEngineOp_171 with input shapes: [[1917,1]]
2020-02-13 02:33:41.272919: W tensorflow/compiler/tf2tensorrt/utils/trt_logger.cc:38] DefaultLogger Current optimization profile is: 0. Please ensure there are no enqueued operations pending in this context prior to switching profiles
2020-02-13 02:33:41.272990: I tensorflow/compiler/tf2tensorrt/kernels/trt_engine_op.cc:736] Building a new TensorRT engine for StatefulPartitionedCall/Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/TRTEngineOp_175 with input shapes: [[1917,1]]
2020-02-13 02:33:41.275116: I tensorflow/compiler/tf2tensorrt/kernels/trt_engine_op.cc:736] Building a new TensorRT engine for StatefulPartitionedCall/Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ClipToWindow_63/TRTEngineOp_81 with input shapes: [[0,4]]
2020-02-13 02:33:41.276148: E tensorflow/compiler/tf2tensorrt/utils/trt_logger.cc:42] DefaultLogger Parameter check failed at: ../builder/builder.cpp::setMaxBatchSize::135, condition: batchSize > 0 && batchSize <= MAX_BATCH_SIZE
2020-02-13 02:33:41.304032: W tensorflow/compiler/tf2tensorrt/utils/trt_logger.cc:38] DefaultLogger Current optimization profile is: 0. Please ensure there are no enqueued operations pending in this context prior to switching profiles
2020-02-13 02:33:41.304124: I tensorflow/compiler/tf2tensorrt/kernels/trt_engine_op.cc:736] Building a new TensorRT engine for StatefulPartitionedCall/Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/TRTEngineOp_176 with input shapes: [[1917,1]]
2020-02-13 02:33:41.316747: W tensorflow/compiler/tf2tensorrt/utils/trt_logger.cc:38] DefaultLogger Current optimization profile is: 0. Please ensure there are no enqueued operations pending in this context prior to switching profiles
2020-02-13 02:33:41.316786: E tensorflow/compiler/tf2tensorrt/utils/trt_logger.cc:42] DefaultLogger Parameter check failed at: engine.cpp::enqueue::292, condition: batchSize > 0 && batchSize <= mEngine.getMaxBatchSize(). Note: Batch size was: 0, but engine max batch size was: 1
2020-02-13 02:33:41.316800: W tensorflow/compiler/tf2tensorrt/kernels/trt_engine_op.cc:635] Failed to enqueue batch for TRT engine: StatefulPartitionedCall/Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ClipToWindow_63/TRTEngineOp_81
2020-02-13 02:33:41.316816: W tensorflow/compiler/tf2tensorrt/kernels/trt_engine_op.cc:506] Failed to execute engine, retrying with native segment for StatefulPartitionedCall/Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ClipToWindow_63/TRTEngineOp_81
2020-02-13 02:33:41.317449: I tensorflow/compiler/tf2tensorrt/kernels/trt_engine_op.cc:736] Building a new TensorRT engine for StatefulPartitionedCall/Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ClipToWindow_67/TRTEngineOp_85 with input shapes: [[0,4]]
2020-02-13 02:33:41.317620: F tensorflow/core/framework/op_kernel.cc:898] Check failed: mutable_output(index) == nullptr (0x7ff68c02e790 vs. nullptr)
Aborted
```
### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
36723,Allow TrtGraphConverterV2 to accept Frozen Graph input as well as saved_model,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using):2.1
- Are you willing to contribute it (Yes/No):Yes



**Describe the feature and the current behavior/state.**
Currently, the trt API for tensorflow [here](https://github.com/tensorflow/tensorflow/blob/39cfd72c068a290cfff3fb5f61009ccc88ec0064/tensorflow/python/compiler/tensorrt/trt_convert.py#L1039) takes only a saved_model dir as input when it internally converts the saved_model to frozen graph before working on it. Before TF2.x, there was support for both in the form of either giving the saved_model directory or giving the frozen graph def. This change has caused codebases which used frozen_graph to break in functionality even after modifying the code to TF2.x supported APIs.
**Will this change the current api? How?**
This will modify the current API to support the previous TrtGraphConverter API
**Who will benefit with this feature?**
Anyone who has been using frozen_graph for converting using TensorRT inside Tensorflow.
**Any Other info.**
"
36722,Bug: Cannot load model with tf.keras.layers.Lambda & eager functions enabled,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Fedora 31
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): Source
- TensorFlow version (use command below): v2.1.0-1-ga9af83a149 2.1.0
- Python version: 3.7.5
- Bazel version (if compiling from source): 0.29.1
- GCC/Compiler version (if compiling from source): 8.3.1
- CUDA/cuDNN version: 10.2.89 / 7.6.5.33
- GPU model and memory: Nvidia GeForce GTX 1070 TI 8GB

**Describe the current behavior**
When attempting to load a saved model that contains a `tf.keras.layers.Lambda` and eager functions are enabled, it throws the following exception
```
Traceback (most recent call last):
  File ""/tmp/test.py"", line 13, in <module>
    tf.keras.models.load_model(""/tmp/foo"")
  File ""/home/phemmer/.local/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/save.py"", line 150, in load_model
    return saved_model_load.load(filepath, compile)
  File ""/home/phemmer/.local/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/saved_model/load.py"", line 89, in load
    model = tf_load.load_internal(path, loader_cls=KerasObjectLoader)
  File ""/home/phemmer/.local/lib/python3.7/site-packages/tensorflow_core/python/saved_model/load.py"", line 552, in load_internal
    export_dir)
  File ""/home/phemmer/.local/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/saved_model/load.py"", line 119, in __init__
    self._finalize()
  File ""/home/phemmer/.local/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/saved_model/load.py"", line 157, in _finalize
    created_layers={layer.name: layer for layer in node.layers})
  File ""/home/phemmer/.local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py"", line 1903, in reconstruct_from_config
    process_node(layer, node_data)
  File ""/home/phemmer/.local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py"", line 1851, in process_node
    output_tensors = layer(input_tensors, **kwargs)
  File ""/home/phemmer/.local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 773, in __call__
    outputs = call_fn(cast_inputs, *args, **kwargs)
  File ""/home/phemmer/.local/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/saved_model/utils.py"", line 59, in return_outputs_and_add_losses
    outputs, losses = fn(inputs, *args, **kwargs)
  File ""/home/phemmer/.local/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/saved_model/utils.py"", line 113, in wrap_with_training_arg
    lambda: replace_training_and_call(False))
  File ""/home/phemmer/.local/lib/python3.7/site-packages/tensorflow_core/python/keras/utils/tf_utils.py"", line 59, in smart_cond
    pred, true_fn=true_fn, false_fn=false_fn, name=name)
  File ""/home/phemmer/.local/lib/python3.7/site-packages/tensorflow_core/python/framework/smart_cond.py"", line 59, in smart_cond
    name=name)
  File ""/home/phemmer/.local/lib/python3.7/site-packages/tensorflow_core/python/util/deprecation.py"", line 507, in new_func
    return func(*args, **kwargs)
  File ""/home/phemmer/.local/lib/python3.7/site-packages/tensorflow_core/python/ops/control_flow_ops.py"", line 1174, in cond
    return cond_v2.cond_v2(pred, true_fn, false_fn, name)
  File ""/home/phemmer/.local/lib/python3.7/site-packages/tensorflow_core/python/ops/cond_v2.py"", line 83, in cond_v2
    op_return_value=pred)
  File ""/home/phemmer/.local/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py"", line 978, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File ""/home/phemmer/.local/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/saved_model/utils.py"", line 112, in <lambda>
    lambda: replace_training_and_call(True),
  File ""/home/phemmer/.local/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/saved_model/utils.py"", line 108, in replace_training_and_call
    return wrapped_call(*args, **kwargs)
  File ""/home/phemmer/.local/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py"", line 555, in __call__
    return self._python_function(*args, **kwds)
  File ""/home/phemmer/.local/lib/python3.7/site-packages/tensorflow_core/python/saved_model/function_deserialization.py"", line 262, in restored_function_body
    ""\n\n"".join(signature_descriptions)))
ValueError: Could not find matching function to call loaded from the SavedModel. Got:
  Positional arguments (1 total):
    * Tensor(""input_1_1:0"", shape=(None, 3), dtype=float32)
  Keyword arguments: {'training': True}

Expected these arguments to match one of the following 2 option(s):

Option 1:
  Positional arguments (3 total):
    * TensorSpec(shape=(None, 3), dtype=tf.float32, name='inputs')
    * None
    * True
  Keyword arguments: {}

Option 2:
  Positional arguments (3 total):
    * TensorSpec(shape=(None, 3), dtype=tf.float32, name='inputs')
    * None
    * False
  Keyword arguments: {}
```
**Describe the expected behavior**
No exception

This issue does kinda make sense, in that eager means to run native python instead of as a graph, in which case the python lambda can't be created from a saved model. But I think there's probably a better way to handle it than this. Maybe forcing this one part of the model to run as a graph.

**Code to reproduce the issue**
```python
import tensorflow as tf

tf.config.experimental_run_functions_eagerly(True)

ds = tf.data.Dataset.from_tensor_slices([[1,2,3],[4,5,6],[7,8,9]])

input = tf.keras.Input(shape=ds.element_spec.shape)

output = tf.keras.layers.Lambda(lambda tb: tb)(input)

model = tf.keras.Model(inputs=[input],outputs=[output])
model.save(""/tmp/foo"")
tf.keras.models.load_model(""/tmp/foo"")
```"
36721,Github issue creation for bugs missing,"Note that the option for bug reports is missing.

![image](https://user-images.githubusercontent.com/1826947/74403305-c9ba2500-4df4-11ea-8ec4-bc18da185557.png)

I suspect this is related to #36636 which was recently merged.

When I look at the [`00-bug-issue.md` file](https://raw.githubusercontent.com/tensorflow/tensorflow/master/.github/ISSUE_TEMPLATE/00-bug-issue.md), there is a space instead of a newline before `about:`. Don't know if this would cause it to go missing, but definitely seems not right.
![image](https://user-images.githubusercontent.com/1826947/74403503-6381d200-4df5-11ea-8d05-39f44b5c7ed8.png)

Others appear missing as well, such as the build/installation issue, & performance issue.
"
36720,Getting SavedModel format from Checkpoint automatically,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using):2.1.0
- Are you willing to contribute it (Yes/No):Yes



**Describe the feature and the current behavior/state.** None

**Will this change the current api? How?** Add a method to the savedModel API for getting savedModel from checkpoint directly. 

**Who will benefit with this feature?** Everyone who is facing trouble converting to a SavedModel from a checkpoint graph

**Any Other info.**
I've faced this challenge 
"
36719,name: Bug Issue about: why the performance of nnapi is much lower than cpu . labels: 'type:bug_template',"#36088 # System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:no
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: android O
- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: GLK-AL00,Mi 6,vivo NEX,MI 8 SE

### Describe the problem
I write  nnapidelegate in my Engine just like nnapidelegate in tensorflowlite. When i run the same model, the performance on devices GLK-AL00,Mi 6,vivo NEX,MI 8 SE is more than 200ms, on Pixel 2 XL is 25ms, on mi 9 ,SamSung G9700  is lower than 10ms. Who can tell me why the performance on GLK-AL00,Mi 6,vivo NEX,MI 8 SE is such lower than Pixel 2 XL.



"
36718,"[TPU Colab] [TF2.1] Many issues only on TPU due to data types, batch sizes and memory (gist provided with explanations)","### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes, see gists with code on Colab [not working on TPU](https://colab.research.google.com/drive/1yk4Emyzxju85gqflEii9FVuMD6VF5vta) and [working on GPU](https://colab.research.google.com/drive/1d4_RPQ2wHg6q4wr-J8VzjSi_DMTLRZDp).
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Google Colab
- **TensorFlow installed from (source or binary)**: `%tensorflow_version 2.x` command
- **TensorFlow version (use command below)**: `2.1.0`

### Describe the problem
All the issues are shown and described in the [gist provided](https://colab.research.google.com/drive/1yk4Emyzxju85gqflEii9FVuMD6VF5vta). Here is the list of the issues:
- Issue 1: Models fitted on TPU does not deal number of samples not divisible by batch size.
- Issue 1bis: With argument validation_split on TPU, issue 1 may occur with number of samples not divisible by batch size.
- Issue 2: List of supported dtypes on TPU is restrictive.
- Issue 2bis: Predict on TPU has the same dtype constraints than fit on TPU.
- Issue 3: Number of samples may cause error for prediction on TPU
- Issue 4: Batch size may cause error for prediction on TPU
- Issue 4bis: Warnings when predicting on TPU
- Issue 5: Trying to fit or predict on TPU a model on a supported dtype after having tried on a not supported dtype may raise an error.
- Issue 6: `UnavailableError: Socket closed` on TPU and related errors

### Source code / logs
[See Gist provided.](https://colab.research.google.com/drive/1yk4Emyzxju85gqflEii9FVuMD6VF5vta)
"
42784,Tensorflow installation document Korean translated page outdated,"## URL(s) with the issue 

https://www.tensorflow.org/install?hl=ko

## Description of issue (what needs changing)

On installation document/windows build from source page, it tells that ""TensorFlow를 컴파일하는 데 사용되는 빌드 도구인 Bazel 0.23.0을 설치합니다. C++를 빌드하도록 Bazel을 설정합니다."" which means install Bazel 0.23.0 to compile Tensorflow. However, most recent version of Tensorflow which is r2.1, doesn't support Bazel 0.23.0. Instead, it uses 0.27.0~0.29.0. I checked English document and it tells me the version of Bazel that is needed. So, I think the Korean page should be renewed like this.

## Bazel 설치

TensorFlow를 컴파일하는 데 사용되는 빌드 도구인 [Bazel](https://docs.bazel.build/versions/master/install.html)을 설치합니다. tensorflow/configure.py에 명시된 _TF_MIN_BAZEL_VERSION과 _TF_MAX_BAZEL_VERSION 사이의 지원되는 버전을 사용합니다.

Bazel 실행 파일의 위치를 %PATH% 환경 변수에 추가합니다."
36717,MKL no longer works with tensorflow 1.15,"------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: NO

- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Centos 7

- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: N/A
- **TensorFlow installed from (source or binary)**: source
- **TensorFlow version (use command below)**: 1.15.2
- **Python version**: N/A
- **Bazel version (if compiling from source)**: 0.24.1
- **GCC/Compiler version (if compiling from source)**: gcc-6 (devtoolset-6 on centos 7)
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**:
```bash
 bazel build -c opt --copt=-msse4.2 --copt=-mavx \
       --copt=-O3 --config=mkl --linkopt -ldl \
       --copt=-march=x86-64 \
       //tensorflow/tools/pip_package:build_pip_package \
       //tensorflow/tools/lib_package:libtensorflow_jni \
       //tensorflow/tools/lib_package:libtensorflow \
       //tensorflow/tools/lib_package:libtensorflow_proto \
```

### Describe the problem
libtensorflow_framework.so build this way does not have any symbols from MKL. When trying to import tensorflow from ~~java~~ scala, it fails with symbol not found for `tensorflow::DisableMKL()`

The number of MKL symbols found in `libtensorflow_framework.so` for 1.15 are also significantly lower than those found in 1.14.

### Source code / logs

Code used to import tensorflow in scala

```scala
import org.tensorflow.Tensorflow
```
Note: We have to ensure `libiomp5.so` and `libmklml_intel.so` are available on library load path. 

The simplest solution we found was to load the libraries manually in order. The code snippet can be seen here:
https://gist.github.com/pavanky/ea6e71e3e7e52c013db844b715723be0
 

Error

```
libtensorflow_jni.so: undefined symbol: _ZN10tensorflow10DisableMKLEv
```

Looking at the number of symbols related to MKL:

```	
 $ nm -D org/tensorflow/native/linux-x86_64/libtensorflow_framework.so.1 | grep -i mkl | wc -l
1
 $ nm -D org/tensorflow/native/linux-x86_64/libtensorflow_jni.so | grep -i mkl | wc -l
9
 $ nm -D org/tensorflow/native/linux-x86_64/libtensorflow_framework.so.1 | grep -i mkl
0000000000e127b0 T _ZN10tensorflow12IsMklEnabledEv
```

For reference, 1.14 had a lot more

```
 $ nm -D org/tensorflow/native/linux-x86_64/libtensorflow_framework.so.1 | grep -i mkl | wc -l
11388
 $ nm -D org/tensorflow/native/linux-x86_64/libtensorflow_jni.so | grep -i mkl | wc -l
8
```

---------
MKL is also not available in the wheel built by the command mentioned above.

```python
>>> import tensorflow as tf
>>> tf.python.pywrap_tensorflow.IsMklEnabled()
False
```"
36715,BUG: tf.random.normal() has a fixed value in eager mode (TF2.0),"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: 
- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**: v2.0.0-rc2-26-g64c3d38 2.0.0
- **Python version**: 3.6.9
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with:

```bash
python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""
```

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

In Tf2.0 eager mode, tf.random.normal() will give the same value over and over again. This happens whether you use a Keras Model or just call the tf.random.normal() tensor repeatedly:

```
import numpy as np
import tensorflow as tf

id = np.ones(shape=(32,10))
i = tf.keras.layers.Input(shape=(10,), batch_size=32, dtype=tf.float64)
y = tf.random.normal(shape=(32,10), name=""noise"", dtype=tf.float64)
o = tf.add(i, y)
model = tf.keras.Model(inputs=i, outputs=o)

# same value every time?
model.predict(id)
model.predict(id)
model.predict(id)
```

This occurs without Keras as well:

```
x = tf.constant(value=np.ones(shape=(32,10)), dtype=tf.float64)
y = tf.random.normal(shape=(32,10), name=""noise"", dtype=tf.float64)
z = tf.add(x, y)
print(z)
print(z)
print(z)
```

If you disable eager mode with tf.compat.v1.disable_eager_execution(), the Keras Model will generate new values each time it's called (as it should).

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
36714,"Tensorflow Serving | Input to reshape is a tensor with 512 values, but the requested shape has 1","### System information
Ubuntu 18.04.4 LTS
TF version 2.1.0
Python 3.6.9

While serving a tensorflow model I keep getting the same error related to tensor shape, it seems that tensors lose 1 dimension while in serving. Everything works fine before hosting.

Model definition:
```import tensorflow as tf
import numpy as np
import requests
import json

x1_ = tf.keras.Input(shape=(64,256,))
x2_ = tf.keras.Input(shape=(512,))


W1 = tf.keras.layers.Dense(512)
W2 = tf.keras.layers.Dense(512)

x1 = W1(x1_)
x2 = tf.expand_dims(x2_, 1)
x2 = W2(x2)
y = tf.math.add(x1, x2)

Model = tf.keras.Model([x1_, x2_], [y])
model = Model

tf.saved_model.save(model, ""/tmp/models/model/1/"")
```
Docker command to launch the container:
```
docker run --rm -p 8504:8501 --name tfserving_test3 \
--mount type=bind,source=""/tmp/models/model"",target=/models/tensorflow_model \
-e MODEL_NAME=tensorflow_model -t tensorflow/serving
```


Send a request to the API:
```
x1 = np.random.normal(size=(1,64,256))
x2 = np.zeros((1, 512), dtype=np.float32)

values = [x1.tolist(), x2.tolist()]
inputs = {t.name[:-2]:t for t in model.inputs}

d = dict(zip(inputs, values))
data = {""instances"": [d]}
data = json.dumps(data)

r = requests.post('http://localhost:8504/v1/models/tensorflow_model:predict', data=data)
print(r.content.decode('utf-8'))
```

It seems that while serving one of the tensors lose a dimension. I tried to expand dims and then reshape to make sure that the model still works fine in training but it had no impact while serving.

"
36712,"KeyError of identity node, when using Skip Connection and RandomDrop together","- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10
- **TensorFlow installed from (source or binary)**: pip
- **TensorFlow version (use command below)**: v2.1.0-rc2-17-ge5bf8de410 2.1.0
- **Python version**: 3.7.6 Anaconda
- **CUDA/cuDNN version**: 10.2 / 7.6.5
- **GPU model and memory**: RTX2070 mobile, 8GB

### Minimal example:
```
import tensorflow as tf

class OpOrSkip(tf.keras.layers.Layer):
    def __init__(self, op):
        super().__init__()
        self.op = op
        
    def call(self, x):
        rnd = tf.random.uniform(())
        if rnd < 0.5:
            return self.op(x)
        else:
            return x

def skip_conv(s):
    x = tf.keras.layers.Conv2D(3, 3, padding='same')(s)
    return x + s #tf.identity(s, name='s')

def func_as_model(func, shape):
    inp = tf.keras.Input(shape)
    out = func(inp)
    return tf.keras.Model(inputs=inp, outputs=out)

inputs = tf.keras.Input((32, 32, 3))
SkipConv = func_as_model(skip_conv, [32, 32, 3])

x = OpOrSkip(SkipConv)(inputs)
model = tf.keras.Model(inputs=inputs, outputs=x)
```

### Describe the problem
I am building a resnet network, so a network with skip connections, but also with RandomDrop, that is dropping the whole residual with some probability. However, I can't do this in tensorflow 2, wheras it was possible in tensorflow 1. The error occurs only when both skip connection and RandomDrop are preset at once.

My observation is tensorflow confuses shortcut in `skip_conv` with another node. When I try to name this shortcut using `tf.identity`, I get yet another error. However I expect it to work without explicitly naming the identity node.

The alternative for `s` is commented in the code (`tf.identity(s, name='s')`). Error in the first version occurs when only defining the model. When named the identity node, the error occurs only when using model in a graph (in `@tf.function` decorated function).

### Source code / logs
```
---------------------------------------------------------------------------
KeyError                                  Traceback (most recent call last)
<ipython-input-9-c655ea21defb> in <module>()
     27 SkipConv = func_as_model(skip_conv, [32, 32, 3])
     28 
---> 29 x = OpOrSkip(SkipConv)(inputs)
     30 model = tf.keras.Model(inputs=inputs, outputs=x)

C:\Users\gaha\Anaconda3\lib\site-packages\tensorflow_core\python\keras\engine\base_layer.py in __call__(self, inputs, *args, **kwargs)
    771                     not base_layer_utils.is_in_eager_or_tf_function()):
    772                   with auto_control_deps.AutomaticControlDependencies() as acd:
--> 773                     outputs = call_fn(cast_inputs, *args, **kwargs)
    774                     # Wrap Tensors in `outputs` in `tf.identity` to avoid
    775                     # circular dependencies.

C:\Users\gaha\Anaconda3\lib\site-packages\tensorflow_core\python\autograph\impl\api.py in wrapper(*args, **kwargs)
    235       except Exception as e:  # pylint:disable=broad-except
    236         if hasattr(e, 'ag_error_metadata'):
--> 237           raise e.ag_error_metadata.to_exception(e)
    238         else:
    239           raise

KeyError: in converted code:

    <ipython-input-1-56c161fa68ed>:12 call  *
        if rnd < 0.5:
    C:\Users\gaha\Anaconda3\lib\site-packages\tensorflow_core\python\autograph\operators\control_flow.py:918 if_stmt
        basic_symbol_names, composite_symbol_names)
    C:\Users\gaha\Anaconda3\lib\site-packages\tensorflow_core\python\autograph\operators\control_flow.py:956 tf_if_stmt
        error_checking_orelse)
    C:\Users\gaha\Anaconda3\lib\site-packages\tensorflow_core\python\util\deprecation.py:507 new_func
        return func(*args, **kwargs)
    C:\Users\gaha\Anaconda3\lib\site-packages\tensorflow_core\python\ops\control_flow_ops.py:1174 cond
        return cond_v2.cond_v2(pred, true_fn, false_fn, name)
    C:\Users\gaha\Anaconda3\lib\site-packages\tensorflow_core\python\ops\cond_v2.py:83 cond_v2
        op_return_value=pred)
    C:\Users\gaha\Anaconda3\lib\site-packages\tensorflow_core\python\framework\func_graph.py:1019 func_graph_from_py_func
        func_graph.variables = variables
    C:\Users\gaha\Anaconda3\lib\site-packages\tensorflow_core\python\framework\auto_control_deps.py:324 __exit__
        for inp in op.inputs:
    C:\Users\gaha\Anaconda3\lib\site-packages\tensorflow_core\python\framework\ops.py:2163 inputs
        c_api.GetOperationInputs(self._c_op)))
    C:\Users\gaha\Anaconda3\lib\site-packages\tensorflow_core\python\framework\ops.py:3696 _get_tensor_by_tf_output
        op = self._get_operation_by_tf_operation(tf_output.oper)
    C:\Users\gaha\Anaconda3\lib\site-packages\tensorflow_core\python\framework\ops.py:3660 _get_operation_by_tf_operation
        return self._get_operation_by_name_unsafe(op_name)
    C:\Users\gaha\Anaconda3\lib\site-packages\tensorflow_core\python\framework\ops.py:3656 _get_operation_by_name_unsafe
        return self._nodes_by_name[name]

    KeyError: 'input_17'
```
"
36711,Error TFLite converting tensorflow graph generated with config file with experimental_new_converter = True,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- TensorFlow installed from (source or binary): binary (pip)
- TensorFlow version (or github SHA if from source): TF Nightly 2.2.0-dev20200212

**Command used to run the converter or code if you’re using the Python API**

```
converter = tf.lite.TFLiteConverter.from_concrete_functions([inception_func])
converter.optimizations = [tf.lite.Optimize.DEFAULT]
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]
converter.target_spec.supported_types = [tf.int8, tf.uint8]
converter.inference_input_type = tf.uint8
converter.inference_output_type = tf.uint8
converter.experimental_new_converter = True
tflite_model = converter.convert()
```

**The output from the converter invocation**

```
2020-02-12 14:44:53.272916: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-02-12 14:44:53.293807: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1558] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 510.07GiB/s
2020-02-12 14:44:53.294407: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1558] Found device 1 with properties: 
pciBusID: 0000:02:00.0 name: TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 510.07GiB/s
2020-02-12 14:44:53.294542: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory
2020-02-12 14:44:53.295848: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-02-12 14:44:53.297069: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-02-12 14:44:53.297272: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-02-12 14:44:53.298655: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-02-12 14:44:53.299389: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-02-12 14:44:53.299452: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory
2020-02-12 14:44:53.299461: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1595] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2020-02-12 14:44:53.299683: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-02-12 14:44:53.327596: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 3597955000 Hz
2020-02-12 14:44:53.328433: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55838544dd10 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-02-12 14:44:53.328472: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-02-12 14:44:53.331414: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1099] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-02-12 14:44:53.331444: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1105]      
<generator object image_files_gen at 0x7febddc4ed50>
2020-02-12 14:44:54.788049: I tensorflow/core/profiler/lib/profiler_session.cc:159] Profiler session started.
2020-02-12 14:44:54.788083: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1363] Profiler found 2 GPUs
2020-02-12 14:44:54.788196: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcupti.so.10.1'; dlerror: libcupti.so.10.1: cannot open shared object file: No such file or directory
2020-02-12 14:44:54.788207: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1408] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI could not be loaded or symbol could not be found.
2020-02-12 14:44:54.788215: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1447] function cupti_interface_->ActivityRegisterCallbacks( AllocCuptiActivityBuffer, FreeCuptiActivityBuffer)failed with error CUPTI could not be loaded or symbol could not be found.
[<tf.Tensor: shape=(1, 100, 4), dtype=float32, numpy=
array([[[0.4523084 , 0.19130976, 0.48489496, 0.25743166],
        [0.44898474, 0.19012845, 0.48815066, 0.2607174 ],
        [0.6068166 , 0.04942099, 0.63641137, 0.11622739],
        [0.45264566, 0.1908576 , 0.48534685, 0.2560804 ],
        [0.45322064, 0.19343509, 0.48580036, 0.25778043],
        [0.50848585, 0.576692  , 0.53330845, 0.6251781 ],
        [0.45322064, 0.19343509, 0.48580036, 0.25778043],
        [0.4494503 , 0.17628026, 0.48778558, 0.2566436 ],
        [0.527445  , 0.33889085, 0.55464226, 0.39898926],
        [0.45296955, 0.1903181 , 0.48529047, 0.25696498],
        [0.5204598 , 0.32256034, 0.5480597 , 0.39266023],
        [0.63632804, 0.6682412 , 0.6719902 , 0.7374546 ],
        [0.45650837, 0.19338551, 0.4927548 , 0.277421  ],
        [0.44446883, 0.1737675 , 0.4827005 , 0.25779355],
        [0.72652483, 0.2473509 , 0.7562058 , 0.30082873],
        [0.9542563 , 0.843302  , 1.        , 0.96409976],
        [0.11040416, 0.00447438, 0.13210008, 0.03558907],
        [0.45264566, 0.1908576 , 0.48534685, 0.2560804 ],
        [0.4523084 , 0.19130976, 0.48489496, 0.25743166],
        [0.44075978, 0.14530185, 0.48041832, 0.25093415],
        [0.15409914, 0.94093376, 0.1896761 , 1.        ],
        [0.45264566, 0.1908576 , 0.48534685, 0.2560804 ],
        [0.6068166 , 0.04942099, 0.63641137, 0.11622739],
        [0.50790685, 0.7605634 , 0.53323144, 0.82372105],
        [0.10795376, 0.0060998 , 0.13245544, 0.04638027],
        [0.4466028 , 0.18642351, 0.4799665 , 0.24573368],
        [0.52835655, 0.28773227, 0.5562326 , 0.34618238],
        [0.45650837, 0.19338551, 0.4927548 , 0.277421  ],
        [0.3502379 , 0.44612858, 0.38212806, 0.50805885],
        [0.64212465, 0.39890158, 0.6739552 , 0.49036568],
        [0.45171025, 0.19052231, 0.4847984 , 0.25762528],
        [0.12097565, 0.00399387, 0.1428402 , 0.03510833],
        [0.4466028 , 0.18642351, 0.4799665 , 0.24573368],
        [0.17729592, 0.19604556, 0.20469955, 0.26705974],
        [0.45841685, 0.14860368, 0.5037309 , 0.26684842],
        [0.11995812, 0.00256568, 0.14446093, 0.05109425],
        [0.5166499 , 0.2938283 , 0.5506055 , 0.39516765],
        [0.5196249 , 0.32896924, 0.54816073, 0.38678855],
        [0.31064248, 0.7969677 , 0.35238957, 0.8906676 ],
        [0.51701736, 0.30636752, 0.55060136, 0.40481085],
        [0.22814384, 0.32451725, 0.259156  , 0.41317737],
        [0.50587946, 0.30761832, 0.53356034, 0.37745112],
        [0.45861158, 0.2037143 , 0.4902828 , 0.2635113 ],
        [0.4471084 , 0.184802  , 0.47876382, 0.25051934],
        [0.43582347, 0.19232129, 0.4744096 , 0.26392525],
        [0.45296955, 0.1903181 , 0.48529047, 0.25696498],
        [0.01486549, 0.        , 0.07320484, 0.08066794],
        [0.        , 0.09366378, 0.21820027, 0.9756663 ],
        [0.54991406, 0.5637065 , 0.691194  , 0.96959376],
        [0.59876406, 0.04728752, 0.6286751 , 0.11585537],
        [0.53492194, 0.08620362, 0.5909355 , 0.24983023],
        [0.70816135, 0.00839768, 0.74530756, 0.06555284],
        [0.686458  , 0.944192  , 0.75062335, 1.        ],
        [0.4471084 , 0.184802  , 0.47876382, 0.25051934],
        [0.13161138, 0.45191422, 0.15738365, 0.5095992 ],
        [0.4885881 , 0.80888736, 0.54836   , 0.978459  ],
        [0.13416171, 0.00377405, 0.1561068 , 0.03560173],
        [0.45158228, 0.19188425, 0.48981753, 0.2612535 ],
        [0.75087017, 0.00396507, 0.78542954, 0.06046526],
        [0.637136  , 0.66719157, 0.66992843, 0.7352523 ],
        [0.5243317 , 0.29501545, 0.5598284 , 0.39330977],
        [0.44330403, 0.1994324 , 0.48607805, 0.27255926],
        [0.4471084 , 0.184802  , 0.47876382, 0.25051934],
        [0.96380365, 0.84537166, 1.        , 0.9437652 ],
        [0.44857678, 0.18810245, 0.48808834, 0.25654176],
        [0.5276355 , 0.2980371 , 0.55767304, 0.364582  ],
        [0.51808655, 0.3211314 , 0.5516435 , 0.41390526],
        [0.44262165, 0.2258066 , 0.49634498, 0.2604202 ],
        [0.51671165, 0.23575601, 0.5696979 , 0.38195243],
        [0.5159677 , 0.2698248 , 0.56696165, 0.4135533 ],
        [0.16784409, 0.18931931, 0.19625813, 0.26827484],
        [0.44924247, 0.11680316, 0.48714614, 0.24786523],
        [0.6068166 , 0.04942099, 0.63641137, 0.11622739],
        [0.5007901 , 0.58252937, 0.527007  , 0.63281745],
        [0.4662144 , 0.19344129, 0.5073866 , 0.26448467],
        [0.19347599, 0.5412288 , 0.21763065, 0.5982214 ],
        [0.44075978, 0.14530185, 0.48041832, 0.25093415],
        [0.44787258, 0.2035003 , 0.48078   , 0.26272708],
        [0.36003056, 0.43164626, 0.39625302, 0.5073702 ],
        [0.85064745, 0.2225066 , 0.8861109 , 0.31016666],
        [0.5810017 , 0.11662646, 0.6081669 , 0.17228721],
        [0.45315146, 0.17665324, 0.48381698, 0.2442483 ],
        [0.63825023, 0.        , 1.        , 1.        ],
        [0.27971706, 0.21467996, 0.33935127, 0.41237378],
        [0.20111686, 0.9416385 , 0.23956841, 1.        ],
        [0.44525808, 0.17430884, 0.47413707, 0.23905429],
        [0.44446883, 0.1737675 , 0.4827005 , 0.25779355],
        [0.44451416, 0.1914759 , 0.4826401 , 0.27257037],
        [0.18308899, 0.00234124, 0.20454633, 0.03471272],
        [0.56354165, 0.11042208, 0.5989641 , 0.18208715],
        [0.8662053 , 0.26750824, 1.        , 0.6562464 ],
        [0.45214534, 0.21824962, 0.48541468, 0.2723656 ],
        [0.5272091 , 0.18768561, 0.5903445 , 0.34028006],
        [0.1258346 , 0.9409971 , 0.16100453, 1.        ],
        [0.44988436, 0.19079384, 0.48194766, 0.25922737],
        [0.5381035 , 0.7981993 , 0.5771181 , 0.885656  ],
        [0.51808256, 0.29529324, 0.54818624, 0.36529002],
        [0.44561428, 0.12746832, 0.48472154, 0.25478205],
        [0.55583   , 0.39829937, 0.6881298 , 0.8807714 ],
        [0.12827086, 0.        , 0.15974712, 0.02394507]]], dtype=float32)>, <tf.Tensor: shape=(1, 100), dtype=float32, numpy=
array([[0.92555547, 0.04032728, 0.04001778, 0.03919104, 0.0389992 ,
        0.03491211, 0.03117302, 0.02736771, 0.02710325, 0.02648216,
        0.02614886, 0.02420676, 0.02387115, 0.02345794, 0.02287492,
        0.02275831, 0.02204138, 0.02131733, 0.02058503, 0.02054   ,
        0.0202291 , 0.0200913 , 0.01930887, 0.01929054, 0.0186362 ,
        0.01838633, 0.01820371, 0.01814541, 0.0180732 , 0.01789805,
        0.01755115, 0.01670685, 0.01663533, 0.01650512, 0.01644138,
        0.01569021, 0.01568368, 0.01562142, 0.0155603 , 0.01543599,
        0.01460987, 0.01423776, 0.0142113 , 0.01356006, 0.01343337,
        0.01308289, 0.01273718, 0.01269153, 0.01266637, 0.01263455,
        0.01250893, 0.01249737, 0.01232877, 0.01232168, 0.01225841,
        0.01223144, 0.01213449, 0.01195824, 0.01176769, 0.01173973,
        0.01167473, 0.01161668, 0.01140118, 0.0113658 , 0.01134393,
        0.01127735, 0.01115933, 0.01114836, 0.01104337, 0.01092488,
        0.0109069 , 0.01084158, 0.01068258, 0.01066345, 0.0105837 ,
        0.01057971, 0.01048639, 0.01046959, 0.01027715, 0.01023829,
        0.01021823, 0.01019359, 0.01015976, 0.01008341, 0.01005188,
        0.00993064, 0.00975928, 0.00972691, 0.00967205, 0.00965327,
        0.00961038, 0.00959793, 0.00955415, 0.00954556, 0.00948521,
        0.0093832 , 0.00936151, 0.00935119, 0.00931564, 0.00920397]],
      dtype=float32)>, <tf.Tensor: shape=(1, 100), dtype=float32, numpy=
array([[15., 13.,  4.,  3., 12., 15., 10., 16.,  8.,  9., 10., 13., 15.,
        15., 15.,  8., 14.,  1.,  2., 16., 12., 14., 10., 10.,  4., 12.,
        13., 13.,  5.,  8.,  8., 14., 13.,  4., 15.,  4., 16.,  8.,  5.,
        10.,  3., 10., 12.,  2., 12.,  4., 11., 16.,  3.,  4., 10., 13.,
         5., 10.,  4., 10., 14., 11., 12.,  8., 16., 15.,  1.,  7.,  6.,
        13., 16., 14., 10., 10.,  4., 16., 16., 15., 15.,  4.,  1., 12.,
        12., 10.,  4., 10., 16.,  4., 12., 10.,  3., 16., 14.,  8.,  1.,
        15.,  3.,  4.,  7.,  8., 10., 10.,  3., 14.]], dtype=float32)>, <tf.Tensor: shape=(1,), dtype=float32, numpy=array([100.], dtype=float32)>]
2020-02-12 14:44:56.654298: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1430] function cupti_interface_->EnableCallback( 0 , subscriber_, CUPTI_CB_DOMAIN_DRIVER_API, cbid)failed with error CUPTI could not be loaded or symbol could not be found.
2020-02-12 14:44:56.654980: I tensorflow/core/profiler/internal/gpu/device_tracer.cc:203]  GpuTracer has collected 0 callback api events and 0 activity events.
CONVERTING




2020-02-12 14:44:56.953373: I tensorflow/core/grappler/devices.cc:55] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 2
2020-02-12 14:44:56.953474: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session
2020-02-12 14:44:57.201293: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55839683e470 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-02-12 14:44:57.201338: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2020-02-12 14:44:57.201351: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): TITAN Xp, Compute Capability 6.1
2020-02-12 14:44:57.205900: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1558] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 510.07GiB/s
2020-02-12 14:44:57.207642: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1558] Found device 1 with properties: 
pciBusID: 0000:02:00.0 name: TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 510.07GiB/s
2020-02-12 14:44:57.207835: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory
2020-02-12 14:44:57.207873: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-02-12 14:44:57.207900: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-02-12 14:44:57.207925: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-02-12 14:44:57.207949: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-02-12 14:44:57.207973: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-02-12 14:44:57.208090: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory
2020-02-12 14:44:57.208110: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1595] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2020-02-12 14:44:57.208187: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1099] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-02-12 14:44:57.208206: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1105]      0 1 
2020-02-12 14:44:57.208221: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1118] 0:   N Y 
2020-02-12 14:44:57.208234: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1118] 1:   Y N 
2020-02-12 14:44:57.433135: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: graph_to_optimize
2020-02-12 14:44:57.433170: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: Graph size after: 2451 nodes (0), 2754 edges (0), time = 28.091ms.
2020-02-12 14:44:57.433174: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: Graph size after: 2451 nodes (0), 2754 edges (0), time = 30.465ms.
2020-02-12 14:44:57.433178: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: PadOrClipBoxList_cond_1_false_5569
2020-02-12 14:44:57.433182: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: Graph size after: 20 nodes (0), 22 edges (0), time = 0.312ms.
2020-02-12 14:44:57.433185: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: Graph size after: 20 nodes (0), 22 edges (0), time = 0.299ms.
2020-02-12 14:44:57.433189: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: PadOrClipBoxList_cond_2_true_5627
2020-02-12 14:44:57.433192: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-02-12 14:44:57.433195: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-02-12 14:44:57.433198: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: PadOrClipBoxList_cond_3_true_5686
2020-02-12 14:44:57.433204: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-02-12 14:44:57.433207: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-02-12 14:44:57.433210: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: cond_true_5533
2020-02-12 14:44:57.433214: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-02-12 14:44:57.433217: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-02-12 14:44:57.433224: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: cond_false_5652
2020-02-12 14:44:57.433228: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-02-12 14:44:57.433231: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-02-12 14:44:57.433236: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: PadOrClipBoxList_cond_2_false_5628
2020-02-12 14:44:57.433242: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: Graph size after: 20 nodes (0), 22 edges (0), time = 0.278ms.
2020-02-12 14:44:57.433246: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: Graph size after: 20 nodes (0), 22 edges (0), time = 0.295ms.
2020-02-12 14:44:57.433251: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: cond_true_5592
2020-02-12 14:44:57.433256: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-02-12 14:44:57.433260: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-02-12 14:44:57.433264: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: PadOrClipBoxList_cond_1_true_5568
2020-02-12 14:44:57.433269: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-02-12 14:44:57.433273: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-02-12 14:44:57.433277: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: Postprocessor_BatchMultiClassNonMaxSuppression_map_while_cond_4116
2020-02-12 14:44:57.433282: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-02-12 14:44:57.433286: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-02-12 14:44:57.433290: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: Preprocessor_map_while_body_20
2020-02-12 14:44:57.433295: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-02-12 14:44:57.433299: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-02-12 14:44:57.433303: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: cond_false_5534
2020-02-12 14:44:57.433308: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-02-12 14:44:57.433312: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-02-12 14:44:57.433316: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: cond_true_5651
2020-02-12 14:44:57.433321: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-02-12 14:44:57.433325: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-02-12 14:44:57.433329: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: PadOrClipBoxList_cond_3_false_5687
2020-02-12 14:44:57.433334: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: Graph size after: 20 nodes (0), 22 edges (0), time = 0.284ms.
2020-02-12 14:44:57.433339: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: Graph size after: 20 nodes (0), 22 edges (0), time = 0.301ms.
2020-02-12 14:44:57.433343: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: cond_false_5711
2020-02-12 14:44:57.433347: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0.002ms.
2020-02-12 14:44:57.433352: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-02-12 14:44:57.433356: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: cond_true_5710
2020-02-12 14:44:57.433361: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-02-12 14:44:57.433365: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-02-12 14:44:57.433369: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: Preprocessor_map_while_cond_19
2020-02-12 14:44:57.433374: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0.002ms.
2020-02-12 14:44:57.433378: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-02-12 14:44:57.433382: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: PadOrClipBoxList_cond_false_5510
2020-02-12 14:44:57.433387: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: Graph size after: 20 nodes (0), 22 edges (0), time = 0.793ms.
2020-02-12 14:44:57.433391: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: Graph size after: 20 nodes (0), 22 edges (0), time = 0.877ms.
2020-02-12 14:44:57.433395: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: Postprocessor_BatchMultiClassNonMaxSuppression_map_while_body_4117
2020-02-12 14:44:57.433400: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: Graph size after: 1290 nodes (0), 1804 edges (0), time = 8.567ms.
2020-02-12 14:44:57.433405: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: Graph size after: 1290 nodes (0), 1804 edges (0), time = 10.381ms.
2020-02-12 14:44:57.433409: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: PadOrClipBoxList_cond_true_5509
2020-02-12 14:44:57.433414: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-02-12 14:44:57.433418: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-02-12 14:44:57.433423: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: cond_false_5593
2020-02-12 14:44:57.433427: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0.001ms.
2020-02-12 14:44:57.433432: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-02-12 14:44:59.331976: I tensorflow/core/grappler/devices.cc:55] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 2
2020-02-12 14:44:59.332072: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session
2020-02-12 14:44:59.333207: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1558] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 510.07GiB/s
2020-02-12 14:44:59.333751: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1558] Found device 1 with properties: 
pciBusID: 0000:02:00.0 name: TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 510.07GiB/s
2020-02-12 14:44:59.333842: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory
2020-02-12 14:44:59.333858: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-02-12 14:44:59.333868: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-02-12 14:44:59.333878: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-02-12 14:44:59.333887: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-02-12 14:44:59.333896: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-02-12 14:44:59.333939: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory
2020-02-12 14:44:59.333946: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1595] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2020-02-12 14:44:59.333988: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1099] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-02-12 14:44:59.333995: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1105]      0 1 
2020-02-12 14:44:59.334002: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1118] 0:   N Y 
2020-02-12 14:44:59.334006: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1118] 1:   Y N 
2020-02-12 14:44:59.918734: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: graph_to_optimize
2020-02-12 14:44:59.918767: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   constant_folding: Graph size after: 937 nodes (-1514), 1045 edges (-1709), time = 270.114ms.
2020-02-12 14:44:59.918772: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   constant_folding: Graph size after: 937 nodes (0), 1045 edges (0), time = 79.506ms.
2020-02-12 14:44:59.918775: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: cond_true_5710_frozen
2020-02-12 14:44:59.918779: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   constant_folding: Graph size after: 10 nodes (0), 8 edges (0), time = 0.278ms.
2020-02-12 14:44:59.918782: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   constant_folding: Graph size after: 10 nodes (0), 8 edges (0), time = 0.171ms.
2020-02-12 14:44:59.918785: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: cond_false_5711_frozen
2020-02-12 14:44:59.918789: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   constant_folding: Graph size after: 8 nodes (0), 5 edges (0), time = 0.17ms.
2020-02-12 14:44:59.918793: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   constant_folding: Graph size after: 8 nodes (0), 5 edges (0), time = 0.119ms.
2020-02-12 14:44:59.918796: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: PadOrClipBoxList_cond_1_true_5568_frozen
2020-02-12 14:44:59.918801: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   constant_folding: Graph size after: 5 nodes (-3), 4 edges (-3), time = 0.285ms.
2020-02-12 14:44:59.918805: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   constant_folding: Graph size after: 5 nodes (0), 4 edges (0), time = 0.093ms.
2020-02-12 14:44:59.918808: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: Postprocessor_BatchMultiClassNonMaxSuppression_map_while_cond_4116_frozen
2020-02-12 14:44:59.918812: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   constant_folding: Graph size after: 18 nodes (0), 7 edges (0), time = 0.253ms.
2020-02-12 14:44:59.918819: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   constant_folding: Graph size after: 18 nodes (0), 7 edges (0), time = 0.199ms.
2020-02-12 14:44:59.918824: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: cond_true_5592_frozen
2020-02-12 14:44:59.918829: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   constant_folding: Graph size after: 10 nodes (0), 8 edges (0), time = 0.248ms.
2020-02-12 14:44:59.918833: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   constant_folding: Graph size after: 10 nodes (0), 8 edges (0), time = 0.172ms.
2020-02-12 14:44:59.918838: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: cond_true_5533_frozen
2020-02-12 14:44:59.918846: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   constant_folding: Graph size after: 10 nodes (0), 8 edges (0), time = 0.22ms.
2020-02-12 14:44:59.918851: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   constant_folding: Graph size after: 10 nodes (0), 8 edges (0), time = 0.198ms.
2020-02-12 14:44:59.918855: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: PadOrClipBoxList_cond_false_5510_frozen
2020-02-12 14:44:59.918860: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   constant_folding: Graph size after: 18 nodes (-2), 20 edges (-2), time = 0.72ms.
2020-02-12 14:44:59.918865: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   constant_folding: Graph size after: 18 nodes (0), 20 edges (0), time = 0.366ms.
2020-02-12 14:44:59.918869: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: Preprocessor_map_while_cond_19_frozen
2020-02-12 14:44:59.918873: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   constant_folding: Graph size after: 11 nodes (0), 7 edges (0), time = 0.222ms.
2020-02-12 14:44:59.918878: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   constant_folding: Graph size after: 11 nodes (0), 7 edges (0), time = 0.141ms.
2020-02-12 14:44:59.918882: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: PadOrClipBoxList_cond_2_false_5628_frozen
2020-02-12 14:44:59.918886: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   constant_folding: Graph size after: 18 nodes (-2), 20 edges (-2), time = 0.716ms.
2020-02-12 14:44:59.918891: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   constant_folding: Graph size after: 18 nodes (0), 20 edges (0), time = 0.369ms.
2020-02-12 14:44:59.918895: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: PadOrClipBoxList_cond_true_5509_frozen
2020-02-12 14:44:59.918899: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   constant_folding: Graph size after: 5 nodes (-3), 4 edges (-3), time = 0.278ms.
2020-02-12 14:44:59.918904: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   constant_folding: Graph size after: 5 nodes (0), 4 edges (0), time = 0.096ms.
2020-02-12 14:44:59.918908: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: cond_false_5593_frozen
2020-02-12 14:44:59.918913: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   constant_folding: Graph size after: 8 nodes (0), 5 edges (0), time = 0.2ms.
2020-02-12 14:44:59.918917: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   constant_folding: Graph size after: 8 nodes (0), 5 edges (0), time = 0.125ms.
2020-02-12 14:44:59.918921: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: Postprocessor_BatchMultiClassNonMaxSuppression_map_while_body_4117_frozen
2020-02-12 14:44:59.918926: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   constant_folding: Graph size after: 1256 nodes (-34), 1804 edges (0), time = 35.923ms.
2020-02-12 14:44:59.918930: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   constant_folding: Graph size after: 1256 nodes (0), 1804 edges (0), time = 22.273ms.
2020-02-12 14:44:59.918935: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: cond_false_5652_frozen
2020-02-12 14:44:59.918939: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   constant_folding: Graph size after: 8 nodes (0), 5 edges (0), time = 0.212ms.
2020-02-12 14:44:59.918943: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   constant_folding: Graph size after: 8 nodes (0), 5 edges (0), time = 0.129ms.
2020-02-12 14:44:59.918948: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: Preprocessor_map_while_body_20_frozen
2020-02-12 14:44:59.918952: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   constant_folding: Graph size after: 28 nodes (-9), 25 edges (-9), time = 1.367ms.
2020-02-12 14:44:59.918956: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   constant_folding: Graph size after: 28 nodes (0), 25 edges (0), time = 0.432ms.
2020-02-12 14:44:59.918961: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: PadOrClipBoxList_cond_3_true_5686_frozen
2020-02-12 14:44:59.918965: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   constant_folding: Graph size after: 5 nodes (-3), 4 edges (-3), time = 0.29ms.
2020-02-12 14:44:59.918969: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   constant_folding: Graph size after: 5 nodes (0), 4 edges (0), time = 0.099ms.
2020-02-12 14:44:59.918974: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: PadOrClipBoxList_cond_3_false_5687_frozen
2020-02-12 14:44:59.918978: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   constant_folding: Graph size after: 18 nodes (-2), 20 edges (-2), time = 0.801ms.
2020-02-12 14:44:59.918982: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   constant_folding: Graph size after: 18 nodes (0), 20 edges (0), time = 0.382ms.
2020-02-12 14:44:59.918986: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: PadOrClipBoxList_cond_1_false_5569_frozen
2020-02-12 14:44:59.918989: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   constant_folding: Graph size after: 18 nodes (-2), 20 edges (-2), time = 0.745ms.
2020-02-12 14:44:59.918994: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   constant_folding: Graph size after: 18 nodes (0), 20 edges (0), time = 0.384ms.
2020-02-12 14:44:59.918998: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: cond_true_5651_frozen
2020-02-12 14:44:59.919002: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   constant_folding: Graph size after: 10 nodes (0), 8 edges (0), time = 0.228ms.
2020-02-12 14:44:59.919006: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   constant_folding: Graph size after: 10 nodes (0), 8 edges (0), time = 0.203ms.
2020-02-12 14:44:59.919011: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: cond_false_5534_frozen
2020-02-12 14:44:59.919015: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   constant_folding: Graph size after: 8 nodes (0), 5 edges (0), time = 0.174ms.
2020-02-12 14:44:59.919019: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   constant_folding: Graph size after: 8 nodes (0), 5 edges (0), time = 0.126ms.
2020-02-12 14:44:59.919024: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: PadOrClipBoxList_cond_2_true_5627_frozen
2020-02-12 14:44:59.919028: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   constant_folding: Graph size after: 5 nodes (-3), 4 edges (-3), time = 0.298ms.
2020-02-12 14:44:59.919032: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   constant_folding: Graph size after: 5 nodes (0), 4 edges (0), time = 0.101ms.
Traceback (most recent call last):
  File ""convert_to_tflite2.py"", line 105, in <module>
    tflite_model = converter.convert()
  File ""/home/eric/.anaconda3/envs/tf_nightly_gpu/lib/python3.7/site-packages/tensorflow_core/lite/python/lite.py"", line 513, in convert
    **converter_kwargs)
  File ""/home/eric/.anaconda3/envs/tf_nightly_gpu/lib/python3.7/site-packages/tensorflow_core/lite/python/convert.py"", line 496, in toco_convert_impl
    enable_mlir_converter=enable_mlir_converter)
  File ""/home/eric/.anaconda3/envs/tf_nightly_gpu/lib/python3.7/site-packages/tensorflow_core/lite/python/convert.py"", line 227, in toco_convert_protos
    raise ConverterError(""See console for info.\n%s\n%s\n"" % (stdout, stderr))
tensorflow.lite.python.convert.ConverterError: See console for info.
2020-02-12 14:45:01.509402: W tensorflow/compiler/mlir/lite/python/graphdef_to_tfl_flatbuffer.cc:108] Ignored output_format.
2020-02-12 14:45:01.509437: W tensorflow/compiler/mlir/lite/python/graphdef_to_tfl_flatbuffer.cc:111] Ignored drop_control_dependency.
2020-02-12 14:45:01.712175: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-02-12 14:45:01.739469: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 3597955000 Hz
2020-02-12 14:45:01.740229: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55dc06f27020 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-02-12 14:45:01.740266: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-02-12 14:45:01.744300: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-02-12 14:45:01.935539: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55dc09be74d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-02-12 14:45:01.935576: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): TITAN Xp, Compute Capability 6.1
2020-02-12 14:45:01.935585: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): TITAN Xp, Compute Capability 6.1
2020-02-12 14:45:01.937373: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1558] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 510.07GiB/s
2020-02-12 14:45:01.938710: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1558] Found device 1 with properties: 
pciBusID: 0000:02:00.0 name: TITAN Xp computeCapability: 6.1
coreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 510.07GiB/s
2020-02-12 14:45:01.938995: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory
2020-02-12 14:45:01.941769: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-02-12 14:45:01.944257: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-02-12 14:45:01.944765: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-02-12 14:45:01.947695: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-02-12 14:45:01.949183: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-02-12 14:45:01.949331: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory
2020-02-12 14:45:01.949349: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1595] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2020-02-12 14:45:01.949431: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1099] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-02-12 14:45:01.949448: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1105]      0 1 
2020-02-12 14:45:01.949462: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1118] 0:   N Y 
2020-02-12 14:45:01.949473: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1118] 1:   Y N 
loc(callsite(""Preprocessor/map/TensorArrayV2_1""(""/home/eric/.anaconda3/envs/tf_nightly_gpu/lib/python3.7/site-packages/tensorflow_core/python/eager/lift_to_graph.py"":339:0) at callsite(""/home/eric/.anaconda3/envs/tf_nightly_gpu/lib/python3.7/site-packages/tensorflow_core/python/eager/wrap_function.py"":321:0 at callsite(""convert_to_tflite2.py"":50:0 at ""convert_to_tflite2.py"":72:0)))): error: operand type 'tensor<i32>' is not compatible with preceding operands; expected rank: 1
Traceback (most recent call last):
  File ""/home/eric/.anaconda3/envs/tf_nightly_gpu/bin/toco_from_protos"", line 8, in <module>
    sys.exit(main())
  File ""/home/eric/.anaconda3/envs/tf_nightly_gpu/lib/python3.7/site-packages/tensorflow_core/lite/toco/python/toco_from_protos.py"", line 93, in main
    app.run(main=execute, argv=[sys.argv[0]] + unparsed)
  File ""/home/eric/.anaconda3/envs/tf_nightly_gpu/lib/python3.7/site-packages/tensorflow_core/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/home/eric/.anaconda3/envs/tf_nightly_gpu/lib/python3.7/site-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/home/eric/.anaconda3/envs/tf_nightly_gpu/lib/python3.7/site-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""/home/eric/.anaconda3/envs/tf_nightly_gpu/lib/python3.7/site-packages/tensorflow_core/lite/toco/python/toco_from_protos.py"", line 56, in execute
    enable_mlir_converter)
Exception: /home/eric/.anaconda3/envs/tf_nightly_gpu/lib/python3.7/site-packages/tensorflow_core/python/eager/lift_to_graph.py:339:11: error: operand type 'tensor<i32>' is not compatible with preceding operands; expected rank: 1
          op=op, graph=graph, op_map=op_map, base_graph=base_graph)
          ^
/home/eric/.anaconda3/envs/tf_nightly_gpu/lib/python3.7/site-packages/tensorflow_core/python/eager/wrap_function.py:321:9: note: called from
        base_graph=self._func_graph)
        ^
convert_to_tflite2.py:50:9: note: called from
        tf.nest.map_structure(import_graph.as_graph_element, outputs))
        ^
convert_to_tflite2.py:72:1: note: called from
inception_func = wrap_frozen_graph(detection_graph.as_graph_def(add_shapes=True), inputs=input_arrays, outputs=output_arrays)
```

**Also, please include a link to the saved model or GraphDef**

```
Can't attach, but here's most of the .config file that was used to generate the graph (frozen graph).
model {
  ssd {
    inplace_batchnorm_update: true
    freeze_batchnorm: false
    num_classes: 16   
    box_coder {
      faster_rcnn_box_coder {
        y_scale: 10.0
        x_scale: 10.0
        height_scale: 5.0
        width_scale: 5.0
      }
    }
    matcher {
      argmax_matcher {
        matched_threshold: 0.5
        unmatched_threshold: 0.5
        ignore_thresholds: false
        negatives_lower_than_unmatched: true
        force_match_for_each_row: true
        use_matmul_gather: true
      }
    }
    similarity_calculator {
      iou_similarity {
      }
    }
    encode_background_as_zeros: true
    anchor_generator {
      multiscale_anchor_generator {
        min_level: 3
        max_level: 7
        anchor_scale: 4.0
        aspect_ratios: [1.0, 2.0, 0.5]
        scales_per_octave: 2
      }
    }
    image_resizer {
      fixed_shape_resizer {
        height: 640
        width: 640
      }
    }
    box_predictor {
      weight_shared_convolutional_box_predictor {
        depth: 256
        class_prediction_bias_init: -4.6
        conv_hyperparams {
          activation: RELU_6,
          regularizer {
            l2_regularizer {
              weight: 0.00004
            }
          }
          initializer {
            random_normal_initializer {
              stddev: 0.01
              mean: 0.0
            }
          }
          batch_norm {
            scale: true,
            decay: 0.997,
            epsilon: 0.001,
          }
        }
        num_layers_before_predictor: 4
        kernel_size: 3
      }
    }
    feature_extractor {
      type: 'ssd_mobilenet_v1_fpn'
      min_depth: 16
      depth_multiplier: 1.0
      conv_hyperparams {
        activation: RELU_6,
        regularizer {
          l2_regularizer {
            weight: 0.00004
          }
        }
        initializer {
          random_normal_initializer {
            stddev: 0.01
            mean: 0.0
          }
        }
        batch_norm {
          scale: true,
          decay: 0.997,
          epsilon: 0.001,
        }
      }
      override_base_feature_extractor_hyperparams: true
    }
    loss {
      classification_loss {
        weighted_sigmoid_focal {
          alpha: 0.25
          gamma: 2.0
        }
      }
      localization_loss {
        weighted_smooth_l1 {
        }
      }
      classification_weight: 1.0
      localization_weight: 1.0
    }
    normalize_loss_by_num_matches: true
    normalize_loc_loss_by_codesize: true
    post_processing {
      batch_non_max_suppression {
        score_threshold: 1e-8
        iou_threshold: 0.6
        max_detections_per_class: 100
        max_total_detections: 100
      }
      score_converter: SIGMOID
    }
  }
}
```

**Failure details**
Model crashes on conversion


**Any other info / logs**

We use the generator scripts in the tensorflow object_detection library to actually make and train our neural net, so it's not easy to see what code would be breaking this. "
36710,Infinite recursion in TFModuleWrapper.__getattr__,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes 
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Docker container gcr.io/deeplearning-platform-release/tf-cpu.1-15
- **TensorFlow version (use command below)**: v1.15
- **Python version**: Python 3.5.6 :: Anaconda, Inc.
- **Exact command to reproduce**:

### Describe the problem
When running a complex Apache Beam job using Tensorflow to create TFRecords, the jobs fails with 
....
  File ""/usr/local/lib/python3.5/site-packages/tensorflow_core/python/util/module_wrapper.py"", line 192, in __getattr__
    attr = getattr(self._tfmw_wrapped_module, name)
  File ""/usr/local/lib/python3.5/site-packages/tensorflow_core/python/util/module_wrapper.py"", line 192, in __getattr__
    attr = getattr(self._tfmw_wrapped_module, name)
  File ""/usr/local/lib/python3.5/site-packages/tensorflow_core/python/util/module_wrapper.py"", line 192, in __getattr__
    attr = getattr(self._tfmw_wrapped_module, name)
  File ""/usr/local/lib/python3.5/site-packages/tensorflow_core/python/util/module_wrapper.py"", line 160, in __getattribute__
    attr_map = object.__getattribute__(self, '_tfmw_attr_map')
RecursionError: maximum recursion depth exceeded while calling a Python object

Sorry, I have been unable to isolate a test case. However, TFModuleWrapper.__getattr__ does look vulberable to recursion errors. See https://nedbatchelder.com/blog/201010/surprising_getattr_recursion.html for a discussion of a similar problem.

I am not using kivy, so this is probably different than: https://github.com/tensorflow/tensorflow/issues/27312 
"
36708,First python project for class--- could someone please help me understand?- exif data using python ,"
Here are the instructions and at the bottom is exp-11's script. I have no idea what to do. VERY new to programming.. thank you ahead of time!

Using the Exp-11.py script provide as a baseline your assignment is as follows:

1) Allow the user to enter a path

2) Using that path, process all the .jpg files contained in that folder  (note you will need to create a directory with jpg images)

3) Extract, EXIF data from each of the images and create a pretty table output.  Note, you will go beyond the basics and extract whatever camera or photo data exists for each photo.

4) Plot the geolocation of each image on a map. 

(Note, there are several ways to do this)  However, the easiest method would be to use MapMaker App, at https://mapmakerapp.com/
you can either manually enter the lat/long values your code generates or you can place your results in a CSV file and upload the data to the map.   
NOTE, this is a manual step process

5) Submit both your script and a screenshot of the results.





'''
EXIF Data Acquistion
January 2019
Version 1.1
'''
from __future__ import print_function

'''
Copyright (c) 2019 Chet Hosmer, Python Forensics

Permission is hereby granted, free of charge, to any person obtaining a copy of this software
and associated documentation files (the ""Software""), to deal in the Software without restriction, 
including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, 
and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, 
subject to the following conditions:

The above copyright notice and this permission notice shall be included in all copies or substantial 
portions of the Software.

'''
# Usage Example:
# python Exp-11.py 
#
# Requirement: Python 2.x or 3.x
#
# Requirement: 3rd Party Library that is utilized is: PILLOW
#                   pip install PILLOW  from the command line


''' LIBRARY IMPORT SECTION '''

import os                       # Python Standard Library : Operating System Methods
import sys                      # Python Standard Library : System Methods
from datetime import datetime   # Python Standard Libary datetime method from Standard Library

# import the Python Image Library 
# along with TAGS and GPS related TAGS
# Note you must install the PILLOW Module
# pip install PILLOW

from PIL import Image
from PIL.ExifTags import TAGS, GPSTAGS


# import the prettytable library
from prettytable import PrettyTable

def ExtractGPSDictionary(fileName):
    ''' Function to Extract GPS Dictionary '''
    try:
        pilImage = Image.open(fileName)
        exifData = pilImage._getexif()

    except Exception:
        # If exception occurs from PIL processing
        # Report the 
        return None, None

    # Interate through the exifData
    # Searching for GPS Tags

    imageTimeStamp = ""NA""
    cameraModel = ""NA""
    cameraMake = ""NA""
    gpsData = False

    gpsDictionary = {}

    if exifData:

        for tag, theValue in exifData.items():

            # obtain the tag
            tagValue = TAGS.get(tag, tag)

            # Collect basic image data if available

            if tagValue == 'DateTimeOriginal':
                imageTimeStamp = exifData.get(tag).strip()

            if tagValue == ""Make"":
                cameraMake = exifData.get(tag).strip()

            if tagValue == 'Model':
                cameraModel = exifData.get(tag).strip()

            # check the tag for GPS
            if tagValue == ""GPSInfo"":

                gpsData = True;

                # Found it !
                # Now create a Dictionary to hold the GPS Data

                # Loop through the GPS Information
                for curTag in theValue:
                    gpsTag = GPSTAGS.get(curTag, curTag)
                    gpsDictionary[gpsTag] = theValue[curTag]

        basicExifData = [imageTimeStamp, cameraMake, cameraModel]    

        return gpsDictionary, basicExifData

    else:
        return None, None

# End ExtractGPSDictionary ============================


def ExtractLatLon(gps):
    ''' Function to Extract Lattitude and Longitude Values '''

    # to perform the calcuation we need at least
    # lat, lon, latRef and lonRef
    
    try:
        latitude     = gps[""GPSLatitude""]
        latitudeRef  = gps[""GPSLatitudeRef""]
        longitude    = gps[""GPSLongitude""]
        longitudeRef = gps[""GPSLongitudeRef""]

        lat = ConvertToDegrees(latitude)
        lon = ConvertToDegrees(longitude)

        # Check Latitude Reference
        # If South of the Equator then lat value is negative

        if latitudeRef == ""S"":
            lat = 0 - lat

        # Check Longitude Reference
        # If West of the Prime Meridian in 
        # Greenwich then the Longitude value is negative

        if longitudeRef == ""W"":
            lon = 0- lon

        gpsCoor = {""Lat"": lat, ""LatRef"":latitudeRef, ""Lon"": lon, ""LonRef"": longitudeRef}

        return gpsCoor

    except:
        return None

# End Extract Lat Lon ==============================================


def ConvertToDegrees(gpsCoordinate):
    ''' Function to CONVERT GPS COORIDINATES TO DEGRESS '''
    d0 = gpsCoordinate[0][0]
    d1 = gpsCoordinate[0][1]
    try:
        degrees = float(d0) / float(d1)
    except:
        degrees = 0.0

    m0 = gpsCoordinate[1][0]
    m1 = gpsCoordinate[1][1]
    try:
        minutes = float(m0) / float(m1)
    except:
        minutes=0.0

    s0 = gpsCoordinate[2][0]
    s1 = gpsCoordinate[2][1]
    try:
        seconds = float(s0) / float(s1)
    except:
        seconds = 0.0

    floatCoordinate = float (degrees + (minutes / 60.0) + (seconds / 3600.0))

    return floatCoordinate

''' MAIN PROGRAM ENTRY SECTION '''

if __name__ == ""__main__"":
    '''
    pyExif Main Entry Point
    '''
    print(""\nExtract EXIF Data from JPEG Files"")

    print(""Script Started"", str(datetime.now()))
    print()

    ''' PROCESS EACH JPEG FILE SECTION '''

    latLonList = []
    targetFile = ""test.jpg""                 # file must be located in the same folder
    if os.path.isfile(targetFile):
        gpsDictionary, exifList = ExtractGPSDictionary(targetFile)
            
        if exifList:
            TS = exifList[0]
            MAKE = exifList[1]
            MODEL = exifList[2]
        else:
            TS = 'NA'
            MAKE = 'NA'
            MODEL = 'NA'

        print(""Photo Details"")
        print(""-------------"")
        print(""TimeStamp:    "", TS)
        print(""Camera Make:  "", MAKE)
        print(""Camera Model: "", MODEL)
        
        if (gpsDictionary != None):

            # Obtain the Lat Lon values from the gpsDictionary
            # Converted to degrees
            # The return value is a dictionary key value pairs

            dCoor = ExtractLatLon(gpsDictionary)

            print(""\nGeo-Location Data"")
            print(""-----------------"")

            if dCoor:
                lat = dCoor.get(""Lat"")
                latRef = dCoor.get(""LatRef"")
                lon = dCoor.get(""Lon"")
                lonRef = dCoor.get(""LonRef"")
                
                if ( lat and lon and latRef and lonRef):
                    print(""Lattitude: "", '{:4.4f}'.format(lat))
                    print(""Longitude: "", '{:4.4f}'.format(lon))
                else:
                    print(""WARNING No GPS EXIF Data"")
            else:
                print(""WARNING No GPS EXIF Data"")                    
        else:
            print(""WARNING"", "" not a valid file"", targetFile)

    # Create Result Table Display using PrettyTable
    ''' GENERATE RESULTS TABLE SECTION'''

    ''' Result Table Heading'''
    resultTable = PrettyTable(['File-Name', 'Lat','Lon', 'TimeStamp', 'Make', 'Model'])
    ''' Your work starts here '''
    
    print()"
36707,TFLite can't quantize op transpose_conv,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- TensorFlow installed from (source or binary): binary
- TensorFlow version (or github SHA if from source): 1.15.2, 2.1.0

Quantization doesn't support op: TRANSPOSE_CONV

```python 
import tensorflow as tf
import numpy as np

def gen_calibration_dataset():
    for _ in range(10):
        yield [np.random.rand(1,2,2,2).astype(np.float32)]

def get_keras_model_conv():
    input_0 = tf.keras.layers.Input(shape=[2, 2, 2])
    transpose_conv_1 = tf.keras.layers.Conv2DTranspose(filters=2, kernel_size=[2, 2],
                                                       use_bias=False, padding=""same"")(input_0)
    model = tf.keras.models.Model(inputs=[input_0], outputs=[transpose_conv_1])
    model.summary()
    return model

def gen_model():
    keras_model = get_keras_model_conv()
    keras_model.save('test_model.h5')
    converter = tf.compat.v1.lite.TFLiteConverter.from_keras_model_file('test_model.h5')
    converter.optimizations = [tf.lite.Optimize.DEFAULT]
    #converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_ACTIVATIONS_INT16_WEIGHTS_INT8]
    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]
    converter.inference_input_type = tf.int8
    converter.inference_output_type = tf.int8
    converter.representative_dataset = gen_calibration_dataset
    tflite_quant_model = converter.convert()
    open('test.tflite', 'wb').write(tflite_quant_model)

print(""TF version: {}"".format(tf.__version__))
gen_model()
```

error mesg:
> Traceback (most recent call last):
>   File ""test_RICH.py"", line 30, in <module>
>     gen_model()
>   File ""test_RICH.py"", line 26, in gen_model
>     tflite_quant_model = converter.convert()
>   File ""/envs/tf-nightly/lib/python3.6/site-packages/tensorflow_core/lite/python/lite.py"", line 469, in convert
>     self.experimental_new_quantizer)
>   File ""/envs/tf-nightly/lib/python3.6/site-packages/tensorflow_core/lite/python/lite.py"", line 243, in _calibrate_quantize_model
>     inference_output_type, allow_float, enable_mlir_quantizer)
>   File ""/envs/tf-nightly/lib/python3.6/site-packages/tensorflow_core/lite/python/optimize/calibrator.py"", line 81, in calibrate_and_quantize
>     enable_mlir_quantizer)
>   File ""/envs/tf-nightly/lib/python3.6/site-packages/tensorflow_core/lite/python/optimize/tensorflow_lite_wrap_calibration_wrapper.py"", line 115, in QuantizeModel
>     return _tensorflow_lite_wrap_calibration_wrapper.CalibrationWrapper_QuantizeModel(self, *args)
> RuntimeError: Quantization not yet supported for op: TRANSPOSE_CONV"
36706,Why do we need to convert Keras model to tf-estimator in TF-2.0,"I want to upgrade my custom estimator model from tf1 to tf2, and I follow this link to upgrade

They recommend the use tf.keras.estimator.model_to_estimator

**TensorFlow-2.0 official doc**
> We recommend that you define your model using Keras, then use the tf.keras.estimator.model_to_estimator utility to turn your model into an estimator. The code below shows how to use this utility when creating and training an estimator.

In TF-1.x, in order to scale model to training on multiple workers, we convert Keras to tf-estimator.

But in TF-2.x, Keras already support distributed training well, so my question is

1. Why do we need to convert Keras to estimator in TF-2.0, dose any benefits?
2. Can we use low-level TF API (like tf.function()) to build custom estimator model ?

I can't find any example to build estimator model in TF-2.0 and without Keras."
36705,TFLite: allocate_tensors() fails for 2 dense layers with quantization,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- TensorFlow installed from (source or binary): binary
- TensorFlow version (or github SHA if from source): 1.15.0

I'm trying to convert a model built with keras to tflite in order to run it on an Edge TPU. If I use more than one dense layer, allocate_tensors() throws an error. It only happens for full integer quantization with a representative dataset. Here is a minimal example which reproduces this error:

```
import keras
import tensorflow as tf
import tflite_runtime.interpreter as tflite
import numpy as np


n = 16

dense_1 = keras.layers.Dense(n)
dense_2 = keras.layers.Dense(n)

x = keras.layers.Input(shape=(n,))

y = dense_1(x)
y = dense_2(y)

model = keras.models.Model(inputs=[x], outputs=[y])

model.compile(optimizer='rmsprop', loss='mean_squared_error')
model.save('example.h5')

input_shapes = {}
input_shapes['input_1'] = (1, n)
converter = tf.lite.TFLiteConverter.from_keras_model_file('example.h5', input_shapes=input_shapes)

converter.optimizations = [tf.lite.Optimize.DEFAULT]
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]

def rep_data_gen():
	for _ in range(100):
		yield [np.random.rand(1, n).astype(np.float32)]

converter.representative_dataset = rep_data_gen

tflite_model = converter.convert()
open(""example.tflite"", ""wb"").write(tflite_model)

interpreter = tflite.Interpreter(""example.tflite"",
								 experimental_delegates=[tflite.load_delegate('libedgetpu.so.1')])

interpreter.allocate_tensors()
```

The error:

```
Traceback (most recent call last):
  File ""example.py"", line 43, in <module>
    interpreter.allocate_tensors()
  File ""/home/julian/anaconda3/envs/keras/lib/python3.7/site-packages/tflite_runtime/interpreter.py"", line 244, in allocate_tensors
    return self._interpreter.AllocateTensors()
  File ""/home/julian/anaconda3/envs/keras/lib/python3.7/site-packages/tensorflow_core/lite/python/interpreter_wrapper/tensorflow_wrap_interpreter_wrapper.py"", line 106, in AllocateTensors
    return _tensorflow_wrap_interpreter_wrapper.InterpreterWrapper_AllocateTensors(self)
RuntimeError: tensorflow/lite/kernels/kernel_util.cc:106 std::abs(input_product_scale - bias_scale) <= 1e-6 * std::min(input_product_scale, bias_scale) was not true.Node number 2 (FULLY_CONNECTED) failed to prepare.
```

Note that the error doesn't occur when I drop ```y = dense_2(y)```. I feel like I am missing something simple, but what is it? This is the simplest two-layer model I can imagine, so it should really work."
36704,Why K.mean is used in tf.keras.losses.binary_crossentropy ?,"In [line 993](https://github.com/tensorflow/tensorflow/blob/a641fa1c5c10f0a278c7671fd6f7df550a74935d/tensorflow/python/keras/losses.py#L993) of the code of `tf.keras.losses.binary_crossentropy`, `K.mean` is called on axis `-1` of `K.binary_crossentropy(y_true, y_pred, from_logits=from_logits)`.

I wonder why there is this `K.mean` call and why `tf.keras.losses.binary_crossentropy` doesn't simply return `K.binary_crossentropy(y_true, y_pred, from_logits=from_logits)`.

On the contrary, `tf.keras.losses.categorical_crossentropy` and `tf.keras.losses.sparse_categorical_crossentropy` just return the call to their `tf.keras.backend` equivalent.

I think it may be inconsistent and misleading, especially because `tf.keras.losses.categorical_crossentropy` and `tf.keras.backend.categorical_crossentropy` behave similarly, but not `tf.keras.losses.binary_crossentropy` and `tf.keras.backend.binary_crossentropy`, so higher level objects like `tf.keras.metrics.CategoricalCrossentropy` may not work as one would expect."
36703,Unable to remove model from memory,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
Yes, it can be found in the following repository https://github.com/acvander/kaggle_real_or_not
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
Ubuntu 18.04
- **TensorFlow installed from (source or binary)**:
Binary
- **TensorFlow version (use command below)**:
v2.1.0-rc2-17-ge5bf8de 2.1.0
- **Python version**:
3.7.5
- **CUDA/cuDNN version**:
10.2
- **GPU model and memory**:
1060 6GB
- **Exact command to reproduce**:
These are for data preprocessing

```python main.py --mode=preprocess```
```python main.py --mode=preprocess_bert```

This is the training command

```python main.py --mode=train_bert --model_dir=./tmp/k_bert --model_name=bert --epochs=2 --subset=0.25```

### Describe the problem
I believe this is a similar problem to #36587. Upon starting to train the second fold, the first model is not properly removed from memory and results in an OOM error.
I run the ```del``` command to delete the model and bert_layers as well as ```tf.keras.backend.clear_session()```
### Source code / logs
```
2020-02-12 12:22:44.782689: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libnvinfer.so.6
2020-02-12 12:22:44.784338: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvrtc.so.10.2: cannot open shared object file: No such file or directory
2020-02-12 12:22:44.784352: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
I0212 12:22:46.138824 139915467714688 train_bert.py:72] loading data
I0212 12:22:46.162351 139915467714688 train_bert.py:80] loading model
I0212 12:22:46.163624 139915467714688 train_bert.py:95] training fold #1
I0212 12:22:46.164219 139915467714688 resolver.py:79] Using /tmp/tfhub_modules to cache modules.
Train on 635 samples, validate on 1268 samples
Epoch 1/2
632/635 [============================>.] - ETA: 0s - loss: 0.5996 - f1_score: 0.6930   
Epoch 00001: val_f1_score improved from -inf to 0.75631, saving model to ./tmp/k_bert/bert_0.h5
635/635 [==============================] - 89s 141ms/sample - loss: 0.6001 - f1_score: 0.6929 - val_loss: 0.5407 - val_f1_score: 0.7563
Epoch 2/2
632/635 [============================>.] - ETA: 0s - loss: 0.4509 - f1_score: 0.8212 
Epoch 00002: val_f1_score improved from 0.75631 to 0.80126, saving model to ./tmp/k_bert/bert_0.h5
635/635 [==============================] - 51s 80ms/sample - loss: 0.4508 - f1_score: 0.8205 - val_loss: 0.4792 - val_f1_score: 0.8013
I0212 12:25:23.587857 139915467714688 train_bert.py:95] training fold #2
Train on 634 samples, validate on 1269 samples
Epoch 1/2
  8/634 [..............................] - ETA: 29:17WARNING:tensorflow:Can save best model only with val_f1_score available, skipping.
W0212 12:26:02.588592 139915467714688 callbacks.py:1018] Can save best model only with val_f1_score available, skipping.
Traceback (most recent call last):
  File ""main.py"", line 119, in <module>
    app.run(main)
  File ""/home/adam/.pyenv/versions/real-or-not/lib/python3.7/site-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/home/adam/.pyenv/versions/real-or-not/lib/python3.7/site-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""main.py"", line 99, in main
    subset=FLAGS.subset)
  File ""/home/adam/machine_learning/real_or_not/training/train_bert.py"", line 125, in train_bert
    callbacks=callbacks)
  File ""/home/adam/.pyenv/versions/real-or-not/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py"", line 819, in fit
    use_multiprocessing=use_multiprocessing)
  File ""/home/adam/.pyenv/versions/real-or-not/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py"", line 342, in fit
    total_epochs=epochs)
  File ""/home/adam/.pyenv/versions/real-or-not/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py"", line 128, in run_one_epoch
    batch_outs = execution_function(iterator)
  File ""/home/adam/.pyenv/versions/real-or-not/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py"", line 98, in execution_function
    distributed_function(input_fn))
  File ""/home/adam/.pyenv/versions/real-or-not/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py"", line 568, in __call__
    result = self._call(*args, **kwds)
  File ""/home/adam/.pyenv/versions/real-or-not/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py"", line 615, in _call
    self._initialize(args, kwds, add_initializers_to=initializers)
  File ""/home/adam/.pyenv/versions/real-or-not/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py"", line 497, in _initialize
    *args, **kwds))
  File ""/home/adam/.pyenv/versions/real-or-not/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py"", line 2389, in _get_concrete_function_internal_garbage_collected
    graph_function, _, _ = self._maybe_define_function(args, kwargs)
  File ""/home/adam/.pyenv/versions/real-or-not/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py"", line 2703, in _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)
  File ""/home/adam/.pyenv/versions/real-or-not/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py"", line 2593, in _create_graph_function
    capture_by_value=self._capture_by_value),
  File ""/home/adam/.pyenv/versions/real-or-not/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py"", line 978, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File ""/home/adam/.pyenv/versions/real-or-not/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py"", line 439, in wrapped_fn
    return weak_wrapped_fn().__wrapped__(*args, **kwds)
  File ""/home/adam/.pyenv/versions/real-or-not/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py"", line 85, in distributed_function
    per_replica_function, args=args)
  File ""/home/adam/.pyenv/versions/real-or-not/lib/python3.7/site-packages/tensorflow_core/python/distribute/distribute_lib.py"", line 763, in experimental_run_v2
    return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)
  File ""/home/adam/.pyenv/versions/real-or-not/lib/python3.7/site-packages/tensorflow_core/python/distribute/distribute_lib.py"", line 1819, in call_for_each_replica
    return self._call_for_each_replica(fn, args, kwargs)
  File ""/home/adam/.pyenv/versions/real-or-not/lib/python3.7/site-packages/tensorflow_core/python/distribute/distribute_lib.py"", line 2164, in _call_for_each_replica
    return fn(*args, **kwargs)
  File ""/home/adam/.pyenv/versions/real-or-not/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/api.py"", line 292, in wrapper
    return func(*args, **kwargs)
  File ""/home/adam/.pyenv/versions/real-or-not/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py"", line 433, in train_on_batch
    output_loss_metrics=model._output_loss_metrics)
  File ""/home/adam/.pyenv/versions/real-or-not/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_eager.py"", line 312, in train_on_batch
    output_loss_metrics=output_loss_metrics))
  File ""/home/adam/.pyenv/versions/real-or-not/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_eager.py"", line 273, in _process_single_batch
    model.optimizer.apply_gradients(zip(grads, trainable_weights))
  File ""/home/adam/.pyenv/versions/real-or-not/lib/python3.7/site-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py"", line 434, in apply_gradients
    self._create_slots(var_list)
  File ""/home/adam/.pyenv/versions/real-or-not/lib/python3.7/site-packages/tensorflow_core/python/keras/optimizer_v2/adam.py"", line 149, in _create_slots
    self.add_slot(var, 'm')
  File ""/home/adam/.pyenv/versions/real-or-not/lib/python3.7/site-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py"", line 599, in add_slot
    initial_value=initial_value)
  File ""/home/adam/.pyenv/versions/real-or-not/lib/python3.7/site-packages/tensorflow_core/python/ops/variables.py"", line 260, in __call__
    return cls._variable_v2_call(*args, **kwargs)
  File ""/home/adam/.pyenv/versions/real-or-not/lib/python3.7/site-packages/tensorflow_core/python/ops/variables.py"", line 254, in _variable_v2_call
    shape=shape)
  File ""/home/adam/.pyenv/versions/real-or-not/lib/python3.7/site-packages/tensorflow_core/python/ops/variables.py"", line 65, in getter
    return captured_getter(captured_previous, **kwargs)
  File ""/home/adam/.pyenv/versions/real-or-not/lib/python3.7/site-packages/tensorflow_core/python/distribute/distribute_lib.py"", line 2080, in creator
    return next_creator(*args, **kwargs)
  File ""/home/adam/.pyenv/versions/real-or-not/lib/python3.7/site-packages/tensorflow_core/python/ops/variables.py"", line 65, in getter
    return captured_getter(captured_previous, **kwargs)
  File ""/home/adam/.pyenv/versions/real-or-not/lib/python3.7/site-packages/tensorflow_core/python/distribute/distribute_lib.py"", line 2080, in creator
    return next_creator(*args, **kwargs)
  File ""/home/adam/.pyenv/versions/real-or-not/lib/python3.7/site-packages/tensorflow_core/python/ops/variables.py"", line 65, in getter
    return captured_getter(captured_previous, **kwargs)
  File ""/home/adam/.pyenv/versions/real-or-not/lib/python3.7/site-packages/tensorflow_core/python/distribute/distribute_lib.py"", line 2080, in creator
    return next_creator(*args, **kwargs)
  File ""/home/adam/.pyenv/versions/real-or-not/lib/python3.7/site-packages/tensorflow_core/python/ops/variables.py"", line 65, in getter
    return captured_getter(captured_previous, **kwargs)
  File ""/home/adam/.pyenv/versions/real-or-not/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py"", line 485, in variable_capturing_scope
    lifted_initializer_graph=lifted_initializer_graph, **kwds)
  File ""/home/adam/.pyenv/versions/real-or-not/lib/python3.7/site-packages/tensorflow_core/python/ops/variables.py"", line 262, in __call__
    return super(VariableMetaclass, cls).__call__(*args, **kwargs)
  File ""/home/adam/.pyenv/versions/real-or-not/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py"", line 178, in __init__
    initial_value() if init_from_fn else initial_value,
  File ""/home/adam/.pyenv/versions/real-or-not/lib/python3.7/site-packages/tensorflow_core/python/ops/init_ops_v2.py"", line 98, in __call__
    return array_ops.zeros(shape, dtype)
  File ""/home/adam/.pyenv/versions/real-or-not/lib/python3.7/site-packages/tensorflow_core/python/ops/array_ops.py"", line 2446, in zeros
    output = fill(shape, constant(zero, dtype=dtype), name=name)
  File ""/home/adam/.pyenv/versions/real-or-not/lib/python3.7/site-packages/tensorflow_core/python/ops/array_ops.py"", line 233, in fill
    result = gen_array_ops.fill(dims, value, name=name)
  File ""/home/adam/.pyenv/versions/real-or-not/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_array_ops.py"", line 3244, in fill
    _ops.raise_from_not_ok_status(e, name)
  File ""/home/adam/.pyenv/versions/real-or-not/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py"", line 6606, in raise_from_not_ok_status
    six.raise_from(core._status_to_exception(e.code, message), None)
  File ""<string>"", line 3, in raise_from
tensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[4096,1024] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:Fill] name: Adam/bert_model/encoder/layer_4/output/kernel/m/Initializer/zeros/
```

"
36702,ImportError: DLL load failed: The specified module could not be found.,"Hi,

I keep hitting an import error shown below

setup is Windows 10 64 bit - Processor	Intel(R) Core(TM) i7-7820HQ - GPU Nividia Quadro M1200, 

Running Spyder version 4.0 (tried 4.01 also) with python 3.7.6 (also tried 3.8) via virtual env  with tensorflow 2.  Despite a weeks worth of various combinations I am having no luck. Any help much appreciated 

Home setup works fine but I need it working on my work PC. I have a local install as I don't have admin rights.

ImportError: Traceback (most recent call last):
  File ""C:\Users\user.user\Python 3.7.6 64bit\3.7.6\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\user.user\Python 3.7.6 64bit\3.7.6\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\user.user\Python 3.7.6 64bit\3.7.6\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\user.user\AppData\Local\Programs\Python\Python37\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\user.user\AppData\Local\Programs\Python\Python37\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: The specified module could not be found.


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/errors

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.





"
36700,tf2 isn't enabled in tensorflow_core.python.keras.layers.__init__,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04
- TensorFlow installed from (source or binary): pip install tensorflow==2.1
- TensorFlow version (use command below): 2.1
- Python version: 3.6.6
- CUDA/cuDNN version: Not used
- GPU model and memory: Not used

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

Whenever you import a layer using the path:
 `from tensorflow.python.keras.layers`

It will import the layer using the tensorflow 1.X behavior.
Which isn't the case when we use tensorflow.keras.layers.

The issue is that every networks from tf.keras.applications (resnet, densenet...) use those import which can lead to some severe bugs (e.g: BatchNormalization).

**Describe the expected behavior**
Importing from `from tensorflow.python.keras.layers` and `from tensorflow.keras.layers` should have exactly the same behavior (2.X).

**Code to reproduce the issue**
```python
from tensorflow.python.keras.layers import BatchNormalization as buggy_BN
from tensorflow.keras.layers import BatchNormalization as good_BN

print(good_BN()._USE_V2_BEHAVIOR) # TRUE
print(buggy_BN()._USE_V2_BEHAVIOR) # FALSE
```

**Other info / logs**

I think that the issue could be fix by changing this [tensorflow_core.python.tf2](https://github.com/tensorflow/tensorflow/blob/9bd55fcb645500a2c859cb3390f32b3a7c48327f/tensorflow/python/tf2.py#L43).

from

```python
def enabled():
  """"""Returns True iff TensorFlow 2.0 behavior should be enabled.""""""
  if _force_enable is None:
    return os.getenv(""TF2_BEHAVIOR"", ""0"") != ""0""
  else:
    return _force_enable
```
to

```python
def enabled():
  """"""Returns True iff TensorFlow 2.0 behavior should be enabled.""""""
  if _force_enable is None:
    return os.getenv(""TF2_BEHAVIOR"", ""1"") != ""0""
  else:
    return _force_enable
```
it will make TF2_BEHAVIOR enabled by default"
36697,Training suddenly freezes,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): unknown 2.0.0 (see below)

tensorboard=2.0.0=pyhb38c66f_1
tensorflow=2.0.0=gpu_py37h57d29ca_0
tensorflow-base=2.0.0=gpu_py37h390e234_0
tensorflow-estimator=2.0.0=pyh2649769_0
tensorflow-gpu=2.0.0=h0d30ee6_0
tensorflow-probability=0.8.0=py_0


- Python version: Python 3.7.6 (Anaconda)
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: cudatoolkit=10.0.130=0 / cudnn=7.6.4=cuda10.0_0
- GPU model and memory: Nvidia GeForce RTX 2070 8GB


**Describe the current behavior**
Training a CNN using `tf.keras.Model.fit()` and tensorflow's data pipeline with tfrecord files randomly seems to freeze/stop/hang. Whenever this happens, the console process stays open but the CPU/GPU will return to 0% utilization. Using verbose=1 as well as tensorboard also shows that no progress is being made anymore.

Waiting for a while does not help. However, if I restart the training without rebooting my PC, the hang is much more likely to occur again.

Looking into Process explorer, I can see that there is only one really active thread:
![grafik](https://user-images.githubusercontent.com/6770131/74343696-c0f13100-4dab-11ea-9858-e7bb70908107.png)

A Callstack for the thread is attached below. The upper few frames (nvcuda.dll!cuProfilerStop) change when refreshing but the rest of the frame stays constant.


**Describe the expected behavior**
The training should continue normally.


**Code to reproduce the issue**
Since I was not able to reproduce the problem reliably, I have no idea which part of my code might actually be important, The data pipeline uses `dataset.map()` with `num_parallel_calls = tf.data.experimental.AUTOTUNE` for multiprocessing and contains two `tf.np_function()`s (after which I have to use tf.ensure_shape to recover the correct shape for the data).

**Other info / logs**

```
nvcuda.dll!cuProfilerStop+0x226617
nvcuda.dll!cuProfilerStop+0x17243c
nvcuda.dll+0x4bbbe
nvcuda.dll+0x10c29d
nvcuda.dll!cuProfilerStop+0x5cc42
nvcuda.dll!cuProfilerStop+0x5da20
nvcuda.dll+0x10bbf0
nvcuda.dll+0x10be3c
nvcuda.dll+0xeac0
nvcuda.dll!cuCtxSynchronize+0x1c2
_pywrap_tensorflow_internal.pyd!std::unique_ptr<tensorflow::Status::State,std::default_delete<tensorflow::Status::State> >::~unique_ptr<tensorflow::Status::State,std::default_delete<tensorflow::Status::State> >+0x10b4f
_pywrap_tensorflow_internal.pyd!tensorflow::Env::NowSeconds+0xd16
_pywrap_tensorflow_internal.pyd!tensorflow::AllocationRecord::Clear+0x550c
_pywrap_tensorflow_internal.pyd!google::protobuf::RepeatedPtrField<tensorflow::InterconnectLink>::Add+0x8f0c
_pywrap_tensorflow_internal.pyd!std::vector<tensorflow::DtypeAndPartialTensorShape,std::allocator<tensorflow::DtypeAndPartialTensorShape> >::operator=+0x623
_pywrap_tensorflow_internal.pyd!TFE_TensorHandleResolve+0x227
_pywrap_tensorflow_internal.pyd!tensorflow::DataTypeSet::Contains+0x2350
_pywrap_tensorflow_internal.pyd!std::vector<tensorflow::monitoring::Point::Label,std::allocator<tensorflow::monitoring::Point::Label> >::reserve+0x85a
python37.dll!PyMethodDef_RawFastCallKeywords+0x387
python37.dll!PyMethodDef_RawFastCallKeywords+0xa5c
python37.dll!PyEval_EvalFrameDefault+0x403
python37.dll!PyFunction_FastCallDict+0xdd
python37.dll!PyObject_FastCall_Prepend+0x6c
python37.dll!PySet_Contains+0x50d
python37.dll!PyErr_NoMemory+0x24eaf
python37.dll!PyEval_SliceIndex+0x42
python37.dll!PySlice_Unpack+0x9d
_multiarray_umath.cp37-win_amd64.pyd+0xc117e
_multiarray_umath.cp37-win_amd64.pyd+0xc0093
python37.dll!PyEval_EvalFrameDefault+0x7e4
python37.dll!PyEval_EvalCodeWithName+0x1a6
python37.dll!PyFunction_FastCallDict+0x1ba
python37.dll!PySlice_New+0x23d
python37.dll!PyEval_EvalFrameDefault+0x1174
python37.dll!PyEval_EvalCodeWithName+0x1a6
python37.dll!PyFunction_FastCallDict+0x1ba
python37.dll!PyObject_Call_Prepend+0x6c
python37.dll!PyType_GetDocFromInternalDoc+0x22d
python37.dll!PyObject_Call+0x75
_pywrap_tensorflow_internal.pyd!std::default_delete<tensorflow::kernel_factory::OpKernelRegistrar::PtrOpKernelFactory>::operator()+0x97d
_pywrap_tensorflow_internal.pyd!std::default_delete<tensorflow::kernel_factory::OpKernelRegistrar::PtrOpKernelFactory>::operator()+0x420
_pywrap_tensorflow_internal.pyd!tensorflow::NodeDef::mutable_experimental_debug_info+0xef56
_pywrap_tensorflow_internal.pyd!tensorflow::NodeDef::mutable_experimental_debug_info+0x11f78
_pywrap_tensorflow_internal.pyd!tensorflow::data::DatasetBaseIterator::RecordElement+0x6f
_pywrap_tensorflow_internal.pyd!Eigen::ThreadPoolTempl<tensorflow::thread::EigenEnvironment>::WorkerLoop+0x3f6
_pywrap_tensorflow_internal.pyd!Eigen::ThreadPoolTempl<tensorflow::thread::EigenEnvironment>::WorkerLoop+0x701
_pywrap_tensorflow_internal.pyd!tensorflow::WindowsFileSystem::TranslateName+0x255
_pywrap_tensorflow_internal.pyd!tensorflow::SavedAsset::GetCachedSize+0x2c19
ucrtbase.dll!beginthreadex+0x142
KERNEL32.DLL!BaseThreadInitThunk+0x14
ntdll.dll!RtlUserThreadStart+0x21
```
"
36696,UpSampling2D doesn't support bfloat16 in TF 2.1,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.1
- Python version: 3.7.6
- CUDA/cuDNN version: CUDA 10.1, cuDNN 7.6.5
- GPU model and memory: NVIDIA Titan V, 12 GB

**Describe the current behavior**
TypeError: Value passed to parameter 'images' has DataType bfloat16 not in list of allowed values: int8, uint8, int16, uint16, int32, int64, float16, float32, float64

**Describe the expected behavior**
bfloat16 should work with this layer

**Code to reproduce the issue**
```
import tensorflow as tf

tf.keras.mixed_precision.experimental.set_policy('mixed_bfloat16')

optimizer = tf.optimizers.SGD(learning_rate=0.1, momentum=0.9)

input=tf.keras.layers.Input(shape=(256, 256, 3))

x=tf.keras.layers.Conv2D(32,(3,3))(input)
x=tf.keras.layers.UpSampling2D()(x)

x=tf.keras.layers.Conv2D(32,(3,3))(x)
out=tf.keras.layers.Activation('sigmoid', dtype='float32')(x)

my_model = tf.keras.models.Model(inputs=input, outputs=out)

optimizer = tf.keras.optimizers.RMSprop()
my_model.compile(loss='binary_crossentropy', optimizer=optimizer)
```

**Other info / logs**

> line 10, in
> x=tf.keras.layers.UpSampling2D()(x)
> File ""C:\Users\mdlambe1\AppData\Local\Continuum\anaconda3\envs\tf2\lib\site-packages\tensorflow_core\python\keras\engine\base_layer.py"", line 773, in call
> outputs = call_fn(cast_inputs, *args, **kwargs)
> File ""C:\Users\mdlambe1\AppData\Local\Continuum\anaconda3\envs\tf2\lib\site-packages\tensorflow_core\python\keras\layers\convolutional.py"", line 2004, in call
> interpolation=self.interpolation)
> File ""C:\Users\mdlambe1\AppData\Local\Continuum\anaconda3\envs\tf2\lib\site-packages\tensorflow_core\python\keras\backend.py"", line 2782, in resize_images
> x, new_shape, method=image_ops.ResizeMethod.NEAREST_NEIGHBOR)
> File ""C:\Users\mdlambe1\AppData\Local\Continuum\anaconda3\envs\tf2\lib\site-packages\tensorflow_core\python\ops\image_ops_impl.py"", line 1357, in resize_images_v2
> skip_resize_if_same=False)
> File ""C:\Users\mdlambe1\AppData\Local\Continuum\anaconda3\envs\tf2\lib\site-packages\tensorflow_core\python\ops\image_ops_impl.py"", line 1133, in _resize_images_common
> images = resizer_fn(images, size)
> File ""C:\Users\mdlambe1\AppData\Local\Continuum\anaconda3\envs\tf2\lib\site-packages\tensorflow_core\python\ops\image_ops_impl.py"", line 1337, in resize_fn
> images_t, new_size, half_pixel_centers=True)
> File ""C:\Users\mdlambe1\AppData\Local\Continuum\anaconda3\envs\tf2\lib\site-packages\tensorflow_core\python\ops\gen_image_ops.py"", line 3419, in resize_nearest_neighbor
> name=name)
> File ""C:\Users\mdlambe1\AppData\Local\Continuum\anaconda3\envs\tf2\lib\site-packages\tensorflow_core\python\framework\op_def_library.py"", line 576, in _apply_op_helper
> param_name=input_name)
> File ""C:\Users\mdlambe1\AppData\Local\Continuum\anaconda3\envs\tf2\lib\site-packages\tensorflow_core\python\framework\op_def_library.py"", line 61, in _SatisfiesTypeConstraint
> "", "".join(dtypes.as_dtype(x).name for x in allowed_list)))
> TypeError: Value passed to parameter 'images' has DataType bfloat16 not in list of allowed values: int8, uint8, int16, uint16, int32, int64, float16, float32, float64
> "
36695,Function String Keras Attention Layer contains error/typo,"It is a documentation issue, but embedded in the code. This seems most appropriate issue template.

## URL(s) with the issue:
https://github.com/tensorflow/tensorflow/blob/v2.1.0/tensorflow/python/keras/layers/dense_attention.py#L187-L313

## Description of issue (what needs changing):
There is an error in the provided example (L236 - 276):

Here is a code example for using `Attention` in a CNN+Attention network:
  ```python
  value_input = tf.keras.Input(shape=(None,), dtype='int32')
  value_embeddings = token_embedding(query_input)
  ```

This last one should be ```value_embeddings = token_embedding(value_input)```
"
36694,Different gradient results for same custom loss function in Tensorflow 2.0,"Tensorflow 2.0 & Python 3.7

```
def custom_loss2(output2, label2):
    loss_value = K.mean(binary_crossentropy(label2, output2)) 
    return loss_value
def EWC_loss(new_weights, old_weights, fisher_matrix, rate):
    sum_w = 0
    for v in range(len(fisher_matrix)):
        sum_w += tf.reduce_sum(tf.multiply(fisher_matrix[v], tf.square(new_weights[v] - old_weights[v]))) 
    return sum_w*rate
```

Two different trains, the same results were expected but two very different results came out. 
First one, just let rate = 0.5

```
del optimizer
del tape
optimizer = tf.keras.optimizers.SGD()
ewc_model = tf.keras.models.clone_model(model)
old_weights = model.trainable_variables.copy()
for epoch in range(num_epochs):
    with tf.GradientTape() as tape:
        out = ewc_model(features_t)
        new_weights = ewc_model.trainable_variables.copy()
        ewc_loss = EWC_loss(new_weights, old_weights, fisher_matrix, 0.5)
        loss = ewc_loss + custom_loss2(out, labels_2_t)
        grad = tape.gradient(loss, ewc_model.trainable_variables)
        optimizer.apply_gradients(grads_and_vars=zip(grad, ewc_model.trainable_variables))
    if (epoch+1)%100 == 0:
        print(""epch: {}, loss: {}"".format(epoch, loss.numpy()))
        print(ewc_loss.numpy(), loss.numpy())
```

In case II, just put the factor out and let rate = 1.0 but put 0.5 to ewc_loss:

```
del optimizer
del tape
optimizer = tf.keras.optimizers.SGD()
ewc_model = tf.keras.models.clone_model(model)
old_weights = model.trainable_variables.copy()
for epoch in range(num_epochs):
    with tf.GradientTape() as tape:
        out = ewc_model(features_t)
        new_weights = ewc_model.trainable_variables.copy()
        ewc_loss = 0.5*EWC_loss(new_weights, old_weights, fisher_matrix, 1.0)
        loss = ewc_loss + custom_loss2(out, labels_2_t)
        grad = tape.gradient(loss, ewc_model.trainable_variables)
        optimizer.apply_gradients(grads_and_vars=zip(grad, ewc_model.trainable_variables))
    if (epoch+1)%100 == 0:
        print(""epch: {}, loss: {}"".format(epoch, loss.numpy()))
        print(ewc_loss.numpy(), loss.numpy())
```

Tests were with random samples, but the same for those test codes described above. 
We evaluated the model using two test sets, loss = custom_loss2(prd, labels_2). 
The first case returned:

```
tf.Tensor(14.144677747478463, shape=(), dtype=float64)
tf.Tensor(14.254150624518838, shape=(), dtype=float64)
```

but the case II returned:

```
tf.Tensor(0.15645654679566814, shape=(), dtype=float64)
tf.Tensor(0.263113701303186, shape=(), dtype=float64)
```

Can anyone identify this issue? If the gradient was wrong, then the risk of applying tf.GradientTape() is very high using custom loss function."
36693,Spelling of placeholder incorrect in line 53... :P,"Thank you for submitting a TensorFlow documentation issue. Per our GitHub
policy, we only address code/doc bugs, performance issues, feature requests, and
build/installation issues on GitHub.

The TensorFlow docs are open source! To get involved, read the documentation
contributor guide: https://www.tensorflow.org/community/contribute/docs

## URL(s) with the issue:
https://github.com/tensorflow/tensorflow/blob/r0.8/tensorflow/examples/tutorials/mnist/mnist_with_summaries.py

Please provide a link to the documentation entry, for example:
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/MyMethod

## Description of issue (what needs changing):

the spelling of placeholder is incorrect in line 53

### Clear description
the spelling in placehoolder and should be placeholder
For example, why should someone use this method? How is it useful?

### Correct links

Is the link to the source code correct?

### Parameters defined

Are all parameters defined and formatted correctly?

### Returns defined

Are return values defined?

### Raises listed and defined

Are the errors defined? For example,
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises

### Usage example

Is there a usage example?

See the API guide: https://www.tensorflow.org/community/contribute/docs_ref
on how to write testable usage examples.

### Request visuals, if applicable

Are there currently visuals? If not, will it clarify the content?

### Submit a pull request?

Maybe.. If you accept the request 

Are you planning to also submit a pull request to fix the issue? See the docs
contributor guide: https://www.tensorflow.org/community/contribute/docs,
docs API guide: https://www.tensorflow.org/community/contribute/docs_ref and the
docs style guide: https://www.tensorflow.org/community/contribute/docs_style
"
36692,"TFLiteConverter: segmentation fault when dilation is not (1,1) in CONV_2D","<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): tf-nightly
- TensorFlow version (use command below): v1.12.1-24656-g0ec37eb 2.2.0-dev20200212
- Python version: 3.6.9
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
I have segmentaion fault when I run the script.

**Describe the expected behavior**
No crashes.

**Code to reproduce the issue**

```
import numpy
import tensorflow
import tensorflow.keras
import tensorflow.lite

def representative_dataset_gen():
    yield [numpy.random.uniform(low=-1, high=1, size=(1,28,28,16)).astype(numpy.float32)]


model=tensorflow.keras.Sequential()
model.add(
    tensorflow.keras.layers.Conv2D(
        filters=16, kernel_size=7, dilation_rate=(2,2), input_shape=(28,28,16),
        use_bias=True, bias_initializer='ones'
    )
)

converter = tensorflow.lite.TFLiteConverter.from_keras_model(model)
converter.optimizations = [tensorflow.lite.Optimize.DEFAULT]
converter.target_spec.supported_ops = [tensorflow.lite.OpsSet.TFLITE_BUILTINS_INT8]
converter.representative_dataset = representative_dataset_gen
converter.experimental_new_converter = False

tflite_model = converter.convert()
```
**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

If I set experimental_new_converter = True, it works
If I set use_bias = False, it works
If I set dilation_rate=(1,1), it works

Logs:

2020-02-12 11:18:37.697439: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1118] 0:   N 
2020-02-12 11:18:37.701589: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: graph_to_optimize
2020-02-12 11:18:37.701631: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   constant_folding: Graph size after: 12 nodes (-7), 13 edges (-2), time = 0.839ms.
2020-02-12 11:18:37.701648: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   constant_folding: Graph size after: 12 nodes (0), 13 edges (0), time = 0.249ms.
WARNING:absl:Please consider switching to use new converter by setting experimental_new_converter to true. Old converter (TOCO) is deprecated and flow will be switched on by default to use new converter soon.
Traceback (most recent call last):
  File ""/home/elezhe01/work/scripts/test_crash.py"", line 24, in <module>
    tflite_model = converter.convert()
  File ""/home/elezhe01/.local/lib/python3.6/site-packages/tensorflow_core/lite/python/lite.py"", line 513, in convert
    **converter_kwargs)
  File ""/home/elezhe01/.local/lib/python3.6/site-packages/tensorflow_core/lite/python/convert.py"", line 496, in toco_convert_impl
    enable_mlir_converter=enable_mlir_converter)
  File ""/home/elezhe01/.local/lib/python3.6/site-packages/tensorflow_core/lite/python/convert.py"", line 227, in toco_convert_protos
    raise ConverterError(""See console for info.\n%s\n%s\n"" % (stdout, stderr))
tensorflow.lite.python.convert.ConverterError: See console for info.
2020-02-12 11:18:39.730113: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 6 operators, 13 arrays (0 quantized)
2020-02-12 11:18:39.730252: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 6 operators, 13 arrays (0 quantized)
Fatal Python error: Segmentation fault

Current thread 0x00007f8f78473740 (most recent call first):
  File ""/home/elezhe01/.local/lib/python3.6/site-packages/tensorflow_core/lite/toco/python/toco_from_protos.py"", line 56 in execute
  File ""/home/elezhe01/.local/lib/python3.6/site-packages/absl/app.py"", line 250 in _run_main
  File ""/home/elezhe01/.local/lib/python3.6/site-packages/absl/app.py"", line 299 in run
  File ""/home/elezhe01/.local/lib/python3.6/site-packages/tensorflow_core/python/platform/app.py"", line 40 in run
  File ""/home/elezhe01/.local/lib/python3.6/site-packages/tensorflow_core/lite/toco/python/toco_from_protos.py"", line 93 in main
  File ""/home/elezhe01/.local/bin/toco_from_protos"", line 8 in <module>
Segmentation fault (core dumped)
"
36691,_pywrap_tensorflow_internal.so: undefined symbol: _ZTIN10tensorflow8OpKernelE,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): `Ubuntu 16.04.6`
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: `N/A`
- TensorFlow installed from (source or binary): `source`
- TensorFlow version: `2.1.0 (master)`
- Python version: `Python 3.5.2`
- Installed using virtualenv? pip? conda?: `apt`
- Bazel version (if compiling from source): `1.2.1`
- GCC/Compiler version (if compiling from source): `gcc 5.4.0`
- CUDA/cuDNN version: `CUDA 10.2 / cuDNN 7.6.5.32-1+cuda10.2`
- GPU model and memory: `NVIDIA Tesla V100`



**Describe the problem**
Observed after 00befcdeb87f1fc490d247d127ee438f63fe3666 commit.
TensorFlow building fails with the error:
```
05:24:13  ./tensorflow/c/eager/tape.h: In instantiation of 'tensorflow::Status tensorflow::eager::{anonymous}::InitialGradients(const tensorflow::eager::VSpace<Gradient, BackwardFunction, TapeTensor>&, tensorflow::gtl::ArraySlice<long long int>, const std::unordered_map<long long int, TapeTensor>&, tensorflow::gtl::ArraySlice<Gradient*>, const TensorTape&, tensorflow::eager::OpTape<BackwardFunction, TapeTensor>&, std::unordered_map<long long int, std::vector<LhsScalar*> >*) [with Gradient = _object; BackwardFunction = std::function<_object*(_object*, const std::vector<long long int>&)>; TapeTensor = PyTapeTensor; tensorflow::gtl::ArraySlice<long long int> = absl::Span<const long long int>; tensorflow::gtl::ArraySlice<Gradient*> = absl::Span<_object* const>; tensorflow::eager::TensorTape = std::unordered_map<long long int, long long int>; tensorflow::eager::OpTape<BackwardFunction, TapeTensor> = std::unordered_map<long long int, tensorflow::eager::OpTapeEntry<std::function<_object*(_object*, const std::vector<long long int>&)>, PyTapeTensor>, std::hash<long long int>, std::equal_to<long long int>, std::allocator<std::pair<const long long int, tensorflow::eager::OpTapeEntry<std::function<_object*(_object*, const std::vector<long long int>&)>, PyTapeTensor> > > >]':
05:24:13  ./tensorflow/c/eager/tape.h:663:30:   required from 'tensorflow::Status tensorflow::eager::GradientTape<Gradient, BackwardFunction, TapeTensor>::ComputeGradient(const tensorflow::eager::VSpace<Gradient, BackwardFunction, TapeTensor>&, tensorflow::gtl::ArraySlice<long long int>, tensorflow::gtl::ArraySlice<long long int>, const std::unordered_map<long long int, TapeTensor>&, tensorflow::gtl::ArraySlice<Gradient*>, std::vector<LhsScalar*>*) [with Gradient = _object; BackwardFunction = std::function<_object*(_object*, const std::vector<long long int>&)>; TapeTensor = PyTapeTensor; tensorflow::gtl::ArraySlice<long long int> = absl::Span<const long long int>; tensorflow::gtl::ArraySlice<Gradient*> = absl::Span<_object* const>]'
05:24:13  tensorflow/python/eager/pywrap_tfe_src.cc:2566:27:   required from here
05:24:13  ./tensorflow/c/eager/tape.h:576:21: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]
05:24:13     for (int i = 0; i < target_tensor_ids.size(); ++i) {
05:24:13                       ^
05:24:13  ./tensorflow/c/eager/tape.h:588:27: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]
05:24:13           for (int j = 0; j < op_it->second.output_tensor_info.size(); ++j) {
05:24:13                             ^
05:24:52  ERROR: /scrap/jenkins/workspace/_ML_DevOps_team/ml-tensorflow-ci-pipeline/tensorflow/tensorflow/python/keras/api/BUILD:130:1: Executing genrule //tensorflow/python/keras/api:keras_python_api_gen_compat_v2 failed (Exit 1)
05:24:52  Traceback (most recent call last):
05:24:52    File ""/home/swx-jenkins/.cache/bazel/_bazel_swx-jenkins/2c3650f385da66a5652cb752baf8a83c/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_keras_python_api_gen_compat_v2.runfiles/org_tensorflow/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>
05:24:52      from tensorflow.python.pywrap_tensorflow_internal import *
05:24:52    File ""/home/swx-jenkins/.cache/bazel/_bazel_swx-jenkins/2c3650f385da66a5652cb752baf8a83c/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_keras_python_api_gen_compat_v2.runfiles/org_tensorflow/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>
05:24:52      _pywrap_tensorflow_internal = swig_import_helper()
05:24:52    File ""/home/swx-jenkins/.cache/bazel/_bazel_swx-jenkins/2c3650f385da66a5652cb752baf8a83c/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_keras_python_api_gen_compat_v2.runfiles/org_tensorflow/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
05:24:52      _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
05:24:52    File ""/usr/lib/python3.5/imp.py"", line 242, in load_module
05:24:52      return load_dynamic(name, filename, file)
05:24:52    File ""/usr/lib/python3.5/imp.py"", line 342, in load_dynamic
05:24:52      return _load(spec)
05:24:52  ImportError: /home/swx-jenkins/.cache/bazel/_bazel_swx-jenkins/2c3650f385da66a5652cb752baf8a83c/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_keras_python_api_gen_compat_v2.runfiles/org_tensorflow/tensorflow/python/_pywrap_tensorflow_internal.so: undefined symbol: _ZTIN10tensorflow8OpKernelE
05:24:52  
05:24:52  During handling of the above exception, another exception occurred:
05:24:52  
05:24:52  Traceback (most recent call last):
05:24:52    File ""/home/swx-jenkins/.cache/bazel/_bazel_swx-jenkins/2c3650f385da66a5652cb752baf8a83c/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_keras_python_api_gen_compat_v2.runfiles/org_tensorflow/tensorflow/python/tools/api/generator/create_python_api.py"", line 27, in <module>
05:24:52      from tensorflow.python.tools.api.generator import doc_srcs
05:24:52    File ""/home/swx-jenkins/.cache/bazel/_bazel_swx-jenkins/2c3650f385da66a5652cb752baf8a83c/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_keras_python_api_gen_compat_v2.runfiles/org_tensorflow/tensorflow/python/__init__.py"", line 50, in <module>
05:24:52      from tensorflow.python import pywrap_tensorflow
05:24:52    File ""/home/swx-jenkins/.cache/bazel/_bazel_swx-jenkins/2c3650f385da66a5652cb752baf8a83c/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_keras_python_api_gen_compat_v2.runfiles/org_tensorflow/tensorflow/python/pywrap_tensorflow.py"", line 69, in <module>
05:24:52      raise ImportError(msg)
05:24:52  ImportError: Traceback (most recent call last):
05:24:52    File ""/home/swx-jenkins/.cache/bazel/_bazel_swx-jenkins/2c3650f385da66a5652cb752baf8a83c/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_keras_python_api_gen_compat_v2.runfiles/org_tensorflow/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>
05:24:52      from tensorflow.python.pywrap_tensorflow_internal import *
05:24:52    File ""/home/swx-jenkins/.cache/bazel/_bazel_swx-jenkins/2c3650f385da66a5652cb752baf8a83c/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_keras_python_api_gen_compat_v2.runfiles/org_tensorflow/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>
05:24:52      _pywrap_tensorflow_internal = swig_import_helper()
05:24:52    File ""/home/swx-jenkins/.cache/bazel/_bazel_swx-jenkins/2c3650f385da66a5652cb752baf8a83c/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_keras_python_api_gen_compat_v2.runfiles/org_tensorflow/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
05:24:52      _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
05:24:52    File ""/usr/lib/python3.5/imp.py"", line 242, in load_module
05:24:52      return load_dynamic(name, filename, file)
05:24:52    File ""/usr/lib/python3.5/imp.py"", line 342, in load_dynamic
05:24:52      return _load(spec)
05:24:52  ImportError: /home/swx-jenkins/.cache/bazel/_bazel_swx-jenkins/2c3650f385da66a5652cb752baf8a83c/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_keras_python_api_gen_compat_v2.runfiles/org_tensorflow/tensorflow/python/_pywrap_tensorflow_internal.so: undefined symbol: _ZTIN10tensorflow8OpKernelE
```

**Provide the exact sequence of commands / steps that you executed before running into the problem**
.tf_configure.bazelrc:
```
build --action_env PYTHON_BIN_PATH=""/usr/bin/python3""
build --action_env PYTHON_LIB_PATH=""/usr/local/lib/python3.5/dist-packages""
build --python_path=""/usr/bin/python3""
build:xla --define with_xla_support=true
build --action_env TF_CUDA_VERSION=""10.2""
build --action_env TF_CUDNN_VERSION=""7""
build --action_env TF_NCCL_VERSION=""2.6.0""
build --action_env TF_CUDA_PATHS=""/hpc/local/oss/cuda10.2/cuda-toolkit,/usr,/usr/local/cuda""
build --action_env CUDA_TOOLKIT_PATH=""/hpc/local/oss/cuda10.2/cuda-toolkit""
build --action_env CUDNN_INSTALL_PATH=""/usr""
build --action_env NCCL_INSTALL_PATH=""<cut>/nccl/stable""
build --action_env TF_CUDA_COMPUTE_CAPABILITIES=""7.0""
build --action_env LD_LIBRARY_PATH=""<cut>/nccl/stable/lib:<cut>/ci_tools_do_not_remove/hpcx-v2.6.pre-gcc-MLNX_OFED_LINUX-4.7-1.0.0.1-ubuntu16.04-x86_64/nccl_rdma_sharp_plugin/lib:<cut>/ci_tools_do_not_remove/hpcx-v2.6.pre-gcc-MLNX_OFED_LINUX-4.7-1.0.0.1-ubuntu16.04-x86_64/ucx/lib/ucx:<cut>/ci_tools_do_not_remove/hpcx-v2.6.pre-gcc-MLNX_OFED_LINUX-4.7-1.0.0.1-ubuntu16.04-x86_64/ucx/lib:<cut>/ci_tools_do_not_remove/hpcx-v2.6.pre-gcc-MLNX_OFED_LINUX-4.7-1.0.0.1-ubuntu16.04-x86_64/sharp/lib:<cut>/ci_tools_do_not_remove/hpcx-v2.6.pre-gcc-MLNX_OFED_LINUX-4.7-1.0.0.1-ubuntu16.04-x86_64/hcoll/lib:<cut>/ci_tools_do_not_remove/hpcx-v2.6.pre-gcc-MLNX_OFED_LINUX-4.7-1.0.0.1-ubuntu16.04-x86_64/ompi/lib:/hpc/local/oss/cuda10.2/cuda-toolkit/lib64:/hpc/local/oss/cuda10.2/cuda-toolkit/lib64/stubs:/usr/local/nvidia/lib:/usr/local/nvidia/lib64""
build --action_env GCC_HOST_COMPILER_PATH=""/usr/bin/gcc-5""
build --config=cuda
build:opt --copt=-march=native
build:opt --host_copt=-march=native
build:opt --define with_default_optimizations=true
test --flaky_test_attempts=3
test --test_size_filters=small,medium
test --test_env=LD_LIBRARY_PATH
test:v1 --test_tag_filters=-benchmark-test,-no_oss,-no_gpu,-oss_serial
test:v1 --build_tag_filters=-benchmark-test,-no_oss,-no_gpu
test:v2 --test_tag_filters=-benchmark-test,-no_oss,-no_gpu,-oss_serial,-v1only
test:v2 --build_tag_filters=-benchmark-test,-no_oss,-no_gpu,-v1only
build --action_env TF_CONFIGURE_IOS=""0""
```

CC @av8ramit"
36687,tflite object detection predictions are always same irrespective of input,"Hi have a tensorflow tflite model that i am trying to deploy on an android device, the issue is that the outputs of the model are always same. Irrespective of input.

Can anyone help ?


Here is the link to that model: https://esriis-my.sharepoint.com/:u:/g/personal/san10428_esri_com/EbO-1fGDczRKnW9E2-hDhbQB17aufX_se-VdMBZrhaid3A?e=UKRiyO

Here is the link to the android project: https://esriis-my.sharepoint.com/:u:/g/personal/san10428_esri_com/ES17ARjqhcdEnvgNlpq3O5MBaDOtHN1H7kk3Q75Y9M5VTA?e=IzemCE


tensorflow version: 2.0.0
"
36686,Dataset padded_batch fails with InvalidArgumentError,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.1.0
- Python version: 3.6

**Describe the current behavior**
```
rt = tf.ragged.constant([[1,2,3], [2], [1,2,3,4], [1,1]])
ds = tf.data.Dataset.from_tensor_slices(rt)
ds.padded_batch(2, padded_shapes=[None])
```
Fails with the following error:
```
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/home/vas/anaconda3/envs/text-ai/lib/python3.6/site-packages/tensorflow_core/python/data/ops/dataset_ops.py"", line 1481, in padded_batch
    drop_remainder)
  File ""/home/vas/anaconda3/envs/text-ai/lib/python3.6/site-packages/tensorflow_core/python/data/ops/dataset_ops.py"", line 3858, in __init__
    output_shapes=structure.get_flat_tensor_shapes(self._structure))
  File ""/home/vas/anaconda3/envs/text-ai/lib/python3.6/site-packages/tensorflow_core/python/ops/gen_dataset_ops.py"", line 4091, in padded_batch_dataset_v2
    _ops.raise_from_not_ok_status(e, name)
  File ""/home/vas/anaconda3/envs/text-ai/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py"", line 6606, in raise_from_not_ok_status
    six.raise_from(core._status_to_exception(e.code, message), None)
  File ""<string>"", line 3, in raise_from
tensorflow.python.framework.errors_impl.InvalidArgumentError: Mismatched type between padding value 0 and input dataset's component 0: int32 vs. variant [Op:PaddedBatchDatasetV2]
```
However:
```
ds.map(lambda x: x).padded_batch(2, padded_shapes=[None])
```
works as expected"
36684,Failed to run visualize.py (tflite model visualizer),"python visualize.py
Traceback (most recent call last):
 File ""visualize.py"", line 30, in <module>
 from tensorflow.lite.python import schema_py_generated as schema_fb
ImportError: cannot import name schema_py_generated

Thanks for your help!
"
36683,DLL load failed: The specified module could not be found.,"Warning:
This Python interpreter is in a conda environment, but the environment has
not been activated.  Libraries may fail to load.  To activate this environment
please see https://conda.io/activation

Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import tensorflow
Traceback (most recent call last):
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\ProgramData\Anaconda3\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\ProgramData\Anaconda3\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: The specified module could not be found.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\__init__.py"", line 101, in <module>
    from tensorflow_core import *
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\__init__.py"", line 40, in <module>
    from tensorflow.python.tools import module_util as _module_util
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\__init__.py"", line 50, in __getattr__
    module = self._load()
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\__init__.py"", line 44, in _load
    module = _importlib.import_module(self.__name__)
  File ""C:\ProgramData\Anaconda3\lib\importlib\__init__.py"", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 74, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\ProgramData\Anaconda3\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\ProgramData\Anaconda3\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: The specified module could not be found.


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/errors

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help."
36682,unspecified errors while building tensorflow,"
**System information**

- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): window 10 
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:N/A
- TensorFlow installed from (source or binary): build from source
- TensorFlow version (use command below):2.1.0
- Python version: python 3.8.1
- Bazel version (if compiling from source):0.29.1
- CUDA/cuDNN version:N/A
- GPU model and memory:N/A

**Describe the current behavior**

While building tensorflow/examples/label_image,build process fails with unspecified error code changing everytime i build. I think this error is due to lack of memory of my laptop. but can't find the reason of it with error code i got from it.
Attaching three error codes i got while building.

ERROR: C:/users/gyuhwan/_bazel_gyuhwan/qrf5imf6/external/com_google_protobuf/BUILD:759:1: ProtoCompile external/com_google_protobuf/python/google/protobuf/field_mask_pb2.py failed (Exit -1). Note: Remote connection/protocol failed with: execution failed
Action failed to execute: java.io.IOException: ERROR: src/main/native/windows/process.cc(199): CreateProcessW(""C:\users\gyuhwan\_bazel_gyuhwan\qrf5imf6\execroot\org_tensorflow\bazel-out\x64_windows-opt\bin\external\com_google_protobuf\protoc.exe"" --python_out=bazel-out/x64_windows-py2-opt/bin/external/com_google_protobuf/python -Iexternal/com_google_protobuf/python -Ibazel-out/x64_windows-py2-opt/bin/external/com_google_protobuf/python bazel-out/x64_windows-py2-opt/bin/external/com_google_protobuf/python/google/protobuf/field_mask.proto): ?≪꽭?ㅺ? 嫄곕??섏뿀?듬땲??

ERROR: C:/users/gyuhwan/tensor_flow/tensorflow/tensorflow/core/kernels/boosted_trees/BUILD:22:1: ProtoCompile tensorflow/core/kernels/boosted_trees/boosted_trees.pb.h failed (Exit -1). Note: Remote connection/protocol failed with: execution failed
Action failed to execute: java.io.IOException: ERROR: src/main/native/windows/process.cc(199): CreateProcessW(""C:\users\gyuhwan\_bazel_gyuhwan\qrf5imf6\execroot\org_tensorflow\bazel-out\x64_windows-opt\bin\external\com_google_protobuf\protoc.exe"" --cpp_out=bazel-out/x64_windows-py2-opt/bin -I. -Iexternal/com_google_protobuf/src -Ibazel-out/x64_windows-py2-opt/bin/external/com_google_protobuf/src tensorflow/core/kernels/boosted_trees/boosted_trees.proto): ?≪꽭?ㅺ? 嫄곕??섏뿀?듬땲??
 (error: 5)

ERROR: C:/users/gyuhwan/tensor_flow/tensorflow/tensorflow/core/BUILD:2499:1: ProtoCompile tensorflow/core/protobuf/saved_model_pb2.py failed due to unexpected I/O exception: C:\users\gyuhwan\_bazel_gyuhwan\qrf5imf6\execroot\org_tensorflow\bazel-out\_tmp\action_outs\stderr-3 (?? ????? ??? ?? ??? ??? ????? ??? ? ? ????)
java.io.FileNotFoundException: C:\users\gyuhwan\_bazel_gyuhwan\qrf5imf6\execroot\org_tensorflow\bazel-out\_tmp\action_outs\stderr-3 (?? ????? ??? ?? ??? ??? ????? ??? ? ? ????)
        at java.base/java.io.FileOutputStream.open0(Native Method)
        at java.base/java.io.FileOutputStream.open(Unknown Source)
        at java.base/java.io.FileOutputStream.<init>(Unknown Source)
        at java.base/java.io.FileOutputStream.<init>(Unknown Source)
        at com.google.devtools.build.lib.vfs.AbstractFileSystem$ProfiledFileOutputStream.<init>(AbstractFileSystem.java:153)
        at com.google.devtools.build.lib.vfs.AbstractFileSystem.createFileOutputStream(AbstractFileSystem.java:89)
        at com.google.devtools.build.lib.vfs.AbstractFileSystem.getOutputStream(AbstractFileSystem.java:101)
        at com.google.devtools.build.lib.vfs.Path.getOutputStream(Path.java:535)
        at com.google.devtools.build.lib.vfs.Path.getOutputStream(Path.java:523)
        at com.google.devtools.build.lib.util.io.FileOutErr$FileRecordingOutputStream.getOutputStream(FileOutErr.java:353)
        at com.google.devtools.build.lib.util.io.FileOutErr$FileRecordingOutputStream.write(FileOutErr.java:460)
        at com.google.devtools.build.lib.exec.local.LocalSpawnRunner$SubprocessHandler.start(LocalSpawnRunner.java:365)
        at com.google.devtools.build.lib.exec.local.LocalSpawnRunner$SubprocessHandler.run(LocalSpawnRunner.java:192)
        at com.google.devtools.build.lib.exec.local.LocalSpawnRunner.exec(LocalSpawnRunner.java:153)
        at com.google.devtools.build.lib.exec.SpawnRunner.execAsync(SpawnRunner.java:225)
        at com.google.devtools.build.lib.exec.AbstractSpawnStrategy.exec(AbstractSpawnStrategy.java:123)
        at com.google.devtools.build.lib.exec.AbstractSpawnStrategy.exec(AbstractSpawnStrategy.java:88)
        at com.google.devtools.build.lib.actions.SpawnActionContext.beginExecution(SpawnActionContext.java:41)
        at com.google.devtools.build.lib.exec.ProxySpawnActionContext.beginExecution(ProxySpawnActionContext.java:60)
        at com.google.devtools.build.lib.actions.SpawnContinuation$1.execute(SpawnContinuation.java:80)
        at com.google.devtools.build.lib.analysis.actions.SpawnAction$SpawnActionContinuation.execute(SpawnAction.java:1344)
        at com.google.devtools.build.lib.analysis.actions.SpawnAction.beginExecution(SpawnAction.java:314)
        at com.google.devtools.build.lib.actions.Action.execute(Action.java:123)
        at com.google.devtools.build.lib.skyframe.SkyframeActionExecutor$4.execute(SkyframeActionExecutor.java:851)
        at com.google.devtools.build.lib.skyframe.SkyframeActionExecutor$ActionRunner.continueAction(SkyframeActionExecutor.java:985)
        at com.google.devtools.build.lib.skyframe.SkyframeActionExecutor$ActionRunner.run(SkyframeActionExecutor.java:957)
        at com.google.devtools.build.lib.skyframe.ActionExecutionState.runStateMachine(ActionExecutionState.java:116)
        at com.google.devtools.build.lib.skyframe.ActionExecutionState.getResultOrDependOnFuture(ActionExecutionState.java:77)
        at com.google.devtools.build.lib.skyframe.SkyframeActionExecutor.executeAction(SkyframeActionExecutor.java:577)
        at com.google.devtools.build.lib.skyframe.ActionExecutionFunction.checkCacheAndExecuteIfNeeded(ActionExecutionFunction.java:760)
        at com.google.devtools.build.lib.skyframe.ActionExecutionFunction.compute(ActionExecutionFunction.java:275)
        at com.google.devtools.build.skyframe.AbstractParallelEvaluator$Evaluate.run(AbstractParallelEvaluator.java:451)        at com.google.devtools.build.lib.concurrent.AbstractQueueVisitor$WrappedRunnable.run(AbstractQueueVisitor.java:399)
        at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)
        at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)
        at java.base/java.lang.Thread.run(Unknown Source)

**Describe the expected behavior**

it would be helpful if error code notice the user that error is because of insufficient memory or notification of expected performance of computer

**Code to reproduce the issue**

bazel build /tensorflow/examples/label_image/...

**Other info / logs**

CPU of my computer is i7 1065G7 and memory is 8G
"
36681,How to build libhexagon_nn_skel.so ?,"Hi
TFLite hexagon delegate is based on hexagon nnlib, I can get nnlib source code from https://source.codeaurora.org/quic/hexagon_nn/nnlib, and I can build ibhexagon_nn_skel.so according to ""README.HOW_TO_BUILD"" in nnlib, but my build libhexagon_nn_skel.so can not be used for tflite, report some error.
Does  tflite modify the nnlib code ? how to build libhexagon_nn_skel.so using the nnlib source code ?
"
36680,Image Augmentation erroring out with ImageDataGenerator.flow and multiple labels,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 2.1.0-rc0
- **Python version**:3.6
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**: 
- **Exact command to reproduce**: Given source code ur
l
You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with:

```bash
python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""
```

### Describe the problem
Getting error : ""tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled"" when running as python script.

But same code running fine in notebook mode

### Source code / logs
https://www.kaggle.com/anirbank/bengali-graphemes-multichannelcnn-with-dataaug"
36679,tf.keras.layers.Softmax should respect image_data_format by default,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): 2.1.0
- Are you willing to contribute it (Yes/No): No



**Describe the feature and the current behavior/state.**
Tensorflow allows one to set image_data_format of either channels_last (set by default, NHWC) or channels_first (NCHW) using `tf.keras.backend.set_image_data_format(data_format)`. Doing so nicely results in almost all layers of the `tf.keras.model` adjust appropriately by either bringing the channel last or first. Even the model.load_weights() work perfectly fine (and transparently), respecting user's choice of image_data_format, as it should. The story is somewhat different when it comes to `tf.keras.layers.Softmax`. Softmax layer/activation is often used in classification problems to normalize the output of the model and such normalization is applied w.r.t to an axis. Currently, Softmax implementation always sets the default value of axis = -1, which is the last axis. This works perfectly fine when image_data_format is channels_last but it for channels_first, one needs to explicitly set the axis to 1. 

This feels like slightly out of sync compared to how all the other layers behave. They respect the image_data_format automatically and adjust accordingly. So why not Softmax? I am pretty sure 90% of the use cases of Softmax applies the function along the channels axis, so why not make it respect the data format automatically,too ?

This is also easy to miss for folks just getting started with TensorFlow. The docs does not mention anything remotely about this.

**Will this change the current api? How?**
Yes. `tf.keras.layers.Softmax` would start respecting the default set_image_data_format set by user and hence axis would be -1 incase of NHWC and 1 incase of NCHW.

This would also allow one to easily specify `activation=""softmax""` in the last layer instead of adding one explicit line like :

`model.add(tf.keras.layers.Softmax(axis=-1 if data_format==""channels_last"" else 1))`

**Who will benefit with this feature?**
A big group of people who are either using Softmax in its default form (i.e. to normalize along channels axis) or someone who is getting started with TF and wants to have flexibility of changing image data layouts. This would render a uniform API experience and expectation to end-user, trusting that tensorflow's layers are respecting the global image data format without much hassle or individual treatment.

**Any Other info.**
"
36678,Tensorflow installation document Korean translated page outdated,"## URL(s) with the issue 

https://www.tensorflow.org/install?hl=ko

## Description of issue (what needs changing)

On installation document/windows build from source page, it tells that ""TensorFlow를 컴파일하는 데 사용되는 빌드 도구인 Bazel 0.23.0을 설치합니다. C++를 빌드하도록 Bazel을 설정합니다."" which means install Bazel 0.23.0 to compile Tensorflow. However, most recent version of Tensorflow which is r2.1, doesn't support Bazel 0.23.0. Instead, it uses 0.27.0~0.29.0. I checked English document and it tells me the version of Bazel that is needed. So, I think the Korean page should be renewed.


"
36677,Custom training loss with custom gradients,"I am trying to write a custom loss in Tensorflow v2, for simplicity let's say that I'm using Mean Squared Error loss as follows,
```
loss_object = tf.keras.losses.MeanSquaredError()


def loss(model, x, y, training):
  # training=training is needed only if there are layers with different
  # behavior during training versus inference (e.g. Dropout).
  y_ = model(x, training=training)
  return loss_object(y_true=y, y_pred=y_)
```

Now I know that Tensorflow does [automatic differentiation](https://stackoverflow.com/questions/48219296/why-doesnt-keras-need-the-gradient-of-a-custom-loss-function).

But I want to specify my **custom gradient**, in the BackPropagation algorithm,
if we use MSE, we have to do the following 

<a href=""https://www.codecogs.com/eqnedit.php?latex=\frac{\partial&space;E}{\partial&space;w}&space;=&space;\frac{\partial&space;E}{\partial&space;y_i}&space;\frac{\partial&space;y_i}{\partial&space;net_i}&space;\frac{\partial&space;net_i}{\partial&space;w}"" target=""_blank""><img src=""https://latex.codecogs.com/gif.latex?\frac{\partial&space;E}{\partial&space;w}&space;=&space;\frac{\partial&space;E}{\partial&space;y_i}&space;\frac{\partial&space;y_i}{\partial&space;net_i}&space;\frac{\partial&space;net_i}{\partial&space;w}"" title=""\frac{\partial E}{\partial w} = \frac{\partial E}{\partial y_i} \frac{\partial y_i}{\partial net_i} \frac{\partial net_i}{\partial w}"" /></a>

<img src=""https://latex.codecogs.com/gif.latex?\frac{\partial&space;E}{\partial&space;w}&space;=&space;(y&space;-&space;\hat{y})*&space;D(activation)&space;*&space;x"" title=""\frac{\partial E}{\partial w} = (y - \hat{y})* D(activation) * x"" />

Is it possible in **Keras** to replace <a href=""https://www.codecogs.com/eqnedit.php?latex=(y&space;-&space;\hat{y})"" target=""_blank""><img src=""https://latex.codecogs.com/gif.latex?(y&space;-&space;\hat{y})"" title=""(y - \hat{y})"" /></a>  with <a href=""https://www.codecogs.com/eqnedit.php?latex=(y&space;-&space;p)"" target=""_blank""><img src=""https://latex.codecogs.com/gif.latex?(y&space;-&space;p)"" title=""(y - p)"" /></a> where `p` is a tensor that is passed during training before applying gradients.

"
36676,TF2 SavedModel does not support multiple signatures? ,"I used `tf.saved_model.save` and `tf.saved_model.load` to save and load TF2 SavedModel. According to [this link][1], I created a signature and this signature is `serving_default`. Then I try to add a new function with the signature decorator in class `Adder`. But after I loaded the model according to [this][2], I find that the signatures disappear in the model, i.e., `print(adder1.signatures)` prints no signature names. I don't find any information about how to use multiple signatures while saving models. So I think this may be a bug. If it is not, can anyone tell me how can I use multiple signatures in one model? Thank you very much. 

Tensorflow `2.1.0`, on Google Colab. The code looks like this: 

```
import tensorflow as tf
import tensorflow_hub as hub
import numpy as np
import os
import pandas as pd

class Adder(tf.Module):

  @tf.function(input_signature=[tf.TensorSpec(shape=None, dtype=tf.float32), tf.TensorSpec(shape=None, dtype=tf.float32)])# 
  def add(self, x, y):
    return x + y ** 2 + 1
  
  @tf.function(input_signature=[tf.TensorSpec(shape=None, dtype=tf.float32)])
  def square(self, x):
    return x ** 2

to_export = Adder()
tf.saved_model.save(
    to_export, 
    '/tmp/adder'            
)

adder1 = tf.saved_model.load(""/tmp/adder"")
print(adder1.signatures)
adder1_sig = adder1.signatures[""serving_default""]
adder1_sig(x = tf.constant(1.), y = tf.constant(2.))
```


  [1]: https://www.tensorflow.org/api_docs/python/tf/saved_model/save#used-in-the-notebooks
  [2]: https://www.tensorflow.org/api_docs/python/tf/saved_model/load"
36675,"[TF2] TRT Engine Ops are not garbage collected, resulting in incorrect reuse","
**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.1
- Python version: 3.6.9
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: CUDA 10.0 cuDNN 7.6.5, TensorRT 6.0.1
- GPU model and memory: RTX 2080 


**Describe the current behavior**

When TRTEngineOps are created for different runs back to back, the first one is not properly cleared, resulting in potential reuse with an incorrect configuration.

In the reproducing case, running the dynamic input shapes TFTRT test creates and uses an fp16 engine op as expected, but the fp32 test does not create a new instance, instead reusing the one from before.  This behavior may result in the test failing, depending on the particular numerical results and tolerances.  In the case where the test passes, the bug can still be observed by parsing through the logs from the run (some snippets of mine are included below).

I'm not sure if the issue is limited to TFTRT, or is the result of a larger problem with the resource manager in TF2.  This forced garbage collection is likely an attempted workaround for the issue:
https://github.com/tensorflow/tensorflow/blob/v2.1.0/tensorflow/python/compiler/tensorrt/test/tf_trt_integration_test_base.py#L372

**Describe the expected behavior**

Created TRTEngineOps should be handled by the resource manager such that they aren't reused in a separate invocation.

**Code to reproduce the issue**

Running the dynamic_input_shapes_test.py with increased verbosity will demonstrate the failure in the logs:
`env TF_CPP_VMODULE=convert_nodes=2,trt_engine_op=1 python tensorflow/python/compiler/tensorrt/test/dynamic_input_shapes_test.py`

**Other info / logs**

(Full log attached)
In the first creation of a TRTEngineOp for the test, we can see that none are found in the TF-TRT cache, so one will be created:

> 2020-02-11 18:21:13.440748: W tensorflow/core/framework/op_kernel.cc:1655] OP_REQUIRES failed at trt_engine_resource_ops.cc:183 : Not found: Container TF-TRT does not exist. (Could not find resource: TF-TRT/TRTEngineOp_0)
> INFO:tensorflow:Could not find TRTEngineOp_0 in TF-TRT cache. This can happen if build() is not called, which means TensorRT engines will be built and cached at runtime.
> I0211 18:21:13.440817 140386763036416 trt_convert.py:1074] Could not find TRTEngineOp_0 in TF-TRT cache. This can happen if build() is not called, which means TensorRT engines will be built and cached at runtime.
> INFO:tensorflow:Assets written to: /tmp/dynamic_input_shapes_test0vdtk5_4/tmpsu9l_mk2/tmpd2ckucmp/assets
> I0211 18:21:13.468731 140386763036416 builder_impl.py:775] Assets written to: /tmp/dynamic_input_shapes_test0vdtk5_4/tmpsu9l_mk2/tmpd2ckucmp/assets
> ...
> ...
> 2020-02-11 18:21:13.624985: I tensorflow/compiler/tf2tensorrt/kernels/trt_engine_op.cc:257] Constructing PartitionedCall/TRTEngineOp_0
> 2020-02-11 18:21:13.625010: I tensorflow/compiler/tf2tensorrt/kernels/trt_engine_op.cc:237] Constructing function handle
> 2020-02-11 18:21:13.625334: I tensorflow/compiler/tf2tensorrt/kernels/trt_engine_op.cc:736] Building a new TensorRT engine for PartitionedCall/TRTEngineOp_0 with input shapes: [[1,5,5,1]]
> 2020-02-11 18:21:13.625404: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libnvinfer.so.6
> 2020-02-11 18:21:13.829528: I tensorflow/compiler/tf2tensorrt/convert/convert_nodes.cc:5645] Starting engine conversion, precision mode: FP16


However, in the FP32 test run later, we do not see the warning about an engine op not being found in the cache, and there is no new engine op created:

> 
> WARNING:tensorflow:From /home/mconley/TF2.1_test_env/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
> Instructions for updating:
> If using Keras pass *_constraint arguments to layers.
> W0211 18:21:16.109585 140386763036416 deprecation.py:506] From /home/mconley/TF2.1_test_env/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
> Instructions for updating:
> If using Keras pass *_constraint arguments to layers.
> INFO:tensorflow:Assets written to: /tmp/dynamic_input_shapes_test0vdtk5_4/tmp45kosn5r/tmpou7_kbrm/assets
> I0211 18:21:16.131422 140386763036416 builder_impl.py:775] Assets written to: /tmp/dynamic_input_shapes_test0vdtk5_4/tmp45kosn5r/tmpou7_kbrm/assets
> WARNING:tensorflow:Unresolved object in checkpoint: (root).trt_engine_resources.TRTEngineOp_0._serialized_trt_resource_filename
> W0211 18:21:16.308784 140386763036416 util.py:144] Unresolved object in checkpoint: (root).trt_engine_resources.TRTEngineOp_0._serialized_trt_resource_filename
> ...
> ...
> 2020-02-11 18:21:16.378245: I tensorflow/compiler/tf2tensorrt/kernels/trt_engine_op.cc:257] Constructing PartitionedCall/TRTEngineOp_0
> 2020-02-11 18:21:16.378281: I tensorflow/compiler/tf2tensorrt/kernels/trt_engine_op.cc:237] Constructing function handle
> 2020-02-11 18:21:16.378781: I tensorflow/compiler/tf2tensorrt/kernels/trt_engine_op.cc:515] Executing TRT engine: PartitionedCall/TRTEngineOp_0
> 2020-02-11 18:21:16.379594: I tensorflow/compiler/tf2tensorrt/kernels/trt_engine_op.cc:515] Executing TRT engine: PartitionedCall/TRTEngineOp_0
> [logged_output.log](https://github.com/tensorflow/tensorflow/files/4189640/logged_output.log)
> "
36674,Tensorflow error ,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No. I'm trying to reproduce simple examples.

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 x64

- TensorFlow installed from (source or binary):
I used the following commands in command promt window:
pip install --user pip
pip install --user tensorflow

- TensorFlow version (use command below): 2.1

- Python version: 3.7.6

- CUDA/cuDNN version: I've installed cuda 10.1

- GPU model and memory: nvidia geforce gtx 650


**Describe the current behavior**
I can import tensorflow with no error messages (`import tensorflow as tf`), but I a error message appear when trying to run a simple line (`tf.set_random_seed(42)`)

Erro message:

> ERROR:root:Internal Python error in the inspect module.
> Below is the traceback from this internal error.
> 
> Traceback (most recent call last):
>   File ""C:\Users\NIP\AppData\Local\Programs\Python\Python37\lib\site-packages\IPython\core\interactiveshell.py"", line 3331, in run_code
>     exec(code_obj, self.user_global_ns, self.user_ns)
>   File ""<ipython-input-16-f8b0a2f8392f>"", line 1, in <module>
>     tf.set_random_seed(42)
> AttributeError: module 'tensorflow' has no attribute 'set_random_seed'
> 
> During handling of the above exception, another exception occurred:
> 
> Traceback (most recent call last):
>   File ""C:\Users\NIP\AppData\Local\Programs\Python\Python37\lib\site-packages\IPython\core\interactiveshell.py"", line 2044, in showtraceback
>     stb = value._render_traceback_()
> AttributeError: 'AttributeError' object has no attribute '_render_traceback_'
> 
> During handling of the above exception, another exception occurred:
> 
> Traceback (most recent call last):
>   File ""C:\Users\NIP\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module>
>     from tensorflow.python.pywrap_tensorflow_internal import *
>   File ""C:\Users\NIP\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module>
>     _pywrap_tensorflow_internal = swig_import_helper()
>   File ""C:\Users\NIP\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
>     _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
>   File ""C:\Users\NIP\AppData\Local\Programs\Python\Python37\lib\imp.py"", line 242, in load_module
>     return load_dynamic(name, filename, file)
>   File ""C:\Users\NIP\AppData\Local\Programs\Python\Python37\lib\imp.py"", line 342, in load_dynamic
>     return _load(spec)
> ImportError: DLL load failed: A dynamic link library (DLL) initialization routine failed.
> 
> During handling of the above exception, another exception occurred:
> 
> Traceback (most recent call last):
>   File ""C:\Users\NIP\AppData\Local\Programs\Python\Python37\lib\site-packages\IPython\core\ultratb.py"", line 1151, in get_records
>     return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)
>   File ""C:\Users\NIP\AppData\Local\Programs\Python\Python37\lib\site-packages\IPython\core\ultratb.py"", line 319, in wrapped
>     return f(*args, **kwargs)
>   File ""C:\Users\NIP\AppData\Local\Programs\Python\Python37\lib\site-packages\IPython\core\ultratb.py"", line 353, in _fixed_getinnerframes
>     records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))
>   File ""C:\Users\NIP\AppData\Local\Programs\Python\Python37\lib\inspect.py"", line 1502, in getinnerframes
>     frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)
>   File ""C:\Users\NIP\AppData\Local\Programs\Python\Python37\lib\inspect.py"", line 1460, in getframeinfo
>     filename = getsourcefile(frame) or getfile(frame)
>   File ""C:\Users\NIP\AppData\Local\Programs\Python\Python37\lib\inspect.py"", line 696, in getsourcefile
>     if getattr(getmodule(object, filename), '__loader__', None) is not None:
>   File ""C:\Users\NIP\AppData\Local\Programs\Python\Python37\lib\inspect.py"", line 733, in getmodule
>     if ismodule(module) and hasattr(module, '__file__'):
>   File ""C:\Users\NIP\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow\__init__.py"", line 50, in __getattr__
>     module = self._load()
>   File ""C:\Users\NIP\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow\__init__.py"", line 44, in _load
>     module = _importlib.import_module(self.__name__)
>   File ""C:\Users\NIP\AppData\Local\Programs\Python\Python37\lib\importlib\__init__.py"", line 127, in import_module
>     return _bootstrap._gcd_import(name[level:], package, level)
>   File ""<frozen importlib._bootstrap>"", line 1006, in _gcd_import
>   File ""<frozen importlib._bootstrap>"", line 983, in _find_and_load
>   File ""<frozen importlib._bootstrap>"", line 953, in _find_and_load_unlocked
>   File ""<frozen importlib._bootstrap>"", line 219, in _call_with_frames_removed
>   File ""<frozen importlib._bootstrap>"", line 1006, in _gcd_import
>   File ""<frozen importlib._bootstrap>"", line 983, in _find_and_load
>   File ""<frozen importlib._bootstrap>"", line 967, in _find_and_load_unlocked
>   File ""<frozen importlib._bootstrap>"", line 677, in _load_unlocked
>   File ""<frozen importlib._bootstrap_external>"", line 728, in exec_module
>   File ""<frozen importlib._bootstrap>"", line 219, in _call_with_frames_removed
>   File ""C:\Users\NIP\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow_core\__init__.py"", line 42, in <module>
>     from . _api.v2 import audio
>   File ""C:\Users\NIP\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow_core\_api\v2\audio\__init__.py"", line 10, in <module>
>     from tensorflow.python.ops.gen_audio_ops import decode_wav
>   File ""C:\Users\NIP\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow_core\python\ops\gen_audio_ops.py"", line 9, in <module>
>     from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow
>   File ""C:\Users\NIP\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow\__init__.py"", line 50, in __getattr__
>     module = self._load()
>   File ""C:\Users\NIP\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow\__init__.py"", line 44, in _load
>     module = _importlib.import_module(self.__name__)
>   File ""C:\Users\NIP\AppData\Local\Programs\Python\Python37\lib\importlib\__init__.py"", line 127, in import_module
>     return _bootstrap._gcd_import(name[level:], package, level)
>   File ""C:\Users\NIP\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow_core\python\__init__.py"", line 49, in <module>
>     from tensorflow.python import pywrap_tensorflow
>   File ""C:\Users\NIP\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 74, in <module>
>     raise ImportError(msg)
> ImportError: Traceback (most recent call last):
>   File ""C:\Users\NIP\AppData\Local\Programs\Python\Python37\lib\site-packages\IPython\core\interactiveshell.py"", line 3331, in run_code
>     exec(code_obj, self.user_global_ns, self.user_ns)
>   File ""<ipython-input-16-f8b0a2f8392f>"", line 1, in <module>
>     tf.set_random_seed(42)
> AttributeError: module 'tensorflow' has no attribute 'set_random_seed'
> 
> During handling of the above exception, another exception occurred:
> 
> Traceback (most recent call last):
>   File ""C:\Users\NIP\AppData\Local\Programs\Python\Python37\lib\site-packages\IPython\core\interactiveshell.py"", line 2044, in showtraceback
>     stb = value._render_traceback_()
> AttributeError: 'AttributeError' object has no attribute '_render_traceback_'
> 
> During handling of the above exception, another exception occurred:
> 
> Traceback (most recent call last):
>   File ""C:\Users\NIP\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module>
>     from tensorflow.python.pywrap_tensorflow_internal import *
>   File ""C:\Users\NIP\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module>
>     _pywrap_tensorflow_internal = swig_import_helper()
>   File ""C:\Users\NIP\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
>     _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
>   File ""C:\Users\NIP\AppData\Local\Programs\Python\Python37\lib\imp.py"", line 242, in load_module
>     return load_dynamic(name, filename, file)
>   File ""C:\Users\NIP\AppData\Local\Programs\Python\Python37\lib\imp.py"", line 342, in load_dynamic
>     return _load(spec)
> ImportError: DLL load failed: A dynamic link library (DLL) initialization routine failed.
> 
> 
> Failed to load the native TensorFlow runtime.
> 
> See https://www.tensorflow.org/install/errors
> 
> for some common reasons and solutions.  Include the entire stack trace
> above this error message when asking for help.
> ---------------------------------------------------------------------------
> 

**Describe the expected behavior**
Trying to reproduce this example https://peterroelants.github.io/posts/gaussian-process-kernel-fitting/

**Code to reproduce the issue**
```
import tensorflow as tf
tf.set_random_seed(42)
```

**Other info / logs**
I'm also using Jupyter. I installed it with `pip install --upgrade --user pip` then `pip install --user notebook`.
I installed python with default settings and checked ""add to path"" option.
I installed ""visual studio community 2019 - desktop develoment with c++"". with lastest ""window sdk"", ""MSVC v140 - VS 2015 C++ buildtools"", ""MSVC v141 - VS 2017 C++ buildtools"", ""MSVC v142 - VS 2019 C++ buildtools"". I'm not sure whether this are the correct so called ""redistributible microsoft visual c++ "" files.
"
36672,Add a raspberry pi docker image,"**System information**
- TensorFlow version (you are using): 2.1.0
- Are you willing to contribute it (Yes/No): Yes



**Describe the feature and the current behavior/state.**

There is already a tensoflow docker image for amd64. I'd like to see if there is interest other than me to have the same for armv7.

I recently made one for tensorflow 2.1.0 here:

https://github.com/fgervais/docker-tensorflow/blob/master/Dockerfile

I think it would be nice to have an image like this published on the official docker hub repository.

Note that this image does not need to be built on an actual raspberry pi. I build mine on my x86_64 system using:

```
docker buildx build --platform linux/arm/v7 -t tensorflow:2.1.0-cp35 --load .
```

I'm guessing whatever CI system that builds the amd64 image could also build the armv7 image.

**Who will benefit with this feature?**

On the raspberry pi, the docker image is quite useful since a lot of pip wheels do not come in binary form and the cost of building, let say scipy, is quite high. Having the docker image ensures a plug-and-play experience.

What do you think? Would this integrate well in tensorflow?"
36669,Error while reading resource variable _AnonymousVar12 from Container: localhost,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): centos 7.7
- TensorFlow installed from (source or binary): yes
- TensorFlow version (use command below): 2.1
- Python version: 3.6



**Describe the current behavior**
Error when trying to update tf.Variable in data.Dataset pipeline

**Describe the expected behavior**
No error

**Code to reproduce the issue**
```
ds=tf.data.Dataset.from_tensor_slices(tf.constant([[9, 10, 11, 12]]))
def update(update):
    ref = tf.Variable([1, 2, 3, 4, 5, 6, 7, 8])
    indices = tf.constant([[4], [3], [1] ,[7]])
    updated = tf.tensor_scatter_nd_update(ref, indices, update)
    return updated
ds=ds.map(update)
for i in ds:
    print(i)
```

**Other info / logs**
```
FailedPreconditionError: {{function_node __inference_Dataset_map_update_674}} Error while reading resource variable _AnonymousVar12 from Container: localhost. This could mean that the variable was uninitialized. Not found: Resource localhost/_AnonymousVar12/N10tensorflow3VarE does not exist.
	 [[{{node TensorScatterUpdate/ReadVariableOp}}]] [Op:IteratorGetNextSync]
```
"
36668,TF 1.15.2: Metrics created in custom layer (self.add_metric) producing wrong output,"(this seems to be the same issue as #32144, but for tf 1.15)

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 1.15.2
- Python version: 3.6.9
- CUDA/cuDNN version: 10.1
- GPU model and memory: GeForce GTX 1080Ti


**Describe the current behavior**

When creating a custom model class (inheriting from `tf.keras.Model`), with a custom layer class (tf.keras.layers.Layer) as attribute, and trying to define metrics (using `self.add_metric()`) in both the outer class and the inner layer, the metrics outputs seem to be swapped (keys and values do not match) when training with `model.fit`.

**Describe the expected behavior**

Metrics names and values should match.
This seems to be an issue only of tf 1. Did not observe this in tf 2.1.

**Code to reproduce the issue**
```python
import tensorflow as tf
from tensorflow.keras import layers

class InnerLayer(layers.Layer):

    def __init__(self):
        super(InnerLayer, self).__init__()

    def call(self, inputs):
        # Should always print 1.0
        self.add_metric(tf.constant(1.0), aggregation='mean',
                        name='should_be_1')
        return inputs


class OuterModel(tf.keras.Model):
    def __init__(self):
        super(OuterModel, self).__init__()
        self.inner = InnerLayer()

    def call(self, inputs):
        # Should always print 2.0
        self.add_metric(tf.constant(2.0), aggregation='mean',
                        name='should_be_2')
        return self.inner(inputs)


model = OuterModel()
model.compile('adam', loss='mse')
dataset = tf.random.normal((100, 5))
model.fit(dataset, dataset, epochs=10, steps_per_epoch=100, verbose=2)
```
Output (with bug):

```
Epoch 1/10
100/100 - 0s - loss: 0.0000e+00 - should_be_1: 2.0000 - should_be_2: 1.0000
Epoch 2/10
100/100 - 0s - loss: 0.0000e+00 - should_be_1: 2.0000 - should_be_2: 1.0000
Epoch 3/10
100/100 - 0s - loss: 0.0000e+00 - should_be_1: 2.0000 - should_be_2: 1.0000
Epoch 4/10
100/100 - 0s - loss: 0.0000e+00 - should_be_1: 2.0000 - should_be_2: 1.0000
Epoch 5/10
100/100 - 0s - loss: 0.0000e+00 - should_be_1: 2.0000 - should_be_2: 1.0000
Epoch 6/10
100/100 - 0s - loss: 0.0000e+00 - should_be_1: 2.0000 - should_be_2: 1.0000
Epoch 7/10
100/100 - 0s - loss: 0.0000e+00 - should_be_1: 2.0000 - should_be_2: 1.0000
Epoch 8/10
100/100 - 0s - loss: 0.0000e+00 - should_be_1: 2.0000 - should_be_2: 1.0000
Epoch 9/10
100/100 - 0s - loss: 0.0000e+00 - should_be_1: 2.0000 - should_be_2: 1.0000
Epoch 10/10
100/100 - 0s - loss: 0.0000e+00 - should_be_1: 2.0000 - should_be_2: 1.0000
```"
36667,Pip package for tensorflow 2.1 for Raspberry Pi (python 3.7),"Current versions of Raspbian use Python 3.7. Yet, the most updated pip packages (TF 2.1) provided by Google for the Raspberry pi are limited to python 3.5:

https://www.tensorflow.org/install/pip

Pypi provides much older versions of TF (1.14) for python 3.7.  

Please update the version provided by either google or Pypi"
36666,Saving model with tf.keras.layers.RNN with unroll=True fails for save_format=tf,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution: Linux Ubuntu 18.04
- Mobile device if the issue happens on mobile device: -
- TensorFlow installed from: binary (tf-nightly via docker)
- TensorFlow version: GIT_VERSION = v1.12.1-23779-g96c5c8a 2.2.0-dev20200202
- Python version: 3.6.9
- Bazel version (if compiling from source): -
- GCC/Compiler version (if compiling from source): -
- CUDA/cuDNN version: CPU only
- GPU model and memory: CPU only

**Describe the current behavior**
Saving a `tf.keras.Sequential` model with `tf.keras.layers.RNN` with `unroll=True` fails for `save_format=tf`(but succeeds for `save_format=ht`).

**Describe the expected behavior**
Saving should succeed for `save_format=tf` as well.

**Code to reproduce the issue**
```python
import tensorflow as tf

model = tf.keras.Sequential()

model.add(tf.keras.layers.Input(shape=(1, 1,)))

cell = tf.keras.layers.GRUCell(10)

model.add(tf.keras.layers.RNN(cell, unroll=True))
    
model.save(""test.tf"", save_format='tf') # fails
#model.save(""test.h5"", save_format='h5') # works
```

**Other info / logs**
Unfortunately, saving as h5 is not an option (which would actually be my favorite), since it fails when having more than one cell (see #36093).

Traceback in case of failure:
```bash
  File ""test.py"", line 11, in <module>
    model.save(""test.tf"", save_format='tf') # fails
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/network.py"", line 999, in save
    signatures, options)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/saving/save.py"", line 138, in save_model
    signatures, options)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/saving/saved_model/save.py"", line 78, in save
    save_lib.save(model, filepath, signatures, options)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/saved_model/save.py"", line 955, in save
    checkpoint_graph_view)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/saved_model/signature_serialization.py"", line 75, in find_function_to_export
    functions = saveable_view.list_functions(saveable_view.root)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/saved_model/save.py"", line 142, in list_functions
    self._serialization_cache)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 2535, in _list_functions_for_serialization
    .list_functions_for_serialization(serialization_cache))
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/saving/saved_model/base_serialization.py"", line 91, in list_functions_for_serialization
    fns = self.functions_to_serialize(serialization_cache)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/saving/saved_model/layer_serialization.py"", line 79, in functions_to_serialize
    serialization_cache).functions_to_serialize)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/saving/saved_model/layer_serialization.py"", line 94, in _get_serialized_attributes
    serialization_cache)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/saving/saved_model/model_serialization.py"", line 53, in _get_serialized_attributes_internal
    serialization_cache))
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/saving/saved_model/layer_serialization.py"", line 103, in _get_serialized_attributes_internal
    functions = save_impl.wrap_layer_functions(self.obj, serialization_cache)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/saving/saved_model/save_impl.py"", line 161, in wrap_layer_functions
    original_fns = _replace_child_layer_functions(layer, serialization_cache)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/saving/saved_model/save_impl.py"", line 249, in _replace_child_layer_functions
    serialization_cache).functions)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/saving/saved_model/layer_serialization.py"", line 94, in _get_serialized_attributes
    serialization_cache)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/saving/saved_model/layer_serialization.py"", line 103, in _get_serialized_attributes_internal
    functions = save_impl.wrap_layer_functions(self.obj, serialization_cache)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/saving/saved_model/save_impl.py"", line 171, in wrap_layer_functions
    '{}_layer_call_and_return_conditional_losses'.format(layer.name))
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/saving/saved_model/save_impl.py"", line 487, in add_function
    self.add_trace(*self._input_signature)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/saving/saved_model/save_impl.py"", line 402, in add_trace
    trace_with_training(True)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/saving/saved_model/save_impl.py"", line 400, in trace_with_training
    fn.get_concrete_function(*args, **kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/saving/saved_model/save_impl.py"", line 531, in get_concrete_function
    return super(LayerCall, self).get_concrete_function(*args, **kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py"", line 953, in get_concrete_function
    concrete = self._get_concrete_function_garbage_collected(*args, **kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py"", line 859, in _get_concrete_function_garbage_collected
    self._initialize(args, kwargs, add_initializers_to=initializers)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py"", line 505, in _initialize
    *args, **kwds))
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py"", line 2440, in _get_concrete_function_internal_garbage_collected
    graph_function, _, _ = self._maybe_define_function(args, kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py"", line 2771, in _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py"", line 2661, in _create_graph_function
    capture_by_value=self._capture_by_value),
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/func_graph.py"", line 981, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py"", line 440, in wrapped_fn
    return weak_wrapped_fn().__wrapped__(*args, **kwds)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/saving/saved_model/save_impl.py"", line 508, in wrapper
    ret = method(*args, **kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/saving/saved_model/utils.py"", line 170, in wrap_with_training_arg
    lambda: replace_training_and_call(False))
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/utils/tf_utils.py"", line 59, in smart_cond
    pred, true_fn=true_fn, false_fn=false_fn, name=name)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/smart_cond.py"", line 54, in smart_cond
    return true_fn()
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/saving/saved_model/utils.py"", line 169, in <lambda>
    lambda: replace_training_and_call(True),
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/saving/saved_model/utils.py"", line 165, in replace_training_and_call
    return wrapped_call(*args, **kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/saving/saved_model/save_impl.py"", line 550, in call_and_return_conditional_losses
    return layer_call(inputs, *args, **kwargs), layer.get_losses_for(inputs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/layers/recurrent.py"", line 734, in call
    raise ValueError('Cannot unroll a RNN if the '
ValueError: Cannot unroll a RNN if the time dimension is undefined. 
- If using a Sequential model, specify the time dimension by passing an `input_shape` or `batch_input_shape` argument to your first layer. If your first layer is an Embedding, you can also use the `input_length` argument.
- If using the functional API, specify the time dimension by passing a `shape` or `batch_shape` argument to your Input layer.

```
"
36665,TensorFlow 2.1 import 'DLL load failed error',"When I tried to import TensorFlow 2,1 in Anaconda environment after seeming successful installation using Aanacond Prompt, I got a 'DLL load failed error'. I tried several times from creating the virtual environment to installation tensorflow 2.1 again without success. The installation process went through fine without any error message. 

Strangely, the tensorflow 2.0 works fine but not tensorflow 2.1.  I am currently can run tensorflow 2.0 but would love to have 2.1 if I can find a fix for the 2.1 error.

Thanks for any help!

Bin
--------------------------------------------------------------------------------

name: Build/Installation Issue about: Use this template for build/installation
issues labels: 'type:build/install'

---

<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version:
- Python version:
- Installed using virtualenv? pip? conda?:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:



**Describe the problem**

**Provide the exact sequence of commands / steps that you executed before running into the problem**


**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
36663,Flatten layer behaves differently on different machine architectures for a 4 D tensor.,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Python version**:
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with:

```bash
python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""
```

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
36662,Issue with tf.estimator.export.ServingInputReceiver(),"**System information**
- I run my project on a Jupyter Notebook on GCP
- TensorFlow version: 1.15
- Python version: 3.5.3

**Describe the current behavior**
I followed every instruction to build a serving_input_receiver_fn(). Valliappa Lakshmanan provides his solution to me but it still does not work. I believe it is not the problem of the codes but some unknown issue.

**Describe the expected behavior**
I do not expect any error in creating and exporting this simple serving function. But when I run it, there are error messages. Despite the errors, I can still use the exported model for prediction.

**Code to reproduce the issue**
def serving_input_receiver_fn():
    inputs = {
        'job' : tf.compat.v1.placeholder(dtype = tf.string, shape = [None]),
        'marital' : tf.compat.v1.placeholder(dtype = tf.string, shape = [None]),
        ......
    }
    return tf.estimator.export.ServingInputReceiver(inputs, inputs)

**Other info / logs**
INFO:tensorflow:'serving_default' : Classification input must be a single string Tensor; got {'job': <tf.Tensor 'Placeholder:0' shape=(?,) dtype=string>, 'marital': <tf.Tensor 'Placeholder_1:0' shape=(?,) dtype=string>, ...
WARNING:tensorflow:Export includes no default signature!
"
36661,undefined reference to `tflite::DefaultErrorReporter()',"System information:  
Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04
TensorFlow installed from (source or binary): source
TensorFlow version (use command below): v1.4.0-19-ga52c8d9 1.4.1
Python version: 2.7.12
Bazel version (if compiling from source): 0.8.1
GCC/Compiler version (if compiling from source): g++ 5.4.0
CUDA/cuDNN version: none
GPU model and memory: none
Exact command to reproduce:

g++ -I../tensorflow  -Llib -ltensorflow_cc -Llib -ltensorflowlite  test.cpp -o exec


Describe the problem
I used this tutorial to build tensorflow [link](https://tuatini.me/building-tensorflow-as-a-standalone-project/).  Also this [link](https://github.com/FloopCZ/tensorflow_cc)


Additionally, I built tensorflow-lite with:

bazel build //tensorflow/lite:libtensorflowlite.so


I am using this code for testing tflite:

  #include < cstdio >
  #include ""tensorflow/lite/interpreter.h""
  #include ""tensorflow/lite/kernels/register.h""
  #include ""tensorflow/lite/model.h""
  #include ""tensorflow/lite/tools/gen_op_registration.h""


  using namespace tflite;

  int main(int argc, char* argv[]) {
  if (argc != 2) {
  fprintf(stderr, ""minimal \n"");
  return 1;
  }
  const char* filename = argv[1];

  std::unique_ptr<tflite::FlatBufferModel> model =
  tflite::FlatBufferModel::BuildFromFile(filename);
  return 0;
  }



Here is the error:

/tmp/ccPKK7am.o: In function `main':
test.cpp:(.text+0x57): undefined reference to `tflite::DefaultErrorReporter()'
test.cpp:(.text+0x6d): undefined reference to `tflite::FlatBufferModel::BuildFromFile(char const*, tflite::ErrorReporter*)'
/tmp/ccPKK7am.o: In function `std::default_delete<tflite::FlatBufferModel>::operator()(tflite::FlatBufferModel*) const':
test.cpp:(.text._ZNKSt14default_deleteIN6tflite15FlatBufferModelEEclEPS1_[_ZNKSt14default_deleteIN6tflite15FlatBufferModelEEclEPS1_]+0x1e): undefined reference to `tflite::FlatBufferModel::~FlatBufferModel()'
collect2: error: ld returned 1 exit status
"
36658,generate_projects target in the tf micro makefile fails for some target architectures,"@tensorflow/micro

**System information**
- Host OS Platform and Distribution: cygwin
- TensorFlow installed from (source or binary):
- Tensorflow version (commit SHA if source):
- Target platform (e.g. Arm Mbed OS, Arduino Nano 33 etc.): ARC

**Describe the problem**
The generate_projects target in the tf micro makefile creates all projects, including the projects that are not valid for the given TARGET_ARCH. Only the projects valid for the provided TARGET_ARCH should be added to the ALL_PROJECT_TARGETS variable.
Possible solutions:
- add TARGET_ARCH specific conditions around filling the ALL_PROJECT_TARGETS list (note that this is not in line with the policy to keep TARGET_ARCH specific code in separate files)
- Change the location of including the arch specific makefiles such that ALL_PROJECT_TARGETS can be filtered.
- ...


**Please provide the exact sequence of commands/steps when you ran into the problem**
make -f tensorflow/lite/micro/tools/make/Makefile TARGET_ARCH=arc generate_projects
"
36657,Hello World example for STM32F746 make error,"@tensorflow/micro

**System information**
- Host OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 x64
- TensorFlow installed from (source or binary): pip
- Tensorflow version (commit SHA if source): 2.1.0
- Target platform (e.g. Arm Mbed OS, Arduino Nano 33 etc.): STM32F7

**Describe the problem**
I started following the guide here : https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/micro/examples/hello_world#deploy-to-STM32F746
which required me to download TensorFlow's sources (I installed it previously using pip), and my goal is to deploy it to STM32F746. Except that the first step : 
`make -f tensorflow/lite/micro/tools/make/Makefile TARGET=mbed TAGS=""CMSIS disco_f746ng"" generate_hello_world_mbed_project`
doesn't work and throws me an error saying that it tried to download gemmlowp for some reason and that tensorflow is not recognized as an internal command... I get that I'm not supposed to run tensorflow outside of python but I'm just running **make** here... Shouldn't have any link whatsoever.

**Please provide the exact sequence of commands/steps when you ran into the problem**

Used the first command from the ""Deploy to STM32F746"" guide `make -f tensorflow/lite/micro/tools/make/Makefile TARGET=mbed TAGS=""CMSIS disco_f746ng"" generate_hello_world_mbed_project`

Encountered first an error with unam -m tied to my OS or architecture, had to manually delete the makefile code regarding that and write it in stone; then I ran it again and got this :

```
make -f tensorflow/lite/micro/tools/make/Makefile TARGET=mbed TAGS=""CMSIS disco_f746ng"" generate_hello_world_mbed_project
tensorflow/lite/micro/tools/make/download_and_extract.sh ""https://github.com/google/gemmlowp/archive/719139ce755a0f31cbf1c37f7f98adcc7fc9f425.zip"" ""7e8191b24853d75de2af87622ad293ba"" tensorflow/lite/micro/tools/make/downloads/gemmlowp
'tensorflow' is not recognized as an internal or external command operable program or batch file
make: *** [tensorflow/lite/micro/tools/make/downloads/gemmlowp] Error 1
```
"
36656,Profiler doesn't work correctly in tensorflow 2.1,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): centos-release-7-6.1810.2.el7.centos.x86_64
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): 2.1.0
- Python version: 3.7.4
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory: None

**Describe the current behavior**

The code below, taken from https://www.tensorflow.org/tensorboard/graphs, and used to profile a function call, seems to behave differently in tf 2.0 and tf 2.1. In 2.0, the memory and CPU usage can be inspected with `tensorboard`; in 2.1, they cannot as the radio buttons are grayed out. I am filing this as a tensorflow issue rather a tensorboard one since it seems to be independent of the tensorboard version. I also suspect it's due to the `tensorflow` pip package now including GPU support by default (the problem appears on a machine without a GPU).

```
# The function to be traced.
@tf.function
def my_func(x, y):
  # A simple hand-rolled layer.
  return tf.nn.relu(tf.matmul(x, y))

# Set up logging.
stamp = datetime.now().strftime(""%Y%m%d-%H%M%S"")
logdir = 'logs/func/%s' % stamp
writer = tf.summary.create_file_writer(logdir)

# Sample data for your function.
x = tf.random.uniform((3, 3))
y = tf.random.uniform((3, 3))

# Bracket the function call with
# tf.summary.trace_on() and tf.summary.trace_export().
tf.summary.trace_on(graph=True, profiler=True)
# Call only one tf.function when tracing.
z = my_func(x, y)
with writer.as_default():
  tf.summary.trace_export(
      name=""my_func_trace"",
      step=0,
      profiler_outdir=logdir)
```

**Describe the expected behavior**

It should be the behaviour found in tf 2.0.

**Other info / logs**

Screenshots of the two tensorboard displays are shown below. Of note, running the code with tf 2.1 shows the errors below, which do not appear with tf 2.0. I do not have a GPU on my machine, but would still expect the profiler to work.

```
(...)
2020-02-11 10:26:17.256467: I tensorflow/core/profiler/lib/profiler_session.cc:225] Profiler session started.
2020-02-11 10:26:17.256643: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcupti.so.10.1'; dlerror: libcupti.so.10.1: cannot open shared object file: No such file or directory
2020-02-11 10:26:17.256681: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1307] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI could not be loaded or symbol could not be found.
2020-02-11 10:26:17.256701: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1346] function cupti_interface_->ActivityRegisterCallbacks( AllocCuptiActivityBuffer, FreeCuptiActivityBuffer)failed with error CUPTI could not be loaded or symbol could not be found.
2020-02-11 10:26:17.393265: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1329] function cupti_interface_->EnableCallback( 0 , subscriber_, CUPTI_CB_DOMAIN_DRIVER_API, cbid)failed with error CUPTI could not be loaded or symbol could not be found.
2020-02-11 10:26:17.393327: I tensorflow/core/profiler/internal/gpu/device_tracer.cc:88]  GpuTracer has collected 0 callback api events and 0 activity events.
```
![tf20profile](https://user-images.githubusercontent.com/45923989/74228945-58c22280-4cb9-11ea-935b-c24d4945f1e4.png)
![tf21](https://user-images.githubusercontent.com/45923989/74228948-595ab900-4cb9-11ea-9609-3c04b6fbfb82.png)


"
36654,"Tensorflow Lite Android Application Crashes on Inference A/libc: Fatal signal 11 (SIGSEGV), code 1 (SEGV_MAPERR), fault addr 0x7759200000 in tid 26388 (mple.inpainting), pid 26388 (mple.inpainting)","**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): N/A
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Samsung A30
- TensorFlow installed from (source or binary): Source
- TensorFlow version (use command below): 1.14.0
- Python version: 3.5.5
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A


**Describe the current behavior**
I am working on InPainting application on android using the TensorflowLite model but the application crashes during inference.

**Describe the expected behavior**
I am developing an Inpainting android application using tensorflow lite. The tensorflow lite model takes two inputs:

1. Input Image (512x680x3)
2. Mask Image(512x680x1)

These two input images are loaded from the asset folder in the form of Bitmaps and then converted into ByteBuffer. After that, they are passed to the tensorflow lite model and the model is supposed to give output in the form of ByteBuffer. Later this ByteBuffer is converted into a restored RGB image.

**Code to reproduce the issue**
Main Activity Code
```
 protected void onCreate(Bundle savedInstanceState) {
        super.onCreate(savedInstanceState);
        setContentView(R.layout.activity_main);
        Toolbar toolbar = findViewById(R.id.toolbar);
        setSupportActionBar(toolbar);

        FloatingActionButton fab = findViewById(R.id.fab);
        fab.setOnClickListener(new View.OnClickListener() {
            @Override
            public void onClick(View view) {
                Snackbar.make(view, ""Replace with your own action"", Snackbar.LENGTH_LONG)
                        .setAction(""Action"", null).show();
            }
        });

        try {
            tflite = new Interpreter(loadModelFile(MainActivity.this, ""converted_model.tflite""));

            Bitmap Image = getBitmapFromAsset(this,""001.png"");
            Bitmap Mask = getBitmapFromAsset(this,""tmp_mask.png"");

            ByteBuffer BImage = convertBitmapToByteBuffer(Image);
            System.out.println(""First Image Converted"");
            ByteBuffer BMask = convertBitmapToByteBuffer1(Mask);
            System.out.println(""Second Image Converted"");

            BImage.order(ByteOrder.nativeOrder());
            BMask.order(ByteOrder.nativeOrder());

            System.out.println(""Bytes in BIMAGE ""+BImage.position());
            System.out.println(""Bytes in BMask ""+BMask.position());

            Object[] Inputs = {BImage,BMask};


            int OutputTensorIndex = 0;
            int[] OutputShape =
                    tflite.getOutputTensor(OutputTensorIndex).shape(); // {1, NUM_CLASSES}
            DataType OutputDataType = tflite.getOutputTensor(OutputTensorIndex).dataType();
            System.out.println(""Output 1 Shape ""+ OutputShape[1]+"" ""+OutputShape[2]+"" +OutputShape[3]);
            System.out.println(""Output 1 DataType "" + OutputDataType);

            TensorBuffer outputBuffer = TensorBuffer.createFixedSize(OutputShape, OutputDataType);
            Map<Integer, Object> outputs = new HashMap<>();
            System.out.println(""Resizing Input"");
            System.out.println(""Bytes in Ouput"" + outputBuffer.getBuffer().position());
            outputs.put(0,outputBuffer.getBuffer());
            int[] input1 = new int[]{1,512,680,3};
            int[] input2 = new int[]{1,512,680,1};
            tflite.resizeInput(0,input1);
            tflite.resizeInput(1,input2);
            System.out.println(""Resizing Input Done"");

            tflite.runForMultipleInputsOutputs(Inputs, outputs);

            Toast.makeText(this,""Working"",Toast.LENGTH_LONG).show();
            System.out.println(""Inference Complete"");

            tflite.close();

        } catch (IOException e) {
            Toast.makeText(this,""Failed"",Toast.LENGTH_LONG).show();
            e.printStackTrace();
        }

}
```
Code for getting Bitmap from Asset folder
```
private Bitmap getBitmapFromAsset(Context context, String filePath) {
        AssetManager assetManager = context.getAssets();

        InputStream istr;
        Bitmap bitmap = null;
        try {
            istr = assetManager.open(filePath);
            bitmap = BitmapFactory.decodeStream(istr);
        } catch (IOException e) {
            // handle exception
        }
        return bitmap;
    }
```
Code for Converting Bitmap to ByteBuffer for RGB Input
```
private ByteBuffer convertBitmapToByteBuffer(Bitmap bitmap) {
        int IMAGE_MEAN = 128;
        float IMAGE_STD = 128.0f;
        ByteBuffer byteBuffer = ByteBuffer.allocateDirect(4 * 1 * 512 * 680 * 3);
        int[] intValues = new int[512 * 680];
        bitmap.getPixels(intValues, 0, bitmap.getWidth(), 0, 0, bitmap.getWidth(), bitmap.getHeight());
        int pixel = 0;
        for (int i = 0; i < 512; ++i) {
            for (int j = 0; j < 680; ++j) {
                final int val = intValues[pixel++];
                byteBuffer.putFloat((((val >> 16) & 0xFF)-IMAGE_MEAN)/IMAGE_STD);
                byteBuffer.putFloat((((val >> 8) & 0xFF)-IMAGE_MEAN)/IMAGE_STD);
                byteBuffer.putFloat((((val) & 0xFF)-IMAGE_MEAN)/IMAGE_STD);
            }
        }
        return byteBuffer;
    }
```
Code for Converting Bitmap to ByteBuffer for Single Channel Input

```
private ByteBuffer convertBitmapToByteBuffer1(Bitmap bitmap) {
        int IMAGE_MEAN = 128;
        float IMAGE_STD = 128.0f;
        ByteBuffer byteBuffer1 = ByteBuffer.allocateDirect(4 * 1 * 512 * 680 * 1);
        //byteBuffer1.order(ByteOrder.nativeOrder());
        int[] intValues = new int[512 * 680];
        bitmap.getPixels(intValues, 0, bitmap.getWidth(), 0, 0, bitmap.getWidth(), bitmap.getHeight());
        int pixel = 0;
        for (int i = 0; i < 512; ++i) {
            for (int j = 0; j < 680; ++j) {
                final int val = intValues[pixel++];
                //byteBuffer1.putFloat((((val >> 16) & 0xFF)-IMAGE_MEAN)/IMAGE_STD);
                //byteBuffer1.putFloat((((val >> 8) & 0xFF)-IMAGE_MEAN)/IMAGE_STD);
                byteBuffer1.putFloat((((val) & 0xFF)-IMAGE_MEAN)/IMAGE_STD);
            }
        }
        return byteBuffer1;
    }
```


**Other info / logs**
```
2020-02-11 14:56:45.730 26572-26572/? A/DEBUG: *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** ***
2020-02-11 14:56:44.696 26388-26388/com.example.inpainting A/libc: Fatal signal 11 (SIGSEGV), code 1 (SEGV_MAPERR), fault addr 0x7759200000 in tid 26388 (mple.inpainting), pid 26388 (mple.inpainting)


2020-02-11 14:56:45.730 26572-26572/? A/DEBUG: Build fingerprint: 'samsung/a30dd/a30:9/PPR1.180610.011/A305FDDU2ASF3:user/release-keys'
2020-02-11 14:56:45.730 26572-26572/? A/DEBUG: Revision: '3'
2020-02-11 14:56:45.730 26572-26572/? A/DEBUG: ABI: 'arm64'
2020-02-11 14:56:45.730 26572-26572/? A/DEBUG: pid: 26388, tid: 26388, name: mple.inpainting  >>> com.example.inpainting <<<
2020-02-11 14:56:45.730 26572-26572/? A/DEBUG: signal 11 (SIGSEGV), code 1 (SEGV_MAPERR), fault addr 0x7759200000
2020-02-11 14:56:45.731 26572-26572/? A/DEBUG:     x0  000000770c7eb900  x1  0000007756164700  x2  ffffffffb35eb630  x3  00000077591fffc0
2020-02-11 14:56:45.731 26572-26572/? A/DEBUG:     x4  000000770974fd80  x5  000000770c7eb680  x6  bf7ff19cbf7fec39  x7  bf7ff8c9bf5baee6
2020-02-11 14:56:45.731 26572-26572/? A/DEBUG:     x8  bf800000bf800000  x9  bf709453bf7fdb6c  x10 bf7fffeebf7ffeac  x11 bf7fff54bf7ffa20
2020-02-11 14:56:45.731 26572-26572/? A/DEBUG:     x12 bf800000bf800000  x13 bf7f9c97bf7fb93d  x14 00000000000000aa  x15 00000000000000aa
2020-02-11 14:56:45.731 26572-26572/? A/DEBUG:     x16 0000007759593008  x17 00000077f5f60cf0  x18 0000000000000000  x19 fffffffffffffa00
2020-02-11 14:56:45.731 26572-26572/? A/DEBUG:     x20 fffffffffffffd80  x21 0000000000000000  x22 0000007709750000  x23 0000000000000000
2020-02-11 14:56:45.731 26572-26572/? A/DEBUG:     x24 000000770c7eb900  x25 0000000000000001  x26 0000000000005500  x27 0000000000000380
2020-02-11 14:56:45.731 26572-26572/? A/DEBUG:     x28 0000000000000000  x29 0000007fe8dc5b90
2020-02-11 14:56:45.731 26572-26572/? A/DEBUG:     sp  0000007fe8dc5af0  lr  0000007759423300  pc  00000077f5f60e18

2020-02-11 14:56:46.346 26572-26572/? A/DEBUG: backtrace:
2020-02-11 14:56:46.347 26572-26572/? A/DEBUG:     #00 pc 000000000001de18  /system/lib64/libc.so (memcpy+296)
2020-02-11 14:56:46.347 26572-26572/? A/DEBUG:     #01 pc 000000000005b2fc  /data/app/com.example.inpainting-40kevdvzYiOK_rsH1RbKGA==/lib/arm64/libtensorflowlite_jni.so
2020-02-11 14:56:46.347 26572-26572/? A/DEBUG:     #02 pc 000000000005b008  /data/app/com.example.inpainting-40kevdvzYiOK_rsH1RbKGA==/lib/arm64/libtensorflowlite_jni.so
2020-02-11 14:56:46.347 26572-26572/? A/DEBUG:     #03 pc 000000000005a5a0  /data/app/com.example.inpainting-40kevdvzYiOK_rsH1RbKGA==/lib/arm64/libtensorflowlite_jni.so
2020-02-11 14:56:46.347 26572-26572/? A/DEBUG:     #04 pc 0000000000061ac8  /data/app/com.example.inpainting-40kevdvzYiOK_rsH1RbKGA==/lib/arm64/libtensorflowlite_jni.so
2020-02-11 14:56:46.347 26572-26572/? A/DEBUG:     #05 pc 000000000005a358  /data/app/com.example.inpainting-40kevdvzYiOK_rsH1RbKGA==/lib/arm64/libtensorflowlite_jni.so
2020-02-11 14:56:46.347 26572-26572/? A/DEBUG:     #06 pc 0000000000141aa8  /data/app/com.example.inpainting-40kevdvzYiOK_rsH1RbKGA==/lib/arm64/libtensorflowlite_jni.so
2020-02-11 14:56:46.347 26572-26572/? A/DEBUG:     #07 pc 0000000000144f88  /data/app/com.example.inpainting-40kevdvzYiOK_rsH1RbKGA==/lib/arm64/libtensorflowlite_jni.so
2020-02-11 14:56:46.347 26572-26572/? A/DEBUG:     #08 pc 000000000000eec8  /data/app/com.example.inpainting-40kevdvzYiOK_rsH1RbKGA==/lib/arm64/libtensorflowlite_jni.so (Java_org_tensorflow_lite_NativeInterpreterWrapper_run+32)
2020-02-11 14:56:46.347 26572-26572/? A/DEBUG:     #09 pc 0000000000563be0  /system/lib64/libart.so (art_quick_generic_jni_trampoline+144)
2020-02-11 14:56:46.347 26572-26572/? A/DEBUG:     #10 pc 000000000055ae4c  /system/lib64/libart.so (art_quick_invoke_static_stub+604)
2020-02-11 14:56:46.347 26572-26572/? A/DEBUG:     #11 pc 00000000000d04e8  /system/lib64/libart.so (art::ArtMethod::Invoke(art::Thread*, unsigned int*, unsigned int, art::JValue*, char const*)+232)
2020-02-11 14:56:46.347 26572-26572/? A/DEBUG:     #12 pc 00000000002838c0  /system/lib64/libart.so (art::interpreter::ArtInterpreterToCompiledCodeBridge(art::Thread*, art::ArtMethod*, art::ShadowFrame*, unsigned short, art::JValue*)+344)
2020-02-11 14:56:46.347 26572-26572/? A/DEBUG:     #13 pc 000000000027d8c8  /system/lib64/libart.so (bool art::interpreter::DoCall<false, false>(art::ArtMethod*, art::Thread*, art::ShadowFrame&, art::Instruction const*, unsigned short, art::JValue*)+968)
2020-02-11 14:56:46.347 26572-26572/? A/DEBUG:     #14 pc 000000000052b784  /system/lib64/libart.so (MterpInvokeStatic+204)
2020-02-11 14:56:46.347 26572-26572/? A/DEBUG:     #15 pc 000000000054d394  /system/lib64/libart.so (ExecuteMterpImpl+14612)
2020-02-11 14:56:46.347 26572-26572/? A/DEBUG:     #16 pc 000000000019b778  /dev/ashmem/dalvik-classes.dex extracted in memory from /data/app/com.example.inpainting-40kevdvzYiOK_rsH1RbKGA==/base.apk_26388_26388 (deleted) (org.tensorflow.lite.NativeInterpreterWrapper.run+156)
2020-02-11 14:56:46.347 26572-26572/? A/DEBUG:     #17 pc 00000000002575cc  /system/lib64/libart.so (_ZN3art11interpreterL7ExecuteEPNS_6ThreadERKNS_20CodeItemDataAccessorERNS_11ShadowFrameENS_6JValueEb.llvm.3090282045+488)
2020-02-11 14:56:46.348 26572-26572/? A/DEBUG:     #18 pc 000000000025d0c0  /system/lib64/libart.so (art::interpreter::ArtInterpreterToInterpreterBridge(art::Thread*, art::CodeItemDataAccessor const&, art::ShadowFrame*, art::JValue*)+216)
2020-02-11 14:56:46.348 26572-26572/? A/DEBUG:     #19 pc 000000000027d8ac  /system/lib64/libart.so (bool art::interpreter::DoCall<false, false>(art::ArtMethod*, art::Thread*, art::ShadowFrame&, art::Instruction const*, unsigned short, art::JValue*)+940)
2020-02-11 14:56:46.348 26572-26572/? A/DEBUG:     #20 pc 000000000052a280  /system/lib64/libart.so (MterpInvokeVirtual+588)
2020-02-11 14:56:46.348 26572-26572/? A/DEBUG:     #21 pc 000000000054d214  /system/lib64/libart.so (ExecuteMterpImpl+14228)
2020-02-11 14:56:46.348 26572-26572/? A/DEBUG:     #22 pc 000000000019adee  /dev/ashmem/dalvik-classes.dex extracted in memory from /data/app/com.example.inpainting-40kevdvzYiOK_rsH1RbKGA==/base.apk_26388_26388 (deleted) (org.tensorflow.lite.Interpreter.runForMultipleInputsOutputs+10)
2020-02-11 14:56:46.348 26572-26572/? A/DEBUG:     #23 pc 00000000002575cc  /system/lib64/libart.so (_ZN3art11interpreterL7ExecuteEPNS_6ThreadERKNS_20CodeItemDataAccessorERNS_11ShadowFrameENS_6JValueEb.llvm.3090282045+488)
2020-02-11 14:56:46.348 26572-26572/? A/DEBUG:     #24 pc 000000000025d0c0  /system/lib64/libart.so (art::interpreter::ArtInterpreterToInterpreterBridge(art::Thread*, art::CodeItemDataAccessor const&, art::ShadowFrame*, art::JValue*)+216)
2020-02-11 14:56:46.348 26572-26572/? A/DEBUG:     #25 pc 000000000027d8ac  /system/lib64/libart.so (bool art::interpreter::DoCall<false, false>(art::ArtMethod*, art::Thread*, art::ShadowFrame&, art::Instruction const*, unsigned short, art::JValue*)+940)
2020-02-11 14:56:46.348 26572-26572/? A/DEBUG:     #26 pc 000000000052a280  /system/lib64/libart.so (MterpInvokeVirtual+588)
2020-02-11 14:56:46.348 26572-26572/? A/DEBUG:     #27 pc 000000000054d214  /system/lib64/libart.so (ExecuteMterpImpl+14228)
2020-02-11 14:56:46.348 26572-26572/? A/DEBUG:     #28 pc 000000000001c28c  /dev/ashmem/dalvik-classes2.dex extracted in memory from /data/app/com.example.inpainting-40kevdvzYiOK_rsH1RbKGA==/base.apk!classes2.dex_26388_26388 (deleted) (com.example.inpainting.MainActivity.onCreate+736)
2020-02-11 14:56:46.348 26572-26572/? A/DEBUG:     #29 pc 00000000002575cc  /system/lib64/libart.so (_ZN3art11interpreterL7ExecuteEPNS_6ThreadERKNS_20CodeItemDataAccessorERNS_11ShadowFrameENS_6JValueEb.llvm.3090282045+488)
2020-02-11 14:56:46.348 26572-26572/? A/DEBUG:     #30 pc 000000000025d0c0  /system/lib64/libart.so (art::interpreter::ArtInterpreterToInterpreterBridge(art::Thread*, art::CodeItemDataAccessor const&, art::ShadowFrame*, art::JValue*)+216)
2020-02-11 14:56:46.348 26572-26572/? A/DEBUG:     #31 pc 000000000027d8ac  /system/lib64/libart.so (bool art::interpreter::DoCall<false, false>(art::ArtMethod*, art::Thread*, art::ShadowFrame&, art::Instruction const*, unsigned short, art::JValue*)+940)
2020-02-11 14:56:46.348 26572-26572/? A/DEBUG:     #32 pc 000000000052a280  /system/lib64/libart.so (MterpInvokeVirtual+588)
2020-02-11 14:56:46.348 26572-26572/? A/DEBUG:     #33 pc 000000000054d214  /system/lib64/libart.so (ExecuteMterpImpl+14228)
2020-02-11 14:56:46.348 26572-26572/? A/DEBUG:     #34 pc 00000000004c641e  /system/framework/boot-framework.vdex (android.app.Activity.performCreate+24)
2020-02-11 14:56:46.348 26572-26572/? A/DEBUG:     #35 pc 00000000002575cc  /system/lib64/libart.so (_ZN3art11interpreterL7ExecuteEPNS_6ThreadERKNS_20CodeItemDataAccessorERNS_11ShadowFrameENS_6JValueEb.llvm.3090282045+488)
2020-02-11 14:56:46.348 26572-26572/? A/DEBUG:     #36 pc 000000000025d0c0  /system/lib64/libart.so (art::interpreter::ArtInterpreterToInterpreterBridge(art::Thread*, art::CodeItemDataAccessor const&, art::ShadowFrame*, art::JValue*)+216)
2020-02-11 14:56:46.348 26572-26572/? A/DEBUG:     #37 pc 000000000027d8ac  /system/lib64/libart.so (bool art::interpreter::DoCall<false, false>(art::ArtMethod*, art::Thread*, art::ShadowFrame&, art::Instruction const*, unsigned short, art::JValue*)+940)
2020-02-11 14:56:46.348 26572-26572/? A/DEBUG:     #38 pc 000000000052d2c4  /system/lib64/libart.so (MterpInvokeVirtualQuick+584)
2020-02-11 14:56:46.348 26572-26572/? A/DEBUG:     #39 pc 0000000000550f94  /system/lib64/libart.so (ExecuteMterpImpl+29972)
2020-02-11 14:56:46.349 26572-26572/? A/DEBUG:     #40 pc 00000000005eaccc  /system/framework/boot-framework.vdex (android.app.Activity.performCreate+2)
2020-02-11 14:56:46.349 26572-26572/? A/DEBUG:     #41 pc 00000000002575cc  /system/lib64/libart.so (_ZN3art11interpreterL7ExecuteEPNS_6ThreadERKNS_20CodeItemDataAccessorERNS_11ShadowFrameENS_6JValueEb.llvm.3090282045+488)
2020-02-11 14:56:46.349 26572-26572/? A/DEBUG:     #42 pc 000000000025d0c0  /system/lib64/libart.so (art::interpreter::ArtInterpreterToInterpreterBridge(art::Thread*, art::CodeItemDataAccessor const&, art::ShadowFrame*, art::JValue*)+216)
2020-02-11 14:56:46.349 26572-26572/? A/DEBUG:     #43 pc 000000000027d8ac  /system/lib64/libart.so (bool art::interpreter::DoCall<false, false>(art::ArtMethod*, art::Thread*, art::ShadowFrame&, art::Instruction const*, unsigned short, art::JValue*)+940)
2020-02-11 14:56:46.349 26572-26572/? A/DEBUG:     #44 pc 000000000052a280  /system/lib64/libart.so (MterpInvokeVirtual+588)
2020-02-11 14:56:46.349 26572-26572/? A/DEBUG:     #45 pc 000000000054d214  /system/lib64/libart.so (ExecuteMterpImpl+14228)
2020-02-11 14:56:46.349 26572-26572/? A/DEBUG:     #46 pc 00000000004e6948  /system/framework/boot-framework.vdex (android.app.Instrumentation.callActivityOnCreate+6)
2020-02-11 14:56:46.349 26572-26572/? A/DEBUG:     #47 pc 00000000002575cc  /system/lib64/libart.so (_ZN3art11interpreterL7ExecuteEPNS_6ThreadERKNS_20CodeItemDataAccessorERNS_11ShadowFrameENS_6JValueEb.llvm.3090282045+488)
2020-02-11 14:56:46.349 26572-26572/? A/DEBUG:     #48 pc 000000000025d0c0  /system/lib64/libart.so (art::interpreter::ArtInterpreterToInterpreterBridge(art::Thread*, art::CodeItemDataAccessor const&, art::ShadowFrame*, art::JValue*)+216)
2020-02-11 14:56:46.349 26572-26572/? A/DEBUG:     #49 pc 000000000027d8ac  /system/lib64/libart.so (bool art::interpreter::DoCall<false, false>(art::ArtMethod*, art::Thread*, art::ShadowFrame&, art::Instruction const*, unsigned short, art::JValue*)+940)
2020-02-11 14:56:46.349 26572-26572/? A/DEBUG:     #50 pc 000000000052a280  /system/lib64/libart.so (MterpInvokeVirtual+588)
2020-02-11 14:56:46.349 26572-26572/? A/DEBUG:     #51 pc 000000000054d214  /system/lib64/libart.so (ExecuteMterpImpl+14228)
2020-02-11 14:56:46.349 26572-26572/? A/DEBUG:     #52 pc 00000000004bd762  /system/framework/boot-framework.vdex (android.app.ActivityThread.performLaunchActivity+864)
2020-02-11 14:56:46.349 26572-26572/? A/DEBUG:     #53 pc 00000000002575cc  /system/lib64/libart.so (_ZN3art11interpreterL7ExecuteEPNS_6ThreadERKNS_20CodeItemDataAccessorERNS_11ShadowFrameENS_6JValueEb.llvm.3090282045+488)
2020-02-11 14:56:46.349 26572-26572/? A/DEBUG:     #54 pc 000000000025d0c0  /system/lib64/libart.so (art::interpreter::ArtInterpreterToInterpreterBridge(art::Thread*, art::CodeItemDataAccessor const&, art::ShadowFrame*, art::JValue*)+216)
2020-02-11 14:56:46.349 26572-26572/? A/DEBUG:     #55 pc 000000000027d8ac  /system/lib64/libart.so (bool art::interpreter::DoCall<false, false>(art::ArtMethod*, art::Thread*, art::ShadowFrame&, art::Instruction const*, unsigned short, art::JValue*)+940)
2020-02-11 14:56:46.349 26572-26572/? A/DEBUG:     #56 pc 000000000052b5c0  /system/lib64/libart.so (MterpInvokeDirect+296)
2020-02-11 14:56:46.349 26572-26572/? A/DEBUG:     #57 pc 000000000054d314  /system/lib64/libart.so (ExecuteMterpImpl+14484)
2020-02-11 14:56:46.349 26572-26572/? A/DEBUG:     #58 pc 00000000004bd37a  /system/framework/boot-framework.vdex (android.app.ActivityThread.handleLaunchActivity+72)
2020-02-11 14:56:46.349 26572-26572/? A/DEBUG:     #59 pc 00000000002575cc  /system/lib64/libart.so (_ZN3art11interpreterL7ExecuteEPNS_6ThreadERKNS_20CodeItemDataAccessorERNS_11ShadowFrameENS_6JValueEb.llvm.3090282045+488)
2020-02-11 14:56:46.349 26572-26572/? A/DEBUG:     #60 pc 000000000025d0c0  /system/lib64/libart.so (art::interpreter::ArtInterpreterToInterpreterBridge(art::Thread*, art::CodeItemDataAccessor const&, art::ShadowFrame*, art::JValue*)+216)
2020-02-11 14:56:46.349 26572-26572/? A/DEBUG:     #61 pc 000000000027d8ac  /system/lib64/libart.so (bool art::interpreter::DoCall<false, false>(art::ArtMethod*, art::Thread*, art::ShadowFrame&, art::Instruction const*, unsigned short, art::JValue*)+940)
2020-02-11 14:56:46.349 26572-26572/? A/DEBUG:     #62 pc 000000000052a280  /system/lib64/libart.so (MterpInvokeVirtual+588)
2020-02-11 14:56:46.349 26572-26572/? A/DEBUG:     #63 pc 000000000054d214  /system/lib64/libart.so (ExecuteMterpImpl+14228)
2020-02-11 14:56:46.349 26572-26572/? A/DEBUG:     #64 pc 00000000005050cc  /system/framework/boot-framework.vdex (android.app.servertransaction.LaunchActivityItem.execute+114)
2020-02-11 14:56:46.349 26572-26572/? A/DEBUG:     #65 pc 00000000002575cc  /system/lib64/libart.so (_ZN3art11interpreterL7ExecuteEPNS_6ThreadERKNS_20CodeItemDataAccessorERNS_11ShadowFrameENS_6JValueEb.llvm.3090282045+488)
2020-02-11 14:56:46.350 26572-26572/? A/DEBUG:     #66 pc 000000000025d0c0  /system/lib64/libart.so (art::interpreter::ArtInterpreterToInterpreterBridge(art::Thread*, art::CodeItemDataAccessor const&, art::ShadowFrame*, art::JValue*)+216)
2020-02-11 14:56:46.350 26572-26572/? A/DEBUG:     #67 pc 000000000027d8ac  /system/lib64/libart.so (bool art::interpreter::DoCall<false, false>(art::ArtMethod*, art::Thread*, art::ShadowFrame&, art::Instruction const*, unsigned short, art::JValue*)+940)
2020-02-11 14:56:46.350 26572-26572/? A/DEBUG:     #68 pc 000000000052a280  /system/lib64/libart.so (MterpInvokeVirtual+588)
2020-02-11 14:56:46.350 26572-26572/? A/DEBUG:     #69 pc 000000000054d214  /system/lib64/libart.so (ExecuteMterpImpl+14228)
2020-02-11 14:56:46.350 26572-26572/? A/DEBUG:     #70 pc 0000000000505d50  /system/framework/boot-framework.vdex (android.app.servertransaction.TransactionExecutor.executeCallbacks+198)
2020-02-11 14:56:46.350 26572-26572/? A/DEBUG:     #71 pc 00000000002575cc  /system/lib64/libart.so (_ZN3art11interpreterL7ExecuteEPNS_6ThreadERKNS_20CodeItemDataAccessorERNS_11ShadowFrameENS_6JValueEb.llvm.3090282045+488)
2020-02-11 14:56:46.350 26572-26572/? A/DEBUG:     #72 pc 000000000025d0c0  /system/lib64/libart.so (art::interpreter::ArtInterpreterToInterpreterBridge(art::Thread*, art::CodeItemDataAccessor const&, art::ShadowFrame*, art::JValue*)+216)
2020-02-11 14:56:46.350 26572-26572/? A/DEBUG:     #73 pc 000000000027d8ac  /system/lib64/libart.so (bool art::interpreter::DoCall<false, false>(art::ArtMethod*, art::Thread*, art::ShadowFrame&, art::Instruction const*, unsigned short, art::JValue*)+940)
2020-02-11 14:56:46.350 26572-26572/? A/DEBUG:     #74 pc 000000000052a280  /system/lib64/libart.so (MterpInvokeVirtual+588)
2020-02-11 14:56:46.350 26572-26572/? A/DEBUG:     #75 pc 000000000054d214  /system/lib64/libart.so (ExecuteMterpImpl+14228)
2020-02-11 14:56:46.350 26572-26572/? A/DEBUG:     #76 pc 0000000000505c62  /system/framework/boot-framework.vdex (android.app.servertransaction.TransactionExecutor.execute+68)
2020-02-11 14:56:46.350 26572-26572/? A/DEBUG:     #77 pc 00000000002575cc  /system/lib64/libart.so (_ZN3art11interpreterL7ExecuteEPNS_6ThreadERKNS_20CodeItemDataAccessorERNS_11ShadowFrameENS_6JValueEb.llvm.3090282045+488)
2020-02-11 14:56:46.350 26572-26572/? A/DEBUG:     #78 pc 000000000025d0c0  /system/lib64/libart.so (art::interpreter::ArtInterpreterToInterpreterBridge(art::Thread*, art::CodeItemDataAccessor const&, art::ShadowFrame*, art::JValue*)+216)
2020-02-11 14:56:46.350 26572-26572/? A/DEBUG:     #79 pc 000000000027d8ac  /system/lib64/libart.so (bool art::interpreter::DoCall<false, false>(art::ArtMethod*, art::Thread*, art::ShadowFrame&, art::Instruction const*, unsigned short, art::JValue*)+940)
2020-02-11 14:56:46.350 26572-26572/? A/DEBUG:     #80 pc 000000000052a280  /system/lib64/libart.so (MterpInvokeVirtual+588)
2020-02-11 14:56:46.350 26572-26572/? A/DEBUG:     #81 pc 000000000054d214  /system/lib64/libart.so (ExecuteMterpImpl+14228)
2020-02-11 14:56:46.350 26572-26572/? A/DEBUG:     #82 pc 00000000004bcb2c  /system/framework/boot-framework.vdex (android.app.ActivityThread$H.handleMessage+208)
2020-02-11 14:56:46.350 26572-26572/? A/DEBUG:     #83 pc 00000000002575cc  /system/lib64/libart.so (_ZN3art11interpreterL7ExecuteEPNS_6ThreadERKNS_20CodeItemDataAccessorERNS_11ShadowFrameENS_6JValueEb.llvm.3090282045+488)
2020-02-11 14:56:46.350 26572-26572/? A/DEBUG:     #84 pc 000000000025d0c0  /system/lib64/libart.so (art::interpreter::ArtInterpreterToInterpreterBridge(art::Thread*, art::CodeItemDataAccessor const&, art::ShadowFrame*, art::JValue*)+216)
2020-02-11 14:56:46.350 26572-26572/? A/DEBUG:     #85 pc 000000000027d8ac  /system/lib64/libart.so (bool art::interpreter::DoCall<false, false>(art::ArtMethod*, art::Thread*, art::ShadowFrame&, art::Instruction const*, unsigned short, art::JValue*)+940)
2020-02-11 14:56:46.350 26572-26572/? A/DEBUG:     #86 pc 000000000052a280  /system/lib64/libart.so (MterpInvokeVirtual+588)
2020-02-11 14:56:46.350 26572-26572/? A/DEBUG:     #87 pc 000000000054d214  /system/lib64/libart.so (ExecuteMterpImpl+14228)
2020-02-11 14:56:46.350 26572-26572/? A/DEBUG:     #88 pc 0000000000c637de  /system/framework/boot-framework.vdex (android.os.Handler.dispatchMessage+42)
2020-02-11 14:56:46.350 26572-26572/? A/DEBUG:     #89 pc 00000000002575cc  /system/lib64/libart.so (_ZN3art11interpreterL7ExecuteEPNS_6ThreadERKNS_20CodeItemDataAccessorERNS_11ShadowFrameENS_6JValueEb.llvm.3090282045+488)
2020-02-11 14:56:46.350 26572-26572/? A/DEBUG:     #90 pc 000000000025d0c0  /system/lib64/libart.so (art::interpreter::ArtInterpreterToInterpreterBridge(art::Thread*, art::CodeItemDataAccessor const&, art::ShadowFrame*, art::JValue*)+216)
2020-02-11 14:56:46.350 26572-26572/? A/DEBUG:     #91 pc 000000000027d8ac  /system/lib64/libart.so (bool art::interpreter::DoCall<false, false>(art::ArtMethod*, art::Thread*, art::ShadowFrame&, art::Instruction const*, unsigned short, art::JValue*)+940)
2020-02-11 14:56:46.350 26572-26572/? A/DEBUG:     #92 pc 000000000052a280  /system/lib64/libart.so (MterpInvokeVirtual+588)
2020-02-11 14:56:46.350 26572-26572/? A/DEBUG:     #93 pc 000000000054d214  /system/lib64/libart.so (ExecuteMterpImpl+14228)
2020-02-11 14:56:46.351 26572-26572/? A/DEBUG:     #94 pc 0000000000c6c452  /system/framework/boot-framework.vdex (android.os.Looper.loop+406)
2020-02-11 14:56:46.351 26572-26572/? A/DEBUG:     #95 pc 00000000002575cc  /system/lib64/libart.so (_ZN3art11interpreterL7ExecuteEPNS_6ThreadERKNS_20CodeItemDataAccessorERNS_11ShadowFrameENS_6JValueEb.llvm.3090282045+488)
2020-02-11 14:56:46.351 26572-26572/? A/DEBUG:     #96 pc 000000000025d0c0  /system/lib64/libart.so (art::interpreter::ArtInterpreterToInterpreterBridge(art::Thread*, art::CodeItemDataAccessor const&, art::ShadowFrame*, art::JValue*)+216)
2020-02-11 14:56:46.351 26572-26572/? A/DEBUG:     #97 pc 000000000027d8ac  /system/lib64/libart.so (bool art::interpreter::DoCall<false, false>(art::ArtMethod*, art::Thread*, art::ShadowFrame&, art::Instruction const*, unsigned short, art::JValue*)+940)
2020-02-11 14:56:46.351 26572-26572/? A/DEBUG:     #98 pc 000000000052b784  /system/lib64/libart.so (MterpInvokeStatic+204)
2020-02-11 14:56:46.351 26572-26572/? A/DEBUG:     #99 pc 000000000054d394  /system/lib64/libart.so (ExecuteMterpImpl+14612)
2020-02-11 14:56:46.351 26572-26572/? A/DEBUG:     #100 pc 00000000004c27b8  /system/framework/boot-framework.vdex (android.app.ActivityThread.main+220)
2020-02-11 14:56:46.351 26572-26572/? A/DEBUG:     #101 pc 00000000002575cc  /system/lib64/libart.so (_ZN3art11interpreterL7ExecuteEPNS_6ThreadERKNS_20CodeItemDataAccessorERNS_11ShadowFrameENS_6JValueEb.llvm.3090282045+488)
2020-02-11 14:56:46.351 26572-26572/? A/DEBUG:     #102 pc 000000000051ab14  /system/lib64/libart.so (artQuickToInterpreterBridge+1020)
2020-02-11 14:56:46.351 26572-26572/? A/DEBUG:     #103 pc 0000000000563cfc  /system/lib64/libart.so (art_quick_to_interpreter_bridge+92)
2020-02-11 14:56:46.351 26572-26572/? A/DEBUG:     #104 pc 000000000055ae4c  /system/lib64/libart.so (art_quick_invoke_static_stub+604)
2020-02-11 14:56:46.351 26572-26572/? A/DEBUG:     #105 pc 00000000000d04e8  /system/lib64/libart.so (art::ArtMethod::Invoke(art::Thread*, unsigned int*, unsigned int, art::JValue*, char const*)+232)
2020-02-11 14:56:46.351 26572-26572/? A/DEBUG:     #106 pc 00000000004618ac  /system/lib64/libart.so (art::(anonymous namespace)::InvokeWithArgArray(art::ScopedObjectAccessAlreadyRunnable const&, art::ArtMethod*, art::(anonymous namespace)::ArgArray*, art::JValue*, char const*)+104)
2020-02-11 14:56:46.351 26572-26572/? A/DEBUG:     #107 pc 0000000000463300  /system/lib64/libart.so (art::InvokeMethod(art::ScopedObjectAccessAlreadyRunnable const&, _jobject*, _jobject*, _jobject*, unsigned long)+1440)
2020-02-11 14:56:46.351 26572-26572/? A/DEBUG:     #108 pc 00000000003f2984  /system/lib64/libart.so (art::Method_invoke(_JNIEnv*, _jobject*, _jobject*, _jobjectArray*)+52)
2020-02-11 14:56:46.351 26572-26572/? A/DEBUG:     #109 pc 000000000011e7e4  /system/framework/arm64/boot.oat (offset 0x114000) (java.lang.Class.getDeclaredMethodInternal [DEDUPED]+180)
2020-02-11 14:56:46.351 26572-26572/? A/DEBUG:     #110 pc 000000000055ab88  /system/lib64/libart.so (art_quick_invoke_stub+584)
2020-02-11 14:56:46.351 26572-26572/? A/DEBUG:     #111 pc 00000000000d04c8  /system/lib64/libart.so (art::ArtMethod::Invoke(art::Thread*, unsigned int*, unsigned int, art::JValue*, char const*)+200)
2020-02-11 14:56:46.351 26572-26572/? A/DEBUG:     #112 pc 00000000002838c0  /system/lib64/libart.so (art::interpreter::ArtInterpreterToCompiledCodeBridge(art::Thread*, art::ArtMethod*, art::ShadowFrame*, unsigned short, art::JValue*)+344)
2020-02-11 14:56:46.351 26572-26572/? A/DEBUG:     #113 pc 000000000027d8c8  /system/lib64/libart.so (bool art::interpreter::DoCall<false, false>(art::ArtMethod*, art::Thread*, art::ShadowFrame&, art::Instruction const*, unsigned short, art::JValue*)+968)
2020-02-11 14:56:46.351 26572-26572/? A/DEBUG:     #114 pc 000000000052a280  /system/lib64/libart.so (MterpInvokeVirtual+588)
2020-02-11 14:56:46.351 26572-26572/? A/DEBUG:     #115 pc 000000000054d214  /system/lib64/libart.so (ExecuteMterpImpl+14228)
2020-02-11 14:56:46.351 26572-26572/? A/DEBUG:     #116 pc 00000000013d1462  /system/framework/boot-framework.vdex (com.android.internal.os.RuntimeInit$MethodAndArgsCaller.run+22)
2020-02-11 14:56:46.352 26572-26572/? A/DEBUG:     #117 pc 00000000002575cc  /system/lib64/libart.so (_ZN3art11interpreterL7ExecuteEPNS_6ThreadERKNS_20CodeItemDataAccessorERNS_11ShadowFrameENS_6JValueEb.llvm.3090282045+488)
2020-02-11 14:56:46.352 26572-26572/? A/DEBUG:     #118 pc 000000000051ab14  /system/lib64/libart.so (artQuickToInterpreterBridge+1020)
2020-02-11 14:56:46.352 26572-26572/? A/DEBUG:     #119 pc 0000000000563cfc  /system/lib64/libart.so (art_quick_to_interpreter_bridge+92)
2020-02-11 14:56:46.352 26572-26572/? A/DEBUG:     #120 pc 0000000000e17090  /system/framework/arm64/boot-framework.oat (offset 0x41f000) (com.android.internal.os.ZygoteInit.main+2208)
2020-02-11 14:56:46.352 26572-26572/? A/DEBUG:     #121 pc 000000000055ae4c  /system/lib64/libart.so (art_quick_invoke_static_stub+604)
2020-02-11 14:56:46.352 26572-26572/? A/DEBUG:     #122 pc 00000000000d04e8  /system/lib64/libart.so (art::ArtMethod::Invoke(art::Thread*, unsigned int*, unsigned int, art::JValue*, char const*)+232)
2020-02-11 14:56:46.352 26572-26572/? A/DEBUG:     #123 pc 00000000004618ac  /system/lib64/libart.so (art::(anonymous namespace)::InvokeWithArgArray(art::ScopedObjectAccessAlreadyRunnable const&, art::ArtMethod*, art::(anonymous namespace)::ArgArray*, art::JValue*, char const*)+104)
2020-02-11 14:56:46.352 26572-26572/? A/DEBUG:     #124 pc 000000000046150c  /system/lib64/libart.so (art::InvokeWithVarArgs(art::ScopedObjectAccessAlreadyRunnable const&, _jobject*, _jmethodID*, std::__va_list)+424)
2020-02-11 14:56:46.352 26572-26572/? A/DEBUG:     #125 pc 0000000000366214  /system/lib64/libart.so (art::JNI::CallStaticVoidMethodV(_JNIEnv*, _jclass*, _jmethodID*, std::__va_list)+652)
2020-02-11 14:56:46.352 26572-26572/? A/DEBUG:     #126 pc 00000000000b8ebc  /system/lib64/libandroid_runtime.so (_JNIEnv::CallStaticVoidMethod(_jclass*, _jmethodID*, ...)+120)
2020-02-11 14:56:46.352 26572-26572/? A/DEBUG:     #127 pc 00000000000bba78  /system/lib64/libandroid_runtime.so (android::AndroidRuntime::start(char const*, android::Vector<android::String8> const&, bool)+772)
2020-02-11 14:56:46.352 26572-26572/? A/DEBUG:     #128 pc 000000000000498c  /system/bin/app_process64 (main+1200)
2020-02-11 14:56:46.352 26572-26572/? A/DEBUG:     #129 pc 00000000000ae8f0  /system/lib64/libc.so (__libc_init+88)
```
"
36653,Results difference after converting a tensorflow op to TfLite,"**System information**
- Have I written custom code: No
- OS Platform and Distribution: MacOS 10.15
- TensorFlow version: 2.0
- Python version: 3.6.9

**Describe the current behavior**
I converted a Tensorflow model with only one Tensorflow Keras layer _tf.keras.layers.Conv2D_ to TFLite and ran the TFLite model. There was no quantization when converting the model.

**Describe the expected behavior**
The expected output of the TFLite model should be the same as the output of the Tensorflow model. However, the output of the TFLite model is slightly different from the result of the original Tensorflow model. I'm not sure whether this is a bug of TFLite framework or there was something wrong when I converted the Tensorflow model toTFLite.

**Code to reproduce the issue**
```Python
import tensorflow as tf

input = tf.keras.layers.Input(shape=(224, 224, 3), dtype='float32')
output = (filters=64, kernel_size=(7,7), strides=(2,2), padding='valid', data_format=""channels_last"", activation='linear', dilation_rate=(1,1), bias_initializer='zeros')(input)
tfmodel = tf.keras.Model(inputs=input, outputs=output)

x = tf.random.normal([1,224, 224, 3], dtype=tf.float32)
tf_y = tfmodel(x)

conv = tf.lite.TFLiteConverter.from_keras_model(tfmodel)
lite_bytes = conv.convert()
interp = tf.lite.Interpreter(model_content=lite_bytes)

input_index = interp.get_input_details()[0]['index']
output_index = interp.get_output_details()[0]['index']
interp.resize_tensor_input(input_index, [1, 224, 224, 3])
interp.allocate_tensors()
interp.set_tensor(input_index, x)
interp.invoke()
lite_y = interp.get_tensor(output_index)
```

**Other info / logs**
The issue is similar when the Conv2D layer is replaced with BatchNormalization layer.

"
36651,VALUE error,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below):
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

ValueError Traceback (most recent call last)
in
----> 1 classifier.fit(X_train, y_train, batch_size=10, epochs=100)

~\Anaconda3\lib\site-packages\keras\engine\training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)
950 sample_weight=sample_weight,
951 class_weight=class_weight,
--> 952 batch_size=batch_size)
953 # Prepare validation data.
954 do_validation = False

~\Anaconda3\lib\site-packages\keras\engine\training.py in _standardize_user_data(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)
787 feed_output_shapes,
788 check_batch_axis=False, # Don't enforce the batch size.
--> 789 exception_prefix='target')
790
791 # Generate sample-wise weight values given the sample_weight and

~\Anaconda3\lib\site-packages\keras\engine\training_utils.py in standardize_input_data(data, names, shapes, check_batch_axis, exception_prefix)
136 ': expected ' + names[i] + ' to have shape ' +
137 str(shape) + ' but got array with shape ' +
--> 138 str(data_shape))
139 return data
140

ValueError: Error when checking target: expected dense_3 to have shape (6,) but got array with shape (1,)


"
36650,Custom layer weights all have the same name by default,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04 
- TensorFlow installed from (source or binary): no
- TensorFlow version (use command below): 2.1
- Python version: 3.6.7
- GPU model and memory: no GPU

**Describe the current behavior**
I am writing a custom layer and stumbled upon the following error: https://github.com/tensorflow/tensorflow/issues/27688. The comment [here](https://github.com/tensorflow/tensorflow/issues/27688#issuecomment-582829374) made me realize that this was probably due to the custom layer weights I was using and realized that in my custom layer the weights all have by default the same name.
But it's not only my custom layer, if I use the code example from the [documentation](https://www.tensorflow.org/guide/keras/custom_layers_and_models#best_practice_deferring_weight_creation_until_the_shape_of_the_inputs_is_known), I also notice that the weights all have the same name (this is why I answered no to the question of whether I had written custom code, because it fails also in the code provided).

**Describe the expected behavior**

To me it's more of a bug than a documentation issue because we expect the weights to have different names by default (increasing ids I mean). However, naming the weights indeed solves the problem.

**Code to reproduce the issue**

```python
import tensorflow as tf

class Linear(tf.keras.layers.Layer):

  def __init__(self, units=32):
    super(Linear, self).__init__()
    self.units = units

  def build(self, input_shape):
    self.w = self.add_weight(shape=(input_shape[-1], self.units),
                             initializer='random_normal',
                             trainable=True)
    self.b = self.add_weight(shape=(self.units,),
                             initializer='random_normal',
                             trainable=True)

  def call(self, inputs):
    return tf.matmul(inputs, self.w) + self.b

l = Linear(32)
l.build((128,))
print([w.name for w in l.weights])
```

**Other info / logs**
The code above gives:

```
['Variable:0', 'Variable:0']
```

This causes a problem when saving the model for example with the  `ModelCheckpoint` callback.
"
36649,IndexError: list index out of range when using tf.dataset and keras for autoencoder,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10, anaconda, python 3.7.6
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): tensorflow 2.0.0 (using tensorflow gpu)
- Python version:3.7.6
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: cudnn -7.6.5 /  cuda - 10.0
- GPU model and memory: GeForce GTX 1050Ti, 4Gb of memory (anaconda sees 2996MB)

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
unknown 2.0.0
**Describe the current behavior**
I'm trying to build an autoencoder using tensorflow keras using a sample of png files.   I've built a pipeline using the tensor flow dataset following closely to the tutorial provided here - https://www.tensorflow.org/guide/data#decoding_image_data_and_resizing_it .   I can see a tensor properly generated with the expected batch and shape.   The model also summarizes and compiles successfully, but when I do a model.fit to begin training, I get an error: IndexError: list index out of range. (full stack track below).  


**Describe the expected behavior**
Model should begin training.

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.
`import tensorflow as tf
PNG_ROOT = 'g:/data/video/'
data_dir = PNG_ROOT + ""*/*""
list_ds = tf.data.Dataset.list_files(data_dir)

def decode_img(img):
  # convert the compressed string to a 3D uint8 tensor
  IMG_WIDTH = 360
  IMG_HEIGHT = 360
  img = tf.io.decode_png(img, channels=3)
  img = tf.image.resize_with_crop_or_pad(img, target_height=IMG_HEIGHT, target_width=IMG_WIDTH)  
  # Use `convert_image_dtype` to convert to floats in the [0,1] range.
  img = tf.image.convert_image_dtype(img, tf.float32) 
  return img

def process_path(file_path):
  img = tf.io.read_file(file_path)
  image_tensor = decode_img(img)  
  image_tensor = tf.reshape(image_tensor,(360,360,3))
  #return img, label
  return image_tensor

batch_size = 8
labeled_ds = list_ds.map(process_path)
labeled_ds = labeled_ds.batch(batch_size)
ds_train= labeled_ds.take(1000)
ds_validate = labeled_ds.take(50)

from tensorflow.keras.models import Model
from tensorflow.keras.layers import Conv2D, Input, MaxPooling2D, UpSampling2D
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint


#Build Model
input_feature = Input(batch_shape=(8,360,360,3))

x = Conv2D(512, (3,3), activation='relu', input_shape=(8,360,360,3), padding='same')(input_feature)
x = Conv2D(256, (3,3), activation='relu', padding='same')(x)
x = MaxPooling2D(pool_size=2, padding='same')(x)
x = Conv2D(128, (3,3), activation='relu', padding='same')(x)
x = Conv2D(64, (3,3), activation='relu', padding='same')(x)
encoded = MaxPooling2D(pool_size=2, padding='same')(x)

x = Conv2D(64, (3,3), activation='relu', padding='same')(encoded)
x = Conv2D(128, (3,3), activation='relu', padding='same')(x)
x = UpSampling2D((2))(x)
x = Conv2D(256, (3,3), activation='relu', padding='same')(x)
x = Conv2D(512, (3,3), activation='relu', padding='same')(x)
x = UpSampling2D((2))(x)
decoded = Conv2D(3, (3,3), activation='sigmoid', padding='same')(x)

autoencoder = Model(inputs=input_feature, outputs=decoded)
optimizer = tf.keras.optimizers.Adam()
autoencoder.compile(optimizer='adam', loss=tf.keras.losses.MeanSquaredError(), metrics=['accuracy'])
autoencoder.summary()

checkpoint = ModelCheckpoint(""best_conv2d_png_v1.hdf5"", monitor=""val_loss"", verbose = 1, save_best_only=True, mode='auto', save_freq=100)
history = autoencoder.fit(ds_train, epochs=5, callbacks=[checkpoint])
`

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

Epoch 1/5
      1/Unknown - 0s 143ms/step
---------------------------------------------------------------------------
IndexError                                Traceback (most recent call last)
<ipython-input-150-e74e2479945a> in <module>
      1 #early_stopping = EarlyStopping(monitor='loss', min_delta=0, patience=10, verbose=5, mode='auto')
      2 checkpoint = ModelCheckpoint(""best_conv2d_video_v1.hdf5"", monitor=""val_loss"", verbose = 1, save_best_only=True, mode='auto', save_freq=100)
----> 3 history = autoencoder.fit(ds_train, epochs=5, callbacks=[checkpoint])

Z:\anaconda\envs\tf-gpu\lib\site-packages\tensorflow_core\python\keras\engine\training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)
    726         max_queue_size=max_queue_size,
    727         workers=workers,
--> 728         use_multiprocessing=use_multiprocessing)
    729 
    730   def evaluate(self,

Z:\anaconda\envs\tf-gpu\lib\site-packages\tensorflow_core\python\keras\engine\training_v2.py in fit(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)
    322                 mode=ModeKeys.TRAIN,
    323                 training_context=training_context,
--> 324                 total_epochs=epochs)
    325             cbks.make_logs(model, epoch_logs, training_result, ModeKeys.TRAIN)
    326 

Z:\anaconda\envs\tf-gpu\lib\site-packages\tensorflow_core\python\keras\engine\training_v2.py in run_one_epoch(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)
    121         step=step, mode=mode, size=current_batch_size) as batch_logs:
    122       try:
--> 123         batch_outs = execution_function(iterator)
    124       except (StopIteration, errors.OutOfRangeError):
    125         # TODO(kaftan): File bug about tf function and errors.OutOfRangeError?

Z:\anaconda\envs\tf-gpu\lib\site-packages\tensorflow_core\python\keras\engine\training_v2_utils.py in execution_function(input_fn)
     84     # `numpy` translates Tensors to values in Eager mode.
     85     return nest.map_structure(_non_none_constant_value,
---> 86                               distributed_function(input_fn))
     87 
     88   return execution_function

Z:\anaconda\envs\tf-gpu\lib\site-packages\tensorflow_core\python\eager\def_function.py in __call__(self, *args, **kwds)
    455 
    456     tracing_count = self._get_tracing_count()
--> 457     result = self._call(*args, **kwds)
    458     if tracing_count == self._get_tracing_count():
    459       self._call_counter.called_without_tracing()

Z:\anaconda\envs\tf-gpu\lib\site-packages\tensorflow_core\python\eager\def_function.py in _call(self, *args, **kwds)
    501       # This is the first call of __call__, so we have to initialize.
    502       initializer_map = object_identity.ObjectIdentityDictionary()
--> 503       self._initialize(args, kwds, add_initializers_to=initializer_map)
    504     finally:
    505       # At this point we know that the initialization is complete (or less

Z:\anaconda\envs\tf-gpu\lib\site-packages\tensorflow_core\python\eager\def_function.py in _initialize(self, args, kwds, add_initializers_to)
    406     self._concrete_stateful_fn = (
    407         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access
--> 408             *args, **kwds))
    409 
    410     def invalid_creator_scope(*unused_args, **unused_kwds):

Z:\anaconda\envs\tf-gpu\lib\site-packages\tensorflow_core\python\eager\function.py in _get_concrete_function_internal_garbage_collected(self, *args, **kwargs)
   1846     if self.input_signature:
   1847       args, kwargs = None, None
-> 1848     graph_function, _, _ = self._maybe_define_function(args, kwargs)
   1849     return graph_function
   1850 

Z:\anaconda\envs\tf-gpu\lib\site-packages\tensorflow_core\python\eager\function.py in _maybe_define_function(self, args, kwargs)
   2148         graph_function = self._function_cache.primary.get(cache_key, None)
   2149         if graph_function is None:
-> 2150           graph_function = self._create_graph_function(args, kwargs)
   2151           self._function_cache.primary[cache_key] = graph_function
   2152         return graph_function, args, kwargs

Z:\anaconda\envs\tf-gpu\lib\site-packages\tensorflow_core\python\eager\function.py in _create_graph_function(self, args, kwargs, override_flat_arg_shapes)
   2039             arg_names=arg_names,
   2040             override_flat_arg_shapes=override_flat_arg_shapes,
-> 2041             capture_by_value=self._capture_by_value),
   2042         self._function_attributes,
   2043         # Tell the ConcreteFunction to clean up its graph once it goes out of

Z:\anaconda\envs\tf-gpu\lib\site-packages\tensorflow_core\python\framework\func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)
    913                                           converted_func)
    914 
--> 915       func_outputs = python_func(*func_args, **func_kwargs)
    916 
    917       # invariant: `func_outputs` contains only Tensors, CompositeTensors,

Z:\anaconda\envs\tf-gpu\lib\site-packages\tensorflow_core\python\eager\def_function.py in wrapped_fn(*args, **kwds)
    356         # __wrapped__ allows AutoGraph to swap in a converted function. We give
    357         # the function a weak reference to itself to avoid a reference cycle.
--> 358         return weak_wrapped_fn().__wrapped__(*args, **kwds)
    359     weak_wrapped_fn = weakref.ref(wrapped_fn)
    360 

Z:\anaconda\envs\tf-gpu\lib\site-packages\tensorflow_core\python\keras\engine\training_v2_utils.py in distributed_function(input_iterator)
     71     strategy = distribution_strategy_context.get_strategy()
     72     outputs = strategy.experimental_run_v2(
---> 73         per_replica_function, args=(model, x, y, sample_weights))
     74     # Out of PerReplica outputs reduce or pick values to return.
     75     all_outputs = dist_utils.unwrap_output_dict(

Z:\anaconda\envs\tf-gpu\lib\site-packages\tensorflow_core\python\distribute\distribute_lib.py in experimental_run_v2(self, fn, args, kwargs)
    758       fn = autograph.tf_convert(fn, ag_ctx.control_status_ctx(),
    759                                 convert_by_default=False)
--> 760       return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)
    761 
    762   def reduce(self, reduce_op, value, axis):

Z:\anaconda\envs\tf-gpu\lib\site-packages\tensorflow_core\python\distribute\distribute_lib.py in call_for_each_replica(self, fn, args, kwargs)
   1785       kwargs = {}
   1786     with self._container_strategy().scope():
-> 1787       return self._call_for_each_replica(fn, args, kwargs)
   1788 
   1789   def _call_for_each_replica(self, fn, args, kwargs):

Z:\anaconda\envs\tf-gpu\lib\site-packages\tensorflow_core\python\distribute\distribute_lib.py in _call_for_each_replica(self, fn, args, kwargs)
   2130         self._container_strategy(),
   2131         replica_id_in_sync_group=constant_op.constant(0, dtypes.int32)):
-> 2132       return fn(*args, **kwargs)
   2133 
   2134   def _reduce_to(self, reduce_op, value, destinations):

Z:\anaconda\envs\tf-gpu\lib\site-packages\tensorflow_core\python\autograph\impl\api.py in wrapper(*args, **kwargs)
    290   def wrapper(*args, **kwargs):
    291     with ag_ctx.ControlStatusCtx(status=ag_ctx.Status.DISABLED):
--> 292       return func(*args, **kwargs)
    293 
    294   if inspect.isfunction(func) or inspect.ismethod(func):

Z:\anaconda\envs\tf-gpu\lib\site-packages\tensorflow_core\python\keras\engine\training_v2_utils.py in train_on_batch(model, x, y, sample_weight, class_weight, reset_metrics)
    262       y,
    263       sample_weights=sample_weights,
--> 264       output_loss_metrics=model._output_loss_metrics)
    265 
    266   if reset_metrics:

Z:\anaconda\envs\tf-gpu\lib\site-packages\tensorflow_core\python\keras\engine\training_eager.py in train_on_batch(model, inputs, targets, sample_weights, output_loss_metrics)
    309           sample_weights=sample_weights,
    310           training=True,
--> 311           output_loss_metrics=output_loss_metrics))
    312   if not isinstance(outs, list):
    313     outs = [outs]

Z:\anaconda\envs\tf-gpu\lib\site-packages\tensorflow_core\python\keras\engine\training_eager.py in _process_single_batch(model, inputs, targets, output_loss_metrics, sample_weights, training)
    250               output_loss_metrics=output_loss_metrics,
    251               sample_weights=sample_weights,
--> 252               training=training))
    253       if total_loss is None:
    254         raise ValueError('The model cannot be run '

Z:\anaconda\envs\tf-gpu\lib\site-packages\tensorflow_core\python\keras\engine\training_eager.py in _model_loss(model, inputs, targets, output_loss_metrics, sample_weights, training)
    164 
    165         if hasattr(loss_fn, 'reduction'):
--> 166           per_sample_losses = loss_fn.call(targets[i], outs[i])
    167           weighted_losses = losses_utils.compute_weighted_loss(
    168               per_sample_losses,

IndexError: list index out of `range`
"
36648,`tf.global_variables_initializer()` doesn't work sometimes,"- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- TensorFlow version: 1.14.0
- Python version: 3.8

`tf.global_variables_initializer()` doesn't work sometimes.

```
import tensorflow as tf
init = tf.global_variables_initializer()
a = tf.Variable([1,2,3])
with tf.Session() as s:
    s.run(init)
    s.run(a)
```

The above code throws an error of uninitialized variable.

```
tensorflow.python.framework.errors_impl.FailedPreconditionError: Attempting to use uninitialized value Variable
	 [[{{node _retval_Variable_0_0}}]]
```

While the below code works fine:

```
a = tf.Variable([1,2,3])
with tf.Session() as s:
    s.run(tf.global_variables_initializer())
    s.run(a)
```

Output:
`array([1, 2, 3], dtype=int32)`
"
36646,keras.callbacks.Tensorboard cannot reduce loss and produces error,"**System information**
- Have I written custom code: Yes
- OS Platform and Distribution: Windows 10
- TensorFlow installed from: binary
- TensorFlow version: 1.15.0
- Python version: 3.6.8
- CUDA/cuDNN version: No GPU

**Describe the current behavior**
When using keras.callbacks.Tensorboard as a callback for fitting a keras model, this error is raised:

`ValueError: can only convert an array of size 1 to a Python scalar`

**Code to reproduce the issue**
```
import tensorflow.keras as keras
import numpy as np

model = keras.Sequential()
model.add(keras.Input(shape=(), batch_size=5))
model.add(keras.layers.Activation('sigmoid'))
model.compile(loss=keras.losses.BinaryCrossentropy())
xs = np.random.normal(size=200)
ys = np.random.randint(0, 2, 200)
cb = keras.callbacks.TensorBoard('tmp')
model.fit(xs, ys, callbacks=[cb], batch_size=5)
```
The code above produces error. If TF 2.0 is used, OR if batch_size=1, the error is gone.
"
36645,Tensorflow lite NnApiDelegate crashes on Pixel 3a XL,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
Android
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Arch Linux
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
Pixel 3A XL running on Android 10
- TensorFlow installed from (source or binary):
binary
- TensorFlow version (use command below):
2.1.0
- Python version:
3.7.0


You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
Run tensorflow lite and specify the intepreter options with NnApiDelegete()
```
            val opts = Interpreter.Options()
            opts.setNumThreads(NUM_LITE_THREADS)
            opts.addDelegate(NnApiDelegate())
            return@use Interpreter(modelBuffer, opts)
```
**Describe the expected behavior**
The code runs fine on emulator

**Code to reproduce the issue**
Add NnApiDelegete and the code crashes on Pixel 3a XL

**Other info / logs**
```
020-02-10 21:38:54.173 18949-18999/org.liberty.android.nlplib_demo E/ExecutionBuilder: ANeuralNetworksExecution_setInputFromMemory: Setting with operand type that is not fully specified
    
    --------- beginning of crash
2020-02-10 21:38:54.182 18949-18949/org.liberty.android.nlplib_demo E/AndroidRuntime: FATAL EXCEPTION: main
    Process: org.liberty.android.nlplib_demo, PID: 18949
    java.lang.IllegalArgumentException: Internal error: Failed to run on the given Interpreter: NN API returned error ANEURALNETWORKS_BAD_DATA at line 3126 while associating NNAPI execution input with a memory object.
    
    Node number 2428 (TfLiteNnapiDelegate) failed to invoke.
    
        at org.tensorflow.lite.NativeInterpreterWrapper.run(Native Method)
        at org.tensorflow.lite.NativeInterpreterWrapper.run(NativeInterpreterWrapper.java:154)
        at org.tensorflow.lite.Interpreter.runForMultipleInputsOutputs(Interpreter.java:311)
        at org.liberty.android.nlplib.gpt2.GPT2Client$generate$1.invokeSuspend(GPT2Client.kt:70)
        at org.liberty.android.nlplib.gpt2.GPT2Client$generate$1.invoke(Unknown Source:10)
        at kotlinx.coroutines.flow.SafeFlow.collect(Builders.kt:53)
        at org.liberty.android.nlplib_demo.MainActivity$onCreate$4$1$1.invokeSuspend(MainActivity.kt:65)
        at kotlin.coroutines.jvm.internal.BaseContinuationImpl.resumeWith(ContinuationImpl.kt:33)
        at kotlinx.coroutines.DispatchedTask.run(Dispatched.kt:241)
        at kotlinx.coroutines.scheduling.CoroutineScheduler.runSafely(CoroutineScheduler.kt:594)
        at kotlinx.coroutines.scheduling.CoroutineScheduler.access$runSafely(CoroutineScheduler.kt:60)
        at kotlinx.coroutines.scheduling.CoroutineScheduler$Worker.run(CoroutineScheduler.kt:740)
```"
36644,"Node has inputs from different frames ('while_context', K.rnn)","I need a simple counter in LSTMCell's `call()`; how can this be accomplished? My attempts below.

<hr>

**Minimal example w/ approach 1**: I'm using TF 1.14.0 in Graph mode. Add the following to [`LSTMCell`](https://github.com/tensorflow/tensorflow/blob/r1.14/tensorflow/python/keras/layers/recurrent.py#L2027):

```python
# in call()
self.add_update(self.step.assign_add(1))

# in __init__()
self._step = None

@property
def step(self):
    """"""Variable. The current layer time step.""""""
    if self._step is None:
        self._step = self.add_weight(
            ""step"",
            shape=[],
            dtype=dtypes.int64,
            trainable=False,
            aggregation=tf_variables.VariableAggregation.ONLY_FIRST_REPLICA)
    return self._step
```

**Approach 2**:
```python
# instead of self._step and @property def step, add below to __init__
self.step = K.variable(0, dtype='int64', name='step')
```

<hr>

**Error traces**:

```python
## APPROACH 1
File ""C:\dev_rbn\main.py"", line 42, in <module>
  model.train_on_batch(x, y)
File ""D:\Anaconda\envs\s4_env\lib\site-packages\tensorflow\python\keras\engine\training.py"", line 1175, in train_on_batch
  outputs = self.train_function(ins)  # pylint: disable=not-callable
File ""D:\Anaconda\envs\s4_env\lib\site-packages\tensorflow\python\keras\backend.py"", line 3289, in __call__
  self._make_callable(feed_arrays, feed_symbols, symbol_vals, session)
File ""D:\Anaconda\envs\s4_env\lib\site-packages\tensorflow\python\keras\backend.py"", line 3222, in _make_callable
  callable_fn = session._make_callable_from_options(callable_opts)
File ""D:\Anaconda\envs\s4_env\lib\site-packages\tensorflow\python\client\session.py"", line 1489, in _make_callable_from_options
  return BaseSession._Callable(self, callable_options)
File ""D:\Anaconda\envs\s4_env\lib\site-packages\tensorflow\python\client\session.py"", line 1446, in __init__
  session._session, options_ptr)

InvalidArgumentError: {{node training_1/group_deps}} has inputs from different frames. 
The input {{node lstm/while/AssignAddVariableOp}} is in frame 'lstm/while/while_context'. 
The input {{node Adam/Adam/AssignAddVariableOp}} is in frame ''.
```
```python
## APPROACH 2
File ""C:\dev_rbn\main.py"", line 42, in <module>
  model.train_on_batch(x, y)
File ""D:\Anaconda\envs\s4_env\lib\site-packages\tensorflow\python\keras\engine\training.py"", line 1174, in train_on_batch
  self._make_train_function()
File ""D:\Anaconda\envs\s4_env\lib\site-packages\tensorflow\python\keras\engine\training.py"", line 2219, in _make_train_function
  params=self._collected_trainable_weights, loss=self.total_loss)
File ""D:\Anaconda\envs\s4_env\lib\site-packages\tensorflow\python\keras\optimizer_v2\optimizer_v2.py"", line 492, in get_updates
  grads = self.get_gradients(loss, params)
File ""D:\Anaconda\envs\s4_env\lib\site-packages\tensorflow\python\keras\optimizer_v2\optimizer_v2.py"", line 399, in get_gradients
  ""K.argmax, K.round, K.eval."".format(param))
  
ValueError: Variable <tf.Variable 'step:0' shape=() dtype=int64> has `None` for gradient. 
Please make sure that all of your ops have a gradient defined (i.e. are differentiable). 
Common ops without gradient: K.argmax, K.round, K.eval.
```

<hr>

**Observations**:
 
 - `self.add_update(self.step.assign_add(1))` inserted right [after `K.rnn`](https://github.com/tensorflow/tensorflow/blob/r1.14/tensorflow/python/keras/layers/recurrent.py#L749) in `RNN` does work w/ approach 1, but `self.step` must be accessible _during_ `K.rnn`'s [`control_flow_ops.while_loop()`](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/backend.py#L4236), and be incremented by `1` at each loop iteration

<hr>

**Note**: I'm aware of workarounds via re-implementations of `RNN` or `K.rnn`, but that's too 'intrusive'; a simple op like this shouldn't require a dedicated base class and backend function."
36643,Error Thrown When Decoration Used: Suggests Using Decoration,"- I am going through the DeepDream tutorial for Tensorflow 2.0 located here:
https://www.tensorflow.org/tutorials/generative/deepdream

- OS Platform and Distribution: Clear Linux OS, VERSION_ID=32270
- TensorFlow installed from (source or binary): clear linux machine-learning-tensorflow bundle
- TensorFlow version (use command below): 2.0.0
- Python version: 3.8.1
- CPU model and memory: Intel(R) Xeon(R) Gold 6136 CPU @ 3.00GHz

**Describe the current behavior**

This works:

```
class DeepDream(tf.Module):
  def __init__(self, model):
    self.model = model

# !!!!! NOTICE THAT THESE LINES ARE COMMENTED OUT !!!!!
# :
#   @tf.function(
#       input_signature=(
#         tf.TensorSpec(shape=[None,None,3], dtype=tf.float32),
#         tf.TensorSpec(shape=[], dtype=tf.int32),
#         tf.TensorSpec(shape=[], dtype=tf.float32),)
#   )
  def __call__(self, img, steps, step_size):
      print(""Tracing"")
      loss = tf.constant(0.0)
      for n in tf.range(steps):
        with tf.GradientTape() as tape:
          # This needs gradients relative to `img`
          # `GradientTape` only watches `tf.Variable`s by default
          tape.watch(img)
          loss = calc_loss(img, self.model)

        # Calculate the gradient of the loss with respect to the pixels of the input image.
        gradients = tape.gradient(loss, img)

        # Normalize the gradients.
        gradients /= tf.math.reduce_std(gradients) + 1e-8 

        # In gradient ascent, the ""loss"" is maximized so that the input image increasingly ""excites"" the layers.
        # You can update the image by directly adding the gradients (because they're the same shape!)
        img = img + gradients*step_size
        img = tf.clip_by_value(img, -1, 1)

      return loss, img
```

This (as is given in the tutorial) does not:

```
class DeepDream(tf.Module):
  def __init__(self, model):
    self.model = model

  @tf.function(
      input_signature=(
        tf.TensorSpec(shape=[None,None,3], dtype=tf.float32),
        tf.TensorSpec(shape=[], dtype=tf.int32),
        tf.TensorSpec(shape=[], dtype=tf.float32),)
  )
  def __call__(self, img, steps, step_size):
      print(""Tracing"")
      loss = tf.constant(0.0)
      for n in tf.range(steps):
        with tf.GradientTape() as tape:
          # This needs gradients relative to `img`
          # `GradientTape` only watches `tf.Variable`s by default
          tape.watch(img)
          loss = calc_loss(img, self.model)

        # Calculate the gradient of the loss with respect to the pixels of the input image.
        gradients = tape.gradient(loss, img)

        # Normalize the gradients.
        gradients /= tf.math.reduce_std(gradients) + 1e-8 

        # In gradient ascent, the ""loss"" is maximized so that the input image increasingly ""excites"" the layers.
        # You can update the image by directly adding the gradients (because they're the same shape!)
        img = img + gradients*step_size
        img = tf.clip_by_value(img, -1, 1)

      return loss, img
```
I've put the error that's thrown in the sections below.  

**Describe the expected behavior**

I would expect it to work with the decoration tag and (perhaps) not work with the decoration tag commented out. However when I run it with the decoration it throws an error that seems to suggest adding the decoration that appears to already be there, and when I comment out the decoration tag it works.  When I use the decoration tag the final error is:

`OperatorNotAllowedInGraphError: iterating over `tf.Tensor` is not allowed: AutoGraph did not convert this function. Try decorating it directly with @tf.function.`

(more detailed log below)

However when I remove the decoration by commenting it out, that is when it works.

NOTE:  I have Tensorflow 2.0.0 setup on google collab as well with python 3.6.9 and it does not display the same behavior.  It works either with or without the decoration.

All of this was installed on a fresh Clear Linux install tonight with no tinkering.  I had another installation earlier where I tried a fix seen elsewhere which included downgrading gast to 0.2.2.  I did that and that did not work.

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.

```
# [CURRENT DEEP DREAM TUTORIAL AT: https://www.tensorflow.org/tutorials/generative/deepdream

def run_deep_dream_simple(img, steps=100, step_size=0.01):
  # Convert from uint8 to the range expected by the model.
  img = tf.keras.applications.inception_v3.preprocess_input(img)
  img = tf.convert_to_tensor(img)
  step_size = tf.convert_to_tensor(step_size)
  steps_remaining = steps
  step = 0
  while steps_remaining:
    if steps_remaining>100:
      run_steps = tf.constant(100)
    else:
      run_steps = tf.constant(steps_remaining)
    steps_remaining -= run_steps
    step += run_steps

    loss, img = deepdream(img, run_steps, tf.constant(step_size))
    
    display.clear_output(wait=True)
    show(deprocess(img))
    print (""Step {}, loss {}"".format(step, loss))


  result = deprocess(img)
  display.clear_output(wait=True)
  show(result)

  return result
```
```
from datetime import datetime
startTime = datetime.now()

dream_img = run_deep_dream_simple(img=original_img, 
                                  steps=100, step_size=0.01)

print(datetime.now() - startTime)
```

**Other info / logs**

```
WARNING:tensorflow:Entity <bound method DeepDream.__call__ of <tensorflow.python.eager.function.TfMethodTarget object at 0x7faea2d46d30>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: invalid value for ""node"": expected ""ast.AST"", got ""<class 'NoneType'>""; to visit lists of nodes, use ""visit_block"" instead
WARNING: Entity <bound method DeepDream.__call__ of <tensorflow.python.eager.function.TfMethodTarget object at 0x7faea2d46d30>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: invalid value for ""node"": expected ""ast.AST"", got ""<class 'NoneType'>""; to visit lists of nodes, use ""visit_block"" instead
Tracing
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
/usr/lib/python3.8/site-packages/tensorflow_core/python/autograph/impl/api.py in converted_call(f, options, args, kwargs, caller_fn_scope)
    505         options=options, autograph_module=tf_inspect.getmodule(converted_call))
--> 506     converted_f = conversion.convert(target_entity, program_ctx)
    507 

/usr/lib/python3.8/site-packages/tensorflow_core/python/autograph/impl/conversion.py in convert(entity, program_ctx)
    320 
--> 321   converted_entity_info = _convert_with_cache(entity, program_ctx,
    322                                               free_nonglobal_var_names)

/usr/lib/python3.8/site-packages/tensorflow_core/python/autograph/impl/conversion.py in _convert_with_cache(entity, program_ctx, free_nonglobal_var_names)
    238 
--> 239     nodes, converted_name, entity_info = convert_entity_to_ast(
    240         entity, program_ctx)

/usr/lib/python3.8/site-packages/tensorflow_core/python/autograph/impl/conversion.py in convert_entity_to_ast(o, program_ctx)
    470   elif tf_inspect.ismethod(o):
--> 471     nodes, name, entity_info = convert_func_to_ast(o, program_ctx)
    472   elif hasattr(o, '__class__'):

/usr/lib/python3.8/site-packages/tensorflow_core/python/autograph/impl/conversion.py in convert_func_to_ast(f, program_ctx, do_rename)
    668   context = converter.EntityContext(namer, entity_info, program_ctx, new_name)
--> 669   node = node_to_graph(node, context)
    670 

/usr/lib/python3.8/site-packages/tensorflow_core/python/autograph/impl/conversion.py in node_to_graph(node, context)
    697 
--> 698   node = converter.standard_analysis(node, context, is_initial=True)
    699   node = converter.apply_(node, context, function_scopes)

/usr/lib/python3.8/site-packages/tensorflow_core/python/autograph/core/converter.py in standard_analysis(node, context, is_initial)
    383   node = qual_names.resolve(node)
--> 384   node = activity.resolve(node, context, None)
    385   node = reaching_definitions.resolve(node, context, graphs, AnnotatedDef)

/usr/lib/python3.8/site-packages/tensorflow_core/python/autograph/pyct/static_analysis/activity.py in resolve(node, context, parent_scope)
    497 def resolve(node, context, parent_scope=None):
--> 498   return ActivityAnalyzer(context, parent_scope).visit(node)

/usr/lib/python3.8/site-packages/tensorflow_core/python/autograph/pyct/transformer.py in visit(self, node)
    479     if not anno.hasanno(node, anno.Basic.SKIP_PROCESSING):
--> 480       result = super(Base, self).visit(node)
    481     self.ctx.current_origin = parent_origin

/usr/lib/python3.8/ast.py in visit(self, node)
    359         visitor = getattr(self, method, self.generic_visit)
--> 360         return visitor(node)
    361 

/usr/lib/python3.8/site-packages/tensorflow_core/python/autograph/pyct/static_analysis/activity.py in visit_FunctionDef(self, node)
    441     self._enter_scope(False)
--> 442     node.body = self.visit_block(node.body)
    443     anno.setanno(node, NodeAnno.BODY_SCOPE, self.scope)

/usr/lib/python3.8/site-packages/tensorflow_core/python/autograph/pyct/transformer.py in visit_block(self, nodes, before_visit, after_visit)
    370 
--> 371       replacement = self.visit(node)
    372 

/usr/lib/python3.8/site-packages/tensorflow_core/python/autograph/pyct/transformer.py in visit(self, node)
    479     if not anno.hasanno(node, anno.Basic.SKIP_PROCESSING):
--> 480       result = super(Base, self).visit(node)
    481     self.ctx.current_origin = parent_origin

/usr/lib/python3.8/ast.py in visit(self, node)
    359         visitor = getattr(self, method, self.generic_visit)
--> 360         return visitor(node)
    361 

/usr/lib/python3.8/site-packages/tensorflow_core/python/autograph/pyct/static_analysis/activity.py in visit_Expr(self, node)
    265   def visit_Expr(self, node):
--> 266     return self._process_statement(node)
    267 

/usr/lib/python3.8/site-packages/tensorflow_core/python/autograph/pyct/static_analysis/activity.py in _process_statement(self, node)
    259     self._enter_scope(False)
--> 260     node = self.generic_visit(node)
    261     anno.setanno(node, anno.Static.SCOPE, self.scope)

/usr/lib/python3.8/ast.py in generic_visit(self, node)
    444             elif isinstance(old_value, AST):
--> 445                 new_node = self.visit(old_value)
    446                 if new_node is None:

/usr/lib/python3.8/site-packages/tensorflow_core/python/autograph/pyct/transformer.py in visit(self, node)
    479     if not anno.hasanno(node, anno.Basic.SKIP_PROCESSING):
--> 480       result = super(Base, self).visit(node)
    481     self.ctx.current_origin = parent_origin

/usr/lib/python3.8/ast.py in visit(self, node)
    359         visitor = getattr(self, method, self.generic_visit)
--> 360         return visitor(node)
    361 

/usr/lib/python3.8/site-packages/tensorflow_core/python/autograph/pyct/static_analysis/activity.py in visit_Call(self, node)
    327     self._enter_scope(False)
--> 328     node.args = self.visit_block(node.args)
    329     node.keywords = self.visit_block(node.keywords)

/usr/lib/python3.8/site-packages/tensorflow_core/python/autograph/pyct/transformer.py in visit_block(self, nodes, before_visit, after_visit)
    370 
--> 371       replacement = self.visit(node)
    372 

/usr/lib/python3.8/site-packages/tensorflow_core/python/autograph/pyct/transformer.py in visit(self, node)
    457                  type(node))
--> 458       raise ValueError(msg)
    459 

ValueError: invalid value for ""node"": expected ""ast.AST"", got ""<class 'NoneType'>""; to visit lists of nodes, use ""visit_block"" instead

During handling of the above exception, another exception occurred:

OperatorNotAllowedInGraphError            Traceback (most recent call last)
<ipython-input-9-43912bcedaa9> in <module>
      2 startTime = datetime.now()
      3 
----> 4 dream_img = run_deep_dream_simple(img=original_img, 
      5                                   steps=100, step_size=0.01)
      6 

<ipython-input-8-193f882b4182> in run_deep_dream_simple(img, steps, step_size)
     14     step += run_steps
     15 
---> 16     loss, img = deepdream(img, run_steps, tf.constant(step_size))
     17 
     18     display.clear_output(wait=True)

/usr/lib/python3.8/site-packages/tensorflow_core/python/eager/def_function.py in __call__(self, *args, **kwds)
    455 
    456     tracing_count = self._get_tracing_count()
--> 457     result = self._call(*args, **kwds)
    458     if tracing_count == self._get_tracing_count():
    459       self._call_counter.called_without_tracing()

/usr/lib/python3.8/site-packages/tensorflow_core/python/eager/def_function.py in _call(self, *args, **kwds)
    501       # This is the first call of __call__, so we have to initialize.
    502       initializer_map = object_identity.ObjectIdentityDictionary()
--> 503       self._initialize(args, kwds, add_initializers_to=initializer_map)
    504     finally:
    505       # At this point we know that the initialization is complete (or less

/usr/lib/python3.8/site-packages/tensorflow_core/python/eager/def_function.py in _initialize(self, args, kwds, add_initializers_to)
    405     self._graph_deleter = FunctionDeleter(self._lifted_initializer_graph)
    406     self._concrete_stateful_fn = (
--> 407         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access
    408             *args, **kwds))
    409 

/usr/lib/python3.8/site-packages/tensorflow_core/python/eager/function.py in _get_concrete_function_internal_garbage_collected(self, *args, **kwargs)
   1846     if self.input_signature:
   1847       args, kwargs = None, None
-> 1848     graph_function, _, _ = self._maybe_define_function(args, kwargs)
   1849     return graph_function
   1850 

/usr/lib/python3.8/site-packages/tensorflow_core/python/eager/function.py in _maybe_define_function(self, args, kwargs)
   2148         graph_function = self._function_cache.primary.get(cache_key, None)
   2149         if graph_function is None:
-> 2150           graph_function = self._create_graph_function(args, kwargs)
   2151           self._function_cache.primary[cache_key] = graph_function
   2152         return graph_function, args, kwargs

/usr/lib/python3.8/site-packages/tensorflow_core/python/eager/function.py in _create_graph_function(self, args, kwargs, override_flat_arg_shapes)
   2029     arg_names = base_arg_names + missing_arg_names
   2030     graph_function = ConcreteFunction(
-> 2031         func_graph_module.func_graph_from_py_func(
   2032             self._name,
   2033             self._python_function,

/usr/lib/python3.8/site-packages/tensorflow_core/python/framework/func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)
    913                                           converted_func)
    914 
--> 915       func_outputs = python_func(*func_args, **func_kwargs)
    916 
    917       # invariant: `func_outputs` contains only Tensors, CompositeTensors,

/usr/lib/python3.8/site-packages/tensorflow_core/python/eager/def_function.py in wrapped_fn(*args, **kwds)
    356         # __wrapped__ allows AutoGraph to swap in a converted function. We give
    357         # the function a weak reference to itself to avoid a reference cycle.
--> 358         return weak_wrapped_fn().__wrapped__(*args, **kwds)
    359     weak_wrapped_fn = weakref.ref(wrapped_fn)
    360 

/usr/lib/python3.8/site-packages/tensorflow_core/python/eager/function.py in bound_method_wrapper(*args, **kwargs)
   2656     # However, the replacer is still responsible for attaching self properly.
   2657     # TODO(mdan): Is it possible to do it here instead?
-> 2658     return wrapped_fn(*args, **kwargs)
   2659   weak_bound_method_wrapper = weakref.ref(bound_method_wrapper)
   2660 

/usr/lib/python3.8/site-packages/tensorflow_core/python/framework/func_graph.py in wrapper(*args, **kwargs)
    894           # TODO(mdan): Push this block higher in tf.function's call stack.
    895           try:
--> 896             return autograph.converted_call(
    897                 original_func,
    898                 autograph.ConversionOptions(

/usr/lib/python3.8/site-packages/tensorflow_core/python/autograph/impl/api.py in converted_call(f, options, args, kwargs, caller_fn_scope)
    532         ' the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and'
    533         ' attach the full output. Cause: %s', target_entity, e)
--> 534     return _call_unconverted(f, args, kwargs, options)
    535 
    536   with StackTraceMapper(converted_f), tf_stack.CurrentModuleFilter():

/usr/lib/python3.8/site-packages/tensorflow_core/python/autograph/impl/api.py in _call_unconverted(f, args, kwargs, options, update_cache)
    324 
    325   if inspect_utils.istfmethodtarget(f):
--> 326     return f.__self__.call(args, kwargs)
    327 
    328   try:

/usr/lib/python3.8/site-packages/tensorflow_core/python/eager/function.py in call(self, args, kwargs)
   2618     if tf_inspect.ismethod(wrapped_fn):
   2619       wrapped_fn = six.get_unbound_function(wrapped_fn)
-> 2620     return wrapped_fn(self.weakrefself_target__(), *args, **kwargs)
   2621 
   2622 

<ipython-input-6-3ac13775042b> in __call__(self, img, steps, step_size)
     12       print(""Tracing"")
     13       loss = tf.constant(0.0)
---> 14       for n in tf.range(steps):
     15         with tf.GradientTape() as tape:
     16           # This needs gradients relative to `img`

/usr/lib/python3.8/site-packages/tensorflow_core/python/framework/ops.py in __iter__(self)
    545   def __iter__(self):
    546     if not context.executing_eagerly():
--> 547       self._disallow_iteration()
    548 
    549     shape = self._shape_tuple()

/usr/lib/python3.8/site-packages/tensorflow_core/python/framework/ops.py in _disallow_iteration(self)
    538       self._disallow_when_autograph_disabled(""iterating over `tf.Tensor`"")
    539     elif ag_ctx.control_status_ctx().status == ag_ctx.Status.ENABLED:
--> 540       self._disallow_when_autograph_enabled(""iterating over `tf.Tensor`"")
    541     else:
    542       # Default: V1-style Graph execution.

/usr/lib/python3.8/site-packages/tensorflow_core/python/framework/ops.py in _disallow_when_autograph_enabled(self, task)
    514 
    515   def _disallow_when_autograph_enabled(self, task):
--> 516     raise errors.OperatorNotAllowedInGraphError(
    517         ""{} is not allowed: AutoGraph did not convert this function. Try""
    518         "" decorating it directly with @tf.function."".format(task))

OperatorNotAllowedInGraphError: iterating over `tf.Tensor` is not allowed: AutoGraph did not convert this function. Try decorating it directly with @tf.function.
```

Thank you!
"
36642,Throw an error when connecting inputs to weight-shared-embedding-layer more than 5 times.,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Google Colaboratory with Ubuntu 18.04.3 LTS (Bionic Beaver)
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): v2.1.0-0-ge5bf8de410 2.1.0
- Python version: 3.6.9
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

When inputs are connected to weight-shared-embedding-layer more than 5 times, tensorflow throws an error while training.

This behavior is not seen with below condition.
- connections to weight-shared-embedding-layer are less than 4
- using tensorflow version 1.15

**Describe the expected behavior**

Successfully train a model using weight-shared-embedding-layer connecting more than 5 inputs.

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.

```
import tensorflow as tf
import tensorflow.keras.backend as K
import numpy as np

# changing this to 4 make train success
n_inputs = 5
dim_embedding = 10

inputs = []
for i in range(n_inputs):
  inputs.append(tf.keras.Input(shape=(1,), dtype='int32'))

embeds = []
shared_embed = tf.keras.layers.Embedding(n_input, dim_embedding)
for i in range(n_inputs):
  embed = shared_embed(inputs[i])
  flatten = tf.keras.layers.Flatten()(embed)
  embeds.append(flatten)

concat = tf.keras.layers.Concatenate(axis=1)(embeds)
output = tf.keras.layers.Dense(1)(concat)
model = tf.keras.Model(inputs=[inputs], outputs=[output])
model.summary()

model.compile(optimizer='adam', loss='mse')

# run
dummy_input = []
for i in range(n_shared_layers):
  dummy_input.append(np.random.randint(0, n_input, size=(1000, )))

dummy = np.arange(1000).reshape(1000, 1, 1)

model.fit(x=dummy_input, y=dummy, batch_size=32, epochs=1, verbose=1)
```

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

https://colab.research.google.com/drive/1NV_KXlKRv148H50SExVYdHkVCh9Acnp_?hl=ja#scrollTo=13C17fSiwhAC
"
36637,expm grad can fail on TF2 when eager execution is disabled,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS 10.15.2
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): v2.1.0-rc2-17-ge5bf8de410 2.1.0
- Python version: 3.7.3

**Describe the current behavior**
Evaluating the gradient of a `tf.linalg.expm` operation can fail with the following exception when eager execution is disabled:
```
Node 'gradients_1/matrix_exponential_1/while_grad/matrix_exponential_1/while_grad': Connecting to invalid output 6 of source node matrix_exponential_1/while which has 6 outputs.
```

Calling `tf.compat.v1.experimental.output_all_intermediates(True)` at the start of the session fixes the issue.

The issue only seems to happen if the gradient op gets added after the `Session` has already evaluated something.

**Describe the expected behavior**
No exception should be thrown.

**Code to reproduce the issue**
```
import tensorflow as tf
tf.compat.v1.disable_eager_execution()
session = tf.compat.v1.Session()
x = tf.constant([[1., 0.], [0., -1.]], dtype=tf.float32)
y = tf.linalg.expm(x)
session.run(y)
session.run(tf.gradients(y, x))
```

Also see gist here: https://colab.research.google.com/drive/1N5KeUBXJAmpict_lofiREHyE1QUcSDUl"
36634,How to create new cuda stream in custom op,"I've written a custom op for the GPU that takes X with shape ```(n,p)``` and Y with shape ```(m,p)``` and returns Z with shape ```(n,m)```. 

In the backward pass, dX and dY are independent computations so I'd like to have launch two separate CUDA kernels and have them run in separate streams. I know the cuDNN RNN is capable of doing kernels in parallel but I cannot find the source code for how to do this. It seems the only usable stream is provided by the OpKernelContext. 

Matrix multiplication must have a similar parallelism when doing the backward pass but I have not found anywhere in the source making use of multiple streams. This is essentially a reopening of [this issue](https://github.com/tensorflow/tensorflow/issues/6675) as there doesn't appear to a public answer
"
36632,Able to disable auto-insert quantize de-quantize node to quantized model.,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- TensorFlow installed from (source or binary): binary
- TensorFlow version (or github SHA if from source): 1.15.2, 2.1.0


TFLiteConverter will automatically insert quantize and dequantize node to quantized model, so that input and output of the quantized model are float32. (check the code, and model example graph below)

```python
import tensorflow as tf
import numpy as np

def gen_calibration_dataset():
    for _ in range(10):
        yield [np.random.rand(1,2,2,2).astype(np.float32)]

def get_keras_model_conv():
    input_0 = tf.keras.layers.Input(shape=[2, 2, 2])
    conv_0 = tf.keras.layers.Conv2D(filters=2, kernel_size=(2, 2),
                                    activation=tf.nn.relu)(input_0)
    model = tf.keras.models.Model(inputs=[input_0], outputs=[conv_0])
    model.summary()
    return model

def gen_model():

    keras_model = get_keras_model_conv()
    converter = tf.lite.TFLiteConverter.from_keras_model(keras_model)
    converter.optimizations = [tf.lite.Optimize.DEFAULT]
    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]
    converter.representative_dataset = gen_calibration_dataset
    tflite_quant_model = converter.convert()
    open('test.tflite', 'wb').write(tflite_quant_model)

print(""TF version: {}"".format(tf.__version__))
gen_model()
```

![image](https://user-images.githubusercontent.com/55463253/74179096-ac3e5d00-4c34-11ea-8f92-6eb1015a1f16.png)

Is there any convenient way (through python api) to force the model input,output remain int8 (not auto insert quantize, dequantize node)? I didn't find official doc about this.
If not, is it reasonable to add such feature to TFLiteConverter?"
36629,Support deeplab v3 model on dsp delegate,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): 1.15
- Are you willing to contribute it (Yes/No):

**Describe the feature and the current behavior/state.**
As tflite can support deeplabv3 on GPU with good performance as shown in:
https://www.tensorflow.org/lite/models/segmentation/overview

But when ran the deeplab v3 model on dsp delegate, found it's very slow and the logs showed the upsupported ops on dsp delegate. @karimnosseir , do you think it's possible to fully support deeplab v3 on dsp delegate:
Model file: https://github.com/tensorflow/tensorflow/files/4182220/deep_lab_v3_mv2.tflite.zip
Converted and quantized from http://download.tensorflow.org/models/deeplabv3_mnv2_dm05_pascal_trainaug_2018_10_01.tar.gz

Here are the logs:
INFO: Initialized TensorFlow Lite runtime.
INFO: Created TensorFlow Lite delegate for Hexagon.
INFO: Hexagon delegate: unsupported node index: 25.

INFO: Hexagon delegate: unsupported node index: 27.

INFO: Hexagon delegate: unsupported node index: 33.

INFO: Hexagon delegate: unsupported node index: 35.

INFO: Hexagon delegate: 32 nodes delegated out of 111 nodes.

INFO: Replacing 32 node(s) with delegate (TfLiteHexagonDelegate) node.


**Will this change the current api? How?** No.

**Who will benefit with this feature?** Developer who is using deeplab v3.

**Any Other info.**
"
36627,GPU memory not released until Java process terminates,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
No

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Ubuntu 18.04.4 LTS, Kernel 4.15.0-76-generic

- TensorFlow installed from (source or binary):
Binary

- TensorFlow version (use command below):
1.15.0

- Python version:
Python 3.6.9

- CUDA/cuDNN version:
10.0.130

- GPU model and memory:
GeForce GTX 1080 Ti, 11177MiB

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
After closing all Tensors, Graphs and Sessions in our Java programm, the Java process still holds the previously used GPU memory until the Java process terminates.

**Describe the expected behavior**
After closing all Tensors, Graphs and Sessions, the Java process should release all allocated GPU memory.

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.

```java
package de.tensorflowtest;

import static org.apache.commons.io.IOUtils.toByteArray;
import java.io.Console;
import java.io.IOException;
import java.io.InputStream;
import org.tensorflow.Graph;
import org.tensorflow.Session;
import org.tensorflow.framework.ConfigProto;
import de.tensorflowtest.Constants;

public class GpuLeakDebug {
    public static void main(String[] args) throws IOException, InterruptedException {

        waitWithMessage(""Create Session"");

        Session session = null;
        Graph graph = null;
        ConfigProto sessionConfig;
        try {
            byte[] graphdef = null;
            try (InputStream graphStream = Constants.class.getResourceAsStream(""/tensorflow/inception_v3.pb"")) {
                graphdef = toByteArray(graphStream);
            } catch (IOException e) {
                System.exit(1);
            }
            graph = new Graph();
            graph.importGraphDef(graphdef);
            sessionConfig = ConfigProto.newBuilder().build();
            session = new Session(graph, sessionConfig.toByteArray());

        } catch (UnsatisfiedLinkError e) {

            throw e;
        } finally {
            waitWithMessage(""Close Session"");
            session.close();
            graph.close();
        }
        session = null;
        graph = null;
        sessionConfig = null;

        waitWithMessage(""Terminate"");
    }

    private static void waitWithMessage(String message, Object... args) {
        Console c = System.console();
        if (c != null) {
            // printf-like arguments
            if (message != null)
                c.format(message, args);
            c.format("" Press ENTER to proceed.\n"");
            c.readLine();
        }
    }
}
```

**Other info / logs**
This is the output of `nvidia-smi` **before the session is created** (""Create Session"") and **after the JVM terminates** (""Terminate"").
```
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 430.50       Driver Version: 430.50       CUDA Version: 10.1     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  GeForce GTX 108...  Off  | 00000000:03:00.0 Off |                  N/A |
| 25%   57C    P5    30W / 250W |      0MiB / 11177MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
```
This is the output of `nvidia-smi` **after the session has been created** and **after the session has been closed**.
```
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 430.50       Driver Version: 430.50       CUDA Version: 10.1     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  GeForce GTX 108...  Off  | 00000000:03:00.0 Off |                  N/A |
| 19%   53C    P5    24W / 250W |    145MiB / 11177MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|    0     20221      C   /usr/bin/java                                135MiB |
+-----------------------------------------------------------------------------+
```


"
36626,Dataset.shuffle leads to worse training performance due to chunked processing,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Mint
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.1.0
- Python version: 3.7.4

**Describe the current behavior**

Dataset.shuffle is (essentially) described as buffering N elements, then choosing 1 out of those N to return. Hence the input data is processed in chunks. In the extreme consider a shuffle buffer of size 2: In the first epoch only the first 2 elements can be returned. And the following code (using the 3rd and 4th element) produces only values of 0-4:

```
dataset = tf.data.Dataset.range(10)
dataset = dataset.shuffle(2)
for _ in range(20):
    print(list(dataset.as_numpy_iterator())[2:4])
```

For good training performance (as in accuracy reaches high values fast) a complete shuffling of the dataset is required. This becomes obvious if one considers (accidentally or purposely) order sets of training data (in the MNIST example: First all zeros, then all ones, etc). There will be many batches mostly or completely consisting of only 1 label value. This does not work well with SGD approaches.

Some statistics on MNIST (validation after 10 epochs by shuffle buffer size):
```
  100: Eval loss: 0.29262512158124876, accuracy: 0.9161659
 1000: Eval loss: 0.2921471730925334,  accuracy: 0.9165665
10000: Eval loss: 0.2914975070131895,  accuracy: 0.9171675
60000: Eval loss: 0.29154436285488117, accuracy: 0.91696715
```
As you can see the accuracy increases with the buffer size with everything else constant.

**Describe the expected behavior**

The whole dataset should be shuffled. This requires the concept of random access datasets. I believe the TFRecord format supports random access(?) So the shuffle operation can take random data from the whole dataset.

**Code to reproduce the issue**
```
import tensorflow_datasets as tfds
import tensorflow as tf
tfds.disable_progress_bar()


def make_datasets_unbatched():
    # Scaling MNIST data from (0, 255] to (0., 1.]
    def scale(image, label):
        image = tf.cast(image, tf.float32)
        image /= 255
        return image, label

    datasets, info = tfds.load(name='mnist',
                               with_info=True,
                               as_supervised=True)

    return {key: ds.map(scale).cache()
            for key, ds in datasets.items()}, info.splits


def build_and_compile_cnn_model():
    model = tf.keras.Sequential([
        tf.keras.layers.Conv2D(32,
                               3,
                               activation='relu',
                               input_shape=(28, 28, 1)),
        tf.keras.layers.MaxPooling2D(),
        tf.keras.layers.Flatten(),
        tf.keras.layers.Dense(64, activation='relu'),
        tf.keras.layers.Dense(10, activation='softmax')
    ])
    model.compile(loss=tf.keras.losses.sparse_categorical_crossentropy,
                  optimizer=tf.keras.optimizers.SGD(learning_rate=0.001),
                  metrics=['accuracy'])
    return model


datasets, infos = make_datasets_unbatched()
model = build_and_compile_cnn_model()
# Init
model.train_on_batch(datasets['train'].batch(64))
WEIGHTS_PATH = './init-weights'
model.save_weights(WEIGHTS_PATH)

for buffer_size in (100, 1000, 5000, 10000, 60000):
    print(""Buffer size: %s"" % buffer_size)
    model.load_weights(WEIGHTS_PATH)

    model.fit(x=datasets['train'].shuffle(buffer_size).batch(64).repeat(),
              epochs=10,
              steps_per_epoch=infos['train'].num_examples // 64)
    eval_loss, eval_acc = model.evaluate(datasets['test'].batch(64),
                                         steps=infos['test'].num_examples //
                                         64)
    print(""Eval loss: %s, accuracy: %s"" % (eval_loss, eval_acc))
```

"
36624,LSTM return_state=True fail with tf.keras.Sequencial model,"- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS 10.13.6
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): v2.1.0-rc2-17-ge5bf8de410 2.1.0
- Python version: v3.6.7:6ec5cf24b7, Oct 20 2018, 03:02:14

**Describe the current behavior**

The `call` method of a `tf.keras.Sequential` object fails and throws an error when one layer is an instance of the `tf.keras.layers.LSTM` class constructed with `return_state=True`. Given the error message, I believe it is because the output of the `call` method of such `LSTM` layer is a `list` instead of a `Tensor`, and the `call` method of `Sequential` does not know what to do with a `list`.

**Describe the expected behavior**

I think that the `call` method of `Sequential` should know that the `Tensor` output of `LSTM` is the first element of the `list` when `return_state=True`.

**Code to reproduce the issue**
Setting : 
```
import tensorflow as tf
import numpy as np

print('Using Tensorflow version {} (git version {})'.format(tf.version.VERSION, tf.version.GIT_VERSION))

batch_size = 3
ts = 9
input_dim = 2
nump = np.arange(examples*batch_size*ts*input_dim, dtype=np.float32).reshape(batch_size, ts, input_dim)
dataset = tf.data.Dataset.from_tensor_slices(nump).batch(batch_size)
for x in dataset:
    print(x.shape)
return_state = True
```
Output:
```
Using Tensorflow version 2.1.0 (git version v2.1.0-rc2-17-ge5bf8de410)
(3, 9, 2)
```

Error with `Sequential`:
```
model_seq = tf.keras.Sequential([tf.keras.layers.LSTM(3, return_state=return_state)])
for x in dataset:
    print(model_seq(x))
```
Output:
```
---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
<ipython-input-57-5500870ab2fc> in <module>
      1 model_seq = tf.keras.Sequential([tf.keras.layers.LSTM(3, return_state=return_state)])
      2 for x in dataset:
----> 3     print(model_seq(x))

~/path/to/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py in __call__(self, inputs, *args, **kwargs)
    820           with base_layer_utils.autocast_context_manager(
    821               self._compute_dtype):
--> 822             outputs = self.call(cast_inputs, *args, **kwargs)
    823           self._handle_activity_regularization(inputs, outputs)
    824           self._set_mask_metadata(inputs, outputs, input_masks)

~/path/to/python3.6/site-packages/tensorflow_core/python/keras/engine/sequential.py in call(self, inputs, training, mask)
    283       # `outputs` will be the inputs to the next layer.
    284       inputs = outputs
--> 285       mask = outputs._keras_mask
    286 
    287     return outputs

AttributeError: 'list' object has no attribute '_keras_mask'
```

It works when constructing the model with the Functional API:
```
def lstm_model(return_state, ts, input_dim):
    inp = tf.keras.Input(shape=(ts, input_dim))
    out = tf.keras.layers.LSTM(3, return_state=return_state)(inp)
    return tf.keras.Model(inputs=inp, outputs=out)
    
model_func = lstm_model(return_state, ts, input_dim)

for x in dataset:
    print(model_func(x))
```
Output:
```
[<tf.Tensor: shape=(3, 3), dtype=float32, numpy=
array([[-8.8475537e-01,  2.9517543e-03, -9.9753261e-01],
       [-9.7553629e-01,  9.5521700e-06, -9.9959475e-01],
       [-9.9497062e-01,  3.0903845e-08, -9.9979442e-01]], dtype=float32)>, <tf.Tensor: shape=(3, 3), dtype=float32, numpy=
array([[-8.8475537e-01,  2.9517543e-03, -9.9753261e-01],
       [-9.7553629e-01,  9.5521700e-06, -9.9959475e-01],
       [-9.9497062e-01,  3.0903845e-08, -9.9979442e-01]], dtype=float32)>, <tf.Tensor: shape=(3, 3), dtype=float32, numpy=
array([[-7.6066346e+00,  2.9581292e-03, -3.3488092e+00],
       [-8.9999275e+00,  9.5521846e-06, -4.2520967e+00],
       [-9.0000000e+00,  3.0903848e-08, -4.5915442e+00]], dtype=float32)>]
```

**Related question**
In my Functional API example, `lstm_model`fails if I use `inp = tf.keras.Input(shape=(ts, None))` instead of providing the explicit input dimension. The error message I get is:
```
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
<ipython-input-64-9b042ffca48d> in <module>
      4     return tf.keras.Model(inputs=inp, outputs=out)
      5 
----> 6 model_func = lstm_model(return_state, ts, input_dim)
      7 
      8 for x in dataset:

<ipython-input-64-9b042ffca48d> in lstm_model(return_state, ts, input_dim)
      1 def lstm_model(return_state, ts, input_dim):
      2     inp = tf.keras.Input(shape=(ts, None))
----> 3     out = tf.keras.layers.LSTM(3, return_state=return_state)(inp)
      4     return tf.keras.Model(inputs=inp, outputs=out)
      5 

~/path/to/python3.6/site-packages/tensorflow_core/python/keras/layers/recurrent.py in __call__(self, inputs, initial_state, constants, **kwargs)
    642 
    643     if initial_state is None and constants is None:
--> 644       return super(RNN, self).__call__(inputs, **kwargs)
    645 
    646     # If any of `initial_state` or `constants` are specified and are Keras

~/path/to/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py in __call__(self, inputs, *args, **kwargs)
    746           # Build layer if applicable (if the `build` method has been
    747           # overridden).
--> 748           self._maybe_build(inputs)
    749           cast_inputs = self._maybe_cast_inputs(inputs)
    750 

~/path/to/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py in _maybe_build(self, inputs)
   2114         # operations.
   2115         with tf_utils.maybe_init_scope(self):
-> 2116           self.build(input_shapes)
   2117       # We must set self.built since user defined build functions are not
   2118       # constrained to set self.built.

~/path/to/python3.6/site-packages/tensorflow_core/python/keras/layers/recurrent.py in build(self, input_shape)
    562     if isinstance(self.cell, Layer):
    563       if not self.cell.built:
--> 564         self.cell.build(step_input_shape)
    565 
    566     # set or validate state_spec

~/path/to/python3.6/site-packages/tensorflow_core/python/keras/utils/tf_utils.py in wrapper(instance, input_shape)
    304     if input_shape is not None:
    305       input_shape = convert_shapes(input_shape, to_tuples=True)
--> 306     output_shape = fn(instance, input_shape)
    307     # Return shapes from `fn` as TensorShapes.
    308     if output_shape is not None:

~/path/to/python3.6/site-packages/tensorflow_core/python/keras/layers/recurrent.py in build(self, input_shape)
   2299         regularizer=self.kernel_regularizer,
   2300         constraint=self.kernel_constraint,
-> 2301         caching_device=default_caching_device)
   2302     self.recurrent_kernel = self.add_weight(
   2303         shape=(self.units, self.units * 4),

~/path/to/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py in add_weight(self, name, shape, dtype, initializer, regularizer, trainable, constraint, partitioner, use_resource, synchronization, aggregation, **kwargs)
    444         synchronization=synchronization,
    445         aggregation=aggregation,
--> 446         caching_device=caching_device)
    447     backend.track_variable(variable)
    448 

~/path/to/python3.6/site-packages/tensorflow_core/python/training/tracking/base.py in _add_variable_with_custom_getter(self, name, shape, dtype, initializer, getter, overwrite, **kwargs_for_getter)
    742         dtype=dtype,
    743         initializer=initializer,
--> 744         **kwargs_for_getter)
    745 
    746     # If we set an initializer and the variable processed it, tracking will not

~/path/to/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer_utils.py in make_variable(name, shape, dtype, initializer, trainable, caching_device, validate_shape, constraint, use_resource, collections, synchronization, aggregation, partitioner)
    140       synchronization=synchronization,
    141       aggregation=aggregation,
--> 142       shape=variable_shape if variable_shape else None)
    143 
    144 

~/path/to/python3.6/site-packages/tensorflow_core/python/ops/variables.py in __call__(cls, *args, **kwargs)
    256   def __call__(cls, *args, **kwargs):
    257     if cls is VariableV1:
--> 258       return cls._variable_v1_call(*args, **kwargs)
    259     elif cls is Variable:
    260       return cls._variable_v2_call(*args, **kwargs)

~/path/to/python3.6/site-packages/tensorflow_core/python/ops/variables.py in _variable_v1_call(cls, initial_value, trainable, collections, validate_shape, caching_device, name, variable_def, dtype, expected_shape, import_scope, constraint, use_resource, synchronization, aggregation, shape)
    217         synchronization=synchronization,
    218         aggregation=aggregation,
--> 219         shape=shape)
    220 
    221   def _variable_v2_call(cls,

~/path/to/python3.6/site-packages/tensorflow_core/python/ops/variables.py in <lambda>(**kwargs)
    195                         shape=None):
    196     """"""Call on Variable class. Useful to force the signature.""""""
--> 197     previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)
    198     for _, getter in ops.get_default_graph()._variable_creator_stack:  # pylint: disable=protected-access
    199       previous_getter = _make_getter(getter, previous_getter)

~/path/to/python3.6/site-packages/tensorflow_core/python/ops/variable_scope.py in default_variable_creator(next_creator, **kwargs)
   2594         synchronization=synchronization,
   2595         aggregation=aggregation,
-> 2596         shape=shape)
   2597   else:
   2598     return variables.RefVariable(

~/path/to/python3.6/site-packages/tensorflow_core/python/ops/variables.py in __call__(cls, *args, **kwargs)
    260       return cls._variable_v2_call(*args, **kwargs)
    261     else:
--> 262       return super(VariableMetaclass, cls).__call__(*args, **kwargs)
    263 
    264 

~/path/to/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py in __init__(self, initial_value, trainable, collections, validate_shape, caching_device, name, dtype, variable_def, import_scope, constraint, distribute_strategy, synchronization, aggregation, shape)
   1409           aggregation=aggregation,
   1410           shape=shape,
-> 1411           distribute_strategy=distribute_strategy)
   1412 
   1413   def _init_from_args(self,

~/path/to/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py in _init_from_args(self, initial_value, trainable, collections, caching_device, name, dtype, constraint, synchronization, aggregation, distribute_strategy, shape)
   1540           with ops.name_scope(""Initializer""), device_context_manager(None):
   1541             initial_value = ops.convert_to_tensor(
-> 1542                 initial_value() if init_from_fn else initial_value,
   1543                 name=""initial_value"", dtype=dtype)
   1544           if shape is not None:

~/path/to/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer_utils.py in <lambda>()
    120           (type(init_ops.Initializer), type(init_ops_v2.Initializer))):
    121         initializer = initializer()
--> 122       init_val = lambda: initializer(shape, dtype=dtype)
    123       variable_dtype = dtype.base_dtype
    124   if use_resource is None:

~/path/to/python3.6/site-packages/tensorflow_core/python/ops/init_ops_v2.py in __call__(self, shape, dtype)
    413       scale /= max(1., fan_out)
    414     else:
--> 415       scale /= max(1., (fan_in + fan_out) / 2.)
    416     if self.distribution == ""truncated_normal"":
    417       # constant from scipy.stats.truncnorm.std(a=-2, b=2, loc=0., scale=1.)

TypeError: unsupported operand type(s) for +: 'NoneType' and 'int'
```
Is it normal? If so, why is that?
"
36623,Unimplemented: Cast string to float is not supported,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 1909
- TensorFlow version (use command below): 2.1.0-gpu-version
- Python version: 3.6.9
- CUDA/cuDNN version: 10.1.243/7.6.5
- GPU model and memory: GTX 1660 ti 6GB and 32GB (available 28GB)

**Describe the current behavior**
I am working on nlp-getting-started compitetion from kaggle and written code but when executing I'm getting this issue and it doesn't seems to go furthuer or it is not even showing error and exiting it is just showing this and waiting...
Here is the snap of the error
![1](https://user-images.githubusercontent.com/44919399/74157450-4eaf0e00-4c3e-11ea-8a26-7ea1947a5d5b.jpg)

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.

import re
import nltk
import numpy as np
import pandas as pd
from tensorflow.keras.models import Sequential
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.layers import Embedding, LSTM, Dense
from tensorflow.keras.preprocessing.sequence import pad_sequences

vocab_size = 10000
batch_size = 32
epochs = 4
max_len = 25

train_df = pd.read_csv('train.csv')
test_df = pd.read_csv('test.csv')

def clean_text(text):
    text = re.sub(r'https?://\S+|www\.\S+', '', text)
    text = re.sub(r'[^a-zA-Z]', ' ', text)
    text = text.lower()
    text = text.split()
    text = [word for word in text if not word in set(nltk.corpus.stopwords.words('english'))]
    text = ' '.join(text)
    return text

train_df['text'] = train_df['text'].apply(lambda x: clean_text(x))
x_train, y_train = train_df.iloc[:, 3].values, train_df.iloc[:, 4].values

tokenizer = Tokenizer(num_words=vocab_size)

tokenizer.fit_on_texts(x_train)
sequences = tokenizer.texts_to_sequences(x_train)
x_train_new = pad_sequences(sequences, maxlen=max_len)

model = Sequential()
model.add(Embedding(vocab_size, 128))
model.add(LSTM(128, dropout=0.2))
model.add(Dense(32, activation='relu'))
model.add(Dense(1, activation='sigmoid'))

model.compile(loss='binary_crossentropy', optimizer = 'RMSprop', metrics=['accuracy'])

model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose = 1)

And also when I press ctrl+c then it gets this message
![2](https://user-images.githubusercontent.com/44919399/74158187-a13cfa00-4c3f-11ea-810b-694e53158c47.jpg)

Thanks in advance. Please help me find the error and correct it.
"
36622,tensorflow-gpu 2.0.0 error | Non-OK-status: GpuLaunchKernel | status: Internal: invalid device function,"```Using TensorFlow backend.
2020-02-10 18:56:03.997155: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_100.dll<br>
2020-02-10 18:56:06.902771: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library nvcuda.dll<br>
2020-02-10 18:56:07.849352: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties:<br>
name: GeForce GTX 1650 major: 7 minor: 5 memoryClockRate(GHz): 1.56
pciBusID: 0000:01:00.0<br>
2020-02-10 18:56:07.855482: I tensorflow/stream_executor/platform/default/dlopen_checker_stub.cc:25] GPU libraries are statically linked, skip dlopen check.
2020-02-10 18:56:07.860526: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0<br>
2020-02-10 18:56:07.863861: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2
2020-02-10 18:56:07.880373: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties:<br>
name: GeForce GTX 1650 major: 7 minor: 5 memoryClockRate(GHz): 1.56<br>
pciBusID: 0000:01:00.0<br>
2020-02-10 18:56:07.886459: I tensorflow/stream_executor/platform/default/dlopen_checker_stub.cc:25] GPU libraries are statically linked, skip dlopen check.
2020-02-10 18:56:07.891278: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0<br>
2020-02-10 18:56:08.001331: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:<br>
2020-02-10 18:56:08.005924: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0<br>
2020-02-10 18:56:08.008184: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N<br>
2020-02-10 18:56:08.011837: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 3023 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1650, pci bus id: 0000:01:00.0, compute capability: 7.5)<br>
2020-02-10 18:56:08.154262: F .\tensorflow/core/kernels/random_op_gpu.h:227] <b>Non-OK-status: <br>GpuLaunchKernel(FillPhiloxRandomKernelLaunch<Distribution>, num_blocks, block_size, 0, d.stream(), gen, data, size, dist) status: Internal: invalid device function</b>
```
I am getting this error while running keras LSTM code. The code is correct. <br>
Believe me I have all possible configurations to install tensorflow-gpu but it is not working.
i installed this one by: <br>
making new env<br>
`conda install -c conda-forge tensorflow-gpu` <br>

i have also tried by installing Cudnn and CUDA toolkit seperately but same thing appears. <br>
CPU : i7 9th gen<br>
GPU : GTX 1650<br>
LAPTOP : ASUS G STRIX g531GT 2019<br>

Someone please help me, i have wasted 5-10 hours trying every possible configuration."
36621,Expected int for argument 'ksizes' not tf.Tensor,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Centos 7.7
- TensorFlow installed from (source or binary): Binary
- TensorFlow version (use command below): 2.1
- Python version: 3.6


**Describe the current behavior**
tf.image.extract_patches only accepts static integers as ksize arguments in data.Dataset API pipeline.

**Describe the expected behavior**
Accept variable data dimension as size argument

**Code to reproduce the issue**
I'm trying to create sliding window feature across all rows in tensor simultaneously. Each tensor can have different number of rows.
```
image=tf.constant([[[[1], [2], [3], [4], [5], [6], [7], [8], [9], [10]],
  [[11], [12], [13], [14], [15], [16], [17], [18], [19], [20]],
  [[21], [22], [23], [24], [25], [26], [27], [28], [29], [30]],
  [[31], [32], [33], [34], [35], [36], [37], [38], [39], [40]],
  [[41], [42], [43], [44], [45], [46], [47], [48], [49], [50]],
  [[51], [52], [53], [54], [55], [56], [57], [58], [59], [60]],
  [[61], [62], [63], [64], [65], [66], [67], [68], [69], [70]],
  [[71], [72], [73], [74], [75], [76], [77], [78], [79], [80]],
  [[81], [82], [83], [84], [85], [86], [87], [88], [89], [90]],
  [[91], [92], [93], [94], [95], [96], [97], [98], [99], [100]]]])

ds=tf.data.Dataset.from_tensor_slices(image)

def create_patches(image):
    return tf.image.extract_patches(image[None,...],
                           [1, tf.shape(image)[1], 3, 1],
                           [1, 1, 1, 1],
                           [1, 1, 1, 1],
                           padding='VALID')
ds=ds.map(create_patches)

for i in ds:
    print(i)
```

**Other info / logs**
`TypeError: Expected int for argument 'ksizes' not <tf.Tensor 'strided_slice_1:0' shape=() dtype=int32>.`
"
36620,GPU performance of TensorflowLite in C++,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): b44fb933866191b94bed36a80e2b1cfd94589d6d
- Python version: 2.7
- Bazel version (if compiling from source): bazel 2.0.0
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
I'm running TFLite using C++ api through JNI wrapper on Android. Two libraries are built: `libtensorflowlite.so` and `libtensorflowlite_gpu_gl.so` for GPU delegate. It's expected that GPU inference should be faster than CPU inference, as mentioned in https://www.tensorflow.org/lite/performance/benchmarks

**Describe the expected behavior**
We found that GPU delegate has the same performance as CPU, even though invoke() returns `kTfLiteOk`
```
interpreter->Invoke() != kTfLiteOk
```

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.

```
void ImageAPI::loadModel(const std::string &model_path) {

    LOGD(""initializing Image\n"");

    model = tflite::FlatBufferModel::BuildFromFile(model_path.c_str());
    if(!model){
        LOGD(""Failed loading model\n"");
        printf(""Failed to mmap model\n"");
        exit(0);
    }

    LOGD(""DONE Image\n"");

    tflite::ops::builtin::BuiltinOpResolver resolver;
    tflite::InterpreterBuilder(*model, resolver)(&interpreter);

}

void ImageAPI::runImage(const unsigned char *rgb, unsigned char *Image) {

    if (use_gpu) {
        if (!delegate) {
            const TfLiteGpuDelegateOptions options = {
                    .metadata = NULL,
                    .compile_options = {
                            .precision_loss_allowed = 1,  // FP16
                            .preferred_gl_object_type = TFLITE_GL_OBJECT_TYPE_FASTEST
                    },
            };

            delegate = TfLiteGpuDelegateCreate(&options);
            if (interpreter->ModifyGraphWithDelegate(delegate) != kTfLiteOk) {
                exit(0);
            }
        }
    }

    interpreter->AllocateTensors();

    float *image_640 = interpreter->typed_input_tensor<float>(1);
    float *image_320 = interpreter->typed_input_tensor<float>(0);

    for (int i = 0; i < H_LARGE * W_LARGE * CHANNEL3; i++) {
        image_640[i] = rgb[i]/255.;
    }

    for (int i = 0; i < H_SMALL; i++) {
        for (int j = 0; j < W_SMALL; j++) {
            for (int c = 0; c < CHANNEL3; c++) {
                image_320[i * CHANNEL3 * W_SMALL + j * CHANNEL3 + c] = image_640[2 * i * CHANNEL3 * W_LARGE + 2 * j * CHANNEL3  + c];
            }
        }
    }

    if (interpreter->Invoke() != kTfLiteOk) return;

    float *output = interpreter->typed_output_tensor<float>(0);

    for (int i = 0; i < H_LARGE * W_LARGE * CHANNEL3; i++) {
        Image[i] = output[i]*255;
    }
}
```

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
36619,unable to save the tensorflow hub model of universal lite with tensorflow 1.15,"I'm unable to save the model, after trained my data by using hub model of universal lite 2( https://tfhub.dev/google/universal-sentence-encoder-lite/2).

tensorflow== 1.15 tensorflow_hub=0.7.0 python =3.7.6 OS = Window 10 64 bit

** model local**

path =""C:/Users/771556/Downloads/ModelLiteUSE"" #url =""https://tfhub.dev/google/universal-sentence-encoder-lite/2"" liteModule = hub.Module(path)

input_placeholder = tf.sparse_placeholder(tf.int64, shape=[None, None]) encodings = liteModule( inputs=dict( values=input_placeholder.values, indices=input_placeholder.indices, dense_shape=input_placeholder.dense_shape))

with tf.Session() as sess: spm_path = sess.run(liteModule(signature=""spm_path""))

sp = spm.SentencePieceProcessor() sp.Load(spm_path) print(""SentencePiece model loaded at {}."".format(spm_path))

def process_to_IDs_in_sparse_format(sp, sentences): ids = [sp.EncodeAsIds(x) for x in sentences] max_len = max(len(x) for x in ids) dense_shape=(len(ids), max_len) values=[item for sublist in ids for item in sublist] indices=[[row,col] for row in range(len(ids)) for col in range(len(ids[row]))] return (values, indices, dense_shape)

def embed(input): values, indices, dense_shape = process_to_IDs_in_sparse_format(sp, input) # Reduce logging output. logging.set_verbosity(logging.ERROR) with tf.Session() as session: session.run([tf.global_variables_initializer(), tf.tables_initializer()]) message_embeddings = session.run( encodings, feed_dict={input_placeholder.values: values, input_placeholder.indices: indices, input_placeholder.dense_shape: dense_shape}) return message_embeddings **Training the data**

TrainModel= embed(file_data.text)

**Saving model**

tf.saved_model.save(TrainModel,'D:/liteTrainmodel')

**Error**
![Capture](https://user-images.githubusercontent.com/16205110/74142686-67f49200-4c1f-11ea-8b2f-07720ffc0f28.JPG)
"
36618,Import issue tensorflow 2.1.0 using Windows 10 AMD Radeon processor with GPU,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): bin
- TensorFlow version: 2.1.0
- Python version: 3.5.2
- Installed using virtualenv? pip? conda?: pip
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: None
- GPU model and memory: AMD Radeon 1 GB



**Describe the problem**

Cannot import tensorflow after installation

**Provide the exact sequence of commands / steps that you executed before running into the problem**

pip install tensorflow


**Any other info / logs**
import tensorflow
Traceback (most recent call last):
  File ""C:\Users\kumar.shivam\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\kumar.shivam\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\kumar.shivam\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\kumar.shivam\AppData\Local\Programs\Python\Python35\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\kumar.shivam\AppData\Local\Programs\Python\Python35\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: The specified module could not be found.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""C:\Users\kumar.shivam\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\__init__.py"", line 101, in <module>
    from tensorflow_core import *
  File ""C:\Users\kumar.shivam\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow_core\__init__.py"", line 40, in <module>
    from tensorflow.python.tools import module_util as _module_util
  File ""C:\Users\kumar.shivam\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\__init__.py"", line 50, in __getattr__
    module = self._load()
  File ""C:\Users\kumar.shivam\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\__init__.py"", line 44, in _load
    module = _importlib.import_module(self.__name__)
  File ""C:\Users\kumar.shivam\AppData\Local\Programs\Python\Python35\lib\importlib\__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""C:\Users\kumar.shivam\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow_core\python\__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\Users\kumar.shivam\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 74, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""C:\Users\kumar.shivam\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\kumar.shivam\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\kumar.shivam\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\kumar.shivam\AppData\Local\Programs\Python\Python35\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\kumar.shivam\AppData\Local\Programs\Python\Python35\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: The specified module could not be found.


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/errors

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.


"
36616,tf.signal.inverse_stft does not reconstructs the original signal,"**System information**
- I have used an example from tf doc
- Ubuntu 18.04.4
- TensorFlow 2.1.0 installed via pip
- Python version: 3.7.3

Following the official example from inverse_stft code to reconstruct signal I got either totally different signal or when frame_step>=frame_length I got nan's every frame_step elements starting at position 0. For clarity, the lengths from the official example were divided by 10.
```
import tensorflow as tf
frame_length = 40
frame_step = 16
waveform = tf.random.normal(dtype=tf.float32, shape=[100])
stft = tf.signal.stft(waveform, frame_length, frame_step)
inverse_stft = tf.signal.inverse_stft(
    stft, frame_length, frame_step,
    window_fn=tf.signal.inverse_stft_window_fn(frame_step))
print(inverse_stft)
print(waveform)
tf.Tensor(
[ 0.00000000e+00  3.99959536e-05 -2.40500085e-04 -1.59982394e-03
  5.19763958e-03 -4.16988507e-03  2.64100209e-02 -9.08877850e-02
  3.40112969e-02  3.86196673e-01  5.13033606e-02 -2.86520272e-01
  6.11472845e-01  4.98466581e-01  1.13349378e+00  1.09166965e-01
 -9.97731745e-01 -5.43629766e-01 -2.73563933e+00  7.85581648e-01
 -8.19584429e-01  1.79670918e+00  9.02783334e-01 -1.48530865e+00
 -2.47491312e+00 -1.24023890e+00  1.15495408e+00  1.42492950e+00
 -7.37325311e-01 -1.20595813e+00 -3.62768292e-01  1.35240197e+00
 -3.68225783e-01 -7.91088283e-01  1.89298892e+00  5.07700205e-01
  6.15092158e-01 -1.92212605e+00 -8.31669629e-01  7.79488802e-01
 -3.24547052e-01 -5.50925493e-01 -7.81439543e-01  8.75341117e-01
 -6.82320118e-01  7.01450050e-01 -4.50847566e-01  6.66174769e-01
 -1.23529518e+00 -1.24680352e+00  3.43645632e-01  1.09950686e+00
  5.97586334e-01 -3.48894447e-01  6.68327957e-02 -1.43280745e+00
 -6.64948940e-01 -7.94504046e-01  1.14265656e+00 -9.80610073e-01
 -4.60786790e-01 -3.97007465e-01 -9.27713037e-01  1.07594097e+00
  5.27661502e-01 -1.61613131e+00 -2.59635901e+00 -3.46627653e-01
  3.27228665e-01 -1.07391989e+00  9.76892650e-01 -2.26863116e-01
 -1.79977849e-01 -7.51911581e-01 -1.52214825e-01 -2.73942560e-01
 -5.64359844e-01  5.01259208e-01  4.91654649e-02 -1.36436284e-01
  1.09956011e-01  7.98072666e-02 -1.27519906e-01  1.10613126e-02
 -3.04599851e-03  1.31062159e-04 -4.15140385e-05  3.23910135e-05], shape=(88,), dtype=float32)
tf.Tensor(
[ 1.4038084   1.0222757  -0.39947665 -0.54522014  0.5803976  -0.19679223
  0.61842763 -1.1810968   0.26712915  1.9677812   0.18064204 -0.73945624
  1.2229462   0.81378937  1.5831046   0.13582362 -1.1432989  -0.58895135
 -2.8576777   0.8025885  -0.8269907   1.8019977   0.9033268  -1.4853681
 -2.4749134  -1.2402394   1.1549553   1.4249299  -0.73732626 -1.205959
 -0.36276835  1.3524033  -0.36822623 -0.7910883   1.8929895   0.50770015
  0.615092   -1.922127   -0.8316696   0.77948934 -0.32454705 -0.5509257
 -0.7814399   0.87534165 -0.6823204   0.7014507  -0.45084816  0.6661754
 -1.2352954  -1.2468035   0.34364572  1.0995075   0.59758615 -0.34889427
  0.06683233 -1.4328083  -0.6649485  -0.7945043   1.1426575  -0.98061115
 -0.46078658 -0.39700815 -0.9277131   1.0759422   0.527661   -1.616195
 -2.5979242  -0.34764734  0.33018574 -1.0971678   1.0204725  -0.24577658
 -0.2062361  -0.9355164  -0.21259227 -0.44723493 -1.1287199   1.293658
  0.1731153  -0.6951827   0.8636062   1.0371045  -2.9860606   0.5220258
 -0.34013367  0.04466997 -0.06895867  0.82789123  0.43297967  0.7684806
 -0.6908023   0.57721597  0.9199321   1.3768114   1.2351048  -0.9184835
  0.5188774   0.88726586  1.4416382  -0.40344936], shape=(100,), dtype=float32)
```

```
import tensorflow as tf
frame_length = 40
frame_step = 40
waveform = tf.random.normal(dtype=tf.float32, shape=[100])
stft = tf.signal.stft(waveform, frame_length, frame_step)
inverse_stft = tf.signal.inverse_stft(
    stft, frame_length, frame_step,
    window_fn=tf.signal.inverse_stft_window_fn(frame_step))
print(inverse_stft)
print(waveform)
tf.Tensor(
[        nan -0.5289995  -0.42322898  1.7522525   0.34771994 -0.7660091
  1.6534201  -0.23190129 -0.64468837 -1.1712008  -2.6483274   1.3840579
 -1.0050658   0.87601507 -0.5170545   0.6623281  -1.0479059  -0.5475797
 -1.2517245  -1.1959579   0.58061975 -0.1989309   0.18141915 -1.7858055
 -0.7680144  -0.21199739  0.2686664   0.06079084 -0.68268234  0.9945366
  2.2236376  -0.56432855  1.281768    0.8328386  -0.6435259   0.85617316
 -0.09510866  0.7118371   2.0645704   0.63955176         nan  0.15469487
  1.0494236   0.3661145  -1.4089363  -1.3391382   1.0011977  -0.07683202
 -1.4500219  -0.0392501   1.1920362   1.8719866   0.7821921  -0.45498323
 -1.890665    0.67334163 -2.023159   -0.29750296 -0.2908026   0.38893116
 -0.10589531  0.7326803   1.2091097  -0.34784627  1.311726    0.79103297
 -0.91987884  0.51282054 -0.20457014  0.50253487 -0.46842676  2.5228522
 -0.07464705  1.7176666  -0.40536413 -0.06539667  1.0447518  -0.42340115
  0.1290549   0.53456116], shape=(80,), dtype=float32)
tf.Tensor(
[-2.005882   -0.5290042  -0.42322478  1.7522544   0.34772    -0.76600945
  1.6534219  -0.23190151 -0.64468867 -1.1712015  -2.6483283   1.3840592
 -1.0050665   0.8760156  -0.5170555   0.66232944 -1.0479063  -0.54757965
 -1.2517256  -1.1959581   0.5806202  -0.19893074  0.1814189  -1.7858069
 -0.76801383 -0.21199743  0.2686672   0.06079032 -0.6826823   0.9945371
  2.2236395  -0.56433004  1.2817682   0.8328381  -0.64352524  0.8561739
 -0.09510913  0.7118365   2.064576    0.6395979   0.7826336   0.15469465
  1.0494274   0.36611095 -1.4089363  -1.339139    1.0011992  -0.07683332
 -1.4500217  -0.03925065  1.1920377   1.8719873   0.78219193 -0.4549838
 -1.8906664   0.67334247 -2.0231593  -0.2975028  -0.2908029   0.3889313
 -0.1058953   0.7326806   1.2091101  -0.34784687  1.3117266   0.79103285
 -0.91987914  0.5128205  -0.20457047  0.5025352  -0.46842635  2.5228539
 -0.07464796  1.7176673  -0.40536594 -0.06539585  1.0447516  -0.42340097
  0.12904675  0.5345574  -0.12362233 -1.9486434   0.53776556 -0.32944998
  0.48096088 -1.0506314  -1.2964804  -0.34489468 -0.38139907  0.49959585
 -0.25842932 -0.8132113   1.0629432  -0.5591399   0.11014029 -0.4576707
 -0.15766484 -0.07155921  0.2819425   0.40777263], shape=(100,), dtype=float32)
```

"
36615,tf.saved_model.save can not save a model containing DenseHashTable,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): colab
- TensorFlow installed from (source or binary): source 
- TensorFlow version (use command below):  tf-nightly(2.2.0.dev20200208)

**Describe the current behavior**
A keras model which contains DenseHashTable cannot be saved by tf.saved_model.save function.
Got a ""RuntimeError: Attempting to capture an EagerTensor without building a function.""

**Describe the expected behavior**
Save the model correctly.

**Code to reproduce the issue**
Here is the simplest situation.
```python
import tensorflow as tf

class Model(tf.keras.Model):

  def __init__(self):
    super(Model, self).__init__()
    self.table = tf.lookup.experimental.DenseHashTable(
        key_dtype=tf.int64,
        value_dtype=tf.int64,
        default_value=-1,
        empty_key=0,
        deleted_key=-1)

  @tf.function(input_signature=[tf.TensorSpec(shape=[None], dtype=tf.int64)])
  def call(self, input):
    return self.table.lookup(input)

m = Model()
tf.saved_model.save(m, '/tmp/test')
```

[Here](https://colab.research.google.com/drive/1ENfP-3vp1c7hoRQU-0egTngatcMMYsMp) is the code gist.
"
36614,tensorflow GPU is not installed properly,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Laptop
- TensorFlow installed from (source or binary): source
- TensorFlow version: 2.1.0
- Python version:3.7.4
- Installed using virtualenv? pip? conda?: using pip
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: CUDA: 10.2 , cuDNN: 7.6.5
- GPU model and memory: GeForce GTX 1650 , 4GB GPU memory
- System Configuration: intel i7 processor, 1 TB memory, 8 GB RAM.



**Describe the problem**

**Provide the exact sequence of commands / steps that you executed before running into the problem**
Executed below code than the eror occured which is pasted in the file ""tensorflow installation error"":
""from tensorflow.examples.tutorials.mnist import input_data
mnist = input_data.read_data_sets(""MNIST_data/"", one_hot=True)""

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

[tensorflow installation error.txt](https://github.com/tensorflow/tensorflow/files/4179294/tensorflow.installation.error.txt)

"
36613,cannot resolve external symbol __imp_TF_Version,"I dowload tensorflow c libs from: https://tensorflow.google.cn/install/lang_c.
when I try to use these libs with vs2019, it turn out an error message: cannot resolve external symbol __imp_TF_Version"
36612,ReduceLROnPlateau callback crashed when learning rate is of type tf.keras.optimizers.schedules,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04
- TensorFlow installed from (source or binary): pip3
- TensorFlow version (use command below): 2.0.0
- Python version: 3.6

**Describe the current behavior**

When using tf.keras.callbacks.ReduceLROnPlateau in callbacks in model.fit(), it fails with an error if model.optimizer.lr is of type  tf.keras.optimizers.schedules. *. 

For example, one can use tf.keras.optimizers.schedules.ExponentialDecay in an optimizer. This would cause the following line to fail:

[https://github.com/tensorflow/tensorflow/blob/6dd3403a89f2f0f9a6219ba926091e203693ff9f/tensorflow/python/keras/callbacks.py#L2021](https://github.com/tensorflow/tensorflow/blob/6dd3403a89f2f0f9a6219ba926091e203693ff9f/tensorflow/python/keras/callbacks.py#L2021)

Above line assumes lr to be a float.

The error it gives in this case is :

TypeError: float() argument must be a string or a number, not 'ExponentialDecay' 


**Describe the expected behavior**

ReduceLROnPlateau should also work with learning rate whose type is of tf.keras.optimizers.schedules

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
36611,Buid failed in redhat system..,"ERROR: /root/.cache/bazel/_bazel_daixiangzi/7c0ccbbd924a8f891a09b57c04646026/external/boringssl/BUILD:130:1: C++ compilation of rule '@boringssl//:crypto' failed (Exit 1)
gcc: error trying to exec 'cc1': execvp: No such file or directory
Target //tensorflow/tools/graph_transforms:transform_graph failed to build
INFO: Elapsed time: 29.467s, Critical Path: 4.82s
INFO: 9 processes: 9 local.
FAILED: Build did NOT complete successfully
Gcc and g++ version is 4.8.5
NO CUDA"
36610,"Successfully convert model through full-integer, but leave nodes with int8 instead of uint8","<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04.3 LTS (GNU/Linux 4.15.0-55-generic x86_64)
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: would run on Raspberry Pi4 +edge TPU or Dev-board
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): v1.15.0-0-g590d6eef7e 1.15.0
- Python version: 3.7.4
- Bazel version (if compiling from source): 0.24.1
- GCC/Compiler version (if compiling from source): GCC 7.3.0
- CUDA/cuDNN version: Cuda compilation tools, release 10.1, V10.1.243
- GPU model and memory: 2080Ti
**(but TensorFlow was not compiled with CUDA support)**
You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
I convert my model from pytorch->onnx->tensorflow->tensorflow lite. And I would run on Edge TPU, thus my tensorflow version should be 1.15.0 as suggestion. However, due to lack of ""split"", and incorrect of ""min and max"". I rebuild from source based on the two links below.

[https://github.com/tensorflow/tensorflow/commit/3c2be61e68acea533030b8f70fa0db3339b19f93](url)
[https://github.com/tensorflow/tensorflow/pull/32582/files?file-filters%5B%5D=.cc&file-filters%5B%5D=.h&file-filters%5B%5D=No+extension#diff-71a783b5a7624430897d44e42f816444](url)

I use full-integer quantization, and all the conversion is successful. The tflite file works fine on interpreter. Input and Output datatype are tf.uint8 correctly. But almost every node in the model except input and output is tf.int8 (quantization).

**Describe the expected behavior**
I think these nodes should be tf.uint8. And I wonder that whether I could just load the tflite file via ""JSON"" format and change the model[""subgraphs""][0][""tensors""][""type""] ""INT8"" to ""UINT8"".

This idea based on the link below.
[https://towardsdatascience.com/hacking-google-coral-edge-tpu-motion-blur-and-lanczos-resize-9b60ebfaa552](url)
Actually, it failed. I want to know the reasons.

**Code to reproduce the issue**
```

import tensorflow as tf
import torch
from PIL import Image
import numpy as np
import pathlib

#tf.compat.v1.enable_eager_execution()
#tf.logging.set_verbosity(tf.logging.DEBUG)

#import matplotlib.pyplot as plt
print(tf.__version__)
print(torch.__version__)


val = ""./ILSVRC2012_img_val/""
val=pathlib.Path(val)
item=np.array([i.name for i in val.glob(""*"")])

image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255,data_format=""channels_first"")

train_data_gen = image_generator.flow_from_directory(directory=str(val),
                                                     batch_size=100,
                                                     shuffle=True,
                                                     target_size=(320,320),
                                                     classes = list(item))

image_batch, label_batch = next(train_data_gen)
image_batch=np.expand_dims(image_batch,1)

print(((image_batch).dtype))

image_batch, label_batch = next(train_data_gen)
mean=([0.485, 0.456, 0.406])
std=([0.229, 0.224, 0.225])
for i in range(3):
    image_batch[:,i,:,:]=(image_batch[:,i,:,:]-mean[i])/(std[i])
print(image_batch.shape)
image_batch=(np.expand_dims(image_batch,1))


def representative_data_gen():
    for i in range(100):
        yield [image_batch[i]]

graph_def_file = ""test_320.pb""
inputs=['input.1']
outputs=['655']
converter = tf.lite.TFLiteConverter.from_frozen_graph(graph_def_file,inputs, outputs)
converter.optimizations = [tf.lite.Optimize.DEFAULT]
#converter.inference_type=tf.uint8
converter.representative_dataset = representative_data_gen
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]
converter.inference_input_type = tf.uint8
converter.inference_output_type = tf.uint8
#converter.experimental_new_quantizer= True
#converter.experimental_enable_mlir_converter = True
tflite_model_op= converter.convert()
open(""cvted_model_320_quant_op.tflite"", ""wb"").write(tflite_model_op)


```

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

I tried compile with Edge TPU Compiler, and find out ""unsupported data type"". Then I use netron find that most of them are tf.int8.

Here is the Edge TPU compiler log, result of Netron and my model. 

```
Edge TPU Compiler version 2.0.291256449

Model compiled successfully in 45 ms.

Input model: /home/xxxxx01/39dstest/cvted_model_320_quant_op.tflite
Input size: 6.28MiB
Output model: cvted_model_320_quant_op_edgetpu.tflite
Output size: 6.03MiB
On-chip memory available for caching model parameters: 0.00B
On-chip memory used for caching model parameters: 0.00B
Off-chip memory used for streaming uncached model parameters: 0.00B
Number of Edge TPU subgraphs: 0
Total number of operations: 7950
Operation log: cvted_model_320_quant_op_edgetpu.log

Model successfully compiled but not all operations are supported by the Edge TPU. A percentage of the model will instead run on the CPU, which is slower. If possible, consider updating your model to use only operations supported by the Edge TPU. For details, visit g.co/coral/model-reqs.
Number of operations that will run on Edge TPU: 0
Number of operations that will run on CPU: 7950

Operator                       Count      Status

SPLIT                          36         Operation is working on an unsupported data type
QUANTIZE                       3729       Operation is otherwise supported, but not mapped due to some unspecified limitation
MUL                            74         Operation is working on an unsupported data type
MAXIMUM                        38         Operation is working on an unsupported data type
MINIMUM                        38         Operation is working on an unsupported data type
ADD                            74         Operation is working on an unsupported data type
CONCATENATION                  56         Operation is working on an unsupported data type
PAD                            37         Operation is working on an unsupported data type
CONV_2D                        38         Operation is working on an unsupported data type
DEPTHWISE_CONV_2D              3680       Operation is working on an unsupported data type
TRANSPOSE                      148        Operation is working on an unsupported data type
MEAN                           1          Operation is working on an unsupported data type
FULLY_CONNECTED                1          Operation is working on an unsupported data type

```
**Result of Netron**
![Results of Netron](https://user-images.githubusercontent.com/60849247/74120385-1be52580-4bfe-11ea-8909-7d636b97be14.PNG)

**My model**
[test_320.zip](https://github.com/tensorflow/tensorflow/files/4178930/test_320.zip)


New to Github, Thx ><"
36609,ImportError:_pywrap_checkpoint_reader,"When I tried to run freeze_graph.py, the following import Error comes out.

from tensorflow.python.training import py_checkpoint_reader
ImportError: cannot import name 'py_checkpoint_reader'
 
I found 'py_checkpoint_reader.py' file in tensorflow/python/training folder.
But inside of 'py_checkpoint_reader.py' file,

from tensorflow.python._pywrap_checkpoint_reader import CheckpointReader

I cannot find the file '_pywrap_checkpoint_reader. 

"
36607,Error when installing: ERROR: tensorflow-2.1.0-cp27-cp27m-macosx_10_15_intel.whl is not a supported wheel on this platform.,"Running Mojave 10.14.6
Tensorflow installed from source (via https://www.tensorflow.org/install/source from cloning the repo)
Python 2.7.15
Installed using pip
Bazel version 1.2.1
Clang version 11.0.0
Intel Iris 1536 MB

When trying to build tensorflow from this [link](https://www.tensorflow.org/install/source) I was able to get through all steps until actually installing using pip. Everything went relatively smoothly although it took a while (although it did take about 5 hours).

I was excited to finally get to the end but was disappointed because pip couldn't install the package giving me the following error:

`ERROR: tensorflow-2.1.0-cp27-cp27m-macosx_10_15_intel.whl is not a supported wheel on this platform.`

I googled the error and searched through the list of other similar issues but most of the issues were either old or didn't apply to the same os.

How do I fix this?"
36605,fft2d different results between tensorflow and numpy,"Hi,

I have one question about the fft2d and fftshift. 
The following code shows the similar process (fft2d > fftshift > * filter(LPF) > ifftshift > ifft2d) with numpy and tensorflow.
However the result is mush different. And the result of tensorflow is so weird.
Could anyone help me figure out what's wrong in the code?
Thanks a lot.

`    
    img = cv2.imread(""xxx.png"")
    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY).astype(np.float32)
    width = img.shape[1]
    height = img.shape[0]

    filter = LPF_Butterworth(width, height, 33, 4)

    # use numpy fft2 ===========
    f = np.fft.fft2(img)
    f = np.fft.fftshift(f)
    f_l = f * filter
    f_l = np.fft.ifftshift(f_l)
    f_l = np.fft.ifft2(f_l)
    f_np = np.real(f_l)
    #===========================

    input_placeholder = tf.compat.v1.placeholder(tf.float32,
                                       shape=[height, width, 1],
                                       name='input')

    # use tensorflow fft2d ===========
    tf_filter = tf.convert_to_tensor(filter, dtype=tf.float32)
    tf_filter_comx = tf.expand_dims(tf.complex(tf_filter, tf.zeros(tf_filter.shape)),2)
    fft_org = tf.fft2d(tf.cast(input_placeholder, tf.complex64))
    fft_org = tf.signal.fftshift(fft_org, axes=[0,1])
    fft_filter = fft_org * tf_filter_comx
    fft_filter = tf.ifft2d(tf.signal.ifftshift(fft_filter, axes=[0,1]))
    fft_filter = tf.real(fft_filter)
    #================================

    sess = tf.Session(config=tf.ConfigProto(device_count={'GPU': 0}))
    sess.run(tf.global_variables_initializer())
    sess.run(tf.local_variables_initializer())

    with sess.as_default():
        feed_dict = {input_placeholder: np.expand_dims(img, axis=2)}
        f_tf = sess.run(fft_filter, feed_dict=feed_dict)

    f_np = cv2.normalize(f_np, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)
    f_tf = cv2.normalize(f_tf, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)
    cv2.imshow(""numpy"", f_np)
    cv2.imshow(""tensorflow"", f_tf)
    cv2.waitKey()
`
result: https://i.stack.imgur.com/0vLSd.png

[](https://i.stack.imgur.com/0vLSd.png)

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): win10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): pip
- TensorFlow version (use command below): 1.15
- Python version: 3.6
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10.0
- GPU model and memory: 2080Ti 11G
"
36603,TensorRT plugins,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): 2.1
- Are you willing to contribute it (Yes/No): Maybe

**Describe the feature and the current behavior/state.**

Is it possible to use TensorRT plugin in TrtGraphConverterV2? Should I register the plugin in TF? I noticed there's some code for  plugins here: https://github.com/tensorflow/tensorflow/tree/master/tensorflow/compiler/tf2tensorrt/plugin, but I can't find any example.
It would be best to be able to use plugins directly from TrtGraphConverterV2

**Will this change the current api? How?**

Not necessary

**Who will benefit with this feature?**

Everyone who want to speed up with TensorRT. Current set od convertable layers is very limited

**Any Other info.**
"
36602,GPU Ram exhaustion TF 2.1 CUDA 10.1,"**System information**
- Have I written custom code : yes, although very minimal
- OS Platform and Distribution: Linux Ubuntu 19.10
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.1.0  (also tested 2.0.0)
- Python version: 3.6.10 anaconda
- CUDA/cuDNN version: 10.1.243
- GPU model and memory: Nvidia RTX 2080 7979MiB

**Describe the current behavior**
Since updating to 2.1.0, the following simple commands cause memory exhaustion and
all further inputs to fail with cuDNN errors:

```python
X = tf.random.normal((16, 128, 16), dtype=tf.float32)
layer_norm = tf.keras.layers.LayerNormalization()
Xn = layer_norm(X)
```
which causes
cuDNN launch failure : input shape ([1,2048,16,1]) [Op:FusedBatchNormV3]
(BatchNormalization has the same issue, unsurprisingly)

Initially, I thought this was a CUDA/CuDNN installation issue, but if I add

```python
for gpu in tf.config.experimental.list_physical_devices('GPU'):
    tf.config.experimental.set_memory_growth(gpu, False)
```

the problem does not occur.

This issue does not happen if I change TF or CUDA versions TF 2.0.0 or CUDA 10.0 
-- it is specific to 2.1.0 + 10.1.  (It is still present in the current nightly).

I have not been able to replicate this problem in, say, colab, but I don't know what version
of Cuda is in use there.

Test cases:
  * TF 2.1.0 Cuda 10.1.243 CuDNN(-Dev) 7.6.5.42-1+cuda10.1 TensorRT 6.0.1.5+cuda10.1
     * Memory Growth: True ->  Failure with CuDNN start error
     * Memory Growth: False -> Success
  * TF 2.0.0 Cuda 10.1.243 CuDNN(-Dev) 7.6.5.42-1+cuda10.1 TensorRT 6.0.1.5+cuda10.1
     * Memory Growth: True ->  Success
     * Memory Growth: False -> Success
  * TF 2.1.0 Cuda 10.0.130 CuDNN(-Dev) 7.6.5.32-1+cuda10.0 TensorRT 7.0.0.11
     * Memory Growth: True ->  Success
     * Memory Growth: False -> Success
  *  TF 2.0.0 Cuda 10.0.130 CuDNN(-Dev) 7.6.5.32-1+cuda10.0 TensorRT 7.0.0.11
     * Memory Growth: True ->  Success
     * Memory Growth: False -> Success
  *  TF 2.0.0 Cuda 10.0.130 CuDNN(-Dev) 7.6.5.32-1+cuda10.0 TensorRT 7.0.0.11
     * Memory Growth: True ->  Success
     * Memory Growth: False -> Success
  *  TF 2.1.0 Cuda 10.0.130 CuDNN(-Dev) 7.6.5.32-1+cuda10.0 TensorRT 6.0.1.5
     * Memory Growth: True ->  Success
     * Memory Growth: False -> Success

Note TensorRT 7 is not available for CUDA 10.1, hence the last test with v6 of TensorRT.
I tried to test on CUDA 10.2 by building from source, but got bogged down with blaze
installation conflicts.  I have reinstalled the failing set of libraries + TF from scratch more than
once as a sanity check, and it has re-occurred each time.

**Describe the expected behavior**
  It should be possible to execute LayerNorm/BatchNorm."
36601,ERROR:root: Internal Python error in the inspect module while installing Tensorflow,"<em>I have installed TensorFlow 2.0 with CUDA 10.1, cuDNN SDK = 7.6 and all the different libraries such as pandas, sci-kit learn, Keras, NumPy, Gensim etc. This error is probably due to new TensorFlow version. When I try to confirm it by running this confirmation code. I am getting an error. Kindly help.

**System information**
- Window 10
- TensorFlow GPU version: 2.0
- Python version: 3.7.6
- Installed using virtualenv? pip? conda?: pip
- CUDA/cuDNN version: 10.1/7.6.5
- GPU model and memory: Geforce 940M and 12 GB


**Command I tried to confirm installation**
import sys
import tensorflow.keras
import pandas as pd
import sklearn as sk
import tensorflow as tf
print(f""Tensor Flow Version: {tf.__version__}"")
print(f""Keras Version: {tensorflow.keras.__version__}"")
print()
print(f""Python {sys.version}"")
print(f""Pandas {pd.__version__}"")
print(f""Scikit-Learn {sk.__version__}"")
print(""GPU is"", ""available"" if tf.test.is_gpu_available() else ""NOT AVAILABLE"")

**ERROR:root: Internal Python error in the inspect module while installing Tensorflow**

`Traceback (most recent call last):
  File ""C:\Users\Abdul\.conda\envs\tensorflow\lib\site-packages\IPython\core\interactiveshell.py"", line 3331, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File ""<ipython-input-5-a5e23077879c>"", line 8, in <module>
    print(f""Tensor Flow Version: {tf.__version__}"")
AttributeError: module 'tensorflow' has no attribute '__version__'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\Abdul\.conda\envs\tensorflow\lib\site-packages\IPython\core\interactiveshell.py"", line 2044, in showtraceback
    stb = value._render_traceback_()
AttributeError: 'AttributeError' object has no attribute '_render_traceback_'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\Abdul\.conda\envs\tensorflow\lib\site-packages\IPython\core\ultratb.py"", line 1151, in get_records
    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)
  File ""C:\Users\Abdul\.conda\envs\tensorflow\lib\site-packages\IPython\core\ultratb.py"", line 319, in wrapped
    return f(*args, **kwargs)
  File ""C:\Users\Abdul\.conda\envs\tensorflow\lib\site-packages\IPython\core\ultratb.py"", line 353, in _fixed_getinnerframes
    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))
  File ""C:\Users\Abdul\.conda\envs\tensorflow\lib\inspect.py"", line 1502, in getinnerframes
    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)
  File ""C:\Users\Abdul\.conda\envs\tensorflow\lib\inspect.py"", line 1460, in getframeinfo
    filename = getsourcefile(frame) or getfile(frame)
  File ""C:\Users\Abdul\.conda\envs\tensorflow\lib\inspect.py"", line 696, in getsourcefile
    if getattr(getmodule(object, filename), '__loader__', None) is not None:
  File ""C:\Users\Abdul\.conda\envs\tensorflow\lib\inspect.py"", line 733, in getmodule
    if ismodule(module) and hasattr(module, '__file__'):
  File ""C:\Users\Abdul\.conda\envs\tensorflow\lib\site-packages\tensorflow\__init__.py"", line 50, in __getattr__
    module = self._load()
  File ""C:\Users\Abdul\.conda\envs\tensorflow\lib\site-packages\tensorflow\__init__.py"", line 44, in _load
    module = _importlib.import_module(self.__name__)
  File ""C:\Users\Abdul\.conda\envs\tensorflow\lib\importlib\__init__.py"", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""<frozen importlib._bootstrap>"", line 1006, in _gcd_import
  File ""<frozen importlib._bootstrap>"", line 983, in _find_and_load
  File ""<frozen importlib._bootstrap>"", line 953, in _find_and_load_unlocked
  File ""<frozen importlib._bootstrap>"", line 219, in _call_with_frames_removed
  File ""<frozen importlib._bootstrap>"", line 1006, in _gcd_import
  File ""<frozen importlib._bootstrap>"", line 983, in _find_and_load
  File ""<frozen importlib._bootstrap>"", line 967, in _find_and_load_unlocked
  File ""<frozen importlib._bootstrap>"", line 677, in _load_unlocked
  File ""<frozen importlib._bootstrap_external>"", line 728, in exec_module
  File ""<frozen importlib._bootstrap>"", line 219, in _call_with_frames_removed
  File ""C:\Users\Abdul\.conda\envs\tensorflow\lib\site-packages\tensorflow_core\__init__.py"", line 45, in <module>
    from . _api.v2 import compat
  File ""C:\Users\Abdul\.conda\envs\tensorflow\lib\site-packages\tensorflow_core\_api\v2\compat\__init__.py"", line 23, in <module>
    from . import v1
  File ""C:\Users\Abdul\.conda\envs\tensorflow\lib\site-packages\tensorflow_core\_api\v2\compat\v1\__init__.py"", line 40, in <module>
    from . import experimental
  File ""C:\Users\Abdul\.conda\envs\tensorflow\lib\site-packages\tensorflow_core\_api\v2\compat\v1\experimental\__init__.py"", line 11, in <module>
    from tensorflow.python.ops.control_flow_v2_toggles import output_all_intermediates
  File ""C:\Users\Abdul\.conda\envs\tensorflow\lib\site-packages\tensorflow_core\python\ops\control_flow_v2_toggles.py"", line 24, in <module>
    from tensorflow.python.ops import control_flow_util_v2
  File ""C:\Users\Abdul\.conda\envs\tensorflow\lib\site-packages\tensorflow_core\python\ops\control_flow_util_v2.py"", line 28, in <module>
    from tensorflow.python.keras.engine import base_layer_utils
  File ""C:\Users\Abdul\.conda\envs\tensorflow\lib\site-packages\tensorflow_core\python\keras\__init__.py"", line 27, in <module>
    from tensorflow.python.keras import applications
  File ""C:\Users\Abdul\.conda\envs\tensorflow\lib\site-packages\tensorflow_core\python\keras\applications\__init__.py"", line 25, in <module>
    from tensorflow.python.keras import engine
  File ""C:\Users\Abdul\.conda\envs\tensorflow\lib\site-packages\tensorflow_core\python\keras\engine\__init__.py"", line 23, in <module>
    from tensorflow.python.keras.engine.base_layer import Layer
  File ""C:\Users\Abdul\.conda\envs\tensorflow\lib\site-packages\tensorflow_core\python\keras\engine\base_layer.py"", line 56, in <module>
    from tensorflow.python.keras.saving.saved_model import layer_serialization
  File ""C:\Users\Abdul\.conda\envs\tensorflow\lib\site-packages\tensorflow_core\python\keras\saving\__init__.py"", line 20, in <module>
    from tensorflow.python.keras.saving.hdf5_format import load_attributes_from_hdf5_group
  File ""C:\Users\Abdul\.conda\envs\tensorflow\lib\site-packages\tensorflow_core\python\keras\saving\hdf5_format.py"", line 32, in <module>
    from tensorflow.python.keras.utils import conv_utils
  File ""C:\Users\Abdul\.conda\envs\tensorflow\lib\site-packages\tensorflow_core\python\keras\utils\__init__.py"", line 38, in <module>
    from tensorflow.python.keras.utils.multi_gpu_utils import multi_gpu_model
  File ""C:\Users\Abdul\.conda\envs\tensorflow\lib\site-packages\tensorflow_core\python\keras\utils\multi_gpu_utils.py"", line 22, in <module>
    from tensorflow.python.keras.engine.training import Model
  File ""C:\Users\Abdul\.conda\envs\tensorflow\lib\site-packages\tensorflow_core\python\keras\engine\training.py"", line 42, in <module>
    from tensorflow.python.keras import metrics as metrics_module
  File ""C:\Users\Abdul\.conda\envs\tensorflow\lib\site-packages\tensorflow_core\python\keras\metrics.py"", line 34, in <module>
    from tensorflow.python.keras.engine.base_layer import Layer
ImportError: cannot import name 'Layer' from 'tensorflow.python.keras.engine.base_layer' (C:\Users\Abdul\.conda\envs\tensorflow\lib\site-packages\tensorflow_core\python\keras\engine\base_layer.py)
---------------------------------------------------------------------------`"
36600,"Tensorflow 2.1 BERt embeddings - Variable is unhashable if Tensor equality is enabled. Instead, use tensor.experimental_ref() as the key","I'm trying to load the [following](https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/1) BERt presaved model from tensorflow hub. As per the previously mentioned page, this is the code that I'm trying to execute

```
max_seq_length = 128  # Your choice here.
input_word_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32,
                                       name=""input_word_ids"")
input_mask = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32,
                                   name=""input_mask"")
segment_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32,
                                    name=""segment_ids"")
bert_layer = hub.KerasLayer(""https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/1"",
                            trainable=True)
pooled_output, sequence_output = bert_layer([input_word_ids, input_mask, segment_ids])
```
However, as soon as I get to execute the hub.KerasLayer, I'm getting the following exception.


```
In [10]: bert_layer = hub.KerasLayer(""https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/1"", 
    ...:                             trainable=True)                                                                                                                                                        

---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
<ipython-input-10-f1fd8e265590> in <module>
      1 bert_layer = hub.KerasLayer(""https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/1"",
----> 2                             trainable=True)

~/anaconda3/lib/python3.7/site-packages/tensorflow_hub/keras_layer.py in __init__(self, handle, trainable, arguments, **kwargs)
    111       for v in self._func.trainable_variables:
    112         self._add_existing_weight(v, trainable=True)
--> 113       trainable_variables = set(self._func.trainable_variables)
    114     else:
    115       trainable_variables = set()

~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/variables.py in __hash__(self)
   1087   def __hash__(self):
   1088     if ops.Tensor._USE_EQUALITY and ops.executing_eagerly_outside_functions():  # pylint: disable=protected-access
-> 1089       raise TypeError(""Variable is unhashable if Tensor equality is enabled. ""
   1090                       ""Instead, use tensor.experimental_ref() as the key."")
   1091     else:

TypeError: Variable is unhashable if Tensor equality is enabled. Instead, use tensor.experimental_ref() as the key.
```

What am I missing? I'm running all of the above on macOS 10.15 and TF 2.1

"
36599,NMT with attention,"Thank you for submitting a TensorFlow documentation issue. Per our GitHub
policy, we only address code/doc bugs, performance issues, feature requests, and
build/installation issues on GitHub.

The TensorFlow docs are open source! To get involved, read the documentation
contributor guide: https://www.tensorflow.org/community/contribute/docs

## URL(s) with the issue:

Please provide a link to the documentation entry, for example:
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/MyMethod

## Description of issue (what needs changing):

### Clear description

For example, why should someone use this method? How is it useful?

### Correct links

Is the link to the source code correct?

### Parameters defined

Are all parameters defined and formatted correctly?

### Returns defined

Are return values defined?

### Raises listed and defined

Are the errors defined? For example,
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises

### Usage example

Is there a usage example?

See the API guide: https://www.tensorflow.org/community/contribute/docs_ref
on how to write testable usage examples.

### Request visuals, if applicable

Are there currently visuals? If not, will it clarify the content?

### Submit a pull request?

Are you planning to also submit a pull request to fix the issue? See the docs
contributor guide: https://www.tensorflow.org/community/contribute/docs,
docs API guide: https://www.tensorflow.org/community/contribute/docs_ref and the
docs style guide: https://www.tensorflow.org/community/contribute/docs_style
"
36598,installation issue,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version:2.0
- Python version:
- Installed using virtualenv? pip? conda?:pip
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:


ERROR:root:Internal Python error in the inspect module.
Below is the traceback from this internal error.

ERROR:root:Internal Python error in the inspect module.
Below is the traceback from this internal error.

Traceback (most recent call last):
  File ""C:\Users\hello\Anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\hello\Anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\hello\Anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\hello\Anaconda3\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\hello\Anaconda3\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: The specified module could not be found.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\hello\Anaconda3\lib\site-packages\IPython\core\interactiveshell.py"", line 3326, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File ""<ipython-input-1-d6579f534729>"", line 1, in <module>
    import tensorflow
  File ""C:\Users\hello\Anaconda3\lib\site-packages\tensorflow\__init__.py"", line 101, in <module>
    from tensorflow_core import *
  File ""C:\Users\hello\Anaconda3\lib\site-packages\tensorflow_core\__init__.py"", line 40, in <module>
    from tensorflow.python.tools import module_util as _module_util
  File ""C:\Users\hello\Anaconda3\lib\site-packages\tensorflow\__init__.py"", line 50, in __getattr__
    module = self._load()
  File ""C:\Users\hello\Anaconda3\lib\site-packages\tensorflow\__init__.py"", line 44, in _load
    module = _importlib.import_module(self.__name__)
  File ""C:\Users\hello\Anaconda3\lib\importlib\__init__.py"", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""C:\Users\hello\Anaconda3\lib\site-packages\tensorflow_core\python\__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\Users\hello\Anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 74, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""C:\Users\hello\Anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\hello\Anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\hello\Anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\hello\Anaconda3\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\hello\Anaconda3\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: The specified module could not be found.


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/errors

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\hello\Anaconda3\lib\site-packages\IPython\core\interactiveshell.py"", line 2040, in showtraceback
    stb = value._render_traceback_()
AttributeError: 'ImportError' object has no attribute '_render_traceback_'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\hello\Anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\hello\Anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\hello\Anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\hello\Anaconda3\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\hello\Anaconda3\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: The specified module could not be found.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\hello\Anaconda3\lib\site-packages\IPython\core\ultratb.py"", line 1101, in get_records
    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)
 
**Describe the problem**

**Provide the exac


**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
36596,tf.keras GradientTape: get gradient with respect to input,"Tensorflow 2.1

I want to get the gradients with respect to the input instead of the gradient with respect to the trainable weights. I adjust the example from https://www.tensorflow.org/guide/keras/train_and_evaluate to

```
import tensorflow as tf
import numpy as np

physical_devices = tf.config.experimental.list_physical_devices('GPU')
assert len(physical_devices) > 0, 'Not enough GPU hardware devices available'
tf.config.experimental.set_memory_growth(physical_devices[0], True)

def loss_fun(y_true, y_pred):
    loss = tf.reduce_mean(tf.square(y_true - y_pred), axis=-1)
    return loss

# Create a dataset
x = np.random.rand(10, 180, 320, 3).astype(np.float32)
y = np.random.rand(10, 1).astype(np.float32)
dataset = tf.data.Dataset.from_tensor_slices((x, y)).batch(1)

# Create a model
base_model = tf.keras.applications.MobileNet(input_shape=(180, 320, 3), weights=None, include_top=False)
x = tf.keras.layers.GlobalAveragePooling2D()(base_model.output)
output = tf.keras.layers.Dense(1)(x)
model = tf.keras.models.Model(inputs=base_model.input, outputs=output)

for input, target in dataset:

    for iteration in range(400):
        with tf.GradientTape() as tape:
            # Run the forward pass of the layer.
            # The operations that the layer applies
            # to its inputs are going to be recorded
            # on the GradientTape.
            prediction = model(input, training=False)  # Logits for this minibatch

            # Compute the loss value for this minibatch.
            loss_value = loss_fun(target, prediction)

        # Use the gradient tape to automatically retrieve
        # the gradients of the trainable variables with respect to the loss.
        grads = tape.gradient(loss_value, model.inputs)
        print(grads)  # output: [None]
        # Run one step of gradient descent by updating
        # the value of the variables to minimize the loss.
        optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)
        optimizer.apply_gradients(zip(grads, model.inputs))

        print('Iteration {}'.format(iteration))
```


However, this doesnot work, because grads = tape.gradient(loss_value, model.inputs) returns [None]. Is this intended behaviour or not? If yes, what is the recommended way to get the gradients with respect to the input?"
36595,'Tensor' object has no attribute 'numpy',"## URL(s) with the issue:
https://www.tensorflow.org/tutorials/quickstart/beginner


## Description of issue (what needs changing):
The instructions state, in the fourth block of sample code, to use a command which returns a fatal error.

`predictions = model(x_train[:1]).numpy()`


### Clear description
When running the example, as written, on Debian Stable (python 3.7.3)

```
>>> predictions = model(x_train[:1]).numpy()
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
AttributeError: 'Tensor' object has no attribute 'numpy'

```"
36594,ValueError: Failed to convert a NumPy array to a Tensor (Unsupported object type NAType).,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 64-bit
- TensorFlow installed from (source or binary): PyCharm
- TensorFlow version (use command below): 2.0.0
- Python version: 3.7.6

**Describe the current behavior**
I more or less tried to follow the instructions to load pandas.DataFrame (https://www.tensorflow.org/tutorials/load_data/pandas_dataframe) using my own dataset. Unfortunately the tf.data.Dataset.from_tensor_slices() function returns the following error:

ValueError: Failed to convert a NumPy array to a Tensor (Unsupported object type NAType).

The only difference in comparision with the tutorial is, that I used Strings as input in my pandas dataframe.

**Describe the expected behavior**
The Tensorflow dataset is created correctly.

**Code to reproduce the issue**
from __future__ import absolute_import, division, print_function, unicode_literals


import numpy as np
import tensorflow as tf
import pandas as pd


def data_preprocessing():
    print(tf.__version__)

    train_file_path = 'Learning Data Input/TrainingData.csv'

    pandas_data = pd.read_csv(train_file_path, delimiter=';', dtype='string')
    for column in pandas_data:
        if pandas_data[column].dtype != 'string':
            print(column)
    print(pandas_data.head())
    print(pandas_data.dtypes)
    
    # Feature to be predicted
    label_column = pandas_data.pop('PARTSET0')  

    raw_training_data = get_dataset(pandas_data, label_column)

def get_dataset(pandas_data, label_column):
    dataset = tf.data.Dataset.from_tensor_slices((pandas_data.values, label_column.values))

    return dataset

**Other info / logs**
My data set looks as follows:
 CC_ENDCUSTOMERNAME CC_ENDCUSTOMERCOUNTRY  ...     PARTSET7     PARTSET8
0  xxx                  THA  ...  123456  123456
1  yyy                   GER  ...  123456  123456
2  zzz                   US ...  123456  123456

and has round about 1000 rows and 190 columns. Please note that the numeric values in the csv are intentionally impported as Strings and this should be persisted.

Thanks for your help!
"
36592,Heatmap function,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using):2.0(I use colab so the latest probably)
- Are you willing to contribute it (Yes/No):
Yes


**Describe the feature and the current behavior/state.**
Presently I have to write lots of code to create a heatmap for images. I would like to have a function that automatically generates one for you
**Will this change the current api? How?**
It will add another function to the API
**Who will benefit with this feature?**
Beginners at ML and others who don't want to write lots of code to do this
**Any Other info.**
"
36591,Nit tutorial inconsistency in text generation with RNN,"## URL(s) with the issue:

https://www.tensorflow.org/tutorials/text/text_generation#the_prediction_loop

## Description of issue (what needs changing):
Consider the previously generated letters for subsequent generations. Right now only the lastly generated letter is considered to generate the immediate next letter. The result reads very far from natural as you can imagine.

### Clear description

The `generate_text()` method is supposed to generate text, letter by letter, by taking into account a starting string and any letter that has been generated so far. Right now, it's generating the first letter by taking into account the starting string, then from then on, it only considers the last generated letter. 

So in this:
```
def generate_text(model, start_string):
  # Evaluation step (generating text using the learned model)

  # Number of characters to generate
  num_generate = 1000

  # Converting our start string to numbers (vectorizing)
  input_eval = [char2idx[s] for s in start_string]
  input_eval = tf.expand_dims(input_eval, 0)

  # Empty string to store our results
  text_generated = []

  # Low temperatures results in more predictable text.
  # Higher temperatures results in more surprising text.
  # Experiment to find the best setting.
  temperature = 1.0

  # Here batch size == 1
  model.reset_states()
  for i in range(num_generate):
      predictions = model(input_eval)
      # remove the batch dimension
      predictions = tf.squeeze(predictions, 0)

      # using a categorical distribution to predict the character returned by the model
      predictions = predictions / temperature
      predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()

      # We pass the predicted character as the next input to the model
      # along with the previous hidden state
      input_eval = tf.expand_dims([predicted_id], 0)

      text_generated.append(idx2char[predicted_id])

  return (start_string + ''.join(text_generated))
```

The end of the for-loop needs to be updated to match the comment description, with something like this:
```
# We pass the predicted character as the next input to the model
# along with the previous hidden state
input_eval = tf.concat([input_eval, tf.expand_dims([predicted_id], 0)], -1)
```
Where we add the newly predicted ID to the end of what is currently `input_eval`

### Submit a pull request?

I plan on submitting a pull request with the quick fix.
"
36590,Building a static library for windows with visual studio.,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): 2.1
- Are you willing to contribute it (Yes/No): yes (but not sure I can)



**Describe the feature and the current behavior/state.**
I want a feature to build a static library for C++ integrating on windows with visual studio. Or a static library that is available for download.

**Will this change the current api? How?**
No, it will not change the api.

**Who will benefit with this feature?**
Everyone who has a C++ project in visual studio and want to implement tensorflow.

**Any Other info.**
It would have been nice with a full guide to how to do it. This is something I could contribute with if we ever get the feature."
36588,Software requirement may lack VC++ runtime,"## URL(s) with the issue:

[Software requirements](https://www.tensorflow.org/install/gpu#software_requirements)

## Description of issue (what needs changing):

The requirement may lack the dependency of [Microsoft Visual C++ Redistributable for Visual Studio](https://support.microsoft.com/en-us/help/2977003/the-latest-supported-visual-c-downloads) runtime.

### Clear description

After installation, TF raises an error with `ImportError: DLL load failed: The specified module could not be found.`

Fixed after installing [Microsoft Visual C++ Redistributable for Visual Studio 2015, 2017 and 2019](https://aka.ms/vs/16/release/vc_redist.x64.exe) via [error page](https://www.tensorflow.org/install/errors) and issue https://github.com/tensorflow/tensorflow/issues/22794 & https://github.com/tensorflow/tensorflow/issues/22512

Wanna confirm whether Microsoft Visual C++ Redistributable for Visual Studio must be installed and its version. If true, please add this information to [software requirements](https://www.tensorflow.org/install/gpu#software_requirements).

### Submit a pull request?

If confirmation, I can PR to [tensorflow/docs](https://github.com/tensorflow/docs/blob/master/site/en/install/gpu.md).

---
PS.. here comes system info to trace that issue.
Hardware:
```
Processor: Intel(R) Core(TM) i7-7500U CPU @ 2.70GHz (4 CPUs), ~2.9GHz
Memory: 16384MB RAM
Card name: NVIDIA GeForce 940MX
Manufacturer: NVIDIA
Chip type: GeForce 940MX
```
Software:
```
Operating System: Windows 10 Pro 64-bit (10.0, Build 18363) (18362.19h1_release.190318-1202) 
(conda)TensorFlow: 2.1.0 (install via pypi)
(conda)cudatoolkit: 10.1.243 (install via anaconda)
(conda)cudnn: 7.6.5 (install via anaconda)
Nvidia Driver Version: 441.87
```
It can be reproduced in `conda install` or `native install`.

Hope those info helps.

Thanks in advance! :-)"
36587,Unable to reset tensorflow model,"I am trying to find the optimal number of neurons in the model. For that I am using a loop for number of layers. But instead of resetting the tensorflow model, it's adding layers to it. I tried K.clear_session(),sess.close(), gc.collect(). It doesn't works. Cuda.close() terminates the program, I am using tensorflow 1.10, win 10."
36581,tf.GradientTape.gradients() does not support graph control flow operations like tf.cond or tf.while at this time. Use tf.gradients() instead.,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Python version**:
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with:

```bash
python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""
```

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
36580,"Stuck while using TFRecordWriter - TypeError: <class 'tensorflow.python.framework.ops.EagerTensor'>, but expected one of: (<class 'int'>,)","I'm using Tensorflow-GPU 1.15.0 in a Colab notebook (Python 3.6.10) with local runtime on a Windows 10 device. I'm receiving the error above when trying to write the predictions I've created to a TfRecord File. It is based on [this](https://github.com/google/earthengine-api/blob/master/python/examples/ipynb/TF_demo1_keras.ipynb) colab notebook. It works fine on that hosted runtime but Running this job there is not an option as it takes too long.

```
# Instantiate the writer.
writer = tf.python_io.TFRecordWriter(outputImageFile)

# Every patch-worth of predictions we'll dump an example into the output
# file with a single feature that holds our predictions. Since our predictions
# are already in the order of the exported data, the patches we create here
# will also be in the right order.
patch = [[], [], [], []]
curPatch = 1
for prediction in predictions:
  patch[0].append(tf.argmax(prediction, 1))
  patch[1].append(prediction[0][0])
  patch[2].append(prediction[0][1])
  patch[3].append(prediction[0][2])
  # Once we've seen a patches-worth of class_ids...
  if (len(patch[0]) == PATCH_WIDTH * PATCH_HEIGHT):
    print('Done with patch ' + str(curPatch) + ' of ' + str(PATCHES) + '...')
    # Create an example
    example = tf.train.Example(
      features=tf.train.Features(
        feature={
          'prediction': tf.train.Feature(
              int64_list=tf.train.Int64List(
                  value=patch[0])),
          'bareProb': tf.train.Feature(
              float_list=tf.train.FloatList(
                  value=patch[1])),
          'vegProb': tf.train.Feature(
              float_list=tf.train.FloatList(
                  value=patch[2])),
          'waterProb': tf.train.Feature(
              float_list=tf.train.FloatList(
                  value=patch[3])),
        }
      )
    )
    # Write the example to the file and clear our patch array so it's ready for
    # another batch of class ids
    writer.write(example.SerializeToString())
    patch = [[], [], [], []]
    curPatch += 1

writer.close()
```

**Error:**
```
TypeError                                 Traceback (most recent call last)
<ipython-input-26-d7a6c8a0115c> in <module>
     21           'prediction': tf.train.Feature(
     22               int64_list=tf.train.Int64List(
---> 23                   value=patch[0])),
     24           'bareProb': tf.train.Feature(
     25               float_list=tf.train.FloatList(

c:\anaconda\envs\tfcollab\lib\site-packages\google\protobuf\internal\python_message.py in init(self, **kwargs)
    533             field_value = [_GetIntegerEnumValue(field.enum_type, val)
    534                            for val in field_value]
--> 535           copy.extend(field_value)
    536         self._fields[field] = copy
    537       elif field.cpp_type == _FieldDescriptor.CPPTYPE_MESSAGE:

c:\anaconda\envs\tfcollab\lib\site-packages\google\protobuf\internal\containers.py in extend(self, elem_seq)
    279       raise
    280 
--> 281     new_values = [self._type_checker.CheckValue(elem) for elem in elem_seq_iter]
    282     if new_values:
    283       self._values.extend(new_values)

c:\anaconda\envs\tfcollab\lib\site-packages\google\protobuf\internal\containers.py in <listcomp>(.0)
    279       raise
    280 
--> 281     new_values = [self._type_checker.CheckValue(elem) for elem in elem_seq_iter]
    282     if new_values:
    283       self._values.extend(new_values)

c:\anaconda\envs\tfcollab\lib\site-packages\google\protobuf\internal\type_checkers.py in CheckValue(self, proposed_value)
    136       message = ('%.1024r has type %s, but expected one of: %s' %
    137                  (proposed_value, type(proposed_value), six.integer_types))
--> 138       raise TypeError(message)
    139     if not self._MIN <= int(proposed_value) <= self._MAX:
    140       raise ValueError('Value out of range: %d' % proposed_value)

TypeError: <tf.Tensor: id=408263, shape=(1,), dtype=int64, numpy=array([5], dtype=int64)> has type <class 'tensorflow.python.framework.ops.EagerTensor'>, but expected one of: (<class 'int'>,)
```"
36579,TPU proto_buf error after migration from 1.3 to 2.1,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Debian 9
- TensorFlow installed from (source or binary):  GCP TF 2.1 image
- TensorFlow version (use command below):  TF v: 2.1.0 Keras v: 2.2.4-tf
- Python version: 3.5.3
- TPU software version is 2.1

I tried sample from here and it works: https://www.tensorflow.org/api_docs/python/tf/keras/losses/CategoricalCrossentropy

When I try to convert my own, **perfectly working TPU model**, from 1.3 to 2.1 using DistributedStrategy it fails.

When I run the below code in Jupyter, kernel dies when it goes to `fit`

```
from __future__ import absolute_import, division, print_function, unicode_literals

import tensorflow as tf
import tensorflow.keras as k

print('TF v:', tf.__version__, 'Keras v:', k.__version__)

resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://xx.xx.xx.xx:8470')
tf.config.experimental_connect_to_cluster(resolver)
tf.tpu.experimental.initialize_tpu_system(resolver)    

strategy = tf.distribute.experimental.TPUStrategy(resolver) 
```
```
with strategy.scope():
    
    model = k.Sequential()
    model.add(k.layers.Conv1D(filters=16,  kernel_size=2, activation = 'relu', input_shape=(window_size, 1) ))
    model.add(k.layers.Conv1D(filters=32,  kernel_size=2, activation = 'relu'))
    model.add(k.layers.Conv1D(filters=64,  kernel_size=2, activation = 'relu'))
    model.add(k.layers.Conv1D(filters=128, kernel_size=2, activation = 'relu'))
    model.add(k.layers.MaxPooling1D(pool_size=2))
    model.add(k.layers.Flatten())
    model.add(k.layers.Dense(cats, activation='softmax'))
    
    # summary
    print(model.metrics_names)
    print(model.summary())

    print('--')
    model.compile(optimizer='adam', loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),
                  metrics=['categorical_accuracy'])
    print('--')
```
```
model.fit(X, y, batch_size = window_size, shuffle=False, epochs = 5)
```

Output:
```
TF v: 2.1.0 Keras v: 2.2.4-tf
INFO:tensorflow:Initializing the TPU system: xxxxxxxxxx:8470
INFO:tensorflow:Initializing the TPU system: xxxxxxxxxx:8470
INFO:tensorflow:Clearing out eager caches
INFO:tensorflow:Clearing out eager caches
INFO:tensorflow:Finished initializing TPU system.
INFO:tensorflow:Finished initializing TPU system.
INFO:tensorflow:Found TPU system:
INFO:tensorflow:Found TPU system:
INFO:tensorflow:*** Num TPU Cores: 8
INFO:tensorflow:*** Num TPU Cores: 8
INFO:tensorflow:*** Num TPU Workers: 1
INFO:tensorflow:*** Num TPU Workers: 1
INFO:tensorflow:*** Num TPU Cores Per Worker: 8
INFO:tensorflow:*** Num TPU Cores Per Worker: 8
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)
INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)
```
```
['loss']
Model: ""sequential""
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv1d (Conv1D)              (None, 1279, 16)          48        
_________________________________________________________________
conv1d_1 (Conv1D)            (None, 1278, 32)          1056      
_________________________________________________________________
conv1d_2 (Conv1D)            (None, 1277, 64)          4160      
_________________________________________________________________
conv1d_3 (Conv1D)            (None, 1276, 128)         16512     
_________________________________________________________________
max_pooling1d (MaxPooling1D) (None, 638, 128)          0         
_________________________________________________________________
flatten (Flatten)            (None, 81664)             0         
_________________________________________________________________
dense (Dense)                (None, 4)                 326660    
=================================================================
Total params: 348,436
Trainable params: 348,436
Non-trainable params: 0
_________________________________________________________________
None
--
--
```
I can see this error in the console though - I am not sure where the proto-buf is coming and why did it work in TF 1.3 - hence I consider this a bug.
```
E0208 17:03:32.001652096    4567 proto_buffer_writer.h:83]   assertion failed: byte_count_ < total_size_
```

If I cut data 50 times the fit starts but fails immediately with different error:
```
NotFoundError: No registered 'Identity' OpKernel for 'TPU' devices compatible with node {{node Identity}}
```

Full traceback:
```
Train on 27720 samples
Epoch 1/5
    0/27720 [..............................] - ETA: 0s
---------------------------------------------------------------------------
NotFoundError                             Traceback (most recent call last)
<ipython-input-14-fae0bbeaa27e> in <module>
----> 1 model.fit(X, y, batch_size = window_size, shuffle=False, epochs = epochs_n)

/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)
    817         max_queue_size=max_queue_size,
    818         workers=workers,
--> 819         use_multiprocessing=use_multiprocessing)
    820 
    821   def evaluate(self,

/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/keras/engine/training_v2.py in fit(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)
    327                 training_data_iter._initializer  # pylint: disable=pointless-statement
    328               else:
--> 329                 training_data_iter = iter(training_dataset)
    330 
    331             training_result = run_one_epoch(

/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/distribute/input_lib.py in __iter__(self)
    563 
    564     worker_iterators = _create_iterators_per_worker(self._cloned_datasets,
--> 565                                                     self._input_workers)
    566     iterator = DistributedIterator(self._input_workers, worker_iterators,
    567                                    self._strategy)

/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/distribute/input_lib.py in _create_iterators_per_worker(worker_datasets, input_workers)
   1009       worker_devices = input_workers.compute_devices_for_worker(i)
   1010       iterator = _SingleWorkerDatasetIterator(worker_datasets[i], worker,
-> 1011                                               worker_devices)
   1012       iterators.append(iterator)
   1013   return iterators

/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/distribute/input_lib.py in __init__(self, dataset, worker, devices)
    862     self._worker = worker
    863     self._devices = devices
--> 864     self._make_iterator()
    865 
    866   def _make_iterator(self):

/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/distribute/input_lib.py in _make_iterator(self)
    868     with ops.device(self._worker):
    869       self._iterator = multi_device_iterator_ops.MultiDeviceIterator(
--> 870           self._dataset, self._devices)
    871 
    872   def get_next(self, device, name=None):

/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/data/ops/multi_device_iterator_ops.py in __init__(self, dataset, devices, max_buffer_size, prefetch_buffer_size, source_device)
    292                                     self._experimental_slack)
    293         if context.executing_eagerly():
--> 294           self._device_iterators.append(dataset_ops.make_one_shot_iterator(ds))
    295         else:
    296           self._device_iterators.append(

/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/data/ops/dataset_ops.py in make_one_shot_iterator(dataset)
   2479     return dataset._make_one_shot_iterator()  # pylint: disable=protected-access
   2480   except AttributeError:
-> 2481     return DatasetV1Adapter(dataset)._make_one_shot_iterator()  # pylint: disable=protected-access
   2482 
   2483 

/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/data/ops/dataset_ops.py in _make_one_shot_iterator(self)
   2057   def _make_one_shot_iterator(self):  # pylint: disable=missing-docstring
   2058     if context.executing_eagerly():
-> 2059       return iterator_ops.OwnedIterator(self)
   2060 
   2061     _ensure_same_dataset_graph(self)

/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/data/ops/iterator_ops.py in __init__(self, dataset, components, element_spec)
    592           context.context().device_spec.device_type != ""CPU""):
    593         with ops.device(""/cpu:0""):
--> 594           self._create_iterator(dataset)
    595       else:
    596         self._create_iterator(dataset)

/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/data/ops/iterator_ops.py in _create_iterator(self, dataset)
    617               output_types=self._flat_output_types,
    618               output_shapes=self._flat_output_shapes))
--> 619       gen_dataset_ops.make_iterator(ds_variant, self._iterator_resource)
    620       # Delete the resource when this object is deleted
    621       self._resource_deleter = IteratorResourceDeleter(

/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/ops/gen_dataset_ops.py in make_iterator(dataset, iterator, name)
   2703         pass  # Add nodes to the TensorFlow graph.
   2704     except _core._NotOkStatusException as e:
-> 2705       _ops.raise_from_not_ok_status(e, name)
   2706   # Add nodes to the TensorFlow graph.
   2707   _, _, _op, _outputs = _op_def_library._apply_op_helper(

/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/framework/ops.py in raise_from_not_ok_status(e, name)
   6604   message = e.message + ("" name: "" + name if name is not None else """")
   6605   # pylint: disable=protected-access
-> 6606   six.raise_from(core._status_to_exception(e.code, message), None)
   6607   # pylint: enable=protected-access
   6608 

/usr/local/lib/python3.5/dist-packages/six.py in raise_from(value, from_value)

NotFoundError: No registered 'Identity' OpKernel for 'TPU' devices compatible with node {{node Identity}}
	 (OpKernel was found, but attributes didn't match) Requested Attributes: T=DT_HALF
	.  Registered:  device='XLA_GPU_JIT'; T in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, ..., DT_HALF, DT_UINT32, DT_UINT64, DT_RESOURCE, DT_VARIANT]
  device='XLA_CPU_JIT'; T in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, ..., DT_HALF, DT_UINT32, DT_UINT64, DT_RESOURCE, DT_VARIANT]
  device='XLA_TPU_JIT'; T in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_BFLOAT16, DT_UINT32, DT_UINT64, DT_RESOURCE, DT_VARIANT]
  device='XLA_CPU'; T in [DT_UINT8, DT_QUINT8, DT_UINT16, DT_INT8, DT_QINT8, ..., DT_DOUBLE, DT_COMPLEX64, DT_COMPLEX128, DT_BOOL, DT_BFLOAT16]
  device='TPU'; T in [DT_INT32, DT_UINT32, DT_BFLOAT16, DT_FLOAT, DT_DOUBLE, DT_BOOL, DT_COMPLEX64, DT_INT64, DT_UINT64]
  device='TPU_SYSTEM'
  device='GPU'; T in [DT_HALF]
  device='GPU'; T in [DT_BFLOAT16]
  device='GPU'; T in [DT_FLOAT]
  device='GPU'; T in [DT_DOUBLE]
  device='GPU'; T in [DT_INT64]
  device='GPU'; T in [DT_UINT16]
  device='GPU'; T in [DT_INT16]
  device='GPU'; T in [DT_UINT8]
  device='GPU'; T in [DT_INT8]
  device='GPU'; T in [DT_COMPLEX64]
  device='GPU'; T in [DT_COMPLEX128]
  device='GPU'; T in [DT_VARIANT]
  device='DEFAULT'; T in [DT_STRING]
  device='DEFAULT'; T in [DT_VARIANT]
  device='DEFAULT'; T in [DT_RESOURCE]
  device='CPU'

	 [[Identity]] [Op:MakeIterator]
```

"
36577,TensorFlow2.0 keras.DenseFeatures can not deal with sparseTensor,"Hello, I find tf.keras.layers.DenseFeatures can not deal with SparseTensor, when using tensorflow 1.15: tf.feature_column.input_layer  without this problem

here is my problem code
```
fea['hisList'] = tf.io.VarLenFeature(tf.int64)
tmp = tf.feature_column.categorical_column_with_hash_bucket('hisList', 1000, dtype=tf.string)
emb = tf.feature_column.embedding_column(tmp , 12)
feature_layer = tf.keras.layers.DenseFeatures([emb])
```

when without using tf.keras.Input
```
    model = tf.keras.Sequential([
      feature_layer,
      tf.keras.layers.Dense(64, activation='relu'),
      tf.keras.layers.Dense(128, activation='relu'),
      tf.keras.layers.Dense(1, activation='sigmoid')
    ])
```
ValueError: All SparseTensor and RaggedTensor inputs must be explicitly declared using a keras.Input() with sparse=True or ragged=True. We found an undeclared input SparseTensor

when using tf.keras.Input
```
    Input = tf.keras.Input(shape=(32, ),sparse=True)
    model = tf.keras.Sequential([
      Input
      feature_layer,
      tf.keras.layers.Dense(64, activation='relu'),
      tf.keras.layers.Dense(128, activation='relu'),
      tf.keras.layers.Dense(1, activation='sigmoid')
    ])
```
ValueError: ('We expected a dictionary here. Instead we got: ', <tensorflow.python.framework.sparse_tensor.SparseTensor object at 0x00000210C00CCCF8>)"
36576,Windows 10 building from source: cl.exe failed: error executing command...,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 64 bit
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): source
- TensorFlow version: r2.0
- Python version: 3.7.6 (tags/v3.7.6:43364a7ae0, Dec 19 2019, 00:42:30) [MSC v.1916 64 bit (AMD64)]
- Installed using virtualenv? pip? conda?: pip
- Bazel version (if compiling from source): 0.26.1
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: release 10.0, V10.0.130 / cudnn-10.0-windows10-x64-v7.6.5.32, Note that I am trying to compile without cuda support.
- GPU model and memory: GTX 1060 6GB



**Describe the problem**
I am trying to compile a C++ library on this current machine, I will later import the lib on a work machine.
I followed the guidelines on: https://www.tensorflow.org/install/source_windows

**Provide the exact sequence of commands / steps that you executed before running into the problem**
More specifically:
1: do the pip3 installs.
2: download bazel 0.26.1 as an .exe, put it in my path
3: install msys2, add to path and run: pacman -S git patch unzip
4: *I did NOT* download visual studio 2019 since it says on the tested build configs that MSVC 2017 (which I have) should be used for r2.0
5: git clone and git checkout r2.0
6: python ./configure using all default and n to all other
7: running bazel build //tensorflow:tensorflow_dll_import_lib as stated on: https://github.com/tensorflow/tensorflow/pull/24963

After about an hour I got the error posted further down.

**Any other info / logs**
```
tensorflow/core/kernels/unique_op.cc(240): note: see reference to class template instantiation 'tensorflow::UniqueOp<bool,tensorflow::int32>' being compiled
ERROR: C:/users/jesper/documents/tensorflow/tensorflow/core/grappler/optimizers/data/BUILD:712:1: C++ compilation of rule '//tensorflow/core/grappler/optimizers/data:rebatch' failed (Exit 2): cl.exe failed: error executing command
  cd C:/users/jesper/_bazel_jesper/mqwe2qxk/execroot/org_tensorflow
  SET INCLUDE=C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\INCLUDE;C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\ATLMFC\INCLUDE;C:\Program Files (x86)\Windows Kits\10\include\10.0.17763.0\ucrt;C:\Program Files (x86)\Windows Kits\NETFXSDK\4.6.1\include\um;C:\Program Files (x86)\Windows Kits\10\include\10.0.17763.0\shared;C:\Program Files (x86)\Windows Kits\10\include\10.0.17763.0\um;C:\Program Files (x86)\Windows Kits\10\include\10.0.17763.0\winrt;
    SET PATH=C:\Program Files (x86)\Microsoft Visual Studio 14.0\Common7\IDE\CommonExtensions\Microsoft\TestWindow;C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\BIN\amd64;C:\Windows\Microsoft.NET\Framework64\v4.0.30319;C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\VCPackages;C:\Program Files (x86)\Microsoft Visual Studio 14.0\Common7\IDE;C:\Program Files (x86)\Microsoft Visual Studio 14.0\Common7\Tools;C:\Program Files (x86)\Microsoft Visual Studio 14.0\Team Tools\Performance Tools\x64;C:\Program Files (x86)\Microsoft Visual Studio 14.0\Team Tools\Performance Tools;C:\Program Files (x86)\Windows Kits\10\bin\x64;C:\Program Files (x86)\Windows Kits\10\bin\x86;C:\Program Files (x86)\Microsoft SDKs\Windows\v10.0A\bin\NETFX 4.6.1 Tools\x64\;;C:\Windows\system32
    SET PWD=/proc/self/cwd
    SET PYTHON_BIN_PATH=C:/Users/Jesper/AppData/Local/Programs/Python/Python37/python.exe
    SET PYTHON_LIB_PATH=C:/Users/Jesper/AppData/Local/Programs/Python/Python37/lib/site-packages
    SET RUNFILES_MANIFEST_ONLY=1
    SET TEMP=C:\Users\Jesper\AppData\Local\Temp
    SET TF2_BEHAVIOR=1
    SET TF_CONFIGURE_IOS=0
    SET TMP=C:\Users\Jesper\AppData\Local\Temp
  C:/Program Files (x86)/Microsoft Visual Studio 14.0/VC/bin/amd64/cl.exe /nologo /DCOMPILER_MSVC /DNOMINMAX /D_WIN32_WINNT=0x0601 /D_CRT_SECURE_NO_DEPRECATE /D_CRT_SECURE_NO_WARNINGS /bigobj /Zm500 /EHsc /wd4351 /wd4291 /wd4250 /wd4996 /I. /Ibazel-out/x64_windows-opt/bin /Iexternal/com_google_absl /Ibazel-out/x64_windows-opt/bin/external/com_google_absl /Iexternal/eigen_archive /Ibazel-out/x64_windows-opt/bin/external/eigen_archive /Iexternal/local_config_sycl /Ibazel-out/x64_windows-opt/bin/external/local_config_sycl /Iexternal/nsync /Ibazel-out/x64_windows-opt/bin/external/nsync /Iexternal/gif_archive /Ibazel-out/x64_windows-opt/bin/external/gif_archive /Iexternal/jpeg /Ibazel-out/x64_windows-opt/bin/external/jpeg /Iexternal/com_google_protobuf /Ibazel-out/x64_windows-opt/bin/external/com_google_protobuf /Iexternal/com_googlesource_code_re2 /Ibazel-out/x64_windows-opt/bin/external/com_googlesource_code_re2 /Iexternal/farmhash_archive /Ibazel-out/x64_windows-opt/bin/external/farmhash_archive /Iexternal/fft2d /Ibazel-out/x64_windows-opt/bin/external/fft2d /Iexternal/highwayhash /Ibazel-out/x64_windows-opt/bin/external/highwayhash /Iexternal/zlib_archive /Ibazel-out/x64_windows-opt/bin/external/zlib_archive /Iexternal/double_conversion /Ibazel-out/x64_windows-opt/bin/external/double_conversion /Iexternal/snappy /Ibazel-out/x64_windows-opt/bin/external/snappy /Iexternal/eigen_archive /Ibazel-out/x64_windows-opt/bin/external/eigen_archive /Iexternal/nsync/public /Ibazel-out/x64_windows-opt/bin/external/nsync/public /Iexternal/gif_archive /Ibazel-out/x64_windows-opt/bin/external/gif_archive /Iexternal/gif_archive/windows /Ibazel-out/x64_windows-opt/bin/external/gif_archive/windows /Iexternal/com_google_protobuf/src /Ibazel-out/x64_windows-opt/bin/external/com_google_protobuf/src /Iexternal/farmhash_archive/src /Ibazel-out/x64_windows-opt/bin/external/farmhash_archive/src /Iexternal/zlib_archive /Ibazel-out/x64_windows-opt/bin/external/zlib_archive /Iexternal/double_conversion /Ibazel-out/x64_windows-opt/bin/external/double_conversion /D__CLANG_SUPPORT_DYN_ANNOTATION__ /DEIGEN_MPL2_ONLY /DEIGEN_MAX_ALIGN_BYTES=64 /DEIGEN_HAS_TYPE_TRAITS=0 /DTF_USE_SNAPPY /showIncludes /MD /O2 /Oy- /DNDEBUG /wd4117 -D__DATE__=""redacted"" -D__TIMESTAMP__=""redacted"" -D__TIME__=""redacted"" /Gy /Gw -w -w -DWIN32_LEAN_AND_MEAN -DNOGDI /Fobazel-out/x64_windows-opt/bin/tensorflow/core/grappler/optimizers/data/_objs/rebatch/rebatch.obj /c tensorflow/core/grappler/optimizers/data/rebatch.cc
Execution platform: @bazel_tools//platforms:host_platform
tensorflow/core/grappler/optimizers/data/rebatch.cc(66): fatal error C1001: An internal error has occurred in the compiler.
(compiler file 'msc1.cpp', line 1468)
 To work around this problem, try simplifying or changing the program near the locations listed above.
Please choose the Technical Support command on the Visual C++
 Help menu, or open the Technical Support help file for more information
Internal Compiler Error in C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\bin\amd64\cl.exe.  You will be prompted to send an error report to Microsoft later.
INTERNAL COMPILER ERROR in 'C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\bin\amd64\cl.exe'
    Please choose the Technical Support command on the Visual C++
    Help menu, or open the Technical Support help file for more information
Target //tensorflow:tensorflow_dll_import_lib failed to build
INFO: Elapsed time: 3372.778s, Critical Path: 1297.23s
INFO: 2289 processes: 2289 local.
FAILED: Build did NOT complete successfully
```
"
36574,TensorFlow 2.0 - ValueError: tf.function-decorated,"Hello, I have a code (for MNIST dataset) in which I am doing the following steps:

1. Train model
1. Prune model (using ""tensorflow_model_optimization"" for say p%)
1. Create a mask of pruned model, so that the sparsity is maintained in subsequent steps
1. Reset weights of non-pruned model to random initialized weights when model was initialized

I do the following steps iteratively 'n' times.

The code can be found in:
https://github.com/arjun-majumdar/tensorflow_codes/blob/master/Recreating_Error.ipynb


For retraining a pruned model, I use 'GradientTape' along with mask. Now, the first time the model is trained using *train_one_step()* and *test_step()* functions which are @tf.function annotated functions, things work fine. But when I try to use them again (in cell 76 of Jupyter notebook), it gives me the error:

> ---------------------------------------------------------------------------
> ValueError                                Traceback (most recent call last)
> <ipython-input-76-9827a84843f1> in <module>
>      13     for x, y in train_dataset:
>      14         # train_step(x, y)
> ---> 15         train_one_step(model_gt_stripped, mask_model_stripped, optimizer, x, y)
>      16 
>      17     for x_t, y_t in test_dataset:
> 
> ~/.local/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py in __call__(self, *args, **kwds)
>     455 
>     456     tracing_count = self._get_tracing_count()
> --> 457     result = self._call(*args, **kwds)
>     458     if tracing_count == self._get_tracing_count():
>     459       self._call_counter.called_without_tracing()
> 
> ~/.local/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py in _call(self, *args, **kwds)
>     485       # In this case we have created variables on the first call, so we run the
>     486       # defunned version which is guaranteed to never create variables.
> --> 487       return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable
>     488     elif self._stateful_fn is not None:
>     489       # Release the lock early so that multiple threads can perform the call
> 
> ~/.local/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py in __call__(self, *args, **kwargs)
>    1820   def __call__(self, *args, **kwargs):
>    1821     """"""Calls a graph function specialized to the inputs.""""""
> -> 1822     graph_function, args, kwargs = self._maybe_define_function(args, kwargs)
>    1823     return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access
>    1824 
> 
> ~/.local/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py in _maybe_define_function(self, args, kwargs)
>    2148         graph_function = self._function_cache.primary.get(cache_key, None)
>    2149         if graph_function is None:
> -> 2150           graph_function = self._create_graph_function(args, kwargs)
>    2151           self._function_cache.primary[cache_key] = graph_function
>    2152         return graph_function, args, kwargs
> 
> ~/.local/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py in _create_graph_function(self, args, kwargs, override_flat_arg_shapes)
>    2039             arg_names=arg_names,
>    2040             override_flat_arg_shapes=override_flat_arg_shapes,
> -> 2041             capture_by_value=self._capture_by_value),
>    2042         self._function_attributes,
>    2043         # Tell the ConcreteFunction to clean up its graph once it goes out of
> 
> ~/.local/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)
>     913                                           converted_func)
>     914 
> --> 915       func_outputs = python_func(*func_args, **func_kwargs)
>     916 
>     917       # invariant: `func_outputs` contains only Tensors, CompositeTensors,
> 
> ~/.local/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py in wrapped_fn(*args, **kwds)
>     356         # __wrapped__ allows AutoGraph to swap in a converted function. We give
>     357         # the function a weak reference to itself to avoid a reference cycle.
> --> 358         return weak_wrapped_fn().__wrapped__(*args, **kwds)
>     359     weak_wrapped_fn = weakref.ref(wrapped_fn)
>     360 
> 
> ~/.local/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py in wrapper(*args, **kwargs)
>     903           except Exception as e:  # pylint:disable=broad-except
>     904             if hasattr(e, ""ag_error_metadata""):
> --> 905               raise e.ag_error_metadata.to_exception(e)
>     906             else:
>     907               raise
> 
> ValueError: in converted code:
> 
>     <ipython-input-44-d0ca499a4063>:29 train_one_step  *
>         optimizer.apply_gradients(zip(grad_mask_mul, model.trainable_variables))
>     /home/majumdar/.local/lib/python3.7/site-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py:435 apply_gradients
>         self._create_slots(var_list)
>     /home/majumdar/.local/lib/python3.7/site-packages/tensorflow_core/python/keras/optimizer_v2/adam.py:146 _create_slots
>         self.add_slot(var, 'm')
>     /home/majumdar/.local/lib/python3.7/site-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py:587 add_slot
>         initial_value=initial_value)
>     /home/majumdar/.local/lib/python3.7/site-packages/tensorflow_core/python/ops/variables.py:260 __call__
>         return cls._variable_v2_call(*args, **kwargs)
>     /home/majumdar/.local/lib/python3.7/site-packages/tensorflow_core/python/ops/variables.py:254 _variable_v2_call
>         shape=shape)
>     /home/majumdar/.local/lib/python3.7/site-packages/tensorflow_core/python/ops/variables.py:65 getter
>         return captured_getter(captured_previous, **kwargs)
>     /home/majumdar/.local/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py:413 invalid_creator_scope
>         ""tf.function-decorated function tried to create ""
> 
>     ValueError: tf.function-decorated function tried to create variables on non-first call.
> 
> 


The only way of avoiding this ""ValueError"" is by rerunning the *train_one_step()* and *test_step()* @tf.function annotated functions!

Why is this happening?

Thanks!"
36569,gcc4.9.0 build error:  insn does not satisfy its constraints,"HI :
    I want to use avx512 to compile tensorflow, so get update gcc from 4.8.5 to 4.9.0, tensorflow is 1.14.

bazel command:
```
bazel build tensorflow:libtensorflow_cc.so -c opt --copt=-march=native --copt=-mfpmath=both  --copt=-mfma --copt=-mavx --copt=-mavx2 --copt=-mavx512f
```

error:
```
external/fft2d/fft/fftsg.c: In function 'cftf162':
external/fft2d/fft/fftsg.c:3028:1: error: insn does not satisfy its constraints:
 }
 ^
(insn 488 487 335 2 (set (reg:DF 28 xmm7 [orig:225 D.7431 ] [225])
        (plus:DF (reg:DF 28 xmm7 [orig:225 D.7431 ] [225])
            (reg:DF 55 xmm18 [orig:225 D.7431 ] [225]))) external/fft2d/fft/fftsg.c:2937 764 {*fop_df_comm_mixed}
     (nil))
external/fft2d/fft/fftsg.c:3028:1: internal compiler error: in copyprop_hardreg_forward_1, at regcprop.c:775
0x82e7d8 _fatal_insn(char const*, rtx_def const*, char const*, int, char const*)
	../../gcc/rtl-error.c:109
0x82e7ff _fatal_insn_not_found(rtx_def const*, char const*, int, char const*)
	../../gcc/rtl-error.c:120
0x8098a1 copyprop_hardreg_forward_1
	../../gcc/regcprop.c:775
0x8098a1 copyprop_hardreg_forward
	../../gcc/regcprop.c:1110
0x8098a1 execute
	../../gcc/regcprop.c:1283
Please submit a full bug report,
with preprocessed source if appropriate.
Please include the complete backtrace with any bug report.
See <http://gcc.gnu.org/bugs.html> for instructions.
Target //tensorflow:libtensorflow_cc.so failed to build
Use --verbose_failures to see the command lines of failed build steps.
```

it seemd that fftsg.c may be has error, but when I compile fftsg.c only, there was no error.
```
gcc fftsg.c -mavx -mavx2 -mavx512f -march=native -mfma -lm //it's ok
```"
36568,[CI] PR merging and CI checks are not completed in time.,"> This template is for miscellaneous issues not covered by the other issue categories.
>
> For questions on how to work with TensorFlow, or support for problems that are not verified bugs in TensorFlow, please go to [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).
>
> If you are reporting a vulnerability, please use the [dedicated reporting process](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md).
> 
> For high-level discussions about TensorFlow, please post to discuss@tensorflow.org, for questions about the development or internal workings of TensorFlow, or if you would like to know how to contribute to TensorFlow, please post to developers@tensorflow.org.
> 
> 


This issue is not on bugs of Tensorflow. So, I chose the ""Issue: Other Issues"" category. I want to talk about on (1) the merging time of the PR and (2) the execution time of the CI checks (3) the build task cost of CI facilities in order to provide the below goals. 
- Reducing the waiting time of the Tensorflow contributors
- Helping the reviewers in order that they can concentrate on the productive reviews on submitted PRs

I summarized three cases among the lots of working PRs as follows. 

- (1) PR https://github.com/tensorflow/tensorflow/pull/36523: About the merging time
   - When the reviewer **frankchn** of two reviewers approved the PR, The CI checks work. Then, all checks are passed. It seems that the PR is still not merged due to the 1 pending reviewer (**gunan**). In this case, what are the criteria to merge this PR as a final step?
   - Screenshot:
      ![image](https://user-images.githubusercontent.com/82404/74029403-f7b3f980-49ef-11ea-81cc-c57e2673b4e2.png)

- (2) PR https://github.com/tensorflow/tensorflow/pull/33524 : About the execution cost of CI checks
   - It's weird. When **omalleyt12** approved the PR 33524, the three checks are still keeping the ""Waiting for status ...."" after 2hour. Why do not CI checks start a task? Does the CI system require 2hour+ to check the PR status?
      - Ubuntu CPU Expected — Waiting for status to be reported  Required
      - Ubuntu Sanity Expected — Waiting for status to be reported Required
      - import/copybara Expected — Waiting for status to be reported
   - Screenshot: 
      ![image](https://user-images.githubusercontent.com/82404/74030714-1071de80-49f3-11ea-9861-415988076e32.png)

- (3) PR https://github.com/tensorflow/tensorflow/pull/36526: About CI cost for Tensorflow build task
   - It seems that the build cost of Tensorflow is too big by introducing JAVA-based Bazel. Why Tensorflow community still not use Cmake (or Meson) instead of Bazel? Is a reason is to be used for the Bazel-based Android software platform by default? When CI checks run the build test, What is the CI/CD software to run the Baze-based build scripts (e.g., Windows, Mac, Ubuntu)? Is this Kbuilder?
   - Screenshot:
   ![image](https://user-images.githubusercontent.com/82404/74078873-24f5bb80-4a73-11ea-8858-11fb1e9670a2.png)


I want someone to tell me on a reason and the CI/CI direction of the Tensorflow community in case of (1) and (2) above.

And, what is the CI software used to run [scripts](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/tools/ci_build/presubmit) if the submitted PRs are correct or not?  For example, Hudson, Jenkins, Travis-CI, Circle-CI, QuickBuild, SWARM-CI, Bamboo, Buildbot, Continuum, Cruise Control, easyCIS, FinalBuilder, Mojo, Gump, Parabuild, Pulse, Sin, Teamcity, Team Foundation, and Zed.

"
36566,Issue,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): 
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): source
- TensorFlow version: Latest as of 2/7/2020
- Python version: 3.7.4
- Installed using virtualenv? pip? conda?: Tried with pip did not work tried with virtualenv did not work
- Bazel version (if compiling from source): NA
- GCC/Compiler version (if compiling from source):NA
- CUDA/cuDNN version:nA
- GPU model and memory: Rtx 1070 16 Gig of ram



**Describe the problem**

**Provide the exact sequence of commands / steps that you executed before running into the problem**
pip install virtualenv 
pip3 install --user --upgrade tensorflow

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

ERROR: Could not find a version that satisfies the requirement tensorflow (from versions: none)
ERROR: No matching distribution found for tensorflow"
36565,TFv1.15.0 run tf_cnn_benchmarks.py bug,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below):
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

**Describe the expected behavior**

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
36564,TFv1.15.0 run tf_cnn_benchmarks.py bug,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below):
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

**Describe the expected behavior**

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
36563,TFv1.15.0 run tf_cnn_benchmarks.py bug,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below):
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

**Describe the expected behavior**

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
36562,TFv1.15.0 run tf_cnn_benchmarks.py bug,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below):
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

**Describe the expected behavior**

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
36561,tfds.load() gives ConnectionResetError,"I am running tensorflow 2.0.0 (python 3.7.4) on a conda virtual environment on Mac. I am trying to get the IMDb dataset through the following command:

`import tensorflow_datasets as tfds

tfds.load('imdb_reviews/subwords8k', split=(tfds.Split.TRAIN, tfds.Split.TEST), with_info = True, as_supervised = True)`

to which I am getting the following error:

> ConnectionError: ('Connection aborted.', ConnectionResetError(54, 'Connection reset by peer'))

No support is available on stackoverflow or any other programming community site."
36559,How to efficiently update a tensor slice?,"Suppose we have `x = K.zeros((4, 6))`, and we wish to add 1 to row 0: `x[0] += 1`. The variable is created via `Layer`'s [`add_weight()`](https://github.com/keras-team/keras/blob/master/keras/engine/base_layer.py#L250) w/ `training=False`, so it isn't updated via backprop. What is the most _speed-efficient_ way to do so? 

<hr>

**Context**: I'm implementing recurrent batch normalization, with `moving_mean` and `moving_variance` variables distinct for each timestep in an RNN - each thus having a shape of `(units, timesteps)`. The goal is to update one `timesteps` slice per step via `K.moving_average_update()`. One approach is as follows:

```python
import tensorflow.keras.backend as K
units, timesteps = 4, 6
x = K.zeros((units, timesteps), dtype='float32', name='x')

x_new = x[:units, 0].assign(K.ones((units,), dtype='float32'))  # dummy example
K.set_value(x, K.get_value(x_new))
print(K.get_value(x))
```
```python
[[1. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0.]]
```
Looks good - except, a _new copy_ of `x` was created. In practice, we can have `timesteps > 100` (e.g. 120), so we are creating an array 120x larger than it needs to be, 120 times (1 / step), making it an `O(timesteps**2)` operation - as opposed to usual slicing, `O(timesteps)`.

Is there anything more efficient? Doesn't have to be `keras`, just at least `tf.keras`-friendly."
36557,Dynamically unrolled graphs ~7x slower than statically unrolled graphs within tf.function,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): wheel
- TensorFlow version (use command below): tf-nightly
- Python version: 3.7
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 7.x.x
- GPU model and memory: 4 x titan xp

**Describe the current behavior**

I have a snippet of code in my evaluation loop that unrolls a model's predictions. Graph is a dictionary which is updated by both the policy_model and dynamics_model. I call the recurrent loop in this pattern, once outside of the loop to ensure the tensors are set to the correct shape (necessary for tf.range) and then inside the loop to continue the unrolling:

```
    graph = dynamics_graph_constructor(model_inputs)
    graph = policy_model(graph)
    predicted_value = policy_normalization(graph)
    rollout_value = predicted_value
    graph = dynamics_model(graph)
    graph_updates = get_graph_delta(graph, 0)
    graph = update_graph(graph, model_inputs, graph_updates)

    for step in tf.range(agent_params[""search_depth""]-1):
        graph = policy_model(graph)
        predicted_value = policy_normalization(graph)
        rollout_value += predicted_value
        graph = dynamics_model(graph)
         graph_updates = get_graph_delta(graph, 0)
        graph = update_graph(graph, model_inputs, graph_updatesl)
```

If I change tf.range to range, I see an approximately 7x speedup. Is this normal? This seems like a huge performance penalty when using tf.while loops, even when using autograph.
"
36556,"TensorFlow should support importing submodules, like a normal Python package","**System information**
- TensorFlow version (you are using): 2.x
- Are you willing to contribute it (Yes/No): No

**Describe the feature and the current behavior/state.**

TensorFlow 1.x supports importing submodules, e.g., `import tensorflow.io`

On TensorFlow 2.x this raises `ModuleNotFoundError: No module named 'tensorflow.io'`. Instead you have to import `tensorflow`, at which point the `io` module is directly available. This is both misleading and highly non-standard for Python.

If you not want to support direct importing of submodules, then perhaps they shouldn't be called modules in the online docs?
https://www.tensorflow.org/api_docs/python/tf/io

**Will this change the current api? How?** Yes, but it would be fully backwards compatible.

**Who will benefit with this feature?** Anyone who expects TensorFlow to work like a normal Python package."
36554,reduce_euclidean_norm false results,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Google colab
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): Google colab
- TensorFlow version (use command below): 1.15.0
- Python version: 3.6.9
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: 10.1.243
- GPU model and memory: N/A

**Describe the current behavior**
reduce_euclidean_norm might return false results?
For example, the following three snippets are all using reduce_euclidean_norm, but all return wrong results (return 4; should return sqrt(17)).

x = tf.constant([[1, 2, 3], [1, 1, 1]])
y = tf.math.reduce_euclidean_norm(x)
with tf.Session() as sess:  print(y.eval()) 
returns 4, should return numerical value of sqrt(17)

x = tf.constant([[1, 2, 3], [1, 1, 1]])
y = tf.compat.v1.math.reduce_euclidean_norm(x)
with tf.Session() as sess:  print(y.eval()) 
returns 4, should return numerical value of sqrt(17)

x = tf.constant([[1, 2, 3], [1, 1, 1]])
y = tf.compat.v2.math.reduce_euclidean_norm(x)
with tf.Session() as sess:  print(y.eval()) 
returns 4, should return numerical value of sqrt(17)


**Describe the expected behavior**

from tensorflow docs
https://www.tensorflow.org/api_docs/python/tf/math/reduce_euclidean_norm
x = tf.constant([[1, 2, 3], [1, 1, 1]])
tf.reduce_euclidean_norm(x)  # sqrt(17)

**Code to reproduce the issue**
Attached above. 

**Other info / logs**
N/A

Thank you so much!"
36553, output 'tensorflow/core/kernels/_objs/reduction_ops_gpu/tensorflow/core/kernels/reduction_ops_half_mean_sum.cu.pic.o' was not created,"### System information
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 18.04
- **Python version**:3.6.6
- **Bazel version (if compiling from source)**:0.11.1
- **GCC/Compiler version (if compiling from source)**:7.3.0
- **CUDA/cuDNN version**:CUDA10.0  , cuDNN 7
- **GPU model and memory**:GTX1050
- **Exact command to reproduce**:
```

### Describe the problem 
While I run the code '''' from https://github.com/VLOGroup/mri-variationalnetwork

I'm using Ubuntu18.04,
bazel 0.11.1
Cuda10.0
cuDNN7.4

I think some attributes not compile in the file "" paramdefination.py""
```
def plt_act_function(x, phi):
    my_dpi = 96.
    fig = matplotlib.figure.Figure(figsize=(350/my_dpi, 250/my_dpi), dpi=my_dpi)
    ax = fig.add_subplot(1, 1, 1)
    images = []
    for s in range(phi.shape[0]):
        images_stage = []
        for i in range(phi.shape[1]):
            ax.clear()
            ax.plot(x, phi[s, i, :])
            if fig.canvas is None:
                FigureCanvasAgg(fig)
            fig.canvas.draw()
            img_data = np.fromstring(fig.canvas.tostring_rgb(), dtype=np.uint8, sep='')
            img_data = img_data.reshape(fig.canvas.get_width_height()[::-1] + (3,))
            images_stage.append(img_data)
        images.append(images_stage)
    return np.asarray(images)
```

This is the following issue:

2020-02-09 14:45:41.165513: W tensorflow/core/framework/op_kernel.cc:1198] Unknown: AttributeError: 'FigureCanvasBase' object has no attribute 'tostring_rgb'
Traceback (most recent call last):
File ""/home/vivi/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1350, in _do_call
return fn(*args)
File ""/home/vivi/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1329, in _run_fn
status, run_metadata)
File ""/home/vivi/.local/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py"", line 473, in exit
c_api.TF_GetCode(self.status.status))
tensorflow.python.framework.errors_impl.UnknownError: AttributeError: 'FigureCanvasBase' object has no attribute 'tostring_rgb'
[[Node: activation_plot/PyFunc = PyFunc[Tin=[DT_FLOAT, DT_FLOAT], Tout=[DT_UINT8], token=""pyfunc_2"", _device=""/job:localhost/replica:0/task:0/device:CPU:0""](activation_plot/strided_slice/_371, activation_plot/Reshape_1/_373)]]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
File ""train_mri_vn.py"", line 315, in
coord.join(enqueue_threads_data)
File ""/home/vivi/.local/lib/python3.6/site-packages/tensorflow/python/training/coordinator.py"", line 387, in join
six.reraise(*self._exc_info_to_raise)
File ""/home/vivi/.local/lib/python3.6/site-packages/six.py"", line 703, in reraise
raise value
File ""train_mri_vn.py"", line 295, in
options=run_options, run_metadata=run_metadata)
File ""/home/vivi/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 895, in run
run_metadata_ptr)
File ""/home/vivi/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1128, in _run
feed_dict_tensor, options, run_metadata)
File ""/home/vivi/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1344, in _do_run
options, run_metadata)
File ""/home/vivi/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py"", line 1363, in _do_call
raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.UnknownError: AttributeError: 'FigureCanvasBase' object has no attribute 'tostring_rgb'
[[Node: activation_plot/PyFunc = PyFunc[Tin=[DT_FLOAT, DT_FLOAT], Tout=[DT_UINT8], token=""pyfunc_2"", _device=""/job:localhost/replica:0/task:0/device:CPU:0""](activation_plot/strided_slice/_371, activation_plot/Reshape_1/_373)]]

Caused by op 'activation_plot/PyFunc', defined at:
File ""train_mri_vn.py"", line 176, in
vn.paramdefinitions.add_activation_function_params(params, reg_config['activation1'])
File ""/home/vivi/mri-variationalnetwork-master/vn/paramdefinitions.py"", line 70, in add_activation_function_params
phi_img = tf.py_func(plt_act_function, [x_plt_tf[:, 0], phi_plt], tf.uint8)
File ""/home/vivi/.local/lib/python3.6/site-packages/tensorflow/python/ops/script_ops.py"", line 300, in py_func
func=func, inp=inp, Tout=Tout, stateful=stateful, eager=False, name=name)
File ""/home/vivi/.local/lib/python3.6/site-packages/tensorflow/python/ops/script_ops.py"", line 209, in _internal_py_func
input=inp, token=token, Tout=Tout, name=name)
File ""/home/vivi/.local/lib/python3.6/site-packages/tensorflow/python/ops/gen_script_ops.py"", line 93, in _py_func
""PyFunc"", input=input, token=token, Tout=Tout, name=name)
File ""/home/vivi/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py"", line 787, in _apply_op_helper
op_def=op_def)
File ""/home/vivi/.local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 3160, in create_op
op_def=op_def)
File ""/home/vivi/.local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 1625, in init
self._traceback = self._graph._extract_stack() # pylint: disable=protected-access

UnknownError (see above for traceback): AttributeError: 'FigureCanvasBase' object has no attribute 'tostring_rgb'
[[Node: activation_plot/PyFunc = PyFunc[Tin=[DT_FLOAT, DT_FLOAT], Tout=[DT_UINT8], token=""pyfunc_2"", _device=""/job:localhost/replica:0/task:0/device:CPU:0""](activation_plot/strided_slice/_371, activation_plot/Reshape_1/_373)]]"
36552,TFv1.15.0 run tf_cnn_benchmarks.py bug,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No
- TensorFlow installed from (source or binary): From source
- TensorFlow version (use command below): v1.15.0
- Python version: Python 3.6.9
- Bazel version (if compiling from source): Bazel 0.26.1
- GCC/Compiler version (if compiling from source): gcc-7.4.0
- CUDA/cuDNN version: CUDA 10.0, cuDNN 7.4.1.5
- GPU model and memory: Tesla V100, 32510MB

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

`v1.15.0-0-g590d6eef7e 1.15.0`

**Describe the current behavior**
While running `python3 tf_cnn_benchmarks.py --num_gpus=1 --batch_size=32 --model=resnet50 --variable_update=parameter_server`, output error:
```
Traceback (most recent call last):
  File ""tf_cnn_benchmarks.py"", line 29, in <module>
    import benchmark_cnn
  File ""/root/benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py"", line 51, in <module>
    from models import model_config
  File ""/root/benchmarks/scripts/tf_cnn_benchmarks/models/model_config.py"", line 152, in <module>
    from tensorflow.contrib import slim  # pylint: disable=unused-import
  File ""<frozen importlib._bootstrap>"", line 1007, in _handle_fromlist
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/__init__.py"", line 50, in __getattr__
    module = self._load()
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/__init__.py"", line 44, in _load
    module = _importlib.import_module(self.__name__)
  File ""/usr/lib/python3.6/importlib/__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/__init__.py"", line 54, in <module>
    from tensorflow.contrib import image
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/image/__init__.py"", line 55, in <module>
    from tensorflow.contrib.image.python.ops.dense_image_warp import dense_image_warp
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/image/__init__.py"", line 57, in <module>
    from tensorflow.contrib.image.python.ops.distort_image_ops import adjust_hsv_in_yiq
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/image/python/ops/distort_image_ops.py"", line 29, in <module>
    resource_loader.get_path_to_datafile('_distort_image_ops.so'))
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/util/loader.py"", line 56, in load_op_library
    ret = load_library.load_op_library(path)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/load_library.py"", line 61, in load_op_library
    lib_handle = py_tf.TF_LoadLibrary(library_filename)
tensorflow.python.framework.errors_impl.NotFoundError: /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/image/python/ops/_distort_image_ops.so: undefined symbol: _ZN4absl5Mutex10ReaderLockEv
python3 tf_cnn_benchmarks.py --num_gpus=1 --batch_size=32 --model=resnet50   3.14s user 2.78s system 291% cpu 2.029 total
```

**Describe the expected behavior**
Successfully run the example code.

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.
Following the command below, `https://github.com/tensorflow/benchmarks/tree/master/scripts/tf_cnn_benchmarks#getting-started`

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
36550,TF_CONFIG is used even though a ClusterResolver was passed,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Mint
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.1.0
- Python version: 3.7.4

**Describe the current behavior**

I'm using a MultiWorkerMirroredStrategy with a cluster_resolver to avoid having to define the (to me obscure) TF_CONFIG env variable. But even though TF_CONFIG is used: https://github.com/tensorflow/tensorflow/blob/925be1049d191f25aa41c26db03205935b2e8582/tensorflow/python/distribute/distribute_coordinator.py#L752

This leads to output like:
> WARNING:tensorflow:Skipped evaluation since `eval_fn` is not passed in.

Which can only happen when no cluster-spec was found: https://github.com/tensorflow/tensorflow/blob/925be1049d191f25aa41c26db03205935b2e8582/tensorflow/python/distribute/distribute_coordinator.py#L778-L787

**Describe the expected behavior**

There should be no need to define this env variable and it should not be used but everything should come from the cluster resolver

**Code to reproduce the issue**

https://www.tensorflow.org/tutorials/distribute/multi_worker_with_keras#train_the_model_with_multiworkermirroredstrategy but with SlurmClusterResolver"
36548,accuracy loss when running inference on edge TPU with keras neural network,"**System information**
- OS Platform and Distribution : Debian 10.2.0
- TensorFlow installed from : https://www.tensorflow.org/install
- TensorFlow version : 2.0


Hi, I'm a student at the University of Bologna ( Italy) and I'm using the Google Coral USB accelerator for my thesis. I realized a keras neural network that classifies my data in four classes and the accuracy I get is roughly 97%. I performed a full integer post- training quantization since keras networks don't support quantization-aware training. I followed the guide on TensorFlow site but I had problems running inference on the edge tpu . In particular my network undergoes an accuracy loss when the model is converted to a `tensorflowlite` one ( the accuracy drops to roughly the 25%) . This is due to quantization since the `tensorflowlite` model without quantization that runs on my pc is not affected by the conversion. I tried to scale my input data in a range [0, 255] with `MinMaxScaler` but in this case , even if the accuracy of the `tensorflowlite` quantized model matches the one of the not converted one , the results are not satisfactory since the accuracy of the network itself is low. I wonder if you could help me solve this problem. Perhaps the values on my dataset are too low and the quantization fails to convert `float32` into `uint8` without information loss. Below you'll find my python code.
```
from __future__ import absolute_import, division, print_function, unicode_literals
import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
from numpy import loadtxt
from tensorflow.keras.models import Sequential 
from tensorflow.keras.layers import Dense
from sklearn.model_selection import train_test_split
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.optimizers import RMSprop
from sklearn.preprocessing import StandardScaler,MinMaxScaler,Normalizer
from sklearn.metrics import confusion_matrix, accuracy_score
from tensorflow.keras.callbacks import EarlyStopping
import os
import time
import tflite_runtime.interpreter as tflite
import collections
import operator

""""""Functions to work with classification models.""""""




Class = collections.namedtuple('Class', ['id', 'score'])




def input_tensor(interpreter):
  """"""Returns input tensor view as numpy array of shape (height, width, 3).""""""
  tensor_index = interpreter.get_input_details()[0]['index']
  return interpreter.tensor(tensor_index)()[0]

def output_tensor(interpreter):
  """"""Returns dequantized output tensor.""""""
  output_details = interpreter.get_output_details()[0] 
  output_data = np.squeeze(interpreter.tensor(output_details['index'])()) #Remove single-dimensional entries from the shape of an array.
  scale, zero_point = output_details['quantization']
  return scale * (output_data - zero_point)


def set_input(interpreter, data):
  """"""Copies data to input tensor.""""""
  input_tensor(interpreter)[:] = data
  return data   


def get_output(interpreter, top_k=1, score_threshold=0.0):
  """"""Returns no more than top_k classes with score >= score_threshold.""""""
  scores = output_tensor(interpreter)
  classes = [
      Class(i, scores[i])
      for i in np.argpartition(scores, -top_k)[-top_k:]
      if scores[i] >= score_threshold
  ]
  return sorted(classes, key=operator.itemgetter(1), reverse=True)

#load the dataset


Modelli_Prova01_Nom01_Acc1L = loadtxt(r'/home/utente/Scrivania/csvtesi/Modelli_Prova01_Nom01_Acc1L.csv',delimiter=',')
Modelli_Prova02_Nom01_Acc1L = loadtxt(r'/home/utente/Scrivania/csvtesi/Modelli_Prova02_Nom01_Acc1L.csv',delimiter=',')
Modelli_Prova03_Nom01_Acc1L = loadtxt(r'/home/utente/Scrivania/csvtesi/Modelli_Prova03_Nom01_Acc1L.csv',delimiter=',')
Modelli_Prova04_Nom01_Acc1L = loadtxt(r'/home/utente/Scrivania/csvtesi/Modelli_Prova04_Nom01_Acc1L.csv',delimiter=',')
Modelli_Prova05_Nom01_Acc1L = loadtxt(r'/home/utente/Scrivania/csvtesi/Modelli_Prova05_Nom01_Acc1L.csv',delimiter=',')

time_start = time.perf_counter()



#split x and y data (train and test)

Acc1L01_train,Acc1L01_test = train_test_split(Modelli_Prova01_Nom01_Acc1L ,test_size=0.015,random_state=42)
Acc1L02_train,Acc1L02_test = train_test_split(Modelli_Prova02_Nom01_Acc1L,test_size=0.3,random_state=42)
Acc1L03_train,Acc1L03_test = train_test_split(Modelli_Prova03_Nom01_Acc1L,test_size=0.3,random_state=42)
Acc1L04_train,Acc1L04_test = train_test_split(Modelli_Prova04_Nom01_Acc1L,test_size=0.3,random_state=42)
Acc1L05_train,Acc1L05_test = train_test_split(Modelli_Prova05_Nom01_Acc1L,test_size=0.15,random_state=42)
Y1_train= np.zeros([len(Acc1L01_train)+len(Acc1L05_train),1]) 
Y2_train= np.ones([len(Acc1L02_train),1]) 
Y3_train= np.ones([len(Acc1L03_train),1]) +1
Y4_train= np.ones([len(Acc1L04_train),1]) +2
Y1_test= np.zeros([len(Acc1L01_test)+len(Acc1L05_test),1]) 
Y2_test= np.ones([len(Acc1L02_test),1])  
Y3_test= np.ones([len(Acc1L03_test),1]) +1
Y4_test= np.ones([len(Acc1L04_test),1]) +2

xAcc1L_train = np.concatenate((Acc1L01_train,Acc1L05_train,Acc1L02_train,Acc1L03_train,Acc1L04_train),axis=0)
xAcc1L_train=MinMaxScaler([0,255]).fit_transform(xAcc1L_train)
#xAcc1L_train=StandardScaler().fit_transform(xAcc1L_train)
#xAcc1L_train=Normalizer().fit_transform(xAcc1L_train)
#xAcc1L_train=np.transpose(xAcc1L_train)
yAcc1L_train = np.concatenate((Y1_train,Y2_train,Y3_train,Y4_train),axis=0)
xAcc1L_test = np.concatenate((Acc1L01_test,Acc1L05_test,Acc1L02_test,Acc1L03_test,Acc1L04_test),axis=0)
xAcc1L_test=Normalizer().fit_transform(xAcc1L_test)
#xAcc1L_test=MinMaxScaler([0,255]).fit_transform(xAcc1L_test)
#xAcc1L_test=StandardScaler().fit_transform(xAcc1L_test)
#xAcc1L_test=np.transpose(xAcc1L_test)
yAcc1L_test = np.concatenate((Y1_test,Y2_test,Y3_test,Y4_test),axis=0)
#1 hot encode y
one_hot_labelsAcc1L =to_categorical(yAcc1L_train, num_classes=4)
one_hot_labelsAcc1L_test = to_categorical(yAcc1L_test, num_classes=4)
#fit the model
model = Sequential()
model.add(Dense(300, activation='relu', input_dim=30))
model.add(Dense(4, activation='softmax'))
model.compile(optimizer='rmsprop',
              loss='categorical_crossentropy',
              metrics=['accuracy'])
model.summary()
es1 = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=100)
es2 = EarlyStopping(monitor='val_accuracy', mode='max', verbose=1, patience=100)

history=model.fit(xAcc1L_train, one_hot_labelsAcc1L,validation_data=(xAcc1L_test,one_hot_labelsAcc1L_test),epochs=500, batch_size=30, verbose=1, callbacks=[es1,es2])
#history=model.fit(tf.cast(xAcc1L_train, tf.float32), one_hot_labelsAcc1L,validation_data=(tf.cast(xAcc1L_test, tf.float32),one_hot_labelsAcc1L_test),epochs=500, batch_size=30, verbose=1, callbacks=[es1,es2])
time_elapsed = (time.perf_counter() - time_start)
print (""%5.1f secs "" % (time_elapsed))

start=time.monotonic()
_, accuracy = model.evaluate(xAcc1L_test, one_hot_labelsAcc1L_test, batch_size=30, verbose=1)
#_, accuracy = model.evaluate(tf.cast(xAcc1L_test, tf.float32), one_hot_labelsAcc1L_test, batch_size=30, verbose=1)
print(accuracy)
inference_time = time.monotonic() - start
print('%.1fms ' % (inference_time * 1000))

# summarize history for accuracy
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper left')
plt.show()
# summarize history for loss
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'test'], loc='upper right')
plt.show()  
#predicted labels
predictions = model.predict(xAcc1L_test)
y_pred = (predictions > 0.5)
matrix = confusion_matrix(one_hot_labelsAcc1L_test.argmax(axis=1), y_pred.argmax(axis=1))
print('confusion matrix = \n',matrix)
print(""Accuracy:"",accuracy_score(one_hot_labelsAcc1L_test.argmax(axis=1), y_pred.argmax(axis=1)))



mod01=model.save('/home/utente/Scrivania/csvtesi/rete_Nom01.h5')

#convert the model


#representative dataset       
train_ds = tf.data.Dataset.from_tensor_slices(
    (tf.cast(xAcc1L_train, tf.float32))).batch(1)
print(train_ds)

def representative_dataset_gen():
    for input_value in train_ds: 
        yield [input_value]

print(model.layers[0].input_shape)

#integer post-training quantization

converter = tf.compat.v1.lite.TFLiteConverter.from_keras_model_file('/home/utente/Scrivania/csvtesi/rete_Nom01.h5') #all operations mapped on edge tpu
#converter = tf.lite.TFLiteConverter.from_keras_model(model)
converter.optimizations = [tf.lite.Optimize.DEFAULT]
converter.representative_dataset = representative_dataset_gen
print(converter.representative_dataset)
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]
converter.inference_input_type = tf.uint8
converter.inference_output_type = tf.uint8
tflite_quant_model = converter.convert()
open('/home/utente/Scrivania/csvtesi/rete_Nom01_quant.tflite', ""wb"").write(tflite_quant_model)



#compiler compila il modello quantizzato tflite per edge tpu
os.system(""edgetpu_compiler \'/home/utente/Scrivania/csvtesi/rete_Nom01_quant.tflite'"")


#interpret the model

interpreter = tf.lite.Interpreter('/home/utente/Scrivania/csvtesi/rete_Nom01_quant_edgetpu.tflite',experimental_delegates=[tflite.load_delegate('libedgetpu.so.1')])


interpreter.allocate_tensors()
idt=print(interpreter.get_input_details())
odt=print(interpreter.get_output_details())



for j in range(5):
  start = time.monotonic()
  o_test=np.arange(len(xAcc1L_test[:,0]))
  o_test=o_test[:,np.newaxis]
  for i in range (len(xAcc1L_test[:,0])):
    input=set_input(interpreter, xAcc1L_test[i,:])
    #print(""inference input    %s"" % input)
    interpreter.invoke()
    classes = get_output(interpreter,4)
    output = interpreter.get_tensor(interpreter.get_output_details()[0]['index'])#/255 con edgetpu
    #print(""inference output    %s"" % output)
    #print(""inference classes      %s"" % classes)
    a=np.array([one_hot_labelsAcc1L_test[i,:].argmax(axis=0)])
    b=np.array(output.argmax(axis=1))
    o_test[i]=b
    #if a==b:
      #print('good classification')
    #else: 
      #print('bad classification')
  inference_time = time.monotonic() - start
  print('%.1fms ' % (inference_time * 1000))
  #print(o_test)
  print(""Accuracy:"",accuracy_score(yAcc1L_test,o_test))
```
My input train dataset is part of csv files and it's a matrix of dimensions = (1756,30) and my input test one is a matrix of (183,30). This is how the data looks like (first two rows):
```
[[-0.283589    -0.0831421  -0.199936   -0.144523   -0.215593   -0.199029   0.0300179   -0.0299262  -0.0759612  -0.0349733  0.102882    -0.00470235 -0.14267    -0.116636   -0.0842867  -0.124638   -0.107917   -0.0995006  -0.222817   -0.256093   -0.121859   -0.130829   -0.186091   -0.174511   -0.0715493  -0.0595195  -0.054914   -0.0362971  -0.0286576  -0.0409128],
[-0.226151  -0.0386177  -0.16834    -0.0768908  -0.166611   -0.161028   0.0493133   -0.00515959 -0.0362308  -0.00723895 0.105943    -0.010825   -0.142335   -0.10863    -0.0634201  -0.112928   -0.0927994  -0.0556194  -0.180721   -0.218341   -0.0934449  -0.100047   -0.134569   -0.119806   -0.0265749  -0.044841   -0.0538225  -0.017408   -0.00528171 -0.0248457]]
```
P.S. I'm using the TensorFlow 2.0 version. I read that there could be problems with this version during the conversion phase but , as you can see in the code, I used a converter compatible with the previous version ` (converter=tf.compat.v1.lite.TFliteConverter.from_keras_model_file()) `.
I also tried to use the downgraded version of TensorFlow( v 1.15) in my code but it didn't make any difference.
"
36547,Documentation error for tf.signal.frame ,"## URL(s) with the issue:
https://github.com/tensorflow/tensorflow/blob/cf7fcf164c9846502b21cebb7d3d5ccf6cb626e8/tensorflow/python/ops/signal/shape_ops.py#L55-L199

Documentation:
https://www.tensorflow.org/api_docs/python/tf/signal/frame

## Description of issue (what needs changing):

In the following example, the count of frames generated with pad_end=False is incorrect
    
    # A batch size 3 tensor of 9152 audio samples.
    audio = tf.random.normal([3, 9152])

    # Compute overlapping frames of length 512 with a step of 180 (frames overlap
    # by 332 samples). By default, only 50 frames are generated since the last
    # 152 samples do not form a full frame.
    frames = tf.signal.frame(audio, 512, 180)
    frames.shape.assert_is_compatible_with([3, 50, 512])

In fact, only 49 frames are generated with pad_true=False (the default).

### Clear description

Suppose we are given a tensor x with x.shape[-1] == N, a frame_length == K, and a frame_step == k.

To compute tf.signal.frame(x, frame_length, frame_step) (here default axis=-1 and pad_end=False), we could equivalently stack along axis -2 the following list of slices:

    [x[..., 0:K],
     x[..., k:K+k],
     x[..., 2*k:K+2*k],
     x[..., 3*k:K+3*k],
     ...
     x[..., j*k:K+j*k]]

where j is the maximum integer such that K+j*k <= N.

We can compute that j = (N - K) // k, so the number of slices in this list is j+1 = 1 + (N - K) // k. 

In the example here, N = 9152, K=512, k=180, so:

    j+1 = 1 + (9152-512) // 180 = 1 + 8640 // 180 = 1+48 = 49

Thus in the example given, the return shape should be [3, 49, 512], not [3, 50, 512]. Attached is a screenshot showing that this is indeed the behavior of tf.signal.frame, so it is an error in the documentation not in the code.

![tf signal frame](https://user-images.githubusercontent.com/47697814/74045729-497e6480-499b-11ea-9107-12305554ee18.png)

### Submit a pull request?

I am planning to submit a pull request."
36544,tpu closed error ,"when I run tpu on colab, I meet error 
Epoch 1/6
WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.
WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.
WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.
WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.
 1/25 [>.............................] - ETA: 28:10
---------------------------------------------------------------------------
UnavailableError                          Traceback (most recent call last)
<ipython-input-25-7386834902ba> in <module>()
     94 
     95 
---> 96         model.fit(train_dataset,epochs=6)
     97 
     98 

10 frames
/usr/local/lib/python3.6/dist-packages/six.py in raise_from(value, from_value)

UnavailableError: Socket closed
Additional GRPC error information:
{""created"":""@1581089996.572389050"",""description"":""Error received from peer"",""file"":""external/grpc/src/core/lib/surface/call.cc"",""file_line"":1039,""grpc_message"":""Socket closed"",""grpc_status"":14}"
36543,ImportError: cannot import name 'feature_column_v2',"I found below issue when trying to import tensorflow-hub - have no clue with this issue and appreciate your help.

ImportError                               Traceback (most recent call last)
<ipython-input-8-9ecaff1b481d> in <module>()
      1 import tensorflow as tf
----> 2 import tensorflow_hub as hub

C:\Program Files\Anaconda3\envs\tensorflow_sessions\lib\site-packages\tensorflow_hub\__init__.py in <module>()
     27 # error message is thrown instead of an obscure error of missing
     28 # symbols at executing the imports.
---> 29 from tensorflow_hub.estimator import LatestModuleExporter
     30 from tensorflow_hub.estimator import register_module_for_export
     31 from tensorflow_hub.feature_column import image_embedding_column

C:\Program Files\Anaconda3\envs\tensorflow_sessions\lib\site-packages\tensorflow_hub\estimator.py in <module>()
     23 from absl import logging
     24 import tensorflow as tf
---> 25 from tensorflow_hub import tf_utils
     26 from tensorflow_hub import tf_v1
     27 

C:\Program Files\Anaconda3\envs\tensorflow_sessions\lib\site-packages\tensorflow_hub\tf_utils.py in <module>()
     31 # depending on TensorFlow internal implementation details.
     32 # pylint: disable=g-direct-tensorflow-import
---> 33 from tensorflow.python.feature_column import feature_column_v2
     34 # pylint: enable=g-direct-tensorflow-import"
36542,TF 2.1.0 crashes during shape inference,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): standard docker image with ubuntu 18.04
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 
- Python version: v2.1.0-rc2-17-ge5bf8de 2.1.0
- CUDA/cuDNN version: 10.1.243-1 / 7.6.4.38-1+cuda10.1
- GPU model and memory: titan rtx 24220MiB

**Describe the current behavior**
Using rather large complex model with lots of tf.TensorArray operations ends up with the crash. 100% reproducible, but overall codebase (python only) is quite large and input pipeline is tricky.

**Code to reproduce the issue**
This is the class I use to operate with tensor arrays, which seems to be a reason for crash.
It works in evaluation mode though
```
class RNNBatch:
    def __init__(self, rnn_layer, rnn_batch_size, true_words, true_lengths, training):
        self.rnn_batch_size = rnn_batch_size
        self.training = training
        self.dtype = tf.float32

        self.rnn_layer = rnn_layer
        max_sequence_len = rnn_layer.max_sequence_len
        dictionary_size = rnn_layer.dictionary_size

        self.true_words = true_words
        self.true_lengths = true_lengths

        self.written = 0
        self.rnn_processed_start = 0

        self.output_written = 0

    def run(self, arrays):
        selected_features = arrays['selected_features'].concat()

        batch_size = tf.shape(selected_features)[0]
        states_h = tf.zeros((batch_size, self.rnn_layer.num_rnn_units), dtype=self.dtype)
        states_c = tf.zeros((batch_size, self.rnn_layer.num_rnn_units), dtype=self.dtype)
        states = [states_h, states_c]

        tw = self.true_words[self.rnn_processed_start : self.rnn_processed_start + self.written, ...]
        tl = self.true_lengths[self.rnn_processed_start : self.rnn_processed_start + self.written, ...]

        out, out_ar = self.rnn_layer(selected_features, tw, tl, states, self.training)

        arrays['outputs'] = arrays['outputs'].write(self.output_written, out)
        arrays['outputs_ar'] = arrays['outputs'].write(self.output_written, out_ar)
        self.output_written += 1

        self.rnn_processed_start += self.written
        self.written = 0

        return arrays

    def feed_crop(self, cropped_features, arrays):
        arrays['selected_features'] = arrays['selected_features'].write(self.written, cropped_features)
        self.written += 1

        if self.written == self.rnn_batch_size:
            arrays = self.run(arrays)
            arrays['selected_features'] = tf.TensorArray(cropped_features.dtype, size=0, element_shape=tf.TensorShape([None] + [cropped_features.shape[1:]]))


        return arrays

    def return_values(self, arrays):
        if self.written != 0:
            arrays = self.run(arrays)

        return arrays['outputs'].concat(), arrays['outputs_ar'].concat()

```

And the use case is something like this:
```
images -> huge tensor of data ->
        rnn_batch = RNNBatch(self.rnn_layer, 64, true_words, true_lengths, training)
        arrays = {
            'selected_features': tf.TensorArray(dtype, size=0, dynamic_size=True, element_shape=tf.TensorShape([None, crop_size, crop_size, features_full.shape[3]])),
            'outputs': tf.TensorArray(dtype, size=0, dynamic_size=True, element_shape=tf.TensorShape([None, self.max_sequence_len, self.dictionary_size])),
            'outputs_ar': tf.TensorArray(dtype, size=0, dynamic_size=True, element_shape=tf.TensorShape([None, self.max_sequence_len, self.dictionary_size])),
        }

        for idx in tf.range(batch_size):
            for crop_idx in tf.range(num_crops):
                  arrays = rnn_batch.feed_crop(cropped_features, arrays)
```

**Other info / logs**
Full traceback: [tf.traceback.txt](https://github.com/tensorflow/tensorflow/files/4171246/tf.traceback.txt)
There is also a core file, gzipped size is about 749M.

What should be the next steps (besides rewriting above class) to debug this problem?

Attached stack trace which ends up like this:
```
Thread 1 ""python3"" received signal SIGSEGV, Segmentation fault.
0x00007fff647051e0 in tensorflow::(anonymous namespace)::{lambda(tensorflow::shape_inference::InferenceContext*)#14}::_FUN(tensorflow::shape_inference::InferenceContext*) ()
   from /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/_pywrap_tensorflow_internal.so
(gdb) bt                                             
#0  0x00007fff647051e0 in tensorflow::(anonymous namespace)::{lambda(tensorflow::shape_inference::InferenceContext*)#14}::_FUN(tensorflow::shape_inference::InferenceContext*) ()
   from /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/_pywrap_tensorflow_internal.so
#1  0x00007fff5d5a6104 in std::_Function_handler<tensorflow::Status (tensorflow::shape_inference::InferenceContext*), tensorflow::Status (*)(tensorflow::shape_inference::InferenceContext*)>::_M_invoke(std::_Any_d
ata const&, tensorflow::shape_inference::InferenceContext*&&) () from /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/_pywrap_tensorflow_internal.so
#2  0x00007fff5a018c22 in tensorflow::shape_inference::InferenceContext::Run(std::function<tensorflow::Status (tensorflow::shape_inference::InferenceContext*)> const&) ()
   from /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/../libtensorflow_framework.so.2
#3  0x00007fff64342a14 in tensorflow::ShapeRefiner::RunShapeFn(tensorflow::Node const*, tensorflow::OpRegistrationData const*, tensorflow::ExtendedInferenceContext*) ()
   from /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/_pywrap_tensorflow_internal.so
#4  0x00007fff643443ee in tensorflow::ShapeRefiner::AddNode(tensorflow::Node const*) () from /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/_pywrap_tensorflow_internal.so
#5  0x00007fff5df740f1 in TF_FinishOperation () from /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/_pywrap_tensorflow_internal.so
#6  0x00007fff5d529dd6 in _wrap_TF_FinishOperation () from /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/_pywrap_tensorflow_internal.so
```

Unfortunately there is no debug package I could use to make better trace "
36541,"Tensor is unhashable if Tensor equality is enabled. Instead, use tensor.experimental_ref() as the key.","**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 64-bit
- TensorFlow installed from (source or binary): Anaconda 4.8.2
- TensorFlow version (use command below): 2.0.0
- TensorrrFlow-probability version: 0.8.0
- Python version: 3.7.6
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

**Describe the current behavior**
Hi everyone,
thi is my first tensorflow project so I'm not really experienced with this API. At the moment I get the following error message when   using the funtion 

tf.feature_column.categorical_column_with_vocabulary_list(key=key,
                                                                                    vocabulary_list=unique_values)

**TypeError: Tensor is unhashable if Tensor equality is enabled. Instead, use tensor.experimental_ref() as the key.**

This error is raised in feature_column_v2.py in the line 1780
if len(set(vocabulary_list)) != len(vocabulary_list):

The invalid part here is set(vocabulary_list)

I checked already if I have compatibility issues with tensorflow-probability version which was recommended in https://github.com/tensorflow/probability/issues/540 and made sure to have both tensorflow and tensorflow-probability up to date. But the error still occures.


**Describe the expected behavior**
The function should create a categorical colun out of a tensor.

**Code to reproduce the issue**
Here is my code:

from __future__ import absolute_import, division, print_function, unicode_literals

import tensorflow as tf


def data_preprocessing():
    print(tf.__version__)
    
    train_file_path = 'Learning Data Input/TrainingData.csv'
       
    # Feature to be predicted
    label_column = 'PARTSET0'  

    raw_training_data = get_dataset(train_file_path, label_column)
  
    show_batch(raw_training_data)
    

    numeric_columns, categorical_columns = get_feature_columns(raw_training_data)
    example_batch, labels_batch = next(iter(raw_training_data))

    preprocessing_layer = tf.keras.layers.DenseFeatures(categorical_columns+numeric_columns)
    print(preprocessing_layer(example_batch).numpy()[0])
    return


def get_dataset(file_path, label_column, **kwargs):
    dataset = tf.data.experimental.make_csv_dataset(file_path, label_name=label_column, batch_size=10, field_delim=';',
                                                    **kwargs)
    return dataset


def show_batch(dataset):
    for batch, label in dataset.take(1):
        for key, value in batch.items():
            print(""{:20s}: {}"".format(key, value.numpy()))
    return


def get_feature_columns(raw_data):
    numeric_columns = []
    categorical_columns = []

    for batch, label in raw_data.take(1):
        for key, value in batch.items():
            unique_values = []
            for unique_value in value:
                if len(unique_values) == 0:
                    unique_values.append(unique_value)
                elif unique_value not in unique_values:
                    unique_values.append(unique_value)
                else:
                    continue
            if value.dtype == 'int32' or value.dtype == 'int64' or value.dtype == 'float32' or value.dtype == 'float64':
                num_col = tf.feature_column.numeric_column(key=key, shape=len(unique_values))
                numeric_columns.append(tf.feature_column.indicator_column(num_col))
            elif value.dtype == 'string':
                cat_col = tf.feature_column.categorical_column_with_vocabulary_list(key=key,
                                                                                    vocabulary_list=unique_values)
                categorical_columns.append(tf.feature_column.indicator_column(cat_col))
            else:
                print(""Undefined column category"" + key)
    return numeric_columns, categorical_columns

**Other info / logs**
Any help is appreciated. thank you!
"
36540,Can't compute distributed gradient in 2 computers with GradientTape,"- TensorFlow version 2.0.0

I am training 2 cascading models, model1 and model2, to be used in 2 different computers. Currently I am simulating it in the same computer. If I train the models in the same gradient tape, it trains perfectly, computing the gradients as:

        import tensorflow as tf
        loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)

        with tf.GradientTape(persistent=True) as tape:
            features = model1(x_batch_train)
            logits = model2(features)
            loss_value = loss_fn(y_batch_train, logits)

        # Computing gradients for model 2
        grads2 = tape.gradient(loss_value, model2.trainable_variables)
        # Computing gradients to pass to model 1
        grads_pass = tape.gradient(loss_value, features)
        # Computing gradients for model 1
        grads1 = tape.gradient(features, model1.trainable_variables, output_gradients=grads_pass)

However, if I want to split the training into 2 different computers, I should have a gradient tape in each one of them, but then the results computed are different!

        import tensorflow as tf
        loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)

        with tf.GradientTape() as tape1:
            features = model1(x_batch_train)
        
        with tf.GradientTape(persistent=True) as tape2:
            logits = model2(features)
            loss_value = loss_fn(y_batch_train, logits)

        # Computing gradients for model 2
        grads2 = tape2.gradient(loss_value, model2.trainable_variables)
        # Computing gradients to pass to model 1
        grads_pass = tape2.gradient(loss_value, features)
        # Computing gradients for model 1
        grads1 = tape1.gradient(features, model1.trainable_variables, output_gradients=grads_pass)

It would be very helpful to have a way to be able to compute gradients in different tapes synchronizing them somehow.

Thanks in advance"
36539,tf.data.Dataset unusable with steps_per_epoch standard training loop,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Mint 
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.1.0
- Python version: 3.7.4

**Describe the current behavior**

This is the underlying issue for https://github.com/tensorflow/tensorflow/issues/36153

Basically:
- `Dataset` can be used as/converted to an iterator
- Once the iterator reaches the end of the dataset it does not restart -> Yields no more samples
- `steps_per_epoch` for the `fit` method of a keras model can be used to specify the number of batches to run per epoch, more exactly: The number of times the iterator is advanced/dereferenced
- `steps_per_epoch` is required for e.g. if not the full dataset should be traversed. Either due to external requirements or to avoid using the trailing (incomplete) batch.
- `steps_per_epoch` is absolutely required to be set for `MultiWorkerMirroredStrategy`: https://www.tensorflow.org/tutorials/distribute/multi_worker_with_keras#train_the_model_with_multiworkermirroredstrategy
- Whether to recreate an iterator for each epoch out of the dataset is determined by `DatasetAdapter.should_recreate_iterator` at https://github.com/tensorflow/tensorflow/blob/v2.1.0/tensorflow/python/keras/engine/training_v2.py#L241-L242
- Note that the iterator absolutely must be recreated for all common use cases:
  - Iterate over full dataset
  - Iterate over full dataset except incomplete trailing batch
  - Iterate over a random subset of the full dataset per epoch
  - Not to be recreated for: Infinite datasets. **Maybe** If the full dataset should be consumed over multiple epochs. But why? What should happen if the dataset is exhausted after some epoch? Usually restart, right?

In the current TF (2.1.0) the implementation of `DatasetAdapter.should_recreate_iterator` is: `return self.get_size() is not None or steps_per_epoch is None`: https://github.com/tensorflow/tensorflow/blob/v2.1.0/tensorflow/python/keras/engine/data_adapter.py#L208

This is **wrong**. For datasets the size is always None (see https://github.com/tensorflow/tensorflow/issues/36531 which intends for this to be changed) and as motivated above having `steps_per_epoch` set is a common use case but the iterator should still be recreated on each epoch.

This was recently changed to ` (self._user_steps is None or cardinality.cardinality(self._dataset).numpy() == self._user_steps)` https://github.com/tensorflow/tensorflow/commit/6be131d0860559954c42685a87c63f16cebb2185#diff-f8dd40712ac721c1b363e1a1ec44c1a3R741-R747

This is also **wrong**. Again assume `_user_steps` is set (see above reasoning): First the `cardinality` might be unknown, e.g. for any TFDS dataset (and `TFRecordDataset`) it is unknown. I guess due to use of `interleave` in the dataset reader. Second even if the size was known it may not be equal to the number of steps. Common example: Skipping the last batch.

**Describe the expected behavior**

This is a design issue and hence hard to resolve.

In general it would be best to eliminate the UNKNOWN size of a dataset. But when reading data line-by-line from a file it might not be known upfront. So the user has to input the size of the dataset or specify explicitly `AUTO` which would iterate over the whole dataset once to get the number of samples. This can be costly but should not be possible in general (e.g. TFDS knows the number of samples)

I think the sanest approach would be to default to recreating the iterator on each epoch UNLESS the dataset is known to be infinite. This might still be wrong for cases I can't imagine right now but is correct for all cases I can think of. Maybe even allow the user to specify this, but this default is IMO way better than the current.

The other approach would be to recreate the iterator when it runs out of data after starting an epoch. This would partially solve the issue, but fails for:
- Omitting the trailing batch: It would yield the incomplete batch from the last epoch first, but that should be skipped.
- Using only some random samples per batch but wanting to shuffle before each batch: It would happily consume the rest of the samples and not see the samples used in an earlier epoch until it runs out of data

With the UNKNOWN size fixed, one could also fix the check at  https://github.com/tensorflow/tensorflow/commit/6be131d0860559954c42685a87c63f16cebb2185#diff-f8dd40712ac721c1b363e1a1ec44c1a3R741-R747 to check if `_user_steps` yields 1 epoch (and optional trailing batches) by using `size // steps == 1` which would be better than the previous approach (recreate iterator when out of data) as the use case with of Omitting the trailing batch is covered. But it would fail for the other.

So my suggestion would to
- (optional) avoid UNKNOWN sizes
- recreate iterators unless dataset is infinite by default
- allow the user to overwrite this explicitly, maybe via `with_options` of the dataset


**Code to reproduce the issue**
Some reduced example code based on e.g. https://www.tensorflow.org/tutorials/distribute/multi_worker_with_keras#train_the_model_with_multiworkermirroredstrategy

```
import tensorflow as tf
import tensorflow_datasets as tfds
import tensorflow as tf
from tensorflow.python.data.experimental.ops import cardinality
import numpy as np
tfds.disable_progress_bar()

# Scaling MNIST data from (0, 255] to (0., 1.]
def scale(image, label):
    image = tf.cast(image, tf.float32)
    image /= 255
    return image, label

def build_and_compile_cnn_model():
    model = tf.keras.Sequential([
        tf.keras.layers.Conv2D(32,
                               3,
                               activation='relu',
                               input_shape=(28, 28, 1)),
        tf.keras.layers.MaxPooling2D(),
        tf.keras.layers.Flatten(),
        tf.keras.layers.Dense(64, activation='relu'),
        tf.keras.layers.Dense(10, activation='softmax')
    ])
    model.compile(loss=tf.keras.losses.sparse_categorical_crossentropy,
                  optimizer=tf.keras.optimizers.SGD(learning_rate=0.001),
                  metrics=['accuracy'])
    return model

BATCH_SIZE = 64
if False:
    examples = np.ones([10*BATCH_SIZE,28,28,1])
    labels = np.ones([examples.shape[0]])
    dataset = tf.data.Dataset.from_tensor_slices((examples, labels))
    num_examples = examples.shape[0]
else:
    datasets, info = tfds.load(name='mnist', with_info=True, as_supervised=True)
    dataset = datasets['test']
    num_examples = info.splits['test'].num_examples

x = dataset.map(scale).cache().shuffle(10000).batch(BATCH_SIZE)
model = build_and_compile_cnn_model()

card = cardinality.cardinality(x)
num_batches = sum(1 for _ in x)
full_batches = num_examples // BATCH_SIZE
print(""Samples: %s\nBatches: %s (%s full)\nCardinality: %s"" % (num_examples, num_batches, full_batches, card))
model.fit(x=x, epochs=2, steps_per_epoch=full_batches)

```

**Other info / logs**
There is a warning:
> WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 312 batches). You may need to use the repeat() function when building your dataset.

It seems that adding `repeat()` and hence creating an infinite dataset is a viable option. However the docu also states
> In TF 1.X, the idiomatic way to create epochs was through the `repeat` transformation:
>     In TF 2.0, `tf.data.Dataset` objects are Python iterables which makes it possible to also create epochs through Python iteration:

So it seems that it should not be required and as per above explanation the return value of `DatasetAdapter.should_recreate_iterator` is not correct."
36538,"Could not download data for ""data = tensorflow_datasets.load('glue/mrpc')""","This template is for miscellaneous issues not covered by the other issue categories.
There is nothing about this in stackflow, Thanks!

Since I execute ""data = tensorflow_datasets.load('glue/mrpc')"" for downloading data. It occurs:

ConnectionError: HTTPSConnectionPool(host='firebasestorage.googleapis.com', port=443): Max retries exceeded with url: /v0/b/mtl-sentence-representations.appspot.com/o/data%2Fmrpc_dev_ids.tsv?alt=media&token=ec5c0836-31d5-48f4-b431-7480817f1adc (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x7fa45008db38>: Failed to establish a new connection: [Errno 101] Network is unreachable',))

I am from China, so maybe I have a useless network for this.
Could you please tell me how to load this mprc data by offline? I have download them and keep files like ""msr_paraphrase_train.txt"" and I also turned them to tsv like:

Quality #1 ID #2 ID #1 String #2 String |  
-- | --
1 1355540 1355592 He said the foodservice pie business doesn 't fit the company 's long-term growth strategy . "" The foodservice pie business does not fit our long-term growth strategy . |  
0 2029631 2029565 Magnarelli said Racicot hated the Iraqi regime and looked forward to using his long years of training in the war . His wife said he was "" 100 percent behind George Bush "" and looked forward to using his years of training in the war . |  

Thank you very much!


"
36537,load_weights problem in Tensorflow.keras.,"Environment
Win10
Conda python 3.7
tensorflow version is 2.0.0.

Using `ModelCheckpoint` and `save_weights_only=True` to save the weights of best model when training model. Using `model.to_json()` save the structure of model.

It's successful to loading model structure from json file, the `model.summary()` is work.
But the problem is when I use `model.load_weigths(weight_path)`, I get `<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x2d871057cc8>
`. And the `summary()` is not work and I cannot use `model.predict` function in this return.

Load model structure from json is work. no problem.
![A](https://user-images.githubusercontent.com/42731603/74031411-668f5380-49ec-11ea-98ea-ec173d5b2f6f.PNG)

Load weights, this problem happen here.
![B](https://user-images.githubusercontent.com/42731603/74031416-6a22da80-49ec-11ea-9839-da8df2e2b891.PNG)

My weight folder, it from checkpoint and save weights only is true.
![C](https://user-images.githubusercontent.com/42731603/74031421-6bec9e00-49ec-11ea-92f2-680263d47f88.PNG)
"
36536,Failed build on Windows with clang-cl,"
**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): source
- TensorFlow version: commit 1cd499a7fc0e782cf2a2fe88eb2e64783e631b2b
- Python version: 3.8
- Installed using virtualenv? pip? conda?: 
- Bazel version (if compiling from source): 1.2.1
- GCC/Compiler version (if compiling from source): clang-cl
- CUDA/cuDNN version: ---
- GPU model and memory: ---

**Describe the problem**
configure: No XLA / ROCm / CUDA. No ""disable inline""

**Provide the exact sequence of commands / steps that you executed before running into the problem**
```
bazel build -s --config opt --define=no_tensorflow_py_deps=true --compiler=clang-cl //tensorflow:tensorflow
```

Build failed on final step: linking tensorflow.dll

**Any other info / logs**
```
SUBCOMMAND: # //tensorflow:tensorflow.dll [action 'Linking tensorflow/tensorflow.dll', configuration: 9b882a621aaf289d03959a0bb55e368bbb8a258a98684e2f2cbeba1e04f08296]
cd F:/.bazel/tf-llvm/execroot/org_tensorflow
  SET LIB=c:\Program Files (x86)\Microsoft Visual Studio\2019\Preview\VC\Tools\MSVC\14.25.28508\ATLMFC\lib\x64;c:\Program Files (x86)\Microsoft Visual Studio\2019\Preview\VC\Tools\MSVC\14.25.28508\lib\x64;C:\Program Files (x86)\Windows Kits\10\lib\10.0.18362.0\ucrt\x64;C:\Program Files (x86)\Windows Kits\8.1\lib\winv6.3\um\x64;;c:\bin\LLVM\lib\clang\9.0.0\lib\windows
    SET PATH=c:\Program Files (x86)\Microsoft Visual Studio\2019\Preview\VC\Tools\MSVC\14.25.28508\bin\HostX64\x64;c:\Program Files (x86)\Microsoft Visual Studio\2019\Preview\Common7\IDE\VC\VCPackages;c:\Program Files (x86)\Microsoft Visual Studio\2019\Preview\Common7\IDE\CommonExtensions\Microsoft\TestWindow;c:\Program Files (x86)\Microsoft Visual Studio\2019\Preview\Common7\IDE\CommonExtensions\Microsoft\TeamFoundation\Team Explorer;c:\Program Files (x86)\Microsoft Visual Studio\2019\Preview\MSBuild\Current\bin\Roslyn;c:\Program Files (x86)\Microsoft Visual Studio\2019\Preview\Team Tools\Performance Tools\x64;c:\Program Files (x86)\Microsoft Visual Studio\2019\Preview\Team Tools\Performance Tools;C:\Program Files (x86)\Microsoft Visual Studio\Shared\Common\VSPerfCollectionTools\vs2019\\x64;C:\Program Files (x86)\Microsoft Visual Studio\Shared\Common\VSPerfCollectionTools\vs2019\;C:\Program Files (x86)\Windows Kits\8.1\bin\x64;c:\Program Files (x86)\Microsoft Visual Studio\2019\Preview\\MSBuild\Current\Bin;C:\Windows\Microsoft.NET\Framework64\v4.0.30319;c:\Program Files (x86)\Microsoft Visual Studio\2019\Preview\Common7\IDE\;c:\Program Files (x86)\Microsoft Visual Studio\2019\Preview\Common7\Tools\;;C:\WINDOWS\system32;c:\Program Files (x86)\Microsoft Visual Studio\2019\Preview\Common7\IDE\CommonExtensions\Microsoft\CMake\CMake\bin;c:\Program Files (x86)\Microsoft Visual Studio\2019\Preview\Common7\IDE\CommonExtensions\Microsoft\CMake\Ninja
    SET PWD=/proc/self/cwd
    SET PYTHON_BIN_PATH=C:/K13/NS/tf-llvm/Scripts/python.exe
    SET PYTHON_LIB_PATH=C:/K13/NS/tf-llvm/Lib/site-packages
    SET RUNFILES_MANIFEST_ONLY=1
    SET TEMP=F:\Temp
    SET TF2_BEHAVIOR=1
    SET TF_CONFIGURE_IOS=0
    SET TMP=F:\Temp
  c:/bin/LLVM/bin/lld-link.exe @bazel-out/x64_windows-opt/bin/tensorflow/tensorflow.dll-2.params
INFO: From Linking tensorflow/tensorflow.dll:
lld-link: warning: ignoring unknown argument '-lpthread'
lld-link: warning: ignoring unknown argument '-lm'
lld-link: warning: ignoring unknown argument '-lpthread'
lld-link: warning: ignoring unknown argument '-lm'
ERROR: F:/lib/tensorflow-llvm/tensorflow/BUILD:623:1: output 'tensorflow/tensorflow.dll' was not created
ERROR: F:/lib/tensorflow-llvm/tensorflow/BUILD:623:1: not all outputs were created or valid
Target //tensorflow:tensorflow failed to build
INFO: Elapsed time: 9411.542s, Critical Path: 3438.48s
INFO: 1964 processes: 1964 local.
FAILED: Build did NOT complete successfully
```

But after repeating same command (with lld-link.exe replaced to LINK.EXE) -- success:
```
(tf-llvm) F:\.bazel\tf-llvm\execroot\org_tensorflow>LINK.EXE @bazel-out/x64_windows-opt/bin/tensorflow/tensorflow.dll-2.params
LINK : warning LNK4044: unrecognized option '/lpthread'; ignored
LINK : warning LNK4044: unrecognized option '/lm'; ignored
LINK : warning LNK4044: unrecognized option '/lpthread'; ignored
LINK : warning LNK4044: unrecognized option '/lm'; ignored
   Creating library bazel-out/x64_windows-opt/bin/tensorflow/tensorflow.dll.if.lib and object bazel-out/x64_windows-opt/bin/tensorflow/tensorflow.dll.if.exp
..... (skip warning) .....

```"
36535,Tensorflow-gpu running issue: CUDA_UNKNOWN_ERROR,"With:

* Tensorflow-gpu 2.0.0
* Windows 10 environment
* NVIDIA GTX 1050 gpu
* cuda 10.0 and corresponding cudnn 7.6.5

I followed the official TF documentation for TF-gpu and I've tried to create and fit a simple CNN model (on a.py file, I've tried with a jupyter but the kernel always dies) but I got the following:

```
2020-02-06 23:57:14.420911: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_100.dll
2020-02-06 23:57:16.081396: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library nvcuda.dll
2020-02-06 23:57:16.861094: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: GeForce GTX 1050 major: 6 minor: 1 memoryClockRate(GHz): 1.493
pciBusID: 0000:01:00.0
2020-02-06 23:57:16.861492: I tensorflow/stream_executor/platform/default/dlopen_checker_stub.cc:25] GPU libraries are statically linked, skip dlopen check.
2020-02-06 23:57:16.862290: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]
2020-02-06 23:58:14.322053: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2
2020-02-06 23:58:14.324900: F tensorflow/stream_executor/lib/statusor.cc:34] Attempting to fetch value instead of handling error Internal: failed to get device attribute 13 for device 0: CUDA_ERROR_UNKNOWN: unknown error
```
"
36533,Tflite micro: segfault after failing to allocate tensors in MicroAllocator,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Arch Linux, NixOS
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: nope
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): latest master
- Python version: C++
- Bazel version (if compiling from source): nope, Make
- GCC/Compiler version (if compiling from source): 8.3.0
- CUDA/cuDNN version: nope
- GPU model and memory: nope

**Describe the current behavior**

`tflite::MicroInterpreter` constructor segfaults

**Describe the expected behavior**

it shouldn't segfault

**Code to reproduce the issue**

grrr call MicroInterpreter constructor with a small arena_size

**Other info / logs**
Fix: https://github.com/tensorflow/tensorflow/blob/753ceb91fc8472a5d9f1293ba97814c04c3a4d4c/tensorflow/lite/micro/micro_allocator.cc#L345 this conditional should return an error code instead of continuing. PR coming up"
36532,Win10 install: ImportError: DLL load failed: The specified module could not be found.,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 Education, Version 1903 (OS Build 18362.592)
- TensorFlow installed from (source or binary): binary
- TensorFlow version: 2.1
- Python version: 3.7.6
- Installed using virtualenv? pip? conda?: pip (in a conda environment, conda 4.8.2)
- CUDA/cuDNN version: -
- GPU model and memory: none

**Steps to reproduce:**

I ran into the issue after installing regular `tensorflow`. Since some reports seem to indicate that cudnn/cuda version incompatibility could be an issue (even though I don't actually have a GPU on this system), I then installed `tensorflow-cpu` (in a fresh environment). The problem persists.

```
conda create -n tf-cpu-test python=3.7
conda activate tf-cpu-test
pip -V
pip install tensorflow_cpu
python
```
Also tried with `pip install tensorflow`, `pip install tensorflow-cpu`
In Python: 
```
import tensorflow as tf
```

**Any other info / logs**
```
Traceback (most recent call last):
  File ""C:\Software\Anaconda37\envs\tf-cpu-test\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Software\Anaconda37\envs\tf-cpu-test\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Software\Anaconda37\envs\tf-cpu-test\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Software\Anaconda37\envs\tf-cpu-test\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Software\Anaconda37\envs\tf-cpu-test\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: The specified module could not be found.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""C:\Software\Anaconda37\envs\tf-cpu-test\lib\site-packages\tensorflow\__init__.py"", line 101, in <module>
    from tensorflow_core import *
  File ""C:\Software\Anaconda37\envs\tf-cpu-test\lib\site-packages\tensorflow_core\__init__.py"", line 40, in <module>
    from tensorflow.python.tools import module_util as _module_util
  File ""C:\Software\Anaconda37\envs\tf-cpu-test\lib\site-packages\tensorflow\__init__.py"", line 50, in __getattr__
    module = self._load()
  File ""C:\Software\Anaconda37\envs\tf-cpu-test\lib\site-packages\tensorflow\__init__.py"", line 44, in _load
    module = _importlib.import_module(self.__name__)
  File ""C:\Software\Anaconda37\envs\tf-cpu-test\lib\importlib\__init__.py"", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""C:\Software\Anaconda37\envs\tf-cpu-test\lib\site-packages\tensorflow_core\python\__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\Software\Anaconda37\envs\tf-cpu-test\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 74, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""C:\Software\Anaconda37\envs\tf-cpu-test\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Software\Anaconda37\envs\tf-cpu-test\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Software\Anaconda37\envs\tf-cpu-test\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Software\Anaconda37\envs\tf-cpu-test\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Software\Anaconda37\envs\tf-cpu-test\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: The specified module could not be found.


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/errors

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.
```
"
36531,Allow datasets to provide the number of examples they contain,"**System information**
- TensorFlow version (you are using): 2.1.0
- Are you willing to contribute it (Yes/No): No



**Describe the feature and the current behavior/state.**

Currently there is no good way to get to the number of samples or batches contained by a dataset although the information is usually available.

What you can do: `sum(1 for _ in dataset)` but this might not do what one wants:
When the dataset is batched it will return the number of batches including the trailing one. `MultiWorkerMirroredStrategy` can't handle that.

Usually this information is already available, see e.g. https://github.com/tensorflow/datasets/issues/1403

**Will this change the current api? How?**

Add a member `num_examples` and/or an overload for `__len__`

**Who will benefit with this feature?**

- Everyone using `MultiWorkerMirroredStrategy`
- Everyone using `steps_per_epoch`
- TF itself as the number of samples/batches is known before executing the training loop avoid status reports like `10/Unknown`
- This would help to provide correct behavior in https://github.com/tensorflow/tensorflow/commit/6be131d0860559954c42685a87c63f16cebb2185#diff-f8dd40712ac721c1b363e1a1ec44c1a3R741-R747

**Any Other info.**

There is an experimental op `cardinality` which might be very related. However it often (always?) returns ""Unknown"". Tested with MNIST from TFDS."
36530,Distributed training time by MirroredStrategy varies greatly between Keras API and Custom training loop,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Ubuntu 16.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
No
- TensorFlow installed from (source or binary):
Source
- TensorFlow version (use command below):
TF 2.0
- Python version:
Python3.5
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
CUDA10
- GPU model and memory:
V100 * 8 

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
The training time by MirroredStrategy in Keras API works fine. The training time is almost linear to the number GPU_num. However, the training time in the custom training loop takes longer, and [2 4 8] GPUs takes the same time in training. Please note that both codes are copied from the tf tutorial with a little bit of modification. The result and source codes are as flows.


**Describe the expected behavior**
Please Provide any bug I had in code or tf bug in the case of experimental support in custom training loop.
![image](https://user-images.githubusercontent.com/33815430/74011734-81010700-49c3-11ea-8c2d-0a505903c6c7.png)
 
**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.

Custom API
```python
from __future__ import absolute_import, division, print_function, unicode_literals

import tensorflow as tf

# Helper libraries
import numpy as np
import os
import time
import tensorflow_datasets as tfds
from datasets.readtf_utils.dataset import get_dataset 
from tensorflow.keras.layers import Input, Dense, Flatten, Conv2D, GlobalAveragePooling2D



os.environ[""CUDA_VISIBLE_DEVICES""] = ""0,1,2,3,4,5,6,7""
gpus = tf.config.experimental.list_physical_devices('GPU')
if gpus:
  try:
    # Currently, memory growth needs to be the same across GPUs
    for gpu in gpus:
      tf.config.experimental.set_memory_growth(gpu, True)
    logical_gpus = tf.config.experimental.list_logical_devices('GPU')
  except RuntimeError as e:
    # Memory growth must be set before GPUs have been initialized
    print(e)



def resize(image, label):
    image = tf.image.resize(image, [224, 224]) / 255.0
    return image, label

def assemble_model(num_classes, model_name='MobileNetV2'):
    import tensorflow as tf 
    base_model = tf.keras.applications.ResNet50(input_shape=(224,224,3),
                                                    weights='imagenet',
                                                    include_top=False)
    model = tf.keras.Sequential([
                                base_model,
                                GlobalAveragePooling2D(),
                                Dense(num_classes, activation='softmax')
                                ])
    model.trainable = True
    return model


print(tf.__version__)


gpus = [1,2,4,8]

for setting_GPUs_num in gpus:
    devices = [""/gpu:""+str(i) for i in range(setting_GPUs_num)]

    strategy = tf.distribute.MirroredStrategy(devices)
    print ('Number of devices: {}'.format(strategy.num_replicas_in_sync))
    BATCH_SIZE_PER_REPLICA = 128
    # GLOBAL_BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync
    GLOBAL_BATCH_SIZE = BATCH_SIZE_PER_REPLICA
    EPOCHS = 5


    ##-----dataset------##
    tfrecords_dir = ""/data121/lijiayuan/test/classify_flowers/datasets""
    train_ds, classes_num = get_dataset(tfrecords_dir, subset=""train"", batch_size=GLOBAL_BATCH_SIZE)

    train_ds = strategy.experimental_distribute_dataset(train_ds)




 


    with strategy.scope():
      # Set reduction to `none` so we can do the reduction afterwards and divide by
      # global batch size.
      loss_object = tf.keras.losses.SparseCategoricalCrossentropy(
          reduction=tf.keras.losses.Reduction.NONE)
      # or loss_fn = tf.keras.losses.sparse_categorical_crossentropy
      def compute_loss(labels, predictions):
        per_example_loss = loss_object(labels, predictions)
        return tf.nn.compute_average_loss(per_example_loss, global_batch_size=GLOBAL_BATCH_SIZE)


    with strategy.scope():

      train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(
          name='train_accuracy')

    # model and optimizer must be created under `strategy.scope`.
    with strategy.scope():
      model = assemble_model(num_classes=classes_num)
      optimizer = tf.keras.optimizers.Adam()
      checkpoint = tf.train.Checkpoint(optimizer=optimizer, model=model)

    with strategy.scope():
      def train_step(inputs):
        images, labels = inputs

        with tf.GradientTape() as tape:
          predictions = model(images, training=True)
          loss = compute_loss(labels, predictions)

        gradients = tape.gradient(loss, model.trainable_variables)
        optimizer.apply_gradients(zip(gradients, model.trainable_variables))

        train_accuracy.update_state(labels, predictions)
        return loss 




    with strategy.scope():
      # `experimental_run_v2` replicates the provided computation and runs it
      # with the distributed input.
      @tf.function
      def distributed_train_step(dataset_inputs):
        per_replica_losses = strategy.experimental_run_v2(train_step,
                                                          args=(dataset_inputs,))
        return strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_losses,
                               axis=None)
     
     
      times = []
      for epoch in range(EPOCHS):
        # TRAIN LOOP

        total_loss = 0.0
        num_batches = 0
        epoch_start = time.time()
        for x in train_ds:
          total_loss += distributed_train_step(x)
          num_batches += 1
        train_loss = total_loss / num_batches
        epoch_end = time.time()
        
        if epoch != 0:
          times.append(epoch_end-epoch_start)
        



        template = (""Epoch {}, Loss: {:.2f}, Accuracy: {:.2f}, ""
                    "" Takes: {:.2f}"")
        print (template.format(epoch+1, train_loss,
                               train_accuracy.result()*100, 
                               epoch_end-epoch_start))

        train_accuracy.reset_states()
      print(""{} GPUs takes average {:.2f} secs"".format(setting_GPUs_num, 
                                                        sum(times)/(EPOCHS-1)))


```

Keras API:
```python
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function
from __future__ import unicode_literals

import tensorflow as tf
import tensorflow_datasets as tfds
import time
import datetime

import argparse
import sys
import shutil
import time
import os
import numpy as np

from functools import partial
from tensorflow.keras.layers import Input, Dense, Flatten, Conv2D, GlobalAveragePooling2D
from tensorflow.keras import Model
from tensorflow.keras.datasets.fashion_mnist import load_data
import tensorflow_datasets as tfds
import read_params
from train_config import configure_model, configure_optimizer, configure_lossfunc
from datasets.readtf_utils.dataset import get_dataset 
from datasets.readtf_utils.dataset import _parse_fn

os.environ[""CUDA_VISIBLE_DEVICES""] = ""0,1,2,3,4,5,6,7""
gpus = tf.config.experimental.list_physical_devices('GPU')
if gpus:
  try:
    # Currently, memory growth needs to be the same across GPUs
    for gpu in gpus:
      tf.config.experimental.set_memory_growth(gpu, True)
    logical_gpus = tf.config.experimental.list_logical_devices('GPU')
  except RuntimeError as e:
    # Memory growth must be set before GPUs have been initialized
    print(e)


num_epochs = 5
batch_size_per_replica = 128
learning_rate = 0.001
setting_GPUs_num = 4
devices = [""/gpu:""+str(i) for i in range(setting_GPUs_num)]

strategy = tf.distribute.MirroredStrategy(devices)
GPUs_num = strategy.num_replicas_in_sync
print('Number of devices: %d' % GPUs_num)  # 输出设备数量

# batch_size = batch_size_per_replica * strategy.num_replicas_in_sync
batch_size = batch_size_per_replica

def resize(image, label):
    image = tf.image.resize(image, [224, 224]) / 255.0
    return image, label



class MyCustomCallback(tf.keras.callbacks.Callback):
    def on_train_begin(self, logs={}):
        self.train_begin = time.time()
        self.times = []
        # print('trian begins at {}'.format(self.train_begin))
        # d

    def on_epoch_begin(self, epoch, logs=None):
        self.epoch_begin = time.time()
        # print('epoch: {} begins at {}'.format(epoch, self.epoch_begin))

    def on_epoch_end(self, epoch, logs=None):
        self.epoch_end = time.time()
        self.epoch = epoch
        # print('epoch: {} ends at {}'.format(epoch, self.epoch_end))
        self.times.append(self.epoch_end-self.epoch_begin)
        print("" epoch: {} takes: {}"".format(epoch, self.epoch_end-self.epoch_begin))

    def on_train_end(self, epoch, logs=None):
        self.train_end = time.time()
        # print('training takes {} secs/epoch: '.format((self.train_end - self.train_begin)/self.epoch))
        print('training takes average {:.2f} secs/epoch'.format(sum(self.times[1::]) / (self.epoch)))



tfrecords_dir = ""/data121/lijiayuan/test/classify_flowers/datasets/""
dataset, _ = get_dataset(tfrecords_dir, subset=""train"", batch_size=batch_size)
end = time.time()



if GPUs_num == 1:
    model = tf.keras.applications.MobileNetV2()
    model.compile(
        optimizer=tf.keras.optimizers.SGD(learning_rate=learning_rate),
        loss=tf.keras.losses.sparse_categorical_crossentropy,
        metrics=[tf.keras.metrics.sparse_categorical_accuracy]
    )
else:
    with strategy.scope():
        model = tf.keras.applications.MobileNetV2()
        model.compile(
            optimizer=tf.keras.optimizers.SGD(learning_rate=learning_rate),
            loss=tf.keras.losses.sparse_categorical_crossentropy,
            metrics=[tf.keras.metrics.sparse_categorical_accuracy]
            # run_eagerly=False
        )


start = time.time()
model.fit(dataset, epochs=num_epochs, callbacks=[MyCustomCallback()])

print(""{} GPUs takes {:.2f} secs/epoch = {:.2f} mins/epoch"".format(strategy.num_replicas_in_sync, 
                                                                    (end-start)/num_epochs, 
                                                                    (end-start)/60/num_epochs))

```
**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
36529,"the tf c version doesn't work when it contains LSTM block, until replacing LSTM with others. It reply that op doesn't register. The tf.contrib module don't work. The tensorflow c version is r1.13. here is the error information: Not found: Op type not registered 'LSTMBlockCell' in binary running on t640_m160p36. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib. accessing(e.g)'tf.contrib.resampler' should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.","<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below):
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

**Describe the expected behavior**

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
36528," the tf c version doesn't work when it contains LSTM block, until replacing LSTM with others. It reply that op doesn't register.  The tf.contrib module don't work. The tensorflow c version is  r1.13.  here is the error information:  Not found: Op type not registered 'LSTMBlockCell' in binary running on t640_m160p36.","<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below):
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

**Describe the expected behavior**

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
36527,"[CI] Ubuntu CPU is still ""Expected — Waiting for status to be reported"" after 14 days.","It is strange. Please look at the execution status (**See the red rectangle below)** of the Tensorflow CI on  PR #36186.  The work status of **Ubuntu CPU** and **Ubuntu Sanity** checker are still running. The current status of two checkers is ""**Expected — Waiting for status to be reported**"" even though 14 days is passed after the contributor submitted PR #36186. Why do not these checkers report the execution result either PASS or FAILURE? As we all know the 14 days are not reasonable to us. And, it will be helpful to the reviewers?

![image](https://user-images.githubusercontent.com/82404/74004185-65443380-49b8-11ea-986c-58791e241d50.png)

Above all, many PRs do not have been getting the test result from the CI checkers in time.  It seems that the TensorFlow community does not have Cloud instances enough to run CI checkers whenever PRs are submitted by the contributors. Or because of the unstable CI system.
"
36525,BinaryElementWiseOp::Operate template argument not used and can cause unnecessary errors,"**System information**
- Have I written custom code: yes
- OS Platform and Distribution: macOS 10
- TensorFlow installed from: binary
- TensorFlow version: 2.1
- Python version: 3.7.2

**Describe the current behavior**

[`BinaryElementWiseOp`](https://github.com/tensorflow/tensorflow/blob/c7a0fc02f6d1211b7c1c34061fd1b821029e089a/tensorflow/core/framework/numeric_op.h#L67-L109) expects child classes to define an `Operate()` method, which is used in the `Compute()` method to perform the class's operation. This `Operate()` method has an `int` template parameter `NDIMS` which represents the dimension of the inputs and output.

https://github.com/tensorflow/tensorflow/blob/c7a0fc02f6d1211b7c1c34061fd1b821029e089a/tensorflow/core/framework/numeric_op.h#L84-L107

However, this template parameter is not used by any `BinaryElementWiseOp` subclass; all subclasses currently call an `OperateNoTemplate()` method from inside `Operate()`. For example, ReLU:

https://github.com/tensorflow/tensorflow/blob/c7a0fc02f6d1211b7c1c34061fd1b821029e089a/tensorflow/core/kernels/relu_op.h#L66-L79

This leads to seemingly unnecessary errors like in the following Python code:

```python
import tensorflow as tf

x = tf.reshape(0.0, [1] * 9)  # Too many dimensions for ReluGradOp
x = tf.Variable(x)
with tf.GradientTape() as tape:
  tape.watch(x)
  y = tf.nn.relu(x)

tape.gradient(y, x)  # tensorflow.python.framework.errors_impl.InvalidArgumentError: We only handle up to Tensor::dims() up to 8, not 9 [Op:ReluGrad]
```

The full list of `BinaryElementWiseOp` subclasses I was able to find is

* [`ReluGradOp`](https://github.com/tensorflow/tensorflow/blob/c7a0fc02f6d1211b7c1c34061fd1b821029e089a/tensorflow/core/kernels/relu_op.h#L61-L80)
* [`Relu6GradOp`](https://github.com/tensorflow/tensorflow/blob/c7a0fc02f6d1211b7c1c34061fd1b821029e089a/tensorflow/core/kernels/relu_op.h#L104-L122)
* [`LeakyReluGradOp`](https://github.com/tensorflow/tensorflow/blob/c7a0fc02f6d1211b7c1c34061fd1b821029e089a/tensorflow/core/kernels/relu_op.h#L154-L182)
* [`EluGradOp`](https://github.com/tensorflow/tensorflow/blob/c7a0fc02f6d1211b7c1c34061fd1b821029e089a/tensorflow/core/kernels/relu_op.h#L207-L225)
* [`SeluGradOp`](https://github.com/tensorflow/tensorflow/blob/c7a0fc02f6d1211b7c1c34061fd1b821029e089a/tensorflow/core/kernels/relu_op.h#L249-L267)
* [`SoftsignGradOp`](https://github.com/tensorflow/tensorflow/blob/c7a0fc02f6d1211b7c1c34061fd1b821029e089a/tensorflow/core/kernels/softsign_op.cc#L46-L66)
* [`SoftplusGradOp`](https://github.com/tensorflow/tensorflow/blob/c7a0fc02f6d1211b7c1c34061fd1b821029e089a/tensorflow/core/kernels/softplus_op.cc#L46-L66)
* [`FakeQuantWithMinMaxArgsGradientOp`](https://github.com/tensorflow/tensorflow/blob/c7a0fc02f6d1211b7c1c34061fd1b821029e089a/tensorflow/core/kernels/fake_quant_ops.cc#L102-L148)

All of them follow the `Operate()` calling `OperateNoTemplate()` pattern. It seems like `BinaryElementWiseOp` and its subclasses can be refactored by removing the `NDIMS` template argument from `Operate()` and moving the contents of each subclass's `OperateNoTemplate()` method into the corresponding `Operate()` method.
"
36524,wide and deep code written fully in tensorflow 2.1 throws tensorflow 1 and 2 incompatability error,"Hi, 
I am writing a code in tensorflow 2.1 with feature_columns but it is giving me errors:

This is the code snippet:
I am keeping the data in pandas dataframe: df
I am defining the feature columns similar to the code snippet below, containing crossed features, categorical features, numerical features:


cat_f1=tf.feature_column.categorical_column_with_vocabulary_list('cat_col_name_1' , df['cat_col_name_1'].unique())
...
num_fn  = tf.feature_column.numeric_column(""num_col_name_n"") 

wide_columns = {cat_f1.key: cat_f1,
...
}
deep_columns = {
...
num_fn.key: num_fn,
}
output_feature = ['label']





And this is how I am defining my input_fn:

def input_fn(df,inner_batch_size=-1,shuffle=False):
    input_features=[]
    for key ,_ in wide_columns.items():
        input_features.append(key)
    for key, _ in deep_columns.items():
        if '-crossed' in key:
            k = key.replace('-crossed','')
            keys=[]
            keys = k.split('-')
            for k in keys: 
                input_features.append(k)
        else: 
            input_features.append(key)
    dataset=tf.data.Dataset.from_tensor_slices((dict(df[input_features]) , df[output_feature].values))
    if shuffle ==True: 
        dataset = dataset.shuffle(100).repeat()
    if inner_batch_size>0:
        dataset = dataset.batch(inner_batch_size)    
    return dataset






And the definition of estimator: 

model_dir = tempfile.mkdtemp()
optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.001)
estimator = tf.estimator.DNNLinearCombinedClassifier(model_dir = model_dir,
                                                linear_feature_columns = wide_columns , 
                                                dnn_feature_columns=deep_columns,
                                                dnn_hidden_units = [100,50],
                                                dnn_optimizer = optimizer)
 






and after data preparation, calling the train:
estimator.train(input_fn = lambda: input_fn(train_batch_data,inner_batch_size,shuffle=True) ,steps=10)
metrics = estimator.evaluate(input_fn = lambda: input_fn(val_batch_data,shuffle=False)  , steps = 5)
for key in sorted(metrics):
    print (""%s: %s"" % (key, results[key]))




This throws the error:

Received a feature column from TensorFlow v1, but this is a TensorFlow v2 Estimator. Please either use v2 feature columns (accessible via tf.feature_column.* in TF 2.x) with this Estimator, or switch to a v1 Estimator for use with v1 feature columns (accessible via tf.compat.v1.estimator.* and tf.compat.v1.feature_column.*, respectively.


What is the problem? "
36522,fcn8_tf2/Scripts/SegNet_fab.py:518 segnet  *         dec = segnet_deconv(     fcn8_tf2/Scripts/SegNet_fab.py:278 segnet_deconv  *         dec = Conv2D(     venv/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py:817 __call__         self._maybe_build(inputs)     venv/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py:2141 _maybe_build         self.build(input_shapes)     venv/lib/python3.6/site-packages/tensorflow_core/python/keras/layers/convolutional.py:153 build         raise ValueError('The channel dimension of the inputs '      ValueError: The channel dimension of the inputs should be defined. Found `None`.,"Hi Everyone, I am trying to implement Segnet in tensorflow 2. 
When I run the code I get this error:

**fcn8_tf2/Scripts/SegNet_fab.py:518 segnet  *
        dec = segnet_deconv(
    fcn8_tf2/Scripts/SegNet_fab.py:278 segnet_deconv  *
        dec = Conv2D(
    venv/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py:817 __call__
        self._maybe_build(inputs)
    venv/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py:2141 _maybe_build
        self.build(input_shapes)
    venv/lib/python3.6/site-packages/tensorflow_core/python/keras/layers/convolutional.py:153 build
        raise ValueError('The channel dimension of the inputs '

    ValueError: The channel dimension of the inputs should be defined. Found `None`.**

Below the scripts.
**train.py**
from Segnet_fab import segnet
inputs = Input(shape=(*params['image_size'], params['num_channels']), name='input')
outputs = segnet(inputs, n_labels=2, kernel=3, pool_size=(2, 2), output_mode=None)
			 # we define our U-Net to output logits
model = Model(inputs, outputs)

**Segnet_fab.py**
import tensorflow as tf
from tensorflow.keras.layers import *
from tensorflow.keras import Model
from tensorflow.keras import backend as K

def MaxUnpooling2D(updates, mask):
	size = 2
	mask = tf.cast(mask, 'int32')
	input_shape = tf.shape(updates, out_type='int32')

	#  calculation new shape
	output_shape = (
			input_shape[0],
			input_shape[1]*size,
			input_shape[2]*size,
			input_shape[3])
	# calculation indices for batch, height, width and feature maps
	one_like_mask = tf.ones_like(mask, dtype='int32')
	batch_shape = tf.concat(
			[[input_shape[0]], [1], [1], [1]],
			axis=0)
	batch_range = tf.reshape(
			tf.range(output_shape[0], dtype='int32'),
			shape=batch_shape)
	b = one_like_mask * batch_range
	y = mask // (output_shape[2] * output_shape[3])
	x = (mask // output_shape[3]) % output_shape[2]
	feature_range = tf.range(output_shape[3], dtype='int32')
	f = one_like_mask * feature_range
	updates_size = tf.size(updates)
	indices = K.transpose(K.reshape(
		tf.stack([b, y, x, f]),
		[4, updates_size]))
	values = tf.reshape(updates, [updates_size])
	return tf.scatter_nd(indices, values, output_shape)

def segnet_conv(
		inputs,
		kernel_size=3,
		kernel_initializer='glorot_uniform',
		batch_norm = False,
		**kwargs):
################################# block1 #################################

	conv1 = Conv2D(
			filters=64,
			kernel_size=kernel_size,
			padding='same',
			activation=None,
			kernel_initializer=kernel_initializer,
			name='conv_1'
		)(inputs)
	
	if batch_norm:
		conv1 = BatchNormalization(name='bn_1')(conv1)
	conv1 = LeakyReLU(alpha=0.3, name='activation_1')(conv1)

	conv1 = Conv2D(
			filters=64,
			kernel_size=kernel_size,
			padding='same',
			activation=None,
			kernel_initializer=kernel_initializer,
			name='conv_2'
		)(conv1)
	
	if batch_norm:
		conv1 = BatchNormalization(name='bn_2')(conv1)
	conv1 = LeakyReLU(alpha=0.3, name='activation_2')(conv1)

	pool1, mask1 = tf.nn.max_pool_with_argmax(
			input=conv1,
			ksize=2,
			strides=2,
			padding='SAME'
		)
	
################################# block2 #################################
	conv2 = Conv2D(
			filters=128,
			kernel_size=kernel_size,
			padding='same',
			activation=None,
			kernel_initializer=kernel_initializer,
			name='conv_3'
		)(pool1)
	
	if batch_norm:
		conv2 = BatchNormalization(name='bn_3')(conv2)
	conv2 = LeakyReLU(alpha=0.3, name='activation_3')(conv2)

	conv2 = Conv2D(
			filters=128,
			kernel_size=kernel_size,
			padding='same',
			activation=None,
			kernel_initializer=kernel_initializer,
			name='conv_4'
		)(conv2)
	
	if batch_norm:
		conv2 = BatchNormalization(name='bn_4')(conv2)
	conv2 = LeakyReLU(alpha=0.3, name='activation_4')(conv2)

	pool2, mask2 = tf.nn.max_pool_with_argmax(
			input=conv2,
			ksize=2,
			strides=2,
			padding='SAME'
		)

################################# block3 #################################
	conv3 = Conv2D(
			filters=256,
			kernel_size=kernel_size,
			padding='same',
			activation=None,
			kernel_initializer=kernel_initializer,
			name='conv_5'
		)(pool2)
	
	if batch_norm:
		conv3 = BatchNormalization(name='bn_5')(conv3)
	conv3 = LeakyReLU(alpha=0.3, name='activation_5')(conv3)
	
	conv3 = Conv2D(
			filters=256,
			kernel_size=kernel_size,
			padding='same',
			activation=None,
			kernel_initializer=kernel_initializer,
			name='conv_6'
		)(conv3)
	
	if batch_norm:
		conv3 = BatchNormalization(name='bn_6')(conv3)
	conv3 = LeakyReLU(alpha=0.3, name='activation_6')(conv3)

	conv3 = Conv2D(
			filters=256,
			kernel_size=kernel_size,
			padding='same',
			activation=None,
			kernel_initializer=kernel_initializer,
			name='conv_7'
		)(conv3)
	
	if batch_norm:
		conv3 = BatchNormalization(name='bn_7')(conv3)
	conv3 = LeakyReLU(alpha=0.3, name='activation_7')(conv3)

	pool3, mask3 = tf.nn.max_pool_with_argmax(
			input=conv3,
			ksize=2,
			strides=2,
			padding='SAME'
		)

################################# block4 #################################
	conv4 = Conv2D(
			filters=512,
			kernel_size=kernel_size,
			padding='same',
			activation=None,
			kernel_initializer=kernel_initializer,
			name='conv_8'
		)(pool3)
	
	if batch_norm:
		conv4 = BatchNormalization(name='bn_8')(conv4)
	conv4 = LeakyReLU(alpha=0.3, name='activation_8')(conv4)

	conv4 = Conv2D(
			filters=512,
			kernel_size=kernel_size,
			padding='same',
			activation=None,
			kernel_initializer=kernel_initializer,
			name='conv_9'
		)(conv4)
	
	if batch_norm:
		conv4 = BatchNormalization(name='bn_9')(conv4)
	conv4 = LeakyReLU(alpha=0.3, name='activation_9')(conv4)

	conv4 = Conv2D(
			filters=512,
			kernel_size=kernel_size,
			padding='same',
			activation=None,
			kernel_initializer=kernel_initializer,
			name='conv_10'
		)(conv4)
	
	if batch_norm:
		conv4 = BatchNormalization(name='bn_10')(conv4)
	conv4 = LeakyReLU(alpha=0.3, name='activation_10')(conv4)

	pool4, mask4 = tf.nn.max_pool_with_argmax(
			input=conv4,
			ksize=2,
			strides=2,
			padding='SAME'
		)

################################# block5 #################################
	conv5 = Conv2D(
			filters=512,
			kernel_size=kernel_size,
			padding='same',
			activation=None,
			kernel_initializer=kernel_initializer,
			name='conv_11'
		)(pool4)
	
	if batch_norm:
		conv5 = BatchNormalization(name='bn_11')(conv5)
	conv5 = LeakyReLU(alpha=0.3, name='activation_11')(conv5)

	conv5 = Conv2D(
			filters=512,
			kernel_size=kernel_size,
			padding='same',
			activation=None,
			kernel_initializer=kernel_initializer,
			name='conv_12'
		)(conv5)
	
	if batch_norm:
		conv5 = BatchNormalization(name='bn_12')(conv5)
	conv5 = LeakyReLU(alpha=0.3, name='activation_12')(conv5)

	conv5 = Conv2D(
			filters=512,
			kernel_size=kernel_size,
			padding='same',
			activation=None,
			kernel_initializer=kernel_initializer,
			name='conv_13'
		)(conv5)
	
	if batch_norm:
		conv5 = BatchNormalization(name='bn_13')(conv5)
	conv5 = LeakyReLU(alpha=0.3, name='activation_13')(conv5)

	pool5, mask5 = tf.nn.max_pool_with_argmax(
			input=conv5,
			ksize=2,
			strides=2,
			padding='SAME'
		)

	return pool5, mask1,mask2,mask3,mask4,mask5
##########################################################################
############################## decod block1 ##############################
##########################################################################

def segnet_deconv(
			pool5,
			mask1,
			mask2,
			mask3,
			mask4,
			mask5,
			kernel_size=3,
			kernel_initializer='glorot_uniform',
			batch_norm = False,
			**kwargs
		):

	dec = MaxUnpooling2D(pool5, mask5)

	dec = Conv2D(
			filters=512,
			kernel_size=kernel_size,
			padding='same',
			activation=None,
			kernel_initializer=kernel_initializer,
			name='upconv_13'
		)(dec)

	if batch_norm:
		dec = BatchNormalization(name='upbn_13')(dec)
	dec = LeakyReLU(alpha=0.3, name='upactivation_13')(dec)
	
	dec = Conv2D(
			filters=512,
			kernel_size=kernel_size,
			padding='same',
			activation=None,
			kernel_initializer=kernel_initializer,
			name='upconv_12'
		)(dec)

	if batch_norm:
		dec = BatchNormalization(name='upbn_12')(dec)
	dec = LeakyReLU(alpha=0.3, name='upactivation_12')(dec)

	dec = Conv2D(
			filters=512,
			kernel_size=kernel_size,
			padding='same',
			activation=None,
			kernel_initializer=kernel_initializer,
			name='upconv_11'
		)(dec)

	if batch_norm:
		dec = BatchNormalization(name='upbn_11')(dec)
	dec = LeakyReLU(alpha=0.3, name='upactivation_11')(dec)

############################## decod block2 ##############################

	dec = MaxUnpooling2D(dec, mask4)
	
	dec = Conv2D(
			filters=512,
			kernel_size=kernel_size,
			padding='same',
			activation=None,
			kernel_initializer=kernel_initializer,
			name='upconv_10'
		)(dec)

	if batch_norm:
		dec = BatchNormalization(name='upbn_10')(dec)
	dec = LeakyReLU(alpha=0.3, name='upactivation_10')(dec)
	
	dec = Conv2D(
			filters=512,
			kernel_size=kernel_size,
			padding='same',
			activation=None,
			kernel_initializer=kernel_initializer,
			name='upconv_9'
		)(dec)

	if batch_norm:
		dec = BatchNormalization(name='upbn_9')(dec)
	dec = LeakyReLU(alpha=0.3, name='upactivation_9')(dec)

	dec = Conv2D(
			filters=256,
			kernel_size=kernel_size,
			padding='same',
			activation=None,
			kernel_initializer=kernel_initializer,
			name='upconv_8'
		)(dec)

	if batch_norm:
		dec = BatchNormalization(name='upbn_8')(dec)
	dec = LeakyReLU(alpha=0.3, name='upactivation_8')(dec)

############################## decod block3 ##############################

	dec = MaxUnpooling2D(dec, mask3)
	
	dec = Conv2D(
			filters=256,
			kernel_size=kernel_size,
			padding='same',
			activation=None,
			kernel_initializer=kernel_initializer,
			name='upconv_7'
		)(dec)

	if batch_norm:
		dec = BatchNormalization(name='upbn_7')(dec)
	dec = LeakyReLU(alpha=0.3, name='upactivation_7')(dec)
	
	dec = Conv2D(
			filters=256,
			kernel_size=kernel_size,
			padding='same',
			activation=None,
			kernel_initializer=kernel_initializer,
			name='upconv_6'
		)(dec)

	if batch_norm:
		dec = BatchNormalization(name='upbn_6')(dec)
	dec = LeakyReLU(alpha=0.3, name='upactivation_6')(dec)

	dec = Conv2D(
			filters=128,
			kernel_size=kernel_size,
			padding='same',
			activation=None,
			kernel_initializer=kernel_initializer,
			name='upconv_5'
		)(dec)

	if batch_norm:
		dec = BatchNormalization(name='upbn_5')(dec)
	dec = LeakyReLU(alpha=0.3, name='upactivation_5')(dec)

############################## decod block4 ##############################

	dec = MaxUnpooling2D(dec, mask2)
	
	dec = Conv2D(
			filters=128,
			kernel_size=kernel_size,
			padding='same',
			activation=None,
			kernel_initializer=kernel_initializer,
			name='upconv_4'
		)(dec)

	if batch_norm:
		dec = BatchNormalization(name='upbn_4')(dec)
	dec = LeakyReLU(alpha=0.3, name='upactivation_4')(dec)
	
	dec = Conv2D(
			filters=64,
			kernel_size=kernel_size,
			padding='same',
			activation=None,
			kernel_initializer=kernel_initializer,
			name='upconv_3'
		)(dec)

	if batch_norm:
		dec = BatchNormalization(name='upbn_3')(dec)
	dec = LeakyReLU(alpha=0.3, name='upactivation_3')(dec)

############################## decod block5 ##############################

	dec = MaxUnpooling2D(dec, mask1)
	
	dec = Conv2D(
			filters=64,
			kernel_size=kernel_size,
			padding='same',
			activation=None,
			kernel_initializer=kernel_initializer,
			name='upconv_2'
		)(dec)

	if batch_norm:
		dec = BatchNormalization(name='upbn_2')(dec)
	dec = LeakyReLU(alpha=0.3, name='upactivation_2')(dec)
	
	dec = Conv2D(
			filters=64,
			kernel_size=kernel_size,
			padding='same',
			activation=None,
			kernel_initializer=kernel_initializer,
			name='upconv_3'
		)(dec)

	if batch_norm:
		dec = BatchNormalization(name='upbn_3')(dec)
	dec = LeakyReLU(alpha=0.3, name='upactivation_3')(dec)
	return dec
##########################################################################
############################### classifier ###############################
##########################################################################
def classifier(
		dec,
		ch_out=2,
		kernel_size=3,
		final_activation=None,
		batch_norm = False,
		**kwargs
	):
	dec = Conv2D(
			filters=64,
			kernel_size=kernel_size,
			activation='relu',
			padding='same',
			name='dec_out1'
		)(dec)

	dec = Dropout(0.3, name='drop_out1')(dec)

	x = Conv2D(
			filters=64,
			kernel_size=kernel_size,
			activation='relu',
			padding='same',
			name='dec_out2'
		)(dec)

	dec = Dropout(0.3, name='drop_out2')(dec)
	dec = Conv2D(
			filters=ch_out,
			kernel_size=1,
			activation=final_activation,
			padding='same',
			name='dec_output'
		)(dec)
	return dec
@tf.function
def segnet(
		inputs,
		ch_out=2,
		kernel_size=3,
		kernel_initializer='glorot_uniform',
		final_activation=None,
		batch_norm = False,
		**kwargs
		):

	pool5, mask1, mask2, mask3, mask4, mask5 = segnet_conv(
								inputs,
								kernel_size=3,
								kernel_initializer='glorot_uniform',
								batch_norm = False
							)
	dec = segnet_deconv(
				pool5,
				mask1,
				mask2,
				mask3,
				mask4,
				mask5,
				kernel_size=kernel_size,
				kernel_initializer=kernel_initializer,
				batch_norm = batch_norm
			)

	output = classifier(
				dec,
				ch_out=2,
				kernel_size=3,
				final_activation=None,
				batch_norm = batch_norm
			)
	return output

apparently the function MaxUnpooling2D gives none output.
Can you help me, Please?"
36520,wrong error message from tf.data.Dataset when GPU OOM,"I am filing this issue in case someone else ran into the same problem.

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.1.0
- Python version: 3.6.9
- CUDA/cuDNN version: 10.1/7
- GPU model and memory:Titan XP/12GB

**Describe the current behavior**

When GPU memory is `fully` taken by another tf session, I failed to run the following script:

```python
tf.data.Dataset.list_files(""some files"")
```

and got the following error:
```
tensorflow.python.framework.errors_impl.InvalidArgumentError: buffer_size must be greater than zero. [Op:ShuffleDatasetV2]
```

**Describe the expected behavior**

I expected to get an OOM error, which is much clear about the real root cause of the problem.

**Code to reproduce the issue**

In one python session, run some tensorflow code to take all the GPU memory  (I ran some MobileNet inference to take  11879MiB / 12194MiB of the GPU memory).
In another python session, run `tf.data.Dataset.list_files(""./*"")`  will reproduce the misleading error message.


"
36518,Allow `tf.keras.activations` to be deserialized with dicts.,"**System information**
- TensorFlow version (you are using): `2.1`
- Are you willing to contribute it (Yes/No): Yes


**Describe the feature and the current behavior/state.**
`tf.keras.activations` deserialization doesn't work for dict-based identifier. It would be nice if it did work in a similar way as other module deserializers such as `tf.keras.initializers`. The following snippet currently raises `ValueError: Unknown activation: relu` for the activation deserialization.

```python
import tensorflow as tf


# Works
initilizer = tf.keras.initializers.get({
    'class_name': 'random_normal_initializer',
    'config': {}
})

# Does not work
activation = tf.keras.activations.get({
    'class_name': 'relu',
    'config': {}
})
```



**Will this change the current api? How?**
It would add the ability to use `tf.keras.activations.get({...})`.

**Who will benefit with this feature?**
Users who want to serialize/deserialize their activation functions for example as json.

**Any Other info.**
I'm happy to submit a PR for this."
36517,TensorFlow Lite Conversion Fails (Check failed: start_indices_size <= num_input_axes (2 vs. 1)StridedSlice op requires no more than 1 start indices),"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux CentOS 7.5
- TensorFlow installed from (source or binary): Tensorflow is preinstalled on the server.
- TensorFlow version (or github SHA if from source): Tensorflow/2.0.0


**Command used to run the converter or code if you’re using the Python API**
```
import tensorflow as tf
# Note: full quantization requires tf 1.15 or higher
import numpy as np
from PIL import Image

def representative_dataset_gen():
  data = np.random.rand(100,416,416,3).astype(dtype=np.float32)
  for i in range(num_calibration_steps):
    # Get sample input data as a numpy array in a method of your choosing.
    # image, = data.take(1)
    image = np.expand_dims(data[i,:,:,:], axis=0)
    yield [image]

num_calibration_steps = 100
saved_model_dir = '/projectnb/ec720prj/nakamura/Spring2020/tf2-yolov3/savedmodel/yolov3/1' # dir of YOLOv3 tf implementation

converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)
converter.optimizations = [tf.lite.Optimize.DEFAULT]
# converter.representative_dataset = tf.lite.RepresentativeDataset(representative_dataset_gen)
converter.representative_dataset = representative_dataset_gen

# Enforce full integer quantization for all ops and use int input/output
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]
converter.inference_input_type = tf.uint8
converter.inference_output_type = tf.uint8

tflite_quant_model = converter.convert()
open(""./converted_model.tflite"", ""wb"").write(tflite_quant_model)
```

**The output from the converter invocation**

```
2020-02-06 10:53:25.407210: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  AVX AVX2 FMA
To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.
2020-02-06 10:53:25.425952: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2394310000 Hz
2020-02-06 10:53:25.427429: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0xce6d420 executing computations on platform Host. Devices:
2020-02-06 10:53:25.427467: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version
2020-02-06 10:53:25.436305: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 28. Tune using inter_op_parallelism_threads for best performance.
2020-02-06 10:53:42.002931: I tensorflow/core/grappler/devices.cc:60] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA support)
2020-02-06 10:53:42.003093: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session
2020-02-06 10:53:42.111911: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:716] Optimization results for grappler item: graph_to_optimize
2020-02-06 10:53:42.111960: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718]   function_optimizer: Graph size after: 2070 nodes (1696), 5733 edges (5354), time = 66.938ms.
2020-02-06 10:53:42.111973: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718]   function_optimizer: function_optimizer did nothing. time = 1.093ms.
2020-02-06 10:53:48.038844: I tensorflow/core/grappler/devices.cc:60] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA support)
2020-02-06 10:53:48.038997: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session
2020-02-06 10:53:49.980217: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:716] Optimization results for grappler item: graph_to_optimize
2020-02-06 10:53:49.980262: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718]   constant folding: Graph size after: 1268 nodes (-370), 4423 edges (-734), time = 922.534ms.
2020-02-06 10:53:49.980274: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:718]   constant folding: Graph size after: 1268 nodes (0), 4423 edges (0), time = 255.534ms.
Traceback (most recent call last):
  File ""coral/coral_quantizer.py"", line 38, in <module>
    tflite_quant_model = converter.convert()
  File ""/share/pkg.7/tensorflow/2.0.0/install/lib/SCC/../python3.6/site-packages/tensorflow_core/lite/python/lite.py"", line 446, in convert
    **converter_kwargs)
  File ""/share/pkg.7/tensorflow/2.0.0/install/lib/SCC/../python3.6/site-packages/tensorflow_core/lite/python/convert.py"", line 449, in toco_convert_impl
    enable_mlir_converter=enable_mlir_converter)
  File ""/share/pkg.7/tensorflow/2.0.0/install/lib/SCC/../python3.6/site-packages/tensorflow_core/lite/python/convert.py"", line 200, in toco_convert_protos
    raise ConverterError(""See console for info.\n%s\n%s\n"" % (stdout, stderr))
tensorflow.lite.python.convert.ConverterError: See console for info.
2020-02-06 10:54:00.060634: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 676 operators, 1271 arrays (0 quantized)
2020-02-06 10:54:00.077126: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 676 operators, 1271 arrays (0 quantized)
2020-02-06 10:54:00.465306: F tensorflow/lite/toco/graph_transformations/resolve_strided_slice_attributes.cc:95] Check failed: start_indices_size <= num_input_axes (2 vs. 1)StridedSlice op requires no more than 1 start indices
Fatal Python error: Aborted

Current thread 0x00007fbbde05b740 (most recent call first):
  File ""/share/pkg.7/tensorflow/2.0.0/install/lib/SCC/../python3.6/site-packages/tensorflow_core/lite/toco/python/toco_from_protos.py"", line 52 in execute
  File ""/share/pkg.7/tensorflow/2.0.0/install/lib/SCC/../python3.6/site-packages/absl/app.py"", line 250 in _run_main
  File ""/share/pkg.7/tensorflow/2.0.0/install/lib/SCC/../python3.6/site-packages/absl/app.py"", line 299 in run
  File ""/share/pkg.7/tensorflow/2.0.0/install/lib/SCC/../python3.6/site-packages/tensorflow_core/python/platform/app.py"", line 40 in run
  File ""/share/pkg.7/tensorflow/2.0.0/install/lib/SCC/../python3.6/site-packages/tensorflow_core/lite/toco/python/toco_from_protos.py"", line 89 in main
  File ""/share/pkg.7/tensorflow/2.0.0/install/bin/toco_from_protos"", line 10 in <module>
```

**Also, please include a link to the saved model or GraphDef**

```
# Put link here or attach to the issue.
https://drive.google.com/a/bu.edu/file/d/1STaqguXrsKaqNbzxmvGVwzpwWZEiC4K6/view?usp=sharing
```

**Failure details**
Hello,
I am trying to run the full YOLOv3 on Coral EdgeTPU. To do this, I am currently trying to convert the savedmodel (.pb format) of trained yolov3 into the quantized .tflite model using the code I attached above.
For some reason, the conversion failed with this error:
```
Check failed: start_indices_size <= num_input_axes (2 vs. 1)StridedSlice op requires no more than 1 start indices
Fatal Python error: Aborted)
```
I was able to convert the official pretrained MobileNetv1 savedmodel file into the quantized .tflite model using the exact same code. 

I am using this repo (https://github.com/YunYang1994/TensorFlow2.0-Examples/tree/master/4-Object_Detection/YOLOV3) for the YOLOv3 Tensorflow 2.0.0 implementation.

Do you know what is causing this failure of conversion?
Thank you.

**Any other info / logs**

Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

YOLOv3's implementation code => (https://github.com/YunYang1994/TensorFlow2.0-Examples/tree/master/4-Object_Detection/YOLOV3)

Thank you for your help.
"
36516,"Misleading documentation for hook parameters in estimators evaluate, predict, train methods","
The documentation for pre-made estimators such as tensorflow.estimator.LinearRegressor says that each of the methods evaluate, predict and train take a parameter called ""hooks"", which is a list of tensorflow.train.SessionRunHooks. However, no such class exist in the v2.1 API; instead, the source code says that it expects instances of tensorflow.compat.v1.train.SessionRunHook.

In the example of LinearRegressor (other pre-made estimators share the same problem), this is the API doc, which I believe is generated directly from the source code (see the documentation of the parameters for the train, evaluate and predict methods):
https://www.tensorflow.org/api_docs/python/tf/estimator/LinearRegressor#evaluate
https://www.tensorflow.org/api_docs/python/tf/estimator/LinearRegressor#predict
https://www.tensorflow.org/api_docs/python/tf/estimator/LinearRegressor#train

This is the source code that says it expects a class from the compat.v1 API:
https://github.com/tensorflow/estimator/blob/a7ba3b45d07dd517a0e6ff38e90ae3aa240f424b/tensorflow_estimator/python/estimator/estimator.py#L1947



"
36515,Provide complete tutorial on how to use MultiWorkerMirroredStrategy,"## URL(s) with the issue:

https://www.tensorflow.org/tutorials/distribute/multi_worker_with_keras#train_the_model_with_multiworkermirroredstrategy

## Description of issue (what needs changing):

There is a large and often overlooked caveat: You need to pass `steps_per_epoch`. This leads to issues like https://github.com/tensorflow/tensorflow/issues/34821, https://github.com/tensorflow/tensorflow/issues/36153. It should be explained, how `steps_per_epoch` should be set. Searching the examples does not really help: `num_samples / batch_size` is sometimes rounded up and sometimes down. A clear guideline for Multi-Worker would be appreciated.

Also it is not described how loading the dataset should happen. Doing that in a Multi-Worker setting is tricky as the data needs to be downloaded exactly once. See https://github.com/tensorflow/datasets/issues/1302

Also the developers of `tensorflow_datasets` claim, that the auto-sharding done by TF won't work properly and suggest to use custom functions: https://github.com/tensorflow/datasets/issues/1302, https://github.com/tensorflow/datasets/issues/1426. It should be evaluated whether this is the case and where this has to be addressed.

Finally a description on how to run the evaluation is missing for completeness. This runs into another issue that by default files are sharded and e.g. MNIST only has 1 file for test data which makes TF fail. See also https://github.com/tensorflow/datasets/issues/1405

For the last point the solution is to use 

```
options = tf.data.Options()
options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.DATA
train_datasets = train_datasets.with_options(options)
```
Which can be found by searching the docs. But it needs to be in the tutorial (and maybe even the default)"
36514,bfloat16 does not flush denormals (subnormal floats) to zero,"[BFloat16: The secret to high performance on Cloud TPUs](https://cloud.google.com/blog/products/ai-machine-learning/bfloat16-the-secret-to-high-performance-on-cloud-tpus), Shibo Wang, Pankaj Kanwar (@pkanwar23 right?) , August 23, 2019, says:

> bfloat16 handles denormals differently from FP32: it flushes them to zero

I assume this implies that for a denormal 32-bit floating point, `denorm`, the expression `float{bfloat16{denorm}}` should be equal to zero.

The current implementation of `tensorflow::bfloat16` (master branch, revision bc28d49ce2659f846e03c13a64ebe83fc6fb8ff1) appears to behave differently. As can be observed by the following test:

    for (float denorm = std::numeric_limits<float>::denorm_min();
      denorm < std::numeric_limits<float>::min();
      denorm = std::nextafterf(denorm, 1.0f))
        ASSERT_EQ(float{ tensorflow::bfloat16{denorm} }, 0.0f);

This assertion fails on the current implementation, from [tensorflow/core/lib/bfloat16](https://github.com/tensorflow/tensorflow/tree/bc28d49ce2659f846e03c13a64ebe83fc6fb8ff1/tensorflow/core/lib/bfloat16)

Is that indeed a bug in `tensorflow::bfloat16`?





"
36513,Cannot perform full-integer post-training quantization in converting to flite models,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Both
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS, Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No
- TensorFlow installed from (source or binary): either
- TensorFlow version (use command below): 1.15.2
- Python version: 3
- Bazel version (if compiling from source): 0.26.1
- GCC/Compiler version (if compiling from source): - 
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A

**Describe the current behavior**
The issue relates to full integer post-training quantization in tflite conversion. Following the same example in the [documentation](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/g3doc/performance/post_training_integer_quant.ipynb), but applied to my data have issues when I identify the input_data for the interpreter as float32 (below my data in R is in float32 already normalized between [0,10]):

`input_data = np.array(R, dtype=np.float32)`
`interpreter.set_tensor(input_details[0]['index'], input_data)`
 `interpreter.invoke()`

When then I call the TFLite converter (using `tf.compat.v1.lite.TFLiteConverter.from_keras_model_file` in TF2.x or `tf.lite.TFLiteConverter.from_keras_model_file` in TF1.x) again following from the documentation:

`converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]`
    `converter.representative_dataset = representative_dataset_gen`
    `converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]`
    `converter.inference_input_type = tf.uint8`
    `converter.inference_output_type = tf.uint8`
    `tflite_quant_model = converter.convert()`


The post-quantized tflite is correctly created (and when compiled for the TPU, all ops are correctly assigned). However, when I run a prediction, I get the following error:
`ValueError: Cannot set tensor: Got value of type FLOAT32 but expected type UINT8 for input 16, name: conv2d_input`

Essentially, the `input_data = np.array(R, dtype=np.float32)`, needs to be set as uint8 for this to work. However, that breaks the model completely, as it casts all data between [0,1] into just zeros. 

To be clear, this does NOT happen when using TF2.x, by calling the converter with `tf.lite.TFLiteConverter.from_keras_model()`. Using the `input_data = np.array(R, dtype=np.float32)`, the post-training quantized tflite model is created and when used for predictions, it works as intended. However, when compiled, because I am using the `TFLiteConverterV2` , the quantization/dequantization ops are not assigned to the TPU, making it useless to deploy in embedded devices that require full integer quantization.

Any insight is greatly appreciated. Thanks in advance.

"
36511,bug of keras.metrics under @tf.function,"**System information**
- TensorFlow installed from source
- TensorFlow version: v2.1.0-0-ge5bf8de410 2.1.0
- Python version: 3.6.9 (default, Nov  7 2019, 10:44:02) [GCC 8.3.0]
- Bazel version (if compiling from source): 0.29.1
- GCC/Compiler version (if compiling from source): gcc (Ubuntu 7.4.0-1ubuntu1~18.04.1) 7.4.0
- CUDA/cuDNN version: n/a
- GPU model and memory: n/a

The tf.keras.metrics.Mean() class is not performing correctly under @tf.function annotation. It looks like some control_dependencies issues and I suspect similar bugs for other metrics.

**Code to reproduce the issue**
The results of `func1()`, `func2()`, and `func3()` should be all the same (a series of numbers starting from 4.5) in the following. However, `func2()` produces different result (a series of numbers starting from 0).
```
import tensorflow as tf

eval_dataset = tf.data.Dataset.range(10)
metric = tf.keras.metrics.Mean(name='mean', dtype=tf.float32)

def func1():
    for step in range(100):
        if tf.equal(step % 5, 0):
            for y in eval_dataset:
                x = tf.cast(y + step, tf.float32)
                metric(x)
            print(metric.result().numpy())
            metric.reset_states()

func1()

@tf.function
def func2():
    for step in range(100):
        if tf.equal(step % 5, 0):
            for y in eval_dataset:
                x = tf.cast(y + step, tf.float32)
                metric(x)
            tf.print(metric.result())
            metric.reset_states()

func2()

@tf.function
def func3():
    for step in range(100):
        if tf.equal(step % 5, 0):
            total = metric.total.assign(0.0)
            count = metric.count.assign(0)
            for y in eval_dataset:
                x = tf.cast(y + step, tf.float32)
                with tf.control_dependencies([total, count]):
                    total = metric.total.assign_add(x)
                    count = metric.count.assign_add(1)
            result = tf.math.divide_no_nan(total, count)
            tf.print(result)

func3()
```"
36510,MirroredStrategy() crashes with NVLinked GPUs,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Progress Linux 5+ (engywuck-backports) (Linux Debian Buster)
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): v2.1.0-rc2-17-ge5bf8de 2.1.0
- Python version: 3.7.3
- CUDA/cuDNN version: 10.1/7.0
- GPU model and memory: 2x Asus GeForxe RTX 2080 Ti, Compute Capability 7.5, With NVLink

**Describe the current behavior**
Training of a ResNet with NVLink enabled crashes with following error:
```bash
tensorflow.python.framework.errors_impl.InternalError: 2 root error(s) found.
  (0) Internal:  unhandled cuda error
         [[node Adam/NcclAllReduce (defined at workspace/gpu_tests/test_gpus.py:60) ]]
  (1) Internal:  unhandled cuda error
         [[node Adam/NcclAllReduce (defined at workspace/gpu_tests/test_gpus.py:60) ]]
         [[GroupCrossDeviceControlEdges_0/Adam/Adam/update_1_1/Const/_39]]
0 successful operations.
1 derived errors ignored. [Op:__inference_distributed_function_36247]

Function call stack:
distributed_function -> distributed_function
```
When I use cross_device_ops=tf.distribute.ReductionToOneDevice() it doesn't crash but it's not the optimal performance since it's not using NCCL. The NCCL seems to work however. Check the NCCL/all_reduce_perf log below. 

**Describe the expected behavior**
Training should not crash. 

**Code to reproduce the issue**
```bash
# -*- coding: utf-8 -*-

import numpy as np
from tensorflow.keras.applications.resnet50 import ResNet50
import tensorflow as tf
import tensorflow_datasets as tfds

LENGTH_DATASET = 17509
NUM_CLASSES = 9
IMG_SHAPE = (256, 256, 3)
BATCH_SIZE = 32


def mymap_func(features):
    return features[""image""], features[""label""]


AUTOTUNE = tf.data.experimental.AUTOTUNE

# create input pipeline
dataset = tfds.load(name=""deep_weeds"", split=""train"")
dataset = dataset.map(mymap_func,
                      num_parallel_calls=tf.data.experimental.AUTOTUNE)
dataset = dataset.cache()
dataset = dataset.shuffle(buffer_size=LENGTH_DATASET, seed=42,
                          reshuffle_each_iteration=True)
dataset = dataset.batch(batch_size=BATCH_SIZE, drop_remainder=True).repeat()
dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)


# create model
img_width, img_height = 270, 270

shape, classes = (img_width, img_height, 1), 3

# strategy = tf.distribute.MirroredStrategy(cross_device_ops=tf.distribute.ReductionToOneDevice())
strategy = tf.distribute.MirroredStrategy()
print(""Number of devices in strategy: {}"".format(strategy.num_replicas_in_sync))

with strategy.scope():

    model = ResNet50(include_top=True,
                       weights=None,
                       input_tensor=None,
                       input_shape=IMG_SHAPE,
                       pooling=None,
                       classes=NUM_CLASSES)

    model.compile(optimizer=tf.optimizers.Adam(),
                    loss='sparse_categorical_crossentropy',
                    metrics=[""accuracy""])

    train_steps = np.ceil(LENGTH_DATASET / BATCH_SIZE)
    history = model.fit(
            x=dataset,
            epochs=10,
            verbose=1,
            steps_per_epoch=train_steps,
            use_multiprocessing=False,
            workers=8)
```

**Other info / logs**
Full Tensorflow Dump:
```bash
2020-02-06 13:50:44.982897: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libnvinfer.so.6
2020-02-06 13:50:44.984479: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libnvinfer_plugin.so.6
2020-02-06 13:50:46.159056: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-02-06 13:50:46.251661: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:3b:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2020-02-06 13:50:46.252336: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 1 with properties: 
pciBusID: 0000:af:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2020-02-06 13:50:46.252374: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-02-06 13:50:46.252413: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-02-06 13:50:46.254193: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-02-06 13:50:46.254548: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-02-06 13:50:46.256609: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-02-06 13:50:46.257880: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-02-06 13:50:46.257929: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-02-06 13:50:46.260454: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0, 1
2020-02-06 13:50:46.260872: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2020-02-06 13:50:46.305692: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2100000000 Hz
2020-02-06 13:50:46.313917: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x43d2220 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-02-06 13:50:46.313956: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-02-06 13:50:46.929224: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4360be0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-02-06 13:50:46.929289: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce RTX 2080 Ti, Compute Capability 7.5
2020-02-06 13:50:46.929335: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): GeForce RTX 2080 Ti, Compute Capability 7.5
2020-02-06 13:50:46.931578: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:3b:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2020-02-06 13:50:46.933238: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 1 with properties: 
pciBusID: 0000:af:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2020-02-06 13:50:46.933319: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-02-06 13:50:46.933354: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-02-06 13:50:46.933404: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-02-06 13:50:46.933441: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-02-06 13:50:46.933477: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-02-06 13:50:46.933514: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-02-06 13:50:46.933544: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-02-06 13:50:46.939900: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0, 1
2020-02-06 13:50:46.939975: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-02-06 13:50:47.657348: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-02-06 13:50:47.657397: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 1 
2020-02-06 13:50:47.657405: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N Y 
2020-02-06 13:50:47.657411: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 1:   Y N 
2020-02-06 13:50:47.659222: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10235 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:3b:00.0, compute capability: 7.5)
2020-02-06 13:50:47.660401: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 10235 MB memory) -> physical GPU (device: 1, name: GeForce RTX 2080 Ti, pci bus id: 0000:af:00.0, compute capability: 7.5)
Number of devices in strategy: 2
Train for 548.0 steps
Epoch 1/10
2020-02-06 13:51:06.516702: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-02-06 13:51:08.552933: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-02-06 13:51:09.714280: W tensorflow/stream_executor/gpu/redzone_allocator.cc:312] Not found: ./bin/ptxas not found
Relying on driver to perform ptx compilation. This message will be only logged once.
2020-02-06 13:51:11.686255: W tensorflow/core/framework/op_kernel.cc:1655] OP_REQUIRES failed at nccl_ops.cc:104 : Internal: unhandled cuda error
2020-02-06 13:51:11.686300: W tensorflow/core/common_runtime/base_collective_executor.cc:217] BaseCollectiveExecutor::StartAbort Internal: unhandled cuda error
         [[{{node Adam/NcclAllReduce}}]]
         [[GroupCrossDeviceControlEdges_0/Adam/Adam/update_1_1/Const/_39]]
2020-02-06 13:51:11.686335: W tensorflow/core/common_runtime/base_collective_executor.cc:217] BaseCollectiveExecutor::StartAbort Internal: unhandled cuda error
         [[{{node Adam/NcclAllReduce}}]]
         [[Identity_2/_60]]
2020-02-06 13:51:11.686381: W tensorflow/core/common_runtime/base_collective_executor.cc:217] BaseCollectiveExecutor::StartAbort Internal: unhandled cuda error
         [[{{node Adam/NcclAllReduce}}]]
2020-02-06 13:51:11.686678: W tensorflow/core/framework/op_kernel.cc:1655] OP_REQUIRES failed at nccl_ops.cc:104 : Internal: unhandled cuda error
  1/548 [..............................] - ETA: 2:54:10Traceback (most recent call last):
  File ""workspace/gpu_tests/test_gpus.py"", line 60, in <module>
    workers=8)
  File ""/home/sam2/workspace/python_venvs/tf-run/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py"", line 819, in fit
    use_multiprocessing=use_multiprocessing)
  File ""/home/sam2/workspace/python_venvs/tf-run/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py"", line 342, in fit
    total_epochs=epochs)
  File ""/home/sam2/workspace/python_venvs/tf-run/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py"", line 128, in run_one_epoch
    batch_outs = execution_function(iterator)
  File ""/home/sam2/workspace/python_venvs/tf-run/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py"", line 98, in execution_function
    distributed_function(input_fn))
  File ""/home/sam2/workspace/python_venvs/tf-run/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py"", line 568, in __call__
    result = self._call(*args, **kwds)
  File ""/home/sam2/workspace/python_venvs/tf-run/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py"", line 632, in _call
    return self._stateless_fn(*args, **kwds)
  File ""/home/sam2/workspace/python_venvs/tf-run/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py"", line 2363, in __call__
    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access
  File ""/home/sam2/workspace/python_venvs/tf-run/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py"", line 1611, in _filtered_call
    self.captured_inputs)
  File ""/home/sam2/workspace/python_venvs/tf-run/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py"", line 1692, in _call_flat
    ctx, args, cancellation_manager=cancellation_manager))
  File ""/home/sam2/workspace/python_venvs/tf-run/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py"", line 545, in call
    ctx=ctx)
  File ""/home/sam2/workspace/python_venvs/tf-run/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py"", line 67, in quick_execute
    six.raise_from(core._status_to_exception(e.code, message), None)
  File ""<string>"", line 3, in raise_from
tensorflow.python.framework.errors_impl.InternalError: 2 root error(s) found.
  (0) Internal:  unhandled cuda error
         [[node Adam/NcclAllReduce (defined at workspace/gpu_tests/test_gpus.py:60) ]]
  (1) Internal:  unhandled cuda error
         [[node Adam/NcclAllReduce (defined at workspace/gpu_tests/test_gpus.py:60) ]]
         [[GroupCrossDeviceControlEdges_0/Adam/Adam/update_1_1/Const/_39]]
0 successful operations.
1 derived errors ignored. [Op:__inference_distributed_function_36247]

Function call stack:
distributed_function -> distributed_function

2020-02-06 13:51:12.044366: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled
2020-02-06 13:51:12.045417: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled

```
NVIDIA NCCL Test Dump:
```bash
workspace/nccl-tests/build/all_reduce_perf -b 8 -e 128M -g 2   
# nThread 1 nGpus 2 minBytes 8 maxBytes 134217728 step: 1048576(bytes) warmup iters: 5 iters: 20 validation: 1 
#
# Using devices
#   Rank  0 Pid   2374 on     tf-run device  0 [0x3b] GeForce RTX 2080 Ti
#   Rank  1 Pid   2374 on     tf-run device  1 [0xaf] GeForce RTX 2080 Ti
#
#                                                     out-of-place                       in-place          
#       size         count    type   redop     time   algbw   busbw  error     time   algbw   busbw  error
#        (B)    (elements)                     (us)  (GB/s)  (GB/s)            (us)  (GB/s)  (GB/s)       
           8             2   float     sum    14.31    0.00    0.00  0e+00    13.72    0.00    0.00  0e+00
     1048584        262146   float     sum    69.45   15.10   15.10  0e+00    69.72   15.04   15.04  0e+00
     2097160        524290   float     sum    111.0   18.89   18.89  0e+00    108.2   19.39   19.39  0e+00
     3145736        786434   float     sum    151.2   20.80   20.80  0e+00    149.1   21.10   21.10  0e+00
     4194312       1048578   float     sum    192.3   21.81   21.81  0e+00    191.3   21.93   21.93  0e+00
     5242888       1310722   float     sum    233.3   22.48   22.48  0e+00    231.2   22.68   22.68  0e+00
     6291464       1572866   float     sum    273.2   23.03   23.03  0e+00    271.2   23.20   23.20  0e+00
     7340040       1835010   float     sum    312.8   23.46   23.46  0e+00    310.1   23.67   23.67  0e+00
     8388616       2097154   float     sum    333.5   25.16   25.16  0e+00    327.8   25.59   25.59  0e+00
     9437192       2359298   float     sum    379.4   24.88   24.88  0e+00    377.8   24.98   24.98  0e+00
    10485768       2621442   float     sum    417.6   25.11   25.11  0e+00    416.1   25.20   25.20  0e+00
    11534344       2883586   float     sum    439.1   26.27   26.27  0e+00    437.6   26.36   26.36  0e+00
    12582920       3145730   float     sum    492.7   25.54   25.54  0e+00    491.0   25.63   25.63  0e+00
    13631496       3407874   float     sum    490.5   27.79   27.79  0e+00    480.3   28.38   28.38  0e+00
    14680072       3670018   float     sum    495.9   29.60   29.60  0e+00    491.4   29.87   29.87  0e+00
    15728648       3932162   float     sum    526.7   29.86   29.86  0e+00    525.1   29.95   29.95  0e+00
    16777224       4194306   float     sum    549.9   30.51   30.51  0e+00    546.8   30.68   30.68  0e+00
    17825800       4456450   float     sum    579.1   30.78   30.78  0e+00    578.4   30.82   30.82  0e+00
    18874376       4718594   float     sum    631.1   29.90   29.90  0e+00    629.7   29.98   29.98  0e+00
    19922952       4980738   float     sum    664.7   29.97   29.97  0e+00    661.5   30.12   30.12  0e+00
    20971528       5242882   float     sum    699.4   29.98   29.98  0e+00    699.0   30.00   30.00  0e+00
    22020104       5505026   float     sum    757.4   29.07   29.07  0e+00    754.8   29.17   29.17  0e+00
    23068680       5767170   float     sum    718.0   32.13   32.13  0e+00    717.8   32.14   32.14  0e+00
    24117256       6029314   float     sum    777.1   31.04   31.04  0e+00    775.5   31.10   31.10  0e+00
    25165832       6291458   float     sum    807.1   31.18   31.18  0e+00    805.2   31.26   31.26  0e+00
    26214408       6553602   float     sum    838.5   31.26   31.26  0e+00    836.8   31.33   31.33  0e+00
    27262984       6815746   float     sum    871.7   31.27   31.27  0e+00    870.8   31.31   31.31  0e+00
    28311560       7077890   float     sum    934.3   30.30   30.30  0e+00    931.6   30.39   30.39  0e+00
    29360136       7340034   float     sum    934.6   31.41   31.41  0e+00    934.2   31.43   31.43  0e+00
    30408712       7602178   float     sum    968.5   31.40   31.40  0e+00    965.5   31.50   31.50  0e+00
    31457288       7864322   float     sum   1035.0   30.39   30.39  0e+00   1032.3   30.47   30.47  0e+00
    32505864       8126466   float     sum   1102.1   29.50   29.50  0e+00   1099.9   29.55   29.55  0e+00
    33554440       8388610   float     sum    963.5   34.83   34.83  0e+00    960.3   34.94   34.94  0e+00
    34603016       8650754   float     sum    989.6   34.97   34.97  0e+00    987.8   35.03   35.03  0e+00
    35651592       8912898   float     sum   1055.1   33.79   33.79  0e+00   1054.7   33.80   33.80  0e+00
    36700168       9175042   float     sum   1163.0   31.56   31.56  0e+00   1158.4   31.68   31.68  0e+00
    37748744       9437186   float     sum   1155.9   32.66   32.66  0e+00   1152.5   32.76   32.76  0e+00
    38797320       9699330   float     sum   1185.6   32.72   32.72  0e+00   1183.4   32.78   32.78  0e+00
    39845896       9961474   float     sum   1261.6   31.58   31.58  0e+00   1259.5   31.64   31.64  0e+00
    40894472      10223618   float     sum   1206.2   33.90   33.90  0e+00   1204.0   33.97   33.97  0e+00
    41943048      10485762   float     sum   1235.5   33.95   33.95  0e+00   1233.4   34.01   34.01  0e+00
    42991624      10747906   float     sum   1310.8   32.80   32.80  0e+00   1307.8   32.87   32.87  0e+00
    44040200      11010050   float     sum   1343.2   32.79   32.79  0e+00   1339.9   32.87   32.87  0e+00
    45088776      11272194   float     sum   1376.5   32.76   32.76  0e+00   1373.3   32.83   32.83  0e+00
    46137352      11534338   float     sum   1406.1   32.81   32.81  0e+00   1403.5   32.87   32.87  0e+00
    47185928      11796482   float     sum   1386.1   34.04   34.04  0e+00   1382.8   34.12   34.12  0e+00
    48234504      12058626   float     sum   1418.1   34.01   34.01  0e+00   1415.0   34.09   34.09  0e+00
    49283080      12320770   float     sum   1498.5   32.89   32.89  0e+00   1494.7   32.97   32.97  0e+00
    50331656      12582914   float     sum   1482.1   33.96   33.96  0e+00   1478.4   34.05   34.05  0e+00
    51380232      12845058   float     sum   1507.4   34.08   34.08  0e+00   1505.2   34.14   34.14  0e+00
    52428808      13107202   float     sum   1536.0   34.13   34.13  0e+00   1534.1   34.18   34.18  0e+00
    53477384      13369346   float     sum   1568.3   34.10   34.10  0e+00   1563.7   34.20   34.20  0e+00
    54525960      13631490   float     sum   1601.1   34.05   34.05  0e+00   1596.8   34.15   34.15  0e+00
    55574536      13893634   float     sum   1691.0   32.87   32.87  0e+00   1687.4   32.93   32.93  0e+00
    56623112      14155778   float     sum   1721.4   32.89   32.89  0e+00   1717.8   32.96   32.96  0e+00
    57671688      14417922   float     sum   1751.2   32.93   32.93  0e+00   1747.9   32.99   32.99  0e+00
    58720264      14680066   float     sum   1716.3   34.21   34.21  0e+00   1714.4   34.25   34.25  0e+00
    59768840      14942210   float     sum   1748.4   34.19   34.19  0e+00   1744.2   34.27   34.27  0e+00
    60817416      15204354   float     sum   1709.5   35.58   35.58  0e+00   1707.4   35.62   35.62  0e+00
    61865992      15466498   float     sum   1803.8   34.30   34.30  0e+00   1799.7   34.38   34.38  0e+00
    62914568      15728642   float     sum   1968.9   31.95   31.95  0e+00   1966.7   31.99   31.99  0e+00
    63963144      15990786   float     sum   2141.1   29.87   29.87  0e+00   2133.0   29.99   29.99  0e+00
    65011720      16252930   float     sum   2173.3   29.91   29.91  0e+00   2168.4   29.98   29.98  0e+00
    66060296      16515074   float     sum   2206.5   29.94   29.94  0e+00   2200.0   30.03   30.03  0e+00
    67108872      16777218   float     sum   1526.3   43.97   43.97  0e+00   1526.4   43.96   43.96  0e+00
    68157448      17039362   float     sum   1547.9   44.03   44.03  0e+00   1549.3   43.99   43.99  0e+00
    69206024      17301506   float     sum   1570.9   44.05   44.05  0e+00   1573.0   44.00   44.00  0e+00
    70254600      17563650   float     sum   1593.1   44.10   44.10  0e+00   1595.0   44.05   44.05  0e+00
    71303176      17825794   float     sum   1773.7   40.20   40.20  0e+00   1770.2   40.28   40.28  0e+00
    72351752      18087938   float     sum   1954.7   37.01   37.01  0e+00   1948.8   37.13   37.13  0e+00
    73400328      18350082   float     sum   2058.5   35.66   35.66  0e+00   2058.1   35.66   35.66  0e+00
    74448904      18612226   float     sum   2005.1   37.13   37.13  0e+00   2003.9   37.15   37.15  0e+00
    75497480      18874370   float     sum   1948.4   38.75   38.75  0e+00   1950.2   38.71   38.71  0e+00
    76546056      19136514   float     sum   1976.9   38.72   38.72  0e+00   1973.3   38.79   38.79  0e+00
    77594632      19398658   float     sum   1999.2   38.81   38.81  0e+00   1999.1   38.81   38.81  0e+00
    78643208      19660802   float     sum   2024.9   38.84   38.84  0e+00   2023.3   38.87   38.87  0e+00
    79691784      19922946   float     sum   2140.6   37.23   37.23  0e+00   2139.8   37.24   37.24  0e+00
    80740360      20185090   float     sum   2167.3   37.25   37.25  0e+00   2166.1   37.28   37.28  0e+00
    81788936      20447234   float     sum   2197.1   37.23   37.23  0e+00   2195.4   37.25   37.25  0e+00
    82837512      20709378   float     sum   2224.3   37.24   37.24  0e+00   2223.9   37.25   37.25  0e+00
    83886088      20971522   float     sum   2075.4   40.42   40.42  0e+00   2076.2   40.40   40.40  0e+00
    84934664      21233666   float     sum   2193.7   38.72   38.72  0e+00   2191.7   38.75   38.75  0e+00
    85983240      21495810   float     sum   2304.1   37.32   37.32  0e+00   2304.0   37.32   37.32  0e+00
    87031816      21757954   float     sum   2336.0   37.26   37.26  0e+00   2332.1   37.32   37.32  0e+00
    88080392      22020098   float     sum   2264.8   38.89   38.89  0e+00   2264.1   38.90   38.90  0e+00
    89128968      22282242   float     sum   2289.7   38.93   38.93  0e+00   2285.5   39.00   39.00  0e+00
    90177544      22544386   float     sum   2322.3   38.83   38.83  0e+00   2319.9   38.87   38.87  0e+00
    91226120      22806530   float     sum   2349.6   38.83   38.83  0e+00   2346.1   38.88   38.88  0e+00
    92274696      23068674   float     sum   2373.6   38.87   38.87  0e+00   2369.7   38.94   38.94  0e+00
    93323272      23330818   float     sum   2499.7   37.33   37.33  0e+00   2498.5   37.35   37.35  0e+00
    94371848      23592962   float     sum   2326.3   40.57   40.57  0e+00   2324.5   40.60   40.60  0e+00
    95420424      23855106   float     sum   2455.4   38.86   38.86  0e+00   2452.3   38.91   38.91  0e+00
    96469000      24117250   float     sum   2478.8   38.92   38.92  0e+00   2478.5   38.92   38.92  0e+00
    97517576      24379394   float     sum   2398.4   40.66   40.66  0e+00   2402.4   40.59   40.59  0e+00
    98566152      24641538   float     sum   2635.1   37.41   37.41  0e+00   2630.0   37.48   37.48  0e+00
    99614728      24903682   float     sum   2769.1   35.97   35.97  0e+00   2766.5   36.01   36.01  0e+00
   100663304      25165826   float     sum   2253.1   44.68   44.68  0e+00   2253.7   44.67   44.67  0e+00
   101711880      25427970   float     sum   2276.9   44.67   44.67  0e+00   2274.8   44.71   44.71  0e+00
   102760456      25690114   float     sum   2411.1   42.62   42.62  0e+00   2410.8   42.62   42.62  0e+00
   103809032      25952258   float     sum   2546.9   40.76   40.76  0e+00   2548.4   40.73   40.73  0e+00
   104857608      26214402   float     sum   2569.5   40.81   40.81  0e+00   2573.8   40.74   40.74  0e+00
   105906184      26476546   float     sum   2486.3   42.60   42.60  0e+00   2483.1   42.65   42.65  0e+00
   106954760      26738690   float     sum   2624.7   40.75   40.75  0e+00   2625.0   40.75   40.75  0e+00
   108003336      27000834   float     sum   2649.5   40.76   40.76  0e+00   2647.9   40.79   40.79  0e+00
   109051912      27262978   float     sum   2553.7   42.70   42.70  0e+00   2553.3   42.71   42.71  0e+00
   110100488      27525122   float     sum   2691.2   40.91   40.91  0e+00   2687.1   40.97   40.97  0e+00
   111149064      27787266   float     sum   2837.8   39.17   39.17  0e+00   2836.9   39.18   39.18  0e+00
   112197640      28049410   float     sum   2506.7   44.76   44.76  0e+00   2508.9   44.72   44.72  0e+00
   113246216      28311554   float     sum   2655.0   42.65   42.65  0e+00   2654.6   42.66   42.66  0e+00
   114294792      28573698   float     sum   2676.8   42.70   42.70  0e+00   2675.6   42.72   42.72  0e+00
   115343368      28835842   float     sum   2697.5   42.76   42.76  0e+00   2689.4   42.89   42.89  0e+00
   116391944      29097986   float     sum   2842.8   40.94   40.94  0e+00   2846.4   40.89   40.89  0e+00
   117440520      29360130   float     sum   2621.1   44.81   44.81  0e+00   2618.9   44.84   44.84  0e+00
   118489096      29622274   float     sum   2777.0   42.67   42.67  0e+00   2774.3   42.71   42.71  0e+00
   119537672      29884418   float     sum   2795.5   42.76   42.76  0e+00   2796.7   42.74   42.74  0e+00
   120586248      30146562   float     sum   2946.1   40.93   40.93  0e+00   2945.9   40.93   40.93  0e+00
   121634824      30408706   float     sum   2712.3   44.85   44.85  0e+00   2714.7   44.81   44.81  0e+00
   122683400      30670850   float     sum   2861.5   42.87   42.87  0e+00   2865.6   42.81   42.81  0e+00
   123731976      30932994   float     sum   2749.9   45.00   45.00  0e+00   2752.6   44.95   44.95  0e+00
   124780552      31195138   float     sum   2778.3   44.91   44.91  0e+00   2779.9   44.89   44.89  0e+00
   125829128      31457282   float     sum   2797.9   44.97   44.97  0e+00   2796.1   45.00   45.00  0e+00
   126877704      31719426   float     sum   2822.8   44.95   44.95  0e+00   2823.7   44.93   44.93  0e+00
   127926280      31981570   float     sum   2838.3   45.07   45.07  0e+00   2845.2   44.96   44.96  0e+00
   128974856      32243714   float     sum   2862.4   45.06   45.06  0e+00   2864.9   45.02   45.02  0e+00
   130023432      32505858   float     sum   2887.1   45.04   45.04  0e+00   2891.1   44.97   44.97  0e+00
   131072008      32768002   float     sum   2907.2   45.08   45.08  0e+00   2913.2   44.99   44.99  0e+00
   132120584      33030146   float     sum   2931.8   45.07   45.07  0e+00   2937.5   44.98   44.98  0e+00
   133169160      33292290   float     sum   2955.3   45.06   45.06  0e+00   2959.4   45.00   45.00  0e+00
# Out of bounds values : 0 OK
# Avg bus bandwidth    : 35.5133 
#

```
"
36509,ValueError: Duplicate node name in graph,"I am trying to run following code（which comes from Chollet's Deep Learning with Python) on a kaggle kernel,but get an error
```
import keras
from keras import layers
from keras import backend as K
from keras.models import Model
import numpy as np
img_shape=(28,28,1)
batch_size=16
latent_dim=2
input_img=keras.Input(shape=img_shape)
x=layers.Conv2D(32,3,padding='same',activation='relu')(input_img)
x=layers.Conv2D(64,3,padding='same',activation='relu',strides=(2,2))(x)
x=layers.Conv2D(64,3,padding='same',activation='relu')(x)
x=layers.Conv2D(64,3,padding='same',activation='relu')(x)
shape_before_flattening=K.int_shape(x)
x=layers.Flatten()(x)
x=layers.Dense(32,activation='relu')(x)
z_mean=layers.Dense(latent_dim)(x)
z_log_var=layers.Dense(latent_dim)(x)
def sampling(args):
    z_mean,z_log_var=args
    epsilon=K.random_normal(shape=(K.shape(z_mean)[0],latent_dim),mean=0,stddev=1)
    return z_mean+K.exp(0.5*z_log_var)*epsilon
z=layers.Lambda(sampling)([z_mean,z_log_var])
```
the trace back is following
```
InvalidArgumentError                      Traceback (most recent call last)
/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py in _create_c_op(graph, node_def, inputs, control_inputs)
   1618   try:
-> 1619     c_op = c_api.TF_FinishOperation(op_desc)
   1620   except errors.InvalidArgumentError as e:

InvalidArgumentError: Duplicate node name in graph: 'lambda_7/random_normal/shape'

During handling of the above exception, another exception occurred:

ValueError                                Traceback (most recent call last)
<ipython-input-12-6c91b1ce5964> in <module>
      3     epsilon=K.random_normal(shape=(K.shape(z_mean)[0],latent_dim),mean=0,stddev=1)
      4     return z_mean+K.exp(0.5*z_log_var)*epsilon
----> 5 z=layers.Lambda(sampling)([z_mean,z_log_var])

/opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py in symbolic_fn_wrapper(*args, **kwargs)
     73         if _SYMBOLIC_SCOPE.value:
     74             with get_graph().as_default():
---> 75                 return func(*args, **kwargs)
     76         else:
     77             return func(*args, **kwargs)

/opt/conda/lib/python3.6/site-packages/keras/engine/base_layer.py in __call__(self, inputs, **kwargs)
    504             if all([s is not None
    505                     for s in to_list(input_shape)]):
--> 506                 output_shape = self.compute_output_shape(input_shape)
    507             else:
    508                 if isinstance(input_shape, list):

/opt/conda/lib/python3.6/site-packages/keras/layers/core.py in compute_output_shape(self, input_shape)
    672                     xs = [K.placeholder(shape=shape, dtype=dtype)
    673                           for shape, dtype in zip(input_shape, self._input_dtypes)]
--> 674                     x = self.call(xs)
    675                 else:
    676                     x = K.placeholder(shape=input_shape, dtype=self._input_dtypes)

/opt/conda/lib/python3.6/site-packages/keras/layers/core.py in call(self, inputs, mask)
    714         else:
    715             self._input_dtypes = K.dtype(inputs)
--> 716         return self.function(inputs, **arguments)
    717 
    718     def compute_mask(self, inputs, mask=None):

<ipython-input-12-6c91b1ce5964> in sampling(args)
      1 def sampling(args):
      2     z_mean,z_log_var=args
----> 3     epsilon=K.random_normal(shape=(K.shape(z_mean)[0],latent_dim),mean=0,stddev=1)
      4     return z_mean+K.exp(0.5*z_log_var)*epsilon
      5 z=layers.Lambda(sampling)([z_mean,z_log_var])

/opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py in random_normal(shape, mean, stddev, dtype, seed)
   4327     with tf_ops.init_scope():
   4328         return tf_keras_backend.random_normal(
-> 4329             shape, mean=mean, stddev=stddev, dtype=dtype, seed=seed)
   4330 
   4331 

/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/keras/backend.py in random_normal(shape, mean, stddev, dtype, seed)
   5600     seed = np.random.randint(10e6)
   5601   return random_ops.random_normal(
-> 5602       shape, mean=mean, stddev=stddev, dtype=dtype, seed=seed)
   5603 
   5604 

/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/ops/random_ops.py in random_normal(shape, mean, stddev, dtype, seed, name)
     67   """"""
     68   with ops.name_scope(name, ""random_normal"", [shape, mean, stddev]) as name:
---> 69     shape_tensor = tensor_util.shape_tensor(shape)
     70     mean_tensor = ops.convert_to_tensor(mean, dtype=dtype, name=""mean"")
     71     stddev_tensor = ops.convert_to_tensor(stddev, dtype=dtype, name=""stddev"")

/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/framework/tensor_util.py in shape_tensor(shape)
    992       # not convertible to Tensors becasue of mixed content.
    993       shape = tuple(map(tensor_shape.dimension_value, shape))
--> 994   return ops.convert_to_tensor(shape, dtype=dtype, name=""shape"")
    995 
    996 

/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py in convert_to_tensor(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)
   1312 
   1313     if ret is None:
-> 1314       ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
   1315 
   1316     if ret is NotImplemented:

/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/ops/array_ops.py in _autopacking_conversion_function(v, dtype, name, as_ref)
   1366   elif dtype != inferred_dtype:
   1367     v = nest.map_structure(_cast_nested_seqs_to_dtype(dtype), v)
-> 1368   return _autopacking_helper(v, dtype, name or ""packed"")
   1369 
   1370 

/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/ops/array_ops.py in _autopacking_helper(list_or_tuple, dtype, name)
   1302           elems_as_tensors.append(
   1303               constant_op.constant(elem, dtype=dtype, name=str(i)))
-> 1304       return gen_array_ops.pack(elems_as_tensors, name=scope)
   1305     else:
   1306       return converted_elems

/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/ops/gen_array_ops.py in pack(values, axis, name)
   5702   axis = _execute.make_int(axis, ""axis"")
   5703   _, _, _op, _outputs = _op_def_library._apply_op_helper(
-> 5704         ""Pack"", values=values, axis=axis, name=name)
   5705   _result = _outputs[:]
   5706   if _execute.must_record_gradient():

/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/framework/op_def_library.py in _apply_op_helper(op_type_name, name, **keywords)
    740       op = g._create_op_internal(op_type_name, inputs, dtypes=None,
    741                                  name=scope, input_types=input_types,
--> 742                                  attrs=attr_protos, op_def=op_def)
    743 
    744     # `outputs` is returned as a separate return value so that the output

/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/framework/func_graph.py in _create_op_internal(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)
    593     return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access
    594         op_type, inputs, dtypes, input_types, name, attrs, op_def,
--> 595         compute_device)
    596 
    597   def capture(self, tensor, name=None, shape=None):

/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py in _create_op_internal(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)
   3320           input_types=input_types,
   3321           original_op=self._default_original_op,
-> 3322           op_def=op_def)
   3323       self._create_op_helper(ret, compute_device=compute_device)
   3324     return ret

/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py in __init__(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)
   1784           op_def, inputs, node_def.attr)
   1785       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,
-> 1786                                 control_input_ops)
   1787       name = compat.as_str(node_def.name)
   1788     # pylint: enable=protected-access

/opt/conda/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py in _create_c_op(graph, node_def, inputs, control_inputs)
   1620   except errors.InvalidArgumentError as e:
   1621     # Convert to ValueError for backwards compatibility.
-> 1622     raise ValueError(str(e))
   1623 
   1624   return c_op

ValueError: Duplicate node name in graph: 'lambda_7/random_normal/shape'
```

This is quite strange as I can run these codes normally on my laptop.I wonder whether it comes 
from difference of environment,but I don't know how to check the environment of kaggle kernel
"
36508,keras LSTM Fail to find the dnn implementation ,"**System information**
- CUDA/cuDNN version: 10.1
- GPU model and memory: GeForce RTX 2080
- TF 2.1.0:

uncommenting the LSTM layer will yield the following error:

```
UnknownError:  [_Derived_]  Fail to find the dnn implementation.
	 [[{{node CudnnRNN}}]]
	 [[sequential_6/bidirectional_2/backward_lstm_3/StatefulPartitionedCall]]
	 [[Reshape_11/_38]] [Op:__inference_distributed_function_39046]
```

working code:
```
model = tf.keras.Sequential([
    tf.keras.layers.Embedding(encoder.vocab_size, 64),
    #tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(1, activation='sigmoid')
])
model.compile(loss='binary_crossentropy',
              optimizer=tf.keras.optimizers.Adam(1e-4),
              metrics=['accuracy'])
history = model.fit(train_dataset, epochs=10,
                    validation_data=test_dataset, 
                    validation_steps=30)
```"
36507,How to use prepare_for_training with model.fit,"

## URL(s) with the issue: 

https://www.tensorflow.org/tutorials/load_data/images

## Description of issue (what needs changing):


I have been spending a lot of time trying to figure out how I can use the batch map to train my model. Which method should I use model.fit, model.fit_generator or something else"
36506,Failed to install tfx=0.15.0 ,"**System information**
- OS Platform and Distribution: Windows 10
- TensorFlow version: 1.15.0
- Python version: 3.7.6

**Describe the problem**

(CPU_3.7.6_tfx_2) C:\Users\SakhawathHossain\AppData\Local\Continuum\anaconda3\envs>pip install tfx==0.15.0
Collecting tfx==0.15.0
  Using cached tfx-0.15.0-py3-none-any.whl (504 kB)
Collecting tensorflow-model-analysis<0.16,>=0.15.2
  Using cached tensorflow_model_analysis-0.15.4-py3-none-any.whl (1.4 MB)
Processing c:\users\sakhawath\appdata\local\pip\cache\wheels\65\72\ba\7ad835954f31d6ef4f2741f602a685ac203fce168c2f31adc6\apache_beam-2.19.0-py3-none-any.whl
Processing c:\users\sakhawath\appdata\local\pip\cache\wheels\46\91\e3\0fced4f5fbc0a051a5667096826186c9ff60f2d0e9bf0f1cdc\absl_py-0.8.1-py3-none-any.whl
ERROR: Could not find a version that satisfies the requirement tensorflow-data-validation<0.16,>=0.15 (from tfx==0.15.0) (from versions: 0.21.0)
ERROR: No matching distribution found for tensorflow-data-validation<0.16,>=0.15 (from tfx==0.15.0)
.............................................................................
(CPU_3.7.6_tfx_2) C:\Users\sakhawath\AppData\Local\Continuum\anaconda3\envs>pip install tfx==0.15.0rc0
Collecting tfx==0.15.0rc0
  Using cached tfx-0.15.0rc0-py3-none-any.whl (475 kB)
ERROR: Could not find a version that satisfies the requirement tfx-bsl<0.16,>=0.15.1 (from tfx==0.15.0rc0) (from versions: 0.21.0)
ERROR: No matching distribution found for tfx-bsl<0.16,>=0.15.1 (from tfx==0.15.0rc0)
.......................................................................
(CPU_3.7.6_tfx_2) C:\Users\Sakhawath\AppData\Local\Continuum\anaconda3\envs>pip install tfx==0.21.0
ERROR: Could not find a version that satisfies the requirement tfx==0.21.0 (from versions: 0.13.0rc0, 0.13.0rc1, 0.13.0rc2, 0.13.0, 0.14.0rc1, 0.14.0, 0.15.0rc0, 0.15.0, 0.21.0rc0)
ERROR: No matching distribution found for tfx==0.21.0
"
36505,Loading Tensorflow models from disk is instant while loading from gcs is very slow,"**System information**
- OS Platform and Distribution: Both MacOS and Ubuntu 18 (Tensorflow/serving)
- TensorFlow version (use command below): 2.0.0
- Python version: 3.6

**Describe the current behavior**

I want to use Tensorflow serving to load multiple Models. If I mount a directory containing the model, loading everything is done in an instant, while loading them from a `gs://` path takes around 10 seconds per model. 

While researching the issue I discovered this is probably a Tensorflow issue and not a Tensorflow Serving issue as loading them in Tensorflow is a huge difference as well:
```
    [ins] In [22]: %timeit tf.saved_model.load('test/1')
    3.88 s ± 719 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)

    [ins] In [23]: %timeit tf.saved_model.load('gs://path/to/test/1')
    30.6 s ± 2.66 s per loop (mean ± std. dev. of 7 runs, 1 loop each)
```
Then it could be that downloading the model (which is very small) is slow, but I tested this as well:
```
    def test_load():
        bucket_name = 'path'
        folder='test'
        delimiter='/'
        file = 'to/test/1'
     
        bucket=storage.Client().get_bucket(bucket_name)
        blobs=bucket.list_blobs(prefix=file, delimiter=delimiter)
        for blob in blobs:
            print(blob.name)
            destination_uri = '{}/{}'.format(folder, blob.name)
            blob.download_to_filename(destination_uri)

    [ins] In [31]: %timeit test_load()
    541 ms ± 54.9 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)
```
Any idea what is happening here?

**Describe the expected behavior**
Around the same load time for external vs local models. The first load from gs can be slow if the auth needs to happen, but even authenticating is still way faster than the models loads.

"
36504,ValueError when trying to speed up model by decorating tf.function,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- TensorFlow installed from (source or binary): pip
- TensorFlow version (use command below): 2.1.0
- Python version:  3.6.7
- CUDA/cuDNN version:  7.6.5
- GPU model and memory:  GTX1660Ti , 6GB

**Describe the current behavior**

    Traceback (most recent call last):
    File ""model_test.py"", line 12, in <module>
        output = ModelTest(input_layer)
    File ""/home/wilson/venv_tf2.0/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py"", line 568, in __call__
        result = self._call(*args, **kwds)
    File ""/home/wilson/venv_tf2.0/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py"", line 632, in _call
        return self._stateless_fn(*args, **kwds)
    File ""/home/wilson/venv_tf2.0/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py"", line 2362, in __call__
        graph_function, args, kwargs = self._maybe_define_function(args, kwargs)
    File ""/home/wilson/venv_tf2.0/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py"", line 2703, in _maybe_define_function
        graph_function = self._create_graph_function(args, kwargs)
    File ""/home/wilson/venv_tf2.0/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py"", line 2593, in _create_graph_function
        capture_by_value=self._capture_by_value),
    File ""/home/wilson/venv_tf2.0/lib/python3.6/site-packages/tensorflow_core/python/framework/func_graph.py"", line 978, in func_graph_from_py_func
        func_outputs = python_func(*func_args, **func_kwargs)
    File ""/home/wilson/venv_tf2.0/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py"", line 439, in wrapped_fn
        return weak_wrapped_fn().__wrapped__(*args, **kwds)
    File ""/home/wilson/venv_tf2.0/lib/python3.6/site-packages/tensorflow_core/python/framework/func_graph.py"", line 968, in wrapper
        raise e.ag_error_metadata.to_exception(e)
    ValueError: in converted code:

        model_test.py:8 ModelTest  *
            x = tf.keras.layers.Dense(10)(x)
        /home/wilson/venv_tf2.0/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py:748 __call__
            self._maybe_build(inputs)
        /home/wilson/venv_tf2.0/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py:2116 _maybe_build
            self.build(input_shapes)
        /home/wilson/venv_tf2.0/lib/python3.6/site-packages/tensorflow_core/python/keras/layers/core.py:1113 build
            trainable=True)
        /home/wilson/venv_tf2.0/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py:446 add_weight
            caching_device=caching_device)
        /home/wilson/venv_tf2.0/lib/python3.6/site-packages/tensorflow_core/python/training/tracking/base.py:744 _add_variable_with_custom_getter
            **kwargs_for_getter)
        /home/wilson/venv_tf2.0/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer_utils.py:142 make_variable
            shape=variable_shape if variable_shape else None)
        /home/wilson/venv_tf2.0/lib/python3.6/site-packages/tensorflow_core/python/ops/variables.py:258 __call__
            return cls._variable_v1_call(*args, **kwargs)
        /home/wilson/venv_tf2.0/lib/python3.6/site-packages/tensorflow_core/python/ops/variables.py:219 _variable_v1_call
            shape=shape)
        /home/wilson/venv_tf2.0/lib/python3.6/site-packages/tensorflow_core/python/ops/variables.py:65 getter
            return captured_getter(captured_previous, **kwargs)
        /home/wilson/venv_tf2.0/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py:502 invalid_creator_scope
            ""tf.function-decorated function tried to create ""

        ValueError: tf.function-decorated function tried to create variables on non-first call.


**Describe the expected behavior**

    print the inference results as below:
    tf.Tensor( [[ 1.5871892   1.028789    0.6445342  -1.9210143  -1.7477174   3.1219487
   1.8073429   2.62254    -0.01772228 -2.2654278 ]], shape=(1, 10), dtype=float32)



**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.

    import numpy as np
    import tensorflow as tf
    from tensorflow.keras.layers import Flatten, Dense
   
    @tf.function  # with this, it will raise error listed above
    def ModelTest(input_layer):
        x = Flatten()(input_layer)
        x = tf.keras.layers.Dense(10)(x)
        return x

    input_layer = tf.keras.layers.Input([32, 32, 3])
    output = ModelTest(input_layer)
    model = tf.keras.Model(input_layer, output)

    a = np.ones([1, 32, 32, 3])
    print(model(a))

I try to run YOLOv3 by TF2, but it's so slow compared to other framework, can be seen from the following table.
![image](https://user-images.githubusercontent.com/20164141/73921384-31a6d200-4902-11ea-9162-d6207f60b425.png)

So by a naive example, I just want to speed up the inference of the model by decorating ModelTest with tf.function, but it will raise error. How should I fix this error or are there other ways to speed up the model? Thanks
"
36503,"Illegal Instruction on importing tensorflow (Intel J3455, debian)","
tensorflow 2.1.0 from pip3 
crashing on execute a PXOR instruction

build with (-Wno-sign-compare -march=skylake -mno-avx -mno-avx2 -mno-fma -msse4.1 -msse4.2)
crashing on execute a SHLX instruction

build with (-Wno-sign-compare -march=skylake -mno-avx -mno-avx2 -mno-fma -msse4.1 -msse4.2 -mno-bmi -mno-sgx -mno-bmi2)
not crash but process freeze




**System information**
```
debian 10.2
Python 3.7.3 (default, Apr  3 2019, 05:39:12) 
[GCC 8.3.0] on linux
tensorflow 2.1.0 from pip3 also tried build from source(-Wno-sign-compare -march=skylake -mno-avx -mno-avx2 -mno-fma -msse4.1 -msse4.2)

$ lscpu 
Architecture:        x86_64
CPU op-mode(s):      32-bit, 64-bit
Byte Order:          Little Endian
Address sizes:       39 bits physical, 48 bits virtual
CPU(s):              4
On-line CPU(s) list: 0-3
Thread(s) per core:  1
Core(s) per socket:  4
Socket(s):           1
NUMA node(s):        1
Vendor ID:           GenuineIntel
CPU family:          6
Model:               92
Model name:          Intel(R) Celeron(R) CPU J3455 @ 1.50GHz
Stepping:            9
CPU MHz:             2179.725
CPU max MHz:         2300.0000
CPU min MHz:         800.0000
BogoMIPS:            2995.20
Virtualization:      VT-x
L1d cache:           24K
L1i cache:           32K
L2 cache:            1024K
NUMA node0 CPU(s):   0-3
Flags:               fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc art arch_perfmon pebs bts rep_good nopl xtopology tsc_reliable nonstop_tsc cpuid aperfmperf tsc_known_freq pni pclmulqdq dtes64 monitor ds_cpl vmx est tm2 ssse3 sdbg cx16 xtpr pdcm sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave rdrand lahf_lm 3dnowprefetch cpuid_fault cat_l2 pti tpr_shadow vnmi flexpriority ept vpid ept_ad fsgsbase tsc_adjust smep erms mpx rdt_a rdseed smap clflushopt intel_pt sha_ni xsaveopt xsavec xgetbv1 xsaves dtherm ida arat pln pts

$ g++ -march=native -Q --help=target
The following options are target specific:
  -m128bit-long-double        		[enabled]
  -m16                        		[disabled]
  -m32                        		[disabled]
  -m3dnow                     		[disabled]
  -m3dnowa                    		[disabled]
  -m64                        		[enabled]
  -m80387                     		[enabled]
  -m8bit-idiv                 		[disabled]
  -m96bit-long-double         		[disabled]
  -mabi=                      		sysv
  -mabm                       		[disabled]
  -maccumulate-outgoing-args  		[disabled]
  -maddress-mode=             		long
  -madx                       		[disabled]
  -maes                       		[enabled]
  -malign-data=               		compat
  -malign-double              		[disabled]
  -malign-functions=          		0
  -malign-jumps=              		0
  -malign-loops=              		0
  -malign-stringops           		[enabled]
  -mandroid                   		[disabled]
  -march=                     		skylake
  -masm=                      		att
  -mavx                       		[disabled]
  -mavx2                      		[disabled]
  -mavx256-split-unaligned-load 	[enabled]
  -mavx256-split-unaligned-store 	[enabled]
  -mavx5124fmaps              		[disabled]
  -mavx5124vnniw              		[disabled]
  -mavx512bitalg              		[disabled]
  -mavx512bw                  		[disabled]
  -mavx512cd                  		[disabled]
  -mavx512dq                  		[disabled]
  -mavx512er                  		[disabled]
  -mavx512f                   		[disabled]
  -mavx512ifma                		[disabled]
  -mavx512pf                  		[disabled]
  -mavx512vbmi                		[disabled]
  -mavx512vbmi2               		[disabled]
  -mavx512vl                  		[disabled]
  -mavx512vnni                		[disabled]
  -mavx512vpopcntdq           		[disabled]
  -mbionic                    		[disabled]
  -mbmi                       		[disabled]
  -mbmi2                      		[disabled]
  -mbranch-cost=<0,5>         		3
  -mcall-ms2sysv-xlogues      		[disabled]
  -mcet-switch                		[disabled]
  -mcld                       		[disabled]
  -mclflushopt                		[enabled]
  -mclwb                      		[disabled]
  -mclzero                    		[disabled]
  -mcmodel=                   		[default]
  -mcpu=                      		
  -mcrc32                     		[disabled]
  -mcx16                      		[enabled]
  -mdispatch-scheduler        		[disabled]
  -mdump-tune-features        		[disabled]
  -mf16c                      		[disabled]
  -mfancy-math-387            		[enabled]
  -mfentry                    		[disabled]
  -mfma                       		[disabled]
  -mfma4                      		[disabled]
  -mforce-drap                		[disabled]
  -mforce-indirect-call       		[disabled]
  -mfp-ret-in-387             		[enabled]
  -mfpmath=                   		sse
  -mfsgsbase                  		[enabled]
  -mfunction-return=          		keep
  -mfused-madd                		
  -mfxsr                      		[enabled]
  -mgeneral-regs-only         		[disabled]
  -mgfni                      		[disabled]
  -mglibc                     		[enabled]
  -mhard-float                		[enabled]
  -mhle                       		[enabled]
  -miamcu                     		[disabled]
  -mieee-fp                   		[enabled]
  -mincoming-stack-boundary=  		0
  -mindirect-branch-register  		[disabled]
  -mindirect-branch=          		keep
  -minline-all-stringops      		[disabled]
  -minline-stringops-dynamically 	[disabled]
  -mintel-syntax              		
  -mlarge-data-threshold=<number> 	65536
  -mlong-double-128           		[disabled]
  -mlong-double-64            		[disabled]
  -mlong-double-80            		[enabled]
  -mlwp                       		[disabled]
  -mlzcnt                     		[disabled]
  -mmemcpy-strategy=          		
  -mmemset-strategy=          		
  -mmitigate-rop              		[disabled]
  -mmmx                       		[enabled]
  -mmovbe                     		[enabled]
  -mmovdir64b                 		[disabled]
  -mmovdiri                   		[disabled]
  -mmpx                       		[disabled]
  -mms-bitfields              		[disabled]
  -mmusl                      		[disabled]
  -mmwaitx                    		[disabled]
  -mno-align-stringops        		[disabled]
  -mno-default                		[disabled]
  -mno-fancy-math-387         		[disabled]
  -mno-push-args              		[disabled]
  -mno-red-zone               		[disabled]
  -mno-sse4                   		[disabled]
  -mnop-mcount                		[disabled]
  -momit-leaf-frame-pointer   		[disabled]
  -mpc32                      		[disabled]
  -mpc64                      		[disabled]
  -mpc80                      		[disabled]
  -mpclmul                    		[enabled]
  -mpcommit                   		[disabled]
  -mpconfig                   		[disabled]
  -mpku                       		[disabled]
  -mpopcnt                    		[enabled]
  -mprefer-avx128             		
  -mprefer-vector-width=      		none
  -mpreferred-stack-boundary= 		0
  -mprefetchwt1               		[disabled]
  -mprfchw                    		[enabled]
  -mpush-args                 		[enabled]
  -mrdpid                     		[disabled]
  -mrdrnd                     		[enabled]
  -mrdseed                    		[enabled]
  -mrecip                     		[disabled]
  -mrecip=                    		
  -mrecord-mcount             		[disabled]
  -mred-zone                  		[enabled]
  -mregparm=                  		6
  -mrtd                       		[disabled]
  -mrtm                       		[disabled]
  -msahf                      		[enabled]
  -msgx                       		[disabled]
  -msha                       		[enabled]
  -mshstk                     		[disabled]
  -mskip-rax-setup            		[disabled]
  -msoft-float                		[disabled]
  -msse                       		[enabled]
  -msse2                      		[enabled]
  -msse2avx                   		[disabled]
  -msse3                      		[enabled]
  -msse4                      		[enabled]
  -msse4.1                    		[enabled]
  -msse4.2                    		[enabled]
  -msse4a                     		[disabled]
  -msse5                      		
  -msseregparm                		[disabled]
  -mssse3                     		[enabled]
  -mstack-arg-probe           		[disabled]
  -mstack-protector-guard-offset= 	
  -mstack-protector-guard-reg= 		
  -mstack-protector-guard-symbol= 	
  -mstack-protector-guard=    		tls
  -mstackrealign              		[disabled]
  -mstringop-strategy=        		[default]
  -mstv                       		[enabled]
  -mtbm                       		[disabled]
  -mtls-dialect=              		gnu
  -mtls-direct-seg-refs       		[enabled]
  -mtune-ctrl=                		
  -mtune=                     		generic
  -muclibc                    		[disabled]
  -mvaes                      		[disabled]
  -mveclibabi=                		[default]
  -mvect8-ret-in-mem          		[disabled]
  -mvpclmulqdq                		[disabled]
  -mvzeroupper                		[enabled]
  -mwbnoinvd                  		[disabled]
  -mx32                       		[disabled]
  -mxop                       		[disabled]
  -mxsave                     		[disabled]
  -mxsavec                    		[disabled]
  -mxsaveopt                  		[disabled]
  -mxsaves                    		[disabled]

  Known assembler dialects (for use with the -masm= option):
    att intel

  Known ABIs (for use with the -mabi= option):
    ms sysv

  Known code models (for use with the -mcmodel= option):
    32 kernel large medium small

  Valid arguments to -mfpmath=:
    387 387+sse 387,sse both sse sse+387 sse,387

  Known indirect branch choices (for use with the -mindirect-branch=/-mfunction-return= options):
    keep thunk thunk-extern thunk-inline

  Known data alignment choices (for use with the -malign-data= option):
    abi cacheline compat

  Known vectorization library ABIs (for use with the -mveclibabi= option):
    acml svml

  Known address mode (for use with the -maddress-mode= option):
    long short

  Known preferred register vector length (to use with the -mprefer-vector-width= option)
    128 256 512 none

  Known stack protector guard (for use with the -mstack-protector-guard= option):
    global tls

  Valid arguments to -mstringop-strategy=:
    byte_loop libcall loop rep_4byte rep_8byte rep_byte unrolled_loop vector_loop

  Known TLS dialects (for use with the -mtls-dialect= option):
    gnu gnu2

```


**Describe the current behavior**

**Describe the expected behavior**

**Code to reproduce the issue**
tensorflow 2.1.0 from pip3 
```
Successfully installed gast-0.2.2 tensorboard-2.1.0 tensorflow-2.1.0 tensorflow-estimator-2.1.0
# gdb --args python3.7 -c ""import tensorflow""
GNU gdb (Debian 8.2.1-2+b3) 8.2.1
Copyright (C) 2018 Free Software Foundation, Inc.
License GPLv3+: GNU GPL version 3 or later <http://gnu.org/licenses/gpl.html>
This is free software: you are free to change and redistribute it.
There is NO WARRANTY, to the extent permitted by law.
Type ""show copying"" and ""show warranty"" for details.
This GDB was configured as ""x86_64-linux-gnu"".
Type ""show configuration"" for configuration details.
For bug reporting instructions, please see:
<http://www.gnu.org/software/gdb/bugs/>.
Find the GDB manual and other documentation resources online at:
    <http://www.gnu.org/software/gdb/documentation/>.

For help, type ""help"".
Type ""apropos word"" to search for commands related to ""word""...
Reading symbols from python3.7...(no debugging symbols found)...done.
(gdb) run
Starting program: /usr/bin/python3.7 -c import\ tensorflow
[Thread debugging using libthread_db enabled]
Using host libthread_db library ""/lib/x86_64-linux-gnu/libthread_db.so.1"".
[New Thread 0x7ffff4c9c700 (LWP 8462)]
[New Thread 0x7ffff249b700 (LWP 8463)]
[New Thread 0x7ffff1c9a700 (LWP 8464)]

Thread 1 ""python3.7"" received signal SIGILL, Illegal instruction.
0x00007fffb412f6c0 in nsync::nsync_mu_init(nsync::nsync_mu_s_*) ()
   from /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/_pywrap_tensorflow_internal.so
(gdb) disas 0x00007fffb412f6c0
Dump of assembler code for function _ZN5nsync13nsync_mu_initEPNS_11nsync_mu_s_E:
=> 0x00007fffb412f6c0 <+0>:	vpxor  %xmm0,%xmm0,%xmm0
   0x00007fffb412f6c4 <+4>:	push   %rbp
   0x00007fffb412f6c5 <+5>:	mov    %rsp,%rbp
   0x00007fffb412f6c8 <+8>:	vmovups %xmm0,(%rdi)
   0x00007fffb412f6cc <+12>:	pop    %rbp
   0x00007fffb412f6cd <+13>:	retq   
End of assembler dump.
(gdb) 

```

build from source tensorflow #v2.1.0(-Wno-sign-compare -march=skylake -mno-avx -mno-avx2 -mno-fma -msse4.1 -msse4.2)
```
root@acd9a1d666ad:/tensorflow_src# ./configure 
WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command ""bazel shutdown"".
You have bazel 1.2.1 installed.
Please specify the location of python. [Default is /usr/local/bin/python]: /usr/bin/python3.7


Found possible Python library paths:
  /usr/lib/python3/dist-packages
  /usr/local/lib/python3.7/dist-packages
Please input the desired Python library path to use.  Default is [/usr/lib/python3/dist-packages]

Do you wish to build TensorFlow with XLA JIT support? [Y/n]: 
XLA JIT support will be enabled for TensorFlow.

Do you wish to build TensorFlow with OpenCL SYCL support? [y/N]: 
No OpenCL SYCL support will be enabled for TensorFlow.

Do you wish to build TensorFlow with ROCm support? [y/N]: 
No ROCm support will be enabled for TensorFlow.

Do you wish to build TensorFlow with CUDA support? [y/N]: 
No CUDA support will be enabled for TensorFlow.

Do you wish to download a fresh release of clang? (Experimental) [y/N]: 
Clang will not be downloaded.

Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -march=native -Wno-sign-compare]: -Wno-sign-compare -march=skylake -mno-avx -mno-avx2 -mno-fma -msse4.1 -msse4.2


Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: 
Not configuring the WORKSPACE for Android builds.

Preconfigured Bazel build configs. You can use any of the below by adding ""--config=<>"" to your build command. See .bazelrc for more details.
	--config=mkl         	# Build with MKL support.
	--config=monolithic  	# Config for mostly static monolithic build.
	--config=ngraph      	# Build with Intel nGraph support.
	--config=numa        	# Build with NUMA support.
	--config=dynamic_kernels	# (Experimental) Build kernels into separate shared objects.
	--config=v2          	# Build TensorFlow 2.x instead of 1.x.
Preconfigured Bazel build configs to DISABLE default on features:
	--config=noaws       	# Disable AWS S3 filesystem support.
	--config=nogcp       	# Disable GCP support.
	--config=nohdfs      	# Disable HDFS support.
	--config=nonccl      	# Disable NVIDIA NCCL support.
Configuration finished

root@acd9a1d666ad:/tensorflow_src# bazel build --config=opt --config=noaws --config=nogcp --config=nonccl //tensorflow/tools/pip_package:build_pip_package --jobs 4
```

```
# gdb --args python3.7 -c ""import tensorflow""
GNU gdb (Debian 8.2.1-2+b3) 8.2.1
Copyright (C) 2018 Free Software Foundation, Inc.
License GPLv3+: GNU GPL version 3 or later <http://gnu.org/licenses/gpl.html>
This is free software: you are free to change and redistribute it.
There is NO WARRANTY, to the extent permitted by law.
Type ""show copying"" and ""show warranty"" for details.
This GDB was configured as ""x86_64-linux-gnu"".
Type ""show configuration"" for configuration details.
For bug reporting instructions, please see:
<http://www.gnu.org/software/gdb/bugs/>.
Find the GDB manual and other documentation resources online at:
    <http://www.gnu.org/software/gdb/documentation/>.

For help, type ""help"".
Type ""apropos word"" to search for commands related to ""word""...
Reading symbols from python3.7...(no debugging symbols found)...done.
(gdb) run
Starting program: /usr/bin/python3.7 -c import\ tensorflow
[Thread debugging using libthread_db enabled]
Using host libthread_db library ""/lib/x86_64-linux-gnu/libthread_db.so.1"".
[New Thread 0x7ffff4c9c700 (LWP 10774)]
[New Thread 0x7ffff249b700 (LWP 10775)]
[New Thread 0x7fffefc9a700 (LWP 10776)]

Thread 1 ""python3.7"" received signal SIGILL, Illegal instruction.
0x00007fffddb28ee0 in tensorflow::UnaryVariantOpRegistry::RegisterDeviceCopyFn(tensorflow::VariantDeviceCopyDirection, tensorflow::TypeIndex const&, std::function<tensorflow::Status (tensorflow::Variant const&, tensorflow::Variant*, std::function<tensorflow::Status (tensorflow::Tensor const&, tensorflow::Tensor*)>)> const&) ()
   from /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/../libtensorflow_framework.so.2
(gdb) disas 0x00007fffddb28ee0,0x00007fffddb28eff
Dump of assembler code from 0x7fffddb28ee0 to 0x7fffddb28eff:
=> 0x00007fffddb28ee0 <_ZN10tensorflow22UnaryVariantOpRegistry20RegisterDeviceCopyFnENS_26VariantDeviceCopyDirectionERKNS_9TypeIndexERKSt8functionIFNS_6StatusERKNS_7VariantEPS7_S5_IFS6_RKNS_6TensorEPSB_EEEE+544>:	shlx   %r14d,%edx,%eax

```

**Other info / logs**
https://www.felixcloutier.com/x86/pxor (AVX)
https://www.felixcloutier.com/x86/sarx:shlx:shrx (BMI2)
"
36501,Tensorflow 1.15 doesn't do incremental memory growth,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): NixOS
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): unknown 1.15.0
- Python version: 3.7.6
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10.2.89
- GPU model and memory: RTX 2070 - 440.44

**Describe the current behavior**

I'm trying to activate incremental memory growth. However in all the ways I've done it, it always ends up allocating almost the entire GPU.

```python
import tensorflow as tf
import tensorflow.keras as keras
import tensorflow.keras.applications as applications
import tensorflow.keras.utils as utils
import numpy as np

num_samples = 1000
height = 224
width = 224
num_classes = 1000

config = tf.compat.v1.ConfigProto()
config.gpu_options.allow_growth = True
sess = tf.compat.v1.Session(config=config)
keras.backend.set_session(sess)

# gpus = tf.config.experimental.list_physical_devices('GPU')
# for gpu in gpus:
#     tf.config.experimental.set_memory_growth(gpu, True)
# logical_gpus = tf.config.experimental.list_logical_devices('GPU')

model = applications.ResNet50(weights=None, input_shape=(height, width, 3), classes=num_classes)

parallel_model = utils.multi_gpu_model(model, gpus=2, cpu_relocation=True)
parallel_model.compile(loss='categorical_crossentropy', optimizer='rmsprop')

x = np.random.random((num_samples, height, width, 3))
y = np.random.random((num_samples, num_classes))

parallel_model.fit(x, y, epochs=20, batch_size=2)

print('all done')
```

As I watch `nvidia-smi`, I always see almost the entire GPUs allocated.

This is true for the compat v1 and for the new tf.config.experimental commands and also for the environment variable `TF_FORCE_GPU_ALLOW_GROWTH`.

The only one that has any effect is `config.gpu_options.per_process_gpu_memory_fraction = 0.5`.

In all other cases I see the the GPU memories get used up entirely and I get these messages:

```
2020-02-06 15:48:35.517899: I tensorflow/stream_executor/cuda/cuda_driver.cc:831] failed to allocate 3.18G (3411184640 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
```"
36500,Error when converting my_frozen_graph.pb to .tflite for Speech Commands example app TF Speech,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- TensorFlow installed from (source or binary): Binary
- TensorFlow version (or github SHA if from source): Tensorflow 2.0.1


**Command used to run the converter or code if you’re using the Python API**
tflite_convert.py
```

# Copy and paste here the exact command
```
python tensorflow/lite/python/tflite_convert.py --enable_v1_converter --output_file=/tmp/foo.tflite --graph_def_file=/tmp/my_frozen_graph_anika_26000.pb --input_arrays=wav_data --output_arrays=labels_softmax --input_shapes=1,3920

**The output from the converter invocation**
```
Here is a list of operators for which you will need custom implementations: AudioSpectrogram, DecodeWav, Mfcc.

# Copy and paste the output here.
```
Traceback (most recent call last):
  File ""tensorflow_core/lite/python/tflite_convert.py"", line 598, in <module>
    main()
  File ""tensorflow_core/lite/python/tflite_convert.py"", line 594, in main
    app.run(main=run_main, argv=sys.argv[:1])
  File ""C:\Anaconda3\envs\tf-gpu\lib\site-packages\tensorflow_core\python\platform\app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""C:\Anaconda3\envs\tf-gpu\lib\site-packages\absl\app.py"", line 299, in run
    _run_main(main, args)
  File ""C:\Anaconda3\envs\tf-gpu\lib\site-packages\absl\app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""tensorflow_core/lite/python/tflite_convert.py"", line 580, in run_main
    _convert_tf1_model(tflite_flags)
  File ""tensorflow_core/lite/python/tflite_convert.py"", line 210, in _convert_tf1_model
    output_data = converter.convert()
  File ""C:\Anaconda3\envs\tf-gpu\lib\site-packages\tensorflow_core\lite\python\lite.py"", line 1007, in convert
    **converter_kwargs)
  File ""C:\Anaconda3\envs\tf-gpu\lib\site-packages\tensorflow_core\lite\python\convert.py"", line 457, in toco_convert_impl
    enable_mlir_converter=enable_mlir_converter)
  File ""C:\Anaconda3\envs\tf-gpu\lib\site-packages\tensorflow_core\lite\python\convert.py"", line 203, in toco_convert_protos
    raise ConverterError(""See console for info.\n%s\n%s\n"" % (stdout, stderr))
tensorflow.lite.python.convert.ConverterError: See console for info.
2020-02-05 20:57:48.272648: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'cudart64_101.dll'; dlerror: cudart64_101.dll not found
2020-02-05 20:57:48.273069: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2020-02-05 20:57:49.877294: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: DecodeWav
2020-02-05 20:57:49.877602: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: AudioSpectrogram
2020-02-05 20:57:49.877911: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Mfcc
2020-02-05 20:57:49.883065: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 24 operators, 36 arrays (0 quantized)
2020-02-05 20:57:49.883549: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 24 operators, 36 arrays (0 quantized)
2020-02-05 20:57:49.884589: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 11 operators, 22 arrays (0 quantized)
2020-02-05 20:57:49.887081: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 2: 10 operators, 21 arrays (0 quantized)
2020-02-05 20:57:49.887552: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 3: 9 operators, 19 arrays (0 quantized)
2020-02-05 20:57:49.888012: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Group bidirectional sequence lstm/rnn: 9 operators, 19 arrays (0 quantized)
2020-02-05 20:57:49.888461: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before dequantization graph transformations: 9 operators, 19 arrays (0 quantized)
2020-02-05 20:57:49.888891: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Identify nearest upsample.: 9 operators, 19 arrays (0 quantized)
2020-02-05 20:57:49.889328: I tensorflow/lite/toco/allocate_transient_arrays.cc:345] Total transient array allocated size: 0 bytes, theoretical optimal value: 0 bytes.
2020-02-05 20:57:49.889717: I tensorflow/lite/toco/toco_tooling.cc:471] Number of parameters: 926865
2020-02-05 20:57:49.890164: E tensorflow/lite/toco/toco_tooling.cc:498] We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md
 and pasting the following:

Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: CONV_2D, FULLY_CONNECTED, MAX_POOL_2D, RESHAPE, SOFTMAX. Here is a list of operators for which you will need custom implementations: AudioSpectrogram, DecodeWav, Mfcc.
Traceback (most recent call last):
  File ""c:\anaconda3\envs\tf-gpu\lib\runpy.py"", line 193, in _run_module_as_main
    ""__main__"", mod_spec)
  File ""c:\anaconda3\envs\tf-gpu\lib\runpy.py"", line 85, in _run_code
    exec(code, run_globals)
  File ""C:\Anaconda3\envs\tf-gpu\Scripts\toco_from_protos.exe\__main__.py"", line 7, in <module>
  File ""c:\anaconda3\envs\tf-gpu\lib\site-packages\tensorflow_core\lite\toco\python\toco_from_protos.py"", line 93, in main
    app.run(main=execute, argv=[sys.argv[0]] + unparsed)
  File ""c:\anaconda3\envs\tf-gpu\lib\site-packages\tensorflow_core\python\platform\app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""c:\anaconda3\envs\tf-gpu\lib\site-packages\absl\app.py"", line 299, in run
    _run_main(main, args)
  File ""c:\anaconda3\envs\tf-gpu\lib\site-packages\absl\app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""c:\anaconda3\envs\tf-gpu\lib\site-packages\tensorflow_core\lite\toco\python\toco_from_protos.py"", line 56, in execute
    enable_mlir_converter)
Exception: We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md
 and pasting the following:

Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: CONV_2D, FULLY_CONNECTED, MAX_POOL_2D, RESHAPE, SOFTMAX. Here is a list of operators for which you will need custom implementations: AudioSpectrogram, DecodeWav, Mfcc.


**Also, please include a link to the saved model or GraphDef**

```
# Put link here or attach to the issue.
```

**Failure details**
If the conversion is successful, but the generated model is wrong,
state what is wrong:
- Producing wrong results and/or decrease in accuracy
- Producing correct results, but the model is slower than expected (model generated from old converter)
When I try to convert without '--target_ops=TFLITE_BUILTINS,SELECT_TF_OPS', I get the error saying Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. These are: AudioSpectrogram, DecodeWav, Mfcc.
When I use '--target_ops=TFLITE_BUILTINS,SELECT_TF_OPS', I do get a .tflite file, but that file fails to run on Andriod, and gives the error message: ""Unexpected failure when preparing tensor allocations: Regular TensorFlow ops are not supported by this interpreter""

**Any other info / logs**
Complete Error when running a .tflite file (that was created using the SELECT_TF_OPS option) on Andriod: 
error running on android:
java.lang.RuntimeException: Unable to start activity ComponentInfo{org.tensorflow.lite.examples.speech/org.tensorflow.lite.examples.speech.SpeechActivity}: java.lang.RuntimeException: java.lang.IllegalStateException: Internal error: Unexpected failure when preparing tensor allocations: Regular TensorFlow ops are not supported by this interpreter. Make sure you apply/link the Flex delegate before inference.


Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
36499,tensorflow.fill does not work in keras.layers and models with dynamic shape as it should and as similar functions do,"
**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): (MacOS) Darwin-19.2.0-x86_64-i386-64bit - mac version: ('10.15.2', ('', '', ''), 'x86_64')
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): binary (pip install)
- TensorFlow version (use command below): v2.1.0-rc2-17-ge5bf8de410 2.1.0
- Python version: Python 3.7.6
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A


**Describe the current behavior**
If I use tensorflow.fill in tf.keras.layers layer, where the shape for the fill depends on the input, it doesn't work, although it works with plenty of other similar functions, and would be reasonably expected to work.  

Specifically, I call:
```
import tensorflow as tf
import numpy as np

X = tf.keras.Input((1,))
X2 = tf.keras.layers.Lambda(lambda x: tf.fill((tf.shape(X)[0],1),2.5))(X)
model = tf.keras.Model(inputs=X,outputs=X2)
model.predict(np.random.randn(10,1))
```

I get the following error when I try to run ""predict"" with a model built with the label (full error output below):
> _SymbolicException: Inputs to eager execution function cannot be Keras symbolic tensors, but found [<tf.Tensor 'input_1:0' shape=(None, 1) dtype=float32>]

**Describe the expected behavior**
I expect it to output a 10x1 numpy array of ones.  This happens with other similar functions used in the same way.  E.g., the following all work fine used in the same way:
```
X2 = tf.keras.layers.Lambda(lambda x: tf.random.uniform(tf.shape(x)))(X) 
X2 = tf.keras.layers.Lambda(lambda x: tf.zeros_like(x))(X)
X2 = tf.keras.layers.Lambda(lambda x: tf.ones_like(x)*3.5)(X)
```
and they all depend on the shape of the input, for the case of random.uniform it even takes the same call tf.shape in the input and works fine.   There's no reason tf.fill shouldn't work / the similar capability to create a full tensor for an arbitrary value and input shape.

**Code to reproduce the issue**
```
import tensorflow as tf
import numpy as np

X = tf.keras.Input((1,))
X2 = tf.keras.layers.Lambda(lambda x: tf.fill((tf.shape(X)[0],1),2.5))(X)
model = tf.keras.Model(inputs=X,outputs=X2)
model.predict(np.random.randn(10,1))
```

**Other info / logs**

> Here is the full error output / trace:
> ---------------------------------------------------------------------------
> TypeError                                 Traceback (most recent call last)
> /Users/workspaces/python_virtualenv/tensorflow2/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)
>      60                                                op_name, inputs, attrs,
> ---> 61                                                num_outputs)
>      62   except core._NotOkStatusException as e:
> 
> TypeError: An op outside of the function building code is being passed
> a ""Graph"" tensor. It is possible to have Graph tensors
> leak out of the function building context by including a
> tf.init_scope in your function building code.
> For example, the following function will fail:
>   @tf.function
>   def has_init_scope():
>     my_constant = tf.constant(1.)
>     with tf.init_scope():
>       added = my_constant * 2
> The graph tensor has name: input_1:0
> 
> During handling of the above exception, another exception occurred:
> 
> _SymbolicException                        Traceback (most recent call last)
> <ipython-input-1-c6ef6980c816> in <module>
>       5 X2 = tf.keras.layers.Lambda(lambda x: tf.fill((tf.shape(X)[0],1),2.5))(X)
>       6 model = tf.keras.Model(inputs=X,outputs=X2)
> ----> 7 model.predict(np.random.randn(10,1))
> 
> /Users/workspaces/python_virtualenv/tensorflow2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py in predict(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)
>    1011         max_queue_size=max_queue_size,
>    1012         workers=workers,
> -> 1013         use_multiprocessing=use_multiprocessing)
>    1014 
>    1015   def reset_metrics(self):
> 
> /Users/workspaces/python_virtualenv/tensorflow2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py in predict(self, model, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing, **kwargs)
>     496         model, ModeKeys.PREDICT, x=x, batch_size=batch_size, verbose=verbose,
>     497         steps=steps, callbacks=callbacks, max_queue_size=max_queue_size,
> --> 498         workers=workers, use_multiprocessing=use_multiprocessing, **kwargs)
>     499 
>     500 
> 
> /Users/workspaces/python_virtualenv/tensorflow2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py in _model_iteration(self, model, mode, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, **kwargs)
>     473               mode=mode,
>     474               training_context=training_context,
> --> 475               total_epochs=1)
>     476           cbks.make_logs(model, epoch_logs, result, mode)
>     477 
> 
> /Users/workspaces/python_virtualenv/tensorflow2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py in run_one_epoch(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)
>     126         step=step, mode=mode, size=current_batch_size) as batch_logs:
>     127       try:
> --> 128         batch_outs = execution_function(iterator)
>     129       except (StopIteration, errors.OutOfRangeError):
>     130         # TODO(kaftan): File bug about tf function and errors.OutOfRangeError?
> 
> /Users/workspaces/python_virtualenv/tensorflow2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py in execution_function(input_fn)
>      96     # `numpy` translates Tensors to values in Eager mode.
>      97     return nest.map_structure(_non_none_constant_value,
> ---> 98                               distributed_function(input_fn))
>      99 
>     100   return execution_function
> 
> /Users/workspaces/python_virtualenv/tensorflow2/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py in __call__(self, *args, **kwds)
>     566         xla_context.Exit()
>     567     else:
> --> 568       result = self._call(*args, **kwds)
>     569 
>     570     if tracing_count == self._get_tracing_count():
> 
> /Users/workspaces/python_virtualenv/tensorflow2/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py in _call(self, *args, **kwds)
>     636               *args, **kwds)
>     637       # If we did not create any variables the trace we have is good enough.
> --> 638       return self._concrete_stateful_fn._filtered_call(canon_args, canon_kwds)  # pylint: disable=protected-access
>     639 
>     640     def fn_with_cond(*inner_args, **inner_kwds):
> 
> /Users/workspaces/python_virtualenv/tensorflow2/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py in _filtered_call(self, args, kwargs)
>    1609          if isinstance(t, (ops.Tensor,
>    1610                            resource_variable_ops.BaseResourceVariable))),
> -> 1611         self.captured_inputs)
>    1612 
>    1613   def _call_flat(self, args, captured_inputs, cancellation_manager=None):
> 
> /Users/workspaces/python_virtualenv/tensorflow2/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py in _call_flat(self, args, captured_inputs, cancellation_manager)
>    1690       # No tape is watching; skip to running the function.
>    1691       return self._build_call_outputs(self._inference_function.call(
> -> 1692           ctx, args, cancellation_manager=cancellation_manager))
>    1693     forward_backward = self._select_forward_and_backward_functions(
>    1694         args,
> 
> /Users/workspaces/python_virtualenv/tensorflow2/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py in call(self, ctx, args, cancellation_manager)
>     543               inputs=args,
>     544               attrs=(""executor_type"", executor_type, ""config_proto"", config),
> --> 545               ctx=ctx)
>     546         else:
>     547           outputs = execute.execute_with_cancellation(
> 
> /Users/workspaces/python_virtualenv/tensorflow2/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)
>      73       raise core._SymbolicException(
>      74           ""Inputs to eager execution function cannot be Keras symbolic ""
> ---> 75           ""tensors, but found {}"".format(keras_symbolic_tensors))
>      76     raise e
>      77   # pylint: enable=protected-access
> 
> _SymbolicException: Inputs to eager execution function cannot be Keras symbolic tensors, but found [<tf.Tensor 'input_1:0' shape=(None, 1) dtype=float32>]
"
36495,Cannot install tensorflow go,"This is a continuation of a similar issue (#35133 ) but the missing package is now different. It appears that the fix has involved substituting one go dependency for another -- however, the new package also cannot be found:

`go get github.com/tensorflow/tensorflow/tensorflow/go
package github.com/tensorflow/tensorflow/tensorflow/go/core/core_protos_go_proto: cannot find package ""github.com/tensorflow/tensorflow/tensorflow/go/core/core_protos_go_proto"" in any of:
	/usr/local/go/src/github.com/tensorflow/tensorflow/tensorflow/go/core/core_protos_go_proto (from $GOROOT)
       /Users/admin/go/src/github.com/tensorflow/tensorflow/tensorflow/go/core/core_protos_go_proto (from $GOPATH)`

"
36494,Tensorflow not properly installing,"

**System information**
- Windows 10 Pro Version	10.0.17763 Build 17763

- Windows I7 Desktop 16gb memory
- TensorFlow version: 2: (2.1.0)
- Python version: 3.6
- Installed using virtualenv? pip? conda?: installed with latest pip


- CUDA/cuDNN version:CUDA 10.1 ,cudnn64_7.dll
- GPU model and memory: 1080, 16 gb(?)

**Describe the problem**

I have had tensorflow 2. running (no problem) and then attempted to get the gpu version going. No luck I have uninstalled the tensorflow-gpu version and reinstalled (pip install tensorflow), the current version.  

**Installing collected packages: tensorflow
Successfully installed tensorflow-2.1.0**

It appears tensorflow is successfully installed.

Here is my python code: **import tensorflow as tf**
Thats it!

Please advise.  Thanks

**Traceback :**
C:\Users\BillS\AppData\Local\Programs\Python\Python36\python.exe ""C:/Users/BillS/AppData/Local/Programs/Python/Python36/Tensorflow test.py""
Traceback (most recent call last):
  File ""C:\Users\BillS\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\BillS\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\BillS\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\BillS\AppData\Local\Programs\Python\Python36\lib\imp.py"", line 243, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\BillS\AppData\Local\Programs\Python\Python36\lib\imp.py"", line 343, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: The specified module could not be found.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:/Users/BillS/AppData/Local/Programs/Python/Python36/Tensorflow test.py"", line 1, in <module>
    import tensorflow as tf
  File ""C:\Users\BillS\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\__init__.py"", line 101, in <module>
    from tensorflow_core import *
  File ""C:\Users\BillS\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow_core\__init__.py"", line 40, in <module>
    from tensorflow.python.tools import module_util as _module_util
  File ""C:\Users\BillS\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\__init__.py"", line 50, in __getattr__
    module = self._load()
  File ""C:\Users\BillS\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\__init__.py"", line 44, in _load
    module = _importlib.import_module(self.__name__)
  File ""C:\Users\BillS\AppData\Local\Programs\Python\Python36\lib\importlib\__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""C:\Users\BillS\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow_core\python\__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\Users\BillS\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 74, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""C:\Users\BillS\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\BillS\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\BillS\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\BillS\AppData\Local\Programs\Python\Python36\lib\imp.py"", line 243, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\BillS\AppData\Local\Programs\Python\Python36\lib\imp.py"", line 343, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: The specified module could not be found.


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/errors

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.

Process finished with exit code 1






"
36493,tf.linalg.diag not working as expected,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): v2.1.0-0-ge5bf8de410 2.1.0
- Python version: 3.7.6
- Bazel version (if compiling from source): 0.27.1
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: 10.1
- GPU model and memory: GTX1070 8GB

**Describe the current behavior**
Function tf.linalg.diag is not working as expected
```
import tensorflow as tf
tf.linalg.diag([1,1,1,1,1,1,1,1,1,1,1,1,1,1], k=2, num_rows=-1, num_cols=-1, padding_value=9)
```

<tf.Tensor: shape=(14, 14), dtype=int32, numpy=
array([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
       [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
       [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
       [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
       [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],
       [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],
       [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],
       [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],
       [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],
       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],
       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],
       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],
       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]], dtype=int32)>

**Describe the expected behavior**
I would expect something like this:

<tf.Tensor: shape=(16, 16), dtype=int32, numpy=
array([[9, 9, 1, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],
       [9, 9, 9, 1, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],
       [9, 9, 9, 9, 1, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],
       [9, 9, 9, 9, 9, 1, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],
       [9, 9, 9, 9, 9, 9, 1, 9, 9, 9, 9, 9, 9, 9, 9, 9],
       [9, 9, 9, 9, 9, 9, 9, 1, 9, 9, 9, 9, 9, 9, 9, 9],
       [9, 9, 9, 9, 9, 9, 9, 9, 1, 9, 9, 9, 9, 9, 9, 9],
       [9, 9, 9, 9, 9, 9, 9, 9, 9, 1, 9, 9, 9, 9, 9, 9],
       [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 1, 9, 9, 9, 9, 9],
       [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 1, 9, 9, 9, 9],
       [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 1, 9, 9, 9],
       [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 1, 9, 9],
       [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 1, 9],
       [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 1],
       [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],
       [9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9]], dtype=int32)>

**Code to reproduce the issue**
```
import tensorflow as tf
tf.linalg.diag([1,1,1,1,1,1,1,1,1,1,1,1,1,1], k=2, num_rows=-1, num_cols=-1, padding_value=9)
```

**Other info / logs**
Running the below code explicitly produces the right results:
```
from tensorflow.python.ops.gen_array_ops import matrix_diag_v2
matrix_diag_v2([1,1,1,1,1,1,1,1,1,1,1,1,1,1], k=2, num_rows=-1, num_cols=-1, padding_value=9)
```
"
36492,saving_utils.compile_args_from_training_config does not work with multiple loss fuctions,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): YES
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NO
- TensorFlow installed from (source or binary):binary
- TensorFlow version (use command below):TF VERSION:  1.15.0-rc2
- Python version: 3.7
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

**Describe the current behavior**
Error when loading a saved keras.model that was compiled with a list of loss functions.
### Stacktrace
```
Traceback (most recent call last):
  File ""reproduce_issue_multiloss.py"", line 27, in <module>
    model = keras.models.load_model(""model.hdf5"")
  File ""/home/X/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/save.py"", line 143, in load_model
    return hdf5_format.load_model_from_hdf5(filepath, custom_objects, compile)
  File ""/home/X/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py"", line 178, in load_model_from_hdf5
    training_config, custom_objects))
  File ""/home/X/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/tracking/base.py"", line 457, in _method_wrapper
    result = method(self, *args, **kwargs)
  File ""/home/X/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py"", line 336, in compile
    self.loss, self.output_names)
  File ""/home/X/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_utils.py"", line 1355, in prepare_loss_functions
    loss_functions = nest.map_structure(get_loss_function, loss)
  File ""/home/X/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/util/nest.py"", line 536, in map_structure
    structure[0], [func(*x) for x in entries],
  File ""/home/X/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/util/nest.py"", line 536, in <listcomp>
    structure[0], [func(*x) for x in entries],
  File ""/home/X/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_utils.py"", line 1092, in get_loss_function
    name=loss_fn.__name__,
AttributeError: 'MeanSquaredError' object has no attribute '__name__'
```

**Describe the expected behavior**
The model is loaded and compiled without error.

**Code to reproduce the issue**
```
import tensorflow as tf
import tensorflow.keras as keras
import numpy as np

print(""TF VERSION: "", tf.__version__)

inputs = keras.Input(2)
d1 = keras.layers.Dense(4)
d2 = keras.layers.Dense(4)
o1 = d1(inputs)
o2 = d2(inputs)

# make a model with multiple outputs
model = keras.Model(inputs=inputs, outputs=[o1, o2])

# compile the model with multiple losses
model.compile(loss=[keras.losses.MeanSquaredError(), keras.losses.MeanSquaredError()])

# try to feed a batch through the model
batch = np.linspace(0, 9, 10).reshape(5, 2)
outs = model.predict(batch)
print(outs)

# save and load the model
model.save(""model.hdf5"")

model = keras.models.load_model(""model.hdf5"")

```


**Other info / logs**
The error is related to the code in function ` compile_args_from_training_config` from `/python/keras/saving/saving_utils.py`

```
def compile_args_from_training_config(training_config, custom_objects=None):
  """"""Return model.compile arguments from training config.""""""
  if custom_objects is None:
    custom_objects = {}

  optimizer_config = training_config['optimizer_config']
  optimizer = optimizers.deserialize(
      optimizer_config, custom_objects=custom_objects)

  # Recover loss functions and metrics.
  loss_config = training_config['loss']  # Deserialize loss class.
  if isinstance(loss_config, dict) and 'class_name' in loss_config:
    loss_config = losses.get(loss_config)
  loss = nest.map_structure(
      lambda obj: custom_objects.get(obj, obj), loss_config)
  metrics = nest.map_structure(
      lambda obj: custom_objects.get(obj, obj), training_config['metrics'])
  weighted_metrics = nest.map_structure(
      lambda obj: custom_objects.get(obj, obj),
      training_config.get('weighted_metrics', None))
  sample_weight_mode = training_config['sample_weight_mode']
  loss_weights = training_config['loss_weights']

  return dict(
      optimizer=optimizer,
      loss=loss,
      metrics=metrics,
      weighted_metrics=weighted_metrics,
      loss_weights=loss_weights,
      sample_weight_mode=sample_weight_mode)
```
Since we have multiple losses `training_config['loss']` is a list: `[{'class_name': 'MeanSquaredError', 'config': {...}}, {'class_name': 'MeanSquaredError', 'config': {...}}]`

This case is not covered, therefore the loss configs in the list are not parsed to functions leading to errors further down the call stack.
"
36491,tf lite model error,"Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: FULLY_CONNECTED. Here is a list of operators for which you will need custom implementations: IdentityN."
36490,"Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: FULLY_CONNECTED. Here is a list of operators for which you will need custom implementations: IdentityN.","**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- TensorFlow installed from (source or binary):
- TensorFlow version (or github SHA if from source):


**Provide the text output from tflite_convert**

```
# Copy and paste here
```

Also, please include a link to a GraphDef or the model if possible.

**Any other info / logs**

Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
36486,import tensorflow (v2.1.0) fails,"**System information**
- Windows 10
- TensorFlow installed from (pip install tensorflow):
- TensorFlow version: 2.1.0
- Python version: 3.7.1
- Installed using virtualenv:

**Describe the problem**
```import tensorflow as tf``` fails

```
(tf2) D:\@Temp\@Issues\2020-02-04-tf\tf2>python -c ""import tensorflow as tf;print(tf.reduce_sum(tf.random.normal([1000, 1000])))""
Traceback (most recent call last):
  File ""D:\@Temp\@Issues\2020-02-04-tf\tf2\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""D:\@Temp\@Issues\2020-02-04-tf\tf2\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""D:\@Temp\@Issues\2020-02-04-tf\tf2\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\igor-z\AppData\Local\Continuum\anaconda3\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\igor-z\AppData\Local\Continuum\anaconda3\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: The specified module could not be found.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""<string>"", line 1, in <module>
  File ""D:\@Temp\@Issues\2020-02-04-tf\tf2\lib\site-packages\tensorflow\__init__.py"", line 101, in <module>
    from tensorflow_core import *
  File ""D:\@Temp\@Issues\2020-02-04-tf\tf2\lib\site-packages\tensorflow_core\__init__.py"", line 40, in <module>
    from tensorflow.python.tools import module_util as _module_util
  File ""D:\@Temp\@Issues\2020-02-04-tf\tf2\lib\site-packages\tensorflow\__init__.py"", line 50, in __getattr__
    module = self._load()
  File ""D:\@Temp\@Issues\2020-02-04-tf\tf2\lib\site-packages\tensorflow\__init__.py"", line 44, in _load
    module = _importlib.import_module(self.__name__)
  File ""C:\Users\igor-z\AppData\Local\Continuum\anaconda3\lib\importlib\__init__.py"", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""D:\@Temp\@Issues\2020-02-04-tf\tf2\lib\site-packages\tensorflow_core\python\__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""D:\@Temp\@Issues\2020-02-04-tf\tf2\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 74, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""D:\@Temp\@Issues\2020-02-04-tf\tf2\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""D:\@Temp\@Issues\2020-02-04-tf\tf2\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""D:\@Temp\@Issues\2020-02-04-tf\tf2\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\igor-z\AppData\Local\Continuum\anaconda3\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\igor-z\AppData\Local\Continuum\anaconda3\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: The specified module could not be found.


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/errors

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.
```

tf (v1.15.0) in other virtual environment shows next:
```
(tf1) D:\@Temp\@Issues\2020-02-04-tf\tf1>python
Python 3.7.1 (default, Dec 10 2018, 22:54:23) [MSC v.1915 64 bit (AMD64)] :: Anaconda, Inc. on win32
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import tensorflow as tf
2020-02-05 15:31:28.406892: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'cudart64_100.dll'; dlerror: cudart64_100.dll not found
2020-02-05 15:31:28.411004: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
>>> tf.__version__
'1.15.0'
>>>
```

"
36485,Failed to load the native TensorFlow runtime.,"**System information**
- OS :windows 10 x64
- TensorFlow installed from (source or binary):binary
- TensorFlow version:2.1
- Python version:3.6.5
- Installed using virtualenv? pip? conda?:installed in python3.6.5 anaconda virtualenv using pip
- CUDA/cuDNN version:cuda10.1 with cudnn 7.6.5.32
- GPU model and memory:nivida gtx 1060

I have installed cuda and cudnn and add them to PATH,but when I try to import tensorflow 
I get the following error

(kr) C:\WINDOWS\system32>python
Python 3.6.5 |Anaconda, Inc.| (default, Mar 29 2018, 13:32:41) [MSC v.1900 64 bit (AMD64)] on win32
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import tensorflow
Traceback (most recent call last):
  File ""D:\anaconda\envs\kr\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""D:\anaconda\envs\kr\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""D:\anaconda\envs\kr\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""D:\anaconda\envs\kr\lib\imp.py"", line 243, in load_module
    return load_dynamic(name, filename, file)
  File ""D:\anaconda\envs\kr\lib\imp.py"", line 343, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: 找不到指定的模块。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""D:\anaconda\envs\kr\lib\site-packages\tensorflow\__init__.py"", line 101, in <module>
    from tensorflow_core import *
  File ""D:\anaconda\envs\kr\lib\site-packages\tensorflow_core\__init__.py"", line 40, in <module>
    from tensorflow.python.tools import module_util as _module_util
  File ""D:\anaconda\envs\kr\lib\site-packages\tensorflow\__init__.py"", line 50, in __getattr__
    module = self._load()
  File ""D:\anaconda\envs\kr\lib\site-packages\tensorflow\__init__.py"", line 44, in _load
    module = _importlib.import_module(self.__name__)
  File ""D:\anaconda\envs\kr\lib\importlib\__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""D:\anaconda\envs\kr\lib\site-packages\tensorflow_core\python\__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""D:\anaconda\envs\kr\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 74, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""D:\anaconda\envs\kr\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""D:\anaconda\envs\kr\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""D:\anaconda\envs\kr\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""D:\anaconda\envs\kr\lib\imp.py"", line 243, in load_module
    return load_dynamic(name, filename, file)
  File ""D:\anaconda\envs\kr\lib\imp.py"", line 343, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: 找不到指定的模块。


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/errors

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.

would somebody kindly offer some help?"
36484,Gradient in keras model with respect to layer outputs is `None` when layer is a Model,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): centos-release-7-6.1810.2.el7.centos.x86_64

- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:

- TensorFlow installed from (source or binary): Binary

- TensorFlow version (use command below): 2.1.0
- Python version: 3.7.4
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

**Describe the current behavior**
I want to obtain the gradients of a network's output with respect to an intermediate layer which is itself a keras `Model`. This returns `None`. 

**Describe the expected behavior**
It should return something other than `None`.

**Code to reproduce the issue**
```
import tensorflow as tf

input = tf.keras.layers.Input(shape=(28,28))

x = tf.keras.layers.Flatten()(input)
x = tf.keras.layers.Dense(128)(x)
x = tf.keras.layers.ReLU()(x)
x = tf.keras.layers.Dense(10)(x)

small_model = tf.keras.models.Model(inputs=[input], outputs=[x])

y = small_model(input)

y = tf.keras.layers.Dense(20)(y)
y = tf.keras.layers.Dense(30)(y)
y = tf.keras.layers.Dense(10)(y)

big_model = tf.keras.models.Model(inputs=[small_model.input], outputs=[y])

ext_model = tf.keras.models.Model(inputs=[small_model.input], outputs=[big_model.output,  big_model.layers[1].output])

images = tf.random.uniform(shape=(32,28,28))
labels = tf.zeros(shape=(32,))

with tf.GradientTape() as tape:    
    predictions, layer = ext_model(images)

print(""grad = "", tape.gradient(predictions, layer))
```

**Other info / logs**
Changing to ```ext_model = tf.keras.models.Model(inputs=[small_model.input], outputs=[big_model.output,  big_model.layers[2].output])``` outputs a gradient different from `None`, which indicates that the problem occurs only when the layer in question is a `Model` itself. But this is precisely the typical use case scenario, where one needs gradients with respect to the outputs of an intermediate layer of a pre-built `tf.keras.applications` model. 

This issue is related (but not identical) to https://github.com/tensorflow/tensorflow/issues/33478 which doesn't seem to have been adequately addressed. "
36483,Trying to install pytorch-neat - No such file or directory setup.py,"I've attempted to install pytorch-neat from https://github.com/uber-research/PyTorch-NEAT.git.
I cloned the repo which is now in C:\Users\username\AppData\Local\Continuum\anaconda3\pkgs\PyTorch-NEAT and the following command 
pip install git+https://github.com/uber-research/PyTorch-NEAT.git
which is giving the following error
 ERROR: Command errored out with exit status 1:
     command: 'c:\users\townsond\appdata\local\continuum\anaconda3\envs\petchem_py36\python.exe' -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'C:\\Users\\townsond\\AppData\\Local\\Temp\\pip-req-build-0krj5_3e\\setup.py'""'""'; __file__='""'""'C:\\Users\\townsond\\AppData\\Local\\Temp\\pip-req-build-0krj5_3e\\setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' egg_info --egg-base 'C:\Users\townsond\AppData\Local\Temp\pip-req-build-0krj5_3e\pip-egg-info'
         cwd: C:\Users\townsond\AppData\Local\Temp\pip-req-build-0krj5_3e\
    Complete output (5 lines):
    Traceback (most recent call last):
      File ""<string>"", line 1, in <module>
      File ""c:\users\townsond\appdata\local\continuum\anaconda3\envs\petchem_py36\lib\tokenize.py"", line 452, in open
        buffer = _builtin_open(filename, 'rb')
    FileNotFoundError: [Errno 2] No such file or directory: 'C:\\Users\\townsond\\AppData\\Local\\Temp\\pip-req-build-0krj5_3e\\setup.py'
    ----------------------------------------
ERROR: Command errored out with exit status 1: python setup.py egg_info Check the logs for full command output.

I can see pytorch-neat does not have a setup.py file and I'm unsure on how to proceed from here.
I'm using Python 3.6 and have upgraded both setuptools and pip, and tried pip3 install also.

Any help appreciated!"
36480,Error when executing model.predict or model.evaluate even though Loading is successful,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Issue is not specific to OS. Could be reproduced in Google Colab
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): N/A
- TensorFlow version (use command below): 1.15
- Python version: Colab Version
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A

**Describe the current behavior**: I have Saved a Model using the command, `cnn_model.save('CNN_MNIST_Sequential.h5')`. Now, when I loaded that Model using `tf.keras.models.load_model('CNN_MNIST_Sequential.h5')`, it is loading properly and is showing the Trained Parameters when I ran `model.summary()`. But when I ran the command, `cnn_model.evaluate(X_test_reshaped,  y_test, verbose=2)` or `cnn_model.predict(X_test_reshaped).shape`, it is resulting in the below error.

> ValueError: When using data tensors as input to a model, you should specify the `steps` argument.

Reason for the error (not quite sure though) might be that the Model which is Saved (CNN_MNIST_Sequential.h5), was executed with `steps_per_epoch` and `validation_steps` as shown below,

```
history = cnn_model.fit(x = X_train_reshaped,
                        y = y_train,
                        batch_size = 512,
                        epochs = 5,
                        verbose = 1, validation_data = (X_test_reshaped, y_test),
                        validation_steps = 10, steps_per_epoch=steps_per_epoch)
```

**Describe the expected behavior**: Commands, `model.evaluate` and `model.predict` should run without error, as the Model is Loading Succesfully

**Code to reproduce the issue**: Please find Gist of my [Golab Colab](https://colab.sandbox.google.com/gist/rmothukuru/8b1639919d9e9eee2c8e95978fea8fc4/cnn_mnist_sequential_restored.ipynb)."
36477,[tf2.1] model saving error for model with Batch Normalization layer and under MirroredStrategy,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Redhat 8.1 (in Docker)
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): TF2.1.0
- Python version: 3.6.8
- CUDA/cuDNN version: 10.1
- GPU model and memory: V100, 32GB

**Describe the current behavior**
In TF2.1.0, if I build and compile a model with Batch Normalization layer under MirroredStrategy scope, model saving will throw some error like 
```
KeyError: ""Failed to add concrete function b'__inference_sequential_layer_call_and_return_conditional_losses_869' to object based saved model as it captures tensor tf.Tensor(<unprintable>, shape=(), dtype=resource) which is unsupported or not reachable from root. One reason could be that a stateful object or a variable that the function depends on is not assigned to an attribute of the serialized trackable object (see SaveTest.test_captures_unreachable_variable).""
```
I have tested with tf2.0.0 and this seems to be fine .

**Code to reproduce the issue**
```python
import tensorflow as tf

def build_and_compile_model():
    
    input = tf.keras.Input((20,))
    x = tf.keras.layers.BatchNormalization()(input)
    y = tf.keras.layers.Dense(2)(x)
    
    model = tf.keras.Model(inputs=input, outputs=y)
    
    model.compile(
        loss=tf.keras.losses.sparse_categorical_crossentropy,
        optimizer=tf.keras.optimizers.SGD(learning_rate=0.001),
        metrics=['accuracy'])
    
    return model

strategy = tf.distribute.MirroredStrategy()
with strategy.scope():
    model = build_and_compile_model()
model.save('test', save_format='tf')
```

**Other info / logs**
Traceback logs as follows:
```
---------------------------------------------------------------------------
KeyError                                  Traceback (most recent call last)
/tmp/site-packages/tensorflow_core/python/saved_model/function_serialization.py in serialize_concrete_function(concrete_function, node_ids, coder)
     53     for capture in concrete_function.captured_inputs:
---> 54       bound_inputs.append(node_ids[capture])
     55   except KeyError:

/tmp/site-packages/tensorflow_core/python/util/object_identity.py in __getitem__(self, key)
    131   def __getitem__(self, key):
--> 132     return self._storage[self._wrap_key(key)]
    133 

KeyError: <_ObjectIdentityWrapper wrapping <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>>

During handling of the above exception, another exception occurred:

KeyError                                  Traceback (most recent call last)
<ipython-input-13-a7ec70c505d2> in <module>()
----> 1 model.save('test10', save_format='tf')

/tmp/site-packages/tensorflow_core/python/keras/engine/network.py in save(self, filepath, overwrite, include_optimizer, save_format, signatures, options)
   1006     """"""
   1007     save.save_model(self, filepath, overwrite, include_optimizer, save_format,
-> 1008                     signatures, options)
   1009 
   1010   def save_weights(self, filepath, overwrite=True, save_format=None):

/tmp/site-packages/tensorflow_core/python/keras/saving/save.py in save_model(model, filepath, overwrite, include_optimizer, save_format, signatures, options)
    113   else:
    114     saved_model_save.save(model, filepath, overwrite, include_optimizer,
--> 115                           signatures, options)
    116 
    117 

/tmp/site-packages/tensorflow_core/python/keras/saving/saved_model/save.py in save(model, filepath, overwrite, include_optimizer, signatures, options)
     76     # we use the default replica context here.
     77     with distribution_strategy_context._get_default_replica_context():  # pylint: disable=protected-access
---> 78       save_lib.save(model, filepath, signatures, options)
     79 
     80   if not include_optimizer:

/tmp/site-packages/tensorflow_core/python/saved_model/save.py in save(obj, export_dir, signatures, options)
    921       compat.as_str(constants.SAVED_MODEL_FILENAME_PB))
    922   object_graph_proto = _serialize_object_graph(
--> 923       saveable_view, asset_info.asset_index)
    924   meta_graph_def.object_graph_def.CopyFrom(object_graph_proto)
    925 

/tmp/site-packages/tensorflow_core/python/saved_model/save.py in _serialize_object_graph(saveable_view, asset_file_def_index)
    645   for concrete_function in saveable_view.concrete_functions:
    646     serialized = function_serialization.serialize_concrete_function(
--> 647         concrete_function, saveable_view.captured_tensor_node_ids, coder)
    648     if serialized is not None:
    649       proto.concrete_functions[concrete_function.name].CopyFrom(

/tmp/site-packages/tensorflow_core/python/saved_model/function_serialization.py in serialize_concrete_function(concrete_function, node_ids, coder)
     61         ""trackable object ""
     62         ""(see SaveTest.test_captures_unreachable_variable).""
---> 63         % (concrete_function.name, capture))
     64   concrete_function_proto = saved_object_graph_pb2.SavedConcreteFunction()
     65   structured_outputs = func_graph_module.convert_structure_to_signature(

KeyError: ""Failed to add concrete function b'__inference_sequential_1_layer_call_and_return_conditional_losses_1937' to object based saved model as it captures tensor tf.Tensor(<unprintable>, shape=(), dtype=resource) which is unsupported or not reachable from root. One reason could be that a stateful object or a variable that the function depends on is not assigned to an attribute of the serialized trackable object (see SaveTest.test_captures_unreachable_variable).""
```
Thanks so much for your time!"
36476,tensorflow==1.15.2 package on PyPI cannot find GPU devices,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04 (in Docker)
- TensorFlow installed from (source or binary): Binary
- TensorFlow version: 1.15.2
- Python version: 3.6
- Installed using virtualenv? pip? conda?: pip
- CUDA/cuDNN version: 10.0
- GPU model and memory: GTX 1080 Ti 12 GB

**Describe the problem**

When using the tensorflow package at version 1.15.2, Tensorflow does not find my GPU. The tensorflow-gpu package works, but I was under the impression that from 1.15.0 onward, the tensorflow package would be capable of running with or without a GPU.

Looking at PyPI, I notice there isn't a tensorflow-cpu package released for 1.15.2. Has the project switched back to using the old model where only tensorflow-gpu has GPU support?

**Provide the exact sequence of commands / steps that you executed before running into the problem**

1. `pip3 install tensorflow==1.15.2`
2. Run the following script:
    ```python3
    from tensorflow.python.client import device_lib
    print(device_lib.list_local_devices())
    ```
3. Observe that CPU devices are found, but GPU devices are not

**Any other info / logs**

I've been testing this in a Docker container that uses Nvidia's Cuda images. I have nvidia-docker2 installed and can confirm that the tensorflow 1.15.0 package is capable of finding the GPU device.

```Dockerfile
FROM nvidia/cuda:10.0-cudnn7-runtime-ubuntu18.04

RUN apt-get update && apt-get install -y python3-pip
RUN pip3 install --upgrade pip
RUN pip3 install tensorflow==1.15.2

ENTRYPOINT [""python3"", ""-c"", ""from tensorflow.python.client import device_lib; print(device_lib.list_local_devices())""]
```

I get the following logs as a result:

```
2020-02-04 22:29:15.945515: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-02-04 22:29:15.971253: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3393255000 Hz
2020-02-04 22:29:15.972730: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x45f0770 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-02-04 22:29:15.972756: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
[name: ""/device:CPU:0""
device_type: ""CPU""
memory_limit: 268435456
locality {
}
incarnation: 14247052760952852178
, name: ""/device:XLA_CPU:0""
device_type: ""XLA_CPU""
memory_limit: 17179869184
locality {
}
incarnation: 3258632196886034744
physical_device_desc: ""device: XLA_CPU device""
]
```
"
36475,tf.keras.utils.get_file issue,"I am using Google Colab with tensorflow and I was trying to download files from my google cloud storage. I was able to download the files to Colab but somehow they are corrupted because I can not read or view the files. Even if I after I downloaded them from Colab to my own PC, I still couldn't open/read the files. But if download them directly from Cloud Storage to my PC, they are fine. The files I am dealing with are .tif files (satellite images). Here' the code to download the files: 
`import tensorflow as tf
tf.keras.utils.get_file(""/root/image.tif"",""https://storage.cloud.google.com/project/image.tif"")`
"
36474,TFLite iOS benchmark app doesn't produce consistent result while using GPU delegate,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Mac OS 10.14.6
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: iPhone XR (tested on iOS 13.3, and 12.3.1), iPhone Xs (13.1.2)
- TensorFlow installed from (source or binary): installed from source.
- TensorFlow version (use command below): 1.14.0
- Python version: 3.6
- Bazel version (if compiling from source): 1.2.1
- GCC/Compiler version (if compiling from source): 4.2.1


**Describe the current behavior**
TFLite iOS benchmark app doesn't produce consistent result while using GPU delegate.

Testing with Mobilenet_1.0_224(float) model on iOS benchmark app, while using the default parameter, I'm able to obtain similar performance with the benchmark provided [here:](https://www.tensorflow.org/lite/performance/benchmarks) (around 14.x ms). 

However, while adding the GPU delegate param according to the instruction (`""use_gpu"" : ""1""` and `""gpu_wait_type"" : ""aggressive""` options were also added to `benchmark_params.json`), the benchmark app still reports almost the same performance, instead of the 4x faster performance shown in the benchmark.


**Describe the expected behavior**

Similar performance for GPU delegate with the results provided in the iOS benchmark page.

**Code to reproduce the issue**
https://github.com/tensorflow/tensorflow/blob/9901f967b11763726ae380273a24ee9b4fdae7f0/tensorflow/lite/tools/benchmark/ios/TFLiteBenchmark/TFLiteBenchmark/benchmark_data/benchmark_params.json
with 
`""use_gpu"" : ""1"",
    ""gpu_wait_type"" : ""aggressive""` added.


**Other info / logs**

```
Min num runs: [20]
Min runs duration (seconds): [1]
Max runs duration (seconds): [150]
Inter-run delay (seconds): [-1]
Num threads: [2]
Benchmark name: [mobile_net_benchmark]
Output prefix: []
Min warmup runs: [1]
Min warmup runs duration (seconds): [0.5]
Graph: [/private/var/containers/Bundle/Application/93C7DE45-ADBA-4E5B-B64B-3F789A357080/TFLiteBenchmark.app/mobilenet_v1_1.0_224.tflite]
Input layers: [input]
Input shapes: [1,224,224,3]
Input value ranges: []
Allow fp16 : [0]
Require full delegation : [0]
Enable op profiling: [0]
Max profiling buffer entries: [1024]
Loaded model /private/var/containers/Bundle/Application/93C7DE45-ADBA-4E5B-B64B-3F789A357080/TFLiteBenchmark.app/mobilenet_v1_1.0_224.tflite
2020-02-04 16:04:27.856557-0500 TFLiteBenchmark[1156:379854] Initialized TensorFlow Lite runtime.
The input model file size (MB): 16.9008
Initialized session in 15.791ms.
Running benchmark for at least 1 iterations and at least 0.5 seconds but terminate if exceeding 150 seconds.
count=31 first=79523 curr=14493 min=14015 max=79523 avg=16387.8 std=11545

Running benchmark for at least 20 iterations and at least 1 seconds but terminate if exceeding 150 seconds.
count=68 first=14721 curr=14936 min=14055 max=15838 avg=14710.9 std=308

Note: as the benchmark tool itself affects memory footprint, the following is only APPROXIMATE to the actual memory footprint of the model at runtime. Take the information at your discretion.
Peak memory footprint (MB): init=0 overall=0
```

"
36473,Program won't execute because of warnings but no errors. ,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution: 18.04
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 1.14.0 using pip install tensorflow-gpu
- Python version:3.6
- CUDA/cuDNN version: 9.2, 7

`+-----------------------------------------------------------------------------+
| NVIDIA-SMI 396.44                 Driver Version: 396.44                    |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  TITAN X (Pascal)    Off  | 00000000:02:00.0 Off |                  N/A |
| 36%   62C    P2   170W / 250W |  11723MiB / 12196MiB |     43%      Default |
+-------------------------------+----------------------+----------------------+
|   1  TITAN X (Pascal)    Off  | 00000000:03:00.0 Off |                  N/A |
| 39%   67C    P2   135W / 250W |  11723MiB / 12196MiB |     31%      Default |
+-------------------------------+----------------------+----------------------+
|   2  TITAN X (Pascal)    Off  | 00000000:81:00.0 Off |                  N/A |
| 23%   23C    P8    15W / 250W |     10MiB / 12196MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   3  TITAN X (Pascal)    Off  | 00000000:82:00.0 Off |                  N/A |
| 23%   23C    P8    16W / 250W |     10MiB / 12196MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
`

`/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([(""qint8"", np.int8, 1)])
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([(""quint8"", np.uint8, 1)])
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([(""qint16"", np.int16, 1)])
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([(""quint16"", np.uint16, 1)])
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([(""qint32"", np.int32, 1)])
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([(""resource"", np.ubyte, 1)])
/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([(""qint8"", np.int8, 1)])
/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([(""quint8"", np.uint8, 1)])
/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([(""qint16"", np.int16, 1)])
/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([(""quint16"", np.uint16, 1)])
/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([(""qint32"", np.int32, 1)])
/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([(""resource"", np.ubyte, 1)])
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/compat/v2_compat.py:61: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.
Instructions for updating:
non-resource variables are not supported in the long term
2020-02-04 15:57:41.054419: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1
2020-02-04 15:57:41.072997: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: 
name: TITAN X (Pascal) major: 6 minor: 1 memoryClockRate(GHz): 1.531
pciBusID: 0000:02:00.0
2020-02-04 15:57:41.073864: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 1 with properties: 
name: TITAN X (Pascal) major: 6 minor: 1 memoryClockRate(GHz): 1.531
pciBusID: 0000:03:00.0
2020-02-04 15:57:41.074920: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 2 with properties: 
name: TITAN X (Pascal) major: 6 minor: 1 memoryClockRate(GHz): 1.531
pciBusID: 0000:81:00.0
2020-02-04 15:57:41.075917: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 3 with properties: 
name: TITAN X (Pascal) major: 6 minor: 1 memoryClockRate(GHz): 1.531
pciBusID: 0000:82:00.0
2020-02-04 15:57:41.076061: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Could not dlopen library 'libcudart.so.10.0'; dlerror: libcudart.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64::/usr/local/nvidia/lib:/usr/local/nvidia/lib64
2020-02-04 15:57:41.076154: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Could not dlopen library 'libcublas.so.10.0'; dlerror: libcublas.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64::/usr/local/nvidia/lib:/usr/local/nvidia/lib64
2020-02-04 15:57:41.076229: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Could not dlopen library 'libcufft.so.10.0'; dlerror: libcufft.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64::/usr/local/nvidia/lib:/usr/local/nvidia/lib64
2020-02-04 15:57:41.076301: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Could not dlopen library 'libcurand.so.10.0'; dlerror: libcurand.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64::/usr/local/nvidia/lib:/usr/local/nvidia/lib64
2020-02-04 15:57:41.076385: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Could not dlopen library 'libcusolver.so.10.0'; dlerror: libcusolver.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64::/usr/local/nvidia/lib:/usr/local/nvidia/lib64
2020-02-04 15:57:41.076456: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Could not dlopen library 'libcusparse.so.10.0'; dlerror: libcusparse.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64::/usr/local/nvidia/lib:/usr/local/nvidia/lib64
2020-02-04 15:57:41.081626: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7
2020-02-04 15:57:41.081657: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1663] Cannot dlopen some GPU libraries. Skipping registering GPU devices...
2020-02-04 15:57:41.082444: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-02-04 15:57:41.774150: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x207b860 executing computations on platform CUDA. Devices:
2020-02-04 15:57:41.774201: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): TITAN X (Pascal), Compute Capability 6.1
2020-02-04 15:57:41.774213: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (1): TITAN X (Pascal), Compute Capability 6.1
2020-02-04 15:57:41.774223: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (2): TITAN X (Pascal), Compute Capability 6.1
2020-02-04 15:57:41.774232: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (3): TITAN X (Pascal), Compute Capability 6.1
2020-02-04 15:57:41.777758: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2094980000 Hz
2020-02-04 15:57:41.782256: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x20995e0 executing computations on platform Host. Devices:
2020-02-04 15:57:41.782292: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2020-02-04 15:57:41.782402: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-02-04 15:57:41.782419: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      
2020-02-04 15:57:41.838944: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to check for files with this prefix.
2020-02-04 15:57:42.106202: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-02-04 15:57:42.106305: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187] `

In my opinion, these warnings should not stop the program execution. I am not sure which warning to tackle to allow program execution. 
"
36471,TF2+ is amazing(!!!) IDC what anyone says...,"This template is for miscellaneous issues not covered by the other issue categories.

For questions on how to work with TensorFlow, or support for problems that are not verified bugs in TensorFlow, please go to [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).

If you are reporting a vulnerability, please use the [dedicated reporting process](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md).

For high-level discussions about TensorFlow, please post to discuss@tensorflow.org, for questions about the development or internal workings of TensorFlow, or if you would like to know how to contribute to TensorFlow, please post to developers@tensorflow.org.
"
36470,Get network output during training.,"Hello,
Is it possible to run `tensor.eval()` in the loss function to get the network output and use it in an external file to compute the loss.
 
Thank you"
36465,How can I clear GPU memory in tensorflow 2?,"

### System information
- Custom code; nothing exotic though.
- Ubuntu 18.04
- installed from source (with pip)
- tensorflow version v2.1.0-rc2-17-ge5bf8de
- 3.6
- CUDA 10.1
- Tesla V100, 32GB RAM

I created a model, nothing especially fancy in it. When I create the model, when using nvidia-smi, I can see that tensorflow takes up nearly all of the memory. When I try to fit the model with a small batch size, it successfully runs. When I fit with a larger batch size, it runs out of memory. Nothing unexpected so far. 

However, the only way I can then release the GPU memory is to restart my computer. When I run nvidia-smi I can see the memory is still used, but there is no process using a GPU. Also, If I try to run another model, it fails much sooner. 

Nothing in the first five pages of google results works. (and most solutions are for TF1)

Is there any way to release GPU memory in tensorflow 2?"
36464,If-Condition with TF-Bools looses track of namescopes,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes (see below)
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: no
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): tested on tf-gpu v2.0.0 and tf v2.1.0 (CPU as I do not have CUDA 10.1 running)
- Python version: 3.6.7
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10.1/7.4.2
- GPU model and memory: tested on Nvidia Quadro P2000

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
When inside a function with graph mode activated, using an `if` statement with a tensorflow bool leads possibly to a new namescope. I assume this, because the observation one can make is that `tf.summary`s inside this if condition are placed inside different name scopes depending on whether the condition is a python bool (so static w.r.t. to the tensorflow graph) or a tensorflow tensor (resulting in a dynamic `tf.cond` through autograph). This happens for both v2.0 and v2.1, afaict. Of course, in eager mode this problem is non-existent.

**Describe the expected behavior**
The final summary scope should be independent of whether a autographed condition was used or a statically compiled one. Attached is a minimal working example producing a tensorboard output show in the image. The two lines are produced by the same `tf.summary.scalar` line inside the `tf.name_scope('monitoring')`. In this case it would be easy enough to move the name_scope creation inside the if-scope, however my use cases do not allow this kind of workaround (summaries are written inside keras layer calls which add their own respective namescope).

**Code to reproduce the issue**
```python
import os.path as osp

import tensorflow as tf


@tf.function
def func_with_summaries(step, write_summary):
    with tf.name_scope(""monitoring""):
        if write_summary:
            tf.summary.scalar(""step"", step, tf.cast(step, dtype=tf.int64))


brok_writer = tf.summary.create_file_writer(
    osp.join(""/tmp"", ""summaries_conds_scopes"", ""broken"")
)
writer = tf.summary.create_file_writer(
    osp.join(""/tmp"", ""summaries_conds_scopes"", ""correct"")
)
st = tf.Variable(0.0, name=""step"", dtype=tf.float32)
for i in range(10):
    st.assign(i)
    with writer.as_default():
        func_with_summaries(st, i % 3 == 0)
    with brok_writer.as_default():
        func_with_summaries(st, tf.constant(i) % 3 == 0)
```
**Other info / logs**
![image](https://user-images.githubusercontent.com/6333870/73756641-3172cf00-4768-11ea-9ec8-31f003c0c049.png)
"
36463,tf.keras.Sequential ignores the outer name scope(s) when built proactively,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS Catalina 10.15.2 (19C57)
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.1.0
- Python version: 3.6.5 (v3.6.5:f59c0932b4)

**Describe the current behavior**

When the `build` method of a `tf.keras.Sequential` instance is (explicitly) called within one (or several nested) `tf.name_scope` context manager(s), the variable (weight) names of the layers wrapped into the `Sequential` don't get the respective name scope prefixes.

**Describe the expected behavior**

After `build`ing a `Sequential`, all the `tf.name_scope`s surrounding the `build` call must be reflected as prefixes of the `Sequential`'s variable (weight) names. This is what currently happens in `tensorflow==1.15.2`.

**Code to reproduce the issue**

```python
import tensorflow as tf

seq = tf.keras.Sequential(layers=[
    tf.keras.layers.Dense(units=10, name=""d1""),
    tf.keras.layers.Dense(units=20, name=""d2""),
])

with tf.name_scope(""a""):
    with tf.name_scope(""b""):
        seq.build(input_shape=[32, 784])

for w in seq.weights:
    print(w.name)
```

the output with `tensorflow==2.1.0`:

```
d1/kernel:0
d1/bias:0
d2/kernel:0
d2/bias:0
```

the output with `tensorflow==1.15.2`:

```
a/b/d1/kernel:0
a/b/d1/bias:0
a/b/d2/kernel:0
a/b/d2/bias:0
```"
36462,Autograph is incompatible with typeguard,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: no
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.1.0
- Python version: 3.6.9
- Bazel version (if compiling from source): no
- GCC/Compiler version (if compiling from source): no
- CUDA/cuDNN version: no
- GPU model and memory: no gpu

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

```python
import tensorflow as tf
from typeguard import typechecked
@tf.function(autograph=True)
@typechecked
def add(a: tf.Tensor, b: tf.Tensor) -> tf.Tensor:
    return a + b

print(add(tf.ones(2), tf.zeros(2)))
```

```
---------------------------------------------------------------------------
NameError                                 Traceback (most recent call last)
<ipython-input-5-5567d1a6d381> in <module>()
      4     return a + b
      5 
----> 6 print(add(tf.ones(2), tf.zeros(2)))

8 frames
/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py in __call__(self, *args, **kwds)
    566         xla_context.Exit()
    567     else:
--> 568       result = self._call(*args, **kwds)
    569 
    570     if tracing_count == self._get_tracing_count():

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py in _call(self, *args, **kwds)
    613       # This is the first call of __call__, so we have to initialize.
    614       initializers = []
--> 615       self._initialize(args, kwds, add_initializers_to=initializers)
    616     finally:
    617       # At this point we know that the initialization is complete (or less

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py in _initialize(self, args, kwds, add_initializers_to)
    495     self._concrete_stateful_fn = (
    496         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access
--> 497             *args, **kwds))
    498 
    499     def invalid_creator_scope(*unused_args, **unused_kwds):

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py in _get_concrete_function_internal_garbage_collected(self, *args, **kwargs)
   2387       args, kwargs = None, None
   2388     with self._lock:
-> 2389       graph_function, _, _ = self._maybe_define_function(args, kwargs)
   2390     return graph_function
   2391 

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py in _maybe_define_function(self, args, kwargs)
   2701 
   2702       self._function_cache.missed.add(call_context_key)
-> 2703       graph_function = self._create_graph_function(args, kwargs)
   2704       self._function_cache.primary[cache_key] = graph_function
   2705       return graph_function, args, kwargs

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py in _create_graph_function(self, args, kwargs, override_flat_arg_shapes)
   2591             arg_names=arg_names,
   2592             override_flat_arg_shapes=override_flat_arg_shapes,
-> 2593             capture_by_value=self._capture_by_value),
   2594         self._function_attributes,
   2595         # Tell the ConcreteFunction to clean up its graph once it goes out of

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)
    976                                           converted_func)
    977 
--> 978       func_outputs = python_func(*func_args, **func_kwargs)
    979 
    980       # invariant: `func_outputs` contains only Tensors, CompositeTensors,

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py in wrapped_fn(*args, **kwds)
    437         # __wrapped__ allows AutoGraph to swap in a converted function. We give
    438         # the function a weak reference to itself to avoid a reference cycle.
--> 439         return weak_wrapped_fn().__wrapped__(*args, **kwds)
    440     weak_wrapped_fn = weakref.ref(wrapped_fn)
    441 

/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/func_graph.py in wrapper(*args, **kwargs)
    966           except Exception as e:  # pylint:disable=broad-except
    967             if hasattr(e, ""ag_error_metadata""):
--> 968               raise e.ag_error_metadata.to_exception(e)
    969             else:
    970               raise

NameError: in converted code:

    /usr/local/lib/python3.6/dist-packages/typeguard/__init__.py:3 wrapper  *
        check_argument_types(memo)
    /usr/local/lib/python3.6/dist-packages/typeguard/__init__.py:663 check_argument_types  *
        for argname, expected_type in memo.type_hints.items():
    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/operators/control_flow.py:339 for_stmt
        return _py_for_stmt(iter_, extra_test, body, get_state, set_state, init_vars)
    /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/operators/control_flow.py:348 _py_for_stmt
        if extra_test is not None and not extra_test(*state):
    /tmp/tmpnaoua4_l.py:96 extra_test
        return ag__.not_(do_return)

    NameError: free variable 'do_return' referenced before assignment in enclosing scope
```

**Describe the expected behavior**

```
tf.Tensor([1. 1.], shape=(2,), dtype=float32)
```

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.

```python
import tensorflow as tf
from typeguard import typechecked

@tf.function(autograph=True)
@typechecked
def add(a: tf.Tensor, b: tf.Tensor) -> tf.Tensor:
    return a + b

print(add(tf.ones(2), tf.zeros(2)))
```

See the colab notebook: https://colab.research.google.com/drive/1RTg-ysyIdKME4fbJQ1D5Dxs-11YfBV5e

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
36461,Missning signaturedef while converting model from .h5 to tensorflow saved format model ,"hi,i am saving the finetuned model as :
model.save_pretrained('directory')
It saves a config.json and .h5 model in the directory.
But,when i load the same model using:
loaded_model = TFDistilBertModel.from_pretrained(""directory"")
and then,save it in tf format using:
tf.saved_model.save(loaded_model, ""./tmp/db/1"")
This tfsaved format model conatins:variables,assets and saved_model.pb file.But,it doesn't contain a signature_def so that I can serve the model using tf_serving.
Please help,i am totally stuck"
36460,saving trained tensor flow data on google colab,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): stock example
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Mac catalina
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below):
- Python version: python 3.0 on colab
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: none
- GPU model and memory: colab

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
I ran a walkthrough using python notebook 3 on google colab and every time I run the model, I have to train with the data and then run the prediction. but I'm curious is there anyway to save your data on google colab, so I don't have to  train the model every time when I need to do the prediction.
**Describe the expected behavior**
I want it to save my trained data.
**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
36459,High RAM Usage for TF Runtime?,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04.4 LTS
- TensorFlow installed from (source or binary): pip
- TensorFlow version (use command below): tensorflow-gpu==2.0.0 or tensorflow==2.1.0
- Python version: 3.6.8
- CUDA/cuDNN version: CUDA Toolkit 10.1.243 / cuDNN 7.6.5.32
- GPU model and memory: 8 x GeForce RTX 2080 Ti, 11019MiB
- System memory: 32GB

**Describe the current behavior**

Even the smallest 'computation' leads to very high RAM usages of the system memory (not GPU memory). As shown in the following, a simple single-float-Variable initialization leads to more than 2GB RAM increase. The fewer graphics cards are visible for tensorflow, the less RAM is used after all. 

**Describe the expected behavior**

The expected behavior is way less memory usage and also a constant amount, independently of the number of GPUs visible to tensorflow. More than 2GB per instance is not viable for my (/our) situation, since multiple users are working on the machine. 

**Code to reproduce the issue**

```
import os, psutil
p = psutil.Process(os.getpid())

print(""Memory Usage (before import):"", p.memory_info().rss/1024/1024, ""MB"")

import tensorflow as tf
num_visible_gpus = 8 # OPTIONAL
gpu_devs = tf.config.experimental.list_physical_devices(""GPU"") # OPTIONAL
tf.config.experimental.set_visible_devices(gpu_devs[:num_visible_gpus], ""GPU"") # OPTIONAL

print(""Memory Usage (after  import):"", p.memory_info().rss/1024/1024, ""MB"")

tf.Variable(42.0) # Do some pseudowork...

print(""Memory Usage (after var-def):"", p.memory_info().rss/1024/1024, ""MB"")
```

Output:
> Memory Usage (before import): 47.62109375 MB
> Memory Usage (after  import): 340.15625 MB
> Memory Usage (after var-def): 2485.1796875 MB

Fewer GPUs result in less memory usage (after var-def):

> num_visible_gpus=8 => 2626.039063 MB
> num_visible_gpus=7 => 2488.765626 MB
> num_visible_gpus=6 => 2267.289063 MB
> num_visible_gpus=5 => 2173.917968 MB
> num_visible_gpus=4 => 2011.917968 MB
> num_visible_gpus=3 => 1809.957031 MB
> num_visible_gpus=2 => 1681.316406 MB
> num_visible_gpus=1 => 1539.554688 MB
> num_visible_gpus=0 => 1201.152343 MB

These results were obtained in a jupyter-notebook environment. When run as a py-file, the usages are slightly (by ~200MB) lower (e.g. num_visible_gpus=8 => 2347.7148437 MB). 
"
36457,Predicting on custom model fails,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): YES
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): bunary
- TensorFlow version (use command below): 2.1.0
- Python version: 3.7
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10.1 / 7.6.4.38-1
- GPU model and memory: RTX 2080 Ti 11GB

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
* While I was trying to train some model (keras subclassed model) and export that model for tensorflow serving, I encountered this error.
* So I tried to mimc same error with different but smaller code as below.
* error is that ... 
  * using tf.saved_model.save() with model that outputs image tensor (not scalar - it works) not working in tf 2.1, but works in tf 2.0
  * debug trace shows this error is related to distribute training, but I'm not using it.. or maybe I'm misleading it.
  * in official package's `training_v2_utils.py` and `_aggregate_predict_results(strategy, batch_outs, model)` function, something seems wrong on `model.output`

**Describe the expected behavior**
* should work on tf 2.1 too

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.

```python

import time
import numpy as np
import tensorflow as tf

import matplotlib.pyplot as plt

# https://www.tensorflow.org/tutorials/generative/dcgan

def set_gpu_memory_growth():
    gpus = tf.config.list_physical_devices('GPU')
    if gpus:
        try:
            # Currently, memory growth needs to be the same across GPUs
            for gpu in gpus:
                tf.config.experimental.set_memory_growth(gpu, True)
            logical_gpus = tf.config.list_logical_devices('GPU')
            print(len(gpus), ""Physical GPUs,"", len(logical_gpus), ""Logical GPUs"")
        except RuntimeError as e:
            # Memory growth must be set before GPUs have been initialized
            print(e)
    return


def generate_and_save_images(model, epoch, test_input):
    # Notice `training` is set to False.
    # This is so all layers run in inference mode (batchnorm).
    predictions = model(test_input, training=False)

    fig = plt.figure(figsize=(4, 4))

    for i in range(predictions.shape[0]):
        plt.subplot(4, 4, i + 1)
        plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')
        plt.axis('off')

    plt.savefig('./results/dcgan/image_at_epoch_{:04d}.png'.format(epoch))
    plt.close(fig)
    return


class Dense(tf.keras.layers.Layer):
    def __init__(self, units, **kwargs):
        super(Dense, self).__init__(**kwargs)
        self.units = units

    def build(self, input_shape):
        fin = np.prod(input_shape[1:])
        weight_shape = [fin, self.units]

        w_init = tf.random.normal(shape=weight_shape, mean=0.0, stddev=0.01)
        self.w = tf.Variable(w_init, name='w', trainable=True)

    def call(self, inputs, training=None, mask=None):
        x = tf.keras.layers.Flatten()(inputs)
        x = tf.matmul(x, self.w)
        return x

    def get_config(self):
        config = super(Dense, self).get_config()
        config.update({'units': self.units})
        return config


class LeakyReLU(tf.keras.layers.Layer):
    def __init__(self, **kwargs):
        super(LeakyReLU, self).__init__(**kwargs)
        self.alpha = 0.2

        self.act = tf.keras.layers.LeakyReLU(alpha=self.alpha)

    def call(self, inputs, training=None, mask=None):
        x = self.act(inputs)
        return x

    def get_config(self):
        config = super(LeakyReLU, self).get_config()
        config.update({'alpha': self.alpha})
        return config


class Generator(tf.keras.Model):
    def __init__(self, kernel, **kwargs):
        super(Generator, self).__init__(**kwargs)

        self.kernel = kernel

        self.dense0 = Dense(units=7 * 7 * 256)
        self.bn0 = tf.keras.layers.BatchNormalization()
        self.lrelu0 = LeakyReLU()

        self.convt1 = tf.keras.layers.Conv2DTranspose(128, self.kernel, strides=(1, 1), padding='same', use_bias=False)
        self.bn1 = tf.keras.layers.BatchNormalization()
        self.lrelu1 = LeakyReLU()

        self.convt2 = tf.keras.layers.Conv2DTranspose(64, self.kernel, strides=(2, 2), padding='same', use_bias=False)
        self.bn2 = tf.keras.layers.BatchNormalization()
        self.lrelu2 = LeakyReLU()

        self.convt3 = tf.keras.layers.Conv2DTranspose(1, self.kernel, strides=(2, 2), padding='same', use_bias=False,
                                                      activation='tanh')

    @tf.function
    def call(self, inputs, training=None, mask=None):
        z = inputs

        x = self.dense0(z)
        x = self.bn0(x, training=training)
        x = self.lrelu0(x)

        x = tf.reshape(x, shape=[-1, 7, 7, 256])

        x = self.convt1(x)
        x = self.bn1(x, training=training)
        x = self.lrelu1(x)

        x = self.convt2(x)
        x = self.bn2(x, training=training)
        x = self.lrelu2(x)

        x = self.convt3(x)
        return x

    def get_config(self):
        config = super(Generator, self).get_config()
        config.update({'kernel': self.kernel})
        return config

    def compute_output_shape(self, input_shape):
        print('[Generator] - compute_output_shape() input_shape: {}'.format(input_shape))
        return input_shape[0], 28, 28, 1

    @tf.function
    def serve(self, z):
        x = self.dense0(z)
        x = self.bn0(x, training=False)
        x = self.lrelu0(x)

        x = tf.reshape(x, shape=[-1, 7, 7, 256])

        x = self.convt1(x)
        x = self.bn1(x, training=False)
        x = self.lrelu1(x)

        x = self.convt2(x)
        x = self.bn2(x, training=False)
        x = self.lrelu2(x)

        x = self.convt3(x)
        return x


def make_discriminator_model():
    model = tf.keras.Sequential()
    model.add(tf.keras.layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same', input_shape=[28, 28, 1]))
    model.add(tf.keras.layers.LeakyReLU())
    model.add(tf.keras.layers.Dropout(0.3))

    model.add(tf.keras.layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))
    model.add(tf.keras.layers.LeakyReLU())
    model.add(tf.keras.layers.Dropout(0.3))

    model.add(tf.keras.layers.Flatten())
    model.add(tf.keras.layers.Dense(1))
    return model


def load_mnist(batch_size):
    (train_images, train_labels), (_, _) = tf.keras.datasets.mnist.load_data()
    train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')
    train_images = (train_images - 127.5) / 127.5  # Normalize the images to [-1, 1]

    # Batch and shuffle the data
    train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(60000).batch(batch_size)
    return train_dataset


def discriminator_loss(real_output, fake_output, cross_entropy):
    real_loss = cross_entropy(tf.ones_like(real_output), real_output)
    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)
    total_loss = real_loss + fake_loss
    return total_loss


def generator_loss(fake_output, cross_entropy):
    return cross_entropy(tf.ones_like(fake_output), fake_output)


# Notice the use of `tf.function`
# This annotation causes the function to be ""compiled"".
@tf.function
def train_step(images, batch_size, noise_dim, generator, discriminator,
               cross_entropy, generator_optimizer, discriminator_optimizer):
    noise = tf.random.normal([batch_size, noise_dim])

    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:
        generated_images = generator(noise, training=True)

        real_output = discriminator(images, training=True)
        fake_output = discriminator(generated_images, training=True)

        gen_loss = generator_loss(fake_output, cross_entropy)
        disc_loss = discriminator_loss(real_output, fake_output, cross_entropy)

    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)
    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)

    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))
    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))


def train_loop():
    batch_size = 256
    epochs = 30
    noise_dim = 100
    num_examples_to_generate = 16

    dataset = load_mnist(batch_size)

    # create models
    generator = Generator(kernel=5)
    discriminator = make_discriminator_model()

    # loss
    cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)

    # optimizer
    generator_optimizer = tf.keras.optimizers.Adam(1e-4)
    discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)

    checkpoint_dir = './models/dcgan'
    checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,
                                     discriminator_optimizer=discriminator_optimizer,
                                     generator=generator,
                                     discriminator=discriminator)
    manager = tf.train.CheckpointManager(checkpoint, checkpoint_dir, max_to_keep=2)

    # We will reuse this seed overtime (so it's easier)
    # to visualize progress in the animated GIF)
    seed = tf.random.normal([num_examples_to_generate, noise_dim])

    for epoch in range(epochs):
        start = time.time()

        for image_batch in dataset:
            train_step(image_batch, batch_size, noise_dim, generator, discriminator,
                       cross_entropy, generator_optimizer, discriminator_optimizer)

        # Save the model every 10 epochs
        if (epoch + 1) % 10 == 0:
            # Produce images for the GIF as we go
            generate_and_save_images(generator, epoch + 1, seed)
            manager.save(checkpoint_number=epoch + 1)

        print('Time for epoch {} is {} sec'.format(epoch + 1, time.time() - start))

    # Generate after the final epoch
    generate_and_save_images(generator, epochs, seed)
    return


def export_model():
    # restore generator model only
    noise_dim = 100
    generator = Generator(kernel=5, dynamic=True)
    test_x = tf.random.normal([1, noise_dim])
    _ = generator(test_x, training=False)

    checkpoint_dir = './models/dcgan'
    checkpoint = tf.train.Checkpoint(generator=generator)
    manager = tf.train.CheckpointManager(checkpoint, checkpoint_dir, max_to_keep=2)
    checkpoint.restore(manager.latest_checkpoint).expect_partial()
    if manager.latest_checkpoint:
        print('Restored from {}'.format(manager.latest_checkpoint))
        _ = generator.predict(test_x)
    else:
        raise ValueError()

    # export generator model
    export_dir = './models/dcgan/1'
    tf.saved_model.save(
        generator,
        export_dir,
        signatures=generator.serve.get_concrete_function(
            z=tf.TensorSpec(shape=[None, noise_dim], dtype=tf.float32)
        )
    )
    return


def main():
    set_gpu_memory_growth()

    train_loop()

    export_model()
    return


if __name__ == '__main__':
    main()

```


**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.


/home/moono/anaconda3/envs/tf-2.1/bin/python /mnt/data_ssd/git-repos/tensorflow-serving-2.x/custom_training_dcgan.py
2020-02-04 17:07:07.806587: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libnvinfer.so.6
2020-02-04 17:07:07.807381: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libnvinfer_plugin.so.6
2020-02-04 17:07:08.226664: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-02-04 17:07:08.252985: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-02-04 17:07:08.253267: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.575GHz coreCount: 68 deviceMemorySize: 10.75GiB deviceMemoryBandwidth: 573.69GiB/s
2020-02-04 17:07:08.253285: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-02-04 17:07:08.253303: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-02-04 17:07:08.254301: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-02-04 17:07:08.254520: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-02-04 17:07:08.255463: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-02-04 17:07:08.255982: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-02-04 17:07:08.256001: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-02-04 17:07:08.256046: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-02-04 17:07:08.256327: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-02-04 17:07:08.256572: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-02-04 17:07:08.256776: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-02-04 17:07:08.277755: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3000000000 Hz
2020-02-04 17:07:08.278023: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55a541a20050 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-02-04 17:07:08.278034: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-02-04 17:07:08.343779: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-02-04 17:07:08.344115: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55a54215a3e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-02-04 17:07:08.344127: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce RTX 2080 Ti, Compute Capability 7.5
2020-02-04 17:07:08.344226: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-02-04 17:07:08.344839: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.575GHz coreCount: 68 deviceMemorySize: 10.75GiB deviceMemoryBandwidth: 573.69GiB/s
2020-02-04 17:07:08.344861: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-02-04 17:07:08.344868: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-02-04 17:07:08.344878: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-02-04 17:07:08.344884: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-02-04 17:07:08.344891: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-02-04 17:07:08.344898: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-02-04 17:07:08.344903: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-02-04 17:07:08.344935: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-02-04 17:07:08.345190: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-02-04 17:07:08.345429: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-02-04 17:07:08.345473: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-02-04 17:07:08.509396: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-02-04 17:07:08.509447: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 
2020-02-04 17:07:08.509452: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N 
2020-02-04 17:07:08.509580: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-02-04 17:07:08.509854: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-02-04 17:07:08.510101: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9565 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5)
1 Physical GPUs, 1 Logical GPUs
2020-02-04 17:07:10.728256: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-02-04 17:07:10.847845: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
Time for epoch 1 is 7.408124208450317 sec
Time for epoch 2 is 4.247774362564087 sec
Time for epoch 3 is 4.300286054611206 sec
Time for epoch 4 is 4.301387786865234 sec
Time for epoch 5 is 4.302702188491821 sec
Time for epoch 6 is 4.3085198402404785 sec
Time for epoch 7 is 4.314511060714722 sec
Time for epoch 8 is 4.3180766105651855 sec
Time for epoch 9 is 4.276162147521973 sec
Time for epoch 10 is 4.594261884689331 sec
Time for epoch 11 is 4.290403127670288 sec
Time for epoch 12 is 4.332635164260864 sec
Time for epoch 13 is 4.34122896194458 sec
Time for epoch 14 is 4.342823505401611 sec
Time for epoch 15 is 4.30718469619751 sec
Time for epoch 16 is 4.350044012069702 sec
Time for epoch 17 is 4.3491082191467285 sec
Time for epoch 18 is 4.352354049682617 sec
Time for epoch 19 is 4.318714618682861 sec
Time for epoch 20 is 4.648451089859009 sec
Time for epoch 21 is 4.324911117553711 sec
Time for epoch 22 is 4.33571720123291 sec
Time for epoch 23 is 4.367572069168091 sec
Time for epoch 24 is 4.363953351974487 sec
Time for epoch 25 is 4.342392683029175 sec
Time for epoch 26 is 4.374950647354126 sec
Time for epoch 27 is 4.375419616699219 sec
Time for epoch 28 is 4.3764965534210205 sec
Time for epoch 29 is 4.358669757843018 sec
Time for epoch 30 is 4.596313714981079 sec
Restored from ./models/dcgan/ckpt-30
[Generator] - compute_output_shape() input_shape: (None, 100)
Traceback (most recent call last):
  File ""/mnt/data_ssd/git-repos/tensorflow-serving-2.x/custom_training_dcgan.py"", line 322, in <module>
    main()
  File ""/mnt/data_ssd/git-repos/tensorflow-serving-2.x/custom_training_dcgan.py"", line 317, in main
    export_model()
  File ""/mnt/data_ssd/git-repos/tensorflow-serving-2.x/custom_training_dcgan.py"", line 296, in export_model
    _ = generator.predict(test_x)
  File ""/home/moono/anaconda3/envs/tf-2.1/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py"", line 1013, in predict
    use_multiprocessing=use_multiprocessing)
  File ""/home/moono/anaconda3/envs/tf-2.1/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py"", line 498, in predict
    workers=workers, use_multiprocessing=use_multiprocessing, **kwargs)
  File ""/home/moono/anaconda3/envs/tf-2.1/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py"", line 475, in _model_iteration
    total_epochs=1)
  File ""/home/moono/anaconda3/envs/tf-2.1/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py"", line 168, in run_one_epoch
    strategy, batch_outs, model)
  File ""/home/moono/anaconda3/envs/tf-2.1/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py"", line 264, in _aggregate_predict_results
    nest.flatten(nested_outs))
  File ""/home/moono/anaconda3/envs/tf-2.1/lib/python3.7/site-packages/tensorflow_core/python/keras/distribute/distributed_training_utils.py"", line 1199, in concat_along_batch_dimension
    if isinstance(outputs[0], sparse_tensor.SparseTensor):
IndexError: list index out of range

Process finished with exit code 1"
36456,Unable to evaluate FusedBatchNormV3 operation without GPU,"**System information**
- Have I written custom code: Yes
- OS Platform and Distribution: Linux Ubuntu 16.04
- Mobile device if the issue happens on mobile device: n/a
- TensorFlow installed from: binary (installed by pip)
- TensorFlow version: v1.15.0-rc3-22-g590d6ee 1.15.0
- Python version: 3.5.2
- Bazel version (if compiling from source): n/a
- GCC/Compiler version (if compiling from source): n/a
- CUDA/cuDNN version: CUDA:10.0, cuDNN:7.6
- GPU model and memory: GeForce GTX 1080 Ti

**Describe the current behavior**
I would like to evaluate the outputs of each operation of our network.
I succeeded to get the outputs by running the following code with GPU (Using `tensorflow-gpu`), but without GPU (Using `tensorflow-cpu`), I got an error as follows.
```
tensorflow.python.framework.errors_impl.OutOfRangeError: Node 'BatchNorm/FusedBatchNormV3' (type: '_FusedConv2D', num of outputs: 1) does not have output 1
```
There are different behavior about `BatchNorm/FusedBatchNormV3` between w/ GPU and w/o GPU.
I think `FusedBatchNormV3`'s num of outputs should be 6 but that error shows num of outputs is 1.

**Describe the expected behavior**
I expected to be enabled to evaluate the outputs of `BatchNorm/FusedBatchNormV3` only using CPU.

**Code to reproduce the issue**
At first, create a test script (`test.py`) as following.
```
import tensorflow as tf
import numpy as np

batch_size=1
image_size = (64,64)

def main():
    graph = tf.Graph()
    with graph.as_default():
        shape = (batch_size, image_size[0], image_size[1], 3)
        images_placeholder = tf.compat.v1.placeholder(
            tf.float32,
            shape=shape,
            name=""images_placeholder"")

        conv = tf.layers.conv2d(images_placeholder, filters=32, kernel_size=3, padding='SAME', use_bias=False)
        batch_normed = tf.contrib.layers.batch_norm(conv,is_training=False)
        softmax = tf.nn.softmax(batch_normed)
        output = tf.identity(softmax, name=""output"")

        init_op = tf.global_variables_initializer()

    session_config = tf.ConfigProto()
    sess = tf.Session(graph=graph, config=session_config)
    sess.run(init_op)

    images = np.expand_dims(np.zeros((image_size[0],image_size[1], 3), dtype=float), axis=0)
    feed_dict = {
        images_placeholder: images,
    }
    
    all_ops = graph.get_operations()
    all_outputs = []
    index = 0
    for op in all_ops:
        for op_output in op.outputs:
            print(op_output)
            val = sess.run(op_output.name, feed_dict=feed_dict)
            all_outputs.append({'val': val, 'name': op_output.name})
            index += 1

if __name__ == '__main__':
    main()
```
After that, run commands as following.
```
$ pip install tensorflow-cpu==1.15.0
$ python test.py
``` 

**Other info / logs**
* [**Success**] Run `test.py` with GPU (`tensorflow-gpu==1.15.0`)
```
$ python test.py 
WARNING:tensorflow:From test.py:16: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
WARNING:tensorflow:From /home/hadusam/tensorflow-gpu/lib/python3.5/site-packages/tensorflow_core/python/layers/convolutional.py:424: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
Please use `layer.__call__` method instead.
WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:From test.py:21: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.

WARNING:tensorflow:From test.py:23: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

WARNING:tensorflow:From test.py:24: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2020-02-04 17:12:56.452491: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2020-02-04 17:12:56.458872: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3599980000 Hz
2020-02-04 17:12:56.459272: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x6728e70 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-02-04 17:12:56.459299: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-02-04 17:12:56.462463: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-02-04 17:12:56.676188: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x67d26e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-02-04 17:12:56.676219: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce GTX 1080 Ti, Compute Capability 6.1
2020-02-04 17:12:56.677202: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.62
pciBusID: 0000:af:00.0
2020-02-04 17:12:56.677442: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2020-02-04 17:12:56.678571: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2020-02-04 17:12:56.679662: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2020-02-04 17:12:56.679943: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2020-02-04 17:12:56.681246: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2020-02-04 17:12:56.682741: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2020-02-04 17:12:56.685936: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-02-04 17:12:56.688818: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2020-02-04 17:12:56.688898: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2020-02-04 17:12:56.689938: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-02-04 17:12:56.689984: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 
2020-02-04 17:12:56.690014: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N 
2020-02-04 17:12:56.691698: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10470 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:af:00.0, compute capability: 6.1)
Tensor(""images_placeholder:0"", shape=(1, 64, 64, 3), dtype=float32)
Tensor(""conv2d/kernel/Initializer/random_uniform/shape:0"", shape=(4,), dtype=int32)
Tensor(""conv2d/kernel/Initializer/random_uniform/min:0"", shape=(), dtype=float32)
Tensor(""conv2d/kernel/Initializer/random_uniform/max:0"", shape=(), dtype=float32)
Tensor(""conv2d/kernel/Initializer/random_uniform/RandomUniform:0"", shape=(3, 3, 3, 32), dtype=float32)
Tensor(""conv2d/kernel/Initializer/random_uniform/sub:0"", shape=(), dtype=float32)
Tensor(""conv2d/kernel/Initializer/random_uniform/mul:0"", shape=(3, 3, 3, 32), dtype=float32)
Tensor(""conv2d/kernel/Initializer/random_uniform:0"", shape=(3, 3, 3, 32), dtype=float32)
Tensor(""conv2d/kernel:0"", shape=(3, 3, 3, 32), dtype=float32_ref)
Tensor(""conv2d/kernel/Assign:0"", shape=(3, 3, 3, 32), dtype=float32_ref)
Tensor(""conv2d/kernel/read:0"", shape=(3, 3, 3, 32), dtype=float32)
Tensor(""conv2d/dilation_rate:0"", shape=(2,), dtype=int32)
Tensor(""conv2d/Conv2D:0"", shape=(1, 64, 64, 32), dtype=float32)
2020-02-04 17:12:57.365891: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-02-04 17:12:58.204387: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
Tensor(""BatchNorm/Const:0"", shape=(32,), dtype=float32)
Tensor(""BatchNorm/beta/Initializer/zeros:0"", shape=(32,), dtype=float32)
Tensor(""BatchNorm/beta:0"", shape=(32,), dtype=float32_ref)
Tensor(""BatchNorm/beta/Assign:0"", shape=(32,), dtype=float32_ref)
Tensor(""BatchNorm/beta/read:0"", shape=(32,), dtype=float32)
Tensor(""BatchNorm/moving_mean/Initializer/zeros:0"", shape=(32,), dtype=float32)
Tensor(""BatchNorm/moving_mean:0"", shape=(32,), dtype=float32_ref)
Tensor(""BatchNorm/moving_mean/Assign:0"", shape=(32,), dtype=float32_ref)
Tensor(""BatchNorm/moving_mean/read:0"", shape=(32,), dtype=float32)
Tensor(""BatchNorm/moving_variance/Initializer/ones:0"", shape=(32,), dtype=float32)
Tensor(""BatchNorm/moving_variance:0"", shape=(32,), dtype=float32_ref)
Tensor(""BatchNorm/moving_variance/Assign:0"", shape=(32,), dtype=float32_ref)
Tensor(""BatchNorm/moving_variance/read:0"", shape=(32,), dtype=float32)
Tensor(""BatchNorm/FusedBatchNormV3:0"", shape=(1, 64, 64, 32), dtype=float32)
Tensor(""BatchNorm/FusedBatchNormV3:1"", shape=(32,), dtype=float32)
Tensor(""BatchNorm/FusedBatchNormV3:2"", shape=(32,), dtype=float32)
Tensor(""BatchNorm/FusedBatchNormV3:3"", shape=(32,), dtype=float32)
Tensor(""BatchNorm/FusedBatchNormV3:4"", shape=(32,), dtype=float32)
Tensor(""BatchNorm/FusedBatchNormV3:5"", dtype=float32)
Tensor(""BatchNorm/Const_1:0"", shape=(), dtype=float32)
Tensor(""Softmax:0"", shape=(1, 64, 64, 32), dtype=float32)
Tensor(""output:0"", shape=(1, 64, 64, 32), dtype=float32)
```


* [**Error**] Run `test.py` without GPU (`tensorflow-cpu==1.15.0`)
```
$ python test.py
WARNING:tensorflow:From test.py:16: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
WARNING:tensorflow:From /home/hadusam/tensorflow-cpu/lib/python3.5/site-packages/tensorflow_core/python/layers/convolutional.py:424: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
Please use `layer.__call__` method instead.
WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:From test.py:21: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.

WARNING:tensorflow:From test.py:23: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

WARNING:tensorflow:From test.py:24: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

2020-02-04 17:26:55.513752: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2020-02-04 17:26:55.518222: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3599980000 Hz
2020-02-04 17:26:55.518610: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x52ffee0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-02-04 17:26:55.518636: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
Tensor(""images_placeholder:0"", shape=(1, 64, 64, 3), dtype=float32)
Tensor(""conv2d/kernel/Initializer/random_uniform/shape:0"", shape=(4,), dtype=int32)
Tensor(""conv2d/kernel/Initializer/random_uniform/min:0"", shape=(), dtype=float32)
Tensor(""conv2d/kernel/Initializer/random_uniform/max:0"", shape=(), dtype=float32)
Tensor(""conv2d/kernel/Initializer/random_uniform/RandomUniform:0"", shape=(3, 3, 3, 32), dtype=float32)
Tensor(""conv2d/kernel/Initializer/random_uniform/sub:0"", shape=(), dtype=float32)
Tensor(""conv2d/kernel/Initializer/random_uniform/mul:0"", shape=(3, 3, 3, 32), dtype=float32)
Tensor(""conv2d/kernel/Initializer/random_uniform:0"", shape=(3, 3, 3, 32), dtype=float32)
Tensor(""conv2d/kernel:0"", shape=(3, 3, 3, 32), dtype=float32_ref)
Tensor(""conv2d/kernel/Assign:0"", shape=(3, 3, 3, 32), dtype=float32_ref)
Tensor(""conv2d/kernel/read:0"", shape=(3, 3, 3, 32), dtype=float32)
Tensor(""conv2d/dilation_rate:0"", shape=(2,), dtype=int32)
Tensor(""conv2d/Conv2D:0"", shape=(1, 64, 64, 32), dtype=float32)
Tensor(""BatchNorm/Const:0"", shape=(32,), dtype=float32)
Tensor(""BatchNorm/beta/Initializer/zeros:0"", shape=(32,), dtype=float32)
Tensor(""BatchNorm/beta:0"", shape=(32,), dtype=float32_ref)
Tensor(""BatchNorm/beta/Assign:0"", shape=(32,), dtype=float32_ref)
Tensor(""BatchNorm/beta/read:0"", shape=(32,), dtype=float32)
Tensor(""BatchNorm/moving_mean/Initializer/zeros:0"", shape=(32,), dtype=float32)
Tensor(""BatchNorm/moving_mean:0"", shape=(32,), dtype=float32_ref)
Tensor(""BatchNorm/moving_mean/Assign:0"", shape=(32,), dtype=float32_ref)
Tensor(""BatchNorm/moving_mean/read:0"", shape=(32,), dtype=float32)
Tensor(""BatchNorm/moving_variance/Initializer/ones:0"", shape=(32,), dtype=float32)
Tensor(""BatchNorm/moving_variance:0"", shape=(32,), dtype=float32_ref)
Tensor(""BatchNorm/moving_variance/Assign:0"", shape=(32,), dtype=float32_ref)
Tensor(""BatchNorm/moving_variance/read:0"", shape=(32,), dtype=float32)
Tensor(""BatchNorm/FusedBatchNormV3:0"", shape=(1, 64, 64, 32), dtype=float32)
Tensor(""BatchNorm/FusedBatchNormV3:1"", shape=(32,), dtype=float32)
Traceback (most recent call last):
  File ""/home/hadusam/tensorflow-cpu/lib/python3.5/site-packages/tensorflow_core/python/client/session.py"", line 1365, in _do_call
    return fn(*args)
  File ""/home/hadusam/tensorflow-cpu/lib/python3.5/site-packages/tensorflow_core/python/client/session.py"", line 1350, in _run_fn
    target_list, run_metadata)
  File ""/home/hadusam/tensorflow-cpu/lib/python3.5/site-packages/tensorflow_core/python/client/session.py"", line 1443, in _call_tf_sessionrun
    run_metadata)
tensorflow.python.framework.errors_impl.OutOfRangeError: Node 'BatchNorm/FusedBatchNormV3' (type: '_FusedConv2D', num of outputs: 1) does not have output 1

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""test.py"", line 43, in <module>
    main()
  File ""test.py"", line 38, in main
    val = sess.run(op_output.name, feed_dict=feed_dict)
  File ""/home/hadusam/tensorflow-cpu/lib/python3.5/site-packages/tensorflow_core/python/client/session.py"", line 956, in run
    run_metadata_ptr)
  File ""/home/hadusam/tensorflow-cpu/lib/python3.5/site-packages/tensorflow_core/python/client/session.py"", line 1180, in _run
    feed_dict_tensor, options, run_metadata)
  File ""/home/hadusam/tensorflow-cpu/lib/python3.5/site-packages/tensorflow_core/python/client/session.py"", line 1359, in _do_run
    run_metadata)
  File ""/home/hadusam/tensorflow-cpu/lib/python3.5/site-packages/tensorflow_core/python/client/session.py"", line 1384, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.OutOfRangeError: Node 'BatchNorm/FusedBatchNormV3' (type: '_FusedConv2D', num of outputs: 1) does not have output 1
```
"
36455,tensorflow.python.framework.errors_impl.InvalidArgumentError: input and filter must have same depth,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **HPC**:
- **TensorFlow installed from conda**:
- **TensorFlow version 1.15**:
- **Python version 3.6.10:
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with:

```bash
python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""
```

### Describe the problem
Folloing is the model graph summary
![image](https://user-images.githubusercontent.com/13520957/73723907-711ac600-472a-11ea-8762-21a4787e2193.png)
And the error code is 
![image](https://user-images.githubusercontent.com/13520957/73723959-8b54a400-472a-11ea-96d0-38cd9e792ce3.png)

I assume that the layer 'block1_conv1' should automatically generate output with depth 64. 
However, from the error message it looks like it generates an output with depth 1 only. What is wrong here?
"
36454,even load work?,"
## URL(s) with the issue:
https://www.tensorflow.org/guide/migrate#saved_models_compatibility

## Description of issue (what needs changing):
The sentence below is unclear in what it means. I think there might be an extra word.

""TensorFlow 2.0 saved_models even load work in TensorFlow 1.x if all the ops are supported.""

"
36453,Keras - Supporting load/save models and weights to Google Storage,"I want to save / load my keras model to / from Google storage bucket.
my environment : docker image - tensorflow/tensorflow-latest-py3 (tensorflow 2.1.0, python 3.6.9)

```python
from tensorflow.keras.models import Sequential

model = Sequential([
...
...
])

model.compile(...)
model.fit(...)

model.save('gs://path/to/my/bucket/model.h5')
```

and I got this error message

```
Traceback (most recent call last):
  File ""main.py"", line 118, in <module>
    model.save('gs://MY-BUCKET/model.h5')
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/network.py"", line 1008, in save
    signatures, options)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/saving/save.py"", line 112, in save_model
    model, filepath, overwrite, include_optimizer)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/saving/hdf5_format.py"", line 92, in save_model_to_hdf5
    f = h5py.File(filepath, mode='w')
  File ""/usr/local/lib/python3.6/dist-packages/h5py/_hl/files.py"", line 408, in __init__
    swmr=swmr)
  File ""/usr/local/lib/python3.6/dist-packages/h5py/_hl/files.py"", line 179, in make_fid
    fid = h5f.create(name, h5f.ACC_TRUNC, fapl=fapl, fcpl=fcpl)
  File ""h5py/_objects.pyx"", line 54, in h5py._objects.with_phil.wrapper
  File ""h5py/_objects.pyx"", line 55, in h5py._objects.with_phil.wrapper
  File ""h5py/h5f.pyx"", line 108, in h5py.h5f.create
OSError: Unable to create file (unable to open file: name = 'gs://MY-BUCKET/model.h5', errno = 2, error message = 'No such file or directory', flags = 13, o_flags = 242)
```

I found [this PR](https://github.com/keras-team/keras/pull/11636) in keras repository, supporting above behavior. but It seems like that it's not implemented in `tensorflow.keras`.

Do you have plans to support it? or, are there any alternatives in tensorflow?
"
36452,Broken outbound links from index pages for older TF API,"## URL(s) with the issue:

Numerous links of the older TF APIs, listing only a few index pages as examples here:

- Links under ""Classes"" and ""Functions"" within https://github.com/tensorflow/docs/blob/r1.11/site/en/api_docs/python/tf.md
- Links under ""Classes"" and ""Functions"" within https://github.com/tensorflow/docs/blob/r1.11/site/en/api_docs/python/tfdbg.md
- Links within https://github.com/tensorflow/docs/blob/r1.5/site/en/api_docs/python/index.md
- ""JAVA"" link within https://github.com/tensorflow/docs/blob/r1.7/site/en/api_docs/index.md

## Description of issue (what needs changing):

A large amount of links on index pages (e.g. for functions and classes) are currently broken (404). This appears to affect only the older TF versions (multiple versions affected), whose index pages are Markdown files within Github repositories.

### Clear description

Outbound links from these indexing pages are currently broken. Some might be fixed by adding a .md after the current URL to point to the correct Markdown available in the repositories, but not all of them can be fixed through this way.

### Correct links

Is the link to the source code correct?
- Incorrect.

### Submit a pull request?

Are you planning to also submit a pull request to fix the issue?
- Currently no plan.
"
36451,Differentiating an extremely complicated weightless transform,"I'm considering inserting a weightless transform between CNN layers in a neural network. The transform is very complicated - details below. I'm aware that custom transformations are supported via e.g. Keras'  `Lambda` layer  - however, I don't know if TF is capable of handling something of this complexity. The code I have needs to be converted for compatibility, but I rather it not be a wasted effort.

Can TensorFlow's autodifferentiation handle [`synsq_cwt_fwd`](https://github.com/OverLordGoldDragon/ssqueezepy/blob/master/ssqueezepy/synsq_cwt.py#L12)?


<hr>

**Continuous Synchrosqueezing Transform** - full dev-stage code in the [ssqueezepy](https://github.com/OverLordGoldDragon/ssqueezepy) repository. Highlights (simplified):

```python
x = np.random.randn(2000)
len(Wx.squeeze().shape) == 2

psihfn = lambda w: np.exp(2 * PI * 1j * .1 * w) * (
    np.abs(w - 1) < .999) * np.exp(-1. / (1 - ((w - 1) * (np.abs(w - 1) < .999)) ** 2))

for i in range(200):
    psih = psihfn(5 * np.arange(500))
    Wx[i] = np.fft.ifftshift(np.fft.ifft(psih * np.fft.fft(x)))
```
```python
Wx.dtype == 'complex128'
u = np.unwrap(np.angle(Wx)).T
w = np.array([np.diff(u), u[-1] - u[0]]).T
```
 1. `psihfn` involves (a) complex exponential; (b) inverse asymptotic real exponential; (c) boolean mask
 2. `Wx` involves (a) `fft` of `ifftshift` of `ifft` of `psih * fft(x)`, (b) computed _iteratively_, but _not recurrently_ (future values don't depend on past)
 3. `w`  (second blob) involves (a) `Wx` computed in 1 & 2, a `complex128` 2D array; (b) applying `dif(unwrap(angle(Wx)).T)`

The complex components may be eliminated entirely, including in 1(a). The main subject of attention is perhaps the FFT nest; I don't know how numpy computes FFT, as it encapsulates an involved op. There's also a question of _performance_ - if it takes hours on a small array, it's not worth it."
36449,Unclear documentation for implementing custom TensorFlow Keras optimizers,"## URL(s) with the issue:

[`tf.keras.optimizers.Optimizer`](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Optimizer), specifically the section [Write a customized optimizer](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Optimizer#write_a_customized_optimizer_2).

## Description of issue (what needs changing):

The instructions for creating a custom optimizer seem to be inconsistent with how `tf.keras.optimizers.Optimizer` subclasses are defined in TensorFlow and other projects.

### Clear description

This originated as a [question on Stack Overflow](https://stackoverflow.com/q/58772846/1917160), which is reproduced below.

Suppose I want to write a custom optimizer class that conforms to the `tf.keras` API (using TensorFlow version>=2.0). I am confused about the documented way to do this versus what's done in implementations.

The documentation for `tf.keras.optimizers.Optimizer` states,

https://github.com/tensorflow/tensorflow/blob/7b1283ecf14e5f057b1a5c321a46db907ea713fc/tensorflow/python/keras/optimizer_v2/optimizer_v2.py#L217-L224

However, the current `tf.keras.optimizers.Optimizer` implementation does not define a `resource_apply_dense` method, but it *does* define a private-looking [`_resource_apply_dense` method stub](https://github.com/tensorflow/tensorflow/blob/7b1283ecf14e5f057b1a5c321a46db907ea713fc/tensorflow/python/keras/optimizer_v2/optimizer_v2.py#L916-L928). Similarly, there are no `resource_apply_sparse` or `create_slots` methods, but there are a [`_resource_apply_sparse` method stub](https://github.com/tensorflow/tensorflow/blob/7b1283ecf14e5f057b1a5c321a46db907ea713fc/tensorflow/python/keras/optimizer_v2/optimizer_v2.py#L958-L977) and a [`_create_slots` method call](https://github.com/tensorflow/tensorflow/blob/7b1283ecf14e5f057b1a5c321a46db907ea713fc/tensorflow/python/keras/optimizer_v2/optimizer_v2.py#L434).

In official `tf.keras.optimizers.Optimizer` subclasses (using `tf.keras.optimizers.Adam` as an example), there are [`_resource_apply_dense`](https://github.com/tensorflow/tensorflow/blob/7b1283ecf14e5f057b1a5c321a46db907ea713fc/tensorflow/python/keras/optimizer_v2/adam.py#L192-L227), [`_resource_apply_sparse`](https://github.com/tensorflow/tensorflow/blob/7b1283ecf14e5f057b1a5c321a46db907ea713fc/tensorflow/python/keras/optimizer_v2/adam.py#L229-L267), and [`_create_slots`](https://github.com/tensorflow/tensorflow/blob/7b1283ecf14e5f057b1a5c321a46db907ea713fc/tensorflow/python/keras/optimizer_v2/adam.py#L150-L159) methods, and there are no such methods without the leading underscore.

There are similar leading-underscore methods in slightly-less-official `tf.keras.optimizers.Optimizer` subclasses (e.g., `tfa.optimizers.MovingAverage` from TensorFlow Addons: [`_resource_apply_dense`](https://github.com/tensorflow/addons/blob/999aebc0961ccddb8174cc5331cc23a7291a2255/tensorflow_addons/optimizers/average_wrapper.py#L73-L76), [`_resource_apply_sparse`](https://github.com/tensorflow/addons/blob/999aebc0961ccddb8174cc5331cc23a7291a2255/tensorflow_addons/optimizers/average_wrapper.py#L78-L82), [`_create_slots`](https://github.com/tensorflow/addons/blob/999aebc0961ccddb8174cc5331cc23a7291a2255/tensorflow_addons/optimizers/moving_average.py#L92-L95)).

Another confounding point for me is that some of the TensorFlow Addons optimizers *also* override the `apply_gradients` method (e.g., [`tfa.optimizers.MovingAverage`](https://github.com/tensorflow/addons/blob/999aebc0961ccddb8174cc5331cc23a7291a2255/tensorflow_addons/optimizers/average_wrapper.py#L55-L57)), whereas the `tf.keras.optimizers` optimizers do not.

Moreover, I noticed that the `apply_gradients` method of `tf.keras.optimizers.Optimizer` method calls `_create_slots`, but the base `tf.keras.optimizers.Optimizer` class does not have a `_create_slots` method. So, it seems that a `_create_slots` method *must* be defined in an optimizer subclass if that subclass does not override `apply_gradients`.

#### Questions

What is the correct way to subclass a `tf.keras.optimizers.Optimizer`? Specifically,

1. Does the `tf.keras.optimizers.Optimizer` documentation listed at the top simply mean to override the leading-underscore versions of the methods they mention (e.g., `_resource_apply_dense` instead of `resource_apply_dense`)? If so, are there any API guarantees about these private-looking methods not changing their behavior in future versions of TensorFlow? What are the signatures of these methods?
2. When would one override `apply_gradients` in addition to the `_apply_resource_[dense|sparse]` methods?"
36448,Categorical encoding in `docs/csv.ipynb` returning inconsistent results.,"## URL(s) with the issue:

https://www.tensorflow.org/tutorials/load_data/csv

which is available on GitHub at

https://github.com/tensorflow/docs/blob/master/site/en/tutorials/load_data/csv.ipynb

## Description of issue:

This is about the output of the last cell in the section _Categorical data_, namely the output of `print(categorical_layer(example_batch).numpy()[0])`. If we remove the index `[0]`, we're supposed to get the one-hot encoding of the categorical features, i.e., a 5-by-20 matrix, where 5 is the batch size and 20 is the total dimensionality of all categorical features.

If, for the sake of reproducibility, we also set `shuffle=False` in the call to `tf.data.experimental.make_csv_dataset()` at the very top of the notebook, the matrix we then get is:

```
[[0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]
 [0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1.]
 [1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]
 [1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0.]]
```

This does not match up with the input categorical features for that batch, namely

```
sex: [b'male' b'female' b'female' b'female' b'male']
class: [b'Third' b'First' b'Third' b'First' b'Third']
deck: [b'unknown' b'C' b'unknown' b'C' b'unknown']
embark_town: [b'Southampton' b'Cherbourg' b'Southampton' b'Southampton' b'Queenstown']
alone: [b'n' b'n' b'y' b'n' b'y']
```

For example, `[b'male' b'female' b'female' b'female' b'male']` does not match up with the first two columns of the matrix."
36447,Saving to file a model within TPUStrategy,"On Tensorflow 2.0 and 2.1, trying to save to file a TPU trained model or a model that was even created within the scope of a `tf.distribute.experimental.TPUStrategy` yields error below. Despite throwing an `UnimplementedException` the code does create a folder on disk with some content. 

The reproducible code can be found in a collab notebook here:
https://colab.research.google.com/drive/1DOkwNlzMLsg0wQZe41eq88XhEUqR9Amn

**The exception and it's stack**
```python
---------------------------------------------------------------------------
UnimplementedError                        Traceback (most recent call last)
<ipython-input-7-b3a563716de1> in <module>()
     48         print(""1.4 "",err)
     49 
---> 50     model.save(""model-new.1"")
     51 
     52     model.compile(

14 frames
/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/network.py in save(self, filepath, overwrite, include_optimizer, save_format, signatures, options)
   1006     """"""
   1007     save.save_model(self, filepath, overwrite, include_optimizer, save_format,
-> 1008                     signatures, options)
   1009 
   1010   def save_weights(self, filepath, overwrite=True, save_format=None):

/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/saving/save.py in save_model(model, filepath, overwrite, include_optimizer, save_format, signatures, options)
    113   else:
    114     saved_model_save.save(model, filepath, overwrite, include_optimizer,
--> 115                           signatures, options)
    116 
    117 

/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/saving/saved_model/save.py in save(model, filepath, overwrite, include_optimizer, signatures, options)
     76     # we use the default replica context here.
     77     with distribution_strategy_context._get_default_replica_context():  # pylint: disable=protected-access
---> 78       save_lib.save(model, filepath, signatures, options)
     79 
     80   if not include_optimizer:

/tensorflow-2.1.0/python3.6/tensorflow_core/python/saved_model/save.py in save(obj, export_dir, signatures, options)
    914   # SavedModel proto itself.
    915   utils_impl.get_or_create_variables_dir(export_dir)
--> 916   object_saver.save(utils_impl.get_variables_path(export_dir))
    917   builder_impl.copy_assets_to_destination_dir(asset_info.asset_filename_map,
    918                                               export_dir)

/tensorflow-2.1.0/python3.6/tensorflow_core/python/training/tracking/util.py in save(self, file_prefix, checkpoint_number, session)
   1166     file_io.recursive_create_dir(os.path.dirname(file_prefix))
   1167     save_path, new_feed_additions = self._save_cached_when_graph_building(
-> 1168         file_prefix=file_prefix_tensor, object_graph_tensor=object_graph_tensor)
   1169     if new_feed_additions:
   1170       feed_dict.update(new_feed_additions)

/tensorflow-2.1.0/python3.6/tensorflow_core/python/training/tracking/util.py in _save_cached_when_graph_building(self, file_prefix, object_graph_tensor)
   1114         or context.executing_eagerly() or ops.inside_function()):
   1115       saver = functional_saver.MultiDeviceSaver(named_saveable_objects)
-> 1116       save_op = saver.save(file_prefix)
   1117       with ops.device(""/cpu:0""):
   1118         with ops.control_dependencies([save_op]):

/tensorflow-2.1.0/python3.6/tensorflow_core/python/training/saving/functional_saver.py in save(self, file_prefix)
    228         # _SingleDeviceSaver will use the CPU device when necessary, but initial
    229         # read operations should be placed on the SaveableObject's device.
--> 230         sharded_saves.append(saver.save(shard_prefix))
    231 
    232     with ops.control_dependencies(sharded_saves):

/tensorflow-2.1.0/python3.6/tensorflow_core/python/training/saving/functional_saver.py in save(self, file_prefix)
     67       for spec in saveable.specs:
     68         tensor_names.append(spec.name)
---> 69         tensors.append(spec.tensor)
     70         tensor_slices.append(spec.slice_spec)
     71     with ops.device(""cpu:0""):

/tensorflow-2.1.0/python3.6/tensorflow_core/python/training/saving/saveable_object.py in tensor(self)
     50   @property
     51   def tensor(self):
---> 52     return self._tensor() if callable(self._tensor) else self._tensor
     53 
     54 

/tensorflow-2.1.0/python3.6/tensorflow_core/python/training/saving/saveable_object_util.py in f()
     89         def f():
     90           with ops.device(v.device):
---> 91             x = v.read_value()
     92             # To allow variables placed on non-CPU devices to be checkpointed,
     93             # we copy them to CPU on the same machine first.

/tensorflow-2.1.0/python3.6/tensorflow_core/python/ops/resource_variable_ops.py in read_value(self)
    633     """"""
    634     with ops.name_scope(""Read""):
--> 635       value = self._read_variable_op()
    636     # Return an identity so it can get placed on whatever device the context
    637     # specifies instead of the device where the variable is.

/tensorflow-2.1.0/python3.6/tensorflow_core/python/ops/resource_variable_ops.py in _read_variable_op(self)
    611     variable_accessed(self)
    612     result = gen_resource_variable_ops.read_variable_op(self._handle,
--> 613                                                         self._dtype)
    614     _maybe_set_handle_data(self._dtype, self._handle, result)
    615 

/tensorflow-2.1.0/python3.6/tensorflow_core/python/ops/gen_resource_variable_ops.py in read_variable_op(resource, dtype, name)
    477         pass  # Add nodes to the TensorFlow graph.
    478     except _core._NotOkStatusException as e:
--> 479       _ops.raise_from_not_ok_status(e, name)
    480   # Add nodes to the TensorFlow graph.
    481   dtype = _execute.make_type(dtype, ""dtype"")

/tensorflow-2.1.0/python3.6/tensorflow_core/python/framework/ops.py in raise_from_not_ok_status(e, name)
   6604   message = e.message + ("" name: "" + name if name is not None else """")
   6605   # pylint: disable=protected-access
-> 6606   six.raise_from(core._status_to_exception(e.code, message), None)
   6607   # pylint: enable=protected-access
   6608 

/usr/local/lib/python3.6/dist-packages/six.py in raise_from(value, from_value)

UnimplementedError: File system scheme '[local]' not implemented (file: 'model-new.1/variables/variables_temp_17ffcf98334348fd8ef1e339869f0bfc')
	Encountered when executing an operation using EagerExecutor. This error cancels all future operations and poisons their output tensors. [Op:ReadVariableOp]
```


**System information**
The error is reproduced in Collab so I'm skipping `tf_env_collect.sh` output.
"
36446,tf.keras model.fit(): enormous difference between train loss and val loss on the same data,"Tensorflow version 2.1

See the colab notebook to reproduce the issue: https://drive.google.com/file/d/1Fvc6G_9v5mek015cai7qYT6HoY-fLkzk/view?usp=sharing

When the training loss goes down the val_loss does not change, although this is exactly the same data.

Train on 2 samples, validate on 2 samples
Epoch 1/30
2/2 [==============================] - 3s 2s/sample - loss: 0.4630 - val_loss: 302.4763
Epoch 2/30
2/2 [==============================] - 1s 457ms/sample - loss: 0.8565 - val_loss: 496.9578
Epoch 3/30
2/2 [==============================] - 1s 457ms/sample - loss: 0.7886 - val_loss: 1050.9148
Epoch 4/30
2/2 [==============================] - 1s 450ms/sample - loss: 0.1080 - val_loss: 744.4895
Epoch 5/30
2/2 [==============================] - 1s 474ms/sample - loss: 0.1144 - val_loss: 1353.2678
Epoch 6/30
2/2 [==============================] - 1s 465ms/sample - loss: 0.0402 - val_loss: 3237.9683
Epoch 7/30
2/2 [==============================] - 1s 465ms/sample - loss: 0.0635 - val_loss: 3946.7822
Epoch 8/30
2/2 [==============================] - 1s 470ms/sample - loss: 0.0355 - val_loss: 4054.5461
Epoch 9/30
2/2 [==============================] - 1s 462ms/sample - loss: 0.0345 - val_loss: 4991.5400

How is this possible?
The code is pretty straightforward:

```
import tensorflow as tf
import numpy as np
base_model = tf.keras.applications.ResNet50V2(input_shape=(180, 320, 3), weights=None, include_top=False)
x = tf.keras.layers.GlobalAveragePooling2D()(base_model.output)
output = tf.keras.layers.Dense(8)(x)
model = tf.keras.models.Model(inputs=base_model.input, outputs=output)
model.compile(optimizer='adam', loss='mse')
data = np.random.rand(2, 180, 320, 3)
labels = np.random.rand(2, 8)

model.fit(data, labels, validation_data=(data,labels), batch_size=2, epochs=30)
```

There are known issues with keras and batch normalization (see for example https://github.com/keras-team/keras/issues/6977). This is probably related, but I don't see directly how. What do I have to change to make this working as expected? Is this something in the included package https://github.com/qubvel/classification_models or where to solve it?

Edit: the behaviour of batch normalization is changed as of TF 2.0, so the other issues might not be related, see https://www.tensorflow.org/api_docs/python/tf/keras/layers/BatchNormalization"
36445,TensorFlow lite on armv6 (Raspberry Zero) crashes wit SIGILL,"sudo apt-get update
sudo apt-get install crossbuild-essential-armhf
git clone https://github.com/tensorflow/tensorflow.git
cd ./tensorflow
git checkout r2.0
./tensorflow/lite/tools/make/download_dependencies.sh

CC_PREFIX=arm-linux-gnueabihf- make -j 8 -f ./tensorflow/lite/tools/make/Makefile TARGET=rpi TARGET_ARCH=armv6l

Try running on Raspberry Pi Zero the example minimal - it crashes with Invalid Instruction
/tensorflow/tensorflow/lite/tools/make/gen/rpi_armv6l/bin/minimal

"
36442,eager,"Thank you for submitting a TensorFlow documentation issue. Per our GitHub
policy, we only address code/doc bugs, performance issues, feature requests, and
build/installation issues on GitHub.

The TensorFlow docs are open source! To get involved, read the documentation
contributor guide: https://www.tensorflow.org/community/contribute/docs

## URL(s) with the issue:

Please provide a link to the documentation entry, for example:
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/MyMethod

## Description of issue (what needs changing):

### Clear description

For example, why should someone use this method? How is it useful?

### Correct links

Is the link to the source code correct?

### Parameters defined

Are all parameters defined and formatted correctly?

### Returns defined

Are return values defined?

### Raises listed and defined

Are the errors defined? For example,
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises

### Usage example

Is there a usage example?

See the API guide: https://www.tensorflow.org/community/contribute/docs_ref
on how to write testable usage examples.

### Request visuals, if applicable

Are there currently visuals? If not, will it clarify the content?

### Submit a pull request?

Are you planning to also submit a pull request to fix the issue? See the docs
contributor guide: https://www.tensorflow.org/community/contribute/docs,
docs API guide: https://www.tensorflow.org/community/contribute/docs_ref and the
docs style guide: https://www.tensorflow.org/community/contribute/docs_style
"
36441,ModuleNotFoundError: No module named 'tensorflow_core.python',"**System information**
- TensorFlow version: 2.1.0
- Python version: 3.7.4


Tensorflow is installed on the computer. When I try to import (import tensorflow as tf) I get this error

ModuleNotFoundError: No module named 'tensorflow_core.python'

What's causing this error? I've tried downgrading TF to below version 2 and still received the error."
36438,Build tensorflow error with keras api,"### I build tensorflow follow [link](https://www.tensorflow.org/install/source)
1. use r2.0
1. bazel 0.25.0
1. CUDA Version: 10.0 
1. ubuntu 18.04
Here my error
```
ERROR: /root/tensorflow/tensorflow/python/keras/api/BUILD:13:1: Executing genrule //tensorflow/python/keras/api:keras_python_api_gen failed (Exit 1)
Traceback (most recent call last):
  File ""/root/.cache/bazel/_bazel_root/efb88f6336d9c4a18216fb94287b8d97/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_1_keras_python_api_gen.runfiles/org_tensorflow/tensorflow/python/tools/api/generator/create_python_api.py"", line 27, in <module>
    from tensorflow.python.tools.api.generator import doc_srcs
  File ""/root/.cache/bazel/_bazel_root/efb88f6336d9c4a18216fb94287b8d97/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_1_keras_python_api_gen.runfiles/org_tensorflow/tensorflow/python/__init__.py"", line 83, in <module>
    from tensorflow.python import keras
  File ""/root/.cache/bazel/_bazel_root/efb88f6336d9c4a18216fb94287b8d97/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_1_keras_python_api_gen.runfiles/org_tensorflow/tensorflow/python/keras/__init__.py"", line 32, in <module>
    from tensorflow.python.keras import datasets
  File ""/root/.cache/bazel/_bazel_root/efb88f6336d9c4a18216fb94287b8d97/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_1_keras_python_api_gen.runfiles/org_tensorflow/tensorflow/python/keras/datasets/__init__.py"", line 25, in <module>
    from tensorflow.python.keras.datasets import imdb
  File ""/root/.cache/bazel/_bazel_root/efb88f6336d9c4a18216fb94287b8d97/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_1_keras_python_api_gen.runfiles/org_tensorflow/tensorflow/python/keras/datasets/imdb.py"", line 25, in <module>
    from tensorflow.python.keras.preprocessing.sequence import _remove_long_seq
  File ""/root/.cache/bazel/_bazel_root/efb88f6336d9c4a18216fb94287b8d97/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_1_keras_python_api_gen.runfiles/org_tensorflow/tensorflow/python/keras/preprocessing/__init__.py"", line 21, in <module>
    import keras_preprocessing
ModuleNotFoundError: No module named 'keras_preprocessing'
Target //tensorflow/tools/pip_package:build_pip_package failed to build
Use --verbose_failures to see the command lines of failed build steps.
INFO: Elapsed time: 11062.314s, Critical Path: 746.52s
INFO: 17931 processes: 17931 local.
FAILED: Build did NOT complete successfully

```"
36437,regarding ckpt.meta file,"hi,i am doing my finetuning in tf 2.1.Since i am using bert model for finetuning,it produces checkpoints, I have .index,.data but i didn'T GET .meta file in checkpoint folder,since i am finetuning in tf 2.1.
I need to run this mentioned down code in tensorflow verion 2,but this mentioned down code is presently in tf 1 version:(This code is basically for down sizing the model size by removing the trainable parameters)
```import tensorflow as tf
import os
#path that contains all 3 ckpt files of your fine-tuned model
path = './bert_output'
#path to output the new optimized model
output_path = os.path.join(path, 'optimized_model')
sess = tf.Session()
imported_meta = tf.train.import_meta_graph(os.path.join(path, 'model.ckpt-236962.meta')) #based on the steps of your fine-tuned model
imported_meta.restore(sess, os.path.join(path, 'model.ckpt-236962')) #based on the steps of your fine-tuned model
my_vars = []
for var in tf.all_variables():
    if 'adam_v' not in var.name and 'adam_m' not in var.name:
        my_vars.append(var)
saver = tf.train.Saver(my_vars)


"
36436,Keras.gradients() returns None in loss function,"Good day and thank you for TensorFlow :-)

I'm trying to implement a Wasserstein GAN with gradient penalty in TF2 (https://arxiv.org/pdf/1704.00028.pdf)
When I compute the gradient of the discriminator output with respect to the interpolated input, I always get `None`.
I have tried to compute the gradient in the layers of my model and in my loss function, in eager mode or not, using a `GradientTape` and I have checked that my discriminator has gradients activated.
To reproduce the issue, I have adapted the implementation [here]( https://github.com/kongyanye/cwgan-gp/blob/master/cwgan_gp.py) to work with TensorFlow as backend and I get exactly the same problem. (Link to adapted version below)

What must I do to get this to work?

Thank you very much :-)

**System information**
```
== check python ===================================================
python version: 3.7.4
python branch: v3.7.4
python build version: ('v3.7.4:e09359112e', 'Jul  8 2019 14:54:52')
python compiler version: Clang 6.0 (clang-600.0.57)
python implementation: CPython


== check os platform ===============================================
os: Darwin
os kernel version: Darwin Kernel Version 18.7.0: Sun Dec  1 18:59:03 PST 2019; root:xnu-4903.278.19~1/RELEASE_X86_64
os release version: 18.7.0
os platform: Darwin-18.7.0-x86_64-i386-64bit
linux distribution: ('', '', '')
linux os distribution: ('', '', '')
mac version: ('10.14.6', ('', '', ''), 'x86_64')
uname: uname_result(system='Darwin', node='MBP-van-Michel', release='18.7.0', version='Darwin Kernel Version 18.7.0: Sun Dec  1 18:59:03 PST 2019; root:xnu-4903.278.19~1/RELEASE_X86_64', machine='x86_64', processor='i386')
architecture: ('64bit', '')
machine: x86_64


== are we in docker =============================================
No

== compiler =====================================================
Apple LLVM version 10.0.1 (clang-1001.0.46.4)
Target: x86_64-apple-darwin18.7.0
Thread model: posix
InstalledDir: /Library/Developer/CommandLineTools/usr/bin

== check pips ===================================================
numpy                    1.18.0    
protobuf                 3.11.2    
tensorflow               2.1.0     
tensorflow-datasets      1.3.2     
tensorflow-estimator     2.1.0     
tensorflow-metadata      0.15.2    

== check for virtualenv =========================================
False

== tensorflow import ============================================
tf.version.VERSION = 2.1.0
tf.version.GIT_VERSION = v2.1.0-rc2-17-ge5bf8de410
tf.version.COMPILER_VERSION = 4.2.1 Compatible Apple LLVM 10.0.1 (clang-1001.0.46.4)

== env ==========================================================
LD_LIBRARY_PATH is unset
DYLD_LIBRARY_PATH is unset

== nvidia-smi ===================================================
./env.sh: line 147: nvidia-smi: command not found

== cuda libs  ===================================================

== tensorflow installed from info ==================
Name: tensorflow
Version: 2.1.0
Summary: TensorFlow is an open source machine learning framework for everyone.
Home-page: https://www.tensorflow.org/
Author-email: packages@tensorflow.org
License: Apache 2.0
Location: /Users/michel/workspace/tf-text2image/venv/lib/python3.7/site-packages
Required-by: 

== python version  ==============================================
(major, minor, micro, releaselevel, serial)
(3, 7, 4, 'final', 0)

== bazel version  ===============================================
```

**Describe the current behavior**

```
python src/cwan_gp.py
2020-02-03 14:37:17.446341: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fef2a728470 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-02-03 14:37:17.446368: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
Tensor(""loss/model_1_2_loss/gradients/model_1_2/flatten_3/Reshape_grad/Reshape:0"", shape=(32, 28, 28, 1), dtype=float32)
None
Traceback (most recent call last):
  File ""src/cwan_gp.py"", line 302, in <module>
    wgan.train()
  File ""src/cwan_gp.py"", line 232, in train
    d_loss = self.critic_model.train_on_batch([imgs, labels, noise], [valid, fake, dummy])
  File ""/Users/michel/workspace/tf-text2image/venv/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py"", line 1078, in train_on_batch
    standalone=True)
  File ""/Users/michel/workspace/tf-text2image/venv/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py"", line 433, in train_on_batch
    output_loss_metrics=model._output_loss_metrics)
  File ""/Users/michel/workspace/tf-text2image/venv/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py"", line 568, in __call__
    result = self._call(*args, **kwds)
  File ""/Users/michel/workspace/tf-text2image/venv/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py"", line 615, in _call
    self._initialize(args, kwds, add_initializers_to=initializers)
  File ""/Users/michel/workspace/tf-text2image/venv/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py"", line 497, in _initialize
    *args, **kwds))
  File ""/Users/michel/workspace/tf-text2image/venv/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py"", line 2389, in _get_concrete_function_internal_garbage_collected
    graph_function, _, _ = self._maybe_define_function(args, kwargs)
  File ""/Users/michel/workspace/tf-text2image/venv/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py"", line 2703, in _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)
  File ""/Users/michel/workspace/tf-text2image/venv/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py"", line 2593, in _create_graph_function
    capture_by_value=self._capture_by_value),
  File ""/Users/michel/workspace/tf-text2image/venv/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py"", line 978, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File ""/Users/michel/workspace/tf-text2image/venv/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py"", line 439, in wrapped_fn
    return weak_wrapped_fn().__wrapped__(*args, **kwds)
  File ""/Users/michel/workspace/tf-text2image/venv/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py"", line 968, in wrapper
    raise e.ag_error_metadata.to_exception(e)
ValueError: in converted code:

    /Users/michel/workspace/tf-text2image/venv/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_eager.py:305 train_on_batch  *
        outs, total_loss, output_losses, masks = (
    /Users/michel/workspace/tf-text2image/venv/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_eager.py:253 _process_single_batch
        training=training))
    /Users/michel/workspace/tf-text2image/venv/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_eager.py:167 _model_loss
        per_sample_losses = loss_fn.call(targets[i], outs[i])
    /Users/michel/workspace/tf-text2image/venv/lib/python3.7/site-packages/tensorflow_core/python/keras/losses.py:221 call
        return self.fn(y_true, y_pred, **self._fn_kwargs)
    src/cwan_gp.py:123 gradient_penalty_loss
        gradients_sqr = K.square(gradients)
    /Users/michel/workspace/tf-text2image/venv/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py:2162 square
        return math_ops.square(x)
    /Users/michel/workspace/tf-text2image/venv/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_math_ops.py:9965 square
        ""Square"", x=x, name=name)
    /Users/michel/workspace/tf-text2image/venv/lib/python3.7/site-packages/tensorflow_core/python/framework/op_def_library.py:486 _apply_op_helper
        (input_name, err))

    ValueError: Tried to convert 'x' to a tensor and failed. Error: None values not supported.
```

**Describe the expected behavior**
The computed gradient is not None

**Code to reproduce the issue**
This is a minimal example to reproduce the error
https://github.com/MichelHalmes/tf-text2image/blob/72df135786c7273fb2e0bea27a30ab60024e92b2/src/cwan_gp.py

**Other info / logs**
This person belivees that doing higher order gradients is only possible with theano: https://github.com/LuEE-C/WGAN-GP-with-keras-for-text/blob/master/README.md

This person seems to have had the same issue about a year ago : https://stackoverflow.com/questions/54076901/k-gradients-returning-none


"
36433,No session factory registered for the given session options,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04.3 LTS
- TensorFlow installed from (source or binary): source
- TensorFlow version: v2.1.0
- Python version: 3.7.4
- Installed using virtualenv? pip? conda?: conda
- Bazel version (if compiling from source): 0.29.1
- GCC/Compiler version (if compiling from source): g++ 7.4.0




**Describe the problem**
I have built TF from source ([link](https://www.tensorflow.org/install/source)). I have trained a DNN in python, frozen it as a .pb file, and now I would like to load the model and perform the evaluation in m my C++ code ([Gist here](https://gist.github.com/nicolastonon/d03605315f00228ace0a3c2a2621feda)). 

However I get a segfault already when trying to create a session : 

```
2020-02-03 11:55:25.001775: E tensorflow/core/common_runtime/session.cc:89] Not found: No session factory registered for the given session options: {target: """" config: } Registered factories are {}.
error while creating session: Not found: No session factory registered for the given session options: {target: """" config: } Registered factories are {}.
```

There have been similar issues (e.g. #3308), for which the proposed solution is to add the `-Wl,--whole-archive` flag when linking the TF libraries ; however this does not seem to work for me.

Does anybody have an idea what I could be doing wrong ?

**Provide the exact sequence of commands / steps that you executed before running into the problem**
1) Build TF from source

2) Compile (successfully) a custom C++ code creating a Session, linking the TF libraries with the relevant option (e.g : `-L/home/ntonon/Documents/Programmes/tensorflow/bazel-bin/tensorflow -Wl,--whole-archive -Wl,--no-as-needed -ltensorflow_framework`)

3) Running the code gives the error cited above.

Thanks in advance.
"
36432,Error when importing tensorflow 2,"Have pip installed tensorflow on my windows. 
When i try and import it, i get this error message.


Traceback (most recent call last):
  File ""C:\Users\vegar\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\vegar\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\vegar\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\vegar\AppData\Local\Programs\Python\Python37\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\vegar\AppData\Local\Programs\Python\Python37\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: module not found.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""test.py"", line 6, in <module>
    import tensorflow as tf
  File ""C:\Users\vegar\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow\__init__.py"", line 101, in <module>
    from tensorflow_core import *
  File ""C:\Users\vegar\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow_core\__init__.py"", line 40, in <module>
    from tensorflow.python.tools import module_util as _module_util
  File ""C:\Users\vegar\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow\__init__.py"", line 50, in __getattr__
    module = self._load()
  File ""C:\Users\vegar\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow\__init__.py"", line 44, in _load
    module = _importlib.import_module(self.__name__)
  File ""C:\Users\vegar\AppData\Local\Programs\Python\Python37\lib\importlib\__init__.py"", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""C:\Users\vegar\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow_core\python\__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\Users\vegar\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 74, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""C:\Users\vegar\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\vegar\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\vegar\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\vegar\AppData\Local\Programs\Python\Python37\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\vegar\AppData\Local\Programs\Python\Python37\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: module not found


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/errors

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help."
36431,TensorFlow2.x should support group convolutions in keras api level.,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): 2.1.0
- Are you willing to contribute it (Yes/No): No



**Describe the feature and the current behavior/state.**
Group convolution has been widely used in various deep learning models, such as ResNeXt(https://arxiv.org/abs/1611.05431). PyTorch has already supported group convolution, while TensorFlow has not. As this issue(https://github.com/tensorflow/tensorflow/issues/34024) says, ```tf.nn.conv2d() ``` supports group convolution on GPU, but not on CPU. Therefore, A keras layer api which supports group convolution is needed for many users. This is a sample code which supports the feature by modifying the keras ```Conv2D``` api:
```
class Conv2D(tf.keras.layers.Layer):
    def __init__(self,
                 input_channels,
                 output_channels,
                 kernel_size,
                 strides=(1, 1),
                 padding='valid',
                 data_format=None,
                 dilation_rate=(1, 1),
                 activation=None,
                 groups=1,
                 use_bias=True,
                 kernel_initializer='glorot_uniform',
                 bias_initializer='zeros',
                 kernel_regularizer=None,
                 bias_regularizer=None,
                 activity_regularizer=None,
                 kernel_constraint=None,
                 bias_constraint=None,
                 **kwargs):
        super(Conv2D, self).__init__()

        if not input_channels % groups == 0:
            raise ValueError(""The value of input_channels must be divisible by the value of groups."")
        if not output_channels % groups == 0:
            raise ValueError(""The value of output_channels must be divisible by the value of groups."")

        self.kernel_size = kernel_size
        self.strides = strides
        self.padding = padding
        self.data_format = data_format
        self.dilation_rate = dilation_rate
        self.activation = activation
        self.groups = groups
        self.use_bias = use_bias
        self.kernel_initializer = kernel_initializer
        self.bias_initializer = bias_initializer
        self.kernel_regularizer = kernel_regularizer
        self.bias_regularizer = bias_regularizer
        self.activity_regularizer = activity_regularizer
        self.kernel_constraint = kernel_constraint
        self.bias_constraint = bias_constraint

        self.group_in_num = input_channels // groups
        self.group_out_num = output_channels // groups
        self.conv_list = []
        for i in range(self.groups):
            self.conv_list.append(tf.keras.layers.Conv2D(filters=self.group_out_num,
                                                         kernel_size=kernel_size,
                                                         strides=strides,
                                                         padding=padding,
                                                         data_format=data_format,
                                                         dilation_rate=dilation_rate,
                                                         activation=activations.get(activation),
                                                         use_bias=use_bias,
                                                         kernel_initializer=initializers.get(kernel_initializer),
                                                         bias_initializer=initializers.get(bias_initializer),
                                                         kernel_regularizer=regularizers.get(kernel_regularizer),
                                                         bias_regularizer=regularizers.get(bias_regularizer),
                                                         activity_regularizer=regularizers.get(activity_regularizer),
                                                         kernel_constraint=constraints.get(kernel_constraint),
                                                         bias_constraint=constraints.get(bias_constraint),
                                                         **kwargs))

    def call(self, inputs, **kwargs):
        feature_map_list = []
        for i in range(self.groups):
            x_i = self.conv_list[i](inputs[:, :, :, i*self.group_in_num: (i + 1) * self.group_in_num])
            feature_map_list.append(x_i)
        out = tf.concat(feature_map_list, axis=-1)
        return out
```

**Will this change the current api? How?**
This will change the current keras convolution api . 

**Who will benefit with this feature?**
Anyone who need to use group conolution in their code will benefit.

**Any Other info.**
"
36430,Bugs padding on Tensorflow Lite Converter,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04, GPU GTX 1660
- TensorFlow installed from (source or binary): pip
- TensorFlow version (or github SHA if from source): 2.1.0


**Command used to run the converter or code if you’re using the Python API**

```
import torch
import torch.nn.functional as F
from torch.nn.utils import weight_norm
import torch.nn as nn
import numpy as np
import os
import tensorflow as tf
import time

# tf.compat.v1.disable_eager_execution()

class TFReflectionPad1d(tf.keras.layers.Layer):
    def __init__(self, padding_size):
        super(TFReflectionPad1d, self).__init__()
        self.padding_size = padding_size
    
    def call(self, x):
        return tf.pad(x, [[0,0],[self.padding_size,self.padding_size],[0,0]], ""REFLECT"")
    

class TFUpsampleConv1d(tf.keras.layers.Layer):
    def __init__(self, upsample_factor, filters, kernel_size,
                 padding='same'):
        super(TFUpsampleConv1d, self).__init__()
        self.upsample1d = tf.keras.layers.UpSampling1D(size=upsample_factor)
        self.conv1d = tf.keras.layers.Conv1D(filters=filters, kernel_size=kernel_size, padding=padding)
    
    def call(self, x):
        x = self.upsample1d(x)
        return self.conv1d(x)
    
    
class TFResnetBlock(tf.keras.layers.Layer):
    def __init__(self, dim, dilation=1):
        super(TFResnetBlock, self).__init__()
        self.block = [
            tf.keras.layers.LeakyReLU(0.2),
            TFReflectionPad1d(dilation),
            tf.keras.layers.Conv1D(filters=dim, kernel_size=3, dilation_rate=dilation),
            tf.keras.layers.LeakyReLU(0.2),
            tf.keras.layers.Conv1D(filters=dim, kernel_size=1),
        ]
        self.shortcut = tf.keras.layers.Conv1D(filters=dim, kernel_size=1)
    
    def call(self, x):
        _x = tf.identity(x)
        for layer in self.block:
            _x = layer(_x)
        return self.shortcut(x) + _x

class TFMelGANGenerator(tf.keras.layers.Layer):
    def __init__(self, ngf, n_residual_layers):
        super(TFMelGANGenerator, self).__init__()
        ratios = [8,8,2,2]
        self.hop_length = np.prod(ratios)
        mult = int(2 ** len(ratios))
        
        model = [
            TFReflectionPad1d(3),
            tf.keras.layers.Conv1D(filters=mult * ngf, kernel_size=7, padding='valid')
        ]
        
        for i, r in enumerate(ratios):
            model += [
                tf.keras.layers.LeakyReLU(0.2),
                TFUpsampleConv1d(
                    upsample_factor=r,
                    filters=mult * ngf // 2,
                    kernel_size=r * 2 - 1,
                    padding='same'
                )
            ]
            
            for j in range(n_residual_layers):
                model += [TFResnetBlock(dim=mult * ngf // 2, dilation=3 ** j)]
            
            mult //= 2

        model += [
            tf.keras.layers.LeakyReLU(0.2),
            TFReflectionPad1d(3),
            tf.keras.layers.Conv1D(filters=1, kernel_size=7, padding='valid'),
            tf.keras.layers.Activation('tanh')
        ]
        self.model = tf.keras.models.Sequential(model)
    
    def call(self, x):
        return self.model(x)

inputs = tf.keras.Input(shape=[241, 80], dtype=tf.float32)
audio = TFMelGANGenerator(ngf=32, n_residual_layers=3)(inputs)
tf_melgan = tf.keras.models.Model(inputs, audio)

converter = tf.lite.TFLiteConverter.from_keras_model(tf_melgan)
converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]
converter.post_training_quantize = True
converter.experimental_new_converter = True
tflite_model = converter.convert()

```


**Any other info / logs**
```
---------------------------------------------------------------------------
ConverterError                            Traceback (most recent call last)
<ipython-input-58-d738e01cc59a> in <module>()
      3 converter.post_training_quantize = True
      4 #converter.experimental_new_converter = True
----> 5 tflite_model = converter.convert()

2 frames
/usr/local/lib/python3.6/dist-packages/tensorflow_core/lite/python/convert.py in toco_convert_protos(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)
    198       stdout = _try_convert_to_unicode(stdout)
    199       stderr = _try_convert_to_unicode(stderr)
--> 200       raise ConverterError(""See console for info.\n%s\n%s\n"" % (stdout, stderr))
    201   finally:
    202     # Must manually cleanup files.

ConverterError: See console for info.
2020-02-03 06:48:15.223818: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 303 operators, 48921 arrays (0 quantized)
2020-02-03 06:48:17.886590: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 303 operators, 48921 arrays (0 quantized)
2020-02-03 06:48:18.761673: I tensorflow/lite/toco/graph_transformations/identify_dilated_conv.cc:202] Replaced sub-network with Dilated Conv2D op outputting ""model_4/tf_mel_gan_generator_4/sequential_4/tf_resnet_block_41/conv1d_149/conv1d"".
2020-02-03 06:48:18.783229: F tensorflow/lite/toco/graph_transformations/propagate_fixed_sizes.cc:118] Check failed: dim_x == dim_y (1928 vs. 1934)Dimensions must match
Fatal Python error: Aborted

Current thread 0x00007f7e2a8b8780 (most recent call first):
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/lite/toco/python/toco_from_protos.py"", line 52 in execute
  File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250 in _run_main
  File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299 in run
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40 in run
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/lite/toco/python/toco_from_protos.py"", line 89 in main
  File ""/usr/local/bin/toco_from_protos"", line 8 in <module>
Aborted (core dumped)

```"
36429,Allocation of 10616832 exceeds 10% of system memory.,"Hi. I'm currently having some problems after running the Object_detection.py like:

2020-02-01 11:57:36.437688: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 10616832 exceeds 10% of system memory.
Killed

My device is **Raspberry Pi 3 B+**.
Tensorflow Version: **1.14.0**
Python Version: **Python 3.7.3**
GPU: **128**
Currently using: **faster_rcnn_inception_v2_coco_2018_01_28**

Can anyone help me with this? I appreciate any response that can fix this problem."
36428,Discrepancy between keras.layers.Reshape and tf.keras.layers.Reshape,"```
tf-version 2.1.0
keras-version 2.2.4-tf
```

In Keras, according to [the documentation](https://keras.io/layers/core/), we expect:

```python
model.add(Reshape((-1, 2, 2)))
# now: model.output_shape == (None, 3, 2, 2)
```

But in tf.Keras [documentation](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Reshape):

```python
model.add(Reshape((-1, 2, 2)))
# now: model.output_shape == (None, None, 2, 2)
```

The second dimension is now `None` instead of the computed value.

This makes tf.Keras incompatible with Keras, and makes it harder to write code that is parameterized by of the output shape of an opaque model. Is there a way to get the true output shape?"
36427,HadoopFileSystem load error,"this is a build/installation issue.

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
```
$ cat /proc/cpuinfo
processor	: 0
model name	: ARMv6-compatible processor rev 7 (v6l)
BogoMIPS	: 697.95
Features	: half thumb fastmult vfp edsp java tls 
CPU implementer	: 0x41
CPU architecture: 7
CPU variant	: 0x0
CPU part	: 0xb76
CPU revision	: 7

Hardware	: BCM2835
Revision	: 0010
Serial		: 00000000
Model		: Raspberry Pi Model B Plus Rev 1.2
$ 
```

```
$ uname -a
Linux raspbari1 4.19.97+ #1293 Wed Jan 22 17:05:40 GMT 2020 armv6l GNU/Linux
```
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
n/a

- TensorFlow installed from (source or binary):
- TensorFlow version:
```
Installing collected packages: tensorflow-estimator, protobuf, h5py, keras-applications, astor, termcolor, cachetools, pyasn1, rsa, pyasn1-modules, google-auth, google-auth-oauthlib, absl-py, grpcio, markdown, tensorboard, gast, google-pasta, opt-einsum, wrapt, keras-preprocessing, tensorflow
Successfully installed absl-py-0.9.0 astor-0.8.1 cachetools-4.0.0 gast-0.2.2 google-auth-1.11.0 google-auth-oauthlib-0.4.1 google-pasta-0.1.8 grpcio-1.26.0 h5py-2.10.0 keras-applications-1.0.8 keras-preprocessing-1.1.0 markdown-3.1.1 opt-einsum-3.1.0 protobuf-3.11.2 pyasn1-0.4.8 pyasn1-modules-0.2.8 rsa-4.0 tensorboard-2.0.2 tensorflow-1.14.0 tensorflow-estimator-1.14.0 termcolor-1.1.0 wrapt-1.11.2

```
- Python version:
```
Python 3.7.3 (default, Apr  3 2019, 05:39:12) 
[GCC 8.2.0] on linux

```
- Installed using virtualenv? pip? conda?:
`python3 -m pip install tensorflow`

- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
n/a
- GPU model and memory:
n/a

**Describe the problem**
`2020-02-02 15:11:00.880396: E tensorflow/core/platform/hadoop/hadoop_file_system.cc:132] HadoopFileSystem load error: libhdfs.so: cannot open shared object file: No such file or directory`

**Provide the exact sequence of commands / steps that you executed before running into the problem**
```
$ python3
Python 3.7.3 (default, Apr  3 2019, 05:39:12) 
[GCC 8.2.0] on linux
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import tensorflow
```


**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
36426,Error:55: Could not load dynamic library 'libcudnn.so.7,"**System information**
- Operating System: 18.04.4 LTS
- TensorFlow installed from: source
- TensorFlow version: 2.1.0
- Python version: 3.6.9
- Installed using: virtualenv, and then pip in order to build the wheel as mentionned in the source installation
- Bazel version: bazel-1.2.1 as mentionned in my configure.py file. No other version was possible
- GCC/Compiler: 7.4.0
- CUDA: 10.2.89
- cuDNN: 7.6.5
- GPU model and memory: GeForce RTX 2070, 8 Gb
- NVIDIA-SMI: 440.33.01
- Driver Version: NVIDIA-SMI 440.33.01

**Describe the problem**
I have followed carefully the installation guide of cuDNN, and tensorflow from source, didn't get any error during the installation, but when I call` tf.test.is_gpu_available()` I get one signle error which is: 
`Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory`
I have looked at the posts already dealing with this question, tried there answers, but nothing changes. I have tried: 
- `export LD_LIBRARY_PATH=/usr/local/cuda/lib64/` from [this post](https://github.com/tensorflow/tensorflow/issues/4827)
- ` sudo sh -c ""echo '/usr/local/cuda/lib64\n/usr/local/cuda/lib >> /etc/ld.so.conf.d/nvidia.conf""`
   `sudo ldconfig` from [here](https://github.com/tensorflow/tensorflow/issues/8898)
- `export LD_LIBRARY_PATH=/usr/local/cuda-10.2/lib64:$LD_LIBRARY_PATH`
  `export LD_LIBRARY_PATH=/usr/local/cuda/lib64:$LD_LIBRARY_PATH` from [here](https://github.com/tensorflow/tensorflow/issues/20271)
After rebooting each time, I still get the error mentioned above.
- I have also verified where is the libcudnn.so.7  in the root file and it is in: 
`/usr/local/cuda-10.2/targets/x86_64-linux/lib`
and important, also in `/usr/local/cuda-10.2/targets/x86_64-linux/lib` there is a file called: 
`libcudnn.so.7.6.5 `

Please consider that I am not a very experienced Programmer.
Any help would be extremely appreciated. Thank you for your time. 

**Provide the exact sequence of commands / steps that you executed before running into the problem**

Activating my virtual environment, in Python (I have checked that the interpreter is indeed the one in my virtualenv): 
```
from __future__ import absolute_import, division, print_function, unicode_literals
import tensorflow as tf
tf.test.is_gpu_available()
```

**Any other info / logs**
The entire error I get calling` tf.test.is_gpu_available()` is 
```
2020-02-02 20:22:17.488097: I tensorflow/core/platform/profile_utils/cpu_utils.cc:101] CPU Frequency: 3493375000 Hz
2020-02-02 20:22:17.489597: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fbde003fa20 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-02-02 20:22:17.489647: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-02-02 20:22:17.492686: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-02-02 20:22:17.598433: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x3d91ff0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-02-02 20:22:17.598490: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce RTX 2070, Compute Capability 7.5
2020-02-02 20:22:17.599531: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1558] Found device 0 with properties: 
pciBusID: 0000:09:00.0 name: GeForce RTX 2070 computeCapability: 7.5
coreClock: 1.815GHz coreCount: 36 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s
2020-02-02 20:22:17.599953: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.2
2020-02-02 20:22:17.601575: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-02-02 20:22:17.603388: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-02-02 20:22:17.603663: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-02-02 20:22:17.605504: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-02-02 20:22:17.606545: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
""""ERROR IS HERE""""
2020-02-02 20:22:17.606679: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory
""""DON'T KNOW IF THIS IS AN ERROR FROM THE PREVIOUS ONE""""
2020-02-02 20:22:17.606693: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1595] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2020-02-02 20:22:17.606721: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1099] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-02-02 20:22:17.606729: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1105]      0 
2020-02-02 20:22:17.606736: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1118] 0:   N 
```
"
36425,tf-lite update 3rd party repo script r2.1 branch ,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): linux raspbian
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:na
- TensorFlow installed from (source or binary): source
- TensorFlow version: r2.1
- Python version: na
- Installed using virtualenv? pip? conda?: na
- Bazel version (if compiling from source): na
- GCC/Compiler version (if compiling from source):na
- CUDA/cuDNN version: na
- GPU model and memory: na



**Describe the problem**
The update 3rd party repository script craps out because it can't find the EIGEN url. 

**Provide the exact sequence of commands / steps that you executed before running into the problem**

./tensorflow/lite/tools/make/download_dependencies.sh

**Any other info / logs** 
It is fixed in HEAD but wasn't backported to the release branch. 

patch: 
[TF-lite-url-patch.txt](https://github.com/tensorflow/tensorflow/files/4145276/TF-lite-url-patch.txt)
"
36424,TensorFlow Feature Columns Fail for Keras Model Functional API,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Databricks 6.3- `Linux version 4.4.0-1100-aws (buildd@lgw01-amd64-030) (gcc version 5.4.0 20160609 (Ubuntu 5.4.0-6ubuntu1~16.04.12) ) #111-Ubuntu SMP Wed Dec 4 12:20:15 UTC 2019 (Ubuntu 4.4.0-1100.111-aws 4.4.203)`
- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:
- **TensorFlow installed from (source or binary)**: binary
- **TensorFlow version (use command below)**: 
```
2020-02-02 17:40:54.646833: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libnvinfer.so.6
2020-02-02 17:40:54.648818: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libnvinfer_plugin.so.6
v2.1.0-rc2-17-ge5bf8de 2.1.0
```
- **Python version**: 3.7.3
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**: GCC 7.3.0
- **CUDA/cuDNN version**: 10.1
- **GPU model and memory**: AWS p2.xlarge
- **Exact command to reproduce**:
```python
source_column = tf.feature_column.numeric_column(""source_name"")
categorical_column = tf.feature_column.bucketized_column(source_column, [0, 10, 100])
embedding_column = tf.feature_column.embedding_column(categorical_column, 7)
feature_columns = [ embedding_column ]

name_schema = tf.feature_column.make_parse_example_spec(feature_columns)
inputs = {
  name: keras.layers.Input(shape=schema.shape, name=name, dtype=schema.dtype)
  for name, schema in name_schema.items()
}

dense_features = keras.layers.DenseFeatures(feature_columns)
column_tensors = {}
dense_tensor = dense_features(inputs, cols_to_output_tensors=column_tensors)
```

### Describe the problem
> Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

I believe it should be possible to use Feature Columns with Keras Model Functional API.  Most feature columns work, however, it appears that some combinations of feature columns like the above embedding - bucketized - numeric columns fail.

It is not clear how to work around this error or apply the suggested wrapping.

### Source code / logs
> Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.

The above code fails with:
```pytb
ValueError                                Traceback (most recent call last)
<command-1166953> in <module>
     12 dense_features = keras.layers.DenseFeatures(feature_columns)
     13 column_tensors = {}
---> 14 dense_tensor = dense_features(inputs, cols_to_output_tensors=column_tensors)

/databricks/python/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py in __call__(self, inputs, *args, **kwargs)
    803               kwargs.pop('mask')
    804             inputs, outputs = self._set_connectivity_metadata_(
--> 805                 inputs, outputs, args, kwargs)
    806           self._handle_activity_regularization(inputs, outputs)
    807           self._set_mask_metadata(inputs, outputs, input_masks)

/databricks/python/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py in _set_connectivity_metadata_(self, inputs, outputs, args, kwargs)
   2012     # This updates the layer history of the output tensor(s).
   2013     self._add_inbound_node(
-> 2014         input_tensors=inputs, output_tensors=outputs, arguments=arguments)
   2015     return inputs, outputs
   2016 

/databricks/python/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py in _add_inbound_node(self, input_tensors, output_tensors, arguments)
   2042         input_tensors=input_tensors,
   2043         output_tensors=output_tensors,
-> 2044         arguments=arguments)
   2045 
   2046     # Update tensor history metadata.

/databricks/python/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/node.py in __init__(self, outbound_layer, inbound_layers, node_indices, tensor_indices, input_tensors, output_tensors, arguments)
    120       if base_layer_utils.needs_keras_history(
    121           tensor_argument, ignore_call_context=True):
--> 122         base_layer_utils.create_keras_history(tensor_argument)
    123 
    124     # Add nodes to all layers involved.

/databricks/python/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer_utils.py in create_keras_history(tensors)
    185     keras_tensors: The Tensors found that came from a Keras Layer.
    186   """"""
--> 187   _, created_layers = _create_keras_history_helper(tensors, set(), [])
    188   return created_layers
    189 

/databricks/python/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer_utils.py in _create_keras_history_helper(tensors, processed_ops, created_layers)
    247               constants[i] = backend.function([], op_input)([])
    248       processed_ops, created_layers = _create_keras_history_helper(
--> 249           layer_inputs, processed_ops, created_layers)
    250       name = op.name
    251       node_def = op.node_def.SerializeToString()

/databricks/python/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer_utils.py in _create_keras_history_helper(tensors, processed_ops, created_layers)
    247               constants[i] = backend.function([], op_input)([])
    248       processed_ops, created_layers = _create_keras_history_helper(
--> 249           layer_inputs, processed_ops, created_layers)
    250       name = op.name
    251       node_def = op.node_def.SerializeToString()

/databricks/python/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer_utils.py in _create_keras_history_helper(tensors, processed_ops, created_layers)
    247               constants[i] = backend.function([], op_input)([])
    248       processed_ops, created_layers = _create_keras_history_helper(
--> 249           layer_inputs, processed_ops, created_layers)
    250       name = op.name
    251       node_def = op.node_def.SerializeToString()

/databricks/python/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer_utils.py in _create_keras_history_helper(tensors, processed_ops, created_layers)
    247               constants[i] = backend.function([], op_input)([])
    248       processed_ops, created_layers = _create_keras_history_helper(
--> 249           layer_inputs, processed_ops, created_layers)
    250       name = op.name
    251       node_def = op.node_def.SerializeToString()

/databricks/python/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer_utils.py in _create_keras_history_helper(tensors, processed_ops, created_layers)
    247               constants[i] = backend.function([], op_input)([])
    248       processed_ops, created_layers = _create_keras_history_helper(
--> 249           layer_inputs, processed_ops, created_layers)
    250       name = op.name
    251       node_def = op.node_def.SerializeToString()

/databricks/python/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer_utils.py in _create_keras_history_helper(tensors, processed_ops, created_layers)
    221             'Sparse ops are not supported with functional models with built-in '
    222             'layer wrapping. Please wrap the sparse ops in a Lambda layer like'
--> 223             ': \n{lambda_example}\n'.format(lambda_example=lambda_example))
    224 
    225       # Recursively set `_keras_history`.

ValueError: Sparse ops are not supported with functional models with built-in layer wrapping. Please wrap the sparse ops in a Lambda layer like: 

        weights_mult = lambda x: tf.sparse.sparse_dense_matmul(x, weights)
        output = tf.keras.layers.Lambda(weights_mult)(input)
```"
36423,Failed to get device attribute 13 for device 0,"When I'am trying to run Yolo detection examples, I got that error:


```
2020-02-02 21:39:00.821721: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll                                                                                                                  
WARNING:tensorflow:From C:\Users\Dominux\AppData\Local\Programs\Python\Python37\lib\site-packages\tensorflow_core\python\ops\resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.                                                                        
Instructions for updating:                                                                                                       
If using Keras pass *_constraint arguments to layers.                                                                            
2020-02-02 21:39:03.863436: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library nvcuda.dll                                                                                                                        
2020-02-02 21:39:04.431694: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties:             
pciBusID: 0000:02:00.0 name: GeForce MX230 computeCapability: 6.1                                                                
coreClock: 1.531GHz coreCount: 2 deviceMemorySize: 2.00GiB deviceMemoryBandwidth: 44.76GiB/s                                     
2020-02-02 21:39:04.437212: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll                                                                                                                  
2020-02-02 21:39:04.444498: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll                                                                                                                   
2020-02-02 21:39:04.450110: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_10.dll                                                                                                                    
2020-02-02 21:39:04.453997: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_10.dll                                                                                                                   
2020-02-02 21:39:04.459404: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_10.dll                                                                                                                 
2020-02-02 21:39:04.464501: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_10.dll                                                                                                                 
2020-02-02 21:39:04.477818: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll                                                                                                                     
2020-02-02 21:39:04.480586: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0               
2020-02-02 21:39:09.674559: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2                                                                                         
2020-02-02 21:39:09.678508: F tensorflow/stream_executor/lib/statusor.cc:34] Attempting to fetch value instead of handling error 
Internal: failed to get device attribute 13 for device 0: CUDA_ERROR_UNKNOWN: unknown error           
```

My stack: 
* Win 10, 
* Tensoflow 2.1, 
* Intel Core I5, 
* Nvidia GeForce MX230 2GB, 
* 8GD DDR4

I checked similar issues, but they don't have solutions. Just despaired people...
But it problem was talked about by them only with TF 1.14 - I didn't find other
But how you could notice at me stack above I'm using TF 2.1 already

Please, can you help me!
Maybe I've got problems with drivers or CUDA software?
Any ideas?"
36422,performance issue when using the function tf.convert_to_tensor(),"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
linux ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
NA
- TensorFlow installed from (source or binary):
binary, loaded from tensorflow docker
- TensorFlow version (use command below):
v2.1.0-rc2-17-ge5bf8de 2.1.0
- Python version:
3.6.9
- Bazel version (if compiling from source):
NA
- GCC/Compiler version (if compiling from source):
NA
- CUDA/cuDNN version:
CUDA 10.1
- GPU model and memory:
v100 32 GB
You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
I'm suspecting a CPU performance issue when converting a numpy array to tensor.
The duration of the function increased significantly (factor ~4) depends on the data size but not linear and also with large jitters.

Inspecting deeply into number of elements as a graph, we observed jitters and better performance, for some data sizes and bad performance for other data sizes, any ideas why there are large jitters? 

Note: we need to understand in a manner of milliseconds for near real-time application.  
attached:

- graph of convert_to_tensor depends for 1,000,000 - 60,000,000 elements 
- graph of convert_to_tensor depends for 1,000,000 - 7,000,000 elements (deeper scope)


**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.

```
import numpy as np
import tensorflow as tf
import time

for j in range(100):
    input_data = np.float32(np.random.rand(1125000 + j * 500000))
    start = time.time()
    converted_data = tf.convert_to_tensor(input_data, dtype=np.float32)
    stop = time.time()
    print(""convert of"", 1125000 + j * 500000, ""took [ms]: "", 1000 * (stop - start))



for j in range(100):
    input_data = np.float32(np.random.rand(1125000 + j * 50000))
    start = time.time()
    converted_data = tf.convert_to_tensor(input_data, dtype=np.float32)
    stop = time.time()
    print(""convert of"", 1125000 + j * 50000, ""took [ms]: "", 1000 * (stop - start))
```

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

![convert_to_tf_graph_1E06_6E07](https://user-images.githubusercontent.com/27951762/73609337-394e3a00-45d5-11ea-8f1e-aaeaa7c71f22.PNG)
![convert_to_tf_graph_1E06_7E06](https://user-images.githubusercontent.com/27951762/73609338-39e6d080-45d5-11ea-95eb-feb1039a71f6.PNG)"
36421,Tensor is unhashable if Tensor equality is enabled,"**System information**
win10
python 3.6
TF 2.1
tfp 0.9 (have trid 0.8 as well)
tf-hightly-2.9-preview 2.0
shap 0.34
my code below:
from __future__ import print_function

from keras.preprocessing import sequence
from keras.models import Sequential
from keras.layers import Dense, Embedding
from keras.layers import LSTM
from keras.datasets import imdb

max_features = 20000
maxlen = 80  # cut texts after this number of words (among top max_features most common words)
batch_size = 16

print('Loading data...')
(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)
print(len(x_train), 'train sequences')
print(len(x_test), 'test sequences')

print('Pad sequences (samples x time)')
x_train = sequence.pad_sequences(x_train, maxlen=maxlen)
x_test = sequence.pad_sequences(x_test, maxlen=maxlen)
print('x_train shape:', x_train.shape)
print('x_test shape:', x_test.shape)

print('Build model...')
model = Sequential()
model.add(Embedding(max_features, 128))
model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))
model.add(Dense(1, activation='sigmoid'))
model.compile(loss='binary_crossentropy',
              optimizer='adam',
              metrics=['accuracy'])
print('Train...')
model.fit(x_train, y_train,
          batch_size=batch_size,
          epochs=1,
          validation_data=(x_test, y_test))
score, acc = model.evaluate(x_test, y_test,
                            batch_size=batch_size)
print('Test score:', score)
print('Test accuracy:', acc)

import shap
explainer = shap.DeepExplainer(model, x_train[:100])
shap_values = explainer.shap_values(x_test[:10])

**Describe the current behavior**
TypeError: Tensor is unhashable if Tensor equality is enabled. Instead, use tensor.experimental_ref() as the key.

anyone can help me out??  THX
"
36420,Tensorflow2.0 checkpoint restore error,"Here is an error message:
`Exception ignored in: <bound method _CheckpointRestoreCoordinatorDeleter.__del__ of <tensorflow.python.training.tracking.util._CheckpointRestoreCoordinatorDeleter object at 0x0000014FDDC7CFD0>>
Traceback (most recent call last):
  File ""C:\Users\17551\Miniconda3\lib\site-packages\tensorflow_core\python\training\tracking\util.py"", line 140, in __del__    
TypeError: 'NoneType' object is not callable`

I'm using tensorflow-gpu 2.0, windows10, I imported the following libraries:
    from tensorflow.keras.preprocessing.text import text_to_word_sequence
    import tensorflow as tf

This is the code piece of how I restore the checkpoint:
    `checkpoint_dir = gConfig['model_data']
    seq2seqModel.checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))`
"
36419,ModuleNotFoundError: No module named 'tensorflow.contrib'. Latest version of TensorFlow not working with TFLearn?,"- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- TensorFlow installed from (source or binary): binary
- TensorFlow version: 2.0.0
- Python version: 3.7, 3.6.10 on virtual environment
- Installed using virtualenv? pip? conda?: conda
- CUDA/cuDNN version: CUDA 9.0 / cuDNN 7.6.5
- GPU model and memory: NVIDIA GeForce GTX 1660 SUPER, 16GB

So iv'e been trying to install Tensorflow for a while and conda seems like the method that worked best for me, iv'e pretty much got it working in good order, i tried messing around a bit then decided to follow a tutorial which prompted to install tflearn

tflearn is what seems to be causing the problem, i saw an issue over at their repository. But i'am not certain of the steps i should be taking to resolve the issue, heres the traceback;
```
 File ""main.py"", line 6, in <module>
   import tflearn
 File ""C:\Users\User\Anaconda3\envs\chatbot\lib\site-packages\tflearn\__init__.py"", line 4, in <module>
   from . import config
 File ""C:\Users\User\Anaconda3\envs\chatbot\lib\site-packages\tflearn\config.py"", line 5, in <module>
   from .variables import variable
  File ""C:\Users\User\Anaconda3\envs\chatbot\lib\site-packages\tflearn\variables.py"", line 7, in <module>
   from tensorflow.contrib.framework.python.ops import add_arg_scope as contrib_add_arg_scope
 
ModuleNotFoundError: No module named 'tensorflow.contrib'
```
I'am not certain if i should downgrade tensorflow, but to what version? Or are there steps i need to take to fix the issue?

Thanks in advance,"
36418,[Nightly] Distributed dataset/variable regression with dictionary data structures 2.2.0.dev20200130 -> 2.2.0.dev20200131,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04
- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:
- **TensorFlow installed from (source or binary)**: Wheel
- **TensorFlow version (use command below)**: 2.2.0.dev20200130, 2.2.0.dev20200131
- **Python version**: 3.7
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**: 10.1/7.x
- **GPU model and memory**: Titan XP
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

When calling next on an iter made from a distributed dataset (a tf-agents replay buffer), I get the following error on the latest tf-nightly:

```
  File ""/home/mjlbach/Repositories/box-physics/boxphysics/run/worker.py"", line 238, in train
    inputs = next(self.iter)[0]
  File ""/home/mjlbach/.virtualenvs/physics3.7/lib/python3.7/site-packages/tensorflow_core/python/distribute/input_lib.py"", line 250, in __next__
    return self.get_next()
  File ""/home/mjlbach/.virtualenvs/physics3.7/lib/python3.7/site-packages/tensorflow_core/python/distribute/input_lib.py"", line 271, in get_next
    return values.regroup(replicas)
  File ""/home/mjlbach/.virtualenvs/physics3.7/lib/python3.7/site-packages/tensorflow_core/python/distribute/values.py"", line 1185, in regroup
    for i in range(len(v0)))
  File ""/home/mjlbach/.virtualenvs/physics3.7/lib/python3.7/site-packages/tensorflow_core/python/distribute/values.py"", line 1185, in <genexpr>
    for i in range(len(v0)))
  File ""/home/mjlbach/.virtualenvs/physics3.7/lib/python3.7/site-packages/tensorflow_core/python/distribute/values.py"", line 1202, in regroup
    for key in v0keys
TypeError: __init__() got an unexpected keyword argument 'flex_states'
```

I did a bisect and found the change was introduced from 20200130 to 20200131. If I had to guess, I would point towards this commit: https://github.com/tensorflow/tensorflow/commit/4c4e3772ae95f17818e1e08cd7d6c33276a6b68f#diff-580627c9b7904095019167ef005a72de

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
36417,Regression: contrib.boosted_trees.estimator_batch modules are not available in 1.15.2,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): v1.15.0-92-g5d80e1e8e6 1.15.2
- Python version: 3.7.4
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
Many modules are simply missing from `tensorflow.contrib.boosted_trees`, including `estimator_batch` and `lib`
```
>>> import tensorflow.contrib.boosted_trees.estimator_batch
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
ModuleNotFoundError: No module named 'tensorflow.contrib.boosted_trees.estimator_batch'
```
 

**Describe the expected behavior**
`import tensorflow.contrib.boosted_trees.estimator_batch` should succeed.

**Code to reproduce the issue**
`import tensorflow.contrib.boosted_trees.estimator_batch`

**Other info / logs**
Looks like a regression since 1.15.0
"
42783,Translating into Greek,"Hello there !

I'm a CSD undergraduate in Greece. I am willing to contribute to this community by translating the TensorFlow docs into Greek . As the language isn't listed , I would like some instructions to begin with . Looking forward to your reply !"
36416,Error while training object detection model,"Hi,
I am gonna to train a model for object detection with ssdlite_mobilenet_v2_coco (training images:30000,testing images:2000). But in almost 24000 itrations, I will be faced a problem.
What's the meaning of this error and how can i fix it?
### System information

- OS Platform and Distribution (Google Colab Ubuntu):

- TensorFlow version (1.15)


INFO:tensorflow:Finished training! Saving model to disk.
I0201 18:58:21.724251 140376424556416 learning.py:785] Finished training! Saving model to disk.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to delete files with this prefix.
W0201 18:58:22.325520 140376424556416 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to delete files with this prefix.
/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/summary/writer/writer.py:386: UserWarning: Attempting to use a closed FileWriter. The operation will be a noop unless the FileWriter is explicitly reopened.
  warnings.warn(""Attempting to use a closed FileWriter. ""
Traceback (most recent call last):
  File ""/content/gdrive/My Drive/Tensorflow/3_train_ssdlite.py"", line 185, in <module>
    tf.app.run()
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 299, in run
    _run_main(main, args)
  File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py"", line 324, in new_func
    return func(*args, **kwargs)
  File ""/content/gdrive/My Drive/Tensorflow/3_train_ssdlite.py"", line 181, in main
    graph_hook_fn=graph_rewriter_fn)
  File ""/content/models/research/object_detection/legacy/trainer.py"", line 417, in train
    saver=saver)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/slim/python/slim/learning.py"", line 790, in train
    ignore_live_threads=ignore_live_threads)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/supervisor.py"", line 839, in stop
    ignore_live_threads=ignore_live_threads)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/coordinator.py"", line 389, in join
    six.reraise(*self._exc_info_to_raise)
  File ""/usr/local/lib/python3.6/dist-packages/six.py"", line 693, in reraise
    raise value
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/queue_runner_impl.py"", line 257, in _run
    enqueue_callable()
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1287, in _single_operation_run
    self._call_tf_sessionrun(None, {}, [], target_list, None)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py"", line 1443, in _call_tf_sessionrun
    run_metadata)
tensorflow.python.framework.errors_impl.UnknownError: /content/gdrive/My Drive/Tensorflow/training_data/train.tfrecord; Input/output error
	 [[{{node IteratorGetNext}}]]"
36415,tf 2.1 do not support bazel 0.26?,"## URL(s) with the issue:

https://www.tensorflow.org/install/source?hl=en

## Description of issue (what needs changing):

### Clear description

It's said that tensorflow 2.1.0 is built by bazel 0.26.1, but when I use bazel 0.26.1 to build, I get the following error:
```
Please upgrade your bazel installation to version 0.27.1 or higher to build TensorFlow!
```

So, what is the correct bazel version?"
36413,Image data Generator in input mode is not running,"I tried to create a Deep Learning model kinda like a Autoencoder.
So i got image inputs and outputs via image data generator.

`image_dataset = keras.preprocessing.image.ImageDataGenerator(rotation_range=180,validation_split=0.25)`

`output_image_dataset = keras.preprocessing.image.ImageDataGenerator(rotation_range=180,validation_split=0.25)`

`train_generator = image_dataset.flow_from_directory(input_data_dir,
                                                    color_mode='grayscale',
                                                    target_size=(image_size, image_size),
                                                    batch_size=batch_size,
                                                    class_mode=None,
                                                    subset='training')`

`validation_generator = image_dataset.flow_from_directory(input_data_dir,
                                                    color_mode='grayscale',
                                                    target_size=(image_size, image_size),
                                                    batch_size=batch_size,
                                                    class_mode=None,
                                                    subset='validation')`

`output_train_generator = output_image_dataset.flow_from_directory(output_data_dir,
                                                    target_size=(image_size, image_size),
                                                    batch_size=batch_size,
                                                    class_mode=None,
                                                    subset='training')`

`output_validation_generator = output_image_dataset.flow_from_directory(output_data_dir,
                                                    target_size=(image_size, image_size),
                                                    batch_size=batch_size,
                                                    class_mode=None,
                                                    subset='validation')`


`model_1 = tf.keras.Sequential([
    keras.layers.Conv2D(512,3,2,padding='same'),
    keras.layers.Dropout(0.5),
    keras.layers.BatchNormalization(),
    keras.layers.Conv2D(512,3,2,padding='same'),
    keras.layers.Dropout(0.5),
    keras.layers.BatchNormalization(),
    keras.layers.Conv2D(512,3,2,padding='same'),
    keras.layers.Dropout(0.5),
    keras.layers.BatchNormalization(),
])`

`model_2 = tf.keras.Sequential([
    keras.layers.Conv2DTranspose(512,3,2,padding='same'),
    keras.layers.Dropout(0.5),
    keras.layers.BatchNormalization(),
    keras.layers.Conv2DTranspose(512,3,2,padding='same'),
    keras.layers.Dropout(0.5),
    keras.layers.BatchNormalization(),
    keras.layers.Conv2DTranspose(3,3,2,padding='same')
])`

`model = tf.keras.Sequential([
    keras.layers.Input(shape=(image_size,image_size,2)),
    model_1,
    model_2
])`

`optimizer = keras.optimizers.Nadam(learning_rate=1.0,clipvalue=0.5)`

`model.compile(optimizer=optimizer,
             loss='mean_absolute_error',
             metrics=['mean_absolute_error'])`

`epochs = 10`
`steps_per_epoch = 1.5*(train_generator.n//batch_size)`
`validation_steps = (validation_generator.n//batch_size)`
`print(steps_per_epoch)`
`history = model.fit_generator(generator=(train_generator,output_train_generator),
                             epochs = epochs,
                             steps_per_epoch = steps_per_epoch,
                             workers = 4,
                             validation_data=(validation_generator,output_validation_generator),
                             validation_steps = validation_steps)`

But when I ran the code it's not working and giving me an error.

File ""C:\Users\kirut\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow_core\python\keras\engine\training_generator.py"", line 477, in convert_to_generator_like
    num_samples = int(nest.flatten(data)[0].shape[0])
AttributeError: 'DirectoryIterator' object has no attribute 'shape'`"
36412,tflite conversion,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 18.04):
- TensorFlow installed from (pip3 install tensorflow==1.13.1):
- TensorFlow version (1.13.1):


**Provide the text output from tflite_convert**

```
Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: CAST, MEAN, PACK. Here is a list of operators for which you will need custom implementations: DecisionTreeResourceHandleOp, TreeSize.
```

Also, please include a link to a GraphDef or the model if possible.

**Any other info / logs**

Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.




"
36407,"ImportError: DLL load failed: The specified module could not be found.  OS Windows 10 , Tensorflow cpu version","python -c ""import tensorflow as tf;print(tf.reduce_sum(tf.random.normal([1000, 1000])))""
Traceback (most recent call last):
  File ""C:\Users\skmishra\AppData\Local\Continuum\anaconda3\envs\FOODRECOGNITION\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\skmishra\AppData\Local\Continuum\anaconda3\envs\FOODRECOGNITION\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\skmishra\AppData\Local\Continuum\anaconda3\envs\FOODRECOGNITION\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\skmishra\AppData\Local\Continuum\anaconda3\envs\FOODRECOGNITION\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\skmishra\AppData\Local\Continuum\anaconda3\envs\FOODRECOGNITION\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: The specified module could not be found.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""<string>"", line 1, in <module>
  File ""C:\Users\skmishra\AppData\Local\Continuum\anaconda3\envs\FOODRECOGNITION\lib\site-packages\tensorflow\__init__.py"", line 101, in <module>
    from tensorflow_core import *
  File ""C:\Users\skmishra\AppData\Local\Continuum\anaconda3\envs\FOODRECOGNITION\lib\site-packages\tensorflow_core\__init__.py"", line 40, in <module>
    from tensorflow.python.tools import module_util as _module_util
  File ""C:\Users\skmishra\AppData\Local\Continuum\anaconda3\envs\FOODRECOGNITION\lib\site-packages\tensorflow\__init__.py"", line 50, in __getattr__
    module = self._load()
  File ""C:\Users\skmishra\AppData\Local\Continuum\anaconda3\envs\FOODRECOGNITION\lib\site-packages\tensorflow\__init__.py"", line 44, in _load
    module = _importlib.import_module(self.__name__)
  File ""C:\Users\skmishra\AppData\Local\Continuum\anaconda3\envs\FOODRECOGNITION\lib\importlib\__init__.py"", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""C:\Users\skmishra\AppData\Local\Continuum\anaconda3\envs\FOODRECOGNITION\lib\site-packages\tensorflow_core\python\__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\Users\skmishra\AppData\Local\Continuum\anaconda3\envs\FOODRECOGNITION\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 74, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""C:\Users\skmishra\AppData\Local\Continuum\anaconda3\envs\FOODRECOGNITION\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\skmishra\AppData\Local\Continuum\anaconda3\envs\FOODRECOGNITION\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\skmishra\AppData\Local\Continuum\anaconda3\envs\FOODRECOGNITION\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\skmishra\AppData\Local\Continuum\anaconda3\envs\FOODRECOGNITION\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\skmishra\AppData\Local\Continuum\anaconda3\envs\FOODRECOGNITION\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: The specified module could not be found.


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/errors

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help."
36404,sample code of while_loop can't execute on tf nightly,"I am using 2.2.0-dev20200129. I find that the sample code [here](https://tensorflow.google.cn/api_docs/python/tf/while_loop#example_2) cause the following error message

>TypeError: Cannot iterate over a scalar tensor.

on this version."
36402,Labels missing on TensorFlow Lite example after applying custom model.,"I'm using Teachable Machine for an image classification problem.

I have exported the model produced by Teachable Machine in FLOAT format.

I strictly followed the instruction about placing the labels.txt and model on the right folder and also about making changes on ClassifierQuantizedMobileNet and activity_camera.xml

Yet still the labels and the percentage of confidence won't show up as they do in the example.
How to fix that?

![Screenshot_2020-02-01-12-34-07-431_org tensorflow lite examples classification](https://user-images.githubusercontent.com/24626324/73590854-26156e80-44f0-11ea-92bd-f5a09a9324fc.jpg)
"
36401,dll loading failed in tensorflow,"raise ImportError(msg)

ImportError: Traceback (most recent call last):
  File ""C:\Users\sidha\Anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\sidha\Anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\sidha\Anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\sidha\Anaconda3\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\sidha\Anaconda3\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: The specified module could not be found."
36400,Metrics passed to on_batch_end(...) in Keras are inconsistent,"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Uubntu 18.04
- **TensorFlow installed from (source or binary)**: pip tensorflow-gpu
- **TensorFlow version (use command below)**: 2.1
- **Python version**: 3.7
- **CUDA/cuDNN version**: 
- **GPU model and memory**: K80
- **Exact command to reproduce**: see code below

### Describe the problem
The method `on_batch_end` of `tf.keras.callbacks.Callback` receives a parameter `logs`, which contains, e.g., `loss` and `accuracy`. While `loss` is the actual loss of the current batch, `accuracy` is a moving average and the same as printed by the progressbar of `model.fit(...)`. 
The expected behavior is a consistent behavior, i.e. either both values are moving average or both are the actual batch values. I don't have a clear preference for either of both, but the moving average probably creates the least amount of confusion as the is consistent with the progress bar and the function `on_epoch_end`.

### Source code / logs
The following snipped shows the current bevior:
```python
    from tensorflow import keras
    from tensorflow.keras import layers

    inputs = keras.Input(shape=(784,), name='digits')
    x = layers.Dense(4*4096, activation='relu', name='dense_1')(inputs)
    x = layers.Dense(4*4096, activation='relu', name='dense_2')(x)
    x = layers.Dense(4*4096, activation='relu', name='dense_3')(x)
    outputs = layers.Dense(10, activation='softmax', name='predictions')(x)

    model = keras.Model(inputs=inputs, outputs=outputs)
    (x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()
    x_train = x_train.reshape(60000, 784).astype('float32') / 255
    y_train = y_train.astype('float32')

    class PrintStatsCallback(keras.callbacks.Callback):
        def on_batch_end(self, epoch, logs=None):
            print('\nON_BATCH_END: loss: {loss:.4f} accuracy: {accuracy:.4f}'.format_map(logs))

    # Specify the training configuration (optimizer, loss, metrics)
    model.compile(optimizer=keras.optimizers.SGD(lr=0.1),
                  loss='sparse_categorical_crossentropy', metrics=['accuracy'])

    model.fit(x_train, y_train,
              steps_per_epoch=10,
              batch_size=1024,
              callbacks=[PrintStatsCallback()])
```

The output is currently as follows:
```
    Train on 60000 samples
    
    ON_BATCH_END: loss: 2.3004 accuracy: 0.1543
     1024/60000 [..............................] - ETA: 1:18 - loss: 2.3004 - accuracy: 0.1543
    ON_BATCH_END: loss: 2.2151 accuracy: 0.2715
     2048/60000 [>.............................] - ETA: 1:11 - loss: 2.2578 - accuracy: 0.2715
    ON_BATCH_END: loss: 2.1440 accuracy: 0.3613
     3072/60000 [>.............................] - ETA: 1:08 - loss: 2.2199 - accuracy: 0.3613
    ...
```

For example, compare the last two lines:
`ON_BATCH_END: loss: 2.1440 accuracy: 0.3613` 
to 
`3072/60000 [>.............................] - ETA: 1:08 - loss: 2.2199 - accuracy: 0.3613`

The accuracy of both `on_batch_end` and the progress bar are identical, but the loss value differs as the loss value is not a moving average."
36399,Hparams with Estimators,"**System information**
- TensorFlow version (you are using): 2.1.0
- Are you willing to contribute it (Yes/No): Yes

**Describe the feature and the current behavior/state.**
Hparams cannot be used with estimators in tensorflow 2. There's a `KerasCallback` class that logs the `hparams` when using Keras `model.fit`, however this is not usable when using Estimator API. 

There could be a feature in the form of a callback or hook that can be attached to estimators (with TrainSpec or EvalSpec) which will log hparams metrics against the `hparams` for the current trial.

**Will this change the current api? How?**
Most likely, **no**.

**Who will benefit with this feature?**
Those who rely on Estimator API and tensorboard will benefit.
"
36398,Support a generic API for modifying loss / gradients in Keras,"**System information**
- TensorFlow version (you are using): 2.2
- Are you willing to contribute it (Yes/No): Yes



**Describe the feature and the current behavior/state.**

In the upcoming 2.2 release, `experimental_run_tf_function` was removed from `tf.keras.Model.compile` (see https://github.com/tensorflow/tensorflow/issues/35138).

As a result, [this](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/engine/training_eager.py#L274) code path is now executed by default.  However, because only the `apply_gradients` method is called on the optimizer, there is no way to perform custom steps such as loss scaling, gradient clipping, or gradient allreduce (in the case of [Horovod](http://horovod.ai/)).

The one exception is for the [LossScaleOptimizer](https://www.tensorflow.org/api_docs/python/tf/keras/mixed_precision/experimental/LossScaleOptimizer), which is hard-coded into the `_process_single_batch` function to get the scaled loss and the unscaled gradients.  

However, this is not a general solution, because (1) not every optimizer will want to inherit from this class in order to provide custom hooks, and (2) because the class is experimental, there's no guarantee of long-term support for this interface from the TensorFlow developers.

We propose adding new classes (`WrappedOptimizer`, `WrappedGradientTape`) from which classes such as `LossScaleOptimizer` and Horovod's [DistributedOptimizer](https://github.com/horovod/horovod/blob/6c80085a3c162947e37d331d2b9b371b724bb61d/horovod/_keras/__init__.py#L22) can inherit to provide these hooks:

1. `def before_compute_gradients_hook(self, loss)`
2. `def after_compute_gradients_hook(self, grads_and_vars)`
3. `def before_apply_gradients_hook(self, grads_and_vars)`
4. `def should_apply_training_step_hook(self, grads_and_vars)` (return a boolean Tensor set to True if the step shall be applied and an `execute_op`)

**Will this change the current api? How?**

This will not change the user-facing API, but will provide new functionality for users who wish to extend the TensorFlow API.  

Internally, this change will modify `_process_single_batch` to use the new `WrappedOptimizer` interface in place of `LossScaleOptimizer`.

**Who will benefit with this feature?**

Anyone who wishes to extend TensorFlow with custom loss or gradient modifications (for example, Horovod).

**Any Other info.**

Contributors:

@DEKHTIARJonathan 
@romerojosh 
@abditag2
@tgaddair

CC:

@reedwm 
"
36396,Error while converting saved_model to tflite,"**System information**
Windows 10
Tensorflow installed via pip tf-nightly
tensorflow 2.2


**Provide the text output from tflite_convert**
```
ConverterError: See console for info.
2020-02-01 09:13:14.262240: W tensorflow/compiler/mlir/lite/python/graphdef_to_tfl_flatbuffer.cc:108] Ignored output_format.
2020-02-01 09:13:14.262433: W tensorflow/compiler/mlir/lite/python/graphdef_to_tfl_flatbuffer.cc:111] Ignored drop_control_dependency.
2020-02-01 09:13:14.751498: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2
loc(fused[""model/head_block2_bn1_8/FusedBatchNorm@__inference__wrapped_model_1223"", ""StatefulPartitionedCall/model/head_block2_bn1_8/FusedBatchNorm""]): error: non-broadcastable operands
Windows fatal exception: access violation

Current thread 0x00003154 (most recent call first):
  File ""c:\users\san10428\.conda\envs\tfpreview\lib\site-packages\tensorflow_core\lite\toco\python\toco_from_protos.py"", line 56 in execute
  File ""c:\users\san10428\.conda\envs\tfpreview\lib\site-packages\absl\app.py"", line 250 in _run_main
  File ""c:\users\san10428\.conda\envs\tfpreview\lib\site-packages\absl\app.py"", line 299 in run
  File ""c:\users\san10428\.conda\envs\tfpreview\lib\site-packages\tensorflow_core\python\platform\app.py"", line 40 in run
  File ""c:\users\san10428\.conda\envs\tfpreview\lib\site-packages\tensorflow_core\lite\toco\python\toco_from_protos.py"", line 93 in main
  File ""C:\Users\san10428\.conda\envs\tfpreview\Scripts\toco_from_protos.exe\__main__.py"", line 7 in <module>
  File ""c:\users\san10428\.conda\envs\tfpreview\lib\runpy.py"", line 85 in _run_code
  File ""c:\users\san10428\.conda\envs\tfpreview\lib\runpy.py"", line 193 in _run_module_as_main
```

Also, please include a link to a GraphDef or the model if possible.

**Any other info / logs**

I am using nchw data format

"
36394,file_io.get_matching_files indefinitely hangs,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): GCP cloud shell
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): Comes pre-installed in  GCP cloud shell
- TensorFlow version (use command below): TF 2.1
- Python version: 3.7.3
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A

**Describe the current behavior**
file_io.get_matching_files indefinitely hangs

**Describe the expected behavior**
file_io.get_matching_files should not hang!

**Code to reproduce the issue**
Note the `//` in the first command
```
gsutil cp README-cloudshell.txt gs://<some_bucket>/test//bug.txt
gsutil cp README-cloudshell.txt gs://<some_bucket>/test/bug.txt
```
This creates a weird `/` folder under the test folder

Now open python
```
from tensorflow.python.lib.io import file_io
file_io.get_matching_files('gs://<some_bucket>/test/bug.txt')
```
This will hang. 
Delete the `/` folder and this would work fine.

One of our training jobs hung because TF somehow created a `/` folder in model output directory!"
36393,LSTM return sequence is not working unless i use return state,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):mac 10.15
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):source
- TensorFlow version (use command below):2.1.0
- Python version:3.7
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:


**Describe the current behavior**
LSTM layer return sequence is not working unless i set return state TRUE 
**Describe the expected behavior**
the expected behavior is to get the hidden states with return sequence without needing to set return state to TRUE
**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.
```
import tensorflow as tf

inputs = np.random.random([32, 10, 8]).astype(np.float32)

lstm = tf.keras.layers.LSTM(4, return_sequences=True)

print(""ouput_shape"",lstm(inputs).shape)

whole_sequence_output, final_memory_state = lstm(inputs)
```

**Other info / logs**

ouput_shape (32, 10, 4)
2020-01-31 20:35:12.115074: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-01-31 20:35:12.124516: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fce9bb25ef0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-01-31 20:35:12.124525: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version

Traceback (most recent call last):
  File ""/Users/ahmedabaas/Desktop/NLP/codes/utils/preprocess_utils.py"", line 177, in <module>
    whole_sequence_output, final_memory_state = lstm(inputs)
ValueError: too many values to unpack (expected 2)
"
36392,ValueError: `handle` is not available outside the replica context or a `tf.distribute.Strategy.update()` call due to gradient tape,"Similar to #355226 I am also getting the same Value error but while handling gradient tape.

```
Traceback (most recent call last):
  File ""train_model.py"", line 211, in <module>
    main()
  File ""train_model.py"", line 194, in main
    batch_loss = train_step(inp, targ, enc_hidden, targ_lang, encoder, decoder)
  File ""train_model.py"", line 115, in train_step
    gradients = tape.gradient(loss, variables)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/eager/backprop.py"", line 1011, in gradient
    flat_sources = [_handle_or_self(x) for x in flat_sources]
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/eager/backprop.py"", line 697, in _handle_or_self
    x = x.handle
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow_core/python/distribute/values.py"", line 720, in handle
    raise ValueError(""`handle` is not available outside the replica context""
ValueError: `handle` is not available outside the replica context or a `tf.distribute.Strategy.update()` call.
``` 

My code:
```
strategy = tf.distribute.MirroredStrategy()
with strategy.scope():
    LOSS_OBJECT = tf.keras.losses.SparseCategoricalCrossentropy(
    from_logits=True, reduction='none')

    OPTIMIZER = tf.keras.optimizers.Adam()


with strategy.scope():
    #@tf.function
    def train_step(inp, targ, enc_hidden, targ_lang, encoder, decoder):
        loss = 0

        with tf.GradientTape(persistent=True) as tape:
            enc_output, enc_hidden = encoder(inp, enc_hidden)

            dec_hidden = enc_hidden

            dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)

            # Teacher forcing - feeding the target as the next input
            for t in range(1, targ.shape[1]):
                # passing enc_output to the decoder
                predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)

                loss += loss_function(targ[:, t], predictions)

                # using teacher forcing
                dec_input = tf.expand_dims(targ[:, t], 1)

            batch_loss = (loss / int(targ.shape[1]))

            variables = encoder.trainable_variables + decoder.trainable_variables

            gradients = tape.gradient(loss, variables)

            OPTIMIZER.apply_gradients(zip(gradients, variables))

        return batch_loss
```

I am using ```Tensorflow==2.1.0``` and ```cuda 10.1```"
36391,[TF 2.1] Error when converting LSTM model to a frozen graph using convert_variables_to_constants_v2(),"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Mac
- TensorFlow installed from (source or binary): pip install tensorflow
- TensorFlow version (use command below): 2.1
- Python version: 2.7

I tried to froze a LSTM model build with tf.keras by using the `convert_variables_to_constants_v2` function with the following code

```
import tensorflow as tf

def build_model(vocab_size, embedding_dim, rnn_units, batch_size):
  model = tf.keras.Sequential([
    tf.keras.layers.Embedding(vocab_size, embedding_dim,
                              batch_input_shape=[batch_size, embedding_dim]),
    tf.keras.layers.LSTM(rnn_units,
                        return_sequences=True,
                        stateful=False,
                        recurrent_activation='sigmoid',
                        recurrent_initializer='glorot_uniform'),
    tf.keras.layers.Dense(vocab_size)
  ])
  return model

embedding_dim = 100
units = 256
vocab_size = 300
batch_size = 32

model = build_model(vocab_size, embedding_dim, units, batch_size)
model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')

from tensorflow.python.keras.saving import saving_utils as _saving_utils
from tensorflow.python.framework import convert_to_constants as _convert_to_constants

tf.keras.backend.set_learning_phase(False)
func = _saving_utils.trace_model_call(model)
concrete_func = func.get_concrete_function()
frozen_func = _convert_to_constants.convert_variables_to_constants_v2(concrete_func)
```
produces
```
Cannot find the Placeholder op that is an input to the ReadVariableOp.
```
"
36390,"Custom metric in tf.keras.Model compile() gives error, but works when run_eagerly=True","*System information**
Tensorflow 2.1 on colab

**Describe the current behavior**
When model.run_eagerly=True this model works correctly. When run_eagerly=False this gives an error

Error:

> ValueError: Tried to convert 'input' to a tensor and failed. Error: None values not supported.

**Describe the expected behavior**
The metric should run without errors in both cases

**Code to reproduce the issue**
See colab notebook: https://colab.research.google.com/drive/1SxCf2N6D9bTbnm5fD0c_UYN4CaQ5neNQ

`class CustomMetric(tf.keras.metrics.Metric):

    def __init__(self, name='custom_metric', **kwargs):
        super(CustomMetric, self).__init__(name=name, **kwargs)

    def update_state(self, src, dst, sample_weight=None):
        src = tf.reshape(src, (-1, 4, 2))
        dst = tf.reshape(dst, (-1, 4, 2))

        def ax(p, q):
            ones = tf.ones(tf.shape(p))[..., 0:1]
            zeros = tf.zeros(tf.shape(p))[..., 0:1]
            return tf.concat(
                [p[:, 0:1], p[:, 1:2], ones, zeros, zeros, zeros,
                 -p[:, 0:1] * q[:, 0:1], -p[:, 1:2] * q[:, 0:1]
                 ], axis=1)

        def ay(p, q):
            ones = tf.ones(tf.shape(p))[..., 0:1]
            zeros = tf.zeros(tf.shape(p))[..., 0:1]
            return tf.concat(
                [zeros, zeros, zeros, p[:, 0:1], p[:, 1:2], ones,
                 -p[:, 0:1] * q[:, 1:2], -p[:, 1:2] * q[:, 1:2]], axis=1)

        # we build matrix A by using only 4 point correspondence. The linear
        # system is solved with the least square method, so here
        # we could even pass more correspondence
        p = []
        p.append(ax(src[:, 0], dst[:, 0]))
        p.append(ay(src[:, 0], dst[:, 0]))

        p.append(ax(src[:, 1], dst[:, 1]))
        p.append(ay(src[:, 1], dst[:, 1]))

        p.append(ax(src[:, 2], dst[:, 2]))
        p.append(ay(src[:, 2], dst[:, 2]))

        p.append(ax(src[:, 3], dst[:, 3]))
        p.append(ay(src[:, 3], dst[:, 3]))

        # A is Bx8x8
        A = tf.stack(p, axis=1)

        # b is a Bx8x1
        b = tf.stack([
            dst[:, 0:1, 0], dst[:, 0:1, 1],
            dst[:, 1:2, 0], dst[:, 1:2, 1],
            dst[:, 2:3, 0], dst[:, 2:3, 1],
            dst[:, 3:4, 0], dst[:, 3:4, 1],
        ], axis=1)

        # solve the system Ax = b
        X = tf.linalg.solve(A, b)
        #return X

    def reset_states(self):
        return
    def result(self):
        return`


"
36385,Tensorflow team is so disappointing in documenting installation on windows pc,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Python version**:
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with:

```bash
python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""
```

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
36383,TimeDistributed does not work with mixed precision training,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 18.04
- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:
- **TensorFlow installed from (source or binary)**: Binary
- **TensorFlow version (use command below)**: 2.1.0
- **Python version**: 3.6
- **Bazel version (if compiling from source)**: X
- **GCC/Compiler version (if compiling from source)**: X
- **CUDA/cuDNN version**: on CPU
- **GPU model and memory**: X
- **Exact command to reproduce**:

```python
import tensorflow as tf
from tensorflow import keras
import tensorflow_datasets as tfds
from tensorflow.keras.mixed_precision import experimental as mixed_precision


policy = mixed_precision.Policy('mixed_float16')
mixed_precision.set_policy(policy)


def preprocess(ex):
    image = tf.cast(tf.expand_dims(ex['image'], axis=0), tf.float32) / 255.
    image = tf.image.resize(image, [224, 224])

    return image, ex['label']


data = tfds.load(name='imagenette/full-size', split=""train"", data_dir=""/home/glorre/tensorflow_datasets"",
                 shuffle_files=True).repeat()
data = data.map(preprocess).batch(5)

image = keras.Input(shape=[1, 224, 224, 3], name=""seq"")
features = keras.layers.TimeDistributed(
    keras.applications.ResNet50(include_top=False, weights=None, pooling='avg'))(image)

features = keras.layers.Lambda(lambda x: tf.squeeze(x, axis=[1]))(features)

logits = keras.layers.Dense(10)(features)
logits = keras.layers.Activation('linear', dtype='float32')(logits)

model = keras.Model(inputs=image, outputs=logits)

optimizer_1 = keras.optimizers.Adam(0.01)
loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True)

model.compile(optimizer=optimizer_1, loss=loss)

model.summary()

model.fit(data, epochs=10, steps_per_epoch=10)
```

### Describe the problem
TimeDistributed layer raises an input shape error when used with mixed precision.
It works fine without mixed precision

### Source code / logs

Traceback (most recent call last):
  File ""/home/glorre/Code2/test_mixed_precision/mixed_precision.py"", line 25, in <module>
    keras.applications.ResNet50(include_top=False, weights=None, pooling='avg'))(image)
  File ""/home/glorre/miniconda3/envs/tensorflow2.0/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 807, in __call__
    self._set_mask_metadata(inputs, outputs, input_masks)
  File ""/home/glorre/miniconda3/envs/tensorflow2.0/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 1937, in _set_mask_metadata
    output_masks = self.compute_mask(inputs, previous_mask)
  File ""/home/glorre/miniconda3/envs/tensorflow2.0/lib/python3.7/site-packages/tensorflow_core/python/keras/layers/wrappers.py"", line 324, in compute_mask
    output_mask = self.layer.compute_mask(inner_inputs, inner_mask)
  File ""/home/glorre/miniconda3/envs/tensorflow2.0/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py"", line 509, in compute_mask
    output_tensors = self._run_internal_graph(inputs, mask=mask)
  File ""/home/glorre/miniconda3/envs/tensorflow2.0/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py"", line 891, in _run_internal_graph
    output_tensors = layer(computed_tensors, **kwargs)
  File ""/home/glorre/miniconda3/envs/tensorflow2.0/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 737, in __call__
    self.name)
  File ""/home/glorre/miniconda3/envs/tensorflow2.0/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/input_spec.py"", line 177, in assert_input_compatibility
    str(x.shape.as_list()))
ValueError: Input 0 of layer conv1_pad is incompatible with the layer: expected ndim=4, found ndim=5. Full shape received: [None, 1, 224, 224, 3]

Process finished with exit code 1

"
36382,Unable to run unit tests on util_nest,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS 10.15.2
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): Source
- TensorFlow version: 2.0
- Python version: 3.7.3
- Installed using virtualenv? pip? conda?: 
- Bazel version (if compiling from source): 1.2.1
- GCC/Compiler version (if compiling from source): 4 (gotten from the command gcc -dumpversion | cut -f1 -d.)
- CUDA/cuDNN version: None
- GPU model and memory: Intel Iris Plus Graphics 640 1.5GB



**Describe the problem**
Unable to run bazel tests using the command `bazel test //tensorflow/python:util_nest_test`.
**Provide the exact sequence of commands / steps that you executed before running into the problem**
I built tensorflow from the source by doing the following in sequence:
1. Installed the tensorflow pip packages as stated in the documentation [here](https://www.tensorflow.org/install/source)
2. Ran `./configure`command (with a success message which I will be posting in the logs).
3. Ran `bazel build` and was shown a success message.
4. Ran `bazel test //tensorflow/python:util_nest_test` and it got terminated with an error message
```
ERROR: /Users/puneethk/Desktop/Projects/Open-Source/tensorflow/tensorflow/core/util/BUILD:338:1: Executing genrule //tensorflow/core/util:version_info_gen failed (Exit 1)
Traceback (most recent call last):
  File ""/private/var/tmp/_bazel_puneethk/4c7f735167707afd63484e296f46e040/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/tools/git/gen_git_source.runfiles/org_tensorflow/tensorflow/tools/git/gen_git_source.py"", line 340, in <module>
    generate(args.generate, args.git_tag_override)
  File ""/private/var/tmp/_bazel_puneethk/4c7f735167707afd63484e296f46e040/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/tools/git/gen_git_source.runfiles/org_tensorflow/tensorflow/tools/git/gen_git_source.py"", line 272, in generate
    git_version = get_git_version(data[""path""], git_tag_override)
  File ""/private/var/tmp/_bazel_puneethk/4c7f735167707afd63484e296f46e040/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/tools/git/gen_git_source.runfiles/org_tensorflow/tensorflow/tools/git/gen_git_source.py"", line 172, in get_git_version
    str(""--work-tree="" + six.ensure_str(git_base_path)), ""describe"",
AttributeError: 'module' object has no attribute 'ensure_str'
Target //tensorflow/python:util_nest_test failed to build
```

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

1. Output of running `./configure`:
```
WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command ""bazel shutdown"".
You have bazel 1.2.1 installed.
Please specify the location of python. [Default is /System/Library/Frameworks/Python.framework/Versions/2.7/Resources/Python.app/Contents/MacOS/Python]: 


Found possible Python library paths:
  /Library/Python/2.7/site-packages
Please input the desired Python library path to use.  Default is [/Library/Python/2.7/site-packages]
/Library/Frameworks/Python3.framework/Versions/3.7/lib/python3.7/site-packages
Do you wish to build TensorFlow with XLA JIT support? [Y/n]: 
XLA JIT support will be enabled for TensorFlow.

Do you wish to build TensorFlow with OpenCL SYCL support? [y/N]: 
No OpenCL SYCL support will be enabled for TensorFlow.

Do you wish to build TensorFlow with ROCm support? [y/N]: 
No ROCm support will be enabled for TensorFlow.

Do you wish to build TensorFlow with CUDA support? [y/N]: 
No CUDA support will be enabled for TensorFlow.

Do you wish to download a fresh release of clang? (Experimental) [y/N]: 
Clang will not be downloaded.

Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -march=native -Wno-sign-compare]: 


Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: 
Not configuring the WORKSPACE for Android builds.

Do you wish to build TensorFlow with iOS support? [y/N]: 
No iOS support will be enabled for TensorFlow.

Preconfigured Bazel build configs. You can use any of the below by adding ""--config=<>"" to your build command. See .bazelrc for more details.
	--config=mkl         	# Build with MKL support.
	--config=monolithic  	# Config for mostly static monolithic build.
	--config=ngraph      	# Build with Intel nGraph support.
	--config=numa        	# Build with NUMA support.
	--config=dynamic_kernels	# (Experimental) Build kernels into separate shared objects.
	--config=v2          	# Build TensorFlow 2.x instead of 1.x.
Preconfigured Bazel build configs to DISABLE default on features:
	--config=noaws       	# Disable AWS S3 filesystem support.
	--config=nogcp       	# Disable GCP support.
	--config=nohdfs      	# Disable HDFS support.
	--config=nonccl      	# Disable NVIDIA NCCL support.
Configuration finished
```
2. Output after running `bazel build`:
```
INFO: Options provided by the client:
  Inherited 'common' options: --isatty=1 --terminal_columns=130
INFO: Reading rc options for 'build' from /Users/puneethk/Desktop/Projects/Open-Source/tensorflow/.bazelrc:
  'build' options: --apple_platform_type=macos --define framework_shared_object=true --define open_source_build=true --java_toolchain=//third_party/toolchains/java:tf_java_toolchain --host_java_toolchain=//third_party/toolchains/java:tf_java_toolchain --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --enable_platform_specific_config --config=v2
INFO: Reading rc options for 'build' from /Users/puneethk/Desktop/Projects/Open-Source/tensorflow/.tf_configure.bazelrc:
  'build' options: --host_force_python=PY2 --action_env PYTHON_BIN_PATH=/System/Library/Frameworks/Python.framework/Versions/2.7/Resources/Python.app/Contents/MacOS/Python --action_env PYTHON_LIB_PATH=/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.7/lib/python3.7/site-packages --python_path=/System/Library/Frameworks/Python.framework/Versions/2.7/Resources/Python.app/Contents/MacOS/Python --config=xla --action_env TF_CONFIGURE_IOS=0
INFO: Found applicable config definition build:v2 in file /Users/puneethk/Desktop/Projects/Open-Source/tensorflow/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1
INFO: Found applicable config definition build:xla in file /Users/puneethk/Desktop/Projects/Open-Source/tensorflow/.bazelrc: --action_env=TF_ENABLE_XLA=1 --define=with_xla_support=true
INFO: Found applicable config definition build:xla in file /Users/puneethk/Desktop/Projects/Open-Source/tensorflow/.tf_configure.bazelrc: --define with_xla_support=true
INFO: Found applicable config definition build:macos in file /Users/puneethk/Desktop/Projects/Open-Source/tensorflow/.bazelrc: --copt=-w --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --cxxopt=-std=c++14 --host_cxxopt=-std=c++14
WARNING: Usage: bazel build <options> <targets>.
Invoke `bazel help build` for full description of usage and options.
Your request is correct, but requested an empty set of targets. Nothing will be built.
INFO: Analyzed 0 targets (0 packages loaded, 0 targets configured).
INFO: Found 0 targets...
INFO: Deleting stale sandbox base /private/var/tmp/_bazel_puneethk/4c7f735167707afd63484e296f46e040/sandbox
INFO: Elapsed time: 1.643s, Critical Path: 0.03s
INFO: 0 processes.
INFO: Build completed successfully, 1 total action
```


If anyone has run into similar problem and fixed it, could you guide me resolve this?"
36381,dense,
36380,"ERROR: No matching distribution found for tensorboard<2.2.0,>=2.1.0 (from tensorflow)","
**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
win10 1903

- TensorFlow installed from (source or binary):
```pip install tensorflow```

- TensorFlow version:
2.1.0

- Python version:
3.7.4

- Installed using virtualenv? pip? conda?:
```pip install tensorflow```

- CUDA/cuDNN version:
10.1 / 7.6.5.32

- GPU model and memory:
rtx 2070s

**Describe the problem**

**Provide the exact sequence of commands / steps that you executed before running into the problem**
```pip install tensorflow```

**Any other info / logs**
```
 pip install tensorflow
Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple
Collecting tensorflow
  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/34/d5/ce8c17971067c0184c9045112b755be5461d5ce5253ef65a367e1298d7c5/tensorflow-2.1.0-cp37-cp37m-win_amd64.whl (355.8MB)
     |████████████████████████████████| 355.9MB 133kB/s
Collecting protobuf>=3.8.0 (from tensorflow)
  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/30/c6/286db43e2d0d4b89d328a222365c7a253a99a24067812253f0d4f8eb0f1c/protobuf-3.11.2-cp37-cp37m-win_amd64.whl (1.0MB)
     |████████████████████████████████| 1.0MB 71kB/s
Collecting grpcio>=1.8.6 (from tensorflow)
  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/8b/14/ab1501cfff78b88d7368659b227c603d7599dd25226ff682c71334e78aed/grpcio-1.26.0-cp37-cp37m-win_amd64.whl (1.8MB)
     |████████████████████████████████| 1.8MB 6.4MB/s
Collecting keras-applications>=1.0.8 (from tensorflow)
  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl
Collecting gast==0.2.2 (from tensorflow)
Collecting tensorflow-estimator<2.2.0,>=2.1.0rc0 (from tensorflow)
  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/18/90/b77c328a1304437ab1310b463e533fa7689f4bfc41549593056d812fab8e/tensorflow_estimator-2.1.0-py2.py3-none-any.whl (448kB)
     |████████████████████████████████| 450kB 6.8MB/s
Requirement already satisfied: wrapt>=1.11.1 in c:\users\hnjyz\anaconda3\lib\site-packages (from tensorflow) (1.11.2)
Requirement already satisfied: six>=1.12.0 in c:\users\hnjyz\anaconda3\lib\site-packages (from tensorflow) (1.12.0)
Requirement already satisfied: wheel>=0.26; python_version >= ""3"" in c:\users\hnjyz\anaconda3\lib\site-packages (from tensorflow) (0.33.6)
Collecting absl-py>=0.7.0 (from tensorflow)
  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/1a/53/9243c600e047bd4c3df9e69cfabc1e8004a82cac2e0c484580a78a94ba2a/absl-py-0.9.0.tar.gz (104kB)
     |████████████████████████████████| 112kB ...
Collecting astor>=0.6.0 (from tensorflow)
  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/c3/88/97eef84f48fa04fbd6750e62dcceafba6c63c81b7ac1420856c8dcc0a3f9/astor-0.8.1-py2.py3-none-any.whl
Collecting tensorboard<2.2.0,>=2.1.0 (from tensorflow)
  ERROR: Could not find a version that satisfies the requirement tensorboard<2.2.0,>=2.1.0 (from tensorflow) (from versions: 1.6.0rc0, 1.6.0, 1.7.0, 1.8.0, 1.9.0, 1.10.0, 1.11.0, 1.12.0, 1.12.1, 1.12.2, 1.13.0, 1.13.1, 1.14.0, 1.15.0, 2.0.0, 2.0.1, 2.0.2)
ERROR: No matching distribution found for tensorboard<2.2.0,>=2.1.0 (from tensorflow)
```
"
36377,unable to import tensorflow after installation- DLL load failed: The specified module could not be found error comes up,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Python version**:
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with:

```bash
python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""
```

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
36376,Callbacks should be able to access the training and validation data,"**System information**
- TensorFlow version (you are using): 2.1
- Are you willing to contribute it (Yes/No): Maybe

**Describe the feature and the current behavior/state.**

Currently, AFAIK, there's no direct way of accessing the training and validation data used for the mini-batch in the `on_batch_end` or `on_batch_begin` methods (in `tf.keras`).  Of course, this feature can be very useful, for example, if you want to debug the training data used for each training or validation mini-batches or, for example, if you want to compute other metrics on the specific batch of data used to update the parameters at each training step. Apparently, it was once possible to access the validation data inside the callback class, but this is no more available (not sure why!). See https://github.com/tensorflow/tensorflow/issues/36375. The training data for the mini-batch was never available, AFAIK.

I have seen people trying to access the training and validation data (used in the current mini-batch/step) in the callbacks, and the solutions are simply disgustingly verbose, inflexible, etc. (see https://stackoverflow.com/q/47079111/3924118). 

Why don't you provide this feature? This is clearly a useful feature (e.g. [this SO question](https://stackoverflow.com/q/53489352/3924118) shows that this feature would be appreciated). See also https://stackoverflow.com/q/47676248/3924118.

**Will this change the current api? How?**

Probably.

**Who will benefit with this feature?**

Everyone.
"
36375,AttributeError: 'Callback' object has no attribute 'validation_data',"## URL(s) with the issue:

Please provide a link to the documentation entry, for example:
https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/Callback

## Description of issue (what needs changing):

Currently, the page https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/Callback says `validation_data: Deprecated. Do not use.`, but if I attempt to access the attribute `validation_data` inside the callback I get the error `AttributeError: 'MyCustomCallbackClass' object has no attribute 'validation_data'.`. You should change the documentation to remove the attribute `validation_data`, which apparently was removed.

See also this issue https://github.com/tensorflow/tensorflow/issues/27318."
36374,regarding hosting of .h5 model using tfserving,"hi, can I host .h5 model through tf serving, or it just supports .tfsavedformat models for hosting. please let me know if I can host it , and if you can suggest me an article for the support"
36373,AUCROC > 80% with sensitivity 1.0 and specificity 0.0?,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): v2.1.0-rc2-17-ge5bf8de 2.1.0
- Python version: Python 3.6.9
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10.1
- GPU model and memory: Tesla K80 11441MiB

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
True negatives and false negatives are 0, sensitivity computes to 1.0 and specificity to 0.0, but the AUCROC is giving 80%.

**Describe the expected behavior**
Isn't AUCROC used a single number to represent performance across the entire confusion matrix of true positives, true negatives, false positives and false negatives?

**Code to reproduce the issue**
This code was used to parse the TensorBoard data into Pandas: https://gist.github.com/ptschandl/ef67bbaa93ec67aba2cab0a7af47700b

With the basic formula for both:
```
'sensitivity': np.divide(tp, np.add(tp, fn)),
'specificity': np.divide(tn, np.add(tn, fp)),
```

**Other info / logs**
Metrics included AUCROC, and all 4 metrics of the confusion matrix taken at threshold 50.
<img width=""918"" alt=""Screen Shot 2020-01-29 at 9 26 16 pm"" src=""https://user-images.githubusercontent.com/807580/73541346-4c9ebf80-4486-11ea-8e03-aba7c2209f9b.png"">"
36372,More advanced ways of collecting metrics in tf.keras while training models,"**System information**
- TensorFlow version (you are using): 2.1
- Are you willing to contribute it (Yes/No): Maybe

**Describe the feature and the current behavior/state.**

Currently, in `tf.keras`,  we can access the metrics by accessing the attribute `metrics` (a list) and `metrics_names` (list) of the model. Furthermore, when developing a callback, e.g. in the definition `def on_epoch_end(epoch, logs)`, `logs` is a dictionary whose keys are the names and whose values the corresponding values of the metrics, including the loss. 

If you have a neural network with multiple outputs, all the metrics for each of these separate outputs are elements of `metrics` (or `metric_names`) and the dictionary `logs`. AFAIK, there's no direct way of getting e.g. the metrics for an output with name `""outpu1""`. This feature would be useful in the case we want to plot all (or a subset of) the metrics associated with one output. The model object could provide a method or attribute, `get_metrics_of_output(output_name)`, where the metrics are returned as an object (e.g. a dictionary) where the metrics associated with one output are collected in one separate list (or dictionary, etc) than the metrics associated with another output, so that `get_metrics_of_output(output_name)` returns the metrics of the output layer with name `output_name`. Furthermore, there should also be a way of differentiating between certain metrics associated with the **same** output. This could be determined by the way we define and pass the metrics to the `metrics` parameter of the `compile` method (e.g. as a dictionary). 

In [this Stack Overflow question](https://stackoverflow.com/q/59996177/3924118), I am describing my current issue where this feature could be useful.

**Will this change the current api? How?**

Probably. You could just introduce a new method that returns a more advanced view of the metrics. `model.metrics` could still return just the flattened version of the metrics (as it is currently the case). However, `logs` (e.g. in `def on_epoch_end(epoch, logs)`) probably should change to return the more advanced view of the metrics. Or maybe there should be a third parameter that returns this advanced view of the metrics, e.g. `def on_epoch_end(epoch, logs, metrics)`.

**Who will benefit with this feature?**

Everyone.

**Any Other info.**
"
36371,cannot import name 'resnet ',"I installed tensorflow using the following command
`conda install tensorflow-gpu`
`conda install keras-gpu`
then
`import tensorflow`
I get the following error:
>>> import tensorflow
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/home/nnir712/anaconda3/envs/tfenv/lib/python3.6/site-packages/tensorflow/__init__.py"", line 98, in <module>
    from tensorflow_core import *
  File ""/home/nnir712/anaconda3/envs/tfenv/lib/python3.6/site-packages/tensorflow_core/__init__.py"", line 40, in <module>
    from tensorflow.python.tools import module_util as _module_util
  File ""/home/nnir712/anaconda3/envs/tfenv/lib/python3.6/site-packages/tensorflow/__init__.py"", line 50, in __getattr__
    module = self._load()
  File ""/home/nnir712/anaconda3/envs/tfenv/lib/python3.6/site-packages/tensorflow/__init__.py"", line 44, in _load
    module = _importlib.import_module(self.__name__)
  File ""/home/nnir712/anaconda3/envs/tfenv/lib/python3.6/importlib/__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""/home/nnir712/anaconda3/envs/tfenv/lib/python3.6/site-packages/tensorflow_core/python/__init__.py"", line 83, in <module>
    from tensorflow.python import keras
  File ""/home/nnir712/anaconda3/envs/tfenv/lib/python3.6/site-packages/tensorflow_core/python/keras/__init__.py"", line 26, in <module>
    from tensorflow.python.keras import activations
  File ""/home/nnir712/anaconda3/envs/tfenv/lib/python3.6/site-packages/tensorflow_core/python/keras/__init__.py"", line 27, in <module>
    from tensorflow.python.keras import applications
  File ""/home/nnir712/anaconda3/envs/tfenv/lib/python3.6/site-packages/tensorflow_core/python/keras/applications/__init__.py"", line 64, in <module>
    from tensorflow.python.keras.applications.resnet import ResNet50
  File ""/home/nnir712/anaconda3/envs/tfenv/lib/python3.6/site-packages/tensorflow_core/python/keras/applications/resnet.py"", line 22, in <module>
    from keras_applications import resnet
ImportError: cannot import name 'resnet'

**System information**
-ubuntu18.04

anaconda env:
# Name                    Version                   Build  Channel
_libgcc_mutex             0.1                        main    defaults
_tflow_select             2.1.0                       gpu    defaults
absl-py                   0.8.1                    py36_0    defaults
astor                     0.8.0                    py36_0    defaults 
blas                      1.0                         mkl    defaults
c-ares                    1.15.0            h7b6447c_1001    defaults
ca-certificates           2020.1.1                      0    defaults
certifi                   2019.11.28               py36_0    defaults                                               
cudatoolkit               10.0.130                      0    defaults
cudnn                     7.6.5                cuda10.0_0    defaults                                                    
cupti                     10.0.130                      0    defaults
gast                      0.2.2                    py36_0    defaults                                                  
google-pasta              0.1.8                      py_0    defaults
grpcio                    1.16.1           py36hf8bcb03_1    defaults                                            
h5py                      2.10.0           py36h7918eee_0    defaults
hdf5                      1.10.4               hb1b8bf9_0    defaults               
intel-openmp              2019.4                      243    defaults
keras-applications        1.0.8                      py_0    defaults                                                           
keras-base                2.2.4                    py36_0    defaults
keras-gpu                 2.2.4                         0    defaults                                                                 
keras-preprocessing       1.1.0                      py_1    defaults
ld_impl_linux-64          2.33.1               h53a641e_7    defaults                                                                 
libedit                   3.1.20181209         hc058e9b_0    defaults
libffi                    3.2.1                hd88cf55_4    defaults                                                                              
libgcc-ng                 9.1.0                hdf63c60_0    defaults
libgfortran-ng            7.3.0                hdf63c60_0    defaults                                                                            
libprotobuf               3.11.2               hd408876_0    defaults
libstdcxx-ng              9.1.0                hdf63c60_0    defaults
markdown                  3.1.1                    py36_0    defaults
mkl                       2019.4                      243    defaults
mkl-service               2.3.0            py36he904b0f_0    defaults
mkl_fft                   1.0.15           py36ha843d7b_0    defaults
mkl_random                1.1.0            py36hd6b4f25_0    defaults
ncurses                   6.1                  he6710b0_1    defaults
numpy                     1.18.1           py36h4f9e942_0    defaults
numpy-base                1.18.1           py36hde5b4d6_1    defaults
openssl                   1.1.1d               h7b6447c_3    defaults
opt_einsum                3.1.0                      py_0    defaults
pip                       20.0.2                   py36_1    defaults
protobuf                  3.11.2           py36he6710b0_0    defaults
python                    3.6.10               h0371630_0    defaults
pyyaml                    5.2              py36h7b6447c_0    defaults
readline                  7.0                  h7b6447c_5    defaults
scipy                     1.3.2            py36h7c811a0_0    defaults
setuptools                45.1.0                   py36_0    defaults
six                       1.14.0                   py36_0    defaults
sqlite                    3.30.1               h7b6447c_0    defaults
tensorboard               2.0.0              pyhb38c66f_1    defaults
tensorflow                2.0.0           gpu_py36h6b29c10_0    defaults
tensorflow-base           2.0.0           gpu_py36h0ec5d1f_0    defaults
tensorflow-estimator      2.0.0              pyh2649769_0    defaults
tensorflow-gpu            2.0.0                h0d30ee6_0    defaults
termcolor                 1.1.0                    py36_1    defaults
tk                        8.6.8                hbc83047_0    defaults
werkzeug                  0.16.1                     py_0    defaults
wheel                     0.34.1                   py36_0    defaults
wrapt                     1.11.2           py36h7b6447c_0    defaults
xz                        5.2.4                h14c3975_4    defaults
yaml                      0.1.7                had09818_2    defaults
zlib                      1.2.11               h7b6447c_3    defaults
(tfenv) nnir712@nnir712-Lenovo:~/temp$ python
Python 3.6.10 |Anaconda, Inc.| (default, Jan  7 2020, 21:14:29)"
36370,error converting to tflite,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows10
- TensorFlow installed from (source or binary): binary
- TensorFlow version (or github SHA if from source): 1.14.0


**Provide the text output from tflite_convert**

```
# Copy and paste here
```

Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: ADD, CAST, CONCATENATION, CONV_2D, DEPTHWISE_CONV_2D, EXP, EXPAND_DIMS, FILL, GATHER, GREATER, GREATER_EQUAL, LESS, LOGICAL_AND, LOGISTIC, MAXIMUM, MINIMUM, MUL, PACK, PAD, RANGE, RESHAPE, RESIZE_BILINEAR, SELECT, SHAPE, SLICE, SPLIT, SQUEEZE, STRIDED_SLICE, SUB, SUM, TILE, TOPK_V2, TRANSPOSE, UNPACK, WHERE, ZEROS_LIKE. Here is a list of operators for which you will need custom implementations: Enter, Exit, LoopCond, Merge, NonMaxSuppressionV3, Switch, TensorArrayGatherV3, TensorArrayReadV3, TensorArrayScatterV3, TensorArraySizeV3, TensorArrayV3, TensorArrayWriteV3.
Traceback (most recent call last):
  File ""c:\program files\python36\lib\runpy.py"", line 193, in _run_module_as_main
    ""__main__"", mod_spec)
  File ""c:\program files\python36\lib\runpy.py"", line 85, in _run_code
    exec(code, run_globals)
  File ""C:\Program Files\Python36\Scripts\toco_from_protos.exe\__main__.py"", line 7, in <module>
  File ""c:\program files\python36\lib\site-packages\tensorflow\lite\toco\python\toco_from_protos.py"", line 59, in main
    app.run(main=execute, argv=[sys.argv[0]] + unparsed)
  File ""c:\program files\python36\lib\site-packages\tensorflow\python\platform\app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""c:\program files\python36\lib\site-packages\absl\app.py"", line 299, in run
    _run_main(main, args)
  File ""c:\program files\python36\lib\site-packages\absl\app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""c:\program files\python36\lib\site-packages\tensorflow\lite\toco\python\toco_from_protos.py"", line 33, in execute
    output_str = tensorflow_wrap_toco.TocoConvert(model_str, toco_str, input_str)
Exception: We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md
 and pasting the following:

Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: ADD, CAST, CONCATENATION, CONV_2D, DEPTHWISE_CONV_2D, EXP, EXPAND_DIMS, FILL, GATHER, GREATER, GREATER_EQUAL, LESS, LOGICAL_AND, LOGISTIC, MAXIMUM, MINIMUM, MUL, PACK, PAD, RANGE, RESHAPE, RESIZE_BILINEAR, SELECT, SHAPE, SLICE, SPLIT, SQUEEZE, STRIDED_SLICE, SUB, SUM, TILE, TOPK_V2, TRANSPOSE, UNPACK, WHERE, ZEROS_LIKE. Here is a list of operators for which you will need custom implementations: Enter, Exit, LoopCond, Merge, NonMaxSuppressionV3, Switch, TensorArrayGatherV3, TensorArrayReadV3, TensorArrayScatterV3, TensorArraySizeV3, TensorArrayV3, TensorArrayWriteV3.

"
36369,Need for more flexible Loss Function,"
**System information**
- TensorFlow version (you are using): 1.15
- Are you willing to contribute it (Yes/No): Yes



**Describe the feature and the current behavior/state.**
Since, we know that sometimes in the training process, we need the **MAE and MSE type of behavior** simultaneously. We have this kind of loss function already - **Huber Loss**.  But in some cases, we don't need just one value, instead, we need the interval. We need the loss function which can output two values corresponding to lower and upper bounds of the interval. 
This type of loss function is called **Quantile Huber Loss**, which is taken from [this paper](https://arxiv.org/pdf/1402.4624.pdf). The behavior is shown in below image.
![73123322-db0dcf80-3fb4-11ea-852d-9dc672bd0906](https://user-images.githubusercontent.com/20843596/73537063-830c1880-444d-11ea-890c-3ed96aa98a51.png)


**Will this change the current api? How?**
No, it will not change the current api. Instead, it will just add one loss function and will include it's tests.

**Who will benefit with this feature?**
This will be very beneficial for the forecasting and time series. Especially, when the variation is very dynamic, then this loss function helps very much in comparison to existing losses in tf. 
"
36368,"You tried to call `count_params` on embedding, but the layer isn't built. You can build it manually via: `embedding.build(batch_input_shape)`.","when i run model.summary(), this issue occures.

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):windows 10 64bit
- TensorFlow installed from (source or binary):pip install tensorflow (cpu-version)
- TensorFlow version (use command below):tensorflow 2.0
- Python version:python 3.6

**Code to reproduce the issue**
import tensorflow as tf
from tagger.crf import crf_decode, crf_log_likelihood

k = tf.keras


class TaggerModel(k.Model):
    def __init__(self, config,  *args, **kwargs):
        super(TaggerModel, self).__init__(args, kwargs)
        self.embedding_layer = k.layers.Embedding(input_dim=config.vocab_size, output_dim=config.embedding_size)
        forward_layer = k.layers.LSTM(units=config.num_units, return_sequences=True, activation=""sigmoid"")
        backward_layer = k.layers.LSTM(units=config.num_units, return_sequences=True, activation=""sigmoid"",
                                       go_backwards=True)
        self.bidirectional_layer = k.layers.Bidirectional(
            layer=forward_layer, backward_layer=backward_layer, merge_mode=""concat""
        )
        self.dropout_layer = k.layers.Dropout(rate=config.dropout)
        self.dense_layer = k.layers.Dense(units=config.num_tags)
        self.transition = tf.Variable(
            initial_value=tf.random.truncated_normal(shape=[config.num_tags, config.num_tags]), name=""transition"",
            trainable=True)

    @tf.function
    def call(self, inputs, training=None, mask=None):
        source, length = inputs

        # embedding
        embeddings = self.embedding_layer(source)

        # bidirectional
        out = self.bidirectional_layer(embeddings)
        out = self.dropout_layer(out)
        potentials = self.dense_layer(out)

        # crf
        logits, score = crf_decode(potentials=potentials, transition_params=self.transition, sequence_length=length)

        return logits

model = TaggerModel(config)
model.compile(optimizer=config.optimizer, loss=tf.losses.binary_crossentropy, metrics={tf.metrics.Accuracy()})
model.build(input_shape=((None, None), (None,)))
model.summary()
"
36367,"Tensorflow 2.1.0 Error  :  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. [Op:Conv2D]","**System information**

Have I written custom code (as opposed to using a stock example script provided in TensorFlow):No
OS Platform and Distribution (Windows): Windows 10 Home, 10.0.18362 Build 18362
TensorFlow installed from : PIP
TensorFlow version: v2.1.0-rc2-17-ge5bf8de410 2.1.0
Python version: 3.7.6
CUDA/cuDNN version: Cuda 10.1, cuDNN 7.6.5
GPU model and memory: RTX 2070 8GB""

**Describe the problem:**

I installed  tensorflow through pip,  when I try to run any of the notebooks downloaded from Tensorflow tutorials section, it gives ' Failed to get convolution error'. Though when I run some simple calculations on gpu it works fine, for example if I run the the following code no error is generated.
```
import tensorflow as tf
print(""Num GPUs Available: "", len(tf.config.experimental.list_physical_devices('GPU')))
tf.debugging.set_log_device_placement(True)

# Create some tensors
a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])
b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])
c = tf.matmul(a, b)

print(c)
```
Output:
Num GPUs Available:  1
tf.Tensor(
[[22. 28.]
 [49. 64.]], shape=(2, 2), dtype=float32)

When I run any  complex algorithm or any pre trained model  ""failed to get convolution error ...."" is generated. 

**Info:**

Tracing
---------------------------------------------------------------------------
UnknownError                              Traceback (most recent call last)
<ipython-input-19-1756cf577d92> in <module>
      1 start = time()
----> 2 dream_img = run_deep_dream_simple(img=original_img, steps=100, step_size=0.01)
      3 print(time()-start)

<ipython-input-17-193f882b4182> in run_deep_dream_simple(img, steps, step_size)
     14     step += run_steps
     15 
---> 16     loss, img = deepdream(img, run_steps, tf.constant(step_size))
     17 
     18     display.clear_output(wait=True)

~\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\python\eager\def_function.py in __call__(self, *args, **kwds)
    566         xla_context.Exit()
    567     else:
--> 568       result = self._call(*args, **kwds)
    569 
    570     if tracing_count == self._get_tracing_count():

~\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\python\eager\def_function.py in _call(self, *args, **kwds)
    636               *args, **kwds)
    637       # If we did not create any variables the trace we have is good enough.
--> 638       return self._concrete_stateful_fn._filtered_call(canon_args, canon_kwds)  # pylint: disable=protected-access
    639 
    640     def fn_with_cond(*inner_args, **inner_kwds):

~\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\python\eager\function.py in _filtered_call(self, args, kwargs)
   1609          if isinstance(t, (ops.Tensor,
   1610                            resource_variable_ops.BaseResourceVariable))),
-> 1611         self.captured_inputs)
   1612 
   1613   def _call_flat(self, args, captured_inputs, cancellation_manager=None):

~\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\python\eager\function.py in _call_flat(self, args, captured_inputs, cancellation_manager)
   1690       # No tape is watching; skip to running the function.
   1691       return self._build_call_outputs(self._inference_function.call(
-> 1692           ctx, args, cancellation_manager=cancellation_manager))
   1693     forward_backward = self._select_forward_and_backward_functions(
   1694         args,

~\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\python\eager\function.py in call(self, ctx, args, cancellation_manager)
    543               inputs=args,
    544               attrs=(""executor_type"", executor_type, ""config_proto"", config),
--> 545               ctx=ctx)
    546         else:
    547           outputs = execute.execute_with_cancellation(

~\AppData\Roaming\Python\Python37\site-packages\tensorflow_core\python\eager\execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)
     65     else:
     66       message = e.message
---> 67     six.raise_from(core._status_to_exception(e.code, message), None)
     68   except TypeError as e:
     69     keras_symbolic_tensors = [

~\AppData\Roaming\Python\Python37\site-packages\six.py in raise_from(value, from_value)

UnknownError:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.
	 [[{{node while/body/_1/model/conv2d/Conv2D}}]] [Op:__inference___call___12702]

Function call stack:
__call__"
36366,Discrepancy in training step accuracy with Tensorflow 2.1,"tag:Bug/Performance Issue</em>

**Describe the current behavior**
1. I followed each and every step from the tensorflow documentation but still there is discrepancy coming in training step accuracy 
2. Training and validation accuracy is far too different though same dataset is used for training and validation

**Describe the expected behavior**
1. Training accuracy should not come that different from the validation accuracy
2. model.fit and model.evaluate accuracy should be nearly same 
**Code to reproduce the issue**
I have attached the link to my google colab notebook: 
[Google Colab Link](https://colab.research.google.com/drive/1Ir8LhIrYB-UexygQKIFuNwRkmb6yJh-w)
<img width=""1095"" alt=""Screenshot 2020-01-31 at 3 48 50 PM"" src=""https://user-images.githubusercontent.com/11526652/73531945-931dfb00-4441-11ea-8401-0cca6ea79142.png"">
"
36363,Different behavior tf.keras and Keras for `stateful=True` ,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): All platforms (tested on Ubuntu 18.04 and macOS)
- TensorFlow installed from (source or binary): pip
- TensorFlow version (use command below): 2.1
- Python version: 3.8

**Describe the current behavior**
The original Keras API specifies that, when an LSTM is set `stateful=True`, it's batch size *must* be known beforehand (by specifying `batch_shape`). The same is true for `tf.keras`, but it adds another hidden requirement that was not there in the original Keras: tf.keras requires that the full input shape (including batch size) is known. If one of the dimensions is `None`, it emits the ""If a RNN is stateful, it needs to know its batch size."" error.

**Describe the expected behavior**
As with the Keras API, it should be allowed to have `None` dimensions besides the `batch_size`.

**Code to reproduce the issue**
Keras:

```
from keras.models import Model
from keras.layers import Input, LSTM, Reshape

def model():
    input_layer = Input(batch_shape=(1, None))
    reshape_layer = Reshape((1, 100))(input_layer)
    lstm_layer = LSTM(units=100, stateful=True)(reshape_layer)
    return Model(inputs=input_layer, outputs=lstm_layer)

model = model()

# Code runs perfectly fine.
```

tf.keras:

```
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, LSTM, Reshape

def model():
    input_layer = Input(batch_shape=(1, None))
    reshape_layer = Reshape((1, 100))(input_layer)
    lstm_layer = LSTM(units=100, stateful=True)(reshape_layer)
    return Model(inputs=input_layer, outputs=lstm_layer)

model = model()

""""""
ValueError: If a RNN is stateful, it needs to know its batch size. Specify the batch size of your input tensors: 
- If using a Sequential model, specify the batch size by passing a `batch_input_shape` argument to your first layer.
- If using the functional API, specify the batch size by passing a `batch_shape` argument to your Input layer.
""""""

```

There are some very legitimate use cases for allowing non-batch dimensions to be unknown! This change in functionality prevents me from migrating a (variable) multi-stream CNN model from Keras to tf.keras."
36362,load_weights fails for custom models,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04 LTS
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): Tensorflow 2.0
- Python version: 3.7.6
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: CPU 
- GPU model and memory:  CPU with 256GB RAM

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
I created a simple custom model. Training runs fine and saving to hdf5 is also fine. When leading it back. I get the error
You are trying to load a weight file containing 3 layers into a model with 0 layers

**Describe the expected behavior**
The weights need to be loaded correctly

**Code to reproduce the issue**

import tensorflow as tf
from random import seed
from random import random

seed(1)
class SqDataset:
    def __init__(self):
        pass
    def generate(self):
        for i in range(1000):
            value = random()
            value = value * 2.0 - 1.0
            yield ({'x':value}, value*value)

dat = SqDataset()

datGen = tf.data.Dataset.from_generator(dat.generate, ({'x':tf.float32}, tf.float32), ({'x':tf.TensorShape([])}, tf.TensorShape([])))
datGen = datGen.batch(10)

class SquareWave(tf.keras.Model):
    def __init__(self):
        super(SquareWave, self).__init__()
        self.dense1 = tf.keras.layers.Dense(5, activation=tf.nn.tanh, name='sqdense1', input_shape=(1,))
        self.dense2 = tf.keras.layers.Dense(5, activation=tf.nn.tanh, name='sqdense2')
        self.dense3 = tf.keras.layers.Dense(1, activation=tf.nn.tanh, name='sqdense3')
        

    def call(self, inputs, training=False):
        ips = inputs['x']
        o = self.dense1(ips)
        o = self.dense2(o)
        o = self.dense3(o)
        return o



modelName = 'weights.h5'
if modelName != None:
    sqMode = SquareWave()
    sqMode.compile(optimizer=tf.keras.optimizers.RMSprop(), 
                   loss=tf.keras.losses.MeanSquaredError())
    sqMode.load_weights(modelName) #fails always
    
else:
    sqMode = SquareWave()
    sqMode.compile(optimizer=tf.keras.optimizers.RMSprop(), 
                   loss=tf.keras.losses.MeanSquaredError())
sqMode.fit(datGen, workers=0, epochs=100, use_multiprocessing=False)       

sqMode.save_weights('weights.h5', save_format='h5')

**Other info / logs**
The set of trainable_variables and trainable_weights is empty during the loading of model because the build methods are not called on the layers. This results in an error"
36361,tf.function using higher GPU memory than normal python function,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04.5
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.1.0
- Python version: (3, 5, 2, 'final', 0)
- CUDA/cuDNN version: 10.0
- GPU model and memory: Tesla V100-PCIE-16GB

**Describe the current behavior**
I am running a simple LSTM model inside a function decorated with tf.function but it's consuming much higher GPU memory (around 8700MB) as compared to a function which isn't decorated with tf.function (which consumes around 2600MB).

**Describe the expected behavior**
Both methods should consume similar amount of GPU memory.

**Code to reproduce the issue**
```
import sys
import tensorflow as tf
tf.debugging.set_log_device_placement(True)

#GPU growth code
gpus = tf.config.experimental.list_physical_devices('GPU')
if gpus:
  try:
    # Currently, memory growth needs to be the same across GPUs
    for gpu in gpus:
      tf.config.experimental.set_memory_growth(gpu, True)
    logical_gpus = tf.config.experimental.list_logical_devices('GPU')
    print(len(gpus), ""Physical GPUs,"", len(logical_gpus), ""Logical GPUs"")
  except RuntimeError as e:
    # Memory growth must be set before GPUs have been initialized
    print(e)

#---------------PARAMS------------
batch_size = 32
max_out_len = 200
num_hidden = 400
num_classes = 73
max_time_steps = 900
num_features = 240
#---------------------------------

class Model(tf.keras.Model):
    def __init__(self):
        super(Model, self).__init__()

        self.forward_cell = [
            tf.keras.layers.LSTMCell(num_hidden, kernel_initializer='glorot_uniform')]
        self.state = tf.keras.layers.RNN(self.forward_cell, time_major=False, return_sequences=True)
        self.dense = tf.keras.layers.Dense(num_classes, use_bias=True, kernel_initializer=tf.initializers.TruncatedNormal(mean=0, stddev=0.1))

    def call(self, inputs):
        x, seq_len = inputs
        mask = tf.sequence_mask(seq_len, maxlen=max_time_steps)
        state = self.state(inputs=x, mask=mask)
        logits = self.dense(state)
        return logits

x = tf.random.normal(shape=(2, batch_size, max_time_steps, num_features))
seq_len = tf.constant([[5]*batch_size,[7]*batch_size])
y_i = [tf.constant(sum([[[i,0],[i,1],[i,2]] for i in range(batch_size)], [])),tf.constant(sum([[[i,0],[i,2],[i,4]] for i in range(batch_size)], []))]
y_v = [tf.constant([1,2,4]*batch_size),tf.constant([5,1,2]*batch_size)]
v = [tf.constant([1,0]*(batch_size//2)),tf.constant([0,1]*(batch_size//2))]
def fn():
    for i in range(2):
        yield x[i], seq_len[i], y_i[i], y_v[i], v[i]

def loss(logits, s, yi, yv):
    y = tf.SparseTensor(yi, yv, tf.TensorShape([batch_size, max_out_len]))
    return tf.cast(tf.sparse.reduce_sum(y, axis=-1), tf.float32) - tf.reduce_sum(logits, axis=[-1, -2])


with tf.device('/cpu:0'):
    model = Model()
    model.build([(batch_size, max_time_steps, num_features), (batch_size,)])
    dataset = tf.data.Dataset.from_generator(fn, output_types=(tf.float32, tf.int32, tf.int64, tf.int32, tf.float32))

def run_eager(x, s, yi, yv, v):
    with tf.device('/gpu:0'):
        with tf.GradientTape() as tape:
            logits = model([x, s])
            losses = tf.reduce_sum(loss(logits, s, yi, yv))
        grads = tape.gradient(losses, model.trainable_variables)

    # ToDo: call optimizer.apply_gradients

    return losses

if len(sys.argv) > 1 and sys.argv[1] == 'func':
    run = tf.function(run_eager)
else:
    run = run_eager

with tf.device('/cpu:0'):
    it = iter(dataset)
    l = run(*next(it))

print(l)
```
"
36360,Parallel Write TFRecords Shards,"**System information**
- TensorFlow version (you are using): TF2.0
- Are you willing to contribute it (Yes/No): No

I have a `tf.data.Dataset` that reads raw image and annotations files and shards them. However, using `tf.data.experimental.TFRecordWriter` writes sequentially and is currently very slow.

```
dataset = tf.data.Dataset.....
for i in range(num_shards):
    write_path = ....
    tfrecords_writer = tf.data.experimental.TFRecordWriter(
        filename=write_path,
        compression_type=compression_type
    )
    dataset_shard = dataset.shard(num_shards, shard_index)

    start_write_time = time.time()
```

I would like to be able to write the shards in parallel to reduce the write time by opening up multiple processes that process each shard individually.

I've tried using a `multiprocessing.Process` and starting a bunch of processes that way, but it doesn't seem to speed up writing."
36359,[Bug] embedding_lookup_sparse divide by zero when use mean combiner,"I come across this issue with TF==1.14.
I found this bug was fixed in this PR: https://github.com/tensorflow/tensorflow/pull/21757.
However, when I checked the implementations in 1.13, 1.14 and 1.15 I found all of them implemented as following:

```
elif combiner == ""mean"":
        embeddings = math_ops.segment_sum(embeddings, segment_ids)
        weight_sum = math_ops.segment_sum(weights, segment_ids)
        embeddings = math_ops.div(embeddings, weight_sum, name=name)
```

Should this be fixed with `math_ops. div_no_nan ` ?

"
36358,TypeError: '>' not supported between instances of 'Nonetype' and 'float',"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**  
- OS Platform and Distribution: Windows 10 1909  
- TensorFlow version: 2.1.0  
- Python version: 3.6.10  
- CUDA/cuDNN version: 10.1/7.6.5  
- GPU model and memory: GTX 1660Ti 6GB/32GB  

        import tensorflow as tf
        ACCURACY_THRESHOLD = 0.95

        class myCallback(tf.keras.callbacks.Callback):
	    def on_epoch_end(self, epoch, logs={}):
	        if(logs.get('acc') > ACCURACY_THRESHOLD):
		    print(""\nReached %2.2f%% accuracy, so stopping training!!"" %(ACCURACY_THRESHOLD*100))
		    self.model.stop_training = True

        callbacks = myCallback()

        mnist = tf.keras.datasets.fashion_mnist
        (x_train, y_train),(x_test, y_test) = mnist.load_data()
        # Scale data
        x_train, x_test = x_train / 255.0, x_test / 255.0

        model = tf.keras.models.Sequential([
        tf.keras.layers.Flatten(input_shape=(28, 28)),
        tf.keras.layers.Dense(512, activation=tf.nn.relu),
        tf.keras.layers.Dense(10, activation=tf.nn.softmax)
        ])

        model.compile(optimizer='adam', \
				loss='sparse_categorical_crossentropy', \
				metrics=['accuracy'])

        model.fit(x_train, y_train, epochs=20, callbacks=[callbacks])  

when I ran this algorithm I got error saying this:

![1](https://user-images.githubusercontent.com/44919399/73509681-fbe78200-4405-11ea-9dde-c9fe07b1f9da.jpg)

Briefly it says that logs.get('acc') is Nonetype and 0.99 is float so, '>' this cannot compare. How to solve it?
"
36349,Keras Layer With Trainable=False Flag Creates Variables With Trainable=True,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): 
System Version: macOS 10.15.2 (19C57)
Kernel Version: Darwin 19.2.0
- TensorFlow installed from (source or binary): binary (pip)
- TensorFlow version (use command below): v1.15.0-rc3-22-g590d6eef7e 1.15.0
- Python version: 3.7.0 

**Describe the current behavior**
When I create a Keras model using layerwise structure in tf.keras.Model, and set one or more of the layers to `trainable=False`, this results in a situation where the keras model believes those variables/parameters to be non-trainable (and reports them as such in `model.non_trainable_variables` and `model.summary`) but doesn't set the actual `trainable` flag on the created Tensorflow variables to be False. This can lead to unintuitive behavior if other systems are reasonably expecting `var_obj.trainable` to correspond with the model's actual trainable variables. 

**Describe the expected behavior**
When a layer is set to `trainable=False`, Tensorflow variables associated with that layer also have the trainable flag set to False 

**Code to reproduce the issue**
```import tensorflow as tf
inputs = tf.keras.layers.Input(shape=(10,))
hiddens = tf.keras.layers.Dense(15,  trainable=True, name=""trainable_layer"")(inputs)
output = tf.keras.layers.Dense(5, trainable=False, name=""nontrainable_layer"")(hiddens)
model = tf.keras.Model(inputs, output)
model.compile(optimizer='rmsprop', loss='categorical_crossentropy')
print(f""Model trainable variables: {model.trainable_variables}"")
print(f""Model non-trainable variables: {model.non_trainable_variables}"")
print(f""Trainable flags on model non-trainable variables: {[v.trainable for v in model.non_trainable_variables]}"")
```
 "
36348,Keras model.train() should automatically run table initializers.,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):  Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Centos 7, OS X 10.15
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 1.15 and 2.1
- Python version: 2.7 and 3.6
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A

**Describe the current behavior**
We have Keras layers that use HashTables (e.g. `tf.lookup.StaticHashTable`), and these tables use initializers such as `tf.lookup.KeyValueTensorInitializer`.  When we perform model training using `model.train()` in **non-eager mode**, it does not run these table initializers and hence causes the training to crash.  Currently, we work around the issue with an ugly hack like this, by saving a reference to the initializer and running it manually. 
```
    if not tf.executing_eagerly():
      tf1.keras.backend.get_session().run(self.table._init_op)
```

**Describe the expected behavior**
Calling model.train() should initialize all initializers, including hash table initializers such as `tf.lookup.KeyValueTensorInitializer`.

**Code to reproduce the issue**
Any Keras layer using StaticHashTable would repro the problem. See
https://gist.github.com/yzhuang/0744b487c7a5ab1b65a5b152a06cda7c#file-keraslayertableinitialization-ipynb

**Suggestions**
My suggestion is to support HashTable initialization or publish documentation / guidance on how to use HashTable with Keras Layers.

Thanks! 🙏 "
36347,Official release of tensorflow==1.15.2 does not include GPU support,"**System information**
- OS Platform and Distribution: Linux
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): [binary](https://pypi.org/project/tensorflow/1.15.2/#files)
- TensorFlow version: 1.15.2
- Python version: python2, python3.6
- Installed using virtualenv? pip? conda?: pip


**Describe the problem**

As [announced](https://groups.google.com/a/tensorflow.org/forum/#!topic/developers/iRCt5m4qUz0) Tensorflow 1.15 contained GPU support by default. Tensorflow 1.15.2 no longer has GPU support.
"
36346,"FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.   np_resource = np.dtype([(""resource"", np.ubyte, 1)])",I am receiving this future warning message after compiling my code. I am following this gentleman's video https://www.youtube.com/watch?v=6g4O5UOH304 online. I don't know what kind of complications it might give me further along as we go through the video. Is this something to worry about?
36345,How can I repeat the generator?,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Window 10
- TensorFlow version (use command below): 2.1
- Python version: 3.7.0

This is my custom generator code as follows:




```import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator

class DataGenerator(tf.keras.utils.Sequence):
    def __init__(self, df, batch_size = 32, target_size = (112, 112), shuffle = True):
        self.len_df = len(df)
        self.batch_size = batch_size
        self.target_size = target_size
        self.shuffle = shuffle
        self.class_col = ['black', 'blue', 'brown', 'green', 'red', 'white', 
             'dress', 'shirt', 'pants', 'shorts', 'shoes']
        self.generator = ImageDataGenerator(rescale = 1./255)
        self.df_generator = self.generator.flow_from_dataframe(dataframe=df, 
                                                          directory='',
                                                            x_col = 'image',
                                                            y_col = self.class_col,
                                                            target_size = self.target_size,
                                                            color_mode='rgb',
                                                            class_mode='other',
                                                            batch_size=self.batch_size,
                                                            seed=42)
        self.colors_df = df['color']
        self.on_epoch_end()
      
    def __len__(self):
        return int(np.floor(self.len_df) / self.batch_size)
    
    def on_epoch_end(self):
        self.indexes = np.arange(self.len_df)
        if self.shuffle:
            np.random.shuffle(self.indexes)
        
    def __getitem__(self, index):
        indexes = self.indexes[index * self.batch_size : (index + 1) * self.batch_size]
        colors = self.__data_generation(indexes)
        
        images, labels = self.df_generator.__getitem__(index)
        
        # return multi-input and output
        return [images, colors], labels
    
    def __data_generation(self, indexes):
        colors = self.colors_df[indexes]
        
        return colors
```

But, it doesn't repeat in fit() with this warning message!
![image](https://user-images.githubusercontent.com/33315343/73481608-836dca80-43df-11ea-8e5a-00e01e82cd87.png)
"
36344,Allow tf.estimator.Estimators to use CuDNN layers,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
N/A
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
N/A
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
N/A
- TensorFlow installed from (source or binary):
source
- TensorFlow version (use command below):
2.0+
- Python version:
3.7
- Bazel version (if compiling from source):
N/A
- GCC/Compiler version (if compiling from source):
N/A
- CUDA/cuDNN version:
N/A
- GPU model and memory:
N/A

**Describe the current behavior**

tf.estimator.Estimators cannot use CuDNN layers

**Describe the expected behavior**

tf.estimator.Estimators implement CuDNN optimized layers

**Code to reproduce the issue**
N/A

**Other info / logs**

Custom `tf.estimator.Estimators`, those that implement a user defined `model_fn`, will not allow for the utilization of CuDNN layers -- like the layers found in `tf.keras.layers.LSTM`

The TensorFlow 2.0 documents state, [""Calling methods of Estimator will work while eager execution is enabled. However, the model_fn and input_fn is not executed eagerly, Estimator will switch to graph mode before calling all user-provided functions (incl. hooks), so their code has to be compatible with graph mode execution. Note that input_fn code using tf.data generally works in both graph and eager modes.""](https://www.tensorflow.org/api_docs/python/tf/estimator/Estimator#eager_compatibility)

Thereby, if a user tries to use CuDNN optimized layers, `ops.executing_eagerly_outside_functions()` will never trigger while the layer is being initialized. 

https://github.com/tensorflow/tensorflow/blob/cf7fcf164c9846502b21cebb7d3d5ccf6cb626e8/tensorflow/python/keras/layers/recurrent_v2.py#L366

It would be great to use CuDNN layers with custom estimators, or even with the prebuilt `tf.estimator.RNNEstimator` class. 

As a temporary workaround, I force the ```self.could_use_cudnn``` to True after initialization and proceed to build the estimator with CuDNN layers. (Ensuring that all other parameters are rationalized) However, I get the below warning:

> [1,0]<stderr>:2020-01-30 17:39:33.939905: W tensorflow/core/grappler/optimizers/implementation_selector.cc:310] Skipping optimization due to error while loading function libraries: Invalid argument: Functions '__inference___backward_standard_lstm_6654_7125' and '__inference___backward_cudnn_lstm_with_fallback_6109_6289_specialized_for_training_gradients_lstm_StatefulPartitionedCall_grad_StatefulPartitionedCall_at_tf_graph' both implement 'lstm_b42b1bb1-dad6-4430-b5f1-d964cdf2b5a3' but their signatures do not match.

Aside from the warning report, this works as expected. 
"
36343,bazel test command broken because of Missing ROCM input files.,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04 tensorflow/tensorflow:devel-py3 container
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): source
- TensorFlow version: commit ID 720b16121ea60d914f2d3df47e580e7e1e5542ae or latest master
- Python version: Python 3.6.9
- Installed using virtualenv? pip? conda?: Not installsed
- Bazel version (if compiling from source): 1.2.1
- GCC/Compiler version (if compiling from source): gcc (Ubuntu 7.4.0-1ubuntu1~18.04.1) 7.4.0
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A



**Describe the problem** 
Unable to complete bazel test command because of missing rocm input files. 

```
[eigen.log.zip](https://github.com/tensorflow/tensorflow/files/4135491/eigen.log.zip)

ERROR: missing input file '@local_config_rocm//rocm:rocm/include/hipcub/hipcub_version.hpp'
ERROR: missing input file '@local_config_rocm//rocm:rocm/include/rocprim/rocprim_version.hpp'
ERROR: /root/.cache/bazel/_bazel_root/104a68818e52204e40c368960e574528/external/local_config_rocm/rocm/BUILD:119:1: @local_config_rocm//rocm:rocprim: missing input file '@local_config_rocm//rocm:rocm/include/hipcub/hipcub_version.hpp'
ERROR: /root/.cache/bazel/_bazel_root/104a68818e52204e40c368960e574528/external/local_config_rocm/rocm/BUILD:119:1: @local_config_rocm//rocm:rocprim: missing input file '@local_config_rocm//rocm:rocm/include/rocprim/rocprim_version.hpp'
ERROR: /host/tensorflow/tensorflow/python/kernel_tests/BUILD:1222:1: Creating runfiles tree bazel-out/k8-opt/bin/tensorflow/python/kernel_tests/summary_v1_ops_test.runfiles failed: build-runfiles failed: error executing command 
  (cd /root/.cache/bazel/_bazel_root/104a68818e52204e40c368960e574528/execroot/org_tensorflow && \
  exec env - \
    PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \
    PYTHON_BIN_PATH=/usr/local/bin/python \
    PYTHON_LIB_PATH=/usr/local/lib/python3.6/dist-packages \
    TF2_BEHAVIOR=1 \
    TF_CONFIGURE_IOS=0 \
    TF_ENABLE_XLA=1 \
  /root/.cache/bazel/_bazel_root/install/84defa6eb1e9416bf92d6f89ab2d4f31/build-runfiles bazel-out/k8-opt/bin/tensorflow/python/kernel_tests/summary_v1_ops_test.runfiles_manifest bazel-out/k8-opt/bin/tensorflow/python/kernel_tests/summary_v1_ops_test.runfiles): Process terminated by signal 15: Process terminated by signal 15
ERROR: /root/.cache/bazel/_bazel_root/104a68818e52204e40c368960e574528/external/local_config_rocm/rocm/BUILD:119:1 2 input file(s) do not exist```

These files do not exist in the bazel cache.


**Provide the exact sequence of commands / steps that you executed before running into the problem**

```$ docker pull tensorflow/tensorflow:devel-py3
$ git clone https://github.com/tensorflow/tensorflow
$ docker run -ti --rm -v $(pwd):/host tensorflow/tensorflow:devel-py3
# cd /host/tensorflow
# yes """" | python configure.py
# bazel --nosystem_rc --nohome_rc test --cxxopt=-D_GLIBCXX_USE_CXX11_ABI=0 --copt=-march=haswell --copt=-mtune=broadwell --copt=-O3 --copt=-Wformat --copt=-Wformat-security --copt=-fstack-protector --copt=-fPIC --copt=-fpic --linkopt=-znoexecstack --linkopt=-zrelro --linkopt=-znow --linkopt=-fstack-protector --config=v2 --test_timeout 300,450,1200,3600 --test_env=KMP_BLOCKTIME=0 -s --cache_test_results=no --test_size_filters=small,medium,large,enormous -c opt -- //tensorflow/... -//tensorflow/compiler/... -//tensorflow/lite/... -//tensorflow/stream_executor/cuda/... -//tensorflow/python/autograph/pyct/... -//tensorflow/core/kernels:eigen_mkldnn_contraction_kernel_test```

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

log file attached
"
36340,"100-line Tensorflow code and Keras equivalent do not produce the same result, Tensorflow result does not converge, why?","I am doing experiments with a basic GAN, the code of which is provided for both TF (I use version 1.15.2, using TF 2.x-style API) and Keras (2.2.5), below.
The GAN learns to generate 2D points fitting a 2D curve, f(x) = x^2. Every point is considered as a 2D vector 'individual', (x,y).

The following 2 python programs compile and run out-of-the-box, and are meant to produce exactly the same result. However, the TF version **does not converge properly at all**.

I tried everything I could to understand what's going wrong, to no avail. Obviously, there is something that I miss.

The TF version is largely inspired from the official GAN tutorial located here: https://www.tensorflow.org/tutorials/generative/dcgan

I also provide the code in 2 pastebin links (for your convenience):

Keras version: https://pastebin.com/N26e3hWh
Tensorflow version: https://pastebin.com/9ebmSyJB

Keras version:

```
import numpy as np
from numpy import hstack
from numpy import zeros
from numpy import ones
from numpy.random import rand
from numpy.random import randn
from keras.models import Sequential
from keras.layers import Dense
import keras.backend as K
from matplotlib import pyplot

class GanPointGraph_Keras(object):
    
    def __init__(self):
        self.latent_dim = 5
        self.discriminator = self.define_discriminator()
        self.generator = self.define_generator(self.latent_dim)
        self.gan_model = self.define_gan(self.generator, self.discriminator)

    def define_discriminator(self, n_inputs=2):
        model = Sequential()
        model.add(Dense(25, activation='relu', kernel_initializer='he_uniform', input_dim=n_inputs))
        model.add(Dense(1, activation='sigmoid'))
        model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
        print(K.eval(model.optimizer.lr))
        return model
    
    def define_generator(self, latent_dim, n_outputs=2):
        model = Sequential()
        model.add(Dense(15, activation='relu', kernel_initializer='he_uniform', input_dim=latent_dim))
        model.add(Dense(n_outputs, activation='linear'))
        return model
    
    def define_gan(self, generator, discriminator):
        discriminator.trainable = False
        model = Sequential()
        model.add(generator)
        model.add(discriminator)
        model.compile(loss='binary_crossentropy', optimizer='adam')
        return model
    
    def generate_latent_points(self, n):
        x_input = randn(self.latent_dim * n)
        x_input = x_input.reshape(n, self.latent_dim)
        return x_input
    
    def generate_fake_samples(self, n):
        x_input = self.generate_latent_points(n)
        X = self.generator.predict(x_input)
        return X

    def generate_real_samples(self, n):
        X1 = rand(n) - 0.5
        X2 = X1 * X1
        X1 = X1.reshape(n, 1)
        X2 = X2.reshape(n, 1)
        X = hstack((X1, X2))    
        return X
    
    def train(self):
        n_batch = 128
        half_batch = int(n_batch / 2)
        x_real = self.generate_real_samples(half_batch)
        y_real = ones((half_batch, 1))
        x_fake = self.generate_fake_samples(half_batch)
        y_fake = zeros((half_batch, 1))
        self.discriminator.train_on_batch(x_real, y_real)
        self.discriminator.train_on_batch(x_fake, y_fake)
        x_gan = self.generate_latent_points(n_batch)
        y_gan = ones((n_batch, 1))
        self.gan_model.train_on_batch(x_gan, y_gan)

if __name__ == ""__main__"":
    g = GanPointGraph_Keras();

    for epoch in range(10000):
        print('Epoch', epoch)
        g.train()
        if epoch % 1000 == 0:
            g_objects = g.generate_fake_samples(100)
            r_objects = g.generate_real_samples(100)
 
            pyplot.clf()
            pyplot.title('Keras iteration ' + str(epoch))
            pyplot.scatter([i[0] for i in r_objects], [i[1] for i in r_objects], c='black')
            pyplot.scatter([i[0] for i in g_objects], [i[1] for i in g_objects], c='red')
            pyplot.show()
```

Tensorflow version:

```
import tensorflow as tf
tf.enable_eager_execution() # if using TF 1.15.x
from tensorflow.keras import layers

import numpy as np
from numpy.random import rand
from numpy import hstack

from matplotlib import pyplot

class GanPointGraph(object):

    def __init__(self):
        self.latent_dim = 5
        self.generator = self.make_generator()
        self.discriminator = self.make_discriminator()
        
        self.cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)        
        self.generator_optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)
        self.discriminator_optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)
        
    def make_generator(self):
        model = tf.keras.Sequential()
        model.add(layers.Dense(15, activation='relu', input_dim=self.latent_dim))
        model.add(layers.Dense(2))
        return model
      
    def make_discriminator(self):
        model = tf.keras.Sequential()
        model.add(layers.Dense(25, activation='relu', input_dim=2))
        model.add(layers.Dense(1, activation='sigmoid')) # (-infinity, infinity) -> (0, 1)
        return model
    
    def generator_loss(self, fake_output):
        #return self.cross_entropy(tf.ones_like(fake_output), fake_output)
        return tf.reduce_mean(tf.math.log(1-fake_output))

    def discriminator_loss(self, real_output, fake_output):
        #real_loss = self.cross_entropy(tf.ones_like(real_output), real_output)
        #fake_loss = self.cross_entropy(tf.zeros_like(fake_output), fake_output)
        #total_loss = real_loss + fake_loss
        #return total_loss
        loss_real = tf.reduce_mean(-tf.math.log(real_output))
        loss_fake = tf.reduce_mean(-tf.math.log(1-fake_output))
        D_loss = loss_real + loss_fake
        return D_loss

    def generate_real_samples(self, n):
        X1 = rand(n) - 0.5
        X2 = X1 * X1
        X1 = X1.reshape(n, 1)
        X2 = X2.reshape(n, 1)
        x_train = hstack((X1, X2))
        return x_train
    
    def generate_fake_samples(self, n):
        z_sample = np.random.normal(0, 1.0, size=[n, self.latent_dim]).astype(np.float32)
        return self.generator(z_sample, training=False).numpy()
    
    def train(self):
        images = self.generate_real_samples(128);
        noise = tf.random.normal([images.shape[0], self.latent_dim])
        
        with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:
            generated_images = self.generator(noise, training=True)
            
            real_output = self.discriminator(images, training=True)
            fake_output = self.discriminator(generated_images, training=True)
            
            gen_loss = self.generator_loss(fake_output)
            disc_loss = self.discriminator_loss(real_output, fake_output)
        
        gradients_of_generator = gen_tape.gradient(gen_loss, self.generator.trainable_variables)
        gradients_of_discriminator = disc_tape.gradient(disc_loss, self.discriminator.trainable_variables)
        
        self.generator_optimizer.apply_gradients(zip(gradients_of_generator, self.generator.trainable_variables))
        self.discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, self.discriminator.trainable_variables))
    
if __name__ == ""__main__"":
    g = GanPointGraph();
    
    for epoch in range(10000):
        print('Epoch', epoch)
        g.train()
        if epoch % 1000 == 0:
            g_objects = g.generate_fake_samples(100)
            r_objects = g.generate_real_samples(100)
 
            pyplot.clf()
            pyplot.title('Tensorflow iteration ' + str(epoch))
            pyplot.scatter([i[0] for i in r_objects], [i[1] for i in r_objects], c='black')
            pyplot.scatter([i[0] for i in g_objects], [i[1] for i in g_objects], c='red')
            pyplot.show()
```

If you run the above programs, you will see that the **Keras version converges quite reliably**. The GAN learns to fit the example points quite nicely. Generate points slowly project onto the curve, and come close to it after about 4000 epochs.

The TF version just ""dances around"" the solution, producing quite bad results, even after a high number of epochs. It never really converges. The movement it does is quite funny, navigating on the left, then on the right, and on the left again, and so on. Sometimes, it seems that it starts to fit the curve, but it quickly goes away unfortunately.

What am I doing wrong in Tensorflow? Obviously, there is something that I am missing.

Please note:

- the layers for both versions are the same (initalizers may both be set to 'he_uniform', this does not change the outcome of the test)
- the learning rate is the same (0.001 for both Keras and Tensorflow Adam optimizers)
- I tried with TF 1.15.0 and 1.15.2 runtimes, same result.
- all samples I have tried on my computer seem to work fine.

I am using Windows x64 and Python 3.6.8 (just the regular Python distribution, not Anaconda).

Help would be immensely appreciated as I would like to migrate from Keras to Tensorflow.

Many thanks in advance.
"
36339,"Unable to convert DeeplabV3 - ""xception_65"" frozen graph to TFLite","**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): 18.04
- TensorFlow installed from (source or binary): source
- TensorFlow version (or github SHA if from source): 1.13


**Command used to run the converter or code if you’re using the Python API**

```
#!/bin/bash

set -e
set -x

python3 models/research/deeplab/export_model.py \
  --logtostderr \
  --checkpoint_path=""train/train_res/deeplav_v3_cityscapes_xception65_trunks_DS_AG-30/ckpt/model.ckpt-3000"" \
  --export_path=""train/train_res/deeplav_v3_cityscapes_xception65_trunks_DS_AG-30/frozen_inference_graph.pb"" \
  --model_variant=""xception_65"" \
  --num_classes=2 \
  --atrous_rates=6 \
  --atrous_rates=12 \
  --atrous_rates=18 \
  --output_stride=4 \
  --decoder_output_stride=4 \
  --train_crop_size=312 \
  --train_crop_size=312 \
  --train_batch_size=1 \
  --fine_tune_batch_norm=False \
  --initialize_last_layer=False \
  --last_layers_contain_logits_only=False \
  --quantize_delay_step=0 \
  --dataset=""trunks_seg""                                              

tflite_convert \
  --graph_def_file=""train/train_res/deeplav_v3_cityscapes_xception65_trunks_DS_AG-30/frozen_inference_graph.pb"" \
  --output_file=""train/train_res/deeplav_v3_cityscapes_xception65_trunks_DS_AG-30/frozen_inference_graph.tflite"" \
  --input_format=TENSORFLOW_GRAPHDEF  \
  --output_format=TFLITE \
  --inference_type=QUANTIZED_UINT8 \
  --mean_values=128 \
  --std_dev_values=128 \
  --input_arrays=ImageTensor \
  --output_arrays=SemanticPredictions \
  --input_shapes=1,312,312,3 \
  --allow_custom_ops
```

**The output from the converter invocation**

```
+ python3 models/research/deeplab/export_model.py --logtostderr --checkpoint_path=train/train_res/deeplav_v3_cityscapes_xception65_trunks_DS_AG-30/ckpt/model.ck
pt-3000 --export_path=train/train_res/deeplav_v3_cityscapes_xception65_trunks_DS_AG-30/frozen_inference_graph.pb --model_variant=xception_65 --num_classes=2 --a
trous_rates=6 --atrous_rates=12 --atrous_rates=18 --output_stride=4 --decoder_output_stride=4 --train_crop_size=312 --train_crop_size=312 --train_batch_size=1 -
-fine_tune_batch_norm=False --initialize_last_layer=False --last_layers_contain_logits_only=False --quantize_delay_step=0 --dataset=trunks_seg
INFO:tensorflow:Prepare to export model to: train/train_res/deeplav_v3_cityscapes_xception65_trunks_DS_AG-30/frozen_inference_graph.pb
INFO:tensorflow:Exported model performs single-scale inference.
WARNING:tensorflow:From /home/andre-criis/Source/coral-deeplearning-ros/detect/models/research/deeplab/core/feature_extractor.py:160: to_float (from tensorflow.
python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
WARNING:tensorflow:From /home/andre-criis/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.p
ython.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
WARNING:tensorflow:From /home/andre-criis/.local/lib/python3.6/site-packages/tensorflow/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.pyt
hon.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to check for files with this prefix.
INFO:tensorflow:Restoring parameters from train/train_res/deeplav_v3_cityscapes_xception65_trunks_DS_AG-30/ckpt/model.ckpt-3000
WARNING:tensorflow:From /home/andre-criis/.local/lib/python3.6/site-packages/tensorflow/python/tools/freeze_graph.py:232: convert_variables_to_constants (from t
ensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.compat.v1.graph_util.convert_variables_to_constants
WARNING:tensorflow:From /home/andre-criis/.local/lib/python3.6/site-packages/tensorflow/python/framework/graph_util_impl.py:245: extract_sub_graph (from tensorf
low.python.framework.graph_util_impl) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.compat.v1.graph_util.extract_sub_graph
INFO:tensorflow:Froze 732 variables.
INFO:tensorflow:Converted 732 variables to const ops.
+ tflite_convert --graph_def_file=train/train_res/deeplav_v3_cityscapes_xception65_trunks_DS_AG-30/frozen_inference_graph.pb --output_file=train/train_res/deepl
av_v3_cityscapes_xception65_trunks_DS_AG-30/frozen_inference_graph.tflite --input_format=TENSORFLOW_GRAPHDEF --output_format=TFLITE --inference_type=QUANTIZED_U
INT8 --mean_values=128 --std_dev_values=128 --input_arrays=ImageTensor --output_arrays=SemanticPredictions --input_shapes=1,312,312,3 --allow_custom_ops
Traceback (most recent call last):
  File ""/home/andre-criis/.local/bin/tflite_convert"", line 8, in <module>
    sys.exit(main())
  File ""/home/andre-criis/.local/lib/python3.6/site-packages/tensorflow/lite/python/tflite_convert.py"", line 442, in main
    app.run(main=run_main, argv=sys.argv[:1])
  File ""/home/andre-criis/.local/lib/python3.6/site-packages/tensorflow/python/platform/app.py"", line 125, in run
    _sys.exit(main(argv))
  File ""/home/andre-criis/.local/lib/python3.6/site-packages/tensorflow/lite/python/tflite_convert.py"", line 438, in run_main
    _convert_model(tflite_flags)
  File ""/home/andre-criis/.local/lib/python3.6/site-packages/tensorflow/lite/python/tflite_convert.py"", line 191, in _convert_model
    output_data = converter.convert()
  File ""/home/andre-criis/.local/lib/python3.6/site-packages/tensorflow/lite/python/lite.py"", line 455, in convert
    **converter_kwargs)
  File ""/home/andre-criis/.local/lib/python3.6/site-packages/tensorflow/lite/python/convert.py"", line 442, in toco_convert_impl
    input_data.SerializeToString())
  File ""/home/andre-criis/.local/lib/python3.6/site-packages/tensorflow/lite/python/convert.py"", line 205, in toco_convert_protos
    ""TOCO failed. See console for info.\n%s\n%s\n"" % (stdout, stderr))
tensorflow.lite.python.convert.ConverterError: TOCO failed. See console for info.
2020-01-30 15:30:08.786078: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 1898 operators, 3080 arrays (0 quantized)
2020-01-30 15:30:08.866046: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After Removing unused ops pass 1: 1888 operators, 3061 arrays (0 quantized)
2020-01-30 15:30:08.974668: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 1888 operators, 3061 arrays (0 quantized)
2020-01-30 15:30:09.328460: F tensorflow/lite/toco/graph_transformations/propagate_fixed_sizes.cc:625] Check failed: input_shape.dims().size() == op->size.size() (4 vs. 3)
Aborted (core dumped)
```

**Link to the saved GraphDef**

```
https://drive.google.com/file/d/1Cvb2LDUHlsSYKds0gev2wDWLdSVJZavi/view?usp=sharing
```

Thanks in advance."
36338,not supported in the pynq board from xilinx,"![image](https://user-images.githubusercontent.com/48592314/73463266-f9a00c00-43a2-11ea-80cf-628d6dbe1a69.png)
"
36337,SSD300 on TF 2.0 is unable to train with batch size 32 on GPU with 8GB memory when it should be able to?,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N.A.
- TensorFlow installed from (source or binary): docker pull tensorflow/tensorflow:2.1.0-gpu-py3
- TensorFlow version (use command below): 2.1.0
- Python version: 3.6.9
- Bazel version (if compiling from source): N.A.
- GCC/Compiler version (if compiling from source): N.A.
- CUDA/cuDNN version: 10.1/7.6
- GPU model and memory: GTX 1070 Ti, 8GB

**Describe the current behavior**
It runs out of memory when the code is run.

**Describe the expected behavior**
This (https://github.com/lufficc/SSD) is an alternative code which is written in PyTorch and it is able to run on my 8GB GPU, consuming only 6.8GB with batch size 32. I have ported the code to TF 2.0 and have provided a minimal runnable code below. The code consumes much more memory than 6.8 GB and causes out of memory error. Since TF does not provide any good way to profile GPU memory usage, I am unable to pinpoint the problem. However, I do not see any part of the code that should cause the code to consume much more memory than the PyTorch's version. Is it an inherent TF problem/bug or is there a way to make it consume less memory?

**Code to reproduce the issue**
```

import tensorflow as tf
from tensorflow.keras.layers import Layer, Conv2D, BatchNormalization, ReLU, MaxPool2D, ZeroPadding2D
from tensorflow.keras import Model, Sequential


feature_extractor_config = {
    '300': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'C', 512, 512, 512, 'M',
            512, 512, 512],
    '512': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'C', 512, 512, 512, 'M',
            512, 512, 512],
}

feature_pyramid_config = {
    '300': [256, 'S', 512, 128, 'S', 256, 128, 256, 128, 256],
    '512': [256, 'S', 512, 128, 'S', 256, 128, 'S', 256, 128, 'S', 256],
}

head_config = {
    '300': [4,6,6,6,4,4]
}


def create_feature_extractor(cfg, batch_norm=False):
    layers = []
    in_channels = 3
    for v in cfg:
        if v == 'M':
            layers += [MaxPool2D(pool_size=2, strides=2)]
        elif v == 'C':
            layers += [ZeroPadding2D(padding=((0,1), (0,1))), MaxPool2D(pool_size=2, strides=2)]
        else:
            pad = ZeroPadding2D(1)
            conv2d = Conv2D(v, kernel_size=3)
            if batch_norm:
                layers += [pad, conv2d, BatchNormalization(v), ReLU()]
            else:
                layers += [pad, conv2d, ReLU()]
            in_channels = v
    pad5 = ZeroPadding2D(padding=1)
    pool5 = MaxPool2D(pool_size=3, strides=1)
    pad6 = ZeroPadding2D(padding=6)
    conv6 = Conv2D(1024, kernel_size=3, dilation_rate=6)
    conv7 = Conv2D(1024, kernel_size=1)
    layers += [pad5, pool5, pad6, conv6,
               ReLU(), conv7, ReLU()]
    return layers

def create_feature_pyramid(cfg, size=300):
    layers = []
    # in_channels = i
    flag = False
    for k, v in enumerate(cfg):
        if k==0 or in_channels != 'S':
            if v == 'S':
                layers += [ZeroPadding2D(padding=1), Conv2D(cfg[k + 1], kernel_size=(1, 3)[flag], strides=2)]
            else:
                layers += [Conv2D(v, kernel_size=(1, 3)[flag])]
            flag = not flag
        in_channels = v
    if size == 512:
        layers.append(Conv2D(128, kernel_size=1, strides=1))
        layers.append(ZeroPadding2D(padding=1))
        layers.append(Conv2D(256, kernel_size=4, strides=1))
    return layers

def create_head(cfg, num_classes):
    reg_layers  = []
    cls_layers = []
    for num_bboxes in cfg:
        cls_layers.append(Sequential([ZeroPadding2D(padding=1), Conv2D(num_bboxes * num_classes, kernel_size=3)]))
        reg_layers.append(Sequential([ZeroPadding2D(padding=1), Conv2D(num_bboxes * 4, kernel_size=3)]))
    head = {'reg': reg_layers, 'cls': cls_layers}

    return head

class L2Norm(Layer):
    def __init__(self, in_channels, scale):
        super(L2Norm, self).__init__()
        self.in_channels = in_channels
        self.gamma = scale or None
        self.eps = 1e-10
        self.w = self.add_weight(
            name='w',
            shape=(self.in_channels,),
            initializer=tf.constant_initializer(20),
            trainable=True,
            dtype=self.dtype
        )

    def call(self, x):
        norm = tf.sqrt(tf.reduce_sum(tf.pow(x, 2), axis=3, keepdims=True)) + self.eps
        x = tf.truediv(x, norm)
        out = self.w * x

        return out

class VGG(Model):
    def __init__(self):
        super(VGG, self).__init__()
        self.feature_extractor = create_feature_extractor(feature_extractor_config['300'])
        self.l2_norm = L2Norm(512, scale=20)
        self.feature_pyramid = create_feature_pyramid(feature_pyramid_config['300'], size=300)
        self.num_classes = 21

        self.head = create_head(head_config['300'], self.num_classes)


    def call(self, x):
        n, h, w, c = x.shape
        features = []
        for i in range(34):
            x = self.feature_extractor[i](x)
        s = self.l2_norm(x)

        features.append(s)

        for i in range(34, len(self.feature_extractor)):
            x = self.feature_extractor[i](x)
        features.append(x)

        for k, v in enumerate(self.feature_pyramid):
            x = tf.nn.relu(v(x))
            if k in [2,5,7,9]:
                features.append(x)

        regressions = []
        classifications = []

        for k, v in enumerate(features):
            regressions.append(tf.reshape(self.head['reg'][k](v), [32, -1, 4]))
            classifications.append(tf.reshape(self.head['cls'][k](v), [32, -1, self.num_classes]))

        regressions = tf.concat(regressions, axis=1)
        classifications = tf.concat(classifications, axis=1)

        return [regressions, classifications]
model = VGG()

optimizer = tf.keras.optimizers.Adam()


smooth_l1_loss = tf.keras.losses.Huber(
    delta=1.0, reduction=tf.keras.losses.Reduction.NONE
)

ce_loss = tf.keras.losses.CategoricalCrossentropy(
    from_logits=True, label_smoothing=0, reduction=tf.keras.losses.Reduction.NONE
)

@tf.function
def train_step(input_imgs, target_bboxes, target_labels):
    outputs = model(input_imgs)

    regressions = outputs[0]
    classifications = outputs[1]

    pos_mask = target_labels > 0
    neg_mask = target_labels == 0
    num_pos = tf.reduce_sum(tf.cast(pos_mask, tf.float32))

    predicted_bboxes = regressions[pos_mask]
    target_bboxes = target_bboxes[pos_mask]

    bbox_loss = tf.reduce_sum(smooth_l1_loss(target_bboxes, predicted_bboxes))

    cls_loss = ce_loss(tf.one_hot(tf.cast(target_labels, tf.int32), classifications.shape[2]), classifications)

    pos_cls_loss = cls_loss[pos_mask]
    neg_cls_loss = cls_loss[neg_mask]
    neg_cls_loss = tf.sort(neg_cls_loss, direction=""DESCENDING"")
    neg_cls_loss = neg_cls_loss[: 3 * tf.cast(num_pos, tf.int32)]

    cls_loss = tf.reduce_sum(
        tf.reduce_sum(pos_cls_loss) + tf.reduce_sum(neg_cls_loss)
    )
    loss = bbox_loss + cls_loss
    loss = loss / num_pos

    gradients = tf.gradients(loss, model.trainable_variables)
    optimizer.apply_gradients(zip(gradients, model.trainable_variables))

while True:
    imgs = tf.random.uniform((32, 300, 300, 3), minval=0, maxval=255)
    img_bboxes = tf.random.uniform((32, 8732, 4), minval=0, maxval=1)
    img_labels = tf.random.uniform((32, 8732), minval=0, maxval=21, dtype=tf.int32)
    train_step(imgs, img_bboxes, img_labels)

```



**Other info / logs**

```
2020-01-30 14:48:46.435271: I tensorflow/core/common_runtime/bfc_allocator.cc:962] Sum Total of in-use chunks: 6.86GiB
2020-01-30 14:48:46.435308: I tensorflow/core/common_runtime/bfc_allocator.cc:964] total_region_allocated_bytes_: 7510566400 memory_limit_: 7510566502 available bytes: 102 curr_region_allocation_bytes_: 15021133312
2020-01-30 14:48:46.435336: I tensorflow/core/common_runtime/bfc_allocator.cc:970] Stats:
Limit:                  7510566502
InUse:                  7367076608
MaxInUse:               7509992704
NumAllocs:                    2794
MaxAllocSize:           3335127040

2020-01-30 14:48:46.435424: W tensorflow/core/common_runtime/bfc_allocator.cc:429] ****************************************************************************************************
2020-01-30 14:48:46.435484: W tensorflow/core/framework/op_kernel.cc:1655] OP_REQUIRES failed at slice_op.cc:154 : Resource exhausted: OOM when allocating tensor with shape[32,512,38,38] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
2020-01-30 14:48:46.435548: W tensorflow/core/common_runtime/base_collective_executor.cc:217] BaseCollectiveExecutor::StartAbort Resource exhausted: OOM when allocating tensor with shape[32,512,38,38] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
         [[{{node gradients/vgg/sequential/zero_padding2d_18/Pad_grad/Slice_1}}]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.

Traceback (most recent call last):
  File ""mve.py"", line 327, in <module>
    train_step(imgs, img_bboxes, img_labels)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py"", line 568, in __call__
    result = self._call(*args, **kwds)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py"", line 599, in _call
    return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py"", line 2363, in __call__
    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py"", line 1611, in _filtered_call
    self.captured_inputs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py"", line 1692, in _call_flat
    ctx, args, cancellation_manager=cancellation_manager))
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py"", line 545, in call
    ctx=ctx)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/execute.py"", line 67, in quick_execute
    six.raise_from(core._status_to_exception(e.code, message), None)
  File ""<string>"", line 3, in raise_from
tensorflow.python.framework.errors_impl.ResourceExhaustedError:  OOM when allocating tensor with shape[32,512,38,38] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
         [[node gradients/vgg/sequential/zero_padding2d_18/Pad_grad/Slice_1 (defined at mve.py:304) ]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.
 [Op:__inference_train_step_5034]

Function call stack:
train_step

```

"
36336,Problem with build_rpi_lib.sh,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
PRETTY_NAME=""Raspbian GNU/Linux 9 (stretch)""
NAME=""Raspbian GNU/Linux""
VERSION_ID=""9""
VERSION=""9 (stretch)""
VERSION_CODENAME=stretch
ID=raspbian
ID_LIKE=debian
HOME_URL=""http://www.raspbian.org/""
SUPPORT_URL=""http://www.raspbian.org/RaspbianForums""
BUG_REPORT_URL=""http://www.raspbian.org/RaspbianBugs""

Device - Raspberry Pi 3B
- TensorFlow clonned from git hub:
- GCC/Compiler version (if compiling from source): 6.3.0 20170519

**Describe the problem**

I am following the example to build the raspberry pi version of the Tensorflow Lite C++ library and the build script fails and the pi locks up and requires a hard reset.  There are numerous warnings displayed when the build script runs.  The last warning shown is: .tensorflow/lite/kernels/cpu_backend_gemm_customer_gemv.h:500:13 warning: attributes at the beginning of statement are ignored [-Wattribute] [[clang::fallthrough]];

Any help appreciated





"
36332,Fit method printout is broken in version 2.1 ,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MACOS
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): 2.1.0
- Python version: 3.7.4

** Info **
The out-prints of in the fit method in version 2.0:
<img width=""1440"" alt=""Screen Shot 2020-01-30 at 11 08 16"" src=""https://user-images.githubusercontent.com/38648402/73436454-36441700-4353-11ea-86e1-7ff0023ae0b1.png"">

The out-prints of in the fit method in version 2.1:
<img width=""1440"" alt=""Screen Shot 2020-01-30 at 11 11 07"" src=""https://user-images.githubusercontent.com/38648402/73436538-5d024d80-4353-11ea-8fcb-d40560a2f79d.png"">

Watch the output of the first epoch (the line, not the values), it prints Epcoh1/3 at the end of the line.


"
36331,Got Warning : Disabling AVX support in Mac OSX Catalina,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOSX 10.15.3 (Catalina)
- TensorFlow installed from (source or binary): Source
- TensorFlow version: 2.0
- Python version: 3.7
- Installed using virtualenv? pip? conda?: no
- Bazel version (if compiling from source): 1.2.1
- GCC/Compiler version (if compiling from source): Apple clang version 11.0.0 (clang-1100.0.33.17) 

**Describe the problem**

Hi, I got so many warning when building TensorFlow in Macosx Catalina with AVX2 Enabled, I got warning like this : 

> 1 warning generated.
INFO: From Compiling tensorflow/core/grappler/utils/functions.cc [for host]:
In file included from tensorflow/core/grappler/utils/functions.cc:15:
In file included from ./tensorflow/core/grappler/utils/functions.h:26:
In file included from ./tensorflow/core/framework/function.h:28:
In file included from ./tensorflow/core/framework/attr_value_util.h:23:
In file included from ./tensorflow/core/framework/partial_tensor_shape.h:20:
In file included from ./tensorflow/core/framework/tensor_shape.h:21:
In file included from ./third_party/eigen3/unsupported/Eigen/CXX11/Tensor:1:
In file included from external/eigen_archive/unsupported/Eigen/CXX11/Tensor:14:
In file included from external/eigen_archive/unsupported/Eigen/CXX11/../../../Eigen/Core:22:
external/eigen_archive/unsupported/Eigen/CXX11/../../../Eigen/src/Core/util/ConfigureVectorization.h:300:10: warning: ""Disabling AVX support: clang compiler shipped with XCode 11.[012] generates broken assembly with -macosx-version-min=10.15 and AVX enabled. "" [-W#warnings]
        #warning ""Disabling AVX support: clang compiler shipped with XCode 11.[012] generates broken assembly with -macosx-version-min=10.15 and AVX enabled. ""
         ^
1 warning generated.

Does anyone know what is the root cause of this problem? thank you

**Provide the exact sequence of commands / steps that you executed before running into the problem**

- bazel build --config=opt --config=mkl --copt=-mavx2 //tensorflow/tools/lib_package:libtensorflow

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
36330,How to profile GPU memory usage in TF2.0?,"How to profile GPU memory usage in TF2.0?

Since TF hogs the entire GPU or requires user to pre-allocate a fixed amount GPU memory, I am not able to know what is the exact memory usage. This is a problem when I need to know which part of my code is using too much memory."
36329,OpenBLASS for efficient Matrix multiplications?,"**System information**
- TensorFlow version (you are using): TFLite micro (on ESP32)
- Are you willing to contribute it (Yes/No): Yes



**Describe the feature and the current behaviour/state.**

The major CPU intensive function here are Convolution functions! Which are nothing but Large Matrix multiplications.
For Face detection example on ESP32, I have seen that it is the major contributor at more than 50% of total CPU eaten by example.

[OpenBLASS](https://github.com/xianyi/OpenBLAS) is open implementation of [BLASS](http://www.netlib.org/blas/) library which is optimised version of large Matrix multiplications which takes into account Cache availability of system etc.

Are there any plans to use this in TensorFlow?


**Will this change the current api? How?**

Need to explore this, but it should most likely not affect existing APIs but shall change the implementations of few functions.

**Who will benefit with this feature?**

All the platforms for which OpenBLASS is optimized to including x86 platforms, ARM, MIPS etc.

**Any Other info.**

Links:
http://www.netlib.org/blas/
https://github.com/xianyi/OpenBLAS
"
36328,Error while saving transformer example to SavedModel ,"**System information**
- OS Platform and Distribution : Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:  N/A
- TensorFlow installed from (source or binary): binary
- TensorFlow version: tf-nightly (2.2.0.dev20200123)
- Python version: 3.7.4
- Installed using virtualenv? pip? conda?: pip3
- Bazel version (if compiling from source):  N/A
- GCC/Compiler version (if compiling from source):  N/A
- CUDA/cuDNN version:  N/A
- GPU model and memory: N/A


Hello, 

I am following transformer example:
https://www.tensorflow.org/tutorials/text/transformer


It is working as expected and saving checkpoint as well, and I want to now save this to SavedModel.

Here is my source code (attached as zip):
[transformer.zip](https://github.com/tensorflow/tensorflow/files/4132379/transformer.zip)

or same code in colab:
https://colab.research.google.com/drive/1MMhRMICpzDwpP5OLNTWHfgXaZ20ckqfL

Command to run the code: 
```
python3 transformer.py
```

But I am getting this error: 
```Traceback (most recent call last):
  File ""transformer.py"", line 860, in <module>
    transformer.save(""/tmp/savedmodel"", save_format=""tf"")
  File ""/home/cherry/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py"", line 1029, in save
    signatures, options)
  File ""/home/cherry/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/save.py"", line 138, in save_model
    signatures, options)
  File ""/home/cherry/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/saved_model/save.py"", line 78, in save
    save_lib.save(model, filepath, signatures, options)
  File ""/home/cherry/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/saved_model/save.py"", line 925, in save
    checkpoint_graph_view)
  File ""/home/cherry/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/saved_model/signature_serialization.py"", line 74, in find_function_to_export
    functions = saveable_view.list_functions(saveable_view.root)
  File ""/home/cherry/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/saved_model/save.py"", line 142, in list_functions
    self._serialization_cache)
  File ""/home/cherry/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 2532, in _list_functions_for_serialization
    .list_functions_for_serialization(serialization_cache))
  File ""/home/cherry/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/saved_model/base_serialization.py"", line 91, in list_functions_for_serialization
    fns = self.functions_to_serialize(serialization_cache)
  File ""/home/cherry/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/saved_model/layer_serialization.py"", line 79, in functions_to_serialize
    serialization_cache).functions_to_serialize)
  File ""/home/cherry/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/saved_model/layer_serialization.py"", line 94, in _get_serialized_attributes
    serialization_cache)
  File ""/home/cherry/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/saved_model/model_serialization.py"", line 47, in _get_serialized_attributes_internal
    default_signature = save_impl.default_save_signature(self.obj)
  File ""/home/cherry/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/saved_model/save_impl.py"", line 211, in default_save_signature
    fn.get_concrete_function()
  File ""/home/cherry/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py"", line 948, in get_concrete_function
    concrete = self._get_concrete_function_garbage_collected(*args, **kwargs)
  File ""/home/cherry/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py"", line 854, in _get_concrete_function_garbage_collected
    self._initialize(args, kwargs, add_initializers_to=initializers)
  File ""/home/cherry/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py"", line 500, in _initialize
    *args, **kwds))
  File ""/home/cherry/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py"", line 2440, in _get_concrete_function_internal_garbage_collected
    graph_function, _, _ = self._maybe_define_function(args, kwargs)
  File ""/home/cherry/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py"", line 2771, in _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)
  File ""/home/cherry/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py"", line 2661, in _create_graph_function
    capture_by_value=self._capture_by_value),
  File ""/home/cherry/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py"", line 981, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File ""/home/cherry/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py"", line 439, in wrapped_fn
    return weak_wrapped_fn().__wrapped__(*args, **kwds)
  File ""/home/cherry/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/saving_utils.py"", line 150, in _wrapped_model
    outputs_list = nest.flatten(model(inputs, training=False))
  File ""/home/cherry/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 793, in __call__
    outputs = call_fn(cast_inputs, *args, **kwargs)
  File ""/home/cherry/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/autograph/impl/api.py"", line 308, in wrapper
    return func(*args, **kwargs)
TypeError: call() missing 4 required positional arguments: 'tar', 'enc_padding_mask', 'look_ahead_mask', and 'dec_padding_mask'
```
"
36327,Ability to calculate projected memory usage for a given model,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): 2.1
- Are you willing to contribute it (Yes/No): Yes, but I would likely need assistance/guidance



**Describe the feature and the current behavior/state.**
The closest feature I can find to this is `tf.keras.Model.summary()`. This feature calculate the trainable and non-trainable parameters per-layer but doesn't attempt to calculate any memory usage statistics.

The proposed feature would extend `tf.keras.Model.summary()` by also calculating memory requirements per-layer and for the complete model. If multiple compute devices are used in the model then a per-device memory breakdown would also be useful.

**Will this change the current api? How?**
This could either just add functionality to `tf.keras.Model.summary()` without changing the interface, or it could add extra parameters to `tf.keras.Model.summary()`. Alternatively, a new function could be added, whatever is deemed most appropriate.

**Who will benefit with this feature?**
Anyone with a desire to get an idea about how much memory their model will need for either training or inference. It should be possible for someone to determine whether the model they wish to train/evaluate will fit into RAM (either system of GPU) that they have available.

**Any Other info.**
My focus is on the `tf.keras.Model.summary()` API, but this feature should probably be extended to other means of model creation.
"
36323,This part of code on `self.save_weights_only` is not necessary,"In [tensorflow/tensorflow/python/keras/callbacks.py ](https://github.com/tensorflow/tensorflow/blob/r2.1/tensorflow/python/keras/callbacks.py#L813-L1166), this part of code on `self.save_weights_only` is not necessary:
```
    # Use name matching rather than `isinstance` to avoid circular dependencies.
    if (not self.save_weights_only and
        not model._is_graph_network and  # pylint: disable=protected-access
        model.__class__.__name__ != 'Sequential'):
      self.save_weights_only = True
```
Because when the argument `save_weights_only` is `True`, no matter what the model._is_graph_network is and no matter what model.__class__.__name__ is 'Sequential' or not,  `self.save_weights_only` will always be `True`.

I am not sure if I am right. So, if you disagree with me, please explain it detaily. 
"
36321,The shape of Tensors is UNKNOWN after batching in graph mode. ,"
**System information**
- Have I written custom code: YES
- OS Platform and Distribution: Google Colab
- TensorFlow installed from: Preinstalled in Colab
- TensorFlow version: v2.1.0-0-ge5bf8de410 2.1.0
- Python version: sys.version_info(major=3, minor=6, micro=9, releaselevel='final', serial=0)

**Describe the current behavior**

The shape of tensors is unknown when batching dataset in the graph mode. In the eager mode, the shape is know.

See the colab: https://colab.research.google.com/drive/1jfRaXtJXCgTSav3hvvE1RqUZ4FRyZ8fb

**Describe the expected behavior**

Shape should be known in both eager and graph mode.

**Code to reproduce the issue**

https://colab.research.google.com/drive/1jfRaXtJXCgTSav3hvvE1RqUZ4FRyZ8fb"
36320, How to replace a layer of a compiled Keras' model ,"I'm in tensorflow 1.14
How can I replace a layer in a Keras model? My new layer has a different output size so set_weights doesn't work."
36319,"How do I create multiple custom AUC metrics, one for each of the outputs, in TensorFlow?","**System information**
- Have I written custom code: Yes
- OS Platform and Distribution: macOS Catalina (Version: 10.15.2 (19C57))
- TensorFlow installed from: binary
- TensorFlow version: 2.1
- Python version: 3.7.5
- GPU model and memory: Intel Iris Pro 1536 MB

**Describe the current behavior**

I get several errors, which are all described in [this Stack Overflow question](https://stackoverflow.com/q/59958089/3924118). In particular, I get the following error.

> tensorflow.python.framework.errors_impl.InvalidArgumentError:  assertion failed: [predictions must be >= 0] [Condition x >= y did not hold element-wise:] [x (strided_slice_1:0) = ] [0.590847135 0.745689 0.524460673...] [y (Cast_1/x:0) = ] [0]
	 [[{{node metrics/custom_auc_2/StatefulPartitionedCall/assert_greater_equal/Assert/AssertGuard/else/_79/Assert}}]] [Op:__inference_keras_scratch_graph_1129]


**Describe the expected behavior**

No error.

**Code to reproduce the issue**

```
def get_model(num_inputs, num_outputs):
    from keras.layers import Dense, Input
    from keras.models import Model

    inputs = Input((num_inputs,))
    outputs = Dense(num_outputs)(inputs)
    return Model(inputs, outputs)


def get_custom_auc(output):
    import tensorflow as tf

    # I may also want to use other metrics other than AUC (e.g. BinaryAccuracy).
    auc = tf.metrics.AUC()

    @tf.function
    def custom_auc(y_true, y_pred):
        y_true = y_true[:, output]
        y_pred = y_pred[:, output]
        auc.update_state(y_true, y_pred)
        return auc.result()

    custom_auc.__name__ = ""custom_auc_"" + str(output)
    return custom_auc


def train():
    import numpy as np

    num_inputs = 5
   
    # I want to implement an AUC metric for each of these outputs SEPARATELY.
    num_outputs = 3 

    num_examples = 10

    model = get_model(num_inputs, num_outputs)

    # Create a separate AUC metric for each of the outputs.
    metrics = [get_custom_auc(m) for m in range(num_outputs)]

    # I want to visualize the metrics for each of the outputs (separately) during training.
    model.compile(loss='mse', metrics=metrics, optimizer='adam')

    print(model.metrics)

    # Error occurs when calling fit.
    model.fit(np.random.rand(num_examples, num_inputs), np.zeros((num_examples, num_outputs)))


if __name__ == '__main__':
    train()
```

**Other info / logs**

In [this Stack Overflow question](https://stackoverflow.com/q/59958089/3924118), I am describing my problem and my attempts to solve it. Please, have a look at it. I've tried other solutions, including implementing a custom class for this metric, but I am getting other errors (as described in the question). Ultimately, I just want to solve my problem, while keeping the use of `compile` and `fit` to train the model (as I dislike custom training loops and I want to keep it as simple as possible).
"
36318,installation of CUDA documentation,"Hi, 

Two important lines are missing from the suggested CUDA >=10 installation scripts: 

```
sudo add-apt-repository ppa:graphics-drivers/ppa
sudo add-apt-repository ""deb http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64/ /""
```
"
36314,Empty step_stats from context.export_run_metadata() in TF 2.1,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Google Colab

As sessions are no more available in TF 2 API we are using `context.enable_run_metadata()` and `context.export_run_metadata()` to accure `run_metadata.step_stats` which then we feed to `timeline.Timeliner` to export tracing information about session execution and visualise it usgin chrome://tracing. This approch worked well with TF 2.0 but once we updated to 2.1 `run_metadata.step_stats` appears to be empty.

Here is code which acquires and prints step stats:
TF 2.0: https://colab.research.google.com/drive/1Jsk7Dn_gTd3xCTTxgQPx3bJvza4oRu1t
TF 2.1: https://colab.research.google.com/drive/1JQ7rqyH5VOAmpHbjMuLGYLwU9dJ7xwk2

I know that according to docs we should use `summary.trace_on` or `profiler_client .start_tracing` to acquire tracing information, however, there is seems an issue with GPU tracing https://github.com/tensorflow/tensorflow/issues/34844"
36313,make_tensor_proto for float16 ndarray,"make_tensor_proto works too slow for float16 arrays because dtypes.float16 not in [_TENSOR_CONTENT_TYPES](https://github.com/tensorflow/tensorflow/blob/339b76d4f1e420d070559051403c71c185df1d57/tensorflow/python/framework/tensor_util.py#L237) list. Is there any reason not to add it to the list?
```
In [58]: a = np.ones((7, 400, 400, 12), dtype=np.float16)

In [59]: b = np.ones((7, 400, 400, 12), dtype=np.float32)

In [60]: %timeit make_tensor_proto(a)
1 loop, best of 3: 1.68 s per loop

In [61]: %timeit make_tensor_proto(b)
10 loops, best of 3: 106 ms per loop
```"
36311,"Why tflite model runs on GPU, and multi batch speed is very slow","<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below):
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

**Describe the expected behavior**

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.

**Other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
36310,"Non-OK-status: GpuLaunchKernel( SwapDimension1And2InTensor3UsingTiles<T, NumThreads, TileLongSide, TileShortSide>, ...) Internal: invalid configuration argument when using the tf.keras MaxPooling3D layer","**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes, I have written my own model training script.
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Linux Ubuntu 19.10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: None
- TensorFlow installed from (source or binary): From binary (pip)
- TensorFlow version (use command below): v2.1.0-rc2-17-ge5bf8de (2.1.0)
- Python version: 3.7.5 (pip version 20.0.2)
- Bazel version (if compiling from source): None
- GCC/Compiler version (if compiling from source): None
- CUDA/cuDNN version: CUDA V10.1.243 (10.1), cuDNN 7.6.5.32-1+cuda10.1
- GPU model and memory: 2x Nvidia GeForce GTX 1070 Ti (8GB VRAM each)

**Describe the current behavior**
When using tensorflow's `tensorflow.distribute.MirrorStrategy` to scale a `tf.keras`-based model with the `tf.keras.layers.MaxPooling3D` layer, tensorflow outputs the error: 
`2020-01-29 13:14:07.089464: F ./tensorflow/core/kernels/conv_2d_gpu.h:659] Non-OK-status: GpuLaunchKernel( SwapDimension1And2InTensor3UsingTiles<T, NumThreads, TileLongSide, TileShortSide>, total_tiles_count, NumThreads, 0, d.stream(), input, input_dims, output) status: Internal: invalid configuration argument`, followed by `Aborted (core dumped)` when trying to train the model.
I was able to verify that the MaxPooling3D layer appears to be the issue, because when taking it out of the test script (see ""Code to reproduce the issue""), the issue does not persist.
The same issue also occurs when using the, now deprecated, `tf.keras.utils.multi_gpu_model`.
I am yet unsure whether this is a problem in tensorflow itself or any of the used frameworks.
Please note, that this issue is most likely not related to #30665 or #33696 since they describe an issue related to the internal CUDA kernel `FillPhiloxRandomKernelLaunch<Distribution>` rather than the `SwapDimension1And2InTensor3UsingTiles<T, NumThreads, TileLongSide, TileShortSide>` described here.
I am happy to provide further, more specific information on the used training script or the issue itself, if requested.

**Describe the expected behavior**
The model should train normally and not output any errors, as it does when executed without the distributed scope or when reducing the MirroredStrategy to only use one GPU.

**Code to reproduce the issue**
```python
from tensorflow.keras.models import *
from tensorflow.keras.layers import *
from tensorflow.keras import *
import tensorflow as tf
import numpy as np

strat = tf.distribute.MirroredStrategy(devices=['/gpu:0', '/gpu:1'])

with strat.scope():
    model = Sequential()
    model.add(MaxPooling3D((1, 2, 2), input_shape=(None, 640, 480, 1)))
    model.add(ConvLSTM2D(16, kernel_size=(3,3)))
    model.add(Flatten())
    model.add(Dense(1))
    model.summary()
    model.compile(loss='mean_squared_error', optimizer='adam', metrics=['acc'])

    x = np.random.rand(1, 10, 640, 480, 1)
    y = np.random.rand(1, 1)
    model.fit(x=x, y=y, epochs=10)
```

**Other info / logs**

Full console output:
```
(venv) [REDACTED]@[REDACTED]:[REDACTED]$ python test.py
2020-01-29 13:32:31.798280: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libnvinfer.so.6
2020-01-29 13:32:31.799195: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libnvinfer_plugin.so.6
2020-01-29 13:32:32.130276: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-01-29 13:32:32.168392: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-01-29 13:32:32.168824: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce GTX 1070 Ti computeCapability: 6.1
coreClock: 1.683GHz coreCount: 19 deviceMemorySize: 7.91GiB deviceMemoryBandwidth: 238.66GiB/s
2020-01-29 13:32:32.168866: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-01-29 13:32:32.169410: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 1 with properties: 
pciBusID: 0000:02:00.0 name: GeForce GTX 1070 Ti computeCapability: 6.1
coreClock: 1.683GHz coreCount: 19 deviceMemorySize: 7.93GiB deviceMemoryBandwidth: 238.66GiB/s
2020-01-29 13:32:32.169467: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-01-29 13:32:32.169549: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-01-29 13:32:32.170673: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-01-29 13:32:32.170902: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-01-29 13:32:32.171948: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-01-29 13:32:32.172544: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-01-29 13:32:32.172565: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-01-29 13:32:32.172641: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-01-29 13:32:32.172988: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-01-29 13:32:32.173522: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-01-29 13:32:32.173857: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-01-29 13:32:32.174368: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0, 1
2020-01-29 13:32:32.174654: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-01-29 13:32:32.198716: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3699850000 Hz
2020-01-29 13:32:32.199091: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x47afc50 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-01-29 13:32:32.199105: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-01-29 13:32:32.293103: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-01-29 13:32:32.303707: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-01-29 13:32:32.304142: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4845b80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-01-29 13:32:32.304154: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce GTX 1070 Ti, Compute Capability 6.1
2020-01-29 13:32:32.304159: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): GeForce GTX 1070 Ti, Compute Capability 6.1
2020-01-29 13:32:32.304924: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-01-29 13:32:32.305196: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce GTX 1070 Ti computeCapability: 6.1
coreClock: 1.683GHz coreCount: 19 deviceMemorySize: 7.91GiB deviceMemoryBandwidth: 238.66GiB/s
2020-01-29 13:32:32.305233: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-01-29 13:32:32.305503: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 1 with properties: 
pciBusID: 0000:02:00.0 name: GeForce GTX 1070 Ti computeCapability: 6.1
coreClock: 1.683GHz coreCount: 19 deviceMemorySize: 7.93GiB deviceMemoryBandwidth: 238.66GiB/s
2020-01-29 13:32:32.305520: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-01-29 13:32:32.305527: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-01-29 13:32:32.305535: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-01-29 13:32:32.305543: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-01-29 13:32:32.305551: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-01-29 13:32:32.305558: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-01-29 13:32:32.305565: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-01-29 13:32:32.305593: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-01-29 13:32:32.305872: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-01-29 13:32:32.306159: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-01-29 13:32:32.306438: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-01-29 13:32:32.306747: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0, 1
2020-01-29 13:32:32.306766: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-01-29 13:32:32.546439: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-01-29 13:32:32.546463: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 1 
2020-01-29 13:32:32.546468: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N Y 
2020-01-29 13:32:32.546471: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 1:   Y N 
2020-01-29 13:32:32.546636: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-01-29 13:32:32.546935: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-01-29 13:32:32.547217: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-01-29 13:32:32.547478: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6807 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1070 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
2020-01-29 13:32:32.547823: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-01-29 13:32:32.548093: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 7562 MB memory) -> physical GPU (device: 1, name: GeForce GTX 1070 Ti, pci bus id: 0000:02:00.0, compute capability: 6.1)
Model: ""sequential""
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
max_pooling3d (MaxPooling3D) (None, None, 320, 240, 1) 0         
_________________________________________________________________
conv_lst_m2d (ConvLSTM2D)    (None, 318, 238, 16)      9856      
_________________________________________________________________
flatten (Flatten)            (None, 1210944)           0         
_________________________________________________________________
dense (Dense)                (None, 1)                 1210945   
=================================================================
Total params: 1,220,801
Trainable params: 1,220,801
Non-trainable params: 0
_________________________________________________________________
Train on 1 samples
Epoch 1/10
2020-01-29 13:32:35.394061: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-01-29 13:32:35.638536: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-01-29 13:32:35.639247: F ./tensorflow/core/kernels/conv_2d_gpu.h:659] Non-OK-status: GpuLaunchKernel( SwapDimension1And2InTensor3UsingTiles<T, NumThreads, TileLongSide, TileShortSide>, total_tiles_count, NumThreads, 0, d.stream(), input, input_dims, output) status: Internal: invalid configuration argument
Aborted (core dumped)
```

Last few lines of output with the `TF_CPP_MIN_VLOG_LEVEL=2` environment variable set:
```
2020-01-29 13:42:39.018679: I tensorflow/core/common_runtime/gpu/gpu_device.cc:523] GpuDevice::ComputeHelper scheduled replica_1/Cast op Cast on GPU 1 stream[0]
2020-01-29 13:42:39.018689: I tensorflow/core/framework/log_memory.cc:34] __LOG_MEMORY__ MemoryLogTensorOutput { step_id: -6348371833153678773 kernel_name: ""replica_1/Cast"" tensor { dtype: DT_FLOAT shape { dim { } dim { size: 10 } dim { size: 640 } dim { size: 480 } dim { size: 1 } } } }
2020-01-29 13:42:39.018696: I tensorflow/core/common_runtime/executor.cc:1912] Synchronous kernel done: 167 step -6348371833153678773 {{node replica_1/Cast}} = Cast[DstT=DT_FLOAT, SrcT=DT_DOUBLE, Truncate=false, _XlaHasReferenceVars=false, _device=""/job:localhost/replica:0/task:0/device:GPU:1""](cond_3/output/_37) device: /job:localhost/replica:0/task:0/device:GPU:1
2020-01-29 13:42:39.018703: I tensorflow/core/common_runtime/executor.cc:1756] Process node: 168 step -6348371833153678773 {{node replica_1/metrics/acc/remove_squeezable_dimensions/Squeeze}} = Squeeze[T=DT_FLOAT, _XlaHasReferenceVars=false, squeeze_dims=[-1], _device=""/job:localhost/replica:0/task:0/device:GPU:1""](replica_1/metrics/acc/Cast) device: /job:localhost/replica:0/task:0/device:GPU:1
2020-01-29 13:42:39.018709: I tensorflow/core/common_runtime/gpu/gpu_device.cc:497] GpuDevice::ComputeHelper replica_1/metrics/acc/remove_squeezable_dimensions/Squeeze op Squeeze on GPU 1 stream[0]
2020-01-29 13:42:39.018720: I tensorflow/core/framework/log_memory.cc:34] __LOG_MEMORY__ MemoryLogTensorAllocation { step_id: -6348371833153678773 kernel_name: ""replica_1/metrics/acc/remove_squeezable_dimensions/Squeeze"" tensor { dtype: DT_FLOAT shape { dim { } } } }
2020-01-29 13:42:39.018726: I tensorflow/core/common_runtime/gpu/gpu_device.cc:523] GpuDevice::ComputeHelper scheduled replica_1/metrics/acc/remove_squeezable_dimensions/Squeeze op Squeeze on GPU 1 stream[0]
2020-01-29 13:42:39.018734: I tensorflow/core/framework/log_memory.cc:34] __LOG_MEMORY__ MemoryLogTensorOutput { step_id: -6348371833153678773 kernel_name: ""replica_1/metrics/acc/remove_squeezable_dimensions/Squeeze"" tensor { dtype: DT_FLOAT shape { dim { } dim { size: 10 } } } }
2020-01-29 13:42:39.018740: I tensorflow/core/common_runtime/executor.cc:1912] Synchronous kernel done: 168 step -6348371833153678773 {{node replica_1/metrics/acc/remove_squeezable_dimensions/Squeeze}} = Squeeze[T=DT_FLOAT, _XlaHasReferenceVars=false, squeeze_dims=[-1], _device=""/job:localhost/replica:0/task:0/device:GPU:1""](replica_1/metrics/acc/Cast) device: /job:localhost/replica:0/task:0/device:GPU:1
2020-01-29 13:42:39.018750: I tensorflow/core/common_runtime/executor.cc:1756] Process node: 169 step -6348371833153678773 {{node replica_1/strided_slice}} = StridedSlice[Index=DT_INT32, T=DT_INT32, _XlaHasReferenceVars=false, begin_mask=0, ellipsis_mask=0, end_mask=0, new_axis_mask=0, shrink_axis_mask=1, _device=""/job:localhost/replica:0/task:0/device:GPU:1""](replica_1/Shape, replica_1/strided_slice/stack, replica_1/strided_slice/stack_1, replica_1/strided_slice/stack_1) device: /job:localhost/replica:0/task:0/device:GPU:1
2020-01-29 13:42:39.018755: I tensorflow/core/common_runtime/gpu/gpu_device.cc:497] GpuDevice::ComputeHelper replica_1/strided_slice op StridedSlice on GPU 1 stream[0]
2020-01-29 13:42:39.018763: I tensorflow/core/common_runtime/bfc_allocator.cc:227] AllocateRaw gpu_host_bfc  4
2020-01-29 13:42:39.018775: I tensorflow/core/framework/log_memory.cc:34] __LOG_MEMORY__ MemoryLogTensorAllocation { step_id: -6348371833153678773 kernel_name: ""replica_1/strided_slice"" tensor { dtype: DT_INT32 shape { } allocation_description { requested_bytes: 4 allocated_bytes: 256 allocator_name: ""gpu_host_bfc"" allocation_id: 193 has_single_reference: true ptr: 140615866159616 } } }
2020-01-29 13:42:39.018785: I tensorflow/core/common_runtime/gpu/gpu_device.cc:523] GpuDevice::ComputeHelper scheduled replica_1/strided_slice op StridedSlice on GPU 1 stream[0]
2020-01-29 13:42:39.018793: I tensorflow/core/framework/log_memory.cc:34] __LOG_MEMORY__ MemoryLogTensorOutput { step_id: -6348371833153678773 kernel_name: ""replica_1/strided_slice"" tensor { dtype: DT_INT32 shape { } allocation_description { requested_bytes: 4 allocated_bytes: 256 allocator_name: ""gpu_host_bfc"" allocation_id: 193 has_single_reference: true ptr: 140615866159616 } } }
2020-01-29 13:42:39.018801: I tensorflow/core/common_runtime/executor.cc:1912] Synchronous kernel done: 169 step -6348371833153678773 {{node replica_1/strided_slice}} = StridedSlice[Index=DT_INT32, T=DT_INT32, _XlaHasReferenceVars=false, begin_mask=0, ellipsis_mask=0, end_mask=0, new_axis_mask=0, shrink_axis_mask=1, _device=""/job:localhost/replica:0/task:0/device:GPU:1""](replica_1/Shape, replica_1/strided_slice/stack, replica_1/strided_slice/stack_1, replica_1/strided_slice/stack_1) device: /job:localhost/replica:0/task:0/device:GPU:1
2020-01-29 13:42:39.018808: I tensorflow/core/framework/log_memory.cc:34] __LOG_MEMORY__ MemoryLogTensorDeallocation { allocation_id: 16619 allocator_name: ""cpu"" }
2020-01-29 13:42:39.018819: I tensorflow/core/common_runtime/executor.cc:1756] Process node: 170 step -6348371833153678773 {{node replica_1/sequential/max_pooling3d/MaxPool3D}} = MaxPool3D[T=DT_FLOAT, _XlaHasReferenceVars=false, data_format=""NDHWC"", ksize=[1, 1, 2, 2, 1], padding=""VALID"", strides=[1, 1, 2, 2, 1], _device=""/job:localhost/replica:0/task:0/device:GPU:1""](replica_1/Cast) device: /job:localhost/replica:0/task:0/device:GPU:1
2020-01-29 13:42:39.018824: I tensorflow/core/common_runtime/gpu/gpu_device.cc:497] GpuDevice::ComputeHelper replica_1/sequential/max_pooling3d/MaxPool3D op MaxPool3D on GPU 1 stream[0]
2020-01-29 13:42:39.018838: I tensorflow/core/framework/log_memory.cc:34] __LOG_MEMORY__ MemoryLogTensorAllocation { step_id: -6348371833153678773 kernel_name: ""replica_1/sequential/max_pooling3d/MaxPool3D"" tensor { dtype: DT_FLOAT shape { dim { } dim { size: 10 } dim { size: 320 } dim { size: 240 } dim { size: 1 } } } }
2020-01-29 13:42:39.018849: I tensorflow/core/framework/log_memory.cc:34] __LOG_MEMORY__ MemoryLogTensorAllocation { step_id: -6348371833153678773 kernel_name: ""replica_1/sequential/max_pooling3d/MaxPool3D"" tensor { dtype: DT_FLOAT shape { dim { } dim { size: 1 } dim { size: 10 } dim { size: 640 } dim { size: 480 } } } }
2020-01-29 13:42:39.018862: F ./tensorflow/core/kernels/conv_2d_gpu.h:659] Non-OK-status: GpuLaunchKernel( SwapDimension1And2InTensor3UsingTiles<T, NumThreads, TileLongSide, TileShortSide>, total_tiles_count, NumThreads, 0, d.stream(), input, input_dims, output) status: Internal: invalid configuration argument
Aborted (core dumped)
```"
36309,"test that the full precision model runs on the CPU and GPU, but it takes 800ms to initialize on the GPU, but it only takes a few milliseconds to initialize on the CPU, how should I optimize","<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using):
- Are you willing to contribute it (Yes/No):



**Describe the feature and the current behavior/state.**

**Will this change the current api? How?**

**Who will benefit with this feature?**

**Any Other info.**
"
36308,Incorrect Error TypeError: padded_batch() missing 1 required positional argument: 'padded_shapes',"### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:  Error is not OS specific. Can be reproduced in Google Colab.
- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: N/A
- **TensorFlow installed from (source or binary)**: N/A
- **TensorFlow version (use command below)**: %tensorflow_version 2.x
- **Python version**: 3.6
- **Bazel version (if compiling from source)**: N/A
- **GCC/Compiler version (if compiling from source)**: N/A
- **CUDA/cuDNN version**: N/A
- **GPU model and memory**: N/A
- **Exact command to reproduce**: Please find this [Github Gist](https://colab.research.google.com/gist/rmothukuru/505e7dfe61f9e236c8fc4b77e434b8aa/word_embeddings.ipynb#scrollTo=7SN5USFEIIK3)

### Describe the problem
As per the Source Code of [Padded_Batch](https://github.com/tensorflow/tensorflow/blob/c4ec9389364cb8d1bff451ab8baf55d25cabdd1f/tensorflow/python/data/ops/dataset_ops.py#L1375-L1379), only the Argument, `batch_size` is Mandatory and remaining arguments are Optional. But as per the code in [this Tutorial](https://www.tensorflow.org/tutorials/text/word_embeddings#learning_embeddings_from_scratch), if we don't pass the second argument, `padded_shapes = ([None],())` it is resulting in the below error,
`TypeError: padded_batch() missing 1 required positional argument: 'padded_shapes'`


Error Log: 
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
<ipython-input-9-a8afa0f91afc> in <module>()
----> 1 train_batches = train_data.shuffle(1000).padded_batch(10)
      2 test_batches = test_data.shuffle(1000).padded_batch(10)
      3 
      4 #Error will be resolved if we uncomment below 3 lines and comment above 2 lines
      5 

TypeError: padded_batch() missing 1 required positional argument: 'padded_shapes'


**Expected Behavior:** Since the argument, `padded_shapes` is an Optional Argument, it shouldn't result in error even when we pass only the argument, `batch_size`"
36307,Wrong CUDA ImportError message in tf-gpu 1.14,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version: 1.14
- Python version: 3.6
- Installed using virtualenv? pip? conda?: conda
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:



**Describe the problem**


**Provide the exact sequence of commands / steps that you executed before running into the problem**
tensorflow-gpu 1.14 missing CUDA error tells to download CUDA 10.0 but links to CUDA 9.0:

`ImportError: Could not find 'cudart64_100.dll'. TensorFlow requires that this DLL be installed in a directory that is named in your %PATH% environment variable. Download and install CUDA 10.0 from this URL: https://developer.nvidia.com/cuda-90-download-archive
`

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
36306,Gradients do not propagate when iterating over dataset in graph mode,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Mac OS X 10.15
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.2.0-dev20200128
- Python version: 3.8

**Describe the current behavior**
Gradients become `None` if iterating over a `tf.data.Dataset` in graph mode. The correct answer is returned in eager mode.
**Describe the expected behavior**
Gradients in eager and graph mode should be the same.

**Code to reproduce the issue**
 Example:

```
data = tf.range(10, dtype=tf.float32)
ds = tf.data.Dataset.from_tensor_slices(data)
u = tf.Variable(1., dtype=tf.float32)

with tf.GradientTape(persistent=True) as g:
    loss1 = ds.reduce(tf.constant(0.), lambda x, y: x + (y - u) ** 2)
    loss2 = tf.reduce_sum([(y - u) ** 2 for y in ds.as_numpy_iterator()])
print(g.gradient(loss1, u))  # returns None
print(g.gradient(loss2, u))  # returns correct gradient
```
The same behavior is observed when using `for x in ds: ...` inside of a `@tf.function`.

Gist [here](https://colab.research.google.com/gist/terhorst/b51638f5e9657eb7f44553922c5a93c5/untitled3.ipynb)."
36304,TensorRT native segment lookup error in calibration mode,"**System information**
- Have I written custom code: yes
- OS Platform and Distribution: Linux Ubuntu 18.04 (docker)
- TensorFlow installed from source
- TensorFlow version: 2.1.0 
- Python version: 3.6.9
- Bazel version: 1.2.1
- GCC/Compiler version : 7.4.0
- CUDA/cuDNN version: 10.2 / 7.6.5
- TensorRT version 7.0
- GPU model and memory: NVIDIA TESLA V100-SXM2-16GB

**Describe the current behavior**

Under specific conditions, there is an error with the native segment lookup for TRTEngineOp. It can happen that we load a native segment that belongs to another graph. In most cases this leads to an error (when the input data is not comptible with the foreign native segment). In an unlucky case, when the input data is compatible, then we have incorrect results.

**Background**

TRTEngineOp falls back to execute the native TensorFlow segment in certain cases:
- there is an error in creating the engine, or with its input data
- during calibration https://github.com/tensorflow/tensorflow/blob/e72c2e601aac87faade051d5ca234a2a9b301b2a/tensorflow/compiler/tf2tensorrt/kernels/trt_engine_op.cc#L381
- during optimization profile creation [PR #36080] https://github.com/pooyadavoodi/tensorflow/blob/3ae92a3d220a8d84f2d7885423254aabae6bb99d/tensorflow/compiler/tf2tensorrt/kernels/trt_engine_op.cc#L535

The error can occur in the last two case. 

The native segment is added to the graph here https://github.com/tensorflow/tensorflow/blob/e72c2e601aac87faade051d5ca234a2a9b301b2a/tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc#L530-L552
and later it is looked up using its name in https://github.com/tensorflow/tensorflow/blob/e72c2e601aac87faade051d5ca234a2a9b301b2a/tensorflow/compiler/tf2tensorrt/kernels/trt_engine_op.cc#L247
For example, in each converted graph TRTEnginoOp_0 has a corresponding native segment TRTEngineOp_0_native_segment.


**Describe the expected behavior**

The expected behavior is to load the correct native segment, the one which corresponds to the TRTEngineOp being executed.

During normal execution the graph of the previous test should be garbage collected, so it cannot happen that we load an incorrect native segment.

We suspect that manipulating the graph during calibration (or build mode) introduces a circular reference that cause the garbage collector to not delete the graph. It is still not clear how does this native segment appear in subsequent tests' graph. The graph is owned by the converter, therefore each test is supposed to have a separate graph.

**Code to reproduce the issue**
To reproduce this error, we need to use either
- calibration (in the current master branch) https://github.com/tensorflow/tensorflow/blob/4152ed672ee107fc52f815443bc4601999f42ded/tensorflow/python/compiler/tensorrt/trt_convert.py#L1067-L1087 or
- build mode with profiles (as proposed in PR #36080) https://github.com/pooyadavoodi/tensorflow/blob/3ae92a3d220a8d84f2d7885423254aabae6bb99d/tensorflow/python/compiler/tensorrt/trt_convert.py#L1102-L1168

The problem is illustrated in the branch https://github.com/tfeher/tensorflow/tree/native_segment_bug This branch extends the test coverage of tf_trt_integration tests by [enabling calibration test](https://github.com/tfeher/tensorflow/commit/3c0d9e8da189bc8dc4e3020204e3080f5fa0d227) in V2 mode. The calibration needs to execute the native segment. 

A simple test file is prepared to reproduce the problem:
https://github.com/tfeher/tensorflow/blob/native_segment_bug/tensorflow/python/compiler/tensorrt/test/native_segment_test.py

The test file defines two tests: AddTest and MulTest, the first one takes one tensor as input, the second takes two tensors. If we call the tests individually, then they work:
```
python tensorflow/python/compiler/tensorrt/test/native_segment_test.py AddTest # works
python tensorflow/python/compiler/tensorrt/test/native_segment_test.py MulTest # works
```
When we try to execute both test then it fails:
```
python tensorflow/python/compiler/tensorrt/test/native_segment_test.py
...
ERROR: testTfTrtV2_OfflineConversion_DynamicEngine_INT8_UseCalibration (__main__.MulTest)
testTfTrtV2_OfflineConversion_DynamicEngine_INT8_UseCalibration (__main__.MulTest)
...
tensorflow.python.framework.errors_impl.InvalidArgumentError:  Expects 1 arguments, but 2 is provided
         [[node TRTEngineOp_0 (defined at /usr/lib/python3.6/unittest/case.py:605) ]] [Op:__inference_pruned_2770]
```
The `InvalidArgumentError` apperas, because AddTest's native segment was loaded instead of MulTest's native segment. This can be confirmed if we add a printout 
`VLOG(2) << SummarizeGraphDef(segment_graph_def_)` to TRTEngineOp's constructor.

The error can manifest different ways (but it is always caused by executing the native segment of a different graph):
- Segfault
- Out or range error
- Mismatched value if the foreign native segment is compatible with the input data. An example for that: https://github.com/tfeher/tensorflow/blob/native_segment_bug/tensorflow/python/compiler/tensorrt/test/native_segment_test2.py
- error due to incorrect data type

Tagging @pooyadavoodi @bixia1 and @aaroey "
36303,tensorboard installation issue ,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution: Linux Ubuntu 16.04
- TensorFlow installed from (source or binary): terminal
- TensorFlow version: tensorflow                         2.1.0              
                                   tensorflow-estimator               2.1.0
- Python version: 3.6.7




**Describe the problem**
am done by following steps in this link https://www.tensorflow.org/tensorboard/get_started  but it gives an error message like that 

**Provide the exact sequence of commands / steps that you executed before running into the problem**

tensorboard --logdir logs/fit


**Any other info / logs**
2020-01-29 15:42:56.124384: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory
2020-01-29 15:42:56.124520: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory
2020-01-29 15:42:56.124541: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
Traceback (most recent call last):
  File ""/home/kuppa/anaconda3/bin/tensorboard"", line 8, in <module>
    sys.exit(run_main())
  File ""/home/kuppa/anaconda3/lib/python3.6/site-packages/tensorboard/main.py"", line 59, in run_main
    default.get_plugins() + default.get_dynamic_plugins(),
  File ""/home/kuppa/anaconda3/lib/python3.6/site-packages/tensorboard/default.py"", line 115, in get_dynamic_plugins
    for entry_point in pkg_resources.iter_entry_points('tensorboard_plugins')
  File ""/home/kuppa/anaconda3/lib/python3.6/site-packages/tensorboard/default.py"", line 115, in <listcomp>
    for entry_point in pkg_resources.iter_entry_points('tensorboard_plugins')
  File ""/home/kuppa/anaconda3/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 2443, in load
    self.require(*args, **kwargs)
  File ""/home/kuppa/anaconda3/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 2466, in require
    items = working_set.resolve(reqs, env, installer, extras=self.extras)
  File ""/home/kuppa/anaconda3/lib/python3.6/site-packages/pkg_resources/__init__.py"", line 792, in resolve
    raise VersionConflict(dist, req).with_context(dependent_req)
pkg_resources.VersionConflict: (grpcio 1.16.1 (/home/kuppa/anaconda3/lib/python3.6/site-packages), Requirement.parse('grpcio>=1.24.3'))"
36302,Tensorflow 2.1 Tracing Error with LSTM layer,"I am implementing a tensorflow model using the keras LSTM layer.


**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu
- TensorFlow version (use command below): 2.1.0
- Python version: 3.7
- GPU model and memory: CPU

**Describe the current behavior**
Method Model.predict raise warning about Tracing
```WARNING:tensorflow:5 out of the last 5 calls to <function _make_execution_function.<locals>.distributed_function at 0x7eff0c74def0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.```

**Describe the expected behavior**
Same as Model.predict_on_batch

**Code to reproduce the issue**
```python
import tensorflow as tf
import numpy as np
import time

feature_dimension=2
lstm_size=256
learning_rate=0.0001

model = tf.keras.Sequential([
    tf.keras.Input([None, feature_dimension]),
    tf.keras.layers.LSTM(lstm_size),
    tf.keras.layers.Dense(1, activation='linear')
])

model.compile(loss='mean_squared_error',
              optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),
              metrics=['mse', 'mae'])

print('Model.predict')
st = time.time()
for i in range(5,100):
    model.predict(np.array([[(0.1,0.1)]*i]*10))
print(f'Model.predict in {time.time() - st}')

print('Model.predict_on_batch')
st = time.time()
for i in range(5,100):
    np.array(model.predict_on_batch(np.array([[(0.1,0.1)]*i]*10)))

print(f'Model.predict_on_batch in {time.time() - st}')
```

**Other info / logs**
For me help use predict_on_batch method.
"
36300,Error message is unclear when we failed to load tflite model.,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): 
   Darwin 19.2.0 
   Android Pixel2 API 29
- TensorFlow installed from (source or binary):
   binary (pip)
- TensorFlow version (or github SHA if from source):
   1.15.0

**Provide the text output from tflite_convert**
tflite_convert succeeded without any error. 
```
$ tflite_convert --saved_model_dir ./tts/exported/more-kss-spk10-tflite \
    --output_file ./tts/tflite/more-kss-spk10.tflite

...
WARNING:tensorflow:From /Users/hyunseok/.venv/py36/lib/python3.6/site-packages/tensorflow_core/lite/python/util.py:208: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.graph_util.convert_variables_to_constants`
W0129 17:08:51.578040 140734888230336 deprecation.py:323] From /Users/hyunseok/.venv/py36/lib/python3.6/site-packages/tensorflow_core/lite/python/util.py:208: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.graph_util.convert_variables_to_constants`
WARNING:tensorflow:From /Users/hyunseok/.venv/py36/lib/python3.6/site-packages/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.graph_util.extract_sub_graph`
W0129 17:08:51.578234 140734888230336 deprecation.py:323] From /Users/hyunseok/.venv/py36/lib/python3.6/site-packages/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.graph_util.extract_sub_graph`
INFO:tensorflow:Froze 198 variables.
I0129 17:08:53.582584 140734888230336 graph_util_impl.py:334] Froze 198 variables.
INFO:tensorflow:Converted 198 variables to const ops.
I0129 17:08:53.853986 140734888230336 graph_util_impl.py:394] Converted 198 variables to const ops.
WARNING:tensorflow:From /Users/hyunseok/.venv/py36/lib/python3.6/site-packages/tensorflow_core/lite/python/util.py:210: remove_training_nodes (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.graph_util.remove_training_nodes`
W0129 17:11:05.991335 140734888230336 deprecation.py:323] From /Users/hyunseok/.venv/py36/lib/python3.6/site-packages/tensorflow_core/lite/python/util.py:210: remove_training_nodes (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.graph_util.remove_training_nodes`
```

But when I tried to load this model on both my local machine and android, I got the below message. 
```
Traceback (most recent call last):
  File ""test.py"", line 6, in <module>
    interpreter = tf.lite.Interpreter(model_path='more-kss-spk10.tflite')
  File ""/Users/hyunseok/.venv/py36/lib/python3.6/site-packages/tensorflow_core/lite/python/interpreter.py"", line 206, in __init__
    model_path))
ValueError: Tensor 2711 is a variable tensor with buffer. It's not supported now.
```
I can't guess the Tensor 2711. 
May I delete all get_variable or tf.Variable statements on my model? 


"
36299,"Unable to import meta graph using tf.train.import_meta_graph, The name '' refers to an Operation not in the graph","[model.zip](https://github.com/tensorflow/tensorflow/files/4126895/model.zip)

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution: `Ubuntu 18.04`
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): `pip install`
- TensorFlow version (use command below): 
```
tf.VERSION = 1.13.1                                                            
tf.GIT_VERSION = b'v1.13.1-0-g6612da8951'                                      
tf.COMPILER_VERSION = b'v1.13.1-0-g6612da8951'
```
- Python version: `3.6.10`
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source): `4.8.5`
- CUDA/cuDNN version: `10.2`
- GPU model and memory: `Nvidia Tesla V100, 16gb`

**Describe the current behavior**

I am not able to import meta graph.
Even If I define `tf.placeholder(name=""data"", shape=(None,64), dtype=tf.float32)`, error comes for next layer.
I tried using tf2.0 also. But same issue there.

**Describe the expected behavior**
We should be able to import the graph

**Code to reproduce the issue**
```
import tensorflow as tf

model_dir=""./model""   # change this line to the directory where checkpoint and models are saved
checkpoint = tf.train.get_checkpoint_state(model_dir)
input_checkpoint = checkpoint.model_checkpoint_path
clear_devices = True

with tf.Session(graph=tf.Graph()) as sess:
    saver = tf.train.import_meta_graph(input_checkpoint + '.meta', clear_devices=clear_devices)
```
Checkpoint files are attached in **model.zip**.

**StackTrace**
```
Traceback (most recent call last):
  File ""import_meta_graph.py"", line 11, in <module>
    saver = tf.train.import_meta_graph(input_checkpoint + '.meta', clear_devices=clear_devices)
  File ""/home/ubuntu/tf1.13/lib/python3.6/site-packages/tensorflow/python/training/saver.py"", line 1435, in import_meta_graph
    meta_graph_or_file, clear_devices, import_scope, **kwargs)[0]
  File ""/home/ubuntu/tf1.13/lib/python3.6/site-packages/tensorflow/python/training/saver.py"", line 1457, in _import_meta_graph_with_return_elements
    **kwargs))
  File ""/home/ubuntu/tf1.13/lib/python3.6/site-packages/tensorflow/python/framework/meta_graph.py"", line 852, in import_scoped_meta_graph_with_return_elements
    ops.prepend_name_scope(value, scope_to_prepend_to_names))
  File ""/home/ubuntu/tf1.13/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 3478, in as_graph_element
    return self._as_graph_element_locked(obj, allow_tensor, allow_operation)
  File ""/home/ubuntu/tf1.13/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 3538, in _as_graph_element_locked
    ""graph."" % repr(name))
KeyError: ""The name 'data' refers to an Operation not in the graph.""
```
"
36298,tf.keras loss/metric argument/return specification,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): 2.1
- Are you willing to contribute it (Yes/No): No

**Describe the feature and the current behavior/state.**

This suggestion eases custom loss and custom metrics implementation restrictions. And it removes dirty/tricky codes for text/TensorBoard logging of single-output-multiple-loss-func from user application.

Losses for `Model.compile()` arguments

```python
# current befavior

# model with single output
model.compile(.., loss=func, ..) # OK
model.compile(.., loss=[func], ..) # OK
model.compile(.., loss=[func1, func2], ..) # Error for single output
# model with two outputs
model.compile(.., loss=func, ..) # OK
model.compile(.., loss=[func1_for_out1, func2_for_out2], ..) # OK
model.compile(.., loss=[(func1_for_out1, func2_for_out1), func3_for_out2], ..) # Error
```

```python
# behavior which I sugest

# model with single output
model.compile(.., loss=[func1, func2], ..)
# OK, func1 and func2 are applied to single output with weight [1., 1.]

# model with two outputs
model.compile(.., loss=[(func1_for_out1, func2_for_out1), func3_for_out2], ..)
# OK, func1 and func2 are applied to output1. func3 is applied to output2
# default weight is [(1., 1.), 1.]
# and joint loss is 1. * func1_for_out1(out1) + 1. * func2_for_out1(out1) + 1. * func3_for_out2(out2)
```

Loss function return value

```python
# current befavior
def my_loss_func(..):
  return [loss1, loss2] # Error
  return (loss1, loss2) # Error
  return dict(my_loss_name1=loss1, my_loss_name2=loss2) # Error
```

```python
# behavior which I sugest
# loss function can return list or tuple
def my_loss_func(..):
  return [loss1, loss2]
  return (loss1, loss2)

model.compile(.., loss=[my_loss_func], loss_weights=[1.2])
# joint loss = loss1 * 1.2 / 2 + loss2 * 1.2 / 2
# and loss names on logging are [my_loss_func_1, my_loss_func_2]

# loss function can return dict
def my_loss_func(..):
  return dict(my_loss_name1=loss1, my_loss_name2=loss2) # Error

model.compile(.., loss=[my_loss_func], loss_weights=[1.2])
# joint loss = loss1 * 1.2 / 2 + loss2 * 1.2 / 2
# and loss names on logging are [my_loss_name1, my_loss_name2]
```

Metrics

```python
# current befavior
# Metric function can't return list or tuple or dict in current version.
def my_metrics(..):
  return [metric1, metric2] # Error
  return (metric1, metric2) # Error
  return dict(metric_name_1=metric1, metric_name_2=metric2) # Error
```

```python
# behavior which I sugest
# Metric function can return list or tuple or dict, and metric names are set properly.
def my_metrics(..):
  return [metric1, metric2] # OK, with names [my_metrics_1, my_metrics_2]
  return (metric1, metric2) # OK, with names  [my_metrics_1, my_metrics_2]
  return dict(metric_name_1=metric1, metric_name_2=metric2) # OK, with names  [metric_name_1, metric_name_2]
```

**Will this change the current api? How?**

No. Old codes will run without behavior changes.

**Who will benefit with this feature?**

This change benefits engineer who is using joint loss and want to log losses separately.
And it benefits engineer who want to calculate multiple losses in single function for performance or code simplification.
And it benefits engineer who want to calculate multiple metrics in single function for performance or code simplification.

**Any Other info.**
"
36297,I need to connect my uvc camera with the object detection application (android).,Could someone tell me how to config or where I should config?
36296,"I want to open spyder. Error show from . import (constants, error, message, context, ImportError: DLL load failed: The specified module could not be found. ","C:\Users\bimalgupta>spyder
Traceback (most recent call last):
  File ""C:\Anaconda3\Scripts\spyder-script.py"", line 6, in <module>
    from spyder.app.start import main
  File ""C:\Anaconda3\lib\site-packages\spyder\app\start.py"", line 22, in <module>
    import zmq
  File ""C:\Anaconda3\lib\site-packages\zmq\__init__.py"", line 47, in <module>
    from zmq import backend
  File ""C:\Anaconda3\lib\site-packages\zmq\backend\__init__.py"", line 40, in <module>
    reraise(*exc_info)
  File ""C:\Anaconda3\lib\site-packages\zmq\utils\sixcerpt.py"", line 34, in reraise
    raise value
  File ""C:\Anaconda3\lib\site-packages\zmq\backend\__init__.py"", line 27, in <module>
    _ns = select_backend(first)
  File ""C:\Anaconda3\lib\site-packages\zmq\backend\select.py"", line 27, in select_backend
    mod = __import__(name, fromlist=public_api)
  File ""C:\Anaconda3\lib\site-packages\zmq\backend\cython\__init__.py"", line 6, in <module>
    from . import (constants, error, message, context,
ImportError: DLL load failed: The specified module could not be found.

kindly help me.
"
36295,````ruby def hello_world  puts 'Hello World!' end ````,"This template is for miscellaneous issues not covered by the other issue categories.

For questions on how to work with TensorFlow, or support for problems that are not verified bugs in TensorFlow, please go to [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).

If you are reporting a vulnerability, please use the [dedicated reporting process](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md).

For high-level discussions about TensorFlow, please post to discuss@tensorflow.org, for questions about the development or internal workings of TensorFlow, or if you would like to know how to contribute to TensorFlow, please post to developers@tensorflow.org.
"
36294,Dyanmic Library not loading tensorflow-gpu,"- OS Platform and Distribution: Zorin OS 15.1
- TensorFlow installed from binary
- TensorFlow version: 2.1.0
- Python version: 3.6.9
- Installed using pip
- CUDA/cuDNN version: 10.2
- GPU model and memory: 2080ti with 11gb of gddr6

So basically I want to leverage tensorflow-gpu since my gpu has a compute capability of 7.5. I went through all the steps that are on the tensorflow gpu installation for ubuntu website and for some reason I get this sort of message: `Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory`

The steps, as mentioned before, are the same ones on the tensorflow-gpu install website: [](https://www.tensorflow.org/install/gpu)

To reproduce this, I am just using this code:
`import tensorflow as tf`
`print(""Num GPUs Available: "", len(tf.config.experimental.list_physical_devices('GPU')))`

This is the full console output:
`2020-01-28 21:41:28.276270: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libnvinfer.so.6
2020-01-28 21:41:28.277129: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libnvinfer_plugin.so.6
2020-01-28 21:41:28.595376: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-01-28 21:41:28.636979: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-01-28 21:41:28.637622: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.65GHz coreCount: 68 deviceMemorySize: 10.76GiB deviceMemoryBandwidth: 573.69GiB/s
2020-01-28 21:41:28.637741: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory
2020-01-28 21:41:28.637802: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-01-28 21:41:28.638713: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-01-28 21:41:28.638860: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-01-28 21:41:28.639785: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-01-28 21:41:28.640301: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-01-28 21:41:28.640321: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-01-28 21:41:28.640326: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1592] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
Num GPUs Available:  0`

"
36293,Decouple RaggedStructure from RaggedTensor,"**System information**
- TensorFlow version (you are using): 2
- Are you willing to contribute it (Yes/No): Yes

**Describe the feature and the current behavior/state.**
I've been doing a lot of work with `RaggedTensor`s since their introduction, and one thing that irks me is that a lot of the methods (`row_lengths`, `row_starts`, `value_rowids` etc) work entirely on their row structure, and independently of the values. The memoization features of the `RaggedTensor` class is very convenient, but those memoized values aren't shared between `RaggedTensor`s that share the same row structure but have different values. As an example

```python
x = tf.RaggedTensor.from_row_splits(tf.range(5), [0, 2, 5])
y = 2 * x
print(x.row_splits is y.row_splits)              # True
print(x.row_lengths() is y.row_lengths())  # False
```
A separate `RaggedStructure` class which handles memoization has two main benefits:

1. Easier memoization across different `RaggedTensor`s
2. Simpler interface to structure manipulation functions without `value`s

**Will this change the current api? How?**
This could be done with no changes to the current API. However, minimal changes - like changing the existing `tf.RaggedTensor.__init__` method, which isn't meant to be used externally anyway - might make things simpler, and exposing a new property (`ragged_structure`) would be helpful in many cases. I would suggest something like the following.

```python
class RaggedTensor(CompositeTensor):
  # changed constructor, publicly usable.
  def __init__(self, values, ragged_structure):
    self._values = values
    self._ragged_structure = ragged_structure
    # error checks
    ...

  # added property
  @property
  def ragged_structure(self):
    return self._ragged_structure 
  
  # redirect row_lengths, row_starts, value_rowids etc. to structure
  def row_lengths(self):
    return self.ragged_structure.row_lengths()

  def with_values(self, values):
    return RaggedTensor(values, self.ragged_structure)

# new class
class RaggedStructure(CompositeTensor):
  def __init__(self, row_splits, cached_row_lengths=None, cached_value_rowids=None, cached_nrows=None, internal=False):
    # most of current tf.RaggedTensor.__init__
    ...

  @classmethod
  def from_row_lengths(cls, row_lengths):
    # most of current tf.RaggedTensor.from_row_lengths
    ...

  # cache here
  def row_lengths(self, row_lengths):
    if self._cached_row_lengths is None:
      ...
    return self._cached_row_lengths
```"
36291,GFile read() terminates with no error message,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
  **No**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
  **Windows 10 1909, 18363.592**
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
  **N/A**
- TensorFlow installed from (source or binary):
  `pip install tensorflow-gpu`
- TensorFlow version:
```
2020-01-28 21:39:22.550881: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll
v2.1.0-rc2-17-ge5bf8de410 2.1.0
```
- Python version:
**Python 3.5.6**
- Bazel version (if compiling from source):
**N/A**
- GCC/Compiler version (if compiling from source):
**N/A**
- CUDA/cuDNN version:
```
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2019 NVIDIA Corporation
Built on Fri_Feb__8_19:08:26_Pacific_Standard_Time_2019
Cuda compilation tools, release 10.1, V10.1.105
```
- GPU model and memory:
Nvidia GeForce RTX2060

**Describe the current behavior**

Attempting to read an existing pb file with `GFile.read()` exits abruptly the python terminal with no error message.

**Describe the expected behavior**

Reading an existing pb file with `GFile.read()` should either terminate successfully or return an error message. 

**Code to reproduce the issue**
```
import tensorflow as tf
from tensorflow.python.platform import gfile

detection_graph = tf.Graph()
with detection_graph.as_default():
	with tf.io.gfile.GFile(""C:\wrkfldr\frozen_inference_graph.pb"", 'rb') as f:
		graph_def = tf.compat.v1.GraphDef()
		print(""1"")
		graph_def.ParseFromString(f.read())
		print(""2"")
		persisted_sess.graph.as_default()
		print(""3"")
		tf.import_graph_def(graph_def)
		print(""4"")
```

**Other info / logs**

The script above outputs the following : 
```
(test-tf) C:\Users\Me>python D:\main.py
2020-01-28 21:44:35.371550: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll
1
```

Restarting anaconda / the whole machine doesn't seem to fix the issue. 

`tf.test.is_gpu_available()` returns the following output

```
>>> tf.test.is_gpu_available()
WARNING:tensorflow:From <stdin>:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.config.list_physical_devices('GPU')` instead.
2020-01-28 21:46:06.878770: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2
2020-01-28 21:46:06.887260: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library nvcuda.dll
2020-01-28 21:46:06.988174: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties:
pciBusID: 0000:01:00.0 name: GeForce RTX 2060 computeCapability: 7.5
coreClock: 1.68GHz coreCount: 30 deviceMemorySize: 6.00GiB deviceMemoryBandwidth: 312.97GiB/s
2020-01-28 21:46:06.997651: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll
2020-01-28 21:46:07.066131: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll
2020-01-28 21:46:07.109559: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_10.dll
2020-01-28 21:46:07.133917: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_10.dll
2020-01-28 21:46:07.179636: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_10.dll
2020-01-28 21:46:07.218387: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_10.dll
2020-01-28 21:46:07.302231: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll
2020-01-28 21:46:07.307632: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-01-28 21:46:08.060601: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-01-28 21:46:08.065979: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0
2020-01-28 21:46:08.069051: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N
2020-01-28 21:46:08.076616: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/device:GPU:0 with 4604 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5)
True
>>>
```
 
"
36290,Not sufficient documentation on custom tf_lite classification model ,"Thank you for submitting a TensorFlow documentation issue. Per our GitHub
policy, we only address code/doc bugs, performance issues, feature requests, and
build/installation issues on GitHub.

The TensorFlow docs are open source! To get involved, read the documentation
contributor guide: https://www.tensorflow.org/community/contribute/docs

## URL(s) with the issue:

Please provide a link to the documentation entry, for example:
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/MyMethod

## Description of issue (what needs changing):

### Clear description

For example, why should someone use this method? How is it useful?

### Correct links

Is the link to the source code correct?

### Parameters defined

Are all parameters defined and formatted correctly?

### Returns defined

Are return values defined?

### Raises listed and defined

Are the errors defined? For example,
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises

### Usage example

Is there a usage example?

See the API guide: https://www.tensorflow.org/community/contribute/docs_ref
on how to write testable usage examples.

### Request visuals, if applicable

Are there currently visuals? If not, will it clarify the content?

### Submit a pull request?

Are you planning to also submit a pull request to fix the issue? See the docs
contributor guide: https://www.tensorflow.org/community/contribute/docs,
docs API guide: https://www.tensorflow.org/community/contribute/docs_ref and the
docs style guide: https://www.tensorflow.org/community/contribute/docs_style
"
36289,Tensorflow 2.1 Tracing Error with Model Subclassing,"I am implementing a tensorflow model using the keras subclassing api, as mentioned in a previous post here:

https://stackoverflow.com/questions/59743161/tensorflow-model-subclassing-mutli-input


I am running into an error that is slowing my entire system, where it is retracing but I cannot narrow down where this error occurs, I do not use @tf.function anywhere in my code. I am looking for support on narrowing down the location of the error or how to solve it.


**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Mac OS
- TensorFlow version (use command below):2.1.0
- Python version: 3.6

**Describe the current behavior**
Without tensorflow eager execution there is constant graph retracing

**Describe the expected behavior**

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.

**Other info / logs**
The exact error is:

> WARNING: Logging before flag parsing goes to stderr. W0127
> 15:31:00.867754 4815351232 def_function.py:586] 5 out of the last 6
> calls to <function
> _make_execution_function.<locals>.distributed_function at 0x157208d08> triggered tf.function retracing. Tracing is expensive and the
> excessive number of tracings is likely due to passing python objects
> instead of tensors. Also, tf.function has
> experimental_relax_shapes=True option that relaxes argument shapes
> that can avoid unnecessary retracing. Please refer to
> https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args
> and https://www.tensorflow.org/api_docs/python/tf/function for more
> details.

Looking into it further disabling eager execution is throwing this warning that may be a causing factor:


> 2020-01-27 16:11:42.781884: W tensorflow/c/c_api.cc:326] Operation
> '{name:'basic_parsing_model/time_distributed/bidirectional/backward_gru/while'
> id:542 op device:{} def:{{{node
> basic_parsing_model/time_distributed/bidirectional/backward_gru/while}}
> = While[T=[DT_INT32, DT_INT32, DT_INT32, DT_VARIANT, DT_FLOAT, ..., DT_VARIANT, DT_VARIANT, DT_VARIANT, DT_VARIANT, DT_VARIANT],
> _lower_using_switch_merge=true, _num_original_outputs=52, body=basic_parsing_model_time_distributed_bidirectional_backward_gru_while_body_708[],
> cond=basic_parsing_model_time_distributed_bidirectional_backward_gru_while_cond_707[],
> output_shapes=[[], [], [], [], [?,32], ..., [], [], [], [], []],
> parallel_iterations=32](basic_parsing_model/time_distributed/bidirectional/backward_gru/while/loop_counter, basic_parsing_model/time_distributed/bidirectional/backward_gru/while/maximum_iterations,
> basic_parsing_model/time_distributed/bidirectional/backward_gru/time,
> basic_parsing_model/time_distributed/bidirectional/backward_gru/TensorArrayV2_1,
> basic_parsing_model/time_distributed/bidirectional/backward_gru/zeros,
> basic_parsing_model/time_distributed/bidirectional/backward_gru/strided_slice_1,
> basic_parsing_model/time_distributed/bidirectional/backward_gru/TensorArrayUnstack/TensorListFromTensor,
> basic_parsing_model/time_distributed/backward_gru/bias,
> basic_parsing_model/time_distributed/backward_gru/kernel,
> basic_parsing_model/time_distributed/backward_gru/recurrent_kernel,
> basic_parsing_model/time_distributed/bidirectional/backward_gru/while/EmptyTensorList,
> basic_parsing_model/time_distributed/bidirectional/backward_gru/while/EmptyTensorList_1,
> basic_parsing_model/time_distributed/bidirectional/backward_gru/while/EmptyTensorList_2,
> basic_parsing_model/time_distributed/bidirectional/backward_gru/while/EmptyTensorList_3,
> basic_parsing_model/time_distributed/bidirectional/backward_gru/while/EmptyTensorList_4,
> basic_parsing_model/time_distributed/bidirectional/backward_gru/while/EmptyTensorList_5,
> basic_parsing_model/time_distributed/bidirectional/backward_gru/while/EmptyTensorList_6,
> basic_parsing_model/time_distributed/bidirectional/backward_gru/while/EmptyTensorList_7,
> basic_parsing_model/time_distributed/bidirectional/backward_gru/while/EmptyTensorList_8,
> basic_parsing_model/time_distributed/bidirectional/backward_gru/while/EmptyTensorList_9,
> basic_parsing_model/time_distributed/bidirectional/backward_gru/while/EmptyTensorList_10,
> basic_parsing_model/time_distributed/bidirectional/backward_gru/while/EmptyTensorList_11,
> basic_parsing_model/time_distributed/bidirectional/backward_gru/while/EmptyTensorList_12,
> basic_parsing_model/time_distributed/bidirectional/backward_gru/while/EmptyTensorList_13,
> basic_parsing_model/time_distributed/bidirectional/backward_gru/while/EmptyTensorList_14,
> basic_parsing_model/time_distributed/bidirectional/backward_gru/while/EmptyTensorList_15,
> basic_parsing_model/time_distributed/bidirectional/backward_gru/while/EmptyTensorList_16,
> basic_parsing_model/time_distributed/bidirectional/backward_gru/while/EmptyTensorList_17,
> basic_parsing_model/time_distributed/bidirectional/backward_gru/while/EmptyTensorList_18,
> basic_parsing_model/time_distributed/bidirectional/backward_gru/while/EmptyTensorList_19,
> basic_parsing_model/time_distributed/bidirectional/backward_gru/while/EmptyTensorList_20,
> basic_parsing_model/time_distributed/bidirectional/backward_gru/while/EmptyTensorList_21,
> basic_parsing_model/time_distributed/bidirectional/backward_gru/while/EmptyTensorList_22,
> basic_parsing_model/time_distributed/bidirectional/backward_gru/while/EmptyTensorList_23,
> basic_parsing_model/time_distributed/bidirectional/backward_gru/while/EmptyTensorList_24,
> basic_parsing_model/time_distributed/bidirectional/backward_gru/while/EmptyTensorList_25,
> basic_parsing_model/time_distributed/bidirectional/backward_gru/while/EmptyTensorList_26,
> basic_parsing_model/time_distributed/bidirectional/backward_gru/while/EmptyTensorList_27,
> basic_parsing_model/time_distributed/bidirectional/backward_gru/while/EmptyTensorList_28,
> basic_parsing_model/time_distributed/bidirectional/backward_gru/while/EmptyTensorList_29,
> basic_parsing_model/time_distributed/bidirectional/backward_gru/while/EmptyTensorList_30,
> basic_parsing_model/time_distributed/bidirectional/backward_gru/while/EmptyTensorList_31,
> basic_parsing_model/time_distributed/bidirectional/backward_gru/while/EmptyTensorList_32,
> basic_parsing_model/time_distributed/bidirectional/backward_gru/while/EmptyTensorList_33,
> basic_parsing_model/time_distributed/bidirectional/backward_gru/while/EmptyTensorList_34,
> basic_parsing_model/time_distributed/bidirectional/backward_gru/while/EmptyTensorList_35,
> basic_parsing_model/time_distributed/bidirectional/backward_gru/while/EmptyTensorList_36,
> basic_parsing_model/time_distributed/bidirectional/backward_gru/while/EmptyTensorList_37,
> basic_parsing_model/time_distributed/bidirectional/backward_gru/while/EmptyTensorList_38,
> basic_parsing_model/time_distributed/bidirectional/backward_gru/while/EmptyTensorList_39,
> basic_parsing_model/time_distributed/bidirectional/backward_gru/while/EmptyTensorList_40,
> basic_parsing_model/time_distributed/bidirectional/backward_gru/while/EmptyTensorList_41)}}'
> was changed by setting attribute after it was run by a session. This
> mutation will have no effect, and will trigger an error in the future.
> Either don't modify nodes after running them or create a new session.
> 2020-01-27 16:11:46.854955: W
> tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error
> occurred when finalizing GeneratorDataset iterator: Cancelled:
> Operation was cancelled
"
36288,Go API performance concerns with NewTensor & Value,"The Go NewTensor call will unnecessarly incur a large number of allocations (e.g. >20,000 for a 100x100x100 tensor). There are similar issues with .Value. It's possible to work around the issue by using ReadTensor and WriteTensorTo.

I'm basically wondering if a PR to fix this would stand a chance of being accepted? If there's a chance I might have a go. The 'best' fix would likely use unsafe - would the maintainers be squeamish about that?"
36287,keras freezing at last step in the first epoch,"My model is using tf 2.0 and tf.keras 2.2.4 . When I train the model, it freezes at the last step of the first epoch. I am using :
 history = model.fit(
     train_dataset,
   epochs=EPOCHS,
    steps_per_epoch=train_steps,
    validation_data=valid_dataset,
   validation_steps=valid_steps,
 )
the train_dataset and valid_dataset is of type: <class 'tensorflow.python.data.ops.dataset_ops.DatasetV1Adapter'>
PLEASE LOOK INTO THE MATTER.
"
36286,ImportError: DLL load failed:,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution :win10
- TensorFlow installed from (source or binary):http://pypi.douban.com/simple
- TensorFlow version:2.1.0
- Python version:3.6.8
- Installed using virtualenv? pip? conda?:anaconda
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:10.1.152
- GPU model and memory:Geforce GTX 1060



**Describe the problem**

**after import tensorflow as tf **


**Any other info / logs**
Traceback (most recent call last):
  File ""G:\anaconda\envs\basecopy\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""G:\anaconda\envs\basecopy\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""G:\anaconda\envs\basecopy\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""G:\anaconda\envs\basecopy\lib\imp.py"", line 243, in load_module
    return load_dynamic(name, filename, file)
  File ""G:\anaconda\envs\basecopy\lib\imp.py"", line 343, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: 找不到指定的模块。

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""G:/pyexercise/pyexercise7(tensor).py"", line 2, in <module>
    import tensorflow as tf
  File ""G:\anaconda\envs\basecopy\lib\site-packages\tensorflow\__init__.py"", line 101, in <module>
    from tensorflow_core import *
  File ""G:\anaconda\envs\basecopy\lib\site-packages\tensorflow_core\__init__.py"", line 40, in <module>
    from tensorflow.python.tools import module_util as _module_util
  File ""G:\anaconda\envs\basecopy\lib\site-packages\tensorflow\__init__.py"", line 50, in __getattr__
    module = self._load()
  File ""G:\anaconda\envs\basecopy\lib\site-packages\tensorflow\__init__.py"", line 44, in _load
    module = _importlib.import_module(self.__name__)
  File ""G:\anaconda\envs\basecopy\lib\importlib\__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""G:\anaconda\envs\basecopy\lib\site-packages\tensorflow_core\python\__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""G:\anaconda\envs\basecopy\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 74, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""G:\anaconda\envs\basecopy\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""G:\anaconda\envs\basecopy\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""G:\anaconda\envs\basecopy\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""G:\anaconda\envs\basecopy\lib\imp.py"", line 243, in load_module
    return load_dynamic(name, filename, file)
  File ""G:\anaconda\envs\basecopy\lib\imp.py"", line 343, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: 找不到指定的模块。


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/errors

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help."
36284,Problems building TF-Lite Android Benchmark tool,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Build machine is an Ubuntu VM with 10GB RAM, Oracle VirtualBox on Win10.
Ubuntu 18.04.3 LTS
kernel 5.3.0-26-generic

- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
Target device - Galaxy Tab S6, Snapdragon 855. Android 9. (and others)

- TensorFlow installed from (source or binary): source
- TensorFlow version: 2.0.1
- Python version: 2.7
- Installed using virtualenv? pip? conda?: no
- Bazel version (if compiling from source): 1.2.1
- GCC/Compiler version (if compiling from source): 7.4.0
- CUDA/cuDNN version: none
- GPU model and memory: none



**Describe the problem**
I have successfully converted Keras models to TF-Lite and run them in a simple Android app.
Now I want to optimise performance, I really need the Benchmark tool to see what operations are being sent to which chips and how long each takes, to see whether they way I've built my models suits the devices.

I can't get the benchmark tool to build. i can't get the camera demo to build either. i have tried various versions of the NDK & SDK and get a variety of errors that look like errors in the code but I'm sure it's just my build environment.

**Provide the exact sequence of commands / steps that you executed before running into the problem**

Build machine is an Ubuntu VM with 10GB RAM, Oracle VirtualBox on Win10.

Ubuntu 18.04.3 LTS
kernel 5.3.0-26-generic

Target device - Galaxy Tab S6, Snapdragon 855. Android 9. 

Bazel version 1.2.1
gcc version 7.4.0

Recent install of Android Studio provides the SDK & NDK as below. (I did try NDK 14 but it didn't seem to help)

Cloned the TF repo. On master branch, commit d75abdf from 28th Jan 2020

Ran ./configure, options:

Please specify the location of python. [Default is /usr/bin/python]: - using default
('which python' shows /usr/bin/python, 'python --version' shows 2.7.17)
Found possible Python library paths:
  /usr/local/lib/python2.7/dist-packages
  /usr/lib/python2.7/dist-packages
Please input the desired Python library path to use.  Default is [/usr/local/lib/python2.7/dist-packages]  - using default
Do you wish to build TensorFlow with XLA JIT support? [Y/n]:  - using default
Do you wish to build TensorFlow with OpenCL SYCL support? [y/N]:  - using default
Do you wish to build TensorFlow with ROCm support? [y/N]:  - using default
Do you wish to build TensorFlow with CUDA support? [y/N]:  - using default
Do you wish to download a fresh release of clang? (Experimental) [y/N]:   - using default
Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -march=native -Wno-sign-compare]:   - using default
Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: y
Please specify the home path of the Android NDK to use. [Default is /home/medaphor/Android/Sdk/ndk-bundle]: 
/home/medaphor/Android/Sdk/ndk/21.0.6113669
Please specify the (min) Android NDK API level to use. [Available levels: ['16', '17', '18', '19', '21', '22', '23', '24', '26', '27', '28', '29']] [Default is 21]:  - using default
Please specify the home path of the Android SDK to use. [Default is /home/medaphor/Android/Sdk]:  - using default
Please specify the Android SDK API level to use. [Available levels: ['24', '28', '29']] [Default is 29]: - using default
Please specify an Android build tools version to use. [Available versions: ['24.0.3', '29.0.2']] [Default is 29.0.2]:   - using default

Then following: https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/tools/benchmark/android
(looking at the Master branch version of the doc)

1st step is:
(0) Refer to https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/android to edit the WORKSPACE to configure the android NDK/SDK.

Well the configure script does that i believe. Doc is out of date? no action taken.

next step is:
(1) Build for your specific platform, e.g.:
bazel build -c opt \
  --config=android_arm64 \
  --cxxopt='--std=c++11' \
  tensorflow/lite/tools/benchmark/android:benchmark_model

ran that, and get error:


ERROR: /home/medaphor/tensorflow/tensorflow/lite/experimental/delegates/hexagon/BUILD:66:1: C++ compilation of rule '//tensorflow/lite/experimental/delegates/hexagon:hexagon_delegate' failed (Exit 1)
tensorflow/lite/experimental/delegates/hexagon/hexagon_delegate.cc:52:32: error: no member named 'make_unique' in namespace 'std'
    auto hexagon_kernel = std::make_unique<HexagonDelegateKernel>();
                          ~~~~~^
tensorflow/lite/experimental/delegates/hexagon/hexagon_delegate.cc:52:44: error: 'HexagonDelegateKernel' does not refer to a value
    auto hexagon_kernel = std::make_unique<HexagonDelegateKernel>();
                                           ^
./tensorflow/lite/experimental/delegates/hexagon/hexagon_delegate_kernel.h:40:7: note: declared here
class HexagonDelegateKernel {
      ^
tensorflow/lite/experimental/delegates/hexagon/hexagon_delegate.cc:52:67: error: expected expression
    auto hexagon_kernel = std::make_unique<HexagonDelegateKernel>();
                                                                  ^

UPDATE:
I missed this warning:

WARNING: The major revision of the Android NDK referenced by android_ndk_repository rule 'androidndk' is 21. The major revisions supported by Bazel are [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]. Bazel will attempt to treat the NDK as if it was r20. This may cause compilation and linkage problems. Please download a supported NDK version.

So installed NDK 20.0.5594570, 
ran configure again, 
did a bazel clean --expunge,
and tried to build. No more warnings but now get this error:

ERROR: /home/medaphor/tensorflow/tensorflow/lite/experimental/ruy/BUILD:246:1: C++ compilation of rule '//tensorflow/lite/experimental/ruy:detect_arm' failed (Exit 1)
tensorflow/lite/experimental/ruy/detect_arm.cc:59:10: error: use of undeclared identifier 'getauxval'
  return getauxval(AT_HWCAP) & kLocalHwcapAsimddp;
         ^

UPDATE:

changing to:

--cxxopt='--std=c++14'

fixes it. Could you please update the readme's?"
36282,What (tf) happened to and in release 1.15.1?,"There was a release of tensorflow-1.15.1 available for a very short time (on Jan 24 2020) that caused a `TypeError: gradients_v2() got an unexpected keyword argument 'colocate_gradients_with_ops'`.

Exact same code that failed with above error on v1.15.1 works with v1.15.0 and v1.15.2.

Now, the release tag 1.15.1 (https://github.com/tensorflow/tensorflow/tags) is not even available anymore on github! To me that seems very fishy to say the least! So of course I am wondering what happened here?"
36281,unsupported operand type(s) for *: 'int' and 'NoneType' in training_v2,"
**System information**
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): 2.1.0

Running a simple evaluation of a Lenet Model with MNIST dataset (from TFDS) with a large batch size (e.g. due to using many workers) leads to 

```
tensorflow.python.framework.errors_impl.OutOfRangeError: 2 root error(s) found.
  (0) Out of range:  End of sequence
	 [[node IteratorGetNext_2 (defined at git/tensorflow_tests/train_distributed.py:212) ]]
	 [[metrics/accuracy/div_no_nan/allreduce_1/CollectiveReduce/_70]]
  (1) Out of range:  End of sequence
	 [[node IteratorGetNext_2 (defined at git/tensorflow_tests/train_distributed.py:212) ]]
```

and

```
File ""/scratch/ws/s3248973-EasyBuild/easybuild-haswell/software/TensorFlow/2.1.0-fosscuda-2019b-Python-3.7.4/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py"", line 152, in run_one_epoch
    total_epochs * steps_per_epoch))
TypeError: unsupported operand type(s) for *: 'int' and 'NoneType'
```

The bug is pretty obvious in https://github.com/tensorflow/tensorflow/blob/7b0cfadc895d74aec99875a23ed296506c98e88c/tensorflow/python/keras/engine/training_v2.py#L152 where `steps_per_epoch` is used although it can be (and is) None, see also https://github.com/tensorflow/tensorflow/blob/7b0cfadc895d74aec99875a23ed296506c98e88c/tensorflow/python/keras/engine/training_v2.py#L135"
36280,Keras: Unable to load SavedModel that includes tf.keras.backend.not_equal call,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **Linux Ubuntu 18.04**
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: **No**
- TensorFlow installed from (source or binary): **binary**
- TensorFlow version (use command below): **2.1.0-rc2**
- Python version: **3.7.4**

**Describe the current behavior**
Loading a Keras model including a call to `tf.keras.backend.not_equal` gives an error:
`ValueError: Could not find matching function to call loaded from the SavedModel`.

Works fine on 2.0.0.

**Describe the expected behavior**
It should be possible to load a model that includes a call to `tf.keras.backend.not_equal`.

**Code to reproduce the issue**
``` python
import tensorflow as tf

inp = tf.keras.layers.Input((1,1))
mask = tf.keras.backend.not_equal(inp, 0)
gru = tf.keras.layers.GRU(1, name='my-output')(inp, mask=mask)

model = tf.keras.Model(inp, gru)

model.save('my-saved-model')
model2 = tf.keras.models.load_model('my-saved-model')
```

**Other info / logs**
The snippet above results in the following traceback:
```
Traceback (most recent call last):
  File ""/home/gustavg/.PyCharm2019.3/config/scratches/scratch_90.py"", line 10, in <module>
    model2 = tf.keras.models.load_model('my-saved-model')
  File ""/home/gustavg/.virtualenvs/dq2/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/save.py"", line 150, in load_model
    return saved_model_load.load(filepath, compile)
  File ""/home/gustavg/.virtualenvs/dq2/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/saved_model/load.py"", line 89, in load
    model = tf_load.load_internal(path, loader_cls=KerasObjectLoader)
  File ""/home/gustavg/.virtualenvs/dq2/lib/python3.7/site-packages/tensorflow_core/python/saved_model/load.py"", line 552, in load_internal
    export_dir)
  File ""/home/gustavg/.virtualenvs/dq2/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/saved_model/load.py"", line 119, in __init__
    self._finalize()
  File ""/home/gustavg/.virtualenvs/dq2/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/saved_model/load.py"", line 157, in _finalize
    created_layers={layer.name: layer for layer in node.layers})
  File ""/home/gustavg/.virtualenvs/dq2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py"", line 1903, in reconstruct_from_config
    process_node(layer, node_data)
  File ""/home/gustavg/.virtualenvs/dq2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py"", line 1851, in process_node
    output_tensors = layer(input_tensors, **kwargs)
  File ""/home/gustavg/.virtualenvs/dq2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py"", line 773, in __call__
    outputs = call_fn(cast_inputs, *args, **kwargs)
  File ""/home/gustavg/.virtualenvs/dq2/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/saved_model/utils.py"", line 59, in return_outputs_and_add_losses
    outputs, losses = fn(inputs, *args, **kwargs)
  File ""/home/gustavg/.virtualenvs/dq2/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py"", line 568, in __call__
    result = self._call(*args, **kwds)
  File ""/home/gustavg/.virtualenvs/dq2/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py"", line 615, in _call
    self._initialize(args, kwds, add_initializers_to=initializers)
  File ""/home/gustavg/.virtualenvs/dq2/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py"", line 497, in _initialize
    *args, **kwds))
  File ""/home/gustavg/.virtualenvs/dq2/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py"", line 2389, in _get_concrete_function_internal_garbage_collected
    graph_function, _, _ = self._maybe_define_function(args, kwargs)
  File ""/home/gustavg/.virtualenvs/dq2/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py"", line 2703, in _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)
  File ""/home/gustavg/.virtualenvs/dq2/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py"", line 2593, in _create_graph_function
    capture_by_value=self._capture_by_value),
  File ""/home/gustavg/.virtualenvs/dq2/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py"", line 978, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File ""/home/gustavg/.virtualenvs/dq2/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py"", line 439, in wrapped_fn
    return weak_wrapped_fn().__wrapped__(*args, **kwds)
  File ""/home/gustavg/.virtualenvs/dq2/lib/python3.7/site-packages/tensorflow_core/python/saved_model/function_deserialization.py"", line 262, in restored_function_body
    ""\n\n"".join(signature_descriptions)))
ValueError: Could not find matching function to call loaded from the SavedModel. Got:
  Positional arguments (1 total):
    * Tensor(""inputs:0"", shape=(None, 1, 1), dtype=float32)
  Keyword arguments: {}

Expected these arguments to match one of the following 1 option(s):

Option 1:
  Positional arguments (1 total):
    * [TensorSpec(shape=(None, 1, 1), dtype=tf.float32, name='inputs/0')]
  Keyword arguments: {}
```
"
36279,Dimension is expanded for Keras scalar input in eager mode,"**System information**
- Have I written custom code: **YES**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **Windows 10**
- TensorFlow installed from (source or binary): **pip**
- TensorFlow version (use command below): **v2.1.0-rc2-17-ge5bf8de410 2.1.0**
- Python version: **Python 3.7.3**
- CUDA/cuDNN version: **CUDA v10.1 / cuDNN 7.6.4** 
- GPU model and memory: **NVIDIA GeForce GTX 1060 with Max-Q Design 6 GB**

**Describe the current behavior**

If input layer for keras model is scalar and model is executing eagerly `model.compile(run_eagerly=True)` then

- The shape of the input tensor is expanded up to 1 dimension (`TensorShape([16, 1])` instead of `TensorShape([16])` including the batch dimension if batch size is 16.
- Warning is shown `WARNING:tensorflow:Model was constructed with shape Tensor(""the_input:0"", shape=(16,), dtype=float32) for input (16,), but it was re-called on a Tensor with incompatible shape (16, 1).`

If `run_eagerly=False` then the shape is as expected.

This is pretty critical in our case because we use scalar input for `label_length` argument of [tf.nn.ctc_loss](https://www.tensorflow.org/api_docs/python/tf/nn/ctc_loss) which requires tensor of shape `[batch_size]` and fails with really vague error if shape is `[batch_size,1]`

**Describe the expected behavior**
The shape should be kept as specified - `TensorShape([16])` - and no warning is shown.

**Code to reproduce the issue**


```python
import tensorflow as tf
import numpy as np
import sys


batch_size = 16
input_batch = np.ones((batch_size,)).astype(np.float32)


class TestSequence(tf.keras.utils.Sequence):
    def __len__(self):
        return 1

    def __getitem__(self, idx):
        return input_batch, input_batch

# Dummy layer to show the tensor shape
class PrintLayer(tf.keras.layers.Layer):
    def call(self, inputs):
        tf.print(inputs.shape, output_stream=sys.stderr)
        return inputs


# The result is the same if shape=() is used to specify scalar input
input_layer = tf.keras.layers.Input(
    name='the_input', batch_shape=(batch_size,), dtype='float32')
x = PrintLayer()(input_layer)
output_layer = tf.keras.layers.ReLU()(x)
model = tf.keras.models.Model(inputs=[input_layer], outputs=[output_layer])

# If run_eagerly=False then the shapes are correct
model.compile(loss='mse', run_eagerly=True)

model.fit(TestSequence(), epochs=3)
```
**Other info / logs**

I've tracked the source of this change up to the following line (callstack below)

```
standardize_single_array, training_utils.py:454
<listcomp>, training_utils.py:529
standardize_input_data, training_utils.py:529
_standardize_tensors, training.py:2410
_standardize_user_data, training.py:2383
train_on_batch, training_v2_utils.py:416
wrapper, api.py:258
_call_for_each_replica, distribute_lib.py:2164
call_for_each_replica, distribute_lib.py:1819
experimental_run_v2, distribute_lib.py:763
distributed_function, training_v2_utils.py:85
execution_function, training_v2_utils.py:98
run_one_epoch, training_v2.py:128
fit, training_v2.py:342
fit, training.py:819
```

Seems like the expected shapes are not passed if the eager mode is on (see [this line](https://github.com/tensorflow/tensorflow/blob/v2.1.0/tensorflow/python/keras/engine/training.py#L2391)) and hence the error.

Here is a [link to gist in colab](https://gist.github.com/PavelKovalets/2e0bb75fe234d355773f291dd8c4bdb3).
"
36278,Support tf.SparseTensor and tf.RaggedTensor in tf.py_function,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): tensorflow==2.1.0
- Are you willing to contribute it (Yes/No): Yes



**Describe the feature and the current behavior/state.**
`tf.py_function` executes eagerly and therefore does support to mix python and TF functions.
Creating instances of  tf.SparseTensor and tf.RaggedTensor is not a problem.
But if there are in the return statement tf.pyfunction crashes, because I assume its expecting a tf.Tensor.

Example:

````
def eager_py_ragged(arg1_eager):

    return tf.RaggedTensor.from_tensor(arg1_eager, dtype=tf.int32)

arg1_const = tf.constant(1, dtype=tf.int32)

tf.py_function(eager_py_sparse, [arg1_const], [tf.int32])
# tf.python.framework.errors_impl.InvalidArgumentError:
# ValueError: Attempt to convert a value (<tensorflow.python.framework.sparse_tensor.SparseTensor object at X)
# with an unsupported type (<class 'tensorflow.python.framework.sparse_tensor.SparseTensor'>) to a Tensor.
````


**Will this change the current api? How?**
I dont think so.
**Who will benefit with this feature?**
People building their `tf.data` pipeline with `tf.pyfunction`.
**Any Other info.**
I will create more `tf.py_function` related stories. Since this are distinct features from my POV, there multiple feature requests. I hope this is ok."
36276,Support nested structure as return value in tf.py_function.,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): tensorflow==2.1.0
- Are you willing to contribute it (Yes/No): Yes



**Describe the feature and the current behavior/state.**
Support for return values in nested structures as in `tf.data.Dataset.from_generator`.
I cant return any nested structure as, e.g., a dict or namedtuple.

See example:
 
````python
arg1_const = tf.constant([0, 1], dtype=tf.int32)
def eager_py_dict(arg1):
    return {0: arg1}

tf.py_function(eager_py_dict, [arg1_const], {0: tf.int32})
# Returns:
# tensorflow.python.eager.core._FallbackException: Expecting a DType.dtype for attr Tout, got dict
````

**Will this change the current api? How?**
Supporting nesting structures.

**Who will benefit with this feature?**
People building their `tf.data` pipeline with `tf.pyfunction`.

**Any Other info.**
I will create more `tf.py_function` related stories. Since this are distinct features from my POV, there multiple feature requests. I hope this is ok.
"
36275,Build on MacOS for Select Operators TFLite error,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS 10.14.5
- TensorFlow installed from (source or binary): installed from source
- TensorFlow version (use command below):  v2.0.1
- Python version: 3.5.2
- Bazel version (if compiling from source):  0.26.1
- GCC/Compiler version (if compiling from source):  Apple clang version 11.0.0 (clang-1100.0.33.17)

**Describe the current behavior**

When build by using  _tensorflow/contrib/makefile/build_all_ios_with_tflite.sh_ the following error occur:

...
tensorflow/lite/minimal_logging_android.cc:18:10: fatal error: 'android/log.h' file not found
#include <android/log.h>
         ^~~~~~~~~~~~~~~
1 error generated.
make: *** [/Users/jay/Documents/tensorflow2/tensorflow/contrib/makefile/gen/obj/ios_ARM64/tensorflow/lite/minimal_logging_android.o] Error 1
....
**Describe the expected behavior**

The build is completed and generates files, libtensorflow-lite.a, libprotobuf.a, nsync.a, for using in XCode.

**Code to reproduce the issue**

- run ./configure 
-- setup WORKSPACE 
-- choose 'build TensorFlow with iOS support'
- run tensorflow/contrib/makefile/build_all_ios_with_tflite.sh

the result of setting up Android WORKSPACE in .tf_configure.bazelrc  is

...
build --action_env ANDROID_NDK_HOME=""/Users/jay/Library/Android/sdk/ndk/17.2.4988734""
build --action_env ANDROID_NDK_API_LEVEL=""21""
build --action_env ANDROID_BUILD_TOOLS_VERSION=""29.0.2""
build --action_env ANDROID_SDK_API_LEVEL=""27""
build --action_env ANDROID_SDK_HOME=""/Users/jay/Library/Android/sdk""
...

"
36274,Support setting shapes directly in tf.py_function,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): tensorflow==2.1.0
- Are you willing to contribute it (Yes/No): Yes



**Describe the feature and the current behavior/state.**
In comparison to `tf.data.Dataset.from_generator`, `tf.py_function` does not take an (optional) shape argument. Therefore all returned tensors have unknown shape. Looking up the docu I realized you can solve this by setting `tf.Tensor.set_shape`. It would be more convienent if  `tf.py_function` would support this directly.
Therefore I wrote a wrapper for myself:

```
def py_function2(
    func: Callable,
    inp: tf.Tensor,
    tOut: Iterable[tf.dtypes.DType],
    shapes: Iterable[Optional[Shape]] = None,
    name: str = None,
) -> Union[tf.Tensor, Iterable[tf.Tensor]]:
    result = tf.py_function(func, inp, tOut, name=None)

    if shapes is not None:
        # Set shape of the output tensors.
        for tensor, shape in zip(result, shapes):
            if shape is not None:
                tensor.set_shape(tf.TensorShape(shape))

    return result
````

Note: This is not working for nested structures, which are on the other hand currently not supported by  `tf.py_function` anyway. But I will create another FR for this.


**Will this change the current api? How?**
Yes, `tf.py_function` would get another optional argument.

**Who will benefit with this feature?**
People building their `tf.data` pipeline with `tf.pyfunction`.
**Any Other info.**
I will create more `tf.py_function` related stories. Since this are distinct features from my POV, there multiple feature requests. I hope this is ok."
36272,Able to Custom Layer's unit test,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): 2.1.0
- Are you willing to contribute it (Yes/No): Yes

**Describe the feature and the current behavior/state.**
I want to write a correct batch normalization in MultiGPU/TPU.
I wrote some [code](https://gist.github.com/MokkeMeguru/35af0c7ddba511f6a268e7c78fdba2d6), but I cannot do your unit test.

**Will this change the current api? How?**
Add any argument for add custom layer in the function [layer_test](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/testing_utils.py#L75-L78)

**Who will benefit with this feature?**
1. Someone wants to fix an official layer.
2. Someone wants to create some layers.
 
**Any Other info.**
"
36270,TFLite FP16 network Fully connected layer failing on gpu in android,"Using tensorflow 2.1 on both python as well as android. Quantized the model to fp16 in python and successfully run inference tests with python interpretor on ubuntu/mac.

But when I deployed the same network on android edge device with tflite java 2.1 pre-built and enabled gpu delegate, its failing with below error. 


tensorflow/lite/kernels/fully_connected.cc:105 filter->type != kTfLiteFloat32 (10 != 1)
    Node number 187 (FULLY_CONNECTED) failed to prepare.
    
    tensorflow/lite/kernels/conv.cc:272 bias->type != input_type (1
        at org.tensorflow.lite.NativeInterpreterWrapper.applyDelegate(Native Method)
        at org.tensorflow.lite.NativeInterpreterWrapper.applyDelegates(NativeInterpreterWrapper.java:336)
        at org.tensorflow.lite.NativeInterpreterWrapper.init(NativeInterpreterWrapper.java:82)
        at org.tensorflow.lite.NativeInterpreterWrapper.<init>(NativeInterpreterWrapper.java:48)
        at org.tensorflow.lite.Interpreter.<init>(Interpreter.java:175)"
36269,ModuleNotFoundError: No module named 'tensorflow.contrib',"Hi. Can anyone help me with this existing problem?

This is the error.
2020-01-28 02:46:01.200715: E tensorflow/core/platform/hadoop/hadoop_file_system.cc:132] HadoopFileSystem load error: libhdfs.so: cannot open shared object file: No such file or directory
Traceback (most recent call last):
  File ""train.py"", line 48, in <module>
    from tensorflow.contrib import framework as contrib_framework
**ModuleNotFoundError: No module named 'tensorflow.contrib'**

It is from train.py in Tensorflow:
**from tensorflow.contrib import framework as contrib_framework** line 48

Tensorflow Version: 1.14.0
Python3 Version: 3.7.3

I am currently coding in Raspberry Pi."
36268,tf.debugging.assert_shapes() does not work for SparseTensor,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Mac OS X 10.15
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.1
- Python version: 3.8

**Describe the current behavior**
`tf.debugging.assert_shapes` cannot be used with sparse tensors.

**Describe the expected behavior**
`tf.debugging.assert_shapes` should allow you to mix and match dense and sparse tensors when checking for dimensional consistency.

**Code to reproduce the issue**
```
import tensorflow as tf
A = tf.range(3)
tf.debugging.assert_shapes(((A, [3]),))  # works
# raises ""ValueError: Attempt to convert a value (...) with an unsupported type (<class 'tensorflow.python.framework.sparse_tensor.SparseTensor'>) to a Tensor.
tf.debugging.assert_shapes(((tf.sparse.from_dense(A), [3]),))
```"
36266,Check failed: 0 <= new_num_elements,"<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below):
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with: 1. TF 1.0: `python -c ""import
tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 2. TF 2.0: `python -c
""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
```
== check python ===================================================
python version: 3.7.3
python branch:
python build version: ('default', 'Jun 27 2019 23:31:30')
python compiler version: GCC 5.5.0
python implementation: CPython


== check os platform ===============================================
os: Linux
os kernel version: #1 SMP Tue Jul 30 17:17:50 UTC 2019
os release version: 4.9.184-0.1.ac.235.83.329.metal1.x86_64
os platform: Linux-4.9.184-0.1.ac.235.83.329.metal1.x86_64-x86_64-with-redhat-5.3-Tikanga
linux distribution: ('Red Hat Enterprise Linux Server', '5.3', 'Tikanga')
linux os distribution: ('redhat', '5.3', 'Tikanga')
mac version: ('', ('', '', ''), '')
uname: uname_result(system='Linux', node='dev-dsk-jsahewal-1b-01f89cec.us-east-1.amazon.com', release='4.9.184-0.1.ac.235.83.329.metal1.x86_64', version='#1 SMP Tue Jul 30 17:17:50 UTC 2019', machine='x86_64', processor='x86_64')
architecture: ('64bit', 'ELF')
machine: x86_64


== are we in docker =============================================
No

== compiler =====================================================
c++ (Homebrew gcc 5.5.0_4) 5.5.0
Copyright (C) 2015 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.


== check pips ===================================================
numpy                             1.18.1
protobuf                          3.9.2
tensorflow-cpu                    2.1.0
tensorflow-estimator              2.1.0

== check for virtualenv =========================================
False

== tensorflow import ============================================
tf.version.VERSION = 2.1.0
tf.version.GIT_VERSION = v2.1.0-rc2-17-ge5bf8de
tf.version.COMPILER_VERSION = 7.3.1 20180303

== env ==========================================================
LD_LIBRARY_PATH is unset
DYLD_LIBRARY_PATH is unset

== nvidia-smi ===================================================
tf_env_collect.sh: line 145: nvidia-smi: command not found

== cuda libs  ===================================================

== tensorflow installed from info ==================

== python version  ==============================================
(major, minor, micro, releaselevel, serial)
(3, 7, 3, 'final', 0)

== bazel version  ===============================================
```

**Describe the current behavior**
```
2020-01-27 22:56:12.796098: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2800045000 Hz
2020-01-27 22:56:12.797977: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x3bad450 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-01-27 22:56:12.798009: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-01-27 22:56:12.806071: F tensorflow/core/framework/tensor_shape.cc:353] Check failed: 0 <= new_num_elements (0 vs. -4523975925047186833)
[1]    10698 abort      python3 demo.py
```

**Describe the expected behavior**
Should not abort

**Code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate the problem.
```
import numpy as np
import pandas as pd

import tensorflow as tf

from tensorflow import feature_column
from tensorflow.keras import layers

# A utility method to create a tf.data dataset from a Pandas Dataframe
def df_to_dataset(dataframe, shuffle=True, batch_size=32):
    dataframe = dataframe.copy()
    labels = dataframe.pop('target')
    ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))
    if shuffle:
        ds = ds.shuffle(buffer_size=len(dataframe))
    ds = ds.batch(batch_size)
    return ds

URL = 'https://storage.googleapis.com/applied-dl/heart.csv'
dataframe = pd.read_csv(URL)

# Replicate the dataFrame to make it a bit bigger
temp = dataframe.copy()
for _ in range(10):
    dataframe = pd.concat([dataframe, temp.copy()])

# Replicate the columns to make it a bit bigger
col_lst = dataframe.columns.tolist()
for i in range(10):
    for ind, col in enumerate(col_lst):
        dataframe[f'{i+1}_{ind}'] = dataframe[col]

batch_size = 5 # A small batch sized is used for demonstration purposes
dataframe_ds = df_to_dataset(dataframe, batch_size=batch_size)
```"
36262,Possible incorrect implementation of inception_v3.py,"""Mixed 0"" between lines 138-152 is the implementation of the figure 5 in the paper. There should be 4 branches that does and have the layer name as :

branch 1x1 = 1x1 conv
branch pool = pooling + 1x1 conv
branch 3x3 = 1x1 conv + 3x3 conv
branch 5x5 = 1x1 conv + 3x3 conv +3x3 conv

The last one is is named as branch3x3dbl in the implementation and its fine doing two 3x3 convs to substitute 5x5 conv, but what should be branch 3x3 is named as branch 5x5 and involves a 5x5 convolution which contradicts the paper. So lines 140 and 141 should be rewritten as:
```
  branch3x3 = conv2d_bn(x, 48, 1, 1)
  branch3x3 = conv2d_bn(branch3x3, 64, 3, 3)  
```

This is not limited to this section and followup codes have the same wrong implementations. I think it should be taken care of. The idea of avoiding bigger convolutions is the main point of this paper and 5x5 convolutions are taking part in the code regardless of this fact. 


"
36259,Error registering Keras serializable loss,"**System information**
- Have I written custom code): yes
- TensorFlow installed from: binary
- TensorFlow version: 2.1
- Python version: 3.7

**Describe the current behavior**

Using the `tf.keras.utils.register_keras_serializable` decorator does not allow correct serialization/restoration of a custom `tf.keras.losses.Loss` subclass without using a `custom_objects` argument.

**Describe the expected behavior**

Using `tf.keras.utils.register_keras_serializable` allows serialization/restoration of custom losses without using a `custom_objects` argument.

**Code to reproduce the issue**

```python
import tensorflow as tf


@tf.keras.utils.register_keras_serializable()
class CustomLoss(tf.keras.losses.MeanSquaredError):
    pass


model = tf.keras.Sequential([tf.keras.layers.Dense(units=1, input_shape=(1,))])
model.compile(optimizer='sgd', loss=CustomLoss())
model.save('model')

# ValueError: Unknown loss function: CustomLoss
tf.keras.models.load_model('model', compile=True)
```

**Other info / logs**
Relevant traceback:

https://github.com/tensorflow/tensorflow/blob/fd242bad45bd9778d61ad116001fd4b191e51c30/tensorflow/python/keras/saving/save.py#L190

https://github.com/tensorflow/tensorflow/blob/fd242bad45bd9778d61ad116001fd4b191e51c30/tensorflow/python/keras/saving/saved_model/load.py#L114-L115

https://github.com/tensorflow/tensorflow/blob/fd242bad45bd9778d61ad116001fd4b191e51c30/tensorflow/python/keras/saving/saving_utils.py#L259

https://github.com/tensorflow/tensorflow/blob/fd242bad45bd9778d61ad116001fd4b191e51c30/tensorflow/python/keras/losses.py#L1301-L1305

https://github.com/tensorflow/tensorflow/blob/fd242bad45bd9778d61ad116001fd4b191e51c30/tensorflow/python/keras/utils/generic_utils.py#L361-L362

https://github.com/tensorflow/tensorflow/blob/fd242bad45bd9778d61ad116001fd4b191e51c30/tensorflow/python/keras/utils/generic_utils.py#L321"
36256,Tensorflow 2.1 Jacobian fails when using Keras LeakyReLU Layer,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes. See attached test case.
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Mac OS 10.14.6
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Unsure
- TensorFlow installed from (source or binary): Binary installed from pip
- TensorFlow version (use command below): ('v2.1.0-rc2-17-ge5bf8de410', '2.1.0')
- Python version: Python 2.7.15 and Python 3.7.0
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A

**Describe the current behavior**
Computing the Jacobian using the Gradient tape function fails when a the LeakyReLU Keras layer is used.

**Describe the expected behavior**
It was expected to calculate the Jacobian of the model with respect to the trainable parameters.

**Code to reproduce the issue**
```
import tensorflow

model = tensorflow.keras.models.Sequential()
model.add(tensorflow.keras.layers.Dense(2,
                                        input_dim=1,
                                        use_bias=True))
model.add(tensorflow.keras.layers.LeakyReLU())
#model.add(tensorflow.keras.layers.ReLU())
model.add(tensorflow.keras.layers.Dense(1,
                                        use_bias=True))

inputs = tensorflow.random.uniform((100,1), 1.0, -1.0)

with tensorflow.GradientTape(watch_accessed_variables=False) as tape:
	tape.watch(model.trainable_weights)
	temp = model(inputs)

jacobian = tape.jacobian(temp, model.trainable_weights)
```

**Other info / logs**
It produces the following error messages.

*** Python 2.7.15 Error Output ***
```
Traceback (most recent call last):
  File ""test.py"", line 18, in <module>
    jacobian = tape.jacobian(temp, model.trainable_weights)
  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/tensorflow_core/python/eager/backprop.py"", line 1121, in jacobian
    sys.exc_info()[2])
  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/tensorflow_core/python/eager/backprop.py"", line 1113, in jacobian
    parallel_iterations=parallel_iterations)
  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/tensorflow_core/python/ops/parallel_for/control_flow_ops.py"", line 189, in pfor
    return f()
  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/tensorflow_core/python/eager/function.py"", line 2362, in __call__
    graph_function, args, kwargs = self._maybe_define_function(args, kwargs)
  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/tensorflow_core/python/eager/function.py"", line 2703, in _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)
  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/tensorflow_core/python/eager/function.py"", line 2593, in _create_graph_function
    capture_by_value=self._capture_by_value),
  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/tensorflow_core/python/framework/func_graph.py"", line 978, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/tensorflow_core/python/framework/func_graph.py"", line 968, in wrapper
    raise e.ag_error_metadata.to_exception(e)
ValueError: in converted code:

    /Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/tensorflow_core/python/ops/parallel_for/control_flow_ops.py:183 f  *
        return _pfor_impl(loop_fn, iters, parallel_iterations=parallel_iterations)
    /Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/tensorflow_core/python/ops/parallel_for/control_flow_ops.py:256 _pfor_impl
        outputs.append(converter.convert(loop_fn_output))
    /Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/tensorflow_core/python/ops/parallel_for/pfor.py:1280 convert
        output = self._convert_helper(y)
    /Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/tensorflow_core/python/ops/parallel_for/pfor.py:1460 _convert_helper
        (y_op.type, y_op, converted_inputs))

    ValueError: No converter defined for LeakyReluGrad
    name: ""loop_body/LeakyReluGrad""
    op: ""LeakyReluGrad""
    input: ""loop_body/MatMul""
    input: ""loop_body/LeakyReluGrad/features""
    attr {
      key: ""T""
      value {
        type: DT_FLOAT
      }
    }
    attr {
      key: ""alpha""
      value {
        f: 0.300000011921
      }
    }
    
    inputs: [WrappedTensor(t=<tf.Tensor 'loop_body/MatMul/pfor/Reshape_1:0' shape=(100, 100, 2) dtype=float32>, is_stacked=True, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'loop_body/LeakyReluGrad/features:0' shape=(100, 2) dtype=float32>, is_stacked=False, is_sparse_stacked=False)]. 
    Either add a converter or set --op_conversion_fallback_to_while_loop=True, which may run slower

Encountered an exception while vectorizing the jacobian computation. Vectorization can be disabled by setting experimental_use_pfor to False.
```

*** Python 3.7.0 Error Output***
```
Traceback (most recent call last):
  File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/eager/backprop.py"", line 1113, in jacobian
    parallel_iterations=parallel_iterations)
  File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/ops/parallel_for/control_flow_ops.py"", line 189, in pfor
    return f()
  File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py"", line 2362, in __call__
    graph_function, args, kwargs = self._maybe_define_function(args, kwargs)
  File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py"", line 2703, in _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)
  File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py"", line 2593, in _create_graph_function
    capture_by_value=self._capture_by_value),
  File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py"", line 978, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py"", line 968, in wrapper
    raise e.ag_error_metadata.to_exception(e)
ValueError: in converted code:

    /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/ops/parallel_for/control_flow_ops.py:183 f  *
        return _pfor_impl(loop_fn, iters, parallel_iterations=parallel_iterations)
    /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/ops/parallel_for/control_flow_ops.py:256 _pfor_impl
        outputs.append(converter.convert(loop_fn_output))
    /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/ops/parallel_for/pfor.py:1280 convert
        output = self._convert_helper(y)
    /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/ops/parallel_for/pfor.py:1460 _convert_helper
        (y_op.type, y_op, converted_inputs))

    ValueError: No converter defined for LeakyReluGrad
    name: ""loop_body/LeakyReluGrad""
    op: ""LeakyReluGrad""
    input: ""loop_body/MatMul""
    input: ""loop_body/LeakyReluGrad/features""
    attr {
      key: ""T""
      value {
        type: DT_FLOAT
      }
    }
    attr {
      key: ""alpha""
      value {
        f: 0.30000001192092896
      }
    }
    
    inputs: [WrappedTensor(t=<tf.Tensor 'loop_body/MatMul/pfor/Reshape_1:0' shape=(100, 100, 2) dtype=float32>, is_stacked=True, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'loop_body/LeakyReluGrad/features:0' shape=(100, 2) dtype=float32>, is_stacked=False, is_sparse_stacked=False)]. 
    Either add a converter or set --op_conversion_fallback_to_while_loop=True, which may run slower


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""test.py"", line 18, in <module>
    jacobian = tape.jacobian(temp, model.trainable_weights)
  File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/eager/backprop.py"", line 1121, in jacobian
    sys.exc_info()[2])
  File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/six.py"", line 702, in reraise
    raise value.with_traceback(tb)
  File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/eager/backprop.py"", line 1113, in jacobian
    parallel_iterations=parallel_iterations)
  File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/ops/parallel_for/control_flow_ops.py"", line 189, in pfor
    return f()
  File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py"", line 2362, in __call__
    graph_function, args, kwargs = self._maybe_define_function(args, kwargs)
  File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py"", line 2703, in _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)
  File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py"", line 2593, in _create_graph_function
    capture_by_value=self._capture_by_value),
  File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py"", line 978, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py"", line 968, in wrapper
    raise e.ag_error_metadata.to_exception(e)
ValueError: in converted code:

    /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/ops/parallel_for/control_flow_ops.py:183 f  *
        return _pfor_impl(loop_fn, iters, parallel_iterations=parallel_iterations)
    /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/ops/parallel_for/control_flow_ops.py:256 _pfor_impl
        outputs.append(converter.convert(loop_fn_output))
    /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/ops/parallel_for/pfor.py:1280 convert
        output = self._convert_helper(y)
    /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow_core/python/ops/parallel_for/pfor.py:1460 _convert_helper
        (y_op.type, y_op, converted_inputs))

    ValueError: No converter defined for LeakyReluGrad
    name: ""loop_body/LeakyReluGrad""
    op: ""LeakyReluGrad""
    input: ""loop_body/MatMul""
    input: ""loop_body/LeakyReluGrad/features""
    attr {
      key: ""T""
      value {
        type: DT_FLOAT
      }
    }
    attr {
      key: ""alpha""
      value {
        f: 0.30000001192092896
      }
    }
    
    inputs: [WrappedTensor(t=<tf.Tensor 'loop_body/MatMul/pfor/Reshape_1:0' shape=(100, 100, 2) dtype=float32>, is_stacked=True, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'loop_body/LeakyReluGrad/features:0' shape=(100, 2) dtype=float32>, is_stacked=False, is_sparse_stacked=False)]. 
    Either add a converter or set --op_conversion_fallback_to_while_loop=True, which may run slower

Encountered an exception while vectorizing the jacobian computation. Vectorization can be disabled by setting experimental_use_pfor to False.
```"
36255,GradientTape does not track intermediate variables inside a tf.function,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Ubuntu 18.04
- TensorFlow installed from (source or binary): 
Binary
- TensorFlow version (use command below):
2.2.0-dev20200123
- Python version:
3.7.3
- CUDA/cuDNN version: 10.1 / 
#define CUDNN_MAJOR 7
#define CUDNN_MINOR 6
#define CUDNN_PATCHLEVEL 4
- GPU model and memory:
```
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 440.33.01    Driver Version: 440.33.01    CUDA Version: 10.1     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  Quadro P3200        On   | 00000000:01:00.0 Off |                  N/A |
| N/A   54C    P3    24W /  N/A |   5911MiB /  6078MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|    0      1326      G   /usr/lib/xorg/Xorg                           282MiB |
|    0      2272      G   kwin_x11                                      53MiB |
|    0      2279      G   /usr/bin/krunner                             105MiB |
|    0      2281      G   /usr/bin/plasmashell                          96MiB |
|    0      3136      C   ...ilso4/anaconda3/envs/fermi21/bin/python  5363MiB |
|    0      4764      G   ...pycharm-community-2019.3.1/jbr/bin/java     2MiB |
+-----------------------------------------------------------------------------+
```

**Describe the current behavior**
Can't compute derivatives of output wrt intermediate variables created inside a tf.function wrapped function. 

If tf.function wrapper is removed the function behaves as expected.

**Describe the expected behavior**
Can compute these derivatives. 

**Code to reproduce the issue**
```
import tensorflow as tf
print(tf.__version__)

y = tf.Variable(2.)
z = tf.Variable(3.)
x = tf.random.normal((1,))

@tf.function # remove this to function
def call(x, y, z):
    a = x * y
    b = a * z
    return a, b

with tf.GradientTape(True) as g:
    g.watch(x)
    a, b = call(x, y, z)

gx, ga =  g.gradient(b, [x, a])
print(ga)
print(gx)
```

**Other info / logs**
2.2.0-dev20200123
None
tf.Tensor([6.], shape=(1,), dtype=float32)

"
36254,Dropout problem in tensorflow 1.14,"**System information**
- OS Platform and Distribution: Windows 10 on two different PCs
- TensorFlow installed from (source or binary): Binary
- TensorFlow version (use command below): 1.12 on one system and 1.14 on another system
- Python version: 3.6.5
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: 9.0 (for tf1.12) and 10.0 (for tf1.14)
- GPU model and memory: Nvidia GTX 1080 Ti (for tf1.12) and RTX 2080 Ti (for tf1.14)

**Describe the current behavior**
I defined a simple one-layer LSTM network with a dropout layer. The code is below and the input is a sequence of shape (105, 15), grouped into 1024 samples per batch.

```
def keras_model(input_shape):
    from tensorflow.keras.layers import Input, CuDNNLSTM, Dense, Dropout

    inputs = Input(shape=input_shape)
    x = CuDNNLSTM(64, return_sequences=False)(inputs)
    x = Dropout(0.1)(x)
    outputs = Dense(NC, activation='softmax')(x)

    return tf.keras.Model(inputs, outputs)
```

 It worked under tf1.12 but it is not working under tf1.14 and I get below log:

```
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
input_1 (InputLayer)         [(None, None, 15)]        0
_________________________________________________________________
cu_dnnlstm (CuDNNLSTM)       (None, 64)                20736
_________________________________________________________________
dropout (Dropout)            (None, 64)                0
_________________________________________________________________
dense (Dense)                (None, 7)                 455
=================================================================
Total params: 21,191
Trainable params: 21,191
Non-trainable params: 0
_________________________________________________________________

Epoch 1/1000
Traceback (most recent call last):
  File ""run_rnn2.py"", line 653, in <module>
    doWork(a)
  File ""run_rnn2.py"", line 502, in doWork
    validation_steps=val_steps, verbose=verbose, callbacks=CB)
  File ""D:\shahriar\tf1.14_py3.6.5\lib\site-packages\tensorflow\python\keras\engine\training.py"", line 780, in fit
    steps_name='steps_per_epoch')
  File ""D:\shahriar\tf1.14_py3.6.5\lib\site-packages\tensorflow\python\keras\engine\training_arrays.py"", line 274, in model_iteration
    batch_outs = f(actual_inputs)
  File ""D:\shahriar\tf1.14_py3.6.5\lib\site-packages\tensorflow\python\keras\backend.py"", line 3292, in __call__
    run_metadata=self.run_metadata)
  File ""D:\shahriar\tf1.14_py3.6.5\lib\site-packages\tensorflow\python\client\session.py"", line 1458, in __call__
    run_metadata_ptr)
tensorflow.python.framework.errors_impl.InvalidArgumentError: 2 root error(s) found.
  (0) Invalid argument: The second input must be a scalar, but it has shape [1024]
         [[{{node dropout/cond/Switch}}]]
         [[metrics/acc/Identity/_89]]
  (1) Invalid argument: The second input must be a scalar, but it has shape [1024]
         [[{{node dropout/cond/Switch}}]]
0 successful operations.
0 derived errors ignored.
```

What can be the reason?
I can not upgrade my tensorflow to another version. I need to have tf1.14 work with the same code as tf1.12 under python 3.6.5.

"
36253,How is the support for tensorflow 2.0 and keras in this?,Need to understand if this support tensorflow 2.0 and tfx serving directly?
36252,TF 2.1 libtensorflow library does not build under Windows,"- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
None
- TensorFlow installed from (source or binary):
Source
- TensorFlow version:
master or 2.1 labeled version
- Python version:
3.6.8
- Installed using virtualenv? pip? conda?:
Partially Pip as specified in manual at 
- Bazel version (if compiling from source):
bazel 1.2.1
- GCC/Compiler version (if compiling from source):
MSVC 2017 or MSVC 2019
- CUDA/cuDNN version:
None
- GPU model and memory:
None

libtensorflow does not build. Tried 2.1 version and current (27 jan 2020) master version

Used
bazel build --define=no_tensorflow_py_deps=true --config opt //tensorflow/tools/lib_package:libtensorflow

Used either set BAZEL_VS= {{ path to VS2019 }} or {{ path to VS2017 }}

Error is always:

ERROR: /tensorflow/tensorflow/core/framework/BUILD:575:1: C++ compilation of rule '//tensorflow/core/framework:bfloat16' failed (Exit 2)
\org_tensorflow\external\eigen_archive\unsupported\eigen\cxx11\src/Tensor/TensorBlock.h(1028): error C2061: syntax error: identifier 'Kind'
\org_tensorflow\external\eigen_archive\unsupported\eigen\cxx11\src/Tensor/TensorBlock.h(1134): note: see reference to class template instantiation 'Eigen::internal::StridedLinearBufferCopy<Scalar,IndexType>' being compiled
\org_tensorflow\external\eigen_archive\unsupported\eigen\cxx11\src/Tensor/TensorBlock.h(1037): error C2061: syntax error: identifier 'Kind'

It seems related to the Eigen library header file(s) missing in includes ? 

"
36250,Tensorflow keras metrics cannot be used straight into the keras compile method,"
**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Linux Ubuntu
- TensorFlow installed from (source or binary): using pip
- TensorFlow version (use command below):  2.1.0
- Keras version: 2.3.1
- Python version: 3.6.4

tensorflow.version.GIT_VERSION, tensorflow.version.VERSION
('v2.1.0-rc2-17-ge5bf8de', '2.1.0')

**Describe the current behavior**

I found an anomalous behavior when specifying tensorflow.keras.metrics directly into the Keras compile API:
```
from tensorflow.keras.metrics import Recall, Precision
model.compile(..., metrics=[Recall(), Precision()]
```
When looking at the history track the precision and recall plots at each epoch (using keras.callbacks.History) I observe very similar performances to both the training set and the validation set.
The weirdest thing is that both Recall and Precision increase at each epoch while the loss is clearly not improving anymore.

I found the issue to be related to the statefulness of the Tensorflow metrics objects.
Everytime you call the metric object it will append a new batch of data that get mixed with both training and validation data and cumulates at each epoch.

**Describe the expected behavior**

The expected behavior is that the metrics object should be stateless and do not depend on previous calls. Each time we calculate the metric (precision, recall or anything else), the function should only depend on the specified y_true and y_pred.

To workaround the issue we need to have either have Keras to be smart enough to re-instantiate the metric object at every call or to provide a tensorflow wrapper that is stateless. Maybe a decorator?

**Code to reproduce the issue**

```from tensorflow.keras.metrics import Recall, Precision, AUC, TopKCategoricalAccuracy, PrecisionAtRecall
recall=Recall()

y_train =[[0, 1, 0, 1],
         [1,0,0,0]]

y_train_pred=[[0.1,0.50001,0.4,0.7],
       [0.5,0.51,1,0]]

y_test =[[1, 1, 0, 0],
         [0,0,0,1]]

y_test_pred=[[0.1,0.80,0.8,0.9],
            [0.1,0.4,0.99,0]]


print(recall(y_train, y_train_pred))
print(recall(y_test, y_test_pred))
recall=Recall()
print(recall(y_test, y_test_pred))

recall=Recall()
print(recall(y_test, y_test_pred))
print(recall(y_train, y_train_pred))
```

**Other info / logs**
The code above will print:
```
tf.Tensor(0.6666667, shape=(), dtype=float32)
tf.Tensor(0.5, shape=(), dtype=float32)
tf.Tensor(0.33333334, shape=(), dtype=float32)
tf.Tensor(0.33333334, shape=(), dtype=float32)
tf.Tensor(0.5, shape=(), dtype=float32)
```
As you can see the behavior is not stateless but is the concatenation of all of the apply calls since the object instantiation.
"
36249,Issue on download_and_extract URL DIR download_dependencies.sh,"I follow [the build for arm64](https://www.tensorflow.org/lite/guide/build_arm64) and try  to execute `download_dependencies.sh` script but end up with issue:

```
~/work/tensorflow$ ./tensorflow/lite/tools/make/download_dependencies.sh
./tensorflow/lite/tools/make/download_dependencies.sh: line 59: 1: Usage: download_and_extract URL DIR
```

How it can be fixed?
"
36248,TF-Lite example label Image w shared library,"Please update `label_image` example to be compilable using a shared library.
It means to use a shared library with `label_image` example."
36247,XLA Warning and could not interpret set environment,"**System information**
- OS Platform and Distribution:18.04
- TensorFlow version: 1.14.0
- Python version: 2.7.17

`Couldn't interpret value =/home/hyadav/deephyp/lib/python2.7/site-packages/tensorflow/compiler/xla:--tf_xla_cpu_global_jit=/home/hyadav/deephyp/lib/python2.7/site-packages/tensorflow/compiler/xla:=--tf_xla_cpu_global_jit=--tf_xla_cpu_global_jit for flag tf_xla_cpu_global_jit.`

I tried using the following export TF_XLA_FLAGS=--tf_xla_cpu_global_jit=/mytensorflowpath/tensorflow/compiler/xla:$TF_XLA_FLAGS=--tf_xla_cpu_global_jit from issue #30308 and get the above. "
36246,Hessian-vector product raises exception about Fetch argument,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Arch Linux
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: n/a
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): v1.15.0-rc3-22-g590d6ee 1.15.0
- Python version: Python 3.7.6
- Bazel version (if compiling from source): n/a
- GCC/Compiler version (if compiling from source): n/a
- CUDA/cuDNN version: n/a
- GPU model and memory: n/a

**Describe the current behavior**
Trying to compute the Hessian-vector product of a graph with a linear dependence on a tensor produces a `TypeError` exception:
```raw
TypeError: Fetch argument None has invalid type <class 'NoneType'>` exception.
```

**Code to reproduce the issue**
```python
import itertools
import os

import numpy.random as rnd
import tensorflow as tf
from tensorflow.python.ops.gradients_impl import _hessian_vector_product

os.environ[""TF_CPP_MIN_LOG_LEVEL""] = ""3""


def main():
    n = 10

    x = tf.Variable(tf.zeros(n, dtype=tf.float64), name=""x"")
    y = tf.Variable(tf.zeros(n, dtype=tf.float64), name=""y"")
    z = tf.Variable(tf.zeros(n, dtype=tf.float64), name=""z"")
    function = tf.reduce_sum(x ** 2 + y + z ** 3)

    arguments = (x, y, z)
    zeros = [tf.zeros_like(argument) for argument in arguments]
    hessian = _hessian_vector_product(function, arguments, zeros)

    x, y, z = [rnd.randn(n) for _ in range(3)]
    u, v, w = [rnd.randn(n) for _ in range(3)]

    feed_dict = {
        key: value
        for key, value in zip(itertools.chain(arguments, zeros),
                              (x, y, z, u, v, w))
    }
    with tf.Session() as session:
        hessian_vector_product = session.run(hessian, feed_dict)

    print(hessian_vector_product)


if __name__ == ""__main__"":
    main()
```"
36245,Malformatted doc page for SGD optimizer,"## URL(s) with the issue:

https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/SGD#apply_gradients

## Description of issue (what needs changing):

### Clear description

The formatting in the ""References"" section is wrong; there is a ``nesterov = True,`` that has nothing to do with the reference."
36244,Default training algorithm: When are the gradients applied?,"## Description of issue (what needs changing):

It is not clear how a Keras model is trained by default. Are the gradients applied after each minibatch, or are they averaged over all minibatches, and then the average gradients are applied?"
36241,EarlyStopping TensorFlow 2.0 discrepancy,"I am running a code using Python 3.7.5 with TensorFlow 2.0 for MNIST classification.
I am using **EarlyStopping** from TensorFlow 2.0 and the callback I have for it is:

    callbacks = [
                 tf.keras.callbacks.EarlyStopping(
                     monitor='val_loss', patience = 3,
                     min_delta=0.001
                 )
    ]


According to [EarlyStopping - TensorFlow 2.0][1] page, the definition of **min_delta** parameter is as follows:

**min_delta: Minimum change in the monitored quantity to qualify as an
improvement, i.e. an absolute change of less than min_delta, will
count as no improvement.**




> Train on 60000 samples, validate on 10000 samples
> 
> Epoch 1/15 60000/60000 [==============================] - 10s
> 173us/sample - loss: 0.2040 - accuracy: 0.9391 - val_loss: 0.1117 -
> val_accuracy: 0.9648
> 
> Epoch 2/15 60000/60000 [==============================] - 9s
> 150us/sample - loss: 0.0845 - accuracy: 0.9736 - val_loss: 0.0801 -
> val_accuracy: 0.9748
> 
> Epoch 3/15 60000/60000 [==============================] - 9s
> 151us/sample - loss: 0.0574 - accuracy: 0.9817 - val_loss: 0.0709 -
> val_accuracy: 0.9795
> 
> Epoch 4/15 60000/60000 [==============================] - 9s
> 149us/sample - loss: 0.0434 - accuracy: 0.9858 - val_loss: 0.0787 -
> val_accuracy: 0.9761
> 
> Epoch 5/15 60000/60000 [==============================] - 9s
> 151us/sample - loss: 0.0331 - accuracy: 0.9893 - val_loss: 0.0644 -
> val_accuracy: 0.9808
> 
> Epoch 6/15 60000/60000 [==============================] - 9s
> 150us/sample - loss: 0.0275 - accuracy: 0.9910 - val_loss: 0.0873 -
> val_accuracy: 0.9779
> 
> Epoch 7/15 60000/60000 [==============================] - 9s
> 151us/sample - loss: 0.0232 - accuracy: 0.9921 - val_loss: 0.0746 -
> val_accuracy: 0.9805
> 
> Epoch 8/15 60000/60000 [==============================] - 9s
> 151us/sample - loss: 0.0188 - accuracy: 0.9936 - val_loss: 0.1088 -
> val_accuracy: 0.9748

Now if I look at the last three epochs viz., epochs 6, 7, and 8 and look at the validation loss ('val_loss'), their values are:

0.0688, 0.0843 and 0.0847.

And the differences between consecutive 3 terms are: 0.0155, 0.0004. But isn't the first difference greater than 'min_delta' as defined in the callback. 

The code I came up with for EarlyStopping is as follows:

    # numpy array to hold last 'patience = 3' values-
    pv = [0.0688, 0.0843, 0.0847]
    
    # numpy array to compute differences between consecutive elements in 'pv'-
    differences = np.diff(pv, n=1)
    
    differences
    # array([0.0155, 0.0004])
    
    
    # minimum change required for monitored metric's improvement-
    min_delta = 0.001
    
    # Check whether the consecutive differences is greater than 'min_delta' parameter-
    check = differences > min_delta
    
    check
    # array([ True,  False])
    
    # Condition to see whether all 3 'val_loss' differences are less than 'min_delta'
    # for training to stop since EarlyStopping is called-
    if np.all(check == False):
        print(""Stop Training - EarlyStopping is called"")
        # stop training 


But according to the 'val_loss', the differences between the not ALL of the 3 last epochs are greater than 'min_delta' of 0.001. For example, the first difference is greater than 0.001 (0.0843 - 0.0688) while the second difference is less than 0.001 (0.0847 - 0.0843).

Also, according to **patience** parameter definition of ""EarlyStopping"":

**patience: Number of epochs with no improvement after which training will be stopped.**

So, EarlyStopping should be called when there is no improvement for 'val_loss' for 3 consecutive epochs where the absolute change of less than 'min_delta' does not count as improvement.

Then why is EarlyStopping called?




Another example is:

Train on 60000 samples, validate on 10000 samples
Epoch 1/30
60000/60000 [==============================] - 11s 179us/sample - loss: 0.2032 - accuracy: 0.9399 - val_loss: 0.1195 - val_accuracy: 0.9626
Epoch 2/30
60000/60000 [==============================] - 9s 155us/sample - loss: 0.0852 - accuracy: 0.9732 - val_loss: 0.0891 - val_accuracy: 0.9712
Epoch 3/30
60000/60000 [==============================] - 9s 154us/sample - loss: 0.0552 - accuracy: 0.9830 - val_loss: 0.0897 - val_accuracy: 0.9723
Epoch 4/30
60000/60000 [==============================] - 9s 153us/sample - loss: 0.0460 - accuracy: 0.9850 - val_loss: 0.0746 - val_accuracy: 0.9794
Epoch 5/30
60000/60000 [==============================] - 9s 152us/sample - loss: 0.0325 - accuracy: 0.9894 - val_loss: 0.0787 - val_accuracy: 0.9774
Epoch 6/30
60000/60000 [==============================] - 9s 154us/sample - loss: 0.0267 - accuracy: 0.9913 - val_loss: 0.0736 - val_accuracy: 0.9782
Epoch 7/30
60000/60000 [==============================] - 9s 153us/sample - loss: 0.0250 - accuracy: 0.9920 - val_loss: 0.0857 - val_accuracy: 0.9777
Epoch 8/30
60000/60000 [==============================] - 9s 153us/sample - loss: 0.0210 - accuracy: 0.9929 - val_loss: 0.0808 - val_accuracy: 0.9790
Epoch 9/30
60000/60000 [==============================] - 9s 153us/sample - loss: 0.0179 - accuracy: 0.9937 - val_loss: 0.1043 - val_accuracy: 0.9768

Here, the last 3 'val_loss' are:
0.08566837142373625, 0.08082119292882962 and 0.10430033170154183.

And the consecutive differences between the 2 adjacent 'val_loss' are:
0.00484718 and 0.02347914

Now, both of these differences are greater than 'min_delta' of 0.001. But, 'EarlyStopping' again halts training.

What am I not getting?

  [1]: https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping


The complete code GitHub URL:
https://github.com/arjun-majumdar/Lottery_Ticket_Hypothesis-TensorFlow_2/blob/master/tfmot_sparsity_experiment.ipynb"
36240,TF 2.1 Keras: Cached datasets use 40% more memory than in TF 2.0,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.1.0
- Python version: 3.7.6
- CUDA/cuDNN version: 10.1 / 7.6.5.32
- GPU model and memory: NVIDIA V100

**Describe the current behavior**

When running training with cached repeated datasets in Keras, TensorFlow 2.1 (and `tf-nightly==2.2.0.dev20200124`) use 40-50% more memory than TensorFlow 2.0.

E.g. a large cached dataset like [ImageNet](https://www.tensorflow.org/datasets/catalog/imagenet2012) will require **~230 GB** of memory where as in TensorFlow 2.0 the same code only required **155 GB**. This is a 75 GB increase in memory usage which makes it hard to cache large datasets in memory.

```python
import math
import tensorflow as tf
from tensorflow import keras
import tensorflow_datasets as tfds


batch_size = 1024

dataset, info = tfds.load(
    ""imagenet2012:5.0.*"",
    decoders={""image"": tfds.decode.SkipDecoding()},
    split=""train"",
    with_info=True,
)

val_dataset = tfds.load(
    ""imagenet2012:5.0.*"",
    decoders={""image"": tfds.decode.SkipDecoding()},
    split=""validation"",
)

steps_per_epoch = math.ceil(info.splits[""train""].num_examples / batch_size)
val_steps = math.ceil(info.splits[""validation""].num_examples / batch_size)


def _decode_and_center_crop(image_bytes):
    """"""Crops to center of image with padding then scales image_size.""""""
    shape = tf.image.extract_jpeg_shape(image_bytes)
    image_height = shape[0]
    image_width = shape[1]
    image_size = 224

    padded_center_crop_size = tf.cast(
        (
            (image_size / (image_size + 32))
            * tf.cast(tf.minimum(image_height, image_width), tf.float32)
        ),
        tf.int32,
    )

    offset_height = ((image_height - padded_center_crop_size) + 1) // 2
    offset_width = ((image_width - padded_center_crop_size) + 1) // 2
    crop_window = tf.stack(
        [offset_height, offset_width, padded_center_crop_size, padded_center_crop_size]
    )
    image = tf.image.decode_and_crop_jpeg(image_bytes, crop_window, channels=3)
    image = tf.compat.v1.image.resize_bicubic([image], [image_size, image_size])[0]
    return image


def preprocessing(data):
    return tf.cast(_decode_and_center_crop(data[""image""]), tf.float32), data[""label""]


dataset = (
    dataset.cache()
    .shuffle(10 * batch_size)
    .repeat()
    .map(preprocessing, num_parallel_calls=tf.data.experimental.AUTOTUNE)
    .batch(batch_size)
    .prefetch(1)
)

val_dataset = (
    val_dataset.cache()
    .repeat()
    .map(preprocessing, num_parallel_calls=tf.data.experimental.AUTOTUNE)
    .batch(batch_size)
    .prefetch(1)
)

model = keras.models.Sequential(
    [
        keras.layers.GlobalMaxPool2D(input_shape=(224, 224, 3)),
        keras.layers.Dense(1000, activation=""softmax"",),
    ]
)

model.compile(
    optimizer=""adam"",
    loss=""sparse_categorical_crossentropy"",
    metrics=[""accuracy"", ""sparse_top_k_categorical_accuracy""],
)

model.fit(
    dataset,
    epochs=5,
    steps_per_epoch=steps_per_epoch,
    validation_data=val_dataset,
    validation_steps=val_steps,
)
```

**Describe the expected behavior**
No increased memory requirements when switching from TensorFlow 2.0 to 2.1

**Other info / logs**

This issue doesn't appear when not using a validation dataset:
```python
model.fit(dataset, epochs=5, steps_per_epoch=steps_per_epoch)
```

The issues also doesn't appear if the dataset is not repeated. However then we would run into #36126 which logs error messages after each epoch:
```python
dataset = (
    dataset.cache()
    .shuffle(10 * batch_size)
    .map(preprocessing, num_parallel_calls=tf.data.experimental.AUTOTUNE)
    .batch(batch_size)
    .prefetch(1)
)

val_dataset = (
    val_dataset.cache()
    .map(preprocessing, num_parallel_calls=tf.data.experimental.AUTOTUNE)
    .batch(batch_size)
    .prefetch(1)
)

model = keras.models.Sequential(
    [
        keras.layers.GlobalMaxPool2D(input_shape=(224, 224, 3)),
        keras.layers.Dense(1000, activation=""softmax"",),
    ]
)

model.compile(
    optimizer=""adam"",
    loss=""sparse_categorical_crossentropy"",
    metrics=[""accuracy"", ""sparse_top_k_categorical_accuracy""],
)

model.fit(dataset, epochs=5, validation_data=val_dataset)
```

Judging from the observations above it looks like the iteration of the validation dataset is broken inside Keras, so it doesn't show up when the dataset iterator is recreated when used without `steps_per_epoch`.

What is the recommended way of using `tf.data.Datasets` with Keras models?"
36238,AutoGraph issue,"**System information**
- OS Platform and Distribution : CentOS Linux release 7.7.1908 (Core) 
- TensorFlow version: 1.15.0-dev20190718
- Python version: 3.4
 
I am trying to save a custom built LSTM model.
The issue arises when saving the lstm model as:
final_model.save(""complete_model"",save_format='tf'), whereas it is doesn't throw an error upon saving it as final_model.save(""complete_model.h5""). 

I tried to downgrade gast to version 0.2.2 as suggested by ticket**(TF2.0 AutoGraph issue
#32377)** but still doesn't work.
The error message is as follows:

W0127 16:22:09.873542 140113418938176 ag_logging.py:146] Entity <function Function._initialize_uninitialized_variables..initialize_variables at 0x7f6de43a8048> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, export AUTOGRAPH_VERBOSITY=10) and attach the full output. Cause: No module named 'tensorflow_core.estimator'
W0127 16:22:09.882860 140113418938176 ag_logging.py:146] Entity <function _wrap_call_and_conditional_losses..call_and_return_conditional_losses at 0x7f6de41e8048> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, export AUTOGRAPH_VERBOSITY=10) and attach the full output. Cause: No module named 'tensorflow_core.estimator'
W0127 16:22:09.911009 140113418938176 save.py:129] Skipping full serialization of object <tensorflow.python.keras.layers.recurrent.LSTM object at 0x7f6e00539f60>, because an error occurred while tracing layer functions. Error message: in converted code:
relative to /usr/local/lib/python3.4/site-packages/tensorflow_core/python/keras:

saving/saved_model/save.py:535 call_and_return_conditional_losses
    return layer_call(inputs, training=training), layer.get_losses_for(inputs)
layers/recurrent.py:2535 call
    inputs, mask=mask, training=training, initial_state=initial_state)
layers/recurrent.py:745 call
    zero_output_for_mask=self.zero_output_for_mask)
backend.py:3794 rnn
    input_time_zero, tuple(initial_states) + tuple(constants))
layers/recurrent.py:730 step
    output, new_states = self.cell.call(inputs, states, **kwargs)

TypeError: wrapped_call() takes 1 positional argument but 2 were given
W0127 16:22:09.916115 140113418938176 ag_logging.py:146] Entity <function _wrap_call_and_conditional_losses..call_and_return_conditional_losses at 0x7f6de41e8488> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, export AUTOGRAPH_VERBOSITY=10) and attach the full output. Cause: No module named 'tensorflow_core.estimator'
W0127 16:22:09.943473 140113418938176 save.py:129] Skipping full serialization of object <tensorflow.python.keras.engine.training.Model object at 0x7f6dff6e65c0>, because an error occurred while tracing layer functions. Error message: in converted code:
relative to /usr/local/lib/python3.4/site-packages/tensorflow_core/python/keras:

saving/saved_model/save.py:535 call_and_return_conditional_losses
    return layer_call(inputs, training=training), layer.get_losses_for(inputs)
engine/network.py:737 call
    return self._run_internal_graph(inputs, training=training, mask=mask)
engine/network.py:879 _run_internal_graph
    output_tensors = layer(computed_tensors, **kwargs)
layers/recurrent.py:621 __call__
    return super(RNN, self).__call__(inputs, **kwargs)
engine/base_layer.py:713 __call__
    outputs = call_fn(inputs, *args, **kwargs)
layers/recurrent.py:2535 call
    inputs, mask=mask, training=training, initial_state=initial_state)
layers/recurrent.py:745 call
    zero_output_for_mask=self.zero_output_for_mask)
backend.py:3794 rnn
    input_time_zero, tuple(initial_states) + tuple(constants))
layers/recurrent.py:730 step
    output, new_states = self.cell.call(inputs, states, **kwargs)

TypeError: wrapped_call() takes 1 positional argument but 2 were given
2020-01-27 16:22:09.957051: W tensorflow/python/util/util.cc:288] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
W0127 16:22:09.982703 140113418938176 ag_logging.py:146] Entity <function Layer._handle_weight_regularization.._loss_for_variable at 0x7f6e017b6d90> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, export AUTOGRAPH_VERBOSITY=10) and attach the full output. Cause: No module named 'tensorflow_core.estimator'
W0127 16:22:09.992292 140113418938176 ag_logging.py:146] Entity <function Function._initialize_uninitialized_variables..initialize_variables at 0x7f6de43a8400> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, export AUTOGRAPH_VERBOSITY=10) and attach the full output. Cause: No module named 'tensorflow_core.estimator


"
36237,Layer Names tf.keras.applications vs keras.applications not matching,"Not sure if this is a documentation issue or a functional bug. 

## Description of issue:
The layer names in 'tf.keras.applications' are not consistent with the layer names in 'keras.applications'.

## Example:
`keras.applications.resnet50.ResNet50(weights='imagenet').summary()` prints the following layers:

> (...)
> __________________________________________________________________________________________________
> **conv1_pad** (ZeroPadding2D)       (None, 230, 230, 3)  0           input_3[0][0]                    
> __________________________________________________________________________________________________
> **conv1** (Conv2D)                  (None, 112, 112, 64) 9472        conv1_pad[0][0]                  
> __________________________________________________________________________________________________
> **bn_conv1** (BatchNormalization)   (None, 112, 112, 64) 256         conv1[0][0]                      
> __________________________________________________________________________________________________
> **activation_50** (Activation)      (None, 112, 112, 64) 0           bn_conv1[0][0]                   
> __________________________________________________________________________________________________
> **pool1_pad** (ZeroPadding2D)       (None, 114, 114, 64) 0           activation_50[0][0]              
> __________________________________________________________________________________________________
> (...)

                           
`tf.keras.applications.resnet50.ResNet50(weights='imagenet').summary()` prints the following layers:

> (...)
> __________________________________________________________________________________________________
> **conv1_pad** (ZeroPadding2D)       (None, 230, 230, 3)  0           input_6[0][0]                    
> __________________________________________________________________________________________________
> **conv1_conv** (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  
> __________________________________________________________________________________________________
> **conv1_bn** (BatchNormalization)   (None, 112, 112, 64) 256         conv1_conv[0][0]                 
> __________________________________________________________________________________________________
> **conv1_relu** (Activation)         (None, 112, 112, 64) 0           conv1_bn[0][0]                   
> __________________________________________________________________________________________________
> **pool1_pad** (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_relu[0][0]                 
> __________________________________________________________________________________________________
> (...)

This can lead to errors if code relying on layer names is migrated from `keras` to `tf.keras`. Even after looking for it for quite a bit, I have not found any documentation explaining the change of layer names. Also, I manually needed to map `keras `layer names to `tf.keras` layer names, which would be avoidable with some nice documentation.

## URL(s) with the issue:
Probably this should be mentioned in the migration docs or the applications docs.
https://www.tensorflow.org/guide/migrate#a_note_on_slim_contriblayers
https://www.tensorflow.org/api_docs/python/tf/keras/applications


## Usage example

The following code snippet runs when applications is imported from `keras `but not with `tf.keras`, as the layer is not found.

```
loaded_model = applications.ResNet50(weights='imagenet')

partial_model = Model(inputs=loaded_model.input, outputs=loaded_model.get_layer('res5c_branch2c').output)
```

Some easily findable documentation should be explaining why the layer is not found (renamed layer names) and where to find the mapping from `keras` layer names to `tf.keras` layer names (i.e., the mapping from `res5c_branch2c ` to `conv5_block3_3_conv`, which is the layer name used in tf.keras).

## Used versions in these examples
tensorflow 2.1.0
Keras 2.3.1

## Final Remark
I'm not sure if renaming the layers was that useful... While the tf.keras layer names might be better readable, papers and tutorials often refer to the keras label names - and users now seem to have to find a mapping themself. 
"
36236,GradientTape.gradient fails when tf.gather is used after LSTM/GRU in tf.function,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): **No**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **Linux Stretch**
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): **binary**
- TensorFlow version (use command below): **2.1.0** and **2.0.0**
- Python version: **3.6**

**Describe the current behavior**
Consider the following simple model running a GRU, tf.gather, and a linear regression:
```python
import tensorflow as tf

inputs = tf.keras.layers.Input(shape=[None, 1], dtype=tf.float32)
hidden = tf.keras.layers.GRU(10)(inputs)
hidden = tf.gather(hidden, [0])
output = tf.keras.layers.Dense(1)(hidden)
model = tf.keras.Model(inputs=inputs, outputs=output)

@tf.function
def train(x, y):
    with tf.GradientTape() as tape:
        predictions = model(x, training=True)
        loss = tf.losses.mean_squared_error(y, predictions)
    gradients = tape.gradient(loss, model.trainable_variables)

train(tf.constant([[[1], [2], [3]]], dtype=tf.float32), tf.constant([[1]], dtype=tf.float32))
```
Both TF 2.0.0 and TF 2.1.0 fails, with a similar error message (the following is TF 2.1):
```
    ValueError: All inputs to `ConcreteFunction`s must be Tensors; on invocation of __backward_standard_gru_918, the 0-th input (IndexedSlices(indices=Tensor(""Reshape_2:0"", shape=(1,), dtype=int32), values=Tensor(""Reshape_1:0"", shape=(1, 10), dtype=float32), dense_shape=Tensor(""Cast_2:0"", shape=(2,), dtype=int32))) was not a Tensor.
```

**Describe the expected behavior**

The code should work.

**Other info / logs**

The problem is caused by `tf.gather` generating `tf.IndexedSlices` as a derivative. However, current LSTM/GRU are graph functions and the backprop algorithm for graph functions assumes the inputs must be `tf.Tensor`s.

One possible workaround is not to use `tf.function` and use eager. Then the code works.

Another solution is to force conversion of the derivatives from `tf.IndexedSlices` to `tf.Tensor`. The easiest solution I found is to use `* 1`, which adds operation `Mul` to the computation graph, for which the conversion from `tf.IndexedSlices` to `Tensor` works. So the following works:
```python
inputs = tf.keras.layers.Input(shape=[None, 1], dtype=tf.float32)
hidden = tf.keras.layers.GRU(10)(inputs)
hidden = tf.gather(hidden * 1, [0])
output = tf.keras.layers.Dense(1)(hidden)
model = tf.keras.Model(inputs=inputs, outputs=output)

@tf.function
def train(x, y):
    with tf.GradientTape() as tape:
        predictions = model(x, training=True)
        loss = tf.losses.mean_squared_error(y, predictions)
    gradients = tape.gradient(loss, model.trainable_variables)

train(tf.constant([[[1], [2], [3]]], dtype=tf.float32), tf.constant([[1]], dtype=tf.float32))
```

**Possible solution**
I assume an automatic conversion of `tf.IndexedSlices` to `tf.Tensor` should be performed. As a proof of concept, I changed the line https://github.com/tensorflow/tensorflow/blob/1f404dc482e3b7e4244cc1603725e555f06f8b9b/tensorflow/python/eager/function.py#L1731
to
```python
  tensor_inputs.append(ops.convert_to_tensor(arg))
```
and the code then works as expected (converting the `tf.IndexedSlices` to `tf.Tensor`). However, a proper fix is definitely more complicated."
36235,Dll load failed,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Python version**:
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with:

```bash
python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""
```

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
36234,SpeechRecognition android example,"**System information**
- OS Platform - macOS mojave:
- TensorFlow version - master


**Failure details**
im trying to build example from tensorflow/tensorflow/examples/speech_commands/
so i save model by freeze.py and get savedModel then i build android app from tensorflow/tensorflow/examples/android/
so my quesion is how to use savedModel in mobile in this example?

another question is how to convert savedModel to Tflite?

**Command used to run the converter**

```
import tensorflow as tf

converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)
tflite_model = converter.convert()
open(""converted_model.tflite"", ""wb"").write(tflite_model)
```

this code produce some errors
"
36233,object_detection,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).
2. The form below must be filled out.
3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:
- **TensorFlow installed from (source or binary)**:
- **TensorFlow version (use command below)**:
- **Python version**:
- **Bazel version (if compiling from source)**:
- **GCC/Compiler version (if compiling from source)**:
- **CUDA/cuDNN version**:
- **GPU model and memory**:
- **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with:

```bash
python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""
```

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
36232,Convert TensorArray to RaggedTensor,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): TensorFlow-gpu 1.14+
- Are you willing to contribute it (Yes/No): No.
  Not this stage.

**Describe the feature and the current behavior/state.**
  As tf.keras.model could take a raggedtensor as an input, there is a need to convert a TensorArray to a RaggedTensor.

**Will this change the current api? How?**
   Yes, it requires a new api to TensorArray (say, to_ragged).

**Who will benefit with this feature?**
   This allows the output (no rectangle tensors of same shape) of tf.map_fn of batch-based slicing operation as an input to a tf.keras.layers.Conv2D seamlessly. 

**Any Other info.**
  No.

Thank you"
36231,How to save weights of part of a network in TF2.0?,"TF provides `save_weights` API which saves the weights of a network. However, it does not allow one to save only part of the network. For instance, I have 

```
class X(Model):
    ...
    group1 = [layer_a, layer_b]
    group2 = [...]

model = X()
```

and I just want to save the weights of `group1`. PyTorch has the `ModuleList` API which is able to turn `group1` into a subnetwork and allows one to just call `X.group1.save_weights(...)`. What about TF? How to do so in TF2.0?

"
36229,"external/pybind11\include/pybind11/pybind11.h(139): error C2783: “std::tuple<pybind11::detail::type_caster<pybind11::handle,void>>::tuple(void) noexcept(<expr>)”: 未能为“__formal”推导 模板 参数","**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Windows 10 1903
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary):source
- TensorFlow version:1.15.0
- Python version: Python 3.6.8rc1
- Installed using virtualenv? pip? conda?: N/A
- Bazel version (if compiling from source):0.25.0
- GCC/Compiler version (if compiling from source):VS2017 MSVC 14.16.27023
- CUDA/cuDNN version:10.2/7.0
- GPU model and memory: GTX1070 8.0GB



**Describe the problem**
使用bazel编译TensorFlow时提示 
external/pybind11\include/pybind11/pybind11.h(139): error C2783: “std::tuple<pybind11::detail::type_caster<pybind11::handle,void>>::tuple(void) noexcept(<expr>)”: 未能为“__formal”推导 模板 参数

**Provide the exact sequence of commands / steps that you executed before running into the problem**

按照https://www.tensorflow.org/install/source_windows?hl=zh-cn#cpu配置

**Any other info / logs**

注意: 包含文件:   F:\Program Files (x86)\Microsoft Visual Studio\2017\Professional\VC\Tools\MSVC\14.16.27023\include\sstream
external/pybind11\include/pybind11/pybind11.h(139): error C2783: “std::tuple<pybind11::detail::type_caster<pybind11::handle,void>>::tuple(void) noexcept(<expr>)”: 未能为“__formal”推导 模板 参数
F:\Program Files (x86)\Microsoft Visual Studio\2017\Professional\VC\Tools\MSVC\14.16.27023\include\tuple(429): note: 参见“std::tuple<pybind11::detail::type_caster<pybind11::handle,void>>::tuple”的声明
external/pybind11\include/pybind11/pybind11.h(73): note: 参见对正在编译的函数 模板 实例化“void pybind11::cpp_function::initialize<_Ty,R,pybind11::handle,pybind11::is_method>(Func &&,Return (__cdecl *)(pybind11::handle),const pybind11::is_method &)”的引用
        with
        [
            _Ty=pybind11::detail::enum_base::init::<lambda_46073d681fcd766eb481a3d0374dc63b>,
            R=pybind11::str,
            Func=pybind11::detail::enum_base::init::<lambda_46073d681fcd766eb481a3d0374dc63b>,
            Return=pybind11::str
        ]
external/pybind11\include/pybind11/pybind11.h(1416): note: 参见对正在编译的函数 模板 实例化“pybind11::cpp_function::cpp_function<pybind11::detail::enum_base::init::<lambda_46073d681fcd766eb481a3d0374dc63b>,pybind11::is_method,void>(Func &&,const pybind11::is_method &)”的引用
        with
        [
            Func=pybind11::detail::enum_base::init::<lambda_46073d681fcd766eb481a3d0374dc63b>
        ]
c:\users\reshiram\_bazel_reshiram\qnykyiqk\execroot\org_tensorflow\external\pybind11\include\pybind11\cast.h(1556): note: 参见对正在编译的 类 模板 实例化 ""pybind11::detail::descr<8>"" 的引用
c:\users\reshiram\_bazel_reshiram\qnykyiqk\execroot\org_tensorflow\external\pybind11\include\pybind11\cast.h(1554): note: 参见对正在编译的 类 模板 实例化 ""pybind11::detail::descr<5>"" 的引用
c:\users\reshiram\_bazel_reshiram\qnykyiqk\execroot\org_tensorflow\external\pybind11\include\pybind11\cast.h(1109): note: 参见对正在编译的 类 模板 实例化 ""pybind11::detail::descr<7>"" 的引用
external/pybind11\include/pybind11/pybind11.h(139): error C2783: “std::tuple<pybind11::detail::type_caster<pybind11::object,void>,pybind11::detail::type_caster<pybind11::object,void>>::tuple(void) noexcept(<expr>)”: 未能为“__formal”推导 模板 参数
F:\Program Files (x86)\Microsoft Visual Studio\2017\Professional\VC\Tools\MSVC\14.16.27023\include\tuple(429): note: 参见“std::tuple<pybind11::detail::type_caster<pybind11::object,void>,pybind11::detail::type_caster<pybind11::object,void>>::tuple”的声明
external/pybind11\include/pybind11/pybind11.h(73): note: 参见对正在编译的函数 模板 实例化“void pybind11::cpp_function::initialize<_Ty,R,pybind11::object,pybind11::object,pybind11::is_method>(Func &&,Return (__cdecl *)(pybind11::object,pybind11::object),const pybind11::is_method &)”的引用
        with
        [
            _Ty=pybind11::detail::enum_base::init::<lambda_ea06563a4979ca80a55a8ff1d879382b>,
            R=bool,
            Func=pybind11::detail::enum_base::init::<lambda_ea06563a4979ca80a55a8ff1d879382b>,
            Return=bool
        ]
external/pybind11\include/pybind11/pybind11.h(1474): note: 参见对正在编译的函数 模板 实例化“pybind11::cpp_function::cpp_function<pybind11::detail::enum_base::init::<lambda_ea06563a4979ca80a55a8ff1d879382b>,pybind11::is_method,void>(Func &&,const pybind11::is_method &)”的引用
        with
        [
            Func=pybind11::detail::enum_base::init::<lambda_ea06563a4979ca80a55a8ff1d879382b>
        ]
external/pybind11\include/pybind11/pybind11.h(139): error C2783: “std::tuple<pybind11::detail::type_caster<pybind11::object,void>>::tuple(void) noexcept(<expr>)”: 未能为“__formal”推导 模板 参数
F:\Program Files (x86)\Microsoft Visual Studio\2017\Professional\VC\Tools\MSVC\14.16.27023\include\tuple(429): note: 参见“std::tuple<pybind11::detail::type_caster<pybind11::object,void>>::tuple”的声明
external/pybind11\include/pybind11/pybind11.h(73): note: 参见对正在编译的函数 模板 实例化“void pybind11::cpp_function::initialize<_Ty,R,pybind11::object,pybind11::is_method>(Func &&,Return (__cdecl *)(pybind11::object),const pybind11::is_method &)”的引用
        with
        [
            _Ty=pybind11::detail::enum_base::init::<lambda_909c581f503d5f259cf84551105b4f30>,
            R=pybind11::int_,
            Func=pybind11::detail::enum_base::init::<lambda_909c581f503d5f259cf84551105b4f30>,
            Return=pybind11::int_
        ]
external/pybind11\include/pybind11/pybind11.h(1507): note: 参见对正在编译的函数 模板 实例化“pybind11::cpp_function::cpp_function<pybind11::detail::enum_base::init::<lambda_909c581f503d5f259cf84551105b4f30>,pybind11::is_method,void>(Func &&,const pybind11::is_method &)”的引用
        with
        [
            Func=pybind11::detail::enum_base::init::<lambda_909c581f503d5f259cf84551105b4f30>
        ]
Target //tensorflow/tools/pip_package:build_pip_package failed to build
INFO: Elapsed time: 767.769s, Critical Path: 62.28s
INFO: 2518 processes: 2518 local.
FAILED: Build did NOT complete successfully
"
