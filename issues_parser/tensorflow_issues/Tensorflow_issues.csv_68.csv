Issue Number,Issue Title,Issue Body
6592,About the implementation of recently added attentional seq2seq decoder function,"Hello, I heard a good news that the attentional seq2seq decoder function is recently added in the master branch.
It is a very pleasing news to me, since nowadays I have been struggling to implement the feature.

However, while reviewing the detailed implementation, I found some unclear points.

~~Firstly, in line 395-397 of attention_decoder_fn.py,
`attention_query` and `context` are concatenated and passed to a fully connected layer to be projected to a vector whose size is `num_units`.
As far as I know, the current implementations of RNN cells already do this procedure.
For example, the current implementation of `LSTMCell` (line 337-338 in core_rnn_cell_impl.py) concatenates `inputs` and `m_prev`, and multiplies the concatenated vector by `(input_dim + num_units, 4 * num_units)` weight matrix.
Thus, to avoid multiplying `inputs` with weight matrices two times, I think line 396-397 should be removed.~~
Reading codes again, I found I understood them wrongly.
And, I also think `concat_v2` function should be used to concatenate two vectors.

~~Secondly, in line 122-123 and 288-289, I see that `cell_output` is used as `attention_query` parameter of `attention_construct_fn`.
This is correct if we choose 'Luong-style' alignment calculation, where the computation path is ""h_t -> a_t -> c_t -> tilde h_t"", however this seems to be problematic if we choose 'Bahdanau-style' alignment calculation, where the computation path is ""h_(t-1) -> a_t -> c_t -> h_t"".
For now I can't think of a simple way to correct this behavior since the style of attention mechanism is unknown in decoder_fn's scope, but I think it should be dealt with anyway.~~

Please tell me if I read the codes wrongly! :)

I am a bit confused with the exact meaning of luong and bahdanau method. The both options use h_(t-1), unlike the referencing paper.
I close this, and will make a new issue after organizing my brain! "
6591,WideNet in examples/learn  throws error on UBUNTU 16.04 LTS,"Am running TensorFlow (0.11.0rc0) On Ubuntu 16.04 LTS installed via pip 

I was going through the guides at  https://www.tensorflow.org/tutorials/wide_and_deep/  I thought that my code had an error, but then running the example script at  https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/learn/wide_n_deep_tutorial.py 

Also throws the same error is the problem my environment? the script or Ubuntu 16.04 I haven't tried it in 14.04.

`Training data is downloaded to /tmp/tmp1SYKCv
Test data is downloaded to /tmp/tmpWhX5FI
model directory = /tmp/tmp9TzI1B
WARNING:tensorflow:The default value of combiner will change from ""sum"" to ""sqrtn"" after 2016/11/01.
WARNING:tensorflow:The default value of combiner will change from ""sum"" to ""sqrtn"" after 2016/11/01.
WARNING:tensorflow:The default value of combiner will change from ""sum"" to ""sqrtn"" after 2016/11/01.
WARNING:tensorflow:The default value of combiner will change from ""sum"" to ""sqrtn"" after 2016/11/01.
WARNING:tensorflow:The default value of combiner will change from ""sum"" to ""sqrtn"" after 2016/11/01.
WARNING:tensorflow:The default value of combiner will change from ""sum"" to ""sqrtn"" after 2016/11/01.
WARNING:tensorflow:The default value of combiner will change from ""sum"" to ""sqrtn"" after 2016/11/01.
WARNING:tensorflow:The default value of combiner will change from ""sum"" to ""sqrtn"" after 2016/11/01.
WARNING:tensorflow:The default value of combiner will change from ""sum"" to ""sqrtn"" after 2016/11/01.
WARNING:tensorflow:The default value of combiner will change from ""mean"" to ""sqrtn"" after 2016/11/01.
WARNING:tensorflow:The default value of combiner will change from ""mean"" to ""sqrtn"" after 2016/11/01.
WARNING:tensorflow:The default value of combiner will change from ""mean"" to ""sqrtn"" after 2016/11/01.
WARNING:tensorflow:The default value of combiner will change from ""mean"" to ""sqrtn"" after 2016/11/01.
WARNING:tensorflow:The default value of combiner will change from ""mean"" to ""sqrtn"" after 2016/11/01.
WARNING:tensorflow:The default value of combiner will change from ""mean"" to ""sqrtn"" after 2016/11/01.
WARNING:tensorflow:Change warning: default value of `enable_centered_bias` will change after 2016-10-09. It will be disabled by default.Instructions for keeping existing behaviour:
Explicitly set `enable_centered_bias` to 'True' if you want to keep existing behaviour.
WARNING:tensorflow:Using default config.
Traceback (most recent call last):
  File ""widenet.py"", line 208, in <module>
    tf.app.run()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 30, in run
    sys.exit(main(sys.argv[:1] + flags_passthrough))
  File ""widenet.py"", line 204, in main
    train_and_eval()
  File ""widenet.py"", line 197, in train_and_eval
    m.fit(input_fn=lambda: input_fn(df_train), steps=FLAGS.train_steps)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py"", line 333, in fit
    max_steps=max_steps)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py"", line 660, in _train_model
    features, targets = input_fn()
  File ""widenet.py"", line 197, in <lambda>
    m.fit(input_fn=lambda: input_fn(df_train), steps=FLAGS.train_steps)
  File ""widenet.py"", line 159, in input_fn
    for k in CATEGORICAL_COLUMNS}
  File ""widenet.py"", line 159, in <dictcomp>
    for k in CATEGORICAL_COLUMNS}
TypeError: __init__() got an unexpected keyword argument 'dense_shape'`"
6590,tf.nn.softmax fails with dim > 0,"If I do this:

    import tensorflow as tf
    import numpy as np

    session = tf.InteractiveSession()
    logits = np.array([[1.0,2.0,4.0],[1.0, 1.0, 1.0]])

    tf.nn.softmax(logits,dim=1).eval()

I get:
`InvalidArgumentError (see above for traceback): Requires start <= limit when delta > 0: 2/1
	 [[Node: range_9 = Range[Tidx=DT_INT32, _device=""/job:localhost/replica:0/task:0/cpu:0""](range_9/start, Sub_6, range_9/delta)]]`

But both of these work:

    tf.nn.softmax(logits.T, dim=0).eval().T
    tf.nn.softmax(logits, dim=-1).eval()

Those are what I would expect to get from the first one with `dim=1`.

I am using '0.12.0-rc1'
"
6589,tensorflow.python.framework.errors_impl.NotFoundError: logs,"NOTE: Only file GitHub issues for bugs and feature requests.  All other topics will be closed.

For general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).
To make bugs and feature requests more easy to find and organize, we close issues that are deemed
out of scope for GitHub Issues and point people to StackOverflow.

For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.

### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?

None

### Environment info
Operating System:
Mac OS X El Capitan

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

If installed from binary pip package, provide:
Used steps shown here with docker
https://codelabs.developers.google.com/codelabs/tensorflow-for-poets/#3


1. A link to the pip package you installed:
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.

If installed from source, provide 

1. The commit hash (`git rev-parse HEAD`)
2. The output of `bazel version`

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)
I am following all the steps in this tutorial
https://codelabs.developers.google.com/codelabs/tensorflow-for-poets/#3 but I am getting the following error

`COMPUTER_NAME:tf_files USERNAME$ docker run -it -v $HOME/tf_files:/tf_files  gcr.io/tensorflow/tensorflow:latest-devel
root@e6a49799067c:~# cd /tensorflow/
root@e6a49799067c:/tensorflow# git pull
remote: Counting objects: 1444, done.
remote: Compressing objects: 100% (719/719), done.
remote: Total 1444 (delta 693), reused 490 (delta 490), pack-reused 221
Receiving objects: 100% (1444/1444), 1.36 MiB | 469.00 KiB/s, done.
Resolving deltas: 100% (753/753), completed with 239 local objects.
From https://github.com/tensorflow/tensorflow
 * [new branch]      fix-dbpedia -> origin/fix-dbpedia
   8308ecd..fa4ba83  master     -> origin/master
   9381242..1092f91  r1.0       -> origin/r1.0
 * [new tag]         0.12.1     -> 0.12.1
Already up-to-date.
root@e6a49799067c:/tensorflow# python tensorflow/examples/image_retraining/retrain.py \ --bottleneck_dir=/tf_files/bottlenecks \ --how_many_training_steps 500 \ --model_dir=/tf_files/inception \ --output_graph=/tf_files/retrained_graph.pb \ --output_labels=/tf_files/retrained_labels.txt \ --image_dir /tf_files/flower_photos
>> Downloading inception-2015-12-05.tgz 100.0%
Successfully downloaded inception-2015-12-05.tgz 88931400 bytes.
Looking for images in '.git'
No files found
Looking for images in 'logs'
Traceback (most recent call last):
  File ""tensorflow/examples/image_retraining/retrain.py"", line 1012, in <module>
    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 43, in run
    sys.exit(main(sys.argv[:1] + flags_passthrough))
  File ""tensorflow/examples/image_retraining/retrain.py"", line 757, in main
    FLAGS.validation_percentage)
  File ""tensorflow/examples/image_retraining/retrain.py"", line 148, in create_image_lists
    file_list.extend(gfile.Glob(file_glob))
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/lib/io/file_io.py"", line 269, in get_matching_files
    compat.as_bytes(filename), status)]
  File ""/usr/lib/python2.7/contextlib.py"", line 24, in __exit__
    self.gen.next()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/errors_impl.py"", line 469, in raise_exception_on_not_ok_status
    pywrap_tensorflow.TF_GetCode(status))
tensorflow.python.framework.errors_impl.NotFoundError: logs`

### What other attempted solutions have you tried?
Tried install tensorflow 0.11 in docker but that didn't help

### Logs or other output that would be helpful
(If logs are large, please upload as attachment or provide link).
"
6586,Crash in  Jupyter Notebook with conv2d - stream->parent()->GetConvolveAlgorithms(&algorithms),"### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?

I have googled for the issue on several fronts and found nothing close since the Windows release.

### Environment info
Operating System:
Windows 7-64bit.  Intel i3-6100 (64-bit), 8 gb DDR4, nVidia GTX 750 ti 2gb, 

nVidia GPU driver: 369.30

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):
CUDA v8.0
cuDNN 5.1 

jupyter notebook messages when importing tensorflow:
successfully loaded:
cublas64_80.dll
cudnn64_5.dll
cufft64_80.dll
nvcuda.dll
curand64_80.dll

Found device 0 with properties:
name: GeForce GTX 750 Ti
major: 5 minor: 0 memoryClockRate (GHz) 1.1105
pciBusID 0000:01:00.0
Total memory: 2.00GiB
Free memory: 1.65GiB
DMA:0
0: Y
Creating TensorFlow device ... 


If installed from binary pip package, provide:

1. A link to the pip package you installed:
I used the default: pip install tensorflow as described on their website.
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.
0.12.0-rc0

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)
I built and tested this jupyter notebook WITHOUT gpu support.  It already builds and runs correctly (as in, have trained and optimized a network).  Now I'm trying to get it to work with gpu to speed it up.

Here's the step in the notebook that causes the issue.  Prior to this, tensorFlow is imported successfully as tf.  This is the first session it's running.  the 'training_operation' uses conv2d.
`
##run Training

with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())
    num_examples = len(X_train)
    
    print(""Training..."")
    print()
    for i in range(EPOCHS):
        X_train, y_train = shuffle(X_train, y_train)
        for offset in range(0, num_examples, BATCH_SIZE):
            end = offset + BATCH_SIZE
            batch_x, batch_y = X_train[offset:end], y_train[offset:end]
            sess.run(training_operation, feed_dict={x: batch_x, y: batch_y})
            
        validation_accuracy = evaluate(X_validation, y_validation)
        print(""EPOCH {} ..."".format(i+1))
        print(""Validation Accuracy = {:.3f}"".format(validation_accuracy))
        print()
        
    saver.save(sess, './lenetTrafficSign')
    print(""Model saved"")`


### What other attempted solutions have you tried?
I saw a similar issue in a pre-windows version that suggested it had something to do with memory.
I tried adding the following before the tensorflow session:
`config = tf.ConfigProto()
config.gpu_options.per_process_gpu_memory_fraction = 0.4
with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())`

It did not resolve the issue.

### Logs or other output that would be helpful
(If logs are large, please upload as attachment or provide link).
The error is as follows, when trying to run the session:
![image](https://cloud.githubusercontent.com/assets/7866171/21579570/f25e4a0c-cf7d-11e6-8136-1f8b681e3dcd.png)


The plain text at the last three lines are:
cuda_event.cc:49]Error polling for event status: failed to query event: CUDA_ERROR_LAUNCH_FAILED
gpu_event_mgr.cc:190] Unexpected Event Status: 1
cuda_dnn.cc:305] could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR
cuda_dnn.cc:352] could not destroy cudnn handle: CUDNN_STATUS_BAD_PARAM
conv_ops.cc:532] Check failed: stream->parent()->GetConvolveAlgorithms(&algorithms)

A few seconds after the script crashes, the screen goes black and the video driver resets.
"
6585,Thank You TensorFlow Team! ,"Special thanks to all TensorFlow engineers for your incredible work this year. Maintaining and developing so successfully a project of this magnitude isn't an easy work. I've personally always seen great attention to the issues and contributions made with an also prompt, helpful and nice attitude and believe the community is very grateful for all you've done this year and the excellence of your work. Can't wait for what is to come in 2017!


"
6584,SKCompat gives error when used with DNNClassifier,"NOTE: Only file GitHub issues for bugs and feature requests.  All other topics will be closed.

For general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).
To make bugs and feature requests more easy to find and organize, we close issues that are deemed
out of scope for GitHub Issues and point people to StackOverflow.

For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.

### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?

Was not able to find any that apply.

### Environment info
Operating System:

Mac

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

If installed from binary pip package, provide:

1. A link to the pip package you installed:
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.

Tried on:

0.12.1
0.12.0-rc0

If installed from source, provide 

1. The commit hash (`git rev-parse HEAD`)
2. The output of `bazel version`

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)

I would like to use SKCompat with a DNN classifier, but it generates an error.  A real easy way to see this is to run: 

https://www.tensorflow.org/tutorials/tflearn/#load_the_iris_csv_data_to_tensorflow

If I run the above example, exactly as it is, I get this warning:

```
Estimator is decoupled from Scikit Learn interface by moving into
separate class SKCompat. Arguments x, y and batch_size are only
available in the SKCompat class, Estimator will only accept input_fn.
Example conversion:
  est = Estimator(...) -> est = SKCompat(Estimator(...))
```

So I follow the advice, and add this line of code, just after the DNNClassifier is created.

`classifier = tf.contrib.learn.SKCompat(classifier)`

This results in the following error.  How do I use SKCompat with this example?  I would like to use the standard sklearn interface for this application.

```
Traceback (most recent call last):
  File ""test3.py"", line 35, in <module>
    steps=2000)
  File ""/Users/jeff/anaconda/envs/tensorflow/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py"", line 1126, in fit
    loss = self._estimator._train_model(
AttributeError: 'DNNClassifier' object has no attribute '_train_model'

```
### What other attempted solutions have you tried?

Examined source code for tensorflow.  It appears that SKCompat is trying to call a function () that DNNClassifier does not have.

### Logs or other output that would be helpful
(If logs are large, please upload as attachment or provide link).
"
6582,Incompatible state size between LSTMCell and LSTMBlockCell,"Hello,

I heard that the implementation of LSTMBlockCell is faster than that of LSTMCell, so I am trying to convert my codes using LSTMCell to use LSTMBlockCell.
However, I found one weird point: the types of state_size of the two are not compatible.
Specifically, LSTMCell's state_size is of type LSTMStateTuple and LSTMBlockCell's state_size is of type tuple.
As far as I know, tuple and LSTMStateTuple are quite similar but the latter handles an internal memory state and a hidden state in a more abstract way.

I know the separated use of tuple and LSTMStateTuple is quite useful; for example when I have to detect whether a cell is MultiRNNCell (where state_size is of type tuple) or a cell is LSTMCell (where state_size is of type LSTMStateTuple).
Thus, I think the current behavior of LSTMBlockCell should be corrected to use LSTMStateTuple as a state type.
It can be easily modified if there is no backward compatibility issue, and I will send a pull request if nobody is working on this now."
6581,Bazel：command not found,"I have install the bazel v0.3.2 per the instruction and it works well on the terminal.but when I was running ./configure, it comes with a result of ""Bazel :command not found"""
6580,`models` directory disappeared in the latest commit,"The documentation refers to `models/image/mnist/convolutional.py`, however it doesn't exist anymore. It exists in `r0.12`, but not `master`. In fact, the whole `models` directory is missing. If restructuring is going on, I think the documentation has to be updated.

[Here is the documentation that refers to it](https://github.com/tensorflow/tensorflow/blob/2e22f1b20/tensorflow/g3doc/get_started/os_setup.md#train-your-first-tensorflow-neural-net-model)"
6579,Just some Grammar,"

![untitled](https://cloud.githubusercontent.com/assets/7543641/21576381/ac92b3a8-cf52-11e6-8662-8b72a36a7caf.png)



NOTE: Only file GitHub issues for bugs and feature requests.  All other topics will be closed.

For general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).
To make bugs and feature requests more easy to find and organize, we close issues that are deemed
out of scope for GitHub Issues and point people to StackOverflow.

For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.

### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?

### Environment info
Operating System:

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

If installed from binary pip package, provide:

1. A link to the pip package you installed:
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.

If installed from source, provide 

1. The commit hash (`git rev-parse HEAD`)
2. The output of `bazel version`

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)


### What other attempted solutions have you tried?


### Logs or other output that would be helpful
(If logs are large, please upload as attachment or provide link).
"
6578,tf.rank not working. Increments each call,"When running this line:
```tf.rank(tf.placeholder(tf.int32))```
the output increments each time:
```<tf.Tensor 'Rank:0' shape=() dtype=int32>```
```<tf.Tensor 'Rank_1:0' shape=() dtype=int32>```
```<tf.Tensor 'Rank_2:0' shape=() dtype=int32>```

Ubuntu 14.04
Latest install from pip
Both gpu and cpu
0.12.0"
6576,[Java] Bulk data transfer for Tensor class,"
Enhance the `Tensor` class with bulk data-access methods, to support the following scenarios:
- serialization of tensors in managed code (regardless of tensor datatype)
- efficient transfer of large blocks of multidimensional data
- support for direct transfers (i.e. using direct `ByteBuffer`s)
- support for typed `Buffer`s
"
6575,does not work on my dataset,"Linux Unbuntu
Python 2.7

I did run word2vec_basic.py example successfully but as i change dataset from text8.zip to mydata.zip, i get following error

Traceback (most recent call last):
  File ""../../statistics/word2vec/word2vec_basic.py"", line 218, in <module>
    close_word = reverse_dictionary[nearest[k]]
KeyError: 21049

i have checked, my data is loading successfully in data array
"
6574,C drive space usage,"# **EDIT:  MY MITAKE** 
**sorry guys**

//I ran this ..
docker run -it -v /$(pwd)/tf_files-local:/tf_files-container gcr.io/tensorflow/tensorflow:latest-devel

then started retrain.py to train my model. Suddenly it took around 60GB of my C drive. I tried to clean using CC Cleaner, Windows DiskCleaner, Uninstalled TensorFlow ,Deleted every file i created including bottleneck files, but still its taking up that space. 
Help Needed.//"
6573,Error with bazel and protobuf building a project that depends on tensorflow in Windows,"We have a project that depends on Tensorflow, using the following in our WORKSPACE file:
local_repository(
  name = ""org_tensorflow"",
  path = __workspace_dir__ + ""/Libraries/TensorFlow/"",
)
and 
""@org_tensorflow//tensorflow/core:tensorflow""
under deps in the BUILD file.
It builds correctly on osX.

We also have a Windows machine that we've set up to build tensorflow (Standard set up: VS 2015 community, java 8, Anaconda Python 3.5, etc) and running the simple build (e.g. build a PIP wheel) works.

However, trying to build our project on Windows fails when it hits tensorflow's protos.
The precise error message is
ERROR: C:/tmp/Bazel/D6SVld$i/external/org_tensorflow/tensorflow/core/kernels/BUILD:272:1: null failed: protoc.exe failed: error executing command
  cd C:/tmp/Bazel/D6SVld$i/execroot/face_tf_desktop
bazel-out/host/bin/external/protobuf/protoc.exe --cpp_out=bazel-out/vc_14_0_x64-opt/genfiles/external/org_tensorflow -Iexternal/org_tensorflow -Ibazel-out/vc_14_0_x64-opt/genfiles/external/org_tensorflow -Iexternal/protobuf/src -Ibazel-out/vc_14_0_x64-opt/genfiles/external/protobuf/src external/org_tensorflow/tensorflow/core/kernels/reader_base.proto: com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status -1073741515.

Trying to run that command manually in the shell produces: 
bazel-out/vc_14_0_x64-opt/genfiles/external/protobuf/src: warning: directory does not exist.
(Accurately: the protobuf folder doesn't exist)

I'm not sure whether this is a bug in tensorflow or in Bazel (or, for that matter, whether the local_repository approach isn't meant to work and only works as a fluke on the Mac.)

I have tried building with the newest Bazel release 0.4.3, and previously with 0.4.1."
6572,Server finished RPC without an explicit exit code -bash: Server: command not found when use bazel build tensorflow,"### Environment info
Operating System:
centos 6.5 x86_64
ldd (GNU libc) 2.12
gcc (GCC) 4.8.2

If installed from source, provide 

1. The commit hash (`git rev-parse HEAD`)
 [****tensorflow]# git rev-parse HEAD
ac28ae043df4bc6f112f964f6df22845b8a05390
2. The output of `bazel version`
bazel  0.4.3
I build bazel and install successfully

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)
bazel build -c opt //tensorflow/tools/pip_package:build_pip_package                                               


### What other attempted solutions have you tried?
1: rebuild and still have errors

### Logs or other output that would be helpful
(If logs are large, please upload as attachment or provide link).
INFO: From Compiling tensorflow/core/distributed_runtime/rpc/grpc_worker_service_impl.cc:
tensorflow/core/distributed_runtime/rpc/grpc_worker_service_impl.cc: In function 'const char* tensorflow::GrpcWorkerMethodName(tensorflow::GrpcWorkerMethod)':
tensorflow/core/distributed_runtime/rpc/grpc_worker_service_impl.cc:50:1: warning: control reaches end of non-void function [-Wreturn-type]
 }
 ^
INFO: From Compiling tensorflow/core/debug/debug_io_utils.cc:
tensorflow/core/debug/debug_io_utils.cc:212:15: warning: 'tensorflow::Status tensorflow::CloseDebugURL(const string&)' defined but not used [-Wunused-function]
 static Status CloseDebugURL(const string& debug_url) { return Status::OK(); }
               ^
Server finished RPC without an explicit exit code"
6568,Get rid of setdlopen() in tests,"We need to find a new strategy for loading `.so` files at runtime that depend on other `.so` files. This is so we can remove the dlopen hack, which is now present in >100 files.

The solution needs to meet the requirement that each .py file fully specifies its dependencies and does not rely on code in `__init__.py` files to run beforehand. This requirement is necessary in order to maintain the work we've done to: a) remove hourglass imports so affected tests can be calculated better; and b) so Python modules can be loaded lazily like Java.

## Background

We've refactored TensorFlow to remove hourglass imports in https://github.com/tensorflow/tensorflow/commit/5866e065bc95c1d7de8a27413b368016941889a6, https://github.com/tensorflow/tensorflow/commit/58201a058853de647b37ddb0ccf63d89b2357f03, etc. Since tests no longer depend on the master `__init__.py` file, we've needed to add code like this to the tops of _test.py files that load custom ops defined by contrib libraries:

```python
import sys

if hasattr(sys, ""getdlopenflags"") and hasattr(sys, ""setdlopenflags""):
  import ctypes
  sys.setdlopenflags(sys.getdlopenflags() | ctypes.RTLD_GLOBAL)

from google3.third_party.tensorflow.contrib.rnn.python.ops import core_rnn_cell_impl
from google3.third_party.tensorflow.python.framework import ops
...
```

Otherwise we get errors like `undefined symbol: _ZTIN10tensorflow8OpKernelE` e.g.

```
Traceback (most recent call last):
  File ""bazel-out/local-fastbuild/bin/tensorflow/contrib/slim/python/slim/nets/inception_v2_test.runfiles/org_tensorflow/tensorflow/contrib/slim/python/slim/nets/inception_v2_test.py"", line 26, in <module>
    from tensorflow.contrib.slim.python.slim.nets import inception_v2
  File ""bazel-out/local-fastbuild/bin/tensorflow/contrib/slim/python/slim/nets/inception_v2_test.runfiles/org_tensorflow/tensorflow/contrib/slim/python/slim/nets/inception_v2.py"", line 21, in <module>
    from tensorflow.contrib import layers
  File ""bazel-out/local-fastbuild/bin/tensorflow/contrib/slim/python/slim/nets/inception_v2_test.runfiles/org_tensorflow/tensorflow/contrib/layers/__init__.py"", line 118, in <module>
    from tensorflow.contrib.layers.python.layers import *
  File ""bazel-out/local-fastbuild/bin/tensorflow/contrib/slim/python/slim/nets/inception_v2_test.runfiles/org_tensorflow/tensorflow/contrib/layers/python/layers/__init__.py"", line 22, in <module>
    from tensorflow.contrib.layers.python.layers.embedding_ops import *
  File ""bazel-out/local-fastbuild/bin/tensorflow/contrib/slim/python/slim/nets/inception_v2_test.runfiles/org_tensorflow/tensorflow/contrib/layers/python/layers/embedding_ops.py"", line 21, in <module>
    from tensorflow.contrib.layers.python.ops import sparse_feature_cross_op
  File ""bazel-out/local-fastbuild/bin/tensorflow/contrib/slim/python/slim/nets/inception_v2_test.runfiles/org_tensorflow/tensorflow/contrib/layers/python/ops/sparse_feature_cross_op.py"", line 31, in <module>
    resource_loader.get_path_to_datafile(""_sparse_feature_cross_op.so""))
  File ""bazel-out/local-fastbuild/bin/tensorflow/contrib/slim/python/slim/nets/inception_v2_test.runfiles/org_tensorflow/tensorflow/contrib/util/loader.py"", line 42, in load_op_library
    ret = load_library.load_op_library(path)
  File ""bazel-out/local-fastbuild/bin/tensorflow/contrib/slim/python/slim/nets/inception_v2_test.runfiles/org_tensorflow/tensorflow/python/framework/load_library.py"", line 64, in load_op_library
    None, None, error_msg, error_code)
tensorflow.python.framework.errors_impl.NotFoundError: bazel-out/local-fastbuild/bin/tensorflow/contrib/slim/python/slim/nets/inception_v2_test.runfiles/org_tensorflow/tensorflow/contrib/layers/python/ops/_sparse_feature_cross_op.so: undefined symbol: _ZTIN10tensorflow8OpKernelE
```

CC: @gunan @martinwicke @yifeif "
6563,Tensorflow 0.12 on Windows - TypeError: init() got an unexpected keyword argument 'dense_shape' running example,"I downloaded the latest Windows native version of Tensorflow and having problems running some examples. I have Windows 10 (TF 0.12) with python 3.5.2.

The issue is with keyword dense_shape while running the wide_n_deep_tutorial shipped with the package. I pulled the latest version of TF as well but still didn't resolve the problem:

TypeError: init() got an unexpected keyword argument 'dense_shape'

Specifically, the issue is in the following section:

  categorical_cols = {
     k: tf.SparseTensor(
          indices=[[i, 0] for i in range(df[k].size)],
          values=df[k].values,
          dense_shape=[df[k].size, 1])
      for k in CATEGORICAL_COLUMNS}

Per documentation SparseTensor does not seem to understand dense_shape but IndexedSlices does. But I would like examples to work as is, without modification.

Cannot comment whether this happens on Unix also. Any ideas on how to resolve? Thanks!"
6561,Android Camera Demo Error when trying to replace default inception model  ,"Hey, 

I am trying tu run the android camera demo with different model.
To get a simple use case, I started with a retrained inception model produced from the TensorFlow for Poets codelab tutorial classifying flowers.

What I have done ?
I place the new model pb file and the new label txt file in the assets directory.
I followed the recommendations specified in the ClassifierActivity.java file 
1/ set IMAGE_SIZE = 299, IMAGE_MEAN = 128, IMAGE_STD = 128
2/ set INPUT_NAME = ""Mul:0"", and OUTPUT_NAME = ""final_result:0""
I bazel build and install the apk file.

Running the app, I got this error in the logcat 

_**E/native: tensorflow_inference_jni.cc:138 Could not create Tensorflow Graph: Invalid argument: No OpKernel was registered to support Op 'DecodeJpeg' with these attrs.  Registered devices: [CPU], Registered kernels: <no registered kernels>  [[Node: DecodeJpeg = DecodeJpeg [ acceptable_fraction=1, channels=3, dct_method="""", fancy_upscaling=true, ratio=1, try_recover_truncated=false](DecodeJpeg/contents)]]**_

To my understanding this node is preceding my input node and is useless in this case.
What is the solution to get rid of it ?

Thanks in advance for your answer.
Alex"
6560,No tf.batch_matmul operation on source built 12.1 distribution ,"Hi all,
I've build from sources the latest version (0.12.1) on my Ubuntu 16 machine.
Then I've found out that I no longer have tf.batch_mat:

import tensorflow as tf
tf.batch_matmul

Traceback (most recent call last):
  File ""<ipython-input-2-95fcb8b3e629>"", line 1, in <module>
    tf.batch_matmul
AttributeError: module 'tensorflow' has no attribute 'batch_matmul'

Any ideas for a solution?

Some details:

 ls -l /usr/local/cuda-8.0
total 64
drwxr-xr-x  3 root root 4096 Sep 28 12:39 bin
drwxr-xr-x  5 root root 4096 Sep 28 12:38 doc
drwxr-xr-x  5 root root 4096 Sep 28 12:38 extras
drwxr-xr-x  5 root root 4096 Sep 28 12:44 include
drwxr-xr-x  5 root root 4096 Sep 28 12:38 jre
drwxr-xr-x  3 root root 4096 Nov  8 09:46 lib64
drwxr-xr-x  8 root root 4096 Sep 28 12:38 libnsight
drwxr-xr-x  7 root root 4096 Sep 28 12:38 libnvvp
drwxr-xr-x  3 root root 4096 Sep 28 12:38 nvml
drwxr-xr-x  7 root root 4096 Sep 28 12:38 nvvm
drwxr-xr-x  2 root root 4096 Sep 28 12:39 pkgconfig
drwxr-xr-x 11 root root 4096 Sep 28 12:39 samples
drwxr-xr-x  3 root root 4096 Sep 28 12:38 share
drwxr-xr-x  2 root root 4096 Sep 28 12:38 src
drwxr-xr-x  2 root root 4096 Sep 28 12:38 tools
-rw-r--r--  1 root root   20 Sep 28 12:38 version.txt


git rev-parse HEAD
ac28ae043df4bc6f112f964f6df22845b8a05390


 bazel version
Build label: 0.4.3
Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Thu Dec 22 12:31:25 2016 (1482409885)
Build timestamp: 1482409885
Build timestamp as int: 1482409885


Thanks!


"
6558,`TensorContractionThreadPool.h' file not found` when using `--copt=-march=native`,"When trying to run 

```
$ ./configure
........
$ bazel build --copt=-march=native -c opt //tensorflow/tools/pip_package:build_pip_package --verbose_failures
```

it fails with the `./third_party/eigen3/unsupported/Eigen/CXX11/FixedPoint:42:10: fatal error: 'src/Tensor/TensorContractionThreadPool.h' file not found` error.

Similar problem was seen in #4680, #580, 

I am on Mac OS X Sierra 10.12.2 with no CUDA and cuDNN installed. I am using virtual environment on Python 2.7

Here is the checked commit and `bazel` version
```
$ git rev-parse HEAD
ac28ae043df4bc6f112f964f6df22845b8a05390
$ bazel version
Build label: 0.4.3-homebrew
Build target: bazel-out/local-opt/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Thu Dec 22 15:20:15 2016 (1482420015)
Build timestamp: 1482420015
Build timestamp as int: 1482420015
```

This works fine:
```
$ git checkout remotes/origin/r0.12
$ ./configure # With defaults
.........
$ bazel build --copt=-march=native -c opt //tensorflow/tools/pip_package:build_pip_package --verbose_failures
# This finishes correctly
```

Here is the full terminal log when `bazel` is run on the `master` branch:
```
$ git checkout master
$ ./configure # With defaults
.........
$ bazel build --copt=-march=native -c opt //tensorflow/tools/pip_package:build_pip_package --verbose_failures
INFO: Found 1 target...
ERROR: /Users/zafar/GitHub/tensorflow/tensorflow/core/kernels/BUILD:856:1: C++ compilation of rule '//tensorflow/core/kernels:gather_functor' failed: cc_wrapper.sh failed: error executing command
  (cd /private/var/tmp/_bazel_zafar/c40dcca6773e4515fd11c724e0ebae51/execroot/tensorflow && \
  exec env - \
    PATH=/Users/zafar/.virtualenvs/tf-dev-env/bin:/Users/zafar/.rbenv/shims:/Users/zafar/.node/bin:/Users/zafar/bin:/Users/zafar/.local/bin:/usr/local/sbin:/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin:/opt/X11/bin:/usr/local/MacGPG2/bin:/Library/TeX/texbin \
    TMPDIR=/var/folders/yx/nf9nvmpn4_79r7nbzkn8cz8h0000gn/T/ \
  external/local_config_cc/cc_wrapper.sh -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -Wall -Wthread-safety -Wself-assign -fcolor-diagnostics -fno-omit-frame-pointer -g0 -O2 -DNDEBUG -ffunction-sections -fdata-sections '-march=native' '-std=c++0x' -MD -MF bazel-out/local-opt/bin/tensorflow/core/kernels/_objs/gather_functor/tensorflow/core/kernels/gather_functor.pic.d '-frandom-seed=bazel-out/local-opt/bin/tensorflow/core/kernels/_objs/gather_functor/tensorflow/core/kernels/gather_functor.pic.o' -fPIC -DEIGEN_MPL2_ONLY -iquote . -iquote bazel-out/local-opt/genfiles -iquote external/bazel_tools -iquote bazel-out/local-opt/genfiles/external/bazel_tools -iquote external/eigen_archive -iquote bazel-out/local-opt/genfiles/external/eigen_archive -iquote external/local_config_sycl -iquote bazel-out/local-opt/genfiles/external/local_config_sycl -isystem external/bazel_tools/tools/cpp/gcc3 -isystem external/eigen_archive -isystem bazel-out/local-opt/genfiles/external/eigen_archive -DEIGEN_AVOID_STL_ARRAY -Iexternal/gemmlowp -Wno-sign-compare -fno-exceptions -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' -c tensorflow/core/kernels/gather_functor.cc -o bazel-out/local-opt/bin/tensorflow/core/kernels/_objs/gather_functor/tensorflow/core/kernels/gather_functor.pic.o): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.
In file included from tensorflow/core/kernels/gather_functor.cc:50:
In file included from ./tensorflow/core/kernels/gather_functor.h:22:
In file included from ./tensorflow/core/framework/type_traits.h:22:
In file included from ./tensorflow/core/framework/numeric_types.h:25:
./third_party/eigen3/unsupported/Eigen/CXX11/FixedPoint:42:10: fatal error: 'src/Tensor/TensorContractionThreadPool.h' file not found
#include ""src/Tensor/TensorContractionThreadPool.h""
         ^
1 error generated.
Target //tensorflow/tools/pip_package:build_pip_package failed to build
INFO: Elapsed time: 34.692s, Critical Path: 25.26s
```
"
6555,[minor] Non-silenced `pushd` followed by `popd` in `tensorflow/configure`,"`tensorflow/configure` has the following lines:

```bash
#!/usr/bin/env bash

set -e
set -o pipefail

# Find out the absolute path to where ./configure resides
pushd `dirname $0` #> /dev/null
SOURCE_BASE_DIR=`pwd -P`
popd > /dev/null
```

I am not sure what is the purpose of the `pushd` followed by `popd` without change in directory. I think this is not necessary, and distracts when reading the source codes. Unless it is allowed to run the `configure` from the directory other than the tensorflow root, it is completely redundant.

Also, the `> /dev/null` is commented out which causes the current directory to print when running the script:

```bash
$ ./configure
  ~/GitHub/tensorflow ~/GitHub/tensorflow
  Please specify the location of python. [Default is ~/.virtualenvs/tf-dev-env/bin/python]:
  .........
```"
6554,Bug or feature - Confusing shapes of Tensor resulted from `tf.decode_csv`,"
```
reader = tf.TextLineReader()
key, value = reader.read(filename_queue)
parsed = tf.decode_csv(value, [[0.0]] * 24)
label = parsed[0]
weight = parsed[1]
feature = tf.pack(parsed[2:])
label_tensor, weight_tensor, feature_tensor = tf.train.shuffle_batch(
      [label, weight, feature],
      batch_size=200,
      capacity=capacity,
      min_after_dequeue=min_after_dequeue,
      num_threads=num_threads)
print(""Parsed tensors: %s, %s, %s"" % )
```

The shapes of `label_tensor`, `weight_tensor` and `feature_tensor` are **`(200, )`**, **`(200, )`** and **`(200, 22)`** respectively.

If we put an extra comma at the end of line 4 and 5, like this:
```
label = parsed[0],
weight = parsed[1],
```
Then the shapes become **`(200, 1)`**, **`(200, 1)`** and **`(200, 26)`** respectively.

So an extra comma determines the shape of the resulted tensor. I am not quite familiar with Python and am new to TensorFlow, but is it supposed so?

"
6553,Issue with tf.InteractiveSession(),"I try to train a neural net with nested loop `tf.while_loop`. If I start the session with `sess = tf.Session()`, the training process will start with the following log for one batch. There seems to be some memory issue, but it still works.
[log1.txt](https://github.com/tensorflow/tensorflow/files/676557/log1.txt)


But if I start with `sess = tf.InteractiveSession()`, there will be errors. The log is as follows. `tf.InteractiveSession()` isn't really different from `tf.Session()` by tutorial. I just wonder what is wrong here.
[log2.txt](https://github.com/tensorflow/tensorflow/files/676555/log2.txt)


### Environment info
- Ubuntu  14.04.5 LTS
- Python 2.7.6
- cuda 8, V8.0.44
- cudnn 5.1.3
- TensorFlow 0.12.0-rc0
- GeForce GTX 1080

"
6552,Issue with tf.matrix_diag() in 0.12.0 in Windows GPU mode (CUDA_ERROR_ILLEGAL_ADDRESS),"Here is my code:
```
with tf.Session() as sess:
    # with tf.device(""/cpu:0""):
    x = tf.ones(shape=[3, 3])
    x_diag = tf.diag_part(x)
    x_diag_matrix = tf.matrix_diag(x_diag)
    print(sess.run(x_diag_matrix))
```
It works ok on a CPU but fails in a GPU mode with the following 'CUDA_ERROR_ILLEGAL_ADDRESS' error:

> I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\stream_executor\dso_loader.cc:128] successfully opened CUDA library cublas64_80.dll locally
> I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\stream_executor\dso_loader.cc:128] successfully opened CUDA library cudnn64_5.dll locally
> I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\stream_executor\dso_loader.cc:128] successfully opened CUDA library cufft64_80.dll locally
> I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\stream_executor\dso_loader.cc:128] successfully opened CUDA library nvcuda.dll locally
> I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\stream_executor\dso_loader.cc:128] successfully opened CUDA library curand64_80.dll locally
> I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\common_runtime\gpu\gpu_device.cc:885] Found device 0 with properties: 
> name: Tesla K40m
> major: 3 minor: 5 memoryClockRate (GHz) 0.745
> pciBusID 0000:27:00.0
> Total memory: 11.16GiB
> Free memory: 11.09GiB
> I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\common_runtime\gpu\gpu_device.cc:906] DMA: 0 
> I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\common_runtime\gpu\gpu_device.cc:916] 0:   Y 
> I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\common_runtime\gpu\gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K40m, pci bus id: 0000:27:00.0)
> E c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\common_runtime\gpu\gpu_device.cc:586] Could not identify NUMA node of /job:localhost/replica:0/task:0/gpu:0, defaulting to 0.  Your kernel may not have been built with NUMA support.
> E c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\stream_executor\cuda\cuda_event.cc:49] Error polling for event status: failed to query event: CUDA_ERROR_ILLEGAL_ADDRESS
> F c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\common_runtime\gpu\gpu_event_mgr.cc:198] Unexpected Event status: 1

I have tried 
```
x = tf.ones(shape=[3, 3])
x_diag = tf.diag_part(x)
```
and `x_diag_matrix = tf.matrix_diag([1., 1., 1.])` , Both work ok in a GPU mode. Maybe the tensor couldn't be input of  tf.matrix_diag() in a Windows GPU mode?
"
6551,Can't restore a partitioned variable,"I have a large matrix.

I use bellow method create this variable as number of shards.
```
softmax_w = tf.get_variable(""softmax_w"", [hps.vocab_size, hps.projected_size],
                            partitioner=tf.fixed_size_partitioner(hps.num_shards, 0))
```
create log:
```
model/softmax_w/part_0:0 (99184, 512) /cpu:0
model/softmax_w/part_1:0 (99184, 512) /cpu:0
model/softmax_w/part_2:0 (99184, 512) /cpu:0
model/softmax_w/part_3:0 (99184, 512) /cpu:0
model/softmax_w/part_4:0 (99184, 512) /cpu:0
model/softmax_w/part_5:0 (99184, 512) /cpu:0
model/softmax_w/part_6:0 (99183, 512) /cpu:0
model/softmax_w/part_7:0 (99183, 512) /cpu:0
```
I can training and save it success. But when I try to restore model I got this error:

restore log
```
W tensorflow/core/framework/op_kernel.cc:975] Not found: Key model/softmax_w/part_7 not found in checkpoint
W tensorflow/core/framework/op_kernel.cc:975] Not found: Key model/softmax_w/part_6 not found in checkpoint
W tensorflow/core/framework/op_kernel.cc:975] Not found: Key model/softmax_w/part_5 not found in checkpoint
W tensorflow/core/framework/op_kernel.cc:975] Not found: Key model/softmax_w/part_4 not found in checkpoint
W tensorflow/core/framework/op_kernel.cc:975] Not found: Key model/softmax_w/part_3 not found in checkpoint
W tensorflow/core/framework/op_kernel.cc:975] Not found: Key model/softmax_w/part_2 not found in checkpoint
W tensorflow/core/framework/op_kernel.cc:975] Not found: Key model/softmax_w/part_1 not found in checkpoint
W tensorflow/core/framework/op_kernel.cc:975] Not found: Key model/softmax_w/part_0 not found in checkpoint
W tensorflow/core/framework/op_kernel.cc:975] Not found: Key model/softmax_w/part_7 not found in checkpoint
```

I found tensorflow save the variable as a whole part. The saved parameter just have one softmax_w. No longer a partitioned variable, I can use bellow code restore that variable. 
```
softmax_w = tf.get_variable(""softmax_w"", [hps.vocab_size, hps.projected_size])
```"
6550,classify_image.py file not found at tensorflow/models/image/imagenet,It seems the tutorials are out of date. 
6549,keep_checkpoint_every_n_hours is ignored,"I think that when creating a new saver [`here`](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/learn/python/learn/graph_actions.py#L249), the `keep_checkpoint_every_n_hours` flag from the RunConfig should be passed to it."
6548,'No module named tensorflow' after installing via pip,"I'm running Anaconda on win64. 
The files are in the correct site-packages directory, with an `__init__.py`, but python doesn't seem to be able to recognize the module, regardless of whether I'm working in a virtual environment or the root directory. 
None of the following has changed this result:
[This.](https://www.tensorflow.org/get_started/os_setup#pip_installation_on_windows)
[This.](https://github.com/tensorflow/tensorflow/issues/6136)
[This.](https://www.reddit.com/r/MachineLearning/comments/3tcxs6/something_does_not_work_for_me_i_get_no_module/)
"
6546,TensorFlow Implementation in MapReduce,"Hello guys,

First, i'm sorry if i break the rules. But, i really stuck right now. So, this is my last hope to ask this question.

I just want to ask something. Can i implement TensorFlow in MapReduce Programming Model within Hadoop ?

Yes, i know that TensorFlow can be runned in distributed mode, according this reference https://www.tensorflow.org/versions/r0.11/how_tos/distributed/ . But, it doesn't explain more detail how to use it in MapReduce.

One last thing, can i use TensorFlow to predict something a lot of data ? Because, i only know that TensorFlow can be used to classify similar images.

I'm sorry if my question look dumb. Well, there are many thing in the world that i don't know. So, when i don't know, i will ask a question :smile:
Thanks for your attention"
6541,"tf.signal CPU FFT implementation is slower than NumPy, PyTorch, etc.","### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?

### Environment info
Operating System:
Ubuntu 16.04 LTS 64bit

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):
`
-rw-r--r-- 1 root root   558720 9月  15 07:02 libcudadevrt.a
lrwxrwxrwx 1 root root       16 9月  15 07:05 libcudart.so -> libcudart.so.8.0
lrwxrwxrwx 1 root root       19 9月  15 07:05 libcudart.so.8.0 -> libcudart.so.8.0.44
-rw-r--r-- 1 root root   415432 9月  15 07:02 libcudart.so.8.0.44
-rw-r--r-- 1 root root   775162 9月  15 07:02 libcudart_static.a
-rwxr-xr-x 1 root root 79337624 10月 27 23:13 libcudnn.so
-rwxr-xr-x 1 root root 79337624 10月 27 23:13 libcudnn.so.5
-rwxr-xr-x 1 root root 79337624 10月 27 23:13 libcudnn.so.5.1.5
-rw-r--r-- 1 root root 69756172 10月 27 23:13 libcudnn_static.a
`
If installed from binary pip package, provide:

1. A link to the pip package you installed:
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.
`0.12.head`
If installed from source, provide 

1. The commit hash (`git rev-parse HEAD`)
2. The output of `bazel version`

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)


```
import numpy as np
import tensorflow as tf
import time

wav = np.random.random_sample((1024,))
spec = np.fft.fft(wav)[:513]


x = tf.placeholder(dtype=tf.complex64, shape=[513])
result = tf.ifft(x) 
sess = tf.Session()

start = time.time()
for i in range(10000):
    something = sess.run(result, feed_dict={x:spec})
print 'tensorflow:{}s'.format(time.time()-start)

start = time.time()
for i in range(10000):
   	something = np.fft.ifft(spec)
print 'numpy:{}s'.format(time.time() - start)

```
```
tensorflow:25.7219519615s
numpy:0.391902923584s
```
### What other attempted solutions have you tried?


### Logs or other output that would be helpful
(If logs are large, please upload as attachment or provide link).
"
6540,`easy_install tensorflow-gpu` fails,"A pip install of tensorflow-gpu and tensorflow works great.

```bash
$ pip install tensorflow-gpu
```

However, when one is trying to create a package with a dependency on tensorflow, one usually has to do the following in `setup.py`:

```python
from setuptools import setup

setup(name='mypkg',
    setup_requires=[""tensorflow-gpu == 0.12.0"", ...],
    install_requires=[""tensorflow-gpu == 0.12.0"", ...],
)
```

Unfortunately, using the above as dependencies fail because setuptools defers to `easy_install` rather than `pip`.

```python
Searching for tensorflow-gpu
Reading https://pypi.python.org/simple/tensorflow-gpu/
No local packages or working download links found for tensorflow-gpu
error: Could not find suitable distribution for Requirement.parse('tensorflow-gpu')
```

easy_install doesn't seem to be able to recognise the wheels found at https://pypi.python.org/simple/tensorflow-gpu/

### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?

### Environment info
Operating System: Ubuntu 16.04

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

```bash
$ ls -l /usr/local/cuda/lib64/libcud*
-rw-r--r-- 1 root root 558720 Sep 15 01:02 /usr/local/cuda/lib64/libcudadevrt.a
lrwxrwxrwx 1 root root     16 Sep 15 01:05 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.8.0
lrwxrwxrwx 1 root root     19 Sep 15 01:05 /usr/local/cuda/lib64/libcudart.so.8.0 -> libcudart.so.8.0.44
-rw-r--r-- 1 root root 415432 Sep 15 01:02 /usr/local/cuda/lib64/libcudart.so.8.0.44
-rw-r--r-- 1 root root 775162 Sep 15 01:02 /usr/local/cuda/lib64/libcudart_static.a

```

If installed from binary pip package, provide:

1. A link to the pip package you installed: N/A
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`. 0.12.0

If installed from source, provide 

1. The commit hash (`git rev-parse HEAD`): N/A
2. The output of `bazel version`: N/A

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)

```bash
$ easy_install tensorflow-gpu
Searching for tensorflow-gpu
Reading https://pypi.python.org/simple/tensorflow-gpu/
No local packages or working download links found for tensorflow-gpu
error: Could not find suitable distribution for Requirement.parse('tensorflow-gpu')
```

But inspection of https://pypi.python.org/simple/tensorflow-gpu/ shows:

```
Links for tensorflow-gpu
tensorflow_gpu-0.12.0-cp34-cp34m-manylinux1_x86_64.whl
tensorflow_gpu-0.12.0-cp35-cp35m-manylinux1_x86_64.whl
tensorflow_gpu-0.12.0rc1-cp35-cp35m-manylinux1_x86_64.whl
tensorflow_gpu-0.12.0rc1-cp35-cp35m-win_amd64.whl
tensorflow_gpu-0.12.0rc1-cp34-cp34m-manylinux1_x86_64.whl
tensorflow_gpu-0.12.0rc1-cp27-cp27m-macosx_10_11_intel.whl
tensorflow_gpu-0.12.0-cp35-cp35m-win_amd64.whl
tensorflow_gpu-0.12.0-cp27-cp27mu-manylinux1_x86_64.whl
tensorflow_gpu-0.12.0rc1-cp35-cp35m-macosx_10_11_x86_64.whl
tensorflow_gpu-0.12.0-cp27-cp27m-macosx_10_11_intel.whl
tensorflow_gpu-0.12.0rc1-cp27-cp27mu-manylinux1_x86_64.whl
tensorflow_gpu-0.12.0-cp35-cp35m-macosx_10_11_x86_64.whl
tensorflow_gpu-0.12.0rc0-cp27-cp27mu-manylinux1_x86_64.whl
tensorflow_gpu-0.12.0rc0-cp35-cp35m-win_amd64.whl
```

### What other attempted solutions have you tried?


### Logs or other output that would be helpful
(If logs are large, please upload as attachment or provide link).
"
6539,better Variable.__repr__,"Right now, I get sth like:

    <tensorflow.python.ops.variables.Variable object at 0x2b9c67daae10>

It would be nice if it would show sth like

    <Variable name=""foo"" shape=(100,200) dtype=""float32"">

or so.
"
6538,Missing GRPC information on Documentation,Both the site and the Git does not say that it is necessary to have GRPC installed to run distributed TensorFlow.
6537,file_io.get_matching_files fails if any unrelated (non-matching) sub-directory is non-readable,"Let `filename = ""/tmp/mymodel.005""`.

`file_io.get_matching_files(filename)` will raise an exception like

    PermissionDeniedError: /tmp/.xrdp/xrdp-sesman-jjz1ox

for me. I think this is a bug as this is an unrelated (non-matching) directory, so it does not matter and it will anyway not match the `filename`, thus it should not raise an exception.

I get this via `saver.restore(sess=..., save_path=filename)` where `saver = tf.train.Saver(...)`.
"
6534,InvalidArgumentError (see above for traceback): Nan in summary histogram for: dnn/hiddenlayer_0_activation,"I am trying to do regression for my own data following the example of [Deep Neural Network Regression with Boston Data](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/learn/boston.py).

Following is my code.

```
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function
from sklearn import cross_validation
from sklearn import metrics
from sklearn import preprocessing
import tensorflow as tf
from tensorflow.contrib import learn
from numpy import genfromtxt
import numpy as np


def main():
  # Load dataset
  # ARM4mDec2002Jul2015OklahomaV2_mar_apr_may_date_time_normalized_16000_test_data_x.csv
  # ARM4mDec2002Jul2015OklahomaV2_mar_apr_may_date_time_normalized_16000_test_data_y.csv

  x_test = genfromtxt('ARM4mDec2002Jul2015OklahomaV2_mar_apr_may_date_time_normalized_16000_test_data_x.csv', delimiter=',')
  y_test = genfromtxt('ARM4mDec2002Jul2015OklahomaV2_mar_apr_may_date_time_normalized_16000_test_data_y.csv', delimiter=',')
  x_test = x_test.astype(np.float32, copy=False)
  y_test = y_test.astype(np.float32, copy=False)
  
  # ARM4mDec2002Jul2015OklahomaV2_mar_apr_may_date_time_normalized_16000_training_data_x.csv
  # ARM4mDec2002Jul2015OklahomaV2_mar_apr_may_date_time_normalized_16000_training_data_y.csv

  x_train = genfromtxt('ARM4mDec2002Jul2015OklahomaV2_mar_apr_may_date_time_normalized_16000_training_data_x.csv', delimiter=',')
  y_train = genfromtxt('ARM4mDec2002Jul2015OklahomaV2_mar_apr_may_date_time_normalized_16000_training_data_y.csv', delimiter=',')
  x_train = x_train.astype(np.float32, copy=False)
  y_train = y_train.astype(np.float32, copy=False)
  
  # ARM4mDec2002Jul2015OklahomaV2_mar_apr_may_date_time_normalized_16000_validate_data_x.csv
  # ARM4mDec2002Jul2015OklahomaV2_mar_apr_may_date_time_normalized_16000_validate_data_y.csv

  # Scale data (training set) to 0 mean and unit standard deviation.
  # scaler = preprocessing.StandardScaler()
  # x_train = scaler.fit_transform(x_train)

  # Build 2 layer fully connected DNN with 10, 10 units respectively.
  feature_columns = learn.infer_real_valued_columns_from_input(x_train)
  regressor = learn.DNNRegressor(
      feature_columns=feature_columns, hidden_units=[10, 10],optimizer=tf.train.GradientDescentOptimizer(
      learning_rate=0.1))

  # Fit
  regressor.fit(x_train, y_train, steps=5000, batch_size=1)

  # Predict and score
  y_predicted = list(
      regressor.predict(scaler.transform(x_test), as_iterable=True))
  score = metrics.mean_squared_error(y_predicted, y_test)

  print('MSE: {0:f}'.format(score))


if __name__ == '__main__':
  tf.app.run()
```

I am getting the following error.

> >>> arm_data_regression.main()
> WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpIda516
> INFO:tensorflow:Using default config.
> INFO:tensorflow:Using config: {'save_summary_steps': 100, '_num_ps_replicas': 0, '_task_type': None, '_environment': 'local', '_is_chief': True, 'save_checkpoints_secs': 600, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f5464bf7a10>, 'tf_config': gpu_options {
>   per_process_gpu_memory_fraction: 1
> }
> , '_task_id': 0, 'tf_random_seed': None, 'keep_checkpoint_every_n_hours': 10000, '_evaluation_master': '', 'save_checkpoints_steps': None, '_master': '', 'keep_checkpoint_max': 5}
> WARNING:tensorflow:From arm_data_regression.py:45 in main.: calling fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.
> Instructions for updating:
> Estimator is decoupled from Scikit Learn interface by moving into
> separate class SKCompat. Arguments x, y and batch_size are only
> available in the SKCompat class, Estimator will only accept input_fn.
> Example conversion:
>   est = Estimator(...) -> est = SKCompat(Estimator(...))
> WARNING:tensorflow:From arm_data_regression.py:45 in main.: calling fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with y is deprecated and will be removed after 2016-12-01.
> Instructions for updating:
> Estimator is decoupled from Scikit Learn interface by moving into
> separate class SKCompat. Arguments x, y and batch_size are only
> available in the SKCompat class, Estimator will only accept input_fn.
> Example conversion:
>   est = Estimator(...) -> est = SKCompat(Estimator(...))
> WARNING:tensorflow:From arm_data_regression.py:45 in main.: calling fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with batch_size is deprecated and will be removed after 2016-12-01.
> Instructions for updating:
> Estimator is decoupled from Scikit Learn interface by moving into
> separate class SKCompat. Arguments x, y and batch_size are only
> available in the SKCompat class, Estimator will only accept input_fn.
> Example conversion:
>   est = Estimator(...) -> est = SKCompat(Estimator(...))
> INFO:tensorflow:Summary name dnn/hiddenlayer_0:fraction_of_zero_values is illegal; using dnn/hiddenlayer_0_fraction_of_zero_values instead.
> INFO:tensorflow:Summary name dnn/hiddenlayer_0:activation is illegal; using dnn/hiddenlayer_0_activation instead.
> INFO:tensorflow:Summary name dnn/hiddenlayer_1:fraction_of_zero_values is illegal; using dnn/hiddenlayer_1_fraction_of_zero_values instead.
> INFO:tensorflow:Summary name dnn/hiddenlayer_1:activation is illegal; using dnn/hiddenlayer_1_activation instead.
> INFO:tensorflow:Summary name logits:fraction_of_zero_values is illegal; using logits_fraction_of_zero_values instead.
> INFO:tensorflow:Summary name logits:activation is illegal; using logits_activation instead.
> INFO:tensorflow:Create CheckpointSaverHook.
> Traceback (most recent call last):
>   File ""<stdin>"", line 1, in <module>
>   File ""arm_data_regression.py"", line 45, in main
>     regressor.fit(x_train, y_train, batch_size=1)
>   File ""/home/shehab/.local/lib/python2.7/site-packages/tensorflow/python/util/deprecation.py"", line 191, in new_func
>     return func(*args, **kwargs)
>   File ""/home/shehab/.local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py"", line 355, in fit
>     max_steps=max_steps)
>   File ""/home/shehab/.local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py"", line 733, in _train_model
>     max_steps=max_steps)
>   File ""/home/shehab/.local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/graph_actions.py"", line 301, in _monitored_train
>     None)
>   File ""/home/shehab/.local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"", line 473, in run
>     run_metadata=run_metadata)
>   File ""/home/shehab/.local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"", line 628, in run
>     run_metadata=run_metadata)
>   File ""/home/shehab/.local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"", line 595, in run
>     return self._sess.run(*args, **kwargs)
>   File ""/home/shehab/.local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"", line 729, in run
>     run_metadata=run_metadata)
>   File ""/home/shehab/.local/lib/python2.7/site-packages/tensorflow/python/training/monitored_session.py"", line 595, in run
>     return self._sess.run(*args, **kwargs)
>   File ""/home/shehab/.local/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 766, in run
>    run_metadata_ptr)
>   File ""/home/shehab/.local/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 964, in _run
>     feed_dict_string, options, run_metadata)
>   File ""/home/shehab/.local/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 1014, in _do_run
>     target_list, options, run_metadata)
>   File ""/home/shehab/.local/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 1034, in _do_call
>     raise type(e)(node_def, op, message)
> tensorflow.python.framework.errors_impl.InvalidArgumentError: Nan in summary histogram for: dnn/hiddenlayer_0_activation
> 	 [[Node: dnn/hiddenlayer_0_activation = HistogramSummary[T=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""](dnn/hiddenlayer_0_activation/tag, dnn/hiddenlayer_0/hiddenlayer_0/Relu)]]
> 
> Caused by op u'dnn/hiddenlayer_0_activation', defined at:
>   File ""<stdin>"", line 1, in <module>
>   File ""arm_data_regression.py"", line 45, in main
>     regressor.fit(x_train, y_train, batch_size=1)
>   File ""/home/shehab/.local/lib/python2.7/site-packages/tensorflow/python/util/deprecation.py"", line 191, in new_func
>     return func(*args, **kwargs)
>   File ""/home/shehab/.local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py"", line 355, in fit
>     max_steps=max_steps)
>   File ""/home/shehab/.local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py"", line 699, in _train_model
>     train_ops = self._get_train_ops(features, labels)
>   File ""/home/shehab/.local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/dnn_linear_combined.py"", line 219, in _get_train_ops
>     logits = self._logits(features, is_training=True)
>   File ""/home/shehab/.local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/dnn_linear_combined.py"", line 312, in _logits
>     logits = self._dnn_logits(features, is_training)
>   File ""/home/shehab/.local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/dnn_linear_combined.py"", line 295, in _dnn_logits
>     features, self._dnn_feature_columns, is_training)
>   File ""/home/shehab/.local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/composable_model.py"", line 360, in build_model
>     self._add_hidden_layer_summary(net, scope.name)
>   File ""/home/shehab/.local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/composable_model.py"", line 322, in _add_hidden_layer_summary
>     summary.histogram(""%s:activation"" % tag, value)
>   File ""/home/shehab/.local/lib/python2.7/site-packages/tensorflow/python/summary/summary.py"", line 205, in histogram
>     tag=scope.rstrip('/'), values=values, name=scope)
>   File ""/home/shehab/.local/lib/python2.7/site-packages/tensorflow/python/ops/gen_logging_ops.py"", line 139, in _histogram_summary
>     name=name)
>   File ""/home/shehab/.local/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py"", line 759, in apply_op
>     op_def=op_def)
>   File ""/home/shehab/.local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 2240, in create_op
>     original_op=self._default_original_op, op_def=op_def)
>   File ""/home/shehab/.local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 1128, in __init__
>     self._traceback = _extract_stack()
> 
> InvalidArgumentError (see above for traceback): Nan in summary histogram for: dnn/hiddenlayer_0_activation
> 	 [[Node: dnn/hiddenlayer_0_activation = HistogramSummary[T=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""](dnn/hiddenlayer_0_activation/tag, dnn/hiddenlayer_0/hiddenlayer_0/Relu)]]


Am I passing any deprecated argument to DNNRegressor.fit()?


"
6533,Python 3.6 support [feature requests],I'm sure that you are aware that Python 3.6 is available and TensorFlow is still not available for this version. Hope next update will cover the cp36 Python version.
6532,Feature request: log-log scale for tensorboard,"Would there be interest in adding a log-log display mode to tensorboard? That is, to enable plotting the x-axis in log scale for step count (and maybe relative time as well).

I find log-log to be very useful for inspecting learning curves (loss vs. iteration). Given a constant learning rate, standard optimization algorithms usually give a straight line in log-log scale. It's really easy to visually spot when the straight line behavior ends, which is generally a sign that the model has almost converged (for its current learning rate). On the other hand, in lin-lin you can't distinguish the two conditions because everything looks vaguely like exponential decay, and log-lin isn't ideal either."
6531,tf.losses.softmax_cross_entropy is deviously inconsistent,"There are at least three variants of `softmax_cross_entropy` in TensorFlow:

1. `tf.nn.softmax_cross_entropy_with_logits`

Accepts `logits` as the first argument, and `labels` as the second argument.

2. `tf.contrib.losses.softmax_cross_entropy`

Accepts `logits` as the first argument, and `onehot_labels` as the second argument. So far so good. Except this is deprecated, and displays the recommendation `Use tf.losses.softmax_cross_entropy instead`.

3. `tf.losses.softmax_cross_entropy`

Decides to switch things around for fun and have `onehot_labels` as the first argument and  `logits` as the second. Since `onehot_labels` and `logits` are identically shaped tensors, the call succeeds without any complaints (until something else fails as a consequence, like the gradient).

This inconsistency seems a bit error prone. If nothing else, perhaps the deprecation warning for  `tf.contrib.losses.softmax_cross_entropy` should include a heads up.

"
6527,[Java] provide a Maven POM,"It would be handy to have a POM file for the Java library.

In the short-term, having a POM facilitates local development of Java applications (potentially using other build frameworks).  For example, it makes it possible to install the built library into Maven's local repository:
```
mvn install:install-file \
  -Dfile=bazel-bin/tensorflow/java/libtensorflow.jar \
  -DpomFile=tensorflow/java/pom.xml
```

The POM file should also be useful for eventual publishing of the library."
6524,Feature request: Support reference counting on Java Tensor class,"The `Tensor` class of the new Java library would be more useful and easier to use with built-in reference counting, based on a common interface `RefCounted`.    This would be in lieu of `AutoCloseable`.

I suggest that reference counting follow the Netty approach as described [in the docs](http://netty.io/wiki/reference-counted-objects.html).   A nice aspect is that it simplifies the common case of supplying an input tensor to `Session.Runner::feed()` or to `OperationBuilder::setAttr` (the caller needn't unref the tensor; the callee will unref it).  At the same time, a reference count is of more general utility than `AutoCloseable`.

Please consider applying the idea to `Session` and `Graph` later.
"
6523,"possible variable typo in ""Vector Representations of Words"" documentation","The variables ""training_inputs"" and ""training_labels"" in the section ""[https://www.tensorflow.org/tutorials/word2vec/#training_the_model](https://www.tensorflow.org/tutorials/word2vec/#training_the_model)"":

```
for inputs, labels in generate_batch(...):
  feed_dict = {training_inputs: inputs, training_labels: labels}
  _, cur_loss = session.run([optimizer, loss], feed_dict=feed_dict)
```

appear to be new per the tutorial text.

Were they supposed to be the previously defined ""train_inputs"" and ""train_labels""?

thanks,"
6520,Interesting phenomenon when running cifar10_train.py and cifar10_multi_gpu_train.py,"### Environment info
Operating System:
```bash
 centos 7 
```

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):
```bash
$ls -l /usr/local/cuda/lib64/libcud*
```
here is the result
```bash
  548 -rw-r--r-- 1 root root   558720 Dec  7 21:02 /usr/local/cuda/lib64/libcudadevrt.a
    0 lrwxrwxrwx 1 root root       16 Dec  7 21:02 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.8.0
    0 lrwxrwxrwx 1 root root       19 Dec  7 21:02 /usr/local/cuda/lib64/libcudart.so.8.0 -> libcudart.so.8.0.44
  408 -rwxr-xr-x 1 root root   415432 Dec  7 21:02 /usr/local/cuda/lib64/libcudart.so.8.0.44
  760 -rw-r--r-- 1 root root   775162 Dec  7 21:02 /usr/local/cuda/lib64/libcudart_static.a
    0 lrwxrwxrwx 1 root root       13 Dec  7 21:02 /usr/local/cuda/lib64/libcudnn.so -> libcudnn.so.5
    0 lrwxrwxrwx 1 root root       17 Dec  7 21:02 /usr/local/cuda/lib64/libcudnn.so.5 -> libcudnn.so.5.1.5
77480 -rwxr-xr-x 1 root root 79337624 Dec 20 13:45 /usr/local/cuda/lib64/libcudnn.so.5.1.5
68124 -rw-r--r-- 1 root root 69756172 Dec 20 13:45 /usr/local/cuda/lib64/libcudnn_static.a
```

If installed from binary pip package, provide:

1. A link to the pip package you installed:
I install tensorflow using pip with command from pypi
```bash
$ pip install tensorflow-gpu 
```
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.
```bash
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcurand.so locally
0.12.0
```

### Phenomenon
#### Performance of cifar10 model on GPU
When running cifar10_train.py, I tried 2000 steps with batch_size 128
```bash
python cifar10_train.py --data_dir ../datasets/cifar10 --batch_size 128 --max_steps 2000
```
Then elasped time on a Telsa M40 graphics card is 
```bash
Elasped Time: 167.51s
```
Here is the speed running cifar10_multi_gpu_train.py with different number of GPUs on my machine (max_steps=2000, batch_size=128)

| System           |   Examples per sec   | Step Time (sec/batch)   |    Elasped Time (sec)  |
| -------------    |  -------------------   |---------------------------|------------------------|
| 1 Tesla M40   |   1300 ~ 2400          |  0.05 ~ 0.10                   |   157.96                      |
| 2 Tesla M40   |   2700 ~ 3700          |  0.03 ~ 0.04                   |   164.49                      |
| 4 Tesla M40   |   3900 ~ 6300          |  0,02 ~ 0.03                   |   231.98                      |
| 8 Tesla M40   |   3700 ~ 6700          |  0.02 ~ 0.04                   |   431.54                      |

The performance improves as the number of GPUs increases.

#### Performance when moving distorted_inputs to cpu
I made some changes on cifar10_train.py and cifar10_muti_gpu_train.py
```python
# cifar10_train.py
def train():
    with tf.Graph().as_default():
        # Here is what I modified
         with tf.device(""/cpu:0""):
            images, labels = cifar10.distorted_inputs()
```
I put function distorted_inputs on cpu, and then the performace is much better than before
```bash
Elasped Time: 42.92s
```
I made the same change on cifar10_multi_gpu_train.py
```python
# cifar10_multi_gpu_train.py
def tower_loss(scope, images, labels):
  # Get images and labels for CIFAR-10.
  # Commented
  #images, labels = cifar10.distorted_inputs()

  logits = cifar10.inference(images)

  _ = cifar10.loss(logits, labels)
  losses = tf.get_collection('losses', scope)
  total_loss = tf.add_n(losses, name='total_loss')

  for l in losses + [total_loss]:
    loss_name = re.sub('%s_[0-9]*/' % cifar10.TOWER_NAME, '', l.op.name)
    tf.scalar_summary(loss_name, l)

  return total_loss

def train():
  """"""Train CIFAR-10 for a number of steps.""""""
  with tf.Graph().as_default(), tf.device('/cpu:0'):
    global_step = tf.get_variable(
        'global_step', [],
        initializer=tf.constant_initializer(0), trainable=False)

    ...build optimizer...

    # Calculate the gradients for each model tower.
    tower_grads = []
    for i in xrange(FLAGS.num_gpus):
      # move distorted_inputs to here
      images, labels = cifar10.distorted_inputs()
      with tf.device('/gpu:%d' % i):
          with tf.name_scope('%s_%d' % (cifar10.TOWER_NAME, i)) as scope:
               loss = tower_loss(scope, images, labels)
```
And then the performance is 

| System           |   Examples per sec   | Step Time (sec/batch)   |    Elasped Time (sec)  |
| -------------    |  -------------------   |---------------------------|------------------------|
| 1 Tesla M40   |   6700 ~ 7700          |  0.016 ~ 0.019               |   42.62                       |
| 2 Tesla M40   |   6800 ~ 7600          |  0.016 ~ 0.018               |   78.18                        |
| 4 Tesla M40   |   7000 ~ 7400          |  0,017 ~ 0.018               |   154.88                      |
| 8 Tesla M40   |   6900 ~ 7200          |  0,017 ~ 0.018               |   309.95                      |

The performce is much better than the previous table but increaing number of GPUs does not acquire better result. "
6519,Can't output summaries using tensorflow.contrib.slim,"When I run my code, it gives the following warning:
`WARNING:tensorflow:From C:\Program Files\Anaconda3\lib\site-packages\tensorflow\python\training\supervisor.py:344 in __init__.: SummaryWriter.__init__ (from tensorflow.python.training.summary_io) is deprecated and will be removed after 2016-11-30.
Instructions for updating:
Please switch to tf.summary.FileWriter. The interface and behavior is the same; this is just a rename.`

And It can't output the summaries. Although I think it is training my net. Here's some of my code:

`summaries = set(tf.get_collection(tf.GraphKeys.SUMMARIES))
for end_point in end:
    x=end[end_point]
    summaries.add(tf.summary.histogram('activations/' + end_point, x))
    summaries.add(tf.summary.scalar('sparsity/' + end_point,  tf.nn.zero_fraction(x)))
for loss in tf.get_collection(tf.GraphKeys.LOSSES):
    summaries.add(tf.summary.scalar('losses/%s' % loss.op.name, loss))
for variable in slim.get_model_variables():
     summaries.add(tf.summary.histogram(variable.op.name, variable))
summaries.add(tf.summary.scalar('learning_rate', learning_rate))
summaries.add(tf.summary.scalar('total_loss', total_loss))
#summaries |= set(tf.get_collection(tf.GraphKeys.SUMMARIES))
summary_op = tf.summary.merge(list(summaries))
slim.learning.train(train_op, 
    model_store_dir, 
    init_fn = init_fn,
    summary_op=summary_op,
    number_of_steps=100000,
    save_summaries_secs=300, 
    save_interval_secs=600)`"
6518,tf.sequence_mask with int64 does not work,"Given some tensor `x` with shape (batch,time) and `seq_lens` of shape (batch,) of dtype `int64`, I wanted to use this code:
```
    mask = tf.sequence_mask(seq_lens, maxlen=tf.shape(x)[1])
```

This fails with `TypeError: Input 'y' of 'Less' Op has type int64 that does not match type int32 of argument 'x'.` in `gen_math_ops._range(0, maxlen, 1) < expand_dims(lengths, 1)`.

If I add `seq_lens = tf.cast(seq_lens, ""int32"")` before, then it works.

Casting `tf.shape(x)[1]` to `int64` does not work (because of `gen_math_ops._range(0, maxlen, 1)` which treats `0` and `1` as `int32` and then raises `TypeError: Input 'limit' of 'Range' Op has type int64 that does not match type int32 of argument 'start'`).
"
6517,no code completion supported in tf0.12.0 ?,"when i typed `tf.contrib.rnn.`, there is no code completion choice with pycharm and ipython.are there some soft reload mechanism ?. what should i do to solve this problem.
"
6515,tensorboard fail to load summaries,"Enviroment: Ubuntu14.04
tensorflow installed with
`sudo pip install --upgrade https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow_gpu-0.12.0-cp27-none-linux_x86_64.whl`

tensorboard fails to load events, even with the tensorflow_root_path/models/image/cifar10/cifar10_train.py.
run `python cifar10_train.py`, [the event file](https://github.com/tensorflow/tensorflow/files/673591/event.zip)

`tensorboard --logdir=/tmp/cifar_train` gives

> I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcurand.so locally
Starting TensorBoard 39 on port 6006
(You can navigate to http://127.0.1.1:6006)

But tensorboard did not load any summary
![image](https://cloud.githubusercontent.com/assets/6497205/21490461/c543dccc-cc2f-11e6-920b-71e61fa20268.png)

"
6514,tensorflow (0.12.0) doesn't work with libcudart.so.8.0.44,"Hi，
I'm using cuda-8.0 on centos7.3, and I install tensorflow(0.12.0)  with pip.
when I tried to import tensorflow, it report ""ImportError: libcudart.so.8.0: cannot open shared object file: No such file or directory"".
I'm sure libcudart.so.8.0 does exist. tensorflow-0.12.0 should works with cuda-8.0 according the docs.

```
# python -c 'import tensorflow'
Traceback (most recent call last):
  File ""<string>"", line 1, in <module>
  File ""/usr/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>
    from tensorflow.python import *
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 60, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 28, in <module>
    _pywrap_tensorflow = swig_import_helper()
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow', fp, pathname, description)
ImportError: libcudart.so.8.0: cannot open shared object file: No such file or directory


Error importing tensorflow.  Unless you are using bazel,
you should not try to import tensorflow from its source directory;
please exit the tensorflow source tree, and relaunch your python interpreter
from there.
# ll  /usr/local/cuda/lib64/libcudart.so*
lrwxrwxrwx. 1 root root     16 Dec 20 16:22 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.8.0
lrwxrwxrwx. 1 root root     19 Dec 20 16:22 /usr/local/cuda/lib64/libcudart.so.8.0 -> libcudart.so.8.0.44
-rwxr-xr-x. 1 root root 415432 Dec 20 16:22 /usr/local/cuda/lib64/libcudart.so.8.0.44
# pip list|grep tensorflow
tensorflow (0.12.0)
tensorflow-gpu (0.12.0)
```"
6513,Tensorboard AttributeError: 'module' object has no attribute 'cpu_count',"### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?
Some people report having similar problems with 'module' objects having no attribute something-or-other and claim they were solved by upgrading.

### Environment info
Operating System:
Ubuntu 17.04 x64
Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):
```
-rw-r--r-- 1 root root   558720 сен 15 02:02 /usr/local/cuda/lib64/libcudadevrt.a
-rw-r--r-- 1 root root   383336 дек 23 01:26 /usr/local/cuda/lib64/libcudart.so
-rw-r--r-- 1 root root   383336 дек 23 01:25 /usr/local/cuda/lib64/libcudart.so.7.5
lrwxrwxrwx 1 root root       19 дек 23 02:17 /usr/local/cuda/lib64/libcudart.so.8.0 -> libcudart.so.8.0.44
-rw-r--r-- 1 root root   415432 сен 15 02:02 /usr/local/cuda/lib64/libcudart.so.8.0.44
-rw-r--r-- 1 root root   775162 сен 15 02:02 /usr/local/cuda/lib64/libcudart_static.a
lrwxrwxrwx 1 root root       13 дек 23 02:17 /usr/local/cuda/lib64/libcudnn.so -> libcudnn.so.5
lrwxrwxrwx 1 root root       17 дек 23 02:17 /usr/local/cuda/lib64/libcudnn.so.5 -> libcudnn.so.5.1.5
-rwxr-xr-x 1 root root 79337624 дек 22 04:25 /usr/local/cuda/lib64/libcudnn.so.5.1.5
-rw-r--r-- 1 root root 69756172 дек 22 04:25 /usr/local/cuda/lib64/libcudnn_static.a

```
(yes, it's an unholy mess, with russian date format. sorry)

If installed from binary pip package, provide:

1. A link to the pip package you installed: 
https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow_gpu-0.12.0-cp27-none-linux_x86_64.whl
as per[ instructions](https://www.tensorflow.org/get_started/os_setup)
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.
```
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcurand.so locally
0.12.0
```


### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)
```
cd example; 
python /usr/local/lib/python2.7/dist-packages/tensorflow/tensorboard/tensorboard.py --logdir=/home/myname/example/log_simple_graph
```

### What other attempted solutions have you tried?
See above; I've tried to run the actual `tensorboard.py` instead of just `tensorboard --logdir=`

### Logs or other output that would be helpful
Running `cd example; 
python /usr/local/lib/python2.7/dist-packages/tensorflow/tensorboard/tensorboard.py --logdir=/home/myname/example/log_simple_graph` results in:
```
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcurand.so locally
Traceback (most recent call last):
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/tensorboard/tensorboard.py"", line 34, in <module>
    from tensorflow.tensorboard.backend import server
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/tensorboard/backend/server.py"", line 37, in <module>
    from tensorflow.tensorboard.backend import handler
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/tensorboard/backend/handler.py"", line 43, in <module>
    from tensorflow.tensorboard.plugins import REGISTERED_PLUGINS
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/tensorboard/plugins/__init__.py"", line 20, in <module>
    from tensorflow.tensorboard.plugins.projector.plugin import ProjectorPlugin
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/tensorboard/plugins/projector/plugin.py"", line 27, in <module>
    from tensorflow.contrib.tensorboard.plugins.projector import PROJECTOR_FILENAME
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/__init__.py"", line 27, in <module>
    from tensorflow.contrib import factorization
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/factorization/__init__.py"", line 24, in <module>
    from tensorflow.contrib.factorization.python.ops.gmm import *
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/factorization/python/ops/gmm.py"", line 30, in <module>
    from tensorflow.contrib.learn.python.learn.estimators import estimator
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/__init__.py"", line 66, in <module>
    from tensorflow.contrib.learn.python.learn import *
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/__init__.py"", line 23, in <module>
    from tensorflow.contrib.learn.python.learn import *
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/__init__.py"", line 27, in <module>
    from tensorflow.contrib.learn.python.learn import estimators
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/__init__.py"", line 269, in <module>
    from tensorflow.contrib.learn.python.learn.estimators.classifier import Classifier
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/classifier.py"", line 25, in <module>
    from tensorflow.contrib.learn.python.learn.estimators import estimator
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py"", line 52, in <module>
    from tensorflow.contrib.learn.python.learn.learn_io import data_feeder
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/learn_io/__init__.py"", line 22, in <module>
    from tensorflow.contrib.learn.python.learn.learn_io.dask_io import extract_dask_data
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/learn_io/dask_io.py"", line 26, in <module>
    import dask.dataframe as dd
  File ""/usr/local/lib/python2.7/dist-packages/dask/dataframe/__init__.py"", line 5, in <module>
    from .io import (from_array, from_pandas, from_bcolz,
  File ""/usr/local/lib/python2.7/dist-packages/dask/dataframe/io/__init__.py"", line 6, in <module>
    from .csv import read_csv, to_csv, read_table
  File ""/usr/local/lib/python2.7/dist-packages/dask/dataframe/io/csv.py"", line 147, in <module>
    CPU_COUNT = psutil.cpu_count()
AttributeError: 'module' object has no attribute 'cpu_count'

```


I've been following [this](https://www.oreilly.com/learning/hello-tensorflow) intro, and the code from there worked perfectly for me (apart from some warnings about deprecations).
"
6512,The meaning of batch_size in ptb_word_lm,"I am new to tensorflow, i am now a little confused about the meaning of batch_size. As commonly known that the meaning of batch_size is the number of samples for each batch, but according to the code in ptb_word_lm, it seems not:
reader.py
data_len = tf.size(raw_data)  #the number of words in dataset
batch_len = data_len // batch_size   #what does batch_len mean? the number of batchs?does not make sense

ptb_word_lm.py
self.epoch_size = ((len(data) // batch_size) - 1) // num_steps   #what does epoch_size mean? the number of sequence in each batch?does not make sense

But if batch_size means the number of batches, then everything make sense. have i got something misunderstood?"
6511,No module named 'gen_word2vec' and missing tf.models,"I got two problems with tensorflow, which was built today from source. My OS is Mac. 
1.I was trying to run the code here https://github.com/tensorflow/models/blob/master/tutorials/embedding/word2vec.py, but received an error: 
     ImportError: No module named 'gen_word2vec'
Could anyone help explain where I could find the gen_word2vec.py? 
2. Another problem is that I couldn't import tensorflow.models anymore:
    AttributeError: module 'tensorflow' has no attribute 'models'

The information of my tensorflow is here:

Name: tensorflow
Version: 0.12.0
Summary: TensorFlow helps the tensors flow
Home-page: http://tensorflow.org/
Author: Google Inc.
Author-email: opensource@google.com
License: Apache 2.0
Location: /usr/local/lib/python3.5/site-packages
Requires: protobuf, wheel, numpy, six"
6510,"Tensorflow0.08+cuda7.5+cudnn v4, GPU is not used as wished","    I have installed Tensorflow0.08+cuda7.5+cudnn v4 by Anaconda installation. However, when I was training the DDPG network, I found that the speed was rather slow and the computation was mainly done in CPU instead of GPU. Hope someone can help me out.
    Regards,
    Cardwing"
6509,Issue with tf.one_hot() in 0.12.0 in GPU mode (CUDA_ERROR_ILLEGAL_ADDRESS),"I'm using a LeNet-5 mnist example from Udacity's course. Link to the source code is below.
Training works ok on a CPU (config = tf.ConfigProto(device_count = {'GPU': 0})),
but fails in a GPU mode with the following 'CUDA_ERROR_ILLEGAL_ADDRESS' error:

> I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\common_runtime\gpu\gpu_device.cc:885] Found device 0 with properties:
name: GeForce GTX 1060 6GB
major: 6 minor: 1 memoryClockRate (GHz) 1.7845
pciBusID 0000:01:00.0
Total memory: 6.00GiB
Free memory: 5.01GiB
I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\common_runtime\gpu\gpu_device.cc:906] DMA: 0
I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\common_runtime\gpu\gpu_device.cc:916] 0:   Y
I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\common_runtime\gpu\gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1060 6GB, pci bus id: 0000:01:00.0)
Training...
E c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\stream_executor\cuda\cuda_event.cc:49] Error polling for event status: failed to query event: **CUDA_ERROR_ILLEGAL_ADDRESS**
F c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\common_runtime\gpu\gpu_event_mgr.cc:198] Unexpected Event status: 1

I have reproduced same error on two setups.
Environment 1 (Home PC):
- windows 10; 
- latest anaconda 4.2.0, python 3.5; 
- cuda 8
- cudnn 5.1 (for win10)
- tensorflow 0.12.0 gpu (https://storage.googleapis.com/tensorflow/windows/gpu/tensorflow_gpu-0.12.0-cp35-cp35m-win_amd64.whl)
- GeForce GTX 1060 6Gb

Environment 2 (Work PC):
- windows 7; 
- latest anaconda 4.2.0, python 3.5; 
- cuda 8
- cudnn 5.1 (for win7)
- tensorflow 0.12.0 gpu (https://storage.googleapis.com/tensorflow/windows/gpu/tensorflow_gpu-0.12.0-cp35-cp35m-win_amd64.whl)
- GeForce GTX 660 3Gb

I'm sharing two scripts with minor changes that allow a workaround:
https://drive.google.com/open?id=0B6jkkqMOGy5cNHh3TVpxU283Ykk

Main difference:
Script from example that crashes (LabLenetBad.py) uses raw mnist label data with the tf.one_hot() call.
The workaround (LabLenetGood.py) reads mnist data with (one_hot=True) flag and does not use tf.one_hot() call on the Y placeholder.

I think that tf.one_hot does not work properly on the gpu."
6508,PS OOM in Distributed Inception,"We are trying to train Inception model on ImageNet in a distributed setting following the guide [here](https://github.com/tensorflow/models/tree/master/inception). TensorFlow successfully trains the model with 32 workers but with 64 worker, the PS dies with OOM killer. 

In all of these experiments, PS was running on a separate machine. Looking at the memory consumption of 32 workers, it seems that there is no memory issue and the memory becomes stable after a couple of iterations. With 64 workers, PS dies after allocating all the available memory (32GB) after only two iterations.

Is this the expected behavior from PS or not? If not, please let us know if we can provide any other information that may help debugging this problem.

#### Environment info
TensorFlow 0.12
CUDA 8.0
CUDNN 5.1
RAM: 32 GB
GPU: K20

"
6507,"Feature request: Add float16 support for Conv3D, MaxPool3D and AvgPool3D ops","Support for `tf.float16 dtype` was recently added ([#1300](https://github.com/tensorflow/tensorflow/issues/1300)) to a bunch of ops. Can we add it for conv3d too, please?

conv3d is important to development of videos and medical images systems. Since both consumes a lot of memory, it would be good to have fp16 support to allow deeper models."
6506,Error in `python': free(): invalid pointer: when running example frac.cc op,"Frac.cc as in repo:
```c++
// legal stuff

// An example Op.

#include ""tensorflow/core/framework/op.h""
#include ""tensorflow/core/framework/op_kernel.h""

using namespace tensorflow;

REGISTER_OP(""Fact"")
    .Output(""fact: string"")
    .Doc(R""doc(
Output a fact about factorials.
)doc"");

class FactOp : public OpKernel {
 public:
  explicit FactOp(OpKernelConstruction* context) : OpKernel(context) {}

  void Compute(OpKernelContext* context) override {
    // Output a scalar string.
    Tensor* output_tensor = NULL;
    OP_REQUIRES_OK(context,
                   context->allocate_output(0, TensorShape(), &output_tensor));
    auto output = output_tensor->template scalar<string>();

    output() = ""0! == 1"";
  }
};

REGISTER_KERNEL_BUILDER(Name(""Fact"").Device(DEVICE_CPU), FactOp);
```

bazel build:
```bazel
load(""//tensorflow:tensorflow.bzl"", ""tf_custom_op_library"")

tf_custom_op_library(
    name = ""fact.so"",
    srcs = [""fact.cc""],
)
```

Test script:
```python
import tensorflow as tf
fact_module = tf.load_op_library('tensorflow/bazel-bin/tensorflow/core/user_ops/fact.so')
```

full core dump: http://pastebin.com/69rLzybC

I'm trying to write tf op. Tf repo is on origin/r0.12 tag

What is going on and how do I fix it/implement my custom op?
Python version 3.5.2
Linux protagonist 4.8.13-1-ARCH #1 SMP PREEMPT Fri Dec 9 07:24:34 CET 2016 x86_64 GNU/Linux
"
6504,Feature Request: Gradient for QR op,"The QR op is currently implemented but has no gradient.  It would be very useful if the gradient were defined so that the op could be used in networks and cost functions.
"
6503,Feature Request: Gradient for SVD op,"The gradient for the SVD op would be very useful so that it could be used in networks and cost functions.  Currently when trying to use SVD I get the follow:

LookupError: No gradient defined for operation 'Svd' (op type: Svd)

So my request is for the gradient for the SVD op
"
6502,"Insert rows ( arrays ) into a tensor at specific index , and index keeps on changing with batch of data","I have function , to which I have to pass a dynamic list of values and dynamic batch size, along with feed dict in Tensorflow. The tf.unstack function accepts an int only. This int here is my batch size and doc_length is list of values. It will change with each batch of data. The idea here, from RNN, i am getting a state matrix and I have to insert zeros at some particular indices.

How to pass these dynamic batch size and list of values with sess.run( _ , feed_dict) for every batch of data ? Hope the question is clear.

```
### sentence_vec is the output from an RNN 

def sentence_converter(sentence_vec, doc_length , batch_size):
    sentence_tensors = tf.unstack(sentence_vec, batch_size, axis=0)
    max_len = max(doc_length)

    zero_tensor = tf.zeros(self.encoder_units)
    temp = 0
    for elem in doc_length:
        if elem == max_len:
            continue
        diff = max_len - elem
        diff_range = range(1, diff+1)
        for sub_elem in diff_range:
            insert = temp + sub_elem + elem
            sentence_tensors.insert(insert-1, zero_tensor)
        temp = insert
    return tf.stack(sentence_tensors)

X = tf.placeholder(tf.int32, shape=[None, None], name='X_input')
X_len = tf.placeholder(tf.int32, shape=[None], name='X_length')

enc_cell = tf.nn.rnn_cell.GRUCell(self.enco:der_units)#python.ops.rnn_cell.GRUCell
enc_out, enc_state = tf.nn.dynamic_rnn(cell=enc_cell, inputs=X,
                             sequence_length=X_len, dtype=tf.float32)
final_state = sentence_converter(enc_state , batch_size , doc_len)


if __name__ == ""__main__"":
      sess = tf.Session()
      sess.run(tf.initialize_all_variables())
      output_state = sess.run(final_state , feed_dict(X:np.random.randn(2,11) , X_len:[3,2])


```

So, here 2 is the batch size . Suppose the doc_len = [5,7] , how will I pass these to get the final_state , each time. These doc_len is dynamically changing list with each batch. "
6501,Issue with tf v0.12.0 when using split,"the code run correctly with tf 0.12rc1.0, but when using 0.12.0, an error occured. 
here is the log. 
I tensorflow/stream_executor/dso_loader.cc:125] successfully opened CUDA library libcublas.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:125] successfully opened CUDA library libcudnn.so.5 locally
I tensorflow/stream_executor/dso_loader.cc:125] successfully opened CUDA library libcufft.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:125] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:125] successfully opened CUDA library libcurand.so.8.0 locally
W tensorflow/core/platform/cpu_feature_guard.cc:95] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:95] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:95] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
W tensorflow/core/platform/cpu_feature_guard.cc:95] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
Traceback (most recent call last):
  File ""/home/keith/PycharmProjects/pic2sentence/Model.py"", line 359, in <module>
    tf.app.run()
  File ""/home/keith/workspace/tfboy_2.7/local/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 44, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""/home/keith/PycharmProjects/pic2sentence/Model.py"", line 343, in main
    model = Model()
  File ""/home/keith/PycharmProjects/pic2sentence/Model.py"", line 42, in __init__
    outputs = self.alex_net2(self.encoder_inputs, is_training)  # [None, 4096]
  File ""/home/keith/PycharmProjects/pic2sentence/Model.py"", line 124, in alex_net2
    conv2_in = conv(maxpool1, conv2W, conv2b, k_h, k_w, c_o, s_h, s_w, padding=""SAME"", group=group)
  File ""/home/keith/PycharmProjects/pic2sentence/Model.py"", line 91, in conv
    input_groups = tf.split(3, group, input)
  File ""/home/keith/workspace/tfboy_2.7/local/lib/python2.7/site-packages/tensorflow/python/ops/array_ops.py"", line 1319, in split
    split_dim=axis, num_split=num_or_size_splits, value=value, name=name)
  File ""/home/keith/workspace/tfboy_2.7/local/lib/python2.7/site-packages/tensorflow/python/ops/gen_array_ops.py"", line 3385, in _split
    num_split=num_split, name=name)
  File ""/home/keith/workspace/tfboy_2.7/local/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py"", line 509, in apply_op
    (prefix, dtypes.as_dtype(input_arg.type).name))
TypeError: Input 'split_dim' of 'Split' Op has type float32 that does not match expected type of int32.
"
6500,Issue with Tensorflow on windows when using TensorForestEstimator,"I already have conda installation in my Windows, I installed tensorflow using pip and it was working fine based on the testing the [tensorflow installation](https://www.tensorflow.org/get_started/os_setup#test_the_tensorflow_installation).

When I'm using TensorForestEstimator, I',m getting the following error
**lib\site-packages\tensorflow\contrib\tensor_forest\python\ops\_training_ops.so not found**

Complete details

**hparams = tf.contrib.tensor_forest.python.tensor_forest.ForestHParams(
        num_trees=2, max_nodes=1000, num_classes=2, num_features=9, model_dir='model/fit/')**

**forest_classifier = tf.contrib.learn.TensorForestEstimator(hparams)**

Warning Messages:

WARNING:tensorflow:Using temporary folder as model directory: C:\Users\username\AppData\Local\Temp\tmpu1vjyu11
INFO:tensorflow:Using default config.
INFO:tensorflow:Using config: {'tf_random_seed': None, 'keep_checkpoint_max': 5, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x00000218062DCE10>, 'save_checkpoints_steps': None, 'save_checkpoints_secs': 600, '_task_id': 0, 'keep_checkpoint_every_n_hours': 10000, 'tf_config': gpu_options {
  per_process_gpu_memory_fraction: 1
}
, '_is_chief': True, '_num_ps_replicas': 0, '_master': '', '_environment': 'local', 'save_summary_steps': 100, '_task_type': None, '_evaluation_master': ''}

**forest_classifier.fit(x=training_data, y=Y_train, batch_size=10, steps=2000)**

WARNING:tensorflow:From D:\Program Files\Anaconda3\lib\site-packages\tensorflow\contrib\learn\python\learn\estimators\random_forest.py:237 in fit.: calling BaseEstimator.fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.
Instructions for updating:
Estimator is decoupled from Scikit Learn interface by moving into
separate class SKCompat. Arguments x, y and batch_size are only
available in the SKCompat class, Estimator will only accept input_fn.
Example conversion:
  est = Estimator(...) -> est = SKCompat(Estimator(...))
WARNING:tensorflow:From D:\Program Files\Anaconda3\lib\site-packages\tensorflow\contrib\learn\python\learn\estimators\random_forest.py:237 in fit.: calling BaseEstimator.fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with y is deprecated and will be removed after 2016-12-01.
Instructions for updating:
Estimator is decoupled from Scikit Learn interface by moving into
separate class SKCompat. Arguments x, y and batch_size are only
available in the SKCompat class, Estimator will only accept input_fn.
Example conversion:
  est = Estimator(...) -> est = SKCompat(Estimator(...))
WARNING:tensorflow:From D:\Program Files\Anaconda3\lib\site-packages\tensorflow\contrib\learn\python\learn\estimators\random_forest.py:237 in fit.: calling BaseEstimator.fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with batch_size is deprecated and will be removed after 2016-12-01.
Instructions for updating:
Estimator is decoupled from Scikit Learn interface by moving into
separate class SKCompat. Arguments x, y and batch_size are only
available in the SKCompat class, Estimator will only accept input_fn.
Example conversion:
  est = Estimator(...) -> est = SKCompat(Estimator(...))
INFO:tensorflow:Constructing forest with params = 
INFO:tensorflow:{'dominate_method': 'hoeffding', 'dominate_fraction': 0.99, 'bagged_num_features': 9, 'split_initializations_per_input': 1, 'num_trees': 2, 'base_random_seed': 0, 'valid_leaf_threshold': 1, 'bagged_features': None, 'min_split_samples': 5, 'bagging_fraction': 1.0, 'num_classes': 2, 'num_features': 9, 'feature_bagging_fraction': 1.0, 'num_splits_to_consider': 10, 'split_after_samples': 250, 'model_dir': 'model/fit/', 'num_outputs': 1, 'max_nodes': 1000, 'num_output_columns': 3, 'regression': False, 'max_fertile_nodes': 500}
INFO:tensorflow:data path: D:\Program Files\Anaconda3\lib\site-packages\tensorflow\contrib\tensor_forest\python\ops\_training_ops.so


**---------------------------------------------------------------------------
NotFoundError                             Traceback (most recent call last)
<ipython-input-23-095850e88d53> in <module>()
----> 1 forest_classifier.fit(x=training_data, y=Y_train, batch_size=10, steps=200)

D:\Program Files\Anaconda3\lib\site-packages\tensorflow\contrib\learn\python\learn\estimators\random_forest.py in fit(self, x, y, input_fn, steps, batch_size, monitors, max_steps)
    235     self._estimator.fit(input_fn=input_fn, x=x, y=y,
    236                         batch_size=batch_size, steps=steps, monitors=monitors,
--> 237                         max_steps=max_steps)
    238 
    239   @deprecated_arg_values(

D:\Program Files\Anaconda3\lib\site-packages\tensorflow\python\util\deprecation.py in new_func(*args, **kwargs)
    189             _call_location(), decorator_utils.get_qualified_name(func),
    190             func.__module__, arg_name, date, instructions)
--> 191       return func(*args, **kwargs)
    192     new_func.__doc__ = _add_deprecated_arg_notice_to_docstring(
    193         func.__doc__, date, instructions)

D:\Program Files\Anaconda3\lib\site-packages\tensorflow\contrib\learn\python\learn\estimators\estimator.py in fit(self, x, y, input_fn, steps, batch_size, monitors, max_steps)
    353                              steps=steps,
    354                              monitors=monitors,
--> 355                              max_steps=max_steps)
    356     logging.info('Loss for final step: %s.', loss)
    357     return self

D:\Program Files\Anaconda3\lib\site-packages\tensorflow\contrib\learn\python\learn\estimators\estimator.py in _train_model(self, input_fn, steps, feed_fn, init_op, init_feed_fn, init_fn, device_fn, monitors, log_every_steps, fail_on_nan_loss, max_steps)
    697       # cases, but will soon be deleted after the subclasses are updated.
    698       # TODO(b/32664904): Update subclasses and delete the else-statement.
--> 699       train_ops = self._get_train_ops(features, labels)
    700       if isinstance(train_ops, model_fn_lib.ModelFnOps):  # Default signature
    701         train_op = train_ops.train_op

D:\Program Files\Anaconda3\lib\site-packages\tensorflow\contrib\learn\python\learn\estimators\estimator.py in _get_train_ops(self, features, labels)
   1050       `ModelFnOps` object.
   1051     """"""
-> 1052     return self._call_model_fn(features, labels, model_fn_lib.ModeKeys.TRAIN)
   1053 
   1054   def _get_eval_ops(self, features, labels, metrics):

D:\Program Files\Anaconda3\lib\site-packages\tensorflow\contrib\learn\python\learn\estimators\estimator.py in _call_model_fn(self, features, labels, mode)
   1021         model_fn_results = self._model_fn(features, labels, mode=mode)
   1022     else:
-> 1023       model_fn_results = self._model_fn(features, labels)
   1024 
   1025     if isinstance(model_fn_results, model_fn_lib.ModelFnOps):

D:\Program Files\Anaconda3\lib\site-packages\tensorflow\contrib\learn\python\learn\estimators\random_forest.py in _model_fn(features, labels)
    116       _assert_float32(labels)
    117 
--> 118     graph_builder = graph_builder_class(params, device_assigner=device_assigner)
    119     inference = {eval_metrics.INFERENCE_PROB_NAME:
    120                  graph_builder.inference_graph(processed_features,

D:\Program Files\Anaconda3\lib\site-packages\tensorflow\contrib\tensor_forest\python\tensor_forest.py in __init__(self, params, device_assigner, variables, tree_variables_class, tree_graphs, training, t_ops, i_ops)
    334             self.variables[i], self.params,
    335             t_ops.Load(), i_ops.Load(), i)
--> 336         for i in range(self.params.num_trees)]
    337 
    338   def _bag_features(self, tree_num, input_data):

D:\Program Files\Anaconda3\lib\site-packages\tensorflow\contrib\tensor_forest\python\tensor_forest.py in <listcomp>(.0)
    334             self.variables[i], self.params,
    335             t_ops.Load(), i_ops.Load(), i)
--> 336         for i in range(self.params.num_trees)]
    337 
    338   def _bag_features(self, tree_num, input_data):

D:\Program Files\Anaconda3\lib\site-packages\tensorflow\contrib\tensor_forest\python\ops\training_ops.py in Load()
     54       ops_path = resource_loader.get_path_to_datafile(TRAINING_OPS_FILE)
     55       logging.info('data path: %s', ops_path)
---> 56       _training_ops = load_library.load_op_library(ops_path)
     57 
     58       assert _training_ops, 'Could not load _training_ops.so'

D:\Program Files\Anaconda3\lib\site-packages\tensorflow\python\framework\load_library.py in load_op_library(library_filename)
     62       # pylint: disable=protected-access
     63       raise errors_impl._make_specific_exception(
---> 64           None, None, error_msg, error_code)
     65       # pylint: enable=protected-access
     66   finally:

NotFoundError: D:\Program Files\Anaconda3\lib\site-packages\tensorflow\contrib\tensor_forest\python\ops\_training_ops.so not found**




"
6499,how test a model made tensorflow and python following the code,"```
from __future__ import print_function
import numpy as np
import tensorflow as tf
import math as math
import argparse

parser = argparse.ArgumentParser()
parser.add_argument('dataset')
args = parser.parse_args()

def file_len(fname):
    with open(fname) as f:
        for i, l in enumerate(f):
            pass
            #print(l)
            #print(""pass"")
            #print(i)
    return i + 1

def read_from_csv(filename_queue):
  reader = tf.TextLineReader(skip_header_lines=1)
  _, csv_row = reader.read(filename_queue)
  record_defaults = [[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0],[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0],[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0],[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0],[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0],[0.0], [0.0], [0.0], [0.0], [0.0], [0.0], [0.0]]
  col0,col1, col2, col3, col4, col5,col6, col7, col8, col9, col10,col11, col12, col13, col14, col15,col16, col17, col18, col19, col20,col21, col22, col23, col24, col25,col26, col27, col28, col29, col30,col31, col32, col33, col34, col35,col36, col37, col38, col39, col40,col41, col42, col43, col44, col45,col46, col47, col48, col49, col50,col51, col52, col53, col54, col55,col56, colLabel = tf.decode_csv(csv_row, record_defaults=record_defaults)
  features = tf.pack([col0,col1, col2, col3, col4, col5,col6, col7, col8, col9, col10,col11, col12, col13, col14, col15,col16, col17, col18, col19, col20,col21, col22, col23, col24, col25,col26, col27, col28, col29, col30,col31, col32, col33, col34, col35,col36, col37, col38, col39, col40,col41, col42, col43, col44, col45,col46, col47, col48, col49, col50,col51, col52, col53, col54, col55,col56])  
  label = tf.pack([colLabel])  
  return features, label

def input_pipeline(batch_size, num_epochs=1):
  #filename_queue = tf.train.string_input_producer([args.dataset], num_epochs=num_epochs, shuffle=True)  
  
  [args.dataset]
  filename_queue = tf.train.string_input_producer([args.dataset], num_epochs=1, shuffle=True)  

  example, label = read_from_csv(filename_queue)
  min_after_dequeue = 4598
  #capacity = min_after_dequeue + 3 * batch_size
  capacity = 4599
  example_batch, label_batch = tf.train.shuffle_batch(
      [example, label], batch_size=batch_size, capacity=capacity,
      min_after_dequeue=min_after_dequeue)
  return example_batch, label_batch
  
def input_pipeline_test(batch_size, num_epochs=1):
  #filename_queue = tf.train.string_input_producer([args.dataset], num_epochs=num_epochs, shuffle=True)  
  
  
  print(""filename_queue_test"")
  filename_queue_test = tf.train.string_input_producer([args.dataset], num_epochs=1, shuffle=True)  

  example, label = read_from_csv(filename_queue_test)
  print(""filename_queue_test end"")
  min_after_dequeue = 1379
  #capacity = min_after_dequeue + 3 * batch_size
  capacity = 1380
  example_batch, label_batch = tf.train.shuffle_batch(
      [example, label], batch_size=batch_size, capacity=capacity,
      min_after_dequeue=min_after_dequeue)
  print(example_batch)
  return example_batch, label_batch
#####################################################################################################################################
#####################################################################################################################################
#####################################################################################################################################
# Parameters
learning_rate = 0.6
training_epochs = 1
batch_size = 1000
display_step = 1

# Network Parameters
n_hidden_1 = 100# 1st layer number of features
n_hidden_2 = 30# 2nd layer number of features
n_input = 57 # MNIST data input (img shape: 28*28)
n_classes = 1 # MNIST total classes (0-9 digits)


# Create model
def multilayer_perceptron(x, weights, biases):
    # Hidden layer with RELU activation
    layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])
    layer_1 = tf.nn.relu(layer_1)
    # Hidden layer with RELU activation
    layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])
    layer_2 = tf.nn.relu(layer_2)
    # Output layer with linear activation
    out_layer = tf.matmul(layer_2, weights['out']) + biases['out']
    return out_layer

# Store layers weight & bias
weights = {
    'h1': tf.Variable(tf.random_normal([n_input, n_hidden_1])),
    'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),
    'out': tf.Variable(tf.random_normal([n_hidden_2, n_classes]))
}
biases = {
    'b1': tf.Variable(tf.random_normal([n_hidden_1])),
    'b2': tf.Variable(tf.random_normal([n_hidden_2])),
    'out': tf.Variable(tf.random_normal([n_classes]))
}





#########################################################################################################################################
#########################################################################################################################################
#print(""file_len(args.dataset) - 1"")
#print(file_len(args.dataset) - 1)
file_length = file_len(args.dataset) - 1
#file_length = 4599
examples, labels = input_pipeline(file_length, 1)
examples_batch=tf.global_variables()
labels_batch=tf.global_variables()
examples_batch_test=tf.global_variables()
labels_batch_test=tf.global_variables()
x = tf.placeholder(""float"", [None, 57])
y = tf.placeholder(""float"", [None, 1])

pred = multilayer_perceptron(x, weights, biases)
cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(pred, y))
optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)
config=tf.ConfigProto(inter_op_parallelism_threads=2)
with tf.Session(config=config) as sess:
  init_op = tf.group(tf.initialize_all_variables(),tf.initialize_local_variables())
  sess.run(init_op)
  #tf.initialize_all_variables().run()

  # start populating filename queue
  coord = tf.train.Coordinator()
  threads = tf.train.start_queue_runners(coord=coord)

  try:
    while not coord.should_stop():
      examples_batch, labels_batch = sess.run([examples, labels])
    #x, y = sess.run([examples, labels])
     
  except tf.errors.OutOfRangeError:
    print('Done training, epoch reached')
    #print(examples_batch)
    #print(labels_batch)

    # Training cycle
    for epoch in range(training_epochs):
        avg_cost = 0.0
        total_batch = 1
        # Loop over all batches
        for i in range(total_batch):
            # Run optimization op (backprop) and cost op (to get loss value)
            _, c = sess.run([optimizer, cost], feed_dict={x: examples_batch,
                                                          y: labels_batch})
            print(""c"")
            print(c)
            #c = {x: batch_x,y: batch_y}
            # Compute average loss
            #print(c / total_batch)
            avg_cost = c / total_batch
        # Display logs per epoch step
        if epoch % display_step == 0:
            print(""Epoch:"", '%04d' % (epoch+1), ""cost="", \
                ""{:.9f}"".format(avg_cost))
    print(""Optimization Finished!"")
    print(""TEST BLOCK!"")
    try:
        file_length_test=1379
        examples_test, labels_test = input_pipeline_test(file_length_test, 1)
        print(""file print"")
        print(sess.run(labels_test))
        print(""file print end"")
    except:
        print(""tftftftftfttftftftft"")
        
    coord.request_stop()


# with tf.Session() as sess_test:
  # init_op = tf.group(tf.initialize_all_variables(),tf.initialize_local_variables())
  # sess_test.run(init_op)
  # #tf.initialize_all_variables().run()

  # # start populating filename queue
  # coord = tf.train.Coordinator()
  # threads = tf.train.start_queue_runners(coord=coord)

  # print(""TEST BLOCK!"")
  # file_length_test=1379
  # examples_test, labels_test = input_pipeline_test(file_length_test, 1)
  # print(examples_test)
 # # start populating filename queue
  # coord = tf.train.Coordinator()
  # threads = tf.train.start_queue_runners(coord=coord)
  # #with tf.Session() as sess_test:
  # try:
       # while not coord.should_stop():
           # examples_batch_test, labels_batch_test = sess_test.run([examples_test, labels_test])
           # #x, y = sess_test.run([examples, labels])
        
  # except tf.errors.OutOfRangeError:
       # # Test model
       # correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))
       # # Calculate accuracy
       # accuracy = tf.reduce_mean(tf.cast(correct_prediction, ""float""))
       # print(""helooOOOOO"")
       # print(""Accuracy:"", accuracy.eval({x: examples_batch_test, y: labels_test}))
    
    
    
  # coord.request_stop()

coord.join(threads) 

#######################################################################################################################################

```

C:\Users\ABC\Desktop\DemoTensarflow>cmd
Microsoft Windows [Version 6.1.7601]
Copyright (c) 2009 Microsoft Corporation.  All rights reserved.

C:\Users\ABC\Desktop\DemoTensarflow>python ReadTF_mod.py train.csv
WARNING:tensorflow:From ReadTF_mod.py:124 in <module>.: initialize_all_variables
 (from tensorflow.python.ops.variables) is deprecated and will be removed after
2017-03-02.
Instructions for updating:
Use `tf.global_variables_initializer` instead.
WARNING:tensorflow:From ReadTF_mod.py:124 in <module>.: initialize_local_variabl
es (from tensorflow.python.ops.variables) is deprecated and will be removed afte
r 2017-03-02.
Instructions for updating:
Use `tf.local_variables_initializer` instead.
Done training, epoch reached
c
0.0
Epoch: 0001 cost= 0.000000000
Optimization Finished!
TEST BLOCK!
filename_queue_test
filename_queue_test end
Tensor(""shuffle_batch_1:0"", shape=(1379, 57), dtype=float32)
file print
^C

the program gets stuck







"
6497,OpenCL isn't working,"TF is configured with OpenCL
```
$ ./configure 
/media/Compressed/Drivers_bios/src/dev/tensorflow /media/Compressed/Drivers_bios/src/dev/tensorflow
Please specify the location of python. [Default is /usr/bin/python]: /usr/bin/python3
Do you wish to build TensorFlow with Google Cloud Platform support? [y/N] 
No Google Cloud Platform support will be enabled for TensorFlow
Do you wish to build TensorFlow with Hadoop File System support? [y/N] 
No Hadoop File System support will be enabled for TensorFlow
Found possible Python library paths:
  /usr/lib/python3/dist-packages
  /usr/local/lib/python3.5/dist-packages
Please input the desired Python library path to use.  Default is [/usr/lib/python3/dist-packages]
/usr/local/lib/python3.5/dist-packages
Do you wish to build TensorFlow with OpenCL support? [y/N] y
OpenCL support will be enabled for TensorFlow
Do you wish to build TensorFlow with CUDA support? [y/N] N
No CUDA support will be enabled for TensorFlow
Please specify which C++ compiler should be used as the host C++ compiler. [Default is ]: /usr/bin/g++
Please specify which C compiler should be used as the host C compiler. [Default is ]: /usr/bin/gcc
Please specify the location where ComputeCpp for SYCL 1.2 is installed. [Default is /usr/local/computecpp]:
```

ComputeCpp is also present
```
$ ls /usr/local/computecpp/*   
/usr/local/computecpp/bin:
compute++  computecpp_info

/usr/local/computecpp/doc:
LICENSE.text  computecpp_error_codes.pdf      computecpp_glossary.pdf  computecpp_man.pdf                     computecpp_release_notes.pdf
api_pages     computecpp_getting_started.pdf  computecpp_info_man.pdf  computecpp_platform_support_notes.pdf  computecpp_stream_class.pdf

/usr/local/computecpp/include:
CL  SYCL

/usr/local/computecpp/lib:
clang  libComputeCpp.so
```

I also has OpenCL
```
$ clinfo |grep -i version
  Platform Version:				 OpenCL 2.0 AMD-APP (1912.5)
  Device OpenCL C version:			 OpenCL C 1.2 
  Driver version:				 1912.5 (VM)
  Version:					 OpenCL 1.2 AMD-APP (1912.5)
  Device OpenCL C version:			 OpenCL C 1.2 
  Driver version:				 1912.5 (sse2,avx,fma4)
  Version:					 OpenCL 1.2 AMD-APP (1912.5)
```

But it seems that TF don't see any OpenCL device in my system.
```python
>>> from tensorflow.python.client import device_lib
>>> [x.name for x in device_lib.list_local_devices()]
['/cpu:0']
```"
6496,tensorflow + opencv webcam hangs,"### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?
Yes posted on stackoverflow but no help and believe this is an issue to report: http://stackoverflow.com/questions/41276085/tensorflow-opencv-webcam-hangs

### Environment info
Operating System: Environment: MAC machine, running my code inside virtual machine with guest OS: Ubuntu 14.4 LTS.

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)
I am compiling openCV within tensorflow workspace under examples. My WORKSPACE and opencv.BUILD file look similar to the one mentioned [here](http://stackoverflow.com/questions/34984290/building-opencv-code-using-bazel) 

My BUILD file for the opencv + tensorflow project looks like following:

```
package(default_visibility = [""//tensorflow:internal""])

licenses([""notice""])  # Apache 2.0

exports_files([""LICENSE""])

cc_binary(
    name = ""label_image"",
    srcs = [
        ""main.cc"",
    ],
    linkopts = [""-lm""],
    copts = [""-DWITH_FFMPEG=OFF""],
    deps = [
        ""//tensorflow/cc:cc_ops"",
        ""//tensorflow/core:framework_internal"",
        ""//tensorflow/core:tensorflow"",
        ""@opencv//:opencv""
    ],
)

filegroup(
    name = ""all_files"",
    srcs = glob(
        [""**/*""],
        exclude = [
            ""**/METADATA"",
            ""**/OWNERS"",
            ""bin/**"",
            ""gen/**"",
        ],
    ),
    visibility = [""//tensorflow:__subpackages__""],
)
```

If i disable tensorflow dependences (and also comment the tensorflow related code). I can see that the webcam is captures properly. like this:

```
deps = [
            #""//tensorflow/cc:cc_ops"",
            #""//tensorflow/core:framework_internal"",
            #""//tensorflow/core:tensorflow"",
            ""@opencv//:opencv""
        ],
```

But if i still keep the code commented/uncommented and also keep the tensorflow dependences my webcam hangs at VideoCapture::read()

By default, opencv use FFMPEG codec and i tried enabling and disabling FFMPEG. Can someone please help me why when tensorflow library is compiled in the project makes my openCV read() hangs?

### What other attempted solutions have you tried?
Later, i tried having OpenCV code in c++ and tensorflow in python and integrate them using [embedded python](https://docs.python.org/3.4/extending/embedding.html). This is working fine. 


### Logs or other output that would be helpful
Attached inline. "
6495,Docker doesn't support GPU for mac OS (doc clarification request),"The docs present instructions for installing via Docker on MacOS. GPU support isn't mentioned explicitly, but it seems that GPU (nvidia-docker) can't be supported for MacOS. See here:
https://github.com/NVIDIA/nvidia-docker/issues/175

If I'm right that GPU is a no-go for Docker on Mac OS, I'd like to see this up-front in the documentation (e.g., write ""GPU support not possible on MacOS X in Docker"") to prevent people from going down the wrong path.




NOTE: Only file GitHub issues for bugs and feature requests.  All other topics will be closed.

For general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).
To make bugs and feature requests more easy to find and organize, we close issues that are deemed
out of scope for GitHub Issues and point people to StackOverflow.

For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.

### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?

### Environment info
Operating System:

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

If installed from binary pip package, provide:

1. A link to the pip package you installed:
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.

If installed from source, provide 

1. The commit hash (`git rev-parse HEAD`)
2. The output of `bazel version`

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)


### What other attempted solutions have you tried?


### Logs or other output that would be helpful
(If logs are large, please upload as attachment or provide link).
"
6493,"The ""training/saver"" is raising an exception  when saving data to the regional Google Cloud bucket","The current version of the TensorFlow that is used with Google Cloud ML (my guessing is TF 0.12) is not working when I'm using the regional bucket as a training source. Detailed step by step reproducing tutorial can be found here: https://blog.kovalevskyi.com/how-to-train-a-chatbot-with-the-tensorflow-and-google-cloud-ml-3a5617289032#.dq3xzjm3h  in order to reproduce the issue you just need to create a regional bucket, instead of the multi-regional. Also, everything works well with the multi-regional bucket.

Logs from the Google Cloud ML:

Creating 3 layers of 1024 units.
Created model with fresh parameters.
Reading development and training data (limit: 0).
  reading data line 100000
Unavailable: Unexpected response code 410
         when resuming upload gs://chatbot_generic/chatbot_generic_20161224_211637/translate.ckpt-1.data-00000-of-00001
Traceback (most recent call last):
  File ""/usr/lib/python2.7/runpy.py"", line 162, in _run_module_as_main
    ""__main__"", fname, loader, pkg_name)
  File ""/usr/lib/python2.7/runpy.py"", line 72, in _run_code
    exec code in run_globals
  File ""/root/.local/lib/python2.7/site-packages/translate/translate.py"", line 326, in <module>
    tf.app.run()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 43, in run
    sys.exit(main(sys.argv[:1] + flags_passthrough))
  File ""/root/.local/lib/python2.7/site-packages/translate/translate.py"", line 323, in main
    train()
  File ""/root/.local/lib/python2.7/site-packages/translate/translate.py"", line 229, in train
    model.saver.save(sess, checkpoint_path, global_step=model.global_step)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1323, in save
    {self.saver_def.filename_tensor_name: checkpoint_file})
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 766, in run
    run_metadata_ptr)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 964, in _run
    feed_dict_string, options, run_metadata)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1014, in _do_run
    target_list, options, run_metadata)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1034, in _do_call
    raise type(e)(node_def, op, message)
UnavailableError: Unexpected response code 410
         when resuming upload gs://chatbot_generic/chatbot_generic_20161224_211637/translate.ckpt-1.data-00000-of-00001
         [[Node: save/SaveV2 = SaveV2[dtypes=[DT_FLOAT, DT_INT32, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=""/job:localhost/replica:0/task:0/cpu:0""](_recv_save/Const_0, save/SaveV2/tensor_names, save/SaveV2/shape_and_slices, Variable, Variable_1, embedding_attention_seq2seq/RNN/EmbeddingWrapper/embedding, embedding_attention_seq2seq/RNN/MultiRNNCell/Cell0/GRUCell/Candidate/Linear/Bias, embedding_attention_seq2seq/RNN/MultiRNNCell/Cell0/GRUCell/Candidate/Linear/Matrix, embedding_attention_seq2seq/RNN/MultiRNNCell/Cell0/GRUCell/Gates/Linear/Bias, embedding_attention_seq2seq/RNN/MultiRNNCell/Cell0/GRUCell/Gates/Linear/Matrix, embedding_attention_seq2seq/RNN/MultiRNNCell/Cell1/GRUCell/Candidate/Linear/Bias, embedding_attention_seq2seq/RNN/MultiRNNCell/Cell1/GRUCell/Candidate/Linear/Matrix, embedding_attention_seq2seq/RNN/MultiRNNCell/Cell1/GRUCell/Gates/Linear/Bias, embedding_attention_seq2seq/RNN/MultiRNNCell/Cell1/GRUCell/Gates/Linear/Matrix, embedding_attention_seq2seq/RNN/MultiRNNCell/Cell2/GRUCell/Candidate/Linear/Bias, embedding_attention_seq2seq/RNN/MultiRNNCell/Cell2/GRUCell/Candidate/Linear/Matrix, embedding_attention_seq2seq/RNN/MultiRNNCell/Cell2/GRUCell/Gates/Linear/Bias, embedding_attention_seq2seq/RNN/MultiRNNCell/Cell2/GRUCell/Gates/Linear/Matrix, embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Linear/Bias, embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Linear/Matrix, embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/Linear/Bias, embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/Linear/Matrix, embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnV_0, embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnW_0, embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Linear/Bias, embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Linear/Matrix, embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MultiRNNCell/Cell0/GRUCell/Candidate/Linear/Bias, embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MultiRNNCell/Cell0/GRUCell/Candidate/Linear/Matrix, embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MultiRNNCell/Cell0/GRUCell/Gates/Linear/Bias, embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MultiRNNCell/Cell0/GRUCell/Gates/Linear/Matrix, embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MultiRNNCell/Cell1/GRUCell/Candidate/Linear/Bias, embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MultiRNNCell/Cell1/GRUCell/Candidate/Linear/Matrix, embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MultiRNNCell/Cell1/GRUCell/Gates/Linear/Bias, embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MultiRNNCell/Cell1/GRUCell/Gates/Linear/Matrix, embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MultiRNNCell/Cell2/GRUCell/Candidate/Linear/Bias, embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MultiRNNCell/Cell2/GRUCell/Candidate/Linear/Matrix, embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MultiRNNCell/Cell2/GRUCell/Gates/Linear/Bias, embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MultiRNNCell/Cell2/GRUCell/Gates/Linear/Matrix, embedding_attention_seq2seq/embedding_attention_decoder/embedding, proj_b, proj_w)]]
-24 21:28:34 -0800       master-replica-0                Caused by op u'save/SaveV2', defined at:
  File ""/usr/lib/python2.7/runpy.py"", line 162, in _run_module_as_main
    ""__main__"", fname, loader, pkg_name)
  File ""/usr/lib/python2.7/runpy.py"", line 72, in _run_code
    exec code in run_globals
  File ""/root/.local/lib/python2.7/site-packages/translate/translate.py"", line 326, in <module>
    tf.app.run()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 43, in run
    sys.exit(main(sys.argv[:1] + flags_passthrough))
  File ""/root/.local/lib/python2.7/site-packages/translate/translate.py"", line 323, in main
    train()
  File ""/root/.local/lib/python2.7/site-packages/translate/translate.py"", line 179, in train
    model = create_model(sess, False)
  File ""/root/.local/lib/python2.7/site-packages/translate/translate.py"", line 136, in create_model
    dtype=dtype)
  File ""/root/.local/lib/python2.7/site-packages/translate/seq2seq_model.py"", line 189, in __init__
    self.saver = tf.train.Saver(tf.global_variables())
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1000, in __init__
    self.build()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1030, in build
    restore_sequentially=self._restore_sequentially)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 622, in build
    save_tensor = self._AddSaveOps(filename_tensor, saveables)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 229, in _AddSaveOps
    save = self.save_op(filename_tensor, saveables)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 172, in save_op
    tensors)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_io_ops.py"", line 550, in save_v2
    tensors=tensors, name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py"", line 759, in apply_op
    op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 2238, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 1130, in __init__
    self._traceback = _extract_stack()
-24 21:28:34 -0800       master-replica-0                UnavailableError (see above for traceback): Unexpected response code 410
         when resuming upload gs://chatbot_generic/chatbot_generic_20161224_211637/translate.ckpt-1.data-00000-of-00001
         [[Node: save/SaveV2 = SaveV2[dtypes=[DT_FLOAT, DT_INT32, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=""/job:localhost/replica:0/task:0/cpu:0""](_recv_save/Const_0, save/SaveV2/tensor_names, save/SaveV2/shape_and_slices, Variable, Variable_1, embedding_attention_seq2seq/RNN/EmbeddingWrapper/embedding, embedding_attention_seq2seq/RNN/MultiRNNCell/Cell0/GRUCell/Candidate/Linear/Bias, embedding_attention_seq2seq/RNN/MultiRNNCell/Cell0/GRUCell/Candidate/Linear/Matrix, embedding_attention_seq2seq/RNN/MultiRNNCell/Cell0/GRUCell/Gates/Linear/Bias, embedding_attention_seq2seq/RNN/MultiRNNCell/Cell0/GRUCell/Gates/Linear/Matrix, embedding_attention_seq2seq/RNN/MultiRNNCell/Cell1/GRUCell/Candidate/Linear/Bias, embedding_attention_seq2seq/RNN/MultiRNNCell/Cell1/GRUCell/Candidate/Linear/Matrix, embedding_attention_seq2seq/RNN/MultiRNNCell/Cell1/GRUCell/Gates/Linear/Bias, embedding_attention_seq2seq/RNN/MultiRNNCell/Cell1/GRUCell/Gates/Linear/Matrix, embedding_attention_seq2seq/RNN/MultiRNNCell/Cell2/GRUCell/Candidate/Linear/Bias, embedding_attention_seq2seq/RNN/MultiRNNCell/Cell2/GRUCell/Candidate/Linear/Matrix, embedding_attention_seq2seq/RNN/MultiRNNCell/Cell2/GRUCell/Gates/Linear/Bias, embedding_attention_seq2seq/RNN/MultiRNNCell/Cell2/GRUCell/Gates/Linear/Matrix, embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Linear/Bias, embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Attention_0/Linear/Matrix, embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/Linear/Bias, embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnOutputProjection/Linear/Matrix, embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnV_0, embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/AttnW_0, embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Linear/Bias, embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/Linear/Matrix, embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MultiRNNCell/Cell0/GRUCell/Candidate/Linear/Bias, embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MultiRNNCell/Cell0/GRUCell/Candidate/Linear/Matrix, embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MultiRNNCell/Cell0/GRUCell/Gates/Linear/Bias, embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MultiRNNCell/Cell0/GRUCell/Gates/Linear/Matrix, embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MultiRNNCell/Cell1/GRUCell/Candidate/Linear/Bias, embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MultiRNNCell/Cell1/GRUCell/Candidate/Linear/Matrix, embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MultiRNNCell/Cell1/GRUCell/Gates/Linear/Bias, embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MultiRNNCell/Cell1/GRUCell/Gates/Linear/Matrix, embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MultiRNNCell/Cell2/GRUCell/Candidate/Linear/Bias, embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MultiRNNCell/Cell2/GRUCell/Candidate/Linear/Matrix, embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MultiRNNCell/Cell2/GRUCell/Gates/Linear/Bias, embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MultiRNNCell/Cell2/GRUCell/Gates/Linear/Matrix, embedding_attention_seq2seq/embedding_attention_decoder/embedding, proj_b, proj_w)]]
-24 21:28:37 -0800       master-replica-0                global step 1 learning rate 0.5000 step-time 22.35 perplexity 39893.68
Module raised an exception Command '['python', '-m', u'translate.translate', u'--from_train_data=gs://chatbot_genBias, embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MultiRNNCell/Cell1/GRUCell/Candidate/Linear/Matrix, embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MultiRNNCell/Cell1/GRUCell/Gates/Linear/Bias, embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MultiRNNCell/Cell1/GRUCell/Gates/Linear/Matrix, embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MultiRNNCell/Cell2/GRUCell/Candidate/Linear/Bias, embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MultiRNNCell/Cell2/GRUCell/Candidate/Linear/Matrix, embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MultiRNNCell/Cell2/GRUCell/Gates/Linear/Bias, embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/MultiRNNCell/Cell2/GRUCell/Gates/Linear/Matrix, embedding_attention_seq2seq/embedding_attention_decoder/embedding, proj_b, proj_w)]]
-24 21:28:37 -0800       master-replica-0                global step 1 learning rate 0.5000 step-time 22.35 perplexity 39893.68
Module raised an exception Command '['python', '-m', u'translate.translate', u'--from_train_data=gs://chatbot_generic/input/train.a', u'--to_train_data=gs://chatbot_generic/input/train.b', u'--from_dev_data=gs://chatbot_generic/input/test.a', u'--to_dev_data=gs://chatbot_generic/input/test.b', u'--train_dir=gs://chatbot_generic/chatbot_generic_20161224_211637', u'--steps_per_checkpoint=1', u'--from_vocab_size=45000', u'--to_vocab_size=45000']' returned non-zero exit status 1."
6492,Error performing lstm using BasicLSTMCell in v0.12.0,"Hey Guys, I have v0.12.0 installed on my system and I'm facing some issue while running a simple LSTM. While trying to get it to work I have even reduced my code to the examples at https://www.tensorflow.org/tutorials/recurrent/, but still facing the same issue. I'm attaching snippets from my code and the error log. The ""lstm"" function takes input from a convolving function that produces latent representations (size: 1024) of a sequence of 40 frames.

```python
frames_batch_size = 40
batch_size = 20

def lstm(x, state_size=1024, initial_state=None, reuse=False):
    with tf.variable_scope(""lstm"") as lstm_scope:
        if reuse:
            tf.get_variable_scope().reuse_variables()
        
        lstm_cell = tf.nn.rnn_cell.BasicLSTMCell(state_size)
        state = initial_state if initial_state else tf.zeros([batch_size, state_size], name=""lstm_state"")
        
        print(x.name, ""-"", x.get_shape())
        print(state.name, ""-"", state.get_shape())

        for i in range(frames_batch_size):
            output, state = lstm_cell(x[:, i], state)
            
        print(output.name, output.get_shape())
    return output
```

The shapes of tensors as per output are:
```
generator/convolution/conv_output:0 - (20, 40, 1024)
generator/lstm/lstm_state:0 - (20, 1024)
```

And the snippet of the error log is:
```
<ipython-input-13-35b652ff4acc> in lstm(x, state_size, initial_state, reuse)
     10 
     11         for i in range(frames_batch_size):
---> 12             output, state = lstm_cell(x[:, i], state)
     13 
     14         print(output.name, output.get_shape())

/usr/local/lib/python3.5/site-packages/tensorflow/python/ops/rnn_cell.py in __call__(self, inputs, state, scope)
    306       # Parameters of gates are concatenated into one multiply for efficiency.
    307       if self._state_is_tuple:
--> 308         c, h = state
    309       else:
    310         c, h = array_ops.split(1, 2, state)

/usr/local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py in __iter__(self)
    508       TypeError: when invoked.
    509     """"""
--> 510     raise TypeError(""'Tensor' object is not iterable."")
    511 
    512   def __bool__(self):

TypeError: 'Tensor' object is not iterable.
```"
6490,Weird concat_v2 behavior with negative axis,"This:
```python
rudolph = tf.zeros((5, 2))
prancer = tf.zeros((5, 2))
comet = tf.concat_v2([rudolph, prancer], axis=-1)

print('Tensor shape: {}'.format(comet.get_shape()))
print('Evaluated shape: {}'.format(comet.eval().shape))
```

Produces:

```
Tensor shape: (5, 4, 5, 2)
Evaluated shape: (5, 4)
```

Tested on tensorflow version `0.12.0`"
6489,Error when trying to run lstm example of ptb,"I was stuck at here when trying to run ptb_word_lm under ubuntu 16 and tensorflow master branch. Any advice would be very much appreciated.  

The exception said:
Epoch: 1 Learning rate: 1.000
Traceback (most recent call last):
  File ""/home/****/.local/lib/python3.5/site-packages/tensorflow/python/training/supervisor.py"", line 964, in managed_session
    yield sess
  File ""ptb_word_lm.py"", line 357, in main
    verbose=True)
  File ""ptb_word_lm.py"", line 298, in run_epoch
    return np.exp(costs / iters)
ZeroDivisionError: float division by zero
"
6487,Errors when trying to build label_image neural net with bazel,"### Environment info
Operating System: El Capitan, 10.11.1

I'm doing this tutorial: https://petewarden.com/2016/09/27/tensorflow-for-mobile-poets/ 
Trying to classify images using tensorflow on iOS app.
When I try to build my net using bazel:
`bazel build tensorflow/examples/label_image:label_image
`

I get these errors:
https://gist.github.com/galharth/36b8f6eeb12f847ab120b2642083a732"
6486,Windows: cannot compile using cmake 3.7.1 generator,"Hello

If I use cmake 3.7.1 generator, I cannot compile tensorflow on Windows with Visual Studio
I get the following error message during tf_core_gpu_kernels project:

`nvcc fatal   : Stray '""' character
30>
30>  CMake Error at tf_core_gpu_kernels_generated_adjust_contrast_op_gpu.cu.cc.obj.Release.cmake:222 (message):
30>    Error generating
30>    C:/libs/tensorflow/tensorflow/contrib/cmake/build/CMakeFiles/tf_core_gpu_kernels.dir/__/__/core/kernels/Release/tf_core_gpu_kernels_generated_adjust_contrast_op_gpu.cu.cc.obj`

If I try to regenerate project using cmake 3.6.3, everything compiles just fine

I was trying to modify CMakeLists.txt, but still no luck

Additional info:
Windows 10
Visual Studio 2015
GPU is enabled, CUDA 8.0
"
6484,"Some of tensorflow GPU OpKernel compute by eigen device without stream sync, is that correct?","from gpu_device.cc

```
   // NOTE(tucker): We need to discriminate between Eigen GPU
   // operations and all others.  If an operation is Eigen
   // implemented (or otherwise tries to launch a cuda kernel
   // directly), we need to establish a stacked-scoped environment
   // that directs it to execute on the proper device.  Otherwise we
   // expect the Op to use StreamExecutor directly and correctly.  The
   // way we make this discrimination is quite hacky: At the moment
   // the only non-Eigen GPU Op is the recv-op, which is known to be
   // asynchronous.
```

and gpu_device only waits when there are different contexts. (sync_every_op is false)

But take argmax_op.h  for example,


    template <typename Device, typename T>
    struct ArgMin {
    #define DECLARE_COMPUTE_SPEC(Dims)                                     \
    EIGEN_ALWAYS_INLINE static void Reduce##Dims(                        \
    const Device& d, typename TTypes<T, Dims>::ConstTensor input,    \
    const int32 dimension,                                           \
    typename TTypes<int64, Dims - 1>::Tensor output) {               \
    output.device(d) = input.argmin(dimension).template cast<int64>(); \
    }

use device compute directly. Is that correct? Or I miss something ... 
Thank you very much!
"
6483,Please update seq2seq tutorial on the Tensorflow website,"It seems like the seq2seq.py library has been deprecated, and it would be nice to know where the new code, and if the tutorial could point to it. "
6479,Bash argument completion for tensorboard,"It be nice to have autocompletion for the tensorboard arguments.
I experimented a bit https://github.com/Garoe/tensorflow/commit/3c217767cd47560c776232207a05b08b6f2cb166 with the [argcomplete](https://argcomplete.readthedocs.io/en/latest/), however the completion is too sluggish to be useful.
The entry point for the completion is after the flags are defined and the slugginesh is due to too much stuff being done before that.
Another option would be to use [native completion](https://github.com/scop/bash-completion), but that would require to duplicate the flag definitions for tensorboard."
6478,t.eval() built with slim outputs wrong predictions when input batch contains identical images,"When evaluating a model built with slim on a batch that contains identical images, the output of the batch will be wrong (mostly the outputs will be the most frequent label). For example, if my evaluation set has 421 images and my batch size is 40, I filled the last batch with 19 identical images (the 421st one) to avoid tensor shape mismatch error. Then,  the output for the 21st to the 40th image of the last batch will be the most common label in training set. If I replace the 19 images with some randomly selected images, the outputs will be correct.

### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?

None.

### Environment info
Operating System: Ubuntu 14.04.5

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):
![image](https://cloud.githubusercontent.com/assets/3335135/21456479/56b99382-c8f6-11e6-88ee-1b83758fb56a.png)

If installed from binary pip package, provide:

1. A link to the pip package you installed:
https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.11.0-cp27-none-linux_x86_64.whl

2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.

I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcurand.so locally
0.11.0

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)
The problem can be reproduced with any model built purely with slim but evaluated with output.eval(feed_dict={batch_image:test_batch}) or sess.run(output, feed_dict={batch_image:test_batch})
when the test batch contains several identical images. 

### What other attempted solutions have you tried?
Avoid identical or similar images in evaluation batch.

### Logs or other output that would be helpful
(If logs are large, please upload as attachment or provide link).
"
6477,"Sub Matrices, Partitioned Matrices and composite matrices through view on undeling data","There are times you want to address portions of a vector or matrix separately and also combine matrices and vectors to form new matrices. Essentially these matrices would be  view on the original data.

E.g.

Concatenate 2 matrices to create a view
Sub current matrix into smaller n * n matrices returning view on the sub matrices"
6476,"Data Structures for Time Series, Vectorized Time Series and real time data processing",There are times you want a tensor to be circular along a dimension so new data can be efficiently and quickly appended along this dimension.
6475,Training with local variables is very slow in distributed tf,"I used local variables on worker tasks in a distributed RNN training. Every update go through 3 steps: 1) assign local variables on each worker with PS variables 2) training local variables in several loops/batches, and accumulate the gradients from each loop 3) apply the accumulated gradients to the PS variables. The first and second step is very slow: for step 1, it takes about 12 seconds; for step 2, every loop takes about 6 seconds. If I combine the three steps together (not use local variable and go through one batch data every update), it only takes about 0.7 second. So, I suspect that it is due to the bad performance of local variables. 

### Environment info
Ubuntu 14.04, CUDA 8.0, tensorflow 0.12.0-rc1"
6474,Change draw_bounding_box() label input to allow different number of inter-batch boxes.,"This is a question or feature request regarding the following function
`tf.image.draw_bounding_boxes(images, boxes, name=None)`
### Current
The required bounding-box format is as follows:
`[batch, num_bounding_boxes, 4]`, in which the labels are in `[y_min, x_min, y_max, x_max]` format.
If i understand correctly, this assumes that every image has the same number of bounding boxes.
### Suggestion
Doesn't it make a lot more sense to change the input format to the following:
`[num_labels, 5]` in the following format `[id, y_min, x_min, y_max, x_max]` where id corresponds to the image in the batch."
6473,Errors_impl - NotFoundError - stringpiece,"### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?

None.

### Environment info
Operating System: Ubuntu 16.04.1 LTS

Installed version of CUDA and cuDNN: None

Binary pip package info:

1. A link to the pip package you installed: https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.12.0rc0-cp35-cp35m-linux_x86_64.whl
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`: 0.12.0

**The error comes from the binary packages indicated above.** I had no problems with the package builded from source.

Source info:

1. The commit hash (`git rev-parse HEAD`): 48fb73a1c94ee2409382225428063d3496dc651e
2. The output of `bazel version`: 
```
Build label: 0.4.1
Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Wed Nov 30 09:13:36 2016 (1480497216)
Build timestamp: 1480497216
Build timestamp as int: 1480497216
```

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)

I guess seeing the problem is that I use inside a new Op some functions from this part of the core: 

```
#include ""tensorflow/core/lib/core/stringpiece.h""
```


### What other attempted solutions have you tried?

This thing is strange because as I said with the package created from the source code I have no error during the execution of the script, but with the binary package provided from the official website I had the runtime error below.


### Logs or other output that would be helpful

```tensorflow.python.framework.errors_impl.NotFoundError: /.../newop.so: undefined symbol: _ZN10tensorflow9LogMemory21RecordRawDeallocationERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEExPvPNS_9AllocatorEb```

"
6472,Timeout does not work with session created with server,"### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem? None

### Environment info
Operating System: Ubuntu

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`): CPU only

If installed from source, provide 

1. The commit hash (`git rev-parse HEAD`)  

c32663d119a4cbd9d4926d4eed2a0705f03a57f9

2. The output of `bazel version` 

Extracting Bazel installation...
Build label: 0.4.3
Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Thu Dec 22 12:31:25 2016 (1482409885)
Build timestamp: 1482409885
Build timestamp as int: 1482409885

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)

```python
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

from datetime import datetime
import os.path
import time

import numpy as np
import random
import tensorflow as tf

import signal
import sys
import os

from tensorflow.python.framework import ops
from tensorflow.python.ops import variables
from tensorflow.python.ops import state_ops
from tensorflow.python.ops import logging_ops
from tensorflow.python.client import timeline

from tensorflow.python.ops import data_flow_ops

# (python test 1 worker > /tmp/output 2>&1 &) && (python test 0 ps > /tmp/output2 2>&1 &) && python test 0 worker

try:

    index, job = int(sys.argv[1]), sys.argv[2]


    ps_hosts = 'localhost:1234'
    worker_hosts = 'localhost:1235,localhost:1236'
    ps_hosts = ps_hosts.split("","")
    worker_hosts = worker_hosts.split("","")

    cluster_spec = tf.train.ClusterSpec({'ps' : ps_hosts, 'worker' : worker_hosts})
    server = tf.train.Server(
	{'ps': ps_hosts,
         'worker': worker_hosts},
	job_name=job,
	task_index=index)

    a = data_flow_ops.FIFOQueue(-1, tf.float32)
    b = a.dequeue()
    sv = tf.train.Supervisor(is_chief=True, logdir='./test_logdir')
    cfg = tf.ConfigProto(
	allow_soft_placement=True,
	log_device_placement=False)
    sess = sv.prepare_or_wait_for_session(server.target, config=cfg)
    print(""Testing timeout"")
    opt = tf.RunOptions(timeout_in_ms=50)
    sess.run(b, options=opt)
except tf.errors.DeadlineExceededError:
    print(""Successfully timed out!"")
```

Above I create a cluster and get a session from the server. I then try to dequeue an empty FIFOQueue with a timeout of 1 second. For some reason, on the latest commits of the tensorflow source, this does not successfully time out. This bug does not happen for the released versions of tensorflow (.11, .12).

To run:
`(python script.py 1 worker > /tmp/output 2>&1 &) && (python script.py 0 ps > /tmp/output2 2>&1 &) && python script.py 0 worker`

where script.py is the above example."
6471,how to custom learning rate decay policy ?,"as it shown in the learning rate deay **[API doc](https://www.tensorflow.org/api_docs/python/train/decaying_the_learning_rate)** , there are only 4 kinds of policies. but in caffe  policies are as follows:  
 
1.   //    - fixed: always return base_lr.  
2.   //    - step: return base_lr * gamma ^ (floor(iter / step))  
3.   //    - exp: return base_lr * gamma ^ iter  
4.   //    - inv: return base_lr * (1 + gamma * iter) ^ (- power)  
5.   //    - multistep: similar to step but it allows non uniform steps defined by  
6.   //      stepvalue  
7.   //    - poly: the effective learning rate follows a polynomial decay, to be  
8.   //      zero by the max_iter. return base_lr (1 - iter/max_iter) ^ (power)  
9.   //    - sigmoid: the effective learning rate follows a sigmod decay  

in issue #2922 they mentioNed on write a warpper for the existing method, but they did not implemented anything new ?  for example the **inv** `[base_lr * (1 + gamma * iter) ^ (- power)]` policy in caffe.

so I wonder if there anyone who can help me out how to custom learning rate decay policy by myself, any suggestions will be sincerely gratitude. 

"
6470,how to use two optimizer in one model,"I want to build a model that can use different optimizers to train different parts, just like the tf.contrib.learn.DNNLinearCombinedClassifier(), what should I do?
thanks
"
6469,"ptb_rnn_lm.py error:tensorflow.python.framework.errors.InvalidArgumentError: logits and labels must have the same first dimension, got logits shape [400,10000] and labels shape [420] ","Getting the error:
tensorflow.python.framework.errors.InvalidArgumentError: logits and labels must have the same first dimension, got logits shape [400,10000] and labels shape [420]

The code is available here:
[http://pastebin.com/FM6M43w7](http://pastebin.com/FM6M43w7)

I am giving the full error log here:

Traceback (most recent call last):
  File ""ptb_word_lm.py"", line 364, in <module>
    tf.app.run()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 30, in run
    sys.exit(main(sys.argv[:1] + flags_passthrough))
  File ""ptb_word_lm.py"", line 350, in main
    verbose=True)
  File ""ptb_word_lm.py"", line 279, in run_epoch
    vals = session.run(fetches, feed_dict)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 717, in run
    run_metadata_ptr)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 915, in _run
    feed_dict_string, options, run_metadata)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 965, in _do_run
    target_list, options, run_metadata)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 985, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors.InvalidArgumentError: logits and labels must have the same first dimension, got logits shape [400,10000] and labels shape [420]
	 [[Node: Train/Model/sequence_loss_by_example/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits = SparseSoftmaxCrossEntropyWithLogits[T=DT_FLOAT, Tlabels=DT_INT32, _device=""/job:localhost/replica:0/task:0/gpu:0""](Train/Model/add, Train/Model/sequence_loss_by_example/Reshape/_129)]]
	 [[Node: Train/Model/truediv/_153 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device_incarnation=1, tensor_name=""edge_1023_Train/Model/truediv"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]

Caused by op u'Train/Model/sequence_loss_by_example/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits', defined at:
  File ""ptb_word_lm.py"", line 364, in <module>
    tf.app.run()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 30, in run
    sys.exit(main(sys.argv[:1] + flags_passthrough))
  File ""ptb_word_lm.py"", line 326, in main
    m = PTBModel(is_training=True, config=config, input_=train_input)
  File ""ptb_word_lm.py"", line 147, in __init__
    [tf.ones([batch_size * num_steps], dtype=data_type())])
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/seq2seq.py"", line 1017, in sequence_loss_by_example
    logit, target)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/nn_ops.py"", line 764, in sparse_softmax_cross_entropy_with_logits
    precise_logits, labels, name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_nn_ops.py"", line 1857, in _sparse_softmax_cross_entropy_with_logits
    features=features, labels=labels, name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py"", line 749, in apply_op
    op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 2380, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 1298, in __init__
    self._traceback = _extract_stack()

InvalidArgumentError (see above for traceback): logits and labels must have the same first dimension, got logits shape [400,10000] and labels shape [420]
	 [[Node: Train/Model/sequence_loss_by_example/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits = SparseSoftmaxCrossEntropyWithLogits[T=DT_FLOAT, Tlabels=DT_INT32, _device=""/job:localhost/replica:0/task:0/gpu:0""](Train/Model/add, Train/Model/sequence_loss_by_example/Reshape/_129)]]
	 [[Node: Train/Model/truediv/_153 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device_incarnation=1, tensor_name=""edge_1023_Train/Model/truediv"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]


"
6468,AttributeError: 'module' object has no attribute 'legacy_seq2seq',"I am running the ptb_rnn_lm.py. The tensorflow version is 0.12. The error is occurring in the line:

loss = tf.contrib.legacy_seq2seq.sequence_loss_by_example(
        [logits],
        [tf.reshape(input_.targets, [-1])],
        [tf.ones([batch_size * num_steps], dtype=data_type())])

The entire error log is:

Traceback (most recent call last):
  File ""ptb_word_lm.py"", line 364, in <module>
    tf.app.run()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 30, in run
    sys.exit(main(sys.argv[:1] + flags_passthrough))
  File ""ptb_word_lm.py"", line 326, in main
    m = PTBModel(is_training=True, config=config, input_=train_input)
  File ""ptb_word_lm.py"", line 144, in __init__
    loss = tf.contrib.legacy_seq2seq.sequence_loss_by_example(
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/__init__.py"", line 35, in __getattr__
    return getattr(contrib, item)
AttributeError: 'module' object has no attribute 'legacy_seq2seq'

Pls help soon !!
"
6466,CudnnLSTM dropout takes no effect,"My environment is: Tensorflow 0.11.0rc2, in unbuntu 16.04, cuda8.0, cudnn5.1, GPU is GTX1080.

I am using the CudnnLSTM from tensorflow.contrib.cudnn_rnn package. I found that the dropout setting in CudnnLSTM seems take no effect, and I checked that there is no test for dropout in op unit test. So I write a simple code to test it, the code is below:
 
    import tensorflow as tf
    from tensorflow.contrib.cudnn_rnn import CudnnLSTM

    class Cudnn_model():
      def __init__(self,dropout):
        self.model = CudnnLSTM(
            num_layers = 1,
            num_units = 8,
            input_size = 8,
            input_mode = ""skip_input"",
            direction = ""unidirectional"",
            dropout = dropout,
            )

        params_size_t = self.model.params_size()
        self.params = tf.Variable(tf.ones([params_size_t]), validate_shape=False)

      def run_step(self,rnn_inputs):
        outputs, output_h, output_c = self.model(
                    input_data = rnn_inputs,
                    input_h = tf.zeros([1,1,8]),
                    input_c = tf.zeros([1,1,8]),
                    params = self.params,
                    is_training= True
                   )
        self.outputs = outputs
        return outputs

    def main():

    inputs = tf.pack([[[0.0,1.0,2.0,3.0,4.0,5.0,6.0,7.0]]])
    m1 = Cudnn_model(dropout = 0.0)
    output1 = m1.run_step(inputs)
    m2 = Cudnn_model(dropout = 0.5)
    output2 = m2.run_step(inputs)
    output3 = tf.nn.dropout(output1,0.5)
    output4 = m1.run_step(tf.nn.dropout(inputs,0.5))

    config = tf.ConfigProto(allow_soft_placement=True)
    config.gpu_options.allow_growth = True
    sess = tf.Session(config=config)
    sess.run(tf.initialize_all_variables())

    for i in range(5):
        out1,out2,out3,out4 = sess.run([output1,output2,output3,output4])
        print "" ----- Try time %d -----"" % i
        print ""cndnn_dropout=0 : "", out1
        print ""cudnn_dropout=0.5 : "", out2
        print ""tf_out_dropout=0.5 : "", out3
        print ""tf_in_dropout=0.5 : "", out4
    return

And the result is：

    ----- Try time 0 -----
    cndnn_dropout=0 [[[ 0.6082834   0.70377535  0.74009657  0.75365263  0.75866807  0.76051712
    0.76119781  0.76144838]]]
    cudnn_dropout=0.5 [[[ 0.6082834   0.70377535  0.74009657  0.75365263  0.75866807  0.76051712
    0.76119781  0.76144838]]]
    tf_out_dropout=0.5 [[[ 1.2165668   0.          0.          0.          0.          1.52103424
    1.52239561  1.52289677]]]
    tf_in_dropout=0.5 [[[ 0.6082834   0.6082834   0.6082834   0.76119781  0.6082834   0.76158684
    0.6082834   0.6082834 ]]]

     ----- Try time 1 -----
    cndnn_dropout=0 [[[ 0.6082834   0.70377535  0.74009657  0.75365263  0.75866807  0.76051712
    0.76119781  0.76144838]]]
    cudnn_dropout=0.5 [[[ 0.6082834   0.70377535  0.74009657  0.75365263  0.75866807  0.76051712
    0.76119781  0.76144838]]]
    tf_out_dropout=0.5 [[[ 0.  0.  0.  0.  0.  0.  0.  0.]]]
    tf_in_dropout=0.5 [[[ 0.6082834   0.74009657  0.6082834   0.76119781  0.6082834   0.76158684
    0.6082834   0.6082834 ]]]

     ----- Try time 2 -----
    cndnn_dropout=0 [[[ 0.6082834   0.70377535  0.74009657  0.75365263  0.75866807  0.76051712
    0.76119781  0.76144838]]]
    cudnn_dropout=0.5 [[[ 0.6082834   0.70377535  0.74009657  0.75365263  0.75866807  0.76051712
    0.76119781  0.76144838]]]
    tf_out_dropout=0.5 [[[ 1.2165668   0.          0.          1.50730526  1.51733613  1.52103424
    1.52239561  0.        ]]]
    tf_in_dropout=0.5 [[[ 0.6082834   0.74009657  0.6082834   0.76119781  0.6082834   0.76158684
    0.6082834   0.761594  ]]]

     ----- Try time 3 -----
    cndnn_dropout=0 [[[ 0.6082834   0.70377535  0.74009657  0.75365263  0.75866807  0.76051712
    0.76119781  0.76144838]]]
    cudnn_dropout=0.5 [[[ 0.6082834   0.70377535  0.74009657  0.75365263  0.75866807  0.76051712
    0.76119781  0.76144838]]]
    tf_out_dropout=0.5 [[[ 0.          0.          1.48019314  0.          0.          0.
    1.52239561  1.52289677]]]
    tf_in_dropout=0.5 [[[ 0.6082834   0.6082834   0.6082834   0.76119781  0.76154053  0.6082834
    0.76159316  0.761594  ]]]

     ----- Try time 4 -----
    cndnn_dropout=0 [[[ 0.6082834   0.70377535  0.74009657  0.75365263  0.75866807  0.76051712
    0.76119781  0.76144838]]]
    cudnn_dropout=0.5 [[[ 0.6082834   0.70377535  0.74009657  0.75365263  0.75866807  0.76051712
    0.76119781  0.76144838]]]
    tf_out_dropout=0.5 [[[ 0.          1.40755069  0.          1.50730526  1.51733613  0.
    1.52239561  1.52289677]]]
    tf_in_dropout=0.5 [[[ 0.6082834   0.74009657  0.75866807  0.76119781  0.6082834   0.76158684
    0.76159316  0.6082834 ]]]

From the result I see that the cudnn_dropout = 0.5 takes no effect, the result is always same with cudnn_dropout = 0.0. "
6460,Slow Adam sparse updates in distributed TF,"I am trying to train a model with the **tf.nn.embedding_lookup_sparse** operation. Small example: https://gist.github.com/Bobrosoft98/2d639d3924dfbc4ec7bc620fd5a4d480

When I run this code with NUM_WORKERS = 1, the output is as follows

```
0 calc in 0.0176000595093
0 apply in 0.184364080429
0 calc in 0.0167639255524
0 apply in 0.189659118652
...
```

However, when I increase the number of workers to 30, every single process works more than 30 times slower:

```
6 calc in 0.432843923569
11 calc in 0.787642002106
3 calc in 0.440953016281
14 calc in 0.377243995667
20 calc in 0.569782018661
...
6 apply in 5.63959908485
```

The CPU load is only ~50%, so there is a lot of resources available for the computation. This makes me think that sparse updates use locking, even though the **use_locking** flag is set to False by default. There is no such problem with other optimizers (I tried GradientDescentOptimizer and AdadeltaOptimizer). Also if I exclude sparse operations from the graph (commented lines), the problem disappears.

### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?

https://github.com/tensorflow/tensorflow/issues/464 - there was mentioned that Adam was slower on sparse updates in general

### Environment info
Operating System: Ubuntu 16.04

Installed version of CUDA and cuDNN: I used the CPU version

If installed from binary pip package, provide:

1. A link to the pip package you installed: https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.12.0-cp27-none-linux_x86_64.whl
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.
```
$ python -c ""import tensorflow; print(tensorflow.__version__)""
0.12.0-rc1
```"
6459,cuda autoconf issues for cuda rpm install,"NOTE: Only file GitHub issues for bugs and feature requests.  All other topics will be closed.

For general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).
To make bugs and feature requests more easy to find and organize, we close issues that are deemed
out of scope for GitHub Issues and point people to StackOverflow.

For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.

### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?
None

### Environment info
Operating System:
Fedora 25

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

Here's the problem.  CUDA is 8.0, and cuDNN is 5.1.5, but that's not necessarily relevant.
If installed from binary pip package, provide:

1. A link to the pip package you installed:
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.

If installed from source, provide 

1. The commit hash (`git rev-parse HEAD`)
1cea4458efe1fc177436a6c04b3f804cc41214d7

2. The output of `bazel version`
Build label: 0.4.2
Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Wed Dec 7 18:47:11 2016 (1481136431)
Build timestamp: 1481136431
Build timestamp as int: 1481136431

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)
The problem, such as it is, is that I installed cuda using the rpms provided by Nvidia.  These place cuda under /usr.  The big thing, building from source is that cudnn.h is now under /usr/include/cuda, as is the CUPTI directory.  There may be other differences.

### What other attempted solutions have you tried?
Since I was just trying to build the android demos, I ran configure without configuring cuda.  That let me build the android demos.  The pip install for tensorflow cuda works OK for my host.  It's more of a cosmetic thing since a few symlinks will get past it.

### Logs or other output that would be helpful
(If logs are large, please upload as attachment or provide link).
"
6458,BasicLSTMCell problem,"In the ptb_rnn_lm.py I have replaced tf.contrib.rnn.BasicLSTMCell by tf.nn.rnn_cell.BasicLSTMCell as suggested in [https://github.com/tensorflow/tensorflow/issues/6432](url) but now a new error is being shown:

Traceback (most recent call last):
File ""ptb_word_lm.py"", line 362, in
tf.app.run()
File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 30, in run
sys.exit(main(sys.argv[:1] + flags_passthrough))
File ""ptb_word_lm.py"", line 324, in main
m = PTBModel(is_training=True, config=config, input_=train_input)
File ""ptb_word_lm.py"", line 110, in init
self._initial_state = cell.zero_state(batch_size, data_type())
File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn_cell.py"", line 166, in zero_state
for s in state_size_flat]
File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn_cell.py"", line 79, in _state_size_with_prefix
result_state_size = tensor_shape.as_shape(state_size).as_list()
File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/tensor_shape.py"", line 815, in as_shape
return TensorShape(shape)
File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/tensor_shape.py"", line 448, in init
self._dims = [as_dimension(dims)]
File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/tensor_shape.py"", line 374, in as_dimension
return Dimension(value)
File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/tensor_shape.py"", line 33, in init
self._value = int(value)
TypeError: int() argument must be a string or a number, not 'BasicLSTMCell'

Pls help soon !!"
6457,Name clash with inspect.py,"Ubuntu 14.04, TF r0.12

I named a script `inspect.py` and then launched TF in the same folder. It crashes. 

Reproducer: 
----------------
In terminal:
```
cd
touch inspect.py
python -c ""import tensorflow as tf""
```
If I remove `inspect.py` it works again.
"
6456,tensorflow.python.framework.errors.InvalidArgumentError,"I getting error when using  cifar10 model to train my tfrecord datasets  which are made with tf.python_io.TFRecordWriter().

on tensorflow0.8 ,it's running ok, but on tensorflow 0.10 and 0.11 ,there is the error : tensorflow.python.framework.errors.InvalidArgumentError

File ""/Users/yang/Documents/cifar10/cifar10_train.py"", line 133, in <module>
    tf.app.run()
  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 30, in run
    sys.exit(main(sys.argv[:1] + flags_passthrough))
  File ""/Users/yang/Documents/cifar10/cifar10_train.py"", line 129, in main
    train()
  File ""/Users/yang/Documents/cifar10/cifar10_train.py"", line 99, in train
    _, loss_value = sess.run([train_op, loss])
  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 717, in run
    run_metadata_ptr)
  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 915, in _run
    feed_dict_string, options, run_metadata)
  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 965, in _do_run
    target_list, options, run_metadata)
  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 985, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors.InvalidArgumentError: Received a label value of 246 which is outside the valid range of [0, 20).  Label values: 10 104 185 191 178 50 116 159 192 201 173 173 81 246 110 116 153 10 114 193 167 208 173 225 97 113 84 82 179 101 90 190 107 208 155 229 239 163 28 71 173 192 200 178 83 125 238 146 213 70 34 121 129 33 207 124 157 70 117 147 80 30 153 231 156 63 130 147 143 205 86 60 97 90 202 94 127 91 191 127 123 199 201 69 220 185 152 175 86 121 60 132 73 109 100 163 218 162 201 202 40 108 63 116 195 105 124 195 107 96 86 152 58 141 166 28 55 135 128 49 180 119 237 38 59 189 202 66
	 [[Node: cross_entropy_per_example/cross_entropy_per_example = SparseSoftmaxCrossEntropyWithLogits[T=DT_FLOAT, Tlabels=DT_INT64, _device=""/job:localhost/replica:0/task:0/cpu:0""](softmax_linear/softmax_linear, Cast_4)]]

Caused by op u'cross_entropy_per_example/cross_entropy_per_example', defined at:
  File ""/Users/yang/Documents/cifar10/cifar10_train.py"", line 133, in <module>
    tf.app.run()
  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 30, in run
    sys.exit(main(sys.argv[:1] + flags_passthrough))
  File ""/Users/yang/Documents/cifar10/cifar10_train.py"", line 129, in main
    train()
  File ""/Users/yang/Documents/cifar10/cifar10_train.py"", line 72, in train
    loss = cifar10.loss(logits, labels)
  File ""/Users/yang/Documents/cifar10/cifar10.py"", line 286, in loss
    logits, labels, name='cross_entropy_per_example')
  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/tensorflow/python/ops/nn_ops.py"", line 764, in sparse_softmax_cross_entropy_with_logits
    precise_logits, labels, name=name)
  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/tensorflow/python/ops/gen_nn_ops.py"", line 1857, in _sparse_softmax_cross_entropy_with_logits
    features=features, labels=labels, name=name)
  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py"", line 748, in apply_op
    op_def=op_def)
  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 2380, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 1298, in __init__
    self._traceback = _extract_stack()

InvalidArgumentError (see above for traceback): Received a label value of 246 which is outside the valid range of [0, 20).  Label values: 10 104 185 191 178 50 116 159 192 201 173 173 81 246 110 116 153 10 114 193 167 208 173 225 97 113 84 82 179 101 90 190 107 208 155 229 239 163 28 71 173 192 200 178 83 125 238 146 213 70 34 121 129 33 207 124 157 70 117 147 80 30 153 231 156 63 130 147 143 205 86 60 97 90 202 94 127 91 191 127 123 199 201 69 220 185 152 175 86 121 60 132 73 109 100 163 218 162 201 202 40 108 63 116 195 105 124 195 107 96 86 152 58 141 166 28 55 135 128 49 180 119 237 38 59 189 202 66
	 [[Node: cross_entropy_per_example/cross_entropy_per_example = SparseSoftmaxCrossEntropyWithLogits[T=DT_FLOAT, Tlabels=DT_INT64, _device=""/job:localhost/replica:0/task:0/cpu:0""](softmax_linear/softmax_linear, Cast_4)]]"
6455,gradient for tf.gather_nd,"I use tf.gather_nd to build a Value Iteration Block(NIPS2016 best paper, value iteration network). 
I need to pick several ""pixels"" (what the input (i,j) points to in the following picture) in the feature map Q_n.
![image](https://cloud.githubusercontent.com/assets/6497205/21421213/a8e6a8be-c86c-11e6-8801-714ca47c4c2f.png)


But I got this error: NotImplementedError: Gradient for gather_nd is not implemented.
I know gradient for tf.gather is implemented, but tf.gather could only slice the first dimentsion. It should be easy to transfer the gradient of tf.gather to tf.gather_nd.
Or anyone could tell me how to implement this operation and train this?"
6454,TypeError: zeros_initializer() got multiple values for keyword argument 'dtype',"### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?
https://github.com/tensorflow/models/issues/672 

### Environment info
Operating System: Ubuntu 16

Installed version of CUDA and cuDNN:  NO
The output of `bazel version`  0.4.2

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)
Export a model for serving: Detailed steps at https://medium.com/osldev-blog/tensorflow-serving-practical-introduction-9ce29ccd63f#.8ul5tqwxe 
Command:
bazel-bin/tensorflow_serving/example/inception_export --checkpoint_dir=inception-v3 --export_dir=inception-export

### Logs or other output that would be helpful
WARNING:tensorflow:tf.variable_op_scope(values, name, default_name) is deprecated, use tf.variable_scope(name, default_name, values)
WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.
Traceback (most recent call last):
  File ""/serving/bazel-bin/tensorflow_serving/example/inception_export.runfiles/tf_serving/tensorflow_serving/example/inception_export.py"", line 169, in <module>
    tf.app.run()
  File ""/serving/bazel-bin/tensorflow_serving/example/inception_export.runfiles/org_tensorflow/tensorflow/python/platform/app.py"", line 44, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""/serving/bazel-bin/tensorflow_serving/example/inception_export.runfiles/tf_serving/tensorflow_serving/example/inception_export.py"", line 165, in main
    export()
  File ""/serving/bazel-bin/tensorflow_serving/example/inception_export.runfiles/tf_serving/tensorflow_serving/example/inception_export.py"", line 79, in export
    logits, _ = inception_model.inference(images, NUM_CLASSES + 1)
  File ""/serving/bazel-bin/tensorflow_serving/example/inception_export.runfiles/inception_model/inception/inception_model.py"", line 87, in inference
    scope=scope)
  File ""/serving/bazel-bin/tensorflow_serving/example/inception_export.runfiles/inception_model/inception/slim/inception_model.py"", line 87, in inception_v3
    scope='conv0')
  File ""/serving/bazel-bin/tensorflow_serving/example/inception_export.runfiles/inception_model/inception/slim/scopes.py"", line 155, in func_with_args
    return func(*args, **current_args)
  File ""/serving/bazel-bin/tensorflow_serving/example/inception_export.runfiles/inception_model/inception/slim/ops.py"", line 234, in conv2d
    outputs = batch_norm(conv, **batch_norm_params)
  File ""/serving/bazel-bin/tensorflow_serving/example/inception_export.runfiles/inception_model/inception/slim/scopes.py"", line 155, in func_with_args
    return func(*args, **current_args)
  File ""/serving/bazel-bin/tensorflow_serving/example/inception_export.runfiles/inception_model/inception/slim/ops.py"", line 90, in batch_norm
    restore=restore)
  File ""/serving/bazel-bin/tensorflow_serving/example/inception_export.runfiles/inception_model/inception/slim/scopes.py"", line 155, in func_with_args
    return func(*args, **current_args)
  File ""/serving/bazel-bin/tensorflow_serving/example/inception_export.runfiles/inception_model/inception/slim/variables.py"", line 289, in variable
    trainable=trainable, collections=collections)
  File ""/serving/bazel-bin/tensorflow_serving/example/inception_export.runfiles/org_tensorflow/tensorflow/python/ops/variable_scope.py"", line 1063, in get_variable
    custom_getter=custom_getter)
  File ""/serving/bazel-bin/tensorflow_serving/example/inception_export.runfiles/org_tensorflow/tensorflow/python/ops/variable_scope.py"", line 889, in get_variable
    custom_getter=custom_getter)
  File ""/serving/bazel-bin/tensorflow_serving/example/inception_export.runfiles/org_tensorflow/tensorflow/python/ops/variable_scope.py"", line 347, in get_variable
    validate_shape=validate_shape)
  File ""/serving/bazel-bin/tensorflow_serving/example/inception_export.runfiles/org_tensorflow/tensorflow/python/ops/variable_scope.py"", line 332, in _true_getter
    caching_device=caching_device, validate_shape=validate_shape)
  File ""/serving/bazel-bin/tensorflow_serving/example/inception_export.runfiles/org_tensorflow/tensorflow/python/ops/variable_scope.py"", line 683, in _get_single_variable
    validate_shape=validate_shape)
  File ""/serving/bazel-bin/tensorflow_serving/example/inception_export.runfiles/org_tensorflow/tensorflow/python/ops/variables.py"", line 225, in __init__
    expected_shape=expected_shape)
  File ""/serving/bazel-bin/tensorflow_serving/example/inception_export.runfiles/org_tensorflow/tensorflow/python/ops/variables.py"", line 322, in _init_from_args
    initial_value(), name=""initial_value"", dtype=dtype)
  File ""/serving/bazel-bin/tensorflow_serving/example/inception_export.runfiles/org_tensorflow/tensorflow/python/ops/variable_scope.py"", line 672, in <lambda>
    shape.as_list(), dtype=dtype, partition_info=partition_info)
TypeError: zeros_initializer() got multiple values for keyword argument 'dtype'


"
6452,Nvidia GTX 960: Abnormal Memory Usage,"### Environment info
Operating System: Ubuntu 16.04

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

-rw-r--r-- 1 root root   558720 Dec 17 21:39 libcudadevrt.a
lrwxrwxrwx 1 root root       16 Dec 17 21:39 libcudart.so -> libcudart.so.8.0
lrwxrwxrwx 1 root root       19 Dec 17 21:39 libcudart.so.8.0 -> libcudart.so.8.0.44
-rwxr-xr-x 1 root root   415432 Dec 17 21:39 libcudart.so.8.0.44
-rw-r--r-- 1 root root   775162 Dec 17 21:39 libcudart_static.a
lrwxrwxrwx 1 root root       13 Dec 18 16:34 libcudnn.so -> libcudnn.so.5
lrwxrwxrwx 1 root root       17 Dec 18 16:34 libcudnn.so.5 -> libcudnn.so.5.1.5
-rwxr-xr-x 1 root root 78065952 Dec 18 16:34 libcudnn.so.5.0.5
-rwxr-xr-x 1 root root 79337624 Dec 18 16:34 libcudnn.so.5.1.5
-rw-r--r-- 1 root root 69756172 Dec 18 16:34 libcudnn_static.a

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)
Just any neural network model. Strangely enough CIFAR functioned fine.
I used images of size 1750 * 1750.
### What other attempted solutions have you tried?

I ran it on CPU and there was no issue at all other than the slow training speed.

### Logs or other output that would be helpful
(If logs are large, please upload as attachment or provide link).

Unfortunately because the memory leak crashes my computer within seconds, I can only give a rough example. It roughly says"" GPU has failed to allocate ~~ around 8 GB of ram. The GTX 960 on my machine only has 4 GB of ram. I'm not sure why 8 GB was suddenly gobbled up at once.
"
6451,ig,"NOTE: Only file GitHub issues for bugs and feature requests.  All other topics will be closed.

For general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).
To make bugs and feature requests more easy to find and organize, we close issues that are deemed
out of scope for GitHub Issues and point people to StackOverflow.

For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.

### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?

### Environment info
Operating System:

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

If installed from binary pip package, provide:

1. A link to the pip package you installed:
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.

If installed from source, provide 

1. The commit hash (`git rev-parse HEAD`)
2. The output of `bazel version`

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)


### What other attempted solutions have you tried?


### Logs or other output that would be helpful
(If logs are large, please upload as attachment or provide link).
"
6449,Using OpenCL on macOS," Thank you very much for developing nice framework. I have a question about OpenCL support for macOS. Is there no way to run tensorflow with GPU on recent MacBookPro?  Tensorflow support OpenCL. But I think this is for Linux, not for macOS. Tensorflow + OpenCL need ComputeCpp. But ComputeCpp compiler do not support macOS(I couldn't find ComputeCpp binary for mac). Do you have a plot to support recent MacBook pro's GPU? "
6448,Documentation request: leave all function names on the sidebar,"Before, I found it really nice that I could `ctrl+f` to look up a function really quickly. Now I either have to Google it or use the search bar, or worse, scan through the hierarchy and click a few times and scroll til I find it. Not a huge deal, but relatively painful.

It was nice to get instant search results for even partial bits of function names."
6446,TF_CUDA_VERSION and TF_CUDNN_VERSION can be too specific,"If you run `./configure` and provide your own `TF_CUDA_VERSION` and `TF_CUDNN_VERSION`, you will get an error message if your version is too specific.

For example, setting `TF_CUDA_VERSION=7.5.18` will result in an error when `nvcc` reports a version `7.5`. If you set `TF_CUDNN_VERSION=5.1.3`, you get an error because `cudnn.h` reports version `5`.

I think in previous versions of TensorFlow this didn't happen, and it's only a minor annoyance, but it would be nice to fix this."
6442,Build on windows using bazel broken,"Operating System: Windows
bazel 0.4.2, issue is seen at master branch.

It looks like sometime after our update to libjpeg turbo, our build has been broken in windows.
I am looking into it, but I cannot see a clear resolution to the problem.
The error message says:
http://ci.tensorflow.org/job/tf-master-win-bzl/218/console
```
00:04:27.376 c:\tmp\_bazel_system\rrc05caq\execroot\tf-master-win-bzl\external\jpeg\jmorecfg.h(242): error C2371: 'boolean': redefinition; different basic types
00:04:27.376 c:\program files (x86)\windows kits\10\include\10.0.14393.0\shared\rpcndr.h(193): note: see declaration of 'boolean'
```

I checked jmorecfg.sh, and tried to use `#define HAVE_BOOLEAN` to get around the issue. However that causes:
http://ci.tensorflow.org/view/Experimental/job/exp-win-bzl/4/console

Creating the issue to track a quick resolution to the problem.

CC Our in house windows experts:
@meteorcloudy @mrry 

@guschmue @vit-stepanovs Do you have any ideas how we can solve this?
We would like to also upgrade cmake build to use libjpeg-turbo, but before that I want to make sure it builds when we do.

"
6440,AttributeError: 'module' object has no attribute 'legacy_seq2sec',"In Tensorflow 0.12.0 && python 2.7.10  When I run :
        `ptb_word_lm.py --data_path=/Users/mac/Documents/Tensor/simple-examples/data/ --model small`

It throws such exception:
      

>   AttributeError: 'module' object has no attribute 'legacy_seq2sec'

How can I fix this issue?"
6439,Have TensorBoard graph smoothing not overestimate last gotten scalar,"When plotting scalars in TensorBoard, the smoothed curve overfits the latest value. It means the curve jumps around with subsequent updates, and for a line fit it just plainly looks bad and feels wrong.

For example, when progress reporting neural networks training and plotting the loss over the training data, surely the blue line will continue with a slight downwards slope given a stable learning rate but instead this happens at the end of the curve:

![image](https://cloud.githubusercontent.com/assets/1595907/21398836/3efff694-c7a9-11e6-94cb-1b996021c1d4.png)

![image](https://cloud.githubusercontent.com/assets/1595907/21398869/64c3fe66-c7a9-11e6-8440-29ca1e959d91.png)"
6438,Cannot show stderr when using Jupyter,"Hello,
Could you please have a look about this.

I am using TF and Jupyter. But what makes me confuse is that the log text cannot be shown in Jupyter output cell (but it output correctly in ipython). 
I think it is because of the stderr. This issue have been discussed before in #3047. You add several lines to determine whether or not current context is in an interactive environment. 

However, even if I use Jupyter, the return value of ""sys.flags.interactive"" is still zero. and the logger lever can never be setted to ""info"" and use ""stdout"" instead of ""stderr"".


Thanks a lot!"
6437,"Separable convolutions in 3D ( For example, separable_conv3d )","Is there a function to implement separable convolutions with 3D convolutions. We have a similar function in the case of 2D called as separable_conv2d()

Is there a similar implementations in 3D as well? 

Thanks in Advance!"
6436,Failed to build from source for r0.12 for missing urls.,"Hi, I'm trying to install tensorflow r0.12 on a cluster with CentOS. Since I don't have sudo permission and got the same problem as [#53]( https://github.com/tensorflow/tensorflow/issues/53 ), I have to build from source.

When trying to build r0.12, during `./configure` step, I got following errors:
```
ERROR: /lustre/home/bmehq/tensorflow-0.12/tensorflow/tensorflow/workspace.bzl:17:3: //external:eigen_archive: no such attribute 'urls' in 'new_http_archive' rule.
ERROR: /lustre/home/bmehq/tensorflow-0.12/tensorflow/tensorflow/workspace.bzl:17:3: //external:eigen_archive: missing value for mandatory attribute 'url' in 'new_http_archive' rule.
ERROR: /lustre/home/bmehq/tensorflow-0.12/tensorflow/tensorflow/workspace.bzl:28:3: //external:libxsmm_archive: no such attribute 'urls' in 'new_http_archive' rule.
ERROR: /lustre/home/bmehq/tensorflow-0.12/tensorflow/tensorflow/workspace.bzl:28:3: //external:libxsmm_archive: missing value for mandatory attribute 'url' in 'new_http_archive' rule.
ERROR: /lustre/home/bmehq/tensorflow-0.12/tensorflow/tensorflow/workspace.bzl:44:3: //external:com_googlesource_code_re2: no such attribute 'urls' in 'http_archive' rule.
ERROR: /lustre/home/bmehq/tensorflow-0.12/tensorflow/tensorflow/workspace.bzl:44:3: //external:com_googlesource_code_re2: missing value for mandatory attribute 'url' in 'http_archive' rule.
ERROR: /lustre/home/bmehq/tensorflow-0.12/tensorflow/tensorflow/workspace.bzl:54:3: //external:gemmlowp: no such attribute 'urls' in 'http_archive' rule.
ERROR: /lustre/home/bmehq/tensorflow-0.12/tensorflow/tensorflow/workspace.bzl:54:3: //external:gemmlowp: missing value for mandatory attribute 'url' in 'http_archive' rule.
ERROR: /lustre/home/bmehq/tensorflow-0.12/tensorflow/tensorflow/workspace.bzl:64:3: //external:farmhash_archive: no such attribute 'urls' in 'new_http_archive' rule.
ERROR: /lustre/home/bmehq/tensorflow-0.12/tensorflow/tensorflow/workspace.bzl:64:3: //external:farmhash_archive: missing value for mandatory attribute 'url' in 'new_http_archive' rule.
ERROR: /lustre/home/bmehq/tensorflow-0.12/tensorflow/tensorflow/workspace.bzl:80:3: //external:highwayhash: no such attribute 'urls' in 'http_archive' rule.
ERROR: /lustre/home/bmehq/tensorflow-0.12/tensorflow/tensorflow/workspace.bzl:80:3: //external:highwayhash: missing value for mandatory attribute 'url' in 'http_archive' rule.
ERROR: /lustre/home/bmehq/tensorflow-0.12/tensorflow/tensorflow/workspace.bzl:90:3: //external:nasm: no such attribute 'urls' in 'new_http_archive' rule.
ERROR: /lustre/home/bmehq/tensorflow-0.12/tensorflow/tensorflow/workspace.bzl:90:3: //external:nasm: missing value for mandatory attribute 'url' in 'new_http_archive' rule.
ERROR: /lustre/home/bmehq/tensorflow-0.12/tensorflow/tensorflow/workspace.bzl:101:3: //external:jpeg: no such attribute 'urls' in 'new_http_archive' rule.
ERROR: /lustre/home/bmehq/tensorflow-0.12/tensorflow/tensorflow/workspace.bzl:101:3: //external:jpeg: missing value for mandatory attribute 'url' in 'new_http_archive' rule.
ERROR: /lustre/home/bmehq/tensorflow-0.12/tensorflow/tensorflow/workspace.bzl:112:3: //external:png_archive: no such attribute 'urls' in 'new_http_archive' rule.
ERROR: /lustre/home/bmehq/tensorflow-0.12/tensorflow/tensorflow/workspace.bzl:112:3: //external:png_archive: missing value for mandatory attribute 'url' in 'new_http_archive' rule.
ERROR: /lustre/home/bmehq/tensorflow-0.12/tensorflow/tensorflow/workspace.bzl:123:3: //external:gif_archive: no such attribute 'urls' in 'new_http_archive' rule.
ERROR: /lustre/home/bmehq/tensorflow-0.12/tensorflow/tensorflow/workspace.bzl:123:3: //external:gif_archive: missing value for mandatory attribute 'url' in 'new_http_archive' rule.
ERROR: /lustre/home/bmehq/tensorflow-0.12/tensorflow/tensorflow/workspace.bzl:135:3: //external:six_archive: no such attribute 'urls' in 'new_http_archive' rule.
ERROR: /lustre/home/bmehq/tensorflow-0.12/tensorflow/tensorflow/workspace.bzl:135:3: //external:six_archive: missing value for mandatory attribute 'url' in 'new_http_archive' rule.
ERROR: /lustre/home/bmehq/tensorflow-0.12/tensorflow/tensorflow/workspace.bzl:151:3: //external:protobuf: no such attribute 'urls' in 'http_archive' rule.
ERROR: /lustre/home/bmehq/tensorflow-0.12/tensorflow/tensorflow/workspace.bzl:151:3: //external:protobuf: missing value for mandatory attribute 'url' in 'http_archive' rule.
ERROR: /lustre/home/bmehq/tensorflow-0.12/tensorflow/tensorflow/workspace.bzl:161:3: //external:gmock_archive: no such attribute 'urls' in 'new_http_archive' rule.
ERROR: /lustre/home/bmehq/tensorflow-0.12/tensorflow/tensorflow/workspace.bzl:161:3: //external:gmock_archive: missing value for mandatory attribute 'url' in 'new_http_archive' rule.
ERROR: /lustre/home/bmehq/tensorflow-0.12/tensorflow/tensorflow/workspace.bzl:187:3: //external:pcre: no such attribute 'urls' in 'new_http_archive' rule.
ERROR: /lustre/home/bmehq/tensorflow-0.12/tensorflow/tensorflow/workspace.bzl:187:3: //external:pcre: missing value for mandatory attribute 'url' in 'new_http_archive' rule.
ERROR: /lustre/home/bmehq/tensorflow-0.12/tensorflow/tensorflow/workspace.bzl:198:3: //external:swig: no such attribute 'urls' in 'new_http_archive' rule.
ERROR: /lustre/home/bmehq/tensorflow-0.12/tensorflow/tensorflow/workspace.bzl:198:3: //external:swig: missing value for mandatory attribute 'url' in 'new_http_archive' rule.
ERROR: /lustre/home/bmehq/tensorflow-0.12/tensorflow/tensorflow/workspace.bzl:222:3: //external:grpc: no such attribute 'urls' in 'new_http_archive' rule.
ERROR: /lustre/home/bmehq/tensorflow-0.12/tensorflow/tensorflow/workspace.bzl:222:3: //external:grpc: missing value for mandatory attribute 'url' in 'new_http_archive' rule.
ERROR: /lustre/home/bmehq/tensorflow-0.12/tensorflow/tensorflow/workspace.bzl:245:3: //external:linenoise: no such attribute 'urls' in 'new_http_archive' rule.
ERROR: /lustre/home/bmehq/tensorflow-0.12/tensorflow/tensorflow/workspace.bzl:245:3: //external:linenoise: missing value for mandatory attribute 'url' in 'new_http_archive' rule.
ERROR: /lustre/home/bmehq/tensorflow-0.12/tensorflow/tensorflow/workspace.bzl:258:3: //external:llvm: no such attribute 'urls' in 'new_http_archive' rule.
ERROR: /lustre/home/bmehq/tensorflow-0.12/tensorflow/tensorflow/workspace.bzl:258:3: //external:llvm: missing value for mandatory attribute 'url' in 'new_http_archive' rule.
ERROR: /lustre/home/bmehq/tensorflow-0.12/tensorflow/tensorflow/workspace.bzl:269:3: //external:jsoncpp_git: no such attribute 'urls' in 'new_http_archive' rule.
ERROR: /lustre/home/bmehq/tensorflow-0.12/tensorflow/tensorflow/workspace.bzl:269:3: //external:jsoncpp_git: missing value for mandatory attribute 'url' in 'new_http_archive' rule.
ERROR: /lustre/home/bmehq/tensorflow-0.12/tensorflow/tensorflow/workspace.bzl:285:3: //external:boringssl: no such attribute 'urls' in 'http_archive' rule.
ERROR: /lustre/home/bmehq/tensorflow-0.12/tensorflow/tensorflow/workspace.bzl:285:3: //external:boringssl: missing value for mandatory attribute 'url' in 'http_archive' rule.
ERROR: /lustre/home/bmehq/tensorflow-0.12/tensorflow/tensorflow/workspace.bzl:295:3: //external:nanopb_git: no such attribute 'urls' in 'new_http_archive' rule.
ERROR: /lustre/home/bmehq/tensorflow-0.12/tensorflow/tensorflow/workspace.bzl:295:3: //external:nanopb_git: missing value for mandatory attribute 'url' in 'new_http_archive' rule.
ERROR: /lustre/home/bmehq/tensorflow-0.12/tensorflow/tensorflow/workspace.bzl:311:3: //external:zlib_archive: no such attribute 'urls' in 'new_http_archive' rule.
ERROR: /lustre/home/bmehq/tensorflow-0.12/tensorflow/tensorflow/workspace.bzl:311:3: //external:zlib_archive: missing value for mandatory attribute 'url' in 'new_http_archive' rule.
ERROR: com.google.devtools.build.lib.packages.BuildFileContainsErrorsException: error loading package '': Encountered error while reading extension file 'cuda/build_defs.bzl': no such package '@local_config_cuda//cuda': error loading package 'external': Could not load //external package.
ERROR: missing fetch expression. Type 'bazel help fetch' for syntax and help.
```

When I turned back to r0.11,  `./configure`  works fine.

Any ideas?"
6432,rnn_cell has no BasicLSTMCell,"lstm_cell = tf.contrib.rnn.BasicLSTMCell(
AttributeError: 'module' object has no attribute 'BasicLSTMCell'.

Is it been replaced by other cell?
"
6431,Does TF support multicore processing on Android?,"As we know, iPhone play better performance than other Android mobiles on single CPU, presenting Android takes more time to run an inference. But Android usually have four or more CPU cores and iPone have only two. So I want to speed up Android's inference by using multicore processing.

**What solutions have you tried?**
I add -fopenmp build options according to Eigen multi-threading docs, but it doesn't work, the speed is still the same. 
Could anyone point me in the right direction here?
Thanks!"
6429,[Tensorboard Feature Requests] Binding the run selectors of the tabs together,"For now, in order to check the Events/Image/Distribution tabs for a run, I need to make the selection for each of the tab. It would be nice to be able to apply the same run filters across all tabs. If I made a selection in one tab, the other tabs will use the same filters automatically."
6426,Outdated documentation of Assert op,"From https://www.tensorflow.org/api_docs/python/control_flow_ops/debugging_operations#Assert

```
 # Ensure maximum element of x is smaller or equal to 1
assert_op = tf.Assert(tf.less_equal(tf.reduce_max(x), 1.), [x])
x = tf.with_dependencies([assert_op], x)
```

`tf.with_dependencies` does not exist (see also a related [stack overflow discussion](http://stackoverflow.com/questions/37980078/tensorflow-has-no-attribute-with-dependencies))"
6422,[Feature request] Ability to reimplement backprop.,"Currently there is no straightforward way to do things like implementing different learning rates for different layers. Much less apply learning rate masks for individual unit adjustment.

Torch allows you to easily reimplement backprop however you want. TF seems limited to this: https://www.tensorflow.org/api_docs/python/framework/core_graph_data_structures#Graph.gradient_override_map"
6419,I cannot generate the pip  wheel ,"Hi,
I am trying to compile tensorflow from scratch. I find the following problem. 
When I execute:
```
bazel   build  -c opt  --config=cuda //tensorflow/tools/pip_package:build_pip_package
```
The compilation goes ok.
But when I try to build the wheel from the program  : 
```
bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg
Tue Dec 20 11:47:44 CET 2016 : === Using tmpdir: /tmp/tmp.zISC44bEnF
tensorflow/bazel-bin/tensorflow/tools/pip_package/build_pip_package.runfiles tensorflow
tensorflow
/tmp/tmp.zISC44bEnF tensorflow
Tue Dec 20 11:47:45 CET 2016 : === Building wheel
/usr/lib/python2.7/distutils/dist.py:267: UserWarning: Unknown distribution option: 'install_requires'
  warnings.warn(msg)
/usr/lib/python2.7/distutils/dist.py:267: UserWarning: Unknown distribution option: 'tests_require'
  warnings.warn(msg)
/usr/lib/python2.7/distutils/dist.py:267: UserWarning: Unknown distribution option: 'zip_safe'
  warnings.warn(msg)
/usr/lib/python2.7/distutils/dist.py:267: UserWarning: Unknown distribution option: 'entry_points'
  warnings.warn(msg)
/usr/lib/python2.7/distutils/dist.py:267: UserWarning: Unknown distribution option: 'include_package_data'
  warnings.warn(msg)
error: cannot copy tree 'build/scripts-2.7': not a directory
``` 

Can anyone help ?

Thanks"
6417,Saver can't handle filename only ,"Hey everyone,

it seems to me like - at least on Windows - the `tf` saver can't save model files whose path consists only of the file's name with no parent path, relative nor absolute. The issue lies at or around [saver.py:1363](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/training/saver.py#L1363) where it tries to check whether the parent directory of the file is actually a directory. There is no parent directory given (i.e. an empty string) and as such `gFile.IsDirectory` can't check anything. It fails and raises a ValueError that the parent directory does not exist. 

Expected behavior _in my opinion_ would be that the current working directory is used as the parent path when using no path/just a filename (i.e. a relative path). 

## Some details about my system specs:

* Windows 10
* Python 3.5.2
* TF 0.12.0 (in a virtual environment; `pip install tensorflow --upgrade` just executed; issue persists)


So, I'm wondering whether this is an expected behavior and how to deal with it or if it is an actual bug that needs to be addressed."
6416,Tensorflow fault tolerance,"Hello,

I have been using the following simple code to learn about the behavior of distributed tensorflow (which claims to be fault tolerant):-

  ```
import tensorflow as tf
cluster = tf.train.ClusterSpec({""local"": [""localhost:2222"", ""localhost:2223"",""localhost:2224"", ""localhost:2225""]})
x = tf.constant(2)
with tf.device(""/job:local/task:1""):
    y1 = x + 300
 with tf.device(""/job:local/task:2""):
    y2 = x**2
with tf.device(""/job:local/task:3""):
    y3 = 5*x
with tf.device(""/job:local/task:0""):
    y0 = x - 66
    y = y0 + y1 + y2 + y3

model = tf.initialize_all_variables()

with tf.Session(""grpc://localhost:2222"") as sess:
    sess.run(model)
    print(sess.run(y0))
    print('\n')
    print(sess.run(y1))
    print('\n')
    print(sess.run(y2))
    print('\n')
    print(sess.run(y3))
    print('\n')
    result = sess.run(y)
    print(result)
```

I create workers by running a separate program as given below:-

```
#get task number from command line
import sys
task_number = int(sys.argv[1])

import tensorflow as tf

cluster = tf.train.ClusterSpec({""local"": [""localhost:2222"", ""localhost:2223"", ""localhost:2224"", ""localhost:2225""]})
server = tf.train.Server(cluster, job_name=""local"", task_index=task_number)

print(""Starting server #{}"".format(task_number))

server.start()
server.join()

```
But when I stop one of the servers(machines), the whole program stops functioning instead of assigning the job to another machine. Is tensorflow fault tolerant when a machine goes down? "
6415,Merging inception retrained models,"Hi,

I know this might not be the place to ask this but I did not get any replies nor comments on SO so I thought to give it a shot.

I have done my own training of tensorflow inception a while ago, recently I wanted to add new classes to the original model. However, when I retrain tensorflow it generates a new graph and labels files completely separate from the older one.

Is there a way to combine models? Or do I have to retrain again with the old and new classes?
"
6414,Feature suggestion: Loss Normalization,"I would like to suggest the following feature be added to TensorFlow. As far as I know, the feature does not exist in TensorFlow. There are some issues that must be discussed and solved before making the pull-request.

### Motivation

When optimizing multiple objectives in TensorFlow, the combined loss-function is typically a weighted sum of the individual loss-functions. Finding the weights for the loss-functions is done experimentally as the weights may depend on a number of factors.

For example, in Style Transfer we want to combine two images so the result has the 'style' of one input image and the 'content' of another image. We do this by creating two loss-functions that we will optimize together. The problem is that when we choose different layers in the neural network for the loss-functions, then their magnitudes may change dramatically, so the weights for the loss-functions will also need to be modified.

The solution I came up with in my recent tutorial on Style Transfer, is to automatically normalize each loss-function so we can define the weights independently of any given choice of layers:

https://github.com/Hvass-Labs/TensorFlow-Tutorials/blob/master/15_Style_Transfer.ipynb

The solution I propose below is a bit more elegant than in the tutorial, and I think it can be made even better.

### Overall Idea

The idea is to evaluate each loss-function to its scalar-value and then divide the loss-function with this scalar-value. This creates a new node in the TensorFlow graph which holds the original loss-function divided by some scalar-value. The new node in the graph is still a mathematical function that can be differentiated, and for the given input it evaluates to the value 1. We do this normalization for each of the loss-functions so they all evaluate to 1. Then we can define loss-weights more easily and independently of e.g. the exact choice of layers in the Style Transfer algorithm.

### Code

In terms of pseudo-code, what we want to do is simply:

    def loss_normalize(loss):
        return loss / value_of(loss)

But if we merely return `loss/loss` then it does not calculate the value of `loss` for the denominator, instead we get a mathematical function divided by itself. I also tried `tf.identity(loss)` but that did not work either. Neither does type-casting.

So we need a small hack. We create a scalar float-variable and assign the loss-value to it. When the variable is used in an assignment like this, then it is not necessary to initialize it first. This works:

    def loss_normalize(loss):
        loss_value = tf.Variable(1.0)
        
        loss_normalized = loss / loss_value.assign(loss)

        return loss_normalized

### Usage

Imagine that we have defined two loss functions, e.g.:

    style_loss = ...
    content_loss = ...

Normally we would have some strange weights that might need to be changed if we choose different layers in the network for the loss-functions. These weights do not indicate how we are actually weighting the loss-functions for the style and content, for example:

    combined_loss = 1e-10 * style_loss + 1e-3 * content_loss

If instead we normalize the loss-functions first, then we can define the weights more intuitively. For example, we might want 90% of the combined-loss to be for the style and only 10% for the content. We would do it like this:

    combined_loss = 0.9 * loss_normalize(style_loss) + \
                    0.1 * loss_normalize(content_loss)

Even if you change the layers used in the two loss-functions, we do not need to change our weights. This may be useful in many other applications than just Style Transfer.

### Issues

Before I make a pull-request there are several issues that must be discussed and solved.

1) The hack using a variable to get the loss-value is not very elegant. I wonder if it would be possible to add something like `value_of(loss)` to TensorFlow? I guess it would be a bit similar to `loss.eval()` except that we don't want to run the session.

2) Division by zero should be handled somehow. If the loss-function is inherently non-negative then we can add a small number such as 1e-10 to the denominator. But this would not be bomb-proof for loss-functions that can take on negative values. Is there a good standard solution for this in TensorFlow?

3) It might be a better design to make `loss_normalize()` take a list of loss-functions so we don't have to wrap all of the loss-functions individually. What do you think? Is there an elegant way of implementing this in TensorFlow, or do I have to resort to Python's list comprehension?

4) It might be useful to have a placeholder bool that decides whether or not to update the normalization. This would allow us to normalize the loss-functions only in the first iteration, or we could normalize every n'th iteration. The reason this might be useful, is that the optimizer might get trapped in a local optimum if we normalize the loss-functions in every iteration. I experimented a bit with `tf.placeholder_with_default()` and `tf.cond()` but it gave me some strange errors about tensor-shapes. Any ideas on how to make an elegant implementation for this?
"
6413,Running Tests in Docker (on Mac) Fails with Cryptic Download Error,"I am currently trying to run the Docker tests on my machine (a Mac).

Building the container succeeds, but then when it builds TensorFlow after `./configure`, it fails with the following error:

```
ERROR: /workspace/tensorflow/tensorboard/bower/BUILD:5:1: no such package '@numericjs_numeric_min_js//file': Error downloading [https://cdnjs.cloudflare.com/ajax/libs/numeric/1.2.6/numeric.min.js] to /Users/gibiansky/tensorflow/bazel-ci_build-cache/.cache/bazel/_bazel_gibiansky/eab0d61a99b6696edb3d2aff87b585e8/external/numericjs_numeric_min_js/numeric.min.js: sun.security.validator.ValidatorException: PKIX path validation failed: java.security.cert.CertPathValidatorException: timestamp check failed and referenced by '//tensorflow/tensorboard/bower:bower'.
```

The error is quite consistent and from my machine I can `wget` that `numeric.min.js` URL.

Have you see this? What does `java.security.cert.CertPathValidatorException` even mean?

Thanks! "
6412,contrib\cmake: configure step errors,"Config & commands used: https://gist.github.com/derofim/b4f150da1269b81af8d12744df730708

`cmake .. -A x64 -DCMAKE_BUILD_TYPE=Release  -DSWIG_EXECUTABLE=""D:/Tensorflow/swigwin-3.0.10/swig.exe"" -DPYTHON_EXECUTABLE=""C:/Program Files/Anaconda3/python.exe"" -DPYTHON_LIBRARIES=""C:/Program Files/Anaconda3/libs/python35.lib"" -Dtensorflow_ENABLE_GPU=ON -DCUDNN_HOME=""D:\Tensorflow\cudnn\cuda"" -Dtensorflow_BUILD_CC_EXAMPLE=ON`

Errors:
**CMake Error: CMake can not determine linker language for target: tf_losses
CMake Error: CMake can not determine linker language for target: tf_models_word2vec_ops
CMake Error: CMake can not determine linker language for target: tf_models_word2vec_kernels**

Full log:
`D:\Tensorflow\tensorflow-master\tensorflow\contrib\cmake\build>cmake .. -A x64 -DCMAKE_BUILD_TYPE=Release  -DSWIG_EXECUTABLE=""D:/Tensorflow/swigwin-3.0.10/swig.exe"" -DPYTHON_EXECUTABLE=""C:/Program Files/Anaconda3/python.exe"" -DPYTHON_LIBRARIES=""C:/Program Files/Anaconda3/libs/python35.lib"" -Dtensorflow_ENABLE_GPU=ON -DCUDNN_HOME=""D:\Tensorflow\cudnn\cuda"" -Dtensorflow_BUILD_CC_EXAMPLE=ON
-- Building for: Visual Studio 14 2015
-- The C compiler identification is MSVC 19.0.24215.1
-- The CXX compiler identification is MSVC 19.0.24215.1
-- Check for working C compiler: D:/Soft/MicrosoftVisualStudio14/VC/bin/x86_amd64/cl.exe
-- Check for working C compiler: D:/Soft/MicrosoftVisualStudio14/VC/bin/x86_amd64/cl.exe -- works
-- Detecting C compiler ABI info
-- Detecting C compiler ABI info - done
-- Check for working CXX compiler: D:/Soft/MicrosoftVisualStudio14/VC/bin/x86_amd64/cl.exe
-- Check for working CXX compiler: D:/Soft/MicrosoftVisualStudio14/VC/bin/x86_amd64/cl.exe -- works
-- Detecting CXX compiler ABI info
-- Detecting CXX compiler ABI info - done
-- Detecting CXX compile features
-- Detecting CXX compile features - done
-- Found CUDA: C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v8.0 (found suitable version ""8.0"", minimum required is ""8.0"")
You have called ADD_LIBRARY for library tf_models_word2vec_ops without any source files. This typically indicates a problem with your CMakeLists.txt file
You have called ADD_LIBRARY for library tf_models_word2vec_kernels without any source files. This typically indicates a problem with your CMakeLists.txt file
You have called ADD_LIBRARY for library tf_losses without any source files. This typically indicates a problem with your CMakeLists.txt file
-- Found PythonInterp: C:/Program Files/Anaconda3/python.exe (found version ""3.5.2"")
-- Found PythonLibs: C:/Program Files/Anaconda3/libs/python35.lib (found version ""3.5.2"")
-- Found SWIG: D:/Tensorflow/swigwin-3.0.10/swig.exe (found version ""3.0.10"")
-- Configuring done
CMake Error: CMake can not determine linker language for target: tf_losses
CMake Error: CMake can not determine linker language for target: tf_models_word2vec_ops
CMake Error: CMake can not determine linker language for target: tf_models_word2vec_kernels
-- Generating done
-- Build files have been written to: D:/Tensorflow/tensorflow-master/tensorflow/contrib/cmake/build`

P.S.
For now im ignoring build errors and tf_label_image_example works fine! (But cannot link in side project https://github.com/tensorflow/tensorflow/issues/6382)

Workaround im using:

```
For now tf_label_image_example works fine in generated .sln!

To stop rebuilding whole tensorflow each time i used workaround
""Configuration Manager"". Un-check the ""Build"" for all except tf_label_image_example as in http://stackoverflow.com/a/1433680

Also in contrib\cmake\build i created folders tensorflow/examples/label_image/data/ and placed in it:
grace_hopper.jpg
imagenet_comp_graph_label_strings.txt
tensorflow_inception_graph.pb

Data may be found at https://storage.googleapis.com/download.tensorflow.org/models/inception_dec_2015.zip in tutorial https://www.tensorflow.org/how_tos/tool_developers/
```"
6411,"Testing in python - import tensorflow as tf throws error ""Exception: Versioning for this project requires either an sdist tarball""","NOTE: Only file GitHub issues for bugs and feature requests.  All other topics will be closed.

### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?
Some of the issues when searching for ""import tensorflow as tf"" gave answers related to either mock not being installed correctly or protobuf.  In my case, all were installed correctly and successfully.
 
### Environment info
Operating System:
Amazon Linux

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):
I installed a CPU only version.  So no CUDA

If installed from binary pip package, provide:

1. A link to the pip package you installed:
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)
the installation completed successfully.  Here is the output:
----------
sudo -H /usr/local/bin/pip install tensorflow
Requirement already satisfied: tensorflow in /usr/local/lib64/python2.7/site-packages
Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib64/python2.7/site-packages (from tensorflow)
Requirement already satisfied: mock>=2.0.0 in /usr/local/lib/python2.7/site-packages (from tensorflow)
Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python2.7/site-packages (from tensorflow)
Requirement already satisfied: protobuf==3.1.0 in /usr/local/lib/python2.7/site-packages (from tensorflow)
Requirement already satisfied: wheel in /usr/local/lib/python2.7/site-packages (from tensorflow)
Requirement already satisfied: funcsigs>=1; python_version < ""3.3"" in /usr/local/lib/python2.7/site-packages (from mock>=2.0.0->tensorflow)
Requirement already satisfied: pbr>=0.11 in /usr/local/lib/python2.7/site-packages (from mock>=2.0.0->tensorflow)
Requirement already satisfied: setuptools in /usr/local/lib/python2.7/site-packages/setuptools-28.3.0-py2.7.egg (from protobuf==3.1.0->tensorflow)
--------
### What other attempted solutions have you tried?
Installed each of the dependencies individually.  Still same issue.

### Logs or other output that would be helpful
----------
 python -c ""import tensorflow; print(tensorflow.__version__)""
Traceback (most recent call last):
  File ""<string>"", line 1, in <module>
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>
    from tensorflow.python import *
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 106, in <module>
    from tensorflow.python.platform import test
  File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/platform/test.py"", line 81, in <module>
    import mock                # pylint: disable=g-import-not-at-top,unused-import
  File ""/usr/local/lib/python2.7/site-packages/mock/__init__.py"", line 2, in <module>
    import mock.mock as _mock
  File ""/usr/local/lib/python2.7/site-packages/mock/mock.py"", line 71, in <module>
    _v = VersionInfo('mock').semantic_version()
  File ""/usr/local/lib/python2.7/site-packages/pbr/version.py"", line 460, in semantic_version
    self._semantic = self._get_version_from_pkg_resources()
  File ""/usr/local/lib/python2.7/site-packages/pbr/version.py"", line 447, in _get_version_from_pkg_resources
    result_string = packaging.get_version(self.package)
  File ""/usr/local/lib/python2.7/site-packages/pbr/packaging.py"", line 725, in get_version
    raise Exception(""Versioning for this project requires either an sdist""
Exception: Versioning for this project requires either an sdist tarball, or access to an upstream git repository. Are you sure that git is installed?
-----------------
"
6405,tf.split_v() is removed in master?,"A bit of history:

- Until <= 0.12, [`tf.split()`](https://www.tensorflow.org/api_docs/python/array_ops/slicing_and_joining#split) has the following signature:
```tf.split(split_dim, num_split, value, name='split')```
- In commit f803bd7c (since 0.12), a new op `split_v()` is introduced:
```tf.split_v(value, size_splits, split_dim=0, num=None, name=""split_v"")```
- In commit a46b6d211 (master), `tf.split_v()` is finally **renamed** to `tf.split()`:
  ```tf.split(value, num_or_size_splits, axis=0, num=None, name=""split"")```

Due to these changes, the signature of `tf.split()` has been changed. AFAIK TensorFlow will having some of breaking changes after 0.12 (after the end of 2016); is this backward-incompatible API change intended?

If so, **my suggestion is** that `tf.split_v()`, which has been introduced in 0.12, should not be removed in the newer versions as well. In the current master, `tf.split_v` is non-existent.
```
AttributeError: 'module' object has no attribute 'split_v'
```

I am reporthing this (minor) issue because I am frequently switching the tensorflow versions, from r0.12 (stable branch) to master (the breaking? future), and thus I need a way to write a code that is **both compatible** in those two versions. However, due to the change of `tf.split()`, it seems that I cannot achieve it at the moment.

Thanks,"
6404,Confusion about Cuda install docs for Mac,"### Environment info
Operating System: Mac OSX 10.11

The docs have 2 issues related to this section at the top:

""The GPU version works best with Cuda Toolkit 8.0 and cuDNN v5. Other versions are supported (Cuda toolkit >= 7.0 and cuDNN >= v3) only when installing from sources. Please see Cuda installation for details. For Mac OS X, please see Setup GPU for Mac.""

1) The link to ""Setup GPU for Mac"" doesn't work; presumably the href target is missing or misspelled.

2) The Setup GPU for Mac section is included in the ""Install Tensorflow from Source"" part of the docs. Several people I know interpreted that to mean that GPU support is only available when installing from source. Furthermore, in the same section is a requirement to use homebrew, and many people I know refuse to use homebrew, so they assumed that Tensorflow was unusable on mac for them. 

I recommend separating out the Setup GPU for Mac instructions to a separate page, unless it truly is dependent on installing from source. If it is, that should also be clarified. 
"
6402,Please provide protobuf 3.1.0 download,"Since #4572, TensorFlow depends on protobuf==3.1.0.

[This section](https://github.com/kashif/tensorflow/blob/f2e17755e9466ff3c3f8a5806264d3baccd0f74e/tensorflow/g3doc/get_started/os_setup.md#protobuf-library-related-issues) of the installation instructions continues to point to a wheel for version 3.0.0, which doesn't help at all.

Therefore: please provide pre-built wheels for protobuf 3.1.0.

Also, those instructions tell me that I should only install the protobuf package _after_ installing TensorFlow via pip.  But this isn't currently helpful advice: the TensorFlow package won't install at all, because there is no protobuf==3.1.0:

```
Downloading/unpacking protobuf==3.1.0 (from tensorflow==0.12.0rc1)
  Could not find a version that satisfies the requirement protobuf==3.1.0 (from tensorflow==0.12.0rc1) (from versions: 3.0.0b4, 3.0.0, 3.0.0b2.post2, 3.0.0a2,
3.0.0b2, 2.6.1, 2.0.3, 2.0.0beta, 2.5.0, 2.4.1, 2.6.0, 3.0.0b2.post1, 3.0.0b3, 3.0.0b1.post2, 3.0.0b2.post2, 3.0.0b2.post1, 2.3.0, 3.0.0a3, 3.1.0.post1)
Cleaning up...
No distributions matching the version for protobuf==3.1.0 (from tensorflow==0.12.0rc1)
```

I think what you're trying to say is that if I had been able to succeed in installing TensorFlow then I ought anyway to overwrite whatever protobuf pip had selected.  If so I'd suggest that this belongs higher up in the instructions, and not in some sort of trouble-shooting afterthought section that would easily be missed."
6401,Numpy.FFT2() vs. TF.FFT2D() gives wrong values,"### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?

None. 

### Environment info
Operating System:
Ubuntu 16.04 LTS

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):
Toolkit-version 8.0

If installed from binary pip package, provide:
Installed it using pip install und Anaconda

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)

```
# check if np.fft2d of TF.fft2d and NP have the same result

testimage = np.random.rand(256, 256)
testimage = testimage+0j

ft_testimage = np.fft.fft2(testimage)
np_result = np.sum(ft_testimage)
print(np_result)

tf_ft_testimage = tf.fft2d(testimage)
tf_result = np.sum(tf_ft_testimage.eval())
print(tf_result)

result_div = np.abs(tf_ft_testimage.eval())

plt.imshow(np.log(result_div))

print(np_result)
(56368.5840888+9.09494701773e-13j)

print(tf_result)
(56368.6+0.00390625j)

```
### What other attempted solutions have you tried?


### Logs or other output that would be helpful



I was encountering this problem, when I did some numerical calculations using the FFT. I simply ported one algorithm from pure python to Tensorflow and the result were not the same. I think one of the reasons could be the wrong interpretation of the FFT2D used in Tensorflow? Do I need to normalize it somehow? Is the usage somehow different compared to Numpy? 

Thanks a lot! 

"
6400,Images missing in api_docs,"A few images are missing at https://www.tensorflow.org/api_docs/python/math_ops/segmentation, e.g. [SegmentSum.png](https://www.tensorflow.org/api_docs/images/SegmentSum.png) and [SegmentProd.png](https://www.tensorflow.org/api_docs/images/SegmentProd.png) are not found "
6399,Make an op compute its input once and hold.,"Currently, tf.constant can take NumPy arrays as input, but it cannot take TensorFlow tensors as input. It would be useful to allow tf.constant to take tensors (that change with every evaluation, e.g. the tensor created by a dequeue op) and turn it into a constant tensor by evaluating the input tensor only once."
6397,Feature suggestion: Total Variation Denoising,"I would like to suggest the following feature be added to TensorFlow and discuss it before making the pull-request. As far as I can tell, the feature does not exist in TensorFlow.

### Motivation

Total Variation Denoising (TVD) is sometimes used as a regularizer in image processing to suppress noise. It is commonly used in Style Transfer implementations. Here is my recent tutorial which uses it:

https://github.com/Hvass-Labs/TensorFlow-Tutorials/blob/master/15_Style_Transfer.ipynb

While researching this tutorial, I saw some bizarre implementations of TVD. In reality it is just a simple array-slicing operation. I thought it would be useful to include it in TensorFlow so it is easy to use for everyone.

### Math Formula

The code below implements the 'anisotropic' version of the formula, because it should be easier to optimize. The formula can be seen here:

https://en.wikipedia.org/wiki/Total_variation_denoising#2D_digital_signals

### Code

This is the code I propose to add to TensorFlow:

    def total_variation(images):
        """"""
        Calculate the Total Variation for one or more images for use in denoising.

        https://en.wikipedia.org/wiki/Total_variation_denoising

        Args:
            images: `Tensor` with one or more images.
                    The shape is `[batch, height, width, channel]`.

        Returns:
            A scalar `Tensor` representing the value.
        """"""

        value = tf.reduce_sum(tf.abs(images[:,1:,:,:] - images[:,:-1,:,:])) + \
                tf.reduce_sum(tf.abs(images[:,:,1:,:] - images[:,:,:-1,:]))
    
        return value

Style note: For more complicated expressions like this, I prefer to assign the value before I return it. It makes the code cleaner and is helpful in debugging.

### Discussion

I studied [this TensorFlow module](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/losses/losses.py) but did not fully understand the design-philosophy and how to make this new function fit in.

Before making the pull-request I have some questions and issues to discuss:

1) Would this belong under losses or regularizers in TensorFlow? Where specifically?

2) Should I add a scope-block?

3) I made an implementation that only reduced the sum for `axis=[1, 2, 3]` thus calculating the value on a per-image basis in case there are multiple images in the batch. But I don't know if it would ever be used in that way and it made the implementation more complicated. Perhaps it is best to have the simple version above and extend it if necessary.
"
6396,Cmake static library build issue,"Hi all,

I have successfully build tensorflow in windows/visual studio using the [cmake project](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/cmake). 

Now due to large build time of tensorflow, I am building the tensorflow as libraries (static library) and trying to use them in an application (tf_label_image_example). However, I get the following runtime error at the points of calling env constructor in the SessionOptions at the following source code:
`session->reset(tensorflow::NewSession(tensorflow::SessionOptions()));.`
Error is: `No session factory registered for the given session options: {target: """" config: } Registered factories are {}.`

It is similar to [this error](https://github.com/tensorflow/tensorflow/issues/3308) in makefiles and MAC os where the compiler is stripping the multiple defined symbols. I tried to add visual studio equivalent of this compiler options (/FORCE:MULTIPLE and /WHOLEARCHIVE) to build of tf_core_lib.lib . however, the compiler options are not applicable to static libraries. Alternative option to is make a DLL, however, that would require modification of all functions with __declspec(dllexport).
Is there a better solution?

The tf_label_image_example application contains main.cc and the following additional lib dependencies:
tf_core_cpu.lib
tf_core_framework.lib
tf_core_kernels.lib
tf_cc_framework.lib
tf_cc_ops.lib
tf_core_ops.lib
tf_stream_executor.lib
tf_core_direct_session.lib
tf_core_lib.lib
 
Thanks in advance.

### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?
https://github.com/tensorflow/tensorflow/issues/3308

### Environment info
Operating System: Win 10

Installed version of CUDA and cuDNN:  Cuda 8
The same configuration [here ](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/cmake#known-good-configurations)is used."
6395,calculate partial gradient,"Hi,

For example, in such a multi-task network.

A=net(input)
o1=softmax(A)
B=fullconnect(A)
o2=softmax(B)

Now, the gradient of  'A' from both 'o1' and 'B'.
But, I only want the gradient of  'A' from  'o1'

Is there a way to do this in tensorflow?

Thanks."
6394,Tensorflow GPU Support for Windows?,Hi I installed tensorflow-GPU through pip on my Windows 10 machine and I have also installed the Nvidia Cuda Toolkit and have downloaded cuDNN. But I came to the realization that there was no GPU version for Windows 10. Is it still possible to use the tensorflow-GPU windows 10 given that it is install-able via pip and all the other dependencies can be installed and configued?
6393,tensorflow.python.framework.errors_impl.PermissionDeniedError: data,"hi,when am run a TensorFlow demo model as this
https://www.tensorflow.org/get_started/os_setup#test_the_tensorflow_installation
i have the problem descripte as follows:


$ python /usr/local/lib/python2.7/dist-packages/tensorflow/models/imag
e/mnist/convolutional.py
Traceback (most recent call last):
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/models/image/mnist/convolutional.py"", line 339, in <module>
    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 43, in run
    sys.exit(main(sys.argv[:1] + flags_passthrough))
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/models/image/mnist/convolutional.py"", line 130, in main
    train_data_filename = maybe_download('train-images-idx3-ubyte.gz')
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/models/image/mnist/convolutional.py"", line 65, in maybe_download
    tf.gfile.MakeDirs(WORK_DIRECTORY)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/lib/io/file_io.py"", line 299, in recursive_create_dir
    pywrap_tensorflow.RecursivelyCreateDir(compat.as_bytes(dirname), status)
  File ""/usr/lib/python2.7/contextlib.py"", line 24, in __exit__
    self.gen.next()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/errors_impl.py"", line 469, in raise_exception_on_not_ok_status
    pywrap_tensorflow.TF_GetCode(status))
tensorflow.python.framework.errors_impl.PermissionDeniedError: data



how can i fix it?


the tensorflow install environment as follows:
ubuntu 16.04
python 2.7
numpy 1.11.2
six 1.10.0
protobuf 3.1.0

i installed tensorflow as follows:
    sudo -H pip install tensorflow



"
6392,Monitors (contrib) documentation,The monitors (contrib) documentation (https://www.tensorflow.org/api_docs/python/contrib.learn.monitors) does not appear to have been deployed properly.
6391,tf.sparse_tensor_to_dense does not have a gradient,"Differentiating `tf.sparse_tensor_to_dense` and also `tf.sparse_to_dense` returns `None`. At the same time, a hacky way of converting a sparse tensor to a dense tensor by using `tf.sparse_add` works. Please see the code below:

```python 
indices = tf.placeholder(tf.int64, (None, 2))
values = tf.placeholder(tf.float32, (None,))
sparse_tensor = tf.SparseTensor(indices, values, (5, 7))
dense_tensor1 = tf.sparse_tensor_to_dense(sparse_tensor)
dense_tensor2 = tf.sparse_add(tf.zeros((5, 7)), sparse_tensor)
sum1 = tf.reduce_sum(dense_tensor1)
sum2 = tf.reduce_sum(dense_tensor2)
print tf.gradients(sum1, values)
>>> [None]
print tf.gradients(sum2, values)
>>> [tf.Tensor ...]
```



### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?

Didn't find anything.

### Environment info

1. A link to the pip package you installed:

pip install --user https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.11.0rc1-cp27-none-linux_x86_64.whl

2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`

0.11.0rc1

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)

Please see the code above. 
"
6390,Extract attention matrix during decoding,"It seems like it's not possible to access the attention weights during decoding since the attention() method in seq2seq_model isn't called during the forward step. Otherwise, is there another feature to allow for this, or was this intended?"
6389,[TensorFlow.org] Anchor Tag Incorrect Reference,"Nothing really serious but I noticed the link on `see Pip installation for Windows` on getting started doc body is using an anchor separated with dashes `#pip-installation-on-windows`  while the corresponding `id` uses underscores `#pip_installation_on_windows`.

For instance, the body anchor (which works on github) 
`#pip-installation-on-windows` 
and the right side nav-bar `Index` link, working normally, with underscores
`#pip_installation_on_windows`

I was going to submit a PR but changing to the latter breaks on github. "
6388,CTC TimeOrder argument inconsistency,"For example, here's signature for dynamicRNN:
```
tf.nn.dynamic_rnn(cell, inputs, sequence_length=None, initial_state=None, dtype=None, parallel_iterations=None, swap_memory=False, time_major=False, scope=None)
```

Here is for ctc_loss:
```
tf.nn.ctc_loss(labels, inputs, sequence_length, preprocess_collapse_repeated=False, ctc_merge_repeated=True, time_major=True)

```

There is the difference between default behavior for **time_major**? (Rest of CTC module is similar in behaving time first.) This is unintuitive and should be changed to batch first in whole CTC module by default to be in consistency with rest of tensorflow library. (Or make other function time first, as long as there's consensus). Conv1D similarly puts batch dimension first, than time one. (Also did other of labels and inputs arguments have changed in ctc_loss between 0.11 and 0.12?)

In enforcing consistency developers using this library have less on their mental workload and enhancing productivity."
6386,Dense CRF implemenation,Is there an easy way to implement or use the dense CRF within tensorflow.  More spesifically i would love to train my network with dens CRF. You can see more information about dense CRF from this paper.[DenseCRF poster ](http://vladlen.info/papers/densecrf-poster.pdf). You can see C++ implementation form here: [Dense CRF C++](https://github.com/lucasb-eyer/pydensecrf/tree/d824b89ee3867bca3e90b9f04c448f1b41821524/pydensecrf/densecrf/src). Is there a way to include this in tensorflow and built with it? 
6385,Unable to build Android Example App using Bazel on Windows,"### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?
https://github.com/tensorflow/tensorflow/issues/6101
https://github.com/tensorflow/tensorflow/issues/6383
http://stackoverflow.com/questions/40978859/creating-simple-android-app-using-android-studio-and-tensorflow

### Environment info
Operating System: Windows

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):
Cuda 8.0
cuDNN 5.0

If installed from source, provide 
1. The commit hash (`git rev-parse HEAD`)
I downloaded the latest ZIP on 18 Dec 2016. Sorry, I have no idea how to get the version.

2. The output of `bazel version`
Build label: 0.4.2
Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Wed Dec 7 18:47:13 2016 (1481136433)
Build timestamp: 1481136433
Build timestamp as int: 1481136433

My goal is to build an Android App which loads pre-trained TensorFlow model and runs it on an Android device. I am working on Android Studio on Windows. Unfortunately using Android Studio on Linux is currently not an option.

Following previous advice from this forum, I am trying to build an Android example using Bazel on Windows. 
I've successfully installed Bazel using Chocolatey.
Following the build instructions, I changed the SDK and NDK paths in WORKSPACE file and ran:
**bazel build //tensorflow/examples/android:tensorflow_demo**

So far I did the following to fix errors:
1) copied aapt.exe to aapt, zipalign.exe to zipalign, since their name is different on Windows/Linux
2) installed using pacman gcc 

But I am stuck again. I am getting the following error which I have no idea how to fix:

```
ERROR: C:/Users/Andrey/AppData/Local/Temp/_bazel_Andrey/gd3-gSwg/external/protobuf/BUILD:73:1: C++ compilation of rule '@protobuf//:protobuf_lite' failed: arm-linux-androideabi-gcc failed: error executing command external/androidndk/ndk/toolchains/arm-linux-androideabi-4.9/prebuilt/windows-x86_64/bin/arm-linux-androideabi-gcc -fstack-protector-strong -fpic -ffunction-sections -funwind-tables ... (remaining 44 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.
external/protobuf/src/google/protobuf/stubs/structurally_valid.cc:588:1: fatal error: opening dependency file bazel-out/android-arm-linux-androideabi-4.9-v7a-gnu-libstdcpp-fastbuild/bin/external/protobuf/_objs/protobuf_lite/external/protobuf/src/google/protobuf/stubs/structurally_valid.d: No such file or directory
 }  // namespace google
 ^
compilation terminated.
ERROR: C:/Tools/tensorflow-master/tensorflow/examples/android/BUILD:58:1: output 'tensorflow/examples/android/tensorflow_demo_symbols/R.txt' was not created.
ERROR: C:/Tools/tensorflow-master/tensorflow/examples/android/BUILD:58:1: output 'tensorflow/examples/android/tensorflow_demo.srcjar' was not created.
ERROR: C:/Tools/tensorflow-master/tensorflow/examples/android/BUILD:58:1: output 'tensorflow/examples/android/proguard/tensorflow_demo/_tensorflow_demo_proguard.cfg' was not created.
ERROR: C:/Tools/tensorflow-master/tensorflow/examples/android/BUILD:58:1: output 'tensorflow/examples/android/tensorflow_demo_processed_manifest/AndroidManifest.xml' was not created.
ERROR: C:/Tools/tensorflow-master/tensorflow/examples/android/BUILD:58:1: output 'tensorflow/examples/android/tensorflow_demo_files/resource_files.zip' was not created.
ERROR: C:/Tools/tensorflow-master/tensorflow/examples/android/BUILD:58:1: output 'tensorflow/examples/android/tensorflow_demo.ap_' was not created.
ERROR: C:/Users/Andrey/AppData/Local/Temp/_bazel_Andrey/gd3-gSwg/external/protobuf/BUILD:73:1: output 'external/protobuf/_objs/protobuf_lite/external/protobuf/src/google/protobuf/stubs/stringprintf.o' was not created.
ERROR: C:/Users/Andrey/AppData/Local/Temp/_bazel_Andrey/gd3-gSwg/external/protobuf/BUILD:73:1: output 'external/protobuf/_objs/protobuf_lite/external/protobuf/src/google/protobuf/arenastring.o' was not created.
ERROR: C:/Users/Andrey/AppData/Local/Temp/_bazel_Andrey/gd3-gSwg/external/protobuf/BUILD:113:1: output 'external/protobuf/_objs/protobuf/external/protobuf/src/google/protobuf/io/strtod.o' was not created.
ERROR: C:/Users/Andrey/AppData/Local/Temp/_bazel_Andrey/gd3-gSwg/external/protobuf/BUILD:73:1: output 'external/protobuf/_objs/protobuf_lite/external/protobuf/src/google/protobuf/repeated_field.o' was not created.
Target //tensorflow/examples/android:tensorflow_demo failed to build
Use --verbose_failures to see the command lines of failed build steps.
INFO: Elapsed time: 4.722s, Critical Path: 1.16s

```
1. Please advice how to proceed?
2. Isn't there an easier way to achieve what I want? I just need pre-built TensorFlow binaries for Android Studio on Windows, to build an example application.  So far I found only pre-built Python distribution and Bazel installation on Windows
"
6384,Error in einsum with unspecified dimensions,"Code:


    import tensorflow as tf
    
    x = tf.placeholder(dtype=tf.int32)
    
    A = tf.random_normal([13, x, 512])
    B = tf.random_normal([512, 3])
    C = tf.einsum('ijk,kl->ijl', A, B)
    
    with tf.Session() as sess:
        print(sess.run(C, {x: 7}))

Output:

    Traceback (most recent call last):
      File ""/home/noam/code/test/test_einsum.py"", line 7, in <module>
        C = tf.einsum('ijk,kl->ijl', A, B)
      File ""/home/noam/miniconda3/envs/ml/lib/python3.5/site-packages/tensorflow/python/ops/special_math_ops.py"", line 212, in einsum
        axes_to_sum)
      File ""/home/noam/miniconda3/envs/ml/lib/python3.5/site-packages/tensorflow/python/ops/special_math_ops.py"", line 341, in _einsum_reduction
        product = _reshape_if_necessary(product, uncompacted_shape)
      File ""/home/noam/miniconda3/envs/ml/lib/python3.5/site-packages/tensorflow/python/ops/special_math_ops.py"", line 366, in _reshape_if_necessary
        return array_ops.reshape(tensor, new_shape)
      File ""/home/noam/miniconda3/envs/ml/lib/python3.5/site-packages/tensorflow/python/ops/gen_array_ops.py"", line 2448, in reshape
        name=name)
      File ""/home/noam/miniconda3/envs/ml/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py"", line 493, in apply_op
        raise err
      File ""/home/noam/miniconda3/envs/ml/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py"", line 490, in apply_op
        preferred_dtype=default_dtype)
      File ""/home/noam/miniconda3/envs/ml/lib/python3.5/site-packages/tensorflow/python/framework/ops.py"", line 669, in convert_to_tensor
        ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
      File ""/home/noam/miniconda3/envs/ml/lib/python3.5/site-packages/tensorflow/python/framework/constant_op.py"", line 176, in _constant_tensor_conversion_function
        return constant(v, dtype=dtype, name=name)
      File ""/home/noam/miniconda3/envs/ml/lib/python3.5/site-packages/tensorflow/python/framework/constant_op.py"", line 165, in constant
        tensor_util.make_tensor_proto(value, dtype=dtype, shape=shape, verify_shape=verify_shape))
      File ""/home/noam/miniconda3/envs/ml/lib/python3.5/site-packages/tensorflow/python/framework/tensor_util.py"", line 441, in make_tensor_proto
        tensor_proto.string_val.extend([compat.as_bytes(x) for x in proto_values])
      File ""/home/noam/miniconda3/envs/ml/lib/python3.5/site-packages/tensorflow/python/framework/tensor_util.py"", line 441, in <listcomp>
        tensor_proto.string_val.extend([compat.as_bytes(x) for x in proto_values])
      File ""/home/noam/miniconda3/envs/ml/lib/python3.5/site-packages/tensorflow/python/util/compat.py"", line 65, in as_bytes
        (bytes_or_text,))
    TypeError: Expected binary or unicode string, got 13

Using Tensorflow version 0.12.0-rc0, also tested and fails the same way on 0.12.0-rc1."
6383,Cannot build Android example on Windows using Bazel,"### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?
https://github.com/tensorflow/tensorflow/issues/6101
http://stackoverflow.com/questions/40978859/creating-simple-android-app-using-android-studio-and-tensorflow

### Environment info
Operating System: Windows

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):
Cuda 8.0
cuDNN 5.0

If installed from source, provide 
1. The commit hash (`git rev-parse HEAD`)
I downloaded the latest ZIP on 18 Dec 2016. Sorry, I have no idea how to get the version.

2. The output of `bazel version`
Build label: 0.4.2
Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Wed Dec 7 18:47:13 2016 (1481136433)
Build timestamp: 1481136433
Build timestamp as int: 1481136433

I am trying to build an Android example using Bazel on Windows. 
I've successfully installed Bazel using Chocolatey.
Following the build instructions, I need to change the SDK and NDK paths in WORKSPACE file and run:

**bazel build //tensorflow/examples/android:tensorflow_demo**

I am having trouble with configuring the WORKSPACE file. I need to uncomment the Android lines and add the paths.  However, no matter what I try, I get an error.

I've tried:
**
1. path = ""C:/Users/Andrey/AppData/Local/Android/sdk""
2. path = ""/C/Users/Andrey/AppData/Local/Android/sdk""
3. path = ""C:\Users\Andrey\AppData\Local\Android\sdk""
4. path = ""C:\\Users\\Andrey\\AppData\\Local\\Android\\sdk""**

For 1,2,4 I am getting:

ERROR: C:/Tools/tensorflow-master/WORKSPACE:3:1: indentation error.
ERROR: error loading package 'external': Failed to parse WORKSPACE file.
INFO: Elapsed time: 0.317s

For 3 I am getting:
ERROR: C:/Tools/tensorflow-master/WORKSPACE:9:12: escape sequence not implemented: \U.
ERROR: C:/Tools/tensorflow-master/WORKSPACE:14:10: escape sequence not implemented: \U.
ERROR: C:/Tools/tensorflow-master/WORKSPACE:3:1: indentation error.
ERROR: error loading package 'external': Failed to parse WORKSPACE file.
INFO: Elapsed time: 0.309s

There is a hint that it is related to indentation, but I could not find anything problematic.
I am attaching an example file for (1)
[WORKSPACE_1.txt](https://github.com/tensorflow/tensorflow/files/659363/WORKSPACE_1.txt)
_(Note: I change the extension to .txt since I could not upload the original file.)_


Any idea?
"
6382,contrib\cmake: how properly depend on generated tensorflow .lib,"Used contrib\cmake ( https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/cmake ) on Windows 10 64bit and VS 2015 64bit to build tensorflow  for C++.

Opened generated tf_tutorials_example_trainer.vcxproj  in VS Release x64 - runs VERY GOOD, but rebuilds whole tensorflow every time i hit play! Tried Build->Configuration Manager->Uncheck projects that i don't want to always build - errors (what projects i need to keep checked to build only tf_tutorials_example_trainer.vcxproj?).

How to depend on tensorflow statically (or at least prevent long build)?

Failed attempts: 
```
Created new VS console project Release x64 (to prevent full rebuilds). 
Used step-by-step build https://gist.github.com/derofim/b4f150da1269b81af8d12744df730708
Added tensorflow include dirs.
Added .lib files:
Release\tf_protos_cc.lib
protobuf\src\protobuf\Release\libprotobuf.lib
Used same flags as in example project.

Error: No session factory registered for the given session options

Tried solutions:
/WHOLEARCHIVE as in https://msdn.microsoft.com/en-us/library/mt732963.aspx - LNK1000: Internal error during IncrBuildImage
/OPT:NOREF - no effect
/FORCE:MULTIPLE  - no effect
 /INCLUDE - what to place here for force inclusion of unused symbols? May it help?
```"
6381,Discussion Online Expanding the Number of Distributed Training Workers ,"Tensorflow distributed training adds a new feature:
When we use the distributed tensorflow training task, if the number of workers is too small to start, but not very good convergence. . Especially when used in conjunction with k8s, then tensorflow should support the online expansion of the current number of workers training tasks.

My idea is: Use python interface, notify the ps server, the new worker task_index and worker addr. such as:

We pre-start the cluster as follows:
# On ps0.example.com:
$ Python trainer.py \
     --ps_hosts = ps0.example.com: 2222, ps1.example.com: 2222 \
     --worker_hosts = worker0.example.com: 2222, worker1.example.com: 2222 \
     --job_name = ps --task_index = 0
# On ps1.example.com:
$ Python trainer.py \
     --ps_hosts = ps0.example.com: 2222, ps1.example.com: 2222 \
     --worker_hosts = worker0.example.com: 2222, worker1.example.com: 2222 \
     --job_name = ps --task_index = 1
# On worker0.example.com:
$ Python trainer.py \
     --ps_hosts = ps0.example.com: 2222, ps1.example.com: 2222 \
     --worker_hosts = worker0.example.com: 2222, worker1.example.com: 2222 \
     --job_name = worker --task_index = 0
# On worker1.example.com:
$ Python trainer.py \
     --ps_hosts = ps0.example.com: 2222, ps1.example.com: 2222 \
     --worker_hosts = worker0.example.com: 2222, worker1.example.com: 2222 \
     --job_name = worker --task_index = 1


We started the original two ps server ,,, two workers. .
Now let's add a third worker


Import tensorflow as tf
Def main (_):
    With tf.Session ('grpc: //ps0.example.com:2222') as sess:
        Sess.add_onlineworker (2, 'worker2.example.com: 2222')

    With tf.Session ('grpc: //ps1.example.com:2222') as sess:
        Sess.add_onlineworker (2, 'worker2.example.com: 2222')

If name == ""main"":
    Tf.app.run ()

Just run this python script, and then start worker2.
Worker2 startup script:
$ Python trainer.py
     --ps_hosts = ps0.example.com: 2222, ps1.example.com: 2222
    --worker_hosts = worker0.example.com: 2222, worker1.example.com: 2222,
     --worker2.example.com:2222 --job_name = worker --task_index = 2

At this point you should be able to see the worker2 has started training.

If ps0 or ps1 restart, it should be added worker2:
$ Python trainer.py
     --ps_hosts = ps0.example.com: 2222, ps1.example.com: 2222
    --worker_hosts = worker0.example.com: 2222, worker1.example.com: 2222,
     --worker2.example.com:2222 --job_name = ps --task_index = 0


The design idea is as follows:
1. Increase the number of workers online, only need to notify all of the ps server can be.
2. Through the use of the python session interface, you can connect a different ps server, and then send an increase in worker instructions can be given to them.



I've done this at https://github.com/ipdcode/tensorflow.

Welcome to the official google and we discuss to see if there is a need to increase this feature.




"
6379,Inconsistency in parameter naming,"```
tf.nn.conv1d(value, filters, stride, padding, use_cudnn_on_gpu=None, data_format=None, name=None)
tf.nn.conv2d(input, filter, strides, padding, use_cudnn_on_gpu=None, data_format=None, name=None)
tf.nn.conv3d(input, filter, strides, padding, name=None)
```

There's discrepancy between parameter naming between conv1d and 2,3d counterparts. Firstly value vs input, and then singular vs plural filter(s) (singular would be correct as in 2d/3s case since function accepts only single filter if I understood documentation correctly.)"
6378,WhereOp: Race condition between counting the number of true elements and writing them,"I have the same problem as issue #4033 and [tensorflow/models#486](https://github.com/tensorflow/models/issues/486) happening to me in my own project with the nightly wheel. It is running fine on CPU, the problem only happens on GPU (titan x pascal).

The code that's causing the problem is this:
`pair_idxs = tf.where(tf.greater_equal(iou, params.thresh))`
(iou is a tensor, params.thresh is a python float)

WIth the error message: 
```
InvalidArgumentError (see above for traceback): WhereOp: Race condition between counting the number of true elements and writing them.  When counting, saw 31641 elements; but when writing their indices, saw 187 elements.
         [[Node: Where = Where[_device=""/job:localhost/replica:0/task:0/cpu:0""](GreaterEqual/_25)]]
```

Cuda:
```
-rw-r--r-- 1 foo bar   52M Dec  8 20:06 libcublas_device.a
lrwxrwxrwx 1 foo bar    16 Dec  8 20:06 libcublas.so -> libcublas.so.8.0
lrwxrwxrwx 1 foo bar    19 Dec  8 20:07 libcublas.so.8.0 -> libcublas.so.8.0.45
-rwxr-xr-x 1 foo bar   40M Dec  8 20:06 libcublas.so.8.0.45
-rw-r--r-- 1 foo bar   46M Dec  8 20:07 libcublas_static.a
-rw-r--r-- 1 foo bar  546K Dec  8 20:07 libcudadevrt.a
lrwxrwxrwx 1 foo bar    16 Dec  8 20:06 libcudart.so -> libcudart.so.8.0
lrwxrwxrwx 1 foo bar    19 Dec  8 20:07 libcudart.so.8.0 -> libcudart.so.8.0.44
-rwxr-xr-x 1 foo bar  406K Dec  8 20:06 libcudart.so.8.0.44
-rw-r--r-- 1 foo bar  757K Dec  8 20:07 libcudart_static.a
lrwxrwxrwx 1 foo bar    15 Dec  8 20:06 libcufft.so -> libcufft.so.8.0
lrwxrwxrwx 1 foo bar    18 Dec  8 20:07 libcufft.so.8.0 -> libcufft.so.8.0.44
-rwxr-xr-x 1 foo bar  140M Dec  8 20:06 libcufft.so.8.0.44
-rw-r--r-- 1 foo bar  124M Dec  8 20:07 libcufft_static.a
lrwxrwxrwx 1 foo bar    16 Dec  8 20:06 libcufftw.so -> libcufftw.so.8.0
lrwxrwxrwx 1 foo bar    19 Dec  8 20:07 libcufftw.so.8.0 -> libcufftw.so.8.0.44
-rwxr-xr-x 1 foo bar  466K Dec  8 20:06 libcufftw.so.8.0.44
-rw-r--r-- 1 foo bar   42K Dec  8 20:07 libcufftw_static.a
lrwxrwxrwx 1 foo bar    17 Dec  8 20:06 libcuinj64.so -> libcuinj64.so.8.0
lrwxrwxrwx 1 foo bar    20 Dec  8 20:06 libcuinj64.so.8.0 -> libcuinj64.so.8.0.44
-rwxr-xr-x 1 foo bar  6.2M Dec  8 20:06 libcuinj64.so.8.0.44
-rw-r--r-- 1 foo bar  1.6M Dec  8 20:07 libculibos.a
lrwxrwxrwx 1 foo bar    16 Dec  8 20:06 libcurand.so -> libcurand.so.8.0
lrwxrwxrwx 1 foo bar    19 Dec  8 20:07 libcurand.so.8.0 -> libcurand.so.8.0.44
-rwxr-xr-x 1 foo bar   57M Dec  8 20:07 libcurand.so.8.0.44
-rw-r--r-- 1 foo bar   57M Dec  8 20:06 libcurand_static.a
lrwxrwxrwx 1 foo bar    18 Dec  8 20:06 libcusolver.so -> libcusolver.so.8.0
lrwxrwxrwx 1 foo bar    21 Dec  8 20:07 libcusolver.so.8.0 -> libcusolver.so.8.0.44
-rwxr-xr-x 1 foo bar   52M Dec  8 20:06 libcusolver.so.8.0.44
-rw-r--r-- 1 foo bar   22M Dec  8 20:07 libcusolver_static.a
lrwxrwxrwx 1 foo bar    18 Dec  8 20:07 libcusparse.so -> libcusparse.so.8.0
lrwxrwxrwx 1 foo bar    21 Dec  8 20:06 libcusparse.so.8.0 -> libcusparse.so.8.0.44
-rwxr-xr-x 1 foo bar   41M Dec  8 20:07 libcusparse.so.8.0.44
-rw-r--r-- 1 foo bar   50M Dec  8 20:06 libcusparse_static.a
```

cuDNN:
```
lrwxrwxrwx 1 foo bar  13 Jul 27 07:55 libcudnn.so -> libcudnn.so.5
lrwxrwxrwx 1 foo bar  17 Jul 27 07:55 libcudnn.so.5 -> libcudnn.so.5.1.5
-rwxr-xr-x 1 foo bar 76M Jul 27 07:53 libcudnn.so.5.1.5
-rw-r--r-- 1 foo bar 67M Jul 27 07:53 libcudnn_static.a
```

`tenserflow.__version__: 0.12.head`

"
6377,error getting gradient of `tf.nn.crelu` (concat_v2 along axis -1),"I am on MacOS Sierra with CPU only nightly. 
tf.__git_version__ is 0.12.0-rc0-1156-g8c18a00-dirty.

The error comes from the gradient calculation in concat_v2 when axis = -1 is used to get the last dimension.  I could not find axis=-1 documentation for concat_v2 but that is how crelu is implemented.  

Concat_v2 along last dimension as a positive int works fine.  The forward pass with axis = -1 also works fine, it is just getting a gradient that gives an error.

Reproduce with:

    import tensorflow as tf

    inputs = tf.random_normal([64, 32,32, 3])
    inputs2 = tf.random_normal([64, 32,32, 3])
    hidden = tf.concat_v2([inputs, inputs2], axis=-1)  # axis = 3 works fine
    grad = tf.gradients(hidden, [inputs])

    with tf.Session() as sess:
	print( sess.run(grad))

Gives error:

> ...which was originally created as op u'concat_v2', defined at:
  File ""crelu.py"", line 5, in <module>
    hidden = tf.concat_v2([inputs, inputs2], axis=-1)
  File ""/Users/mikowals/projects/tensorflow/lib/python2.7/site-packages/tensorflow/python/ops/array_ops.py"", line 1062, in concat_v2
    name=name)
  File ""/Users/mikowals/projects/tensorflow/lib/python2.7/site-packages/tensorflow/python/ops/gen_array_ops.py"", line 498, in _concat_v2
    name=name)
  File ""/Users/mikowals/projects/tensorflow/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py"", line 763, in apply_op
    op_def=op_def)
  File ""/Users/mikowals/projects/tensorflow/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 2389, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/Users/mikowals/projects/tensorflow/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 1264, in __init__
    self._traceback = _extract_stack()

>InvalidArgumentError (see above for traceback): Concat dim is out of range: -1 vs. 4
	 [[Node: gradients/concat_v2_grad/ConcatOffset = ConcatOffset[N=2, _device=""/job:localhost/replica:0/task:0/cpu:0""](concat_v2/axis, gradients/concat_v2_grad/Shape, gradients/concat_v2_grad/Shape_1)]]
"
6374,BUG when trainning with multiple ps-server,"I post a issue previous https://github.com/tensorflow/tensorflow/issues/6326

The original problem is solved by @yaroslavvb  with add `sharded=True` to Saver's __init__ .

#### BUT , One more problem occurs: 

* when I training with 5 workers and **m (m=1)** ps-server, then training process works well.
* BUT when training with 5 workers and **m (m>1)** ps-servers, then training process crash with error `NotFoundError (see above for traceback): ./supervisor/model.ckpt-0_temp_994ae96906954e838fc2f3481ce8f296/part-00001-of-00002.data-00000-of-00001`

It seems that when have multiple ps-servers , the checkpoint-save has some weird bugs.

The detail error:
```
Traceback (most recent call last):
  File ""distributed_deepcake.py"", line 441, in <module>
    exit(1)
  File ""/home/serving/anaconda2/lib/python2.7/contextlib.py"", line 24, in __exit__
    self.gen.next()
  File ""/home/serving/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/supervisor.py"", line 974, in managed_session
    self.stop(close_summary_writer=close_summary_writer)
  File ""/home/serving/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/supervisor.py"", line 802, in stop
    stop_grace_period_secs=self._stop_grace_secs)
  File ""/home/serving/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/coordinator.py"", line 386, in join
    six.reraise(*self._exc_info_to_raise)
  File ""/home/serving/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/coordinator.py"", line 296, in stop_on_exception
    yield
  File ""/home/serving/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/coordinator.py"", line 487, in run
    self.run_loop()
  File ""/home/serving/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/supervisor.py"", line 1069, in run_loop
    global_step=self._sv.global_step)
  File ""/home/serving/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 1323, in save
    {self.saver_def.filename_tensor_name: checkpoint_file})
  File ""/home/serving/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 766, in run
    run_metadata_ptr)
  File ""/home/serving/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 964, in _run
    feed_dict_string, options, run_metadata)
  File ""/home/serving/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 1014, in _do_run
    target_list, options, run_metadata)
  File ""/home/serving/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 1034, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.NotFoundError: ./supervisor/distributed_img0_uid_extra-ftrl-lr0.01-fs30000000-b1000-u63.31.31.15/model.ckpt-0_temp_cde50a9b175b4ca596e757677ce5d86c/part-00004-of-00006.data-00000-of-00001
         [[Node: save/SaveV2_4 = SaveV2[dtypes=[DT_INT32], _device=""/job:ps/replica:0/task:2/cpu:0""](save/ShardedFilename_4, save/SaveV2_4/tensor_names, save/SaveV2_4/shape_and_slices, global_step)]]
         [[Node: save/Identity_S197 = _Recv[client_terminated=false, recv_device=""/job:worker/replica:0/task:0/cpu:0"", send_device=""/job:ps/replica:0/task:2/cpu:0"", send_device_incarnation=-6527834651342755590, tensor_name=""edge_107_save/Identity"", tensor_type=DT_STRING, _device=""/job:worker/replica:0/task:0/cpu:0""]()]]

Caused by op u'save/SaveV2_4', defined at:
  File ""distributed_deepcake.py"", line 293, in <module>
    saver = tf.train.Saver(max_to_keep = 2, sharded=True)
  File ""/home/serving/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 1000, in __init__
    self.build()
  File ""/home/serving/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 1030, in build
    restore_sequentially=self._restore_sequentially)
  File ""/home/serving/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 618, in build
    save_tensor = self._AddShardedSaveOps(filename_tensor, per_device)
  File ""/home/serving/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 314, in _AddShardedSaveOps
    return self._AddShardedSaveOpsForV2(filename_tensor, per_device)
  File ""/home/serving/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 288, in _AddShardedSaveOpsForV2
    sharded_saves.append(self._AddSaveOps(sharded_filename, saveables))
  File ""/home/serving/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 229, in _AddSaveOps
    save = self.save_op(filename_tensor, saveables)
  File ""/home/serving/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 172, in save_op
    tensors)
  File ""/home/serving/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/gen_io_ops.py"", line 552, in save_v2
    tensors=tensors, name=name)
  File ""/home/serving/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py"", line 759, in apply_op
    op_def=op_def)
  File ""/home/serving/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 2240, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/home/serving/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 1128, in __init__
    self._traceback = _extract_stack()

NotFoundError (see above for traceback): ./supervisor/distributed_img0_uid_extra-ftrl-lr0.01-fs30000000-b1000-u63.31.31.15/model.ckpt-0_temp_cde50a9b175b4ca596e757677ce5d86c/part-00004-of-00006.data-00000-of-00001
         [[Node: save/SaveV2_4 = SaveV2[dtypes=[DT_INT32], _device=""/job:ps/replica:0/task:2/cpu:0""](save/ShardedFilename_4, save/SaveV2_4/tensor_names, save/SaveV2_4/shape_and_slices, global_step)]]
         [[Node: save/Identity_S197 = _Recv[client_terminated=false, recv_device=""/job:worker/replica:0/task:0/cpu:0"", send_device=""/job:ps/replica:0/task:2/cpu:0"", send_device_incarnation=-6527834651342755590, tensor_name=""edge_107_save/Identity"", tensor_type=DT_STRING, _device=""/job:worker/replica:0/task:0/cpu:0""]()]]
```

### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?
Only find one issue and it's myself . https://github.com/tensorflow/tensorflow/issues/6326

### Environment info
Operating System:
centos 6.5 ,glibc 2.17, gcc6.2, Python 2.7.12, `tensorflow newest version 0.12rc1 with cpu`

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)
```
with tf.device(tf.train.replica_device_setter(
        worker_device=""/job:worker/task:%d"" % FLAGS.task_index,
        cluster=cluster)):
    # Read TFRecords files for training
    filename_queue = tf.train.string_input_producer(
        tf.train.match_filenames_once(FLAGS.train),
        num_epochs=epoch_number)
    serialized_example = read_and_decode(filename_queue)
    batch_serialized_example = tf.train.shuffle_batch(
        [serialized_example],
        batch_size=batch_size,
        num_threads=thread_number,
        capacity=capacity,
        min_after_dequeue=min_after_dequeue)
    features = tf.parse_example(
        batch_serialized_example,
        features={
            ""label"": tf.FixedLenFeature([], tf.float32),
            ""ids"": tf.VarLenFeature(tf.int64),
            ""values"": tf.VarLenFeature(tf.float32),
        })
    batch_labels = features[""label""]
    batch_ids = features[""ids""]
    batch_values = features[""values""]

    # Read TFRecords file for validatioin
    validate_filename_queue = tf.train.string_input_producer(
        tf.train.match_filenames_once(FLAGS.eval),
        num_epochs=epoch_number)
    validate_serialized_example = read_and_decode(validate_filename_queue)
    validate_batch_serialized_example = tf.train.shuffle_batch(
        [validate_serialized_example],
        batch_size=validate_batch_size,
        num_threads=thread_number,
        capacity=capacity,
        min_after_dequeue=min_after_dequeue)
    validate_features = tf.parse_example(
        validate_batch_serialized_example,
        features={
            ""label"": tf.FixedLenFeature([], tf.float32),
            ""ids"": tf.VarLenFeature(tf.int64),
            ""values"": tf.VarLenFeature(tf.float32),
        })
    validate_batch_labels = features[""label""]
    validate_batch_ids = features[""ids""]
    validate_batch_values = features[""values""]
    logits = inference(batch_ids, batch_values)
    batch_labels = tf.to_int64(batch_labels)
    cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits,
                                                                   batch_labels)
    loss = tf.reduce_mean(cross_entropy, name='loss')

    print(""Use the optimizer: {}"".format(FLAGS.optimizer))

    optimizer = tf.train.FtrlOptimizer(learning_rate)

    global_step = tf.Variable(0, name='global_step', trainable=False)
    train_op = optimizer.minimize(loss, global_step=global_step)

    # Initialize saver and summary
    steps_to_validate = FLAGS.steps_to_validate
    init_op = tf.initialize_all_variables()

    saver = tf.train.Saver(max_to_keep = 2)
    keys_placeholder = tf.placeholder(""float"")
    keys = tf.identity(keys_placeholder)
    tf.add_to_collection(""inputs"", json.dumps({'key': keys_placeholder.name}))
    tf.add_to_collection(""outputs"", json.dumps({'key': keys.name,
                                                'softmax': inference_softmax.name,
                                                'prediction': inference_op.name}))

    summary_op = tf.merge_all_summaries()


sv = tf.train.Supervisor(is_chief=(FLAGS.task_index == 0),
                         logdir=""./supervisor/"",
                         init_op=init_op,
                         summary_op=summary_op,
                         saver=saver,
                         global_step=global_step,
                         save_model_secs=60)

with sv.managed_session(server.target) as sess:

    while not sv.should_stop():
        # Get coordinator and run queues to read data
        coord = tf.train.Coordinator()
        threads = tf.train.start_queue_runners(coord=coord, sess=sess)

        try:
            while not coord.should_stop():
                _, loss_value, step = sess.run([train_op, loss, global_step])

        except tf.errors.OutOfRangeError:
            print(""Done training after reading all data"")
        finally:
            coord.request_stop()

        coord.join(threads)
```
"
6370,Library not loaded: @rpath/libcudart.8.0.dylib but I have libcudart.7.5.dylib,"I have the following error when importing tensor flow (GPU OSX version);

```
ImportError: dlopen(/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/_pywrap_tensorflow.so, 10): Library not loaded: @rpath/libcudart.8.0.dylib
  Referenced from: /Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/tensorflow/python/_pywrap_tensorflow.so
  Reason: image not found
```

It looks to me like it is looking for `@rpath/libcudart.8.0.dylib` but in my `/usr/local/cuda/lib` I have `libcudart.7.5.dylib` and no 8.0. How do I redirect it?"
6369,error: conv3d_transpose layer,"The conv3d_transpose seems buggy

>>> import tensorflow as tf

>>> deconv3d = tf.nn.conv3d_transpose(tf.zeros((10,3,3,3,10), dtype=tf.float32), tf.zeros((4,4,4,8,10), dtype=tf.float32), output_shape=[10,6,6,6,8], strides=[1, 1, 1, 1, 1])

>>> deconv2d = tf.nn.conv2d_transpose(tf.zeros((10,3,3,10), dtype=tf.float32), tf.zeros((4,4,8,10), dtype=tf.float32), output_shape=[10,6,6,8], strides=[1, 1, 1, 1])

>>> deconv3d
<tf.Tensor 'conv3d_transpose:0' shape=(?, ?, ?, ?, ?) dtype=float32>

>>> deconv2d
<tf.Tensor 'conv2d_transpose:0' shape=(10, 6, 6, 8) dtype=float32>
"
6366,Make VLOG minimum level can be updated via environment,"I found inside c++ core implementation there're lots of verbose messages like:
```
    VLOG(1) << ""Direct session inter op parallelism threads: "" << num_threads;
```
They will be very helpful for developer to understand what happens internally and troubleshoot problems.

However I found in implementation, it doesn't look like works without changing the code. (Credit to @yaroslavvb for the solution, see discussion thread: https://groups.google.com/a/tensorflow.org/forum/#!topic/discuss/D0_3jG5_XRQ)
```
    // TODO(jeff): Define a proper implementation of VLOG_IS_ON
    #define VLOG_IS_ON(lvl) ((lvl) <= 0)

    #define VLOG(lvl)      \
        if (VLOG_IS_ON(lvl)) \
          ::tensorflow::internal::LogMessage(__FILE__, __LINE__, tensorflow::INFO)
```

It will be very helpful if we can update the minimum lvl via passing environment."
6365,Support of gradient for TF.MOD,"Hello there,

When I include `tf.mod` in my Graph, I have this error:

`LookupError: No gradient defined for operation 'RNN/while/LSTM/Mod' (op type: Mod)`

Will it be handled in the future?

Thanks!

References: https://www.tensorflow.org/api_docs/python/math_ops/arithmetic_operators#mod
Tensorflow version: `0.12.0-rc1`"
6363,User Contributed Tutorials,"It would be great if there was a section in the tensorflow.org website where the community could provide tutorials for new users. There are a lot of great tutorials in the web and having some on the tensorflow.org website would be very valuable for people just starting out. Thoughts?

Here is an example of what I would love to share:
https://bitbucket.org/hrojas/learn-tensorflow "
6362,error: stride must be less than or equal to kernel size,"I'm using TensorFlow 0.12.0rc0 for CPU. This version seems not support a stride less or equal to kernel size, so it reports this error. It works fine for GPU version"
6361,Using Multiple CPU Threads in an op,"Hi all,

I'm interested in using multithreading within a CPU op to increase speed. More specifically, I have some linear algebra code which, for batched matrix multiplies, is much faster than MKL (and probably Eigen).
I should be able to get the corresponding GPU version working without much trouble.

Currently my code uses OpenMP and SIMD pragmas which, as I understand it, don't play nicely with tensorflow at the moment. I've been digging through the documentation all day but haven't found any examples of a CPU op with multithreading (that isn't just calling eigen) which I can use.

Could anyone please point me in the right direction here?

Cheers!

### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?
#22 #1747 

### Environment info
Operating System: Ubuntu 16.04

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):
-rw-r--r-- 1 root root   558720 Sep 15 00:02 /usr/local/cuda-8.0/lib64/libcudadevrt.a
lrwxrwxrwx 1 root root       16 Sep 15 00:05 /usr/local/cuda-8.0/lib64/libcudart.so -> libcudart.so.8.0
lrwxrwxrwx 1 root root       19 Sep 15 00:05 /usr/local/cuda-8.0/lib64/libcudart.so.8.0 -> libcudart.so.8.0.44
-rw-r--r-- 1 root root   415432 Sep 15 00:02 /usr/local/cuda-8.0/lib64/libcudart.so.8.0.44
-rw-r--r-- 1 root root   775162 Sep 15 00:02 /usr/local/cuda-8.0/lib64/libcudart_static.a
lrwxrwxrwx 1 root root       13 Dec 15 12:42 /usr/local/cuda-8.0/lib64/libcudnn.so -> libcudnn.so.5
lrwxrwxrwx 1 root root       17 Dec 15 12:42 /usr/local/cuda-8.0/lib64/libcudnn.so.5 -> libcudnn.so.5.1.5
-rwxr-xr-x 1 root root 79337624 Dec 15 12:42 /usr/local/cuda-8.0/lib64/libcudnn.so.5.1.5
-rw-r--r-- 1 root root 69756172 Dec 15 12:42 /usr/local/cuda-8.0/lib64/libcudnn_static.a

If installed from source, provide 

1. The commit hash (`git rev-parse HEAD`)
git rev-parse HEAD
dbe5e17e2ed307e86e1a6e79e558ec3e335d46fc

2. The output of `bazel version`
bazel version
Build label: 0.4.2
Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Wed Dec 7 18:47:11 2016 (1481136431)
Build timestamp: 1481136431
Build timestamp as int: 1481136431

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)
N/A

### What other attempted solutions have you tried?
N/A

### Logs or other output that would be helpful
(If logs are large, please upload as attachment or provide link).
N/A"
6360,Locking mechanisms,"Especially when integrating TensorFlow into an exiting multi-threaded application, it's not always easy to use queues for synchronization. Currently, we must use Python locks to lock the `sess.run(...)` calls from different threads. Exposing a TensorFlow lock interface could allow to synchronize access only to needed values of the session:

```python
x = tf.placeholder(tf.float32, [None, 784])
y = tf.placeholder(tf.float32, [None, 10])
W = tf.Variable(tf.zeros([784, 10]))
b = tf.Variable(tf.zeros([10]))

lock = tf.Lock()
with lock:
  pred = tf.nn.softmax(tf.matmul(x, W) + b)
loss = -tf.reduce_mean(tf.reduce_sum(y * tf.log(pred), 1))
with lock:
  train_step = tf.train.GradientDescentOptimizer(0.5).minimize(loss)

def inference_thread():
  while True:
    # Generate data...
    sess.run(pred, data)

def training_thread():
  while True:
    # Generate data...
    sess.run(train_step, data)
```

Or simpler:

```python
with tf.Lock():
  W = tf.Variable(tf.zeros([784, 10]))
# ...
```"
6357,TF for Embedded Devices,"Has there been any effort to port the TensorFlow inference routines to lightweight cores commonly found in embedded devices (i.e. ARM Cortex M4F)?  Memory footprints are often small, but with efficient use of small datatypes, it seems that this could be fruitful.  Thanks."
6356,Build errors for libtensorflow_inference.so,"I am trying to build `libtensorflow_inference.so`, in order to run a TF model in an Android app.  I found the following command in issue #6166, however the command is failing.  I reported an earlier error message in that issue, but now the error message has changed and it fails completely.  
It is worth noting that I am able to compile the Inception demo app with no trouble (from inside Android Studio), so I think the full tool chain is functional.
I added the verbose option to try to troubleshoot the issue (not that it helped):

`$  bazel build //tensorflow/contrib/android:libtensorflow_inference.so    --crosstool_top=//external:android/crosstool    --host_crosstool_top=@bazel_tools//tools/cpp:toolchain    --cpu=armeabi-v7a --verbose_failures
`
I am running on MacOS (10.12.1) with TF0.12 (SHA=46b7b6).
Installed version of CUDA and cuDNN: None
Bazel Verion:
```
Build label: 0.4.2-homebrew
Build target: bazel-out/local-opt/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Thu Dec 8 03:17:26 2016 (1481167046)
Build timestamp: 1481167046
Build timestamp as int: 1481167046
```

Here is the error message:
```
WARNING: /Users/kevin/tensorflow/tensorflow/core/BUILD:779:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:avgpooling_op.h' directly. You should either move the file to this package or depend on an appropriate rule there.
WARNING: /Users/kevin/tensorflow/tensorflow/core/BUILD:779:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:bounds_check.h' directly. You should either move the file to this package or depend on an appropriate rule there.
WARNING: /Users/kevin/tensorflow/tensorflow/core/BUILD:779:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:cwise_ops.h' directly. You should either move the file to this package or depend on an appropriate rule there.
WARNING: /Users/kevin/tensorflow/tensorflow/core/BUILD:779:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:cwise_ops_common.h' directly. You should either move the file to this package or depend on an appropriate rule there.
<snip>
WARNING: /Users/kevin/tensorflow/tensorflow/core/BUILD:779:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/util/tensor_bundle:tensor_bundle.cc' directly. You should either move the file to this package or depend on an appropriate rule there.
WARNING: /Users/kevin/tensorflow/tensorflow/core/BUILD:779:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/util/tensor_bundle:tensor_bundle.h' directly. You should either move the file to this package or depend on an appropriate rule there.
INFO: Found 1 target...
ERROR: /Users/kevin/tensorflow/tensorflow/core/BUILD:163:1: C++ compilation of rule '//tensorflow/core:protos_all_cc' failed: sandbox-exec failed: error executing command 
  (cd /private/var/tmp/_bazel_kevin/a09094529daf7e22afa1fbacb9484a3a/bazel-sandbox/4c850042-6906-474b-9554-e958a1aadaeb-3/execroot/tensorflow && \
  exec env - \
    PATH=/Users/kevin/anaconda2/bin:/Users/kevin/anaconda/bin:/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin \
    TMPDIR=/var/folders/cm/1r6x6rbj7hn_51qvfjzj7nx80000gn/T/ \
  /usr/bin/sandbox-exec -f /private/var/tmp/_bazel_kevin/a09094529daf7e22afa1fbacb9484a3a/bazel-sandbox/4c850042-6906-474b-9554-e958a1aadaeb-3/sandbox.sb /bin/false -MD -MF bazel-out/stub_armeabi-v7a-fastbuild/bin/tensorflow/core/_objs/protos_all_cc/tensorflow/core/framework/device_attributes.pb.pic.d '-frandom-seed=bazel-out/stub_armeabi-v7a-fastbuild/bin/tensorflow/core/_objs/protos_all_cc/tensorflow/core/framework/device_attributes.pb.pic.o' -fPIC -iquote . -iquote bazel-out/stub_armeabi-v7a-fastbuild/genfiles -iquote external/protobuf -iquote bazel-out/stub_armeabi-v7a-fastbuild/genfiles/external/protobuf -iquote external/bazel_tools -iquote bazel-out/stub_armeabi-v7a-fastbuild/genfiles/external/bazel_tools -isystem external/protobuf/src -isystem bazel-out/stub_armeabi-v7a-fastbuild/genfiles/external/protobuf/src -isystem external/bazel_tools/tools/cpp/gcc3 -Wno-unknown-warning-option -Wno-unused-but-set-variable -Wno-sign-compare -c bazel-out/stub_armeabi-v7a-fastbuild/genfiles/tensorflow/core/framework/device_attributes.pb.cc -o bazel-out/stub_armeabi-v7a-fastbuild/bin/tensorflow/core/_objs/protos_all_cc/tensorflow/core/framework/device_attributes.pb.pic.o).
sandbox-exec: /bin/false: No such file or directory
Target //tensorflow/contrib/android:libtensorflow_inference.so failed to build
INFO: Elapsed time: 44.632s, Critical Path: 2.86s
```"
6355,TensorBoard command unable to handle the path properly in Windows,"If you try to save the graph in a specific path eg `C:\documents`
`writer = tf.train.SummaryWriter('C:/documents/my_graph', sess.graph)`

and try to show the graph with TensorBoard

`tensorboard --logdir=""C:/documents/my_graph""`

TensorBoard will not find any graph because is unable to load the path and looks always for the graph files in the default user path` C:\Users\andrew\mygraph\` if I run console as user or `C:\Windows\System32` if I run console as administrator. This is a bug and should be fixed.

Tensorflow version 0.12.0rc1 pip installation
OS: Windows 10 x64

Related Stackoverflow question
http://stackoverflow.com/questions/41157645/tensorflow-tensorboard-on-windows-shows-a-blank-page?noredirect=1#comment69557752_41157645"
6352,how to commit code to tensorflow??I ,"When using distributed tensorflow, once the start of the cluster task, you can not online expansion of the number of workers trained, I achieved this feature, would like to submit to tensorflow。。。

how do it?"
6351,What is login password in the jupyter notebook?,What is login password in the jupyter notebook?
6349,"compile tensorflow with option ""-xMIC-AVX512"" on INTEL XEON PHI PROCESSORS failed～～","Hi,All,Thanks for your time.
I'm guest of a server with INTEL XEON PHI PROCESSORS(KNL) with CentOS7.
I set my own env at first and compile bazel(0.3.2) and tensorflow(v0.9.0rc0) successfully(CC=gcc).
(1) I set my own env as follows(most of it):
export HOME=/home/guest
export HOME_USR=$HOME/usr
export JAVA_HOME=$HOME/jdk1.8.0_112
export PATH=$HOME/intel/bin:$HOME/bazel_bin:$HOME_USR/bin:$JAVA_HOME/bin:$PATH
export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar
export CPATH=$HOME_USR/include:$HOME/intel/include
export C_INCLUDE_PATH=$CPATH
export CPLUS_INCLUDE_PATH=$CPATH
export LIBRARY_PATH=$HOME_USR/lib:$HOME_USR/lib64:$HOME/intel/lib/intel64_lin_mic/
export LD_LIBRARY_PATH=$LIBRARY_PATH
export LD_RUN_PATH=$LIBRARY_PATH
export COMPILER_PATH=$PATH
export CC=gcc
export PKG_CONFIG_PATH=$HOME_USR/lib/pkgconfig:$PKG_CONFIG_PATH
export PERL5LIB=$HOME_USR
(2)bazel is OK:  
./compile.sh
(3)tensorflow is OK:   
./configure 
bazel build -c opt //tensorflow/tools/pip_package:build_pip_package
(4)Then the problem comes,I change the env CC=icpc , and run:
bazel build -c opt --copt=-xMIC-AVX512 //tensorflow/tools/pip_package:build_pip_package

1. ERROR: /home/guest/.cache/bazel/_bazel_guest/ac941aabf1be9475583be832ae449128/external/gif_archive/BUILD:6:1: C++ compilation of rule '@gif_archive//:gif' failed: icpc failed: error executing command 
2.   (cd /home/guest/.cache/bazel/_bazel_guest/ac941aabf1be9475583be832ae449128/execroot/tensorflow && \
3.   exec env - \
4.     LD_LIBRARY_PATH=/home/guest/usr/lib:/home/guest/usr/lib64:/home/guest/cuda/lib64:/home/guest/cuda/lib64:/home/guest/cudnn:/home/guest/intel/lib/intel64_lin_mic/ \
5.     PATH=/home/guest/intel/bin:/home/guest/bazel_bin:/home/guest/usr/bin:/home/guest/cuda/bin:/home/guest/jdk1.8.0_112/bin:/usr/lib64/mpich/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/home/guest/.local/bin:/home/guest/bin \
6.   /home/guest/intel/bin/icpc -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -Wall -Wl,-z,-relro,-z,now -B/home/guest/intel/bin -B/usr/bin -Wunused-but-set-parameter -fno-omit-frame-pointer -g0 -O2 -DNDEBUG -ffunction-sections -fdata-sections -g0 -MD -MF bazel-out/host/bin/external/gif_archive/_objs/gif/external/gif_archive/gif_font.d -iquote external/gif_archive -iquote bazel-out/host/genfiles/external/gif_archive -iquote external/bazel_tools -iquote bazel-out/host/genfiles/external/bazel_tools -isystem external/gif_archive -isystem bazel-out/host/genfiles/external/gif_archive -isystem external/bazel_tools/tools/cpp/gcc3 -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' -c external/gif_archive/gif_font.c -o bazel-out/host/bin/external/gif_archive/_objs/gif/external/gif_archive/gif_font.o): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 2.
7. icpc: command line warning #10006: ignoring unknown option '-Wno-builtin-macro-redefined'
8. Warning #2011: predefined meaning of ""__DATE__"" discarded
9. 
10. Warning #2011: predefined meaning of ""__TIMESTAMP__"" discarded
11. 
12. Warning #2011: predefined meaning of ""__TIME__"" discarded
13. 
14. external/gif_archive/gif_font.c(231): error: a value of type ""void *"" cannot be assigned to an entity of type ""char *""
15.       dup = malloc(strlen(legend)+1);
16.           ^
17. 
18. compilation aborted for external/gif_archive/gif_font.c (code 2)
19. Target //tensorflow/tools/pip_package:build_pip_package failed to build

(5)I've found a similar problem here :
https://github.com/tensorflow/tensorflow/issues/4775
but I don't know how to solve this problem?
I update bazel by ""git checkout tags/0.4.2"" under bazel, and try to ./compile.sh again(CC=icpc),but it doesn't work."
6348,Tensorflow library for python 3 not available from the suggested docker image,"I noticed that tensorflow is not available from the standard `gcr.io/tensorflow/tensorflow` docker image.

I spun a docker container:

    docker run -it --rm gcr.io/tensorflow/tensorflow bash

then I tried importing the Tensorflow from within python3:

```
root@dc7f436ca5e9:/notebooks# python3
Python 3.4.3 (default, Oct 14 2015, 20:28:29)
[GCC 4.8.4] on linux
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import tensorflow
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
ImportError: No module named 'tensorflow'
```

but the library is not available. Is this a bug or is this the intended feature? Does this mean I need to install tensorflow (for python3) myself with pip3 then in my own image? or maybe its a small bug?

### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?

http://stackoverflow.com/questions/41170610/what-is-the-correct-way-to-have-tensorflow-available-in-a-docker-container-or-do

### Environment info
Operating System: MAC OS X sierra 10.12.1 
"
6346,Windows 10 -> tensorflow-gpu -> TCC mode = Hangs forever,"Anybody getting this to work in windows while in TCC CUDA mode? Seems to work fine in WDDM driver mode but WDDM cripples performance. To replicate issue, run on machine with Tesla class GPU in TCC mode, then try to create a session (sess = tf.Session()). The python process consumes a CPU core indefinitely and the session is never created."
6345,Udacity LSTM: module 'tensorflow' has no attribute 'concat_v2',"### Environment info
Operating System: OSX 10.12.1


2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.
```
➜  ~ `python -c ""import tensorflow; print(tensorflow.__version__)""`.
zsh: command not found: 0.12.0-rc1.
```

I'm going through the udacity deep learning class and getting an error when evaluating

`logits = tf.nn.xw_plus_b(tf.concat_v2(outputs, 0), w, b)`

which was changed in https://github.com/tensorflow/tensorflow/commit/d4eb834824d79c6a64a3c4a1c4a88b434b73e63e#diff-e4eb32d9f7b7f06d7547050e1ce3d937

```
>>> import tensorflow
>>> tensorflow.__version__
'0.12.0-rc1'
>>> tensorflow.concat_v2
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
AttributeError: module 'tensorflow' has no attribute 'concat_v2'
>>> tensorflow.concat
<function concat at 0x10bc03730>
>>>
```

I installed and am running the latest release rc1 where `concat_v2` was added in https://github.com/tensorflow/tensorflow/commit/4564322e249017c030123b249451614bc2ff7658, has anyone else seen this?  Thanks in advance!



"
6343,0.12.0rc1 windows package for Python 3.5 (x64) does not include lib or include files,"I installed the 0.12.0rc1 tensorflow package for Python 3.5 (64 bit) on Windows 10.  

I started to try to add running trained models into an existing C++ software package, but the include and lib files specified by the documentation and found with `tensorflow.sysconfig.get_include()` and `.get_lib()` don't exist They return values:

```
In [5]: tensorflow.sysconfig.get_include()
Out[5]: 'e:\\python35\\lib\\site-packages\\tensorflow\\include'

In [6]: tensorflow.sysconfig.get_lib()
Out[6]: 'e:\\python35\\lib\\site-packages\\tensorflow\\core'
```

But these directories do not exist. I do not know if there is a problem with the package or the documentation."
6342,TypeError: Cannot create initializer for non-floating point type,"Operating System: Mac OS [10.11.6]

Installed version of CUDA and cuDNN: CUDA 8.0, cudnn-8.0-osx-x64-v5.1 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):
```
 8 lrwxr-xr-x  1 root    admin    13B Dec 15 13:34 /usr/local/cuda/lib/libcuda.1.dylib@ -> libcuda.dylib
    32 -rwxr-xr-x  1 root    wheel    13K Nov  3 22:09 /usr/local/cuda/lib/libcuda.dylib*
     8 lrwxr-xr-x  1 root    wheel    45B Nov  3 22:10 /usr/local/cuda/lib/libcudadevrt.a@ -> /Developer/NVIDIA/CUDA-8.0/lib/libcudadevrt.a
     8 lrwxr-xr-x  1 root    wheel    50B Nov  3 22:10 /usr/local/cuda/lib/libcudart.8.0.dylib@ -> /Developer/NVIDIA/CUDA-8.0/lib/libcudart.8.0.dylib
     8 lrwxr-xr-x  1 root    wheel    46B Nov  3 22:10 /usr/local/cuda/lib/libcudart.dylib@ -> /Developer/NVIDIA/CUDA-8.0/lib/libcudart.dylib
     8 lrwxr-xr-x  1 root    wheel    49B Nov  3 22:10 /usr/local/cuda/lib/libcudart_static.a@ -> /Developer/NVIDIA/CUDA-8.0/lib/libcudart_static.a
151304 -rwxr-xr-x@ 1 AmirHJ  admin    74M Jul 27 11:48 /usr/local/cuda/lib/libcudnn.5.dylib*
     8 lrwxr-xr-x  1 AmirHJ  admin    16B Jul 27 11:51 /usr/local/cuda/lib/libcudnn.dylib@ -> libcudnn.5.dylib
128152 -rw-r--r--@ 1 AmirHJ  admin    63M Jul 27 11:48 /usr/local/cuda/lib/libcudnn_static.a
```

If installed from binary pip package, provide:

1. A link to the pip package you installed: tensorflow-gpu==0.12.0rc1
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`. 0.12.0-rc1

Running [Text Classification Using Convolutional Neural Networks on Characters](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/learn/text_classification_character_cnn.py):

> python test.py
> I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcublas.dylib locally
> I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcudnn.dylib locally
> I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcufft.dylib locally
> I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcuda.1.dylib locally
> I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcurand.dylib locally
> WARNING:tensorflow:Using temporary folder as model directory: /var/folders/gy/035w5b717yn01k9qlwvtcp1h0000gn/T/tmpU1WjvQ
> WARNING:tensorflow:From test.py:105 in main.: calling fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.
> Instructions for updating:
> Estimator is decoupled from Scikit Learn interface by moving into
> separate class SKCompat. Arguments x, y and batch_size are only
> available in the SKCompat class, Estimator will only accept input_fn.
> Example conversion:
>   est = Estimator(...) -> est = SKCompat(Estimator(...))
> WARNING:tensorflow:From test.py:105 in main.: calling fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with y is deprecated and will be removed after 2016-12-01.
> Instructions for updating:
> Estimator is decoupled from Scikit Learn interface by moving into
> separate class SKCompat. Arguments x, y and batch_size are only
> available in the SKCompat class, Estimator will only accept input_fn.
> Example conversion:
>   est = Estimator(...) -> est = SKCompat(Estimator(...))
> Traceback (most recent call last):
>   File ""test.py"", line 121, in <module>
>     tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)
>   File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 43, in run
>     sys.exit(main(sys.argv[:1] + flags_passthrough))
>   File ""test.py"", line 105, in main
>     classifier.fit(x_train, y_train, steps=100)
>   File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/util/deprecation.py"", line 191, in new_func
>     return func(*args, **kwargs)
>   File ""/usr/local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py"", line 355, in fit
>     max_steps=max_steps)
>   File ""/usr/local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py"", line 699, in _train_model
>     train_ops = self._get_train_ops(features, labels)
>   File ""/usr/local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py"", line 1052, in _get_train_ops
>     return self._call_model_fn(features, labels, model_fn_lib.ModeKeys.TRAIN)
>   File ""/usr/local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/estimator.py"", line 1023, in _call_model_fn
>     model_fn_results = self._model_fn(features, labels)
>   File ""test.py"", line 59, in char_cnn_model
>     byte_list, N_FILTERS, FILTER_SHAPE1, padding='VALID')
>   File ""/usr/local/lib/python2.7/site-packages/tensorflow/contrib/framework/python/ops/arg_scope.py"", line 177, in func_with_args
>     return func(*args, **current_args)
>   File ""/usr/local/lib/python2.7/site-packages/tensorflow/contrib/layers/python/layers/layers.py"", line 840, in convolution
>     trainable=trainable)
>   File ""/usr/local/lib/python2.7/site-packages/tensorflow/contrib/framework/python/ops/arg_scope.py"", line 177, in func_with_args
>     return func(*args, **current_args)
>   File ""/usr/local/lib/python2.7/site-packages/tensorflow/contrib/framework/python/ops/variables.py"", line 244, in model_variable
>     caching_device=caching_device, device=device)
>   File ""/usr/local/lib/python2.7/site-packages/tensorflow/contrib/framework/python/ops/arg_scope.py"", line 177, in func_with_args
>     return func(*args, **current_args)
>   File ""/usr/local/lib/python2.7/site-packages/tensorflow/contrib/framework/python/ops/variables.py"", line 208, in variable
>     caching_device=caching_device)
>   File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py"", line 1024, in get_variable
>     custom_getter=custom_getter)
>   File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py"", line 850, in get_variable
>     custom_getter=custom_getter)
>   File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py"", line 346, in get_variable
>     validate_shape=validate_shape)
>   File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py"", line 331, in _true_getter
>     caching_device=caching_device, validate_shape=validate_shape)
>   File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py"", line 677, in _get_single_variable
>     expected_shape=shape)
>   File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/ops/variables.py"", line 224, in __init__
>     expected_shape=expected_shape)
>   File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/ops/variables.py"", line 327, in _init_from_args
>     initial_value(), name=""initial_value"", dtype=dtype)
>   File ""/usr/local/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py"", line 665, in <lambda>
>     shape.as_list(), dtype=dtype, partition_info=partition_info)
>   File ""/usr/local/lib/python2.7/site-packages/tensorflow/contrib/layers/python/layers/initializers.py"", line 120, in _initializer
>     raise TypeError('Cannot create initializer for non-floating point type.')
> TypeError: Cannot create initializer for non-floating point type."
6341,ImportError: No module named google.protobuf,"**Problem description**
This issue happens randomly. For same machine, same CPU,works randomly. I run it for 10 times, 6 times succeed, 4 times fail. Same code is running for every time. The code is 
```
import tensorflow as tf
# with tf.device('/cpu:0'):
a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')
b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')
c = tf.matmul(a, b)
with tf.Session(config=tf.ConfigProto(log_device_placement=True)) as sess:
	print sess.run(c)
```

**System information**
Information of cluster:
Basically our cluster is made of IBM Power System S822LC for commercial computing

    OS: Red Hat Enterprise Linux Server release 7.2 (Maipo)
    TF version: 0.10.0rc0
    protobuf: 3.0.0b2
    Python: 2.7.5

**Error**
```
>>> import os
>>> cwd = os.getcwd()
>>> cwd
'/gpfs/gpfs0/groups/duraisamy/shawnpan/test/script'
>>> import tensorflow
import tensorflow
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so.5.1.5 locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so.8.0 locally
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/gpfs/gpfs0/software/rhel72/packages/tensorflow_gpu/tensorflow/__init__.py"", line 23, in <module>
    from tensorflow.python import *
  File ""/gpfs/gpfs0/software/rhel72/packages/tensorflow_gpu/tensorflow/python/__init__.py"", line 58, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""/gpfs/gpfs0/software/rhel72/packages/tensorflow_gpu/tensorflow/python/__init__.py"", line 52, in <module>
    from tensorflow.core.framework.graph_pb2 import *
  File ""/gpfs/gpfs0/software/rhel72/packages/tensorflow_gpu/tensorflow/core/framework/graph_pb2.py"", line 6, in <module>
    from google.protobuf import descriptor as _descriptor
ImportError: No module named google.protobuf


Error importing tensorflow.  Unless you are using bazel,
you should not try to import tensorflow from its source directory;
please exit the tensorflow source tree, and relaunch your python interpreter
from there.
```"
6340,cannot enable peer access for GPU cards on one machine,"**Error:**
```
I tensorflow/core/common_runtime/gpu/gpu_init.cc:59] cannot enable peer access from device ordinal 0 to device ordinal 2
I tensorflow/core/common_runtime/gpu/gpu_init.cc:59] cannot enable peer access from device ordinal 0 to device ordinal 3
I tensorflow/core/common_runtime/gpu/gpu_init.cc:59] cannot enable peer access from device ordinal 1 to device ordinal 2
I tensorflow/core/common_runtime/gpu/gpu_init.cc:59] cannot enable peer access from device ordinal 1 to device ordinal 3
I tensorflow/core/common_runtime/gpu/gpu_init.cc:59] cannot enable peer access from device ordinal 2 to device ordinal 0
I tensorflow/core/common_runtime/gpu/gpu_init.cc:59] cannot enable peer access from device ordinal 2 to device ordinal 1
I tensorflow/core/common_runtime/gpu/gpu_init.cc:59] cannot enable peer access from device ordinal 3 to device ordinal 0
I tensorflow/core/common_runtime/gpu/gpu_init.cc:59] cannot enable peer access from device ordinal 3 to device ordinal 1
I tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0 1 2 3 
I tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y Y N N 
I tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 1:   Y Y N N 
I tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 2:   N N Y Y 
I tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 3:   N N Y Y 
```

**Information of GPU**
```
name: Tesla P100-SXM2-16GB
major: 6 minor: 0 memoryClockRate (GHz) 1.4805
pciBusID 0002:01:00.0
Total memory: 15.90GiB
Free memory: 15.62GiB
W tensorflow/stream_executor/cuda/cuda_driver.cc:572] creating context when one is currently active; existing: 0x10037db0cd0
I tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 1 with properties: 
name: Tesla P100-SXM2-16GB
major: 6 minor: 0 memoryClockRate (GHz) 1.4805
pciBusID 0003:01:00.0
Total memory: 15.90GiB
Free memory: 15.62GiB
W tensorflow/stream_executor/cuda/cuda_driver.cc:572] creating context when one is currently active; existing: 0x3effffc22000
I tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 2 with properties: 
name: Tesla P100-SXM2-16GB
major: 6 minor: 0 memoryClockRate (GHz) 1.4805
pciBusID 0006:01:00.0
Total memory: 15.90GiB
Free memory: 15.62GiB
W tensorflow/stream_executor/cuda/cuda_driver.cc:572] creating context when one is currently active; existing: 0x3dffffb856e0
I tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 3 with properties: 
name: Tesla P100-SXM2-16GB
major: 6 minor: 0 memoryClockRate (GHz) 1.4805
pciBusID 0007:01:00.0
Total memory: 15.90GiB
Free memory: 15.62GiB

```
**Information of cluster:**
Basically our cluster is made of IBM Power System S822LC for commercial computing

    OS: Red Hat Enterprise Linux Server release 7.2 (Maipo)
    TF version: 0.10.0rc0
    protobuf: 3.0.0b2
    Python: 2.7.5
"
6337,Can't develop TensorBoard under macOS,"I read [DEVELOPMENT.md](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tensorboard/DEVELOPMENT.md)
After npm run prepare finished, gulp come up with error:

> [23:42:32] Using gulpfile ~/Desktop/Going/tensorflow-master/tensorflow/tensorboard/gulpfile.js
(node:20770) DeprecationWarning: os.tmpDir() is deprecated. Use os.tmpdir() instead.
[23:42:32] Starting 'watch'...
[23:42:32] Finished 'watch' after 129 ms
[23:42:32] Starting 'first-compile'...
[23:42:41] Finished 'first-compile' after 9.16 s
[23:42:41] Starting 'server'...
[23:42:41] Finished 'server' after 17 ms
[23:42:41] Starting 'default'...
[23:42:41] Finished 'default' after 18 μs
[23:42:41] Webserver started at http://0.0.0.0:8000
2016-12-15 23:42 gulp[20770] (FSEvents.framework) FSEventStreamStart: register_with_server: ERROR: f2d_register_rpc() => (null) (-22)
events.js:160
      throw er; // Unhandled 'error' event
      ^
Error: Error watching file for changes: EMFILE
    at exports._errnoException (util.js:1022:11)
    at FSEvent.FSWatcher._handle.onchange (fs.js:1282:11)


macOS 10.12.1
➜  tensorboard gulp -v
[23:44:58] CLI version 3.9.1
[23:44:58] Local version 3.9.1
➜  tensorboard node -v
v7.2.1
➜  tensorboard npm -v
3.10.10
➜  tensorboard bower -v
1.8.0

"
6336,session_bundle in TensorFlow 0.12.0-rc1 cannot restore v2 checkpoint,"I used [example/export_half_plus_two.py](https://github.com/tensorflow/tensorflow/blob/r0.12/tensorflow/contrib/session_bundle/example/export_half_plus_two.py) to test session_bundle. I run the below command to write v2 checkpoint files in export path,
```shell
root§b47d8eea090e:/tensorflow/model-export/session_bundle# python export_half_plus_two.py --use_checkpoint_v2=True
copying asset files to: /tmp/half_plus_two/00000123-tmp/assets
copying asset file: hello2.txt
copying asset file: hello1.txt
```

The export directory is 
```shell
root@b47d8eea090e:/tmp/half_plus_two/00000123# ls -l
total 32
drwxr-xr-x 2 root root  4096 Dec 15 13:59 assets
-rw-r--r-- 1 root root   133 Dec 15 13:59 checkpoint
-rw-r--r-- 1 root root     8 Dec 15 13:59 export.data-00000-of-00001
-rw-r--r-- 1 root root   134 Dec 15 13:59 export.index
-rw-r--r-- 1 root root 14980 Dec 15 13:59 export.meta
```

Then I write a import python file, the content is
```python
import tensorflow as tf
import numpy as np
from tensorflow.contrib.session_bundle import session_bundle
from tensorflow.contrib.session_bundle import constants
from tensorflow.contrib.session_bundle import manifest_pb2

export_dir = ""/tmp/half_plus_two/00000123""

tf.reset_default_graph()

sess, meta_graph_def = session_bundle.load_session_bundle_from_path(
    export_dir, target="""", config=tf.ConfigProto(device_count={""CPU"": 2}))

with sess.as_default():
    collection_def = meta_graph_def.collection_def
    signatures_any = collection_def[constants.SIGNATURES_KEY].any_list.value
    print(""signatures length: %d\n"" % len(signatures_any))

    signatures = manifest_pb2.Signatures()
    signatures_any[0].Unpack(signatures)

    named_signatures = signatures.named_signatures
    input_name = (named_signatures[""inputs""].generic_signature.map[""x""].tensor_name)
    output_name = (named_signatures[""outputs""].generic_signature.map[""y""].tensor_name)

    y = sess.run([output_name], {input_name: np.array([[0], [1], [2], [3]])})
    print(y[0])
```

It will tell me the variables are uninitialized,
```shell
root§b47d8eea090e:/tensorflow/model-export/session_bundle# python import_half_plus_two.py 
signatures length: 1

Traceback (most recent call last):
  File ""import_half_plus_two.py"", line 26, in <module>
    y = sess.run(Äoutput_nameÜ, äinput_name: np.array(ÄÄ0Ü, Ä1Ü, Ä2Ü, Ä3ÜÜ)¨)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 766, in run
    run_metadata_ptr)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 964, in _run
    feed_dict_string, options, run_metadata)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1014, in _do_run
    target_list, options, run_metadata)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1034, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.FailedPreconditionError: Attempting to use uninitialized value b
	 ÄÄNode: b/read = IdentityÄT=DT_FLOAT, _class=Ä""loc:§b""Ü, _device=""/job:localhost/replica:0/task:0/cpu:0""Ü(b)ÜÜ

Caused by op u'b/read', defined at:
  File ""import_half_plus_two.py"", line 12, in <module>
    export_dir, target="""", config=tf.ConfigProto(device_count=ä""CPU"": 2¨))
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/session_bundle/session_bundle.py"", line 95, in load_session_bundle_from_path
    saver = tf.train.import_meta_graph(meta_graph_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1526, in import_meta_graph
    **kwargs)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/meta_graph.py"", line 502, in import_scoped_meta_graph
    producer_op_list=producer_op_list)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/importer.py"", line 285, in import_graph_def
    op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 2240, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 1128, in __init__
    self._traceback = _extract_stack()

FailedPreconditionError (see above for traceback): Attempting to use uninitialized value b
	 ÄÄNode: b/read = IdentityÄT=DT_FLOAT, _class=Ä""loc:§b""Ü, _device=""/job:localhost/replica:0/task:0/cpu:0""Ü(b)ÜÜ
```

If I changed the ""use_checkpoint_v2"" option to ""False"", there would be no error.

```shell
root§b47d8eea090e:/tensorflow/model-export/session_bundle# python export_half_plus_two.py --use_checkpoint_v2=False
WARNING:tensorflow:*******************************************************
WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.
WARNING:tensorflow:Consider switching to the more efficient V2 format:
WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`
WARNING:tensorflow:now on by default.
WARNING:tensorflow:*******************************************************
copying asset files to: /tmp/half_plus_two/00000123-tmp/assets
copying asset file: hello2.txt
copying asset file: hello1.txt
root§b47d8eea090e:/tensorflow/model-export/session_bundle# 
root§b47d8eea090e:/tensorflow/model-export/session_bundle# python import_half_plus_two.py                          
signatures length: 1

ÄÄ 2. Ü
 Ä 2.5Ü
 Ä 3. Ü
 Ä 3.5ÜÜ
root§b47d8eea090e:/tensorflow/model-export/session_bundle# 
```

At this time, the export directory is

```shell
root@b47d8eea090e:/tmp/half_plus_two/00000123# ls -l
total 28
drwxr-xr-x 2 root root  4096 Dec 15 14:07 assets
-rw-r--r-- 1 root root   163 Dec 15 14:07 checkpoint
-rw-r--r-- 1 root root   169 Dec 15 14:07 export-00000-of-00001
-rw-r--r-- 1 root root 13740 Dec 15 14:07 export.meta
```

I found that the diff between v2 checkpoint file and v1 checkpoint is a substring "".data"" in v2 checkpoint filename. Just see the above example, the v2 checkpoint filename is ""export.data-00000-of-00001"" and the v1 checkpoint filename is ""export-00000-of-00001"". 

So, I moved to read the load function ""load_session_bundle_from_path"", I found a bug at [L64](https://github.com/tensorflow/tensorflow/blob/r0.12/tensorflow/contrib/session_bundle/session_bundle.py#L64). See following code snippet

```python
if not file_io.file_exists(variables_filename):
    variables_filename = os.path.join(
        export_dir, constants.VARIABLES_FILENAME_PATTERN)
    if not file_io.get_matching_files(variables_filename):
      # If graph_util.convert_variables_to_constants() is called on a model
      # it won't have any variables, and that's OK.
      #
      # TODO(yxshi): verify that the graph_def in fact does not have any
      # reachable variables.
      variables_filename = None
```

where the constant ""constants.VARIABLES_FILENAME_PATTERN""( defined in [constant.py](https://github.com/tensorflow/tensorflow/blob/r0.12/tensorflow/contrib/session_bundle/constants.py#L28)) is ""export-????-of-????"". It cannot match the v2 checkpoint filename, so the load function cannot restore the v2 checkpoint file.
"
6334,Offering a small TensorFlow runtime for production environments,"I noticed in https://github.com/tensorflow/tensorflow/pull/1109 that some attempts to reduce the PyPI package have been made,  but since 0.9 the package has grown quite a bit.

Are there any ongoing attempts of creating a smaller TensorFlow runtime that can be used for putting graphs into production? For example, the most common use case for TensorFlow is probably running a machine learning model's forward pass. For that, all of the gradient related code could be excluded from the package, no?

Preferably I'd love a utility that takes in a graph protobuf and spits out a pip installable TensorFlow version with only the required parts of the codebase. Is this at all doable?"
6333,Very low GPU usage,"I try to use single dynamic_rnn to process very long sequence for classification task.
Here are some parameters:
rnn_size=500, seq_max_length=2500, batch_size=50, embedding_size=64, softmax_size=1600.

the code is as below:
```
x_vec = tf.nn.embedding_lookup(embedding_matrix_variable, self.x)
lstm_fw_cell = rnn_cell.LSTMCell(num_units = hidden_unit, input_size = word_dim)
lstm_fw_cell = rnn_cell.DropoutWrapper(lstm_fw_cell, output_keep_prob=self.dropout_keep_prob, input_keep_prob=self.dropout_keep_prob)
outputs, _ = rnn.dynamic_rnn(lstm_fw_cell, x, dtype=tf.float32, sequence_length=real_length, swap_memory=False)

outputs = tf.transpose(outputs, [1, 0, 2])
outputs = tf.unpack(outputs)

output = outputs[0]
one = tf.ones([1, hidden_unit], tf.float32)
with tf.variable_scope(""output""):
    tf.get_variable_scope().reuse_variables()
        for i in range(1, len(outputs_6)):
            ind = self.real_length < (i+1)
            ind = tf.to_float(ind)
             ind = tf.expand_dims(ind, -1)
             mat = tf.matmul(ind, one)
             output=tf.add(tf.mul(output, mat), tf.mul(outputs[i], 1.0-mat))


y_prediction = tf.matmul(output, w_h2y) + b_h2y
y_prediction = tf.nn.softmax(y_prediction)	
		
weight_decay = L2  * ( tf.nn.l2_loss(w_h2y) + tf.nn.l2_loss(b_h2y) )
self.cost = tf.reduce_mean( -tf.reduce_sum(self.y*tf.log(y_prediction + 1e-10)) ) + weight_decay
self.optimizer = tf.train.AdamOptimizer(alpha).minimize(self.cost)
```


The usage of GPU on TITAN is only 5%.
The usage of CPU  is about 150%.
I am not sure what's the problem."
6331,Tensorflow installation Error in Mac Sierra due to numpy,"Hi,

I want to install TensorFlow on Mac. Currently I am using MacOS Sierra (Version 10.12.1).
Python was already installed in this current version. My Python version is 2.7.10.

I followed the instructions given on the webpage of Tensorflow to install it on my Mac. When I entered the command 
$ pip install tensorflow then I have the following error:




$ pip install tensorflow
Collecting tensorflow
  Downloading tensorflow-0.12.0rc1-cp27-cp27m-macosx_10_11_x86_64.whl (38.5MB)
    100% |████████████████████████████████| 38.5MB 23kB/s 
Collecting numpy>=1.11.0 (from tensorflow)
  Downloading numpy-1.11.2-cp27-cp27m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (3.9MB)
    100% |████████████████████████████████| 3.9MB 263kB/s 
Requirement already satisfied: six>=1.10.0 in /Library/Python/2.7/site-packages/six-1.10.0-py2.7.egg (from tensorflow)
Collecting mock>=2.0.0 (from tensorflow)
  Downloading mock-2.0.0-py2.py3-none-any.whl (56kB)
    100% |████████████████████████████████| 61kB 4.9MB/s 
Collecting wheel (from tensorflow)
  Downloading wheel-0.29.0-py2.py3-none-any.whl (66kB)
    100% |████████████████████████████████| 71kB 3.3MB/s 
Collecting protobuf==3.1.0 (from tensorflow)
  Downloading protobuf-3.1.0-py2.py3-none-any.whl (339kB)
    100% |████████████████████████████████| 348kB 2.1MB/s 
Collecting funcsigs>=1; python_version < ""3.3"" (from mock>=2.0.0->tensorflow)
  Downloading funcsigs-1.0.2-py2.py3-none-any.whl
Collecting pbr>=0.11 (from mock>=2.0.0->tensorflow)
  Downloading pbr-1.10.0-py2.py3-none-any.whl (96kB)
    100% |████████████████████████████████| 102kB 7.4MB/s 
Requirement already satisfied: setuptools in /System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python (from protobuf==3.1.0->tensorflow)
Installing collected packages: numpy, funcsigs, pbr, mock, wheel, protobuf, tensorflow
  Found existing installation: numpy 1.8.0rc1
    DEPRECATION: Uninstalling a distutils installed project (numpy) has been deprecated and will be removed in a future version. This is due to the fact that uninstalling a distutils project will only partially uninstall the project.
    Uninstalling numpy-1.8.0rc1:
Exception:
Traceback (most recent call last):
  File ""/Library/Python/2.7/site-packages/pip-9.0.1-py2.7.egg/pip/basecommand.py"", line 215, in main
    status = self.run(options, args)
  File ""/Library/Python/2.7/site-packages/pip-9.0.1-py2.7.egg/pip/commands/install.py"", line 342, in run
    prefix=options.prefix_path,
  File ""/Library/Python/2.7/site-packages/pip-9.0.1-py2.7.egg/pip/req/req_set.py"", line 778, in install
    requirement.uninstall(auto_confirm=True)
  File ""/Library/Python/2.7/site-packages/pip-9.0.1-py2.7.egg/pip/req/req_install.py"", line 754, in uninstall
    paths_to_remove.remove(auto_confirm)
  File ""/Library/Python/2.7/site-packages/pip-9.0.1-py2.7.egg/pip/req/req_uninstall.py"", line 115, in remove
    renames(path, new_path)
  File ""/Library/Python/2.7/site-packages/pip-9.0.1-py2.7.egg/pip/utils/__init__.py"", line 267, in renames
    shutil.move(old, new)
  File ""/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/shutil.py"", line 302, in move
    copy2(src, real_dst)
  File ""/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/shutil.py"", line 131, in copy2
    copystat(src, dst)
  File ""/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/shutil.py"", line 103, in copystat
    os.chflags(dst, st.st_flags)
OSError: [Errno 1] Operation not permitted: '/var/folders/jk/s2ngqqls71v9vj7z02p79w880000gn/T/pip-hpgFvE-uninstall/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/numpy-1.8.0rc1-py2.7.egg-info'





I think there is some issue with numpy. My current numpy version is 1.8.0rc1 and it was already installed with MacOS Sierra. I tried to uninstall it so that Tensorflow install the new version by itself but no success.

I tried different solutions available on the web to solve this issue but no success.

Could anybody tell me that how I can solve this issue and install Tensorfow.

Thanks.
Zeeshan"
6330,Error of using a custom classifier for android demo,"I want to build android demo of my classifier.
Following the steps at [https://www.oreilly.com/learning/tensorflow-on-android](url),
the error appeared for 
`bazel build tensorflow/python/tools:optimize_for_inference` .
My bazel version is 0.4.2.
Error :
> ERROR: /home/dlm/tensorflow_new/tensorflow/python/BUILD:1907:1: Linking of rule '//tensorflow/python:_pywrap_tensorflow.so' failed: link_dynamic_library.sh failed: error executing command external/bazel_tools/tools/cpp/link_dynamic_library.sh no ignored ignored ignored /usr/bin/gcc -shared -o bazel-out/local-fastbuild/bin/tensorflow/python/_pywrap_tensorflow.so -Wl,--version-script ... (remaining 14 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.
bazel-out/local-fastbuild/bin/tensorflow/core/libversion_lib.a(version_info.pic.o): In function `tf_git_version()':
version_info.cc:(.text+0x0): multiple definition of `tf_git_version()'
bazel-out/local-fastbuild/bin/tensorflow/core/libframework_internal.lo(version_info.pic.o):version_info.cc:(.text+0x0): first defined here
bazel-out/local-fastbuild/bin/tensorflow/core/libversion_lib.a(version_info.pic.o): In function `tf_compiler_version()':
version_info.cc:(.text+0xd): multiple definition of `tf_compiler_version()'
bazel-out/local-fastbuild/bin/tensorflow/core/libframework_internal.lo(version_info.pic.o):version_info.cc:(.text+0xd): first defined here
collect2: error: ld returned 1 exit status
Target //tensorflow/python/tools:optimize_for_inference failed to build
Use --verbose_failures to see the command lines of failed build steps.

How do I fix this error ?
"
6329,ValueError: Variable d_h0_conv/w/Adam/ does not exist,"I got a error:

`
ValueError: Variable d_h0_conv/w/Adam/ does not exist, or was not created with tf.get_variable(). Did you mean to set reuse=None in VarScope?
`

this is DCGAN's code 
[dcgan-tensorflow](https://github.com/carpedm20/DCGAN-tensorflow)

And my tensorflow version is 0.12
my ubuntu : 14.04

code detail:

con2d code

`def conv2d(input_, output_dim, 
           k_h=5, k_w=5, d_h=2, d_w=2, stddev=0.02,
           name=""conv2d""):
    with tf.variable_scope(name):


        w = tf.get_variable('w', [k_h, k_w, input_.get_shape()[-1], output_dim],
                            initializer=tf.truncated_normal_initializer(stddev=stddev))
        conv = tf.nn.conv2d(input_, w, strides=[1, d_h, d_w, 1], padding='SAME')

        biases = tf.get_variable('biases', [output_dim], initializer=tf.constant_initializer(0.0))
        conv = tf.reshape(tf.nn.bias_add(conv, biases), conv.get_shape())

        return conv`

Optimizer:

`
        d_optim = tf.train.AdamOptimizer(config.learning_rate ,  beta1=config.beta1).minimize(self.d_loss , var_list=self.d_vars)
        g_optim = tf.train.AdamOptimizer(config.learning_rate, beta1=config.beta1) \
                          .minimize(self.g_loss, var_list=self.g_vars)
`

Thanks, Now I need help!
"
6327,Embedding Projector: show vector labels on custom projection view,"A feature request for the Embedding Projector: show vector labels as plot axis labels on custom projection view

minimal example, mocked up on a screenshot:
<img width=""317"" alt=""screen shot 2016-12-14 at 11 30 40 pm"" src=""https://cloud.githubusercontent.com/assets/2119400/21215544/ae2c994e-c256-11e6-9a8a-5501b4592695.png"">
<img width=""1311"" alt=""custom-projection-blocks"" src=""https://cloud.githubusercontent.com/assets/2119400/21215550/b7a945ee-c256-11e6-9667-1ca8052c9483.png"">
"
6326,Bug when generate checkpoint in distributed training,"I am training model in distributed mode  with 1 ps and 2 worker all in localhost with different ports.
My model is a 4 layer with full connected network.
I find that , when traing in 10,10,10,10(4 layer, each layer 10 hidden unit ), every thinks works well,
But, when enlarge network to 20,20,20,20 , the traing process works well, but can not generate checkponit any more.  with adding log , I find it's stuck at https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/training/saver.py#L1372
it maybe not slow , I wait for hours, nothing but stuck at it.

more:
when traing not in distributed with same size(20,20,20,20) network,it's works well with checkpoint.

### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?
cannot find  any thing about this.

### Environment info
Operating System:
centos6.5

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)
```
with tf.device(tf.train.replica_device_setter(
        worker_device=""/job:worker/task:%d"" % FLAGS.task_index,
        cluster=cluster)):
    # Read TFRecords files for training
    filename_queue = tf.train.string_input_producer(
        tf.train.match_filenames_once(FLAGS.train),
        num_epochs=epoch_number)
    serialized_example = read_and_decode(filename_queue)
    batch_serialized_example = tf.train.shuffle_batch(
        [serialized_example],
        batch_size=batch_size,
        num_threads=thread_number,
        capacity=capacity,
        min_after_dequeue=min_after_dequeue)
    features = tf.parse_example(
        batch_serialized_example,
        features={
            ""label"": tf.FixedLenFeature([], tf.float32),
            ""ids"": tf.VarLenFeature(tf.int64),
            ""values"": tf.VarLenFeature(tf.float32),
        })
    batch_labels = features[""label""]
    batch_ids = features[""ids""]
    batch_values = features[""values""]

    # Read TFRecords file for validatioin
    validate_filename_queue = tf.train.string_input_producer(
        tf.train.match_filenames_once(FLAGS.eval),
        num_epochs=epoch_number)
    validate_serialized_example = read_and_decode(validate_filename_queue)
    validate_batch_serialized_example = tf.train.shuffle_batch(
        [validate_serialized_example],
        batch_size=validate_batch_size,
        num_threads=thread_number,
        capacity=capacity,
        min_after_dequeue=min_after_dequeue)
    validate_features = tf.parse_example(
        validate_batch_serialized_example,
        features={
            ""label"": tf.FixedLenFeature([], tf.float32),
            ""ids"": tf.VarLenFeature(tf.int64),
            ""values"": tf.VarLenFeature(tf.float32),
        })
    validate_batch_labels = features[""label""]
    validate_batch_ids = features[""ids""]
    validate_batch_values = features[""values""]
    logits = inference(batch_ids, batch_values)
    batch_labels = tf.to_int64(batch_labels)
    cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits,
                                                                   batch_labels)
    loss = tf.reduce_mean(cross_entropy, name='loss')

    print(""Use the optimizer: {}"".format(FLAGS.optimizer))

    optimizer = tf.train.FtrlOptimizer(learning_rate)

    global_step = tf.Variable(0, name='global_step', trainable=False)
    train_op = optimizer.minimize(loss, global_step=global_step)




    # Initialize saver and summary
    steps_to_validate = FLAGS.steps_to_validate
    init_op = tf.initialize_all_variables()

    saver = tf.train.Saver(max_to_keep = 2)
    keys_placeholder = tf.placeholder(""float"")
    keys = tf.identity(keys_placeholder)
    tf.add_to_collection(""inputs"", json.dumps({'key': keys_placeholder.name}))
    tf.add_to_collection(""outputs"", json.dumps({'key': keys.name,
                                                'softmax': inference_softmax.name,
                                                'prediction': inference_op.name}))

    summary_op = tf.merge_all_summaries()


sv = tf.train.Supervisor(is_chief=(FLAGS.task_index == 0),
                         logdir=""./supervisor/"",
                         init_op=init_op,
                         summary_op=summary_op,
                         saver=saver,
                         global_step=global_step,
                         save_model_secs=60)

# Create session to run graph
with sv.managed_session(server.target) as sess:

    while not sv.should_stop():
        # Get coordinator and run queues to read data
        coord = tf.train.Coordinator()
        threads = tf.train.start_queue_runners(coord=coord, sess=sess)

        start_time = datetime.datetime.now()

        try:
            while not coord.should_stop():
                _, loss_value, step = sess.run([train_op, loss, global_step])
                if step % steps_to_validate == 0:
                    accuracy_value, auc_value, summary_value = sess.run(
                        [accuracy, auc_op, summary_op])
                    end_time = datetime.datetime.now()
                    print(""[{}] Task: {}, Step: {}, loss: {}, accuracy: {}, auc: {}"".format(
                        end_time - start_time,
                        FLAGS.task_index,
                        step, loss_value, accuracy_value,
                        auc_value))

                    start_time = end_time
        except tf.errors.OutOfRangeError:
            print(""Done training after reading all data"")
        finally:
            coord.request_stop()
            print(""coord stopped"")

        # Wait for threads to exit
        coord.join(threads)
```
"
6325,"How can I know what variables or constants in a "".ckpt"" file","How can I know what variables or constants in a "".ckpt"" file?

If I restore a "".ckpt"" file without defining any variables, I will get error.
However I just want to know what's in that "".ckpt"" file.

I didn't see any function can achieve it."
6322,No real code example for using the tensorboard embedding tab,"I spent a long time yesterday trying to understand how to get something to show up in the embedding tab on Tensorboard. It is not very well documented, and there are no code examples except for the tiny, incomplete snippets in the tutorial. I was finally able to get something working, but I think it would be helpful for future users to have a real code tutorial. I could pretty easily write one for the MNIST example since I already have my own working. Is that something that people will want?"
6319,"Occasional ""Connection timed out"" in distributed TensorFlow","We are occasionally observing crashes like below (training on AWS, seeing couple of crashes per day). It looks like in gRPC, recvmsg returns with ""Connection timed out"". The error points to [this line](https://github.com/grpc/grpc/blob/a98778f33dc602ad474b19e2f5243972722e758e/src/core/lib/iomgr/tcp_posix.c#L224). Default behavior in TensorFlow seems to be ""wait forever"", is there way to have same behavior for slow grpc connections?

@mrry

```
Traceback (most recent call last):
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py"", line 972, in _do_call
    return fn(*args)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py"", line 954, in _run_fn
    status, run_metadata)
  File ""/usr/lib/python3.5/contextlib.py"", line 66, in __exit__
    next(self.gen)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/errors.py"", line 463, in raise_exception_on_not_ok_status
    pywrap_tensorflow.TF_GetCode(status))
tensorflow.python.framework.errors.UnavailableError: {""created"":""@1481750298.553120216"",""description"":""OS Error"",""errno"":110,""file"":""external/grpc/src/core/lib/iomgr/tcp_posix.c"",""file_line"":229,""grpc_status"":14,""os_error"":""Connection timed out"",""syscall"":""recvmsg""}
     [[Node: ExponentialMovingAverage/decay_S37 = _Recv[client_terminated=false, recv_device=""/job:ps/replica:0/task:0/cpu:0"", send_device=""/job:worker/replica:0/task:2/cpu:0"", send_device_incarnation=3009888913849196393, tensor_name=""edge_1032_ExponentialMovingAverage/decay"", tensor_type=DT_FLOAT, _device=""/job:ps/replica:0/task:0/cpu:0""]()]]
     [[Node: gradients/truediv_grad/Shape_1_S63 = _HostRecv[client_terminated=false, recv_device=""/job:worker/replica:0/task:2/cpu:0"", send_device=""/job:ps/replica:0/task:0/cpu:0"", send_device_incarnation=-6688974477600735349, tensor_name=""edge_115_gradients/truediv_grad/Shape_1"", tensor_type=DT_INT32, _device=""/job:worker/replica:0/task:2/cpu:0""]()]]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""bin/worker"", line 231, in <module>
    tf.app.run()
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/app.py"", line 30, in run
    sys.exit(main(sys.argv[:1] + flags_passthrough))
  File ""bin/worker"", line 228, in main
    run_generic(server, args, trainer, num_global_steps=num_global_steps)
  File ""bin/worker"", line 152, in run_generic
    trainer.process(sess)
  File ""/experiment/vnc-agents/trainers/base.py"", line 351, in process
    fetched = sess.run(fetches, feed_dict=feed_dict)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py"", line 717, in run
    run_metadata_ptr)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py"", line 915, in _run
    feed_dict_string, options, run_metadata)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py"", line 965, in _do_run
    target_list, options, run_metadata)
  File ""/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py"", line 985, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors.UnavailableError: {""created"":""@1481750298.553120216"",""description"":""OS Error"",""errno"":110,""file"":""external/grpc/src/core/lib/iomgr/tcp_posix.c"",""file_line"":229,""grpc_status"":14,""os_error"":""Connection timed out"",""syscall"":""recvmsg""}
     [[Node: ExponentialMovingAverage/decay_S37 = _Recv[client_terminated=false, recv_device=""/job:ps/replica:0/task:0/cpu:0"", send_device=""/job:worker/replica:0/task:2/cpu:0"", send_device_incarnation=3009888913849196393, tensor_name=""edge_1032_ExponentialMovingAverage/decay"", tensor_type=DT_FLOAT, _device=""/job:ps/replica:0/task:0/cpu:0""]()]]
     [[Node: gradients/truediv_grad/Shape_1_S63 = _HostRecv[client_terminated=false, recv_device=""/job:worker/replica:0/task:2/cpu:0"", send_device=""/job:ps/replica:0/task:0/cpu:0"", send_device_incarnation=-6688974477600735349, tensor_name=""edge_115_gradients/truediv_grad/Shape_1"", tensor_type=DT_INT32, _device=""/job:worker/replica:0/task:2/cpu:0""]()]]
```"
6316,"training on one GPU, but the other one is also occupied","Hi,
I have two GPUs, and I just would like to use one GPU to train a network by tensorflow. When I train it, the code use all the memories of two GPUs, but only one GPU is working:
![screenshot from 2016-12-14 20-12-57](https://cloud.githubusercontent.com/assets/15608199/21197459/cfbcc86a-c23b-11e6-88d5-e04f7537e676.png)


How to solve this problem? I would like just one to work, but not occupy the other.

"
6315,Session initialization must not require values for tensors with dtype string,"### Environment info
Operating System: Ubuntu 16.04

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):
CUDA 8.0
TF 0.12.0-rc1

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)
I create a string variable, among others, then try to initialize the session:
```
mode = tf.placeholder(tf.string, name='mode')
...

init = tf.global_variables_initializer()
session.run(init)
```

This results in
```
tensorflow.python.framework.errors_impl.InvalidArgumentError: You must feed a value for placeholder tensor 'mode' with dtype string
	 [[Node: mode = Placeholder[dtype=DT_STRING, shape=[], _device=""/job:localhost/replica:0/task:0/gpu:0""]()]]
	 [[Node: mode/_1 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device_incarnation=1, tensor_name=""edge_360_mode"", tensor_type=DT_STRING, _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]
```

Fix for me is to set `session.run(init, feed_dict={mode: 'foo'})`
But it looks like a regression since rc0."
6314,Error 404 when downloading Tensorflow on Windows,"The links provided on the website to the .whl used to install Tensorflow on Windows seem to be broken : https://www.tensorflow.org/get_started/os_setup#pip_installation_on_windows
I'm getting an HTTP Error 404.
I found the CPU Build elsewhere but I can't find the GPU build which I would like tu use."
6313,Tensorboard has wrong logdir on Windows,"I use Tensorflow 0.12rc1 on Windows. ""Tensorboard"" has problems parsing the `logdir`. My log-directory is at `E:\tmp\tflogs`. When I start tensorboard from the windows shell (cmd.exe) with:

`tensorboard --logdir=E:\tmp\tflogs`

it depends on the current directory / drive if it works or not (i.e., if tensorboard finds the runs and shows the data). If the current directory is, e.g., on the `C:\` drive, tensorboard tries to add runs from `c:\tmp\tflogs` instead of `E:\tmp\tflogs`. 

Example:
`
C:\Users\wrammer>tensorboard --logdir=E:\tmp\tflearn_logs --debug
`
The log contains lines such as:
`
INFO:tensorflow:Starting AddRunsFromDirectory: C:\tmp\tflearn_logs
`

"
6311,Problem with specifying worker_device for contrib.estimator,"Hello

In `tensorflow/contrib/learn/python/learn/estimator/estimator.py`, the function `_get_replica_device_setter` will specify the `worker_device` we will use. The function is as follows.

```python
def _get_replica_device_setter(config):
  """"""Creates a replica device setter if required.

  Args:
    config: A RunConfig instance.

  Returns:
    A replica device setter, or None.
  """"""
  ps_ops = [
      'Variable', 'AutoReloadVariable', 'MutableHashTable',
      'MutableHashTableOfTensors', 'MutableDenseHashTable'
  ]

  if config.task_type:
    worker_device = '/job:%s/task:%d' % (config.task_type, config.task_id)
  else:
    worker_device = '/job:worker'

  if config.num_ps_replicas > 0:
    return device_setter.replica_device_setter(
        ps_tasks=config.num_ps_replicas, worker_device=worker_device,
        merge_devices=True, ps_ops=ps_ops, cluster=config.cluster_spec)
  else:
    return None
```

However, if our device has name like `/job:0/replica:0/task:0`, then what should do?"
6310,Multiple GPUs: Out of Memory,"Hi,

I used to train my model on a single GPU with a batch size of ```20``` (images) without a problem. Now I want to take advantage of multiple GPU training. Currently I'm using 4 GPUs and want to do **data-parallel replicated training** with a batch size of ```20*4```.

If I understood it correctly, each batch will be splitted into 4 equal parts (in this case for every model on each GPU, the batch size will be ```20```) and be feeded to each GPU.  But I'm getting out of memory error:

```
...
W tensorflow/core/common_runtime/bfc_allocator.cc:274] ********************************************************************************************
W tensorflow/core/common_runtime/bfc_allocator.cc:275] Ran out of memory trying to allocate 1.32GiB.  See logs for memory state.
W tensorflow/core/framework/op_kernel.cc:975] Resource exhausted: OOM when allocating tensor with shape[80,921600,6]
...
ResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[80,921600,6]
```
any suggestions will be greatly appreciated!"
6308,Bug in error message from dynamic_rnn,"When using inputs of dimention 2 instead of 3 I get following error

""ValueError: Dimension must be 2 but is 3 for 'transpose' ""

I believe the numbers in the error message are switched."
6307,Duplicate content on the new website,"In the Updates section of the new TensorFlow website, two news have the same text:

[![image](https://cloud.githubusercontent.com/assets/1140359/21177890/64615340-c1ed-11e6-82bc-c440ebc9dfd2.png)](https://www.tensorflow.org/)
"
6306,Windows GPU pip install http error,"pip install --upgrade https://storage.googleapis.com/tensorflow/windows/gpu/tensorflow_gpu-0.12.0rc1-cp35-cp35m-win_amd64.whl


Collecting tensorflow-gpu==0.12.0rc1 from https://storage.googleapis.com/tensorflow/windows/gpu/tensorflow_gpu-0.12.0rc1-cp35-cp35m-win_amd64.whl
  **HTTP error 404 while getting** https://storage.googleapis.com/tensorflow/windows/gpu/tensorflow_gpu-0.12.0rc1-cp35-cp35m-win_amd64.whl
  Could not install requirement tensorflow-gpu==0.12.0rc1 from https://storage.googleapis.com/tensorflow/windows/gpu/tensorflow_gpu-0.12.0rc1-cp35-cp35m-win_amd64.whl because of error 404 Client Error: Not Found for url: https://storage.googleapis.com/tensorflow/windows/gpu/tensorflow_gpu-0.12.0rc1-cp35-cp35m-win_amd64.whl"
6305,RNN Variables mistakenly (?) placed on GPU when doing multi tower training. ,"I'm trying to do ""data parallelism"" following the cifar-10 multi gpu example. Main difference is that I am using tensorflow's rnn abstractions. When I run the code ( [mgf.tar.gz](https://github.com/tensorflow/tensorflow/files/651211/mgf.tar.gz) ) on a CPU machine it works but when I run it on a machine with 1-4 gpus it crashes, reporting that some of the GRU/LSTm variables have not been initialized (on the gpu). 

```
Traceback (most recent call last):
  File ""trainMultiGPU.py"", line 211, in <module>
    tf.app.run()
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 43, in run
    sys.exit(main(sys.argv[:1] + flags_passthrough))
  File ""trainMultiGPU.py"", line 207, in main
    train(args)
  File ""trainMultiGPU.py"", line 171, in train
    sess.run(init)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 766, in run
    run_metadata_ptr)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 964, in _run
    feed_dict_string, options, run_metadata)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 1014, in _do_run
    target_list, options, run_metadata)
  File ""/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 1034, in _do_call
    raise type(e)(node_def, op, message)



tensorflow.python.framework.errors_impl.FailedPreconditionError: Attempting to use uninitialized value RNN/GRUCell/Gates/Linear/Matrix
         [[Node: RNN/GRUCell/Gates/Linear/Matrix/_52 = _Send[T=DT_FLOAT, client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device_incarnation=1, tensor_name=""edge_149_RNN/GRUCell/Gates/Linear/Matrix"", _device=""/job:localhost/replica:0/task:0/gpu:0""](RNN/GRUCell/Gates/Linear/Matrix)]]
         [[Node: init/NoOp_1/_62 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device_incarnation=1, tensor_name=""edge_164_init/NoOp_1"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]`**

```
I've tried this both with the vanilla and dynamic variations of the rnn functions and with LSTM as well as GRU. 

### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?
Issue #1390  


### Environment info
Operating System:
RHEL 7.2

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

> [tal@E8A2-DL380G90-01-1G multi_gpu_lstm_fail]$ ls -l /usr/local/cuda/lib64/libcud*
> -rw-r--r--. 1 root root   558720 Dec  6 10:55 /usr/local/cuda/lib64/libcudadevrt.a
> lrwxrwxrwx. 1 root root       16 Dec  6 10:55 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.8.0
> lrwxrwxrwx. 1 root root       19 Dec  6 10:55 /usr/local/cuda/lib64/libcudart.so.8.0 -> libcudart.so.8.0.44
> -rwxr-xr-x. 1 root root   415432 Dec  6 10:55 /usr/local/cuda/lib64/libcudart.so.8.0.44
> -rw-r--r--. 1 root root   775162 Dec  6 10:55 /usr/local/cuda/lib64/libcudart_static.a
> -rwxr-xr-x. 1 root root 79337624 Dec 13 10:51 /usr/local/cuda/lib64/libcudnn.so
> -rwxr-xr-x. 1 root root 79337624 Dec 13 10:51 /usr/local/cuda/lib64/libcudnn.so.5
> -rwxr-xr-x. 1 root root 79337624 Dec 13 10:51 /usr/local/cuda/lib64/libcudnn.so.5.1.5
> -rw-r--r--. 1 root root 69756172 Dec 13 10:51 /usr/local/cuda/lib64/libcudnn_static.a
> 

If installed from binary pip package, provide:

1. A link to the pip package you installed:
 export TF_BINARY_URL=https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow_gpu-0.12.0rc1-cp27-none-linux_x86_64.whl
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.
[tal@E8A2-DL380G90-01-1G multi_gpu_lstm_fail]$ python -c ""import tensorflow; 

> print(tensorflow.__version__)""
> I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcublas.so locally
> I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcudnn.so locally
> I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcufft.so locally
> I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcuda.so.1 locally
> I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcurand.so locally
> 0.12.0-rc1
> 

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)
I've attached a tar with a minimal reproducing example. Unfortunately I am behind a corporate proxy and can't push to github. 
[[mgf.tar.gz - reproducible example ](https://github.com/tensorflow/tensorflow/files/651211/mgf.tar.gz)
To recreate the example simply run 

> python trainMultiGPU.py
It should work fine on a CPU only machine. On a machine with gpus you should see the above traceback. 


### What other attempted solutions have you tried?

- I've tried variants of rnn (dynamic, regular, bidirectional)
- I've tried LSTMCell and GRUCell
- I've tried passing the scope explicitly to the call to rnn
- I've tried wrapping the call to rnn with a device placement on the cpu. This prevents the traceback but I think it places the OP on the cpu as well as processing becomes incredibly slow. 


### Logs or other output that would be helpful
(If logs are large, please upload as attachment or provide link).
[device_placements.txt](https://github.com/tensorflow/tensorflow/files/651206/device_placements.txt)
[nvidia-smi.out.txt](https://github.com/tensorflow/tensorflow/files/651207/nvidia-smi.out.txt)
[TRACEBACK.txt](https://github.com/tensorflow/tensorflow/files/651208/TRACEBACK.txt)




"
6304,Inference with TensorFlow does not work properly,"I have a strange problem with my neural network: while CV accuracy is good, inference accuracy is at the random guess level.

Inference is done in a standard ImageNet style way: five 224x224 squares, corners of the image plus center crop.

The CV and inference code goes together as follows:

`    inference_images = tf.placeholder(tf.float32, shape=(5, image_size_rows, image_size_cols, num_channels), name='input_images')

    ...    

    # Calculate CV loss and accuracy

    cv_images_batch, cv_labels_batch, cv_filenames = cv_runner.get_inputs()

    cv_predictions, cv_logits = network(cv_images_batch, num_labels)
    cv_loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(cv_logits, cv_labels_batch))

    cv_correct_prediction = tf.equal(tf.argmax(cv_predictions, 1), tf.argmax(cv_labels_batch, 1))
    cv_accuracy = tf.reduce_mean(tf.cast(cv_correct_prediction, 'float'))

    # Calculate inference

    inference_predictions, _ = network(inference_images, num_labels)
    predicted_classes = tf.argmax(inference_predictions, 1, name='predicted_classes')
    predicted_class = tf.argmax(tf.reduce_sum(inference_predictions, 0), 0, name='predicted_class')`

Training and CV accuracy quickly grow to >50% but inference accuracy remains at the random guess level of 10%.

I used for inference the same images I use for cross-validation and training. In both cases the inference accuracy remains low while I would expect it to be at the CV and train accuracy respectively.

Preprocessing code is the same for training, CV and inference. Restoring images from CV and inference matrices works fine for both types. So, the problem apparently is not in different preprocessing for train/CV and inference.

To isolate this effect, I have extracted train images out of a queue used for training and used them to make inference. Here are the results:

`Step 35140: train loss: 0.170477, cv loss: 2.183839, train accuracy: 0.955357, cv accuracy: 0.535714, inference accuracy: 0.400000

Step 35160: train loss: 0.233728, cv loss: 2.114637, train accuracy: 0.937500, cv accuracy: 0.517857, inference accuracy: 0.200000

Step 35180: train loss: 0.362239, cv loss: 1.962119, train accuracy: 0.906250, cv accuracy: 0.544643, inference accuracy: 0.400000

Step 35200: train loss: 0.190649, cv loss: 2.122064, train accuracy: 0.946429, cv accuracy: 0.540179, inference accuracy: 0.800000

Step 35220: train loss: 0.161332, cv loss: 2.006443, train accuracy: 0.968750, cv accuracy: 0.513393, inference accuracy: 1.000000

Step 35240: train loss: 0.185687, cv loss: 1.981431, train accuracy: 0.950893, cv accuracy: 0.535714, inference accuracy: 0.600000

Step 35260: train loss: 0.123562, cv loss: 2.030116, train accuracy: 0.977679, cv accuracy: 0.562500, inference accuracy: 0.800000

Step 35280: train loss: 0.216172, cv loss: 1.883790, train accuracy: 0.941964, cv accuracy: 0.549107, inference accuracy: 0.600000

Step 35300: train loss: 0.256623, cv loss: 2.012454, train accuracy: 0.897321, cv accuracy: 0.549107, inference accuracy: 0.200000`

Each inference batch is 5 images. As you can see, mean inference accuracy is way below train accuracy of 90%+.

I have tried to add tf.get_variable_scope().reuse_variables() before the inference with no effect.

Stackoverflow community did not help:
http://stackoverflow.com/questions/40820250/inference-with-tensorflow-does-not-work

What am I doing wrong with inference here?

### Environment info
Operating System:
Ubuntu 14.04

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

-rw-r--r-- 1 root root   322936 Aug 15  2015 /usr/local/cuda/lib64/libcudadevrt.a
lrwxrwxrwx 1 root root       16 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.7.5
lrwxrwxrwx 1 root root       19 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so.7.5 -> libcudart.so.7.5.18
-rwxr-xr-x 1 root root   383336 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so.7.5.18
-rw-r--r-- 1 root root   720192 Aug 15  2015 /usr/local/cuda/lib64/libcudart_static.a
-rwxr-xr-x 1 root root 61453024 Nov 14 14:08 /usr/local/cuda/lib64/libcudnn.so
-rwxr-xr-x 1 root root 61453024 Nov 14 14:08 /usr/local/cuda/lib64/libcudnn.so.4
-rwxr-xr-x 1 root root 61453024 Nov 14 14:08 /usr/local/cuda/lib64/libcudnn.so.4.0.7
-rw-r--r-- 1 root root 62025862 Nov 14 14:08 /usr/local/cuda/lib64/libcudnn_static.a

The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.

I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcublas.so.7.5 locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcudnn.so.4 locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcufft.so.7.5 locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcurand.so.7.5 locally
0.11.0rc2"
6303,TensorFlowEstimator can not be found,"when i am running sequence predicting program in windows10 ,it stucked in an error :AttributeError: module 'tensorflow.contrib.learn' has no attribute 'TensorFlowEstimator'. the tensorflow edition is 0.12rc  and python3.5 .how can i fix this problem? "
6301,add custom loss ,"I have noticed that tensorflow can add custom op, however, I want to add an custom loss function. To my
point of view, an custom op and an custom loss are different. Dose tensorflow support adding an custom loss? "
6298,Long sentence take too much memory,"I use one layer LSTM to train my data.
I use Dynamic_rnn, rnn_size=128, num_layers=1, seq_max_length=2500, batch_size=10, embedding_size=128, softmax_size=1600.


My code like this:

> x_vec = tf.nn.embedding_lookup(embedding_matrix_variable, self.x)
> lstm_fw_cell = rnn_cell.LSTMCell(num_units = hidden_unit, input_size = hidden_unit)
> lstm_fw_cell = rnn_cell.DropoutWrapper(lstm_fw_cell, output_keep_prob=self.dropout_keep_prob, input_keep_prob=self.dropout_keep_prob)
> outputs, _ = rnn.dynamic_rnn(lstm_fw_cell, x, dtype=tf.float32, sequence_length=real_length, swap_memory=False)
> 


I specify the GPU like this:
<img width=""281"" alt=""screenshot"" src=""https://cloud.githubusercontent.com/assets/4569055/21170698/3bbf5de8-c20a-11e6-9b66-647830bdd371.png"">



Command ""nvidia-smi"" shows as:
<img width=""511"" alt=""screenshot"" src=""https://cloud.githubusercontent.com/assets/4569055/21170316/7738d3b6-c207-11e6-860a-cdc5ea166f40.png"">



After lunching the program, it always shows :

> ""I tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator:..............."":

details show as below:

> Step: 0       (epoch: 0.00000)       time:28.85937s
> Minibatch loss:          7.43977     Minibatch accuracy:  0.00000
> Test loss:         nan     Test accuracy: 0.00000
> I tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 0 get requests, put_count=9012 evicted_count=9000 eviction_rate=0.998668 and unsatisfied allocation rate=0
> I tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 9559 get requests, put_count=15572 evicted_count=6000 eviction_rate=0.385307 and unsatisfied allocation rate=0
> I tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 25809 get requests, put_count=41821 evicted_count=16000 eviction_rate=0.382583 and unsatisfied allocation rate=3.87462e-05
> I tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 42059 get requests, put_count=68071 evicted_count=26000 eviction_rate=0.381954 and unsatisfied allocation rate=2.37761e-05
> I tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 58309 get requests, put_count=94321 evicted_count=36000 eviction_rate=0.381675 and unsatisfied allocation rate=1.715e-05
> I tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 0 get requests, put_count=8014 evicted_count=8000 eviction_rate=0.998253 and unsatisfied allocation rate=0
> I tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 7817 get requests, put_count=25828 evicted_count=18000 eviction_rate=0.696918 and unsatisfied allocation rate=0.000383779
> I tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 24067 get requests, put_count=52078 evicted_count=28000 eviction_rate=0.537655 and unsatisfied allocation rate=0.000124652
> I tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 40317 get requests, put_count=78328 evicted_count=38000 eviction_rate=0.485139 and unsatisfied allocation rate=7.44103e-05
> I tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 56567 get requests, put_count=104578 evicted_count=48000 eviction_rate=0.458988 and unsatisfied allocation rate=5.30345e-05
> I tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 0 get requests, put_count=7016 evicted_count=7000 eviction_rate=0.997719 and unsatisfied allocation rate=0
> I tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 6070 get requests, put_count=23084 evicted_count=17000 eviction_rate=0.736441 and unsatisfied allocation rate=0.000329489
> I tensorflow/core/common_runtime/gpu/pool_allocator.cc:244] PoolAllocator: After 22320 get requests, put_count=49333 evicted_count=27000 eviction_rate=0.547301 and unsatisfied allocation rate=0.000134409
> 


"
6294,feature request: MaxPool gradient of a gradient,"MaxPool gradient of a gradient is not supported as determined in https://github.com/fchollet/keras/issues/4694, which means that examples work in keras with the theano backend but not with the TensorFlow backend. I believe the relevant place where the op is registered is at https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/ops/nn_grad.cc#L153.

From the keras issue:

I successfully ran `python mnist_cnn.py` from https://github.com/fchollet/keras/commit/7e2e7a5e5a43443122df0b497f88dd77fd3bfc7c on my GTX1080 with a TensorFlow R0.12rc0 backend. I then ran python [mnist_swwae.py](https://github.com/fchollet/keras/blob/7e2e7a5e5a43443122df0b497f88dd77fd3bfc7c/examples/mnist_swwae.py)  and got the following failure:

```bash
~/src/keras/examples on master
± python mnist_swwae.py
Using TensorFlow backend.
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcublas.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcudnn.so.5 locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcufft.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcurand.so.8.0 locally
X_train shape: (60000, 1, 28, 28)
60000 train samples
10000 test samples
Traceback (most recent call last):
  File ""mnist_swwae.py"", line 136, in <module>
    y = MaxPooling2D(pool_size=(pool_sizes[i], pool_sizes[i]))(y_prepool)
  File ""/usr/local/lib/python2.7/dist-packages/Keras-1.1.2-py2.7.egg/keras/engine/topology.py"", line 517, in __call__
    self.add_inbound_node(inbound_layers, node_indices, tensor_indices)
  File ""/usr/local/lib/python2.7/dist-packages/Keras-1.1.2-py2.7.egg/keras/engine/topology.py"", line 571, in add_inbound_node
    Node.create_node(self, inbound_layers, node_indices, tensor_indices)
  File ""/usr/local/lib/python2.7/dist-packages/Keras-1.1.2-py2.7.egg/keras/engine/topology.py"", line 155, in create_node
    output_tensors = to_list(outbound_layer.call(input_tensors[0], mask=input_masks[0]))
  File ""/usr/local/lib/python2.7/dist-packages/Keras-1.1.2-py2.7.egg/keras/layers/pooling.py"", line 158, in call
    dim_ordering=self.dim_ordering)
  File ""/usr/local/lib/python2.7/dist-packages/Keras-1.1.2-py2.7.egg/keras/layers/pooling.py"", line 207, in _pooling_function
    border_mode, dim_ordering, pool_mode='max')
  File ""/usr/local/lib/python2.7/dist-packages/Keras-1.1.2-py2.7.egg/keras/backend/tensorflow_backend.py"", line 1853, in pool2d
    x = tf.nn.max_pool(x, pool_size, strides, padding=padding)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/nn_ops.py"", line 1617, in max_pool
    name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_nn_ops.py"", line 1598, in _max_pool
    data_format=data_format, name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py"", line 759, in apply_op
    op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 2242, in create_op
    set_shapes_for_outputs(ret)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 1617, in set_shapes_for_outputs
    shapes = shape_func(op)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 1568, in call_with_requiring
    return call_cpp_shape_fn(op, require_shape_fn=True)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/common_shapes.py"", line 610, in call_cpp_shape_fn
    debug_python_shape_fn, require_shape_fn)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/common_shapes.py"", line 675, in _call_cpp_shape_fn_impl
    raise ValueError(err.message)
ValueError: Negative dimension size caused by subtracting 2 from 1 for 'MaxPool' (op: 'MaxPool') with input shapes: [?,1,32,8].
-> [1]
```"
6292,Squeeze dimension in compute_weighted_loss(),"Operating System: Debian Jessy. CUDA8, CuDNN v5.1. TF 0.12rc0

I am training a CNN for semantic image labeling task and use an FCN-style architecture. In one of the prediction layers I compute weighted loss. The prediction tensor is of dimensions [1, Height, Width, num_predictions] and weight tensor is [1, Height, Width], batch size is always 1 for me. Training fails on this piece of code:

https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/losses/python/losses/loss_ops.py#L178-L179

```
  File ""/BS/eldar/work/src/pose-tf/train_net.py"", line 30, in <module>
    losses = pose_net_train(train_param, batch)
  File ""/BS/eldar/work/src/pose-tf/PoseNet.py"", line 108, in pose_net_train
    loss['locref_loss'] = loss_func(locref_pred, locref_targets, locref_weights)
  File ""/BS/eldar/work/src/pose-tf/losses.py"", line 39, in huber_loss
    return tf_losses.compute_weighted_loss(losses, weight)
  File ""/BS/eldar/work/software/python3_tf_0.12/lib/python3.4/site-packages/tensorflow/python/util/deprecation.py"", line 191, in new_func
    return func(*args, **kwargs)
  File ""/BS/eldar/work/software/python3_tf_0.12/lib/python3.4/site-packages/tensorflow/contrib/losses/python/losses/loss_ops.py"", line 176, in compute_weighted_loss
    weights = array_ops.squeeze(weights, [-1])
  File ""/BS/eldar/work/software/python3_tf_0.12/lib/python3.4/site-packages/tensorflow/python/ops/array_ops.py"", line 2258, in squeeze
    return gen_array_ops._squeeze(input, axis, name)
  File ""/BS/eldar/work/software/python3_tf_0.12/lib/python3.4/site-packages/tensorflow/python/ops/gen_array_ops.py"", line 3313, in _squeeze
    squeeze_dims=squeeze_dims, name=name)
  File ""/BS/eldar/work/software/python3_tf_0.12/lib/python3.4/site-packages/tensorflow/python/framework/op_def_library.py"", line 759, in apply_op
    op_def=op_def)
  File ""/BS/eldar/work/software/python3_tf_0.12/lib/python3.4/site-packages/tensorflow/python/framework/ops.py"", line 2240, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/BS/eldar/work/software/python3_tf_0.12/lib/python3.4/site-packages/tensorflow/python/framework/ops.py"", line 1128, in __init__
    self._traceback = _extract_stack()

InvalidArgumentError (see above for traceback): Tried to explicitly squeeze dimension 2 but dimension was not 1: 24
         [[Node: absolute_difference/Squeeze = Squeeze[T=DT_FLOAT, squeeze_dims=[-1], _device=""/job:localhost/replica:0/task:0/gpu:0""](fifo_queue_Dequeue/_1045)]]
         [[Node: Momentum/update/_1080 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device_incarnation=1, tensor
_name=""edge_4872_Momentum/update"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]
```

My assumption is that it squeezes the dummy dimension that corresponds to the batch size=1, while it clearly shouldn't. For now I just comment out these two lines in the code, but it'd be nicer if there was a fix upstream.

Cheers,
Eldar."
6290,Run tensorboard embedding visualization learning in backgroup (inactive tab of Chrome),"Hi, 

I came across a chrome problem when running embedding visualization using tensorboard. The visualization learning (t-SNE) takes hours to finish. If I switch browser to another tab, the tensorboard tab becomes inactive. Any javascript stops working on the inactive tab. This seems to be the root cause: https://blog.pivotal.io/labs/labs/chrome-and-firefox-throttle-settimeout-setinterval-in-inactive-tabs

I tried making the tab a standalone window, it doesn't work.

That means I have to dedicate a laptop to run the learning. This is awful. Does anyone have a solution? Thanks
"
6289,Is there 3D ConvNets support in TF Slim?,"Is there support for 3D Convnets in Tensorflow Slim? I know Tensorflow does provide support, just would be easier to use TF Slim. "
6287,Windows cuptiActivityRegisterCallbacks not found,"### Environment info
Operating System:
Windows 10 64bit
Python 3.5.2
nVidia GTX 760 (compute capability 3.0)

Installed version of CUDA and cuDNN: 
CUDA 8.0
cuDNN 5.1

A link to the pip package you installed:
Latest nightly build (at least latest I could find)

http://ci.tensorflow.org/job/nightly-win/DEVICE=gpu,OS=windows/lastSuccessfulBuild/artifact/*zip*/archive.zip

2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.
0.12.head

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)

This is the complete code:

```
import tensorflow as tf
import matplotlib.image as mpimg
from tensorflow.python.client import timeline

filename = 'data/MarshOrchid.jpg'
image = mpimg.imread(filename)

with tf.device('/gpu:0'):
    x = tf.Variable(image, name='x', dtype=tf.float32)
    y = tf.transpose(x, perm=[1, 0, 2])
    model = tf.global_variables_initializer()

with tf.Session(config=tf.ConfigProto(log_device_placement=True)) as sess:
    run_options = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)
    run_metadata = tf.RunMetadata()
    sess.run(model)
    result = sess.run(y, options=run_options, run_metadata=run_metadata)

    tl = timeline.Timeline(run_metadata.step_stats)
    ctf = tl.generate_chrome_trace_format()
    with open('timeline.json', 'w') as f:
        f.write(ctf)

```

### What other attempted solutions have you tried?
Works OK:
tf.RunOptions.SOFTWARE_TRACE

Don't work:
tf.RunOptions.HARDWARE_TRACE
tf.RunOptions.FULL_TRACE

### Logs or other output that would be helpful

```
""C:\Program Files\Python35\python.exe"" E:/Documents/Workspace/machine_learning/test/test-1.py
E c:\tf_jenkins\home\workspace\nightly-win\device\gpu\os\windows\tensorflow\core\common_runtime\gpu\gpu_device.cc:586] Could not identify NUMA node of /job:localhost/replica:0/task:0/gpu:0, defaulting to 0.  Your kernel may not have been built with NUMA support.
Device mapping:
/job:localhost/replica:0/task:0/gpu:0 -> device: 0, name: GeForce GTX 760, pci bus id: 0000:01:00.0
x: (Variable): /job:localhost/replica:0/task:0/gpu:0
x/read: (Identity): /job:localhost/replica:0/task:0/gpu:0
transpose: (Transpose): /job:localhost/replica:0/task:0/gpu:0
x/Assign: (Assign): /job:localhost/replica:0/task:0/gpu:0
init: (NoOp): /job:localhost/replica:0/task:0/gpu:0
transpose/perm: (Const): /job:localhost/replica:0/task:0/gpu:0
x/initial_value: (Const): /job:localhost/replica:0/task:0/gpu:0
F c:\tf_jenkins\home\workspace\nightly-win\device\gpu\os\windows\tensorflow\core\platform\default\gpu\cupti_wrapper.cc:59] Check failed: ::tensorflow::Status::OK() == (::tensorflow::Env::Default()->GetSymbolFromLibrary( GetDsoHandle(), kName, &f)) (OK vs. Not found: cuptiActivityRegisterCallbacks not found)could not find cuptiActivityRegisterCallbacksin libcupti DSO

Process finished with exit code -1073740791 (0xC0000409)
```

I suppressed ""I"" messages with ""TF_CPP_MIN_LOG_LEVEL = 1"". I don't know if I'm missing something but it seems like it's trying to load libcupti.so from ""c:\tf_jenkins\..."" path witch doesn't exist. I do have:
""C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v8.0\bin""
""C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v8.0\libnvvp""
in path environment variable. Program works OK. It just gives me an error when I try to trace execution.

I don't know if I messed up something or is this a bug."
6286,Problem about get_variable() and variable_scope(),"NOTE: Only file GitHub issues for bugs and feature requests.  All other topics will be closed.

For general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).
To make bugs and feature requests more easy to find and organize, we close issues that are deemed
out of scope for GitHub Issues and point people to StackOverflow.

For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.

### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?
I retrained the inception-V3 model according to the image_retrain example with one extra conv and pool layers on the top of the original bottleneck layer. The two layers are initialized with get_variable() function
in a variable_scope() and after training the graph and parameters are stored in a .pb file.
But when i read the just trained .pb file for test and wanna retrieve the variables in the two layers, with variable_scope() and get_variable(,reuse=true), exception are raised about 
'Variable weights/W does not exist, or was not created with tf.get_variable(). Did you mean to set reuse=None in VarScope?'

### Environment info
Operating System: Ubuntu 14.04

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):
cuda 8.0
cudnn 5.1

If installed from binary pip package, provide:

1. A link to the pip package you installed: rc0.12.0
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcurand.so locally
0.12.0-rc0



### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)
I initialize the two extra layer as:

```
  with tf.variable_scope('CAM_unit'):
      CAM_conv = new_conv_layer(bottleneck_input,   [3,3,BOTTLENECK_TENSOR_SIZE,BOTTLENECK_TENSOR_SIZE], 'CAM_CONV')
      CAM_pool = tf.reduce_mean(tf.nn.relu(CAM_conv), [1,2], name='CAM_AVG_POOL')
  with tf.variable_scope('weights'):
      layer_weights = tf.get_variable('W', 
                                      shape = [BOTTLENECK_TENSOR_SIZE, class_count], 
                                      initializer = tf.random_normal_initializer(0., 0.01))
```

And access the weights/W variables as:

```
 with tf.variable_scope('weights', reuse=True):
        label_w = tf.gather(tf.transpose(tf.get_variable('W')), label)
```
error is
`Variable weights/W does not exist, or was not created with tf.get_variable(). Did you mean to set reuse=None in VarScope?`

### What other attempted solutions have you tried?
I tried to set reuse=None, but the error is 
`Shape of a new variable (weights/W) must be fully defined, but instead was <unknown>`
I doubt about the .pb file in which the model converged with a very high accuracy, because when i retrain again with this output .pb file, the accuracy is very low like an untrained one. But i import the model, the new added layers are there as expected, just inaccessible with get_variable()


### Logs or other output that would be helpful
(If logs are large, please upload as attachment or provide link).
I import the .pb file with code:
```
ops = [op.name for op in graph.get_operations() if 'weights/' in op.name]
    pprint.pprint(ops)
```
and find the weights/W variables are available:
`[u'weights/W', u'weights/W/read']`"
6285,"in debug mode, got Assertion `cudaGetLastError() == cudaSuccess' failed","Environment: Ubuntu 14.04, CUDA 8, CuDNN 5.1, Tensorflow r0.12
Build command
`bazel build -c opt --config cuda -c dbg --strip=never  //tensorflow/tools/pip_package:build_pip_package`

previously, following the installation of tensorflow (not in debug mode), my code works well. But, after I rebuild with above command, it shows this error in the middle of running the session.

> I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcupti.so.8.0 locally
> python: external/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorExecutor.h:262: static void Eigen::internal::TensorExecutor<Expression, Eigen::GpuDevice, Vectorizable>::run(const Expression&, const Eigen::GpuDevice&) [with Expression = const Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long int>, 16, Eigen::MakePointer>, const Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<const float, const float>, const Eigen::TensorMap<Eigen::Tensor<const float, 1, 1, long int>, 16, Eigen::MakePointer>, const Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<const float>, const Eigen::TensorMap<Eigen::Tensor<const float, 1, 1, long int>, 16, Eigen::MakePointer> > > >; bool Vectorizable = true]: Assertion `cudaGetLastError() == cudaSuccess' failed.

the backtrace result from gdb when the error comes (seems from ReLU operator):
> (gdb) bt
> #0  0x00007ff450df6c37 in __GI_raise (sig=sig@entry=6) at ../nptl/sysdeps/unix/sysv/linux/raise.c:56
> #1  0x00007ff450dfa028 in __GI_abort () at abort.c:89
> #2  0x00007ff450defbf6 in __assert_fail_base (
>     fmt=0x7ff450f403b8 ""%s%s%s:%u: %s%sAssertion `%s' failed.\n%n"", 
>     assertion=assertion@entry=0x7ff42dc57260 ""cudaGetLastError() == cudaSuccess"", 
>     file=file@entry=0x7ff42dc57210 ""external/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorExecutor.h"", line=line@entry=262, 
>     function=function@entry=0x7ff42dc58f80 <Eigen::internal::TensorExecutor<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice, true>::run(Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const&, Eigen::GpuDevice const&)::__PRETTY_FUNCTION__> ""static void Eigen::internal::TensorExecutor<Expression, Eigen::GpuDevice, Vectorizable>::run(const Expression&, const Eigen::GpuDevice&) [with Expression = const Eigen::TensorAssignOp<Eigen::TensorMap""...) at assert.c:92
> #3  0x00007ff450defca2 in __GI___assert_fail (
>     assertion=0x7ff42dc57260 ""cudaGetLastError() == cudaSuccess"", 
>     file=0x7ff42dc57210 ""external/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorExecutor.h"", line=262, 
>     function=0x7ff42dc58f80 <Eigen::internal::TensorExecutor<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice, true>::run(Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const&, Eigen::GpuDevice const&)::__PRETTY_FUNCTION__> ""static void Eigen::internal::TensorExecutor<Expression, Eigen::GpuDevice, Vectorizable>::run(const Expression&, const Eigen::GpuDevice&) [with Expression = const Eigen::TensorAssignOp<Eigen::TensorMap""...) at assert.c:101
> #4  0x00007ff42ad39672 in Eigen::internal::TensorExecutor<Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> const> const, Eigen::GpuDevice, true>::run (expr=..., device=...)
>     at external/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorExecutor.h:260
> #5  0x00007ff42ad37a6b in Eigen::TensorDevice<Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16, Eigen::MakePointer>, Eigen::GpuDevice>::operator=<Eigen::TensorCwiseBinaryOp<Eigen::internal::scalar_max_op<float const, float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const, Eigen::TensorCwiseNullaryOp<Eigen::internal::scalar_constant_op<float const>, Eigen::TensorMap<Eigen::Tensor<float const, 1, 1, long>, 16, Eigen::MakePointer> const> const> > (
>     this=0x7ff35b7fcfe0, other=...)
>     at external/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorDevice.h:35
> #6  0x00007ff42ad36cb0 in tensorflow::functor::Relu<Eigen::GpuDevice, float>::operator() (
>     this=0x7ff35b7fd04f, d=..., features=..., activations=...)
>     at ./tensorflow/core/kernels/relu_op_functor.h:35
> #7  0x00007ff42acf48c1 in tensorflow::ReluOp<Eigen::GpuDevice, float>::Operate (this=0x59fde00, 
>     context=0x7ff35b7fd8f0, input=..., output=0x7ff23ce68390)
>     at ./tensorflow/core/kernels/relu_op.h:40
> #8  0x00007ff42acee479 in tensorflow::UnaryElementWiseOp<float, tensorflow::ReluOp<Eigen::GpuDevice, float> >::Compute (this=0x59fde00, context=0x7ff35b7fd8f0)
>     at ./tensorflow/core/framework/numeric_op.h:62
> #9  0x00007ff42c18523c in tensorflow::BaseGPUDevice::Compute (this=0x5964560, op_kernel=0x59fde00, 
>     context=0x7ff35b7fd8f0) at tensorflow/core/common_runtime/gpu/gpu_device.cc:385
> #10 0x00007ff42c402c39 in tensorflow::(anonymous namespace)::ExecutorState::Process (
>     this=0x3d553c80, tagged_node=..., scheduled_usec=1481634999542636)
>     at tensorflow/core/common_runtime/executor.cc:1364
> #11 0x00007ff42c404881 in tensorflow::(anonymous namespace)::ExecutorState::__lambda4::operator() (
>     __closure=0x3d557a70) at tensorflow/core/common_runtime/executor.cc:1746
> #12 0x00007ff42c40ada4 in std::_Function_handler<void(), tensorflow::(anonymous namespace)::ExecutorState::ScheduleReady(const TaggedNodeSeq&, tensorflow::(anonymous namespace)::ExecutorState::TaggedNodeReadyQueue*)::__lambda4>::_M_invoke(const std::_Any_data &) (__functor=...)
>     at /usr/include/c++/4.8/functional:2071
> #13 0x00007ff428bcc7a8 in std::function<void ()>::operator()() const (this=0x3d557ab0)
>     at /usr/include/c++/4.8/functional:2471
> #14 0x00007ff42c6f0b80 in tensorflow::thread::EigenEnvironment::ExecuteTask (this=0x59921a8, t=...)
>     at tensorflow/core/lib/core/threadpool.cc:82
> #15 0x00007ff42c6f29fb in Eigen::NonBlockingThreadPoolTempl<tensorflow::thread::EigenEnvironment>::WorkerLoop (this=0x59921a0, thread_id=7)
>     at external/eigen_archive/unsupported/Eigen/CXX11/src/ThreadPool/NonBlockingThreadPool.h:167
> #16 0x00007ff42c6f1508 in Eigen::NonBlockingThreadPoolTempl<tensorflow::thread::EigenEnvironment>::NonBlockingThreadPoolTempl(int, tensorflow::thread::EigenEnvironment)::{lambda()#1}::operator()() const
>     () at external/eigen_archive/unsupported/Eigen/CXX11/src/ThreadPool/NonBlockingThreadPool.h:58
> #17 0x00007ff42c6f3927 in std::_Function_handler<void (), Eigen::NonBlockingThreadPoolTempl<tensorflow::thread::EigenEnvironment>::NonBlockingThreadPoolTempl(int, tensorflow::thread::EigenEnvironment)::{lambda()#1}>::_M_invoke(std::_Any_data const&) (__functor=...) at /usr/include/c++/4.8/functional:2071
> #18 0x00007ff428bcc7a8 in std::function<void ()>::operator()() const (this=0x59c3bf0)

I haven't tried anything as I don't have any idea about this error. I tried with other architecture, it was working. The difference between this and other architecture is this architecture (the one with error) has depthwise layer and the other (the one without error) doesn't have depthwise layer. Seems not connected with the error from relu layer, so I don't have any idea. Both architectures were working in the non-debugging mode"
6284,Permission denied: '/usr/local/lib/python2.7/dist-packages/protobuf-3.1.0.post1-py2.7.egg/EGG-INFO/namespace_packages.txt',"Operating System: **Ubuntu 14.04**
Tensorflow version: **0.12.0rc1**

hi all, I have successfully installed tensorflow in my computer, but I encountered the following problem when `import tensorflow` in python 2.7 environment: 

```
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcublas.so.7.0 locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcudnn.so.4 locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcufft.so.7.0 locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcurand.so.7.0 locally
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/tensorflow/_python_build/tensorflow/__init__.py"", line 24, in <module>
    from tensorflow.python import *
  File ""/tensorflow/_python_build/tensorflow/python/__init__.py"", line 63, in <module>
    from tensorflow.core.framework.graph_pb2 import *
  File ""/tensorflow/_python_build/tensorflow/core/framework/graph_pb2.py"", line 6, in <module>
    from google.protobuf import descriptor as _descriptor
  File ""/usr/local/lib/python2.7/dist-packages/protobuf-3.1.0.post1-py2.7.egg/google/__init__.py"", line 2, in <module>
  File ""/usr/lib/python2.7/dist-packages/pkg_resources.py"", line 2760, in <module>
    add_activation_listener(lambda dist: dist.activate())
  File ""/usr/lib/python2.7/dist-packages/pkg_resources.py"", line 738, in subscribe
    callback(dist)
  File ""/usr/lib/python2.7/dist-packages/pkg_resources.py"", line 2760, in <lambda>
    add_activation_listener(lambda dist: dist.activate())
  File ""/usr/lib/python2.7/dist-packages/pkg_resources.py"", line 2314, in activate
    for pkg in self._get_metadata('namespace_packages.txt'):
  File ""/usr/lib/python2.7/dist-packages/pkg_resources.py"", line 2305, in _get_metadata
    for line in self.get_metadata_lines(name):
  File ""/usr/lib/python2.7/dist-packages/pkg_resources.py"", line 1369, in get_metadata_lines
    return yield_lines(self.get_metadata(name))
  File ""/usr/lib/python2.7/dist-packages/pkg_resources.py"", line 1361, in get_metadata
    return self._get(self._fn(self.egg_info,name))
  File ""/usr/lib/python2.7/dist-packages/pkg_resources.py"", line 1470, in _get
    stream = open(path, 'rb')
IOError: [Errno 13] Permission denied: '/usr/local/lib/python2.7/dist-packages/protobuf-3.1.0.post1-py2.7.egg/EGG-INFO/namespace_packages.txt'
```

By searching online, I can solve this error by 
```
sudo chmod o+r /usr/local/lib/python2.7/dist-packages/protobuf-3.1.0.post1-py2.7.egg/EGG-INFO/namespace_packages.txt
```
However, does anyone has other solutions, since I **DO NOT** want use `sudo` frequently? 

Btw, can anyone solve another confusion of mine? I installed tensorflow from source according to the tensorflow's [tutorial.](https://www.tensorflow.org/versions/r0.12/get_started/os_setup.html#installing-from-sources) But I don't quite understand the differences of the following commands used in my installation:
```
sudo pip install /tmp/tensorflow_pkg/tensorflow-0.12.0rc1-py2-none-any.whl
```
and
```
python setup.py develop
```

It seems to me that these two commands all install tensorflow in my system and they all need sudo privilege to work. I also see from tensorflow installation guide that the second command is for development. Could anyone explain in more detail about the differences and purposes of them?

Thanks in advance!"
6282,TensorFlow Serving Broken ?,"I am running TensorFlow from branch r0.11 along with Bazel 0.3.2. I have managed to build TF and with the work arounds to several bugs get TensorBoard up and running. The last problem I am trying to overcome is TensorFlow Serving.

Currently when I try and run: bazel build tensorflow_serving/...

I get the following crash :

bazel build tensorflow_serving/...
.........
WARNING: /home/ubuntu/.cache/bazel/_bazel_ubuntu/7317d353d890cf5e09cb18f5cfc053f7/external/inception_model/WORKSPACE:1: Workspace name in /home/ubuntu/.cache/bazel/_bazel_ubuntu/7317d353d890cf5e09cb18f5cfc053f7/external/inception_model/WORKSPACE (@inception) does not match the name given in the repository's definition (@inception_model); this will cause a build error in future versions.
ERROR: /home/ubuntu/.cache/bazel/_bazel_ubuntu/7317d353d890cf5e09cb18f5cfc053f7/external/org_tensorflow/tensorflow/core/BUILD:1121:1: no such target '@org_tensorflow//tensorflow/tools/git:gen/spec.json': target 'gen/spec.json' not declared in package 'tensorflow/tools/git' defined by /home/ubuntu/.cache/bazel/_bazel_ubuntu/7317d353d890cf5e09cb18f5cfc053f7/external/org_tensorflow/tensorflow/tools/git/BUILD and referenced by '@org_tensorflow//tensorflow/core:version_info_gen'.
ERROR: /home/ubuntu/.cache/bazel/_bazel_ubuntu/7317d353d890cf5e09cb18f5cfc053f7/external/org_tensorflow/tensorflow/core/BUILD:1121:1: no such target '@org_tensorflow//tensorflow/tools/git:gen/head': target 'gen/head' not declared in package 'tensorflow/tools/git' defined by /home/ubuntu/.cache/bazel/_bazel_ubuntu/7317d353d890cf5e09cb18f5cfc053f7/external/org_tensorflow/tensorflow/tools/git/BUILD and referenced by '@org_tensorflow//tensorflow/core:version_info_gen'.
ERROR: /home/ubuntu/.cache/bazel/_bazel_ubuntu/7317d353d890cf5e09cb18f5cfc053f7/external/org_tensorflow/tensorflow/core/BUILD:1121:1: no such target '@org_tensorflow//tensorflow/tools/git:gen/branch_ref': target 'gen/branch_ref' not declared in package 'tensorflow/tools/git' defined by /home/ubuntu/.cache/bazel/_bazel_ubuntu/7317d353d890cf5e09cb18f5cfc053f7/external/org_tensorflow/tensorflow/tools/git/BUILD and referenced by '@org_tensorflow//tensorflow/core:version_info_gen'.
ERROR: Analysis of target '//tensorflow_serving/model_servers:server_core' failed; build aborted.
INFO: Elapsed time: 2.908s

Is this a known problem ?

If I run the following as I am using GPU processing (working on AWS) :

bazel build -c opt --config=cuda tensorflow_serving/...

I get this error:

bazel build -c opt --config=cuda tensorflow_serving/...
ERROR: /home/ubuntu/.cache/bazel/_bazel_ubuntu/7317d353d890cf5e09cb18f5cfc053f7/external/local_config_cuda/crosstool/BUILD:4:1: Traceback (most recent call last):
	File ""/home/ubuntu/.cache/bazel/_bazel_ubuntu/7317d353d890cf5e09cb18f5cfc053f7/external/local_config_cuda/crosstool/BUILD"", line 4
		error_gpu_disabled()
	File ""/home/ubuntu/.cache/bazel/_bazel_ubuntu/7317d353d890cf5e09cb18f5cfc053f7/external/local_config_cuda/crosstool/error_gpu_disabled.bzl"", line 3, in error_gpu_disabled
		fail(""ERROR: Building with --config=c..."")
ERROR: Building with --config=cuda but TensorFlow is not configured to build with GPU support. Please re-run ./configure and enter 'Y' at the prompt to build with GPU support.
ERROR: no such target '@local_config_cuda//crosstool:toolchain': target 'toolchain' not declared in package 'crosstool' defined by /home/ubuntu/.cache/bazel/_bazel_ubuntu/7317d353d890cf5e09cb18f5cfc053f7/external/local_config_cuda/crosstool/BUILD.
INFO: Elapsed time: 0.275s

Both these issues seem to be related to the cache. The second message is odd as GPU processing is enabled and is being used when I run TensorFlow.  Is there a safe way of removing the cache and rebuilding just the bits needed for TensorFlow Serving ? Do you have to install TensorFlow Serving before you install TensorFlow ? I don't want to rebuild everything if I can help it ?"
6281,Cannot import name synthetic - when using add_arg_scope,"### Environment info
Operating System:
Ubuntu 16.04
Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):
````
/path/to/opt/cuda/toolkit_tensorflow/cuda/lib/libcudadevrt.a
/path/to/opt/cuda/toolkit_tensorflow/cuda/lib/libcudart.so -> libcudart.so.8.0
/path/to/opt/cuda/toolkit_tensorflow/cuda/lib/libcudart.so.8.0 -> libcudart.so.8.0.44
/path/to/opt/cuda/toolkit_tensorflow/cuda/lib/libcudart.so.8.0.44
/path/to/opt/cuda/toolkit_tensorflow/cuda/lib/libcudart_static.a
/path/to/opt/cuda/toolkit_tensorflow/cuda/lib/libcudnn.so -> libcudnn.so.5
/path/to/opt/cuda/toolkit_tensorflow/cuda/lib/libcudnn.so.5 -> libcudnn.so.5.1.5
/path/to/opt/cuda/toolkit_tensorflow/cuda/lib/libcudnn.so.5.1.3
/path/to/opt/cuda/toolkit_tensorflow/cuda/lib/libcudnn.so.5.1.5
/path/to/opt/cuda/toolkit_tensorflow/cuda/lib/libcudnn_static.a
````
If installed from source, provide 

1. The commit hash (`git rev-parse HEAD`)
9c41d5f64efedf44d30e5cc21f900ea07097395c

2. The output of `bazel version`
````
Build label: 0.3.2-2016-10-18 (@8fd25d7)
Build target: bazel-out/local-opt/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Tue Oct 18 13:58:42 2016 (1476799122)
Build timestamp: 1476799122
Build timestamp as int: 1476799122
````

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)
````python
import tensorflow as tf

@tf.contrib.framework.add_arg_scope
def my_func(*args, **kwargs):
    pass

````

### Logs or other output that would be helpful
(If logs are large, please upload as attachment or provide link).

````
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/home/user/.local/lib/python2.7/site-packages/tensorflow/contrib/__init__.py"", line 29, in <module>
    from tensorflow.contrib import factorization
  File ""/home/user/.local/lib/python2.7/site-packages/tensorflow/contrib/factorization/__init__.py"", line 24, in <module>
    from tensorflow.contrib.factorization.python.ops.gmm import *
  File ""/home/user/.local/lib/python2.7/site-packages/tensorflow/contrib/factorization/python/ops/gmm.py"", line 30, in <module>
    from tensorflow.contrib.learn.python.learn.estimators import estimator
  File ""/home/user/.local/lib/python2.7/site-packages/tensorflow/contrib/learn/__init__.py"", line 66, in <module>
    from tensorflow.contrib.learn.python.learn import *
  File ""/home/user/.local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/__init__.py"", line 23, in <module>
    from tensorflow.contrib.learn.python.learn import *
  File ""/home/user/.local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/__init__.py"", line 26, in <module>
    from tensorflow.contrib.learn.python.learn import datasets
  File ""/home/user/.local/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/__init__.py"", line 29, in <module>
    from tensorflow.contrib.learn.python.learn.datasets import synthetic
ImportError: cannot import name synthetic
````
"
6279,No attribute batch_matmul,"Hello,
When i run this following python code, i get the error, 

> 'module' object has no attribute 'batch_matmul'

`a = tf.batch_matmul(None,None)`

NB:
I use the bazel build command for CPU optimization

### Environment info
Operating System: Debian jessy

If installed from source, provide 

1. The commit hash (`git rev-parse HEAD`)
9c41d5f64efedf44d30e5cc21f900ea07097395c"
6278,Does the op assign change the gradient computation?,"I use the op ""assign"" to change the value of variables instead of ""="", but I found the gradient I got is quite different. Could anyone tell me the difference and why? thanks!
Like change `w = w1` to  `op1 = tf.assign(w, w1) sess.run(op1)`"
6277,save imgs in tensorboard as eps,Is there any solution to save the images visualized by tensorboard as the eps figures?(like the histogram pictures)
6276,Check failed size >=0,"### Environment info
Operating System: WIndows 10

If installed from binary pip package, provide:
TF_BINARY_URL=https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.11.0-cp27-none-linux_x86_64.whl

I am using a similar code provided in the wide and deep learning tutorial.

Logs  :
F tensorflow/core/framework/tensor_shape.cc:172] Check failed: size >= 0 (-82806 vs. 0)
F tensorflow/core/framework/tensor_shape.cc:36] Check failed: NDIMS == dims() (2 vs. 1)Asking for tensor of 2dimensions from a tensor of 1 dimensions
"
6275,Links to windows builds in os setup documentation are bad,"Build location is listed under https://www.tensorflow.org/versions/r0.12/get_started/os_setup.html#pip-installation-on-windows

For example when trying to retrieve:
```
https://storage.googleapis.com/tensorflow/windows/cpu/tensorflow-0.12.0rc1-cp35-cp35m-win_amd64.whl
```

I get the response
```xml
<Error>
   <Code>NoSuchKey</Code>
   <Message>The specified key does not exist.</Message>
</Error>
```"
6274,seq2seq checkpoints not working,"I am seeing abnormal behavior when I train seq2seq...there are 3 checkpoint files being generated at each checkpoint i.e.:
- seq2seq.ckpt-300.data-00000-of-00001 
- seq2seq.ckpt-300.index
- seq2seq.ckpt-300.meta

Training seems to progress normally with no errors but when I pause training and try to resume or test from the last checkpoint, a model with fresh parameters is created and my training is rendered useless. 

UPDATE:
Initializing tf.train.Saver() with write_version=1 to revert back to the deprecated version appears to have fixed the problem. Now I see that only two files are created at each checkpoint i.e.:
- seq2seq.ckpt-300
- seq2seq.ckpt-300.meta

Obviously this would suggest something is going on with the new write version...any ideas?

**UPDATE:**
The problem is referenced and solved here: http://stackoverflow.com/questions/40469553/tensorflow-loading-model-with-saver-v2"
6272,update docker image,The docker image does not provide updated version of tensorflow. How should I upgrade to 0.12.0 cpu version?
6271,Request for spatial softmax implementation,"Spatial softmax is defined in [End-to-End Training of Deep Visuomotor Policies](https://arxiv.org/abs/1504.00702). This is a request for an implementation in the TensorFlow API, or if the dimension flag for the [regular softmax](https://www.tensorflow.org/versions/r0.12/api_docs/python/nn.html#softmax) does this, could the term and an example be explicitly added to the g3doc?

It seems this may already be implemented with tf but not yet incorporated upstream according to [Collective Robot Reinforcement Learning with Distributed Asynchronous Guided Policy Search](https://arxiv.org/pdf/1610.00673.pdf):

> This entire system, which we call asynchronous distributed
guided policy search (ADGPS), was implemented in the
distributed machine learning framework TensorFlow [...snip...] 
Our architecture resembles prior work, with the visual features 
represented by feature points produced via a spatial softmax
applied to the last convolutional
response maps."
6270,Non-backwards compatible change in moving_averages.assign_moving_average,"A `zero_debias` argument has recently been added to `moving_averages.assign_moving_average`. `zero_debias=True` significantly changes the behavior of `moving_averages.assign_moving_average`, in an unexpected way.

The default value for `zero_debias` is True. It should be False. The True default breaks existing code (it was breaking Keras), and it also a bad default value on its own because it introduces unexpected behavior (one would expect `assign_moving_average` to merely assign a moving average, i.e. return the equivalent of an `assign_add` op. Instead it creates weights, etc)."
6269,GPU kernel for tf.random_shuffle,"There doesn't seem to be a `tf.random_shuffle` impl for the GPU. Some of the work I do can utilize a GPU shuffle.

Running:
  - tf0.12RC0
  - CUDA8.0
  - CUDNN5.1
  - Titan X (non-pascal)

```bash
InvalidArgumentError (see above for traceback): Cannot assign a device to node 'RandomShuffle_8': Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.
	 [[Node: RandomShuffle_8 = RandomShuffle[T=DT_FLOAT, seed=87654321, seed2=703433, _device=""/device:GPU:0""](transpose_16)]]
```"
6268,Gradients in C and C++ APIs,"I have started [porting Tensorflow to Node.js](https://github.com/kmalakoff/tensorflow-node) and was wondering about the status of gradients support in the C and C++ APIs:

- https://www.tensorflow.org/versions/r0.12/how_tos/language_bindings/index.html
- https://github.com/tensorflow/tensorflow/blob/master/tensorflow/g3doc/resources/roadmap.md 

Could I ask for some help and / or offer some assistance? A couple of ideas:

1. I would be happy to test the work-in-progress API in Node.js using either of both [C](https://github.com/kmalakoff/tensorflow-node/tree/master/src/native/c) or [C++](https://github.com/kmalakoff/tensorflow-node/tree/master/src/native/cc). I have tried both APIs and would be happy to maintain both as a test case.  
2. I would be happy to receive some guidance from someone on the tensorflow team on how to implement gradients / training without an official API. I see from this issue (https://github.com/tensorflow/tensorflow/issues/4473) that it might be possible, but it has been hard to study the Python and OCAML code to understand what to do. Some pseudocode or links to existing code that would need to replicated could be enough.
3. Something else? For example, I could help move the gradient API forward by working with someone on the tensorflow team.

Let me know if you have any suggestions for a path forward. Thank you!
"
6267,Request for distribution of prebuilt headers and libraries,"I have been working on a port of [tensorflow to Node.js](https://github.com/kmalakoff/tensorflow-node) and when the node module is installed, it currently requires a time consuming build step and the user to set up bazel. Here is how I trigger the install:  [script](https://github.com/kmalakoff/tensorflow-node/blob/master/scripts/build_tensorflow.sh) and [vendor folder structure](https://github.com/kmalakoff/tensorflow-node/tree/master/vendor).

As part of an investigation into this, I noticed that as part of [installing the python package](https://www.tensorflow.org/versions/r0.10/get_started/os_setup.html), tensorflow is distributing the libraries...for example inside of https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-0.11.0-py2-none-any.whl.

<img width=""691"" alt=""screen shot 2016-12-12 at 12 19 34 pm"" src=""https://cloud.githubusercontent.com/assets/756520/21115291/7c90ada0-c065-11e6-9322-c38d9a2277bf.png"">

I was wondering if the tensorflow team would be open to building and hosting the headers and libraries for a variety of platforms and configurations (eg. cuda, no cuda) that can be downloaded and directly linked to in C++?

FYI: I have also opened an issue with bazel (https://github.com/bazelbuild/bazel/issues/2206) about their plans for prebuilt asset distribution tooling.
"
6266, Could not import the Python Imaging Library (PIL) required to load image files,"NOTE: Only file GitHub issues for bugs and feature requests.  All other topics will be closed.

For general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).
To make bugs and feature requests more easy to find and organize, we close issues that are deemed
out of scope for GitHub Issues and point people to StackOverflow.

For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.

### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?
[http://stackoverflow.com/questions/35534220/importerror-could-not-import-the-python-imaging-library-pil-required-to-load](url)
[http://stackoverflow.com/questions/26720968/pil-importerror-the-imaging-extension-was-built-for-another-version-of-pillow](url)
### Environment info
Operating System:
using docker and tensorflow is installed in a container with IPython notebook. 
Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

If installed from binary pip package, provide:

1. A link to the pip package you installed:
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.
0.11.0
If installed from source, provide 

1. The commit hash (`git rev-parse HEAD`)
2. The output of `bazel version`

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)


### What other attempted solutions have you tried?
I tried the solution provided on stack overflow. I also uninstall pillow package and the install it but no result


### Logs or other output that would be helpful
(If logs are large, please upload as attachment or provide link).
![capture](https://cloud.githubusercontent.com/assets/3126387/21103146/593a86c6-c0d5-11e6-9beb-d685ed80588c.JPG)
"
6265,Feature request: tf.contrib.ffmpeg.decode_video(),"Currently, there is support for audio decoding using FFMmpeg through [tf.contrib.ffmpeg.decode_audio()](https://www.tensorflow.org/versions/master/api_docs/python/contrib.ffmpeg.html). Would it be possible to add something similar for decoding video files?

Thanks!"
6264,Freeze weights during training," Is there any solution to freeze weights? For example, I want to keep some weights unchanged when them satisfy some condition(like weight<0.5) during training."
6263,Document that tf.train.Supervisor is deprecated,"I am using CUDA 8.0, cuDNN 5.1, ubuntu 16.04, GPU: TitanX, tensorflow r0.12.
And I met some problems when using tf.train.Supervisor in distributed training. I have simplified my  code shown as belown:
```python
from __future__ import print_function
import tensorflow as tf

server = tf.train.Server.create_local_server()
logs_path = ""mnist/logs""


global_step = tf.get_variable('global_step', [],
                              initializer=tf.constant_initializer(0),
                              trainable=False)
with tf.name_scope(""weights""):
    W1 = tf.Variable(tf.random_normal([784, 100]))
    W2 = tf.Variable(tf.random_normal([784, 100]))

init_op = tf.global_variables_initializer()
print(""Variables initialized ..."")
sv = tf.train.Supervisor(is_chief=True,
                         logdir=logs_path,
                         global_step=global_step,
                         init_op=init_op,
                         save_model_secs=600)
with sv.managed_session(server.target) as sess:
    while not sv.should_stop():
        print('==============')
sv.stop()
```
The problem is that if I set `logdir` explicitly in tf.train.Supervisor, then the code above will met error like this:`NotFoundError (see above for traceback): Key weights/Variable not found in checkpoint`. But if I comment the lines about defining W1 and W2, then the code could work. So I assume there might be come issues in saving and restoring the checkpoint files in `tf.train.Supervisor` or maybe I did not use `tf.train.Supervisor` correctly. 
"
6262,CMake Build Error for Computing Capability 2.1,"Thanks a lot guys for giving support to windows 💯 


But since I'm having an old GPU(Nvidia 610M) with computing capabilty 2.1 I'm unable to use GPU. Is it possible to run Tensorflow on this GPU???

For trying my luck, I followed instructions from this [comment](https://github.com/tensorflow/tensorflow/issues/6001#issuecomment-264263354) and this cmake [instruction](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/cmake) but I'm running into build errors.

Environment : Windows 10 Pro 1607 64 Bit & Nvidia 610M with Python 3.5, Visual Studio 2015, CUDA 8

I got build error on both MSBuild /p:Configuration=Release tf_python_build_pip_package.vcxproj and MSBuild /p:Configuration=Release tf_tutorials_example_trainer.vcxproj  

Please help me in compiling for this GPU or it would be great if someone could share the whl.
Thank you
![image](https://cloud.githubusercontent.com/assets/7101452/21090262/7b50fe1e-c064-11e6-86f0-0337ae526768.png)
"
6261,text_classification_cnn dataset error,"The dbpedia_csv.tar.gz file downloaded seems to be corrupt and the link for the dataset, i.e.
https://googledrive.com/host/0Bz8a_Dbh9Qhbfll6bVpmNUtUcFdjYmF2SEpmZUZUcVNiMUw1TWN6RDV3a0JHT3kxLVhVR2M/dbpedia_csv.tar.gz

is giving 404 error. The file dbpedia_csv.tar.gz seems to be downloaded but upon running tensorflow/tensorflow/examples/learn/text_classification_cnn.py, an error is produced giving

Successfully downloaded dbpedia_csv.tar.gz 1657 bytes.
Traceback (most recent call last):
  File ""main.py"", line 122, in <module>
    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 43, in run
    sys.exit(main(sys.argv[:1] + flags_passthrough))
  File ""main.py"", line 88, in main
    'dbpedia', test_with_fake_data=FLAGS.test_with_fake_data, size='large')
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/datasets/__init__.py"", line 64, in load_dataset
    return DATASETS[name](size, test_with_fake_data)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/datasets/text_datasets.py"", line 48, in load_dbpedia
    maybe_download_dbpedia(data_dir)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/datasets/text_datasets.py"", line 40, in maybe_download_dbpedia
    tfile = tarfile.open(archive_path, 'r:*')
  File ""/usr/lib/python2.7/tarfile.py"", line 1678, in open
    raise ReadError(""file could not be opened successfully"")
tarfile.ReadError: file could not be opened successfully
"
6260, Android error: No OpKernel was registered to support Op 'DecodeJpeg' with these attrs,"hi! there is a mistake when i try to use my model on Android to classify pictures. 

tensorflow_jni.cc:304 Error during inference: Invalid argument: No OpKernel was registered to support Op 'DecodeJpeg' with these attrs
          	 [[Node: DecodeJpeg = DecodeJpeg[acceptable_fraction=1, channels=3, fancy_upscaling=true, ratio=1, try_recover_truncated=false](DecodeJpeg/contents)]]

### Environment info
my tensorflow version is 0.10 and i train pictures by tensorflow/examples/image_retraining/retain.py on ubuntu 16.04 with GPU

how can i solve it? thanks!

"
6259,Embedding Projector Standalone isn't reading its demo data folder,"Upon opening https://github.com/tensorflow/embedding-projector-standalone, there is nondescript popup error message and application loads with no data. 

index.html has:
`projector-config-json-path=""oss_data/oss_demo_projector_config.json""`
but the data isn't loading. 

Project also has no Readme so perhaps I'm not running it, correctly? "
6256,grpc worker->client fetch tops out at 120 MB/s,"Fetching data as numpy arrays is slow for grpc sessions. Evaluating 128MB variable repeatedly from `Session(""grpc://localhost.."")` only gets me 116 MB/s, compared to 5150MB/s for `Session()`

https://gist.github.com/yaroslavvb/59bc8d3d635e1027306486cc418b26aa
```
python client_transfer_benchmark.py --profile
5150.04 MB per second
116.70 MB per second

```
Attached are CPU profiles for worker and for client. Worker uses 2x CPU and both of them are spending majority of the time in in gRPC code, specifically doing `strcmp` (reported as [__nss_hosts_lookup](https://github.com/gperftools/gperftools/issues/1)). 

[profile.client.pdf](https://github.com/tensorflow/tensorflow/files/644905/profile.client.pdf)
[profile.worker.pdf](https://github.com/tensorflow/tensorflow/files/644906/profile.worker.pdf)


This is related but slightly different from https://github.com/tensorflow/tensorflow/issues/6116 -- that issue looks at worker->worker transfer which hits 520 MB/second for the same message size (degrading below 100 MB/second for larger messages)

https://gist.github.com/yaroslavvb/e196107b5e0afc834652bd3153030c42
```
python benchmark_grpc_recv.py --data_mb=128
Local rate:       15214.63 MB/s
Distributed rate: 569.27 MB/s


```
"
6255,TF0.12  NewCheckpointReader() Unsuccessful TensorSliceReader constructor,"I am using Ubuntu 16.04.1 LTS.

I recently switched from TF r0.10 to TF r0.12. With TF r0.12, NewCheckpointReader('name.ckpt') gives error 'Unsuccessful TensorSliceReader constructor'. The files: 'name.ckpt.meta', 'name.ckpt.index' and 'name.ckpt.data-00000-of-00001' exist (as produced by the saver object).

In TF 0.10, the saver was producing  the file 'name.ckpt' that I could read using NewCheckpointReader('name.ckpt'). This does not seem to work in TF r0.12. In TF r0.12, the python documentation says to use: tf.train.NewCheckpointReader(filepattern), but I cannot find any
detail about filepattern  (tried something obvious, but I could not make it work).

Is this a bug ? If not, could somebody explain what is a filepattern  (corresponding to 'name.ckpt') in TF r0.12 ?

Issue #751 seems similar to this one, but it is different as  that is related to the saver, rather than to NewCheckPointReader()

Thank you"
6254,Fail Installation through pip on Windows version 10.0.10586,"For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.

### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?

### Environment info
Operating System: windows 10 (version 10.0.10586)

pip version 
pip 9.0.1 from d:\program files\python\lib\site-packages (python 3.5)

the Fail issue information :

C:\Users\Administrator>pip install --upgrade https://storage.googleapis.com/tensorflow/windows/cpu/tensorflow-0.12.0rc0-cp35-cp35m-win_amd64.whl

tensorflow-0.12.0rc0-cp35-cp35m-win_amd64.whl is not a supported wheel on this platform.
![bug](https://cloud.githubusercontent.com/assets/8590489/21081141/91a281b0-bffb-11e6-898a-60fa48b243dc.png)


### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)


### What other attempted solutions have you tried?


### Logs or other output that would be helpful
(If logs are large, please upload as attachment or provide link).
"
6253,reduce_mean operation gives inconsistent results on GPU,"After hyperparameter optimization, the program I wrote does some checks to see that the results are consistent. However even with the same seeds everywhere, I found that TF doesn't always give the same results. Furthermore: the results of numpy mean and tensorflow reduce_mean also differ.

After quite some digging, I found it's because the reduce_mean operation on the GPU gives inconsistent results. I think it's because the last two bits of the mantissa of the float returned are sometimes 01 and sometimes 10. The differences are minimally, however after a lot of reduce_mean operations, the differences can become quite significant.

Below I've included a short code to reproduce the error. When using the GPU the results of the mean operation are sometimes different. When using the CPU the results are consistent However with both CPU & GPU the results of Numpy and TensorFlow are still sometimes different.



### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?
None

### Environment info
Operating System:
Debian 8.6
Kernel: Linux 3.16.0-4-amd64

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):
/usr/local/cuda/lib64/libcudadevrt.a /usr/local/cuda/lib64/libcudart.so.8.0.44 /usr/local/cuda/lib64/libcudnn.so.5
/usr/local/cuda/lib64/libcudart.so /usr/local/cuda/lib64/libcudart_static.a /usr/local/cuda/lib64/libcudnn.so.5.1.5
/usr/local/cuda/lib64/libcudart.so.8.0 /usr/local/cuda/lib64/libcudnn.so /usr/local/cuda/lib64/libcudnn_static.a


If installed from binary pip package, provide:

1. A link to the pip package you installed:
pip install tensorflow-gpu

2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.
0.12.rc1

If installed from source, provide 

1. The commit hash (`git rev-parse HEAD`)
2. The output of `bazel version`

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)
```
import os
# comment line below to use CPU instead of GPU
os.environ['CUDA_VISIBLE_DEVICES'] = ''

import tensorflow as tf
import numpy as np

SIZE = 1000

tf_x = tf.placeholder(tf.float32, (None))
tf_var2 = tf.reduce_mean(tf_x)

x = np.random.rand(SIZE).astype(np.float32)
sess = tf.Session()
sess.run(tf.global_variables_initializer())

tf_mean= np.empty(SIZE, dtype=np.float32)
np_mean=np.empty(SIZE, dtype=np.float32)

for j in range(SIZE):
    x_evaled, mean_ = sess.run([tf_x, tf_var2], feed_dict={tf_x: x})
    tf_mean[j] = mean_
    np_mean[j] = x.mean()

same_ = (tf_mean == np_mean).astype(np.float32).mean()
consistency_ = (tf_mean == tf_mean[0]).astype(np.float32).mean()

# print results
print('\nMin, Max TF mean: {}, {} \nMin, Max NP mean: {}, {}'.format(tf_mean.min(), tf_mean.max(), np_mean.min(), np_mean.max()))
print('TF & NP was the same: {:.2%}'.format(same_))
print('TF consistency: {:.2%}'.format(consistency_))
```

### What other attempted solutions have you tried?
Changing the float to 16, 32, or 64 bit made no difference

### Logs or other output that would be helpful
Using CPU:
'''
Min, Max TF mean: 0.49667325615882874, 0.49667325615882874 
Min, Max NP mean: 0.4966733157634735, 0.4966733157634735
TF & NP were the same: 0.00%
TF consistency: 100.00%
'''
Using GPU:
'''
Min, Max TF mean: 0.49240124225616455, 0.4924013018608093 
Min, Max NP mean: 0.49240124225616455, 0.49240124225616455
TF & NP were the same: 29.80%
TF consistency: 47.90%
'''
"
6252,"""Notebook validation failed"" (docker, official image, gpu)","### The bug

An error box pops up whenever Jupyter tries to save [the 1_hello_tensorflow notebook](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/docker/notebooks/1_hello_tensorflow.ipynb).

### Environment info
Ubuntu 16.04.1
Nvidia driver 375.20
GeForce GTX 1070

### Minimal reproducible example

`nvidia-docker run -it -p 8888:8888 -e PASSWORD=""hi"" gcr.io/tensorflow/tensorflow:latest-gpu`

### Logs

```
$ nvidia-docker run -it -p 8888:8888 -e PASSWORD=""hi"" gcr.io/tensorflow/tensorflow:latest-gpu
[...]
[E 11:41:58.708 NotebookApp] Notebook JSON is invalid: Additional properties are not allowed (u'metadata' was unexpected)
    
    Failed validating u'additionalProperties' in stream:
    
    On instance[u'cells'][3][u'outputs'][0]:
    {u'metadata': {},
     u'name': u'stdout',
     u'output_type': u'stream',
     u'text': u'result:  [ 3.  3.  3.  3.]\n'}
```
![screenshot from 2016-12-11 03-50-33](https://cloud.githubusercontent.com/assets/8968171/21079898/059c7ab4-bf55-11e6-8986-d8238f90cdcc.png)

### Why I posted this here
The bug occurs on an official TensorFlow Docker image.

### Dockerless version of the bug
https://github.com/jupyter/notebook/issues/1964

#### Minimal reproducible example

```
wget https://raw.githubusercontent.com/tensorflow/tensorflow/master/tensorflow/tools/docker/notebooks/1_hello_tensorflow.ipynb
jupyter notebook --port=8889 1_hello_tensorflow.ipynb
```"
6251,tensorflow crash when training in distribution,"I'am train my model in distribution, running 12 workers and 2 ps server.
But the worker crash and dumping core files continuously.


### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?
nothing

### Environment info
Operating System:
centos 6.3 with cpu
tensorflow version 0.12

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)
```
if __name__ == ""__main__"":
  ps_hosts = FLAGS.ps_hosts.split("","")
  worker_hosts = FLAGS.worker_hosts.split("","")
  cluster = tf.train.ClusterSpec({""ps"": ps_hosts, ""worker"": worker_hosts})
  server = tf.train.Server(cluster,
                           job_name=FLAGS.job_name,
                           task_index=FLAGS.task_index)
  if FLAGS.job_name == ""ps"":
    server.join()
  elif FLAGS.job_name == ""worker"":
    with tf.device(tf.train.replica_device_setter(
            worker_device=""/job:worker/task:%d"" % FLAGS.task_index,
            cluster=cluster)):
        # Read TFRecords files for training
        filename_queue = tf.train.string_input_producer(
            tf.train.match_filenames_once(FLAGS.train),
            num_epochs=epoch_number)
        serialized_example = read_and_decode(filename_queue)
        batch_serialized_example = tf.train.shuffle_batch(
            [serialized_example],
            batch_size=batch_size,
            num_threads=thread_number,
            capacity=capacity,
            min_after_dequeue=min_after_dequeue)
        features = tf.parse_example(
            batch_serialized_example,
            features={
                ""label"": tf.FixedLenFeature([], tf.float32),
                ""ids"": tf.VarLenFeature(tf.int64),
                ""values"": tf.VarLenFeature(tf.float32),
            })
        batch_labels = features[""label""]
        batch_ids = features[""ids""]
        batch_values = features[""values""]

        # Read TFRecords file for validatioin
        validate_filename_queue = tf.train.string_input_producer(
            tf.train.match_filenames_once(FLAGS.eval),
            num_epochs=epoch_number)
        validate_serialized_example = read_and_decode(validate_filename_queue)
        validate_batch_serialized_example = tf.train.shuffle_batch(
            [validate_serialized_example],
            batch_size=validate_batch_size,
            num_threads=thread_number,
            capacity=capacity,
            min_after_dequeue=min_after_dequeue)
        validate_features = tf.parse_example(
            validate_batch_serialized_example,
            features={
                ""label"": tf.FixedLenFeature([], tf.float32),
                ""ids"": tf.VarLenFeature(tf.int64),
                ""values"": tf.VarLenFeature(tf.float32),
            })
        validate_batch_labels = features[""label""]
        validate_batch_ids = features[""ids""]
        validate_batch_values = features[""values""]
        logits = inference(batch_ids, batch_values)
        batch_labels = tf.to_int64(batch_labels)
        cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits,
                                                                       batch_labels)
        loss = tf.reduce_mean(cross_entropy, name='loss')

        print(""Use the optimizer: {}"".format(FLAGS.optimizer))
        if FLAGS.optimizer == ""sgd"":
            optimizer = tf.train.GradientDescentOptimizer(learning_rate)
        elif FLAGS.optimizer == ""momentum"":
            # optimizer = tf.train.MomentumOptimizer(learning_rate)
            print(""Not support optimizer: {} yet, exit now"".format(FLAGS.optimizer))
            exit(1)
        elif FLAGS.optimizer == ""adadelta"":
            optimizer = tf.train.AdadeltaOptimizer(learning_rate)
        elif FLAGS.optimizer == ""adagrad"":
            optimizer = tf.train.AdagradOptimizer(learning_rate)
        elif FLAGS.optimizer == ""adam"":
            optimizer = tf.train.AdamOptimizer(learning_rate)
        elif FLAGS.optimizer == ""ftrl"":
            optimizer = tf.train.FtrlOptimizer(learning_rate)
        elif FLAGS.optimizer == ""rmsprop"":
            optimizer = tf.train.RMSPropOptimizer(learning_rate)
        else:
            print(""Unknow optimizer: {}, exit now"".format(FLAGS.optimizer))
            exit(1)

        #with tf.device(""/cpu:0""):
        global_step = tf.Variable(0, name='global_step', trainable=False)
        train_op = optimizer.minimize(loss, global_step=global_step)

        # Compute accuracy
        tf.get_variable_scope().reuse_variables()
        accuracy_logits = inference(validate_batch_ids, validate_batch_values)
        validate_softmax = tf.nn.softmax(accuracy_logits)
        validate_batch_labels = tf.to_int64(validate_batch_labels)
        correct_prediction = tf.equal(
            tf.argmax(validate_softmax, 1), validate_batch_labels)
        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))

        # Compute auc
        validate_batch_labels = tf.cast(validate_batch_labels, tf.int32)
        sparse_labels = tf.reshape(validate_batch_labels, [-1, 1])
        derived_size = tf.shape(validate_batch_labels)[0]
        indices = tf.reshape(tf.range(0, derived_size, 1), [-1, 1])
        concated = tf.concat(1, [indices, sparse_labels])
        outshape = tf.pack([derived_size, LABEL_SIZE])
        new_validate_batch_labels = tf.sparse_to_dense(concated, outshape, 1.0, 0.0)
        _, auc_op = tf.contrib.metrics.streaming_auc(validate_softmax,
                                                     new_validate_batch_labels)

        # Define inference op
        sparse_index = tf.placeholder(tf.int64)
        sparse_ids = tf.placeholder(tf.int64)
        sparse_values = tf.placeholder(tf.float32)
        sparse_shape = tf.placeholder(tf.int64)
        inference_ids = tf.SparseTensor(sparse_index, sparse_ids, sparse_shape)
        inference_values = tf.SparseTensor(sparse_index, sparse_values, sparse_shape)
        inference_logits = inference(inference_ids, inference_values)
        inference_softmax = tf.nn.softmax(inference_logits)
        inference_op = tf.argmax(inference_softmax, 1)

        # Initialize saver and summary
        #checkpoint_file = checkpoint_dir + ""checkpoint.ckpt""
        steps_to_validate = FLAGS.steps_to_validate
        init_op = tf.initialize_all_variables()

        saver = tf.train.Saver(max_to_keep = 2)
        keys_placeholder = tf.placeholder(""float"")
        keys = tf.identity(keys_placeholder)
        tf.add_to_collection(""inputs"", json.dumps({'key': keys_placeholder.name}))
        tf.add_to_collection(""outputs"", json.dumps({'key': keys.name,
                                                    'softmax': inference_softmax.name,
                                                    'prediction': inference_op.name}))
        tf.scalar_summary('loss', loss)
        tf.scalar_summary('accuracy', accuracy)
        tf.scalar_summary('auc', auc_op)
        summary_op = tf.merge_all_summaries()


    sv = tf.train.Supervisor(is_chief=(FLAGS.task_index == 0),
                             logdir=""./train_process/"",
                             init_op=init_op,
                             summary_op=summary_op,
                             saver=saver,
                             global_step=global_step,
                             save_model_secs=60)

    # Create session to run graph
    with sv.managed_session(server.target) as sess:
        if mode == ""train"" or mode == ""train_from_scratch"":
            while not sv.should_stop():
                # Get coordinator and run queues to read data
                coord = tf.train.Coordinator()
                threads = tf.train.start_queue_runners(coord=coord, sess=sess)

                start_time = datetime.datetime.now()

                try:
                    while not coord.should_stop():
                        _, loss_value, step = sess.run([train_op, loss, global_step])
                        if step % steps_to_validate == 0:
                            accuracy_value, auc_value, summary_value = sess.run(
                                [accuracy, auc_op, summary_op])
                            end_time = datetime.datetime.now()
                            print(""[{}] Task: {}, Step: {}, loss: {}, accuracy: {}, auc: {}"".format(
                                end_time - start_time,
                                FLAGS.task_index,
                                step, loss_value, accuracy_value,
                                auc_value))

                            start_time = end_time
                except tf.errors.OutOfRangeError:
                    print(""Done training after reading all data"")
                finally:
                    coord.request_stop()
                    print(""coord stopped"")

                # Wait for threads to exit
                coord.join(threads)
```

### logs

gdb python core.xxxxx , and then 'bt', shows that

```

#0  0x00007f5943d3f166 in pthread_detach () from /opt/glibc-2.17/lib/libpthread.so.0
#1  0x00007f58fc8c8ab5 in std::thread::detach() ()
    at /opt/install/gcc-build/x86_64-redhat-linux/libstdc++-v3/include/x86_64-redhat-linux/bits/gthr-default.h:674
#2  0x00007f58fec7f0bf in tensorflow::(anonymous namespace)::PosixEnv::SchedClosure(std::function<void ()()>) ()
   from /home/serving/anaconda2/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so
#3  0x00007f58fea8e981 in tensorflow::SchedClosure(std::function<void ()()>) ()
   from /home/serving/anaconda2/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so
#4  0x00007f58fd5f72cd in tensorflow::Master::RunStep(tensorflow::CallOptions*, tensorflow::RunStepRequest const*, tensorflow::RunStepResponse*, std::function<void ()(tensorflow::Status const&)>) ()
   from /home/serving/anaconda2/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so
#5  0x00007f58fd5f10f9 in tensorflow::GrpcMasterService::RunStepHandler(tensorflow::Call<tensorflow::GrpcMasterService, tensorflow::grpc::MasterService::AsyncService, tensorflow::RunStepRequest, tensorflow::RunStepResponse>*) ()
   from /home/serving/anaconda2/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so
#6  0x00007f58fd5f2c4c in tensorflow::GrpcMasterService::HandleRPCsLoop() ()
   from /home/serving/anaconda2/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so
#7  0x00007f58fc8c8b80 in execute_native_thread_routine_compat ()
    at ../../../../../gcc-6.2.0/libstdc++-v3/src/c++11/thread.cc:110
#8  0x00007f5943d3df83 in start_thread () from /opt/glibc-2.17/lib/libpthread.so.0
#9  0x00007f59433668bd in clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:113

```"
6250,can't export data via event_accumulator.py,"f you'd like to export data to visualize elsewhere (e.g. iPython Notebook), that's possible too. You can directly depend on the underlying classes that TensorBoard uses for loading data: python/summary/event_accumulator.py (for loading data from a single run) or python/summary/event_multiplexer.py (for loading data from multiple runs, and keeping it organized). These classes load groups of event files, discard data that was ""orphaned"" by TensorFlow crashes, and organize the data by tag.

And I do it as what it sayid with the mnist example in tensorflow. But I can't get any event from the original data whereas it shows on the tensorboard normally.

below is my code:

x = EventAccumulator(path=""/tmp/tensorflow/mnist/logs/mnist_with_summaries/"")
x.Reload()
print(x.Tags())
x.FirstEventTimestamp()
print(x.Tags())
And the result showed like below:

{'scalars': [], 'histograms': [], 'run_metadata': [], 'images': [], 'graph': False, 'audio': [], 'meta_graph': False, 'compressedHistograms': []}

I can't get any tag or event from the original data. However, when I open the tensorboard. Everything just look fine.

"
6249,"InvalidArgumentError: Input to reshape is a tensor with 313600 values, but the requested shape requires a multiple of 4608","When I implemented this (https://github.com/fchollet/keras/blob/master/examples/mnist_cnn.py) by TensorFlow, I had an issue on reshaping. When I tried to flatten 12 \* 12 \* 32 tensor, I had an error message saying 
`
tensorflow.python.framework.errors.InvalidArgumentError: Input to reshape is a tensor with 313600 values, but the requested shape requires a multiple of 4608
     [[Node: Reshape_1 = Reshape[T=DT_FLOAT, Tshape=DT_INT32, _device=""/job:localhost/replica:0/task:0/cpu:0""](dropout/mul, Reshape_1/shape)]]`

I tried to match the input shape, but the error message said ""a tensor with 313600 values"" which I had no idea where this came from. Therefore, I thought this might be an issue on TensorFlow.  

All the code and error message are uploaded here. http://stackoverflow.com/questions/40955223/tensorflow-python-framework-errors-invalidargumenterror-input-to-reshape-is-a-t 

### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?
http://stackoverflow.com/questions/38397258/error-tensorflow-cnn-dimension
https://github.com/tensorflow/tensorflow/issues/2048

### Environment info
Operating System: macOS Sierra 10.12.1 
Python 3.5.1

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):
No such file or directory

If installed from binary pip package, provide:

1. A link to the pip package you installed: pip install tensorflow
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.
0.11.0rc1

If installed from source, provide 

1. The commit hash (`git rev-parse HEAD`)
2. The output of `bazel version`

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)


### What other attempted solutions have you tried?
I tried the following solutions and I confirmed that I defined the target image for reshaping/flattening.
http://stackoverflow.com/questions/38397258/error-tensorflow-cnn-dimension
https://github.com/tensorflow/tensorflow/issues/2048

### Logs or other output that would be helpful
(If logs are large, please upload as attachment or provide link).
I wrote all the code and errors here.
http://stackoverflow.com/questions/40955223/tensorflow-python-framework-errors-invalidargumenterror-input-to-reshape-is-a-t

"
6248,Configure fails when run non-interactively,"Running ./configure non-interactively fails for 0.12.0-rc0, and it worked on previous releases.  We're relying on this for the TensorFlow Rust bindings and expect it to configure with default options.  configure seems to be failing on a 'read -p', probably because of 'set -e' being added.

### Environment info
Operating System: Linux (Ubuntu 16.04.1)
Checked out tag: 0.12.0-rc0

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)
./configure < /dev/null"
6247,How can a tensor remain in gpu when the kernel is launched but does not finish yet?,"It confuse me a lot. I'm reading the stream executor part of tensorflow's source code. I find that once a graph is executed on a gpu device, each kernel of the graph's nodes just allocates the output memory and launches the cuda kernel on gpu on a stream by passing the input and output device memory. So the op kernel is done but the real execution of the kernel (e.g. cuda) may not be done on the gpu yet. Here is the question: how can tensorflow assure the input memory allocated on the gpu devices still live when the execution really happens on the gpu? I checked the executor.cc file and found that once a kernel is launched, the input tensor is destroyed. Can anyone show me what I miss? Thanks!"
6242,DNNLinearCombinedClassifier predict method generate : Predictions: <generator object _as_iterable at 0x7eff0a1b2910>,"NOTE: Only file GitHub issues for bugs and feature requests.  All other topics will be closed.

For general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).
To make bugs and feature requests more easy to find and organize, we close issues that are deemed
out of scope for GitHub Issues and point people to StackOverflow.

For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.

### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?

### Environment info
Operating System:

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

If installed from binary pip package, provide:

1. A link to the pip package you installed:
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.

If installed from source, provide 

1. The commit hash (`git rev-parse HEAD`)
2. The output of `bazel version`

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)


### What other attempted solutions have you tried?


### Logs or other output that would be helpful
(If logs are large, please upload as attachment or provide link).
"
6241,TensorFlow Models now missing ?,"So currently doing some testing of the latest master branch on an AWS box. I built yesterday (UK time) and I went through installing tensorflow fine with no issues.

Today I have done a fresh install again taking from the master branch and for some reason when I run my samples through I get the following:

python -m tensorflow.models.image.mnist.convolutional
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcublas.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcudnn.so.5 locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcufft.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcurand.so.8.0 locally
/home/ubuntu/anaconda3/bin/python: Error while finding spec for 'tensorflow.models.image.mnist.convolutional' (<class 'ImportError'>: No module named 'tensorflow.models')
"
6240,what is op 'Switch' in RNN?,"I build a two-layer RNN (GRU) network using tf.nn.dynamic_rnn with argument sequence_length. Then the graph contains an op 'Switch' which I haven't seen before. 
 919 node {
 920   name: ""Test/Model/RNN/RNN/Assert/AssertGuard/Switch""
 921   op: ""Switch""
 922   input: ""Test/Model/RNN/RNN/All""
 923   input: ""Test/Model/RNN/RNN/All""
 924   attr {
 925     key: ""T""
 926     value {
 927       type: DT_BOOL
 928     }
 929   }

I need to do inference in android and it complains this op is not registered in kernel files. I wonder what it is and there should be a python wrap or .cc file to implement this I guess."
6237,Embedding projector: clicking on points doesn't select them.,"In Chrome, clicking on points (regardless of dataset, PCA or T-SNE, 2D or 3D) will not select them. Win10, Chrome Version 55.0.2883.87 m"
6235,[Windows] Couldn't open CUDA library cupti64_80.dll,"NOTE: Only file GitHub issues for bugs and feature requests.  All other topics will be closed.

For general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).
To make bugs and feature requests more easy to find and organize, we close issues that are deemed
out of scope for GitHub Issues and point people to StackOverflow.

For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.

### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?

[This issue ](https://github.com/tensorflow/tensorflow/issues/5968) is not applicable for me as CuDNN is getting loaded. I checked the CuDNN folder manually, there is no such dll.

### Environment info
Operating System: Windows 10 Pro

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

```
D:\TensorFlow>nvcc --version
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2016 NVIDIA Corporation
Built on Sat_Sep__3_19:05:48_CDT_2016
Cuda compilation tools, release 8.0, V8.0.44
```

```
cudnn-8.0-windows10-x64-v5.1.zip
```

If installed from binary pip package, provide:

1. A link to the pip package you installed: Sorry, I cant remember which package pip fetched. I just ran this command.
```
D:\TensorFlow>pip3.5 install --upgrade tensorflow-gpu
Requirement already up-to-date: tensorflow-gpu in c:\users\windows\appdata\local\programs\python\python35\lib\site-packages
Requirement already up-to-date: wheel>=0.26 in c:\users\windows\appdata\local\programs\python\python35\lib\site-packages (from tensorflow-gpu)
Requirement already up-to-date: six>=1.10.0 in c:\users\windows\appdata\local\programs\python\python35\lib\site-packages (from tensorflow-gpu)
Requirement already up-to-date: numpy>=1.11.0 in c:\users\windows\appdata\local\programs\python\python35\lib\site-packages (from tensorflow-gpu)
Requirement already up-to-date: protobuf==3.1.0 in c:\users\windows\appdata\local\programs\python\python35\lib\site-packages (from tensorflow-gpu)
Requirement already up-to-date: setuptools in c:\users\windows\appdata\local\programs\python\python35\lib\site-packages (from protobuf==3.1.0->tensorflow-gpu)
```
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.

```
I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\stream_executor\dso_loader.cc:128] successfully opened CUDA library cublas64_80.dll locally
I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\stream_executor\dso_loader.cc:128] successfully opened CUDA library cudnn64_5.dll locally
I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\stream_executor\dso_loader.cc:128] successfully opened CUDA library cufft64_80.dll locally
I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\stream_executor\dso_loader.cc:128] successfully opened CUDA library nvcuda.dll locally
I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\stream_executor\dso_loader.cc:128] successfully opened CUDA library curand64_80.dll locally
0.12.0-rc1
```

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)

```
import tensorflow as tf
import numpy as np
import random

vLength = 8

nodeCount = [vLength,8,8,vLength]

SUMMARY_DIR = 'D:/Summary/'

BATCH_SIZE = 10
TRAIN_SIZE = 100

def model(x_t):    
    layerCount = len(nodeCount)
    layer = [None for _ in range(layerCount)]
    weights = [None for _ in range(layerCount - 1)]
    biases = [None for _ in range(layerCount - 1)]
    layer[0] = x_t
    for i in range(layerCount-1):
        weights[i] = tf.Variable(tf.random_normal([nodeCount[i],nodeCount[i+1]]))
        biases[i] = tf.Variable(tf.random_normal([nodeCount[i+1]]))
          
        layer[i+1] = tf.add(tf.matmul(layer[i],weights[i]),biases[i])
        if(i != layerCount-2):
            layer[i+1] = tf.nn.tanh(layer[i+1])
        else:
            layer[i+1] = tf.nn.softmax(layer[i+1])

    return layer[i+1]

def getNextBatch():
    v = [0.0 for _ in range(vLength)]
    v[0] = 1.0

    r = [None for _ in range(BATCH_SIZE)]
    for i in range(BATCH_SIZE):
        random.shuffle(v)
        r[i] = v.copy()
    return r,r
    
m = None
def trainNN():
    x_t = tf.placeholder(tf.float32,[None,vLength],'input')
    y_t = tf.placeholder(tf.float32, [None, vLength],'actual')
    
    m = model(x_t)    

    with tf.name_scope('Cost_Function'):
        cost = tf.reduce_mean(-tf.reduce_sum(y_t * tf.log(m)))
        
    with tf.name_scope('Learning_Rate'):
        learning_rate = tf.Variable(0.5,dtype=tf.float32)

    with tf.name_scope('Optimizer'):
        optimizer = tf.train.AdamOptimizer().minimize(cost)

    with tf.name_scope('testing'):
        correct = tf.equal(tf.argmax(y_t,1),tf.argmax(m,1))
        accuracy = tf.reduce_mean(tf.cast(correct,'float'))
        tf.summary.scalar('accuracy',accuracy)

    epochs = 10

    with tf.Session() as sess:
        merged = tf.summary.merge_all()
        
        sess.run(tf.global_variables_initializer())
        
        for epoch in range(epochs):            
            tw = tf.summary.FileWriter(SUMMARY_DIR+'/epoch'+str(epoch),sess.graph)
            epochLoss = 0
            c = 0
            for i in range(TRAIN_SIZE):
                bx,by = getNextBatch()    
                fd = {x_t:bx,y_t:by}                
                run_metadata = tf.RunMetadata()
                run_options = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)
                summary,c,_ = sess.run([merged,cost,optimizer],
                              feed_dict=fd,
                              options=run_options,
                              run_metadata=run_metadata)
                if(i%BATCH_SIZE == 0):
                    tw.add_summary(summary,i)
                    tw.add_run_metadata(run_metadata,'step%d'%i)
                
                epochLoss += c       
            
            tx,ty = getNextBatch()
            print('Epoch ',epoch,'/',epochs,':',epochLoss/TRAIN_SIZE,' ',accuracy.eval({x_t:tx,y_t:ty}))
       
        tw.close()            

trainNN()
```

### What other attempted solutions have you tried?
I googled the said dll file. No, results.

Could PTI stand for Parameter Tuning Interface?
I found [this](http://www.socsci.uci.edu/~jkrichma/CARLsim/) link, but I am hesitant to installed anything that is not prescribed officially.

### Logs or other output that would be helpful
(If logs are large, please upload as attachment or provide link).

```
D:\TensorFlow>D:\TensorFlow\identity_dnn_bare.py
I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\stream_executor\dso_loader.cc:128] successfully opened CUDA library cublas64_80.dll locally
I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\stream_executor\dso_loader.cc:128] successfully opened CUDA library cudnn64_5.dll locally
I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\stream_executor\dso_loader.cc:128] successfully opened CUDA library cufft64_80.dll locally
I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\stream_executor\dso_loader.cc:128] successfully opened CUDA library nvcuda.dll locally
I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\stream_executor\dso_loader.cc:128] successfully opened CUDA library curand64_80.dll locally
I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\common_runtime\gpu\gpu_device.cc:885] Found device 0 with properties:
name: GeForce 930MX
major: 5 minor: 0 memoryClockRate (GHz) 1.0195
pciBusID 0000:01:00.0
Total memory: 2.00GiB
Free memory: 1.66GiB
I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\common_runtime\gpu\gpu_device.cc:906] DMA: 0
I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\common_runtime\gpu\gpu_device.cc:916] 0:   Y
I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\common_runtime\gpu\gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce 930MX, pci bus id: 0000:01:00.0)
I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\stream_executor\dso_loader.cc:119] Couldn't open CUDA library cupti64_80.dll
F c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\platform\default\gpu\cupti_wrapper.cc:59] Check failed: ::tensorflow::Status::OK() == (::tensorflow::Env::Default()->GetSymbolFromLibrary( GetDsoHandle(), kName, &f)) (OK vs. Not found: cuptiActivityRegisterCallbacks not found)could not find cuptiActivityRegisterCallbacksin libcupti DSO
```
"
6233,Import tensorflow in ipython  Couldn't open CUDA library libcuda.so.1. LD_LIBRARY_PATH,"I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:105] Couldn't open CUDA library libcuda.so.1. LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:160] hostname: zsx-All-Series
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:185] libcuda reported version is: Not found: was unable to find libcuda.so DSO loaded into this program
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:356] driver version file contents: """"""NVRM version: NVIDIA UNIX x86_64 Kernel Module  367.57  Mon Oct  3 20:37:01 PDT 2016
GCC version:  gcc version 5.4.0 20160609 (Ubuntu 5.4.0-6ubuntu1~16.04.4) 
""""""
I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:189] kernel reported version is: 367.57.0
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1080] LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64:
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1081] failed to find libcuda.so on this system: Failed precondition: could not dlopen DSO: libcuda.so.1; dlerror: libnvidia-fatbinaryloader.so.367.57: cannot open shared object file: No such file or directory
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcurand.so locally
"
6232,Format Error on the Website,"Hi, on tensorflow.org there is part of documentation accidentally formatted into code. It's not a serious problem.  It's about initializer on r0.11. I didn't check if other versions have the same problem. Just  want to post it here for your information.

![screen shot 2016-12-09 at 20 41 19](https://cloud.githubusercontent.com/assets/16264284/21070208/e29a628e-be4f-11e6-973e-e5a936a5f794.png)

[link: https://www.tensorflow.org/versions/r0.11/api_docs/python/state_ops.html#random_normal_initializer](https://www.tensorflow.org/versions/r0.11/api_docs/python/state_ops.html#random_normal_initializer) (this actually won't lead you right to the location because of the error )."
6230,Poor colors for embedding projector,"The second and third colors available in ""color by"" are extremely similar when there is overlap: the second color (orangish) appears very similar to third (redish) one.   This prevents any pop-out effect."
6229,tf.contrib.learn.LinearClassifier.evaluate reports incorrect labels/prediction_mean,"Relatively new to machine learning but this appears to be a reproducible bug. Have not been able to find related issues on web searches.

OS is MacOS,  no CUDA. Installed using pip package:
# Mac OS X, CPU only, Python 2.7:
$ export TF_BINARY_URL=https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-0.12.0rc0-py2-none-any.whl
tensorflow version: 0.12.0-rc0

I first noted discrepancy between on my data using a tf.contrib.learn.LinearClassifier. The evaluate function returned a 'labels/actual_label_mean' that was accurate but a 'labels/prediction_mean' that was too low. I was able to reproduce similar results (i.e. 'labels/prediction_mean' too low) using the linearclassifier tutorial at:
https://www.tensorflow.org/versions/r0.12/tutorials/wide/index.html

Following the tutorial, I get the following from `m.evaluate(input_fn=eval_input_fn, steps=1)`

{'accuracy': 0.83582091,
 'accuracy/baseline_label_mean': 0.23622628,
 'accuracy/threshold_0.500000_mean': 0.83582091,
 'auc': 0.88367212,
 'global_step': 400,
 'labels/actual_label_mean': 0.23622628,
 'labels/prediction_mean': 0.23983434,
 'loss': 0.35221672,
 'precision/positive_threshold_0.500000_mean': 0.70658684,
 'recall/positive_threshold_0.500000_mean': 0.52158087}

The  'labels/actual_label_mean' value exactly matches `sum(df_test.label)/len(df_test.label)`

If I actually use the predict using 

```
pred = m.predict(input_fn = lambda:input_fn(df_test))
predictions = []
for i in range( df_test.shape[0] ):
    predictions.append(pred.next())
### I realize above code looks ugly but I can't get it to work in a less kludgy way, e.g.
### predictions = list(pred) will hang indefinitely until control-c
### Is this a separate bug?

sum(predictions) -> 2839
len(predictions) -> 16281
```
The ratio is 0.1743750 which is much lower than the reported value for 'labels/prediction_mean', 0.23983434.

I think that this is a serious bug as predicting/guessing the more likely label artificially inflates the accuracy. As an extreme example, predicting 'no meteor today' will give you a 99.99_% accuracy.

If this is not a bug but rather a misunderstanding of how prediction/evaluation work, pardon my error."
6226,Feature request to specify substitutions in embedding_lookup for invalid indices ,"In the current master code, https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/gather_op.cc it says that the attribute _validate_indices_ is not supported anymore:
` // We used to grab the validate_indices attribute here, but now we
    // always validate indices since the speed difference was only 1.5%.
    // TODO(irving): Remove the validate_indices attribute once we have
    // support for removing attrs in a backwards compatible way.`

I actually do want an option to specify validate_indices as false. I am using _embedding_lookup_ and it would be useful for out of vocabulary words that are not in the embedding matrix.  

If it's not possible to support _validate_indices_, can you suggest a way to get all zeros (instead of an exception) for indices that are not in the embedding matrix."
6224,Extremely inefficient cuda event polling,"I am running tensorflow with this application: https://github.com/openai/pixel-cnn. I am running on 4 NVIDIA K80 cards and CUDA 7.5. For my experiment, I modified the code to only do 100 training iterations.

During the 100 iterations, tensorflow destroys 2662 cuda events. But how many times it polls event status? 40669120 times. This means on average it polls ~15,000 times for 1 destroy. Isn't it extremely inefficient?

Per my understanding of tensorflow source code, it uses one dedicated thread to poll event status and destroy an event once it's complete. That's the only place where the event status is polled."
6222,slice_input_producer output tensor of wrong shape under certain conditions,"From the verison
tensorflow-0.12.0rc0-cp27-cp27mu-manylinux1_x86_64.whl

When using  tf.train.slice_input_producer with a tensor_list containing only a single tensor, the output from the tf.train.batch has incorrect dimension.

Code to reproduce it

```
import tensorflow as tf

data=tf.random_uniform(shape=(50, 50))
labels=tf.ones(50)
sample, _=tf.train.slice_input_producer([data, labels])
batch=tf.train.batch([sample], batch_size=8)

print batch

sample=tf.train.slice_input_producer([data])
batch=tf.train.batch([sample], batch_size=8)

print batch

```

the output is

```
Tensor(""batch:0"", shape=(8, 50), dtype=float32)
Tensor(""batch_1:0"", shape=(8, 1, 50), dtype=float32)

```

I think the two output should be the same? Simple workaround like reshaping the batch data is feasible. However, I think this is a bug."
6220,"Upgrade from r11 to r12 prodeuces ""Variables not defined"" when using any optimizer but GradientDescentOptimizer","After a recent upgrade to the latest version of tensorflow in github, several things stop working. I found out that all the optimizers, such as Adam or Adagrad are now producing an error related to variable scope that I have not managed to solve yet. However, GradientDescentOptimizer works fine.

It may be related to the issue: https://github.com/tensorflow/tensorflow/issues/5652

The error looks like this:
```
File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variable_scope.py"", line 651, in _get_single_variable
    ""VarScope?"" % name)
ValueError: Variable filter/Adadelta/ does not exist, or was not created with tf.get_variable(). Did you mean to set reuse=None in VarScope?

```

It works fine with tensorflow r11

Operating System: Ubuntu 16 and Ubuntu 14
Installed version of CUDA and cuDNN: cuda 8.0, cuda 5.1
[cuda.txt](https://github.com/tensorflow/tensorflow/files/642888/cuda.txt)
 The commit hash  6dc8deaed8d8bd9cc6d52a03474d0b82891c8b86
Build time: Wed Nov 2 17:54:14 2016 (1478109254)
Build timestamp: 1478109254
Build timestamp as int: 1478109254

Find below a minimal version that causes the error:
```
import tensorflow as tf
import pdb

def main():

    ## !!! change this to test the different behaviors !!!
    #optimizer = tf.train.GradientDescentOptimizer(1e-3)                 # This one is working
    optimizer = tf.train.AdamOptimizer(1e-3, beta1=0.9, beta2=0.999999) # This one is not working
    #optimizer = tf.train.AdagradOptimizer(1e-3)                         # This one is not working
    #optimizer = tf.train.AdadeltaOptimizer(1e-3)                        # This one is not working
	
    list_grads = []
    for i in xrange(2):
        with tf.device('/gpu:%d' % i):
            with tf.name_scope('%d' % i) as scope:
                W = tf.get_variable(name=""filter"", initializer=tf.random_uniform_initializer(dtype=tf.float32), shape=[5, 1])
                X = tf.get_variable(name=""data"", initializer=tf.random_uniform_initializer(dtype=tf.float32), shape=[5, 1])
                Y_ = tf.get_variable(name=""out"", initializer=tf.random_uniform_initializer(dtype=tf.float32), shape=[5, 1])
                Y = W+X
                loss =tf.reduce_mean(Y-Y_)
                grad = optimizer.compute_gradients(loss)
                list_grads.append(grad)

                tf.get_variable_scope().reuse_variables()	
    
    grads = list_grads[0] + list_grads[1]
    #pdb.set_trace()

    op_train = optimizer.apply_gradients(grads)

    init_global = tf.global_variables_initializer()
    init_local =  tf.local_variables_initializer()

    sess = tf.Session()
    sess.run([init_global, init_local])

    _, sol = sess.run([op_train, loss])
    print(str(sol))

if (__name__ == '__main__'):
	main()
```
"
6219,Allow using raw values for Projector?,It would be great if Projector would allow raw values for visualization (e.g. in case the data has PCA or t-SNE applied already )
6217,process_bounding_boxes.py does not ouput .csv file,"
https://github.com/tensorflow/models/blob/master/inception/inception/data/process_bounding_boxes.py

**process_bounding_boxes.py** does not output any files after processing .xml files.

it says: The script dumps out a CSV text file in which each line contains an entry. but if go through the python code, there is no write() function is called.

i can only see:

**Finished processing 544546 XML files.
Skipped 0 XML files not in ImageNet Challenge.
Skipped 0 bounding boxes not in ImageNet Challenge.
Wrote 615299 bounding boxes from 544546 annotated images.
Finished.**



"
6216,task assignment in tensorflow distributed process,"I'm confused about the distributed training process in tensorflow.
I think the tensorflow feed a batch_size of data to a worker and then the worker update the ps server,is this right? 
But when training , I noticed that the step number in the log may strange.
If I have only 2 workers , I thinks the right process should be some thing like
[worker1] step 0 xxxxxxx
[worker2] step 100 xxxxxxx
[worker1] step 200 xxxxxxx
[worker2] step 300 xxxxxxx
.....
every worker should print different step to log.

Actually , the log are as below:
[worker1] step 0 xxxxxxx
[worker2] step 100 xxxxxxx
[worker1] step 100 xxxxxxx
[worker2] step 200 xxxxxxx
[worker1] step 300 xxxxxxx
...
Why the worker1 dosn't print step 200? 

I am confused about the job assign .... a step to a worker? or every worker run every step?

### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?
there are nothing about the tensorflow distributed process in these websites

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)
```
def main(_):
  ps_hosts = FLAGS.ps_hosts.split("","")
  worker_hosts = FLAGS.worker_hosts.split("","")

  # Create a cluster from the parameter server and worker hosts.
  cluster = tf.train.ClusterSpec({""ps"": ps_hosts, ""worker"": worker_hosts})

  # Create and start a server for the local task.
  server = tf.train.Server(cluster,
                           job_name=FLAGS.job_name,
                           task_index=FLAGS.task_index)

  if FLAGS.job_name == ""ps"":
    server.join()
  elif FLAGS.job_name == ""worker"":

    # Assigns ops to the local worker by default.
    with tf.device(tf.train.replica_device_setter(
        worker_device=""/job:worker/task:%d"" % FLAGS.task_index,
        cluster=cluster)):

      # Variables of the hidden layer
      hid_w = tf.Variable(
          tf.truncated_normal([IMAGE_PIXELS * IMAGE_PIXELS, FLAGS.hidden_units],
                              stddev=1.0 / IMAGE_PIXELS), name=""hid_w"")
      hid_b = tf.Variable(tf.zeros([FLAGS.hidden_units]), name=""hid_b"")

      # Variables of the softmax layer
      sm_w = tf.Variable(
          tf.truncated_normal([FLAGS.hidden_units, 10],
                              stddev=1.0 / math.sqrt(FLAGS.hidden_units)),
          name=""sm_w"")
      sm_b = tf.Variable(tf.zeros([10]), name=""sm_b"")

      x = tf.placeholder(tf.float32, [None, IMAGE_PIXELS * IMAGE_PIXELS])
      y_ = tf.placeholder(tf.float32, [None, 10])

      hid_lin = tf.nn.xw_plus_b(x, hid_w, hid_b)
      hid = tf.nn.relu(hid_lin)

      y = tf.nn.softmax(tf.nn.xw_plus_b(hid, sm_w, sm_b))
      loss = -tf.reduce_sum(y_ * tf.log(tf.clip_by_value(y, 1e-10, 1.0)))

      global_step = tf.Variable(0)

      train_op = tf.train.AdagradOptimizer(0.01).minimize(
          loss, global_step=global_step)

      saver = tf.train.Saver()
      summary_op = tf.merge_all_summaries()
      init_op = tf.initialize_all_variables()

    # Create a ""supervisor"", which oversees the training process.
    sv = tf.train.Supervisor(is_chief=(FLAGS.task_index == 0),
                             logdir=""/tmp/train_logs"",
                             init_op=init_op,
                             summary_op=summary_op,
                             saver=saver,
                             global_step=global_step,
                             save_model_secs=600)

    mnist = input_data.read_data_sets(FLAGS.data_dir, one_hot=True)

    # The supervisor takes care of session initialization, restoring from
    # a checkpoint, and closing when done or an error occurs.
    with sv.managed_session(server.target) as sess:
      # Loop until the supervisor shuts down or 1000000 steps have completed.
      step = 0
      while not sv.should_stop() and step < 1000000:
        # Run a training step asynchronously.
        # See `tf.train.SyncReplicasOptimizer` for additional details on how to
        # perform *synchronous* training.

        batch_xs, batch_ys = mnist.train.next_batch(FLAGS.batch_size)
        train_feed = {x: batch_xs, y_: batch_ys}

        _, step = sess.run([train_op, global_step], feed_dict=train_feed)
        if step % 100 == 0: 
            print ""Done step %d"" % step

    # Ask for all the services to stop.
    sv.stop()
```

### Logs or other output that would be helpful
(If logs are large, please upload as attachment or provide link).
```
[0:00:17.115814] Task: 0, Step: 74600, loss: 0.303285002708, accuracy: 0.910000026226, auc: 0.946377456188
[0:00:03.804889] Task: 1, Step: 74700, loss: 0.287385582924, accuracy: 0.879999995232, auc: 0.946395516396
[0:00:03.778589] Task: 0, Step: 74800, loss: 0.247096762061, accuracy: 0.860000014305, auc: 0.946370542049
[0:00:03.772320] Task: 1, Step: 74900, loss: 0.264987647533, accuracy: 0.899999976158, auc: 0.946406364441
[0:00:03.795459] Task: 0, Step: 75000, loss: 0.228719010949, accuracy: 0.899999976158, auc: 0.946437120438
[0:00:01.902293] Task: 1, Step: 75000, loss: 0.217391207814, accuracy: 0.910000026226, auc: 0.946473121643
[0:00:01.942055] Task: 1, Step: 75100, loss: 0.284583866596, accuracy: 0.889999985695, auc: 0.946496844292
[0:00:03.860608] Task: 0, Step: 75200, loss: 0.273199081421, accuracy: 0.850000023842, auc: 0.946503221989
[0:00:03.800881] Task: 1, Step: 75300, loss: 0.189931258559, accuracy: 0.930000007153, auc: 0.946559965611
```"
6215,Embedding Projector hangs when data with string-based features are added,"### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?
None

### Environment info
Operating System: OS X 10.11.6

Answer to other prompts: N/A

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)
My issue is on the online tool Embedding Projector (http://projector.tensorflow.org). On both Safari and Chrome, if I upload data via the ""Load Data"" button, I see a window ""Computing PCA..."" that _never goes away_. 

A 10-sample version of my data can be found at [10samples.txt](https://github.com/tensorflow/tensorflow/files/642762/10samples.txt).

If I remove the string-based feature at the end—which happens to be the output/label for these samples—the problem goes away.

This case should be caught and an informative error message should be returned. 

(Relatedly, I can't understand from the current interface how to add string-based labels for the data. The implication is that these labels are ""metadata"", but that's not clear.)"
6213,[Android] Put large .pb files outside of Asset-folder? [ERROR]: Check failed: message->ParseFromZeroCopyStream(&lis) ,"Right now, I'm facing a problem which throws the following error:

```
12-09 14:11:51.635 194-194/? A/DEBUG: Abort message: 'jni_utils.cc:125 Check failed: message->ParseFromZeroCopyStream(&lis) '
12-09 14:11:51.635 194-194/? A/DEBUG:     r0 00000000  r1 000011e8  r2 00000006  r3 9df38978
12-09 14:11:51.636 194-194/? A/DEBUG:     r4 9df38980  r5 9df38930  r6 00000058  r7 0000010c
12-09 14:11:51.636 194-194/? A/DEBUG:     r8 9df37c14  r9 9df37ac0  sl b4d13c90  fp 9df38400
12-09 14:11:51.636 194-194/? A/DEBUG:     ip 00000006  sp 9df37a68  lr b6c95b61  pc b6c97f50  cpsr 400f0010
12-09 14:11:51.645 194-194/? A/DEBUG: backtrace:
12-09 14:11:51.645 194-194/? A/DEBUG:     #00 pc 00041f50  /system/lib/libc.so (tgkill+12)
12-09 14:11:51.645 194-194/? A/DEBUG:     #01 pc 0003fb5d  /system/lib/libc.so (pthread_kill+32)
12-09 14:11:51.646 194-194/? A/DEBUG:     #02 pc 0001c30f  /system/lib/libc.so (raise+10)
12-09 14:11:51.646 194-194/? A/DEBUG:     #03 pc 000194c1  /system/lib/libc.so (__libc_android_abort+34)
12-09 14:11:51.646 194-194/? A/DEBUG:     #04 pc 000174ac  /system/lib/libc.so (abort+4)
12-09 14:11:51.646 194-194/? A/DEBUG:     #05 pc 0058bb74  /data/app/de.-2/lib/arm/libnative_microscope.so
12-09 14:11:51.646 194-194/? A/DEBUG:     #06 pc 0058bcf4  /data/app/de.-2/lib/arm/libnative_microscope.so
12-09 14:11:51.646 194-194/? A/DEBUG:     #07 pc 0058bd10  /data/app/de.-2/lib/arm/libnative_microscope.so
12-09 14:11:51.646 194-194/? A/DEBUG:     #08 pc 00076700  /data/app/de.-2/lib/arm/libnative_microscope.so (_Z15ReadFileToProtoP13AAssetManagerPKcPN6google8protobuf11MessageLiteE+984)
12-09 14:11:51.647 194-194/? A/DEBUG:     #09 pc 0007459c  /data/app/de.-2/lib/arm/libnative_microscope.so (Java_de_beamerscope_nativepart_NativePart_init+772)
12-09 14:11:51.647 194-194/? A/DEBUG:     #10 pc 0000087d  /data/data/de./cache/slice-slice_6-classes.dex (offset 0x3000)

```

I think it's coming due to the larg protobuffer file .pb which is loaded from the asset folder. I build the app with Android Studio and tuned the compression in the gradle-file of via 
```
    aaptOptions {
        noCompress 'pb'
    }
```
When I load a smaller model it's working fine. I think it's still coming from a wrong file-transfer-conversion thing in Android Studio?! Is it possible?

So my question. Is it also possible to place large "".pb""-files (i.e. 130 mb) somewhere else on the SD-card and load it in seperately?

Or do you think, it's a different problem? I'm training boss models with the same version of TF. 

Thank you! :)

"
6211,"ImportError: No module named nets, r0.12","I am trying to run `resnet_v2.py`  from provided modles but getting error `ImportError: No module named nets
`.
I have done following 
First installing slim
`cd $HOME/tensorflow
git clone https://github.com/tensorflow/models/`

To verify that this has worked, execute the following commands; it should run
without raising any errors.

```
`cd $HOME/tensorflow/models/slim
python3 -c ""from nets import cifarnet; mynet = cifarnet.cifarnet""`
```
I got no error.

But when I run following gives error **""ImportError: No module named nets""**. I have also tried
`cd $HOME/tensorflow/models/slim/
python3 -c ""from nets import resnet_utils""`

Got not error.  Also build  using `bazel build nets` output 
`INFO: Found 1 target...
Target //slim:nets up-to-date (nothing to build)
INFO: Elapsed time: 0.096s, Critical Path: 0.00s
`

I don't know why this is not working.
"
6210,[Installing TensorFlow offline] $ ./configure fails because no Internet connection is available for my server.,"**My environment without Internet**
My server can't access the Internet because my company's firewall blocks any external network or the Internet. To install Tensorflow on this server, I have to install TensorFlow offline. In other words, I have to correct tens of errors by myself. Upon this error, I had to submit an issue. 

I moved the template below because it's way too long. (I filled in some information.) I'd appreciate your feedback.
 
**Questions**
My question nails down to two core questions.
Q1. How can I manually fetch all the packages for tensorflow without using bazel command?
      I took a closer look at the ""configure"" file and the following line causes the problem.
       $bazel fetch //tensorflow/...

      This bazel command fetches all the packages in target ""tensorflow"". 
       No Internet connection in my server, so this command fails!. 
       I'll have to download all these packages in ANOTHER computer with Internet connection and   
       move them to my server.
 
       In another computer with Internet connection, how can I download them without bazel command? Alternative commands can be wget, git, apt-get, pip and so on.

Q2. Where should I place the downloaded packages?
    Say all the packages for target ""tensorflow"" are downloaded.
    Where should I place them to run the next command successfully?
 
     $ bazel build -c opt -config=cuda //tensorflow/cc:tutorials_example_trainer
 
    I'll have to move all the package to my server from another computer.
   So I need some information about the directory that the above command refers to.

(This is all because of the security measure in my company. As a matter of fact, this process is more complex than using another computer, but this gives you an idea about my installation environment without the Internet)
-----------------------------------------------------------------------------------
NOTE: Only file GitHub issues for bugs and feature requests.  All other topics will be closed.
 
For general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).
To make bugs and feature requests more easy to find and organize, we close issues that are deemed
out of scope for GitHub Issues and point people to StackOverflow.
 
For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.
 
### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?
""How to make the ./configure find package in local place #5428""
GaofengCheng opened this issue on 6 Nov and there're 13 comments, but no solution is presented.
 
### Environment info
1. Operating System: Ubuntu Linux 14.04
2. NO INTERNET CONNECTION.
    My company's firewall blocks my server from the Internet connection.  So no Internet connection is available. A comment in Issue #5029 says ""Long story short, [...] a network access is required."", but a network access on this server is not an option. I'll have to download necessary packages from another computer with Internet connection and upload them to my server via sftp.
 
3. CUDA & cuDNN are installed in ~/local/ because of the system admin asked me to do so.
   When I run "" $ ./configure"", CUDA & cuDNN installation was done manually.  
 
Installed version of CUDA and cuDNN:
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):
~/local/cuda-8.0/lib64$ ls -l libcud*
-rw-r--r-- 1 root root   558720 Dec  9 01:00 libcudadevrt.a
lrwxrwxrwx 1 root root       16 Dec  9 01:00 libcudart.so -> libcudart.so.8.0
lrwxrwxrwx 1 root root       19 Dec  9 01:00 libcudart.so.8.0 -> libcudart.so.8.0.44
-rwxr-xr-x 1 root root   415432 Dec  9 01:00 libcudart.so.8.0.44
-rw-r--r-- 1 root root   775162 Dec  9 01:00 libcudart_static.a
lrwxrwxrwx 1 root root       13 Dec  9 01:05 libcudnn.so -> libcudnn.so.5
lrwxrwxrwx 1 root root       17 Dec  9 01:05 libcudnn.so.5 -> libcudnn.so.5.1.5
-rwxr-xr-x 1 root root 79337624 Dec  9 01:05 libcudnn.so.5.1.5
-rw-r--r-- 1 root root 69756172 Dec  9 01:05 libcudnn_static.a
 
If installed from source, provide
1. The commit hash (`git rev-parse HEAD`)
$ git rev-parse HEAD
fatal: Not a git repository (or any parent up to mount point /home)
Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).
 
2. The output of `bazel version`
$ bazel version
Build label: 0.4.0
Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Wed Nov 2 17:54:14 2016 (1478109254)
Build timestamp: 1478109254
Build timestamp as int: 1478109254
 
### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)
$ ./configure
[...]
ERROR: package contains errors: tensorflow/examples/android.
ERROR: error loading package 'tensorflow/examples/android': Encountered error while reading extension file 'protobuf.bzl': no such package '@protobuf//': Error downloading from http://github.com/google/protobuf/archive/008b5a228b37c054f46ba478ccafa5e855cb16db.tar.gz to /home/the.kim/.cache/bazel/_bazel_the.kim/e904ac0e4fbd2c03039cdbaeea674781/external/protobuf: Error downloading http://github.com/google/protobuf/archive/008b5a228b37c054f46ba478ccafa5e855cb16db.tar.gz to /home/the.kim/.cache/bazel/_bazel_the.kim/e904ac0e4fbd2c03039cdbaeea674781/external/protobuf/008b5a228b37c054f46ba478ccafa5e855cb16db.tar.gz: Timed out connecting to http://github.com/google/protobuf/archive/008b5a228b37c054f46ba478ccafa5e855cb16db.tar.gz : connect timed out.
(tensorflow) $
 
(The following line within configure causes my problem.
My server has no Internet connection, so download fails.)
$ bazel fetch //tensorflow/...
INFO: Downloading from http://github.com/google/protobuf/archive/008b5a228b37c054f46ba478ccafa5e85\
5cb16db.tar.gz: 0B
 
### Logs or other output that would be helpful
(If logs are large, please upload as attachment or provide link).
 
the.kim@clover3:~/tensorflow/downloads/tensorflow$ source ~/tensorflow/bin/activate
(tensorflow) the.kim@clover3:~/tensorflow/downloads/tensorflow$ ls
008b5a228b37c054f46ba478ccafa5e855cb16db.tar.gz  eigen.BUILD        LICENSE          tensorflow
ACKNOWLEDGMENTS                                  farmhash.BUILD     linenoise.BUILD  third_party
ADOPTERS.md                                      gif.BUILD          models.BUILD     tools
AUTHORS                                          gmock.BUILD        nanopb.BUILD     util
bower.BUILD                                      grpc.BUILD         png.BUILD        WORKSPACE
BUILD                                            ISSUE_TEMPLATE.md  README.md        zlib.BUILD
configure                                        jpeg.BUILD         RELEASE.md
CONTRIBUTING.md                                  jsoncpp.BUILD      six.BUILD
(tensorflow) the.kim@clover3:~/tensorflow/downloads/tensorflow$ ./configure
~/tensorflow/downloads/tensorflow ~/tensorflow/downloads/tensorflow
Please specify the location of python. [Default is /home/the.kim/tensorflow/bin/python]: /home/the.kim/tensorflow/bin/python3
Do you wish to build TensorFlow with Google Cloud Platform support? [y/N] n
No Google Cloud Platform support will be enabled for TensorFlow
Do you wish to build TensorFlow with Hadoop File System support? [y/N] n
No Hadoop File System support will be enabled for TensorFlow
Found possible Python library paths:
  /home/the.kim/tensorflow/lib/python3.4/site-packages
Please input the desired Python library path to use.  Default is [/home/the.kim/tensorflow/lib/python3.4/site-packages]
 
Using python library path: /home/the.kim/tensorflow/lib/python3.4/site-packages
Do you wish to build TensorFlow with OpenCL support? [y/N] y
OpenCL support will be enabled for TensorFlow
Do you wish to build TensorFlow with CUDA support? [y/N] y
CUDA support will be enabled for TensorFlow
Please specify which gcc should be used by nvcc as the host compiler. [Default is /usr/bin/gcc]:
Please specify the CUDA SDK version you want to use, e.g. 7.0. [Leave empty to use system default]: 8.0
Please specify the location where CUDA 8.0 toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: /home/the.kim/local/cuda-8.0
Please specify the Cudnn version you want to use. [Leave empty to use system default]:
Please specify the location where cuDNN  library is installed. Refer to README.md for more details. [Default is /home/the.kim/local/cuda-8.0]:
libcudnn.so resolves to libcudnn.5
Please specify a list of comma-separated Cuda compute capabilities you want to build with.
You can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.
Please note that each additional compute capability significantly increases your build time and binary size.
[Default is: ""3.5,5.2""]: 3.7
Please specify which C++ compiler should be used as the host C++ compiler. [Default is /usr/bin/g++]:
Please specify which C compiler should be used as the host C compiler. [Default is /usr/bin/gcc]:
Please specify the location where ComputeCpp 1.2 is installed. Refer to README.md for more details. [Default is /usr/local/computecpp]: /home/the.kim/local/ComputeCpp-CE-0.1.1-Linux
INFO: Starting clean (this may take a while). Consider using --expunge_async if the clean takes more than several minutes.
........
ERROR: package contains errors: tensorflow/examples/android.
ERROR: error loading package 'tensorflow/examples/android': Encountered error while reading extension file 'protobuf.bzl': no such package '@protobuf//': Error downloading from http://github.com/google/protobuf/archive/008b5a228b37c054f46ba478ccafa5e855cb16db.tar.gz to /home/the.kim/.cache/bazel/_bazel_the.kim/e904ac0e4fbd2c03039cdbaeea674781/external/protobuf: Error downloading http://github.com/google/protobuf/archive/008b5a228b37c054f46ba478ccafa5e855cb16db.tar.gz to /home/the.kim/.cache/bazel/_bazel_the.kim/e904ac0e4fbd2c03039cdbaeea674781/external/protobuf/008b5a228b37c054f46ba478ccafa5e855cb16db.tar.gz: Timed out connecting to http://github.com/google/protobuf/archive/008b5a228b37c054f46ba478ccafa5e855cb16db.tar.gz : connect timed out.
(tensorflow) the.kim@clover3:~/tensorflow/downloads/tensorflow$
 
(Before the error, $ ./configure attempts this.)
INFO: Downloading from http://github.com/google/protobuf/archive/008b5a228b37c054f46ba478ccafa5e85\
5cb16db.tar.gz: 0B"
6209,Bug: while_loop gives invalid gradients (NaN) even when loss is computed using only non NaNs,"### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?

https://github.com/tensorflow/tensorflow/issues/2540 is the only thing that is seemingly related, but it's a different issue.

### Environment info
Operating System: Ubuntu 14.04

Installed version of CUDA and cuDNN: This bug occurs even if I only use CPUs.

Compiled from source. Commit hash: a5074383617a9947f248a0ddd56b94f9fb0f970b

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)

Overview: Build a minimalist RNN-like model and compute derivatives with respect to the loss. Allow the ability to specify invalid time steps using NaNs.

Behavior:
- If no NaNs are included, it works
- If only one invalid time step is included, it still works (odd)
- If two or more invalid time steps are included, it fails.
- If we change `INVALID_FLOAT_SYMBOL` to, say, `0.12345`, then it works as expected.

```
import tensorflow as tf
import numpy as np

INVALID_FLOAT_SYMBOL = np.nan

w = tf.Variable(1.0)
inputs = tf.placeholder(tf.float32, shape=[None])
targets = tf.placeholder(tf.float32, shape=[None])
T = tf.size(inputs)

x_ta = tf.TensorArray(tf.float32, size=T).unpack(inputs)
h_ta = tf.TensorArray(tf.float32, size=T)

def cond(t, h, h_ta):
  return tf.less(t, T)

def body(t, h, h_ta):
  x = x_ta.read(t)
  h = w * h + x
  h_ta = h_ta.write(t, h)
  return t + 1, h, h_ta

t = tf.constant(0)
h = tf.constant(0.0)
_, _, h_ta = tf.while_loop(cond, body, [t, h, h_ta])
outputs = h_ta.pack()

invalid_mask = tf.is_nan(inputs) if np.isnan(INVALID_FLOAT_SYMBOL) else tf.equal(inputs, INVALID_FLOAT_SYMBOL)
valid_mask = tf.logical_not(invalid_mask)

valid_outputs = tf.boolean_mask(outputs, valid_mask)
valid_targets = tf.boolean_mask(targets, valid_mask)

valid_losses = tf.nn.sigmoid_cross_entropy_with_logits(valid_outputs, valid_targets)
valid_loss = tf.reduce_sum(valid_losses)

grad, = tf.gradients(valid_loss, w)

sess = tf.Session()
sess.run(tf.initialize_all_variables())
```

### Logs or other output that would be helpful
(If logs are large, please upload as attachment or provide link).

```
# Case 1: INVALID_FLOAT_SYMBOL = np.nan, but no INVALID symbol is used.
print(sess.run(grad, feed_dict={inputs: [1.0, 2.0, 3.0],
                                targets: [1.0, 1.0, 1.0]}))
# Correctly prints -0.0573164

# Case 2: INVALID_FLOAT_SYMBOL = np.nan, and one INVALID symbol is used.
print(sess.run(grad, feed_dict={inputs: [1.0, 2.0, 3.0, INVALID_FLOAT_SYMBOL],
                                targets: [1.0, 1.0, 1.0, INVALID_FLOAT_SYMBOL]}))
# Correctly prints -0.0573164

# Case 3: INVALID_FLOAT_SYMBOL = np.nan, and two INVALID symbols are used.
print(sess.run(grad, feed_dict={inputs: [1.0, 2.0, 3.0, INVALID_FLOAT_SYMBOL, INVALID_FLOAT_SYMBOL],
                                targets: [1.0, 1.0, 1.0, INVALID_FLOAT_SYMBOL, INVALID_FLOAT_SYMBOL]}))
# Incorrectly prints nan

# Case 4: INVALID_FLOAT_SYMBOL = 0.12345, and two INVALID symbols are used.
print(sess.run(grad, feed_dict={inputs: [1.0, 2.0, 3.0, INVALID_FLOAT_SYMBOL, INVALID_FLOAT_SYMBOL],
                                targets: [1.0, 1.0, 1.0, INVALID_FLOAT_SYMBOL, INVALID_FLOAT_SYMBOL]}))
# Correctly prints -0.0573164
```"
6207,Batch support for cropping operators,"I had a look at the issues and I don't think this has been submitted yet. Sorry if I missed one.

The [cropping](https://www.tensorflow.org/versions/r0.12/api_docs/python/image.html#cropping) operators like `tf.image.resize_image_with_crop_or_pad`, `tf.image.crop_to_bounding_box`, etc only support 3-D tensors. It would be useful to support 4-D tensors for those operators, specially when there are used after the [resizing](https://www.tensorflow.org/versions/r0.12/api_docs/python/image.html#resizing) operators, which support 4-D tensor.

Edit: I just saw there was `extract_glimpse` or `crop_and_resize` which could works for 4-D tensors. It's confusing to have 2 different functions with different name which seems to perform the same operation with just a different input rank

Edit 2: It's not exactly the same functions. `extract_glimpse` and `crop_and_resize` both require normalized coordinates. `crop_to_bounding_box` use pixel values. It would be good to have a function which allows both pixel based coordinates and 4-D input tensors but anyway, at least there is a way to do what I wanted."
6202,Inconsistent API for ones_initializer/zeros_initializer,"This [cl](https://github.com/tensorflow/tensorflow/commit/cfb2280d3f6ced298681bd1141479a59a06abde8) has removed `shape` argument from `ones_initializer`, however, this argument remains for `zeros_initializer`.

This is a breaking change so maybe it should be mentioned in RELEASE.md with instructions on how code should transition (ie `ones_initializer` should be replaced with `ones_initializer()`). Currently older code that works in 0.11 fails in 0.12 with obscure message

ie

```
    update = tf.get_variable(name=""update"", shape=[params_size], dtype=dtype,
                             initializer=tf.ones_initializer)

```

fails with
```
...
    initial_value(), name=""initial_value"", dtype=dtype)
  File ""/home/yaroslav/.conda/envs/openai/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py"", line 665, in <lambda>
    shape.as_list(), dtype=dtype, partition_info=partition_info)
TypeError: ones_initializer() got multiple values for argument 'dtype'

```

@itsmeolivia "
6201,Undefined symbols for architecture x86_64,"I builded a sample of ios app from https://github.com/yjmade/ios_camera_object_detection, but:

```
Undefined symbols for architecture x86_64:
  ""_cblas_sgemm"", referenced from:
      tensorflow::Conv2DUsingGemmOp<float, tensorflow::(anonymousnamespace)::Im2ColConvFunctor<float, float, float, FastGemmFunctor<float, float,float> > >::Compute(tensorflow::OpKernelContext*) in libtensorflow-core.a(conv_ops_using_gemm.o)
      tensorflow::FusedResizeConv2DUsingGemmOp<float, tensorflow::(anonymousnamespace)::FusedResizeAndPadConvFunctor<float, float, float,FastGemmFunctor<float, float, float>, (tensorflow::(anonymousnamespace)::SamplingMode)0>, true>::Compute(tensorflow::OpKernelContext*) in libtensorflow-core.a(conv_ops_fused.o)
      tensorflow::FusedResizeConv2DUsingGemmOp<float, tensorflow::(anonymousnamespace)::FusedResizeAndPadConvFunctor<float, float, float,FastGemmFunctor<float, float, float>, (tensorflow::(anonymousnamespace)::SamplingMode)1>, false>::Compute(tensorflow::OpKernelContext*) in libtensorflow-core.a(conv_ops_fused.o)
ld: symbol(s) not found for architecture x86_64
clang: error: linker command failed with exit code 1 (use -v to see invocation)
```

Is that any problem of my tensorflow?
Mac pro  
Intel Iris Graphics 6100 1536 MB
64bit"
6199,"""Invalid proto descriptor for file ""tensorflow/contrib/tensorboard/plugins/trace/trace_info.proto""","[trace_info.proto](https://github.com/tensorflow/tensorflow/blob/287db3a9b0701021f302e7bb58af5cf89fdcd424/tensorflow/contrib/tensorboard/plugins/trace/trace_info.proto) seems to be missing `import tensorflow/core/protobuf/meta_graph.proto`. It works for Python protobuf implementation but fails with tracing runs on stricter cpp implementation:

[scratch.py](https://gist.github.com/yaroslavvb/b0b9e51d88bb97aa0f739f8130e1c3d5)

```
python scratch.py

...
    contrib = importlib.import_module('tensorflow.contrib')
  File ""/home/yaroslav/.conda/envs/openai/lib/python3.5/importlib/__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""<frozen importlib._bootstrap>"", line 986, in _gcd_import
  File ""<frozen importlib._bootstrap>"", line 969, in _find_and_load
  File ""<frozen importlib._bootstrap>"", line 958, in _find_and_load_unlocked
  File ""<frozen importlib._bootstrap>"", line 673, in _load_unlocked
  File ""<frozen importlib._bootstrap_external>"", line 665, in exec_module
  File ""<frozen importlib._bootstrap>"", line 222, in _call_with_frames_removed
  File ""/home/yaroslav/.conda/envs/openai/lib/python3.5/site-packages/tensorflow/contrib/__init__.py"", line 49, in <module>
    from tensorflow.contrib import tensorboard
  File ""/home/yaroslav/.conda/envs/openai/lib/python3.5/site-packages/tensorflow/contrib/tensorboard/__init__.py"", line 22, in <module>
    from tensorflow.contrib.tensorboard import plugins
  File ""/home/yaroslav/.conda/envs/openai/lib/python3.5/site-packages/tensorflow/contrib/tensorboard/plugins/__init__.py"", line 23, in <module>
    from tensorflow.contrib.tensorboard.plugins import trace
  File ""/home/yaroslav/.conda/envs/openai/lib/python3.5/site-packages/tensorflow/contrib/tensorboard/plugins/trace/__init__.py"", line 22, in <module>
    from tensorflow.contrib.tensorboard.plugins.trace.trace import *
  File ""/home/yaroslav/.conda/envs/openai/lib/python3.5/site-packages/tensorflow/contrib/tensorboard/plugins/trace/trace.py"", line 28, in <module>
    from tensorflow.contrib.tensorboard.plugins.trace.trace_info_pb2 import TraceInfo
  File ""/home/yaroslav/.conda/envs/openai/lib/python3.5/site-packages/tensorflow/contrib/tensorboard/plugins/trace/trace_info_pb2.py"", line 22, in <module>
    serialized_pb=_b('\n=tensorflow/contrib/tensorboard/plugins/trace/trace_info.proto\x12\ntensorflow\""Q\n\tTraceInfo\x12\x1f\n\x03ops\x18\x01 \x03(\x0b\x32\x12.tensorflow.OpInfo\x12#\n\x05\x66iles\x18\x02 \x03(\x0b\x32\x14.tensorflow.FileInfo\""\xb2\x01\n\x06OpInfo\x12\x0c\n\x04name\x18\x01 \x01(\t\x12\x0f\n\x07op_type\x18\x02 \x01(\t\x12\x0e\n\x06\x64\x65vice\x18\x03 \x01(\t\x12(\n\ttraceback\x18\x04 \x03(\x0b\x32\x15.tensorflow.LineTrace\x12&\n\x06inputs\x18\x05 \x03(\x0b\x32\x16.tensorflow.TensorInfo\x12\'\n\x07outputs\x18\x06 \x03(\x0b\x32\x16.tensorflow.TensorInfo\""3\n\tLineTrace\x12\x11\n\tfile_path\x18\x01 \x01(\t\x12\x13\n\x0bline_number\x18\x02 \x01(\r\""Y\n\nTensorInfo\x12\r\n\x05shape\x18\x01 \x03(\x05\x12\r\n\x05\x64type\x18\x02 \x01(\t\x12\x1a\n\x12num_bytes_per_elem\x18\x03 \x01(\r\x12\x11\n\tconsumers\x18\x04 \x03(\t\""\xbb\x01\n\x08\x46ileInfo\x12\x11\n\tfile_path\x18\x01 \x01(\t\x12\x13\n\x0bsource_code\x18\x02 \x01(\t\x12K\n\x14multiline_statements\x18\x03 \x03(\x0b\x32-.tensorflow.FileInfo.MultilineStatementsEntry\x1a:\n\x18MultilineStatementsEntry\x12\x0b\n\x03key\x18\x01 \x01(\r\x12\r\n\x05value\x18\x02 \x01(\r:\x02\x38\x01\x62\x06proto3')
  File ""/home/yaroslav/.conda/envs/openai/lib/python3.5/site-packages/google/protobuf/descriptor.py"", line 827, in __new__
    return _message.default_pool.AddSerializedFile(serialized_pb)
TypeError: Couldn't build proto file into descriptor pool!
Invalid proto descriptor for file ""tensorflow/contrib/tensorboard/plugins/trace/trace_info.proto"":
  tensorflow.TensorInfo.dtype: ""tensorflow.TensorInfo.dtype"" is already defined in file ""tensorflow/core/protobuf/meta_graph.proto"".
  tensorflow.TensorInfo: ""tensorflow.TensorInfo"" is already defined in file ""tensorflow/core/protobuf/meta_graph.proto"".
  tensorflow.OpInfo.inputs: ""tensorflow.TensorInfo"" seems to be defined in ""tensorflow/core/protobuf/meta_graph.proto"", which is not imported by ""tensorflow/contrib/tensorboard/plugins/trace/trace_info.proto"".  To use it here, please add the necessary import.
  tensorflow.OpInfo.outputs: ""tensorflow.TensorInfo"" seems to be defined in ""tensorflow/core/protobuf/meta_graph.proto"", which is not imported by ""tensorflow/contrib/tensorboard/plugins/trace/trace_info.proto"".  To use it here, please add the necessary import.

```

`__git_version__: ""b'0.12.0-rc0-437-g6d63f67'""` ( pulled from head Dec 6th 5pm)
"
6196,Some example .py files missing from pip-installed TensorFlow source tree,"I'm working through TensorFlow's [the RNN tutorial](https://www.tensorflow.org/versions/master/tutorials/recurrent/index.html). Navigating to the `tensorflow/models/rnn/ptb` directory, I should see `reader.py` and `ptb_word_lm.py`, but I only see `reader.py` (alongside `__init__.py` etc).

I've tried both the install using `https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-0.12.0rc0-py3-none-any.whl`, and the default pip installation; they don't differ in this regard.

I wonder if this is related to #5014, which also deals with missing files. Everything seems to _work_ correctly, as far as I can tell — it's just that some of these examples are missing from the source tree.

### Environment info

- Operating System: macOS 10.12.1
- I'm using Homebrew'd Python 3.5 in a virtualenv.
- The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`: `0.12.0-rc0`"
6195,Running summary call crashes sporadically,"Every so often when calling session.run on my summary graph, the whole thing crashes. The only error it says is Segmentation fault (core dumped). I don't know exactly what steps to take to reproduce it, but I do know it fails on this line:
``` python
_, summary_str = sess.run([train_op, summary],  
    options=run_options,
    run_metadata=run_metadata)
```
Summary is just defined as `summary = tf.summary.merge_all()`

It never crashes when only running train_op, and only crashes when running the summary every 10,000 or so iterations.

### Environment info
Operating System: Ubuntu 16.04

Installed version of CUDA and cuDNN: 8.0, cudnn 5.1.5
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):
ls -l /usr/local/cuda/lib64/libcud* results in 

-rw-r--r-- 1 root root   558720 Nov 17 14:07 /usr/local/cuda/lib64/libcudadevrt.a
lrwxrwxrwx 1 root root       16 Nov 17 14:07 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.8.0
lrwxrwxrwx 1 root root       19 Nov 17 14:07 /usr/local/cuda/lib64/libcudart.so.8.0 -> libcudart.so.8.0.44
-rwxr-xr-x 1 root root   415432 Nov 17 14:07 /usr/local/cuda/lib64/libcudart.so.8.0.44
-rw-r--r-- 1 root root   775162 Nov 17 14:07 /usr/local/cuda/lib64/libcudart_static.a
-rwxr-xr-x 1 root root 79337624 Nov 17 17:24 /usr/local/cuda/lib64/libcudnn.so
lrwxrwxrwx 1 root root       33 Nov 17 17:25 /usr/local/cuda/lib64/libcudnn.so.5 -> /usr/local/cuda/lib64/libcudnn.so
lrwxrwxrwx 1 root root       33 Nov 17 17:25 /usr/local/cuda/lib64/libcudnn.so.5.1 -> /usr/local/cuda/lib64/libcudnn.so
lrwxrwxrwx 1 root root       33 Nov 17 17:25 /usr/local/cuda/lib64/libcudnn.so.5.1.5 -> /usr/local/cuda/lib64/libcudnn.so

1. The commit hash (`git rev-parse HEAD`) 93a91d9b782e01612175bb1f76688aa2580a968f
2. The output of `bazel version`
Extracting Bazel installation...
..........
Build label: 0.4.0
Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Wed Nov 2 17:54:14 2016 (1478109254)
Build timestamp: 1478109254
Build timestamp as int: 1478109254
"
6194,Can I reshape Tensor in C++ like Caffe's Blob,"Hello,
I want to use tensors of dynamic shapes in C++.
Can I reshape Tensor like Caffe's Blob, which means after reshape, the  total size of new tensor  can be unchanged.
"
6193,"gradients for assign/tf.scatter_update, etc","Hello,

I was wondering whether there is a specific reason for tf.assign not having gradients.

I think that it would make sense that tf.assign, i.e. a call of the form `variable.assign(value)` ""inherits"" the gradients from value, such that `grad(variable) = grad(value)`, after the assignment.

This would be especially useful within the context of the scatter-update functions, since those are one of the most convenient ways to avoid indexing and do partial updates of variables.

If there are cases where this is not required, assign could maybe take an argument that allows this, such as ""inherit_gradients"", or some such, do not break compatibility.

Thank you!
"
6192,tensorflow android camera demo: replacing inception5h with incetoption-resnetV2,"I am trying to replace the provided inception5h with latest inception-resnetV2. I have downloaded the inception-resnet-V2 by entring 
 `wget http://download.tensorflow.org/models/inception_resnet_v2_2016_08_30.tar.gz -O /tmp/inception_resnet_v2_2016_08_30.tar.gz`

And unzip it in 

`unzip /tmp/inception_resnet_v2_2016_08_30.tar.gz -d tensorflow/examples/android/assets/`

After unzip I only found **inception_resnet_v2_2016_08_30.ckpt** but for Android demo requires a `MODEL_FILE` with .pb extension and a `LABEL_FILE`. How I can get these files for inception-resnetV2.
"
6191,Tensorflow pypi packages not found from TravisCI,"I am experiencing trouble installing tensorflow from TravisCI. As tensorflow 0.12.0rc0 is on pypi a simple

    pip install tensorflow

should install tensorflow (CPU). Yet, although this works locally, it does not work on Travis with the following error:

    Could not find any downloads that satisfy the requirement tensorflow==0.12.0rc0 (from -r requirements.txt (line 1))
      No distributions at all found for tensorflow==0.12.0rc0 (from -r requirements.txt (line 1))

According to [this scipy issue](https://github.com/scipy/scipy/issues/6213), it could be a problem with the packages that are being uploaded to pypi. In particular, there is a `cp27mu-manylinux` version for python 2.7 and `cp34m-manylinux` versions for python 3.4 (and also 3.5). The above issue seems to suggest that the ""mu"" versions would be used for python3 and the ""m"" versions for 2.7.

Other packages solve this problem by installing tensorflow from the URL. Given that tensorflow is now on pypi, the failure to import it from travis seems to point to a bug in your build system."
6190,Hanging when Matching Filenames in 0.12,"I have a network which uses `tf.train.shuffle_batch` with a `tf.train.string_input_produces`. The network worked in 0.11, but hangs in 0.12. 

Disclaimer: I don't have access to 0.11 anymore and I changed some other stuff, but I'm fairly sure that the important bit is still the same.

Hanging means: I don't get further than the ""Creating TensorFlow device"" message.

The reason I'm thinking it's due to the queue is because after enabling the `log_device_placement` flag, the last output I'm seeing is

    I tensorflow/core/common_runtime/simple_placer.cc:827] 
        matching_filenames/MatchingFiles/pattern

Also, using a barebowns graph like

```
a = tf.constant(4)
b = tf.constant(2)
s = tf.Session()
s.run(a + b)
```

works, so I don't think it is due to my TensorFlow installation.

The hang is reproducible for me. I don't know how to enable further logging but would be glad to do so.

---

The code to create the queue is as follows, basically it's the same as [in the tutorial](https://www.tensorflow.org/versions/r0.12/how_tos/reading_data/index.html)

```
filenames = tf.train.match_filenames_once(filenames_glob)
filename_queue = tf.train.string_input_producer(
    filenames, num_epochs=num_epochs, shuffle=shuffle)
image = _read_pngs(filename_queue)

min_after_dequeue = 100
capacity = min_after_dequeue + 1 * batch_size

return tf.train.shuffle_batch(
    [image],
    batch_size=batch_size, capacity=capacity,
    min_after_dequeue=min_after_dequeue,
    seed=666, name=name)
```"
6189,Inconsistent behavior for tf.variable_scope,"#### Problem:
Tensorflow doesn't place ops (e.g. `mul`) in pre-existing variable scopes (and automatically creates a new scope instead). 

#### Minimal Reproducible Example
```python
with tf.variable_scope('layer123'):
    v = tf.get_variable('v', [], initializer=tf.constant_initializer(42., tf.float32))
    w = v * 2
print(w.name)    # Prints 'layer123/mul:0'
```

However, 
```python
with tf.variable_scope('layer123'):
    v = tf.get_variable('v', [], initializer=tf.constant_initializer(42., tf.float32))

with tf.variable_scope('layer123'):
    w = v * 2

print(w.name)    # Prints 'layer123_1/mul:0'
```

Observe that for the latter, the op `w` is placed in a different variable scope, auto-named `layer123_1`.

I've tried the following, to the same effect:

```python
with tf.variable_scope('layer123') as scope:
    v = tf.get_variable('v', [], initializer=tf.constant_initializer(42., tf.float32))

with tf.variable_scope(scope):
    w = v * 2

print(w.name)    # Prints 'layer123_1/mul:0'
```

```python
with tf.variable_scope('layer123'):
    v = tf.get_variable('v', [], initializer=tf.constant_initializer(42., tf.float32))

with tf.variable_scope('layer123', reuse=True):
    w = v * 2

print(w.name)    # Prints 'layer123_1/mul:0'
```

#### VersionSpec
Tensorflow version: 0.11.0 (GPU)
OS: Ubuntu 14.04 (w/ CUDA 8)"
6188,NotFoundError: ..._cudnn_rnn_ops.so [0.12.0],"no luck with new build so far (running linux-64, conda 4.2.13, Python3.5)

`conda install -c jjhelmus tensorflow=0.12.0rc0 `

trying to run a script I get:
```
NotFoundError: /home/miriam/anaconda2/envs/py35/lib/python3.5/site-packages/tensorflow/contrib/cudnn_rnn/python/ops/_cudnn_rnn_ops.so: cannot open shared object file: No such file or directory
```"
6186,tf.split_v results in unknown shape size,"### Environment info
Operating System:
Linux Mint 17.3 3.19.0-32-generic
Tensorflow Version 0.12.0-rc0 (https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow_gpu-0.12.0rc0-cp34-cp34m-linux_x86_64.whl)

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)
`
tf.split_v(tf.placeholder(tf.float32, shape=[10, 32, 32, 3]), [3,7], 0)
`
The result is of shape (?, ?, ?, ?). 

However, when using split for equal length splits it shows the resulting shape:
`
tf.split(0, 2, tf.placeholder(tf.float32, shape=[10, 32, 32, 3]))
`

"
6184,wide_n_deep Tutorial example not working,"Windows 10 - 0.12.0-rc0

Encountered error ""AttributeError: 'NoneType' object has no attribute 'bucketize'"" when running the example without any modification.

Full working and error log as follows:

WARNING:tensorflow:The default value of combiner will change from ""sum"" to ""sqrtn"" after 2016/11/01.
WARNING:tensorflow:The default value of combiner will change from ""sum"" to ""sqrtn"" after 2016/11/01.
WARNING:tensorflow:The default value of combiner will change from ""sum"" to ""sqrtn"" after 2016/11/01.
WARNING:tensorflow:The default value of combiner will change from ""sum"" to ""sqrtn"" after 2016/11/01.
WARNING:tensorflow:The default value of combiner will change from ""sum"" to ""sqrtn"" after 2016/11/01.
WARNING:tensorflow:The default value of combiner will change from ""sum"" to ""sqrtn"" after 2016/11/01.
WARNING:tensorflow:The default value of combiner will change from ""sum"" to ""sqrtn"" after 2016/11/01.
WARNING:tensorflow:The default value of combiner will change from ""sum"" to ""sqrtn"" after 2016/11/01.
WARNING:tensorflow:The default value of combiner will change from ""sum"" to ""sqrtn"" after 2016/11/01.
WARNING:tensorflow:The default value of combiner will change from ""mean"" to ""sqrtn"" after 2016/11/01.
WARNING:tensorflow:The default value of combiner will change from ""mean"" to ""sqrtn"" after 2016/11/01.
WARNING:tensorflow:The default value of combiner will change from ""mean"" to ""sqrtn"" after 2016/11/01.
WARNING:tensorflow:The default value of combiner will change from ""mean"" to ""sqrtn"" after 2016/11/01.
WARNING:tensorflow:The default value of combiner will change from ""mean"" to ""sqrtn"" after 2016/11/01.
WARNING:tensorflow:The default value of combiner will change from ""mean"" to ""sqrtn"" after 2016/11/01.
WARNING:tensorflow:From C:\Python35\lib\site-packages\tensorflow\contrib\learn\python\learn\estimators\dnn_linear_combined.py:711 in fit.: calling BaseEstimator.fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.
Instructions for updating:
Estimator is decoupled from Scikit Learn interface by moving into
separate class SKCompat. Arguments x, y and batch_size are only
available in the SKCompat class, Estimator will only accept input_fn.
Example conversion:
  est = Estimator(...) -> est = SKCompat(Estimator(...))
WARNING:tensorflow:From C:\Python35\lib\site-packages\tensorflow\contrib\learn\python\learn\estimators\dnn_linear_combined.py:711 in fit.: calling BaseEstimator.fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with y is deprecated and will be removed after 2016-12-01.
Instructions for updating:
Estimator is decoupled from Scikit Learn interface by moving into
separate class SKCompat. Arguments x, y and batch_size are only
available in the SKCompat class, Estimator will only accept input_fn.
Example conversion:
  est = Estimator(...) -> est = SKCompat(Estimator(...))
WARNING:tensorflow:From C:\Python35\lib\site-packages\tensorflow\contrib\learn\python\learn\estimators\dnn_linear_combined.py:711 in fit.: calling BaseEstimator.fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with batch_size is deprecated and will be removed after 2016-12-01.
Instructions for updating:
Estimator is decoupled from Scikit Learn interface by moving into
separate class SKCompat. Arguments x, y and batch_size are only
available in the SKCompat class, Estimator will only accept input_fn.
Example conversion:
  est = Estimator(...) -> est = SKCompat(Estimator(...))
WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.
WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.
WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.
WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.
WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.
Traceback (most recent call last):
  File ""wide_n_deep_tutorial.py"", line 207, in <module>
    tf.app.run()
  File ""C:\Python35\lib\site-packages\tensorflow\python\platform\app.py"", line 43, in run
    sys.exit(main(sys.argv[:1] + flags_passthrough))
  File ""wide_n_deep_tutorial.py"", line 203, in main
    train_and_eval()
  File ""wide_n_deep_tutorial.py"", line 196, in train_and_eval
    m.fit(input_fn=lambda: input_fn(df_train), steps=FLAGS.train_steps)
  File ""C:\Python35\lib\site-packages\tensorflow\contrib\learn\python\learn\estimators\dnn_linear_combined.py"", line 711, in fit
    max_steps=max_steps)
  File ""C:\Python35\lib\site-packages\tensorflow\python\util\deprecation.py"", line 191, in new_func
    return func(*args, **kwargs)
  File ""C:\Python35\lib\site-packages\tensorflow\contrib\learn\python\learn\estimators\estimator.py"", line 355, in fit
    max_steps=max_steps)
  File ""C:\Python35\lib\site-packages\tensorflow\contrib\learn\python\learn\estimators\estimator.py"", line 699, in _train_model
    train_ops = self._get_train_ops(features, labels)
  File ""C:\Python35\lib\site-packages\tensorflow\contrib\learn\python\learn\estimators\estimator.py"", line 1052, in _get_train_ops
    return self._call_model_fn(features, labels, model_fn_lib.ModeKeys.TRAIN)
  File ""C:\Python35\lib\site-packages\tensorflow\contrib\learn\python\learn\estimators\estimator.py"", line 1019, in _call_model_fn
    params=self.params)
  File ""C:\Python35\lib\site-packages\tensorflow\contrib\learn\python\learn\estimators\dnn_linear_combined.py"", line 504, in _dnn_linear_combined_model_fn
    scope=scope)
  File ""C:\Python35\lib\site-packages\tensorflow\contrib\layers\python\layers\feature_column_ops.py"", line 526, in weighted_sum_from_feature_columns
    transformed_tensor = transformer.transform(column)
  File ""C:\Python35\lib\site-packages\tensorflow\contrib\layers\python\layers\feature_column_ops.py"", line 869, in transform
    feature_column.insert_transformed_feature(self._columns_to_tensors)
  File ""C:\Python35\lib\site-packages\tensorflow\contrib\layers\python\layers\feature_column.py"", line 1489, in insert_transformed_feature
    name=""bucketize"")
  File ""C:\Python35\lib\site-packages\tensorflow\contrib\layers\python\ops\bucketization_op.py"", line 48, in bucketize
    return _bucketization_op.bucketize(input_tensor, boundaries, name=name)
AttributeError: 'NoneType' object has no attribute 'bucketize'

"
6182,SummaryWriter.add_summary() gives error AttributeError: 'FileWriter' object has no attribute 'add_sumary',"I literally copied and pasted an example from the tensor board training site and it doesn't run.

summary, _ = sess.run([merged, train_step], feed_dict=feed_dict(True)) train_writer.add_summary(summary, i)

Both these lines give an error.
apparently sess.run returns a None type."
6181,Quantization code in different path to where specified in Help Documentation,"Following the documentation here to Quantize - https://www.tensorflow.org/versions/r0.12/how_tos/quantization/index.html

seems to be wrong.

I had to change  
`bazel build tensorflow/contrib/quantization/tools:quantize_graph
bazel-bin/tensorflow/contrib/quantization/tools/quantize_graph \
--input=/tmp/classify_image_graph_def.pb \
--output_node_names=""softmax"" --output=/tmp/quantized_graph.pb \
--mode=eightbit`
TO
`bazel build tensorflow/tools/quantization/quantize_graph
bazel-bin/tensorflow/tools/quantization/quantize_graph \
--input=/tmp/classify_image_graph_def.pb \
--output_node_names=""softmax"" --output=/tmp/quantized_graph.pb \
--mode=eightbit
`
ie it seems like it's moved from tensorflow/contrib to tensorflow/tools/
"
6180,How to create a 5D tensor as the input of a 3DCNN,"I try to create a 4D tensor as input of a 2DCNN. I am confused about how to create a 5DCNN .Is the 4D tensor as one of dimension of a 5D tensor? Is there someone who know the detials ?
"
6179,How to localize the position of object by using tensorflow,"The ILSVRC competition held by imagenet includes Object localization and Object detection and other tasks.

How did the convolutional neural network solve the localization problem? 
I can only find tutorials on classification task.

I think it is proper to add an example of localization in tensorflow tutorial."
6177,[Compression]Compression issues of File isn't open for reading with r0.12,"I have met a problem with the model of  Compression again.

[https://github.com/tensorflow/models/tree/master/compression](url)
I use the OS of Ubuntu 14.04 LTS and the version of Tensorflow is r0.12

The error print as:
Traceback (most recent call last):
  File ""encoder.py"", line 103, in <module>
    tf.app.run()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 44, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""encoder.py"", line 99, in main
    np.savez_compressed(code_file, shape=int_codes.shape, codes=export)
  File ""/usr/local/lib/python2.7/dist-packages/numpy/lib/npyio.py"", line 600, in savez_compressed
    _savez(file, args, kwds, True)
  File ""/usr/local/lib/python2.7/dist-packages/numpy/lib/npyio.py"", line 642, in _savez
    zipf.write(tmpfile, arcname=fname)
  File ""/usr/lib/python2.7/zipfile.py"", line 1139, in write
    zinfo.header_offset = self.fp.tell()    # Start of header bytes
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/lib/io/file_io.py"", line 141, in tell
    ""File isn't open for reading"")
tensorflow.python.framework.errors_impl.PermissionDeniedError: File isn't open for reading
Exception tensorflow.python.framework.errors_impl.PermissionDeniedError: PermissionDeniedError() in <bound method ZipFile.__del__ of <zipfile.ZipFile object at 0x7f368ed35a50>> ignored
"
6175,What is All_op in tf.nn.dynamic_rnn?,"Hi, I am doing an android demo for RNN. I built a two-layer GRU network for inference. I used the API tf.nn.dynamic_rnn. However, when using this API, the saved generated .pb file contains an op called ""All"". And after I moved my .pb file to assets directory and run my android app demo, it said the op ""All"" is not registered. I know I can register an op in /core/kernels/BUILD file. However, I didn't find such an op in BUILD file. What is it and how can I fix the problem?
Thank you very much!

Here is the .pb file:
node {
    name: ""Test/Model/RNN/RNN/All""
    op: ""All""
    input: ""Test/Model/RNN/RNN/Equal""
    input: ""Test/Model/RNN/RNN/Const""
    attr {
       key: ""Tidx""
       value {
          type: DT_INT32
       }
}
attr {
key: ""keep_dims""
      value {
      b: false
     }
   }
 }


"
6174,DBPEDIA_URL is not a valid download url anymore,"DBPEDIA_URL in [text_datasets.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/learn/python/learn/datasets/text_datasets.py) is not a valid url anymore because web hosting in Google Drive has been deprecated, https://gsuite-developers.googleblog.com/2015/08/deprecating-web-hosting-support-in.html

Proposed fix: 
- Move [dbpedia_csv.tar.gz](https://drive.google.com/drive/folders/0Bz8a_Dbh9Qhbfll6bVpmNUtUcFdjYmF2SEpmZUZUcVNiMUw1TWN6RDV3a0JHT3kxLVhVR2M) to cloud storage.

What is affected:
- Text classification examples that depend on DBpedia data like [text_classification.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/learn/text_classification.py) are now broken."
6171,tfprof: Python3 incompatibility,"[This line in tfprof_logger.py](https://github.com/tensorflow/tensorflow/blob/20c3d37ecc9bef0e106002b9d01914efd548e66b/tensorflow/contrib/tfprof/python/tools/tfprof/tfprof_logger.py#L127) uses `dict.iteritems()`, which breaks my Python 3 code.
"
6170,training process dies without warning,"I have two GPUs. I start an LSTM training process on one GPU by masking CUDA_VISIBLE_DEVICES in the python script:

```python
gpu_id='0'
os.environ['CUDA_VISIBLE_DEVICES'] = gpu_id
```
I then start a second training process using the same technique, but with `gpu_id='1'`. Shortly after launching the second training process, the first one dies without any message. 

Each invocation looks something like this

```bash
nohup python train.py .... >& train.log &
```

When I do the same thing without redirecting to a file, I see simply `Killed`

This only happens when I try to run two training processes. I am able to run training and evaluation at the same time on different cards. 

### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?
Nothing looks similar. 

### Environment info
Operating System: CentOS 7

Installed version of CUDA and cuDNN: 
CUDA = 8.0 cuDNN = 5.1

(please attach the output of `ls -l /path/to/cuda/lib/libcud*`): 
https://paste.debian.net/901121/

If installed from binary pip package, provide:

1. A link to the pip package you installed: https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.11.0-cp27-none-linux_x86_64.whl
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.
0.11.0


### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)


### What other attempted solutions have you tried?
*  I tried setting CUDA_VISIBLE_DEVICES from the command line before starting the training script. e.g. `CUDA_VISIBLE_DEVICES=0`

### Logs or other output that would be helpful
Driver Version: 367.48

"
6168,Placeholder mismatch,"I am trying to train two classifiers in one session. I declared two separate placeholders and pass each of them to different classifiers in run-time. The first one works fine, but the second one does not. The error message tells me that the second classifier is trying to look for the placeholder for the first classifier (instead of its own).

The code is attached below
```
from __future__ import absolute_import, division, print_function
import os
import prettytensor as pt
import tensorflow as tf
from tensorflow.examples.tutorials.mnist import input_data
dataset_name = ""data/MNIST""
if not os.path.exists(dataset_name):
    os.makedirs(dataset_name)
dataset = input_data.read_data_sets(
    dataset_name,
    reshape=False,
    one_hot=True
)

########################
# Construct Classifier #
########################
def construct_lenet(lenet_images, lenet_labels):
    images = pt.wrap(lenet_images)
    with pt.defaults_scope(activation_fn=tf.nn.relu, l2loss=0.00001):
        return (
            images
            .conv2d(5, 20)
            .max_pool(2, 2)
            .conv2d(5, 50)
            .max_pool(2, 2)
            .flatten()
            .fully_connected(500)
            .softmax_classifier(10, lenet_labels)
        )

####################
# First Classifier #
####################
classifier_images_placeholder_1 = tf.placeholder(
    tf.float32,
    [
        50,
        28,
        28,
        1
    ]
)
classifier_labels_placeholder_1 = tf.placeholder(
    tf.float32,
    [
        50,
        10
    ]
)

classifier_result_1 = construct_lenet(
    classifier_images_placeholder_1,
    classifier_labels_placeholder_1
)
classifier_optimizer_1 = tf.train.AdamOptimizer(0.01)
classifier_train_op_1 = pt.apply_optimizer(
    classifier_optimizer_1,
    losses=[classifier_result_1.loss]
)

#####################
# Second Classifier #
#####################
classifier_images_placeholder_2 = tf.placeholder(
    tf.float32,
    [
        50,
        28,
        28,
        1
    ]
)
classifier_labels_placeholder_2 = tf.placeholder(
    tf.float32,
    [
        50,
        10
    ]
)

classifier_result_2 = construct_lenet(
    classifier_images_placeholder_2,
    classifier_labels_placeholder_2
)
classifier_optimizer_2 = tf.train.AdamOptimizer(0.01)
classifier_train_op_2 = pt.apply_optimizer(
    classifier_optimizer_2,
    losses=[classifier_result_2.loss]
)



init = tf.initialize_all_variables()
with tf.Session() as sess:
    sess.run(init)
##########################
# Train First Classifier #
##########################
    classifier_training_loss = 0.0
    for i in range(10):
        training_images, training_labels = dataset.train.next_batch(
            50
        )
        _, classifier_runtime_loss = sess.run(
            fetches=[
                classifier_train_op_1,
                classifier_result_1.loss
            ],
            feed_dict={
                classifier_images_placeholder_1: training_images,
                classifier_labels_placeholder_1: training_labels
            }
        )
        classifier_training_loss += classifier_runtime_loss
    classifier_training_loss /= dataset.train.num_examples
    print(classifier_training_loss)
###########################
# Train Second Classifier #
###########################
    classifier_training_loss = 0.0
    for i in range(10):
        training_images, training_labels = dataset.train.next_batch(
            50
        )
        _, classifier_runtime_loss = sess.run(
            fetches=[
                classifier_train_op_2,
                classifier_result_2.loss
            ],
            feed_dict={
                classifier_images_placeholder_2: training_images,
                classifier_labels_placeholder_2: training_labels
            }
        )
        classifier_training_loss += classifier_runtime_loss
    classifier_training_loss /= dataset.train.num_examples
    print(classifier_training_loss)
```

Error message is attached below
```
W tensorflow/core/framework/op_kernel.cc:968] Invalid argument: You must feed a value for placeholder tensor 'Placeholder' with dtype float and shape [50,28,28,1]
    [[Node: Placeholder = Placeholder[dtype=DT_FLOAT, shape=[50,28,28,1], _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]
Traceback (most recent call last):
  File ""stack_overflow.py"", line 134, in <module>
    classifier_labels_placeholder_2: training_labels
  File ""/Users/user/Packages/anaconda/envs/tensorflow2/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 717, in run
    run_metadata_ptr)
  File ""/Users/user/Packages/anaconda/envs/tensorflow2/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 915, in _run
    feed_dict_string, options, run_metadata)
  File ""/Users/user/Packages/anaconda/envs/tensorflow2/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 965, in _do_run
    target_list, options, run_metadata)
  File ""/Users/user/Packages/anaconda/envs/tensorflow2/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 985, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors.InvalidArgumentError: You must feed a value for placeholder tensor 'Placeholder' with dtype float and shape [50,28,28,1]
     [[Node: Placeholder = Placeholder[dtype=DT_FLOAT, shape=[50,28,28,1], _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]

Caused by op u'Placeholder', defined at:
  File ""stack_overflow.py"", line 44, in <module>
    1
  File ""/Users/user/Packages/anaconda/envs/tensorflow2/lib/python2.7/site-packages/tensorflow/python/ops/array_ops.py"", line 1332, in placeholder
    name=name)
  File ""/Users/user/Packages/anaconda/envs/tensorflow2/lib/python2.7/site-packages/tensorflow/python/ops/gen_array_ops.py"", line 1748, in _placeholder
    name=name)
  File ""/Users/user/Packages/anaconda/envs/tensorflow2/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py"", line 749, in apply_op
    op_def=op_def)
  File ""/Users/user/Packages/anaconda/envs/tensorflow2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 2380, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/Users/user/Packages/anaconda/envs/tensorflow2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 1298, in __init__
    self._traceback = _extract_stack()

InvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'Placeholder' with dtype float and shape [50,28,28,1]
     [[Node: Placeholder = Placeholder[dtype=DT_FLOAT, shape=[50,28,28,1], _device=""/job:localhost/replica:0/task:0/cpu:0""]()]]
```"
6166,"Build ""general"" shared library for Android to use with Android Make ","Luckily there is a very good introduction into programming with Tensorflow on an Android device provided here:
https://github.com/miyosuda/TensorFlowAndroidDemo

The version of TF used in this project is 0.10 which doesn't work with my trained model coming from TF 0.12. I was wondering which is the best way to have a ""generalized"" shared library (or however this is called), built with bazel that I could use interchangeably like the one provided in the project mentioned above. 
I was able to build the TF-Android Example using Bazel. My Anrdoid-project, which uses Tensorflow, also needs OpenCV to work. Therefore I'm building my App with a make-file which worked quiet well so far. 

Maybe I'm completely wrong, as I'm not really a programmer - so far. Thank you for any advice. 

"
6164,TFRecords: DataLossError (see above for traceback): corrupted record at XXX,"I convert large data from csv to tfrecords using tf.python_io.TFRecordWriter in hadoop
there're some error happens:
* BUG 1) if I use zlib or gzip when create tfrecord writer , I can convert the csv successfully. But when I  loop all files to read , it's  stuck at some lines without any error.  when use these tfrecords to train model ,  errors ""TFRecords: DataLossError (see above for traceback): corrupted record at XXX""
(I use writer.close() when write done. so I maybe it's  a bug )
* BUG 2) When I create tfrecord write without any compress option, the convert process goes well, and when I use the same program loop all the converted files , It all good . BUT when I use these tfrecords to train model in tensorflow , it's report ""TFRecords: DataLossError (see above for traceback): corrupted record at XXX"" again（some step after, not at the begining, so maybe some part of the tfrecords error） . 

my question:
* (if solve these bugs are diffcult ) how to skip the corruted records? 
OR
* how to solve these errors ?

### Environment info
Operating System:
centos 6 + hadoop

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)
my convert code:
```
          writer = tf.python_io.TFRecordWriter(pb_path)
          example = tf.train.Example(features=tf.train.Features(feature={
              ""label"":
                  tf.train.Feature(float_list=tf.train.FloatList(value=[label])),
              ""ids"":
                  tf.train.Feature(int64_list=tf.train.Int64List(value=ids)),
              ""values"":
                  tf.train.Feature(float_list=tf.train.FloatList(value=values))
          }))

          writer.write(example.SerializeToString())
          writer.close()
```

my debug code (for loop all files):
```
  for f in files:
   for serialized_example in tf.python_io.tf_record_iterator(f):
      example = tf.train.Example()
      example.ParseFromString(serialized_example)

      # Read data in specified format
      label = example.features.feature[""label""].float_list.value
      ids = example.features.feature[""ids""].int64_list.value
      values = example.features.feature[""values""].float_list.value
```

my train code
```
# Read TFRecords files for training
filename_queue = tf.train.string_input_producer(
    tf.train.match_filenames_once(FLAGS.train),
    num_epochs=epoch_number)
serialized_example = read_and_decode(filename_queue)
batch_serialized_example = tf.train.shuffle_batch(
    [serialized_example],
    batch_size=batch_size,
    num_threads=thread_number,
    capacity=capacity,
    min_after_dequeue=min_after_dequeue)
features = tf.parse_example(
    batch_serialized_example,
    features={
        ""label"": tf.FixedLenFeature([], tf.float32),
        ""ids"": tf.VarLenFeature(tf.int64),
        ""values"": tf.VarLenFeature(tf.float32),
    })
batch_labels = features[""label""]
batch_ids = features[""ids""]
batch_values = features[""values""]
```

### Logs or other output that would be helpful
(If logs are large, please upload as attachment or provide link).
```
coord stopped
Traceback (most recent call last):
  File ""deepcake.py"", line 327, in <module>
    coord.join(threads)
  File ""/home/serving/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/coordinator.py"", line 386, in join
    six.reraise(*self._exc_info_to_raise)
  File ""/home/serving/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/queue_runner_impl.py"", line 234, in _run
    sess.run(enqueue_op)
  File ""/home/serving/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 766, in run
    run_metadata_ptr)
  File ""/home/serving/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 964, in _run
    feed_dict_string, options, run_metadata)
  File ""/home/serving/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 1014, in _do_run
    target_list, options, run_metadata)
  File ""/home/serving/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 1034, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.DataLossError: corrupted record at 2863006
         [[Node: ReaderRead = ReaderRead[_class=[""loc:@TFRecordReader"", ""loc:@input_producer""], _device=""/job:localhost/replica:0/task:0/cpu:0""](TFRecordReader, input_producer)]]

Caused by op u'ReaderRead', defined at:
  File ""deepcake.py"", line 99, in <module>
    serialized_example = read_and_decode(filename_queue)
  File ""deepcake.py"", line 92, in read_and_decode
    _, serialized_example = reader.read(filename_queue)
  File ""/home/serving/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/io_ops.py"", line 265, in read
    return gen_io_ops._reader_read(self._reader_ref, queue_ref, name=name)
  File ""/home/serving/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/gen_io_ops.py"", line 213, in _reader_read
    queue_handle=queue_handle, name=name)
  File ""/home/serving/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py"", line 759, in apply_op
    op_def=op_def)
  File ""/home/serving/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 2240, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/home/serving/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 1128, in __init__
    self._traceback = _extract_stack()

DataLossError (see above for traceback): corrupted record at 2863006
         [[Node: ReaderRead = ReaderRead[_class=[""loc:@TFRecordReader"", ""loc:@input_producer""], _device=""/job:localhost/replica:0/task:0/cpu:0""](TFRecordReader, input_producer)]]
```"
6163,Opening http://projector.tensorflow.org/ shows a white screen in Chrome 55,"### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?

I have search for open GitHub issues with the keyword `WebGL`, but none showed up.

### Issue

Today I opened http://projector.tensorflow.org/ in my browser, but got a complete white screen. The attached logs show the errors that are show in the console of the browser. Opening in Firefox on the same machine does succesfully launch the application and I was able to interact with it. 

### Environment info
Operating System: Ubuntu 16.04
```
Google Chrome	55.0.2883.75 (Official Build) (64-bit)
Revision	451c239c3b0722dc867b0f75839b959f729b756a-refs/branch-heads/2883@{#698}
OS	Linux 
JavaScript	V8 5.5.372.29
Flash	23.0.0.207
User Agent	Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/55.0.2883.75 Safari/537.36
```


### Logs or other output that would be helpful
```
(index):7671 THREE.WebGLRenderer 77
(index):7671 THREE.WebGLRenderer: Error creating WebGL context.
THREE.WebGLRenderer
(index):7722 Uncaught TypeError: Cannot read property 'getExtension' of null
    at THREE.WebGLExtensions.get ((index):7722)
    at new THREE.WebGLRenderer ((index):7672)
    at new Gp ((index):8253)
    at new cq ((index):8320)
    at HTMLElement.q.setupUIControls ((index):8430)
    at HTMLElement.q.ready ((index):8413)
    at HTMLElement._invokeBehavior ((index):5501)
    at HTMLElement._doBehavior ((index):5501)
    at HTMLElement._readySelf ((index):5516)
    at HTMLElement._ready ((index):5516)
(index):8430 Uncaught TypeError: Cannot read property 'resize' of undefined
    at (index):8430
```
"
6162,Import error with skflow,"Hello,

I get an error when I try to import skflow with the command 
`from tensorflow.contrib import skflow`
The error is ""ImportError: cannot import name 'skflow"". I have googled the error came across this similar issue: https://github.com/tensorflow/tensorflow/issues/1931. Apparently I have a lower version of tensorflow (I had 0.12) and need a newer version, such as 0.80.

I had done the installation by looking at this website (for cpu based): https://www.tensorflow.org/versions/r0.12/get_started/os_setup.html#pip-installation-on-windows. 

Probably only 0.12 is released for windows. Is there a way to get a higher version for Windows, or some workaround?

As a solution I have also separately installed skflow, but some of the functions are not there, as I see them in this tutorial: http://learningtensorflow.com/lesson8/, since it is an older version probably.

I am now trying to build tensorflow on my computer with cmake and MSBuild, but it also does not run smoothly. You can see the issue with that here: https://github.com/tensorflow/tensorflow/issues/6160

I have the following specs:
- Windows 7, service pack 1, 64 bit
- Python 3.5
- Tensorflow 0.12

Thanks a lot,
Kerem"
6160,Windows MSBuild fails,"Hello,
I am trying to build tensorflow for cpu on my Windows computer using cmake and MS Visual Studio. I do the steps as described in the link below, I came until step 4, however at step 4 however MSBuild fails. Since I don't need the test program, I am trying to dirrectly build the .whl file by building the tf_python_copy_scripts_to_destination.vcxproj.

I am using the instructions from the link: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/cmake/README.md

 I have a service pack 1 Windows 7, 64 bit.

In terms of Prerequisites:
- CMake version 3.5 up to 3.6 (I have 3.6.3)
- Git (I have 2.10.0.windows.1)
- SWIG (I have swigwin 3.0.10)

Additional pre-requisites for Microsoft Windows:
- Visual Studio 2015 (I have VS 2015 and MSBuild 14.0)
- Python 3.5 (I have Python 3.5)
- NumPy 1.11.0 or later (I have 1.11.2)

Since there are multiple MSBuilds, I set the path string to the MSBuild 14.0: C:\Program Files (x86)\MSBuild\14.0\Bin\amd64. Also there are two versions, one directly under \Bin and one under \Bin\amd64. I choose the latter one. 


The error message I get is:
============================================

Done Building Project ""C:\Users\ktezcan\temp_tensorflowbuildfiles\tensorflow\tensorflow\contrib\cmake\build\tf_python_build_pip_package.vcxproj"" (default targe
ts) -- FAILED.


Build FAILED.

""C:\Users\ktezcan\temp_tensorflowbuildfiles\tensorflow\tensorflow\contrib\cmake\build\tf_python_build_pip_package.vcxproj"" (default target) (1) ->
""C:\Users\ktezcan\temp_tensorflowbuildfiles\tensorflow\tensorflow\contrib\cmake\build\pywrap_tensorflow.vcxproj"" (default target) (3) ->
""C:\Users\ktezcan\temp_tensorflowbuildfiles\tensorflow\tensorflow\contrib\cmake\build\tf_core_cpu.vcxproj"" (default target) (4) ->
""C:\Users\ktezcan\temp_tensorflowbuildfiles\tensorflow\tensorflow\contrib\cmake\build\tf_core_framework.vcxproj"" (default target) (5) ->
""C:\Users\ktezcan\temp_tensorflowbuildfiles\tensorflow\tensorflow\contrib\cmake\build\proto_text.vcxproj"" (default target) (6) ->
""C:\Users\ktezcan\temp_tensorflowbuildfiles\tensorflow\tensorflow\contrib\cmake\build\grpc.vcxproj"" (default target) (7) ->
(CustomBuild target) ->
  cl : Command line warning D9002: ignoring unknown option '-std=c11' [C:\Users\ktezcan\temp_tensorflowbuildfiles\tensorflow\tensorflow\contrib\cmake\build\grp
c\src\grpc\grpc_unsecure.vcxproj] [C:\Users\ktezcan\temp_tensorflowbuildfiles\tensorflow\tensorflow\contrib\cmake\build\grpc.vcxproj]
  cl : Command line warning D9002: ignoring unknown option '-std=c11' [C:\Users\ktezcan\temp_tensorflowbuildfiles\tensorflow\tensorflow\contrib\cmake\build\grp
c\src\grpc\grpc_unsecure.vcxproj] [C:\Users\ktezcan\temp_tensorflowbuildfiles\tensorflow\tensorflow\contrib\cmake\build\grpc.vcxproj]


""C:\Users\ktezcan\temp_tensorflowbuildfiles\tensorflow\tensorflow\contrib\cmake\build\tf_python_build_pip_package.vcxproj"" (default target) (1) ->
""C:\Users\ktezcan\temp_tensorflowbuildfiles\tensorflow\tensorflow\contrib\cmake\build\pywrap_tensorflow.vcxproj"" (default target) (3) ->
""C:\Users\ktezcan\temp_tensorflowbuildfiles\tensorflow\tensorflow\contrib\cmake\build\tf_core_cpu.vcxproj"" (default target) (4) ->
""C:\Users\ktezcan\temp_tensorflowbuildfiles\tensorflow\tensorflow\contrib\cmake\build\tf_core_framework.vcxproj"" (default target) (5) ->
""C:\Users\ktezcan\temp_tensorflowbuildfiles\tensorflow\tensorflow\contrib\cmake\build\proto_text.vcxproj"" (default target) (6) ->
""C:\Users\ktezcan\temp_tensorflowbuildfiles\tensorflow\tensorflow\contrib\cmake\build\grpc.vcxproj"" (default target) (7) ->
(CustomBuild target) ->
  C:\Users\ktezcan\temp_tensorflowbuildfiles\tensorflow\tensorflow\contrib\cmake\build\grpc\src\grpc\src\core\ext\transport\chttp2\transport\chttp2_transport.c
(2319): error C2440: 'initializing' : cannot convert from 'gpr_slice' to 'gpr_slice_refcount *' [C:\Users\ktezcan\temp_tensorflowbuildfiles\tensorflow\tensorfl
ow\contrib\cmake\build\grpc\src\grpc\grpc_unsecure.vcxproj] [C:\Users\ktezcan\temp_tensorflowbuildfiles\tensorflow\tensorflow\contrib\cmake\build\grpc.vcxproj]
  C:\Users\ktezcan\temp_tensorflowbuildfiles\tensorflow\tensorflow\contrib\cmake\build\grpc\src\grpc\src\core\ext\transport\chttp2\transport\chttp2_transport.c
(2319): error C2440: 'initializing' : cannot convert from 'gpr_slice' to 'gpr_slice_refcount *' [C:\Users\ktezcan\temp_tensorflowbuildfiles\tensorflow\tensorfl
ow\contrib\cmake\build\grpc\src\grpc\grpc_unsecure.vcxproj] [C:\Users\ktezcan\temp_tensorflowbuildfiles\tensorflow\tensorflow\contrib\cmake\build\grpc.vcxproj]

2 Warning(s)
2 Error(s)

Time Elapsed 00:00:58.06

=================================

Any help is appreciated. Thanks,
Kerem


"
6158,installation issues on Ubuntu 16.04 GPU version,"Dear developers:
I encountered one error with fine setting configuration
All the settings is right, and it said that 

                                           all external dependencies fetch successful 
                                           configuration finished 

all the thing right until I generate the pip_package

(bazel build -c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package), 

process like below:

`yuze@nlp:~/tensorflow$ ./configure 
~/tensorflow ~/tensorflow
Please specify the location of python. [Default is /usr/bin/python]: 
Do you wish to build TensorFlow with Google Cloud Platform support? [y/N] n
No Google Cloud Platform support will be enabled for TensorFlow
Do you wish to build TensorFlow with Hadoop File System support? [y/N] n
No Hadoop File System support will be enabled for TensorFlow
Found possible Python library paths:
  /usr/local/lib/python2.7/dist-packages
  /usr/lib/python2.7/dist-packages
Please input the desired Python library path to use.  Default is [/usr/local/lib/python2.7/dist-packages]

Using python library path: /usr/local/lib/python2.7/dist-packages
Do you wish to build TensorFlow with OpenCL support? [y/N] y
OpenCL support will be enabled for TensorFlow
Do you wish to build TensorFlow with CUDA support? [y/N] y
CUDA support will be enabled for TensorFlow
Please specify which gcc should be used by nvcc as the host compiler. [Default is /usr/bin/gcc]: 
Please specify the CUDA SDK version you want to use, e.g. 7.0. [Leave empty to use system default]: 8.0
Please specify the location where CUDA 8.0 toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: 
Please specify the Cudnn version you want to use. [Leave empty to use system default]: 
Please specify the location where cuDNN  library is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: 
Please specify a list of comma-separated Cuda compute capabilities you want to build with.
You can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.
Please note that each additional compute capability significantly increases your build time and binary size.
[Default is: ""3.5,5.2""]: 
Please specify which C++ compiler should be used as the host C++ compiler. [Default is /usr/bin/g++]: 
Please specify which C compiler should be used as the host C compiler. [Default is /usr/bin/gcc]: 
Please specify the location where ComputeCpp 1.2 is installed. Refer to README.md for more details. [Default is /usr/local/computecpp]: 
INFO: Starting clean (this may take a while). Consider using --expunge_async if the clean takes more than several minutes.
......
INFO: All external dependencies fetched successfully.
Configuration finished


yuze@nlp:~/tensorflow$ bazel build -c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package
INFO: Found 1 target...
ERROR: missing input file '@local_config_sycl//sycl:LICENSE.text'.
ERROR: /home/yuze/.cache/bazel/_bazel_yuze/540cd99ea4fee1092020a833f635df2b/external/farmhash_archive/BUILD:13:1: C++ compilation of rule '@farmhash_archive//:farmhash' failed: crosstool_wrapper_driver_is_not_gcc failed: error executing command external/local_config_cuda/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -fPIE -Wall -Wunused-but-set-parameter ... (remaining 37 argument(s) skipped): com.google.devtools.build.lib.shell.AbnormalTerminationException: Process terminated by signal 15.
ERROR: /home/yuze/tensorflow/tensorflow/tools/pip_package/BUILD:105:1: //tensorflow/tools/pip_package:build_pip_package: missing input file '@local_config_sycl//sycl:LICENSE.text'.
Target //tensorflow/tools/pip_package:build_pip_package failed to build
Use --verbose_failures to see the command lines of failed build steps.
ERROR: /home/yuze/tensorflow/tensorflow/tools/pip_package/BUILD:105:1 1 input file(s) do not exist.
INFO: Elapsed time: 3.485s, Critical Path: 1.17s
`
can you kindly tell me where is wrong?

Thank you!"
6155,Update tf.zeros_initializer method,"The `tf.zeros_initializer` method has an unnecessary argument, asking for the tensor shape. See [tensorflow documentation](https://www.tensorflow.org/versions/r0.12/api_docs/python/state_ops.html#zeros_initializer). The `tf.ones_initializer` method, which is essentialy equivalent in functionality, does not have this argument.

As a sidenote, the method `tf.constant_initializer` (see [documentation](https://www.tensorflow.org/versions/r0.12/api_docs/python/state_ops.html#constant_initializer)) also doesn't have this argument and serves the same purpose. In fact, if no keyword args are provided, it will behave as the `zeros_initializer` is intended to."
6154,dynamic variants of attention_decoder and embedding_attention_decoder,"I've been following @alrojo's PR(#4686) for the `tf.contrib.seq2seq.dynamic_rnn_decoder`. I recently had to customize `tf.nn.seq2seq.embedding_attention_decoder` and `tf.nn.seq2seq.attention_decoder` with while loops for a personal project, so I'd be happy to help write `attention` and `embedding_attention` decoder functions for use with `tf.contrib.seq2seq.dynamic_rnn_decoder` if that would be helpful. I'm unclear on whether this is already being worked on, since I see discussion of a `rnn_decoder_attention` function in #4761, but it was a commit which followed the old structure of `tf.contrib.seq2seq`. "
6153,Training on GPU and CPU with the same code differs significantly.,"I am training a TF network on two machines. It is the same code, which is basically a modification of the MNIST example. In one case, I use GPU on Amazon Cloud, in the other I use a standard CPU Intel Xeon. I have the same version of TF, the same code, the same parameters, the same packages the and same Ubuntu distribution.

In one case on GPU the learning process is significantly different, and particularly slower. It reaches only 0.60 performance while CPU one reaches 0.90. Increasing learning rate by 10 I managed to get the GPU result to 0.90 too. Have you encountered this problem before? Is this intended?"
6150,summary name of the new `summary` module,"With the new `tf.summary` module, the name shown in tensorboard has to be equal to the summary op in the graph.
As a result, the name shown in tensorboard cannot be the same as any existing op in the graph.
This can create a bit of problem. Before this change, I could have some op named `loss` and the summary of its output also named `loss`, which is very consistent and easy to play with -- I can just look for the name of the tensor in tensorboard.
Now it looks like I have to add a prefix/suffix to everything because they cannot use the same name. Otherwise I got `loss_1` in tensorboard which is confusing especially to new users.

Is there some changes that could be done to the new `summary` module that keeps the nice old feature? "
6148,"Data Parallel, multi GPU (minimal) example?","I am trying to get a simple example of tensorflow that parallelises the data over multiple GPUs to train. I have looked at `cifar10_multi_gpu.py` and its associated input files etc. but it seems to be a bit beyond me at this stage. Especially since I'm not sure why multiple GPUs would speed up the process in that example. If I understand correctly in that example all GPUs get the same copy of the data and the model. The only advantage that I see from this is that you can search a more spread out weight/parameter space.

What I expected was a line that did something similar to:
```
with tf.Session() as sess:
    for i in range(4): #for 4 gpus
        with tf.device('/gpu:%d' % i):
            tf.feed_dict({x: data[i*step:(i+1)*step], y: labels[i*step:(i+1)*step])
```
with the emphasis of the feed dict feeding different data to the four different gpus. I haven't however thought how I would go about getting the gradients and averaging them yet. 

Any code examples would be highly appreciated. If not thoughts or any direction on how to proceed is also welcome."
6146,Fast Layer Normalization GPU kernel,"Hi, I wrote a [custom CUDA op for layer normalization](https://github.com/MycChiu/fast-LayerNorm-TF), which is about 5-10x faster than the current `tf.contrib.layers.layer_norm`.

After I posted the link on reddit, some people suggested that I should try to merge this kernel into the trunk, but I have never done this before, so I need some guidance on how this custom kernel could be integrated into TensorFlow's current code.

With my current understanding on how TensorFlow's code is organized, here are some of the problems I think should be solved before the custom op can be integrated into the trunk:
1. It doesn't have CPU kernels.
2. Since the kernel uses shuffle instructions, it only supports cards newer than Kepler.
3. Current implementation has a restriction on the size of last dimension (cannot be larger than 5102)

Without solving these problems, the fastest way to merge this op into the trunk is probably by putting it under the `tf.contrib` folder as it is right now. I will fill out the CLA and make a pull request if you guys think this custom kernel is ready to be merged into the `tf.contrib` folder."
6144,hitting 2GB limit when importing large frozen graphs onto multiple gpus,"When I tried to import a big graph onto multiple gpus (multiple times), the graph def usually goes beyond 2GB. Is there a solution to this in tf?"
6143,Feature request: second derivatives for pooling operations,"Currently, neither `tf.nn.avg_pool` or `tf.nn.max_pool` support automatically taking second derivatives, making it difficult to experiment with second-order methods on neural networks that use any sort of pooling (which unfortunately includes most modern networks). Trying to take a second derivative gives a `LookupError`, e.g., `LookupError: No gradient defined for operation 'gradients_4...AvgPoolGrad' (op type: AvgPoolGrad)`.  

Do you have any plans for implementing second derivatives for pooling operations, or any suggested workarounds like rewriting the pooling operations in terms of elementary functions that have second derivatives defined? Thank you!
"
6142,NewCheckpointReader does not work for the V2 checkpoint format,"Unable to read the new checkpoints (V2 format) that became default from r0.12 release using `NewCheckpointReader`. This breaks the TF slim API, specifically:
https://github.com/tensorflow/tensorflow/blob/c2d14aa0d80897b7164e32e16951d03a36342370/tensorflow/contrib/framework/python/ops/variables.py#L487

### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?
https://groups.google.com/a/tensorflow.org/forum/#!topic/discuss/3AalcBJ-6z8
I started that thread and was suggested to post an issue here

### Environment info
Operating System: CentOS 6.6

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`): CUDA 8, cuDNN 5

If installed from binary pip package, provide:

1. A link to the pip package you installed:
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`. 0.12.0-rc0


### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)

```python
import tensorflow as tf

w1 = tf.Variable(tf.truncated_normal(shape=[10]), name='w1')
saver = tf.train.Saver()
sess = tf.Session()
sess.run(tf.initialize_all_variables())
saver.save(sess, 'my-model')

reader = tf.train.NewCheckpointReader('my-model.index')  ## error
print reader.get_variable_to_shape_map()
```

The error is:
```txt
Traceback (most recent call last):
  File ""save_and_restore.py"", line 9, in <module>
    reader = tf.train.NewCheckpointReader('my-model.index')
  File ""/anaconda2/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 110, in NewCheckpointReader
    return CheckpointReader(compat.as_bytes(filepattern), status)
  File ""/anaconda2/lib/python2.7/contextlib.py"", line 24, in __exit__
    self.gen.next()
  File ""/anaconda2/lib/python2.7/site-packages/tensorflow/python/framework/errors_impl.py"", line 469, in raise_exception_on_not_ok_status
    pywrap_tensorflow.TF_GetCode(status))
tensorflow.python.framework.errors_impl.NotFoundError: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for my-model.index
```
"
6141,Feature request: directional distributions (like von Mises-Fisher),"Are there plans to implement directional statistical distributions? In particular, I'm looking to get a von Mises-Fisher distribution into `contrib/distributions/python`.

I'm beginning work on a VMF distribution myself, but as a new TF user my progress is likely to be slow.

(Note that `scipy.stats` implements a basic von Mises distribution.)

References:
[Wikipedia: Von Mises–Fisher distribution](https://en.wikipedia.org/wiki/Von_Mises%E2%80%93Fisher_distribution)
[Arxiv: Directional Statistics in Machine Learning: a Brief Review]( https://arxiv.org/pdf/1605.00316.pdf
)"
6136,ImportError: No module named 'tensorflow' on windows + anaconda,"I followed the instructions on downloading and setting up tensorflow on windows. they result in one red line on the pip installation and the no-module-found error message in python interactive.

steps:
- install anaconda for windows 64bit for python 3.5 as per given link in the tensorflow install page
- issue a pip for tensorflow (either one of these would result in the samething):
C:\> pip install --upgrade https://storage.googleapis.com/tensorflow/windows/cpu/tensorflow-0.12.0rc0-cp35-cp35m-win_amd64.whl
or
C:\> pip install --upgrade https://storage.googleapis.com/tensorflow/windows/gpu/tensorflow_gpu-0.12.0rc0-cp35-cp35m-win_amd64.whl

the pip installation ends with a line printed in red:
""Cannot remove entries from nonexistent file c:\users\jesaremi\appdata\local\continuum\anaconda3\lib\site-packages\easy-install.pth""

- open up python and type ""import tensorflow as tf"":
>>> import tensorflow as tf
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
ImportError: No module named 'tensorflow'"
6134,"make `tensorflow.python.tools` importable (freeze_graph, and others)","for mysterious reasons, these functions aren't importable

can we add an `__init__.py` to this directory so that we can import them? thoughts?"
6132,contrib.learn.Estimator does not work with multiple GPU,"Attempting to assign ops to a GPU within model_fn passed to an Estimator produces the following error:

```
tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device to node 'save/ShardedFilename_2': Could not satisfy explicit device specification '/device:GPU:1' because no supported kernel for GPU devices is available.
Colocation Debug Info:
Colocation group had the following types and devices: 
Identity: CPU 
ShardedFilename: CPU 
	 [[Node: save/ShardedFilename_2 = ShardedFilename[_device=""/device:GPU:1""](save/Const, save/ShardedFilename_2/shard, save/num_shards)]]
```

This can be reproduced by running the example in examples/learn/multiple_gpu.py"
6131,tf.get_session_tensor awkwardness,"`tf.get_session_tensor()` op constructor is unique in that it needs to be passed output of a session.run call. IE, when you are setting up your graph structure and don't have a relevant handle, you need to do something like this

```
dummy_handle = sess.run(tf.get_session_handle(tf.constant(1, dtype=dt)))
tensor_holder, tensor = tf.get_session_tensor(dummy_handle, dtype=dt)

```
This means that it's incompatible with workflow of ""create graph -> finalize graph -> run ops"" (like when using Supervisor which finalizes graph at the end of `init`). It seems the reason was to figure out which device the tensor would live on. Would it make sense to have it take device from the current graph context instead of a live tensor handle?

@yuanbyu @keveman "
6125,[Windows] Compute 3.0 ,"I'm trying to run tensorflow 0.12.0rc0 on Windows 10 with a Compute 3.0 Device (gtx 660 Ti) but I get the following message:
```
I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\common_runtime\gpu\gpu_device.cc:948] Ignoring visible gpu device (device: 0, name: GeForce GTX 660 Ti, pci bus id: 0000:01:00.0) with Cuda c
ompute capability 3.0. The minimum required Cuda capability is 3.5.
```
The installation manual seems to suggest that it should work with 3.0. (And it works just fine on Linux)
```
TensorFlow GPU support requires having a GPU card with NVidia Compute Capability (>= 3.0). Supported cards include but are not limited to:

NVidia Titan
NVidia Titan X
NVidia K20
NVidia K40
```"
6124,Using Boolean Placeholder for is_training Causes Problems when Loading on iOS,"Currently I am training a model that uses Batch Normalization and Dropout. Because of this I build the model to take a placeholder, `is_training`, that I can feed_dict true or false depending on whether the graph is being used for training or validation.

I take the trained model and export using `tensorflow.contrib.session_bundle.exporter` however when I try to load this graph on iOS, I run into problems (see [SO](http://stackoverflow.com/questions/40855271/no-opkernel-was-registered-to-support-op-switch-with-these-attrs-on-ios)):
```
No OpKernel was registered to support Op 'Switch' with these attrs.
```
I have tried removing the placeholder and injecting the actual value of `False` for `is_training` (see [SO](http://stackoverflow.com/questions/40852729/permanently-inject-constant-into-tensorflow-graph-for-inference) and [GH](https://github.com/tensorflow/tensorflow/issues/5919)), however the model still does not load (see [SO](http://stackoverflow.com/questions/40852729/permanently-inject-constant-into-tensorflow-graph-for-inference) post):
```
Input 0 of node dropout6/cond/dropout/random_uniform/max was passed bool from dropout6/cond/Switch:1 incompatible with expected INVALID.
```

It seems like something is missing to clean up / recompile the graph, stripping out the training part of the graph because the [inject](https://github.com/tensorflow/tensorflow/issues/5919) does not seem like enough. This was one idea to solve the problem: https://github.com/tensorflow/tensorflow/issues/5919.

Right now, I can instead of using placeholder for `is_training` use constants and create the model twice, sharing weights, and then export just the validation subgraph and then load this into iOS, but the downside is that I need to instantiate the model twice into the graph.

EDIT: Would be nice to not have to resort to compiling iOS with switch: https://github.com/tensorflow/tensorflow/issues/2680#issuecomment-237483554 since that node shouldn't even be needed in the final graph. It would be nice to fully remove it from the saved graph."
6120,Error needed when loading a GraphDef created in a newer version of TensorFlow,"There are a lot of issues (e.g. #5628) that are caused by users loading GraphDefs that were created by a newer version of TensorFlow (e.g. 0.12 that introduces SaverV2) into older code bases. This currently results in cryptic errors late in the loading process, but instead we should raise an error (or at least a prominent warning) when a newer GraphDef version than is supported is loaded."
6119,Different prediction result for tf.learn QuickStart?,"Hello,

Today I upgrade tensorflow package and read the [tutorials from the beginning](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/g3doc/tutorials/tflearn/index.md).And find the result of classifier prediction is different, it is `[1, 1]`. I remember that the old version tf run out `[1, 2]`. So what's the problem?

The OS is OSX EI Capitan, and tensoflow is 0.12.0-rc0

``` 
$ `python -c ""import tensorflow; print(tensorflow.__version__)""`
-bash: 0.12.0-rc0: command not found
```

If I turn on the INFO log level, the log lists below:
```
$ python iris_classifier.py
WARNING:tensorflow:From /Library/Python/2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/dnn.py:315 in fit.: calling fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.
Instructions for updating:
Estimator is decoupled from Scikit Learn interface by moving into
separate class SKCompat. Arguments x, y and batch_size are only
available in the SKCompat class, Estimator will only accept input_fn.
Example conversion:
  est = Estimator(...) -> est = SKCompat(Estimator(...))
WARNING:tensorflow:From /Library/Python/2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/dnn.py:315 in fit.: calling fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with y is deprecated and will be removed after 2016-12-01.
Instructions for updating:
Estimator is decoupled from Scikit Learn interface by moving into
separate class SKCompat. Arguments x, y and batch_size are only
available in the SKCompat class, Estimator will only accept input_fn.
Example conversion:
  est = Estimator(...) -> est = SKCompat(Estimator(...))
WARNING:tensorflow:From /Library/Python/2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/dnn.py:315 in fit.: calling fit (from tensorflow.contrib.learn.python.learn.estimators.estimator) with batch_size is deprecated and will be removed after 2016-12-01.
Instructions for updating:
Estimator is decoupled from Scikit Learn interface by moving into
separate class SKCompat. Arguments x, y and batch_size are only
available in the SKCompat class, Estimator will only accept input_fn.
Example conversion:
  est = Estimator(...) -> est = SKCompat(Estimator(...))
WARNING:tensorflow:*******************************************************
WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.
WARNING:tensorflow:Consider switching to the more efficient V2 format:
WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`
WARNING:tensorflow:now on by default.
WARNING:tensorflow:*******************************************************
WARNING:tensorflow:*******************************************************
WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.
WARNING:tensorflow:Consider switching to the more efficient V2 format:
WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`
WARNING:tensorflow:now on by default.
WARNING:tensorflow:*******************************************************
WARNING:tensorflow:From /Library/Python/2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/dnn.py:323 in evaluate.: calling evaluate (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.
Instructions for updating:
Estimator is decoupled from Scikit Learn interface by moving into
separate class SKCompat. Arguments x, y and batch_size are only
available in the SKCompat class, Estimator will only accept input_fn.
Example conversion:
  est = Estimator(...) -> est = SKCompat(Estimator(...))
WARNING:tensorflow:From /Library/Python/2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/dnn.py:323 in evaluate.: calling evaluate (from tensorflow.contrib.learn.python.learn.estimators.estimator) with y is deprecated and will be removed after 2016-12-01.
Instructions for updating:
Estimator is decoupled from Scikit Learn interface by moving into
separate class SKCompat. Arguments x, y and batch_size are only
available in the SKCompat class, Estimator will only accept input_fn.
Example conversion:
  est = Estimator(...) -> est = SKCompat(Estimator(...))
WARNING:tensorflow:From /Library/Python/2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/dnn.py:323 in evaluate.: calling evaluate (from tensorflow.contrib.learn.python.learn.estimators.estimator) with batch_size is deprecated and will be removed after 2016-12-01.
Instructions for updating:
Estimator is decoupled from Scikit Learn interface by moving into
separate class SKCompat. Arguments x, y and batch_size are only
available in the SKCompat class, Estimator will only accept input_fn.
Example conversion:
  est = Estimator(...) -> est = SKCompat(Estimator(...))
Accuracy: 0.966667
WARNING:tensorflow:From /Library/Python/2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/dnn.py:348 in predict.: calling predict (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.
Instructions for updating:
Estimator is decoupled from Scikit Learn interface by moving into
separate class SKCompat. Arguments x, y and batch_size are only
available in the SKCompat class, Estimator will only accept input_fn.
Example conversion:
  est = Estimator(...) -> est = SKCompat(Estimator(...))
WARNING:tensorflow:From /Library/Python/2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/dnn.py:348 in predict.: calling predict (from tensorflow.contrib.learn.python.learn.estimators.estimator) with batch_size is deprecated and will be removed after 2016-12-01.
Instructions for updating:
Estimator is decoupled from Scikit Learn interface by moving into
separate class SKCompat. Arguments x, y and batch_size are only
available in the SKCompat class, Estimator will only accept input_fn.
Example conversion:
  est = Estimator(...) -> est = SKCompat(Estimator(...))
WARNING:tensorflow:From /Library/Python/2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/dnn.py:348 in predict.: calling predict (from tensorflow.contrib.learn.python.learn.estimators.estimator) with as_iterable is deprecated and will be removed after 2016-12-01.
Instructions for updating:
Estimator is decoupled from Scikit Learn interface by moving into
separate class SKCompat. Arguments x, y and batch_size are only
available in the SKCompat class, Estimator will only accept input_fn.
Example conversion:
  est = Estimator(...) -> est = SKCompat(Estimator(...))
Predictions: [1, 1]
```
"
6118,Export Model For Serving But Tensor Type Dismatch,"### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?
I am trying to export the model for serving , but it's report type error about *inputs* tensor.
but in the export and predict part , the **inputs** are the same type.

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)
here is a sample code for my exporting
```
            named_graph_signature = {
                'inputs': exporter.generic_signature({
                              'sparse_index': tf.placeholder(tf.int64, name=""feature_index"")
                              'sparse_ids': tf.placeholder(tf.int64,name = ""feature_ids""),
                              'sparse_values':tf.placeholder(tf.int64, name =""feature_values""),
                              'sparse_shape':tf.placeholder(tf.int64, name=""feature_shape"")
                }),
                'outputs': exporter.generic_signature({
                    'prob': inference_softmax
                })}
            model_exporter.init(
                sess.graph.as_graph_def(),
                #default_graph_signature=named_graph_signature,
                named_graph_signatures=named_graph_signature,
                init_op=init_op)
            model_exporter.export(export_path, tf.constant(export_version), sess)
            print('Done exporting!')
```
here is my code for predicting
```
  ins = ""0 142635:1 250810:1 335229:1 375278:1 392970:1 506983:1 554566:1 631968:1 647823:1 658803:1 733446:1 856305:1 868202:1""
  FEATURE_SIZE = 1000000
  tokens = ins.split("" "")
  feature_num = 0
  feature_ids = []
  feature_values = []
  feature_index = []

  for feature in tokens[1:]:
      feature_id, feature_value = feature.split("":"")
      feature_ids.append(int(feature_id))
      feature_values.append(float(feature_value))
      feature_index.append([1, feature_num])
      feature_num += 1

  feature_shape = [1, FEATURE_SIZE]

  sparse_index = tf.contrib.util.make_tensor_proto(numpy.asarray(feature_index), dtype=tf.int64)
  sparse_ids = tf.contrib.util.make_tensor_proto(numpy.asarray(feature_ids), dtype=tf.int64)
  sparse_values = tf.contrib.util.make_tensor_proto(numpy.asarray(feature_values), dtype=tf.float32)
  sparse_shape= tf.contrib.util.make_tensor_proto(numpy.asarray(feature_shape), dtype=tf.int64)

  channel = implementations.insecure_channel(host, port)
  stub = prediction_service_pb2.beta_create_PredictionService_stub(channel)
  request = predict_pb2.PredictRequest()
  request.model_spec.name = model_name
  request.model_spec.version.value = model_version
  print model_name,model_version

  request.inputs['sparse_index'].CopyFrom(sparse_index)
  request.inputs['sparse_ids'].CopyFrom(sparse_ids)
  request.inputs['sparse_values'].CopyFrom(sparse_values)
  request.inputs['sparse_shape'].CopyFrom(sparse_shape)
  # Send request

  result = stub.Predict(request, request_timeout)
```

### Logs or other output that would be helpful
(If logs are large, please upload as attachment or provide link).

```
Traceback (most recent call last):
  File ""run.py"", line 63, in <module>
    main()
  File ""run.py"", line 59, in main
    result = stub.Predict(request, request_timeout)
  File ""/home/serving/.local/lib/python2.7/site-packages/grpc/beta/_client_adaptations.py"", line 305, in __call__
    self._request_serializer, self._response_deserializer)
  File ""/home/serving/.local/lib/python2.7/site-packages/grpc/beta/_client_adaptations.py"", line 203, in _blocking_unary_unary
    raise _abortion_error(rpc_error_call)
grpc.framework.interfaces.face.face.AbortionError: AbortionError(code=StatusCode.INVALID_ARGUMENT, details=""input size does not match signature"")
```"
6117,distributed tensorflow failed to save variable larger than 2G,"  when use distributed tensorflow saver to save larger variables(more than 2G),  it get stuck and won't save successfully.
   tensorflow version: rc0.11
   bazel version: 0.3.
  minimal reproducible example:

file1: test_saver.py
------------------------------------------
```
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import os
import time
from datetime import datetime

import numpy
import tensorflow as tf

import sys

flags = tf.app.flags
FLAGS = flags.FLAGS
tf.app.flags.DEFINE_string('job_name', '', 'One of ""ps"", ""worker""')

def run_training(target, cluster_spec):
  with tf.device(tf.train.replica_device_setter(
        worker_device=""/job:worker/task:%d/%s"" % (0, 'cpu:0'),
        cluster=cluster_spec)):
    with tf.name_scope('test'):
        test_weight1 = tf.get_variable(""test_weight1"", [24500000, 22],  # bigger then 2G
                    initializer=tf.random_normal_initializer())
        test_weight2 = tf.get_variable(""test_weight2"", [24500, 22], # smaller then 2G
                    initializer=tf.random_normal_initializer())

    saver1 = tf.train.Saver([test_weight1 ], write_version=tf.train.SaverDef.V2)
#    saver2 = tf.train.Saver([test_weight2], write_version=tf.train.SaverDef.V2)

    # The op for initializing the variables.
    init_op = tf.group(tf.initialize_all_variables(),
                       tf.initialize_local_variables())
    sv = tf.train.Supervisor(is_chief=True,
                             logdir=""log"",
                             init_op=init_op,
                             summary_op=None,
                             saver=saver1,
#                             saver=saver2,
                             )
    # Get a session.
    sess = sv.prepare_or_wait_for_session(target)

    # Start the queue runners.
    queue_runners = tf.get_collection(tf.GraphKeys.QUEUE_RUNNERS)
    sv.start_queue_runners(sess, queue_runners)

    coord = tf.train.Coordinator()
    threads = tf.train.start_queue_runners(sess=sess, coord=coord)
    step = 1
    print('start to train.')
    sys.stdout.flush()
    while not coord.should_stop():
      w1 = sess.run([test_weight2])
      print('start to save checkpoint, time=%s'%datetime.now())
      sys.stdout.flush()
      checkpoint_path = 'model.ckpt'
      saver1.save(sess, checkpoint_path, global_step=1)    # saver1 get stuck with high cpu, please refer to line 29 and 39
      #saver2.save(sess, checkpoint_path, global_step=1)   # saver2 can save smoothly, please refer to line 30 and 40
      print('after save checkpoint, time=%s'%datetime.now())
      sys.stdout.flush()
      step += 1
    sess.close()

def main(_):
  assert FLAGS.job_name in ['ps', 'worker'], 'job_name must be ps or worker'

  ps_hosts = ['127.0.0.1:3721',]
  worker_hosts = ['127.0.0.1:3722',]
  cluster_spec = tf.train.ClusterSpec({'ps': ps_hosts, 'worker': worker_hosts})
  server = tf.train.Server(
      {'ps': ps_hosts,
       'worker': worker_hosts},
      job_name=FLAGS.job_name,
      task_index=0)   # test for one ps and one worker

  if FLAGS.job_name == 'ps':
    # `ps` jobs wait for incoming connections from the workers.
    server.join()
  else:
    run_training(server.target, cluster_spec)

if __name__ == '__main__':
  tf.app.run()
```
-------------------------------------------------------------------------------------
file2: run_test_saver.sh
-------------------------------------------------------------------------------------
```
#!/bin/bash

CUDA_VISIBLE_DEVICES='' nohup python test_saver.py --job_name=ps > ps.out&

CUDA_VISIBLE_DEVICES='' nohup python test_saver.py --job_name=worker > worker.out &
```
-------------------------------------------------------------------------------------

  
PS:  both saver1 and saver2 can work correctly when use standalone tensorflow(i.e  without parameter server)"
6116,grpc RecvTensor is slow,"I made benchmark tests for distributed setup with loopback network, profiling it and found there is excessive memory copying in the client side of RecvTensor call, which is actually one of the bottleneck.

Here is the code, which mainly stolen from @yaroslavvb [here](https://gist.github.com/yaroslavvb/1124bb02a9fd4abce3d86caf2f950cb2),
```python
  with tf.device(device1):                                                      
    params = tf.get_variable(""params"", shape=[params_size], dtype=dtype,        
                             initializer=tf.zeros_initializer)                  
  with tf.device(device2):                                                      
    # constant node gets placed on device1 because of simple_placer             
    #    update = tf.constant(1, shape=[params_size], dtype=dtype)              
    update = tf.get_variable(""update"", shape=[params_size], dtype=dtype,        
                             initializer=tf.ones_initializer())                 
    add_op = params.assign(update)
```

Here is the profiling result (google perftools) with tensor size 100MB (one fact is, the throughput will degrade with the increasing of tensor size):
* [device1 worker profiling report](https://github.com/tensorflow/tensorflow/files/633183/device1-prof.pdf)
* [device2 worker profiling report](https://github.com/tensorflow/tensorflow/files/633184/device2-prof.pdf)

From the result, the sending side (device2) look fine, but the receiving side (device1, the grpc client) consumes too many CPU cycles for the data transfer.

By the way, I made rough stats for this [memmove](https://github.com/grpc/grpc/blob/d7ff4ff40071d2b486a052183e3e9f9382afb745/src/core/lib/support/slice_buffer.c#L278) call. For one round of 100MB tensor assignment, there are roughly 2GB data moved (actually, including the copy inside memmove, it should be 4GB copied with a naive memmove), which is 20+ times RAM bandwidth amplification (the result is an average of 100 round run, which may not precise but the scale should be ok)."
6115,[Windows] How can we call builtin ops function in Windows like _set_ops.dense_to_dense_set_operation?,"### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?
http://stackoverflow.com/questions/40947669/attributeerror-nonetype-object-has-no-attribute-dense-to-dense-set-operation

Operating System: Windows

Installed version of CUDA and cuDNN: 
 ```
Directory of C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v8.0\lib\x64

12/02/2016  02:50 PM    <DIR>          .
12/02/2016  02:50 PM    <DIR>          ..
09/11/2016  10:26 AM            93,804 cublas.lib
09/11/2016  10:19 AM        62,239,924 cublas_device.lib
09/05/2016  02:51 PM            87,834 cuda.lib
09/05/2016  02:51 PM           681,064 cudadevrt.lib
09/05/2016  02:51 PM            64,550 cudart.lib
09/05/2016  02:51 PM         2,318,456 cudart_static.lib
07/26/2016  11:31 PM            37,452 cudnn.lib
09/05/2016  02:51 PM            17,042 cufft.lib
09/05/2016  02:51 PM            15,838 cufftw.lib
09/05/2016  02:51 PM             8,534 curand.lib
09/05/2016  02:51 PM           115,226 cusolver.lib
09/05/2016  02:51 PM           175,020 cusparse.lib
09/05/2016  02:51 PM             4,746 nppc.lib
09/05/2016  02:51 PM         1,312,172 nppi.lib
09/05/2016  02:51 PM           202,098 nppial.lib
09/05/2016  02:51 PM           102,322 nppicc.lib
09/05/2016  02:51 PM             9,324 nppicom.lib
09/05/2016  02:51 PM           176,272 nppidei.lib
09/05/2016  02:51 PM           244,310 nppif.lib
09/05/2016  02:51 PM            73,428 nppig.lib
09/05/2016  02:51 PM            25,078 nppim.lib
09/05/2016  02:51 PM           441,650 nppist.lib
09/05/2016  02:51 PM             8,416 nppisu.lib
09/05/2016  02:51 PM            55,026 nppitc.lib
09/05/2016  02:51 PM           214,486 npps.lib
09/05/2016  02:51 PM            11,250 nvblas.lib
09/05/2016  02:51 PM             6,814 nvcuvid.lib
09/05/2016  02:51 PM             8,720 nvgraph.lib
09/05/2016  02:51 PM            40,096 nvml.lib
09/05/2016  02:51 PM             3,954 nvrtc.lib
09/05/2016  02:51 PM            23,076 OpenCL.lib
              31 File(s)     68,817,982 bytes
               2 Dir(s)  206,249,398,272 bytes free
```


If installed from binary pip package, provide:

1. A link to the pip package you installed:
https://github.com/tensorflow/tensorflow.git

2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.
```
(tensorflow) C:\Users\e-budur>python -c ""import tensorflow; print(tensorflow.__v
ersion__)""
I c:\tensorflow\tensorflow\stream_executor\dso_loader.cc:128] successfully opene
d CUDA library cublas64_80.dll locally
I c:\tensorflow\tensorflow\stream_executor\dso_loader.cc:128] successfully opene
d CUDA library cudnn64_5.dll locally
I c:\tensorflow\tensorflow\stream_executor\dso_loader.cc:128] successfully opene
d CUDA library cufft64_80.dll locally
I c:\tensorflow\tensorflow\stream_executor\dso_loader.cc:128] successfully opene
d CUDA library nvcuda.dll locally
I c:\tensorflow\tensorflow\stream_executor\dso_loader.cc:128] successfully opene
d CUDA library curand64_80.dll locally
0.12.head
```

If installed from source, provide 

1. The commit hash (`git rev-parse HEAD`)
C:\tensorflow>git rev-parse HEAD
778539ce3cb4a0effabe46e7674c22602cb08dc0

2. The output of `bazel version`
I've used MSBuild.

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)
`true_positives = set_ops.set_intersection(predictions_idx, labels)`

I've run udc_train.py by following the preliminary steps give in the repository page https://github.com/dennybritz/chatbot-retrieval.  As a result of the execution I got the following exception when the application calls the function tf.contrib.metrics.streaming_sparse_recall_at_k in udc_metrics.py

### What other attempted solutions have you tried?
I've rebuilded the source code by following the instruction in the following link hoping that the ops library will be compiled and embedded into the main excutable of tensorflow like '_pywrap_tensorflow.pyd' but no luck.  I kept receiving the same error after successful compilation and deployment of the latest source code (778539ce3cb4a0effabe46e7674c22602cb08dc0).
https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/cmake/README.md

I've posted the question on Stackoverflow but I got no answer.
http://stackoverflow.com/questions/40947669/attributeerror-nonetype-object-has-no-attribute-dense-to-dense-set-operation


### Logs or other output that would be helpful
I've downloaded the sample project Chatbot Retrieval from the following repository
https://github.com/dennybritz/chatbot-retrieval

I've run udc_train.py by following the preliminary steps give in the repository page above.  As a result of the execution I got the following exception when the application calls the function tf.contrib.metrics.streaming_sparse_recall_at_k

```
Traceback (most recent call last):
  File ""C:/Users/e-budur/PycharmProjects/chatbot-retrieval/udc_train.py"", line 72, in <module>
    tf.app.run()
  File ""C:\Program Files\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow\python\platform\app.py"", line 44, in run
    _sys.exit(main(_sys.argv[:1] + flags_passthrough))
  File ""C:/Users/e-budur/PycharmProjects/chatbot-retrieval/udc_train.py"", line 68, in main
    estimator.fit(input_fn=input_fn_train, steps=None, monitors=[eval_monitor])
  File ""C:\Program Files\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow\python\util\deprecation.py"", line 247, in new_func
    return func(*args, **kwargs)
  File ""C:\Program Files\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow\contrib\learn\python\learn\estimators\estimator.py"", line 364, in fit
    max_steps=max_steps)
  File ""C:\Program Files\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow\contrib\learn\python\learn\estimators\estimator.py"", line 741, in _train_model
    max_steps=max_steps)
  File ""C:\Program Files\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow\contrib\learn\python\learn\graph_actions.py"", line 301, in _monitored_train
    None)
  File ""C:\Program Files\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow\python\training\monitored_session.py"", line 473, in run
    run_metadata=run_metadata)
  File ""C:\Program Files\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow\python\training\monitored_session.py"", line 628, in run
    run_metadata=run_metadata)
  File ""C:\Program Files\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow\python\training\monitored_session.py"", line 595, in run
    return self._sess.run(*args, **kwargs)
  File ""C:\Program Files\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow\python\training\monitored_session.py"", line 737, in run
    run_metadata=run_metadata))
  File ""C:\Program Files\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow\contrib\learn\python\learn\monitors.py"", line 1210, in after_run
    induce_stop = m.step_end(self._last_step, result)
  File ""C:\Program Files\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow\contrib\learn\python\learn\monitors.py"", line 409, in step_end
    return self.every_n_step_end(step, output)
  File ""C:/Users/e-budur/PycharmProjects/chatbot-retrieval/udc_train.py"", line 65, in every_n_step_end
    steps=None)
  File ""C:\Program Files\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow\python\util\deprecation.py"", line 247, in new_func
    return func(*args, **kwargs)
  File ""C:\Program Files\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow\contrib\learn\python\learn\estimators\estimator.py"", line 436, in evaluate
    name=name)
  File ""C:\Program Files\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow\contrib\learn\python\learn\estimators\estimator.py"", line 800, in _evaluate_model
    eval_ops = self._get_eval_ops(features, labels, metrics)
  File ""C:\Program Files\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow\contrib\learn\python\learn\estimators\estimator.py"", line 1111, in _get_eval_ops
    metrics, features, labels, model_fn_ops.predictions))
  File ""C:\Program Files\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow\contrib\learn\python\learn\estimators\estimator.py"", line 280, in _make_metrics_ops
    result[name] = metric(predictions, labels_tensor_or_dict)
  File ""C:\Program Files\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow\contrib\metrics\python\ops\metric_ops.py"", line 1422, in streaming_sparse_recall_at_k
    weights=weights)
  File ""C:\Program Files\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow\contrib\metrics\python\ops\metric_ops.py"", line 2102, in _streaming_sparse_true_positive_at_k
    weights=weights)
  File ""C:\Program Files\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow\contrib\metrics\python\ops\metric_ops.py"", line 2054, in _sparse_true_positive_at_k
    tp = set_ops.set_size(set_ops.set_intersection(predictions_idx, labels))
  File ""C:\Program Files\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow\contrib\metrics\python\ops\set_ops.py"", line 138, in set_intersection
    return _set_operation(a, b, ""intersection"", validate_indices)
  File ""C:\Program Files\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow\contrib\metrics\python\ops\set_ops.py"", line 113, in _set_operation
    indices, values, shape = _set_ops.dense_to_dense_set_operation(
AttributeError: 'NoneType' object has no attribute 'dense_to_dense_set_operation'
```

The main problem turns out to be loader.load_op_library fails to load .so files in NT system.

```
_set_ops = loader.load_op_library(resource_loader.get_path_to_datafile(""_set_ops.so""))

indices, values, shape = _set_ops.dense_to_dense_set_operation(
        a, b, set_operation, validate_indices) #_set_ops turns out to be None
```

```
def load_op_library(path):
  """"""Loads a contrib op library from the given path.

  NOTE(mrry): On Windows, we currently assume that contrib op
  libraries are statically linked into the main TensorFlow Python
  extension DLL.

  Args:
    path: An absolute path to a shared object file.

  Returns:
    A Python module containing the Python wrappers for Ops defined in the
    plugin.
  """"""
  if os.name != 'nt':
    path = resource_loader.get_path_to_datafile(path)
    ret = load_library.load_op_library(path)
    assert ret, 'Could not load %s' % path
    return ret
  else:
    # NOTE(mrry):
    return None
```
The comments belongs to @mrry 

Hence the question is : How can we call builtin ops function in Windows like _set_ops.dense_to_dense_set_operation?

Thanks"
6111,"Flawed memory management: allow_growth=True consumes more memory, causing out-of-memory","To prevent tensorflow (TF) from allocating the totality of graphic memory, I always use the following options when creating sessions:

```
config = tf.ConfigProto()
config.gpu_options.allow_growth = True
sess = tf.Session(config=config)
```

However, doing so causes some experiments to run out of memory while not doing so will not cause memory overflow. For example, when running experiments involving RNN, such as translate.py or ptb_word_lm.py in the sample code, if I specify allow_growth=True, I always encounter the following:

```
Training Epoch 0 ; learning_rate= 0.002 :                                                                                                
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:245] PoolAllocator: After 2631 get requests, put_count=2230 evicted_count=1000 eviction_rate=0.44843 and unsatisfied allocation rate=0.570506                                                                              
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:257] Raising pool_size_limit_ from 100 to 110                                     
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:245] PoolAllocator: After 2631 get requests, put_count=2546 evicted_count=1000 eviction_rate=0.392773 and unsatisfied allocation rate=0.421133                                                                             
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:257] Raising pool_size_limit_ from 256 to 281                                     
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:245] PoolAllocator: After 9384 get requests, put_count=9389 evicted_count=1000 eviction_rate=0.106508 and unsatisfied allocation rate=0.112319                                                                             
I tensorflow/core/common_runtime/gpu/pool_allocator.cc:257] Raising pool_size_limit_ from 655 to 720                                     
E tensorflow/stream_executor/cuda/cuda_driver.cc:965] failed to allocate 2.00G (2147483648 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY  
E tensorflow/stream_executor/cuda/cuda_driver.cc:965] failed to allocate 1.80G (1932735232 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY  
E tensorflow/stream_executor/cuda/cuda_driver.cc:965] failed to allocate 1.62G (1739461632 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY  
E tensorflow/stream_executor/cuda/cuda_driver.cc:965] failed to allocate 1.46G (1565515520 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY  
E tensorflow/stream_executor/cuda/cuda_driver.cc:965] failed to allocate 1.31G (1408964096 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY  
E tensorflow/stream_executor/cuda/cuda_driver.cc:965] failed to allocate 1.18G (1268067840 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY  
```
However, without specifying allow_growth=True, I can run it successfully. Moreover, the OOM occurs only after going through some epoches in the training data, not right from the beginning.

In principle, for an ideal memory manager, whether OOM will occur should not depends on whether memory is pre-allocated in one go or allocated step-by-step dynamically. Thus, Tensorflow's low-level memory management code must be flawed in one way or another.


Below are my system info:
```
Operating System:
Ubuntu 14.04.5 LTS

Installed version of CUDA and cuDNN:
/usr/local/cuda-8.0
cudnn-8.0-linux-x64-v5.1.tgz

It is installed from binary pip package

A link to the pip package you installed:
https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.11.0-cp27-none-linux_x86_64.whl

The output from python -c ""import tensorflow; print(tensorflow.version)""
xuancong@wxc-i2r:~/projects/tf-rnnlm$ python -c ""import tensorflow; print(tensorflow.version)""
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcurand.so locally
0.11.0
```
"
6110,generate signature for SparseTensor failed,"### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?
I can not find any posts about how to export a sparse model in tensorflow. I searched for hours.

### Environment info
Operating System:
centos7 without gpu

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)
export function:
```
# Read TFRecords files for training
filename_queue = tf.train.string_input_producer(
    tf.train.match_filenames_once(FLAGS.train),
    num_epochs=epoch_number)
serialized_example = read_and_decode(filename_queue)
batch_serialized_example = tf.train.shuffle_batch(
    [serialized_example],
    batch_size=batch_size,
    num_threads=thread_number,
    capacity=capacity,
    min_after_dequeue=min_after_dequeue)
features = tf.parse_example(
    batch_serialized_example,
    features={
        ""label"": tf.FixedLenFeature([], tf.float32),
        ""ids"": tf.VarLenFeature(tf.int64),
        ""values"": tf.VarLenFeature(tf.float32),
    })
batch_labels = features[""label""]
batch_ids = features[""ids""]
batch_values = features[""values""]

        print(""Start to run export model"")
        start_time = datetime.datetime.now()

        ckpt = tf.train.get_checkpoint_state(checkpoint_dir)
        if ckpt and ckpt.model_checkpoint_path:
            print(""Use the model {}"".format(ckpt.model_checkpoint_path))
            saver.restore(sess, ckpt.model_checkpoint_path)
            export_version = FLAGS.export_version
            export_path = ""./export/""+job_name
            print('Exporting trained model to %s' % export_path)
            model_exporter = exporter.Exporter(saver)
            model_exporter.init(
                sess.graph.as_graph_def(),
                named_graph_signatures = {
                  'inputs': exporter.generic_signature({'ids': features['ids'], 'values':features['values']}),
                  'outputs': exporter.generic_signature({'labels': features['labels']})},
                init_op=init_op)
            model_exporter.export(export_path, tf.constant(export_version), sess)
            print('Done exporting!')
```

### Logs or other output that would be helpful
(If logs are large, please upload as attachment or provide link).
```
Traceback (most recent call last):
  File ""run.py"", line 343, in <module>
    'inputs': exporter.generic_signature({'ids': features['ids'], 'values':features['values']}),
  File ""/home/serving/anaconda2/lib/python2.7/site-packages/tensorflow/contrib/session_bundle/exporter.py"", line 121, in generic_signature
    signature.generic_signature.map[name].tensor_name = tensor.name
AttributeError: 'SparseTensor' object has no attribute 'name'
```"
6108,[TensorBoard] Charts in TensorBoard in Safari don't display correctly,"macOS Sierra, latest Safari (Version 10.0.1). Works good in Chrome.

Steps to repro:
1. Run https://github.com/openai/universe-starter-agent

2. Observe the following graphs:
<img width=""423"" alt=""screen shot 2016-12-05 at 6 32 12 pm"" src=""https://cloud.githubusercontent.com/assets/823890/20910888/30ec783a-bb19-11e6-8514-5c1027ca068a.png"">

3. Console contains these errors:
<img width=""505"" alt=""screen shot 2016-12-05 at 6 32 58 pm"" src=""https://cloud.githubusercontent.com/assets/823890/20910904/4936486c-bb19-11e6-8032-417677a78d2e.png"">"
6104,Generating NaN when computing gradient,"### Environment info
**Operating System:**
Red Hat Enterprise Linux Server release 6.6
**Tensorflow version:** 
0.10.0rc0

**Installed version of CUDA and cuDNN:** 
/usr/local/cuda/lib64/libcudart.so.7.5.23

I'm running a model with temporal attention strategy (https://arxiv.org/abs/1608.02927). I use `tf.nn.seq2seq.sequence_loss_by_example()` to compute the loss, and use adam gradient (lr:0.001) to minimize loss. The loss is not NaN, but gradients of all weigths became NaN values. If I use plain attention strategy, it won't have this NaN problem.

I even print out all hyperparameters, their values land in a sensible range until their gradients become NaN.

Hope someone can help me fix this issue. Thanks in advance.
"
6101,Feature request - Android example app for Windows tensorflow.,"There is now a support of TensorFlow for Windows. I installed it using the instructions provided as part of Anaconda, and it works. However, I can't seem to find information about developing an application with TensorFlow for Android in Windows, by using Android Studio.

I found the path of TensorFlow installation in Windows,  C:\Program Files\Miniconda2\envs\py35\Lib\site-packages\tensorflow\contrib\android\java, but it is completely empty.

Is there a chance of getting an example app for Windows Android Studio?

I've also asked it on stackeoverflow, but didn't get any answer yet. 
I am asking it here because it looks like the example has not been developed yet.
(http://stackoverflow.com/questions/40978859/creating-simple-android-app-using-android-studio-and-tensorflow/40979627#40979627)"
6100,Error on compiling model using Keras,"### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?
I don't know where to begin looking for this problem. It seems like an internal bug but I am not entirely sure if it is something I did wrong. I am fairly new to tensorflow, please help!

### Environment info
Operating System: Ubuntu 16.04

Installed version of CUDA and cuDNN:
CUDA 8.0, cuDNN 5.1

If installed from binary pip package, provide:

1. A link to the pip package you installed: https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow_gpu-0.12.0rc0-cp27-none-linux_x86_64.whl
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.
0.12.0-rc0

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)
```
import tensorflow as tf
import numpy as np
from keras.models import Sequential
from keras.layers import Dense, Activation, Dropout
from keras.layers.convolutional import Convolution1D
from keras.layers.pooling import MaxPooling1D
from keras.layers.core import Flatten
from keras.engine.topology import Merge
from keras import backend as K
from keras.optimizers import SGD
from keras.objectives import *
from keras.utils.layer_utils import layer_from_config
from keras.regularizers import l1, l2
from keras.callbacks import *
from keras.metrics import *

sgd = SGD(lr=10 ** (-lr), momentum=0.9, decay=0, nesterov=True)

# model1: ConvNet
model = Sequential()
model.add(Convolution1D(128, 6, border_mode='same', input_shape=(256,2)))
model.add(MaxPooling1D())
model.add(Convolution1D(64, 6, border_mode='same'))
model.add(MaxPooling1D())
model.add(Convolution1D(32, 6, border_mode='same'))
model.add(MaxPooling1D())
model.add(Convolution1D(16, 6, border_mode='same'))
model.add(MaxPooling1D())
model.add(Flatten())

# merge model:
model.add(Dense(128, name='d1'))
model.add(Activation('relu'))
model.add(Dense(128, name='d2'))
model.add(Activation('relu'))
model.add(Dense(128, name='d3'))
model.add(Activation('tanh'))
model.add(Dense(3))
model.add(Activation('softmax'))

# My y contains three columns, which can be understood as '-1', '0' and '+1'. I want to maximize the correct labeling of '+1' and '-1', don't care how many 0's that I label, and minimize the number of mis-labeling of '+1' or '-1'. 
def func_loss(y_true, y_pred):
	return -K.mean(K.prod(K.cast(K.argmax(y_pred, axis=1), K.floatx()) - 1.0), (K.cast(K.argmax(y_true, axis=1), K.floatx()) - 1.0))

model.compile(loss=func_loss, optimizer='sgd', metrics=[categorical_accuracy])
```

### What other attempted solutions have you tried?
I tried numerous tweaking on the loss function but they all end up with some problems. 

### Logs or other output that would be helpful
(If logs are large, please upload as attachment or provide link).

> Traceback (most recent call last):
>   File ""<stdin>"", line 1, in <module>
>   File ""/usr/local/lib/python2.7/dist-packages/keras/models.py"", line 547, in compile
>     **kwargs)
>   File ""/usr/local/lib/python2.7/dist-packages/keras/engine/training.py"", line 622, in compile
>     sample_weight, mask)
>   File ""/usr/local/lib/python2.7/dist-packages/keras/engine/training.py"", line 324, in weighted
>     score_array = fn(y_true, y_pred)
>   File ""<stdin>"", line 2, in func_loss
>   File ""/usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py"", line 490, in mean
>     axis = _normalize_axis(axis, ndim(x))
>   File ""/usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py"", line 435, in _normalize_axis
>     if axis is not None and axis < 0:
>   File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 547, in __nonzero__
>     raise TypeError(""Using a `tf.Tensor` as a Python `bool` is not allowed. ""
> TypeError: Using a `tf.Tensor` as a Python `bool` is not allowed. Use `if t is not None:` instead of `if t:` to test if a tensor is defined, and use TensorFlow ops such as tf.cond to execute subgraphs conditioned on the value of a tensor.
> "
6097,Using classifiers with scikit-learn ensemble methods,"NOTE: Only file GitHub issues for bugs and feature requests.  All other topics will be closed.

For general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).
To make bugs and feature requests more easy to find and organize, we close issues that are deemed
out of scope for GitHub Issues and point people to StackOverflow.

For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.

### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?: http://stackoverflow.com/questions/35464652/how-to-create-ensemble-in-tensorflow

### Environment info
Operating System: Ubuntu 16.04.1 LTS

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`): Using CPU only version of TensorFlow

If installed from binary pip package, provide:

1. A link to the pip package you installed:
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`: 0.12.0-rc0

If installed from source, provide 

1. The commit hash (`git rev-parse HEAD`)
2. The output of `bazel version`

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)
It would be useful if the TensorFlow Learn classifiers had a `get_params` method so that they could be used with the `VotingClassifier` in `scikit-learn`. Note that XGBoost does currently work well with `VotingClassifier`

```python
from sklearn.svm import SVC
from sklearn import tree
from sklearn.ensemble import RandomForestClassifier
from sklearn import neighbors
from sklearn.ensemble import VotingClassifier

import tensorflow as tf
from tensorflow.contrib import learn

clf_svm = SVC(C=1000, gamma=1)
clf_dt = tree.DecisionTreeClassifier(max_depth=30)
clf_knn = neighbors.KNeighborsClassifier(7, weights=""distance"")
feature_columns = learn.infer_real_valued_columns_from_input(X_train)
clf_dnn = learn.DNNClassifier(feature_columns=feature_columns, hidden_units=[200, 400, 200], n_classes=10)
clf_rf = RandomForestClassifier(n_estimators=10, max_depth=None, min_samples_split=2, random_state=0)

eclf = VotingClassifier(estimators=[('SVM', clf_svm), 
                                    ('DecisionTree', clf_dt), 
                                    ('KNN', clf_knn), 
                                    ('DNN', clf_dnn), 
                                    ('RandomForest', clf_rf),], 
                        voting='hard')

eclf.fit(X_train, y_train)
predicted_labels = eclf.predict(X_test)
```

### What other attempted solutions have you tried?


### Logs or other output that would be helpful
(If logs are large, please upload as attachment or provide link).
```
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
<ipython-input-117-461ecf12b1de> in <module>()
     17                         voting='hard')
     18 
---> 19 eclf.fit(X_train, y_train)
     20 predicted_labels = eclf.predict(X_test)
     21 

/usr/local/lib/python3.5/dist-packages/sklearn/ensemble/voting_classifier.py in fit(self, X, y, sample_weight)
    163                 delayed(_parallel_fit_estimator)(clone(clf), X, transformed_y,
    164                     sample_weight)
--> 165                     for _, clf in self.estimators)
    166 
    167         return self

/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self, iterable)
    756             # was dispatched. In particular this covers the edge
    757             # case of Parallel used with an exhausted iterator.
--> 758             while self.dispatch_one_batch(iterator):
    759                 self._iterating = True
    760             else:

/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/parallel.py in dispatch_one_batch(self, iterator)
    601 
    602         with self._lock:
--> 603             tasks = BatchedCalls(itertools.islice(iterator, batch_size))
    604             if len(tasks) == 0:
    605                 # No more tasks available in the iterator: tell caller to stop.

/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/parallel.py in __init__(self, iterator_slice)
    125 
    126     def __init__(self, iterator_slice):
--> 127         self.items = list(iterator_slice)
    128         self._size = len(self.items)
    129 

/usr/local/lib/python3.5/dist-packages/sklearn/ensemble/voting_classifier.py in <genexpr>(.0)
    163                 delayed(_parallel_fit_estimator)(clone(clf), X, transformed_y,
    164                     sample_weight)
--> 165                     for _, clf in self.estimators)
    166 
    167         return self

/usr/local/lib/python3.5/dist-packages/sklearn/base.py in clone(estimator, safe)
     63                             ""it does not seem to be a scikit-learn estimator ""
     64                             ""as it does not implement a 'get_params' methods.""
---> 65                             % (repr(estimator), type(estimator)))
     66     klass = estimator.__class__
     67     new_object_params = estimator.get_params(deep=False)

TypeError: Cannot clone object '<tensorflow.contrib.learn.python.learn.estimators.dnn.DNNClassifier object at 0x7f1d773f80f0>' (type <class 'tensorflow.contrib.learn.python.learn.estimators.dnn.DNNClassifier'>): it does not seem to be a scikit-learn estimator as it does not implement a 'get_params' methods.
```
"
6096,error download files during run ./configure,"when i run ./configure, there are 2 files can't be downloaded.

http://cdimage.debian.org/mirror/xbmc.org/build-deps/sources/swig-3.0.8.tar.gz

http://cdimage.debian.org/mirror/xbmc.org/build-deps/sources/giflib-5.1.4.tar.gz


============


ERROR: /home/scopeserver/RaidDisk/DeepLearning/mwang/tensorflow/tensorflow/contrib/tfprof/python/tools/tfprof/BUILD:49:1: every rule of type _py_wrap_cc implicitly depends upon the target '@swig//:templates', but this target could not be found because of: no such package '@swig//': Error downloading from **http://cdimage.debian.org/mirror/xbmc.org/build-deps/sources/swig-3.0.8.tar.gz** to /home/scopeserver/.cache/bazel/_bazel_root/4bbf7fc8d0645aa96f0d41866ce2885c/external/swig: Error downloading http://cdimage.debian.org/mirror/xbmc.org/build-deps/sources/swig-3.0.8.tar.gz to /home/scopeserver/.cache/bazel/_bazel_root/4bbf7fc8d0645aa96f0d41866ce2885c/external/swig/swig-3.0.8.tar.gz: Timed out connecting to http://cdimage.debian.org/mirror/xbmc.org/build-deps/sources/swig-3.0.8.tar.gz : connect timed out.

ERROR: /home/scopeserver/RaidDisk/DeepLearning/mwang/tensorflow/tensorflow/core/platform/default/build_config/BUILD:96:1: no such package '@gif_archive//': Error downloading from **http://cdimage.debian.org/mirror/xbmc.org/build-deps/sources/giflib-5.1.4.tar.gz** to /home/scopeserver/.cache/bazel/_bazel_root/4bbf7fc8d0645aa96f0d41866ce2885c/external/gif_archive: Error downloading http://cdimage.debian.org/mirror/xbmc.org/build-deps/sources/giflib-5.1.4.tar.gz to /home/scopeserver/.cache/bazel/_bazel_root/4bbf7fc8d0645aa96f0d41866ce2885c/external/gif_archive/giflib-5.1.4.tar.gz: Timed out connecting to http://cdimage.debian.org/mirror/xbmc.org/build-deps/sources/giflib-5.1.4.tar.gz : connect timed out and referenced by '//tensorflow/core/platform/default/build_config:gif'.
"
6095,Add atan2 trigonometry function,"Tensorflow has a number of built-in trigonometry functions like `atan` but it doesn't have `atan2` yet.

This can be achieved with some custom code as pointed in this comment: https://github.com/tensorflow/tensorflow/issues/3624#issuecomment-242085609.

There's actually a small mistake on the first line, where `np.pi` should not be added. The corrected code is presented below:

```python
def atan2(y, x):
    angle = tf.select(tf.greater(x,0.0), tf.atan(y/x), tf.zeros_like(x))
    angle = tf.select(tf.logical_and(tf.less(x,0.0),  tf.greater_equal(y,0.0)), tf.atan(y/x) + np.pi, angle)
    angle = tf.select(tf.logical_and(tf.less(x,0.0),  tf.less(y,0.0)), tf.atan(y/x) - np.pi, angle)
    angle = tf.select(tf.logical_and(tf.equal(x,0.0), tf.greater(y,0.0)), 0.5*np.pi * tf.ones_like(x), angle)
    angle = tf.select(tf.logical_and(tf.equal(x,0.0), tf.less(y,0.0)), -0.5*np.pi * tf.ones_like(x), angle)
    angle = tf.select(tf.logical_and(tf.equal(x,0.0), tf.equal(y,0.0)), np.nan * tf.zeros_like(x), angle)
    return angle
```

While this custom code performs reasonably well, it'd be both faster and more convenient if Tensorflow had it built-in like the other existing functions."
6094,build fail: ERROR: no such target '@local_config_cuda//crosstool:toolchain',"I just sync the latest code and meet build error. in fact i already assign to use GPU support during run **./configure**. but it can't find.

I am using Ubuntu 16.04, cuda 8.0 and bazel 0.32

git rev-parse HEAD

dca48e8b5adbb328c09a43b7d19300b52680d7ac


======

ERROR: /home/scopeserver/.cache/bazel/_bazel_scopeserver/b562266fb6ddaaff7ca2ee0b31316144/external/local_config_cuda/crosstool/BUILD:4:1: Traceback (most recent call last):
	File ""/home/scopeserver/.cache/bazel/_bazel_scopeserver/b562266fb6ddaaff7ca2ee0b31316144/external/local_config_cuda/crosstool/BUILD"", line 4
		error_gpu_disabled()
	File ""/home/scopeserver/.cache/bazel/_bazel_scopeserver/b562266fb6ddaaff7ca2ee0b31316144/external/local_config_cuda/crosstool/error_gpu_disabled.bzl"", line 3, in error_gpu_disabled
		fail(""ERROR: Building with --config=c..."")
ERROR: **Building with --config=cuda but TensorFlow is not configured to build with GPU support. Please re-run ./configure and enter 'Y' at the prompt to build with GPU support.**
ERROR: **no such target '@local_config_cuda//crosstool:toolchain': target 'toolchain' not declared in package 'crosstool' defined by /home/scopeserver/.cache/bazel/_bazel_scopeserver/b562266fb6ddaaff7ca2ee0b31316144/external/local_config_cuda/crosstool/BUILD.**
INFO: Elapsed time: 0.352s


"
6091,Use model after trained in tensorflow (save/load graph),"**What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?**
http://stackoverflow.com/questions/33759623/tensorflow-how-to-restore-a-previously-saved-model-python

 **Environment info
Operating System:** Ubuntu 14.04

**Installed version of tensorflow**: '0.11.0'

I already asked my question on stackoverflow: http://stackoverflow.com/questions/40956040/how-to-use-model-after-trained-in-tensorflow-save-load-graph
But I can't find any helps so I have to ask here.

I want to save a graph after training or save something else which tensorflow can load it. 
I found there are two ways : 

- using MetaGraph : https://www.tensorflow.org/versions/r0.11/how_tos/meta_graph/index.html
- save Graph like the example **image_retraining** : https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/image_retraining

**## I/ Using Exporting and Importing a MetaGraph**

My [Save.py](https://github.com/shaolinkhoa/tensorflow/blob/master/05_convolutional_net.py) file:
```
X = tf.placeholder(""float"", [None, 28, 28, 1], name='X')
Y = tf.placeholder(""float"", [None, 10], name='Y')

tf.train.Saver()
with tf.Session() as sess:
     ...run something ...
     final_tensor = tf.nn.softmax(py_x, name='final_result')
     tf.add_to_collection(""final_tensor"", final_tensor)

     predict_op = tf.argmax(py_x, 1)
     tf.add_to_collection(""predict_op"", predict_op)

saver.save(sess, 'my_project') 
```

Then I run [load.py](https://github.com/shaolinkhoa/tensorflow/blob/master/load_05_convolution.py):
```
with tf.Session() as sess:
   new_saver = tf.train.import_meta_graph('my_project.meta')
   new_saver.restore(sess, 'my_project')
   predict_op = tf.get_collection(""predict_op"")[0]
   for i in range(2):
        test_indices = np.arange(len(teX)) # Get A Test Batch
        np.random.shuffle(test_indices)
        test_indices = test_indices[0:test_size]

        print(i, np.mean(np.argmax(teY[test_indices], axis=1) ==
                         sess.run(predict_op, feed_dict={""X:0"": teX[test_indices],
                                                         ""p_keep_conv:0"": 1.0,
                                                         ""p_keep_hidden:0"": 1.0})))


```

but it return error

```
Traceback (most recent call last):
  File ""load_05_convolution.py"", line 62, in <module>
    ""p_keep_hidden:0"": 1.0})))
  File ""/home/khoa/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 717, in run
    run_metadata_ptr)
  File ""/home/khoa/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 894, in _run
    % (np_val.shape, subfeed_t.name, str(subfeed_t.get_shape())))
ValueError: Cannot feed value of shape (256, 784) for Tensor u'X:0', which has shape '(?, 28, 28, 1)'

```
I really don't know why?


If I add `final_tensor = tf.get_collection(""final_result"")[0]`

It return another error:

```
Traceback (most recent call last):
  File ""load_05_convolution.py"", line 46, in <module>
    final_tensor = tf.get_collection(""final_result"")[0]
IndexError: list index out of range
```

Is it because tf.add_to_collection only contains only one tensor ?

## **II/ using tf.train.write_graph**

I add this line to the end of the save.py :  `tf.train.write_graph(graph, 'folder', 'train.pb')`

It created file 'train.pb' successfully.

My [load.py](https://github.com/shaolinkhoa/tensorflow/blob/master/load_05_convolution.py):
```
with tf.gfile.FastGFile('folder/train.pb', 'rb') as f:
    graph_def = tf.GraphDef()
    graph_def.ParseFromString(f.read())
    _ = tf.import_graph_def(graph_def, name='')

with tf.Session() as sess:
  predict_op = sess.graph.get_tensor_by_name('predict_op:0')
  for i in range(2):
        test_indices = np.arange(len(teX)) # Get A Test Batch
        np.random.shuffle(test_indices)
        test_indices = test_indices[0:test_size]

        print(i, np.mean(np.argmax(teY[test_indices], axis=1) ==
                         sess.run(predict_op, feed_dict={""X:0"": teX[test_indices],
                                                         ""p_keep_conv:0"": 1.0,
                                                         ""p_keep_hidden:0"": 1.0})))

```
Then it return error:

```
Traceback (most recent call last):
  File ""load_05_convolution.py"", line 22, in <module>
    graph_def.ParseFromString(f.read())
  File ""/home/khoa/tensorflow/lib/python2.7/site-packages/google/protobuf/message.py"", line 185, in ParseFromString
    self.MergeFromString(serialized)
  File ""/home/khoa/tensorflow/lib/python2.7/site-packages/google/protobuf/internal/python_message.py"", line 1085, in MergeFromString
    raise message_mod.DecodeError('Unexpected end-group tag.')
google.protobuf.message.DecodeError: Unexpected end-group tag.
```

would you mind sharing the standard way, code or tutorial to save/load model ? I'm really confused."
6088,Strided slice op CHECK failure,"Two reports of a `CHECK` failure in the strided slice op have surfaced on Stack Overflow:

* [Tensorflow print value of a tensor](http://stackoverflow.com/q/40979001/3574081)
* [Tensorflow evaluate: Aborted (core dumped)](http://stackoverflow.com/q/40963017/3574081)

In both cases, the error message is:

```
F tensorflow/core/kernels/strided_slice_op.cc:316] Check failed: tmp.CopyFrom(input.Slice(begin[0], end[0]), final_shape) 
Aborted (core dumped)
```

...which appears to match the `CHECK` [here](https://github.com/tensorflow/tensorflow/blob/d9c173fc7adf9443d58310dd08a84b9eb89d4c8f/tensorflow/core/kernels/strided_slice_op.cc#L90).

It looks like both questions might be using the same model code, so I'll ask the questioner to post additional details if possible."
6087,control_dependencies throw Frame error when used in while_loop,"Hello,

### Problem description
I need to put InceptionV3 in a while loop to save both GPU and CPU memory usage since I am handling videos, each contains hundreds of images. The problem is, InceptionV3 uses `control_dependencies` for BatchNorm and TensorFlow throws Frame Error if   `control_dependencies` function is in the `while_loop`. It can run without errors if `control_dependencies` is removed though. 

Below is a minimal snippet that reproduces the error:

```python
sess = tf.Session()

with tf.variable_scope('state'):
    x = tf.get_variable('x', shape=(), 
                             initializer=tf.constant_initializer(1), 
                             dtype=tf.float32)
    update_x = tf.assign(x, x+1)

def iter_fun(i, y):
    # comment the line below, the program will run without any error
    # but I need control_dependencies, or at least some way to replace it...
    with tf.control_dependencies([update_x]): 
        y = y + x
    return (i+1, y)

with tf.variable_scope('iteration'):
    num_iterations = 5   
    initial_i = tf.constant(0, dtype=tf.int32)
    initial_y = tf.constant(0, dtype=tf.float32)
    _, result = tf.while_loop(
        cond=lambda i, *_: i < num_iterations,
        body=iter_fun,
        loop_vars=(initial_i, initial_y))

init_op = tf.global_variables_initializer()
sess.run(init_op)
sess.run(result)  
``` 

The stack trace of the error:
```
Traceback (most recent call last):
  File ""demo.py"", line 28, in <module>
    sess.run(result)
  File ""/workspace/bily/anoaconda2/envs/tensorflow0.12/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 766, in run
    run_metadata_ptr)
  File ""/workspace/bily/anoaconda2/envs/tensorflow0.12/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 964, in _run
    feed_dict_string, options, run_metadata)
  File ""/workspace/bily/anoaconda2/envs/tensorflow0.12/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 1014, in _do_run
    target_list, options, run_metadata)
  File ""/workspace/bily/anoaconda2/envs/tensorflow0.12/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 1034, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InvalidArgumentError: The node 'iteration/while/add' has inputs from different frames. The input 'iteration/while/add/Enter' is in frame 'iteration/while/iteration/while/'. The input 'state/Assign' is in frame ''.
```
### Environments
- CentOS Linux release 7.2.1511
- TensorFlow 0.12 built from source
- Python 2.7.12
- CUDA 7.5 and CUDNN v5.1

### Related issues
1. [This issue in tflearn](https://github.com/tflearn/tflearn/issues/427) seems to be related to my problem but removing `control_denpendencies` isn't a solution for me. 
2. #4478 and #3114 are issues about frame errors but these errors are caused by variables instead of `control_dependencies`.

Any help will be appreciated : )"
6085,Tensorflow SVD inaccurate.  U is not orthogonal.,"NOTE: Only file GitHub issues for bugs and feature requests.  All other topics will be closed.

For general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).
To make bugs and feature requests more easy to find and organize, we close issues that are deemed
out of scope for GitHub Issues and point people to StackOverflow.

For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.

### What related GitHub issues or StackOverflow threads have you found by searching the web for https://github.com/tensorflow/tensorflow/issues/2207

### Environment info
Operating System: Linux Mint 17.3 a.k.a. Ubuntu 14.04.4 LTS, Trusty Tahr

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):
CUDA 7.5
cuDNN 5.5
-rw-r--r-- 1 root root 322936 Aug 15  2015 /usr/local/cuda/lib64/libcudadevrt.a
lrwxrwxrwx 1 root root     16 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.7.5
lrwxrwxrwx 1 root root     19 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so.7.5 -> libcudart.so.7.5.18
-rwxr-xr-x 1 root root 383336 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so.7.5.18
-rw-r--r-- 1 root root 720192 Aug 15  2015 /usr/local/cuda/lib64/libcudart_static.a

If installed from binary pip package, provide:

1. A link to the pip package you installed:
export TF_BINARY_URL=https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.10.0-cp34-cp34m-linux_x86_64.whl
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.
kps3@newton ~ $ python3 -c ""import tensorflow; print(tensorflow.__version__)""
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so locally
0.10.0

If installed from source, provide 

1. The commit hash (`git rev-parse HEAD`)
2. The output of `bazel version`

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)

import pickle
import tensorflow as tf
import numpy as np
#pickle.dump( u_np, open( ""A.txt"", ""wb"" ) )
A = pickle.load( open( ""A.txt"", ""rb"" ) )

u_np, s, V = np.linalg.svd(A, full_matrices=False)
np.dot(np.transpose(u_np), u_np)
#orthogonal in numpy
array([[  1.00000024e+00,  -9.31322575e-09],
       [ -9.31322575e-09,   1.00000036e+00]], dtype=float32)

#analysis of orthogonality
sess = tf.Session()
A = tf.constant(A)
S,U,V = tf.svd(A)
#singular values look ok
sess.run(S)
u_np = sess.run(U)
np.dot(np.transpose(u_np), u_np)
#This should give the identity but does not, indicating
#U is not orthonormal
array([[  9.99998868e-01,  -1.16007868e-07],
       [ -1.16007868e-07,   1.00000167e+00]], dtype=float32)

### What other attempted solutions have you tried?
I need to obtain orthonormal vectors such as output by a QR decomposition.
I have tried getting orthonormal vectors using the Cholesky operation to do a QR (still missing in tensorflow). 
L=Cholesky(A^T*A)
U=A*L^-1
 In this case the matrix inverse operation introduces stochastic variation into a completely deterministic net with identity weights and the results is slightly not orthonormal.  Additionally using the tf.assign operation (to save L^-1) on the results of the L^-1 output from the cholesky actually changes its value.  tf.assign seems to work in other cases.

### Logs or other output that would be helpful
(If logs are large, please upload as attachment or provide link).
The following is the pickled matrix needed for the example

[A.txt](https://github.com/tensorflow/tensorflow/files/630980/A.txt)
"
6084,Confused by the bottle_neck name in retrain tutorial and the inception-v3 model definition,"Inception-v3 model definition link: https://github.com/tensorflow/models/blob/master/inception/inception/slim/inception_model.py

The 'retrain.py' tutorial link: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/image_retraining/retrain.py


In the retrain.py, I find the bottle_neck name of inception3 model is 'pool_3/_reshape:0' (line 95), but in the inception model definition file i can not find definition of 'pool3'.

Also I load the file 'http://download.tensorflow.org/models/image/imagenet/inception-2015-12-05.tgz', and get the bottle_neck tensor by using name 'pool_3:0'. And it is a 4 dimension tensor instead of 2.

What is the real name of bottle_neck tensor? Why can not find the bottle_name in model definition python file?

"
6083,Cuda Compute Capability 3.0 not supported on Windows?,"Running on Windows 8.1, Python 3.5.2, Cuda 8.0

name: GeForce GTX 660M
major: 3 minor: 0 memoryClockRate (GHz) 0.95
pciBusID 0000:01:00.0
Total memory: 2.00GiB
Free memory: 1.64GiB

I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\common_runtime\gpu\gpu_device.cc:948] Ignoring visible gpu device (device: 0, name: GeForce GTX 660M, pci bus id: 0000:01:00.0) with Cuda compute capability 3.0. The minimum required Cuda capability is 3.5."
6082,0.12 Saver.restore broken? Unsuccessful TensorSliceReader constructor: Failed to find any matching files ,"Here is the traceback:
W tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for model_epoch0_128_0.100_[200].ckpt-577569
W tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for model_epoch0_128_0.100_[200].ckpt-577569
W tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for model_epoch0_128_0.100_[200].ckpt-577569
W tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for model_epoch0_128_0.100_[200].ckpt-577569
W tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for model_epoch0_128_0.100_[200].ckpt-577569
W tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for model_epoch0_128_0.100_[200].ckpt-577569
W tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for model_epoch0_128_0.100_[200].ckpt-577569
W tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for model_epoch0_128_0.100_[200].ckpt-577569
W tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for model_epoch0_128_0.100_[200].ckpt-577569
W tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for model_epoch0_128_0.100_[200].ckpt-577569
W tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for model_epoch0_128_0.100_[200].ckpt-577569
W tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for model_epoch0_128_0.100_[200].ckpt-577569
W tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for model_epoch0_128_0.100_[200].ckpt-577569
W tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for model_epoch0_128_0.100_[200].ckpt-577569
W tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for model_epoch0_128_0.100_[200].ckpt-577569
Traceback (most recent call last):
  File ""validate.py"", line 163, in <module>
    tf.app.run()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 43, in run
    sys.exit(main(sys.argv[:1] + flags_passthrough))
  File ""validate.py"", line 155, in main
    model.saver.restore(session,i[:-5])
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1388, in restore
    {self.saver_def.filename_tensor_name: save_path})
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 766, in run
    run_metadata_ptr)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 964, in _run
    feed_dict_string, options, run_metadata)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1014, in _do_run
    target_list, options, run_metadata)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1034, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.NotFoundError: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for model_epoch0_128_0.100_[200].ckpt-577569
	 [[Node: save/RestoreV2_12 = RestoreV2[dtypes=[DT_FLOAT], _device=""/job:localhost/replica:0/task:0/cpu:0""](_recv_save/Const_0, save/RestoreV2_12/tensor_names, save/RestoreV2_12/shape_and_slices)]]
	 [[Node: save/RestoreV2_7/_11 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device_incarnation=1, tensor_name=""edge_4_save/RestoreV2_7"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/gpu:0""]()]]

Caused by op u'save/RestoreV2_12', defined at:
  File ""validate.py"", line 163, in <module>
    tf.app.run()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 43, in run
    sys.exit(main(sys.argv[:1] + flags_passthrough))
  File ""validate.py"", line 148, in main
    model = cnnW2v(opts, session)
  File ""/nobackup/s1/nlip/hejunqing/tf-lstm-char-cnn-gpu/cnn_w2v.py"", line 152, in __init__
    self.build_graph()
  File ""/nobackup/s1/nlip/hejunqing/tf-lstm-char-cnn-gpu/cnn_w2v.py"", line 206, in build_graph
    self.saver = tf.train.Saver()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1000, in __init__
    self.build()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1030, in build
    restore_sequentially=self._restore_sequentially)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 624, in build
    restore_sequentially, reshape)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 361, in _AddRestoreOps
    tensors = self.restore_op(filename_tensor, saveable, preferred_shard)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 200, in restore_op
    [spec.tensor.dtype])[0])
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_io_ops.py"", line 441, in restore_v2
    dtypes=dtypes, name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py"", line 759, in apply_op
    op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 2240, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 1128, in __init__
    self._traceback = _extract_stack()

NotFoundError (see above for traceback): Unsuccessful TensorSliceReader constructor: Failed to find any matching files for model_epoch0_128_0.100_[200].ckpt-577569
	 [[Node: save/RestoreV2_12 = RestoreV2[dtypes=[DT_FLOAT], _device=""/job:localhost/replica:0/task:0/cpu:0""](_recv_save/Const_0, save/RestoreV2_12/tensor_names, save/RestoreV2_12/shape_and_slices)]]
	 [[Node: save/RestoreV2_7/_11 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device_incarnation=1, tensor_name=""edge_4_save/RestoreV2_7"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/gpu:0""]()]

tf version:
0.12.0-rc0 
It is done on Debian Jessie with CUDA-8.0 and cudnn-5.1,using python 2.7

The model is in the directory,
Here are the models in the directory:
model_epoch0_128_0.100_[200].ckpt-577569.meta
model_epoch1_128_0.100_[200].ckpt-1155138.meta
model_epoch2_128_0.100_[200].ckpt-1732707.meta
model_epoch3_128_0.100_[200].ckpt-2310276.meta
model_epoch4_128_0.100_[200].ckpt-2887845.meta
model_epoch0_128_0.100_[200].ckpt-577569.index
model_epoch1_128_0.100_[200].ckpt-1155138.index
model_epoch0_128_0.100_[200].ckpt-577569.data-00000-of-00001
model_epoch1_128_0.100_[200].ckpt-1155138.data-00000-of-00001
model_epoch2_128_0.100_[200].ckpt-1732707.data-00000-of-00001
model_epoch2_128_0.100_[200].ckpt-1732707.index
model_epoch3_128_0.100_[200].ckpt-2310276.data-00000-of-00001
model_epoch3_128_0.100_[200].ckpt-2310276.index
model_epoch4_128_0.100_[200].ckpt-2887845.data-00000-of-00001
model_epoch4_128_0.100_[200].ckpt-2887845.index
model_epoch5_128_0.100_[200].ckpt-3465414.data-00000-of-00001
model_epoch5_128_0.100_[200].ckpt-3465414.index
model_epoch5_128_0.100_[200].ckpt-3465414.meta
model_epoch6_128_0.100_[200].ckpt-4042983.data-00000-of-00001
model_epoch6_128_0.100_[200].ckpt-4042983.index
model_epoch6_128_0.100_[200].ckpt-4042983.meta
model_epoch7_128_0.100_[200].ckpt-4620552.data-00000-of-00001
model_epoch7_128_0.100_[200].ckpt-4620552.index
model_epoch7_128_0.100_[200].ckpt-4620552.meta
model_epoch8_128_0.100_[200].ckpt-5198121.data-00000-of-00001
model_epoch8_128_0.100_[200].ckpt-5198121.index
model_epoch8_128_0.100_[200].ckpt-5198121.meta
model_epoch9_128_0.100_[200].ckpt-5775690.data-00000-of-00001
model_epoch9_128_0.100_[200].ckpt-5775690.index
model_epoch9_128_0.100_[200].ckpt-5775690.meta
model_epoch10_128_0.100_[200].ckpt-6353259.data-00000-of-00001
model_epoch10_128_0.100_[200].ckpt-6353259.index
model_epoch10_128_0.100_[200].ckpt-6353259.meta
model_epoch11_128_0.100_[200].ckpt-6930828.data-00000-of-00001
model_epoch11_128_0.100_[200].ckpt-6930828.index
model_epoch11_128_0.100_[200].ckpt-6930828.meta
model_epoch12_128_0.100_[200].ckpt-7508397.data-00000-of-00001
model_epoch12_128_0.100_[200].ckpt-7508397.index
model_epoch12_128_0.100_[200].ckpt-7508397.meta
model_epoch13_128_0.100_[200].ckpt-8085966.data-00000-of-00001
model_epoch13_128_0.100_[200].ckpt-8085966.index
model_epoch13_128_0.100_[200].ckpt-8085966.meta

"
6081,How to restore training when MonitoredTrainingSession is used,"I ran cifar10_train.py from [master branch](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/models/image/cifar10/cifar10_train.py). My  question is how to restore the checkpoint file in case that `MonitoredTrainingSession` is being used instead of `Session`. I have modified the code like this:
```python
def train():
  """"""Train CIFAR-10 for a number of steps.""""""
  with tf.Graph().as_default():
    global_step = tf.contrib.framework.get_or_create_global_step()

    # Get images and labels for CIFAR-10.
    images, labels = cifar10.distorted_inputs()

    # Build a Graph that computes the logits predictions from the
    # inference model.
    logits = cifar10.inference(images)

    # Calculate loss.
    loss = cifar10.loss(logits, labels)

    # Build a Graph that trains the model with one batch of examples and
    # updates the model parameters.
    train_op = cifar10.train(loss, global_step)

    class _LoggerHook(tf.train.SessionRunHook):
      """"""Logs loss and runtime.""""""

      def begin(self):
        self._step = -1

      def before_run(self, run_context):
        self._step += 1
        self._start_time = time.time()
        return tf.train.SessionRunArgs(loss)  # Asks for loss value.

      def after_run(self, run_context, run_values):
        duration = time.time() - self._start_time
        loss_value = run_values.results
        if self._step % 10 == 0:
          num_examples_per_step = FLAGS.batch_size
          examples_per_sec = num_examples_per_step / duration
          sec_per_batch = float(duration)

          format_str = ('%s: step %d, loss = %.2f (%.1f examples/sec; %.3f '
                        'sec/batch)')
          print (format_str % (datetime.now(), self._step, loss_value,
                               examples_per_sec, sec_per_batch))

    saver = tf.train.Saver()
    with tf.train.MonitoredTrainingSession(checkpoint_dir=FLAGS.train_dir,
                                           hooks=[tf.train.StopAtStepHook(last_step=FLAGS.max_steps),
                                                  tf.train.NanTensorHook(loss),
                                                  _LoggerHook()],
                                           config=tf.ConfigProto(log_device_placement=FLAGS.log_device_placement),
                                           save_checkpoint_secs=600,
                                           save_summaries_steps=100) as mon_sess:
        ckpt = tf.train.get_checkpoint_state(FLAGS.train_dir)
        if ckpt and ckpt.model_checkpoint_path:
            # Restores from checkpoint
            saver.restore(mon_sess, ckpt.model_checkpoint_path)
            # Assuming model_checkpoint_path looks something like:
            #   /my-favorite-path/cifar10_train/model.ckpt-0,
            # extract global_step from it.
            global_step = ckpt.model_checkpoint_path.split('/')[-1].split('-')[-1]
        while not mon_sess.should_stop():
            mon_sess.run(train_op)


def main(argv=None):  # pylint: disable=unused-argument
  # cifar10.maybe_download_and_extract()
  # if tf.gfile.Exists(FLAGS.train_dir):
  #   tf.gfile.DeleteRecursively(FLAGS.train_dir)
  # tf.gfile.MakeDirs(FLAGS.train_dir)
  # train()
  cifar10.maybe_download_and_extract()
  if not tf.gfile.Exists(FLAGS.train_dir):
      tf.gfile.MakeDirs(FLAGS.train_dir)
  train()
```
The training variables seem to be restored, but the step variable still started from 0, how to make the step increases from the restored checkpoint step?
"
6080,TF_Input and TF_Output,"`TF_Input` and `TF_Output` were introduced in 0.12, and the graph and session APIs were updated accordingly. There are the following five functions right now:

```c
extern void TF_AddInput(TF_OperationDescription* desc, TF_Output input);

extern void TF_AddInputList(TF_OperationDescription* desc,
                            const TF_Output* inputs, int num_inputs);

extern void TF_SessionRun(TF_Session* session,
                          // RunOptions
                          const TF_Buffer* run_options,
                          // Input tensors
                          const TF_Output* inputs,
                          TF_Tensor* const* input_values, int ninputs,
                          // Output tensors
                          const TF_Output* outputs, TF_Tensor** output_values,
                          int noutputs,
                          // Target operations
                          const TF_Operation* const* target_opers, int ntargets,
                          // RunMetadata
                          TF_Buffer* run_metadata,
                          // Output status
                          TF_Status*);

extern void TF_SessionPRunSetup(TF_Session*,
                                // Input names
                                const TF_Output* inputs, int ninputs,
                                // Output names
                                const TF_Output* outputs, int noutputs,
                                // Target operations
                                const TF_Operation* const* target_opers,
                                int ntargets,
                                // Output handle
                                const char** handle,
                                // Output status
                                TF_Status*);

extern void TF_SessionPRun(TF_Session*, const char* handle,
                           // Input tensors
                           const TF_Output* inputs,
                           TF_Tensor* const* input_values, int ninputs,
                           // Output tensors
                           const TF_Output* outputs, TF_Tensor** output_values,
                           int noutputs,
                           // Target operations
                           const TF_Operation* const* target_opers,
                           int ntargets,
                           // Output status
                           TF_Status*);
```

Assuming that there are no typos here, I am trying to understand how one should think about the `input` and `inputs` arguments of these functions as their corresponding types involve `TF_Output`, not `TF_Input`. Take `TF_SessionRun`, for instance. It is a bit confusing that both `inputs` and `outputs` are `TF_Output`. It would be great if somebody could explain the reasoning behind this. Thank you.

Regards,
Ivan"
6079,Different Graphs on Tensorboard when running cifar10_train.py from master branch and r0.12 branch,"I got different views of network graphs when running cifar10_train.py from [master branch](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/models/image/cifar10/cifar10_train.py) and [r0.12 bracnch](https://github.com/tensorflow/tensorflow/blob/r0.12/tensorflow/models/image/cifar10/cifar10_train.py).

So running cifar10_train.py from r0.12 gave a complete graph in which each layer like conv1 and conv2 are connected, just like this:

[cifar10_train.py graph from r0.12 branch][1]


But running cifar10_train.py from master gave several graphs where each layer like conv1 and conv2 are not connected, just like this:

[cifar10_train.py graph from master branch][2]


I saw that cifar10_train.py from master branch used tf.train.MonitoredTrainingSession, is this a bug of this class or is this just what it is expected to generate?


  [1]: https://i.stack.imgur.com/dk0zl.png
  [2]: https://i.stack.imgur.com/NdAFs.png"
6076,Session has been closed,"using ubuntu 16.04 tensorflow 0.11

Installed from binary
export TF_BINARY_URL=https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.11.0-cp27-none-linux_x86_64.whl
sudo pip install --upgrade $TF_BINARY_URL


### What other attempted solutions have you tried?
I tried using version 0.12. But getting some other import errors for them

### Logs or other output that would be helpful
![sessionclosed](https://cloud.githubusercontent.com/assets/11742991/20874179/6a0f8006-bad5-11e6-9eb1-20d6c5e6c95a.png)
"
6072,Support to convert CudnnLSTM params to normal Weights and Bias,"
My environment is Tensorflow r0.11, Linux 16.04, CUDA8.0, cuDNN5.1

I am using the CudnnLSTM class  from tensorflow.contrib.cudnn_rnn , the training speed is really fast with about 5~6x speedup. However after training I need to move the model to an embeded system which is not CUDA based. So how can I convert the CudnnLSTM params to normal weights and bias. 

Is this feature still in plan or already have other solutions to this issue ?
"
6071,[Feature request] To add the ability to use own data during the training a RNN network for translation by the translate.py script,"Right now the script [translate.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/models/rnn/translate/translate.py) does not allow to use own data for training. At the moment it works only with the data, that the script downloads from the Internet (en/fr). Also there is not any documentation on the format of the input data that it expects in the input. In order to have the ability to train the model with own data 2 changes need to be made to the script:
* to document the format of the input data;
* enable the ability to pass an own input file path via the script arguments, the file path should be used for training instead of downloading the data from the internet."
6070,tf.contrib.learn.LinearRegressor builds bad model for a data with one feature,"Reproduce steps:

[csv with data](http://%22https//vincentarelbundock.github.io/Rdatasets/csv/car/Davis.csv%22). Data includes weight and height values of some people. Overall learning process is very simple:

```
MAX_STEPS = 2000
# ...
features = [tf.contrib.layers.real_valued_column(feature_name) for feature_name in FEATURES_COL]
# ...
linear_regressor = tf.contrib.learn.LinearRegressor(feature_columns=features)
linear_regressor.fit(input_fn=prepare_input, max_steps=MAX_STEPS)
```

However, the model that is built by the regressor is, unexpectedly, bad. Result could be illustrated with the next picture: 
<img width=""556"" alt=""umbhj"" src=""https://cloud.githubusercontent.com/assets/554101/20871476/1aaa1f42-ba4b-11e6-84cb-3bb5f3544f1a.png"">
Visualization code(just in case):
```
plt.plot(height_and_weight_df_filtered[WEIGHT_COL], 
         linear_regressor.predict(input_fn=prepare_full_input), 
         color='blue',
         linewidth=3)
```
Why I think the model is bad? Here is the same data been given to the LinearRegression class from the scikit-learn:

```
lr_updated = linear_model.LinearRegression()
lr_updated.fit(weight_filtered_reshaped, height_filtered)
```

And the visualization: 

<img width=""548"" alt=""gi1ui"" src=""https://cloud.githubusercontent.com/assets/554101/20871501/5949a3e4-ba4b-11e6-970c-d5afaf002b85.png"">

Increasing amount of steps has no effect. I would assume I'm using regressor from the TensorFlow in a wrong way.

[iPython notebook with the code.](https://storage.googleapis.com/stackoverflow-b0noi/Intro%2Bwith%2BTensorFlow.ipynb)

Env details

1. A link to the pip package you installed:
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.
0.11.0rc0

### What other attempted solutions have you tried?

The issue was opened originally as a question on the [stackoverflow](http://stackoverflow.com/questions/40734394/tf-contrib-learn-linearregressor-builds-unexpectedly-bad-model-for-a-data-with-o)."
6068,RNN Tutorial Code cant find sample data,"Followed the directions here on my mac
https://www.tensorflow.org/versions/master/tutorials/recurrent/index.html#recurrent-neural-networks

```
cd tensorflow/models/rnn/ptb
python ptb_word_lm.py --data_path=/tmp/simple-examples/data/ --model small
```

```
Traceback (most recent call last):
  File ""ptb_word_lm.py"", line 368, in <module>
    tf.app.run()
  File ""/Users/shleifer/flow/kensho-learn/kml/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 43, in run
    sys.exit(main(sys.argv[:1] + flags_passthrough))
  File ""ptb_word_lm.py"", line 315, in main
    raw_data = reader.ptb_raw_data(FLAGS.data_path)
  File ""/Users/shleifer/flow/kensho-learn/kml/lib/python2.7/site-packages/tensorflow/models/rnn/ptb/reader.py"", line 73, in ptb_raw_data
    word_to_id = _build_vocab(train_path)
  File ""/Users/shleifer/flow/kensho-learn/kml/lib/python2.7/site-packages/tensorflow/models/rnn/ptb/reader.py"", line 34, in _build_vocab
    data = _read_words(filename)
  File ""/Users/shleifer/flow/kensho-learn/kml/lib/python2.7/site-packages/tensorflow/models/rnn/ptb/reader.py"", line 30, in _read_words
    return f.read().decode(""utf-8"").replace(""\n"", ""<eos>"").split()
  File ""/Users/shleifer/flow/kensho-learn/kml/lib/python2.7/site-packages/tensorflow/python/lib/io/file_io.py"", line 106, in read
    self._preread_check()
  File ""/Users/shleifer/flow/kensho-learn/kml/lib/python2.7/site-packages/tensorflow/python/lib/io/file_io.py"", line 73, in _preread_check
    compat.as_bytes(self.__name), 1024 * 512, status)
  File ""/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/contextlib.py"", line 24, in __exit__
    self.gen.next()
  File ""/Users/shleifer/flow/kensho-learn/kml/lib/python2.7/site-packages/tensorflow/python/framework/errors_impl.py"", line 469, in raise_exception_on_not_ok_status
    pywrap_tensorflow.TF_GetCode(status))
tensorflow.python.framework.errors_impl.NotFoundError: /tmp/simple-examples/data/ptb.train.txt
```

Versions:

tensorflow==0.12.0rc0



I think I am missing something simple. Where should the data directory be? thanks
"
6067,Improve severly lacking Trainable.fit() documentation,"I'm a beginner, some questions that came to mind after reading it multiple times:

- Give examples of x and y, I never got those to work. It either breaks because they have no ""dtype"" or complains that I should use input_fn instead.
- Are x/y supposed to be tensors?
- When is input_fn called?
- If input_fn returns some kind of ""queue"" how is it used?
- What would you actually expect a ""step"" to do? (Needed to know estimate a good value of ""steps"")
- How many training examples does each step consume/look at?
- Why can't batch_size be specified together with input_fn?
- What does batch_size actually do? What is a batch?
- Do you always want to do training with limited batch size?

Thanks."
6065,Bug: _linear's optional scope argument is ignored,"Here is the relevant code from https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/rnn_cell_impl.py

```
def _linear(args, output_size, bias, bias_start=0.0, scope=None):
  # ...
  scope = vs.get_variable_scope()
  with vs.variable_scope(scope) as outer_scope:
    # ...
```"
6064,AttributeError: module 'tensorflow.contrib.slim' has no attribute 'nets',"### Environment info
Operating System:` Mac os x 10.10`

1. A link to the pip package you installed: `https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-0.12.0rc0-py3-none-any.whl`
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`:  `0.12.0-rc0`

### reproducible example

    import tensorflow as tf
    import tensorflow.contrib.slim as slim
    from tensorflow.examples.tutorials.mnist import input_data
    vgg = tf.contrib.slim.nets.vgg

    mnist = input_data.read_data_sets('MNIST_data', one_hot=True)
    x = tf.placeholder(""float"", shape=[None, 784])
    y_ = tf.placeholder(""float"", shape=[None, 10])
    pred = vgg.vgg16(x)

    cross_entropy = -tf.reduce_sum(y_ * tf.log(pred))



### Error Message:

    Traceback (most recent call last):
    File ""resnet.py"", line 4, in <module>
    vgg = tf.contrib.slim.nets.vgg
    AttributeError: module 'tensorflow.contrib.slim' has no attribute 'nets'
"
6063,AttributeError: 'module' object has no attribute 'deprecated',"### Environment info
Operating System: Ubuntu 14.04.5 LTS

Installed version of CUDA and cuDNN: 
No CUDA, I use CPU-only.

* Pip version: pip 1.5.4
* Python version: 2.7.6
* Operating System: Ubuntu 14.04.5 LTS
* Tensorflow version: tensorflow-0.12.0rc0-cp27-none-linux_x86_64 , CPU-only
### Description:

I was testing the tutorial example of LSTM [here](https://www.tensorflow.org/versions/r0.12/tutorials/recurrent/index.html). 
I followed the instructions to download the code and dataset, and run the program using the command. But the code cannot execute and reports the error message:
`  File ""ptb_word_lm.py"", line 332, in main
    tf.contrib.deprecated.scalar_summary(""Training Loss"", m.cost)`
`AttributeError: 'module' object has no attribute 'deprecated'`
### What I've run:

I just ran the following commands:
`wget http://www.fit.vutbr.cz/~imikolov/rnnlm/simple-examples.tgz`
`tar xvf simple-examples.tgz`
`python ptb_word_lm.py --data_path=simple-examples/data/`

I download the code from the [github repository](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/models/rnn). 
My tensorflow version is the very latest tensorflow-0.12.0rc0-cp27-none-linux_x86_64.
Why can't I run this example?
Thank you all for your kind help!!!

"
6062,Feature Request: Argument of a complex number,"There has been `tf.complex_abs` for absolute value.
I request for something like `tf.complex_arg` which calculate the argument of complex numbers.
Constructor like `tf.complex_polar(abs, arg, name=None)` is also nice. "
6061,Get tensor dimension error when retrain Inception3,"I followed the 'retrain.py' example, but get error.
I print the bottleneck tensor shape, and it is [1, 1, 1, 2048]. It runs into error when execute ""tf.placeholder_with_default(
        bottleneck_tensor, shape=[None, BOTTLENECK_TENSOR_SIZE],
        name='BottleneckInputPlaceholder')""

It seems that bottleneck_tensor is a tensor with 4 dimension, what does each dimension mean? And Why it is not a 2 dimension tensor?

My code:

    BOTTLENECK_TENSOR_NAME = 'pool_3:0'
    BOTTLENECK_TENSOR_SIZE = 2048
    sess = tf.InteractiveSession()
    graph = create_inception_graph()
    bottleneck_tensor = graph.get_tensor_by_name(ensure_name_has_port(
        BOTTLENECK_TENSOR_NAME))
    print bottleneck_tensor.get_shape()

    bottleneck_input = tf.placeholder_with_default(
        bottleneck_tensor, shape=[None, BOTTLENECK_TENSOR_SIZE],
        name='BottleneckInputPlaceholder')

The error:

> ValueError: Shapes must be equal rank, but are 4 and 2 for 'BottleneckInputPlaceholder' (op: 'PlaceholderWithDefault') with input shapes: [1,1,1,2048].

The retrain.py:
https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/image_retraining/retrain.py"
6059,Learning works on 0.11 but fails on .12rc0 (Titan X Pascal) ,"I have a training experiment which fails to learn using TF 0.12rc0, but works fine if I revert TF version to 0.11 and run on the same machine. Unfortunately there are no errors logged, and the symptom is that original run starts improving after 5 minutes, but the 0.12rc0 graph fails to improve. This is blocking our transition to 0.12. It would take a bit of time to isolate the difference to a specific op, meanwhile, any suggestions of things to try?

NVIDIA-SMI 370.28                 Driver Version: 370.28 
/usr/local/cuda-8.0/lib64/libcublas.so.8.0.27
/usr/local/cuda-8.0/lib64/libcudnn.so.5.1.5
<img width=""506"" alt=""screen shot 2016-12-03 at 3 39 03 pm"" src=""https://cloud.githubusercontent.com/assets/23068/20862957/de5d955a-b96e-11e6-8c7f-fa268465872f.png"">
"
6058,tf.cond() + tf.dynamic_rnn() gives AttributeError: 'NoneType' object has no attribute 'pivot',"### Environment info
Operating System: ubuntu 14.04.5
Installed version of CUDA and cuDNN: cuda7.5 + cuDNNv5
Installed from pip package: python 2.7+0.11.0rc0

### Code
```python
import tensorflow as tf

def linear(input_, output_size, scope, init_bias=0.0):
    shape = input_.get_shape().as_list()
    with tf.variable_scope(scope):
        W = tf.get_variable(""Matrix"", [shape[-1], output_size], tf.float32, tf.random_normal_initializer(stddev=1.0 / math.sqrt(shape[-1])))
    with tf.variable_scope(scope):
        b = tf.get_variable(""bias"", [output_size], initializer=tf.constant_initializer(init_bias))
    return tf.matmul(input_, W) + b

batch_size = 64
hidden_size = 300
vocab_size = 10000

session = tf.Session()
source = tf.placeholder(tf.float32, [batch_size, 10, hidden_size])
src_len = tf.placeholder(tf.int32, [batch_size])
enc_holder = tf.placeholder(tf.float32, [batch_size, hidden_size])
decode_mode = tf.placeholder(tf.bool)
label = tf.placeholder(tf.int32, [batch_size])

def encoder():
    src_cell = tf.nn.rnn_cell.GRUCell(hidden_size)
    src_init = src_cell.zero_state(batch_size, tf.float32)
    src_hiddens, src_final = tf.nn.dynamic_rnn(src_cell, source, initial_state=src_init, sequence_length=src_len, scope=""encoder"")
    return src_final

decode_state = tf.cond(decode_mode, lambda:enc_holder, lambda:encoder())
outputs = linear(decode_state, vocab_size, ""output"")
loss = tf.nn.sparse_softmax_cross_entropy_with_logits(outputs, label)
optimizer = tf.train.AdamOptimizer().minimize(loss)
```

## Error Message:
```
Traceback (most recent call last):
  File ""issue.py"", line 33, in <module>
    optimizer = tf.train.AdamOptimizer().minimize(loss)
  File ""~/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/optimizer.py"", line 196, in minimize
    grad_loss=grad_loss)
  File ""~/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/optimizer.py"", line 253, in compute_gradients
    colocate_gradients_with_ops=colocate_gradients_with_ops)
  File ""~/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/gradients.py"", line 469, in gradients
    in_grads = _AsList(grad_fn(op, *out_grads))
  File ""~/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/control_flow_grad.py"", line 91, in _MergeGrad
    return control_flow_ops._SwitchRefOrTensor(grad, grad_ctxt.pivot)
AttributeError: 'NoneType' object has no attribute 'pivot'
```
## Note
If I change the line 
```python
decode_state = tf.cond(decode_mode, lambda:enc_holder, lambda:encoder())
```
to
```python
decode_state = tf.cond(decode_mode, lambda:enc_holder, lambda:enc_holder)
```
or
```python
decode_state = encoder()
```
No error thrown. So I guess there must be something wrong when tf.cond() + tf.dynamic_rnn() is combined. "
6057,Install error on Ubuntu 16.04 with Cuda 8.,"I am trying to install tensorflow 0.12.  I am running Ubuntu 16.04 with a GTX 1080.  I get the following error.

./configure 
~/Desktop/tensorflow-r0.12 ~/Desktop/tensorflow-r0.12
Please specify the location of python. [Default is /usr/bin/python]: /usr/bin/python3
Do you wish to build TensorFlow with Google Cloud Platform support? [y/N] n
No Google Cloud Platform support will be enabled for TensorFlow
Do you wish to build TensorFlow with Hadoop File System support? [y/N] n
No Hadoop File System support will be enabled for TensorFlow
Found possible Python library paths:
  /usr/local/lib/python3.5/dist-packages
  /usr/lib/python3/dist-packages
Please input the desired Python library path to use.  Default is [/usr/local/lib/python3.5/dist-packages]

Using python library path: /usr/local/lib/python3.5/dist-packages
Do you wish to build TensorFlow with OpenCL support? [y/N] n
No OpenCL support will be enabled for TensorFlow
Do you wish to build TensorFlow with GPU support? [y/N] y
GPU support will be enabled for TensorFlow
Please specify which gcc should be used by nvcc as the host compiler. [Default is /usr/bin/gcc]: 
Please specify the Cuda SDK version you want to use, e.g. 7.0. [Leave empty to use system default]: 8.0
Please specify the location where CUDA 8.0 toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: 
Please specify the Cudnn version you want to use. [Leave empty to use system default]: 8.0
Please specify the location where cuDNN 8.0 library is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: 
Invalid path to cuDNN  toolkit. Neither of the following two files can be found:
/usr/local/cuda-8.0/lib64/libcudnn.so.8.0
/usr/local/cuda-8.0/libcudnn.so.8.0
/usr/local/cuda/lib64/libcudnn.so.8.0
Please specify the Cudnn version you want to use. [Leave empty to use system default]: 5
Please specify the location where cuDNN 5 library is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: 
Please specify a list of comma-separated Cuda compute capabilities you want to build with.
You can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.
Please note that each additional compute capability significantly increases your build time and binary size.
[Default is: ""3.5,5.2""]: 6.1
.
INFO: Starting clean (this may take a while). Consider using --expunge_async if the clean takes more than several minutes.
.
ERROR: com.google.devtools.build.lib.packages.BuildFileContainsErrorsException: error loading package '': Encountered error while reading extension file 'cuda/build_defs.bzl': no such package '@local_config_cuda//cuda': Traceback (most recent call last):
	File ""/home/chase/Desktop/tensorflow-r0.12/third_party/gpus/cuda_configure.bzl"", line 517
		_create_cuda_repository(repository_ctx)
	File ""/home/chase/Desktop/tensorflow-r0.12/third_party/gpus/cuda_configure.bzl"", line 432, in _create_cuda_repository
		_cuda_toolkit_path(repository_ctx, cuda_version)
	File ""/home/chase/Desktop/tensorflow-r0.12/third_party/gpus/cuda_configure.bzl"", line 148, in _cuda_toolkit_path
		str(repository_ctx.path(cuda_toolkit...)
	File ""/home/chase/Desktop/tensorflow-r0.12/third_party/gpus/cuda_configure.bzl"", line 148, in str
		repository_ctx.path(cuda_toolkit_path).realpath
Object of type 'path' has no field ""realpath""."
6056,"accuracy.eval on MNIST, extremely slow on Win7, P3.5 CPU only","Hi I tested the MNIST tutorial on Win7, Python3.5, CPU only. Icore5.
Tested with Geany+CMD console, and Idle+Python shell.

I found that everything runs fine, but the accuracy.eval routine takes more than 20min to run on the MNIST test data. Normally that is done within less than a minute (Ubuntu).  As soon as the evaluation starts, I am not able to use any other programs. Looks like the CPU is completely blocked by calculations from the eval routine. Any idea how to optimize??

print(""test accuracy %g""%accuracy.eval(feed_dict={
    x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0}))"
6055,Tensorflow 0.12 failed to install on Window 10,"I have installed python3.5.2+cuda8.0+cudnn5.1 on my computer with Windows 10(64-bits)+ GTX960M.Also excute the command line as following:
 
pip install --upgrade https://storage.googleapis.com/tensorflow/windows/gpu/tensorflow_gpu-0.12.0rc0-cp35-cp35m-win_amd64.whl

while when i get into python and input:    import tensorflow as tf , it shows errors:
![1](https://cloud.githubusercontent.com/assets/11583292/20858023/bc4712d2-b975-11e6-818f-b43b04c4f4ff.png)
![2](https://cloud.githubusercontent.com/assets/11583292/20858024/be9e4c8a-b975-11e6-8a3a-a590daab3afa.png)


Then i install the bazel but it is useless,what should i do?

"
6054,Do the ksize and strides value of tf.nn.max_pool() support tf.Tensor ?,"Here is the problem:
I would like to train a network with two different shapes of input tensor. Each epoch chooses one type. Here I write a small code:

```
import tensorflow as tf
import numpy as np


with tf.Session() as sess:

    imgs1 = tf.placeholder(tf.float32, [4, 224, 224, 3], name = 'input_imgs1')
    imgs2 = tf.placeholder(tf.float32, [4, 180, 180, 3], name = 'input_imgs2')
    epoch_num_tf = tf.placeholder(tf.int32, [], name = 'input_epoch_num')

    imgs = tf.cond(tf.equal(tf.mod(epoch_num_tf, 2), 0), 
                lambda: tf.Print(imgs2, [imgs2.get_shape()], message='(even number) input epoch number is '),
                lambda: tf.Print(imgs1, [imgs1.get_shape()], message='(odd number) input epoch number is'))


    print(imgs.get_shape())


    for epoch in range(10):
        epoch_num = np.array(epoch).astype(np.int32)
        imgs1_input = np.ones([4, 224, 224, 3], dtype = np.float32)
        imgs2_input = np.ones([4, 180, 180, 3], dtype = np.float32)

        output = sess.run(imgs, feed_dict = {epoch_num_tf: epoch_num,
                                          imgs1: imgs1_input,
                                          imgs2: imgs2_input})
```
When I execute it, the output of `imgs.get_shape()` is `(4, ?, ?, 3)` i.e. `imgs.get_shape()[1]=None, imgs.get_shape()[2]=None`.

But I will use the value of the output of `imgs.get_shape()` to define the kernel (`ksize`) and strides size (`strides`) of the `tf.nn.max_pool()` e.g. `ksize=[1,imgs.get_shape()[1]/6, imgs.get_shape()[2]/6, 1]` in the future code. I think ksize and strides cannot support `tf.Tensor` value.

How to solve this problem?

I also asked in the [stackoverflow](http://stackoverflow.com/questions/40932002/tensorflow-how-to-set-the-shape-of-tensor-with-different-conditional-statements).



"
6048,CUDA_ERROR_OUT_OF_MEMORY (Memory Available),"Tensorflow is failing like so - very odd since I have memory available and it sees that. This runs fine in CPU only.

Ubuntu 16.04, Cuda 8.0, CUDNN 5.1 for 8.0, Nvidia 367.57 driver, tensorflow_gpu-0.12.0rc0-cp27-none-linux_x86_64.whl. The rest you can see in the log. I have also tried with CUDNN 5.0 with the same result. Cuda 7.5 works for me but is very slow.

**Log:**
```
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcurand.so locally
Exceptions: 0
1403
1403
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties: 
name: GeForce GTX 660
major: 3 minor: 0 memoryClockRate (GHz) 1.0975
pciBusID 0000:02:00.0
Total memory: 1.99GiB
Free memory: 1.43GiB
W tensorflow/stream_executor/cuda/cuda_driver.cc:590] creating context when one is currently active; existing: 0x2c47900
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 1 with properties: 
name: GeForce GTX 660
major: 3 minor: 0 memoryClockRate (GHz) 1.0975
pciBusID 0000:01:00.0
Total memory: 1.99GiB
Free memory: 1.41GiB
I tensorflow/core/common_runtime/gpu/gpu_device.cc:777] Peer access not supported between device ordinals 0 and 1
I tensorflow/core/common_runtime/gpu/gpu_device.cc:777] Peer access not supported between device ordinals 1 and 0
I tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0 1 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y N 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 1:   N Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 660, pci bus id: 0000:02:00.0)
I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:1) -> (device: 1, name: GeForce GTX 660, pci bus id: 0000:01:00.0)
E tensorflow/stream_executor/cuda/cuda_driver.cc:1002] failed to allocate 198.83M (208486400 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY
Traceback (most recent call last):
  File ""build.py"", line 84, in <module>
    model = tflearn.DNN(net)
  File ""/usr/local/lib/python2.7/dist-packages/tflearn/models/dnn.py"", line 63, in __init__
    best_val_accuracy=best_val_accuracy)
  File ""/usr/local/lib/python2.7/dist-packages/tflearn/helpers/trainer.py"", line 135, in __init__
    keep_checkpoint_every_n_hours=keep_checkpoint_every_n_hours)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1000, in __init__
    self.build()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1021, in build
    raise ValueError(""No variables to save"")
ValueError: No variables to save
```

**Code:**
```
net = tflearn.input_data(shape=[None, 5])
net = tflearn.fully_connected(net, 64)
net = tflearn.fully_connected(net, 64)
net = tflearn.fully_connected(net, 2, activation='softmax')
net = tflearn.regression(net)

# Training
model = tflearn.DNN(net)
model.fit(X, Y, n_epoch=10000, batch_size=64, show_metric=True)

for x in range(0,50):
    rand = randint(0,len(X))
    print(model.predict([X[rand]]), Y[rand])

model.save(""model.tfl"")
```"
6046,ResourceExhaustedError when save model. Both memory and disk are enough,"Hi,
  I was running tensorflow 0.12.0rc0 on ubuntu 14.04. The training is on CPU only. The crash happened when saver saves the model.

>W tensorflow/core/framework/op_kernel.cc:975] Resource exhausted:/home/code/2016_11_28_90d_strict_win10.emb-354830.data-00000-of-00001
Traceback (most recent call last):
  File ""/home/code/tf_train.py"", line 474, in <module>
    save_model_and_log_step(tf_saver=saver, tf_session=session, global_step=step)
  File ""/home/code/tf_train.py"", line 199, in save_model_and_log_step
    tf_saver.save(tf_session, FLAGS.out_model_path, global_step=global_step)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1323, in save
    {self.saver_def.filename_tensor_name: checkpoint_file})
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 766, in run
    run_metadata_ptr)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 964, in _run
    feed_dict_string, options, run_metadata)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1014, in _do_run
    target_list, options, run_metadata)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"", line 1034, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.ResourceExhaustedError: ~/2016_11_28_90d_strict_win10.emb-354830.data-00000-of-00001
         [[Node: save/SaveV2 = SaveV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=""/job:localhost/replica:0/task:0/cpu:0""](_r$
cv_save/Const_0, save/SaveV2/tensor_names, save/SaveV2/shape_and_slices, embeddings, embeddings/Adagrad, sm_b, sm_b/Adagrad, sm_w_t, sm_w_t/Adagrad)]]
>Caused by op u'save/SaveV2', defined at:
  File ""/home/code/train.py"", line 430, in <module>
    saver = tf.train.Saver(max_to_keep=FLAGS.max_to_keep)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1000, in __init__
    self.build()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1030, in build
    restore_sequentially=self._restore_sequentially)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 622, in build
    save_tensor = self._AddSaveOps(filename_tensor, saveables)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 229, in _AddSaveOps
    save = self.save_op(filename_tensor, saveables)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 172, in save_op
    tensors)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_io_ops.py"", line 552, in save_v2
    tensors=tensors, name=name)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py"", line 759, in apply_op
    op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 2240, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py"", line 1128, in __init__
    self._traceback = _extract_stack()
>ResourceExhaustedError (see above for traceback): ~/2016_11_28_90d_strict_win10.emb-354830.data-00000-of-00001
         [[Node: save/SaveV2 = SaveV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=""/job:localhost/replica:0/task:0/cpu:0""](_re
cv_save/Const_0, save/SaveV2/tensor_names, save/SaveV2/shape_and_slices, embeddings, embeddings/Adagrad, sm_b, sm_b/Adagrad, sm_w_t, sm_w_t/Adagrad)]]

No OOM or OOD happened on the machine. I remember this was a bug in 0.9.0 when saving a large tensor it has tensor size too large (>2G) problem because of a proto field is defined as int32. I am not sure if it's related?

"
6045,Not able to use tensorflow::mutex (../nptl/pthread_mutex_lock.c: No such file or directory),"Hi All,

I am trying to add a self-defined class under the core/common_runtime/ directory to log the information of each step([https://github.com/laosiaudi/tensorflow/blob/test/tensorflow/core/common_runtime/graph_logger.cc]) and try to use the tensorflow::mutex as step_stats_collector does, but when I run the example/tutorials/mnist/mnist_with_summaries.py, it throws out a segmentation fault. After inspecting via gdb, it reports the error **""../nptl/pthread_mutex_lock.c: No such file or directory.""**.

Could you please provide some advice of how to use tensorflow::mutex correctly or how to fix such errors? Should I modify some BUILD files? I have been stuck in this for a while.

Thanks!

Information about the configuration:
Operating system: Ubuntu14.04
bazel version:  
-- Build label:0.4.1
-- Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar

Installed from source and no CUDA supported"
6039,Precision of reduce_sum operation,"There seems to be a numerical precision problem with the reduce_sum operation, see the example provided below. Even though everything is set to float32 as datatype tensorflow produces a much more imprecise result than numpy (whose result is numerically exact).

Is this intended? It seems strange that tensorflow makes such serious numerical errors. Am I doing something wrong?

### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?

nothing there to my knowledge

### Environment info
Operating System: Mac OSX 10.12.1
Tensorflow 0.11.0 CPU
https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-0.11.0-py2-none-any.whl

could be reproduced in docker-container `tensorflow/tensorflow:0.12.0-rc0` in a virtualbox linux vm

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)

```python
import tensorflow as tf
import numpy as np

data = tf.constant(1.23456, shape=[250,250], dtype=tf.float32)
sum = tf.reduce_sum(data)
sess = tf.Session()
sess.run(sum) #77151.477

data2 = np.full([250, 250], np.float32(1.23456), dtype=np.float32)
np.sum(data2) #77160
```
https://gist.github.com/flash1293/84c2719dd646c0314ec0f4ea05df117a

### What other attempted solutions have you tried?

-

### Logs or other output that would be helpful

-
"
6037,Cannot get the values of tf.contrib.learn.DNNRegressor.predict() in boston.py,"I am following the tutorials on the tensorflow's official website. And when I executed boston.py, I cannot get the prediction values. But when I executed iris.py, I can get the prediction values. The only difference I found between these two files is that boston.py uses DNNRegressor, but iris.py uses DNNClassifier. I am using **0.12 tensorflow, ubuntu 16.04, CUDA 8.0, cuDNN 5.1.5**, my gpu is **TITAN X (Pascal)**.
Here is the ending output of boston.py:
```bash
INFO:tensorflow:Summary name dnn/hiddenlayer_0:fraction_of_zero_values is illegal; using dnn/hiddenlayer_0_fraction_of_zero_values instead.
INFO:tensorflow:Summary name dnn/hiddenlayer_0:activation is illegal; using dnn/hiddenlayer_0_activation instead.
INFO:tensorflow:Summary name dnn/hiddenlayer_1:fraction_of_zero_values is illegal; using dnn/hiddenlayer_1_fraction_of_zero_values instead.
INFO:tensorflow:Summary name dnn/hiddenlayer_1:activation is illegal; using dnn/hiddenlayer_1_activation instead.
INFO:tensorflow:Summary name logits:fraction_of_zero_values is illegal; using logits_fraction_of_zero_values instead.
INFO:tensorflow:Summary name logits:activation is illegal; using logits_activation instead.
Predictions: <generator object _as_iterable at 0x7ff9f406db90>
```
"
6036,File object not being closed properly in 6_lstm.ipynb,"The [**6_lstm.ipynb**](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/udacity/6_lstm.ipynb) file contains the following code: 

```python
def read_data(filename):
  f = zipfile.ZipFile(filename)
  for name in f.namelist():
    return tf.compat.as_str(f.read(name))
  f.close()
```

This code has the following issues: 

- The file object `f` does not get to close properly, since the function is 
  exited before the `f.close()` method ever gets to be called. 
- The `for` loop is uneccesary, since there is only one item in the zip file, 
  *and* since the `return` operator forces the loop to end on the first 
  loop anyway. 
  
I propose the following code instead: 

```python
def read_data(filename):
  with zipfile.ZipFile(filename) as f:
    name = f.namelist()[0]
    data = tf.compat.as_str(f.read(name))
  return data
```

This code fixes the issues in the following ways: 

- The `with` statement will handle the file `f` being closed automatically, even 
  if there is an unexpected early termination. 
- Since there is actually only one item in the zip file, then we can just get 
  the zeroeth element in `f.namelist()`

I will create a pull request with this suggested code shortly. "
6035,Error message for running tf.nn.max_pool_with_argmax() on CPU,"Running `tf.nn.max_pool_with_argmax()` on CPU gives a very obscure error:

`tensorflow.python.framework.errors_impl.InvalidArgumentError: No OpKernel was registered to support Op 'MaxPoolWithArgmax' with these attrs.  Registered devices: [CPU], Registered kernels:
`  <no registered kernels>

From this line:

https://github.com/tensorflow/tensorflow/blob/bc64f05d4090262025a95438b42a54bfdc5bcc80/tensorflow/core/kernels/maxpooling_op.cc#L672

I think it's useful to mention `tf.nn.max_pool_with_argmax()` is only implemented for GPU instead."
6034,ctc_beam_search_decoder()'s log_probabilities holds invalid values,"### Environment info
Operating System: OS X 10.11.6
TF Version: 0.10.0rc0 (No GPU)

### Example
Ran `log_probabilities` op created from
```python
decoded, log_probabilities = ctc_ops.ctc_beam_search_decoder(logits, \
                                                             seq_length, \
                                                             beam_width=beam_width, \
                                                             top_paths=top_paths, \
                                                             merge_repeated=False)
```
The `decoded` result is as expected. However, the `log_probabilities` contains positive values which can not be log probabilities. For example, with batch size 4 and top_paths=10 the `log_probabilities` printout is as follows
```
[[ 3.85424066 -1.97321272 -1.99056399 -2.18253303 -2.18592954 -2.40727925
  -2.87798476 -2.88267159 -2.94563317 -2.94854331]
 [ 3.85424066 -1.97321272 -1.99056399 -2.18253303 -2.18592954 -2.40727925
  -2.87798476 -2.88267159 -2.94563317 -2.94854331]
 [ 3.85424066 -1.97321272 -1.99056399 -2.18253303 -2.18592954 -2.40727925
  -2.87798476 -2.88267159 -2.94563317 -2.94854331]
 [ 3.85424066 -1.97321272 -1.99056399 -2.18253303 -2.18592954 -2.40727925
  -2.87798476 -2.88267159 -2.94563317 -2.94854331]]
```

### Other attempted solutions
None


### Logs or other output that would be helpful
Link to the entire code in context[[1](https://github.com/mozilla/DeepSpeech/blob/issue8++/DeepSpeech.ipynb)]
"
6033,Tensorflow Random Function Always return 0,"So import tensorflow showing following
```
Python 3.5.2 |Anaconda 4.2.0 (64-bit)| (default, Jul  5 2016, 11:41:13) [MSC v.1900 64 bit (AMD64)]
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import tensorflow as tf
I c:\tensorflow\tensorflow\tensorflow\stream_executor\dso_loader.cc:128] successfully opened CUDA li
l locally
I c:\tensorflow\tensorflow\tensorflow\stream_executor\dso_loader.cc:128] successfully opened CUDA li
locally
I c:\tensorflow\tensorflow\tensorflow\stream_executor\dso_loader.cc:128] successfully opened CUDA li
 locally
I c:\tensorflow\tensorflow\tensorflow\stream_executor\dso_loader.cc:128] successfully opened CUDA li
ally
I c:\tensorflow\tensorflow\tensorflow\stream_executor\dso_loader.cc:128] successfully opened CUDA li
l locally
>>> sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))
I c:\tensorflow\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:885] Found device 0 with
name: GeForce GTX 760
major: 3 minor: 0 memoryClockRate (GHz) 1.15
pciBusID 0000:01:00.0
Total memory: 4.00GiB
Free memory: 3.35GiB
I c:\tensorflow\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:906] DMA: 0
I c:\tensorflow\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:916] 0:   Y
I c:\tensorflow\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:975] Creating TensorFlow
(device: 0, name: GeForce GTX 760, pci bus id: 0000:01:00.0)
E c:\tensorflow\tensorflow\tensorflow\core\common_runtime\gpu\gpu_device.cc:586] Could not identify
calhost/replica:0/task:0/gpu:0, defaulting to 0.  Your kernel may not have been built with NUMA supp
Device mapping:
/job:localhost/replica:0/task:0/gpu:0 -> device: 0, name: GeForce GTX 760, pci bus id: 0000:01:00.0
I c:\tensorflow\tensorflow\tensorflow\core\common_runtime\direct_session.cc:255] Device mapping:
/job:localhost/replica:0/task:0/gpu:0 -> device: 0, name: GeForce GTX 760, pci bus id: 0000:01:00.0
```
And generate random matrix

```
>>> a = tf.random_normal((100,100))
>>> sess.run(a)
random_normal/RandomStandardNormal: (RandomStandardNormal): /job:localhost/replica:0/task:0/gpu:0
I c:\tensorflow\tensorflow\tensorflow\core\common_runtime\simple_placer.cc:827] random_normal/RandomStandardNormal: (Ran
domStandardNormal)/job:localhost/replica:0/task:0/gpu:0
random_normal/mul: (Mul): /job:localhost/replica:0/task:0/gpu:0
I c:\tensorflow\tensorflow\tensorflow\core\common_runtime\simple_placer.cc:827] random_normal/mul: (Mul)/job:localhost/r
eplica:0/task:0/gpu:0
random_normal: (Add): /job:localhost/replica:0/task:0/gpu:0
I c:\tensorflow\tensorflow\tensorflow\core\common_runtime\simple_placer.cc:827] random_normal: (Add)/job:localhost/repli
ca:0/task:0/gpu:0
random_normal/stddev: (Const): /job:localhost/replica:0/task:0/gpu:0
I c:\tensorflow\tensorflow\tensorflow\core\common_runtime\simple_placer.cc:827] random_normal/stddev: (Const)/job:localh
ost/replica:0/task:0/gpu:0
random_normal/mean: (Const): /job:localhost/replica:0/task:0/gpu:0
I c:\tensorflow\tensorflow\tensorflow\core\common_runtime\simple_placer.cc:827] random_normal/mean: (Const)/job:localhos
t/replica:0/task:0/gpu:0
random_normal/shape: (Const): /job:localhost/replica:0/task:0/gpu:0
I c:\tensorflow\tensorflow\tensorflow\core\common_runtime\simple_placer.cc:827] random_normal/shape: (Const)/job:localho
st/replica:0/task:0/gpu:0
array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],
       [ 0.,  0.,  0., ...,  0.,  0.,  0.],
       [ 0.,  0.,  0., ...,  0.,  0.,  0.],
       ...,
       [ 0.,  0.,  0., ...,  0.,  0.,  0.],
       [ 0.,  0.,  0., ...,  0.,  0.,  0.],
       [ 0.,  0.,  0., ...,  0.,  0.,  0.]], dtype=float32)
```

The basic matrix operation still works fine

For general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).
To make bugs and feature requests more easy to find and organize, we close issues that are deemed
out of scope for GitHub Issues and point people to StackOverflow.

For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.

### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?
https://github.com/tensorflow/tensorflow/issues/1734 seems has similar problems
### Environment info
Operating System:
Windows 10
GeForce GTX 760 GPU
Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):
CUDA 8.0
cuDNN 5.1

I follow the CMake instruction build from source (tf 0.12)


### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)


### What other attempted solutions have you tried?


### Logs or other output that would be helpful
(If logs are large, please upload as attachment or provide link).
"
6032,freeze_graph not working in v0.11.0 . giving V2 error,"### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?
https://github.com/tensorflow/tensorflow/issues/5938
https://stackoverflow.com/questions/40616430/load-exported-model-in-tensorflow
https://github.com/tensorflow/tensorflow/issues/5639
https://stackoverflow.com/questions/40616430/load-exported-model-in-tensorflow

### Environment info
Operating System: CentOS (AWS p2.xlarge)

Installed version of CUDA and cuDNN:  cuda 8.0 , cudnn 5.1.5
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):
```
/usr/local/cuda-8.0/lib64/libcudadevrt.a
/usr/local/cuda-8.0/lib64/libcudart.so
/usr/local/cuda-8.0/lib64/libcudart.so.8.0
/usr/local/cuda-8.0/lib64/libcudart.so.8.0.44
/usr/local/cuda-8.0/lib64/libcudart_static.a
/usr/local/cuda-8.0/lib64/libcudnn.so
/usr/local/cuda-8.0/lib64/libcudnn.so.5
/usr/local/cuda-8.0/lib64/libcudnn.so.5.1.5
/usr/local/cuda-8.0/lib64/libcudnn_static.a
```

If installed from binary pip package, provide:

1. A link to the pip package you installed:
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`. 
```
0.11.0
```
If installed from source, provide 

1. The commit hash (`git rev-parse HEAD`)
```
https://github.com/tensorflow/tensorflow/archive/v0.11.0.zip
```
2. The output of `bazel version`
```
Build label: 0.3.2
Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Fri Oct 7 17:25:10 2016 (1475861110)
Build timestamp: 1475861110
Build timestamp as int: 1475861110
```

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)
I trained my convolution network on v0.11.0 and then running freeze_graph on the same tensorflow v0.11.0 . freeze_graph does not work.
```
saving model:
saver = tf.train.Saver(tf.all_variables(), max_to_keep=100)
saver.save(sess, checkpoint_prefix, global_step=current_step)

writing graph:
tf.train.write_graph(sess.graph.as_graph_def(), checkpoint_prefix, ""graph""+str(nn)+"".pb"", as_text=False)

running freeze_graph:
tensorflow-0.11.0/bazel-bin/tensorflow/python/tools/freeze_graph --input_graph=graph4000 --input_checkpoint=runs/1479444509/checkpoints/model-4000 --output_graph=my.pb --output_node_names=output0/predictions0,accuracy0/accuracy0,output0/scores0,output0/Softmax --input_binary=True --clear_devices=True --initializer_nodes=embedding/W

```


### What other attempted solutions have you tried?


### Logs or other output that would be helpful
```
tensorflow-0.11.0/bazel-bin/tensorflow/python/tools/freeze_graph --input_graph=graph4000 --input_checkpoint=runs/1479444509/checkpoints/model-4000 --output_graph=my.pb --output_node_names=output0/predictions0,accuracy0/accuracy0,output0/scores0,output0/Softmax --input_binary=True --clear_devices=True --initializer_nodes=embedding/W
Traceback (most recent call last):
  File ""/data3/tensorflow-0.11.0/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/tools/freeze_graph.py"", line 134, in <module>
    tf.app.run()
  File ""/data3/tensorflow-0.11.0/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/platform/app.py"", line 30, in run
    sys.exit(main(sys.argv[:1] + flags_passthrough))
  File ""/data3/tensorflow-0.11.0/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/tools/freeze_graph.py"", line 131, in main
    FLAGS.output_graph, FLAGS.clear_devices, FLAGS.initializer_nodes)
  File ""/data3/tensorflow-0.11.0/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/tools/freeze_graph.py"", line 103, in freeze_graph
    _ = tf.import_graph_def(input_graph_def, name="""")
  File ""/data3/tensorflow-0.11.0/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/framework/importer.py"", line 258, in import_graph_def
    op_def = op_dict[node.op]
KeyError: u'RestoreV2'
```"
6027,tracing batch normalization: apparently unnecessary gpu-cpu-gpu transfer for gather op.,"I am running:
CUDA 8.0. CUDNN 5.1. tensorflow 0.11. Ubuntu 12.04.

I was experiencing low GPU utilization. As per #1824 I did a trace and found many instances of the following interaction, as shown by the screenshot in chrome:

The op I have highlighted (with arrows going in and out in the screenshot) is a `gather` op. I provide a link to the context in which it is called.
https://github.com/tensorflow/tensorflow/blob/eb56a8af24695bf8258addf28b0c53fbabff72e6/tensorflow/python/ops/nn_impl.py#L472

The call stack (at graph construction) time is:
`tf.contrib.layers.batch_norm`, `python.ops.nn_impl.moments`, `python.ops.nn_impl.sufficient_statics`

If I understand correctly, I am seeing that the GPU gets blocked as a result of shuffling a trivial `gather` op unnecessarily off to the CPU only to wait forever for it to come back. 

![screenshot from 2016-12-01 11 45 17](https://cloud.githubusercontent.com/assets/4404828/20810886/67cbd92e-b7c0-11e6-991d-75ab54a1c699.png)

"
6026,Tensorboard erorr when adding metadata to embedding ,"### Environment info
Operating System: Linux gaia 3.13.0-95-generic

If installed from binary pip package, provide:

1. A link to the pip package you installed: https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.12.0rc0-cp35-cp35m-linux_x86_64.whl
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.
0.12.0-rc0

Followed the instructions on 'https://www.tensorflow.org/versions/r0.12/how_tos/embedding_viz/index.html'
to add labels to my embedding. My metadata.tsv file is just a single column with the ith row being the label corresponing to the ith row of embedding tensor

However after I did this and ran Tensorboard everything is fine until I click 'embeddings'  then I get this error message  
```
'Exception happened during processing of request from ('127.0.0.1', 56645)
Traceback (most recent call last):
  File ""/usr/local/lib/python3.5/socketserver.py"", line 625, in process_request_thread
    self.finish_request(request, client_address)
  File ""/usr/local/lib/python3.5/socketserver.py"", line 354, in finish_request
    self.RequestHandlerClass(request, client_address, self)
  File ""/usr/local/lib/python3.5/site-packages/tensorflow/tensorboard/backend/handler.py"", line 103, in __init__
    BaseHTTPServer.BaseHTTPRequestHandler.__init__(self, *args)
  File ""/usr/local/lib/python3.5/socketserver.py"", line 681, in __init__
    self.handle()
  File ""/usr/local/lib/python3.5/http/server.py"", line 422, in handle
    self.handle_one_request()
  File ""/usr/local/lib/python3.5/http/server.py"", line 410, in handle_one_request
    method()
  File ""/usr/local/lib/python3.5/site-packages/tensorflow/tensorboard/backend/handler.py"", line 531, in do_GET
    self.data_handlers[clean_path](query_params)
  File ""/usr/local/lib/python3.5/site-packages/tensorflow/tensorboard/plugins/projector/plugin.py"", line 278, in _serve_runs
    request.respond(list(self.configs.keys()), 'application/json')
  File ""/usr/local/lib/python3.5/site-packages/tensorflow/tensorboard/plugins/projector/plugin.py"", line 141, in configs
    _latest_checkpoints_changed(self._configs, run_path_pairs)):
  File ""/usr/local/lib/python3.5/site-packages/tensorflow/tensorboard/plugins/projector/plugin.py"", line 65, in _latest_checkpoints_changed
    if run_name not in configs:
TypeError: argument of type 'NoneType' is not iterable
```

If i removed the ``` projector_config.pbtxt ```  from the LOGDIR tensoboard runs properly again. 

Also found on the documentation page 

``` embedding = config.embeddings.add() ```  should be ```embedding = config.embedding.add() ```
"
6025,For which inputs are gradients computed?,"What is a good way to determine which inputs of a tensorflow op are backpropagated through?
For example, consider the [crop_and_resize](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/g3doc/api_docs/python/functions_and_classes/shard2/tf.image.crop_and_resize.md) op. The description sounds rather straightforward - 
>""Extracts crops from the input image tensor and bilinearly resizes them"". 

However, if you dig through the code, this function pops up [_CropAndResizeGrad](https://github.com/tensorflow/tensorflow/blob/33e88f6d7b69f796d4fad452394237448f62b976/tensorflow/python/ops/image_grad.py#L77), which states 

> ""We back-propagate to the image only when the input image tensor has floating point dtype but we always back-propagate to the input boxes tensor."",

which indicates that the input bounding box coordinates will get gradients.

It might just be me, but I have a hard time telling which input tensor variables will get gradients and which will not. Is there a standard way? Should this be part of the documentation? 

Thanks."
6024,where is Tensorflow directory on Windows ?,"I have installed and verified Tensorflow installation on Windows, that's great. But how I am supposed to to stuff like `pyhthon3 cifar10_train.py`? ran that command got error no such file or directory. Also run the whole code in cifar10.py and got error there is no module named tensorflow.modles.

`ImportError was unhandled by user code
Message: No module named 'tensorflow.models'`
"
6022,Negative axis support for argmin and argmax,"I'd like `tf.argmax(value, axis=-1)` to work.  A lot of other ops support negative axes (`tf.concat`, `tf.stack`, etc.), but not `argmin` and `argmax`."
6021,Linker error when building custom op,"I was not getting this error a couple of weeks ago, but now when I repull it/update the repository I am getting an error when running configure.

git clone https://github.com/tensorflow/tensorflow.git
git pull
git status
    `On branch master
Your branch is up-to-date with 'origin/master'.
Untracked files:
  (use ""git add <file>..."" to include in what will be committed)

	tensorflow/core/platform/default/build_config.bzl-e
	tensorflow/models/image/mnist/data/
	tensorflow/user_ops/zero_out.cc
	zero_out.cc
	zero_out_2.so

nothing added to commit but untracked files present (use ""git add"" to track)`

Then I run ./configure:

Error:
`ERROR: /Users/johnpeurifoy/Documents/Skewl/GeneralUnitaryRNN/tensorflow/tensorflow/tensorflow.bzl:660:21: syntax error at '=': expected expression.
ERROR: /Users/johnpeurifoy/Documents/Skewl/GeneralUnitaryRNN/tensorflow/tensorflow/tensorflow.bzl:735:1: nested functions are not allowed. Move the function to top-level.
ERROR: /Users/johnpeurifoy/Documents/Skewl/GeneralUnitaryRNN/tensorflow/tensorflow/tensorflow.bzl:763:1: nested functions are not allowed. Move the function to top-level.
ERROR: /Users/johnpeurifoy/Documents/Skewl/GeneralUnitaryRNN/tensorflow/tensorflow/tensorflow.bzl:797:1: nested functions are not allowed. Move the function to top-level.
ERROR: /Users/johnpeurifoy/Documents/Skewl/GeneralUnitaryRNN/tensorflow/tensorflow/tensorflow.bzl:800:1: nested functions are not allowed. Move the function to top-level.
ERROR: com.google.devtools.build.lib.packages.BuildFileContainsErrorsException: error loading package '': Extension 'tensorflow/tensorflow.bzl' has errors.
`

Overall, I am trying to implement a new operator using tensorflow. I am able to easily import tensorflow, but when I try to build the new operator (following the tutorial on https://www.tensorflow.org/versions/r0.12/how_tos/adding_an_op/index.html), i get:

`  ""tensorflow::Tensor::CheckTypeAndIsAligned(tensorflow::DataType) const"", referenced from:
      ZeroOutOp::Compute(tensorflow::OpKernelContext*) in zero_out-a7cd0e.o
  ""typeinfo for tensorflow::OpKernel"", referenced from:
      typeinfo for ZeroOutOp in zero_out-a7cd0e.o
ld: symbol(s) not found for architecture x86_64
clang: error: linker command failed with exit code 1 (use -v to see invocation)`

Thoughts? I have tried checking out the other branches as well and trying them, but no luck.

My pip freeze looks like:

`alabaster==0.7.9
anaconda-clean==1.0
anaconda-client==1.5.1
anaconda-navigator==1.3.1
appnope==0.1.0
appscript==1.0.1
argcomplete==1.0.0
astroid==1.4.7
astropy==1.2.1
Babel==2.3.4
backports-abc==0.4
backports.shutil-get-terminal-size==1.0.0
backports.ssl-match-hostname==3.4.0.2
beautifulsoup4==4.5.1
bitarray==0.8.1
blaze==0.10.1
bokeh==0.12.2
boto==2.42.0
Bottleneck==1.1.0
cdecimal==2.3
cffi==1.7.0
chest==0.2.3
click==6.6
cloudpickle==0.2.1
clyent==1.2.2
colorama==0.3.7
conda==4.2.12
conda-build==2.0.2
configobj==5.0.6
configparser==3.5.0
contextlib2==0.5.3
cryptography==1.5
cycler==0.10.0
Cython==0.24.1
cytoolz==0.8.0
dask==0.11.0
datashape==0.5.2
decorator==4.0.10
dill==0.2.5
docutils==0.12
dynd==0.7.3.dev1
enum34==1.1.6
et-xmlfile==1.0.1
fastcache==1.0.2
filelock==2.0.6
Flask==0.11.1
Flask-Cors==2.1.2
funcsigs==1.0.2
functools32==3.2.3.post2
futures==3.0.5
gevent==1.1.2
greenlet==0.4.10
grin==1.2.1
h5py==2.6.0
HeapDict==1.0.0
idna==2.1
imagesize==0.7.1
ipaddress==1.0.16
ipykernel==4.5.0
ipython==5.1.0
ipython-genutils==0.1.0
ipywidgets==5.2.2
itsdangerous==0.24
jdcal==1.2
jedi==0.9.0
Jinja2==2.8
jsonschema==2.5.1
jupyter==1.0.0
jupyter-client==4.4.0
jupyter-console==5.0.0
jupyter-core==4.2.0
Keras==1.1.1
lazy-object-proxy==1.2.1
llvmlite==0.13.0
locket==0.2.0
lxml==3.6.4
MarkupSafe==0.23
matplotlib==1.5.3
mistune==0.7.3
mock==2.0.0
mpmath==0.19
multipledispatch==0.4.8
nb-anacondacloud==1.2.0
nb-conda==2.0.0
nb-conda-kernels==2.0.0
nbconvert==4.2.0
nbformat==4.1.0
nbpresent==3.0.2
networkx==1.11
nltk==3.2.1
nose==1.3.7
notebook==4.2.3
numba==0.28.1+0.gfe99fbc.dirty
numexpr==2.6.1
numpy==1.11.1
odo==0.5.0
openpyxl==2.3.2
pandas==0.18.1
partd==0.3.6
path.py==0.0.0
pathlib2==2.1.0
patsy==0.4.1
pbr==1.10.0
pep8==1.7.0
pexpect==4.0.1
pickleshare==0.7.4
Pillow==3.3.1
pkginfo==1.3.2
ply==3.9
prompt-toolkit==1.0.3
protobuf==3.0.0
psutil==4.3.1
ptyprocess==0.5.1
py==1.4.31
pyasn1==0.1.9
PyAudio==0.2.7
pycosat==0.6.1
pycparser==2.14
pycrypto==2.6.1
pycurl==7.43.0
pyflakes==1.3.0
Pygments==2.1.3
pylint==1.5.4
pyOpenSSL==16.0.0
pyparsing==2.1.4
pytest==2.9.2
python-dateutil==2.5.3
pytz==2016.6.1
PyYAML==3.12
pyzmq==15.4.0
QtAwesome==0.3.3
qtconsole==4.2.1
QtPy==1.1.2
redis==2.10.5
requests==2.11.1
rope==0.9.4
ruamel-yaml===-VERSION
scikit-image==0.12.3
scikit-learn==0.17.1
scipy==0.18.1
simplegeneric==0.8.1
singledispatch==3.4.0.3
six==1.10.0
snowballstemmer==1.2.1
sockjs-tornado==1.0.3
Sphinx==1.4.6
spyder==3.0.0
SQLAlchemy==1.0.13
statsmodels==0.6.1
sympy==1.0
tables==3.2.3.1
tensorflow==0.11.0rc2
terminado==0.6
Theano==0.8.2
toolz==0.8.0
tornado==4.4.1
traitlets==4.3.0
unicodecsv==0.14.1
wcwidth==0.1.7
Werkzeug==0.11.11
widgetsnbextension==1.2.6
wrapt==1.10.6
xlrd==1.0.0
XlsxWriter==0.9.3
xlwings==0.10.0
xlwt==1.1.2`



"
6019,Computer freeze when feeding a large numpy array as input in MNIST tutorial,"### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?
None

### Environment info
intel i5, 8gb ram
Operating System:
Ubuntu 14.04.5:
Linux 4.4.0-45-generic #66~14.04.1-Ubuntu SMP Wed Oct 19 15:05:38 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux

Installed version of CUDA and cuDNN: 
No cuda or cuDNN, running on CPU

If installed from binary pip package, provide:

1. A link to the pip package you installed:
TF_BINARY_URL=https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.11.0-cp34-cp34m-linux_x86_64.whl
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.
0.11.0rc2

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)
Use the mnist tutorial, replace
    `train_accuracy = accuracy.eval(feed_dict={
        x:batch[0], y_: batch[1], keep_prob: 1.0})`
with 
`train_accuracy = accuracy.eval(feed_dict={ x:mnist.train.images, y_: mnist.train.labels, keep_prob: 1.0})`

So that the accuracy is evaluated over the entire training set. I've reproduced this using another dataset, and the problem goes away when using a smaller number of examples.
(pastebin for entire file with this modification: http://pastebin.com/THNqB4ws)

### What other attempted solutions have you tried?
None, there's no error message and the computer hangs the first time it executes `accuracy.eval`

"
6018,Unecessary messages in queue handling,"Suppose you want to have one or multiple threads to preload/preprocess images and push them into an image queue that is going to be consumed by your main process, running on the GPU. A simple way of doing so would be:

```
def load_image(session, image_list, enqueue_op, image_data_placeholder, coord):
  index = 0
  while not coord.should_stop():
    idata = image_list[index]
    session.run(enqueue_op, feed_dict={image_data_placeholder: idata})
    index = (index + 1) % len(image_list)
```

Eventually, your optimization is finished and you want all threads to end, but if you have threads feeding your queue, they are most likely blocked at the enqueue_op, waiting for an image to be consumed, so they can finally insert theirs in the queue.

Since closing the queue doesn't unblock them (surprisingly), your most evident choice is to use the timeout option to limit how long the enqueue_op can block your thread, with something like this:

```
def load_image(session, image_list, enqueue_op, image_data_placeholder, coord):
  index = 0
  while not coord.should_stop():
    idata = image_list[index]
    try:
      session.run(enqueue_op, feed_dict={image_data_placeholder: idata}, options=tf.RunOptions(timeout_in_ms=1000))
      index = (index + 1) % len(name_list)
    except:
      pass
```

And it does work: the thread will continue trying to push the same image until either it succeeds (and moves on to the next one) or coordinator says it should stop everything and finish.

The problem is that the timeout not only throws an exception saying that the time has been exceeded, but TF also ""manually"" prints a warning message. Bad news, you have 3 options: (1) manually edit TryAttemptLocked in queue_base.cc to remove the message from your tensorflow copy, (2) accept that this pesky message is going to flood your logs with useless information or (3) force TF_CPP_MIN_LOG_LEVEL to be at level 2, suppressing all information messages and warnings that could be important, only to get rid of this one message. There is also a 4th option: open an issue here in hope there is a better way of handling this, or that some dev changes this behavior — the exception should be enough for any situation, the forced message doesn't seem to do any good. :-)

Disclaimer: I know it's far from optimal to pass a list of features (image_list) to be enqueued. This is just for the sake of simplicity in this example."
6015,initialization of local variables missing in example: fully_connected_preloaded.py,"change introduced in this commit: 
https://github.com/tensorflow/tensorflow/commit/cbd3cacfb73bbea912b9d01c2540187684f751a7
so, not sure if the other files have to be changed as well

`init_op = tf.global_variables_initializer()`
->
`init_op = tf.group(tf.global_variables_initializer(),
                       tf.local_variables_initializer())`

without the change the loop is exited immediately and this error occus:

> tensorflow.python.framework.errors_impl.FailedPreconditionError: Attempting to use uninitialized value input/input_producer/input_producer/fraction_of_32_full/limit_epochs/epochs
	 [[Node: input/input_producer/input_producer/fraction_of_32_full/limit_epochs/CountUpTo = CountUpTo[T=DT_INT64, _class=[""loc:@input/input_producer/input_producer/fraction_of_32_full/limit_epochs/epochs""], limit=2, _device=""/job:localhost/replica:0/task:0/cpu:0""](input/input_producer/input_producer/fraction_of_32_full/limit_epochs/epochs)]]
  "
6012,Editing Tensorboard graphs,"Thanks for the powerful package, equipped with an awesome tensorboard like visualization environment.

There is just one issue. Graphs generated under Tensorboard occupy too much space than necessary, which makes it difficult to understand what is going on, thanks to consequent relative reduction in font size for all the blocks. It would be really helpful if user could move the nodes around, such that rearranged view is printer friendly, and also user friendly. Please implement the feature soonest you can, as it will help newbies like me (and anyone in general, since this package too is quite new relatively) to ramp up quickly, and also for debugging the code. Thank you.

Vedhas"
6011,Is it possible to implement spatial pyramid pooling layer with tensorflow?,"I would like to implement the spatial pyramid pooling layer as introduced [in this paper.](https://arxiv.org/pdf/1406.4729v4.pdf)
As the paper setting, the keypoint is to define variant kernel size and stride size of max_pooling layer, which is:
```
kernel_size = ceil(a/n)
stride_size = floor(a/n)
```
where `a` is the input tensor spatial size, and `n` is the pyramid level, i.e. spatial bins of the pooling output.

I try to implement this layer with tensorflow, the code is:

```
def spp_layer(input_, name = 'SPP_layer'):
    '''4 level spp layer 
    spatial bins: [6_6, 3_3, 2_2, 1_1] '''

    shape = input_.get_shape().as_list()

    with tf.variable_scope(name):

        spp_6_6_pool = tf.nn.max_pool(input_, ksize=[1, np.ceil(shape[1]/6).astype(np.int32), np.ceil(shape[1]/6).astype(np.int32), 1], 
                                      strides=[1, shape[1]//6, shape[2]//6, 1], 
                                      padding='SAME')
        print('SPP layer level 6:', spp_6_6_pool.get_shape().as_list())

        spp_3_3_pool = tf.nn.max_pool(input_, ksize=[1, np.ceil(shape[1]/3).astype(np.int32), np.ceil(shape[2]/3).astype(np.int32), 1], 
                                      strides=[1, shape[1]//3, shape[2]//3, 1], 
                                      padding='SAME')
        print('SPP layer level 3:', spp_3_3_pool.get_shape().as_list())

        spp_2_2_pool = tf.nn.max_pool(input_, ksize=[1, np.ceil(shape[1]/2).astype(np.int32), np.ceil(shape[2]/2).astype(np.int32), 1], 
                                      strides=[1, shape[1]//2, shape[2]//2, 1], 
                                      padding='SAME')
        print('SPP layer level 2:', spp_2_2_pool.get_shape().as_list())

        spp_1_1_pool = tf.nn.max_pool(input_, ksize=[1, np.ceil(shape[1]/1).astype(np.int32), np.ceil(shape[2]/1).astype(np.int32), 1], 
                                      strides=[1, shape[1]//1, shape[2]//1, 1], 
                                      padding='SAME')
        print('SPP layer level 1:', spp_1_1_pool.get_shape().as_list())


        spp_6_6_pool_flat = tf.reshape(spp_6_6_pool, [shape[0], -1])
        spp_3_3_pool_flat = tf.reshape(spp_3_3_pool, [shape[0], -1])
        spp_2_2_pool_flat = tf.reshape(spp_2_2_pool, [shape[0], -1])
        spp_1_1_pool_flat = tf.reshape(spp_1_1_pool, [shape[0], -1])

        spp_pool = tf.concat(1, [spp_6_6_pool_flat, spp_3_3_pool_flat, spp_2_2_pool_flat, spp_1_1_pool_flat])

    return spp_pool
```

But it cannot gurantee the same length pooling output, when the input sizes are different.

Does tensorflow support the fixed length spatial pyramid pooling layer?

I also post the question on the [stackoverflow](http://stackoverflow.com/questions/40913794/tensorflow-how-to-implement-the-fixed-length-spatial-pyramid-pooling-layer).


"
6010,Public access to current absolute name scope,I can get it via `tf.get_default_graph()._name_stack`. But I think there is no public API to get that information. Some public API would be nice.
6008,Unintuitive error messages when using functions that require a axis parameter,"Multiple tensorflow functions (I tested tf.argmax,tf.argmin), that require axis parameters to be provided, show very unintuitive error messages if the axis parameter is omitted.

It would probably be more convenient to either throw exceptions earlier with more intuitive error descriptions ('Axis parameter must be passed/must not be None') or to define the axis parameters as a required positional parameters. 

### Environment info
Operating System:
OS X 10.11.6, running with cpu backend

1. A link to the pip package you installed:
https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-0.12.0rc0-py3-none-any.whl
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.:
0.12.0-rc0

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)
```
import tensorflow as tf
t =tf.get_variable('test', shape=[100])
maxt = tf.argmax(t)
```

### Logs or other output that would be helpful
Exception:
```
Traceback (most recent call last):
  File ""/Users/maexlich/.virtualenvs/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py"", line 490, in apply_op
    preferred_dtype=default_dtype)
  File ""/Users/maexlich/.virtualenvs/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/ops.py"", line 669, in convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
  File ""/Users/maexlich/.virtualenvs/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/constant_op.py"", line 176, in _constant_tensor_conversion_function
    return constant(v, dtype=dtype, name=name)
  File ""/Users/maexlich/.virtualenvs/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/constant_op.py"", line 165, in constant
    tensor_util.make_tensor_proto(value, dtype=dtype, shape=shape, verify_shape=verify_shape))
  File ""/Users/maexlich/.virtualenvs/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/tensor_util.py"", line 360, in make_tensor_proto
    raise ValueError(""None values not supported."")
ValueError: None values not supported.
During handling of the above exception, another exception occurred:
Traceback (most recent call last):
  File ""/Users/maexlich/.virtualenvs/tensorflow/lib/python3.5/site-packages/IPython/core/interactiveshell.py"", line 2881, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File ""<ipython-input-6-8fd26b27f1ef>"", line 1, in <module>
    max = tf.argmax(t)
  File ""/Users/maexlich/.virtualenvs/tensorflow/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py"", line 249, in argmax
    return gen_math_ops.arg_max(input, axis, name)
  File ""/Users/maexlich/.virtualenvs/tensorflow/lib/python3.5/site-packages/tensorflow/python/ops/gen_math_ops.py"", line 168, in arg_max
    name=name)
  File ""/Users/maexlich/.virtualenvs/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py"", line 503, in apply_op
    as_ref=input_arg.is_ref).dtype.name
  File ""/Users/maexlich/.virtualenvs/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/ops.py"", line 669, in convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
  File ""/Users/maexlich/.virtualenvs/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/constant_op.py"", line 176, in _constant_tensor_conversion_function
    return constant(v, dtype=dtype, name=name)
  File ""/Users/maexlich/.virtualenvs/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/constant_op.py"", line 165, in constant
    tensor_util.make_tensor_proto(value, dtype=dtype, shape=shape, verify_shape=verify_shape))
  File ""/Users/maexlich/.virtualenvs/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/tensor_util.py"", line 360, in make_tensor_proto
    raise ValueError(""None values not supported."")
ValueError: None values not supported.
```"
6007,tf.name_scope with reuse,"I want to reuse a name scope which was created earlier with `tf.name_scope`. Normally, name_scope will create a new unique name in the current namespace. If it ends with ""/"", it will ignore the current namespace and use it as an absolute name scope but then it doesn't make it unique. I want a way that it just uses the name as I provide it in the current namespace.

Current code:
```
  @contextlib.contextmanager
  def name_scope(self, name):
      ...
      old_stack = self._name_stack
      if not name:  # Both for name=None and name="""" we re-set to empty scope.
        new_stack = None
      elif name and name[-1] == ""/"":
        new_stack = name[:-1]
      else:
        new_stack = self.unique_name(name)
      self._name_stack = new_stack
      yield """" if new_stack is None else new_stack + ""/""
```

I suggest something like:

```
  @contextlib.contextmanager
  def name_scope(self, name, reuse=False):
    if reuse:
      new_stack = self._name_stack + ""/"" + name
    else:
      ...
```
"
6005,Tensorboard can't show item on windows,"I have install the tensorflow by pip on windows 10 64bit

tensorflow have no Problem.
but,Tensorboard can't run.

this is Log
---------------------------------------------------------------------------------------------------------
D:\Python35\Lib\site-packages\tensorflow\tensorboard>d:\Python35\python.exe tensorboard.py --logdir=D:\tensorBoard --debug
INFO:tensorflow:TensorBoard is in debug mode.
INFO:tensorflow:Starting TensorBoard in directory D:\Python35\Lib\site-packages\tensorflow\tensorboard
INFO:tensorflow:TensorBoard path_to_run is: {'D:\\tensorBoard': 'D'}
INFO:tensorflow:Event Multiplexer initializing.
INFO:tensorflow:Event Multiplexer done initializing
INFO:tensorflow:TensorBoard reload process beginning
INFO:tensorflow:Starting AddRunsFromDirectory: D:\tensorBoard
INFO:tensorflow:Adding events from directory D:\tensorBoard
INFO:tensorflow:Constructing EventAccumulator for D:\tensorBoard
INFO:tensorflow:Done with AddRunsFromDirectory: D:\tensorBoard
INFO:tensorflow:TensorBoard reload process: Reload the whole Multiplexer
INFO:tensorflow:Beginning EventMultiplexer.Reload()
DEBUG:tensorflow:Opening a record reader pointing at D:\tensorBoard\events.out.tfevents.1480577231.SHPC052
DEBUG:tensorflow:No more events in D:\tensorBoard\events.out.tfevents.1480577231.SHPC052
INFO:tensorflow:No path found after D:\tensorBoard\events.out.tfevents.1480577231.SHPC052
INFO:tensorflow:Finished with EventMultiplexer.Reload()
INFO:tensorflow:TensorBoard done reloading. Load took 0.008 secs
INFO:tensorflow:TensorBoard is tag: b'39'
Starting TensorBoard b'39' on port 6006
(You can navigate to http://10.237.101.186:6006)
INFO:tensorflow:path ../external\webcomponentsjs/webcomponents-lite.min.js not found, sending 404
INFO:tensorflow:returning 404 to 127.0.0.1 for /webcomponentsjs/webcomponents-lite.min.js
INFO:tensorflow:path ../external\plottable/plottable.css not found, sending 404
INFO:tensorflow:returning 404 to 127.0.0.1 for /plottable/plottable.css
INFO:tensorflow:TensorBoard reload process beginning
INFO:tensorflow:Starting AddRunsFromDirectory: D:\tensorBoard
INFO:tensorflow:Adding events from directory D:\tensorBoard
INFO:tensorflow:Done with AddRunsFromDirectory: D:\tensorBoard
INFO:tensorflow:TensorBoard reload process: Reload the whole Multiplexer
INFO:tensorflow:Beginning EventMultiplexer.Reload()
DEBUG:tensorflow:No more events in D:\tensorBoard\events.out.tfevents.1480577231.SHPC052
INFO:tensorflow:No path found after D:\tensorBoard\events.out.tfevents.1480577231.SHPC052
INFO:tensorflow:Finished with EventMultiplexer.Reload()
INFO:tensorflow:TensorBoard done reloading. Load took 0.009 secs

---------------------------------------------------------------------------------------
this is like 404 problem.

INFO:tensorflow:path ../external\webcomponentsjs/webcomponents-lite.min.js not found, sending 404
INFO:tensorflow:returning 404 to 127.0.0.1 for /webcomponentsjs/webcomponents-lite.min.js
INFO:tensorflow:path ../external\plottable/plottable.css not found, sending 404
INFO:tensorflow:returning 404 to 127.0.0.1 for /plottable/plottable.css

Can anyone help me?
Thank you very much.




"
6003,C/Other Languages: Support serialization and deserialization of Tensors,"In C++ and Python, Tensors can be serialized into a `TensorProto` using functions like [`Tensor::AsProtoTensorContents`](https://github.com/tensorflow/tensorflow/blob/f7ec99516ce0e0937e0b865e90aa02c748cd36c6/tensorflow/core/framework/tensor.h#L205)  and [`make_tensor_proto`](https://www.tensorflow.org/versions/r0.12/api_docs/python/contrib.util.html#make_tensor_proto)

This is particularly useful when communicating tensors across process boundaries such as [PredictRequest](https://github.com/tensorflow/serving/blob/8c89d72259a7c15f0a9711a67eecf284d9460cca/tensorflow_serving/apis/predict.proto#L22) RPCs to a [TensorFlow Model Server](https://tensorflow.github.io/serving/) 

Filing this to track any changes to the [C API](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/c/c_api.h) and language bindings.

Interested parties: @asimshankar @jhseu @nfiedel @josh11b "
6001,How to enable the support of cuda compute capability 3.0 GPU in windows,"I just setup gpu supported tensorflow on my windows 10 PC following https://developers.googleblog.com/2016/11/tensorflow-0-12-adds-support-for-windows.html

But right now I found I cannot use my GPU as it is a GeForece GTX760 and only has 3.0 CUDA compute capability

### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?

There are several discussion for linux and MAC tensorflow, as they can build from source so they can just change the list of the computer capability. right now I cannot build from source so I am wondering if there are any other way to change the setup?

### Environment info
Operating System:
Windows 10 64bit

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):
CUDA 8.0
cuDNN 5.1

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)
"
6000,distributed seq2seq used SyncReplicasOptimizerV2 question,"Now I want to change seq2seq to distributed mode used SyncReplicasOptimizerV2. I've been trying for a few days，but still can't work out. this is my code,one file is seq2seq_train.py,on file is seq2seq_model.py
I try to run in 1 ps and 2 worker

the error is:
Traceback (most recent call last):
  File ""/home/test/replicas_seq2seq_v4/seq2seq_train.py"", line 188, in <module>
    tf.app.run()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 43, in run
    sys.exit(main(sys.argv[:1] + flags_passthrough))
  File ""/home/test/replicas_seq2seq_v4/seq2seq_train.py"", line 82, in main
    task_index = FLAGS.task_index ,replicas_to_aggregate=num_workers, forward_only=False)
  File ""/home/test/replicas_seq2seq_v4/seq2seq_model.py"", line 221, in __init__
    self.session = supervisor.prepare_or_wait_for_session(self.server.target, config=sess_config)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/supervisor.py"", line 720, in prepare_or_wait_for_session
    init_feed_dict=self._init_feed_dict, init_fn=self._init_fn)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py"", line 251, in prepare_session
    self._local_init_op, msg))
RuntimeError: Init operations did not make model ready.  Init op: init, init fn: None, local_init_op: name: ""sync_replicas_3/group_deps""
op: ""NoOp""
input: ""^sync_replicas_3/group_deps/NoOp""
input: ""^sync_replicas_3/group_deps/NoOp_1""
input: ""^sync_replicas_3/group_deps/NoOp_2""
device: ""/job:worker/task:0""
, error: Variables not initialized: sync_rep_local_step, sync_rep_local_step_1, sync_rep_local_step_2

ps:
 python seq2seq_train.py --ps_hosts=127.0.0.1:2240 --worker_hosts=127.0.0.1:2230,127.0.0.1:2242 --job_name=ps --task_index=0 --data_dir=data1 --train_dir=result  --batch_size=128 --size=1024 --num_layers=2 --steps_per_checkpoint=5 --en_vocab_size=40000 --fr_vocab_size=40000 --learning_rate=0.5 --learning_rate_decay_factor=0.95 --max_gradient_norm=2.0 --max_train_data_size=50000

worker1:
 python seq2seq_train.py --ps_hosts=127.0.0.1:2240 --worker_hosts=127.0.0.1:2230,127.0.0.1:2242 --job_name=worker --task_index=0 --data_dir=data1 --train_dir=result  --batch_size=128 --size=1024 --num_layers=2 --steps_per_checkpoint=5 --en_vocab_size=40000 --fr_vocab_size=40000 --learning_rate=0.5 --learning_rate_decay_factor=0.95 --max_gradient_norm=2.0 --max_train_data_size=50000

worker2:
 python seq2seq_train.py --ps_hosts=127.0.0.1:2240 --worker_hosts=127.0.0.1:2230,127.0.0.1:2242 --job_name=worker --task_index=1 --data_dir=data1 --train_dir=result  --batch_size=128 --size=1024 --num_layers=2 --steps_per_checkpoint=5 --en_vocab_size=40000 --fr_vocab_size=40000 --learning_rate=0.5 --learning_rate_decay_factor=0.95 --max_gradient_norm=2.0 --max_train_data_size=50000



seq2seq_train.py

```python
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import tempfile
import math
import os
import random
import sys
import time
import json

import numpy as np
from six.moves import xrange  # pylint: disable=redefined-builtin
import tensorflow as tf

from tensorflow.models.rnn.translate import data_utils
import seq2seq_model

tf.app.flags.DEFINE_string(""ps_hosts"", """",
                           ""Comma-separated list of hostname:port pairs"")
tf.app.flags.DEFINE_string(""worker_hosts"", """",
                           ""Comma-separated list of hostname:port pairs"")

tf.app.flags.DEFINE_string(""job_name"", """", ""One of 'ps', 'worker'"")
tf.app.flags.DEFINE_integer(""task_index"", 0, ""Index of task within the job"")

tf.app.flags.DEFINE_float(""learning_rate"", 0.5, ""Learning rate."")
tf.app.flags.DEFINE_float(""learning_rate_decay_factor"", 0.99,
                          ""Learning rate decays by this much."")
tf.app.flags.DEFINE_float(""max_gradient_norm"", 5.0,
                          ""Clip gradients to this norm."")
tf.app.flags.DEFINE_integer(""batch_size"", 64,
                            ""Batch size to use during training."")
tf.app.flags.DEFINE_integer(""size"", 1024, ""Size of each model layer."")
tf.app.flags.DEFINE_integer(""num_layers"", 3, ""Number of layers in the model."")
tf.app.flags.DEFINE_integer(""en_vocab_size"", 40000, ""English vocabulary size."")
tf.app.flags.DEFINE_integer(""fr_vocab_size"", 40000, ""French vocabulary size."")
tf.app.flags.DEFINE_string(""data_dir"", ""/tmp/data"", ""Data directory"")
tf.app.flags.DEFINE_string(""train_dir"", ""/tmp"", ""Training directory."")
tf.app.flags.DEFINE_integer(""max_train_data_size"", 0,
                            ""Limit on the size of training data (0: no limit)."")
tf.app.flags.DEFINE_integer(""steps_per_checkpoint"", 200,
                            ""How many training steps to do per checkpoint."")
tf.app.flags.DEFINE_boolean(""decode"", False,
                            ""Set to True for interactive decoding."")
tf.app.flags.DEFINE_boolean(""self_test"", False,
                            ""Run a self-test if this is set to True."")

FLAGS = tf.app.flags.FLAGS

_buckets = [(5, 10), (10, 15), (20, 25), (40, 50)]

def main(_):
  if FLAGS.job_name is None or FLAGS.job_name == """":
    raise ValueError(""Must specify an explicit `job_name`"")
  if FLAGS.task_index is None or FLAGS.task_index =="""":
    raise ValueError(""Must specify an explicit `task_index`"")


  ps_hosts = FLAGS.ps_hosts.split("","")
  worker_hosts = FLAGS.worker_hosts.split("","")

  cluster = tf.train.ClusterSpec({""ps"": ps_hosts, ""worker"": worker_hosts})

  server = tf.train.Server(cluster, job_name=FLAGS.job_name, task_index=FLAGS.task_index)
  num_workers = len(worker_hosts)

  server = tf.train.Server(cluster, job_name=FLAGS.job_name, task_index=FLAGS.task_index)
  if FLAGS.job_name == ""ps"":
    server.join()
    return
  is_chief = (FLAGS.task_index == 0)
  model = seq2seq_model.Seq2SeqModel(server, FLAGS.en_vocab_size, FLAGS.fr_vocab_size, _buckets,
      FLAGS.size, FLAGS.num_layers, FLAGS.max_gradient_norm, FLAGS.batch_size,
      FLAGS.learning_rate, FLAGS.learning_rate_decay_factor,num_workers = num_workers, 
      task_index = FLAGS.task_index ,replicas_to_aggregate=num_workers, forward_only=False)
  step_time, loss = 0.0, 0.0
  current_step = 0
  previous_losses = []

  print(""query -> title:"")
  en_train = FLAGS.data_dir + ""/giga-fren.release2.ids40000.en""
  fr_train = FLAGS.data_dir + ""/giga-fren.release2.ids40000.fr""
  en_dev = FLAGS.data_dir + ""/newstest2013.ids40000.en""
  fr_dev = FLAGS.data_dir + ""/newstest2013.ids40000.fr""

  print (""Reading development and training data (limit: %d)."" % FLAGS.max_train_data_size)
  dev_set = read_data(en_dev, fr_dev)
  train_set = read_train_data(en_train, fr_train, num_workers, FLAGS.max_train_data_size)
  train_bucket_sizes = [len(train_set[b]) for b in xrange(len(_buckets))]
  train_total_size = float(sum(train_bucket_sizes))

  train_buckets_scale = [sum(train_bucket_sizes[:i + 1]) / train_total_size for i in xrange(len(train_bucket_sizes))]
  print(""finish to load data"")
  sess = model.session
  while True:
    random_number_01 = np.random.random_sample()
    bucket_id = min([i for i in xrange(len(train_buckets_scale)) if train_buckets_scale[i] > random_number_01])

    start_time = time.time()
    encoder_inputs, decoder_inputs, target_weights = model.get_batch(train_set, bucket_id)
    _, step_loss, _ = model.step(sess, encoder_inputs, decoder_inputs, target_weights, bucket_id, False)
    step_time += (time.time() - start_time) / FLAGS.steps_per_checkpoint
    step_time_now = (time.time() - start_time)
    loss += step_loss / FLAGS.steps_per_checkpoint
    step_loss_now = step_loss
    current_step += 1
    print(""step: %d"" % current_step);

    if (True):
      perplexity = math.exp(step_loss) if step_loss < 300 else float('inf')
      print (""global step %d learning rate %.4f step-time %.2f perplexity ""
             ""%.2f"" % (model.global_step.eval(sess), model.learning_rate.eval(sess), step_time_now, perplexity))

      previous_losses.append(step_loss)

      checkpoint_path = os.path.join(train_dir, ""translate.ckpt"")
      model.saver.save(sess, checkpoint_path, global_step=model.global_step)
      if (current_step %  FLAGS.steps_per_checkpoint == 0):
        for bucket_id in xrange(len(_buckets)):
          if len(dev_set[bucket_id]) == 0:
            print(""  eval: empty bucket %d"" % (bucket_id))
            continue
          encoder_inputs, decoder_inputs, target_weights = model.get_batch(dev_set, bucket_id)
          _, eval_loss, _ = model.step(sess, encoder_inputs, decoder_inputs, target_weights, bucket_id, True)
          eval_ppx = math.exp(eval_loss) if eval_loss < 300 else float('inf')
          print(""  eval: bucket %d perplexity %.2f"" % (bucket_id, eval_ppx))
        step_time, loss = 0.0, 0.0
      sys.stdout.flush()


def read_train_data(source_path, target_path, num_workers, max_size=None):
  data_set = [[] for _ in _buckets]
  with tf.gfile.GFile(source_path, mode=""r"") as source_file:
    with tf.gfile.GFile(target_path, mode=""r"") as target_file:
      source, target = source_file.readline(), target_file.readline()
      counter = 0
      while source and target and (not max_size or counter < max_size):
        counter += 1
        if counter % 1000000 == 0:
          print(""  reading data line %d"" % counter)
          sys.stdout.flush()
        source_ids = [int(x) for x in source.split()]
        target_ids = [int(x) for x in target.split()]
        target_ids.append(data_utils.EOS_ID)
        if (counter % num_workers == 0):
          for bucket_id, (source_size, target_size) in enumerate(_buckets):
            if len(source_ids) < source_size and len(target_ids) < target_size:
              data_set[bucket_id].append([source_ids, target_ids])
              break
        source, target = source_file.readline(), target_file.readline()
  return data_set

def read_data(source_path, target_path, max_size=None):
  data_set = [[] for _ in _buckets]
  with tf.gfile.GFile(source_path, mode=""r"") as source_file:
    with tf.gfile.GFile(target_path, mode=""r"") as target_file:
      source, target = source_file.readline(), target_file.readline()
      counter = 0
      while source and target and (not max_size or counter < max_size):
        counter += 1
        if counter % 100000 == 0:
          print(""  reading data line %d"" % counter)
          sys.stdout.flush()
        source_ids = [int(x) for x in source.split()]
        target_ids = [int(x) for x in target.split()]
        target_ids.append(data_utils.EOS_ID)
        for bucket_id, (source_size, target_size) in enumerate(_buckets):
          if len(source_ids) < source_size and len(target_ids) < target_size:
            data_set[bucket_id].append([source_ids, target_ids])
            break
        source, target = source_file.readline(), target_file.readline()
  return data_set

if __name__ == ""__main__"":
      tf.app.run()
```

seq2seq_model.py



```python
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import random

import numpy as np
from six.moves import xrange  # pylint: disable=redefined-builtin
import tensorflow as tf

from tensorflow.models.rnn.translate import data_utils


class Seq2SeqModel(object):

  def __init__(self,
               server,
               source_vocab_size,
               target_vocab_size,
               buckets,
               size,
               num_layers,
               max_gradient_norm,
               batch_size,
               learning_rate,
               learning_rate_decay_factor,
               num_workers=2, 
               task_index=0,
               replicas_to_aggregate=2,
               use_lstm=False,
               num_samples=512,
               forward_only=False,
               dtype=tf.float32):

    self.graph = tf.Graph()
    self.server = server
    self.source_vocab_size = source_vocab_size
    self.target_vocab_size = target_vocab_size
    self.buckets = buckets
    self.batch_size = batch_size
    self.num_workers = num_workers 
    self.task_index = task_index
    self.is_chief = (task_index == 0)
    self.num_workers = num_workers
    self.replicas_to_aggregate = replicas_to_aggregate

    with self.graph.as_default():
      with tf.device(""/job:ps/task:0""): 
      #with tf.device(""/cpu:0""): 
        self.global_step = tf.Variable(0, trainable=False)
        self.learning_rate = tf.Variable(
            float(learning_rate), trainable=False, dtype=dtype)

      output_projection = None
      softmax_loss_function = None
      if num_samples > 0 and num_samples < self.target_vocab_size:
        with tf.device(""/job:ps/task:0""): 
          w_t = tf.get_variable(""proj_w"", [self.target_vocab_size, size], dtype=dtype)
          w = tf.transpose(w_t)
          b = tf.get_variable(""proj_b"", [self.target_vocab_size], dtype=dtype)
        output_projection = (w, b)
  
        def sampled_loss(inputs, labels):
          with tf.device(""/job:worker/task:""+str(self.task_index)):
            labels = tf.reshape(labels, [-1, 1])
            local_w_t = tf.cast(w_t, tf.float32)
            local_b = tf.cast(b, tf.float32)
            local_inputs = tf.cast(inputs, tf.float32)
            return tf.cast(
                tf.nn.sampled_softmax_loss(local_w_t, local_b, local_inputs, labels,
                                           num_samples, self.target_vocab_size),
                dtype)
        softmax_loss_function = sampled_loss
  
      with tf.device(""/job:worker/task:""+str(self.task_index)):
        single_cell = tf.nn.rnn_cell.GRUCell(size)
        if use_lstm:
          single_cell = tf.nn.rnn_cell.BasicLSTMCell(size)
        cell = single_cell
        if num_layers > 1:
          cell = tf.nn.rnn_cell.MultiRNNCell([single_cell] * num_layers)
  
      def seq2seq_f(encoder_inputs, decoder_inputs, do_decode):
        with tf.device(""/job:worker/task:""+str(self.task_index)):
          return tf.nn.seq2seq.embedding_attention_seq2seq(
              encoder_inputs,
              decoder_inputs,
              cell,
              num_encoder_symbols=source_vocab_size,
              num_decoder_symbols=target_vocab_size,
              embedding_size=size,
              output_projection=output_projection,
              feed_previous=do_decode,
              dtype=dtype)

      with tf.device(""/job:worker/task:""+str(self.task_index)):
        self.encoder_inputs = []
        self.decoder_inputs = []
        self.target_weights = []
        for i in xrange(buckets[-1][0]):  # Last bucket is the biggest one.
          self.encoder_inputs.append(tf.placeholder(tf.int32, shape=[None],
                                                    name=""encoder{0}"".format(i)))
        for i in xrange(buckets[-1][1] + 1):
          self.decoder_inputs.append(tf.placeholder(tf.int32, shape=[None],
                                                    name=""decoder{0}"".format(i)))
          self.target_weights.append(tf.placeholder(dtype, shape=[None],
                                                    name=""weight{0}"".format(i)))
  
        targets = [self.decoder_inputs[i + 1]
                   for i in xrange(len(self.decoder_inputs) - 1)]
        if forward_only:
          self.outputs, self.losses = tf.nn.seq2seq.model_with_buckets(
              self.encoder_inputs, self.decoder_inputs, targets,
              self.target_weights, buckets, lambda x, y: seq2seq_f(x, y, True),
              softmax_loss_function=softmax_loss_function)
          if output_projection is not None:
            for b in xrange(len(buckets)):
              self.outputs[b] = [
                  tf.matmul(output, output_projection[0]) + output_projection[1]
                  for output in self.outputs[b]
              ]
        else:
          self.outputs, self.losses = tf.nn.seq2seq.model_with_buckets(
              self.encoder_inputs, self.decoder_inputs, targets,
              self.target_weights, buckets,
              lambda x, y: seq2seq_f(x, y, False),
              softmax_loss_function=softmax_loss_function)
  
      with tf.device(""/job:worker/task:""+str(self.task_index)):
        params = tf.trainable_variables()
        self.gradient_norms = []
        self.updates = []
        sgd_opt = tf.train.GradientDescentOptimizer(2.0)
        sync_rep_opt = tf.train.SyncReplicasOptimizerV2(
            sgd_opt, replicas_to_aggregate=replicas_to_aggregate,
            total_num_replicas=num_workers)
        for b in xrange(len(buckets)):
          gradients = tf.gradients(self.losses[b], params)
          clipped_gradients, norm = tf.clip_by_global_norm(gradients,
                                                           max_gradient_norm)
          self.gradient_norms.append(norm)
          self.updates.append(sync_rep_opt.apply_gradients(
              zip(clipped_gradients, params), global_step=self.global_step))

        init_op = tf.global_variables_initializer()
        local_init_op = sync_rep_opt.local_step_init_op
        if self.is_chief:
          local_init_op = sync_rep_opt.chief_init_op
        ready_for_local_init_op = sync_rep_opt.ready_for_local_init_op

        chief_queue_runner = sync_rep_opt.get_chief_queue_runner()
        sync_init_op = sync_rep_opt.get_init_tokens_op(num_workers)

    supervisor = tf.train.Supervisor(
        graph=self.graph,
        is_chief=self.is_chief,
        recovery_wait_secs=1,
        init_op=init_op,
        local_init_op=local_init_op,
        ready_for_local_init_op=ready_for_local_init_op)

    sess_config = tf.ConfigProto(
        allow_soft_placement=True,
        log_device_placement=True,
        device_filters=[""/job:ps"", ""/job:worker/task:%d"" % self.task_index])


    self.session = supervisor.prepare_or_wait_for_session(self.server.target, config=sess_config)

    if self.is_chief:
      self.session.run(sync_init_op)
      supervisor.StartQueueRunners(self.session, [chief_queue_runner])

    if self.is_chief:
      self.session.run(sync_init_op)
      supervisor.StartQueueRunners(self.session, [chief_queue_runner])


  def step(self, session, encoder_inputs, decoder_inputs, target_weights,
           bucket_id, forward_only):

    encoder_size, decoder_size = self.buckets[bucket_id]
    if len(encoder_inputs) != encoder_size:
      raise ValueError(""Encoder length must be equal to the one in bucket,""
                       "" %d != %d."" % (len(encoder_inputs), encoder_size))
    if len(decoder_inputs) != decoder_size:
      raise ValueError(""Decoder length must be equal to the one in bucket,""
                       "" %d != %d."" % (len(decoder_inputs), decoder_size))
    if len(target_weights) != decoder_size:
      raise ValueError(""Weights length must be equal to the one in bucket,""
                       "" %d != %d."" % (len(target_weights), decoder_size))


    input_feed = {}
    for l in xrange(encoder_size):
      input_feed[self.encoder_inputs[l].name] = encoder_inputs[l]
    for l in xrange(decoder_size):
      input_feed[self.decoder_inputs[l].name] = decoder_inputs[l]
      input_feed[self.target_weights[l].name] = target_weights[l]


    last_target = self.decoder_inputs[decoder_size].name
    input_feed[last_target] = np.zeros([self.batch_size], dtype=np.int32)


    if not forward_only:
      output_feed = [self.updates[bucket_id],  # Update Op that does SGD.
                     self.gradient_norms[bucket_id],  # Gradient norm.
                     self.losses[bucket_id]]  # Loss for this batch.
    else:
      output_feed = [self.losses[bucket_id]]  # Loss for this batch.
      for l in xrange(decoder_size):  # Output logits.
        output_feed.append(self.outputs[bucket_id][l])

    outputs = session.run(output_feed, input_feed)
    if not forward_only:
      return outputs[1], outputs[2], None  # Gradient norm, loss, no outputs.
    else:
      return None, outputs[0], outputs[1:]  # No gradient norm, loss, outputs.

  def get_batch(self, data, bucket_id):

    encoder_size, decoder_size = self.buckets[bucket_id]
    encoder_inputs, decoder_inputs = [], []


    for _ in xrange(self.batch_size):
      encoder_input, decoder_input = random.choice(data[bucket_id])


      encoder_pad = [data_utils.PAD_ID] * (encoder_size - len(encoder_input))
      encoder_inputs.append(list(reversed(encoder_input + encoder_pad)))


      decoder_pad_size = decoder_size - len(decoder_input) - 1
      decoder_inputs.append([data_utils.GO_ID] + decoder_input +
                            [data_utils.PAD_ID] * decoder_pad_size)


    batch_encoder_inputs, batch_decoder_inputs, batch_weights = [], [], []


    for length_idx in xrange(encoder_size):
      batch_encoder_inputs.append(
          np.array([encoder_inputs[batch_idx][length_idx]
                    for batch_idx in xrange(self.batch_size)], dtype=np.int32))


    for length_idx in xrange(decoder_size):
      batch_decoder_inputs.append(
          np.array([decoder_inputs[batch_idx][length_idx]
                    for batch_idx in xrange(self.batch_size)], dtype=np.int32))


      batch_weight = np.ones(self.batch_size, dtype=np.float32)
      for batch_idx in xrange(self.batch_size):
        if length_idx < decoder_size - 1:
          target = decoder_inputs[batch_idx][length_idx + 1]
        if length_idx == decoder_size - 1 or target == data_utils.PAD_ID:
          batch_weight[batch_idx] = 0.0
      batch_weights.append(batch_weight)
    return batch_encoder_inputs, batch_decoder_inputs, batch_weights
```
"
5999,distributed seq2seq used SyncReplicasOptimizerV2 question,"Now I want to change seq2seq to distributed mode used SyncReplicasOptimizerV2. I've been trying for a few days，but still can't work out. this is my code,one file is seq2seq_train.py,on file is seq2seq_model.py
I try to run in 1 ps and 2 worker

the error is:
Traceback (most recent call last):
  File ""/home/test/replicas_seq2seq_v4/seq2seq_train.py"", line 188, in <module>
    tf.app.run()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 43, in run
    sys.exit(main(sys.argv[:1] + flags_passthrough))
  File ""/home/test/replicas_seq2seq_v4/seq2seq_train.py"", line 82, in main
    task_index = FLAGS.task_index ,replicas_to_aggregate=num_workers, forward_only=False)
  File ""/home/test/replicas_seq2seq_v4/seq2seq_model.py"", line 221, in __init__
    self.session = supervisor.prepare_or_wait_for_session(self.server.target, config=sess_config)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/supervisor.py"", line 720, in prepare_or_wait_for_session
    init_feed_dict=self._init_feed_dict, init_fn=self._init_fn)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py"", line 251, in prepare_session
    self._local_init_op, msg))
RuntimeError: Init operations did not make model ready.  Init op: init, init fn: None, local_init_op: name: ""sync_replicas_3/group_deps""
op: ""NoOp""
input: ""^sync_replicas_3/group_deps/NoOp""
input: ""^sync_replicas_3/group_deps/NoOp_1""
input: ""^sync_replicas_3/group_deps/NoOp_2""
device: ""/job:worker/task:0""
, error: Variables not initialized: sync_rep_local_step, sync_rep_local_step_1, sync_rep_local_step_2

ps:
 python seq2seq_train.py --ps_hosts=127.0.0.1:2240 --worker_hosts=127.0.0.1:2230,127.0.0.1:2242 --job_name=ps --task_index=0 --data_dir=data1 --train_dir=result  --batch_size=128 --size=1024 --num_layers=2 --steps_per_checkpoint=5 --en_vocab_size=40000 --fr_vocab_size=40000 --learning_rate=0.5 --learning_rate_decay_factor=0.95 --max_gradient_norm=2.0 --max_train_data_size=50000

worker1:
 python seq2seq_train.py --ps_hosts=127.0.0.1:2240 --worker_hosts=127.0.0.1:2230,127.0.0.1:2242 --job_name=worker --task_index=0 --data_dir=data1 --train_dir=result  --batch_size=128 --size=1024 --num_layers=2 --steps_per_checkpoint=5 --en_vocab_size=40000 --fr_vocab_size=40000 --learning_rate=0.5 --learning_rate_decay_factor=0.95 --max_gradient_norm=2.0 --

worker2:
 python seq2seq_train.py --ps_hosts=127.0.0.1:2240 --worker_hosts=127.0.0.1:2230,127.0.0.1:2242 --job_name=worker --task_index=1 --data_dir=data1 --train_dir=result  --batch_size=128 --size=1024 --num_layers=2 --steps_per_checkpoint=5 --en_vocab_size=40000 --fr_vocab_size=40000 --learning_rate=0.5 --learning_rate_decay_factor=0.95 --max_gradient_norm=2.0 --



seq2seq_train.py

from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import tempfile
import math
import os
import random
import sys
import time
import json

import numpy as np
from six.moves import xrange  # pylint: disable=redefined-builtin
import tensorflow as tf

from tensorflow.models.rnn.translate import data_utils
#from tensorflow.models.rnn.translate import seq2seq_model
import seq2seq_model

# Flags for defining the tf.train.ClusterSpec
tf.app.flags.DEFINE_string(""ps_hosts"", """",
                           ""Comma-separated list of hostname:port pairs"")
tf.app.flags.DEFINE_string(""worker_hosts"", """",
                           ""Comma-separated list of hostname:port pairs"")

# Flags for defining the tf.train.Server
tf.app.flags.DEFINE_string(""job_name"", """", ""One of 'ps', 'worker'"")
tf.app.flags.DEFINE_integer(""task_index"", 0, ""Index of task within the job"")

tf.app.flags.DEFINE_float(""learning_rate"", 0.5, ""Learning rate."")
tf.app.flags.DEFINE_float(""learning_rate_decay_factor"", 0.99,
                          ""Learning rate decays by this much."")
tf.app.flags.DEFINE_float(""max_gradient_norm"", 5.0,
                          ""Clip gradients to this norm."")
tf.app.flags.DEFINE_integer(""batch_size"", 64,
                            ""Batch size to use during training."")
tf.app.flags.DEFINE_integer(""size"", 1024, ""Size of each model layer."")
tf.app.flags.DEFINE_integer(""num_layers"", 3, ""Number of layers in the model."")
tf.app.flags.DEFINE_integer(""en_vocab_size"", 40000, ""English vocabulary size."")
tf.app.flags.DEFINE_integer(""fr_vocab_size"", 40000, ""French vocabulary size."")
tf.app.flags.DEFINE_string(""data_dir"", ""/tmp/data"", ""Data directory"")
tf.app.flags.DEFINE_string(""train_dir"", ""/tmp"", ""Training directory."")
tf.app.flags.DEFINE_integer(""max_train_data_size"", 0,
                            ""Limit on the size of training data (0: no limit)."")
tf.app.flags.DEFINE_integer(""steps_per_checkpoint"", 200,
                            ""How many training steps to do per checkpoint."")
tf.app.flags.DEFINE_boolean(""decode"", False,
                            ""Set to True for interactive decoding."")
tf.app.flags.DEFINE_boolean(""self_test"", False,
                            ""Run a self-test if this is set to True."")

FLAGS = tf.app.flags.FLAGS

_buckets = [(5, 10), (10, 15), (20, 25), (40, 50)]

def main(_):
  if FLAGS.job_name is None or FLAGS.job_name == """":
    raise ValueError(""Must specify an explicit `job_name`"")
  if FLAGS.task_index is None or FLAGS.task_index =="""":
    raise ValueError(""Must specify an explicit `task_index`"")


  ps_hosts = FLAGS.ps_hosts.split("","")
  worker_hosts = FLAGS.worker_hosts.split("","")

  # Create a cluster from the parameter server and worker hosts.
  cluster = tf.train.ClusterSpec({""ps"": ps_hosts, ""worker"": worker_hosts})

  # Create and start a server for the local task.
  server = tf.train.Server(cluster, job_name=FLAGS.job_name, task_index=FLAGS.task_index)
  num_workers = len(worker_hosts)

  server = tf.train.Server(cluster, job_name=FLAGS.job_name, task_index=FLAGS.task_index)
  if FLAGS.job_name == ""ps"":
    server.join()
    return
  is_chief = (FLAGS.task_index == 0)
  model = seq2seq_model.Seq2SeqModel(server, FLAGS.en_vocab_size, FLAGS.fr_vocab_size, _buckets,
      FLAGS.size, FLAGS.num_layers, FLAGS.max_gradient_norm, FLAGS.batch_size,
      FLAGS.learning_rate, FLAGS.learning_rate_decay_factor,num_workers = num_workers, 
      task_index = FLAGS.task_index ,replicas_to_aggregate=num_workers, forward_only=False)
  step_time, loss = 0.0, 0.0
  current_step = 0
  previous_losses = []

  print(""query -> title:"")
  en_train = FLAGS.data_dir + ""/giga-fren.release2.ids40000.en""
  fr_train = FLAGS.data_dir + ""/giga-fren.release2.ids40000.fr""
  en_dev = FLAGS.data_dir + ""/newstest2013.ids40000.en""
  fr_dev = FLAGS.data_dir + ""/newstest2013.ids40000.fr""

  # Read data into buckets and compute their sizes.
  print (""Reading development and training data (limit: %d)."" % FLAGS.max_train_data_size)
  dev_set = read_data(en_dev, fr_dev)
  train_set = read_train_data(en_train, fr_train, num_workers, FLAGS.max_train_data_size)
  train_bucket_sizes = [len(train_set[b]) for b in xrange(len(_buckets))]
  train_total_size = float(sum(train_bucket_sizes))

  train_buckets_scale = [sum(train_bucket_sizes[:i + 1]) / train_total_size for i in xrange(len(train_bucket_sizes))]
  print(""finish to load data"")
  sess = model.session
  while True:
    random_number_01 = np.random.random_sample()
    bucket_id = min([i for i in xrange(len(train_buckets_scale)) if train_buckets_scale[i] > random_number_01])

    # Get a batch and make a step.
    start_time = time.time()
    encoder_inputs, decoder_inputs, target_weights = model.get_batch(train_set, bucket_id)
    _, step_loss, _ = model.step(sess, encoder_inputs, decoder_inputs, target_weights, bucket_id, False)
    step_time += (time.time() - start_time) / FLAGS.steps_per_checkpoint
    step_time_now = (time.time() - start_time)
    loss += step_loss / FLAGS.steps_per_checkpoint
    step_loss_now = step_loss
    current_step += 1
    print(""step: %d"" % current_step);

    if (True):
      perplexity = math.exp(step_loss) if step_loss < 300 else float('inf')
      print (""global step %d learning rate %.4f step-time %.2f perplexity ""
             ""%.2f"" % (model.global_step.eval(sess), model.learning_rate.eval(sess), step_time_now, perplexity))
      previous_losses.append(step_loss)

      checkpoint_path = os.path.join(train_dir, ""translate.ckpt"")
      model.saver.save(sess, checkpoint_path, global_step=model.global_step)
      if (current_step %  FLAGS.steps_per_checkpoint == 0):
        for bucket_id in xrange(len(_buckets)):
          if len(dev_set[bucket_id]) == 0:
            print(""  eval: empty bucket %d"" % (bucket_id))
            continue
          encoder_inputs, decoder_inputs, target_weights = model.get_batch(dev_set, bucket_id)
          _, eval_loss, _ = model.step(sess, encoder_inputs, decoder_inputs, target_weights, bucket_id, True)
          eval_ppx = math.exp(eval_loss) if eval_loss < 300 else float('inf')
          print(""  eval: bucket %d perplexity %.2f"" % (bucket_id, eval_ppx))
        step_time, loss = 0.0, 0.0
      sys.stdout.flush()


def read_train_data(source_path, target_path, num_workers, max_size=None):
  data_set = [[] for _ in _buckets]
  with tf.gfile.GFile(source_path, mode=""r"") as source_file:
    with tf.gfile.GFile(target_path, mode=""r"") as target_file:
      source, target = source_file.readline(), target_file.readline()
      counter = 0
      while source and target and (not max_size or counter < max_size):
        counter += 1
        if counter % 1000000 == 0:
          print(""  reading data line %d"" % counter)
          sys.stdout.flush()
        source_ids = [int(x) for x in source.split()]
        target_ids = [int(x) for x in target.split()]
        target_ids.append(data_utils.EOS_ID)
        # if (counter % num_workers == 0):
        if (True):
          for bucket_id, (source_size, target_size) in enumerate(_buckets):
            if len(source_ids) < source_size and len(target_ids) < target_size:
              data_set[bucket_id].append([source_ids, target_ids])
              break
        source, target = source_file.readline(), target_file.readline()
  return data_set

def read_data(source_path, target_path, max_size=None):
  data_set = [[] for _ in _buckets]
  with tf.gfile.GFile(source_path, mode=""r"") as source_file:
    with tf.gfile.GFile(target_path, mode=""r"") as target_file:
      source, target = source_file.readline(), target_file.readline()
      counter = 0
      while source and target and (not max_size or counter < max_size):
        counter += 1
        if counter % 100000 == 0:
          print(""  reading data line %d"" % counter)
          sys.stdout.flush()
        source_ids = [int(x) for x in source.split()]
        target_ids = [int(x) for x in target.split()]
        target_ids.append(data_utils.EOS_ID)
        for bucket_id, (source_size, target_size) in enumerate(_buckets):
          if len(source_ids) < source_size and len(target_ids) < target_size:
            data_set[bucket_id].append([source_ids, target_ids])
            break
        source, target = source_file.readline(), target_file.readline()
  return data_set

if __name__ == ""__main__"":
      tf.app.run()

seq2seq_model.py

# Copyright 2015 The TensorFlow Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# 

""""""Sequence-to-sequence model with an attention mechanism.""""""

from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import random

import numpy as np
from six.moves import xrange  # pylint: disable=redefined-builtin
import tensorflow as tf

from tensorflow.models.rnn.translate import data_utils


class Seq2SeqModel(object):

  def __init__(self,
               server,
               source_vocab_size,
               target_vocab_size,
               buckets,
               size,
               num_layers,
               max_gradient_norm,
               batch_size,
               learning_rate,
               learning_rate_decay_factor,
               num_workers=2, 
               task_index=0,
               replicas_to_aggregate=2,
               use_lstm=False,
               num_samples=512,
               forward_only=False,
               dtype=tf.float32):

    self.graph = tf.Graph()
    self.server = server
    self.source_vocab_size = source_vocab_size
    self.target_vocab_size = target_vocab_size
    self.buckets = buckets
    self.batch_size = batch_size
    self.num_workers = num_workers 
    self.task_index = task_index
    self.is_chief = (task_index == 0)
    self.num_workers = num_workers
    self.replicas_to_aggregate = replicas_to_aggregate

    with self.graph.as_default():
      with tf.device(""/job:ps/task:0""): 
        self.global_step = tf.Variable(0, trainable=False)
        self.learning_rate = tf.Variable(
            float(learning_rate), trainable=False, dtype=dtype)
  
      output_projection = None
      softmax_loss_function = None
      # Sampled softmax only makes sense if we sample less than vocabulary size.
      if num_samples > 0 and num_samples < self.target_vocab_size:
        with tf.device(""/job:ps/task:0""): 
          w_t = tf.get_variable(""proj_w"", [self.target_vocab_size, size], dtype=dtype)
          w = tf.transpose(w_t)
          b = tf.get_variable(""proj_b"", [self.target_vocab_size], dtype=dtype)
        output_projection = (w, b)
  
        def sampled_loss(inputs, labels):
          with tf.device(""/job:worker/task:""+str(self.task_index)):
            labels = tf.reshape(labels, [-1, 1])
            # We need to compute the sampled_softmax_loss using 32bit floats to
            # avoid numerical instabilities.
            local_w_t = tf.cast(w_t, tf.float32)
            local_b = tf.cast(b, tf.float32)
            local_inputs = tf.cast(inputs, tf.float32)
            return tf.cast(
                tf.nn.sampled_softmax_loss(local_w_t, local_b, local_inputs, labels,
                                           num_samples, self.target_vocab_size),
                dtype)
        softmax_loss_function = sampled_loss
  
      # Create the internal multi-layer cell for our RNN.
      with tf.device(""/job:worker/task:""+str(self.task_index)):
        single_cell = tf.nn.rnn_cell.GRUCell(size)
        if use_lstm:
          single_cell = tf.nn.rnn_cell.BasicLSTMCell(size)
        cell = single_cell
        if num_layers > 1:
          cell = tf.nn.rnn_cell.MultiRNNCell([single_cell] * num_layers)
  
      # The seq2seq function: we use embedding for the input and attention.
      def seq2seq_f(encoder_inputs, decoder_inputs, do_decode):
        with tf.device(""/job:worker/task:""+str(self.task_index)):
          return tf.nn.seq2seq.embedding_attention_seq2seq(
              encoder_inputs,
              decoder_inputs,
              cell,
              num_encoder_symbols=source_vocab_size,
              num_decoder_symbols=target_vocab_size,
              embedding_size=size,
              output_projection=output_projection,
              feed_previous=do_decode,
              dtype=dtype)

      # Feeds for inputs.
      with tf.device(""/job:worker/task:""+str(self.task_index)):
        self.encoder_inputs = []
        self.decoder_inputs = []
        self.target_weights = []
        for i in xrange(buckets[-1][0]):  # Last bucket is the biggest one.
          self.encoder_inputs.append(tf.placeholder(tf.int32, shape=[None],
                                                    name=""encoder{0}"".format(i)))
        for i in xrange(buckets[-1][1] + 1):
          self.decoder_inputs.append(tf.placeholder(tf.int32, shape=[None],
                                                    name=""decoder{0}"".format(i)))
          self.target_weights.append(tf.placeholder(dtype, shape=[None],
                                                    name=""weight{0}"".format(i)))
  
        # Our targets are decoder inputs shifted by one.
        targets = [self.decoder_inputs[i + 1]
                   for i in xrange(len(self.decoder_inputs) - 1)]
        if forward_only:
          self.outputs, self.losses = tf.nn.seq2seq.model_with_buckets(
              self.encoder_inputs, self.decoder_inputs, targets,
              self.target_weights, buckets, lambda x, y: seq2seq_f(x, y, True),
              softmax_loss_function=softmax_loss_function)
          # If we use output projection, we need to project outputs for decoding.
          if output_projection is not None:
            for b in xrange(len(buckets)):
              self.outputs[b] = [
                  tf.matmul(output, output_projection[0]) + output_projection[1]
                  for output in self.outputs[b]
              ]
        else:
          self.outputs, self.losses = tf.nn.seq2seq.model_with_buckets(
              self.encoder_inputs, self.decoder_inputs, targets,
              self.target_weights, buckets,
              lambda x, y: seq2seq_f(x, y, False),
              softmax_loss_function=softmax_loss_function)
  
        # Gradients and SGD update operation for training the model.
      with tf.device(""/job:worker/task:""+str(self.task_index)):
        params = tf.trainable_variables()
        self.gradient_norms = []
        self.updates = []
      #sync_rep_opt = tf.train.AdamOptimizer(self.learning_rate)
        sgd_opt = tf.train.GradientDescentOptimizer(2.0)
        sync_rep_opt = tf.train.SyncReplicasOptimizerV2(
            sgd_opt, replicas_to_aggregate=replicas_to_aggregate,
            total_num_replicas=num_workers)
        for b in xrange(len(buckets)):
          gradients = tf.gradients(self.losses[b], params)
          clipped_gradients, norm = tf.clip_by_global_norm(gradients,
                                                           max_gradient_norm)
          self.gradient_norms.append(norm)
          self.updates.append(sync_rep_opt.apply_gradients(
              zip(clipped_gradients, params), global_step=self.global_step))

        init_op = tf.global_variables_initializer()
        local_init_op = sync_rep_opt.local_step_init_op
        if self.is_chief:
          local_init_op = sync_rep_opt.chief_init_op
        ready_for_local_init_op = sync_rep_opt.ready_for_local_init_op

        # Chief_queue_runner
        chief_queue_runner = sync_rep_opt.get_chief_queue_runner()
        sync_init_op = sync_rep_opt.get_init_tokens_op(num_workers)

    # Creates session for chief.
    supervisor = tf.train.Supervisor(
        graph=self.graph,
        is_chief=self.is_chief,
        recovery_wait_secs=1,
        init_op=init_op,
        local_init_op=local_init_op,
        ready_for_local_init_op=ready_for_local_init_op)

    sess_config = tf.ConfigProto(
        allow_soft_placement=True,
        log_device_placement=True,
        device_filters=[""/job:ps"", ""/job:worker/task:%d"" % self.task_index])


    self.session = supervisor.prepare_or_wait_for_session(self.server.target, config=sess_config)

    # Chief should execute the sync_init_op and start the chief queue runner.
    if self.is_chief:
      self.session.run(sync_init_op)
      supervisor.StartQueueRunners(self.session, [chief_queue_runner])

    if self.is_chief:
      self.session.run(sync_init_op)
      supervisor.StartQueueRunners(self.session, [chief_queue_runner])


  def step(self, session, encoder_inputs, decoder_inputs, target_weights,
           bucket_id, forward_only):
    """"""Run a step of the model feeding the given inputs.

    Args:
      session: tensorflow session to use.
      encoder_inputs: list of numpy int vectors to feed as encoder inputs.
      decoder_inputs: list of numpy int vectors to feed as decoder inputs.
      target_weights: list of numpy float vectors to feed as target weights.
      bucket_id: which bucket of the model to use.
      forward_only: whether to do the backward step or only forward.

    Returns:
      A triple consisting of gradient norm (or None if we did not do backward),
      average perplexity, and the outputs.

    Raises:
      ValueError: if length of encoder_inputs, decoder_inputs, or
        target_weights disagrees with bucket size for the specified bucket_id.
    """"""
    # Check if the sizes match.
    encoder_size, decoder_size = self.buckets[bucket_id]
    if len(encoder_inputs) != encoder_size:
      raise ValueError(""Encoder length must be equal to the one in bucket,""
                       "" %d != %d."" % (len(encoder_inputs), encoder_size))
    if len(decoder_inputs) != decoder_size:
      raise ValueError(""Decoder length must be equal to the one in bucket,""
                       "" %d != %d."" % (len(decoder_inputs), decoder_size))
    if len(target_weights) != decoder_size:
      raise ValueError(""Weights length must be equal to the one in bucket,""
                       "" %d != %d."" % (len(target_weights), decoder_size))

    # Input feed: encoder inputs, decoder inputs, target_weights, as provided.
    input_feed = {}
    for l in xrange(encoder_size):
      input_feed[self.encoder_inputs[l].name] = encoder_inputs[l]
    for l in xrange(decoder_size):
      input_feed[self.decoder_inputs[l].name] = decoder_inputs[l]
      input_feed[self.target_weights[l].name] = target_weights[l]

    # Since our targets are decoder inputs shifted by one, we need one more.
    last_target = self.decoder_inputs[decoder_size].name
    input_feed[last_target] = np.zeros([self.batch_size], dtype=np.int32)

    # Output feed: depends on whether we do a backward step or not.
    if not forward_only:
      output_feed = [self.updates[bucket_id],  # Update Op that does SGD.
                     self.gradient_norms[bucket_id],  # Gradient norm.
                     self.losses[bucket_id]]  # Loss for this batch.
    else:
      output_feed = [self.losses[bucket_id]]  # Loss for this batch.
      for l in xrange(decoder_size):  # Output logits.
        output_feed.append(self.outputs[bucket_id][l])

    outputs = session.run(output_feed, input_feed)
    if not forward_only:
      return outputs[1], outputs[2], None  # Gradient norm, loss, no outputs.
    else:
      return None, outputs[0], outputs[1:]  # No gradient norm, loss, outputs.

  def get_batch(self, data, bucket_id):
    """"""Get a random batch of data from the specified bucket, prepare for step.

    To feed data in step(..) it must be a list of batch-major vectors, while
    data here contains single length-major cases. So the main logic of this
    function is to re-index data cases to be in the proper format for feeding.

    Args:
      data: a tuple of size len(self.buckets) in which each element contains
        lists of pairs of input and output data that we use to create a batch.
      bucket_id: integer, which bucket to get the batch for.

    Returns:
      The triple (encoder_inputs, decoder_inputs, target_weights) for
      the constructed batch that has the proper format to call step(...) later.
    """"""
    encoder_size, decoder_size = self.buckets[bucket_id]
    encoder_inputs, decoder_inputs = [], []

    # Get a random batch of encoder and decoder inputs from data,
    # pad them if needed, reverse encoder inputs and add GO to decoder.
    for _ in xrange(self.batch_size):
      encoder_input, decoder_input = random.choice(data[bucket_id])

      # Encoder inputs are padded and then reversed.
      encoder_pad = [data_utils.PAD_ID] * (encoder_size - len(encoder_input))
      encoder_inputs.append(list(reversed(encoder_input + encoder_pad)))

      # Decoder inputs get an extra ""GO"" symbol, and are padded then.
      decoder_pad_size = decoder_size - len(decoder_input) - 1
      decoder_inputs.append([data_utils.GO_ID] + decoder_input +
                            [data_utils.PAD_ID] * decoder_pad_size)

    # Now we create batch-major vectors from the data selected above.
    batch_encoder_inputs, batch_decoder_inputs, batch_weights = [], [], []

    # Batch encoder inputs are just re-indexed encoder_inputs.
    for length_idx in xrange(encoder_size):
      batch_encoder_inputs.append(
          np.array([encoder_inputs[batch_idx][length_idx]
                    for batch_idx in xrange(self.batch_size)], dtype=np.int32))

    # Batch decoder inputs are re-indexed decoder_inputs, we create weights.
    for length_idx in xrange(decoder_size):
      batch_decoder_inputs.append(
          np.array([decoder_inputs[batch_idx][length_idx]
                    for batch_idx in xrange(self.batch_size)], dtype=np.int32))

      # Create target_weights to be 0 for targets that are padding.
      batch_weight = np.ones(self.batch_size, dtype=np.float32)
      for batch_idx in xrange(self.batch_size):
        # We set weight to 0 if the corresponding target is a PAD symbol.
        # The corresponding target is decoder_input shifted by 1 forward.
        if length_idx < decoder_size - 1:
          target = decoder_inputs[batch_idx][length_idx + 1]
        if length_idx == decoder_size - 1 or target == data_utils.PAD_ID:
          batch_weight[batch_idx] = 0.0
      batch_weights.append(batch_weight)
    return batch_encoder_inputs, batch_decoder_inputs, batch_weights

"
5997,Please update the optimized protobuf binary library recommended on tensorflow.org,"The following page [1] describes how to use the optimized protobuf binary to allow for large protos. Recently the protobuf library removed the limit on the proto size once and for all [2]. 

This should fix some of the issues still being reported on #582. 

Could you please update the binary to the latest version and the documentation if applicable?

Thanks

[1] https://www.tensorflow.org/versions/r0.12/get_started/os_setup.html#protobuf-library-related-issues
[2] https://github.com/google/protobuf/commit/5a76e633ea9b5adb215e93fdc11e1c0c08b3fc74#diff-922cc541c2d97d0ca70fce2b001de379R640"
5995,GPU MUCH slower than CPU,"GPU training is MUCH slower than CPU training. It's possible I'm doing something wrong. If I'm not I can gather more data on this. The data set is pretty small and it slows to a crawl. GPU usage is around 2-5%, It fills up the memory in the GPU pretty quickly to 90% but the PCIe Bandwidth Utilization is 1%. My CPU and Memory usage are otherwise minimal.

My setup: 32gb ram, 8 core 4.3 Ghz processor, (2) GTX 660's, 367.57 Nvidia Driver, Cuda Toolkit 7.5, cudnn 7.5, Python 2.7. Tensorflow matches 7.5.

I can take exact time measurements later if needed but I would guess GPU is about 10x slower if not more than the CPU training.

```
pprint.pprint(len(X))
pprint.pprint(len(Y))

net = tflearn.input_data(shape=[None, 7])
net = tflearn.fully_connected(net, 32)
net = tflearn.fully_connected(net, 32)
net = tflearn.fully_connected(net, 2, activation='softmax')
net = tflearn.regression(net)

model = tflearn.DNN(net)
model.fit(X, Y, n_epoch=100, batch_size=16, show_metric=True)

model.save(""model.tfl"")
```

```
camj256@camj256:~/PycharmProjects/DeepLearning$ python build.py 
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so locally
Exceptions: 0
3003
3003
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:925] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties: 
name: GeForce GTX 660
major: 3 minor: 0 memoryClockRate (GHz) 1.0975
pciBusID 0000:02:00.0
Total memory: 1.99GiB
Free memory: 1.27GiB
W tensorflow/stream_executor/cuda/cuda_driver.cc:572] creating context when one is currently active; existing: 0x2af5d00
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:925] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 1 with properties: 
name: GeForce GTX 660
major: 3 minor: 0 memoryClockRate (GHz) 1.0975
pciBusID 0000:01:00.0
Total memory: 1.99GiB
Free memory: 1.24GiB
I tensorflow/core/common_runtime/gpu/gpu_init.cc:59] cannot enable peer access from device ordinal 0 to device ordinal 1
I tensorflow/core/common_runtime/gpu/gpu_init.cc:59] cannot enable peer access from device ordinal 1 to device ordinal 0
I tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0 1 
I tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y N 
I tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 1:   N Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:838] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 660, pci bus id: 0000:02:00.0)
I tensorflow/core/common_runtime/gpu/gpu_device.cc:838] Creating TensorFlow device (/gpu:1) -> (device: 1, name: GeForce GTX 660, pci bus id: 0000:01:00.0)
I tensorflow/core/common_runtime/gpu/gpu_device.cc:838] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 660, pci bus id: 0000:02:00.0)
I tensorflow/core/common_runtime/gpu/gpu_device.cc:838] Creating TensorFlow device (/gpu:1) -> (device: 1, name: GeForce GTX 660, pci bus id: 0000:01:00.0)
---------------------------------
Run id: 17E6I9
Log directory: /tmp/tflearn_logs/
---------------------------------
Training samples: 3003
Validation samples: 0
```


"
5994,build failure,"Attempting to install master on a SLES11sp3 system under
gcc-4.9.3
Python 3.5.1
bazel-0.4.1

TensorFlow hash is
git rev-parse HEAD
a70a2d9f0e7d34e36018e83e4b17c45a26a2f3dc

Seems similar to
https://groups.google.com/a/tensorflow.org/forum/#!topic/discuss/Tm5ztabIUCw

./configure
~/play/TensorFlow/tensorflow ~/play/TensorFlow/tensorflow
Please specify the location of python. [Default is /usr/bin/python]: /nasa/pkgsrc/2016Q2/bin/python3.5
Do you wish to build TensorFlow with Google Cloud Platform support? [y/N] N
No Google Cloud Platform support will be enabled for TensorFlow
Do you wish to build TensorFlow with Hadoop File System support? [y/N] N
No Hadoop File System support will be enabled for TensorFlow
Found possible Python library paths:
  /nasa/pkgsrc/2016Q2/lib/python3.5/site-packages
Please input the desired Python library path to use.  Default is [/nasa/pkgsrc/2016Q2/lib/python3.5/site-packages]

Using python library path: /nasa/pkgsrc/2016Q2/lib/python3.5/site-packages
Do you wish to build TensorFlow with OpenCL support? [y/N] N
No OpenCL support will be enabled for TensorFlow
Do you wish to build TensorFlow with CUDA support? [y/N] y
CUDA support will be enabled for TensorFlow
Please specify which gcc should be used by nvcc as the host compiler. [Default is /nasa/pkgsrc/2015Q4/gcc49/bin/gcc]: 
Please specify the CUDA SDK version you want to use, e.g. 7.0. [Leave empty to use system default]: 7.5
Please specify the location where CUDA 7.5 toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: /nasa/cuda/7.5
Please specify the Cudnn version you want to use. [Leave empty to use system default]: 5
Please specify the location where cuDNN 5 library is installed. Refer to README.md for more details. [Default is /nasa/cuda/7.5]: /u/dkokron/play/cuDNN/cuda
Please specify a list of comma-separated Cuda compute capabilities you want to build with.
You can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.
Please note that each additional compute capability significantly increases your build time and binary size.
[Default is: ""3.5,5.2""]: 3.5
..........
INFO: Starting clean (this may take a while). Consider using --expunge_async if the clean takes more than several minutes.
..........
INFO: All external dependencies fetched successfully.
Configuration finished


bazel --output_base=/tmp/dkokron build -c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package
WARNING: Sandboxed execution is not supported on your system and thus hermeticity of actions cannot be guaranteed. See http://bazel.build/docs/bazel-user-manual.html#sandboxing for more information. You can turn off this warning via --ignore_unsupported_sandboxing.
INFO: Found 1 target...
ERROR: /home6/dkokron/play/TensorFlow/tensorflow/tensorflow/core/BUILD:1121:1: Executing genrule //tensorflow/core:version_info_gen failed: bash failed: error executing command /bin/bash -c ... (remaining 1 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.
Traceback (most recent call last):
  File ""tensorflow/tools/git/gen_git_source.py"", line 260, in <module>
    generate(args.generate)
  File ""tensorflow/tools/git/gen_git_source.py"", line 212, in generate
    git_version = get_git_version(data[""path""])
  File ""tensorflow/tools/git/gen_git_source.py"", line 150, in get_git_version
    val = bytes(subprocess.check_output([
AttributeError: 'module' object has no attribute 'check_output'
Target //tensorflow/tools/pip_package:build_pip_package failed to build
Use --verbose_failures to see the command lines of failed build steps.
INFO: Elapsed time: 2.236s, Critical Path: 1.79s

ll /nasa/cuda/7.5/lib64/libcu*
lrwxrwxrwx 1 hsp cstaff        16 Feb 11  2016 /nasa/cuda/7.5/lib64/libcublas.so -> libcublas.so.7.5
lrwxrwxrwx 1 hsp cstaff        19 Feb 11  2016 /nasa/cuda/7.5/lib64/libcublas.so.7.5 -> libcublas.so.7.5.18
-rwxr-xr-x 1 hsp cstaff  23938736 Feb 11  2016 /nasa/cuda/7.5/lib64/libcublas.so.7.5.18
-rw-r--r-- 1 hsp cstaff  28585480 Feb 11  2016 /nasa/cuda/7.5/lib64/libcublas_device.a
-rw-r--r-- 1 hsp cstaff  28220076 Feb 11  2016 /nasa/cuda/7.5/lib64/libcublas_static.a
-rw-r--r-- 1 hsp cstaff    322936 Feb 11  2016 /nasa/cuda/7.5/lib64/libcudadevrt.a
lrwxrwxrwx 1 hsp cstaff        16 Feb 11  2016 /nasa/cuda/7.5/lib64/libcudart.so -> libcudart.so.7.5
lrwxrwxrwx 1 hsp cstaff        19 Feb 11  2016 /nasa/cuda/7.5/lib64/libcudart.so.7.5 -> libcudart.so.7.5.18
-rwxr-xr-x 1 hsp cstaff    383336 Feb 11  2016 /nasa/cuda/7.5/lib64/libcudart.so.7.5.18
-rw-r--r-- 1 hsp cstaff    720192 Feb 11  2016 /nasa/cuda/7.5/lib64/libcudart_static.a
lrwxrwxrwx 1 hsp cstaff        15 Feb 11  2016 /nasa/cuda/7.5/lib64/libcufft.so -> libcufft.so.7.5
lrwxrwxrwx 1 hsp cstaff        18 Feb 11  2016 /nasa/cuda/7.5/lib64/libcufft.so.7.5 -> libcufft.so.7.5.18
-rwxr-xr-x 1 hsp cstaff 111231960 Feb 11  2016 /nasa/cuda/7.5/lib64/libcufft.so.7.5.18
-rw-r--r-- 1 hsp cstaff 115104400 Feb 11  2016 /nasa/cuda/7.5/lib64/libcufft_static.a
lrwxrwxrwx 1 hsp cstaff        16 Feb 11  2016 /nasa/cuda/7.5/lib64/libcufftw.so -> libcufftw.so.7.5
lrwxrwxrwx 1 hsp cstaff        19 Feb 11  2016 /nasa/cuda/7.5/lib64/libcufftw.so.7.5 -> libcufftw.so.7.5.18
-rwxr-xr-x 1 hsp cstaff    447664 Feb 11  2016 /nasa/cuda/7.5/lib64/libcufftw.so.7.5.18
-rw-r--r-- 1 hsp cstaff     42206 Feb 11  2016 /nasa/cuda/7.5/lib64/libcufftw_static.a
lrwxrwxrwx 1 hsp cstaff        17 Feb 11  2016 /nasa/cuda/7.5/lib64/libcuinj64.so -> libcuinj64.so.7.5
lrwxrwxrwx 1 hsp cstaff        20 Feb 11  2016 /nasa/cuda/7.5/lib64/libcuinj64.so.7.5 -> libcuinj64.so.7.5.18
-rwxr-xr-x 1 hsp cstaff   5751400 Feb 11  2016 /nasa/cuda/7.5/lib64/libcuinj64.so.7.5.18
-rw-r--r-- 1 hsp cstaff   1649726 Feb 11  2016 /nasa/cuda/7.5/lib64/libculibos.a
lrwxrwxrwx 1 hsp cstaff        16 Feb 11  2016 /nasa/cuda/7.5/lib64/libcurand.so -> libcurand.so.7.5
lrwxrwxrwx 1 hsp cstaff        19 Feb 11  2016 /nasa/cuda/7.5/lib64/libcurand.so.7.5 -> libcurand.so.7.5.18
-rwxr-xr-x 1 hsp cstaff  51765952 Feb 11  2016 /nasa/cuda/7.5/lib64/libcurand.so.7.5.18
-rw-r--r-- 1 hsp cstaff  51992564 Feb 11  2016 /nasa/cuda/7.5/lib64/libcurand_static.a
lrwxrwxrwx 1 hsp cstaff        18 Feb 11  2016 /nasa/cuda/7.5/lib64/libcusolver.so -> libcusolver.so.7.5
lrwxrwxrwx 1 hsp cstaff        21 Feb 11  2016 /nasa/cuda/7.5/lib64/libcusolver.so.7.5 -> libcusolver.so.7.5.18
-rwxr-xr-x 1 hsp cstaff  37034328 Feb 11  2016 /nasa/cuda/7.5/lib64/libcusolver.so.7.5.18
-rw-r--r-- 1 hsp cstaff  16613348 Feb 11  2016 /nasa/cuda/7.5/lib64/libcusolver_static.a
lrwxrwxrwx 1 hsp cstaff        18 Feb 11  2016 /nasa/cuda/7.5/lib64/libcusparse.so -> libcusparse.so.7.5
lrwxrwxrwx 1 hsp cstaff        21 Feb 11  2016 /nasa/cuda/7.5/lib64/libcusparse.so.7.5 -> libcusparse.so.7.5.18
-rwxr-xr-x 1 hsp cstaff  36816424 Feb 11  2016 /nasa/cuda/7.5/lib64/libcusparse.so.7.5.18
-rw-r--r-- 1 hsp cstaff  44445334 Feb 11  2016 /nasa/cuda/7.5/lib64/libcusparse_static.a

ll /u/dkokron/play/cuDNN/cuda/lib64/
total 117596
lrwxrwxrwx 1 dkokron scicon       13 Jun 10 01:20 libcudnn.so -> libcudnn.so.5
lrwxrwxrwx 1 dkokron scicon       17 Jun 10 01:20 libcudnn.so.5 -> libcudnn.so.5.1.3
-rwx------ 1 dkokron scicon 60696704 Jun 10 01:18 libcudnn.so.5.1.3
-rw------- 1 dkokron scicon 59715990 Jun 10 01:18 libcudnn_static.a

"
5990,iOS: No OpKernel for Pow op,"We're running a model on iOS and finding that the `tf.pow` Pow op is not supported; we added a line with `tensorflow/core/kernels/cwise_op_pow.cc` to `tensorflow/contrib/makefile/tf_op_files.txt`, rebuild TensorFlow, and after that, the model worked.

Could this op be added to the iOS makefile so that in the future other folks do not run into this problem?

(I would submit a PR but this is at a company that has not signed the TensorFlow CLA so for such a small change it is not worth the hassle.)
"
5989,RuntimeError for minimal RNNCell example,"I am just trying to get a simple RNNCell to work. This simple code:

    with tf.Session() as sess:
        x = tf.Variable(np.ones((2, 3)))
        tf.global_variables_initializer().run()
        out, state = BasicRNNCell(4)(x, x)

Throws the following error:

    /Users/ethan/env/bin/python /Users/ethan/tf-bug/main.py
    Traceback (most recent call last):
      File ""/Users/ethan/tf-bug/main.py"", line 8, in <module>
        out, state = BasicRNNCell(4)(x, x)
      File ""/Users/ethan/env/lib/python2.7/site-packages/tensorflow/python/ops/rnn_cell.py"", line 200, in __call__
        output = self._activation(_linear([inputs, state], self._num_units, True))
      File ""/Users/ethan/env/lib/python2.7/site-packages/tensorflow/python/ops/rnn_cell.py"", line 905, in _linear
        ""Matrix"", [total_arg_size, output_size], dtype=dtype)
      File ""/Users/ethan/env/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py"", line 1024, in get_variable
        custom_getter=custom_getter)
      File ""/Users/ethan/env/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py"", line 850, in get_variable
        custom_getter=custom_getter)
      File ""/Users/ethan/env/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py"", line 346, in get_variable
        validate_shape=validate_shape)
      File ""/Users/ethan/env/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py"", line 331, in _true_getter
        caching_device=caching_device, validate_shape=validate_shape)
      File ""/Users/ethan/env/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py"", line 677, in _get_single_variable
        expected_shape=shape)
      File ""/Users/ethan/env/lib/python2.7/site-packages/tensorflow/python/ops/variables.py"", line 224, in __init__
        expected_shape=expected_shape)
      File ""/Users/ethan/env/lib/python2.7/site-packages/tensorflow/python/ops/variables.py"", line 327, in _init_from_args
        initial_value(), name=""initial_value"", dtype=dtype)
      File ""/Users/ethan/env/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.py"", line 665, in <lambda>
        shape.as_list(), dtype=dtype, partition_info=partition_info)
      File ""/Users/ethan/env/lib/python2.7/site-packages/tensorflow/python/ops/init_ops.py"", line 284, in _initializer
        dtype, seed=seed)
      File ""/Users/ethan/env/lib/python2.7/site-packages/tensorflow/python/ops/random_ops.py"", line 231, in random_uniform
        minval = ops.convert_to_tensor(minval, dtype=dtype, name=""min"")
      File ""/Users/ethan/env/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 683, in convert_to_tensor
        dtype.name, ret.dtype.name))
    RuntimeError: min: Conversion function <function _constant_tensor_conversion_function at 0x10cb461b8> for type <type 'object'> returned incompatible dtype: requested = float64_ref, actual = float64

    Process finished with exit code 1

This is the output of `pip show tensorflow`:

 > Name: tensorflow
 > Version: 0.12.0rc0
 > Summary: TensorFlow helps the tensors flow
 > Home-page: http://tensorflow.org/
 > Author: Google Inc.
 > Author-email: opensource@google.com
 > License: Apache 2.0
 > Location: /Users/ethan/env/lib/python2.7/site-packages
 > Requires: numpy, mock, wheel, six, protobuf


Thanks!
"
5988,fused_batch_norm throws ValueError for partially known 2D-Tensor,"I'm trying to use the new fused_batch_norm layer (as I also have this problem #3290)
Using it for 4D Tensors works fine so far (as in: it doens't crash)
However, when using 2D Tensors ([None, X]) I get this error:


> Traceback (most recent call last):
...
  File ""/home/userName/.local/lib/python2.7/site-packages/tensorflow/contrib/framework/python/ops/arg_scope.py"", line 177, in func_with_args
    return func(*args, **current_args)
  File ""/home/userName/.local/lib/python2.7/site-packages/tensorflow/contrib/layers/python/layers/layers.py"", line 467, in batch_norm
    scope=scope)
  File ""/home/userName/.local/lib/python2.7/site-packages/tensorflow/contrib/layers/python/layers/layers.py"", line 350, in _fused_batch_norm
    outputs = array_ops.reshape(outputs, original_shape)
  File ""/home/userName/.local/lib/python2.7/site-packages/tensorflow/python/ops/gen_array_ops.py"", line 2448, in reshape
    name=name)
  File ""/home/userName/.local/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py"", line 503, in apply_op
    as_ref=input_arg.is_ref).dtype.name
  File ""/home/userName/.local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 669, in convert_to_tensor
    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
  File ""/home/userName/.local/lib/python2.7/site-packages/tensorflow/python/framework/constant_op.py"", line 194, in _tensor_shape_tensor_conversion_function
    ""Cannot convert a partially known TensorShape to a Tensor: %s"" % s)
ValueError: Cannot convert a partially known TensorShape to a Tensor: (?, 256)

Same code works for the normal batch_norm layer.
Also works if I reshape it manually to [None, 1, 1, X] before calling fused_batch_norm

Cuda 8.0, cuDNN 5.1, tf r0.12"
5987,"Request for documentation on recommended flow in slim for train, validation, and test sets","The examples in the [slim README.md](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/slim) give basic documentation for training and evaluating models when used separately; however, there is guidance missing on how to do the classic cycle of mini-batch gradient descent using shuffled subsets of the training set, periodically evaluating validation set, and then evaluating on the test set post-training. 

Using the [MNIST tutorial](https://www.tensorflow.org/versions/r0.12/tutorials/mnist/tf/index.html) and [this tutorial](https://github.com/mnuke/tf-slim-mnist) for reference, the best I came up with was something like this where I'm effectively monkey-patching the train_step_fn to periodically output accuracies: 

```
from tensorflow.contrib.slim.python.slim.learning import train_step

graph = tf.Graph()
with graph.as_default():
  image, label = input('train', FLAGS.dataset_dir)
  images, labels = tf.train.shuffle_batch([image, label], batch_size=FLAGS.batch_size, capacity=1000 + 3 * FLAGS.batch_size, min_after_dequeue=1000)
  images_validation, labels_validation = inputs('validation', FLAGS.dataset_dir, 5000)
  images_test, labels_test = inputs('test', FLAGS.dataset_dir, 10000)
 
  with tf.variable_scope(""model"") as scope:
    predictions = model(images, FLAGS)
    scope.reuse_variables()
    predictions_validation = model(images_validation, FLAGS)
    predictions_test = model(images_test, FLAGS)
    
  slim.losses.softmax_cross_entropy(predictions, labels)
  optimizer = tf.train.AdamOptimizer(FLAGS.learning_rate)
  train_op = slim.learning.create_train_op(slim.losses.get_total_loss(), optimizer)

  accuracy_validation = slim.metrics.accuracy(tf.to_int32(tf.argmax(predictions_validation, 1)), tf.to_int32(tf.argmax(labels_validation, 1)))
  accuracy_test = slim.metrics.accuracy(tf.to_int32(tf.argmax(predictions_test, 1)), tf.to_int32(tf.argmax(labels_test, 1)))
    
def train_step_fn(session, *args, **kwargs):
  total_loss, should_stop = train_step(session, *args, **kwargs)

  if train_step_fn.step % FLAGS.validation_check == 0:
    accuracy = session.run(train_step_fn.accuracy_validation)
    print('Step %s - Loss: %.2f Accuracy: %.2f%%' % (str(train_step_fn.step).rjust(6, '0'), total_loss, accuracy * 100))

  if train_step_fn.step == (FLAGS.max_steps - 1):
    accuracy = session.run(accuracy_test)
    print('%s - Loss: %.2f Accuracy: %.2f%%' % ('FINAL TEST', total_loss, accuracy * 100))
    
  train_step_fn.step += 1
  return [total_loss, should_stop]

train_step_fn.step = 0
train_step_fn.accuracy_validation = accuracy_validation

slim.learning.train(
  train_op,
  FLAGS.logs_dir,
  train_step_fn=train_step_fn,
  graph=graph,
  number_of_steps=FLAGS.max_steps
)
```

**Note**: one problem with this implementation is that the final test set is not guaranteed to be run in the case of early exit.
 
I've posted in the slack channel and Googled around, but haven't been able to find any examples for this basic use case. Accordingly, I would like to propose that an example providing the best practice to periodically evaluate batch trained models using the validate set and the trained model against the test set to be added to the slim README.md.

I think it would really help the community to have a clearer idea on the intentions of the slim team on how the batch training and evaluation paths were designed to be used together during and after training.
"
5986,"TensorFlow on Windows logs an error when using GPUs: ""Could not identify NUMA node""","I use one GPU card now,  tensorflow(0.12) reports follow error, but the process run correctly.   How to suport  if we use multi-gpu on windows ?

E c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core\common_runtime\gpu\gpu_device.cc:586] Could not identify NUMA node of /job:localhost/replica:0/task:0/gpu:0, defaulting to 0.  Your kernel may not have been built with NUMA support.

"
5985,None gradient from GRU,"Hello everybody,

**Introduction:**
I am trying to reproduce the work of Szegedy et al: [Intriguing properties of neural networks](https://arxiv.org/abs/1312.6199) and Dezfooli et al: [Universal adversarial perturbations](https://arxiv.org/abs/1610.08401). What they do, briefly, is that they take the gradient `g` of the network with respect to the input image `x`, then slightly modify the input image `x` ""against"" the obtained gradient, i.e. `x-0.001g`. The modified images are consequently considered as another network input, hence new gradients `g'` might be computed and obtained. The result gradients are manually set to the average of those two set obtains gradients, i.e. `g/2 + g'/2`. I hope I explained that clearly.

I successfully implemented it for images in TF 0.10 (working on 0.12RC as well). Now I want to do something similar with recurrent networks (sentiment analysis task). So I have a input sequence of tokens (numbers), a variable `embeddings` which is used by `tf.nn.embedding_lookup`. After the lookup, the sequence of proper embeddings is traversed by GRU (dynamically). It's last state is considered as the representation of the sequence. Then a MLP with a single hidden layer and ReLU activation is applied, resulting in 2 neurons representing the positive and negative logits respectively. The loss is traditional categorical cross entropy.

**Bug**
Similarly to the papers mentioned above, I obtain gradients of the embedding, and modify the current embeddings slightly ""against"" the obtained gradient. Than I compute the new loss and _new gradients (here is the problem!)_ and update the network by their mean.

The problem is that the returned _new gradients_ are all `None`s. I originally worked with TF 0.10, however, I got an error explaining that second order derivatives are impossible to obtain from scan. I upgraded to recently released TF 0.12RC which doesn't throw this error but returns `None`s instead.

**Related Issues and SOs**
#783 is somewhat similar, but not the same. [This question](http://stackoverflow.com/questions/36874522/tensorflow-gradients) deals with very the same problem  but the solution isn't sufficient as replacing the `None` value with zero is really worthless in my case since I need to modify the variable against the gradient.

**Minimal Not-Working Example**
I am sorry the code is so long. It is partially caused by the fact that the problem is non-trivial and requires few lines and partially by the amount of comments I tried to write in order to make the code more readable. All platform/version information is stored at beginning of the file.

The `main()` function constructs two `SimpleSentiment`s as the models that are trained. Each one is trained for few epochs and batches. First instance is without the adversarial, hence we perform no trick regarding modifying the gradients (for a sanity check). The second uses the complicated `if` branch in the constructor and obtains `None`s as described above.

I believe this is a bug and not my mistake, however, it can't be ruled out as I am not as experienced with TF as I'd like to be.

```python
# #!/usr/bin/env python3

# python 3.5 (anaconda)
# TF 0.12 RC from https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.12.0rc0-cp35-cp35m-linux_x86_64.whl
# $ python -c ""import tensorflow; print(tensorflow.__version__)""
#  0.12.0-rc0

# OS: RedHat 7.2
# CPU version only, no GPU, no CUDA, no CUDNN

import numpy as np
import tensorflow as tf
from tensorflow.python.ops.rnn_cell import GRUCell


BATCH = 5  # batch size
MAX_LEN = 10  # max length of the sequence
MLP_HIDDEN_DIM = 128  # number of hidden neurons in the MLP
EMBEDDING_DIM = 300  # embedding dimension
VOCAB_SIZE = 8  # vocabulary size

THREADS = 4  # number of threads to be used
STD=0.001  # standard deviation of ariable initializers


class SimpleSentiment:
    def __init__(self, adversarial=False, device='/cpu:0'):

        self.embeddings = tf.get_variable('word_embeddings',
                                          initializer=tf.random_uniform([VOCAB_SIZE, EMBEDDING_DIM], -1.0, 1.0))

        with tf.variable_scope('sentiment') as scope:
            with tf.device(device):
                # Inputs
                self.text = tf.placeholder(tf.int32, [BATCH, MAX_LEN])
                self.text_len = tf.placeholder(tf.int32, [BATCH])
                self.sentiment = tf.placeholder(tf.int32, [BATCH])

                # Normal loss
                loss_normal = self._loss(self.text, self.text_len, self.sentiment)

                # Define the optimizer
                # Note: I've tried multiple of optimizers and none helped
                optimizer = tf.train.AdamOptimizer(learning_rate=0.0005)

                if adversarial:  # Define adversarial loss
                    # Let's acces already defined variables
                    scope.reuse_variables()

                    # Gradients of all variable (according to normal loss)
                    gradients = optimizer.compute_gradients(loss_normal)
                    print(len(gradients), gradients)

                    # gradients of the embeddings
                    emb_gradient = optimizer.compute_gradients(loss_normal, [self.embeddings])[0][0]

                    # this how much we want to shift the embeddings, i.e. going ""against"" the gradient
                    delta = 0.001*tf.sign(emb_gradient)

                    # let's compute the loss once again but this time we add the delta to the embeddings
                    loss_adversarial = self._loss(self.text, self.text_len, self.sentiment, delta)

                    # new gradient of the whole computational graph
                    adversarial_gradients = optimizer.compute_gradients(loss_adversarial)
                    print(len(adversarial_gradients), adversarial_gradients)  # everything is None!

                    # Now we compute an average of old and new gradients
                    new_gradients = [((g + ag)/2, vg) for ((g, vg), (ag, avg)) in zip(gradients, adversarial_gradients)]

                    # and apply them
                    self.training = optimizer.apply_gradients(new_gradients)

                    # Btw this doesn't work either
                    # self.training = optimizer.apply_gradients(adversarial_gradients)

                    self.loss_final = (loss_normal + loss_adversarial) / 2

                else:  # Normal loss
                    # simply minimize according to the gradients
                    self.loss_final = loss_normal
                    self.training = optimizer.minimize(loss_normal)

                # Create the session
                self.session = tf.Session(config=tf.ConfigProto(inter_op_parallelism_threads=THREADS,
                                                                intra_op_parallelism_threads=THREADS,
                                                                allow_soft_placement=True))

                # init everything (still deprecated way)
                self.session.run(tf.initialize_all_variables())

    def _loss(self, text, text_len, sentiment, emb_delta=0):
        # use embedding
        # note that emb_delta is zero as long as adversarial=False
        # if adversarial=False then each embedding is shifted by appropriate emb_delta
        text = tf.nn.embedding_lookup(self.embeddings + emb_delta, text)

        # run gru
        gru_cell = GRUCell(MLP_HIDDEN_DIM)
        outputs, state = tf.nn.dynamic_rnn(cell=gru_cell,
                                           inputs=text,
                                           sequence_length=text_len,
                                           dtype=tf.float32)

        # define MLP
        W1 = tf.get_variable(name='MLP_W1',
                             shape=[state.get_shape()[1], MLP_HIDDEN_DIM],
                             initializer=tf.random_normal_initializer(mean=0, stddev=STD))
        W2 = tf.get_variable(name='MLP_W2',
                             shape=[MLP_HIDDEN_DIM, 2],
                             initializer=tf.random_normal_initializer(mean=0, stddev=STD))
        h1 = tf.get_variable(name='MLP_h1',
                             shape=[MLP_HIDDEN_DIM],
                             initializer=tf.random_normal_initializer(mean=0, stddev=STD))
        h2 = tf.get_variable(name='MLP_h2',
                             shape=[2],
                             initializer=tf.random_normal_initializer(mean=0, stddev=STD))

        # apply MLP of the last GRU state
        after_first_layer = tf.nn.relu(tf.matmul(state, W1) + h1)
        logits = tf.matmul(after_first_layer, W2) + h2

        # compute loss via categorial cross entropy
        loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits, sentiment))
        return loss


def main():
    for adversarial in [False, True]:
        print('\n=================================')
        if adversarial:
            print('Using the adversarial loss')
        else:
            print('Using the standard loss')

        net = SimpleSentiment(adversarial=adversarial)

        for epoch in range(5):
            print('Epoch {}'.format(epoch))

            for batch in range(3):
                _, loss_final = net.session.run([net.training, net.loss_final],
                                                {net.text: np.array([[3, 1, 1, 2, 1, 0, 0, 0, 0, 0],
                                                                     [3, 4, 1, 2, 1, 4, 4, 0, 0, 0],
                                                                     [1, 1, 1, 2, 0, 0, 0, 0, 0, 0],
                                                                     [3, 3, 3, 2, 1, 7, 0, 0, 0, 0],
                                                                     [7, 1, 5, 2, 4, 2, 2, 2, 1, 7]], dtype='int32'),
                                                 net.text_len: np.array([5, 7, 4, 6, 10], dtype='int32'),
                                                 net.sentiment: np.array([0, 0, 1, 1, 0], dtype='int32')})

                print('\tBatch {}: {}'.format(batch, loss_final))

if __name__ == '__main__':
    main()
```

Thanks for help
Petr"
5984,Bug report : tf.contrib.learn.train API has a problem,"Hi, everyone

First, please understand that I cannot speak English well

I tried to use high-level API(tf.contrib) for code simplicity. 
When I use tf.contrib.learn.train API, I find a problem that execution time per batch increases

An example code is described as below 
```
tf.conbrib.learn.train(defualt_graph, FLAGS.train_dir, train_op, loss, global_step, max_steps=300,
                                            supervisor_save_summaries_steps = 100)
```

when I run above code, execution time per batch increases after step 100.
So, I analyzed tf.contrib.learn.train API

In **graph_actions.py** file, there is train function and this function calls **_train_internal function** in the same file

In _train_internal function, _run_with_monitors function is called for execution of train_op and monitor

_run_with_monitors function is described as below
```
  for monitor in monitors:
    tensors +=  monitor.step_begin(step)
  tensors = list(set(tensors))

  outputs = session.run(tensors, feed_dict=feed_dict)
  outputs = dict(zip(
      [t.name if isinstance(t, ops.Tensor) else t for t in tensors],
      outputs))

  should_stop = False
  for monitor in monitors:
    induce_stop = monitor.step_end(step, outputs)
    should_stop = should_stop or induce_stop
  return outputs, should_stop
```
In this function, I examined two functions in class EveryN(monitors.py) : **monitor.step_begin**,  **monitor.step_end**

In monitor.step_begin function, monitor is executed when the following conditions are fulfilled
```
    if (step <= self._first_n_steps or
        step >= (self._every_n_steps + self._last_active_step) or
        step == self._max_steps):  # Note: max_steps can be None here.
      self._every_n_step_begin_called = True
      return self.every_n_step_begin(step)
```
and monitor.step_end function is described as follows
```
  def step_end(self, step, output):
    super(EveryN, self).step_end(step, output)
    if self._every_n_step_begin_called:
      return self.every_n_step_end(step, output)
    return False
```
In these codes, I find **self._last_active_step variable** is not updated.
So, I add the **monitor.post_step function** in _run_with_monitors function as follows
```
  for monitor in monitors:
    tensors += monitor.step_begin(step)
  tensors = list(set(tensors))

  outputs = session.run(tensors, feed_dict=feed_dict)
  outputs = dict(zip(
      [t.name if isinstance(t, ops.Tensor) else t for t in tensors],
      outputs))

  should_stop = False
  for monitor in monitors:
    induce_stop = monitor.step_end(step, outputs)
    monitor.post_step(step, session=session)
    should_stop = should_stop or induce_stop
  return outputs, should_stop
```
**monitor.post_step function** performs _last_active_step variable update as follows
```
  def post_step(self, step, session):
    super(EveryN, self).post_step(step, session)
    if self._every_n_step_begin_called:
      self.every_n_post_step(step, session)
      self._last_active_step = step
    self._last_successful_step = step
```

When the code is revised above, tf.contrib.learn.train function is well operated.
"
5983,[Windows] TensorBoard doesn't work,"I installed the tensorflow for windows with
`pip install --upgrade --ignore-installed https://storage.googleapis.com/tensorflow/windows/cpu/tensorflow-0.12.0rc0-cp35-cp35m-win_amd64.whl`
(I added the '--ignore-installed', for the official one didn't work on my pc)

Then I tried some code and ran tensorboard, however the browser shows nothing 
When running with '--debug' there appears some 404.
I also tried tensorboard on mac os, it worked well, so the problem is not caused by the .tfevent file
I've read through a bunch of related issues, and found that maybe the pip install didn't install tensorflow completely. And I searched the tensorflow file and did not found some certain files appears in mac os tensorflow, such as 'paper-toolkit'

"
5982,tf.dynamic_rnn causes rnn state vector to have an undefined batch size,"Minimal example:

```python
import tensorflow as tf

sess = tf.Session()
inputs = tf.zeros([4, 10, 12], tf.float32)
cell = tf.nn.rnn_cell.BasicLSTMCell(20)
multicell = tf.nn.rnn_cell.MultiRNNCell([cell] * 2)
output, state = tf.nn.dynamic_rnn(cell, inputs, dtype=tf.float32)
print state, '\n', output
# LSTMStateTuple(c=<tf.Tensor 'RNN/while/Exit_2:0' shape=(?, 20) dtype=float32>, h=<tf.Tensor 'RNN/while/Exit_3:0' shape=(?, 20) dtype=float32>) 
# Tensor(""RNN/transpose:0"", shape=(4, 10, 20), dtype=float32)
```

[This code](https://github.com/tensorflow/tensorflow/blob/5657d0dee8d87f4594b3e5902ed3e3ca8d6dfc0a/tensorflow/python/ops/rnn.py#L809) seems to be the the where the problem is being caused:
```python
    input_shape = tuple(array_ops.shape(input_) for input_ in flat_input)
    batch_size = input_shape[0][1]

    for input_ in input_shape:
      if input_[1].get_shape() != batch_size.get_shape():
        raise ValueError(""All inputs should have the same batch size"")
```
From what I understand:
1. `flat_input` is a tuple of tensors
2. thus `input_shape` is a tuple of 1D tensors
3. `batch_size` gets the 2nd element of the 1st `input_shape` tensor, which is a 0D tensor
4. `input_[1]` is the shape of the 1st element of the 1D `input_shape` tensor which is a 0D tensor
5. => `input_[1].get_shape() == batch_size.get_shape() == TensorShape([]) ` for all `flat_input`

Thus regardless of the content of `flat_input`, the `ValueError` will never be raised and batch_size will always be a 0D tensor, unknown until it is evaluated, as opposed to a number.

Rewriting the above code to something that makes more sense to me (below) causes the tests to fail when `dynamic_rnn` is instantiated with variable batch size.

```python
    input_shape = tuple(input_.get_shape() for input_ in flat_input)
    batch_size = input_shape[0][1]
 
    for shape in input_shape:
      if shape[1] != batch_size:
        raise ValueError(""All inputs should have the same batch size"")
```

I suppose the question I'm asking is whether it is intended behaviour to throw away the batch size information when it is fixed? If it isn't, I'm happy to write a fix.

This was brought to my attention by a subtle bug found when implementing a custom LSTM cell:

```python
class VariationalLSTMCell(tf.nn.rnn_cell.BasicLSTMCell):
	""""""
	Long short-term memory unit (LSTM) recurrent network cell based on:

	http://arxiv.org/pdf/1512.05287v3.pdf

	Yarin Gal
	""A theoretically grounded application of dropout in recurrent neural networks""
	""""""
	def __init__(self, num_units, keep_prob_w, keep_prob_u=None, **kwargs):
		super(VariationalLSTMCell, self).__init__(num_units, **kwargs)
		self._keep_prob_w = keep_prob_w
		self._keep_prob_u = keep_prob_u if keep_prob_u is not None else keep_prob_w
		self._t0_cell = False

	def __call__(self, inputs, state, scope=None):
		""""""Long short-term memory cell (LSTM).""""""
		with tf.variable_scope(scope or type(self).__name__) as scope:	# ""VariationalLSTMCell""
			if not scope.reuse:
				self._t0_cell = True

			if self._state_is_tuple:
				c, h = state
			else:
				c, h = tf.split(1, 2, state)

			dtype = inputs.dtype
			batch_size, input_size = inputs.get_shape().with_rank(2)
			if input_size.value is None:
				raise ValueError(""Could not infer input size from inputs.get_shape()[-1]"")
			(w_i, w_g, w_f, w_o), (u_i, u_g, u_f, u_o) = self.get_weights(input_size, dtype)
			b_i, b_g, b_f, b_o = self.get_biases(dtype)
			(m_wi, m_wg, m_wf, m_wo), (m_ui, m_ug, m_uf, m_uo) = self.get_dropout_masks(batch_size, input_size)

			# i = input_gate, g = new_input, f = forget_gate, o = output_gate
			i = tf.matmul(inputs * m_wi, w_i) + tf.matmul(h * m_ui, u_i) + b_i
			g = tf.matmul(inputs * m_wg, w_g) + tf.matmul(h * m_ug, u_g) + b_g
			f = tf.matmul(inputs * m_wf, w_f) + tf.matmul(h * m_uf, u_f) + b_f
			o = tf.matmul(inputs * m_wo, w_o) + tf.matmul(h * m_uo, u_o) + b_o

			new_c = (c * tf.sigmoid(f + self._forget_bias) + tf.sigmoid(i) * self._activation(g))
			new_h = self._activation(new_c) * tf.sigmoid(o)

			if self._state_is_tuple:
				new_state = tf.nn.rnn_cell.LSTMStateTuple(new_c, new_h)
			else:
				new_state = tf.concat(1, [new_c, new_h])
		return new_h, new_state

	def get_dropout_masks(self, batch_size, input_size):
		with tf.variable_scope('dropout'):
			w_mask = tf.get_variable('w_mask', [4, batch_size.value, input_size.value], tf.float32, tf.ones_initializer, trainable=False)
			u_mask = tf.get_variable('u_mask', [4, batch_size.value, self._num_units], tf.float32, tf.ones_initializer, trainable=False)
			if self._t0_cell:
				w_mask = w_mask.assign(tf.random_uniform([4, batch_size.value, input_size.value], dtype=tf.float32))
				u_mask = u_mask.assign(tf.random_uniform([4, batch_size.value, self._num_units], dtype=tf.float32))
			w_mask = tf.maximum(tf.sign(self._keep_prob_w - w_mask), 0) / self._keep_prob_w
			u_mask = tf.maximum(tf.sign(self._keep_prob_u - u_mask), 0) / self._keep_prob_u
			w_masks, u_masks = [tf.unpack(mask) for mask in [w_mask, u_mask]]
			return w_masks, u_masks

	def get_weights(self, input_size, dtype):
		w_weights = tf.get_variable('w_weights', [4, input_size.value, self._num_units], dtype)
		u_weights = tf.get_variable('u_weights', [4, self._num_units, self._num_units], dtype)
		tf.add_to_collection('weights', w_weights)
		tf.add_to_collection('weights', u_weights)
		w_weights, u_weights = [tf.unpack(weights) for weights in [w_weights, u_weights]]
		return w_weights, u_weights

	def get_biases(self, dtype):
		biases = tf.get_variable('biases', [4, self._num_units], dtype, tf.zeros_initializer)
		tf.add_to_collection('biases', biases)
		return tf.unpack(biases)
```

When `batch_size > 1` this works fine, but when `batch_size == 1` due to the potential to be broadcast, the dimensions of `new_h` and `new_c` cannot be inferred, leading to crashes in higher layers in `get_dropout_masks`. This works fine however with the change to `dynamic_rnn` I mentioned above.

I'm mainly working in `r0.11`, but I have also observed the issue in master (`5657d0d`) and `0.12.0-rc0`

Please let me know if any more information would be helpful."
5981,Tensorflow profiling overhead,"The profiling mechanism (which by the way really deserves to be documented...) can add a prohibitive large computational overhead to the execution. Specifically, my training script runs 10 times slower with profiling. I stripped it down to a small self-contained [example](https://gist.github.com/rizar/f4556741c2c79c4adf4f47c6ed1cefd7) and the slowdown became just 3x, but I think this is bad enough.

### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?

https://github.com/tensorflow/tensorflow/issues/1824

### Environment info
Operating System:

Debian 8.6
CUDA 8.0
CUDNN 5.1.3

Tensorflow was installed by running

`pip install --user https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.11.0rc1-cp27-none-linux_x86_64.whl`

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)

https://gist.github.com/rizar/f4556741c2c79c4adf4f47c6ed1cefd7



"
5978,"Broken link in ""A Tool Developer's Guide..."" for graph_run_run2.pbtxt",The link for `graph_run_run2.pbtxt` is broken in https://github.com/tensorflow/tensorflow/blob/master/tensorflow/g3doc/how_tos/tool_developers/index.md
5977,"split_v generates tensors of unspecified size for all dimensions, when one dimension is missing at the original one","The new split_v function introduced in 0.12rc0 does not correctly predict the shapes of the resulting tensors when the original tensor has an unknown dimension, resulting on the split dimension being of unknown size. For instance:

```
tensor = tf.placeholder(tf.float32, [None, 12])
parts = tf.split_v(tensor, [6, 4, 2], split_dim=1)
```

This results in three tensors, all with shapes [?, ?], instead of the expected [?, 6], [?, 4] and [?, 2]. While at runtime the resulting tensors are of the right size, this makes it more difficult to debug the code during graph definition.

EDIT: This also creates problems when combined with scan. Because scan expects fn to return tensors of the same shape as the initializers, it forces the use of a reshape just to clear the 'unknown' dimension."
5975,no such target '//tensorflow/tools/git:gen/spec.json': target 'gen/spec.json' not declared in package ,"when I run inceptionv3, tensorflow/examples/image_retraining, I encounter a problem，i go to the root directory and run:
`bazel build tensorflow/examples/image_retraining:retrain` or `bazel build -c opt --copt=-mavx tensorflow/examples/image_retraining:retrain`:
it appear the same error :

`
ERROR: /home/duan/tensorflow/tensorflow/core/BUILD:1121:1: no such target '//tensorflow/tools/git:gen/spec.json': target 'gen/spec.json' not declared in package 'tensorflow/tools/git' defined by /home/duan/tensorflow/tensorflow/tools/git/BUILD and referenced by '//tensorflow/core:version_info_gen'.
ERROR: /home/duan/tensorflow/tensorflow/core/BUILD:1121:1: no such target '//tensorflow/tools/git:gen/head': target 'gen/head' not declared in package 'tensorflow/tools/git' defined by /home/duan/tensorflow/tensorflow/tools/git/BUILD and referenced by '//tensorflow/core:version_info_gen'.
ERROR: /home/duan/tensorflow/tensorflow/core/BUILD:1121:1: no such target '//tensorflow/tools/git:gen/branch_ref': target 'gen/branch_ref' not declared in package 'tensorflow/tools/git' defined by /home/duan/tensorflow/tensorflow/tools/git/BUILD and referenced by '//tensorflow/core:version_info_gen'.
ERROR: Analysis of target '//tensorflow/examples/image_retraining:retrain' failed; build aborted.
INFO: Elapsed time: 4.179s
`
how to slove this problem?

and my content is：

`tensorflow-
           +-tensorflow
           +-third_party
           +-tools
           +-util
           +-......
           +-......
`
bazel version:
`
Build label: 0.4.0
Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Wed Nov 2 17:54:14 2016 (1478109254)
Build timestamp: 1478109254
Build timestamp as int: 1478109254
`
my operating system is：
`Linux ubuntu 3.13.0-24-generic #46-Ubuntu SMP Thu Apr 10 19:11:08 UTC 2014 x86_64 x86_64 x86_64 GNU/Linux`
and  my TensorFlow version is cpu version：
`python -c ""import tensorflow; print(tensorflow.__version__)""
0.9.0
`
"
5974,tensorboard visualize embedding error,"env: tensorflow v. 0.12.0 RC0

Following the [instructions](https://www.tensorflow.org/versions/master/how_tos/embedding_viz/index.html#tensorboard-embedding-visualization), I use tensorboard to visualize embeddings (without any metadata) and comes the following error:

> File ""/home/morphe/miniconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/tensorboard/plugins/projector/plugin.py"", line 139, in configs
    run_path_pairs.append(('.', self.logdir))
AttributeError: 'dict_items' object has no attribute 'append'

It seems to work if I attempt to change `tensorflow/tensorboard/plugins/projector/plugin.py`:
```
- run_path_pairs.append(('.', self.logdir))
+ run_path_pairs = [('.', self.logdir)]
```

Not sure if this is the right way to go. Is this a bug?"
5972,optimize variable with dynamic shape not supported,"TensorFlow 0.11.0.

I want to use a variable where the shape is unknown in advance and it will change from time to time (although ndim is known and fixed).

I declare it like:

```
initializer = tf.random_uniform_initializer()
shape = (s0, s1, s2)  # these are symbolic vars
foo_var = tf.Variable(initializer(shape=shape), name=""foo"", validate_shape=False)
```
This seems to work when I create the computation graph up to the point where I want to optimize w.r.t. this variable, i.e.:
```
optimizer = tf.train.AdamOptimizer(learning_rate=0.1, epsilon=1e-4)
optim = optimizer.minimize(loss, var_list=[foo_var])
```

That fails in the optimizer in some function `create_zeros_slot` where it seems to depend on the static shape information (it uses `primary.get_shape().as_list()`).

So, using the optimizer works only with variables with static shape? Is that a bug?

My current solution is some hacky monkey patching:
```
def _tf_create_slot_var(primary, val, scope):
  """"""Helper function for creating a slot variable.""""""

  from tensorflow.python.ops import variables
  slot = variables.Variable(val, name=scope, trainable=False, validate_shape=primary.get_shape().is_fully_defined())
  # pylint: disable=protected-access
  if isinstance(primary, variables.Variable) and primary._save_slice_info:
    # Primary is a partitioned variable, so we need to also indicate that
    # the slot is a partitioned variable.  Slots have the same partitioning
    # as their primaries.
    real_slot_name = scope[len(primary.op.name + ""/""):-1]
    slice_info = primary._save_slice_info
    slot._set_save_slice_info(variables.Variable.SaveSliceInfo(
        slice_info.full_name + ""/"" + real_slot_name,
        slice_info.full_shape[:],
        slice_info.var_offset[:],
        slice_info.var_shape[:]))
  # pylint: enable=protected-access
  return slot


def _tf_create_zeros_slot(primary, name, dtype=None, colocate_with_primary=True):
  """"""Create a slot initialized to 0 with same shape as the primary object.

  Args:
    primary: The primary `Variable` or `Tensor`.
    name: Name to use for the slot variable.
    dtype: Type of the slot variable.  Defaults to the type of `primary`.
    colocate_with_primary: Boolean.  If True the slot is located
      on the same device as `primary`.

  Returns:
    A `Variable` object.
  """"""
  if dtype is None:
    dtype = primary.dtype
  from tensorflow.python.ops import array_ops
  val = array_ops.zeros(
      primary.get_shape().as_list() if primary.get_shape().is_fully_defined() else tf.shape(primary),
      dtype=dtype)
  from tensorflow.python.training import slot_creator
  return slot_creator.create_slot(primary, val, name, colocate_with_primary=colocate_with_primary)


def monkey_patch_tf_slot_creator():
    """"""
    The TensorFlow optimizers cannot handle variables with unknown shape.
    We hack this.
    """"""
    from tensorflow.python.training import slot_creator
    slot_creator._create_slot_var = _tf_create_slot_var
    slot_creator.create_zeros_slot = _tf_create_zeros_slot
```

(That was also asked [on StackOverflow](http://stackoverflow.com/questions/40863082/optimize-variable-with-dynamic-shape/).)"
5971,Very strange issue on estimator predict function,"Yesterday, I use the tf.contrib.learn.LinearClassifier to fit my data and predict the result. Every thing works fine. The predict function will return an numpy array of label.

Today I use the same LinearClassifier, it give me the warning like this:
WARNING:tensorflow:From /s/chopin/l/grad/tthhmm/miniconda3/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/estimators/linear.py:454 in evaluate.: calling BaseEstimator.evaluate (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.
Instructions for updating:
Estimator is decoupled from Scikit Learn interface by moving into
separate class SKCompat. Arguments x, y and batch_size are only
available in the SKCompat class, Estimator will only accept input_fn.
Example conversion:
  est = Estimator(...) -> est = SKCompat(Estimator(...))

And the predict function just return <generator object _as_iterable at 0x7fb490fe1f68>. I have no idea how to use these function any more. I don't know where I can find SKCompat class from tensorflow also. "
5970,[Windows] How to install cuDNN and enable GPU for Windows?,"Operating System: Windows 10

Here is what I got when tried to import tensorflow (which is successful in itself):

`C:\Users\GoBack>python
Python 3.5.2 |Anaconda 4.2.0 (64-bit)| (default, Jul  5 2016, 11:41:13) [MSC v.1
900 64 bit (AMD64)] on win32
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import tensorflow as tf
I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\stre
am_executor\dso_loader.cc:128] successfully opened CUDA library cublas64_80.dll
locally
I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\stre
am_executor\dso_loader.cc:119] Couldn't open CUDA library cudnn64_5.dll
I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\stre
am_executor\cuda\cuda_dnn.cc:3459] Unable to load cuDNN DSO
I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\stre
am_executor\dso_loader.cc:128] successfully opened CUDA library cufft64_80.dll l
ocally
I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\stre
am_executor\dso_loader.cc:128] successfully opened CUDA library nvcuda.dll local
ly
I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\stre
am_executor\dso_loader.cc:128] successfully opened CUDA library curand64_80.dll
locally
>>>`

It seems that the Cuda Toolkit can be installed properly, but cuDNN may not. Besides, I didn't see any instructions about this matter in the Tutorials or the Release notes.
Thanks a lot in advance!"
5968,[Windows] Tensorflow GPU fails to find CUDA.,"NOTE: Only file GitHub issues for bugs and feature requests.  All other topics will be closed.

For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.

### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?

**NONE** (Tensorflow for Windows is very new).

### Environment info
Operating System: Windows 8.1 (Conda 4.2.9)

`conda --version
conda 4.2.9`


Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):
`nvcc --version
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2016 NVIDIA Corporation
Built on Sat_Sep__3_19:05:48_CDT_2016
Cuda compilation tools, release 8.0, V8.0.44`

If installed from binary pip package, provide:

1. A link to the pip package you installed:
`pip install --upgrade https://storage.googleapis.com/tensorflow/windows/gpu/tensorflow_gpu-0.12.0rc0-cp35-cp35m-win_amd64.whl`

2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.

`python -c ""import tensorflow; print(tensorflow.__version__)""
0.12.0-rc0
I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\stream_executor\dso_loader.cc:128] successfully opened CUDA library cublas64_80.dll locally
I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\stream_executor\dso_loader.cc:119] Couldn't open CUDA library cudnn64_5.dll
I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\stream_executor\cuda\cuda_dnn.cc:3459] Unable to load cuDNN DSO
I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\stream_executor\dso_loader.cc:128] successfully opened CUDA library cufft64_80.dll locally
I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\stream_executor\dso_loader.cc:128] successfully opened CUDA library nvcuda.dll locally
I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\stream_executor\dso_loader.cc:128] successfully opened CUDA library curand64_80.dll locally
`

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)

What I did:
I attempt to run some tensorflow code that works within ubuntu CPU instance. 

Code:
MNIST simple autoencoder (requires MNIST dataset);
[CODE](https://gist.github.com/kingtaurus/ae5b38b07cbf3775992ca7be479bb45c)

Error Message [error_message](https://gist.github.com/kingtaurus/3f75835b33501ba51be7fccb0fb0ab8e):
```
In [10]: %run CNN_autoencoder.py
I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\stre
am_executor\dso_loader.cc:128] successfully opened CUDA library cublas64_80.dll
locally
I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\stre
am_executor\dso_loader.cc:119] Couldn't open CUDA library cudnn64_5.dll
I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\stre
am_executor\cuda\cuda_dnn.cc:3459] Unable to load cuDNN DSO
I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\stre
am_executor\dso_loader.cc:128] successfully opened CUDA library cufft64_80.dll l
ocally
I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\stre
am_executor\dso_loader.cc:128] successfully opened CUDA library nvcuda.dll local
ly
I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\stre
am_executor\dso_loader.cc:128] successfully opened CUDA library curand64_80.dll
locally
Extracting MNIST_data/train-images-idx3-ubyte.gz
Extracting MNIST_data/train-labels-idx1-ubyte.gz
Extracting MNIST_data/t10k-images-idx3-ubyte.gz
Extracting MNIST_data/t10k-labels-idx1-ubyte.gz
I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core
\common_runtime\gpu\gpu_device.cc:885] Found device 0 with properties:
name: GeForce GTX 965M
major: 5 minor: 2 memoryClockRate (GHz) 0.9495
pciBusID 0000:01:00.0
Total memory: 2.00GiB
Free memory: 1.86GiB
I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core
\common_runtime\gpu\gpu_device.cc:906] DMA: 0
I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core
\common_runtime\gpu\gpu_device.cc:916] 0:   Y
I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core
\common_runtime\gpu\gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (d
evice: 0, name: GeForce GTX 965M, pci bus id: 0000:01:00.0)
E c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\core
\common_runtime\gpu\gpu_device.cc:586] Could not identify NUMA node of /job:loca
lhost/replica:0/task:0/gpu:0, defaulting to 0.  Your kernel may not have been bu
ilt with NUMA support.
WARNING:tensorflow:From C:\Users\Gregoty\Programming\cs231n\repo\project\tensorf
low\autoencoder\CNN_autoencoder.py:188 in <module>.: initialize_all_variables (f
rom tensorflow.python.ops.variables) is deprecated and will be removed after 201
7-03-02.
Instructions for updating:
Use `tf.global_variables_initializer` instead.
number of test       =  10000
number of train      =  55000
number_of validation =  5000
Done splitting up test data set;
Starting training loop.
Epoch:  0
Shuffling the training data;
F c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\stre
am_executor\cuda\cuda_dnn.cc:221] Check failed: s.ok() could not find cudnnCreat
e in cudnn DSO; dlerror: cudnnCreate not found
```

### What other attempted solutions have you tried?
Tried running it through `ipython` (conda), `python` (initiated by msys2)

### Logs or other output that would be helpful
(If logs are large, please upload as attachment or provide link).
"
5966,How to map '\n' to id in a metadata.tsv when visualizing embedding,"I'm quite excited about the new embedding visualization feature in TF 0.12.0-RC0. But when I walk through the [new documentation page](https://www.tensorflow.org/versions/master/how_tos/embedding_viz/index.html#tensorboard-embedding-visualization) in the metadata part, it says that the metadata has the exact format with first line as header and others as fields.

What if I have to map char '\n' to id? In this way, the specific format of tsv file will broken. This is often the case in most NLP tasks. 

Hope the developer will explain this. thanks."
5965,Feature request: GPU ops for tf.unique; tf.where; and tf.dynamic_partition ,"This is a feature request.  As far as I know, all three of them currently do not have GPU ops.

It seems that if we can at least get a GPU implementation of `tf.unique` for integers, then the user can make `tf.where` and `tf.dynamic_partition` manually.  For those of us who are trying to build models that want to mess around with indices rather frequently, this would be incredibly helpful. "
5964,Should slim.learning.train and slim.evaluation.evaluation handle OutOfRange gracefully?,"I'm finding it very hard train DNN for specific number of epochs unless I precompute number of batches, which is not convenient in streaming case, since TFRecord files don't have # of examples handy.

Should slim.learning.train and slim.evaluation.evaluation handle OutOfRange gracefully?  If that was the case, I could just set num_epochs on my input and max out num_evals.

Happy to send PR if this seems reasonable."
5963,get error when get labels of TFRecord dataset made by myself,"I use the cifar10 model train my own TFRecord dataset ,it's running on Ubuntu 14.4 without error,but getting these errors when I run it on Mac or GPU server。And I am sure the labels of my dataset are right ,I don't know why get labels bigger than 10 ,I just have 10 classifications。

I use this code write images and labels in binfile:

image_raw = image.tostring()
        example = tf.train.Example(features=tf.train.Features(feature={
            'image_raw' : _bytes_feature(image_raw),
            'height' : _int64_feature(image.shape[0]),
            'width' : _int64_feature(image.shape[1]),
            'deepth' : _int64_feature(image.shape[2]),
            'label' : _int64_feature(label)
            }))
        writer.write(example.SerializeToString())
    writer.close()

The errors:

W tensorflow/core/framework/op_kernel.cc:975] Invalid argument: Received a label value of 245 which is outside the valid range of [0, 10).  Label values: 180 96 226 166 162 179 147 115 162 141 150 136 129 118 162 141 78 154 133 155 89 184 116 179 176 70 209 177 65 177 89 36 80 139 117 187 115 182 106 42 203 120 48 72 96 126 74 123 134 115 112 154 128 163 64 113 35 140 198 193 189 67 164 110 117 61 215 186 189 84 95 206 163 82 122 160 37 179 236 157 140 181 178 128 67 114 43 211 143 70 0 91 184 142 172 127 80 160 127 90 62 151 158 23 180 192 21 97 125 94 98 136 125 190 158 128 119 30 198 111 206 66 137 126 245 210 158 188
Traceback (most recent call last):
  File ""/Users/yangk/cifar10/cifar10_train.py"", line 137, in <module>
    tf.app.run()
  File ""/Library/Python/2.7/site-packages/tensorflow/python/platform/app.py"", line 43, in run
    sys.exit(main(sys.argv[:1] + flags_passthrough))
  File ""/Users/yangk/cifar10/cifar10_train.py"", line 133, in main
    train()
  File ""/Users/yangk/cifar10/cifar10_train.py"", line 103, in train
    _, loss_value = sess.run([train_op, loss])
  File ""/Library/Python/2.7/site-packages/tensorflow/python/client/session.py"", line 766, in run
    run_metadata_ptr)
  File ""/Library/Python/2.7/site-packages/tensorflow/python/client/session.py"", line 964, in _run
    feed_dict_string, options, run_metadata)
  File ""/Library/Python/2.7/site-packages/tensorflow/python/client/session.py"", line 1014, in _do_run
    target_list, options, run_metadata)
  File ""/Library/Python/2.7/site-packages/tensorflow/python/client/session.py"", line 1034, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InvalidArgumentError: Received a label value of 245 which is outside the valid range of [0, 10).  Label values: 180 96 226 166 162 179 147 115 162 141 150 136 129 118 162 141 78 154 133 155 89 184 116 179 176 70 209 177 65 177 89 36 80 139 117 187 115 182 106 42 203 120 48 72 96 126 74 123 134 115 112 154 128 163 64 113 35 140 198 193 189 67 164 110 117 61 215 186 189 84 95 206 163 82 122 160 37 179 236 157 140 181 178 128 67 114 43 211 143 70 0 91 184 142 172 127 80 160 127 90 62 151 158 23 180 192 21 97 125 94 98 136 125 190 158 128 119 30 198 111 206 66 137 126 245 210 158 188
	 [[Node: cross_entropy_per_example/cross_entropy_per_example = SparseSoftmaxCrossEntropyWithLogits[T=DT_FLOAT, Tlabels=DT_INT64, _device=""/job:localhost/replica:0/task:0/cpu:0""](softmax_linear/softmax_linear, Cast_4)]]

Caused by op u'cross_entropy_per_example/cross_entropy_per_example', defined at:
  File ""/Users/yangk/cifar10/cifar10_train.py"", line 137, in <module>
    tf.app.run()
  File ""/Library/Python/2.7/site-packages/tensorflow/python/platform/app.py"", line 43, in run
    sys.exit(main(sys.argv[:1] + flags_passthrough))
  File ""/Users/yangk/cifar10/cifar10_train.py"", line 133, in main
    train()
  File ""/Users/yangk/cifar10/cifar10_train.py"", line 76, in train
    loss = cifar10.loss(logits, labels)
  File ""/Users/yangk/cifar10/cifar10.py"", line 289, in loss
    logits, labels, name='cross_entropy_per_example')
  File ""/Library/Python/2.7/site-packages/tensorflow/python/ops/nn_ops.py"", line 1537, in sparse_softmax_cross_entropy_with_logits
    precise_logits, labels, name=name)
  File ""/Library/Python/2.7/site-packages/tensorflow/python/ops/gen_nn_ops.py"", line 2378, in _sparse_softmax_cross_entropy_with_logits
    features=features, labels=labels, name=name)
  File ""/Library/Python/2.7/site-packages/tensorflow/python/framework/op_def_library.py"", line 763, in apply_op
    op_def=op_def)
  File ""/Library/Python/2.7/site-packages/tensorflow/python/framework/ops.py"", line 2371, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/Library/Python/2.7/site-packages/tensorflow/python/framework/ops.py"", line 1258, in __init__
    self._traceback = _extract_stack()

InvalidArgumentError (see above for traceback): Received a label value of 245 which is outside the valid range of [0, 10).  Label values: 180 96 226 166 162 179 147 115 162 141 150 136 129 118 162 141 78 154 133 155 89 184 116 179 176 70 209 177 65 177 89 36 80 139 117 187 115 182 106 42 203 120 48 72 96 126 74 123 134 115 112 154 128 163 64 113 35 140 198 193 189 67 164 110 117 61 215 186 189 84 95 206 163 82 122 160 37 179 236 157 140 181 178 128 67 114 43 211 143 70 0 91 184 142 172 127 80 160 127 90 62 151 158 23 180 192 21 97 125 94 98 136 125 190 158 128 119 30 198 111 206 66 137 126 245 210 158 188
	 [[Node: cross_entropy_per_example/cross_entropy_per_example = SparseSoftmaxCrossEntropyWithLogits[T=DT_FLOAT, Tlabels=DT_INT64, _device=""/job:localhost/replica:0/task:0/cpu:0""](softmax_linear/softmax_linear, Cast_4)]]"
5962,Image Recognition: No route to host when run classify_image.py,"I read this tutorial: https://www.tensorflow.org/versions/r0.12/tutorials/image_recognition/index.html

I encountered IOError when run 'python classify_image.py' in terminal.
It seems that i can not get access to 'http://download.tensorflow.org'.
Also i get access denied when use chrome to browse 'http://download.tensorflow.org'
How can i execute the inception-v3 example correctly?

The error is as follow:

> ➜  imagenet git:(master) ✗ python classify_image.py
Traceback (most recent call last):
  File ""classify_image.py"", line 227, in <module>
    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)
  File ""/Users/universe/Program/conda/anaconda/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 43, in run
    sys.exit(main(sys.argv[:1] + flags_passthrough))
  File ""classify_image.py"", line 190, in main
    maybe_download_and_extract()
  File ""classify_image.py"", line 182, in maybe_download_and_extract
    filepath, _ = urllib.request.urlretrieve(DATA_URL, filepath, _progress)
  File ""/Users/universe/Program/conda/anaconda/lib/python2.7/urllib.py"", line 98, in urlretrieve
    return opener.retrieve(url, filename, reporthook, data)
  File ""/Users/universe/Program/conda/anaconda/lib/python2.7/urllib.py"", line 245, in retrieve
    fp = self.open(url, data)
  File ""/Users/universe/Program/conda/anaconda/lib/python2.7/urllib.py"", line 213, in open
    return getattr(self, name)(url)
  File ""/Users/universe/Program/conda/anaconda/lib/python2.7/urllib.py"", line 350, in open_http
    h.endheaders(data)
  File ""/Users/universe/Program/conda/anaconda/lib/python2.7/httplib.py"", line 1053, in endheaders
    self._send_output(message_body)
  File ""/Users/universe/Program/conda/anaconda/lib/python2.7/httplib.py"", line 897, in _send_output
    self.send(msg)
  File ""/Users/universe/Program/conda/anaconda/lib/python2.7/httplib.py"", line 859, in send
    self.connect()
  File ""/Users/universe/Program/conda/anaconda/lib/python2.7/httplib.py"", line 836, in connect
    self.timeout, self.source_address)
  File ""/Users/universe/Program/conda/anaconda/lib/python2.7/socket.py"", line 575, in create_connection
    raise err
IOError: [Errno socket error] [Errno 65] No route to host"
5960,Is there a quick tutorial for Windows users to use Tensorflow?,"The good news is Tensorflow finally supports Windows platform, but with very trival configurations.
And there is another important: Most of the PCs are running Windows.
So I really think it is truly necessary to provide a easy way for Windows users to run Tensorflow. A good toolkit is always the one that can cross all the platforms, right?
Is there a quick way to connect? On Linux/Mac, we can use pip, just a simple loc, and that's all. Everything seems not so fluid on Windows, why? Is it really that hard? I do think Tensorflow will get far more way if Windows is supported.
"
5959,RNN model in the tutorial doesn't work: tensorflow.python.framework.errors.NotFoundError: /tmp/simple-examples/data/ptb.train.txt,"Hi, my computer works on Mac OS X, CPU only, Python 2.7, use pip install tensorflow and run the first neural net model successfully: tensorflow/models/image/mnist/ convolutional.py 

But I try to repeat the tutorial of CNN model according to the instructions:
cd tensorflow/models/rnn/ptb
python ptb_word_lm.py --data_path=/tmp/simple-examples/data/ --model small

Firstly, there is no such file ptb_word_lm.py in the default directory /Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/tensorflow/models/rnn/ptb/, then I copied the file to this directory, but another error occurred:
tensorflow.python.framework.errors.NotFoundError: /tmp/simple-examples/data/ptb.train.txt

Can you help explain a little bit about such error    @jmhodges 

Thanks
"
5956,OSAtomic* OS X includes deprecated in 10.12,"

### Environment info
Operating System: Mac OS X 10.12.1

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):
N/A

1. The commit hash (`git rev-parse HEAD`)
41285cf7a11fa3a2c2ead6b6e9adcec4232b18ad (rc11  release from GIT)

2. The output of `bazel version`
Build label: 0.4.0-homebrew

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)

#import ""tensorflow/cc/ops/const_op.h""

`
Showing All Messages
/Users/vade/Documents/Repositories/Synopsis/Synopsis/Synopsis/TensorFlowAnalyzer/includes/google/protobuf/stubs/atomicops_internals_macosx.h:47:9: 'OSAtomicCompareAndSwap32' is deprecated: first deprecated in macOS 10.12 - Use std::atomic_compare_exchange_strong_explicit(std::memory_order_relaxed) from <atomic> instead

`

etc etc

### What other attempted solutions have you tried?

N/A

### Logs or other output that would be helpful
(If logs are large, please upload as attachment or provide link).
"
5953,Windows 'models' directory,"I'm following through the tutorial and it seems that the 'tensorflow/models/' directory is missing from the TensorFlow 0.12.0 RC0 build for Windows - at least when downloaded using pip.

I installed TensorFlow using `pip3 install --upgrade https://storage.googleapis.com/tensorflow/windows/gpu/tensorflow_gpu-0.12.0rc0-cp35-cp35m-win_amd64.whl`. The initial test of TensorFlow ran fine.

Additionally running `python3 -m tensorflow.models.image.mnist.convolutional` produces the follwing error:

	I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\stream_executor\dso_loader.cc:128] successfully opened CUDA library cublas64_80.dll locally
	I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\stream_executor\dso_loader.cc:128] successfully opened CUDA library cudnn64_5.dll locally
	I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\stream_executor\dso_loader.cc:128] successfully opened CUDA library cufft64_80.dll locally
	I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\stream_executor\dso_loader.cc:128] successfully opened CUDA library nvcuda.dll locally
	I c:\tf_jenkins\home\workspace\release-win\device\gpu\os\windows\tensorflow\stream_executor\dso_loader.cc:128] successfully opened CUDA library curand64_80.dll locally
	C:\Program Files\Python35\python3.exe: Error while finding spec for 'tensorflow.models.image.mnist.convolutional' (ImportError: No module named 'tensorflow.models')


I'm new to TensorFlow so please correct me if the Models module is not supposed to be packaged with the pip download."
5952,pthread cond_wait deadlock on assignment via tf.while_loop,"State:
- tf 0.12RC0 (installed via pip URL)
- Ubuntu 16.04
- cuda 8.0 w/cudnn 5.1

Ran python through gdb and it looks like there is a deadlock?
```python
import tensorflow as tf

with tf.Session() as sess:
    index = tf.constant(0)
    values_0 = [tf.constant(0, dtype=tf.int32), tf.zeros([10, 100])]
    cond = lambda i, val: tf.less(i, 10)
    def _update(i, val):
        row = tf.random_normal([1, 100])
        update = val + tf.concat(0, [tf.zeros([i, 100]),
                                     row,
                                     tf.zeros([10-1-i, 100])])
       # Just to verify sizing
        print 'update = ', update.get_shape().as_list(), \
            ' | values_0 = ', values_0[1].get_shape().as_list()

        return [i+i, update]

    _, values_t = tf.while_loop(cond, _update, values_0,
                                parallel_iterations=10)

    print sess.run(values_t)
```

Is this expected behavior? I want to update different rows of the matrix in parallel and this seemed somewhat logical to me. Since each row is independent it ""shouldn't"" really collide even if it is in parallel."
5951,possible bug for saver.restore not compact with previous version of tensorflow in tensorflow r-0.12,"NOTE: Only file GitHub issues for bugs and feature requests.  All other topics will be closed.

For general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).
To make bugs and feature requests more easy to find and organize, we close issues that are deemed
out of scope for GitHub Issues and point people to StackOverflow.

For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.

### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?

### Environment info
Operating System: Ubuntu 16.04.1 LTS

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):
`rw-r--r-- 1 root root   558720 Sep 14 19:02 /usr/local/cuda-8.0/lib64/libcudadevrt.a
lrwxrwxrwx 1 root root       16 Sep 14 19:05 /usr/local/cuda-8.0/lib64/libcudart.so -> libcudart.so.8.0
lrwxrwxrwx 1 root root       19 Sep 14 19:05 /usr/local/cuda-8.0/lib64/libcudart.so.8.0 -> libcudart.so.8.0.44
-rw-r--r-- 1 root root   415432 Sep 14 19:02 /usr/local/cuda-8.0/lib64/libcudart.so.8.0.44
-rw-r--r-- 1 root root   775162 Sep 14 19:02 /usr/local/cuda-8.0/lib64/libcudart_static.a
lrwxrwxrwx 1 root root       13 Oct 13 23:19 /usr/local/cuda-8.0/lib64/libcudnn.so -> libcudnn.so.5
lrwxrwxrwx 1 root root       17 Oct 13 23:19 /usr/local/cuda-8.0/lib64/libcudnn.so.5 -> libcudnn.so.5.1.5
-rw-r--r-- 1 root root 79337624 Oct 13 23:17 /usr/local/cuda-8.0/lib64/libcudnn.so.5.1.5
-rw-r--r-- 1 root root 69756172 Oct 13 23:17 /usr/local/cuda-8.0/lib64/libcudnn_static.a`

If installed from binary pip package, provide:

1. A link to the pip package you installed: https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow_gpu-0.12.0rc0-cp27-none-linux_x86_64.whl
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.
0.12.0-rc0

If installed from source, provide 

1. The commit hash (`git rev-parse HEAD`)
2. The output of `bazel version`

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)
I have a model which saved by tensorflow-0.11, for example:
```
import tensorflow as tf
import numpy as np
x_data = np.random.rand(100).astype(np.float32)
y_data = x_data * 0.1 + 0.3

W = tf.Variable(tf.random_uniform([1], -1.0, 1.0))
b = tf.Variable(tf.zeros([1]))
y = W * x_data + b
all_vars = tf.trainable_variables()
sess=tf.InteractiveSession()
tf.initialize_all_variables().run()
saver = tf.train.Saver(all_vars)

saver.save(sess,""./model.ckpt"")

sess.close()
```
after update to tensorflow 0.12 version, and when I load the model by:

```
import tensorflow as tf
import numpy as np
x_data = np.random.rand(100).astype(np.float32)
y_data = x_data * 0.1 + 0.3
W = tf.Variable(tf.random_uniform([1], -1.0, 1.0))
b = tf.Variable(tf.zeros([1]))
y = W * x_data + b
all_vars = tf.trainable_variables()
sess=tf.InteractiveSession()
tf.initialize_all_variables().run()
saver = tf.train.Saver(all_vars)

saver.restore(sess,""model.ckpt"")

sess.close()
```
the error rises, log output as follows 

### What other attempted solutions have you tried?
I have no problem to restore it in tensorflow 0.11

### Logs or other output that would be helpful
(If logs are large, please upload as attachment or provide link).
```
W tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for model.ckpt
W tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for model.ckpt
---------------------------------------------------------------------------
NotFoundError                             Traceback (most recent call last)
<ipython-input-3-debe9897f9a0> in <module>()
----> 1 saver.restore(sess,""model.ckpt"")

/home/fctl/.local/lib/python2.7/site-packages/tensorflow/python/training/saver.pyc in restore(self, sess, save_path)
   1386       return
   1387     sess.run(self.saver_def.restore_op_name,
-> 1388              {self.saver_def.filename_tensor_name: save_path})
   1389 
   1390   @staticmethod

/home/fctl/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in run(self, fetches, feed_dict, options, run_metadata)
    764     try:
    765       result = self._run(None, fetches, feed_dict, options_ptr,
--> 766                          run_metadata_ptr)
    767       if run_metadata:
    768         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)

/home/fctl/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in _run(self, handle, fetches, feed_dict, options, run_metadata)
    962     if final_fetches or final_targets:
    963       results = self._do_run(handle, final_targets, final_fetches,
--> 964                              feed_dict_string, options, run_metadata)
    965     else:
    966       results = []

/home/fctl/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)
   1012     if handle is None:
   1013       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,
-> 1014                            target_list, options, run_metadata)
   1015     else:
   1016       return self._do_call(_prun_fn, self._session, handle, feed_dict,

/home/fctl/.local/lib/python2.7/site-packages/tensorflow/python/client/session.pyc in _do_call(self, fn, *args)
   1032         except KeyError:
   1033           pass
-> 1034       raise type(e)(node_def, op, message)
   1035 
   1036   def _extend_graph(self):

NotFoundError: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for model.ckpt
	 [[Node: save/RestoreV2_1 = RestoreV2[dtypes=[DT_FLOAT], _device=""/job:localhost/replica:0/task:0/cpu:0""](_recv_save/Const_0, save/RestoreV2_1/tensor_names, save/RestoreV2_1/shape_and_slices)]]
	 [[Node: save/RestoreV2_1/_1 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device_incarnation=1, tensor_name=""edge_9_save/RestoreV2_1"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/gpu:0""]()]]

Caused by op u'save/RestoreV2_1', defined at:
  File ""/usr/bin/ipython"", line 5, in <module>
    start_ipython()
  File ""/home/fctl/.local/lib/python2.7/site-packages/IPython/__init__.py"", line 119, in start_ipython
    return launch_new_instance(argv=argv, **kwargs)
  File ""/home/fctl/.local/lib/python2.7/site-packages/traitlets/config/application.py"", line 658, in launch_instance
    app.start()
  File ""/home/fctl/.local/lib/python2.7/site-packages/IPython/terminal/ipapp.py"", line 348, in start
    self.shell.mainloop()
  File ""/home/fctl/.local/lib/python2.7/site-packages/IPython/terminal/interactiveshell.py"", line 440, in mainloop
    self.interact()
  File ""/home/fctl/.local/lib/python2.7/site-packages/IPython/terminal/interactiveshell.py"", line 431, in interact
    self.run_cell(code, store_history=True)
  File ""/home/fctl/.local/lib/python2.7/site-packages/IPython/core/interactiveshell.py"", line 2717, in run_cell
    interactivity=interactivity, compiler=compiler, result=result)
  File ""/home/fctl/.local/lib/python2.7/site-packages/IPython/core/interactiveshell.py"", line 2821, in run_ast_nodes
    if self.run_code(code, result):
  File ""/home/fctl/.local/lib/python2.7/site-packages/IPython/core/interactiveshell.py"", line 2881, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File ""<ipython-input-2-ba9a814a49ca>"", line 1, in <module>
    saver = tf.train.Saver(all_vars)
  File ""/home/fctl/.local/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 1000, in __init__
    self.build()
  File ""/home/fctl/.local/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 1030, in build
    restore_sequentially=self._restore_sequentially)
  File ""/home/fctl/.local/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 624, in build
    restore_sequentially, reshape)
  File ""/home/fctl/.local/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 361, in _AddRestoreOps
    tensors = self.restore_op(filename_tensor, saveable, preferred_shard)
  File ""/home/fctl/.local/lib/python2.7/site-packages/tensorflow/python/training/saver.py"", line 200, in restore_op
    [spec.tensor.dtype])[0])
  File ""/home/fctl/.local/lib/python2.7/site-packages/tensorflow/python/ops/gen_io_ops.py"", line 441, in restore_v2
    dtypes=dtypes, name=name)
  File ""/home/fctl/.local/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py"", line 759, in apply_op
    op_def=op_def)
  File ""/home/fctl/.local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 2240, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/home/fctl/.local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 1128, in __init__
    self._traceback = _extract_stack()

NotFoundError (see above for traceback): Unsuccessful TensorSliceReader constructor: Failed to find any matching files for model.ckpt
	 [[Node: save/RestoreV2_1 = RestoreV2[dtypes=[DT_FLOAT], _device=""/job:localhost/replica:0/task:0/cpu:0""](_recv_save/Const_0, save/RestoreV2_1/tensor_names, save/RestoreV2_1/shape_and_slices)]]
	 [[Node: save/RestoreV2_1/_1 = _Recv[client_terminated=false, recv_device=""/job:localhost/replica:0/task:0/gpu:0"", send_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device_incarnation=1, tensor_name=""edge_9_save/RestoreV2_1"", tensor_type=DT_FLOAT, _device=""/job:localhost/replica:0/task:0/gpu:0""]()]]

```"
5950,get error when directly running retrain.py (without build) ,"I get error when directly running retrain.py, without build it first. I run it without build before, but the latest code does not work.

  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 30, in run
    sys.exit(main(sys.argv[:1] + flags_passthrough))
  File ""retrain.py"", line 798, in main
    bottleneck_tensor)
  File ""retrain.py"", line 706, in add_final_training_ops
    variable_summaries(layer_weights)
  File ""retrain.py"", line 668, in variable_summaries
    tf.summary.histogram('histogram', var)
**AttributeError: 'module' object has no attribute 'histogram'**
"
5949,"Error importing tensorflow on windows 10 ( Tensorflow 0.12.0 RC0, python3.5 )","Was excited to try out 0.12.0 RC0 for windows
Followed Tensorflow 0.12.0 RC0 Installation guide for Windows, on Windows 10. 
Ran into following error.

Python 3.5.2 (v3.5.2:4def2a2901a5, Jun 25 2016, 22:18:55) [MSC v.1900 64 bit (AMD64)] on win32
Type ""copyright"", ""credits"" or ""license()"" for more information.
>>> import tensorflow
Traceback (most recent call last):
  File ""C:\Users\hp\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 18, in swig_import_helper
    return importlib.import_module(mname)
  File ""C:\Users\hp\AppData\Local\Programs\Python\Python35\lib\importlib\__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""<frozen importlib._bootstrap>"", line 986, in _gcd_import
  File ""<frozen importlib._bootstrap>"", line 969, in _find_and_load
  File ""<frozen importlib._bootstrap>"", line 958, in _find_and_load_unlocked
  File ""<frozen importlib._bootstrap>"", line 666, in _load_unlocked
  File ""<frozen importlib._bootstrap>"", line 577, in module_from_spec
  File ""<frozen importlib._bootstrap_external>"", line 906, in create_module
  File ""<frozen importlib._bootstrap>"", line 222, in _call_with_frames_removed
ImportError: DLL load failed: The specified module could not be found.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\hp\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\__init__.py"", line 54, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\Users\hp\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 21, in <module>
    _pywrap_tensorflow = swig_import_helper()
  File ""C:\Users\hp\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 20, in swig_import_helper
    return importlib.import_module('_pywrap_tensorflow')
  File ""C:\Users\hp\AppData\Local\Programs\Python\Python35\lib\importlib\__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
ImportError: No module named '_pywrap_tensorflow'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""<pyshell#0>"", line 1, in <module>
    import tensorflow
  File ""C:\Users\hp\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\__init__.py"", line 24, in <module>
    from tensorflow.python import *
  File ""C:\Users\hp\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\__init__.py"", line 60, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""C:\Users\hp\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 18, in swig_import_helper
    return importlib.import_module(mname)
  File ""C:\Users\hp\AppData\Local\Programs\Python\Python35\lib\importlib\__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""<frozen importlib._bootstrap>"", line 986, in _gcd_import
  File ""<frozen importlib._bootstrap>"", line 969, in _find_and_load
  File ""<frozen importlib._bootstrap>"", line 958, in _find_and_load_unlocked
  File ""<frozen importlib._bootstrap>"", line 666, in _load_unlocked
  File ""<frozen importlib._bootstrap>"", line 577, in module_from_spec
  File ""<frozen importlib._bootstrap_external>"", line 906, in create_module
  File ""<frozen importlib._bootstrap>"", line 222, in _call_with_frames_removed
ImportError: DLL load failed: The specified module could not be found.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:\Users\hp\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\__init__.py"", line 54, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\Users\hp\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 21, in <module>
    _pywrap_tensorflow = swig_import_helper()
  File ""C:\Users\hp\AppData\Local\Programs\Python\Python35\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 20, in swig_import_helper
    return importlib.import_module('_pywrap_tensorflow')
  File ""C:\Users\hp\AppData\Local\Programs\Python\Python35\lib\importlib\__init__.py"", line 126, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
ImportError: No module named '_pywrap_tensorflow'


Error importing tensorflow.  Unless you are using bazel,
you should not try to import tensorflow from its source directory;
please exit the tensorflow source tree, and relaunch your python interpreter
from there."
5948,Move SummaryWriter from `train` to `summary` submodule,"Haven't seen this mentioned yet, so I figured it was worth asking. Since we're moving all of the summary operations to a separate `summary` module, would it make sense to migrate `SummaryWriter` over there as well? 
"
5946,`tf.global_variable_initializer` is misspelled as `tf.global_variable_initializers` (extra 's' at end) in release notes,"In the [release notes for 0.12.0rc0](https://github.com/tensorflow/tensorflow/releases/tag/0.12.0-rc0), the note on the renaming of `tf.initialize_all_variables` to `tf.global_variable_initializer` has a typo, calling it `tf.global_variable_initializers` instead. It's a small typo, but I think it's worth fixing since this is such an important breaking change."
5945,Release notes indicate summary ops were deprecated,"The release notes at https://github.com/tensorflow/tensorflow/releases seem to indicate that scalar_summary and a few other *_summary ops were deprecated. Yet the docs for 0.r12 still list all the *_summary ops and do not mention deprecation. Also, I do not get any warnings when using the *_summary ops."
5942,Update Cmake README Doc Reflecting 0.12r,"Now with 0.12r would be interesting to update Readme as current status, instructions or simply reference the release? "
5941,Tensorboard not showing charts after upgrade to 0.12rc0,"
Tensorboard charts (scalars, distributions, histograms) don't show up after upgrading to 0.12rc0.
No errors are logged on the server.
Check the images below to get a sense of the problem.

Operating System: Ubuntu 15.10

1. pip installation from here:
Ubuntu/Linux 64-bit, CPU only, Python 3.4
$ export TF_BINARY_URL=https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.12.0rc0-cp34-cp34m-linux_x86_64.whl

2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.
0.12.0-rc0

![tensorboard 0 11](https://cloud.githubusercontent.com/assets/11388492/20718925/46980fda-b652-11e6-852b-09a4abdf20b6.png)
![tensorboard 0 12rc0](https://cloud.githubusercontent.com/assets/11388492/20718926/46aca26a-b652-11e6-842f-873425deeb89.png)

"
5938,Saved model by TensorForestEstimator can not be freezed,"### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?
I asked a question in stackoverflow, but I guess it is a bug or inconsistency in tensorflow.

http://stackoverflow.com/questions/40849477/error-in-saving-and-using-model-of-tensorforestestimator-for-android

### Environment info
Operating System:

Mac OSX 10.10.2
Python 2.7.12

If installed from binary pip package, provide:

1. A link to the pip package you installed: https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-0.12.0rc0-py2-none-any.whl
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`. Version: 0.12.0-rc0

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)

import tensorflow as tf
import numpy as np
from freeze_graph import freeze_graph
import os
from tensorflow.contrib.learn.python.learn.estimators.random_forest import TensorForestEstimator

Creating the model and saving:
=========================
hparams = tf.contrib.tensor_forest.python.tensor_forest.ForestHParams(
        num_trees=3, max_nodes=1000, num_classes=3, num_features=4)
classifier = TensorForestEstimator(hparams, model_dir='test/')
iris = tf.contrib.learn.datasets.load_iris()
data = iris.data.astype(np.float32)
target = iris.target.astype(np.float32)
classifier.fit(x=data, y=target, steps=100)

Freezing the model:
=========================
model_name = 'test/'
checkpoint_state_name = ""checkpoint""
input_graph_name = ""graph.pbtxt""
output_graph_name = ""newgraph.pb""
input_graph_path = os.path.join(model_name, input_graph_name)
input_saver_def_path = model_name
input_binary = False
input_checkpoint_path = os.path.join(model_name, checkpoint_state_name)
output_node_names = ""sample""
restore_op_name = ""save/restore_all""
filename_tensor_name = ""save/Const:0""
output_graph_path = os.path.join(model_name, output_graph_name)
clear_devices = True
freeze_graph(input_graph_path, input_saver_def_path,
                          input_binary, input_checkpoint_path,
                          output_node_names, restore_op_name,
                          filename_tensor_name, output_graph_path,
                          clear_devices, """")

### Logs or other output that would be helpful
(If logs are large, please upload as attachment or provide link).

The code can create and save the model perfectly (I can open the graph by tensorboard), but I get the following error for freezing the graph:

Traceback (most recent call last):
  File ""/XXXXX/model/test.py"", line 41, in <module>
    clear_devices, """")
  File ""/XXXXX/model/freeze_graph.py"", line 99, in freeze_graph
    _ = tf.import_graph_def(input_graph_def, name="""")
  File ""/XXXXX/lib/python2.7/site-packages/tensorflow/python/framework/importer.py"", line 258, in import_graph_def
    op_def = op_dict[node.op]
KeyError: u'TreePredictions'

When I am building the model, I get the following warning:

Estimator is decoupled from Scikit Learn interface by moving into
separate class SKCompat. Arguments x, y and batch_size are only
available in the SKCompat class, Estimator will only accept input_fn.
Example conversion:
  est = Estimator(...) -> est = SKCompat(Estimator(...))
WARNING:tensorflow:*******************************************************
WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.
WARNING:tensorflow:Consider switching to the more efficient V2 format:
WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`
WARNING:tensorflow:now on by default.
WARNING:tensorflow:*******************************************************
WARNING:tensorflow:*******************************************************
WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.
WARNING:tensorflow:Consider switching to the more efficient V2 format:
WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`
WARNING:tensorflow:now on by default.
WARNING:tensorflow:*******************************************************


"
5936,update python.platform.flags,"... in particular, merge glags's DEFINE_multi_float etc.

Is this planned for or should I do it and send a PR?"
5935,Failed to build android demo,"build android demo with ""bazel build //tensorflow/examples/android:tensorflow_demo""

**Environment:**
OS: OSX 10.11.6  64bit
branch: master
python:2.7.10
AndroidSDK: 24 BuildToolsVersion: 24.0.1
NDK: 24

To build an android apk, i suppose cuda is not required, so there is following cuda error.
**ls -l /path/to/cuda/lib/libcud***
ls: /path/to/cuda/lib/libcud*: No such file or directory
**python -c ""import tensorflow; print(tensorflow.__version__)""**
Traceback (most recent call last):
  File ""<string>"", line 1, in <module>
  File ""tensorflow/__init__.py"", line 24, in <module>
    from tensorflow.python import *
  File ""tensorflow/python/__init__.py"", line 60, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""tensorflow/python/__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
ImportError: cannot import name pywrap_tensorflow
**git rev-parse HEAD:** 5657d0dee8d87f4594b3e5902ed3e3ca8d6dfc0a
**bazel version:**
Build label: 0.4.0-homebrew
Build target: bazel-out/local-opt/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Wed Nov 2 19:15:37 2016 (1478114137)
Build timestamp: 1478114137
Build timestamp as int: 1478114137

-------------------------OUTPUT-------------------------

**ERROR:** /Volumes/ext/data/workspace/research/ai/tensorflow/tensorflow/examples/android/BUILD:53:1: Processing Android resources for //tensorflow/examples/android:tensorflow_demo failed: sandbox-exec failed: error executing command 
  (cd /private/var/tmp/_bazel_Yeeio/a35c6185f684e2289845701b593f9bd2/bazel-sandbox/7fdb6518-a872-4a3c-96e6-64bf6e8713e4-13/execroot/tensorflow && \
  exec env - \
  /usr/bin/sandbox-exec -f /private/var/tmp/_bazel_Yeeio/a35c6185f684e2289845701b593f9bd2/bazel-sandbox/7fdb6518-a872-4a3c-96e6-64bf6e8713e4-13/sandbox.sb bazel-out/host/bin/external/bazel_tools/src/tools/android/java/com/google/devtools/build/android/AndroidResourceProcessingAction --buildToolsVersion 24.0.1 --aapt bazel-out/host/bin/external/androidsdk/aapt_binary --annotationJar external/androidsdk/tools/support/annotations.jar --androidJar external/androidsdk/platforms/android-24/android.jar --primaryData tensorflow/examples/android/res:external/inception5h:tensorflow/examples/android/AndroidManifest.xml --rOutput bazel-out/local-fastbuild/bin/tensorflow/examples/android/tensorflow_demo_symbols/R.txt --srcJarOutput bazel-out/local-fastbuild/bin/tensorflow/examples/android/tensorflow_demo.srcjar --proguardOutput bazel-out/local-fastbuild/bin/tensorflow/examples/android/proguard/tensorflow_demo/_tensorflow_demo_proguard.cfg --mainDexProguardOutput bazel-out/local-fastbuild/bin/tensorflow/examples/android/proguard/tensorflow_demo/main_dex_tensorflow_demo_proguard.cfg --manifestOutput bazel-out/local-fastbuild/bin/tensorflow/examples/android/tensorflow_demo_processed_manifest/AndroidManifest.xml --resourcesOutput bazel-out/local-fastbuild/bin/tensorflow/examples/android/tensorflow_demo_files/resource_files.zip --packagePath bazel-out/local-fastbuild/bin/tensorflow/examples/android/tensorflow_demo.ap_ --debug --packageForR org.tensorflow.demo).
十一月 29, 2016 8:29:03 下午 com.google.devtools.build.android.AndroidResourceProcessingAction main
严重: Error during merging resources
Error: tensorflow/examples/android/res/layout/activity_camera.xml: Operation not permitted
	at com.android.ide.common.res2.MergingException$Builder.build(MergingException.java:129)
	at com.google.devtools.build.android.AndroidResourceProcessor.mergeData(AndroidResourceProcessor.java:1141)
	at com.google.devtools.build.android.AndroidResourceProcessingAction.main(AndroidResourceProcessingAction.java:245)
Caused by: java.nio.file.FileSystemException: tensorflow/examples/android/res/layout/activity_camera.xml: Operation not permitted
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.newByteChannel(UnixFileSystemProvider.java:214)
	at java.nio.file.Files.newByteChannel(Files.java:361)
	at java.nio.file.Files.newByteChannel(Files.java:407)
	at java.nio.file.spi.FileSystemProvider.newInputStream(FileSystemProvider.java:384)
	at java.nio.file.Files.newInputStream(Files.java:152)
	at com.google.devtools.build.android.DataValueFileWithIds.parse(DataValueFileWithIds.java:49)
	at com.google.devtools.build.android.ParsedAndroidData$ResourceFileVisitor.visitFile(ParsedAndroidData.java:306)
	at com.google.devtools.build.android.ParsedAndroidData$ResourceFileVisitor.visitFile(ParsedAndroidData.java:245)
	at java.nio.file.Files.walkFileTree(Files.java:2670)
	at com.google.devtools.build.android.ParsedAndroidData$ParsedAndroidDataBuildingPathWalker.walkResources(ParsedAndroidData.java:204)
	at com.google.devtools.build.android.UnvalidatedAndroidDirectories.walk(UnvalidatedAndroidDirectories.java:80)
	at com.google.devtools.build.android.ParsedAndroidData.from(ParsedAndroidData.java:348)
	at com.google.devtools.build.android.AndroidResourceProcessor.mergeData(AndroidResourceProcessor.java:1137)
	... 1 more

Exception in thread ""main"" Error: tensorflow/examples/android/res/layout/activity_camera.xml: Operation not permitted
	at com.android.ide.common.res2.MergingException$Builder.build(MergingException.java:129)
	at com.google.devtools.build.android.AndroidResourceProcessor.mergeData(AndroidResourceProcessor.java:1141)
	at com.google.devtools.build.android.AndroidResourceProcessingAction.main(AndroidResourceProcessingAction.java:245)
Caused by: java.nio.file.FileSystemException: tensorflow/examples/android/res/layout/activity_camera.xml: Operation not permitted
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:91)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.newByteChannel(UnixFileSystemProvider.java:214)
	at java.nio.file.Files.newByteChannel(Files.java:361)
	at java.nio.file.Files.newByteChannel(Files.java:407)
	at java.nio.file.spi.FileSystemProvider.newInputStream(FileSystemProvider.java:384)
	at java.nio.file.Files.newInputStream(Files.java:152)
	at com.google.devtools.build.android.DataValueFileWithIds.parse(DataValueFileWithIds.java:49)
	at com.google.devtools.build.android.ParsedAndroidData$ResourceFileVisitor.visitFile(ParsedAndroidData.java:306)
	at com.google.devtools.build.android.ParsedAndroidData$ResourceFileVisitor.visitFile(ParsedAndroidData.java:245)
	at java.nio.file.Files.walkFileTree(Files.java:2670)
	at com.google.devtools.build.android.ParsedAndroidData$ParsedAndroidDataBuildingPathWalker.walkResources(ParsedAndroidData.java:204)
	at com.google.devtools.build.android.UnvalidatedAndroidDirectories.walk(UnvalidatedAndroidDirectories.java:80)
	at com.google.devtools.build.android.ParsedAndroidData.from(ParsedAndroidData.java:348)
	at com.google.devtools.build.android.AndroidResourceProcessor.mergeData(AndroidResourceProcessor.java:1137)
	... 1 more
Target //tensorflow/examples/android:tensorflow_demo failed to build
"
5934,Errors on AWS with 8 NVIDIA K80 cards.,"### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?

convnet-benchmarks/tensorflow$ python benchmark_alexnet.py 
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcublas.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcudnn.so.5 locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcufft.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcurand.so.8.0 locally
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:925] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/core/common_runtime/gpu/gpu_device.cc:951] Found device 0 with properties: 
name: Tesla K80
major: 3 minor: 7 memoryClockRate (GHz) 0.8235
pciBusID 0000:00:17.0
Total memory: 11.17GiB
Free memory: 11.11GiB
W tensorflow/stream_executor/cuda/cuda_driver.cc:572] creating context when one is currently active; existing: 0x31a4790
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:925] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/core/common_runtime/gpu/gpu_device.cc:951] Found device 1 with properties: 

I tensorflow/core/common_runtime/gpu/gpu_device.cc:972] DMA: 0 1 2 3 4 5 6 7 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] 0:   Y Y Y Y Y Y Y Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] 1:   Y Y Y Y Y Y Y Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] 2:   Y Y Y Y Y Y Y Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] 3:   Y Y Y Y Y Y Y Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] 4:   Y Y Y Y Y Y Y Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] 5:   Y Y Y Y Y Y Y Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] 6:   Y Y Y Y Y Y Y Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] 7:   Y Y Y Y Y Y Y Y 
I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:00:17.0)
I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Creating TensorFlow device (/gpu:1) -> (device: 1, name: Tesla K80, pci bus id: 0000:00:18.0)
I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Creating TensorFlow device (/gpu:2) -> (device: 2, name: Tesla K80, pci bus id: 0000:00:19.0)
I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Creating TensorFlow device (/gpu:3) -> (device: 3, name: Tesla K80, pci bus id: 0000:00:1a.0)
I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Creating TensorFlow device (/gpu:4) -> (device: 4, name: Tesla K80, pci bus id: 0000:00:1b.0)
I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Creating TensorFlow device (/gpu:5) -> (device: 5, name: Tesla K80, pci bus id: 0000:00:1c.0)
I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Creating TensorFlow device (/gpu:6) -> (device: 6, name: Tesla K80, pci bus id: 0000:00:1d.0)
I tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Creating TensorFlow device (/gpu:7) -> (device: 7, name: Tesla K80, pci bus id: 0000:00:1e.0)
E tensorflow/stream_executor/cuda/cuda_driver.cc:1110] failed to synchronize the stop event: CUDA_ERROR_MISALIGNED_ADDRESS
E tensorflow/stream_executor/cuda/cuda_timer.cc:54] Internal: error destroying CUDA event in context 0x34d6b30: CUDA_ERROR_MISALIGNED_ADDRESS
E tensorflow/stream_executor/cuda/cuda_timer.cc:59] Internal: error destroying CUDA event in context 0x34d6b30: CUDA_ERROR_MISALIGNED_ADDRESS
F tensorflow/stream_executor/cuda/cuda_dnn.cc:1979] failed to enqueue convolution on stream: CUDNN_STATUS_EXECUTION_FAILED
Aborted (core dumped)

### Environment info
Operating System:

DISTRIB_ID=Ubuntu
DISTRIB_RELEASE=16.04
DISTRIB_CODENAME=xenial
DISTRIB_DESCRIPTION=""Ubuntu 16.04.1 LTS""

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):
CUDA 8.0 (from: http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64/cuda-repo-ubuntu1604_8.0.44-1_amd64.deb)
cudnn:5.1

If installed from source, provide 
1. https://github.com/tensorflow/tensorflow/archive/v0.11.0.tar.gz

2. The output of `bazel version`
Build label: 0.3.2
Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Fri Oct 7 17:25:10 2016 (1475861110)
Build timestamp: 1475861110
Build timestamp as int: 1475861110

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)
python https://github.com/soumith/convnet-benchmarks/blob/master/tensorflow/benchmark_alexnet.py

### What other attempted solutions have you tried?
reinstall tensorflow and reconfigure the environment.
If only has 1 K80 card, it is success.

### Logs or other output that would be helpful
(If logs are large, please upload as attachment or provide link).
"
5933,http://download.tensorflow.org/models/image/imagenet/inception-2015-12-05.tgz failing to download,"sidra@ironheart:/tmp$ wget http://download.tensorflow.org/models/image/imagenet/inception-2015-12-05.tgz
--2016-11-29 14:23:24--  http://download.tensorflow.org/models/image/imagenet/inception-2015-12-05.tgz
Resolving download.tensorflow.org (download.tensorflow.org)... 216.58.208.240, 2a00:1450:4007:80e::2010
Connecting to download.tensorflow.org (download.tensorflow.org)|216.58.208.240|:80... connected.
HTTP request sent, awaiting response... 200 OK
Length: 88931400 (85M) [application/x-compressed-tar]
Saving to: ‘inception-2015-12-05.tgz’

inception-2015-12-05.tgz                             0%[                                                                                                                 ]  15.34K  --.-KB/s    in 0.1s    

2016-11-29 14:23:29 (113 KB/s) - Read error at byte 15709/88931400 (Connection reset by peer). Retrying.

--2016-11-29 14:23:30--  (try: 2)  http://download.tensorflow.org/models/image/imagenet/inception-2015-12-05.tgz
Connecting to download.tensorflow.org (download.tensorflow.org)|216.58.208.240|:80... connected.
HTTP request sent, awaiting response... 206 Partial Content
Length: 88931400 (85M), 88915691 (85M) remaining [application/x-compressed-tar]
Saving to: ‘inception-2015-12-05.tgz’

inception-2015-12-05.tgz                             0%[                                                                                                                 ]  30.62K  94.9KB/s    in 0.2s    

2016-11-29 14:23:31 (94.9 KB/s) - Read error at byte 31359/88931400 (Connection reset by peer). Retrying.

--2016-11-29 14:23:33--  (try: 3)  http://download.tensorflow.org/models/image/imagenet/inception-2015-12-05.tgz
Connecting to download.tensorflow.org (download.tensorflow.org)|216.58.208.240|:80... connected.
HTTP request sent, awaiting response... 206 Partial Content
Length: 88931400 (85M), 88900041 (85M) remaining [application/x-compressed-tar]
Saving to: ‘inception-2015-12-05.tgz’

inception-2015-12-05.tgz                             0%[                                                                                                                 ]  45.91K  --.-KB/s    in 0.1s    

2016-11-29 14:23:34 (113 KB/s) - Read error at byte 47009/88931400 (Connection reset by peer). Retrying.

"
5932,"W tensorflow/core/framework/op_kernel.cc:975] Invalid argument: Received a label value of 255 which is outside the valid range of [0, 10).","I use cifar10 model training my dataset,which is made by tf.python_io.TFRecordWriter() .
I am sure labels in dataset are right,because it's running ok on Ubuntu PC but  get Error Invalid argument: Received a label value of 255 which is outside the valid range of [0, 10)  on Mac and GPU Server.

W tensorflow/core/framework/op_kernel.cc:975] Invalid argument: Received a label value of 255 which is outside the valid range of [0, 10).  Label values: 65 229 184 161 102 117 112 160 66 93 107 117 131 122 129 132 113 163 149 130 75 52 109 84 161 165 99 203 82 42 57 179 155 63 126 49 172 50 144 224 152 220 164 82 195 169 171 125 107 127 70 60 93 115 165 143 78 116 60 153 113 62 89 175 125 90 85 178 167 200 133 168 125 92 62 93 166 141 98 172 102 103 72 179 138 108 49 176 46 70 55 101 141 144 107 126 60 146 108 77 125 59 58 109 171 107 63 151 55 93 172 131 52 128 75 167 255 97 108 171 113 130 77 166 150 132 62 196
Traceback (most recent call last):
  File ""/Users/yangk/cifar10/cifar10_train.py"", line 137, in <module>
    tf.app.run()
  File ""/Library/Python/2.7/site-packages/tensorflow/python/platform/app.py"", line 43, in run
    sys.exit(main(sys.argv[:1] + flags_passthrough))
  File ""/Users/yangk/cifar10/cifar10_train.py"", line 133, in main
    train()
  File ""/Users/yangk/cifar10/cifar10_train.py"", line 103, in train
    _, loss_value = sess.run([train_op, loss])
  File ""/Library/Python/2.7/site-packages/tensorflow/python/client/session.py"", line 766, in run
    run_metadata_ptr)
  File ""/Library/Python/2.7/site-packages/tensorflow/python/client/session.py"", line 964, in _run
    feed_dict_string, options, run_metadata)
  File ""/Library/Python/2.7/site-packages/tensorflow/python/client/session.py"", line 1014, in _do_run
    target_list, options, run_metadata)
  File ""/Library/Python/2.7/site-packages/tensorflow/python/client/session.py"", line 1034, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InvalidArgumentError: Received a label value of 255 which is outside the valid range of [0, 10).  Label values: 65 229 184 161 102 117 112 160 66 93 107 117 131 122 129 132 113 163 149 130 75 52 109 84 161 165 99 203 82 42 57 179 155 63 126 49 172 50 144 224 152 220 164 82 195 169 171 125 107 127 70 60 93 115 165 143 78 116 60 153 113 62 89 175 125 90 85 178 167 200 133 168 125 92 62 93 166 141 98 172 102 103 72 179 138 108 49 176 46 70 55 101 141 144 107 126 60 146 108 77 125 59 58 109 171 107 63 151 55 93 172 131 52 128 75 167 255 97 108 171 113 130 77 166 150 132 62 196
	 [[Node: cross_entropy_per_example/cross_entropy_per_example = SparseSoftmaxCrossEntropyWithLogits[T=DT_FLOAT, Tlabels=DT_INT64, _device=""/job:localhost/replica:0/task:0/cpu:0""](softmax_linear/softmax_linear, Cast_4)]]

Caused by op u'cross_entropy_per_example/cross_entropy_per_example', defined at:
  File ""/Users/yangk/cifar10/cifar10_train.py"", line 137, in <module>
    tf.app.run()
  File ""/Library/Python/2.7/site-packages/tensorflow/python/platform/app.py"", line 43, in run
    sys.exit(main(sys.argv[:1] + flags_passthrough))
  File ""/Users/yangk/cifar10/cifar10_train.py"", line 133, in main
    train()
  File ""/Users/yangk/cifar10/cifar10_train.py"", line 76, in train
    loss = cifar10.loss(logits, labels)
  File ""/Users/yangk/cifar10/cifar10.py"", line 289, in loss
    logits, labels, name='cross_entropy_per_example')
  File ""/Library/Python/2.7/site-packages/tensorflow/python/ops/nn_ops.py"", line 1537, in sparse_softmax_cross_entropy_with_logits
    precise_logits, labels, name=name)
  File ""/Library/Python/2.7/site-packages/tensorflow/python/ops/gen_nn_ops.py"", line 2378, in _sparse_softmax_cross_entropy_with_logits
    features=features, labels=labels, name=name)
  File ""/Library/Python/2.7/site-packages/tensorflow/python/framework/op_def_library.py"", line 763, in apply_op
    op_def=op_def)
  File ""/Library/Python/2.7/site-packages/tensorflow/python/framework/ops.py"", line 2371, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/Library/Python/2.7/site-packages/tensorflow/python/framework/ops.py"", line 1258, in __init__
    self._traceback = _extract_stack()

InvalidArgumentError (see above for traceback): Received a label value of 255 which is outside the valid range of [0, 10).  Label values: 65 229 184 161 102 117 112 160 66 93 107 117 131 122 129 132 113 163 149 130 75 52 109 84 161 165 99 203 82 42 57 179 155 63 126 49 172 50 144 224 152 220 164 82 195 169 171 125 107 127 70 60 93 115 165 143 78 116 60 153 113 62 89 175 125 90 85 178 167 200 133 168 125 92 62 93 166 141 98 172 102 103 72 179 138 108 49 176 46 70 55 101 141 144 107 126 60 146 108 77 125 59 58 109 171 107 63 151 55 93 172 131 52 128 75 167 255 97 108 171 113 130 77 166 150 132 62 196
	 [[Node: cross_entropy_per_example/cross_entropy_per_example = SparseSoftmaxCrossEntropyWithLogits[T=DT_FLOAT, Tlabels=DT_INT64, _device=""/job:localhost/replica:0/task:0/cpu:0""](softmax_linear/softmax_linear, Cast_4)]]"
5931,what is tag id or master commit id for 0.11rc2 version,"NOTE: Only file GitHub issues for bugs and feature requests.  All other topics will be closed.

For general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).
To make bugs and feature requests more easy to find and organize, we close issues that are deemed
out of scope for GitHub Issues and point people to StackOverflow.

For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.

### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?

### Environment info
Operating System:

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

If installed from binary pip package, provide:

1. A link to the pip package you installed:
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.

If installed from source, provide 

1. The commit hash (`git rev-parse HEAD`)
2. The output of `bazel version`

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)


### What other attempted solutions have you tried?


### Logs or other output that would be helpful
(If logs are large, please upload as attachment or provide link).
"
5930,base class order for tensorflow distributions,"this is a feature request for `tf.contrib.distributions`. on master (i.e., beyond version r0.11), tensorflow distributions require that the first parent class is Distribution.

https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/distributions/python/ops/distribution.py#L136-L138

this is a problem for our work with random variables in edward, which requires that random variable classes are first and Distribution is second:

https://github.com/blei-lab/edward/blob/master/edward/models/random_variable.py#L35
https://github.com/blei-lab/edward/blob/master/edward/models/random_variables.py#L33

i chatted with @ebrevdo and @jvdillon about this a few weeks ago. they said it's possible to change. (i'm adding a GitHub issue to formalize the request.) can i help in any way? it is a high priority to fix for edward as it breaks all random variable support."
5929,checkpoints file's max_to_keep not working,"### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?

cannot find any related post in the web

### Environment info
Operating System:

centos6.5   , tensorflow 0.11.0 without gpu(cpu only)

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)

```
tf.train.Saver(max_to_keep = 5)
then
saver.save(sess, checkpoint_file, global_step=step)
```
### What other attempted solutions have you tried?
***IMPORTANT*** 
I run the same code in my laptop, it's right with only 5 latest checkponits
**but** in the centos server , it generate unlimited checkponits files and the disk almost full

### Logs or other output that would be helpful
(If logs are large, please upload as attachment or provide link).

no error log"
5928,Support distributed aggregation in embedding_lookup_sparse,"The current code just gather the slice (co-located with the partition) and send back to the caller for the further aggregation with the specified combiner. In some cases, making the aggregation co-located with the variable partition can reduce latency (both computing time and transfer time).

For example, the embedding weights has shape `10000000 * 1024` with `10` partitions. The batch size is `256`. And the average number non-zero value of each feature tensor is `100`. Without aggregation, the transfer size out of each partition is around `256 * 100/10 * 1024 * 4 = 10MB`. If we make the aggregation first, the data size can be reduced to around `256 * 1024 * 4 = 1MB`. There are two benefits for the latency, first is the reduced transfer size, the second is partial of the aggregation is done in parallel.

It's suggested to add an option with this feature default to false (whether to use this feature depends on the devices speed up ratio and transfer bandwidth)."
5927,Cannot able to install Tensorflow r0.12 in Windows 10 - HTTP error 404,"I was following the documentation of the [tensorflow](https://www.tensorflow.org/versions/r0.12/get_started/os_setup.html#pip-installation-on-windows) with respect to installing tensorflow in windows 10.

When I execute pip command I'm getting following error

**pip install --upgrade https://storage.googleapis.com/tensorflow/windows/cpu/tensorflow-0.12.0rc0-cp35-cp35m-win_amd64.whl**

Collecting tensorflow==0.12.0rc0 from https://storage.googleapis.com/tensorflow/windows/cpu/tensorflow-0.12.0rc0-cp35-cp35m-win_amd64.whl
  HTTP error 404 while getting https://storage.googleapis.com/tensorflow/windows/cpu/tensorflow-0.12.0rc0-cp35-cp35m-win_amd64.whl
  Could not install requirement tensorflow==0.12.0rc0 from https://storage.googleapis.com/tensorflow/windows/cpu/tensorflow-0.12.0rc0-cp35-cp35m-win_amd64.whl because of error 404 Client Error: Not Found for url: https://storage.googleapis.com/tensorflow/windows/cpu/tensorflow-0.12.0rc0-cp35-cp35m-win_amd64.whl
Could not install requirement tensorflow==0.12.0rc0 from https://storage.googleapis.com/tensorflow/windows/cpu/tensorflow-0.12.0rc0-cp35-cp35m-win_amd64.whl because of HTTP error 404 Client Error: Not Found for url: https://storage.googleapis.com/tensorflow/windows/cpu/tensorflow-0.12.0rc0-cp35-cp35m-win_amd64.whl for URL https://storage.googleapis.com/tensorflow/windows/cpu/tensorflow-0.12.0rc0-cp35-cp35m-win_amd64.whl"
5925,Should we use cudnn v5.0 or v5.1?,"NOTE: Only file GitHub issues for bugs and feature requests.  All other topics will be closed.

For general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).
To make bugs and feature requests more easy to find and organize, we close issues that are deemed
out of scope for GitHub Issues and point people to StackOverflow.

For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.

### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?

### Environment info
Operating System: osx Sierra

Installed version of CUDA and cuDNN:

- cuda v8.0,
- cudnn v5.0
 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

```
lib/libcuda.1.dylib     lib/libcudart.8.0.dylib lib/libcudnn.5.dylib
lib/libcuda.dylib       lib/libcudart.dylib     lib/libcudnn.dylib
lib/libcudadevrt.a      lib/libcudart_static.a  lib/libcudnn_static.a
```

If installed from binary pip package, provide:

1. A link to the pip package you installed: https://storage.googleapis.com/tensorflow/mac/gpu/tensorflow-0.11.0-py3-none-any.whl
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.

```
python3 -c ""import tensorflow; print(tensorflow.__version__)""
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcublas.dylib locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcudnn.dylib locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcufft.dylib locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcuda.1.dylib locally
I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcurand.dylib locally
0.11.0rc2
```

If installed from source, provide 

1. The commit hash (`git rev-parse HEAD`)
2. The output of `bazel version`

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)

```
cd /usr/local/lib/python3.5/site-packages/tensorflow/models/image/mnist
python3 convolutional.py
````

### What other attempted solutions have you tried?

**Install cudnn v5.1**

### Logs or other output that would be helpful
(If logs are large, please upload as attachment or provide link).

The code sample failed, complaining about cudnn and tensorflow version mismatch. I lost the original output. It said something like the tensorflow is build with cudnn 51000x, but the loaded cudnn lib is 50000.

Then, I installed cudnn v5.1, and the message is gone, and the sample code runs.

I followed the installation instruction on https://www.tensorflow.org/versions/master/get_started/os_setup.html#pip-installation. I think either the instruction needs update to tell people to install cudnn v5.1; or something mistakenly build tensorflow with cudnn v5.1 and released it.
"
5924,PLZ help.thx.tensorflow constatnly fails to download some packages!,"On a KNL server, I tried to install Tensorflow by compiling way. I'm not root so I manually set the env in my directory.  And there is no network on the server, so I use SSH FORWARD.
Here is the problem I've met:


ERROR: /home/guest/tensorflow/tensorflow/tensorboard/bower/BUILD:5:1: no such package '@iron_resizable_behavior//': Error downloading from https://github.com/polymerelements/iron-resizable-behavior/archive/v1.0.3.tar.gz to /home/guest/.cache/bazel/_bazel_guest/ac941aabf1be9475583be832ae449128/external/iron_resizable_behavior: Error downloading https://github.com/polymerelements/iron-resizable-behavior/archive/v1.0.3.tar.gz to /home/guest/.cache/bazel/_bazel_guest/ac941aabf1be9475583be832ae449128/external/iron_resizable_behavior/v1.0.3.tar.gz: Timed out connecting to https://github.com/polymerelements/iron-resizable-behavior/archive/v1.0.3.tar.gz : Read timed out and referenced by '//tensorflow/tensorboard/bower:bower'.
ERROR: /home/guest/tensorflow/tensorflow/tensorboard/bower/BUILD:5:1: no such package '@iron_resizable_behavior//': Error downloading from https://github.com/polymerelements/iron-resizable-behavior/archive/v1.0.3.tar.gz to /home/guest/.cache/bazel/_bazel_guest/ac941aabf1be9475583be832ae449128/external/iron_resizable_behavior: Error downloading https://github.com/polymerelements/iron-resizable-behavior/archive/v1.0.3.tar.gz to /home/guest/.cache/bazel/_bazel_guest/ac941aabf1be9475583be832ae449128/external/iron_resizable_behavior/v1.0.3.tar.gz: Timed out connecting to https://github.com/polymerelements/iron-resizable-behavior/archive/v1.0.3.tar.gz : Read timed out and referenced by '//tensorflow/tensorboard/bower:bower'.
ERROR: Evaluation of query ""deps((//tensorflow/... union @bazel_tools//tools/jdk:toolchain))"" failed: errors were encountered while computing transitive closure.
"
5922,"the sample code ""translate.py"" does not train a correct model","After v0.10, the seq2seq sample code, translate.py, although runnable, but does not give correct output.
I trained a default model using downloaded EN->FR data set, the trained system cannot even translate basic words like: I, you, he and she.
Does someone know why?


Below are my system info:
    Operating System:
    Ubuntu 14.04.5 LTS

    Installed version of CUDA and cuDNN:
    /usr/local/cuda-8.0
    cudnn-8.0-linux-x64-v5.1.tgz

    It is installed from binary pip package

    A link to the pip package you installed:
    https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.11.0-cp27-none-linux_x86_64.whl

    The output from python -c ""import tensorflow; print(tensorflow.version)""
    xuancong@wxc-i2r:~/projects/tf-rnnlm$ python -c ""import tensorflow; print(tensorflow.version)""
    I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcublas.so locally
    I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcudnn.so locally
    I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcufft.so locally
    I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcuda.so.1 locally
    I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcurand.so locally
    0.11.0

"
5921,IOS - No OpKernel was registered to support Op ‘SpaceToBatchND' with these attrs,"I am trying to use `tf.nn.atrous_conv2d` to solve a segmentation problem. It works on my mac but when I saved this graph using `convert_variables_to_constants` and `tf.train.write_graph` then read it in using C++ API trying to get it running on my iPad, I got this error:

```
Could not create TensorFlow Graph: Invalid argument: No OpKernel was registered to support Op 'SpaceToBatchND' with these attrs.  Registered devices: [CPU], Registered kernels:
  <no registered kernels>

	 [[Node: CCC/SpaceToBatchND = SpaceToBatchND[T=DT_FLOAT, Tblock_shape=DT_INT32, Tpaddings=DT_INT32](BBB, CCC/SpaceToBatchND/block_shape, CCC/SpaceToBatchND/paddings)]]
F /workplace/testTensorFlow/testTensorFlowXcode/Classes/test_tensorflow.mm:162] test_tensorflow.mm : Couldn't load model: Invalid argument: No OpKernel was registered to support Op 'SpaceToBatchND' with these attrs.  Registered devices: [CPU], Registered kernels:
  <no registered kernels>

	 [[Node: CCC/SpaceToBatchND = SpaceToBatchND[T=DT_FLOAT, Tblock_shape=DT_INT32, Tpaddings=DT_INT32](BBB, CCC/SpaceToBatchND/block_shape, CCC/SpaceToBatchND/paddings)]]
```

## What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?

https://github.com/tensorflow/tensorflow/issues/1269
https://github.com/tensorflow/tensorflow/issues/2680
https://github.com/tensorflow/tensorflow/issues/2929

## If possible, provide a minimal reproducible example

In Python:

```
import tensorflow as tf
from tensorflow.python.framework.graph_util import convert_variables_to_constants

flt = tf.Variable(tf.random_normal([3, 3, 3, 3], stddev=0.35), name='AAA')
inputs = tf.placeholder(shape=(1, 224, 224, 3), dtype=tf.float32, name='BBB')
conv = tf.nn.atrous_conv2d(value=inputs, filters=flt, rate=2, padding='SAME', name='CCC')

sess = tf.Session(config=config)
init = tf.initialize_all_variables()
sess.run(init)

with sess.as_default():
    minimal_graph = convert_variables_to_constants(sess, sess.graph_def, [""CCC""])
    tf.train.write_graph(minimal_graph, '.', 'rand_init_min_cpu.pb', as_text=False)
```

I can load and run graphs not using atrous_conv2d correctly, so I think my C++ code is ok.
 
## What other attempted solutions have you tried?

Following the related issues above, I tried to add SpaceToBatchND kernel to 

`tensorflow/contrib/makefile/tf_op_files.txt`

I found SpaceToBatchND in array_ops.cc (which has already been included in `tf_op_files.txt`)
and maybe in these two files:

`tensorflow/core/kernels/spacetobatch_op.cc`
`tensorflow/core/kernels/batchtospace_op.cc`

So I added them to `tf_op_files.txt`, but then when I `./build_all_ios.sh`, I got these errors (short version, I can post them all out if you need):

```
Undefined symbols for architecture armv7:     
""tensorflow::functor::SpaceToBatchFunctor<Eigen::ThreadPoolDevice, float, 4, $
rue>::operator()(Eigen::ThreadPoolDevice const&, Eigen::TensorMap<Eigen::Tensor$
float, 6, 1, int>, 16, Eigen::MakePointer>, long long const*, long long const*, 
Eigen::TensorMap<Eigen::Tensor<float const, 6, 1, int>, 16, Eigen::MakePointer>$
"", referenced from: 

...

void tensorflow::(anonymous namespace)::SpaceToBatchOpCompute<Eigen::Threa
dPoolDevice, int>(tensorflow::OpKernelContext*, tensorflow::Tensor const&, tenso
rflow::Tensor const&, tensorflow::Tensor const&) in libtensorflow-core-armv7.a(s
pacetobatch_op.o)
ld: symbol(s) not found for architecture armv7
clang: error: linker command failed with exit code 1 (use -v to see invocation)
make: *** [workingspace/tensorflow/tensorflow/contrib/makefile/gen/b
in/ios_ARMV7/benchmark] Error 1
+ '[' 2 -ne 0 ']'
+ echo 'armv7 compilation failed.'
armv7 compilation failed.
```

## Environment info

Operating System:
mac: OSX 10.11.6
iPad: IOS 10.1.1

Installed version of CUDA and cuDNN:
None

Source:
commit d6b25985ac219a6e58d186a2beb74d5e8d9e4533

bazel version:                                     
.................................................
Build label: 0.4.0-homebrew
Build target: bazel-out/local-opt/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Wed Nov 2 19:15:37 2016 (1478114137)
Build timestamp: 1478114137
Build timestamp as int: 1478114137
"
5920,Make activation function support sparse tensors,"Usually, the input features need to be normalized, for example, when the feature is *duration of app usage* in *wide and deep* model. Usually you are not clear which normalization function is best for your model when you generate the features. So in the model, an activation function(for example softsign) can be applied to the input first. Currently sparse tensor is not supported. This change can be trivial.
"
5919,strip_unused should remove Switch Node with Constant Input,`strip_unused` does not appear to remove a `Switch` node with constant input.
5918,add convert_placeholders_to_constants to tensorflow,"Add `convert_placeholders_to_constants` which permanently injects a constant to fill in the value of a Placeholder.

Repost from [SO](http://stackoverflow.com/questions/40852729/permanently-inject-constant-into-tensorflow-graph-for-inference/40852855). /CC @mrry "
5917,"Broken link in ""A Tool Developer's Guide..."" for graph_metrics.py","In [this page](https://www.tensorflow.org/versions/master/how_tos/tool_developers/index.html), 
graph_metrics.py link broken. graph_metrics.py is deleted by [this commit](https://github.com/tensorflow/tensorflow/commit/d8c94dba8f53626077b21f90df309577827a0f18#diff-2839c4fb2e611a1359978388f55f3583)."
5914,No documentation for sending input parameters of request to TensorFlow Serving ,"I am running the sample iris program in TensorFlow Serving. Since it is a TF.Learn model, I am exporting the model using the following `classifier.export(export_dir=model_dir,signature_fn=my_classification_signature_fn)`

and the signature_fn is defined as shown below:

```
def my_classification_signature_fn(examples, unused_features, predictions):
  """"""Creates classification signature from given examples and predictions.
  Args:
    examples: `Tensor`.
    unused_features: `dict` of `Tensor`s.
    predictions: `Tensor` or dict of tensors that contains the classes tensor
      as in {'classes': `Tensor`}.
  Returns:
    Tuple of default classification signature and empty named signatures.
  Raises:
    ValueError: If examples is `None`.
  """"""
  if examples is None:
    raise ValueError('examples cannot be None when using this signature fn.')

  if isinstance(predictions, dict):
    default_signature = exporter.classification_signature(
        examples, classes_tensor=predictions['classes'])

  else:

    default_signature = exporter.classification_signature(
        examples, classes_tensor=predictions)
  named_graph_signatures={
        'inputs': exporter.generic_signature({'x_values': examples}),
        'outputs': exporter.generic_signature({'preds': predictions})}    
  return default_signature, named_graph_signatures
```
The model gets successfully exported using the following piece of code.

I have created a client which makes real-time predictions using TensorFlow Serving.

The following is the code for the client:

```
flags.DEFINE_string(""model_dir"", ""/tmp/iris_model_dir"", ""Base directory for output models."")
tf.app.flags.DEFINE_integer('concurrency', 1,
                            'maximum number of concurrent inference requests')
tf.app.flags.DEFINE_string('server', '', 'PredictionService host:port')

#connection
host, port = FLAGS.server.split(':')
channel = implementations.insecure_channel(host, int(port))
stub = prediction_service_pb2.beta_create_PredictionService_stub(channel)


# Classify two new flower samples.
new_samples = np.array([5.8, 3.1, 5.0, 1.7], dtype=float)

request = predict_pb2.PredictRequest()
request.model_spec.name = 'iris'

request.inputs[""x_values""].CopyFrom(
        tf.contrib.util.make_tensor_proto(new_samples))

result = stub.Predict(request, 10.0)  # 10 secs timeout
```

However, on making the predictions, the following error is displayed:

`grpc.framework.interfaces.face.face.AbortionError: AbortionError(code=StatusCode.INTERNAL, details=""Output 0 of type double does not match declared output type string for node _recv_input_example_tensor_0 = _Recv[client_terminated=true, recv_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device=""/job:localhost/replica:0/task:0/cpu:0"", send_device_incarnation=2016246895612781641, tensor_name=""input_example_tensor:0"", tensor_type=DT_STRING, _device=""/job:localhost/replica:0/task:0/cpu:0""]()"")`

Here is the entire stack trace.
![image](https://cloud.githubusercontent.com/assets/17990840/20688020/fac6285a-b58c-11e6-8a93-1fed6d78b8de.png)

The iris model is defined in the following manner:

```
# Specify that all features have real-value data
feature_columns = [tf.contrib.layers.real_valued_column("""", dimension=4)]

# Build 3 layer DNN with 10, 20, 10 units respectively.
classifier = tf.contrib.learn.DNNClassifier(feature_columns=feature_columns,
                                            hidden_units=[10, 20, 10],
                                            n_classes=3, model_dir=model_dir)

# Fit model.
classifier.fit(x=training_set.data, 
               y=training_set.target, 
               steps=2000)
```

Can someone provide some documentation for creating the client program which sends the request to TensorFlow Serving. "
5913,strip_unused assumes all placeholders are the same type,"[`strip_unused`](https://github.com/tensorflow/tensorflow/blob/5657d0dee8d87f4594b3e5902ed3e3ca8d6dfc0a/tensorflow/python/tools/strip_unused.py) assumes that all of the placeholders are of the same type which may not be the case. This method is also used by [`optimize_for_inference`](https://github.com/tensorflow/tensorflow/blob/5657d0dee8d87f4594b3e5902ed3e3ca8d6dfc0a/tensorflow/python/tools/optimize_for_inference_lib.py#L82-L85) which leads to errors when the models is loaded:
```
 msg std::__1::string ""Input 0 of node dropout6/cond/Switch was passed float from Placeholder_2:0 incompatible with expected bool."" 
```

I suggest having an option to introspect the graph to determine type."
5912,tf.nn.crelu Static shape not defined,"Currently (version 0.11.0) the static shape is not defined for crelu. Minimal example:

    f = tf.random_normal([50, 5, 7, 10])

    f2 = tf.nn.crelu(f)
    print(f2.get_shape().as_list())  # [None, None, None, None]

    f3 = tf.nn.relu(f)
    print(f3.get_shape().as_list()) # [50, 5, 7, 10]


"
5910,Transposed Atrous Convolutions,"Hi there,

I'm looking for atrous (dilated) transposed convolutions, but did not find much.
There is a brief section in the [`tf.nn.atrous_conv2d`](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/g3doc/api_docs/python/nn.md#tfnnatrous_conv2dvalue-filters-rate-padding-namenone-atrous_conv2d) doc

> Used in conjunction with bilinear interpolation, it offers an alternative to conv2d_transpose in dense prediction tasks such as semantic image segmentation, optical flow computation, or depth estimation.

But it is not quite clear how to proceed from there, it looks like tensorflow does not implement the transposed atrous convolution, yet?"
5907,FIFOQueue speed problem ,"Hi I am testing the speed of FIFOQueue. I create a queue of Tensor with type of tf.float32 and shape of (576, 3, 220, 220). Then I push a tensor to the queue, followed by pop the tensor from the queue.
The speed of single node version( sess = tf.Session())  and distributed version of tensorflow (even in single machine single process scenario, sess = tf.Session(server.target) ) differs much. 
Pushing and poping take about 0.2s in single node version while 4s in  distributed version.
I know that using distributed version of tensorflow will encounter some proto serialize overhead, but the overhead seems too much.

The main code is like this (I also give a link to full source code below, which can be used to reproduce the problem)
```
    raw_shape = [576, 3, 220, 220]
    shape = tf.TensorShape(raw_shape)
    if FLAGS.cluster:    
        server = tf.train.Server.create_local_server()
        sess = tf.Session(server.target)
    else:
        sess = tf.Session()
    with tf.device('/cpu:0'): 
        q = tf.FIFOQueue(10, tf.float32, shape)
        rand_data = tf.zeros(shape)
        init_op = tf.initialize_local_variables()
        sess.run(init_op)
        result = q.dequeue()
        x = tf.placeholder(tf.float32, shape, 'data')
        enqueue_op = q.enqueue(x)
        while True:
            log('pushing')
            sess.run(enqueue_op, feed_dict = {x: np.zeros(raw_shape)})
            log('push done')
            sess.run(result)
            log('pop done')
```


### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?

https://github.com/tensorflow/tensorflow/issues/3009 
But this issue is more related to threading, not same as mine case.

### Environment info
Operating System:
Ubuntu 14.04
CPU E5-2643 v3 @ 3.40GHz

Installed version of CUDA and cuDNN: 
None (I used CUDA_VISIBLE_DEVICES='')



If installed from source, provide 
1. The commit hash (`git rev-parse HEAD`)
d6b25985ac219a6e58d186a2beb74d5e8d9e4533
2. The output of `bazel version`
Build label: 0.4.0
Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Wed Nov 2 17:54:14 2016 (1478109254)
Build timestamp: 1478109254
Build timestamp as int: 1478109254


### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)
https://gist.github.com/gowithqi/6bcb1dc50facfd992639f09e9af463a8

Log
CUDA_VISIBLE_DEVICES='' python test_queue_release.py --cluster=true
```
2016-11-28 16:18:13.767 pushing
2016-11-28 16:18:13.998 push done
2016-11-28 16:18:14.112 pop done
2016-11-28 16:18:14.112 pushing
2016-11-28 16:18:14.337 push done
2016-11-28 16:18:14.501 pop done
2016-11-28 16:18:14.502 pushing
2016-11-28 16:18:14.746 push done
2016-11-28 16:18:14.916 pop done
2016-11-28 16:18:14.916 pushing
2016-11-28 16:18:15.155 push done
2016-11-28 16:18:15.269 pop done
```

CUDA_VISIBLE_DEVICES='' python test_queue_release.py --cluster=true
```
2016-11-28 16:17:00.218 pushing
2016-11-28 16:17:03.470 push done
2016-11-28 16:17:07.395 pop done
2016-11-28 16:17:07.395 pushing
2016-11-28 16:17:10.908 push done
2016-11-28 16:17:14.732 pop done
2016-11-28 16:17:14.733 pushing
2016-11-28 16:17:17.878 push done
2016-11-28 16:17:21.788 pop done
```
"
5905,Tensorflow - ValueError: Cannot feed value of shape,"I have 12 input integer features. Output and labels is 1 or 0. I examines MNIST example from tensorflow website.
Here is my code:

```
import tensorflow as tf
import numpy as np
def init_weights(shape):
    return tf.Variable(tf.random_normal(shape, stddev=0.01))
def model(X, w):
    return tf.matmul(X, w) # notice we use the same model as linear regression, this is because there is a baked in cost function which performs softmax and cross entropy
train_data1  = ""./data/xx.csv""
test_data1 = ""./data/xxx.csv""
train_label1 = ""./data/xxl.csv""
test_label1 = ""./data/xx.csv""
train_data = np.genfromtxt(train_data1, delimiter=',')
train_label = np.genfromtxt(train_label1, delimiter=',').astype(int)
test_data = np.genfromtxt(test_data1, delimiter=',')
test_label = np.genfromtxt(test_label1, delimiter=',').astype(int)
# Load datasets.
trX, trY, teX, teY = train_data,train_label, test_data, test_label
X = tf.placeholder(""float"", [None, 12]) # create symbolic variables
Y = tf.placeholder(""float"", [None, 2])

w = init_weights([12, 2]) 
py_x = model(X, w)

cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(py_x, Y)) # compute mean cross entropy (softmax is applied internally)
train_op = tf.train.GradientDescentOptimizer(0.05).minimize(cost) # construct optimizer
predict_op = tf.argmax(py_x, 1) # at predict time, evaluate the argmax of the logistic regression

# Launch the graph in a session
with tf.Session() as sess:
    # you need to initialize all variables
    tf.initialize_all_variables().run()

    for i in range(100):
         #for (x, y) in zip(train_X, train_Y):
             #sess.run(optimizer, feed_dict={X: trX, Y: trY})
        for start, end in zip(range(0, len(trX), 128), range(128, len(trX)+1, 128)):
            sess.run(train_op, feed_dict={X: trX[start:end], Y: trY[start:end]})
        print(i, np.mean(np.argmax(teY, axis=1) ==
                         sess.run(predict_op, feed_dict={X: teX})))

```

**But I run upper code, I get an error. The compiler says that:**
```
Traceback (most recent call last):
  File ""LRexample.py"", line 74, in <module>
    sess.run(train_op, feed_dict={X: trX[start:end], Y: trY[start:end]})
ValueError: Cannot feed value of shape (128,) for Tensor u'Placeholder_1:0', which has shape '(?, 2)
```

How can I handle this error?"
5904,slim/preprocess missing,"I would like to use slim.preprocess (as featured in slim/README.md).

Thanks,
Philip"
5902,Input tensor on GPU in C++ API,"I am trying to feed a Tensor (using the C++ API) that has memory allocated on the GPU (using GPUBFCAllocator) into a network.
Now, the placeholder in the network is on the GPU (I checked this in Tensorboard), and the memory allocated for the input tensor is on the GPU, but whenever I run the network, `nvprof --print-gpu-trace` shows me `[CUDA memcpy HtoD]` and `[CUDA memcpy DtoH]`, before the computations (i.e. convolutions etc.) start.
This suggests to me that the input tensor is being copied to CPU memory, and then back to GPU memory.

While debugging this, I found multiple hints in the source that seem to suggest the CPU is always used as device to feed tensors from.
See e.g.:
https://github.com/tensorflow/tensorflow/blob/eb56a8af24695bf8258addf28b0c53fbabff72e6/tensorflow/core/common_runtime/direct_session.cc#L264
https://github.com/tensorflow/tensorflow/blob/429905c6283d3182a816487807e97e592849ce19/tensorflow/core/common_runtime/graph_runner.cc#L109

1. Is this analysis correct?
2. How can one feed in a tensor that has memory allocated on GPU memory, without copying back and forth to CPU memory? If this is currently not possible, then I think this would be a good feature to add.
Especially when one wants to combine Tensorflow input/output with other algorithms (not in TF), one might want to keep data on the GPU, to avoid host to device and device to host transfers.

Thanks in advance.

### Environment info
Operating System: Ubuntu 16.04.1 LTS

Installed version of CUDA and cuDNN: CUDA 8.0, cuDNN 5.1.5
Output of `ls -l /usr/local/cuda/lib64/libcud*`:
```
-rw-r--r-- 1 root root 558720 Sep 15 00:02 /usr/local/cuda/lib64/libcudadevrt.a
lrwxrwxrwx 1 root root     16 Sep 15 00:05 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.8.0
lrwxrwxrwx 1 root root     19 Sep 15 00:05 /usr/local/cuda/lib64/libcudart.so.8.0 -> libcudart.so.8.0.44
-rw-r--r-- 1 root root 415432 Sep 15 00:02 /usr/local/cuda/lib64/libcudart.so.8.0.44
-rw-r--r-- 1 root root 775162 Sep 15 00:02 /usr/local/cuda/lib64/libcudart_static.a
lrwxrwxrwx 1 root root     43 Oct  3 17:03 /usr/local/cuda/lib64/libcudnn.so -> /usr/local/cudnn-8.0-v5.1/lib64/libcudnn.so
lrwxrwxrwx 1 root root     45 Oct  3 17:03 /usr/local/cuda/lib64/libcudnn.so.5 -> /usr/local/cudnn-8.0-v5.1/lib64/libcudnn.so.5
lrwxrwxrwx 1 root root     49 Oct  3 17:03 /usr/local/cuda/lib64/libcudnn.so.5.1.5 -> /usr/local/cudnn-8.0-v5.1/lib64/libcudnn.so.5.1.5
lrwxrwxrwx 1 root root     49 Oct  3 17:03 /usr/local/cuda/lib64/libcudnn_static.a -> /usr/local/cudnn-8.0-v5.1/lib64/libcudnn_static.a
```
Tensorflow installed from source:
1. The commit hash (`git rev-parse HEAD`): a5074383617a9947f248a0ddd56b94f9fb0f970b
2. The output of `bazel version`:
```
Build label: 0.4.0
Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Wed Nov 2 17:54:14 2016 (1478109254)
Build timestamp: 1478109254
Build timestamp as int: 1478109254
```

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)

This should give the general idea.
```cpp
tensorflow::GPUBFCAllocator* allocator = new tensorflow::GPUBFCAllocator(0, sizeof(float) * height * width * 3);
tensorflow::Tensor input_tensor = tensorflow::Tensor(allocator, tensorflow::DataType::DT_FLOAT, tensorflow::TensorShape( { 1, height, width, 3 }));
std::vector<tensorflow::Tensor>* outputs = new std::vector<tensorflow::Tensor>;
<copy some data into the allocated space>
<create a new session, load graph etc.> // Note: the ""input_layer"" is on the GPU
session->Run( { { ""input_layer"", input_tensor } }, { ""output_layer"" }, { }, outputs);
```

### Logs or other output that would be helpful

Partial output of nvprof --print-gpu-trace:
```
   Start  Duration            Grid Size      Block Size     Regs*    SSMem*    DSMem*      Size  Throughput           Device   Context    Stream  Name
249.54ms  4.7360us                    -               -         -         -         -  1.0039KB  207.01MB/s  GeForce GTX 107         1         7  [CUDA memset]
932.67ms  44.799us                    -               -         -         -         -  384.00KB  8.1745GB/s  GeForce GTX 107         1         7  [CUDA memcpy HtoD]
933.22ms  15.584us            (12 32 1)        (32 8 1)        20        0B        0B         -           -  GeForce GTX 107         1         7  void cv::cudev::grid_transform_detail::transformSmart<int=4, unsigned char, float, cv::cudev::saturate_cast_func<unsigned char, float>, cv::cudev::WithOutMask>(cv::cudev::GlobPtr<unsigned char>, cv::cudev::grid_transform_detail::transformSmart<int=4, unsigned char, float, cv::cudev::saturate_cast_func<unsigned char, float, float>, cv::cudev::WithOutMask>, unsigned char, float, int, int) [158]
933.29ms  121.12us                    -               -         -         -         -  1.5000MB  12.094GB/s  GeForce GTX 107         1         7  [CUDA memcpy DtoH]
1.24468s  2.1120us                    -               -         -         -         -        4B  1.8062MB/s  GeForce GTX 107         1        14  [CUDA memcpy HtoD]
1.24492s     992ns                    -               -         -         -         -        4B  3.8455MB/s  GeForce GTX 107         1        14  [CUDA memcpy HtoD]
1.24522s     992ns                    -               -         -         -         -        4B  3.8455MB/s  GeForce GTX 107         1        14  [CUDA memcpy HtoD]
1.24553s     992ns                    -               -         -         -         -        4B  3.8455MB/s  GeForce GTX 107         1        14  [CUDA memcpy HtoD]
1.24594s  1.0880us                    -               -         -         -         -        4B  3.5062MB/s  GeForce GTX 107         1        14  [CUDA memcpy HtoD]
1.24632s     992ns                    -               -         -         -         -        4B  3.8455MB/s  GeForce GTX 107         1        14  [CUDA memcpy HtoD]
1.24800s     992ns                    -               -         -         -         -        8B  7.6909MB/s  GeForce GTX 107         1        14  [CUDA memcpy HtoD]
1.24816s  1.1200us                    -               -         -         -         -      512B  435.97MB/s  GeForce GTX 107         1        14  [CUDA memcpy HtoD]
1.24830s  38.879us                    -               -         -         -         -  288.00KB  7.0644GB/s  GeForce GTX 107         1        14  [CUDA memcpy HtoD]
1.24846s  1.0880us                    -               -         -         -         -      512B  448.79MB/s  GeForce GTX 107         1        14  [CUDA memcpy HtoD]
1.24858s  1.1200us                    -               -         -         -         -      512B  435.97MB/s  GeForce GTX 107         1        14  [CUDA memcpy HtoD]
1.24868s  1.1200us                    -               -         -         -         -      512B  435.97MB/s  GeForce GTX 107         1        14  [CUDA memcpy HtoD]
1.24874s  1.1200us                    -               -         -         -         -      512B  435.97MB/s  GeForce GTX 107         1        14  [CUDA memcpy HtoD]
1.24963s  106.62us                    -               -         -         -         -  1.1250MB  10.304GB/s  GeForce GTX 107         1        14  [CUDA memcpy HtoD]
1.24981s  1.4080us                    -               -         -         -         -  1.0000KB  693.58MB/s  GeForce GTX 107         1        14  [CUDA memcpy HtoD]
1.24987s  1.1840us                    -               -         -         -         -  1.0000KB  824.80MB/s  GeForce GTX 107         1        14  [CUDA memcpy HtoD]
1.25153s  196.60us                    -               -         -         -         -  2.2500MB  11.176GB/s  GeForce GTX 107         1        14  [CUDA memcpy HtoD]
1.25189s  1.4080us                    -               -         -         -         -  1.0000KB  693.58MB/s  GeForce GTX 107         1        14  [CUDA memcpy HtoD]
1.25196s  1.2800us                    -               -         -         -         -  1.0000KB  762.94MB/s  GeForce GTX 107         1        14  [CUDA memcpy HtoD]
1.25250s  180.92us                    -               -         -         -         -  2.2500MB  12.145GB/s  GeForce GTX 107         1        14  [CUDA memcpy HtoD]
1.25276s  1.4080us                    -               -         -         -         -  1.0000KB  693.58MB/s  GeForce GTX 107         1        14  [CUDA memcpy HtoD]
1.25281s  1.1840us                    -               -         -         -         -  1.0000KB  824.80MB/s  GeForce GTX 107         1        14  [CUDA memcpy HtoD]
1.25332s  180.67us                    -               -         -         -         -  2.2500MB  12.162GB/s  GeForce GTX 107         1        14  [CUDA memcpy HtoD]
1.25355s  1.4400us                    -               -         -         -         -  1.0000KB  678.17MB/s  GeForce GTX 107         1        14  [CUDA memcpy HtoD]
1.25359s  1.1520us                    -               -         -         -         -  1.0000KB  847.71MB/s  GeForce GTX 107         1        14  [CUDA memcpy HtoD]
1.25406s  191.36us                    -               -         -         -         -  2.2500MB  11.483GB/s  GeForce GTX 107         1        14  [CUDA memcpy HtoD]
1.25431s  1.4400us                    -               -         -         -         -  1.0000KB  678.17MB/s  GeForce GTX 107         1        14  [CUDA memcpy HtoD]
1.25435s  1.1520us                    -               -         -         -         -  1.0000KB  847.71MB/s  GeForce GTX 107         1        14  [CUDA memcpy HtoD]
1.25461s  90.910us                    -               -         -         -         -  1.1250MB  12.085GB/s  GeForce GTX 107         1        14  [CUDA memcpy HtoD]
1.25477s  1.3120us                    -               -         -         -         -  1.0000KB  744.33MB/s  GeForce GTX 107         1        14  [CUDA memcpy HtoD]
1.25482s  1.1520us                    -               -         -         -         -  1.0000KB  847.71MB/s  GeForce GTX 107         1        14  [CUDA memcpy HtoD]
1.25486s  1.0560us                    -               -         -         -         -       68B  61.411MB/s  GeForce GTX 107         1        14  [CUDA memcpy HtoD]
1.25490s  4.1280us                    -               -         -         -         -  38.250KB  8.8367GB/s  GeForce GTX 107         1        14  [CUDA memcpy HtoD]
1.25500s  1.1840us                    -               -         -         -         -      256B  206.20MB/s  GeForce GTX 107         1        14  [CUDA memcpy HtoD]
1.25506s  1.0560us                    -               -         -         -         -      256B  231.19MB/s  GeForce GTX 107         1        14  [CUDA memcpy HtoD]
1.25511s  12.288us                    -               -         -         -         -  144.00KB  11.176GB/s  GeForce GTX 107         1        14  [CUDA memcpy HtoD]
1.25523s  1.0880us                    -               -         -         -         -      256B  224.39MB/s  GeForce GTX 107         1        14  [CUDA memcpy HtoD]
1.25526s  1.0560us                    -               -         -         -         -      256B  231.19MB/s  GeForce GTX 107         1        14  [CUDA memcpy HtoD]
1.25532s  12.320us                    -               -         -         -         -  144.00KB  11.147GB/s  GeForce GTX 107         1        14  [CUDA memcpy HtoD]
1.25542s  1.0880us                    -               -         -         -         -      256B  224.39MB/s  GeForce GTX 107         1        14  [CUDA memcpy HtoD]
1.25545s  1.0880us                    -               -         -         -         -      256B  224.39MB/s  GeForce GTX 107         1        14  [CUDA memcpy HtoD]
1.25549s  1.6640us                    -               -         -         -         -  6.7500KB  3.8686GB/s  GeForce GTX 107         1        14  [CUDA memcpy HtoD]
1.25552s  1.0880us                    -               -         -         -         -      256B  224.39MB/s  GeForce GTX 107         1        14  [CUDA memcpy HtoD]
1.25555s  1.1840us                    -               -         -         -         -      256B  206.20MB/s  GeForce GTX 107         1        14  [CUDA memcpy HtoD]
1.25559s  1.0880us                    -               -         -         -         -      256B  224.39MB/s  GeForce GTX 107         1        14  [CUDA memcpy HtoD]
1.25562s  1.0880us                    -               -         -         -         -      256B  224.39MB/s  GeForce GTX 107         1        14  [CUDA memcpy HtoD]
1.25570s  23.487us                    -               -         -         -         -  288.00KB  11.694GB/s  GeForce GTX 107         1        14  [CUDA memcpy HtoD]
1.25580s  1.1200us                    -               -         -         -         -      512B  435.97MB/s  GeForce GTX 107         1        14  [CUDA memcpy HtoD]
1.25584s  1.1200us                    -               -         -         -         -      512B  435.97MB/s  GeForce GTX 107         1        14  [CUDA memcpy HtoD]
1.25597s  45.919us                    -               -         -         -         -  576.00KB  11.963GB/s  GeForce GTX 107         1        14  [CUDA memcpy HtoD]
1.25607s  1.1200us                    -               -         -         -         -      512B  435.97MB/s  GeForce GTX 107         1        14  [CUDA memcpy HtoD]
1.25610s  1.0880us                    -               -         -         -         -      512B  448.79MB/s  GeForce GTX 107         1        14  [CUDA memcpy HtoD]
1.25624s  45.919us                    -               -         -         -         -  576.00KB  11.963GB/s  GeForce GTX 107         1        14  [CUDA memcpy HtoD]
1.25634s  1.0880us                    -               -         -         -         -      512B  448.79MB/s  GeForce GTX 107         1        14  [CUDA memcpy HtoD]
1.25638s  1.2800us                    -               -         -         -         -  2.0000KB  1.4901GB/s  GeForce GTX 107         1        14  [CUDA memcpy HtoD]
1.25641s  1.4720us                    -               -         -         -         -  2.0000KB  1.2958GB/s  GeForce GTX 107         1        14  [CUDA memcpy HtoD]
1.25645s  1.2800us                    -               -         -         -         -  2.0000KB  1.4901GB/s  GeForce GTX 107         1        14  [CUDA memcpy HtoD]
1.25649s  1.1520us                    -               -         -         -         -  1.0000KB  847.71MB/s  GeForce GTX 107         1        14  [CUDA memcpy HtoD]
1.25652s  1.1840us                    -               -         -         -         -  1.0000KB  824.80MB/s  GeForce GTX 107         1        14  [CUDA memcpy HtoD]
1.25656s  1.1520us                    -               -         -         -         -  1.0000KB  847.71MB/s  GeForce GTX 107         1        14  [CUDA memcpy HtoD]
1.25659s  1.0880us                    -               -         -         -         -      512B  448.79MB/s  GeForce GTX 107         1        14  [CUDA memcpy HtoD]
1.25662s  1.1200us                    -               -         -         -         -      512B  435.97MB/s  GeForce GTX 107         1        14  [CUDA memcpy HtoD]
1.25666s  1.0880us                    -               -         -         -         -      256B  224.39MB/s  GeForce GTX 107         1        14  [CUDA memcpy HtoD]
1.25669s  1.0560us                    -               -         -         -         -      256B  231.19MB/s  GeForce GTX 107         1        14  [CUDA memcpy HtoD]
1.25673s  1.1520us                    -               -         -         -         -  1.0000KB  847.71MB/s  GeForce GTX 107         1        14  [CUDA memcpy HtoD]
1.25676s  1.1840us                    -               -         -         -         -  1.0000KB  824.80MB/s  GeForce GTX 107         1        14  [CUDA memcpy HtoD]
1.25680s  1.1520us                    -               -         -         -         -  1.0000KB  847.71MB/s  GeForce GTX 107         1        14  [CUDA memcpy HtoD]
1.25965s  360.89us                    -               -         -         -         -  4.5000MB  12.177GB/s  GeForce GTX 107         1        14  [CUDA memcpy HtoD]
1.26011s  1.5360us                    -               -         -         -         -  2.0000KB  1.2418GB/s  GeForce GTX 107         1        14  [CUDA memcpy HtoD]
1.26015s  1.2800us                    -               -         -         -         -  2.0000KB  1.4901GB/s  GeForce GTX 107         1        14  [CUDA memcpy HtoD]
1.26543s  719.60us                    -               -         -         -         -  9.0000MB  12.214GB/s  GeForce GTX 107         1        14  [CUDA memcpy HtoD]
1.26626s  1.8240us                    -               -         -         -         -  2.0000KB  1.0457GB/s  GeForce GTX 107         1        14  [CUDA memcpy HtoD]
1.26630s  1.2480us                    -               -         -         -         -  2.0000KB  1.5283GB/s  GeForce GTX 107         1        14  [CUDA memcpy HtoD]
1.26788s  727.98us                    -               -         -         -         -  9.0000MB  12.073GB/s  GeForce GTX 107         1        14  [CUDA memcpy HtoD]
1.26872s  1.5040us                    -               -         -         -         -  2.0000KB  1.2682GB/s  GeForce GTX 107         1        14  [CUDA memcpy HtoD]
1.26876s  1.2480us                    -               -         -         -         -  2.0000KB  1.5283GB/s  GeForce GTX 107         1        14  [CUDA memcpy HtoD]
1.27030s  718.67us                    -               -         -         -         -  9.0000MB  12.230GB/s  GeForce GTX 107         1        14  [CUDA memcpy HtoD]
1.27109s  1.5680us                    -               -         -         -         -  2.0000KB  1.2164GB/s  GeForce GTX 107         1        14  [CUDA memcpy HtoD]
1.27112s  1.2800us                    -               -         -         -         -  2.0000KB  1.4901GB/s  GeForce GTX 107         1        14  [CUDA memcpy HtoD]
1.27268s  718.58us                    -               -         -         -         -  9.0000MB  12.231GB/s  GeForce GTX 107         1        14  [CUDA memcpy HtoD]
1.27349s  1.5040us                    -               -         -         -         -  2.0000KB  1.2682GB/s  GeForce GTX 107         1        14  [CUDA memcpy HtoD]
1.27359s  1.6000us                    -               -         -         -         -  2.0000KB  1.1921GB/s  GeForce GTX 107         1        14  [CUDA memcpy HtoD]
1.27437s  360.12us                    -               -         -         -         -  4.5000MB  12.203GB/s  GeForce GTX 107         1        14  [CUDA memcpy HtoD]
1.27479s  1.5360us                    -               -         -         -         -  2.0000KB  1.2418GB/s  GeForce GTX 107         1        14  [CUDA memcpy HtoD]
1.27484s  1.2800us                    -               -         -         -         -  2.0000KB  1.4901GB/s  GeForce GTX 107         1        14  [CUDA memcpy HtoD]
1.27487s  1.2480us                    -               -         -         -         -  2.0000KB  1.5283GB/s  GeForce GTX 107         1        14  [CUDA memcpy HtoD]
1.27491s  1.3120us                    -               -         -         -         -  2.0000KB  1.4538GB/s  GeForce GTX 107         1        14  [CUDA memcpy HtoD]
1.27495s  1.2800us                    -               -         -         -         -  2.0000KB  1.4901GB/s  GeForce GTX 107         1        14  [CUDA memcpy HtoD]
1.27651s  719.02us                    -               -         -         -         -  9.0000MB  12.224GB/s  GeForce GTX 107         1        14  [CUDA memcpy HtoD]
1.27732s  1.5040us                    -               -         -         -         -  2.0000KB  1.2682GB/s  GeForce GTX 107         1        14  [CUDA memcpy HtoD]
1.27736s  1.3440us                    -               -         -         -         -  2.0000KB  1.4192GB/s  GeForce GTX 107         1        14  [CUDA memcpy HtoD]
1.27890s  719.02us                    -               -         -         -         -  9.0000MB  12.224GB/s  GeForce GTX 107         1        14  [CUDA memcpy HtoD]
1.27970s  1.5350us                    -               -         -         -         -  2.0000KB  1.2426GB/s  GeForce GTX 107         1        14  [CUDA memcpy HtoD]
1.27976s  1.2800us                    -               -         -         -         -  2.0000KB  1.4901GB/s  GeForce GTX 107         1        14  [CUDA memcpy HtoD]
1.28131s  719.09us                    -               -         -         -         -  9.0000MB  12.223GB/s  GeForce GTX 107         1        14  [CUDA memcpy HtoD]
1.28212s  1.5360us                    -               -         -         -         -  2.0000KB  1.2418GB/s  GeForce GTX 107         1        14  [CUDA memcpy HtoD]
1.28222s  1.2480us                    -               -         -         -         -  2.0000KB  1.5283GB/s  GeForce GTX 107         1        14  [CUDA memcpy HtoD]
1.28377s  718.06us                    -               -         -         -         -  9.0000MB  12.240GB/s  GeForce GTX 107         1        14  [CUDA memcpy HtoD]
1.28463s  1.6320us                    -               -         -         -         -  2.0000KB  1.1687GB/s  GeForce GTX 107         1        14  [CUDA memcpy HtoD]
1.28468s  1.2800us                    -               -         -         -         -  2.0000KB  1.4901GB/s  GeForce GTX 107         1        14  [CUDA memcpy HtoD]
1.28619s  719.86us                    -               -         -         -         -  9.0000MB  12.209GB/s  GeForce GTX 107         1        14  [CUDA memcpy HtoD]
1.28703s  1.5040us                    -               -         -         -         -  2.0000KB  1.2682GB/s  GeForce GTX 107         1        14  [CUDA memcpy HtoD]
1.28707s  1.2800us                    -               -         -         -         -  2.0000KB  1.4901GB/s  GeForce GTX 107         1        14  [CUDA memcpy HtoD]
1.28863s  719.28us                    -               -         -         -         -  9.0000MB  12.219GB/s  GeForce GTX 107         1        14  [CUDA memcpy HtoD]
1.28946s  1.5040us                    -               -         -         -         -  2.0000KB  1.2682GB/s  GeForce GTX 107         1        14  [CUDA memcpy HtoD]
1.28951s  1.2800us                    -               -         -         -         -  2.0000KB  1.4901GB/s  GeForce GTX 107         1        14  [CUDA memcpy HtoD]
1.28955s  1.2800us                    -               -         -         -         -  2.0000KB  1.4901GB/s  GeForce GTX 107         1        14  [CUDA memcpy HtoD]
1.28960s  1.2800us                    -               -         -         -         -  2.0000KB  1.4901GB/s  GeForce GTX 107         1        14  [CUDA memcpy HtoD]
1.28964s  1.2800us                    -               -         -         -         -  2.0000KB  1.4901GB/s  GeForce GTX 107         1        14  [CUDA memcpy HtoD]
1.29034s  20.768us                    -               -         -         -         -  1.5000MB  70.534GB/s  GeForce GTX 107         1        14  [CUDA memcpy DtoD]
1.29047s  30.015us             (16 1 1)      (1024 1 1)        25        0B        0B         -           -  GeForce GTX 107         1        13  void tensorflow::functor::SwapDimension1And2InTensor3<float>(int, float const *, tensorflow::functor::Dimension<int=3>, tensorflow::functor::SwapDimension1And2InTensor3<float>*) [936]
1.29050s  3.7120us              (2 1 1)      (1024 1 1)        27        0B        0B         -           -  GeForce GTX 107         1        13  void tensorflow::functor::SwapDimension0And2InTensor3<float>(int, float const *, tensorflow::functor::Dimension<int=3>, tensorflow::functor::SwapDimension0And2InTensor3<float>*) [942]
1.59580s     864ns                    -               -         -         -         -      112B  123.62MB/s  GeForce GTX 107         1         7  [CUDA memcpy HtoD]
<computations start>
```
"
5901,"Im2txt: ""No variables to save"" error at the initial training stage","Hi,

I'm trying to train im2txt (show & tell) model with mscoco dataset using tensorflow-0.11.

I successfully completed the downloaded & preprocess steps described in the guide (https://github.com/tensorflow/models/tree/master/im2txt).

I'm using the inception_v3.ckpt model for the initial training process.

But I'm getting ""no variables to save"" error @ show_and_tell_model.py in function setup_inception_initializer at line 
 saver = tf.train.Saver(self.inception_variables)
I print out self.inception_variables on the line above and I see that it is an empty list.

Below is the complete dump of the error.

Any help would be appreciated.

Thanks.

python train.py \
	--input_file_pattern=""/usr/local/tensorflow-models/im2txt/im2txt/data/mscoco/train-?????-of-00256"" \
	--inception_checkpoint_file=""/usr/local/tensorflow-models/im2txt/im2txt/data/inception_v3.ckpt"" \
	--train_dir=""/usr/local/tensorflow-models/im2txt/im2txt/model/train"" \
	--train_inception=false \
	--number_of_steps=1000000
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcublas.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcudnn.so.5.1 locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcufft.so.8.0 locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcurand.so.8.0 locally
INFO:tensorflow:Prefetching values from 256 files matching /usr/local/tensorflow-models/im2txt/im2txt/data/mscoco/train-?????-of-00256
Traceback (most recent call last):
  File ""train.py"", line 117, in <module>
    tf.app.run()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py"", line 43, in run
    sys.exit(main(sys.argv[:1] + flags_passthrough))
  File ""train.py"", line 67, in main
    model.build()
  File ""/usr/local/tensorflow-models/im2txt/im2txt/show_and_tell_model.py"", line 361, in build
    self.setup_inception_initializer()
  File ""/usr/local/tensorflow-models/im2txt/im2txt/show_and_tell_model.py"", line 335, in setup_inception_initializer
    saver = tf.train.Saver(self.inception_variables)
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1000, in __init__
    self.build()
  File ""/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py"", line 1021, in build
    raise ValueError(""No variables to save"")
ValueError: No variables to save

"
5898,pool efficiency on cpu,"### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?

I have searched about cpu usage and try everything I can. But it's still pool efficiency usage, **only use 30% of my cpu**
I thought it maybe the train-dataset read speed limitation?

### Environment info
Operating System:
centos6.5 with latest version of tensorflow 

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)
full code here
https://github.com/tobegit3hub/deep_recommend_system/blob/master/a8a_classifier.py
```
# Read TFRecords files for training
filename_queue = tf.train.string_input_producer(
    tf.train.match_filenames_once(""data/a8a_train.libsvm.tfrecords""),
    num_epochs=epoch_number)
serialized_example = read_and_decode(filename_queue)
batch_serialized_example = tf.train.shuffle_batch(
    [serialized_example],
    batch_size=batch_size,
    num_threads=thread_number,
    capacity=capacity,
    min_after_dequeue=min_after_dequeue)
```

### What other attempted solutions have you tried?
try the specify the thread number when init session , the shuffle_batch num_threads etc.

### Logs or other output that would be helpful
(If logs are large, please upload as attachment or provide link).
here is a tensorboard screenshot

<img width=""750"" alt=""screen shot 2016-11-28 at 4 15 15 pm"" src=""https://cloud.githubusercontent.com/assets/918889/20661115/0014e198-b588-11e6-8c33-b692c32568cd.png"">

"
5896,VocabularyProcessor does not work with Chinese,"In order to train a model with tensorflow, try to use tf.contrib.learn.preprocessing.VocabularyProcessor to get a vocabulary vector. 

```
def create_vocab(input_iter, min_frequency):
  """"""
  Creates and returns a VocabularyProcessor object with the vocabulary
  for the input iterator.
  """"""
  vocab_processor = tf.contrib.learn.preprocessing.VocabularyProcessor(
      FLAGS.max_sentence_len,
      min_frequency=min_frequency,
      tokenizer_fn=tokenizer_fn)
  vocab_processor.fit(input_iter)
  return vocab_processor

```

It works well with English. But all the Chinese words are not parsed. They are treated as a single word.

![image](https://cloud.githubusercontent.com/assets/3538629/20660678/cc49a12a-b585-11e6-9018-8f8dc0d628b3.png)


### Environment info
Operating System: Mac OSX, CPU Only
TensorFlow: Version - **0.11.0rc1**

### What other attempted solutions have you tried?
Not yet. 
"
5895,Cannot import tensorflow using simple Pip installation instructions,"This is the error im getting. I saw the other posts for conda and windows computers, but I have a mac and im not using conda...

$ python
Python 2.7.10 (default, Jul 30 2016, 18:31:42) 
[GCC 4.2.1 Compatible Apple LLVM 8.0.0 (clang-800.0.34)] on darwin
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import tensorflow as tf
dyld: warning, LC_RPATH $ORIGIN/../../_solib_darwin/_U@local_Uconfig_Ucuda_S_Scuda_Ccudart___Uexternal_Slocal_Uconfig_Ucuda_Scuda_Slib in /Library/Python/2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so being ignored in restricted program because it is a relative path
dyld: warning, LC_RPATH ../local_config_cuda/cuda/lib in /Library/Python/2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so being ignored in restricted program because it is a relative path
dyld: warning, LC_RPATH ../local_config_cuda/cuda/extras/CUPTI/lib in /Library/Python/2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so being ignored in restricted program because it is a relative path
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/Library/Python/2.7/site-packages/tensorflow/__init__.py"", line 23, in <module>
    from tensorflow.python import *
  File ""/Library/Python/2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""/Library/Python/2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 21, in <module>
    _pywrap_tensorflow = swig_import_helper()
  File ""/Library/Python/2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 20, in swig_import_helper
    return importlib.import_module('_pywrap_tensorflow')
  File ""/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/importlib/__init__.py"", line 37, in import_module
    __import__(name)
ImportError: No module named _pywrap_tensorflow
>>> exit()
"
5894,Does the random regression forest works with multi-variable in labels?,"For example, each label is a vector of floats.
"
5892,Huge network traffic between parameter server and worker,"hi, we found huge network traffic between parameter server and worker during distributed dnn training. our model has one embedding layer with 40M sparse features, those features are spitted into 20 groups and each group full-connected to one 5-dimension vector, so for sparse part, total parameter count is 200M. we used tf.nn.embedding_lookup_sparse to retrieve sparse parameters. however, with one parameter server one worker, parameter will send about 700M to worker for one batch, this traffic is very close to whole parameter size.
here is our code for sparse part:

```
W_embeddings = []
for i in range(1, FLAGS.feature_group_count):
    W_embeddings.append(tf.get_variable(""W_embedding_%d"" % (i-1), [feature_dimensions[i], FLAGS.embedding_count], partitioner=tf.min_max_variable_partitioner(ps_count)))

embedding_tensors = []
for i in range(len(W_embeddings)):
    embedding_tensors.append(tf.nn.embedding_lookup_sparse(W_embeddings[i],sp_ids=feature_groups[i+1],sp_weights=None,combiner=""sum""))
```

python version is Ubuntu 3.4.3, tensorflow 0.11.0 is downloaded following official site using pip3.
I searched and found no one reported this kind of issue before, i am not sure whether we are using tensorflow incorrectly or something wrong with our environment, any idea about how to fix this?
"
5890,catch22 situation with tf.nn.sampled_softmax_loss and tf.nn.softmax,"Hi,
referring to this: 
https://github.com/tensorflow/tensorflow/blob/master/tensorflow/g3doc/api_docs/python/functions_and_classes/shard1/tf.nn.sampled_softmax_loss.md
and this:
https://github.com/tensorflow/tensorflow/issues/4138

to make samlped_softmax efficient we need to invert w and w_t to take transpose out of the loss function.
but then it becomes an issue at test / inference time when you need to use the full softmax with the tranpose inside.

ie: either training is slow or testing is slow.

what's the solution ?"
5888,No gradient defined for operation 'Round' (op type: Round),"1. A link to the pip package you installed:
https://ci.tensorflow.org/view/Nightly/job/nightly-matrix-linux-gpu/TF_BUILD_IS_OPT=OPT,TF_BUILD_IS_PIP=PIP,TF_BUILD_PYTHON_VERSION=PYTHON2,label=gpu-linux/lastSuccessfulBuild/artifact/pip_test/whl/tensorflow_gpu-0.11.0-cp27-cp27mu-linux_x86_64.whl

2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.
0.11.head


`tf.round` used to have gradients. but now it gives error.
```python
a = tf.get_variable('a', shape=[1])
x = tf.round(a)
g = tf.gradients(x, a)
```"
5887,It's not possible to read csv without TextLineReader?,"`def input_data(start_index, amount, shuffle):
    
    data_folder = '/media/sf_vb-shared/data/'
    range_queue = tf.train.range_input_producer(amount, shuffle = shuffle)
    range_value = range_queue.dequeue()

    abs_index = tf.add(range_value, tf.constant(start_index))    
    abs_index_str = tf.as_string(abs_index, width = 9, fill = '0')
    
    png_file_name = tf.string_join([tf.constant(data_folder), tf.constant('data'), abs_index_str, tf.constant('.png')])
    csv_file_name = tf.string_join([tf.constant(data_folder), tf.constant('data'), abs_index_str, tf.constant('.csv')])

    csv_data = tf.read_file(csv_file_name)
    csv_data = tf.Print(csv_data, [csv_data], message = ""This is csv_data: "")
    label_defaults = [[0.0] for x in range(n_classes)]   
    unpacked_labels = tf.decode_csv(csv_data, record_defaults = label_defaults)
    labels = tf.pack(unpacked_labels)
    labels = tf.Print(labels, [labels], message = ""These are labels: "")`

The output is ""This is csv_data: [0,0,0,1,0\n]"", so
csv_data is read ok, but ""These are labels"" never gets printed out...
Is it possible to feed decode_csv with read_file output?"
5886,"Crash with dynamic tf.reshape ""Check failed: dtype() == expected_dtype (9 vs. 3)""","```py
import tensorflow as tf

queue = tf.train.string_input_producer(['data.tfrecord'])

reader = tf.TFRecordReader()
_, example = reader.read(queue)

features = tf.parse_single_example(example,features={
    'mr_image': tf.FixedLenFeature([], tf.string),
    'us_image': tf.FixedLenFeature([], tf.string),
    'mr_shape': tf.FixedLenFeature([2], tf.int64),
    'us_shape': tf.FixedLenFeature([2], tf.int64),
})

mr_image = tf.decode_raw(features['mr_image'], tf.int16)
us_image = tf.decode_raw(features['us_image'], tf.uint8)

mr_shape = tf.cast(features['mr_shape'], tf.int64)
us_shape = tf.cast(features['us_shape'], tf.int64)

with tf.Session() as sess:
    coord = tf.train.Coordinator()
    threads = tf.train.start_queue_runners(sess=sess, coord=coord)
    
    #mr = tf.reshape(mr_image, mr_shape)
    #us = tf.reshape(us_image, us_shape)

    print(len(sess.run(mr_image)),len(sess.run(us_image)))
    print(sess.run([mr_shape, us_shape]))
    #print(sess.run(tf.reshape(mr_image, mr_shape)))
    
    coord.request_stop()
    coord.join(threads)
```

Will print:
```
183604 118218
[array([466, 394]), array([366, 323])]
```

However `print(sess.run(tf.reshape(mr_image, mr_shape)))` will cause a crash with:
```sh
F tensorflow/core/framework/tensor.cc:441] Check failed: dtype() == expected_dtype (9 vs. 3)
```

Also `print(sess.run(tf.reshape(mr_image, [466, 394])))` works as expected.

- macOS 10.12.1
- Python 3.5.2
- tensorflow 0.11"
5885,decode_csv result shape,
5884,Tensor slice is too large to serialize,"### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?

I have read the realted isssue  https://github.com/tensorflow/tensorflow/issues/4291 , but it's not solved.

### Environment info
centos with cpu support and tensorflow latest version

no cuda or cudnn

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)

I am build a 4 layer network (128*64*64*32), input_unit feature size 20000000（sparse feature size）,  when train the model ,it errors that ""Tensor slice is too large to serialize"".


my training code is like this https://github.com/tobegit3hub/deep_recommend_system/blob/master/a8a_classifier.py

### What other attempted solutions have you tried?

nothing , it's seems that a protobuf limitation , but I want to know how to solve this with changes in my training code 

### Logs or other output that would be helpful
""Tensor slice is too large to serialize""


"
5883,Android TF Error: Not found: Op type not registered 'Const',"Hello,

I'm trying to run a dummy inference model I built in TF with python.
The model takes an input vector (size 3x200) and multiply (component-wise) it with a variable vector of the same size whose values were randomized. so output_node = input_node * variable_node
Then there is a reduce_sum to a final value.
The model was generated with this procedure:
`  
    checkpoint_prefix = ""mygraph.ckpt""
    checkpoint_state_name = ""mygraph.ckpt""
    input_graph_name = ""input_graph.pb""
    output_graph_name = ""output_graph.pb""

    def dummy_model(input):
        with tf.Graph().as_default():
            sess = tf.Session()
            with sess.as_default():

            variable_node = tf.Variable(tf.random_normal([3, 200], stddev=0.35), name=""variable_node"")
            input_node = tf.Variable(input, name=""input_node"")
            output_node = tf.reduce_sum(tf.mul(variable_node, input_node, name=""output_node""), axis=1)
            init_op = tf.global_variables_initializer()

            #init = tf.global_variables_initializer()
            sess.run(init_op)
 
            saver = tf.train.Saver(write_version=2)
            checkpoint_path = saver.save(sess, checkpoint_prefix, global_step=0, latest_filename=checkpoint_state_name)
            tf.train.write_graph(sess.graph, ""./"", input_graph_name)`
   

After generating the model files (and renaming them) I made the process of freezing and optimizing the graph for inference on android using the script in the python\tools folder (freeze_graph.py, optimize_for_inference.py, print_selective_registration_header.py). In the end of this process I get the optimized graph 'my_optimized_graph.pb' and the ops_to_register.h' header which is used to tell tensorflow (bazel) what kernels to register when you add the ""SELECTIVE_REGISTRATION"" flag to the build rule.

My problem is, when I load the model in android I get the following errors occurred after the session->create() call:

> E/native: op_kernel.cc:925 OpKernel ('op: ""_Send"" device_type: ""GPU""') for unknown op: _Send
E/native: op_kernel.cc:925 OpKernel ('op: ""_Recv"" device_type: ""GPU""') for unknown op: _Recv
E/native: op_kernel.cc:925 OpKernel ('op: ""_Send"" device_type: ""CPU""') for unknown op: _Send
E/native: op_kernel.cc:925 OpKernel ('op: ""NoOp"" device_type: ""GPU""') for unknown op: NoOp
E/native: op_kernel.cc:925 OpKernel ('op: ""_Recv"" device_type: ""CPU""') for unknown op: _Recv
E/native: op_kernel.cc:925 OpKernel ('op: ""NoOp"" device_type: ""CPU""') for unknown op: NoOp
E/native: op_kernel.cc:925 OpKernel ('op: ""Placeholder"" device_type: ""GPU""') for unknown op: Placeholder
E/native: op_kernel.cc:925 OpKernel ('op: ""Placeholder"" device_type: ""CPU""') for unknown op: Placeholder
E/native: op_kernel.cc:925 OpKernel ('op: ""Const"" device_type: ""CPU""') for unknown op: Const
E/native: tensorflow_inference_jni.cc:138 Could not create Tensorflow Graph: Not found: Op type not registered 'Const'

It seems like the kernels did registered but the ops are unknown.
I searched a lot the forum and couldn't find solution for this issue.
### Did anyone succeed in compiling TF on Android with SELECTIVE_REGISTRATION and running a custom graph model other than the ""inception"" model which used in the demo?"
5882,TF sometimes hangs indefinitely when initializing variables,"When doing a hyperoptimization TF hangs sometimes (once every 30 times) when initializing variables.
There are no error messages and it stalls for hours so I have to kill it manually.

I have included information below. Please let me know if there's anything else you need.

### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?
https://github.com/tensorflow/tensorflow/issues/2788
https://github.com/tensorflow/tensorflow/issues/5448

### Environment info
Operating System:
Debian 8.6
Kernel: Linux 3.16.0-4-amd64

### Installed version of CUDA and cuDNN: 
/usr/local/cuda/lib64/libcudadevrt.a    /usr/local/cuda/lib64/libcudart.so.8.0.44  /usr/local/cuda/lib64/libcudnn.so.5
/usr/local/cuda/lib64/libcudart.so      /usr/local/cuda/lib64/libcudart_static.a   /usr/local/cuda/lib64/libcudnn.so.5.1.5
/usr/local/cuda/lib64/libcudart.so.8.0  /usr/local/cuda/lib64/libcudnn.so          /usr/local/cuda/lib64/libcudnn_static.a

If installed from binary pip package, provide:

1. A link to the pip package you installed:
https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.11.0-cp34-cp34m-linux_x86_64.whl

2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.
0.11.0


### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)
```
# clean up from previous trial
self.sess.close()
tf.reset_default_graph()

# initialize model
tf_config = tf.ConfigProto()
tf_config.gpu_options.per_process_gpu_memory_fraction = 0.45
self.sess = tf.Session(config=tf_config)

*** create model ***

self.sess.run(tf.initialize_all_variables())
``` 
<--- HANGS HERE


### What other attempted solutions have you tried?
initialize variables one by one --> hangs at first variable
config.operation_timeout_in_ms=60000 (as a temporary workaround)

### Logs or other output that would be helpful

```
tail -n 2 nohup.log:

2016-11-26 23:48:13.170 |  INFO |         create_model | tf_model.py:277 | 47.9 | Initializing all variables...
Initializing: learning_rate:0

```


```
strace -p 15477 --> 

Process 15477 attached
futex(0x7ffc1aabd91c, FUTEX_WAIT_PRIVATE, 1, NULL

```
```
nvidia-smi -->

+-----------------------------------------------------------------------------+
| NVIDIA-SMI 367.48                 Driver Version: 367.48                    |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  GeForce GTX 980 Ti  Off  | 0000:01:00.0     Off |                  N/A |
|  1%   60C    P2    44W / 275W |   2901MiB /  6077MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+

+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID  Type  Process name                               Usage      |
|=============================================================================|
|    0     15477    C   python                                        2899MiB |
+-----------------------------------------------------------------------------+
```"
5880,Android custom classifier importing error,"Hi

I am having trouble importing a graph that I made in python into the Android demo app and running it. I built a CNN for character recognition. I am having problems finding the input and output nodes so I kept trying random logical combinations. Also I froze the graph and ran it through inference.
There seems to be no documentation at all for importing your own classifier into Android.
Both the data set and the ipython notebook are at: https://drive.google.com/drive/folders/0By50gGWStkpFZ1ZsajI0WHpFN0E?usp=sharing

In the ipython noteboook, the CNN at the bottom of the file is what I am trying to import to Android, the one with Dropout and MaxPooling.

"
5878,server used by model reset connection,"
### tensorflow official tutorial link with problem
<a href=""https://www.tensorflow.org/versions/r0.11/tutorials/image_recognition/index.html"">https://www.tensorflow.org/versions/r0.11/tutorials/image_recognition/index.html</a>

### Environment info
Ubuntu 14 64bit

### Installation
Installed with pip to virtualenv
pip wheel used: https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.10.0-cp27-none-linux_x86_64.whl

### Execution of model
python tensorflow/models/image/imagenet/classify_image.py

### Output
```
python classify_image.py
>> Downloading inception-2015-12-05.tgz 100.0%Traceback (most recent call last):
  File ""classify_image.py"", line 212, in <module>
    tf.app.run()
  File ""/home/user/Documents/virt_env/python-tensorflow-test/local/lib/python2.7/site-packages/tensorflow/python/platform/app.py"", line 30, in run
    sys.exit(main(sys.argv))
  File ""classify_image.py"", line 205, in main
    maybe_download_and_extract()
  File ""classify_image.py"", line 197, in maybe_download_and_extract
    filepath, _ = urllib.request.urlretrieve(DATA_URL, filepath, _progress)
  File ""/usr/lib/python2.7/urllib.py"", line 94, in urlretrieve
    return _urlopener.retrieve(url, filename, reporthook, data)
  File ""/usr/lib/python2.7/urllib.py"", line 268, in retrieve
    block = fp.read(bs)
  File ""/usr/lib/python2.7/socket.py"", line 380, in read
    data = self._sock.recv(left)
socket.error: [Errno 104] Connection reset by peer
```"
5877,GraphKeys.VARIABLES deprecated early,"`GraphKeys.VARIABLES` was intended to be deprecated next march according to the code.

But [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/framework/ops.py#L4067) it is set as a property. Therefore back-compatibility of `GraphKeys.VARIABLES` is already broken now because one has to use `GraphKeys().VARIABLES` instead.

It should something like a classproperty instead."
5876,Error in hessians() and _hessian_vector_product() for tf.nn.sparse_softmax_cross_entropy_with_logits(),"On a simple model that implements logistic regression, constructing the loss using tf.nn.sparse_softmax_cross_entropy_with_logits() makes both hessians() and _hessian_vector_product() return identically zero vectors, which is incorrect. If I instead write the loss function manually using tf.log, tf.sigmoid, etc., hessians() and _hessian_vector_product return the correct answer. These two versions of the loss function agree on their values and their gradients; however, the Hessian output is different. 

Here is some sample output:

```
Using sparse_softmax_cross_entropy_with_logits:
Loss before first step: 0.686726
Loss after first step : 0.686181
Actual diff in grad:
[ 0.000122    0.00014928]
Predicted diff in grad using _hessian_vector_product:
[array([ 0.,  0.], dtype=float32)]
Hessian:
[array([[ 0.,  0.],
       [ 0.,  0.]], dtype=float32)]

Using custom loss function:
Loss before first step: 0.686726
Loss after first step : 0.686181
Actual diff in grad:
[ 0.00012201  0.00014931]
Predicted diff in grad using _hessian_vector_product:
[array([ 0.00012199,  0.0001493 ], dtype=float32)]
Hessian:
[array([[ 0.08229966,  0.        ],
       [ 0.        ,  0.08278375]], dtype=float32)]
```
### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?

None that I can find. The code below uses hessians() and _hessian_vector_product() from https://github.com/tensorflow/tensorflow/blob/a4c8df209d7413068f4ed3e71c43eb798fbd5580/tensorflow/python/ops/gradients_impl.py

Here is the PR that implemented hessians(): https://github.com/tensorflow/tensorflow/pull/5329

### Environment info
Operating System: Ubuntu 16.04

Installed version of CUDA and cuDNN: 
```
-rw-r--r-- 1 root root   558720 Oct  1 00:18 /usr/local/cuda/lib64/libcudadevrt.a
lrwxrwxrwx 1 root root       16 Oct  1 00:18 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.8.0
lrwxrwxrwx 1 root root       19 Oct  1 00:18 /usr/local/cuda/lib64/libcudart.so.8.0 -> libcudart.so.8.0.44
-rwxr-xr-x 1 root root   415432 Oct  1 00:18 /usr/local/cuda/lib64/libcudart.so.8.0.44
-rw-r--r-- 1 root root   775162 Oct  1 00:18 /usr/local/cuda/lib64/libcudart_static.a
-rwxr-xr-x 1 root root 78065952 Oct  1 16:19 /usr/local/cuda/lib64/libcudnn.so
-rwxr-xr-x 1 root root 78065952 Oct  1 16:19 /usr/local/cuda/lib64/libcudnn.so.5
-rwxr-xr-x 1 root root 78065952 Oct  1 16:19 /usr/local/cuda/lib64/libcudnn.so.5.0.5
-rw-r--r-- 1 root root 68709594 Oct  1 16:19 /usr/local/cuda/lib64/libcudnn_static.a
```
The same behavior occurs when running on CPU only.

Installed from: https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.11.0-cp27-none-linux_x86_64.whl
v0.11.0

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)

```
tf.set_random_seed(0)

### Setup toy data and weights
images_placeholder = tf.placeholder(tf.float32, shape=(3, 2))
labels_placeholder = tf.placeholder(tf.int32, shape=(3))
feed_dict = {
    images_placeholder: np.array([[0, 0], [0, 1], [1, 0]]),
    labels_placeholder: np.array([0, 1, 1]),
}
  
weights = tf.Variable(
  tf.truncated_normal([2],
                      stddev=1.0 / math.sqrt(float(2))),
  name='weights')

### Calculate loss using built-in TF function
weights_with_zeros = tf.pack([tf.zeros([2]), weights], axis=1)
logits = tf.matmul(images_placeholder, weights_with_zeros)
cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits, labels_placeholder)
loss = tf.reduce_mean(cross_entropy)

### Calculate loss using manually constructed TF function
logits2 = tf.matmul(images_placeholder, tf.reshape(weights, [2, 1]))
labels2 = (tf.to_float(labels_placeholder) * 2) - 1
logits_mul_labels = tf.mul(tf.reshape(logits2, [-1]), tf.reshape(labels2, [-1]))
cross_entropy2 = - tf.log(tf.sigmoid(logits_mul_labels))
loss2 = tf.reduce_mean(cross_entropy2)

### Create train_op
optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)
global_step = tf.Variable(0, name='global_step', trainable=False)
train_op = optimizer.minimize(loss, global_step=global_step)

### Calculate gradients, Hessians, and Hessian-vector products for both versions of loss
grad = tf.gradients(loss, [weights])
grad2 = tf.gradients(loss2, [weights])
v_placeholder = tf.placeholder(tf.float32, shape=weights.get_shape())
hessian_vector = _hessian_vector_product(loss, [weights], [v_placeholder])
hessian_vector2 = _hessian_vector_product(loss2, [weights], [v_placeholder])
hessian = hessians(loss, [weights])
hessian2 = hessians(loss2, [weights])

### Run training for a single step to get the parameters to change.
init = tf.initialize_all_variables()
sess = tf.Session()
sess.run(init)

old_weights_val, old_loss_val, old_grad_val, old_loss2_val, old_grad2_val= sess.run(
  [weights, loss, grad, loss2, grad2], 
  feed_dict=feed_dict)

_ = sess.run(train_op, feed_dict=feed_dict)

new_weights_val, new_loss_val, new_grad_val, new_loss2_val, new_grad2_val = sess.run(
  [weights, loss, grad, loss2, grad2], 
  feed_dict=feed_dict)

hessian_val, hessian2_val = sess.run(
  [hessian, hessian2], 
  feed_dict=feed_dict)

### Calculate the actual difference in gradients before and after the train step,
### and compare with the predicted difference in gradients based on the Hessian.
diff_in_weights = new_weights_val - old_weights_val
actual_diff_in_grad = new_grad_val[0] - old_grad_val[0]
actual_diff_in_grad2 = new_grad2_val[0] - old_grad2_val[0]

feed_dict[v_placeholder] = diff_in_weights
predicted_diff_in_grad = sess.run(hessian_vector, feed_dict=feed_dict)
predicted_diff_in_grad2 = sess.run(hessian_vector2, feed_dict=feed_dict)

print('Diff in weights:\n%s' % diff_in_weights)

print('\nUsing sparse_softmax_cross_entropy_with_logits:')
print('Loss before first step: %s' % old_loss_val)
print('Loss after first step : %s' % new_loss_val)
print('Actual diff in grad:\n%s' % actual_diff_in_grad)
print('Predicted diff in grad using _hessian_vector_product:\n%s' % predicted_diff_in_grad)
print('Hessian:\n%s' % hessian_val)

print('\nUsing custom loss function:')
print('Loss before first step: %s' % old_loss2_val)
print('Loss after first step : %s' % new_loss2_val)
print('Actual diff in grad:\n%s' % actual_diff_in_grad2)
print('Predicted diff in grad using _hessian_vector_product:\n%s' % predicted_diff_in_grad2)
print('Hessian:\n%s' % hessian2_val)

sess.close()

```
### What other attempted solutions have you tried?
Running in CPU or GPU makes no difference.

Using more complicated networks (i.e., adding some non-linear hidden layers before the linear softmax step) makes the Hessian returned from sparse_softmax_cross_entropy_with_logits() non-zero, but the returned value is still wrong in the sense that it does not match the empirical values. In contrast, using the same custom loss function above returns the correct Hessians.  

The same problem occurs when using ""real"" data (e.g., MNIST) or with more examples.

### Logs or other output that would be helpful
Full output when using CPU:
```
Diff in weights:
[ 0.00148226  0.0018035 ]

Using sparse_softmax_cross_entropy_with_logits:
Loss before first step: 0.686726
Loss after first step : 0.686181
Actual diff in grad:
[ 0.000122    0.00014928]
Predicted diff in grad using _hessian_vector_product:
[array([ 0.,  0.], dtype=float32)]
Hessian:
[array([[ 0.,  0.],
       [ 0.,  0.]], dtype=float32)]

Using custom loss function:
Loss before first step: 0.686726
Loss after first step : 0.686181
Actual diff in grad:
[ 0.00012201  0.00014931]
Predicted diff in grad using _hessian_vector_product:
[array([ 0.00012199,  0.0001493 ], dtype=float32)]
Hessian:
[array([[ 0.08229966,  0.        ],
       [ 0.        ,  0.08278375]], dtype=float32)]
```"
5873,tensorboard HTTP 404 errors,"Observing the following, it seems chromedeveditor is obsolete, is there a recommended replacement library?

INFO:tensorflow:path ../external\core_overlay/core-overlay.html not found, sending 404
INFO:tensorflow:returning 404 to 127.0.0.1 for /core-overlay/core-overlay.html
INFO:tensorflow:path ../external\core_transition/core-transition-css.html not found, sending 404
INFO:tensorflow:returning 404 to 127.0.0.1 for /core-transition/core-transition-css.html
INFO:tensorflow:path ../external\core_media_query/core-media-query.html not found, sending 404
INFO:tensorflow:returning 404 to 127.0.0.1 for /core-media-query/core-media-query.html
"
5872,Not able to download Mac GPU build. 404. ,"Link in README is broken.

https://ci.tensorflow.org/view/Nightly/job/nightly-matrix-mac-gpu/TF_BUILD_IS_OPT=OPT,TF_BUILD_IS_PIP=PIP,TF_BUILD_PYTHON_VERSION=PYTHON2,label=gpu-mac/lastSuccessfulBuild/artifact/pip_test/whl/tensorflow-0.11.0-py2-none-any.whl"
5871,Check the Status after call builder.Finalize() in generated io_ops.cc,"e.g.

Let's assume someone passed an int32 tensor into ReaderReadUpTo as the third input(num_records), which should have a type of int64.
```
ReaderReadUpTo::ReaderReadUpTo(const ::tensorflow::Scope& scope,
                               ::tensorflow::ops::Input reader_handle,
                               ::tensorflow::ops::Input queue_handle,
                               ::tensorflow::ops::Input num_records) {
  if (!scope.ok()) return;
  auto _reader_handle = ::tensorflow::ops::AsNodeOut(scope, reader_handle);
  if (!scope.ok()) return;
  auto _queue_handle = ::tensorflow::ops::AsNodeOut(scope, queue_handle);
  if (!scope.ok()) return;
  auto _num_records = ::tensorflow::ops::AsNodeOut(scope, num_records);
  if (!scope.ok()) return;
  ::tensorflow::Node* ret;
  const auto  unique_name = scope.GetUniqueNameForOp(""ReaderReadUpTo"");
  auto builder = ::tensorflow::NodeBuilder(unique_name, ""ReaderReadUpTo"")
                     .Input(_reader_handle)
                     .Input(_queue_handle)
                     .Input(_num_records)
  ;
  scope.UpdateBuilder(&builder);
  scope.UpdateStatus(builder.Finalize(scope.graph(), &ret));
  //HERE: builder.Finalize may fails. We should check if ret==NULL, otherwise it will cause a core dump.
  ::tensorflow::NameRangeMap _outputs_range;
  ::tensorflow::Status _status_ = ::tensorflow::NameRangesForNode(ret->def(), ret->op_def(), nullptr, &_outputs_range);
  if (!_status_.ok()) {
    scope.UpdateStatus(_status_);
    return;
  }

  this->keys = Output(ret, _outputs_range[""keys""].first);
  this->values = Output(ret, _outputs_range[""values""].first);
}
```

We need modify the function at tensorflow\tensorflow\cc\framework\cc_op_gen.cc:655 

string OpInfo::GetConstructorBody() const 

to add the check."
5870,Feature Request: Bivariate/multivariate Gaussian CDF,Would it be possible to support computing the CDF of multivariate Gaussian distributions? The multivariate Gaussian implementation under https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/distributions/python/ops doesn't seem to support the CDF for multivariate Gaussian yet.
5869,Model Exporting Does not Use optimize_for_inference_lib,"Looking at the code in master, It looks like neither [`tensorflow.python.training.saver`](https://github.com/tensorflow/tensorflow/blob/eea96fc81bb1ae22eeb1d2141e47e182cecb7608/tensorflow/python/training/saver.py) nor [`tensorflow.contrib.session_bundle.exporter`](https://github.com/tensorflow/tensorflow/blob/eea96fc81bb1ae22eeb1d2141e47e182cecb7608/tensorflow/contrib/session_bundle/exporter.py) use [`optimize_for_inference_lib`](https://github.com/tensorflow/tensorflow/blob/df871edcff2faf643975b9863100ed41b6da9c3f/tensorflow/python/tools/optimize_for_inference_lib.py) which is described as:
>There are several common transformations ... that help reduce the amount of computation needed when the network is used only for inference.

Further these optimizations are not mentioned / suggested in the tensorflow serving docs:
* https://tensorflow.github.io/serving/
* https://github.com/tensorflow/tensorflow/blob/55cb1b37133e6c0409a708a763fccf566580a90a/tensorflow/contrib/session_bundle/README.md

Arguable the serving logic could be changed to [use frozen models](https://github.com/tensorflow/tensorflow/blob/5a5a25ea3ebef623e07fb9a46419a9df377a37a5/tensorflow/g3doc/how_tos/tool_developers/index.md#freezing) (see [`freeze_graph`](https://github.com/tensorflow/tensorflow/blob/df871edcff2faf643975b9863100ed41b6da9c3f/tensorflow/python/tools/freeze_graph.py)) which calls `convert_variables_to_constants`."
5868,how to continues tensor flow training after crash,"I am training inception v2 slim model, but it is crash during the training. which cmd can let me continue the training using the latest checkpoint file? I can't find it in the link below. it has fine tune but not continue training.

https://github.com/tensorflow/models/tree/master/slim

"
5867,optimize_for_inference.py should remove Dropout operations,"When I first tried using an exported MNIST model with TensorFlow on iOS, I got the following error:

    Invalid argument: No OpKernel was registered to support Op 'RandomUniform' with these attrs.  Registered devices: [CPU], Registered kernels:
      <no registered kernels>
    
         [[Node: dropout/random_uniform/RandomUniform = RandomUniform[T=DT_INT32, dtype=DT_FLOAT, seed=0, seed2=0](dropout/Shape)]]

Since Dropout operations are no-ops during inference (we pass in a keep probability of 1), it would be nice if they were removed (or turned into no-ops of some kind that can be parsed and ignored by the iOS library).

While I was able to work around this by explicitly exporting a separate graph that does not contain Dropout, it was pretty tedious and it would be nice if the `optimize_for_inference.py` script did this automatically.

### Environment info
Operating System: macOS 10.12

Installed version of CUDA and cuDNN: 
None

Source:
This week's tip-of-tree (around d93d526cb804896004c1c20a41586ce0e2415b9c)
"
5863,"Feature request: before throwing OutOfRangeError, dequeue the rest samples from a queue","When using a FIFOQueue as the input for a pipeline, we often encounter the case that `epoch_size % batch_size == M` where `M != 0`. It will lead the following issue:

if we would like to evaluate our model with the entire validation dataset, we cannot test the last `M` samples before getting the exception `OutOfRangeError` if we set `num_epoches` to 1. Even if we set `num_epoches` to `None` to avoid `OutOfRangeError`, we cannot exactly get the result because of the indivisibility issue.

So what I can think of is, we need a feature like this:
1) if `num_epoches` is set to None, we need to dequeue the rest M samples from the queue before every epoch is finished. For example, a dataset's size is 10, saying they are `[a,b,c,d,e,f,g,h,i,j]`, and `batch_size` is 3, the size of dequeued samples would be `[a,b,c], [d,e,f], [g,h,i], [j], [a,b,c], ...`;
2) if `num_epoches` is set to 1, we need to dequeue the rest M samples from the queue before throwing `OutOfRangeError`.For the above example, the result would be `[a,b,c], [d,e,f], [g,h,i], [j], OutOfRangeError`."
5862,Feature request: easier access to all variables inside a scope,"Right now, in order to access the variables inside a scope, AFAIK we have to do the following:

    variables = tf.get_collection(tf.GraphKeys.VARIABLES, scope)

It would be far easier if we could just write

    variables = scope.get_all_variables()

or maybe

    variables = tf.get_scope_variables(scope)

Is it a reasonable request?"
5861,"compute_gradients error, if there are unneeded variables","I hope this hasn't been reported already. A Google and GitHub search came up empty.

### Minimum example
```python
tf.reset_default_graph()

optimizer = tf.train.GradientDescentOptimizer(0.1)

x1_var = tf.Variable([1, 2, 3], dtype=tf.float32)
x2_var = tf.Variable([2, 3, 4], dtype=tf.float32)

grad_op = optimizer.compute_gradients(x1_var)

init = tf.initialize_all_variables()

sess = tf.Session()

sess.run(init)

grads = sess.run(grad_op)

print grads
```

### Expected Output
A list of tuples containing all variables needed to compute the input, `x1_var` in this example, and their gradients. Alternativly, a list of all variables in the graph with zeros or `None` values for the gradients of those variables that are not needed to compute the input to `compute_gradients`.

### Actual Output
```
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
<ipython-input-9-868cc989ac50> in <module>()
     15 
     16 sess.run(init)
---> 17 print sess.run(grad_op)

/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc in run(self, fetches, feed_dict, options, run_metadata)
    715     try:
    716       result = self._run(None, fetches, feed_dict, options_ptr,
--> 717                          run_metadata_ptr)
    718       if run_metadata:
    719         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)

/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc in _run(self, handle, fetches, feed_dict, options, run_metadata)
    900 
    901     # Create a fetch handler to take care of the structure of fetches.
--> 902     fetch_handler = _FetchHandler(self._graph, fetches, feed_dict_string)
    903 
    904     # Run request and get response.

/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc in __init__(self, graph, fetches, feeds)
    356     """"""
    357     with graph.as_default():
--> 358       self._fetch_mapper = _FetchMapper.for_fetch(fetches)
    359     self._fetches = []
    360     self._targets = []

/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc in for_fetch(fetch)
    179     elif isinstance(fetch, (list, tuple)):
    180       # NOTE(touts): This is also the code path for namedtuples.
--> 181       return _ListFetchMapper(fetch)
    182     elif isinstance(fetch, dict):
    183       return _DictFetchMapper(fetch)

/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc in __init__(self, fetches)
    286     """"""
    287     self._fetch_type = type(fetches)
--> 288     self._mappers = [_FetchMapper.for_fetch(fetch) for fetch in fetches]
    289     self._unique_fetches, self._value_indices = _uniquify_fetches(self._mappers)
    290 

/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc in for_fetch(fetch)
    179     elif isinstance(fetch, (list, tuple)):
    180       # NOTE(touts): This is also the code path for namedtuples.
--> 181       return _ListFetchMapper(fetch)
    182     elif isinstance(fetch, dict):
    183       return _DictFetchMapper(fetch)

/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc in __init__(self, fetches)
    286     """"""
    287     self._fetch_type = type(fetches)
--> 288     self._mappers = [_FetchMapper.for_fetch(fetch) for fetch in fetches]
    289     self._unique_fetches, self._value_indices = _uniquify_fetches(self._mappers)
    290 

/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc in for_fetch(fetch)
    176     if fetch is None:
    177       raise TypeError('Fetch argument %r has invalid type %r' %
--> 178                       (fetch, type(fetch)))
    179     elif isinstance(fetch, (list, tuple)):
    180       # NOTE(touts): This is also the code path for namedtuples.

TypeError: Fetch argument None has invalid type <type 'NoneType'>
```

### Further examples
This works:
```python
# ...

x1_var = tf.Variable([1, 2, 3], dtype=tf.float32)
# x2_var = tf.Variable([2, 3, 4], dtype=tf.float32)

grad_op = optimizer.compute_gradients(x1_var)

# ...
```
```
[(array([ 1.,  1.,  1.], dtype=float32), array([ 1.,  2.,  3.], dtype=float32))]
```

This works:
```python
# ...

x1_var = tf.Variable([1, 2, 3], dtype=tf.float32)
x2_var = tf.Variable([2, 3, 4], dtype=tf.float32)

combined_op = tf.concat(0, [x1_var, x2_var])

grad_op = optimizer.compute_gradients(combined_op)

# ...
```
```
[(array([ 1.,  1.,  1.], dtype=float32), array([ 1.,  2.,  3.], dtype=float32)), (array([ 1.,  1.,  1.], dtype=float32), array([ 2.,  3.,  4.], dtype=float32))]
```

This doesn't:
```python
# ...

x1_var = tf.Variable([1, 2, 3], dtype=tf.float32)
x2_var = tf.Variable([2, 3, 4], dtype=tf.float32)

combined_op = tf.concat(0, [x1_var, x2_var])

grad_op = optimizer.compute_gradients(x1_var)

# ...
```
```
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
<ipython-input-18-23fbf6b769d2> in <module>()
     16 sess.run(init)
     17 
---> 18 grads = sess.run(grad_op)
     19 
     20 print grads
...
```

### Workaround
Keep track of all variables needed to compute the input and pass them explicitly to `compute_gradients`.

```python
# ...

x1_var = tf.Variable([1, 2, 3], dtype=tf.float32)
x2_var = tf.Variable([2, 3, 4], dtype=tf.float32)

grad_op = optimizer.compute_gradients(x1_var, [x1_var])

# ...
```
```
[(array([ 1.,  1.,  1.], dtype=float32), array([ 1.,  2.,  3.], dtype=float32))]
```

Tensorflow version: 0.11.0rc0"
5859,Ignore,
5858,ImportError: cannot import name descriptor,"I installed tensorflow from source follow[ tutorial](https://www.tensorflow.org/versions/master/get_started/os_setup.html) and the os is macOS Sierra,tensorflow version is v0.11.0, i set up TensorFlow such that all files are linked (instead of copied) from the system directories, run the following commands inside the TensorFlow root directory:

        bazel build -c opt //tensorflow/tools/pip_package:build_pip_package_
        mkdir _python_build
        cd _python_build
        ln -s ../bazel-bin/tensorflow/tools/pip_package/build_pip_package.runfiles/org_tensorflow/* .
        ln -s ../tensorflow/tools/pip_package/* .
        python setup.py develop

when i follow the tutorial to retrain Inception's Final Layer for classifying flowers with  scripts as follows:

        “bazel build tensorflow/examples/image_retraining:retrain“
        “bazel-bin/tensorflow/examples/image_retraining/retrain --image_dir ~/flower_photos“

**i got the same error as follows:**

         Traceback (most recent call last):
         File ""/Users/jway/Documents/tensorflow/bazel-       bin/tensorflow/examples/image_retraining/retrain.runfiles/org_tensorflow/tensorflow/examples/image_retraining/retrain.py"", line 79, in <module>
         import tensorflow as tf
         File ""/Users/jway/Documents/tensorflow/bazel-bin/tensorflow/examples/image_retraining/retrain.runfiles/org_tensorflow/tensorflow/__init__.py"", line 24, in <module>
         from tensorflow.python import *
         File ""/Users/jway/Documents/tensorflow/bazel-bin/tensorflow/examples/image_retraining/retrain.runfiles/org_tensorflow/tensorflow/python/__init__.py"", line 63, in <module>
         from tensorflow.core.framework.graph_pb2 import *
         File ""/Users/jway/Documents/tensorflow/bazel-bin/tensorflow/examples/image_retraining/retrain.runfiles/org_tensorflow/tensorflow/core/framework/graph_pb2.py"", line 6, in <module>
         from google.protobuf import descriptor as _descriptor
         ImportError: cannot import name descriptor

I don't know how to solve it,can somebody give me some advices?"
5857,Error while Retraining Inception,"On running this command:

python tensorflow/examples/image_retraining/retrain.py \
--bottleneck_dir=/tf_files/bottlenecks \
--how_many_training_steps 500 \
--model_dir=/tf_files/inception \
--output_graph=/tf_files/retrained_graph.pb \
--output_labels=/tf_files/retrained_labels.txt \
--image_dir /tf_files/flower_photos

I am getting: 
IOError: CRC check failed 0x76f1f85e != 0x6caceac0L
"
5854,std::system_error after tensor flow install,"As suggested from stack overflow, i move this issue here.

I installed tensorflow in a virtual environment via pip (Ubuntu/Linux 64-bit, CPU only, Python 2.7), and tried to run the test example:

```
import tensorflow as tf
hello = tf.constant('Hello, TensorFlow!')
sess = tf.Session()
```

I get:

```
terminate called after throwing an instance of 'std::system_error'
what():  Resource temporarily unavailable
Aborted
```

I've looked around for the common troubleshooting with no success. Any ideas where to start?"
5853,sparse_tensor_dense_matmul not working with float64 on gpu,"tensorflow (I tried 0.11, 0.12 and master) claims sparse_tensor_dense_matmul be not supported on gpu, yet the docs

https://www.tensorflow.org/versions/r0.11/api_docs/python/sparse_ops.html#sparse_tensor_dense_matmul

and the fact that there is a source file

tensorflow/core/kernels/sparse_tensor_dense_matmul_op_gpu.cu.cc

which apparently gets compiled

.cache/bazel/_bazel_panzer/eb98e8482caa36ec89e479cdd4c996e7/execroot/tensorflow/bazel-out/local_linux-py3-opt/bin/tensorflow/core/kernels/libsparse_tensor_dense_matmul_op_gpu.pic.lo

suggest it should.

############ example script
```
import tensorflow as tf
import numpy as np

with tf.device('/gpu:0'):
    M = tf.SparseTensor(np.arange(4).reshape(2, 2), np.ones((2,)), (3, 3))
    v = tf.constant(np.ones((3, 1)))
    p = tf.sparse_tensor_dense_matmul(M, v)

    init = tf.initialize_all_variables()
    sess = tf.Session()
    sess.run(init)
    p = sess.run (p)
```
############ output
```
panzer:~$ python3 sparse_tensor_dense_matmul.py
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcublas.so locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcudnn.so locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcufft.so locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcuda.so.1 locally
I tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcurand.so locally
WARNING:tensorflow:From sparse_tensor_dense_matmul.py:9 in <module>.: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.
Instructions for updating:
Use `tf.global_variables_initializer` instead.
I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
I tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties:
name: GeForce GTX 1080
major: 6 minor: 1 memoryClockRate (GHz) 1.8095
pciBusID 0000:01:00.0
Total memory: 7.92GiB
Free memory: 7.81GiB
I tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0
I tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y
I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0)
Traceback (most recent call last):
  File ""/home/panzer/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 1021, in _do_call
    return fn(*args)
  File ""/home/panzer/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 999, in _run_fn
    self._extend_graph()
  File ""/home/panzer/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 1048, in _extend_graph
    self._session, graph_def.SerializeToString(), status)
  File ""/usr/lib/python3.5/contextlib.py"", line 66, in __exit__
    next(self.gen)
  File ""/home/panzer/.local/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py"", line 469, in raise_exception_on_not_ok_status
    pywrap_tensorflow.TF_GetCode(status))
tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device to node 'SparseTensorDenseMatMul/SparseTensorDenseMatMul': Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.
         [[Node: SparseTensorDenseMatMul/SparseTensorDenseMatMul = SparseTensorDenseMatMul[T=DT_DOUBLE, adjoint_a=false, adjoint_b=false, _device=""/device:GPU:0""](SparseTensor/indices, SparseTensor/values, SparseTensor/shape, Const)]]
```
During handling of the above exception, another exception occurred:
```
Traceback (most recent call last):
  File ""sparse_tensor_dense_matmul.py"", line 11, in <module>
    sess.run(init)
  File ""/home/panzer/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 766, in run
    run_metadata_ptr)
  File ""/home/panzer/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 964, in _run
    feed_dict_string, options, run_metadata)
  File ""/home/panzer/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 1014, in _do_run
    target_list, options, run_metadata)
  File ""/home/panzer/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py"", line 1034, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InvalidArgumentError: Cannot assign a device to node 'SparseTensorDenseMatMul/SparseTensorDenseMatMul': Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.
         [[Node: SparseTensorDenseMatMul/SparseTensorDenseMatMul = SparseTensorDenseMatMul[T=DT_DOUBLE, adjoint_a=false, adjoint_b=false, _device=""/device:GPU:0""](SparseTensor/indices, SparseTensor/values, SparseTensor/shape, Const)]]

Caused by op 'SparseTensorDenseMatMul/SparseTensorDenseMatMul', defined at:
  File ""sparse_tensor_dense_matmul.py"", line 7, in <module>
    p = tf.sparse_tensor_dense_matmul(M, v)
  File ""/home/panzer/.local/lib/python3.5/site-packages/tensorflow/python/ops/sparse_ops.py"", line 1339, in sparse_tensor_dense_matmul
    adjoint_b=adjoint_b)
  File ""/home/panzer/.local/lib/python3.5/site-packages/tensorflow/python/ops/gen_sparse_ops.py"", line 975, in _sparse_tensor_dense_mat_mul
    adjoint_b=adjoint_b, name=name)
  File ""/home/panzer/.local/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py"", line 759, in apply_op
    op_def=op_def)
  File ""/home/panzer/.local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py"", line 2240, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/home/panzer/.local/lib/python3.5/site-packages/tensorflow/python/framework/ops.py"", line 1128, in __init__
    self._traceback = _extract_stack()

InvalidArgumentError (see above for traceback): Cannot assign a device to node 'SparseTensorDenseMatMul/SparseTensorDenseMatMul': Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available.
         [[Node: SparseTensorDenseMatMul/SparseTensorDenseMatMul = SparseTensorDenseMatMul[T=DT_DOUBLE, adjoint_a=false, adjoint_b=false, _device=""/device:GPU:0""](SparseTensor/indices, SparseTensor/values, SparseTensor/shape, Const)]]
```

### Environment info
Operating System:
linux (ubuntu 16.04)

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):
/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudart.so.8.0.44
/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudnn.so.5.1.5

If installed from source, provide 

1. The commit hash (`git rev-parse HEAD`)
e5d44ffa3d78271e2619c577f8240e530538bb61

2. The output of `bazel version`
Build label: 0.4.0
Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Wed Nov 2 17:54:14 2016 (1478109254)
Build timestamp: 1478109254
Build timestamp as int: 1478109254

"
5852,tf.contrib.metrics.accuracy doesn't have expected weights behavior,"My assumption here is that 'weights' is intended to allow us to indicate that certain indices should be ignored entirely.

Below code generates accuracy of .67, which seems wrong.  There are no weights-related unit tests for accuracy(), so I can't verify that this is unintended, but it seems inconsistent with the rest of the tf code base.

```
import tensorflow as tf

preds=tf.Variable([1,1,1])
labels=tf.Variable([1,1,0])
weights=tf.Variable([1,1,0])

acc=tf.contrib.metrics.accuracy(preds, labels, tf.to_float(weights))

with tf.Session() as sess:
    sess.run(tf.initialize_all_variables())

    acc=sess.run(acc)
    print(acc)
```"
5850,"adding zero-sized layer costs huge amount of memory, but without increasing total # of trainable parameters","In order to make code generic, my code does append a layer with a variable-sized layer which might be of length 0, i.e.
`
tv_concat = tf.concat(1, [tf.reshape(tf.slice(X,[0,time_step,0],[-1,Ncontext,-1]), [tp_current_batch_size,embed_size*Ncontext]), tv_hh])`

In the above code, X is a tensor of shape [batch_size, max_time_step, state_size], tv_hh of shape [batch_size, state_size]. Depending on the value of Ncontext, a differently sized layer will be concatenated with the existing layer tv_hh. So when Ncontext=0, a zero-size layer will be concatenated so that tv_concat will be the same as tv_hh. I have explicitly checked and confirmed that tv_concat is indeed of the same shape as tv_hh. I have also checked that the total number of trainable parameters are the same.

However, when Ncontext=0, the graphics memory consumption is >3G, if I use tv_concat=tv_hh, the graphics memory consumption is only 2G.

So is this behaviour expected?"
5849,how to generate tfrecord files in pure python without tensorflow?,"Is there a way to convert csv file to tfrecord  in python without tensorflow?
I want to convert large data , but my hadoop cluster cannot run tensorflow because of low version of glibc "
5848,/usr/local/computecpp not found when install tensorflow.,"when run tensorflow configure, it shows /usr/local/computecpp not found when install tensorflow.
I followed the instrcution, But i can not find how to install computecpp. plz help."
5847,the embedding_lookup() returns zeros when the index exceed embedding matrix size?,"NOTE: Only file GitHub issues for bugs and feature requests.  All other topics will be closed.

I wrote an issues a month ago about the same problem #5260 
I recently update the TF to latest master branch(`0.11.head`) without any custom modification and the commit hash is 55dbc54192a378c5e685c52595f42503f037320e

The tf.embedding_lookup() still do not raise error even though the index is exceeding the embedding matrix size. It automatically fills zeros as you can see in the below example. 

I tested same code with two different machines and the result was same.
In the previous issue(#5260), @strategist333 said it raise an `InvalidArgumentError` in binary release.
But when I tested TF installed from source, it didn't...
 

```
 import tensorflow as tf
 import numpy as np

 embd_mat = np.linspace(1,10,10).reshape([10,1])*np.array([1,2,3]).reshape([1,3])
 idx = np.linspace(0,19,20)

 embd_in = tf.placeholder(tf.float32,[10,3])
 idx_in = tf.placeholder(tf.int32,[20])

 output = tf.nn.embedding_lookup(embd_in,idx_in)

 with tf.Session() as sess:
     sess.run(tf.initialize_all_variables())

     embd_out = sess.run(output,feed_dict={embd_in:embd_mat, idx_in:idx})

     print embd_out
```

The output of above code is,

```
[[  1.   2.   3.]
 [  2.   4.   6.]
 [  3.   6.   9.]
 [  4.   8.  12.]
 [  5.  10.  15.]
 [  6.  12.  18.]
 [  7.  14.  21.]
 [  8.  16.  24.]
 [  9.  18.  27.]
 [ 10.  20.  30.]
 [  0.   0.   0.]
 [  0.   0.   0.]
 [  0.   0.   0.]
 [  0.   0.   0.]
 [  0.   0.   0.]
 [  0.   0.   0.]
 [  0.   0.   0.]
 [  0.   0.   0.]
 [  0.   0.   0.]
 [  0.   0.   0.]]
```"
5845,How to speed up？ why so so slower than caffe,"I use tensoflow r11+Titan x+cuda8+cudnnv5
but the speed of training is much slower than caffe.  It can run about 5W epochs with caffe in a night, but only 350 epochs with tensorflow, I don't know why the gap of speed is so big.
If anywhere need I to change? I follow the cifar10 example to suit my experiment

thanks~"
5843,Smaller dataset to use for the seq2seq translate example?,"I'm running the translate/seq2seq_model.py example code, and the dataset is rather large and I'm running out of space in my allocated remote node. Is there a smaller dataset that could be compatible with the code? 

Many thanks!"
5842,Implementing SVD rank threshold?,"It might be useful to use Eigen SVD's `Eigen::BDCSVD::setThreshold` function in order to cull the effectively zero singular values, perhaps by introducing a new parameter to TensorFlow's SVD so that `tf.svd(tensor, compute_uv=True, full_matrices=False, thresholded=True, name=None)` uses
- the default Eigen threshold for `thresholded=True`
- the full P = min(M, N) singular values for `thresholded=False`
- whatever threshold is specified with a float, such as `thresholded=1e-7`

I can get started on a PR if this is something that might be useful."
5840,Move Torch to TensorFlow,"Hi, I try to translate a torch code to TensorFlow, but I cannot find the corresponding tensorflow function of `SpatialFullConvolution` which is able to apply transpose convoluation on vector (not only image).

How can I deal with it?
here is an example https://github.com/soumith/dcgan.torch/blob/master/main.lua"
5837,Streaming Median Metric,"I'd like to contribute a streaming median metric to:
https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/metrics/python/ops/metric_ops.py

Using something like the min/max heap streaming median algorithm:
http://stackoverflow.com/questions/10657503/find-running-median-from-a-stream-of-integers

This method requires some kind of heap/list of tensors. To my knowledge you can't define a tf.Variable to be a list. Can you suggest how to solve this, or a better way to approach this problem? Thanks."
5834,TensorForestEstimator with input_fn results in infinite loop for evaluate and predict.,"When using `TensorForestEstimator`, using the previous implementation with x= and y= works. However, when trying to convert to the soon-to-be standard of input_fn, I get strange behaviors. Given 

```
params = tf.contrib.tensor_forest.python.tensor_forest.ForestHParams(
num_trees=10,
max_nodes=100,
num_classes=2,
num_features=features_count)
classifier = TensorForestEstimator(params)
```

calling 
```
classifier.fit(input_fn=(lambda: training_input_fn(trainset)))
```
works and completes correctly. The input_fn used is the following :

```
features_name = [] # ordered list of all features in the dataset
def training_input_fn(dataset):
        data, target = dataset
        # 'data' is a numpy array where data[:,i] returns all observations for a given feature
        # It is reshaped because otherwise I had a concat error
        features = {features_name[i]: tf.constant(data[:, i], shape=(data.shape[0], 1))
                    for i in range(len(features_name)) if features_name[i] in DEFAULT_FEATURES}
        labels = tf.constant(target)
        return features, labels
```


However, calling 
```
classifier.evaluate(input_fn=(lambda: training_input_fn(validset)))
```
afterwards results in an apparently neverending loop in `tf.contrib.learn.python.learn.graph_actions` in function `run_feeds_iter` in the following snippet :
```
      try:
        threads = queue_runner.start_queue_runners(session, coord=coord)
        for f in feed_dicts:
          yield session.run(output_dict, f)
      finally:
        coord.request_stop()
        if threads:
          coord.join(threads, stop_grace_period_secs=120)
```
The loop seems like never stopping. Also, memory starts increasing slowly but steadily from there (had to stop at 10 GB for this fairly small dataset). The same goes if I try predict on it. 
My Training dataset is composed of 3633 entries with 183 features and my validation dataset is composed of 2180 entries. 

### Environment info
Operating System: 
Ubuntu 16.04, running on Python3.5

Installed version of CUDA and cuDNN: 
```
-rw-r--r-- 1 root root   558720 Nov 22 10:52 /usr/local/cuda/lib64/libcudadevrt.a
lrwxrwxrwx 1 root root       16 Nov 22 10:52 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.8.0
lrwxrwxrwx 1 root root       19 Nov 22 10:52 /usr/local/cuda/lib64/libcudart.so.8.0 -> libcudart.so.8.0.44
-rwxr-xr-x 1 root root   415432 Nov 22 10:52 /usr/local/cuda/lib64/libcudart.so.8.0.44
-rw-r--r-- 1 root root   775162 Nov 22 10:52 /usr/local/cuda/lib64/libcudart_static.a
lrwxrwxrwx 1 root root       13 Nov 22 12:47 /usr/local/cuda/lib64/libcudnn.so -> libcudnn.so.5
lrwxrwxrwx 1 root root       17 Nov 22 12:47 /usr/local/cuda/lib64/libcudnn.so.5 -> libcudnn.so.5.1.5
-rwxr-xr-x 1 root root 79337624 Nov 22 12:47 /usr/local/cuda/lib64/libcudnn.so.5.1.5
-rw-r--r-- 1 root root 69756172 Nov 22 12:47 /usr/local/cuda/lib64/libcudnn_static.a
```

If installed from source, provide 
1. The commit hash (`git rev-parse HEAD`) : `a26a5925b0500d0e9cd259989fc0e113fa29e27f`
2. The output of `bazel version` : 

`Build label: 0.4.0
Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Wed Nov 2 17:54:14 2016 (1478109254)
Build timestamp: 1478109254
Build timestamp as int: 1478109254`"
5832,Still 0.11.RC0 after upgrading to RC2,"I've used Anaconda-Pip installation in the tutorial to upgrade my TensorFlow

```
# Ubuntu/Linux 64-bit, CPU only, Python 3.5
(tensorflow)$ export TF_BINARY_URL=https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.11.0rc2-cp35-cp35m-linux_x86_64.whl

# Python 3
(tensorflow)$ pip3 install --ignore-installed --upgrade $TF_BINARY_URL

....> ipython

In [1]: import tensorflow as tf
In [2]: tf.__version__
Out[2]: '0.11.0rc0'

```

But it seems it is still in RC0, in which doesn't include new method such as `tf.summary.merge_all()`

"
5831,Is there a backpropagation-method for all math-layers i.e. tf.fft2d?,"When building a deep NN, where one of the layer is represented by a fouriertransform (i.e. tf.fft), does tensorflow provide a backpropagation method for it? In this case it could/would be complex I guess. 
How does the optimizer work on that? Are there any documents which could explain this behavior? 

In theory, I understand how the gradient of a multiplication is carried out, but doing this for a more complicated function makes things more difficult for me. 

Thank you very much :) "
5830,RNN support in tensorflow slim,Is there any plan to build RNN support into tf.slim layers? Or is there a road map for tf.slim development that you could please share?
5829,"sampled_softmax souldn't be linear with respect to vocabulary size, but actually is","Hi,

[tf.nn.sampled_softmax_loss API doc page](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/g3doc/api_docs/python/functions_and_classes/shard1/tf.nn.sampled_softmax_loss.md) tells us to get into Section 3 of [Jean et al., 2014](https://arxiv.org/abs/1412.2007) ([pdf](https://arxiv.org/pdf/1412.2007v2.pdf)) for more information about it.

And actually, they quite start sec. 3.1saying:
> ""With  the  proposed  approach,  the  computational complexity of training becomes constant with respect to the size of the target vocabulary""

Which, kept my attention.   
I ran a benchmark using my [custom RNN LM script](https://github.com/pltrdy/tf_rnnlm) (derived from [tensorflow 0.11 ptb_word_lm.py](https://github.com/tensorflow/tensorflow/blob/282823b877f173e6a33bbc9d4b9ad7dd8413ada6/tensorflow/models/rnn/ptb/ptb_word_lm.py).    

[Results shows](https://github.com/pltrdy/tf_rnnlm/blob/master/benchmark.md) that, only changing vocab_size increases computation time linearly. (the benchmark is using ['SmallConfig'](https://github.com/tensorflow/tensorflow/blob/282823b877f173e6a33bbc9d4b9ad7dd8413ada6/tensorflow/models/rnn/ptb/ptb_word_lm.py#L189) with `vocab_size` of either 10k or 150k.


### Environment info
Operating System: Ubuntu 14.04.

Installed version of CUDA and cuDNN: 
```
$ ls -l /usr/local/cuda-8.0/lib64/libcud*
-rw-r--r-- 1 root root 546K oct.  21 10:20 /usr/local/cuda-8.0/lib64/libcudadevrt.a
lrwxrwxrwx 1 root root   16 oct.  21 10:20 /usr/local/cuda-8.0/lib64/libcudart.so -> libcudart.so.8.0*
lrwxrwxrwx 1 root root   19 oct.  21 10:20 /usr/local/cuda-8.0/lib64/libcudart.so.8.0 -> libcudart.so.8.0.44*
-rwxr-xr-x 1 root root 406K oct.  21 10:20 /usr/local/cuda-8.0/lib64/libcudart.so.8.0.44*
-rw-r--r-- 1 root root 757K oct.  21 10:20 /usr/local/cuda-8.0/lib64/libcudart_static.a
```


#### TensorFlow Version:
0.11RC2



Thx for your reading & feebacks
`pltrdy`
"
5828,"tf.train.range_input_producer computes ""limit"" argument more than once","Hello, I have an issue with unexpected behavior of range_input_producer. It recomputes its ""limit"" argument more times than needed.

`
import tensorflow as tf

limit = tf.Print(tf.constant(5, dtype=tf.int32), [0], ""compute limit"")
range = tf.train.range_input_producer(limit, shuffle=False, num_epochs=1)
idx = range.dequeue()

with tf.Session() as ss:
    ss.run(tf.initialize_all_variables())
    ss.run(tf.initialize_local_variables())
    coord = tf.train.Coordinator()
    threads = tf.train.start_queue_runners(sess=ss, coord=coord)
    while True:
        print(ss.run([idx]))
`

When num_epoch=1, the output will have ""compute limit"" twice. I expect it to appear only once.
When num_epoch=None, the output will have infinitely many ""compute limit"" messages. But I am expecting, that it should read limit only once and then cycle through generated range infinitely.

Things get important when ""limit"" is coming from previous queue, which after getting empty produces OutOfRange and for some reasons it is not handled by range_input_producer.



### Environment info
Operating System: Fedora 24

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):
/usr/local/cuda/lib64/libcudadevrt.a       /usr/local/cuda/lib64/libcudnn.so
/usr/local/cuda/lib64/libcudart.so         /usr/local/cuda/lib64/libcudnn.so.5
/usr/local/cuda/lib64/libcudart.so.8.0     /usr/local/cuda/lib64/libcudnn.so.5.1.5
/usr/local/cuda/lib64/libcudart.so.8.0.44  /usr/local/cuda/lib64/libcudnn_static.a
/usr/local/cuda/lib64/libcudart_static.a

If installed from binary pip package, provide:
1. A link to the pip package you installed:
    https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.11.0-cp35-cp35m-linux_x86_64.whl
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.
    0.11.0"
5827,"Should variables in ExponentialMovingAverage use ""get_variable""","zero_debias for moving average was introduced recently on master branches.  (tensorflow/tensorflow/python/training/moving_averages.py)
Variables in func “_zero_debias” is created by ""variable_scope.get_variable"", while slot_creator creates moving variable with ""variables.Variable"". This causes some problem when outer scope set “reuse=True”, if we only want to reuse variables of the network but not the moving averages.
At least, the new feature introduces inconsistency on how to maintain moving variables."
5823,[FEATURE REQUEST] expand decode_csv to work with whole csv files.,"I'm a bit new to tensorflow, so forgive me if this exists and I just missed it, but it seems decode_csv treats csv files exclusively as a set of records, returning a 1D tensor. This makes decoding 2D samples unintuitive (I've yet to figure out how to do so without simply telling numpy to get them and throw them into a placeholder). How much work would it be to either expand the current function or add a new one that works in a similar manner to decode_png?"
5818,[Windows] DepthwiseConv2DNative not available,"The DepthwiseConv2DNative op (and some related ops for backprop) are currently excluded from the Windows build ([CMake reference](https://github.com/tensorflow/tensorflow/blob/e297257e458654c7743c59c7f37154b7f6118c16/tensorflow/contrib/cmake/tf_core_kernels.cmake#L87), [Bazel reference](https://github.com/tensorflow/tensorflow/blob/e297257e458654c7743c59c7f37154b7f6118c16/tensorflow/core/kernels/BUILD#L1719)). This is causing issues for models that use these ops (e.g. https://github.com/fchollet/keras/issues/4478).

We should figure out why it doesn't build and fix it."
5816,MaxPool3DGrad - Out of Memory Issue,"I am training a fairly big network with many 3D convolutions that almost fills up all the GPU memory (Titan X). When settings the batch size to a small amount, e.g. 32 examples the training process crashes after a number of steps with an out of memory issue caused by `MaxPool3DGrad`. I lowered the batch size to 20, which makes the training run fine for >2000 training steps but then at some point the model crashes again with the same error. It seems like some operations are not freeing memory, maybe the `MaxPool3DGrad` kernel? Full error message is given below. 

**Configuration**: Linux Mint, checkout of the TensorFlow master 5 days ago (`dfc5cd48a095b133ece9caff663e3cc512e8a268`) with CUDA 8.0 and CuDNN 5.1.  

This might be relevant: https://github.com/tensorflow/tensorflow/issues/3696

```
I tensorflow/core/common_runtime/bfc_allocator.cc:696] 3 Chunks of size 1722368000 totalling 4.81GiB
I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 2674491392 totalling 2.49GiB
I tensorflow/core/common_runtime/bfc_allocator.cc:696] 1 Chunks of size 3444734720 totalling 3.21GiB
I tensorflow/core/common_runtime/bfc_allocator.cc:700] Sum Total of in-use chunks: 11.21GiB
I tensorflow/core/common_runtime/bfc_allocator.cc:702] Stats:
Limit:                 12051264308
InUse:                 12032303616
MaxInUse:              12032303616
NumAllocs:                 2860074
MaxAllocSize:           3444734976

W tensorflow/core/common_runtime/bfc_allocator.cc:274] ******************************xxxxxxxxxxxxx**************************************************xxxxxxx
W tensorflow/core/common_runtime/bfc_allocator.cc:275] Ran out of memory trying to allocate 205.32MiB.  See logs for memory state.
W tensorflow/core/framework/op_kernel.cc:975] Resource exhausted: OOM when allocating tensor with shape[20,64,50,29,29]
Traceback (most recent call last):
  File ""train_c3d.py"", line 324, in <module>
    is_training: True
  File ""/home/trunia/virtualenv/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 766, in run
    run_metadata_ptr)
  File ""/home/trunia/virtualenv/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 964, in _run
    feed_dict_string, options, run_metadata)
  File ""/home/trunia/virtualenv/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 1014, in _do_run
    target_list, options, run_metadata)
  File ""/home/trunia/virtualenv/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/client/session.py"", line 1034, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[20,64,50,29,29]
         [[Node: gradients/3D_CNN/conv-relu-0/MaxPool3D_grad/MaxPool3DGrad = MaxPool3DGrad[T=DT_FLOAT, ksize=[1, 1, 2, 2, 1], padding=""VALID"", strides=[1, 2, 2, 2, 1], _device=""/job:localhost/repl
ica:0/task:0/gpu:0""](3D_CNN/conv-relu-0/Relu, 3D_CNN/conv-relu-0/MaxPool3D, gradients/3D_CNN/conv-relu-1/conv-1_grad/tuple/control_dependency)]]

Caused by op u'gradients/3D_CNN/conv-relu-0/MaxPool3D_grad/MaxPool3DGrad', defined at:
  File ""train_c3d.py"", line 145, in <module>
    grads_and_vars = optimizer.compute_gradients(total_loss)
  File ""/home/trunia/virtualenv/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/training/optimizer.py"", line 335, in compute_gradients
    colocate_gradients_with_ops=colocate_gradients_with_ops)
  File ""/home/trunia/virtualenv/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/ops/gradients_impl.py"", line 482, in gradients
    in_grads = grad_fn(op, *out_grads)
  File ""/home/trunia/virtualenv/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/ops/nn_grad.py"", line 130, in _MaxPool3DGrad
    padding=op.get_attr(""padding""))
  File ""/home/trunia/virtualenv/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/ops/gen_nn_ops.py"", line 1657, in max_pool3d_grad
    name=name)
  File ""/home/trunia/virtualenv/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py"", line 759, in apply_op
    op_def=op_def)
  File ""/home/trunia/virtualenv/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 2259, in create_op
    original_op=self._default_original_op, op_def=op_def)
  File ""/home/trunia/virtualenv/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/framework/ops.py"", line 1130, in __init__
    self._traceback = _extract_stack()

...which was originally created as op u'3D_CNN/conv-relu-0/MaxPool3D', defined at:
  File ""train_c3d.py"", line 128, in <module>
```"
5809,multi-GPU training? ,"We are trying to scale up one of the detection deep learning architecture written in Tensorflow for multi-GPU training. Here's the [link](https://github.com/Russell91/TensorBox) to the architecture.

We need specific help in understanding the properties of the gradients such as shape, type and more importantly ways to access the same so that it can be built on two GPUs separately and synchronize like in the cifar_multi_gpu training.. 

This is the grad step in build function and we would like to access in train function:

if H['clip_norm'] <= 0:
                grads = tf.gradients(loss['train'], tvars)
            else:
                grads, norm = tf.clip_by_global_norm(tf.gradients(loss['train'], tvars), H['clip_norm'])


We have the following functions in the train and build model steps in the overall architecture.

def build(H, q):
    '''
    Build full model for training, including forward / backward passes,
    optimizers, and summary statistics.
    '''
    arch = H
    solver = H[""solver""]

    os.environ['CUDA_VISIBLE_DEVICES'] = str(solver.get('gpu', ''))

    #gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.8)
    gpu_options = tf.GPUOptions()
    config = tf.ConfigProto(gpu_options=gpu_options)

    learning_rate = tf.placeholder(tf.float32)
    if solver['opt'] == 'RMS':
        opt = tf.train.RMSPropOptimizer(learning_rate=learning_rate,
                                        decay=0.9, epsilon=solver['epsilon'])
    elif solver['opt'] == 'Adam':
        opt = tf.train.AdamOptimizer(learning_rate=learning_rate,
                                        epsilon=solver['epsilon'])
    elif solver['opt'] == 'SGD':
        opt = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)
    else:
        raise ValueError('Unrecognized opt type')
    loss, accuracy, confidences_loss, boxes_loss = {}, {}, {}, {}
    for phase in ['train', 'test']:
        # generate predictions and losses from forward pass
        x, confidences, boxes = q[phase].dequeue_many(arch['batch_size'])
        flags = tf.argmax(confidences, 3)


        grid_size = H['grid_width'] * H['grid_height']

        (pred_boxes, pred_confidences,
         loss[phase], confidences_loss[phase],
         boxes_loss[phase]) = build_forward_backward(H, x, phase, boxes, flags)
        pred_confidences_r = tf.reshape(pred_confidences, [H['batch_size'], grid_size, H['rnn_len'], arch['num_classes']])
        pred_boxes_r = tf.reshape(pred_boxes, [H['batch_size'], grid_size, H['rnn_len'], 4])


        # Set up summary operations for tensorboard
        a = tf.equal(tf.argmax(confidences[:, :, 0, :], 2), tf.argmax(pred_confidences_r[:, :, 0, :], 2))
        accuracy[phase] = tf.reduce_mean(tf.cast(a, 'float32'), name=phase+'/accuracy')

        if phase == 'train':
            global_step = tf.Variable(0, trainable=False)

            tvars = tf.trainable_variables()
            if H['clip_norm'] <= 0:
                grads = tf.gradients(loss['train'], tvars)
            else:
                grads, norm = tf.clip_by_global_norm(tf.gradients(loss['train'], tvars), H['clip_norm'])
            train_op = opt.apply_gradients(zip(grads, tvars), global_step=global_step)
        elif phase == 'test':
            moving_avg = tf.train.ExponentialMovingAverage(0.95)
            smooth_op = moving_avg.apply([accuracy['train'], accuracy['test'],
                                          confidences_loss['train'], boxes_loss['train'],
                                          confidences_loss['test'], boxes_loss['test'],
                                          ])

            for p in ['train', 'test']:
                tf.scalar_summary('%s/accuracy' % p, accuracy[p])
                tf.scalar_summary('%s/accuracy/smooth' % p, moving_avg.average(accuracy[p]))
                tf.scalar_summary(""%s/confidences_loss"" % p, confidences_loss[p])
                tf.scalar_summary(""%s/confidences_loss/smooth"" % p,
                    moving_avg.average(confidences_loss[p]))
                tf.scalar_summary(""%s/regression_loss"" % p, boxes_loss[p])
                tf.scalar_summary(""%s/regression_loss/smooth"" % p,
                    moving_avg.average(boxes_loss[p]))

        if phase == 'test':
            test_image = x
            # show ground truth to verify labels are correct
            test_true_confidences = confidences[0, :, :, :]
            test_true_boxes = boxes[0, :, :, :]

            # show predictions to visualize training progress
            test_pred_confidences = pred_confidences_r[0, :, :, :]
            test_pred_boxes = pred_boxes_r[0, :, :, :]

            def log_image(np_img, np_confidences, np_boxes, np_global_step, pred_or_true):
                
                merged = train_utils.add_rectangles(H, np_img, np_confidences, np_boxes,
                                                    use_stitching=True,
                                                    rnn_len=H['rnn_len'])[0]
                
                num_images = 10
                img_path = os.path.join(H['save_dir'], '%s_%s.jpg' % ((np_global_step / H['logging']['display_iter']) % num_images, pred_or_true))
                misc.imsave(img_path, merged)
                return merged

            pred_log_img = tf.py_func(log_image,
                                      [test_image, test_pred_confidences, test_pred_boxes, global_step, 'pred'],
                                      [tf.float32])
            true_log_img = tf.py_func(log_image,
                                      [test_image, test_true_confidences, test_true_boxes, global_step, 'true'],
                                      [tf.float32])
            tf.image_summary(phase + '/pred_boxes', tf.pack(pred_log_img),max_images=10)
            tf.image_summary(phase + '/true_boxes', tf.pack(true_log_img),max_images=10)

    summary_op = tf.merge_all_summaries()

    return (config, loss, accuracy, summary_op, train_op,
            smooth_op, global_step, learning_rate)


def train(H, test_images):
    '''
    Setup computation graph, run 2 prefetch data threads, and then run the main loop
    '''

    if not os.path.exists(H['save_dir']): os.makedirs(H['save_dir'])

    ckpt_file = H['save_dir'] + '/save.ckpt'
    with open(H['save_dir'] + '/hypes.json', 'w') as f:
        json.dump(H, f, indent=4)

    x_in = tf.placeholder(tf.float32)
    confs_in = tf.placeholder(tf.float32)
    boxes_in = tf.placeholder(tf.float32)
    q = {}
    enqueue_op = {}
    for phase in ['train', 'test']:
        dtypes = [tf.float32, tf.float32, tf.float32]
        grid_size = H['grid_width'] * H['grid_height']
        shapes = (
            [H['image_height'], H['image_width'], 3],
            [grid_size, H['rnn_len'], H['num_classes']],
            [grid_size, H['rnn_len'], 4],
            )
        q[phase] = tf.FIFOQueue(capacity=30, dtypes=dtypes, shapes=shapes)
        enqueue_op[phase] = q[phase].enqueue((x_in, confs_in, boxes_in))

    def make_feed(d):
        return {x_in: d['image'], confs_in: d['confs'], boxes_in: d['boxes'],
                learning_rate: H['solver']['learning_rate']}

    def thread_loop(sess, enqueue_op, phase, gen):
        for d in gen:
            sess.run(enqueue_op[phase], feed_dict=make_feed(d))

    (config, loss, accuracy, summary_op, train_op,
     smooth_op, global_step, learning_rate) = build(H, q)

    saver = tf.train.Saver(max_to_keep=None)
    writer = tf.train.SummaryWriter(
        logdir=H['save_dir'],
        flush_secs=10
    )

    with tf.Session(config=config) as sess:
        tf.train.start_queue_runners(sess=sess)
        for phase in ['train', 'test']:
            # enqueue once manually to avoid thread start delay
            gen = train_utils.load_data_gen(H, phase, jitter=H['solver']['use_jitter'])
            d = gen.next()
            sess.run(enqueue_op[phase], feed_dict=make_feed(d))
            t = tf.train.threading.Thread(target=thread_loop,
                                 args=(sess, enqueue_op, phase, gen))
            t.daemon = True
            t.start()

        tf.set_random_seed(H['solver']['rnd_seed'])
        sess.run(tf.initialize_all_variables())
        writer.add_graph(sess.graph)
        weights_str = H['solver']['weights']
        if len(weights_str) > 0:
            print('Restoring from: %s' % weights_str)
            saver.restore(sess, weights_str)
        else:
            init_fn = slim.assign_from_checkpoint_fn(
                  '%s/data/inception_v1.ckpt' % os.path.dirname(os.path.realpath(__file__)),
                  [x for x in tf.all_variables() if x.name.startswith('InceptionV1') and not H['solver']['opt'] in x.name])
            init_fn(sess)

        # train model for N iterations
        start = time.time()
        max_iter = H['solver'].get('max_iter', 10000000)
        for i in xrange(max_iter):
            display_iter = H['logging']['display_iter']
            adjusted_lr = (H['solver']['learning_rate'] *
                           0.5 ** max(0, (i / H['solver']['learning_rate_step']) - 2))
            lr_feed = {learning_rate: adjusted_lr}

            if i % display_iter != 0:
                # train network
                batch_loss_train, _ = sess.run([loss['train'], train_op], feed_dict=lr_feed)
            else:
                # test network every N iterations; log additional info
                if i > 0:
                    dt = (time.time() - start) / (H['batch_size'] * display_iter)
                start = time.time()
                (train_loss, test_accuracy, summary_str,
                    _, _) = sess.run([loss['train'], accuracy['test'],
                                      summary_op, train_op, smooth_op,
                                     ], feed_dict=lr_feed)
                writer.add_summary(summary_str, global_step=global_step.eval())
                print_str = string.join([
                    'Step: %d',
                    'lr: %f',
                    'Train Loss: %.2f',
                    'Softmax Test Accuracy: %.1f%%',
                    'Time/image (ms): %.1f'
                ], ', ')
                print(print_str %
                      (i, adjusted_lr, train_loss,
                       test_accuracy * 100, dt * 1000 if i > 0 else 0))

            if global_step.eval() % H['logging']['save_iter'] == 0 or global_step.eval() == max_iter - 1:
                saver.save(sess, ckpt_file, global_step=global_step)

Thanks in advance!

"
5808,mac install fail,"when excute command
sudo pip install --upgrade $TF_BINARY_URLException:
Traceback (most recent call last):
  File ""/Library/Python/2.7/site-packages/pip-9.0.1-py2.7.egg/pip/basecommand.py"", line 215, in main
    status = self.run(options, args)
  File ""/Library/Python/2.7/site-packages/pip-9.0.1-py2.7.egg/pip/commands/install.py"", line 342, in run
    prefix=options.prefix_path,
  File ""/Library/Python/2.7/site-packages/pip-9.0.1-py2.7.egg/pip/req/req_set.py"", line 778, in install
    requirement.uninstall(auto_confirm=True)
  File ""/Library/Python/2.7/site-packages/pip-9.0.1-py2.7.egg/pip/req/req_install.py"", line 754, in uninstall
    paths_to_remove.remove(auto_confirm)
  File ""/Library/Python/2.7/site-packages/pip-9.0.1-py2.7.egg/pip/req/req_uninstall.py"", line 115, in remove
    renames(path, new_path)
  File ""/Library/Python/2.7/site-packages/pip-9.0.1-py2.7.egg/pip/utils/__init__.py"", line 267, in renames
    shutil.move(old, new)
  File ""/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/shutil.py"", line 299, in move
    copytree(src, real_dst, symlinks=True)
  File ""/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/shutil.py"", line 208, in copytree
    raise Error, errors
Error: [('/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/_markerlib/__init__.py', '/tmp/pip-1gfyUU-uninstall/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/_markerlib/__init__.py', ""[Errno 1] Operation not permitted: '/tmp/pip-1gfyUU-uninstall/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/_markerlib/__init__.py'""), ('/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/_markerlib/__init__.pyc', '/tmp/pip-1gfyUU-uninstall/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/_markerlib/__init__.pyc', ""[Errno 1] Operation not permitted: '/tmp/pip-1gfyUU-uninstall/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/_markerlib/__init__.pyc'""), ('/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/_markerlib/markers.py', '/tmp/pip-1gfyUU-uninstall/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/_markerlib/markers.py', ""[Errno 1] Operation not permitted: '/tmp/pip-1gfyUU-uninstall/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/_markerlib/markers.py'""), ('/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/_markerlib/markers.pyc', '/tmp/pip-1gfyUU-uninstall/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/_markerlib/markers.pyc', ""[Errno 1] Operation not permitted: '/tmp/pip-1gfyUU-uninstall/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/_markerlib/markers.pyc'""), ('/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/_markerlib', '/tmp/pip-1gfyUU-uninstall/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/_markerlib', ""[Errno 1] Operation not permitted: '/tmp/pip-1gfyUU-uninstall/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/_markerlib'"")]
libaochengdeMacBook-Pro:~ libaocheng$ 
"
5807,max_pool3d output shape is more undefined than input shape,"It looks like `tf.nn.max_pool3d` returns wrong output shape:

```
tf.nn.max_pool3d(tf.placeholder(tf.float32, [None, None, 100, 100, 1]), [1, 1, 1, 1, 1], [1, 1, 1, 1, 1], 'VALID')
```

returns following tensor: 
`<tf.Tensor 'MaxPool3D_6:0' shape=(?, ?, ?, ?, 1) dtype=float32>`

I believe that dimensions 2 and 3 (counting from 0) should not be undefined.

In similar situation `tf.nn.max_pool` returns correct result.

```
tf.nn.max_pool(tf.placeholder(tf.float32, [None, None, 100, 1]), [1, 1, 1, 1], [1, 1, 1, 1], 'VALID')
```
produces: 
`<tf.Tensor 'MaxPool_3:0' shape=(?, ?, 100, 1) dtype=float32>`


### Environment info
Operating System: Linux
Tensorflow version: v0.11.0 (282823b877f173e6a33bbc9d4b9ad7dd8413ada6), built from sources with bazel 0.4.0
"
5806,What's wrong with this loss? Shape () must have rank 1,
5805,The repository named 'local_config_cuda' could not be resolved.,"I'm trying to use this structure for my project (using tensorflow as a module in my project) and my_project only contains code to build an .so library.
```
my_project
|-- WORKSPACE
|-- my_android_app
|   |-- BUILD
|   `-- ...
|-- tensorflow
|   |-- tensorflow
|   |   |   |-- workspace.bzl
|   |   |   |-- tensorflow.bzl
|   |   |   `-- ...
|   |-- WORKSPACE
|   |-- BUILD
.    `-- ...
```

The content of `my_project/WORKSPACE` is 
```
workspace(name = ""my_project"")

local_repository(
  name = ""org_tensorflow"",
  path = ""tensorflow/""
)
```

The content of `my_project/my_android_app/BUILD` for now is:

```
package(default_visibility = [""//visibility:public""])
load(""@org_tensorflow//tensorflow:tensorflow.bzl"", ""tf_copts"")
tf_copts()
```

When I try build this project with bazel I have this error:

`bazel build -c opt //my_project --crosstool_top=//external:android/crosstool  --cpu=armeabi-v7a  --host_crosstool_top=@bazel_tools//tools/cpp:toolchain`

`ERROR: error loading package 'my_project': Encountered error while reading extension file 'cuda/build_defs.bzl': no such package '@local_config_cuda//cuda': error loading package 'external': The repository named 'local_config_cuda' could not be resolved.`

NB: I'm successfully building the TensorFlow Android Camera Demo `tensorflow/tenssorflow/examples/android/`

Related Issue: [#2775](https://github.com/tensorflow/tensorflow/issues/2775)"
5804,ffmpeg.decode_audio cannot be run in parallel,"To decode the input, the function writes the content to a temporary file. Its name is generated by the function `GetTempFilename` found in `tensorflow/contrib/ffmpeg/default/ffmpeg_lib.cc`. The template for the filename is `%tmp_dir/tmp_file_%PID.%EXT`.

**When using multiple decoders in parallel this causes an undetermined behaviour since all decoders want to write and afterwards delete the same file.**

A possible solution would be to use the thread id instead of the process id. I.e.

```
#include <sys/syscall.h>
#define gettid() syscall(SYS_gettid)
...
return io::JoinPath(dir, StrCat(""tmp_file_"", gettid(), ""."", extension));
```
The first two lines are necessary because [glibc does not wrap the call](http://man7.org/linux/man-pages/man2/gettid.2.html).

This solution works for me (on Linux). I'm, however, not sure if it works on all supported platforms. If that's fine, I can make a pull request."
5803,The parameters are not updated using multi-gpu training. ,"from __future__ import print_function

import tensorflow as tf
import numpy as np

##------ Import MNIST data
from tensorflow.examples.tutorials.mnist import input_data
mnist = input_data.read_data_sets(""/tmp/data/"", one_hot=True)

##------- Parameters
learning_rate = 0.001
training_iters = 100000
batch_size = 32
display_step = 10
num_gpus = 2

##--------- Network Parameters
n_input = 784 # MNIST data input (img shape: 28*28)
n_classes = 10 # MNIST total classes (0-9 digits)
dropout = 0.75 # Dropout, probability to keep units


##------- Create some wrappers for simplicity

def conv2d(x, W, b, strides=1):
    # Conv2D wrapper, with bias and relu activation
    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='SAME')
    x = tf.nn.bias_add(x, b)
    return tf.nn.relu(x)


def maxpool2d(x, k=2):
    # MaxPool2D wrapper
    return tf.nn.max_pool(x, ksize=[1, k, k, 1], strides=[1, k, k, 1],
                          padding='SAME')


def average_gradients(tower_grads):

    average_grads = []
    for grad_and_vars in zip(*tower_grads):
    # Note that each grad_and_vars looks like the following:
    #   ((grad0_gpu0, var0_gpu0), ... , (grad0_gpuN, var0_gpuN))
        grads = []
        for g, _ in grad_and_vars:
      # Add 0 dimension to the gradients to represent the tower.
            expanded_g = tf.expand_dims(g, 0)

      # Append on a 'tower' dimension which we will average over below.
            grads.append(expanded_g)

    # Average over the 'tower' dimension.
            grad = tf.concat(0, grads)
            grad = tf.reduce_mean(grad, 0)

    # Keep in mind that the Variables are redundant because they are shared
    # across towers. So .. we will just return the first tower's pointer to
    # the Variable.
    v = grad_and_vars[0][1]
    grad_and_var = (grad, v)
    average_grads.append(grad_and_var)
    return average_grads



##--------   Create model
def conv_net(images, dropout):
    # Reshape input picture
    images = tf.reshape(images, shape=[-1, 28, 28, 1])

    # Convolution Layer
    with tf.variable_scope('conv1'):
        W = tf.get_variable('weights', [5, 5, 1, 32], initializer=tf.random_normal_initializer())
        b = tf.get_variable(""biases"", [32], initializer=tf.random_normal_initializer())
        conv1 = conv2d(images, W, b)
        # Max Pooling (down-sampling)
        conv1 = maxpool2d(conv1, k=2)

    # Convolution Layer
    with tf.variable_scope('conv2'):
        W = tf.get_variable('weights', [5, 5, 32, 64], initializer=tf.random_normal_initializer())
        b = tf.get_variable(""biases"", [64], initializer=tf.random_normal_initializer())
    # Max Pooling (down-sampling)
        conv2 = conv2d(conv1, W, b)
        conv2 = maxpool2d(conv2, k=2)

    # Fully connected layer
    # Reshape conv2 output to fit fully connected layer input
    fc1 = tf.reshape(conv2, [-1, 7*7*64])

    with tf.variable_scope('fully'):
        weights = tf.get_variable('weights', [7*7*64, 1024], initializer=tf.random_normal_initializer())
        bias = tf.get_variable('bias', [1024], initializer=tf.random_normal_initializer())
        fc1 = tf.add(tf.matmul(fc1, weights), bias)
        fc1 = tf.nn.relu(fc1)
    # Apply Dropout
        fc1 = tf.nn.dropout(fc1, dropout)

    # Output, class prediction

    with tf.variable_scope('softmax'):
        weights = tf.get_variable('weights', [1024, 10], initializer=tf.random_normal_initializer())
        bias = tf.get_variable('bias', [10], initializer=tf.random_normal_initializer())     
        out = tf.add(tf.matmul(fc1, weights), bias)

    return out

##----------    multi-GPU

def train():

    with tf.Graph().as_default():

        x = tf.placeholder(tf.float32, [batch_size*num_gpus, 784])
        y = tf.placeholder(tf.float32, [batch_size*num_gpus, n_classes])
        keep_prob = tf.placeholder(tf.float32) #dropout (keep probability)

        global_step = tf.get_variable('global_step', [], initializer=tf.constant_initializer(0), trainable=False)


        optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)
        tower_grads = []
        for i in xrange(num_gpus):
            with tf.device('/gpu:%d' % i):
                with tf.name_scope('%s_%d' % ('MNIST', i)) as scope:
          # Calculate the loss for one tower of the CIFAR model. This function
          # constructs the entire CIFAR model but shares the variables across
          # all towers
          # Reuse variables for the next tower.

                    next_batch = x[i*batch_size:(i+1)*batch_size, :]
                    next_label_batch = y[i*batch_size:(i+1)*batch_size, :]
                    pred = conv_net(next_batch, keep_prob)
                    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(pred, next_label_batch))
                    correct_pred = tf.equal(tf.argmax(pred, 1), tf.argmax(next_label_batch, 1))
                    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))

                    tf.get_variable_scope().reuse_variables()

          # Calculate the gradients for the batch of data on this CIFAR tower.
                    grads = optimizer.compute_gradients(cost)
          # Keep track of the gradients across all towers.
                    tower_grads.append(grads)



        grads = average_gradients(tower_grads)
        apply_gradient_op = optimizer.apply_gradients(grads, global_step=global_step)


##--------------------start training----------------------

##---------- Initializing the variables
        init = tf.initialize_all_variables()

##----------- Launch the graph
        with tf.Session() as sess:

            sess = tf.Session(config=tf.ConfigProto(
            allow_soft_placement=True,
            log_device_placement=True))
            sess.run(init)
            saver = tf.train.Saver()
            var = [v for v in tf.trainable_variables()][0]
            aa = sess.run(var)
            np.save('initial.npy', aa)

            step = 1
    # Keep training until reach max iterations
            while step * (num_gpus*batch_size) < training_iters:

                large_input = np.zeros((num_gpus*batch_size, n_input))
                large_labels = np.zeros((num_gpus*batch_size, n_classes))
        
                for index in xrange(num_gpus):
                    batch_x, batch_y = mnist.train.next_batch(batch_size)
                    large_input[index*batch_size:(index+1)*batch_size, :] = batch_x
                    large_labels[index*batch_size:(index+1)*batch_size, :] = batch_y

        # Run optimization op (backprop)
                sess.run(apply_gradient_op, feed_dict={x: large_input, y: large_labels,
                                       keep_prob: dropout})
                if step % display_step == 0:
            # Calculate batch loss and accuracy
                    loss, acc = sess.run([cost, accuracy], feed_dict={x: large_input,
                                                              y: large_labels,
                                                              keep_prob: 1.})
                    print(""Iter "" + str(step*num_gpus*batch_size) + "", Minibatch Loss= "" + \
                  ""{:.6f}"".format(loss) + "", Training Accuracy= "" + \
                  ""{:.5f}"".format(acc))
                step += 1
            print(""Optimization Finished!"")
            var = [v for v in tf.trainable_variables()][0]
            aa = sess.run(var)
            np.save('final.npy', aa)

##-----------main---
if __name__ == '__main__':
    train()


I'm a beginner of Tensorflow and wrote a piece of code to test on the MNIST dataset. I find that during training my parameters doesn't change at all and cannot find the problem, so SOS!!!
"
5801,Hello. How can I use pre-train tensorflow's weights in my cnn library? Can you explain how conv layers work? How it use weights and input channels to get result?,"NOTE: Only file GitHub issues for bugs and feature requests.  All other topics will be closed.

For general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).
To make bugs and feature requests more easy to find and organize, we close issues that are deemed
out of scope for GitHub Issues and point people to StackOverflow.

For bugs or installation issues, please provide the following information.
The more information you provide, the more easily we will be able to offer
help and advice.

### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?

### Environment info
Operating System:

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):

If installed from binary pip package, provide:

1. A link to the pip package you installed:
2. The output from `python -c ""import tensorflow; print(tensorflow.__version__)""`.

If installed from source, provide 

1. The commit hash (`git rev-parse HEAD`)
2. The output of `bazel version`

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)


### What other attempted solutions have you tried?


### Logs or other output that would be helpful
(If logs are large, please upload as attachment or provide link).
"
5799,nvcc fatal   : Unknown option '-expt-relaxed-constexpr' while bazel build,"NOTE: Only file GitHub issues for bugs and feature requests.  All other topics will be closed.

### Environment info
Operating System: Ubuntu 14.04.4

Installed version of CUDA and cuDNN: 
(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):
CUDA v7.0
cuDNN 4

    -rw-r--r-- 1 root root   310328  3월  6  2015 /usr/local/cuda/lib64/libcudadevrt.a
    lrwxrwxrwx 1 root root       16  3월  6  2015 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.7.0
    lrwxrwxrwx 1 root root       19  3월  6  2015 /usr/local/cuda/lib64/libcudart.so.7.0 -> libcudart.so.7.0.28
    -rwxr-xr-x 1 root root   377896  3월  6  2015 /usr/local/cuda/lib64/libcudart.so.7.0.28
    -rw-r--r-- 1 root root   708938  3월  6  2015 /usr/local/cuda/lib64/libcudart_static.a
    -rwxr-xr-x 1 root root 61453024  6월  9 18:46 /usr/local/cuda/lib64/libcudnn.so
    -rwxr-xr-x 1 root root 61453024  6월  9 18:46 /usr/local/cuda/lib64/libcudnn.so.4
    -rwxr-xr-x 1 root root 61453024  6월  9 18:46 /usr/local/cuda/lib64/libcudnn.so.4.0.7
    -rwxr-xr-x 1 root root 48217000 11월 24  2015 /usr/local/cuda/lib64/libcudnn.so.7.0
    -rwxr-xr-x 1 root root 48217000 11월 24  2015 /usr/local/cuda/lib64/libcudnn.so.7.0.64
    -rw-r--r-- 1 root root 62025862  6월  9 18:46 /usr/local/cuda/lib64/libcudnn_static.a


If installed from source, provide 

1. The commit hash (`git rev-parse HEAD`)
55dbc54192a378c5e685c52595f42503f037320e

2. The output of `bazel version`

    Build label: 0.3.2
    Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar

### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)

I'm trying to install from source and faces following errors while build. I'm not sure what is the problem. Is this because of CUDA version?

    bazel build -c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package --verbose_failures
    
    ...
    ERROR: /home/jinhyung/tensorflow/tensorflow/core/kernels/BUILD:1128:1: error while parsing .d file: /home/jinhyung/.cache/bazel/_bazel_jinhyung/24f731f36d8cecf427d437d0326fcc3c/execroot/tensorflow/bazel-out/local_linux-opt/bin/tensorflow/core/kernels/_objs/resize_nearest_neighbor_op_gpu/tensorflow/core/kernels/resize_nearest_neighbor_op_gpu.cu.pic.d (No such file or directory).
    nvcc fatal   : Unknown option '-expt-relaxed-constexpr'
    Target //tensorflow/tools/pip_package:build_pip_package failed to build"
5796,"Change Optimizer while training, after a certain number of steps?","I am working on machine translation, using seq2seq model in Tensorflow. I am aware that once the graph has been established, it cannot be modified during training.
What if I want to change the optimizer from SGD to Adam after certain global steps?
How should the code be?
Thanks a lot."
