Issue Number,Issue Title,Issue Body
45556,lstm related tests are failing due to unprovided optional inputs are not read correctly as nullptr on s390x machine,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): N
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 20.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): 2.3.1
- Python version: 3.8.5
- Bazel version (if compiling from source): 3.1.0
- GCC/Compiler version (if compiling from source): gcc (Ubuntu 9.3.0-17ubuntu1~20.04) 9.3.0
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A

**Describe the current behavior**
`NoCifgNoPeepholeNoProjectionNoClippingLstmTest.LstmBlackBoxTest` from `nnapi_delegate_test` is failing due to seg fault on s390x. I looked into this issue a bit and found that it has this error because of this flag from `tensorflow/lite/kernels/lstm_eval.cc` is not set properly when `use_layer_norm` should be `false`.
```
const bool use_layer_norm = (forget_layer_norm_coefficients_ptr != nullptr);
```

As I checked further, I found that this is an interesting issue because these are the 4 optional inputs that come together:
```
// Layer norm coefficients of size 'n_cell', representing diagonal matrices.
//   input_layer_norm_coefficients_ptr  - optional
//   forget_layer_norm_coefficients_ptr - optional
//   cell_layer_norm_coefficients_ptr   - optional
//   output_layer_norm_coefficients_ptr - optional
```
So it looks like they should be either all be used or all not be used. However, I found that when the test model does not have these 4 optional inputs, only one of them is `nullptr` while the other 3 are some random values. On an x86 machine this one input is `forget_layer_norm_coefficients_ptr` while on an s390x machine this one input is `cell_layer_norm_coefficients_ptr`. In other words, if I change this flag check into:
```
const bool use_layer_norm = (cell_layer_norm_coefficients_ptr != nullptr);
```
then the test will pass on s390x and fail with seg fault on x86. 
I just wonder is this flag check just randomly choose `forget_layer_norm_coefficients_ptr` or there are some rational behind it? It looks to me that the 4 optional inputs are always treated equally in the `LSTMOpModel` object in the test file, but there is this subtle difference between them. It will be very helpful to understand why only `forget_layer_norm_coefficients_ptr` is picked here so that I will be able to fix it for s390x rather than simply modifying the flag definition.

After solving this issue, another lstm test case `NoCifgPeepholeProjectionClippingLstmTest.LstmBlackBoxTest` fails again in this test file. This time it is due to the `GetTensorData` function in `tensorflow/lite/kernels/internal/tensor_ctypes.h` does not return a `nullptr` for tensor of type `kTfLiteNoType`. I think all the tensor of type `kTfLiteNoType` should have it `data.raw` field points to a `nullptr`, but looks it is breaking for this test case only. I have to make the following change to fix it:
```diff
diff --git a/tensorflow/lite/kernels/internal/tensor_ctypes.h b/tensorflow/lite/kernels/internal/tensor_ctypes.h
index f1d3e17fcb..f5165cc0f0 100644
--- a/tensorflow/lite/kernels/internal/tensor_ctypes.h
+++ b/tensorflow/lite/kernels/internal/tensor_ctypes.h
@@ -27,8 +27,8 @@ inline T* GetTensorData(TfLiteTensor* tensor) {
 template <typename T>
 inline const T* GetTensorData(const TfLiteTensor* tensor) {
-  return tensor != nullptr ? reinterpret_cast<const T*>(tensor->data.raw)
-                           : nullptr;
+  return tensor != nullptr ? (tensor->type != kTfLiteNoType ?
+                 reinterpret_cast<const T*>(tensor->data.raw) : nullptr) : nullptr;
 }
 inline RuntimeShape GetTensorShape(const TfLiteTensor* tensor) {
```
I am not sure but it looks like these two issues are related. They all seem to be originated from the fact that the unprovided optional input is not set correctly. I am also suspecting that it has something to do with the model field initialization process or `lstm.cc` evaluation process, but all these errors are not straightforward so I would appreciate if any help could be provided, thanks.

**Describe the expected behavior**
The unprovided optional input should be `nullptr`, and test case should pass

**Standalone code to reproduce the issue**
Running the test case on s390x will reproduce the error.
```
bazel test --host_javabase=""@local_jdk//:jdk"" --cache_test_results=no --build_tests_only --test_output=errors -- //tensorflow/lite/delegates/nnapi:nnapi_delegate_test
```

**Other info / logs** 
"
45546,"Tensorflow does not use the GPU during training with eager execution, despite manual activation","<em>Please make sure that this is an issue related to performance of TensorFlow.
As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:performance_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux (Google colab)):
- TensorFlow installed using `pip install tensorflow-gpu`:
- TensorFlow version (2.3.1):
- Python version: 3.6.9
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10.1.243
- GPU model and memory: Tesla T4 computeCapability: 7.5 coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
I'm experiencing a very slow training time when running a third party [script](https://github.com/marload/DeepRL-TensorFlow2/blob/master/DQN/DQN_Discrete.py) which is the same(0% difference between GPU and CPU). I use the following command for activating the GPU on google colab after installing `tensorflow-gpu` using `pip`:

```
physical_devices = tf.config.experimental.list_physical_devices('GPU')
if len(physical_devices) > 0:
    tf.config.experimental.set_memory_growth(physical_devices[0], True)
```
I add the lines above in `main()` in the script I referred to earlier and I use [wandb](https://github.com/wandb/client) for monitoring the training. Here are the [graphs](https://drive.google.com/file/d/1Fgn7tlm6HBUyZIcPelVjxNz_RWvY7QU_/view?usp=sharing) within a few minutes of training showing 0% GPU utilization.

**Describe the expected behavior**

A fast performance which results in a remarkable difference in speeds (CPU vs GPU) and GPU utilization above 0% if the metrics are accurate and if they are not, I'm still experiencing the same speed when run on CPU or GPU.

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

```
import wandb
import tensorflow as tf
from tensorflow.keras.layers import Input, Dense
from tensorflow.keras.optimizers import Adam

import gym
import argparse
import numpy as np
from collections import deque
import random

tf.keras.backend.set_floatx('float64')
wandb.init(name='DQN', project=""deep-rl-tf2"")

parser = argparse.ArgumentParser()
parser.add_argument('--gamma', type=float, default=0.95)
parser.add_argument('--lr', type=float, default=0.005)
parser.add_argument('--batch_size', type=int, default=32)
parser.add_argument('--eps', type=float, default=1.0)
parser.add_argument('--eps_decay', type=float, default=0.995)
parser.add_argument('--eps_min', type=float, default=0.01)

args = parser.parse_args()

class ReplayBuffer:
    def __init__(self, capacity=10000):
        self.buffer = deque(maxlen=capacity)
    
    def put(self, state, action, reward, next_state, done):
        self.buffer.append([state, action, reward, next_state, done])
    
    def sample(self):
        sample = random.sample(self.buffer, args.batch_size)
        states, actions, rewards, next_states, done = map(np.asarray, zip(*sample))
        states = np.array(states).reshape(args.batch_size, -1)
        next_states = np.array(next_states).reshape(args.batch_size, -1)
        return states, actions, rewards, next_states, done
    
    def size(self):
        return len(self.buffer)

class ActionStateModel:
    def __init__(self, state_dim, aciton_dim):
        self.state_dim  = state_dim
        self.action_dim = aciton_dim
        self.epsilon = args.eps
        
        self.model = self.create_model()
    
    def create_model(self):
        model = tf.keras.Sequential([
            Input((self.state_dim,)),
            Dense(32, activation='relu'),
            Dense(16, activation='relu'),
            Dense(self.action_dim)
        ])
        model.compile(loss='mse', optimizer=Adam(args.lr))
        return model
    
    def predict(self, state):
        return self.model.predict(state)
    
    def get_action(self, state):
        state = np.reshape(state, [1, self.state_dim])
        self.epsilon *= args.eps_decay
        self.epsilon = max(self.epsilon, args.eps_min)
        q_value = self.predict(state)[0]
        if np.random.random() < self.epsilon:
            return random.randint(0, self.action_dim-1)
        return np.argmax(q_value)

    def train(self, states, targets):
        self.model.fit(states, targets, epochs=1, verbose=0)
    

class Agent:
    def __init__(self, env):
        self.env = env
        self.state_dim = self.env.observation_space.shape[0]
        self.action_dim = self.env.action_space.n

        self.model = ActionStateModel(self.state_dim, self.action_dim)
        self.target_model = ActionStateModel(self.state_dim, self.action_dim)
        self.target_update()

        self.buffer = ReplayBuffer()

    def target_update(self):
        weights = self.model.model.get_weights()
        self.target_model.model.set_weights(weights)
    
    def replay(self):
        for _ in range(10):
            states, actions, rewards, next_states, done = self.buffer.sample()
            targets = self.target_model.predict(states)
            next_q_values = self.target_model.predict(next_states).max(axis=1)
            targets[range(args.batch_size), actions] = rewards + (1-done) * next_q_values * args.gamma
            self.model.train(states, targets)
    
    def train(self, max_episodes=1000):
        for ep in range(max_episodes):
            done, total_reward = False, 0
            state = self.env.reset()
            while not done:
                action = self.model.get_action(state)
                next_state, reward, done, _ = self.env.step(action)
                self.buffer.put(state, action, reward*0.01, next_state, done)
                total_reward += reward
                state = next_state
            if self.buffer.size() >= args.batch_size:
                self.replay()
            self.target_update()
            print('EP{} EpisodeReward={}'.format(ep, total_reward))
            wandb.log({'Reward': total_reward})


def main():
    physical_devices = tf.config.experimental.list_physical_devices('GPU')
    if len(physical_devices) > 0:
        tf.config.experimental.set_memory_growth(physical_devices[0], True)
    env = gym.make('CartPole-v1')
    agent = Agent(env)
    agent.train(max_episodes=1000)

if __name__ == ""__main__"":
    main()
```

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
45543,Windows Tensorflow load large than 4GB file will meet outOfRange error.,"**System information**
-OS Platform and Distribution: Windows
-TensorFlow installed from: binary
-TensorFlow version: 1.0.1, 1.15
-Python version: 3.6

**Describe the current behavior**
Tensorflow load large than 4GB file on Windows will meet **outOfRange** error.

**Other info / logs** 
Tensorflow Windows version's file stat function by default use **_wstat** which represents the file size as 32-bit integer, once load large than 4GB file on Windows will meet **outOfRange** error. So I change the default to use **_wstat64** which represents the file size as 64-bit integer to fix the issue.

Attach [PR](https://github.com/tensorflow/tensorflow/pull/45542) here.




"
45541,Official Example For TensorFlow Lite Model Maker keeps crashing,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
 **No**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
**Mac Book Pro 2017(2.3 GHz Dual-Core Intel Core i5, 8 GB 2133 MHz LPDDR3), MacOS Big Sur 11.0.1,
Browser: Version 87.0.4280.88 (Official Build) (x86_64),
but I guess the above info does not matter as I run the example in Google Colab [here](https://www.tensorflow.org/lite/tutorials/model_maker_question_answer)**
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
**No**
- TensorFlow installed from (source or binary):
**TensorFlow is provided by Google Colab environment**
- TensorFlow version (use command below):
**2.4.0-dev20200902**
- Python version:
Python 3.6.9
- Bazel version (if compiling from source):
**N/A**
- GCC/Compiler version (if compiling from source):
**N/A**
- CUDA/cuDNN version:
**nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2019 NVIDIA Corporation
Built on Sun_Jul_28_19:07:16_PDT_2019
Cuda compilation tools, release 10.1, V10.1.243**
- GPU model and memory:
**I cannot check this as I run the Colab provided in official Tensorflow page on the provided Google Colab Environment, which you can see in the following url: https://www.tensorflow.org/lite/tutorials/model_maker_question_answer**


**Describe the current behavior**
When I try to run the officially provided Colab from TensorFlow Lite Model Maker Library for BERT Q&A
not changing anything, everything goes fine until the training model = `question_answer.create(train_data, model_spec=spec)`
As soon as training process started, after a while it begins to consume memory with big chunks (e.g. memory consumption increases by 2GB per 2-3 seconds) and shortly it crashes the **Colab** telling ""Your session crashed after using all available RAM"". I think this is some sort of a bug, because otherwise this will not be an official example, or it would be documented somewhere in the example that the free Colab environment provided by Google with 16GB RAM is not enough to run this example.
I also tried to run the example with much smaller dataset, but the same problem in the same way is being reproduced. So I am almost sure that this is a bug in the library.


**Describe the expected behavior**
The example project provided in Official website of TensorFlow should run without any problem on the officially provided Colab Environment.

**Standalone code to reproduce the issue**
Please just go node by node through the official example [in the following Colab](https://www.tensorflow.org/lite/tutorials/model_maker_question_answer) with a basic free Colab plan, without changing anything in the example.
when you reach ""Customize the TensorFlow Model"" point, and run the following code `model = question_answer.create(train_data, model_spec=spec)` wait for 2-3 minutes, and you will get and error that Colab environment was crashed telling ""Your session crashed after using all available RAM"".

**Other info / logs** 
There is the logs that I get after running `!cat /var/log/colab-jupyter.log` in Colab just after the crash
https://gist.github.com/ando0689/c67406e124ce8180935f36fe5e95e835"
45540,TFLite java.lang.IllegalArgumentException: Internal error: Failed to run on the given Interpreter on Android SDK 29,"Hello. I have a simple Android app connected to an accelerometer. I have a few tflite models in the app, one of which is throwing  a ""Failed to run on the given Interpreter"" error without any additional information. The code works fine on SDK 25.

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Android SDK 29
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Samsung Galaxy A20e, Android version 10
- TFLite version: ""org.tensorflow:tensorflow-lite:1.13.1""

**Describe the current behavior**
When the interpreter is called on the Android 10 phone, this error is thrown: 
```
java.lang.IllegalArgumentException: Internal error: Failed to run on the given Interpreter: 
2020-12-09 13:08:10.985 30085-30561/com.specknet.respeckmodeltesting W/System.err:     at org.tensorflow.lite.NativeInterpreterWrapper.run(Native Method)
2020-12-09 13:08:10.985 30085-30561/com.specknet.respeckmodeltesting W/System.err:     at org.tensorflow.lite.NativeInterpreterWrapper.run(NativeInterpreterWrapper.java:145)
2020-12-09 13:08:10.985 30085-30561/com.specknet.respeckmodeltesting W/System.err:     at org.tensorflow.lite.Interpreter.runForMultipleInputsOutputs(Interpreter.java:250)
2020-12-09 13:08:10.985 30085-30561/com.specknet.respeckmodeltesting W/System.err:     at com.specknet.respeckmodeltesting.classification.Classifier.classifyActivityWithFeatures(Classifier.kt:111)
2020-12-09 13:08:10.986 30085-30561/com.specknet.respeckmodeltesting W/System.err:     at com.specknet.respeckmodeltesting.live.LiveDataActivity$onCreate$2.onReceive(LiveDataActivity.kt:176)
2020-12-09 13:08:10.986 30085-30561/com.specknet.respeckmodeltesting W/System.err:     at android.app.LoadedApk$ReceiverDispatcher$Args.lambda$getRunnable$0$LoadedApk$ReceiverDispatcher$Args(LoadedApk.java:1646)
2020-12-09 13:08:10.986 30085-30561/com.specknet.respeckmodeltesting W/System.err:     at android.app.-$$Lambda$LoadedApk$ReceiverDispatcher$Args$_BumDX2UKsnxLVrE6UJsJZkotuA.run(Unknown Source:2)
2020-12-09 13:08:10.986 30085-30561/com.specknet.respeckmodeltesting W/System.err:     at android.os.Handler.handleCallback(Handler.java:883)
2020-12-09 13:08:10.986 30085-30561/com.specknet.respeckmodeltesting W/System.err:     at android.os.Handler.dispatchMessage(Handler.java:100)
2020-12-09 13:08:10.987 30085-30561/com.specknet.respeckmodeltesting W/System.err:     at android.os.Looper.loop(Looper.java:237)
2020-12-09 13:08:10.987 30085-30561/com.specknet.respeckmodeltesting W/System.err:     at android.os.HandlerThread.run(HandlerThread.java:67)

```
**Describe the expected behavior**
The code works fine and classifies correctly when run on an Android 7.1.2 phone.
There is no code change between these two phones. Furthermore, other tflite models work on both phones. The only difference I see between the working models and the ones that crash are the conversion types. The models that crash have been ""MLIR Converted"" (inspected with Netron), and the models that do not crash are TOCO converted. 

Is there something preventing MLIR converted models from running on more recent Android versions? 

Thank you for your help.
"
45539,Bug in tensorflow.python.ops.parallel_for.gradients.batch_jacobian(),"There is a bug on `line 113` of the `batch_jacobian` function:
https://github.com/tensorflow/tensorflow/blob/5681c179eff80bce00e526303950b67b23cad14c/tensorflow/python/ops/parallel_for/gradients.py#L83-L113

## Explaining the bug
On `line 113` the `output_shape[0]` is not an instance of the class `tf.TensorShape()`.
It is either an `integer` or `None` and therefore has no `is_compatible_with()` method.

## Suggesting a fix
```python 
if not output_shape[0].is_compatible_with(inp.shape[0])
``` 
could be replaced with 
```python
if not output_shape[0:1].is_compatible_with(inp.shape[0])
```
because `output_shape[0:1]` is an instance of `tf.TensorShape()`

## Minimal Example - showing the bug and testing the fix

The example below has been evaluated in a docker container running the image: `tensorflow/tensorflow:2.3.0-gpu-jupyter`

```python
import tensorflow as tf
from tensorflow.python.ops.parallel_for.gradients import batch_jacobian

# Define function that computes f(x) = x^2 and its derivative df/dx = 2*x
@tf.function
def square(x):    
    y = x**2
    dydx = batch_jacobian(y, x)
    return y, dydx

# Create a model that uses the function
x = tf.keras.backend.placeholder(shape=(None, 2), dtype=tf.float32)
y, dydx = tf.keras.layers.Lambda(lambda c: square(c))(x)
model = tf.keras.Model(x, [y, dydx])

# Test case: evaluate model with dummy input
x_input = tf.constant([[1., 2.], [3., 4.], [5., 6.]])
y_output, dydx_output = model(x_input)
print(y_output)
print(dydx_output)
```

Results in the following error:
```
AttributeError: in user code:

    <ipython-input-1-5f56962453df>:8 square  *
        dydx = batch_jacobian(y, x)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/parallel_for/gradients.py:113 batch_jacobian  **
        if not output_shape[0].is_compatible_with(inp.shape[0]):

    AttributeError: 'NoneType' object has no attribute 'is_compatible_with'
```

After the suggested fix it outputs:
```
tf.Tensor(
[[ 1.  4.]
 [ 9. 16.]
 [25. 36.]], shape=(3, 2), dtype=float32)
tf.Tensor(
[[[ 2.  0.]
  [ 0.  4.]]

 [[ 6.  0.]
  [ 0.  8.]]

 [[10.  0.]
  [ 0. 12.]]], shape=(3, 2, 2), dtype=float32)
```

## Colab demonstrating the minimal example (mentioned above)
https://colab.research.google.com/drive/1UNCyHc6d7mrZv7p7VD3GekI3YqAntQ9q?usp=sharing

## Next steps
If you want I can make a pull request. But I first want to know whether this an intended way of using the batch_jacobian function."
45538,tf.while_loop allow to vary shapes by default,"I tried everything with tf.while_loop. In nested loops I always get ValueError due to the shape. 
I think the problem is with **shape_invariants**.
In my opinion, it's a **bad feature that a developer should think about the initial shape of the loop variable**. I think that **to allow the shape to vary across iterations must be by deafult**. 
So one more parameter should be, for exmaple, **shape_variation**, that can be **True** or **False**. If **shape_variation = False** - we need to define **shape_invariant**. If **shape_variation = True** - shape has been allowed to vary across iterations, so **shape_invariant doesn't need to be defined**.

So in my opinion, it is necessary to correct this feature in the way I suggested
"
45537,save/load pair do not preserve `trainable` attribute,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Debian testing
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):binary
- TensorFlow version (use command below): 2.3.0
- Python version: 3.8.6
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
I have a model with some layers set as `trainable=False`. However, after saving this model and loading it back, all parameters are trainable again. 

**Describe the expected behavior**
I would expect that save/load pair would reconstruct the model precisely in its original state. 

**Standalone code to reproduce the issue**

```python
m1 = Sequential([
    Input((100,)),
    Dense(20),
    Dense(10),
])

m1.trainable = False

m2 = Sequential([
    Input((100,)),
    m1,
    Dense(5),
    Dense(3)
])

m2.summary()

Model: ""sequential_7""
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
sequential_6 (Sequential)    (None, 10)                2230      
_________________________________________________________________
dense_13 (Dense)             (None, 5)                 55        
_________________________________________________________________
dense_14 (Dense)             (None, 3)                 18        
=================================================================
Total params: 2,303
Trainable params: 73
Non-trainable params: 2,230
_________________________________________________________________
```

Note that only 73 parameters are trainable (as expected).
Now let's save and load back the model:

```python
tf.keras.models.save_model(m2, ""/tmp/mymodel"")
m2_reloaded = tf.keras.models.load_model(""/tmp/mymodel"")
m2_reloaded.summary()

Model: ""sequential_7""
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
sequential_6 (Sequential)    (None, 10)                2230      
_________________________________________________________________
dense_13 (Dense)             (None, 5)                 55        
_________________________________________________________________
dense_14 (Dense)             (None, 3)                 18        
=================================================================
Total params: 2,303
Trainable params: 2,303
Non-trainable params: 0
_________________________________________________________________
```

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
45536,RMSprop fails if using mixed precision training and eager functions,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): colab
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.4.0rc4
- Python version: any
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A

`v2.4.0-rc3-20-g97c3fef64ba 2.4.0-rc4`

**Describe the current behavior**

RMSprop failes if using mixed precision training and eager functions

**Describe the expected behavior**

succeed without errors

**Standalone code to reproduce the issue**

https://colab.research.google.com/drive/1-ZrJyKtaWmOMtga44Efc8DOu1fnRo1wN?usp=sharing

Originated from addons https://github.com/tensorflow/addons/pull/2250"
45533,TypeError: 'NoneType' object is not subscriptable when training with tf.dataset,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): 2.4.0-rc3
- Python version: 3.8.5
- Bazel version (if compiling from source): 3.1.0
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 11.1, 8
- GPU model and memory: RTX 3080 10GB

```
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
<ipython-input-18-4f2f618e8fe2> in <module>
----> 1 model.fit(train_tiles, epochs = 2, validation_data = val_tiles)

~\anaconda3\envs\hk4\lib\site-packages\tensorflow\python\keras\engine\training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)
   1098                 _r=1):
   1099               callbacks.on_train_batch_begin(step)
-> 1100               tmp_logs = self.train_function(iterator)
   1101               if data_handler.should_sync:
   1102                 context.async_wait()

~\anaconda3\envs\hk4\lib\site-packages\tensorflow\python\eager\def_function.py in __call__(self, *args, **kwds)
    826     tracing_count = self.experimental_get_tracing_count()
    827     with trace.Trace(self._name) as tm:
--> 828       result = self._call(*args, **kwds)
    829       compiler = ""xla"" if self._experimental_compile else ""nonXla""
    830       new_tracing_count = self.experimental_get_tracing_count()

~\anaconda3\envs\hk4\lib\site-packages\tensorflow\python\eager\def_function.py in _call(self, *args, **kwds)
    869       # This is the first call of __call__, so we have to initialize.
    870       initializers = []
--> 871       self._initialize(args, kwds, add_initializers_to=initializers)
    872     finally:
    873       # At this point we know that the initialization is complete (or less

~\anaconda3\envs\hk4\lib\site-packages\tensorflow\python\eager\def_function.py in _initialize(self, args, kwds, add_initializers_to)
    723     self._graph_deleter = FunctionDeleter(self._lifted_initializer_graph)
    724     self._concrete_stateful_fn = (
--> 725         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access
    726             *args, **kwds))
    727 

~\anaconda3\envs\hk4\lib\site-packages\tensorflow\python\eager\function.py in _get_concrete_function_internal_garbage_collected(self, *args, **kwargs)
   2967       args, kwargs = None, None
   2968     with self._lock:
-> 2969       graph_function, _ = self._maybe_define_function(args, kwargs)
   2970     return graph_function
   2971 

~\anaconda3\envs\hk4\lib\site-packages\tensorflow\python\eager\function.py in _maybe_define_function(self, args, kwargs)
   3359 
   3360           self._function_cache.missed.add(call_context_key)
-> 3361           graph_function = self._create_graph_function(args, kwargs)
   3362           self._function_cache.primary[cache_key] = graph_function
   3363 

~\anaconda3\envs\hk4\lib\site-packages\tensorflow\python\eager\function.py in _create_graph_function(self, args, kwargs, override_flat_arg_shapes)
   3194     arg_names = base_arg_names + missing_arg_names
   3195     graph_function = ConcreteFunction(
-> 3196         func_graph_module.func_graph_from_py_func(
   3197             self._name,
   3198             self._python_function,

~\anaconda3\envs\hk4\lib\site-packages\tensorflow\python\framework\func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)
    988         _, original_func = tf_decorator.unwrap(python_func)
    989 
--> 990       func_outputs = python_func(*func_args, **func_kwargs)
    991 
    992       # invariant: `func_outputs` contains only Tensors, CompositeTensors,

~\anaconda3\envs\hk4\lib\site-packages\tensorflow\python\eager\def_function.py in wrapped_fn(*args, **kwds)
    632             xla_context.Exit()
    633         else:
--> 634           out = weak_wrapped_fn().__wrapped__(*args, **kwds)
    635         return out
    636 

~\anaconda3\envs\hk4\lib\site-packages\tensorflow\python\framework\func_graph.py in wrapper(*args, **kwargs)
    975           except Exception as e:  # pylint:disable=broad-except
    976             if hasattr(e, ""ag_error_metadata""):
--> 977               raise e.ag_error_metadata.to_exception(e)
    978             else:
    979               raise

TypeError: in user code:

    C:\Users\eck\anaconda3\envs\hk4\lib\site-packages\tensorflow\python\keras\engine\training.py:805 train_function  *
        return step_function(self, iterator)
    D:\Workspace\CustomModules\crispy\core\ecdl.py:293 call  *
        Zo = self.conv1(Z)
    C:\Users\eck\anaconda3\envs\hk4\lib\site-packages\tensorflow\python\keras\engine\base_layer.py:1008 __call__  **
        self._maybe_build(inputs)
    C:\Users\eck\anaconda3\envs\hk4\lib\site-packages\tensorflow\python\keras\engine\base_layer.py:2710 _maybe_build
        self.build(input_shapes)  # pylint:disable=not-callable
    C:\Users\eck\anaconda3\envs\hk4\lib\site-packages\tensorflow\python\keras\layers\convolutional.py:188 build
        input_channel = self._get_input_channel(input_shape)
    C:\Users\eck\anaconda3\envs\hk4\lib\site-packages\tensorflow\python\keras\layers\convolutional.py:359 _get_input_channel
        if input_shape.dims[channel_axis].value is None:

    TypeError: 'NoneType' object is not subscriptable
```


- Model : Keras subclass model
- Data : tf.dataset

**Colab code** : [https://colab.research.google.com/drive/1bRpTcelfKHNK1SphTmvTo6qbxaYY9Ovl?usp=sharing][1]

**What I've done:**
1) Dummy dataset with `tf.random.normal` + the subclass model : worked
2) tf.dataset + a dummy model(functional API) : worked
3) `run_eagerly = True` when compiling the subclass model : worked, but don't want to use it for performance.
4) Iterate over tf.dataset(train and validation) : didn't raise any error, I could see the tensor value.



  [1]: https://colab.research.google.com/drive/1bRpTcelfKHNK1SphTmvTo6qbxaYY9Ovl?usp=sharing"
45532,"report error ""tensorflow.python.framework.errors_impl.InvalidArgumentError ""when visit dataset","version: 2.3.0
OS：mac
### report error ""tensorflow.python.framework.errors_impl.InvalidArgumentError ""when visit dataset
### script：
from __future__ import absolute_import, division, print_function, unicode_literals
import tensorflow as tf

import IPython.display as display
from PIL import Image
import numpy as np
import matplotlib.pyplot as plt
import pathlib


AUTOTUNE = tf.data.experimental.AUTOTUNE

data_dir = tf.keras.utils.get_file(origin='https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz',
                                         fname='flower_photos', untar=True)

data_dir = pathlib.Path(data_dir)
print(""data_dir:"",data_dir)

image_list = list(data_dir.glob('*/*.jpg'))
image_count = len(image_list)
print(""image_count:"",image_count)


CLASS_NAMES = np.array([item.name for item in data_dir.glob('*') if item.name != ""LICENSE.txt""])
print(""CLASS_NAMES:"",CLASS_NAMES)




image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)

BATCH_SIZE = 32
IMG_HEIGHT = 224
IMG_WIDTH = 224
STEPS_PER_EPOCH = np.ceil(image_count/BATCH_SIZE)


train_data_gen = image_generator.flow_from_directory(directory=str(data_dir),
                                                     batch_size=BATCH_SIZE,
                                                     shuffle=True,
                                                     target_size=(IMG_HEIGHT, IMG_WIDTH),
                                                     classes = list(CLASS_NAMES))


list_ds = tf.data.Dataset.list_files(str(data_dir/'*/*'))

def get_label(file_path):
    # convert the path to a list of path components
    parts = tf.strings.split(file_path, '\\')
    print(""+++++"",parts)
    # The second to last is the class-directory
    return parts[-2] == CLASS_NAMES


def decode_img(img):
    # convert the compressed string to a 3D uint8 tensor
    img = tf.image.decode_jpeg(img, channels=3)
    # Use `convert_image_dtype` to convert to floats in the [0,1] range.
    img = tf.image.convert_image_dtype(img, tf.float32)
    # resize the image to the desired size.
    return tf.image.resize(img, [IMG_WIDTH, IMG_HEIGHT])


def process_path(file_path):
    label = get_label(file_path)
    # load the raw data from the file as a string
    img = tf.io.read_file(file_path)
    img = decode_img(img)
    return img, label


labeled_ds = list_ds.map(process_path, num_parallel_calls=AUTOTUNE)

print(labeled_ds)

for image, label in labeled_ds:
    print(""Image shape: "", image.numpy().shape)
    print(""Label: "", label.numpy())

### Full error message：
<ParallelMapDataset shapes: ((224, 224, 3), (5,)), types: (tf.float32, tf.bool)>
2020-12-09 10:57:39.973749: W tensorflow/core/framework/op_kernel.cc:1767] OP_REQUIRES failed at strided_slice_op.cc:108 : Invalid argument: slice index -1 of dimension 0 out of bounds.
2020-12-09 10:57:39.973883: W tensorflow/core/framework/op_kernel.cc:1767] OP_REQUIRES failed at strided_slice_op.cc:108 : Invalid argument: slice index -1 of dimension 0 out of bounds.
2020-12-09 10:57:39.973962: W tensorflow/core/framework/op_kernel.cc:1767] OP_REQUIRES failed at strided_slice_op.cc:108 : Invalid argument: slice index -1 of dimension 0 out of bounds.
2020-12-09 10:57:39.974040: W tensorflow/core/framework/op_kernel.cc:1767] OP_REQUIRES failed at strided_slice_op.cc:108 : Invalid argument: slice index -1 of dimension 0 out of bounds.
2020-12-09 10:57:39.974411: W tensorflow/core/framework/op_kernel.cc:1767] OP_REQUIRES failed at strided_slice_op.cc:108 : Invalid argument: slice index -1 of dimension 0 out of bounds.
Traceback (most recent call last):
  File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/eager/context.py"", line 2102, in execution_mode
    yield
  File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/data/ops/iterator_ops.py"", line 758, in _next_internal
    output_shapes=self._flat_output_shapes)
  File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/ops/gen_dataset_ops.py"", line 2610, in iterator_get_next
    _ops.raise_from_not_ok_status(e, name)
  File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/framework/ops.py"", line 6843, in raise_from_not_ok_status
    six.raise_from(core._status_to_exception(e.code, message), None)
  File ""<string>"", line 3, in raise_from
tensorflow.python.framework.errors_impl.InvalidArgumentError: slice index -1 of dimension 0 out of bounds.
         [[{{node strided_slice}}]] [Op:IteratorGetNext]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/Users/dingjiawei/Desktop/daily_demo/load_image_data/tensorflow2.0_load_data.py"", line 85, in <module>
    for image, label in labeled_ds:
  File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/data/ops/iterator_ops.py"", line 736, in __next__
    return self.next()
  File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/data/ops/iterator_ops.py"", line 772, in next
    return self._next_internal()
  File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/data/ops/iterator_ops.py"", line 764, in _next_internal
    return structure.from_compatible_tensor_list(self._element_spec, ret)
  File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/contextlib.py"", line 130, in __exit__
    self.gen.throw(type, value, traceback)
  File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/eager/context.py"", line 2105, in execution_mode
    executor_new.wait()
  File ""/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/tensorflow/python/eager/executor.py"", line 67, in wait
    pywrap_tfe.TFE_ExecutorWaitForAllPendingNodes(self._handle)
tensorflow.python.framework.errors_impl.InvalidArgumentError: slice index -1 of dimension 0 out of bounds.
         [[{{node strided_slice}}]]

I don't know what this error mean, and how to sovle it. please help me to check it. thank you ~"
45510,"When installed by pip, dependencies' versions are not fixed.","**System information**
- OS Platform and Distribution: window & linux
- TensorFlow installed from: binary
- TensorFlow version: 1.13, 1.14
- Python version: 3.6.8
- Installed using virtualenv? pip? conda?: pip

**Describe the problem**
grpcio>=1.8.6 has been installed, which is always the newest one: eg. 1.34.0; however grpcio~=1.32.0 is expected

**Provide the exact sequence of commands / steps that you executed before running into the problem**
pip install tensorflow-gpu"
45504,Bus error when load the tflite model,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): N/A
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux 4.14.119
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): Installed tflite runtime from source code.
- TensorFlow version (use command below): 2.3.0
- Python version: 3.7
- Bazel version (if compiling from source): 3.1.0
- GCC/Compiler version (if compiling from source): 8.3
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A

**Describe the current behavior**
I have enable the FlexDelegate and compiled the tflite runtime code by using the below command for ARM 32bit machine, the wheel file is created and I have installed it in my machine. But when I load the .tflite model, I am getting the Bus error. But, I didn't got this ""Bus error"" when I use the same wheel file in Raspberry Pi, it is working fine in the Raspberry Pi(ARM 32bit).

Before enable the FlexDelegate I didn't got this Bus error while load the tflite model, but that time I got the below RuntimeError.
RuntimeError: Regular TensorFlow ops are not supported by this interpreter. Make sure you apply/link the Flex delegate before inference.Node number 16 (FlexMul) failed to prepare.

Note: Actually my machine is the aarm64 64bit machine, but due to some build restrictions I am using the 32bit applications in my machine.

**Command used for compilation:**
CI_DOCKER_EXTRA_PARAMS=""-e CUSTOM_BAZEL_FLAGS=--define=tflite_pip_with_flex=true -e CI_BUILD_PYTHON=python3 -e CROSSTOOL_PYTHON_INCLUDE_PATH=/usr/include/python3.7"" tensorflow/tools/ci_build/ci_build.sh PI-PYTHON37 tensorflow/lite/tools/pip_package/build_pip_package_with_bazel.sh armhf

**Other info / logs**
I ran the code by using gdb and got the below back trace.

INFO: Created TensorFlow Lite delegate for select TF ops.
[New Thread 0xebc59460 (LWP 1157)]
[New Thread 0xeb458460 (LWP 1158)]
[New Thread 0xeaa57460 (LWP 1159)]
[New Thread 0xea0ff460 (LWP 1160)]
[New Thread 0xe94ff460 (LWP 1161)]

Thread 2 ""python3"" received signal SIGBUS, Bus error.
[Switching to Thread 0xebc59460 (LWP 1157)]
0xf642d574 in std::condition_variable::condition_variable (this=0xea10075c)
    at /tmp/dgboter/bbs/rhev-vm8--rhe6x86_64/buildbot/rhe6x86_64--arm-linux-gnueabihf/build/build-arm-linux-gnueabihf/obj/gcc3/arm-linux-gnueabihf/libstdc++-v3/include/condition_variable:65
65	/tmp/dgboter/bbs/rhev-vm8--rhe6x86_64/buildbot/rhe6x86_64--arm-linux-gnueabihf/build/build-arm-linux-gnueabihf/obj/gcc3/arm-linux-gnueabihf/libstdc++-v3/include/condition_variable: No such file or directory.
(gdb) bt
#0  0xf642d574 in std::condition_variable::condition_variable (this=0xea10075c)
    at /tmp/dgboter/bbs/rhev-vm8--rhe6x86_64/buildbot/rhe6x86_64--arm-linux-gnueabihf/build/build-arm-linux-gnueabihf/obj/gcc3/arm-linux-gnueabihf/libstdc++-v3/include/condition_variable:65
#1  0xf4df5a24 in nsync::nsync_mu_semaphore_init(nsync::nsync_semaphore_s_*) ()
   from /usr/lib/python3.7/site-packages/tflite_runtime/_pywrap_tensorflow_interpreter_wrapper.so
Backtrace stopped: previous frame identical to this frame (corrupt stack?)
(gdb) "
45497,> It  work for me.Thank you,"> It didn't work for me. Still getting that error.

try
`conda update wrapt`

_Originally posted by @congee524 in https://github.com/tensorflow/tensorflow/issues/30191#issuecomment-514249543_"
45494,TF2 GPUs on Kubernetes,"I made a helm chart for TF2 and it doesn't seem to be able to recognize the GPU, although cupy seems to work fine. 
Is there any avail guidance on this or working helm chart example to inspect?"
45492,downloaded flatbuffers result in bazel build errors (when attempting to recursively build all the bazel targets),"@tensorflow/micro

If we download flatbuffers via the TFLM makefile and then use the following command:
```
bazel build tensorflow/lite/micro/...
```

we get an error due to the BUILD files in tensorflow/lite/micro/downloads/flatbuffers.

These build files are not needed and can be deleted."
45488,Selective builds to reduce tensorflow-lite binary size missing needed java package org.tensorflow.lite,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
Try to build a custom .aar file from https://raw.githubusercontent.com/tensorflow/tensorflow/master/tensorflow/lite/tools/build_aar_with_docker.sh


**Describe the problem**
The result aar.file missing all java-wrapper classes (Interpreter, etc) under package: org.tensorflow.lite. These classes are needed to perform inference from a model in Android.

**Provide the exact sequence of commands / steps that you executed before running into the problem**
Following the instruction building selective build for a given tflite model using docker: https://www.tensorflow.org/lite/guide/reduce_binary_size#selectively_build_tensorflow_lite_with_docker

```
curl -o build_aar_with_docker.sh \
  https://raw.githubusercontent.com/tensorflow/tensorflow/master/tensorflow/lite/tools/build_aar_with_docker.sh &&
chmod +x build_aar_with_docker.sh
```

and 
```
sh tensorflow/lite/tools/build_aar.sh \
  --input_models=/a/b/my_model.tflite \
  --target_archs=x86,x86_64,arm64-v8a,armeabi-v7a \
  --checkpoint=master \
```

**Any other info/ logs**
Rename resulted aar files to .zip and attached:

1. aar file built from Mobilenet_1.0_224(float) model: [tensorflow-lite-with-mobile-net-model.zip](https://github.com/tensorflow/tensorflow/files/5661364/tensorflow-lite-with-mobile-net-model.zip)
2. aar file built from my custom model: [tflite-with-my-custom-model.zip](https://github.com/tensorflow/tensorflow/files/5661324/tflite-with-my-custom-model.zip)

Both missing java classes

Note: did try to copy needed java classes into the resulted_aar but this approach seems not working. Might-be the generated .so files missing C++ files which support org.tensorflow.lite java classes as well."
45483,Same code - difference result from PC and jetson nano,"
**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device: Jetson nano
- TensorFlow version : 2.3.1+nv20.11
- Python version: 3.6
- tflite-runtime: 2.5.0

**Describe the current behavior**
 I run same code below. but difference result from my pc (ubuntu 18.04) and my jetson nano (ubuntu 16.04 without tpu) 
```
def __init__(self, model_dir, tpu=True, mask=False):

        self.tpu = tpu
        self.mask = mask
        if self.tpu:
            self.interpreter = tflite.Interpreter(model_path=model_dir,
                                                  experimental_delegates=[tflite.load_delegate(EDGETPU_SHARED_LIB)])
        else:
            self.interpreter = tf.compat.v1.lite.Interpreter(model_path=model_dir)
        self.interpreter.allocate_tensors()
        self.rec_input_index = self.interpreter.get_input_details()[0]['index']
        if self.mask:
            self.rec_output_index = self.interpreter.get_output_details()[1]['index']
            self.mask_output_index = self.interpreter.get_output_details()[0]['index']
            print('here')
        else:
            self.rec_output_index = self.interpreter.get_output_details()[0]['index']

    def rec(self, image, landmark=None):
        aligned = image

        if not self.tpu:
            aligned_norm = np.expand_dims(aligned, axis=0).astype(np.float32)
        else:
            aligned_norm = np.expand_dims(aligned, axis=0)

        self.interpreter.set_tensor(self.rec_input_index, aligned_norm)
        self.interpreter.invoke()
        feature = get_quant_int8_output(self.interpreter, self.rec_output_index)
```

**Describe the expected behavior**
 i wish i got the same result from these two devices"
45482,Running a part of a calculation in double precision,"Is it possible to use float32 generally and for only  a part of the code use float64 and then switch back to float32?
"
45481,TF-TRT Dynamic Shapes Feature Tracker,"### Introduction
The dynamic shape mode in TF-TRT utilizes TensorRT’s [dynamic shape feature](https://docs.nvidia.com/deeplearning/tensorrt/developer-guide/index.html#work_dynamic_shapes) to improve the conversion rate of networks and handle networks with unknown input shapes efficiently. This issue tracks the ongoing development to enable TRT's dynamic shape mode trough TF-TRT.

**Who will benefit with this feature?**
The conversion rate and therefore the performance will improve for the following inference problems:
- Network with unknown input shapes (e.g. fully convolutional object detection networks)
- Networks where the first (batch) dimension of a tensor changes within the graph (e.g. BERT)
- Networks that have subgraphs where the tensors have non identical first dimension

Additionally the memory usage will improve: to handle input tensors with different shapes (eg image size, sequence length) currently requires separate TRT engine creation for each input. With dynamic shape mode a single engine can handle various input shapes.

**Will this change the current api? How?**

Some change in the [conversion parameters](https://github.com/tensorflow/tensorflow/blob/b34e7144ed6dd0ab51c03df783aa14009589e800/tensorflow/python/compiler/tensorrt/trt_convert.py#L118) will be necessary to enable/disable dynamic shape mode and provide a way to select optimization profiles.

### Phase 1
The first phase of this work is the basic scaffolding to enable the TF-TRT converter to use TRT's dynami shape API.

0. Add implicit batch experimental #34293
1. Enable explicit batch mode #36379
2. Improve binding index query #36434
3. Add binding size specification #36435
4. Define networks with dynamic shapes #36439
5. Add optimizaton profiles #36660
6. Execution context managment #36664
7. TensorRT profile generation mode #36729

### Phase 2
Enable dynamic shape mode for ops used in MobileNet, ResNet, Bert. This includes improvement in the converters plus increasing their unit test coverage. Note that at this stage dynamic shape mode is still experimental.

- Refactor ExecuteTrtEngine #38118 
- Use Unified Memory in TRT opconverter tests  #38124
- ConvertSqueeze #38146
- ConvertUnary, ConvertRsqrt #39153
- ConvertTranspose #39151 
- ConvertActivation, ConvertLeakyRelu #39155 
- BiasAdd - ConvertBiasAdd #39156
- Conv2D, DepthWiseConv2dNative #39204
- ConvertConv2dBackPropInput #47840
- ConvertPack #39859
- ConvertReshape #40545
- ConvertExpandDims  #39282
- ConvertSlice, ConvertStridedSlice #40736
- ConvertGather #39848
- ConvertMatMul and ConvertBatchMatMul #47215
- ConvertBinary #39785
- ConvertSquaredDifference #39758
- ConvertReduce #40201
- ConvertFusedBatchNorm #40179
- ConvertSoftMax  #47039
- ConvertShape #39990
- ConvertPool #40184
- Update related python integration tests: Unary_test.py, Batch_matmul_test.py, biasadd_matmul_test.py, Conv2d_test.py, reshape_traspose_test.py

### Phase 3
This is a direct continuation of Phase 2. Ensure that all op converter support dynamic shape mode and test it. We have almost 20 converters to update and test. The bulk of this work is improving the test coverage. 
- ConvertSquare #40483
- ConvertClipByValue #45589 
- ConvertPad #45597
- ConvertResize #46376
- ConvertArgMinMax #45862 
- ConvertQuantize #45599
- ConvertTopK #46299
- ConvertUnpack #48049
- ConvertAddN #46675 
- ConvertConcat #46382
- ConvertConv3D #46940
- ConvertDepthSpaceShuffle #47590
- ConvertSplit #48246
- ConvertCombinedNMS #40062
- Enable calibration if static input shapes are used #48244

### Phase 3+
Some converters in phase 3 were updated only for explicit batch support with static shape. Enable dynamic shape mode for them:
- ConvertCombinedNMS
- ConvertResize #51462
- ConvertStridedSlice #51475
- ConvertConv2DBackpropInput #51468

Additionally:
- Fix shape output bug https://github.com/tensorflow/tensorrt/issues/251 
  #52181 
  #52186
- Update python integration tests #51411 #51471

### Phase 4
 Implement calibration in dynamic shape mode. Using TRT 7.1 one can  run calibration in [dynamic shape mode](https://docs.nvidia.com/deeplearning/sdk/tensorrt-developer-guide/index.html#int8-calib-dynamic-shapes).
- TRTEngineOp: allow profile collection before calibration
- Refine APIs: build mode + calibration + lazy calibration

### Phase 5
Test performance of dynamic shape mode

### Phase 6
Define API to enable dynamic shape and specify optimization profiles.
- Finalize API - [implemeted here](https://github.com/tensorflow/tensorflow/blob/e52ccf29b87d7262078040b86a0fb4669149cb05/tensorflow/python/compiler/tensorrt/trt_convert.py#L944-L987)
- Implement additional optimization profiles
  - basic profiles for testing #45588 
  - Pass profile params to TrtShapeOptimizationProfiles class #48060
  - Implement Range, Range+Optimal profiles #48414

### Phase 7
- C++ conversion API #52012
Optional elements from Phase 6 are moved here.
- Implement UserDefined profile 
- Change default conversion param from implicit batch mode to dynamic shape mode

Tagging @DEKHTIARJonathan and @bixia1 "
45478,Fail to run tflite on DSP - BATCH_TO_SPACE_ND failed to prepare,"@tensorflow/micro

**System information**
- Host OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Android 

- TensorFlow installed from (source or binary):
source (dde0fe783c8208358971979460611caca75dc363)

- Tensorflow version (commit SHA if source):
tf-nightly 2.4

- Target platform (e.g. Arm Mbed OS, Arduino Nano 33 etc.):
dsp on mobile

**Describe the problem**
INFO: Created TensorFlow Lite delegate for Hexagon.
INFO: Initialized TensorFlow Lite runtime.
INFO: Interpreter::UseNNAPI() is deprecated. Use tflite::NnApiDelegate() directly instead.
INFO: Hexagon delegate: 52 nodes delegated out of 88 nodes with 10 partitions.

ERROR: tensorflow/lite/kernels/batch_to_space_nd.cc:81 output_batch_size % block_shape[dim] != 0 (1 != 0)
ERROR: Node number 6 (BATCH_TO_SPACE_ND) failed to prepare.

**Please provide the exact sequence of commands/steps when you ran into the problem**
tflite model attached
[myModel4DSP.zip](https://github.com/tensorflow/tensorflow/files/5660174/myModel4DSP.zip)

"
45477,When pre-built libtensorflow C API will be updated to 2.4?,"I rely on pre-build C API libs that I download from https://www.tensorflow.org/install/lang_c, so I wonder when it is going to be updated with recent tensorflow 2.4 version with CUDA 11 support."
45476,tf.nn larger support for RaggedTensor,"**System information**
- TensorFlow version (you are using): 2.3
- Are you willing to contribute it (Yes/No): Yes



**Describe the feature and the current behavior/state.**

I would like to be able to use `tf.nn`, and in turn `tf.keras.layers` such as `Conv2D` on `RaggedTensor`.

**Will this change the current api? How?**

I think it shouldn't in any way, just that keras layers and tf.nn operations should accept ragged tensors.

**Who will benefit with this feature?**

Anyone wanting to use keras layers on ragged tensors. 
I am giving a bit more explanation on my specific use case below.

**Any Other info.**

So in my use case, I want to perform distributed training using images that have widely different sizes (and it doesn't make sense to pad them). I would want for each of the elements of the ragged tensor to be distributed on different GPUs.
But if I use a ragged tensor as is, it is not supported by my models with an error like:

```
TypeError: Failed to convert object of type <class 'tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor'> to Tensor. Contents: tf.RaggedTensor(values=tf.RaggedTensor(values=tf.RaggedTensor(values=tf.RaggedTensor(values=Tensor(""RaggedFromVariant/RaggedTensorFromVariant:4"", shape=(None, 1), dtype=complex64), row_splits=Tensor(""RaggedFromVariant/RaggedTensorFromVariant:3"", shape=(None,), dtype=int64)), row_splits=Tensor(""RaggedFromVariant/RaggedTensorFromVariant:2"", shape=(None,), dtype=int64)), row_splits=Tensor(""RaggedFromVariant/RaggedTensorFromVariant:1"", shape=(None,), dtype=int64)), row_splits=Tensor(""RaggedFromVariant/RaggedTensorFromVariant:0"", shape=(None,), dtype=int64)). Consider casting elements to a supported type.
```

Even if I use the setting advised [here](https://github.com/tensorflow/tensorflow/issues/27170#issuecomment-587571120), I still get this error.

"
45473,SSD Mobilenet v2 model fail in PPD op,"@tensorflow/micro

**System information**
- Host OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- TensorFlow installed from (source or binary):
- Tensorflow version (commit SHA if source): 0939f0b7a8aed30559b54ae0dd5b9e6b312de1c5
- Target platform (e.g. Arm Mbed OS, Arduino Nano 33 etc.):

**Describe the problem**
SSD Mobilenet v2 crash in detection postprocess operator because of a bug.
 
**Please provide the exact sequence of commands/steps when you ran into the problem**

"
45472,"No OpKernel was registered to support Op 'BroadcastTo' used by {{node gradients/Mean_grad/BroadcastTo}}with these attrs: [Tidx=DT_INT32, T=DT_FLOAT]","I have created a simple linear regression model and got a graph.pb file so i can used it in my android studio app. When I call  sess.runner().addTarget(""init"").run(); I got this error: No OpKernel was registered to support Op 'BroadcastTo' used by {{node gradients/Mean_grad/BroadcastTo}}with these attrs: [Tidx=DT_INT32, T=DT_FLOAT]

Here is the python model code:

import tensorflow.compat.v1 as tf
tf.disable_v2_behavior()

x = tf.placeholder(tf.float32, name='input')
y_ = tf.placeholder(tf.float32, name='target')

W = tf.Variable(5., name='W')
b = tf.Variable(3., name='b')
y = tf.add(tf.multiply(W,x), b)
y = tf.identity(y, name='output')

           
loss = tf.reduce_mean(tf.square(y - y_))
optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)
train_op = optimizer.minimize(loss, name='train')

init = tf.global_variables_initializer()
saver_def = tf.train.Saver().as_saver_def()
with open('graph.pb', 'wb') as f:
  f.write(tf.get_default_graph().as_graph_def().SerializeToString())
"
45471,Failed to load native tensorflow runtime,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution : Windows Server 2012 R2 Standard
- TensorFlow installed from : Binary (pip)
- TensorFlow version: 2.2.0
- Python version: 3.7.2
- Installed using : pip
- CUDA/cuDNN version: NA
- GPU model and memory: NA

Tensorflow is installed without any issues. But when running my program I am getting the below error.

> D:\Tetherfi\TRS\TFaceAuthServer>python tfacecompare.py
> Traceback (most recent call last):
>   File ""C:\Users\kiolocal\AppData\Local\Programs\Python\Python37\lib\site-packag
> es\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
>     from tensorflow.python.pywrap_tensorflow_internal import *
>   File ""C:\Users\kiolocal\AppData\Local\Programs\Python\Python37\lib\site-packag
> es\tensorflow\python\pywrap_tensorflow_internal.py"", line 28, in <module>
>     _pywrap_tensorflow_internal = swig_import_helper()
>   File ""C:\Users\kiolocal\AppData\Local\Programs\Python\Python37\lib\site-packag
> es\tensorflow\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_hel
> per
>     _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, descript
> ion)
>   File ""C:\Users\kiolocal\AppData\Local\Programs\Python\Python37\lib\imp.py"", li
> ne 242, in load_module
>     return load_dynamic(name, filename, file)
>   File ""C:\Users\kiolocal\AppData\Local\Programs\Python\Python37\lib\imp.py"", li
> ne 342, in load_dynamic
>     return _load(spec)
> ImportError: DLL load failed: The specified module could not be found.
> 
> During handling of the above exception, another exception occurred:
> 
> Traceback (most recent call last):
>   File ""tfacecompare.py"", line 20, in <module>
>     import tensorflow.keras
>   File ""C:\Users\kiolocal\AppData\Local\Programs\Python\Python37\lib\site-packag
> es\tensorflow\__init__.py"", line 41, in <module>
>     from tensorflow.python.tools import module_util as _module_util
>   File ""C:\Users\kiolocal\AppData\Local\Programs\Python\Python37\lib\site-packag
> es\tensorflow\python\__init__.py"", line 50, in <module>
>     from tensorflow.python import pywrap_tensorflow
>   File ""C:\Users\kiolocal\AppData\Local\Programs\Python\Python37\lib\site-packag
> es\tensorflow\python\pywrap_tensorflow.py"", line 69, in <module>
>     raise ImportError(msg)
> ImportError: Traceback (most recent call last):
>   File ""C:\Users\kiolocal\AppData\Local\Programs\Python\Python37\lib\site-packag
> es\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
>     from tensorflow.python.pywrap_tensorflow_internal import *
>   File ""C:\Users\kiolocal\AppData\Local\Programs\Python\Python37\lib\site-packag
> es\tensorflow\python\pywrap_tensorflow_internal.py"", line 28, in <module>
>     _pywrap_tensorflow_internal = swig_import_helper()
>   File ""C:\Users\kiolocal\AppData\Local\Programs\Python\Python37\lib\site-packag
> es\tensorflow\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_hel
> per
>     _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, descript
> ion)
>   File ""C:\Users\kiolocal\AppData\Local\Programs\Python\Python37\lib\imp.py"", li
> ne 242, in load_module
>     return load_dynamic(name, filename, file)
>   File ""C:\Users\kiolocal\AppData\Local\Programs\Python\Python37\lib\imp.py"", li
> ne 342, in load_dynamic
>     return _load(spec)
> ImportError: DLL load failed: The specified module could not be found.
> 
> 
> Failed to load the native TensorFlow runtime.
> 
> See https://www.tensorflow.org/install/errors
> 
> for some common reasons and solutions.  Include the entire stack trace
> above this error message when asking for help.

I have tried installing visual c++ redistributable for 2015 (64 and 32 bit), but still the same. Reinstalling of python also didn't help.
Please guide and help to solve this.
"
45470,Raspberry Pi 4 camera feed doesn't appear,"Hi everyone,

**System information**
- OS Platform and Distribution : Raspbian
- TensorFlow installed from : binary
- TensorFlow version : v2.3.0-0-gb36436b087 2.3.0
- Python version: Python 3.7.3
- Model : Raspberry Pi 4 4gb ram

**Describe the current behavior**
When I'm using [image_classification example](https://github.com/tensorflow/examples/tree/master/lite/examples/image_classification/raspberry_pi) or [object_detection example](https://github.com/tensorflow/examples/tree/master/lite/examples/object_detection/raspberry_pi) I didn't get any error but the camera feed doesn't appear so I couldn't check if it's working.

**Other info / logs**
I checked picamera and I could get the stream from the pi camera so my camera is working great.
I build and install from setup.py in the main directory and downloaded the files in /tmp.
Everytime I use ctrl+c to stop the program I got different writing like it is looping into the code. 

Thanks for you help.

I attached a picture with the terminal.
<img width=""1213"" alt=""Capture d’écran 2020-12-08 à 11 37 08"" src=""https://user-images.githubusercontent.com/45320002/101474746-d2638500-394b-11eb-9ad9-fcdbaa383bad.png"">

"
45469,Failed to build person_detection example test,"@tensorflow/micro

**System information**
- Host OS Platform and Distribution (e.g., Linux Ubuntu 16.04): All (presumably)
- TensorFlow installed from (source or binary): Source
- Tensorflow version (commit SHA if source): 4a11dfdd3bb
- Target platform (e.g. Arm Mbed OS, Arduino Nano 33 etc.): All (presumably), tested for ARC.

**Describe the problem**
As I can see, now there is no longer common person detection, and int8 version became the [main one](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/micro/examples/person_detection). 
So, actually I faced two issues, when I was trying to **build tests** for person detection.

1. [This command](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/examples/person_detection/README.md#run-the-tests-on-a-development-machine) doesn't work at all, it says `make: *** No rule to make target 'test_person_detection_test'.  Stop.` and the right target actually is `test_person_detection_test_int8` as it used to be when it was an experimental version. Similarly, test generation works with `make -f tensorflow/lite/micro/tools/make/Makefile generate_person_detection_test_int8_make_project`.
2. When test project is generated, it is stored in a following path: 
```
\gen\[platform]\prj\person_detection_test_int8\make
```
And build gives following error:
```
make: *** No rule to make target 'tensorflow/lite/micro/tools/make/downloads/person_model_int8/person_detect_model_data.cc', needed by 'tensorflow/lite/micro/tools/make/downloads/person_model_int8/person_detect_model_data.o'.  Stop.
```
Thing is, it requires following project path (winthout _int8):
```
\gen\[platform]\prj\person_detection_test\make
```
If I change it manually, test can be built successfully. 

**Please provide the exact sequence of commands/steps when you ran into the problem**

1. `make -f tensorflow/lite/micro/tools/make/Makefile generate_person_detection_test_make_project`
2.  
```
make -f tensorflow/lite/micro/tools/make/Makefile generate_person_detection_test_int8_make_project
*go into project folder*
make
```
"
45468,Strange Out Of Memory error when trying example Colab ,"When I try to run the [officially provided Colab ](https://www.tensorflow.org/lite/tutorials/model_maker_question_answer)
not changing any row, everything goes fine until the training `model = question_answer.create(train_data, model_spec=spec)` 
As soon as training process started, after a while it begins to consume memory with big chunks (e.g. memory consumption increases by 2GB per 2-3 seconds) and shortly it crashes the Colab environment as it throws Out of Memory error. I think this is some sort of a bug, because otherwise this will not be official example, or it would be documented somewhere in the example that the free Colab environment with 16GB ram is not enough to run this example. 
I also tried to run the example with much smaller dataset, but the same problem in the same way is being reproduced. So I am almost sure that this is a bug in the library. 
"
45467,TFlite fails to run on GPU with - ERROR: TfLiteGpuDelegate Prepare: No shader implementation for reduce_sum,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- TensorFlow installed from (source or binary):
tf-nightly from source 
- TensorFlow version (or github SHA if from source):
2.4 nightly


**Provide the text output from tflite_convert**
non conversion issue but run time on mobile GPU
```
INFO: Initialized TensorFlow Lite runtime.
INFO: Interpreter::UseNNAPI() is deprecated. Use tflite::NnApiDelegate() directly instead.
INFO: Created TensorFlow Lite delegate for GPU.
ERROR: TfLiteGpuDelegate Prepare: No shader implementation for reduce_sum
ERROR: Node number 51 (TfLiteGpuDelegate) failed to prepare.

tflite model attatched.
[MyModel2.zip](https://github.com/tensorflow/tensorflow/files/5657747/MyModel2.zip)

"
45465,How to unset changes made by tf.debugging.set_log_device_placement?,"
## URL(s) with the issue:  https://www.tensorflow.org/api_docs/python/tf/debugging/set_log_device_placement



## Description of issue (what needs changing): 
It is not specified as to how to unset the changes made by this function.  Therefore it's becoming difficult to suppress the info level messages and a long trail of info messages gets printed leading to difficulty in analyzing actual results.

![image](https://user-images.githubusercontent.com/9129069/101432051-265f7100-392e-11eb-9987-f5b1de11e71f.png)

### Clear description

Maybe a feature needs to be developed to provide functionality within the function to disable its behaviour.

`tf.debugging.set_log_device_placement(False)`
`tf.get_logger().setLevel(3)`
`os.environ[""KMP_WARNINGS""] = ""FALSE"" `
`tf.get_logger().setLevel('INFO')`



None of the above methods work.
### Correct links

Is the link to the source code correct? Yes

### Parameters defined

Are all parameters defined and formatted correctly? Yes
 
### Returns defined

Are return values defined? Yes

### Raises listed and defined

NA

### Usage example

Is there a usage example?

Yes

### Request visuals, if applicable

Are there currently visuals? If not, will it clarify the content?  NA

### Submit a pull request? 

Unclear how to slove the issue yet.

"
45463,Cannot ./configure Tensorflow on Ubuntu 18.04 LTS with CUDA 11.1,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04 LTS
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): Source
- TensorFlow version: latest
- Python version: 3.6
- Installed using virtualenv? pip? conda?: pip
- Bazel version (if compiling from source): 3.7.1 
- GCC/Compiler version (if compiling from source): 9.3.0
- CUDA/cuDNN version: 11.1/8
- GPU model and memory: RTX TITAN (DUAL) 24 GB



**Describe the problem**
Attempting to configure tensorflow for using the ./compile script.
CUDA is not found 

**Provide the exact sequence of commands / steps that you executed before running into the problem**
./configure 
You have bazel 3.1.0 installed.
Please specify the location of python. [Default is /usr/bin/python3]: 


Found possible Python library paths:
  /usr/local/lib/python3.6/dist-packages
  /usr/lib/python3/dist-packages
Please input the desired Python library path to use.  Default is [/usr/local/lib/python3.6/dist-packages]

Do you wish to build TensorFlow with ROCm support? [y/N]: y
ROCm support will be enabled for TensorFlow.

Do you wish to build TensorFlow with CUDA support? [y/N]: y
CUDA support will be enabled for TensorFlow.

Do you wish to build TensorFlow with TensorRT support? [y/N]: y
TensorRT support will be enabled for TensorFlow.

Could not find any NvInferVersion.h matching version '' in any subdirectory:
        ''
        'include'
        'include/cuda'
        'include/*-linux-gnu'
        'extras/CUPTI/include'
        'include/cuda/CUPTI'
        'local/cuda/extras/CUPTI/include'
of:
        '/lib'
        '/lib/i386-linux-gnu'
        '/lib/x86_64-linux-gnu'
        '/lib32'
        '/opt/ont/guppy/lib'
        '/usr'
        '/usr/lib'
        '/usr/lib/i386-linux-gnu'
        '/usr/lib/x86_64-linux-gnu'
        '/usr/lib/x86_64-linux-gnu/libfakeroot'
        '/usr/lib32'
        '/usr/local/cuda'
        '/usr/local/cuda-11.1/targets/x86_64-linux/lib'
Asking for detailed CUDA configuration...

Please specify the CUDA SDK version you want to use. [Leave empty to default to CUDA 10]: 11.1


Please specify the cuDNN version you want to use. [Leave empty to default to cuDNN 7]: 8


Please specify the TensorRT version you want to use. [Leave empty to default to TensorRT 6]: 7


Please specify the locally installed NCCL version you want to use. [Leave empty to use http://github.com/nvidia/nccl]: 


Please specify the comma-separated list of base paths to look for CUDA libraries and headers. [Leave empty to use the default]: /usr/local/cuda-11.1/targets/x86_64-linux/lib,/usr/local/cuda-11.1/targets/x86_64-linux/include,/usr/lib/x86_64-linux-gnu,/usr/include,/usr/local/cuda-11.1/bin/,/usr/local/cuda-11.1/nvvm/libdevice/              

Could not find any libdevice*.10.bc in any subdirectory:
        'nvvm/libdevice'
        'share/cuda'
        'lib/nvidia-cuda-toolkit/libdevice'
        'local/cuda/nvvm/libdevice'
of:
        '/usr/include'
        '/usr/lib/x86_64-linux-gnu'
        '/usr/local/cuda-11.1/bin/'
        '/usr/local/cuda-11.1/nvvm/libdevice/'
        '/usr/local/cuda-11.1/targets/x86_64-linux/include'
        '/usr/local/cuda-11.1/targets/x86_64-linux/lib'
Asking for detailed CUDA configuration...

Please specify the CUDA SDK version you want to use. [Leave empty to default to CUDA 10]:

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
45462,Pip install issue on windows 10 with error ERROR: Could not install packages due to an EnvironmentError: [Errno 2] No such file or directory: 'C:\\Users\\jc_mr.TSE-DEV64-2\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\tensorflow\\include\\external\\aws\\aws-cpp-sdk-core\\include\\aws\\core\\client\\SpecifiedRetryableErrorsRetryStrategy.h',"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version:
- Python version:
- Installed using virtualenv? pip? conda?:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:



**Describe the problem**

**Provide the exact sequence of commands / steps that you executed before running into the problem**


**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
45460,Cannot convert model: Exception has occurred: ValueError,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04
- TensorFlow installed from (source or binary): built from source
- TensorFlow version (or github SHA if from source): 2.3.0


Here you can find a **tf-trt, tflite converter** issue with model train code and build model - [Collab Notebook](https://colab.research.google.com/drive/1-dRG9O2B_NfvjmQz9du5A0oRQJaIC6dH?usp=sharing) 
Here is the converter error
```
InvalidArgumentError: Input 1 of node functional_1/keras_layer/StatefulPartitionedCall/StatefulPartitionedCall/StatefulPartitionedCall/StatefulPartitionedCall/StatefulPartitionedCall was passed float from Func/functional_1/keras_layer/StatefulPartitionedCall/StatefulPartitionedCall/StatefulPartitionedCall/StatefulPartitionedCall/input/_1510:0 incompatible with expected resource.
```
**Also, please include a link to the saved model or GraphDef**
Here is the link to the saved_model also - [saved_model.zip](https://drive.google.com/file/d/10olY_D9HcSOjDS6Ufrrd2Ci6HA5kRW4D/view?usp=sharing)

**Failure details**
Trying to convert model to fp16 using tflite or with tf-trt. 
TensorRT - version 7.2.1.6
Cuda - 11.1
GPU - Nvidia GeForce 1060 6GB
Tensorflow as mentioned before - version 2.3.0 source build.
Also tried converting from saved_model directly but the problem is similar.

Can you help me with issues please? As I see, there is a problem somewhere in Input but I don't understand where.
Bigger priority here is to use TF-TRT, but TF-Lite is ok too.
Also could you please clarify which issues, bottleneck I can meet with this mix of tf, tf-text, tflite, tf-trt?"
45459,"""keras predict"" uses one more batch than specified by ""steps"" argument with generator x","
**System information**
- OS Platform and Distribution: Linux Ubuntu 18.04
- TensorFlow installed from: pip
- TensorFlow version (use command below): 2.3.1
- Python version: 3.6.9
- CUDA/cuDNN version: 10.1

**Describe the current behavior**
When providing a python generator to the keras.Model.predict function with a number of steps=N then, the generator is called N+1 times whereas the output of the predict function is the expected result (of size N x batch_size).

**Describe the expected behavior**
I expect the generator to be called only N times. It makes it impossible to resume the prediction just after the last called batch. Beside, the last batch is taken from the generator but not used for the prediction.

**Standalone code to reproduce the issue**
```python
import tensorflow as tf
import numpy as np

# a model that simply take a float as input and return it Model(x) = x
inputs = tf.keras.Input(shape=(1,))
outputs = tf.keras.layers.Dense(
    1, 
    activation=None, 
    use_bias=False, 
    kernel_initializer=tf.keras.initializers.Ones()
)(inputs)
model = tf.keras.Model(inputs=inputs, outputs=outputs)

def get_generator(batch_size=32, max_value=100):
    for begin in np.arange(start=0, stop=max_value, step=batch_size):
        end = min(max_value, begin + batch_size)
        print(""Call generator {} to {}"".format(begin, end))
        yield np.arange(begin, end)[:,None]

batch_size = 32
max_value = 100
data_generator = get_generator(batch_size=batch_size, max_value=max_value)

N = 3
# 3 steps but generator called 4 times...
res = model.predict(x=data_generator, steps=N)
```
![image](https://user-images.githubusercontent.com/7781975/101401829-2da56100-38d3-11eb-8013-7ed0d1470226.png)

```python
expected_result = np.arange(0, N * batch_size)[:, None]
print(np.allclose(res, expected_result))
```
![image](https://user-images.githubusercontent.com/7781975/101401914-5168a700-38d3-11eb-8dc4-4d4eaf25e3dc.png)

"
45458,"tensorflow.python.framework.errors_impl.UnknownError: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. [Op:Conv2D]","<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version: 2.1.0
- Python version: 3.6
- Installed using virtualenv? pip? conda?: conda 4.9.1
- Bazel version (if compiling from source): --
- GCC/Compiler version (if compiling from source): --
- CUDA/cuDNN version: cuda 10.1 / cudnn 7.6.5
- GPU model and memory: Geforce GTX 1650Ti, 4 GB, 7.5 capability 



**Describe the problem**
Application outputs an error message (tensorflow.python.framework.errors_impl.UnknownError: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. [Op:Conv2D]). I have tensorflow-gpu 2.1.0 installed via conda. This error happened first when installing tensorflow via conda, and after I read other issues, some suggested installing via pip because of possible mismatch between conda installed cuda and cudnn. However, even with pip-installed tensorflow, I am still receiving this error. Error is persistent also for tensorflow 2.2.0. 

I have tried different version of cudnn (7.6.0, for cuda 10.1) but the error persists. I have system install of cuda and cudnn, and have set the environment variables as per [tensorflow guide](https://www.tensorflow.org/install/gpu).

**Any other info / logs**
`2020-12-09 18:25:30.256782: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library nvcuda.dll
2020-12-09 18:25:31.215117: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce GTX 1650 Ti computeCapability: 7.5
coreClock: 1.485GHz coreCount: 16 deviceMemorySize: 4.00GiB deviceMemoryBandwidth: 178.84GiB/s
2020-12-09 18:25:31.215279: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll
2020-12-09 18:25:31.218433: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll
2020-12-09 18:25:31.220939: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_10.dll
2020-12-09 18:25:31.221819: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_10.dll
2020-12-09 18:25:31.225000: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_10.dll
2020-12-09 18:25:31.227314: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_10.dll
2020-12-09 18:25:31.240284: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll
2020-12-09 18:25:31.240428: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0
2020-12-09 18:25:31.240721: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2
2020-12-09 18:25:31.247163: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1a1643df6a0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-12-09 18:25:31.247314: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-12-09 18:25:31.247518: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce GTX 1650 Ti computeCapability: 7.5
coreClock: 1.485GHz coreCount: 16 deviceMemorySize: 4.00GiB deviceMemoryBandwidth: 178.84GiB/s
2020-12-09 18:25:31.247692: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll
2020-12-09 18:25:31.247812: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll
2020-12-09 18:25:31.247930: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_10.dll
2020-12-09 18:25:31.248007: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_10.dll
2020-12-09 18:25:31.248105: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_10.dll
2020-12-09 18:25:31.248187: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_10.dll
2020-12-09 18:25:31.248283: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll
2020-12-09 18:25:31.248447: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0
2020-12-09 18:25:31.669306: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-12-09 18:25:31.669402: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 
2020-12-09 18:25:31.669453: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N 
2020-12-09 18:25:31.669628: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 2913 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1650 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5)
2020-12-09 18:25:31.672216: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1a101d2a3a0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-12-09 18:25:31.672324: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce GTX 1650 Ti, Compute Capability 7.5
2020-12-09 18:25:33.789645: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll
2020-12-09 18:25:34.661555: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_ALLOC_FAILED
2020-12-09 18:25:34.662100: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_ALLOC_FAILED
Traceback (most recent call last):
  File ""A:\ProgramFiles\anaconda3\envs\tf-gpu\lib\site-packages\tensorflow\python\ops\gen_nn_ops.py"", line 926, in conv2d
    ""dilations"", dilations)
tensorflow.python.eager.core._FallbackException: Expecting int64_t value for attr strides, got numpy.int32

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""A:/projekti/diplomski/train.py"", line 61, in <module>
    run_train(yolo_model, num_epochs=2)
  File ""A:/projekti/diplomski/train.py"", line 39, in run_train
    y_preds = model(x_batch)
  File ""A:\ProgramFiles\anaconda3\envs\tf-gpu\lib\site-packages\tensorflow\python\keras\engine\base_layer.py"", line 968, in __call__
    outputs = self.call(cast_inputs, *args, **kwargs)
  File ""A:\ProgramFiles\anaconda3\envs\tf-gpu\lib\site-packages\tensorflow\python\keras\engine\network.py"", line 719, in call
    convert_kwargs_to_constants=base_layer_utils.call_context().saving)
  File ""A:\ProgramFiles\anaconda3\envs\tf-gpu\lib\site-packages\tensorflow\python\keras\engine\network.py"", line 888, in _run_internal_graph
    output_tensors = layer(computed_tensors, **kwargs)
  File ""A:\ProgramFiles\anaconda3\envs\tf-gpu\lib\site-packages\tensorflow\python\keras\engine\base_layer.py"", line 968, in __call__
    outputs = self.call(cast_inputs, *args, **kwargs)
  File ""A:\ProgramFiles\anaconda3\envs\tf-gpu\lib\site-packages\tensorflow\python\keras\layers\convolutional.py"", line 207, in call
    outputs = self._convolution_op(inputs, self.kernel)
  File ""A:\ProgramFiles\anaconda3\envs\tf-gpu\lib\site-packages\tensorflow\python\ops\nn_ops.py"", line 1106, in __call__
    return self.conv_op(inp, filter)
  File ""A:\ProgramFiles\anaconda3\envs\tf-gpu\lib\site-packages\tensorflow\python\ops\nn_ops.py"", line 638, in __call__
    return self.call(inp, filter)
  File ""A:\ProgramFiles\anaconda3\envs\tf-gpu\lib\site-packages\tensorflow\python\ops\nn_ops.py"", line 237, in __call__
    name=self.name)
  File ""A:\ProgramFiles\anaconda3\envs\tf-gpu\lib\site-packages\tensorflow\python\ops\nn_ops.py"", line 2014, in conv2d
    name=name)
  File ""A:\ProgramFiles\anaconda3\envs\tf-gpu\lib\site-packages\tensorflow\python\ops\gen_nn_ops.py"", line 933, in conv2d
    data_format=data_format, dilations=dilations, name=name, ctx=_ctx)
  File ""A:\ProgramFiles\anaconda3\envs\tf-gpu\lib\site-packages\tensorflow\python\ops\gen_nn_ops.py"", line 1022, in conv2d_eager_fallback
    ctx=ctx, name=name)
  File ""A:\ProgramFiles\anaconda3\envs\tf-gpu\lib\site-packages\tensorflow\python\eager\execute.py"", line 60, in quick_execute
    inputs, attrs, num_outputs)
tensorflow.python.framework.errors_impl.UnknownError: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. [Op:Conv2D]`

This is how i use convolution in code: 

`  

    def conv_norm_lrelu(inputs, filters, kernel_size, stride=1, training=True, **conv_kwargs):

        stride = tf.cast(stride, tf.int64)

        conv = tf.keras.layers.Conv2D(filters, kernel_size, strides=(stride, stride), padding='same', **conv_kwargs)(inputs)

        bn = tf.keras.layers.BatchNormalization(trainable=training)(conv)

        return tf.keras.layers.LeakyReLU(alpha=0.1)(bn)

`"
45454,keras model to a single pb file or valid graph,"
I use TensorFlow 2.3.1

currently, you cant export a Keras model to a pb file without a folder that is a valid graph to use in the c++ api.

I don't think this will change the api. just a feature for making a valid graph for the c++ api.

I think that labs that work with c++ and other languages that use the c_api.h file for wrapping for the language (maybe python uses it too?) with tensorflow because that is what they've worked with.

thank you, Im sorry if I just cant find it. I use the cppflow wrapper. is it that? can you assist me if its not your own and it *is* valid?
"
45453,Suspected memory leak - when loading multiple models with tf.saved_model.load,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
YES
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Linux Ubuntu 18.04
- TensorFlow installed from (source or binary):
binary wheel via PyPI
- TensorFlow version (use command below):
v2.4.0-rc3-20-g97c3fef64ba 2.4.0-rc4
- Python version:
3.6
Bazel version (if compiling from source):
NA
GCC/Compiler version (if compiling from source):
NA
- CUDA/cuDNN version:
CUDA 11.1

- GPU model and memory:
V100 16GB

**Describe the current behavior**
I'm suspecting a CPU memory leak when loading multiple models.
When I'm running infinite loop that keeps loading the same model while using the same variable the memory (private bytes and working set) of the process keep increasing. At some points the working set seems to free some memory, but the trend is that the memory keeps on rising.
For example I used a simple model.
For our **current real** model the memory leak in tf 2.3 is 0.32MB per load model 
For our **current real** model the memory leak in tf 2.4 is 0.08MB per load model it is still an issue since the model can be changed and our server serve different models 24/7 

This trend happens even though I call gc.collect() on every iteration and tf.keras.backend.clear_session().

**Describe the expected behavior**
The memory shouldnt increase on each interation

**Standalone code to reproduce the issue**
```
import tensorflow as tf
import gc


def build_and_save_own_model():
    model = tf.keras.models.Sequential([
        tf.keras.layers.Flatten(input_shape=(28, 28)),
        tf.keras.layers.Dense(128, activation='relu'),
        tf.keras.layers.Dropout(0.2),
        tf.keras.layers.Dense(10, activation='softmax')
    ])
    model.save('my_model')
    tf.keras.backend.clear_session()
    del model
    gc.collect()


def profile_load_model(path):
    model = tf.saved_model.load(path)
    tf.keras.backend.clear_session()
    del model
    gc.collect()


def run_model():
    model_path = 'my_model'
    build_and_save_own_model()
    print(""load model in loops:"")
    c = 1
    while True:
        print(""----------- iter"", c)
        profile_load_model(model_path)
        c += 1


if __name__ == '__main__':
    print(""*****************************************************"")
    print(""START LOADING MODEL"")
    print(tf.version.GIT_VERSION, tf.version.VERSION)
    print(""*****************************************************"")
    run_model()
```


TF2_3 memory leak:
![memleak_tf2_3](https://user-images.githubusercontent.com/27951762/101373173-5585cc00-38b5-11eb-8405-124b885033ab.PNG)


TF2_4 memory leak:
![memleak_tf2_4](https://user-images.githubusercontent.com/27951762/101373017-2bcca500-38b5-11eb-9b22-cc652036b455.PNG)

thanks
"
45452,tflite quantized model unable to run on DSP,"@tensorflow/micro

**System information**
- Host OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- TensorFlow installed from (source or binary):
Binary 
- Tensorflow version (commit SHA if source):
tf-nightly 
- Target platform (e.g. Arm Mbed OS, Arduino Nano 33 etc.):
Android
**Describe the problem**
Model with full quantization. 
I get the following message:
INFO: Created TensorFlow Lite delegate for Hexagon.
INFO: Initialized TensorFlow Lite runtime.
INFO: Interpreter::UseNNAPI() is deprecated. Use tflite::NnApiDelegate() directly instead.
INFO: Hexagon delegate: 0 nodes delegated out of 51 nodes with 0 partitions.

**Please provide the exact sequence of commands/steps when you ran into the problem**
Converter configuration:
converter.optimizations = [tf.lite.Optimize.DEFAULT] # dynamic range quantization
converter.representative_dataset = representative_data_gen  # + float fallback quantization
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]  # +integer only quantization
converter.inference_input_type = tf.int8 # +integer only quantization
converter.inference_output_type  = tf.int8    


tflite model is attatched
[myModel.zip](https://github.com/tensorflow/tensorflow/files/5653707/myModel.zip)



"
45451,tensorflow_estimator-2.4.0rc0.dist-info is missing METADATA file,"FileNotFoundError: [Errno 2] No such file or directory: 'c:\\users\\USER\\anaconda3\\envs\\tf-gpu-latest\\lib\\site-packages\\tensorflow_estimator-2.4.0rc0.dist-info\\METADATA'

Only the INSTALLER file is in the directory. 

Edit:
Reinstall it in a new environment and it now has those files, something must have gone wrong during pip installation. "
45450,all CUDA-capable devices are busy or unavailable,"

(tfv1) [root@bogon ~]# cat /etc/redhat-release
CentOS Linux release 7.9.2009 (Core)



tfv1) [root@bogon ~]# nvidia-smi
Mon Dec  7 22:21:25 2020
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 450.80.02    Driver Version: 450.80.02    CUDA Version: 11.0     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Tesla T4            Off  | 00000000:00:0C.0 Off |                    0 |
| N/A   44C    P0    15W /  70W |      0MiB / 15109MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+

+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+



2020-12-07 22:03:48.390261: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.9.0
Traceback (most recent call last):
  File ""cpu.py"", line 91, in <module>
    with tf.Session() as sess:
  File ""/root/anaconda3/envs/tfv1/lib/python3.7/site-packages/tensorflow/python/client/session.py"", line 1570, in __init__
    super(Session, self).__init__(target, graph, config=config)
  File ""/root/anaconda3/envs/tfv1/lib/python3.7/site-packages/tensorflow/python/client/session.py"", line 693, in __init__
    self._session = tf_session.TF_NewSessionRef(self._graph._c_graph, opts)
tensorflow.python.framework.errors_impl.InternalError: CUDA runtime implicit initialization on GPU:0 failed. Status: all CUDA-capable devices are busy or unavailable



The CPU version of tensorflow can execute successfully, but GPU version of tensorflow fails. Why？
tensorflow version ：
           conda install tensorflow=1.14.0=gpu_py37hae64822_0
"
45449,Segmenation fault when saving StringLookup layer,"

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- MacOS 
- TensorFlow installed from binary
- TensorFlow version: '2.3.1' 
- Python version: 3.7

**Current behavior**
A Model with just input and StringLookup layers is failing to save after loading it twice. It gives a segmentation fault.
**Expected behavior**
Saving without having a Segmentation fault

**Standalone code to reproduce the issue**
```python
import tensorflow as tf

lookup = tf.keras.layers.experimental.preprocessing.StringLookup(vocabulary=[""a"", ""b""])

s = tf.keras.Input(1, dtype=tf.string)
k = lookup(s)

model = tf.keras.Model(s, k)
model.compile()

tf.keras.models.save_model(model, ""./out/dummy/"")

load2 = tf.keras.models.load_model(""./out/dummy/"")
tf.keras.models.save_model(load2, ""./out/dummy2/"")

load3 = tf.keras.models.load_model(""./out/dummy2/"")
tf.keras.models.save_model(load3, ""./out/dummy3/"")
```
"
45448,2.4.0-rc4: import keras error,"This is likely to be a stupid question.
I use an RTX 3090 and hence am very interested in the 2.4.0 version of Tensorflow.

However, when I use the 2.4.0-rc4 and attempt to import keras...
`from tensorflow import keras`

... I get the error:
```
---------------------------------------------------------------------------
ModuleNotFoundError                       Traceback (most recent call last)
<ipython-input-9-256f42a18d91> in <module>
     22 print('ok0')
     23 
---> 24 from tensorflow import keras
     25 
     26 print('ok1')

~/anaconda3/envs/tsne/lib/python3.8/site-packages/tensorflow/keras/__init__.py in <module>
     17 from . import callbacks
     18 from . import constraints
---> 19 from . import datasets
     20 from . import estimator
     21 from . import experimental

~/anaconda3/envs/tsne/lib/python3.8/site-packages/tensorflow/keras/datasets/__init__.py in <module>
     12 from . import cifar100
     13 from . import fashion_mnist
---> 14 from . import imdb
     15 from . import mnist
     16 from . import reuters

~/anaconda3/envs/tsne/lib/python3.8/site-packages/tensorflow/keras/datasets/imdb/__init__.py in <module>
      9 import sys as _sys
     10 
---> 11 from tensorflow.python.keras.datasets.imdb import get_word_index
     12 from tensorflow.python.keras.datasets.imdb import load_data
     13 

~/anaconda3/envs/tsne/lib/python3.8/site-packages/tensorflow/python/keras/datasets/imdb.py in <module>
     23 import numpy as np
     24 
---> 25 from tensorflow.python.keras.preprocessing.sequence import _remove_long_seq
     26 from tensorflow.python.keras.utils.data_utils import get_file
     27 from tensorflow.python.platform import tf_logging as logging

~/anaconda3/envs/tsne/lib/python3.8/site-packages/tensorflow/python/keras/preprocessing/__init__.py in <module>
     21 # TODO(mihaimaruseac): remove the import of keras_preprocessing and injecting
     22 # once we update to latest version of keras_preprocessing
---> 23 import keras_preprocessing
     24 
     25 from tensorflow.python.keras import backend

ModuleNotFoundError: No module named 'keras_preprocessing'
```

Is this an expected behaviour for this rc -- and I should have known that keras does not work with rc versions?
Is there a simple way for me to get keras to work with 2.4.0-rc4?"
45447,addv2,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- TensorFlow installed from (source or binary):
- TensorFlow version (or github SHA if from source):


**Provide the text output from tflite_convert**

```
# Copy and paste here
```

**Standalone code to reproduce the issue** 
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

Also, please include a link to a GraphDef or the model if possible.

**Any other info / logs**

Include any logs or source code that would be helpful to diagnose the problem.
If including tracebacks, please include the full traceback. Large logs and files
should be attached.
"
45446,Source compilation fails on Musl system on multiple places,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Alpine Linux edge
- TensorFlow installed from (source or binary): source
- TensorFlow version: 2.3.1
- Python version: 3.8.6
- Installed using virtualenv? pip? conda?: source
- Bazel version (if compiling from source): 3.5.0
- GCC/Compiler version (if compiling from source): 10.2.1_pre1

**Describe the problem**

I'm trying to compile TensorFlow from source on Alpine Linux which is a Musl based system. It fails on several points however:

```
ERROR: /builds/PureTryOut/aports/testing/tensorflow/src/tensorflow-2.3.1/tensorflow/core/platform/default/BUILD:75:11: Couldn't build file tensorflow/core/platform/default/_objs/env/0/env.pic.o: C++ compilation of rule '//tensorflow/core/platform/default:env' failed (Exit 1)
tensorflow/core/platform/default/env.cc: In member function 'virtual bool tensorflow::{anonymous}::PosixEnv::GetCurrentThreadName(std::string*)':
tensorflow/core/platform/default/env.cc:160:15: error: 'pthread_getname_np' was not declared in this scope; did you mean 'pthread_setname_np'?
  160 |     int res = pthread_getname_np(pthread_self(), buf, static_cast<size_t>(100));
      |               ^~~~~~~~~~~~~~~~~~
      |               pthread_setname_np
```

```
ERROR: /builds/PureTryOut/aports/testing/tensorflow/src/tensorflow-2.3.1/tensorflow/core/platform/s3/BUILD:44:11: Couldn't build file tensorflow/core/platform/s3/_objs/aws_crypto/aws_crypto.pic.o: C++ compilation of rule '//tensorflow/core/platform/s3:aws_crypto' failed (Exit 1)
tensorflow/core/platform/s3/aws_crypto.cc: In member function 'virtual Aws::Utils::Crypto::HashResult tensorflow::AWSSha256HMACOpenSSLImpl::Calculate(const ByteBuffer&, const ByteBuffer&)':
tensorflow/core/platform/s3/aws_crypto.cc:38:14: error: aggregate 'HMAC_CTX ctx' has incomplete type and cannot be defined
   38 |     HMAC_CTX ctx;
      |              ^~~
tensorflow/core/platform/s3/aws_crypto.cc:39:5: error: 'HMAC_CTX_init' was not declared in this scope; did you mean 'HMAC_CTX_new'?
   39 |     HMAC_CTX_init(&ctx);
      |     ^~~~~~~~~~~~~
      |     HMAC_CTX_new
tensorflow/core/platform/s3/aws_crypto.cc:45:5: error: 'HMAC_CTX_cleanup' was not declared in this scope
   45 |     HMAC_CTX_cleanup(&ctx);
      |     ^~~~~~~~~~~~~~~~
```

**Provide the exact sequence of commands / steps that you executed before running into the problem**
The build script can be found at https://gitlab.alpinelinux.org/alpine/aports/-/raw/4cf626b10d2f4700cc5e5e9e7536061137c8c6a1/testing/tensorflow/APKBUILD. Note that `prepare()` there is called before `build()` and the environment variables set carry over."
45445,"Unable to succeed ""pip install tensorflow"" due to error ""Failed building wheel for grpcio"" in virtualenv","**System information**
- OS Platform and Distribution Linux Ubuntu 16.04
- TensorFlow installed from pip install
- TensorFlow version:1.14.0
- Installed using pip inside a virtual environment created using virtualenv command

**When I was trying to install tensorflow in a virtual environment(created using `virtualenv` command, it is showing the following error at some point of installation:**
```
Building wheels for collected packages: grpcio
  Running setup.py bdist_wheel for grpcio ... /

Failed building wheel for grpcio
```

**Provide the exact sequence of commands / steps that you executed before running into the problem**
```
virtualenv dd
source dd/bin/activate
pip install tensorflow
```


**Any other info / logs**
T=1536 -DGPR_BACKWARDS_COMPATIBILITY_MODE=1 -DHAVE_CONFIG_H=1 -DGRPC_ENABLE_FORK_SUPPORT=1 -DPyMODINIT_FUNC=extern ""C"" __attribute__((visibility (""default""))) void -DGRPC_POSIX_FORK_ALLOW_PTHREAD_ATFORK=1 -Isrc/python/grpcio -Iinclude -I. -Ithird_party/abseil-cpp -Ithird_party/address_sorting/include -Ithird_party/cares -Ithird_party/cares/cares -Ithird_party/cares/config_linux -Ithird_party/re2 -Ithird_party/boringssl-with-bazel/src/include -Ithird_party/upb -Isrc/core/ext/upb-generated -Isrc/core/ext/upbdefs-generated -Ithird_party/zlib -I/usr/include/python2.7 -c src/core/ext/upb-generated/google/api/http.upb.c -o python_build/temp.linux-x86_64-2.7/src/core/ext/upb-generated/google/api/http.upb.o -std=c++11 -std=gnu99 -fvisibility=hidden -fno-wrapv -fno-exceptions -pthread
    gcc -pthread -fno-strict-aliasing -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -DNDEBUG -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions-fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -fPIC -D_WIN32_WINNT=1536 -DGPR_BACKWARDS_COMPATIBILITY_MODE=1 -DHAVE_CONFIG_H=1 -DGRPC_ENABLE_FORK_SUPPORT=1 -DPyMODINIT_FUNC=extern ""C"" __attribute__((visibility (""default""))) void -DGRPC_POSIX_FORK_ALLOW_PTHREAD_ATFORK=1 -Isrc/python/grpcio -Iinclude -I. -Ithird_party/abseil-cpp -Ithird_party/address_sorting/include -Ithird_party/cares -Ithird_party/cares/cares -Ithird_party/cares/config_linux -Ithird_party/re2 -Ithird_party/boringssl-with-bazel/src/include -Ithird_party/upb -Isrc/core/ext/upb-generated -Isrc/core/ext/upbdefs-generated -Ithird_party/zlib -I/usr/include/python2.7 -c src/core/ext/upbdefs-generated/envoy/service/listener/v3/lds.upbdefs.c -o python_build/temp.linux-x86_64-2.7/src/core/ext/upbdefs-generated/envoy/service/listener/v3/lds.upbdefs.o -std=c++11 -std=gnu99 -fvisibility=hidden -fno-wrapv -fno-exceptions -pthread
    cc1: warning: command line option ‘-std=c++11’ is valid for C++/ObjC++ but not for C [enabled by default]
    cc1: warning: command line option ‘-std=c++11’ is valid for C++/ObjC++ but not for C [enabled by default]
    gcc -pthread -fno-strict-aliasing -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -DNDEBUG -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions-fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -fPIC -I/usr/include/python2.7 -c /tmp/tmpcOA4GA/a.c -o None/tmp/tmpcOA4GA/a.o
    gcc -pthread -fno-strict-aliasing -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -DNDEBUG -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions-fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -fPIC -D_WIN32_WINNT=1536 -DGPR_BACKWARDS_COMPATIBILITY_MODE=1 -DHAVE_CONFIG_H=1 -DGRPC_ENABLE_FORK_SUPPORT=1 -DPyMODINIT_FUNC=extern ""C"" __attribute__((visibility (""default""))) void -DGRPC_POSIX_FORK_ALLOW_PTHREAD_ATFORK=1 -Isrc/python/grpcio -Iinclude -I. -Ithird_party/abseil-cpp -Ithird_party/address_sorting/include -Ithird_party/cares -Ithird_party/cares/cares -Ithird_party/cares/config_linux -Ithird_party/re2 -Ithird_party/boringssl-with-bazel/src/include -Ithird_party/upb -Isrc/core/ext/upb-generated -Isrc/core/ext/upbdefs-generated -Ithird_party/zlib -I/usr/include/python2.7 -c src/core/ext/upbdefs-generated/envoy/config/core/v3/address.upbdefs.c -o python_build/temp.linux-x86_64-2.7/src/core/ext/upbdefs-generated/envoy/config/core/v3/address.upbdefs.o -std=c++11 -std=gnu99 -fvisibility=hidden -fno-wrapv -fno-exceptions -pthread
    cc1: warning: command line option ‘-std=c++11’ is valid for C++/ObjC++ but not for C [enabled by default]
    gcc -pthread -fno-strict-aliasing -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -DNDEBUG -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions-fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -fPIC -D_WIN32_WINNT=1536 -DGPR_BACKWARDS_COMPATIBILITY_MODE=1 -DHAVE_CONFIG_H=1 -DGRPC_ENABLE_FORK_SUPPORT=1 -DPyMODINIT_FUNC=extern ""C"" __attribute__((visibility (""default""))) void -DGRPC_POSIX_FORK_ALLOW_PTHREAD_ATFORK=1 -Isrc/python/grpcio -Iinclude -I. -Ithird_party/abseil-cpp -Ithird_party/address_sorting/include -Ithird_party/cares -Ithird_party/cares/cares -Ithird_party/cares/config_linux -Ithird_party/re2 -Ithird_party/boringssl-with-bazel/src/include -Ithird_party/upb -Isrc/core/ext/upb-generated -Isrc/core/ext/upbdefs-generated -Ithird_party/zlib -I/usr/include/python2.7 -c src/core/ext/upbdefs-generated/envoy/config/listener/v3/listener_components.upbdefs.c -o python_build/temp.linux-x86_64-2.7/src/core/ext/upbdefs-generated/envoy/config/listener/v3/listener_components.upbdefs.o -std=c++11 -std=gnu99 -fvisibility=hidden -fno-wrapv -fno-exceptions -pthread
    cc1: warning: command line option ‘-std=c++11’ is valid for C++/ObjC++ but not for C [enabled by default]
    gcc -pthread -fno-strict-aliasing -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -DNDEBUG -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions-fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -fPIC -D_WIN32_WINNT=1536 -DGPR_BACKWARDS_COMPATIBILITY_MODE=1 -DHAVE_CONFIG_H=1 -DGRPC_ENABLE_FORK_SUPPORT=1 -DPyMODINIT_FUNC=extern ""C"" __attribute__((visibility (""default""))) void -DGRPC_POSIX_FORK_ALLOW_PTHREAD_ATFORK=1 -Isrc/python/grpcio -Iinclude -I. -Ithird_party/abseil-cpp -Ithird_party/address_sorting/include -Ithird_party/cares -Ithird_party/cares/cares -Ithird_party/cares/config_linux -Ithird_party/re2 -Ithird_party/boringssl-with-bazel/src/include -Ithird_party/upb -Isrc/core/ext/upb-generated -Isrc/core/ext/upbdefs-generated -Ithird_party/zlib -I/usr/include/python2.7 -c src/core/ext/upbdefs-generated/udpa/core/v1/resource_locator.upbdefs.c -o python_build/temp.linux-x86_64-2.7/src/core/ext/upbdefs-generated/udpa/core/v1/resource_locator.upbdefs.o -std=c++11 -std=gnu99 -fvisibility=hidden -fno-wrapv -fno-exceptions -pthread
    cc1: warning: command line option ‘-std=c++11’ is valid for C++/ObjC++ but not for C [enabled by default]
    cc1: warning: command line option ‘-std=c++11’ is valid for C++/ObjC++ but not for C [enabled by default]
    cc1: warning: command line option ‘-std=c++11’ is valid for C++/ObjC++ but not for C [enabled by default]
    gcc -pthread -fno-strict-aliasing -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -DNDEBUG -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions-fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -fPIC -D_WIN32_WINNT=1536 -DGPR_BACKWARDS_COMPATIBILITY_MODE=1 -DHAVE_CONFIG_H=1 -DGRPC_ENABLE_FORK_SUPPORT=1 -DPyMODINIT_FUNC=extern ""C"" __attribute__((visibility (""default""))) void -DGRPC_POSIX_FORK_ALLOW_PTHREAD_ATFORK=1 -Isrc/python/grpcio -Iinclude -I. -Ithird_party/abseil-cpp -Ithird_party/address_sorting/include -Ithird_party/cares -Ithird_party/cares/cares -Ithird_party/cares/config_linux -Ithird_party/re2 -Ithird_party/boringssl-with-bazel/src/include -Ithird_party/upb -Isrc/core/ext/upb-generated -Isrc/core/ext/upbdefs-generated -Ithird_party/zlib -I/usr/include/python2.7 -c src/core/ext/upb-generated/envoy/config/listener/v3/listener_components.upb.c -o python_build/temp.linux-x86_64-2.7/src/core/ext/upb-generated/envoy/config/listener/v3/listener_components.upb.o -std=c++11 -std=gnu99 -fvisibility=hidden -fno-wrapv -fno-exceptions -pthread
    gcc -pthread -fno-strict-aliasing -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -DNDEBUG -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions-fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -fPIC -D_WIN32_WINNT=1536 -DGPR_BACKWARDS_COMPATIBILITY_MODE=1 -DHAVE_CONFIG_H=1 -DGRPC_ENABLE_FORK_SUPPORT=1 -DPyMODINIT_FUNC=extern ""C"" __attribute__((visibility (""default""))) void -DGRPC_POSIX_FORK_ALLOW_PTHREAD_ATFORK=1 -Isrc/python/grpcio -Iinclude -I. -Ithird_party/abseil-cpp -Ithird_party/address_sorting/include -Ithird_party/cares -Ithird_party/cares/cares -Ithird_party/cares/config_linux -Ithird_party/re2 -Ithird_party/boringssl-with-bazel/src/include -Ithird_party/upb -Isrc/core/ext/upb-generated -Isrc/core/ext/upbdefs-generated -Ithird_party/zlib -I/usr/include/python2.7 -c src/core/ext/upb-generated/google/protobuf/any.upb.c -o python_build/temp.linux-x86_64-2.7/src/core/ext/upb-generated/google/protobuf/any.upb.o -std=c++11 -std=gnu99 -fvisibility=hidden -fno-wrapv-fno-exceptions -pthread
    cc1: warning: command line option ‘-std=c++11’ is valid for C++/ObjC++ but not for C [enabled by default]
    gcc -pthread -fno-strict-aliasing -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -DNDEBUG -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions-fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -fPIC -D_WIN32_WINNT=1536 -DGPR_BACKWARDS_COMPATIBILITY_MODE=1 -DHAVE_CONFIG_H=1 -DGRPC_ENABLE_FORK_SUPPORT=1 -DPyMODINIT_FUNC=extern ""C"" __attribute__((visibility (""default""))) void -DGRPC_POSIX_FORK_ALLOW_PTHREAD_ATFORK=1 -Isrc/python/grpcio -Iinclude -I. -Ithird_party/abseil-cpp -Ithird_party/address_sorting/include -Ithird_party/cares -Ithird_party/cares/cares -Ithird_party/cares/config_linux -Ithird_party/re2 -Ithird_party/boringssl-with-bazel/src/include -Ithird_party/upb -Isrc/core/ext/upb-generated -Isrc/core/ext/upbdefs-generated -Ithird_party/zlib -I/usr/include/python2.7 -c src/core/ext/upb-generated/envoy/service/route/v3/rds.upb.c -o python_build/temp.linux-x86_64-2.7/src/core/ext/upb-generated/envoy/service/route/v3/rds.upb.o -std=c++11 -std=gnu99 -fvisibility=hidden -fno-wrapv -fno-exceptions -pthread
    gcc -pthread -fno-strict-aliasing -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -DNDEBUG -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions-fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -fPIC -D_WIN32_WINNT=1536 -DGPR_BACKWARDS_COMPATIBILITY_MODE=1 -DHAVE_CONFIG_H=1 -DGRPC_ENABLE_FORK_SUPPORT=1 -DPyMODINIT_FUNC=extern ""C"" __attribute__((visibility (""default""))) void -DGRPC_POSIX_FORK_ALLOW_PTHREAD_ATFORK=1 -Isrc/python/grpcio -Iinclude -I. -Ithird_party/abseil-cpp -Ithird_party/address_sorting/include -Ithird_party/cares -Ithird_party/cares/cares -Ithird_party/cares/config_linux -Ithird_party/re2 -Ithird_party/boringssl-with-bazel/src/include -Ithird_party/upb -Isrc/core/ext/upb-generated -Isrc/core/ext/upbdefs-generated -Ithird_party/zlib -I/usr/include/python2.7 -c src/core/ext/upbdefs-generated/google/protobuf/descriptor.upbdefs.c -o python_build/temp.linux-x86_64-2.7/src/core/ext/upbdefs-generated/google/protobuf/descriptor.upbdefs.o -std=c++11 -std=gnu99 -fvisibility=hidden -fno-wrapv -fno-exceptions -pthread
    cc1: warning: command line option ‘-std=c++11’ is valid for C++/ObjC++ but not for C [enabled by default]
    gcc -pthread -fno-strict-aliasing -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -DNDEBUG -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions-fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -fPIC -D_WIN32_WINNT=1536 -DGPR_BACKWARDS_COMPATIBILITY_MODE=1 -DHAVE_CONFIG_H=1 -DGRPC_ENABLE_FORK_SUPPORT=1 -DPyMODINIT_FUNC=extern ""C"" __attribute__((visibility (""default""))) void -DGRPC_POSIX_FORK_ALLOW_PTHREAD_ATFORK=1 -Isrc/python/grpcio -Iinclude -I. -Ithird_party/abseil-cpp -Ithird_party/address_sorting/include -Ithird_party/cares -Ithird_party/cares/cares -Ithird_party/cares/config_linux -Ithird_party/re2 -Ithird_party/boringssl-with-bazel/src/include -Ithird_party/upb -Isrc/core/ext/upb-generated -Isrc/core/ext/upbdefs-generated -Ithird_party/zlib -I/usr/include/python2.7 -c src/core/lib/channel/connected_channel.cc -o python_build/temp.linux-x86_64-2.7/src/core/lib/channel/connected_channel.o -std=c++11 -std=gnu99 -fvisibility=hidden -fno-wrapv -fno-exceptions -pthread
    cc1: warning: command line option ‘-std=c++11’ is valid for C++/ObjC++ but not for C [enabled by default]
    gcc -pthread -fno-strict-aliasing -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -DNDEBUG -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions-fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -fPIC -D_WIN32_WINNT=1536 -DGPR_BACKWARDS_COMPATIBILITY_MODE=1 -DHAVE_CONFIG_H=1 -DGRPC_ENABLE_FORK_SUPPORT=1 -DPyMODINIT_FUNC=extern ""C"" __attribute__((visibility (""default""))) void -DGRPC_POSIX_FORK_ALLOW_PTHREAD_ATFORK=1 -Isrc/python/grpcio -Iinclude -I. -Ithird_party/abseil-cpp -Ithird_party/address_sorting/include -Ithird_party/cares -Ithird_party/cares/cares -Ithird_party/cares/config_linux -Ithird_party/re2 -Ithird_party/boringssl-with-bazel/src/include -Ithird_party/upb -Isrc/core/ext/upb-generated -Isrc/core/ext/upbdefs-generated -Ithird_party/zlib -I/usr/include/python2.7 -c src/core/ext/upbdefs-generated/envoy/service/load_stats/v3/lrs.upbdefs.c -o python_build/temp.linux-x86_64-2.7/src/core/ext/upbdefs-generated/envoy/service/load_stats/v3/lrs.upbdefs.o -std=c++11 -std=gnu99 -fvisibility=hidden -fno-wrapv -fno-exceptions -pthread
    cc1: warning: command line option ‘-std=c++11’ is valid for C++/ObjC++ but not for C [enabled by default]
    gcc -pthread -fno-strict-aliasing -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -DNDEBUG -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions-fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -fPIC -D_WIN32_WINNT=1536 -DGPR_BACKWARDS_COMPATIBILITY_MODE=1 -DHAVE_CONFIG_H=1 -DGRPC_ENABLE_FORK_SUPPORT=1 -DPyMODINIT_FUNC=extern ""C"" __attribute__((visibility (""default""))) void -DGRPC_POSIX_FORK_ALLOW_PTHREAD_ATFORK=1 -Isrc/python/grpcio -Iinclude -I. -Ithird_party/abseil-cpp -Ithird_party/address_sorting/include -Ithird_party/cares -Ithird_party/cares/cares -Ithird_party/cares/config_linux -Ithird_party/re2 -Ithird_party/boringssl-with-bazel/src/include -Ithird_party/upb -Isrc/core/ext/upb-generated -Isrc/core/ext/upbdefs-generated -Ithird_party/zlib -I/usr/include/python2.7 -c src/core/ext/upbdefs-generated/envoy/config/listener/v3/udp_listener_config.upbdefs.c -o python_build/temp.linux-x86_64-2.7/src/core/ext/upbdefs-generated/envoy/config/listener/v3/udp_listener_config.upbdefs.o -std=c++11 -std=gnu99 -fvisibility=hidden -fno-wrapv -fno-exceptions -pthread
    cc1: warning: command line option ‘-std=c++11’ is valid for C++/ObjC++ but not for C [enabled by default]
    gcc -pthread -fno-strict-aliasing -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -DNDEBUG -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions-fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -fPIC -D_WIN32_WINNT=1536 -DGPR_BACKWARDS_COMPATIBILITY_MODE=1 -DHAVE_CONFIG_H=1 -DGRPC_ENABLE_FORK_SUPPORT=1 -DPyMODINIT_FUNC=extern ""C"" __attribute__((visibility (""default""))) void -DGRPC_POSIX_FORK_ALLOW_PTHREAD_ATFORK=1 -Isrc/python/grpcio -Iinclude -I. -Ithird_party/abseil-cpp -Ithird_party/address_sorting/include -Ithird_party/cares -Ithird_party/cares/cares -Ithird_party/cares/config_linux -Ithird_party/re2 -Ithird_party/boringssl-with-bazel/src/include -Ithird_party/upb -Isrc/core/ext/upb-generated -Isrc/core/ext/upbdefs-generated -Ithird_party/zlib -I/usr/include/python2.7 -c src/core/ext/upbdefs-generated/envoy/config/core/v3/backoff.upbdefs.c -o python_build/temp.linux-x86_64-2.7/src/core/ext/upbdefs-generated/envoy/config/core/v3/backoff.upbdefs.o -std=c++11 -std=gnu99 -fvisibility=hidden -fno-wrapv -fno-exceptions -pthread
    cc1plus: warning: command line option ‘-std=gnu99’ is valid for C/ObjC but not for C++ [enabled by default]
    gcc -pthread -fno-strict-aliasing -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -DNDEBUG -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions-fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -fPIC -D_WIN32_WINNT=1536 -DGPR_BACKWARDS_COMPATIBILITY_MODE=1 -DHAVE_CONFIG_H=1 -DGRPC_ENABLE_FORK_SUPPORT=1 -DPyMODINIT_FUNC=extern ""C"" __attribute__((visibility (""default""))) void -DGRPC_POSIX_FORK_ALLOW_PTHREAD_ATFORK=1 -Isrc/python/grpcio -Iinclude -I. -Ithird_party/abseil-cpp -Ithird_party/address_sorting/include -Ithird_party/cares -Ithird_party/cares/cares -Ithird_party/cares/config_linux -Ithird_party/re2 -Ithird_party/boringssl-with-bazel/src/include -Ithird_party/upb -Isrc/core/ext/upb-generated -Isrc/core/ext/upbdefs-generated -Ithird_party/zlib -I/usr/include/python2.7 -c src/core/ext/upbdefs-generated/udpa/core/v1/resource_name.upbdefs.c -o python_build/temp.linux-x86_64-2.7/src/core/ext/upbdefs-generated/udpa/core/v1/resource_name.upbdefs.o -std=c++11 -std=gnu99 -fvisibility=hidden -fno-wrapv -fno-exceptions -pthread
    cc1: warning: command line option ‘-std=c++11’ is valid for C++/ObjC++ but not for C [enabled by default]
    gcc -pthread -fno-strict-aliasing -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -DNDEBUG -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions-fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -fPIC -D_WIN32_WINNT=1536 -DGPR_BACKWARDS_COMPATIBILITY_MODE=1 -DHAVE_CONFIG_H=1 -DGRPC_ENABLE_FORK_SUPPORT=1 -DPyMODINIT_FUNC=extern ""C"" __attribute__((visibility (""default""))) void -DGRPC_POSIX_FORK_ALLOW_PTHREAD_ATFORK=1 -Isrc/python/grpcio -Iinclude -I. -Ithird_party/abseil-cpp -Ithird_party/address_sorting/include -Ithird_party/cares -Ithird_party/cares/cares -Ithird_party/cares/config_linux -Ithird_party/re2 -Ithird_party/boringssl-with-bazel/src/include -Ithird_party/upb -Isrc/core/ext/upb-generated -Isrc/core/ext/upbdefs-generated -Ithird_party/zlib -I/usr/include/python2.7 -c src/core/ext/transport/inproc/inproc_plugin.cc -o python_build/temp.linux-x86_64-2.7/src/core/ext/transport/inproc/inproc_plugin.o -std=c++11 -std=gnu99 -fvisibility=hidden -fno-wrapv -fno-exceptions -pthread
    cc1: warning: command line option ‘-std=c++11’ is valid for C++/ObjC++ but not for C [enabled by default]
    cc1: warning: command line option ‘-std=c++11’ is valid for C++/ObjC++ but not for C [enabled by default]
    gcc -pthread -fno-strict-aliasing -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -DNDEBUG -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions-fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -fPIC -D_WIN32_WINNT=1536 -DGPR_BACKWARDS_COMPATIBILITY_MODE=1 -DHAVE_CONFIG_H=1 -DGRPC_ENABLE_FORK_SUPPORT=1 -DPyMODINIT_FUNC=extern ""C"" __attribute__((visibility (""default""))) void -DGRPC_POSIX_FORK_ALLOW_PTHREAD_ATFORK=1 -Isrc/python/grpcio -Iinclude -I. -Ithird_party/abseil-cpp -Ithird_party/address_sorting/include -Ithird_party/cares -Ithird_party/cares/cares -Ithird_party/cares/config_linux -Ithird_party/re2 -Ithird_party/boringssl-with-bazel/src/include -Ithird_party/upb -Isrc/core/ext/upb-generated -Isrc/core/ext/upbdefs-generated -Ithird_party/zlib -I/usr/include/python2.7 -c src/core/ext/upb-generated/google/protobuf/descriptor.upb.c -o python_build/temp.linux-x86_64-2.7/src/core/ext/upb-generated/google/protobuf/descriptor.upb.o -std=c++11 -std=gnu99 -fvisibility=hidden -fno-wrapv -fno-exceptions -pthread
    cc1: warning: command line option ‘-std=c++11’ is valid for C++/ObjC++ but not for C [enabled by default]
    gcc -pthread -fno-strict-aliasing -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -DNDEBUG -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions-fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -fPIC -D_WIN32_WINNT=1536 -DGPR_BACKWARDS_COMPATIBILITY_MODE=1 -DHAVE_CONFIG_H=1 -DGRPC_ENABLE_FORK_SUPPORT=1 -DPyMODINIT_FUNC=extern ""C"" __attribute__((visibility (""default""))) void -DGRPC_POSIX_FORK_ALLOW_PTHREAD_ATFORK=1 -Isrc/python/grpcio -Iinclude -I. -Ithird_party/abseil-cpp -Ithird_party/address_sorting/include -Ithird_party/cares -Ithird_party/cares/cares -Ithird_party/cares/config_linux -Ithird_party/re2 -Ithird_party/boringssl-with-bazel/src/include -Ithird_party/upb -Isrc/core/ext/upb-generated -Isrc/core/ext/upbdefs-generated -Ithird_party/zlib -I/usr/include/python2.7 -c src/core/ext/upb-generated/envoy/config/listener/v3/udp_listener_config.upb.c -o python_build/temp.linux-x86_64-2.7/src/core/ext/upb-generated/envoy/config/listener/v3/udp_listener_config.upb.o -std=c++11 -std=gnu99 -fvisibility=hidden -fno-wrapv -fno-exceptions -pthread
    Traceback (most recent call last):
      File ""<string>"", line 1, in <module>
      File ""/tmp/pip-build-KkOhKw/grpcio/setup.py"", line 488, in <module>
        cmdclass=COMMAND_CLASS,
      File ""/usr/lib64/python2.7/distutils/core.py"", line 152, in setup
    cc1: warning: command line option ‘-std=c++11’ is valid for C++/ObjC++ but not for C [enabled by default]
    gcc -pthread -fno-strict-aliasing -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -DNDEBUG -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions-fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -fPIC -D_WIN32_WINNT=1536 -DGPR_BACKWARDS_COMPATIBILITY_MODE=1 -DHAVE_CONFIG_H=1 -DGRPC_ENABLE_FORK_SUPPORT=1 -DPyMODINIT_FUNC=extern ""C"" __attribute__((visibility (""default""))) void -DGRPC_POSIX_FORK_ALLOW_PTHREAD_ATFORK=1 -Isrc/python/grpcio -Iinclude -I. -Ithird_party/abseil-cpp -Ithird_party/address_sorting/include -Ithird_party/cares -Ithird_party/cares/cares -Ithird_party/cares/config_linux -Ithird_party/re2 -Ithird_party/boringssl-with-bazel/src/include -Ithird_party/upb -Isrc/core/ext/upb-generated -Isrc/core/ext/upbdefs-generated -Ithird_party/zlib -I/usr/include/python2.7 -c src/core/ext/upb-generated/envoy/service/route/v3/srds.upb.c -o python_build/temp.linux-x86_64-2.7/src/core/ext/upb-generated/envoy/service/route/v3/srds.upb.o -std=c++11 -std=gnu99 -fvisibility=hidden -fno-wrapv -fno-exceptions -pthread
        dist.run_commands()
      File ""/usr/lib64/python2.7/distutils/dist.py"", line 953, in run_commands
        self.run_command(cmd)
      File ""/usr/lib64/python2.7/distutils/dist.py"", line 972, in run_command
        cmd_obj.run()
      File ""/home/vagdevi4768/dd/lib/python2.7/site-packages/setuptools/command/install.py"", line 61, in run
        return orig.install.run(self)
      File ""/usr/lib64/python2.7/distutils/command/install.py"", line 563, in run
        self.run_command('build')
      File ""/usr/lib64/python2.7/distutils/cmd.py"", line 326, in run_command
        self.distribution.run_command(command)
    cc1plus: warning: command line option ‘-std=gnu99’ is valid for C/ObjC but not for C++ [enabled by default]
      File ""/usr/lib64/python2.7/distutils/dist.py"", line 972, in run_command
        cmd_obj.run()
      File ""/usr/lib64/python2.7/distutils/command/build.py"", line 127, in run
        self.run_command(cmd_name)
      File ""/usr/lib64/python2.7/distutils/cmd.py"", line 326, in run_command
        self.distribution.run_command(command)
      File ""/usr/lib64/python2.7/distutils/dist.py"", line 972, in run_command
        cmd_obj.run()
      File ""/home/vagdevi4768/dd/lib/python2.7/site-packages/setuptools/command/build_ext.py"", line 75, in run
        _build_ext.run(self)
      File ""/usr/lib64/python2.7/distutils/command/build_ext.py"", line 339, in run
        self.build_extensions()
      File ""/tmp/pip-build-KkOhKw/grpcio/src/python/grpcio/commands.py"", line 272, in build_extensions
        ""Failed `build_ext` step:\n{}"".format(formatted_exception))
    commands.CommandError: Failed `build_ext` step:
    Traceback (most recent call last):
      File ""/tmp/pip-build-KkOhKw/grpcio/src/python/grpcio/commands.py"", line 267, in build_extensions
        build_ext.build_ext.build_extensions(self)
      File ""/usr/lib64/python2.7/distutils/command/build_ext.py"", line 448, in build_extensions
        self.build_extension(ext)
      File ""/home/vagdevi4768/dd/lib/python2.7/site-packages/setuptools/command/build_ext.py"", line 196, in build_extension
        _build_ext.build_extension(self, ext)
      File ""/usr/lib64/python2.7/distutils/command/build_ext.py"", line 498, in build_extension
        depends=ext.depends)
      File ""/tmp/pip-build-KkOhKw/grpcio/src/python/grpcio/_parallel_compile_patch.py"", line 59, in _parallel_compile
        _compile_single_file, objects)
      File ""/usr/lib64/python2.7/multiprocessing/pool.py"", line 250, in map
        return self.map_async(func, iterable, chunksize).get()
      File ""/usr/lib64/python2.7/multiprocessing/pool.py"", line 554, in get
        raise self._value
    CompileError: command 'gcc' failed with exit status 1

    gcc -pthread -fno-strict-aliasing -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -DNDEBUG -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions-fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -fPIC -D_WIN32_WINNT=1536 -DGPR_BACKWARDS_COMPATIBILITY_MODE=1 -DHAVE_CONFIG_H=1 -DGRPC_ENABLE_FORK_SUPPORT=1 -DPyMODINIT_FUNC=extern ""C"" __attribute__((visibility (""default""))) void -DGRPC_POSIX_FORK_ALLOW_PTHREAD_ATFORK=1 -Isrc/python/grpcio -Iinclude -I. -Ithird_party/abseil-cpp -Ithird_party/address_sorting/include -Ithird_party/cares -Ithird_party/cares/cares -Ithird_party/cares/config_linux -Ithird_party/re2 -Ithird_party/boringssl-with-bazel/src/include -Ithird_party/upb -Isrc/core/ext/upb-generated -Isrc/core/ext/upbdefs-generated -Ithird_party/zlib -I/usr/include/python2.7 -c src/core/ext/upbdefs-generated/envoy/service/route/v3/rds.upbdefs.c -o python_build/temp.linux-x86_64-2.7/src/core/ext/upbdefs-generated/envoy/service/route/v3/rds.upbdefs.o -std=c++11 -std=gnu99 -fvisibility=hidden -fno-wrapv -fno-exceptions -pthread
    cc1: warning: command line option ‘-std=c++11’ is valid for C++/ObjC++ but not for C [enabled by default]
    gcc -pthread -fno-strict-aliasing -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -DNDEBUG -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions-fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -fPIC -D_WIN32_WINNT=1536 -DGPR_BACKWARDS_COMPATIBILITY_MODE=1 -DHAVE_CONFIG_H=1 -DGRPC_ENABLE_FORK_SUPPORT=1 -DPyMODINIT_FUNC=extern ""C"" __attribute__((visibility (""default""))) void -DGRPC_POSIX_FORK_ALLOW_PTHREAD_ATFORK=1 -Isrc/python/grpcio -Iinclude -I. -Ithird_party/abseil-cpp -Ithird_party/address_sorting/include -Ithird_party/cares -Ithird_party/cares/cares -Ithird_party/cares/config_linux -Ithird_party/re2 -Ithird_party/boringssl-with-bazel/src/include -Ithird_party/upb -Isrc/core/ext/upb-generated -Isrc/core/ext/upbdefs-generated -Ithird_party/zlib -I/usr/include/python2.7 -c src/core/lib/gpr/cpu_linux.cc -o python_build/temp.linux-x86_64-2.7/src/core/lib/gpr/cpu_linux.o -std=c++11 -std=gnu99 -fvisibility=hidden -fno-wrapv -fno-exceptions -pthread
    cc1: warning: command line option ‘-std=c++11’ is valid for C++/ObjC++ but not for C [enabled by default]
    gcc -pthread -fno-strict-aliasing -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -DNDEBUG -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions-fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -fPIC -D_WIN32_WINNT=1536 -DGPR_BACKWARDS_COMPATIBILITY_MODE=1 -DHAVE_CONFIG_H=1 -DGRPC_ENABLE_FORK_SUPPORT=1 -DPyMODINIT_FUNC=extern ""C"" __attribute__((visibility (""default""))) void -DGRPC_POSIX_FORK_ALLOW_PTHREAD_ATFORK=1 -Isrc/python/grpcio -Iinclude -I. -Ithird_party/abseil-cpp -Ithird_party/address_sorting/include -Ithird_party/cares -Ithird_party/cares/cares -Ithird_party/cares/config_linux -Ithird_party/re2 -Ithird_party/boringssl-with-bazel/src/include -Ithird_party/upb -Isrc/core/ext/upb-generated -Isrc/core/ext/upbdefs-generated -Ithird_party/zlib -I/usr/include/python2.7 -c src/core/ext/upbdefs-generated/envoy/config/core/v3/base.upbdefs.c -o python_build/temp.linux-x86_64-2.7/src/core/ext/upbdefs-generated/envoy/config/core/v3/base.upbdefs.o -std=c++11 -std=gnu99 -fvisibility=hidden -fno-wrapv -fno-exceptions -pthread
    cc1plus: warning: command line option ‘-std=gnu99’ is valid for C/ObjC but not for C++ [enabled by default]
    gcc -pthread -fno-strict-aliasing -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -DNDEBUG -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions-fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -fPIC -D_WIN32_WINNT=1536 -DGPR_BACKWARDS_COMPATIBILITY_MODE=1 -DHAVE_CONFIG_H=1 -DGRPC_ENABLE_FORK_SUPPORT=1 -DPyMODINIT_FUNC=extern ""C"" __attribute__((visibility (""default""))) void -DGRPC_POSIX_FORK_ALLOW_PTHREAD_ATFORK=1 -Isrc/python/grpcio -Iinclude -I. -Ithird_party/abseil-cpp -Ithird_party/address_sorting/include -Ithird_party/cares -Ithird_party/cares/cares -Ithird_party/cares/config_linux -Ithird_party/re2 -Ithird_party/boringssl-with-bazel/src/include -Ithird_party/upb -Isrc/core/ext/upb-generated -Isrc/core/ext/upbdefs-generated -Ithird_party/zlib -I/usr/include/python2.7 -c src/core/ext/upbdefs-generated/google/protobuf/duration.upbdefs.c -o python_build/temp.linux-x86_64-2.7/src/core/ext/upbdefs-generated/google/protobuf/duration.upbdefs.o -std=c++11 -std=gnu99 -fvisibility=hidden -fno-wrapv -fno-exceptions -pthread
    gcc -pthread -fno-strict-aliasing -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -DNDEBUG -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions-fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -fPIC -D_WIN32_WINNT=1536 -DGPR_BACKWARDS_COMPATIBILITY_MODE=1 -DHAVE_CONFIG_H=1 -DGRPC_ENABLE_FORK_SUPPORT=1 -DPyMODINIT_FUNC=extern ""C"" __attribute__((visibility (""default""))) void -DGRPC_POSIX_FORK_ALLOW_PTHREAD_ATFORK=1 -Isrc/python/grpcio -Iinclude -I. -Ithird_party/abseil-cpp -Ithird_party/address_sorting/include -Ithird_party/cares -Ithird_party/cares/cares -Ithird_party/cares/config_linux -Ithird_party/re2 -Ithird_party/boringssl-with-bazel/src/include -Ithird_party/upb -Isrc/core/ext/upb-generated -Isrc/core/ext/upbdefs-generated -Ithird_party/zlib -I/usr/include/python2.7 -c src/core/ext/upbdefs-generated/validate/validate.upbdefs.c -o python_build/temp.linux-x86_64-2.7/src/core/ext/upbdefs-generated/validate/validate.upbdefs.o -std=c++11 -std=gnu99 -fvisibility=hidden -fno-wrapv -fno-exceptions -pthread
    cc1: warning: command line option ‘-std=c++11’ is valid for C++/ObjC++ but not for C [enabled by default]
    gcc -pthread -fno-strict-aliasing -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -DNDEBUG -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions-fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -fPIC -D_WIN32_WINNT=1536 -DGPR_BACKWARDS_COMPATIBILITY_MODE=1 -DHAVE_CONFIG_H=1 -DGRPC_ENABLE_FORK_SUPPORT=1 -DPyMODINIT_FUNC=extern ""C"" __attribute__((visibility (""default""))) void -DGRPC_POSIX_FORK_ALLOW_PTHREAD_ATFORK=1 -Isrc/python/grpcio -Iinclude -I. -Ithird_party/abseil-cpp -Ithird_party/address_sorting/include -Ithird_party/cares -Ithird_party/cares/cares -Ithird_party/cares/config_linux -Ithird_party/re2 -Ithird_party/boringssl-with-bazel/src/include -Ithird_party/upb -Isrc/core/ext/upb-generated -Isrc/core/ext/upbdefs-generated -Ithird_party/zlib -I/usr/include/python2.7 -c src/core/lib/gpr/sync_abseil.cc -o python_build/temp.linux-x86_64-2.7/src/core/lib/gpr/sync_abseil.o -std=c++11 -std=gnu99 -fvisibility=hidden -fno-wrapv -fno-exceptions -pthread
    cc1: warning: command line option ‘-std=c++11’ is valid for C++/ObjC++ but not for C [enabled by default]
    cc1: warning: command line option ‘-std=c++11’ is valid for C++/ObjC++ but not for C [enabled by default]
    gcc -pthread -fno-strict-aliasing -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -DNDEBUG -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions-fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -fPIC -D_WIN32_WINNT=1536 -DGPR_BACKWARDS_COMPATIBILITY_MODE=1 -DHAVE_CONFIG_H=1 -DGRPC_ENABLE_FORK_SUPPORT=1 -DPyMODINIT_FUNC=extern ""C"" __attribute__((visibility (""default""))) void -DGRPC_POSIX_FORK_ALLOW_PTHREAD_ATFORK=1 -Isrc/python/grpcio -Iinclude -I. -Ithird_party/abseil-cpp -Ithird_party/address_sorting/include -Ithird_party/cares -Ithird_party/cares/cares -Ithird_party/cares/config_linux -Ithird_party/re2 -Ithird_party/boringssl-with-bazel/src/include -Ithird_party/upb -Isrc/core/ext/upb-generated -Isrc/core/ext/upbdefs-generated -Ithird_party/zlib -I/usr/include/python2.7 -c src/core/ext/upb-generated/envoy/config/rbac/v3/rbac.upb.c -o python_build/temp.linux-x86_64-2.7/src/core/ext/upb-generated/envoy/config/rbac/v3/rbac.upb.o -std=c++11 -std=gnu99 -fvisibility=hidden -fno-wrapv -fno-exceptions -pthread
    gcc -pthread -fno-strict-aliasing -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -DNDEBUG -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions-fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -fPIC -D_WIN32_WINNT=1536 -DGPR_BACKWARDS_COMPATIBILITY_MODE=1 -DHAVE_CONFIG_H=1 -DGRPC_ENABLE_FORK_SUPPORT=1 -DPyMODINIT_FUNC=extern ""C"" __attribute__((visibility (""default""))) void -DGRPC_POSIX_FORK_ALLOW_PTHREAD_ATFORK=1 -Isrc/python/grpcio -Iinclude -I. -Ithird_party/abseil-cpp -Ithird_party/address_sorting/include -Ithird_party/cares -Ithird_party/cares/cares -Ithird_party/cares/config_linux -Ithird_party/re2 -Ithird_party/boringssl-with-bazel/src/include -Ithird_party/upb -Isrc/core/ext/upb-generated -Isrc/core/ext/upbdefs-generated -Ithird_party/zlib -I/usr/include/python2.7 -c src/core/ext/upbdefs-generated/envoy/service/route/v3/srds.upbdefs.c -o python_build/temp.linux-x86_64-2.7/src/core/ext/upbdefs-generated/envoy/service/route/v3/srds.upbdefs.o -std=c++11 -std=gnu99 -fvisibility=hidden -fno-wrapv -fno-exceptions -pthread
    cc1plus: warning: command line option ‘-std=gnu99’ is valid for C/ObjC but not for C++ [enabled by default]
    gcc -pthread -fno-strict-aliasing -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -DNDEBUG -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions-fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -fPIC -D_WIN32_WINNT=1536 -DGPR_BACKWARDS_COMPATIBILITY_MODE=1 -DHAVE_CONFIG_H=1 -DGRPC_ENABLE_FORK_SUPPORT=1 -DPyMODINIT_FUNC=extern ""C"" __attribute__((visibility (""default""))) void -DGRPC_POSIX_FORK_ALLOW_PTHREAD_ATFORK=1 -Isrc/python/grpcio -Iinclude -I. -Ithird_party/abseil-cpp -Ithird_party/address_sorting/include -Ithird_party/cares -Ithird_party/cares/cares -Ithird_party/cares/config_linux -Ithird_party/re2 -Ithird_party/boringssl-with-bazel/src/include -Ithird_party/upb -Isrc/core/ext/upb-generated -Isrc/core/ext/upbdefs-generated -Ithird_party/zlib -I/usr/include/python2.7 -c src/core/lib/gpr/cpu_posix.cc -o python_build/temp.linux-x86_64-2.7/src/core/lib/gpr/cpu_posix.o -std=c++11 -std=gnu99 -fvisibility=hidden -fno-wrapv -fno-exceptions -pthread
    cc1: warning: command line option ‘-std=c++11’ is valid for C++/ObjC++ but not for C [enabled by default]
    cc1: warning: command line option ‘-std=c++11’ is valid for C++/ObjC++ but not for C [enabled by default]
    gcc -pthread -fno-strict-aliasing -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -DNDEBUG -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions-fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -fPIC -D_WIN32_WINNT=1536 -DGPR_BACKWARDS_COMPATIBILITY_MODE=1 -DHAVE_CONFIG_H=1 -DGRPC_ENABLE_FORK_SUPPORT=1 -DPyMODINIT_FUNC=extern ""C"" __attribute__((visibility (""default""))) void -DGRPC_POSIX_FORK_ALLOW_PTHREAD_ATFORK=1 -Isrc/python/grpcio -Iinclude -I. -Ithird_party/abseil-cpp -Ithird_party/address_sorting/include -Ithird_party/cares -Ithird_party/cares/cares -Ithird_party/cares/config_linux -Ithird_party/re2 -Ithird_party/boringssl-with-bazel/src/include -Ithird_party/upb -Isrc/core/ext/upb-generated -Isrc/core/ext/upbdefs-generated -Ithird_party/zlib -I/usr/include/python2.7 -c src/core/ext/upb-generated/envoy/type/matcher/v3/metadata.upb.c -o python_build/temp.linux-x86_64-2.7/src/core/ext/upb-generated/envoy/type/matcher/v3/metadata.upb.o -std=c++11 -std=gnu99 -fvisibility=hidden -fno-wrapv -fno-exceptions -pthread
    cc1: warning: command line option ‘-std=c++11’ is valid for C++/ObjC++ but not for C [enabled by default]
    gcc -pthread -fno-strict-aliasing -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -DNDEBUG -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions-fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -fPIC -D_WIN32_WINNT=1536 -DGPR_BACKWARDS_COMPATIBILITY_MODE=1 -DHAVE_CONFIG_H=1 -DGRPC_ENABLE_FORK_SUPPORT=1 -DPyMODINIT_FUNC=extern ""C"" __attribute__((visibility (""default""))) void -DGRPC_POSIX_FORK_ALLOW_PTHREAD_ATFORK=1 -Isrc/python/grpcio -Iinclude -I. -Ithird_party/abseil-cpp -Ithird_party/address_sorting/include -Ithird_party/cares -Ithird_party/cares/cares -Ithird_party/cares/config_linux -Ithird_party/re2 -Ithird_party/boringssl-with-bazel/src/include -Ithird_party/upb -Isrc/core/ext/upb-generated -Isrc/core/ext/upbdefs-generated -Ithird_party/zlib -I/usr/include/python2.7 -c src/core/lib/gprpp/mpscq.cc -o python_build/temp.linux-x86_64-2.7/src/core/lib/gprpp/mpscq.o -std=c++11 -std=gnu99 -fvisibility=hidden -fno-wrapv -fno-exceptions -pthread
    cc1plus: warning: command line option ‘-std=gnu99’ is valid for C/ObjC but not for C++ [enabled by default]
    gcc -pthread -fno-strict-aliasing -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -DNDEBUG -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions-fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -fPIC -D_WIN32_WINNT=1536 -DGPR_BACKWARDS_COMPATIBILITY_MODE=1 -DHAVE_CONFIG_H=1 -DGRPC_ENABLE_FORK_SUPPORT=1 -DPyMODINIT_FUNC=extern ""C"" __attribute__((visibility (""default""))) void -DGRPC_POSIX_FORK_ALLOW_PTHREAD_ATFORK=1 -Isrc/python/grpcio -Iinclude -I. -Ithird_party/abseil-cpp -Ithird_party/address_sorting/include -Ithird_party/cares -Ithird_party/cares/cares -Ithird_party/cares/config_linux -Ithird_party/re2 -Ithird_party/boringssl-with-bazel/src/include -Ithird_party/upb -Isrc/core/ext/upb-generated -Isrc/core/ext/upbdefs-generated -Ithird_party/zlib -I/usr/include/python2.7 -c src/core/lib/iomgr/endpoint_pair_uv.cc -o python_build/temp.linux-x86_64-2.7/src/core/lib/iomgr/endpoint_pair_uv.o -std=c++11 -std=gnu99 -fvisibility=hidden -fno-wrapv -fno-exceptions -pthread
    gcc -pthread -fno-strict-aliasing -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -DNDEBUG -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions-fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -fPIC -D_WIN32_WINNT=1536 -DGPR_BACKWARDS_COMPATIBILITY_MODE=1 -DHAVE_CONFIG_H=1 -DGRPC_ENABLE_FORK_SUPPORT=1 -DPyMODINIT_FUNC=extern ""C"" __attribute__((visibility (""default""))) void -DGRPC_POSIX_FORK_ALLOW_PTHREAD_ATFORK=1 -Isrc/python/grpcio -Iinclude -I. -Ithird_party/abseil-cpp -Ithird_party/address_sorting/include -Ithird_party/cares -Ithird_party/cares/cares -Ithird_party/cares/config_linux -Ithird_party/re2 -Ithird_party/boringssl-with-bazel/src/include -Ithird_party/upb -Isrc/core/ext/upb-generated -Isrc/core/ext/upbdefs-generated -Ithird_party/zlib -I/usr/include/python2.7 -c src/core/lib/gpr/cpu_windows.cc -o python_build/temp.linux-x86_64-2.7/src/core/lib/gpr/cpu_windows.o -std=c++11 -std=gnu99 -fvisibility=hidden -fno-wrapv -fno-exceptions -pthread
    cc1plus: warning: command line option ‘-std=gnu99’ is valid for C/ObjC but not for C++ [enabled by default]
    gcc -pthread -fno-strict-aliasing -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -DNDEBUG -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions-fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -fPIC -D_WIN32_WINNT=1536 -DGPR_BACKWARDS_COMPATIBILITY_MODE=1 -DHAVE_CONFIG_H=1 -DGRPC_ENABLE_FORK_SUPPORT=1 -DPyMODINIT_FUNC=extern ""C"" __attribute__((visibility (""default""))) void -DGRPC_POSIX_FORK_ALLOW_PTHREAD_ATFORK=1 -Isrc/python/grpcio -Iinclude -I. -Ithird_party/abseil-cpp -Ithird_party/address_sorting/include -Ithird_party/cares -Ithird_party/cares/cares -Ithird_party/cares/config_linux -Ithird_party/re2 -Ithird_party/boringssl-with-bazel/src/include -Ithird_party/upb -Isrc/core/ext/upb-generated -Isrc/core/ext/upbdefs-generated -Ithird_party/zlib -I/usr/include/python2.7 -c src/core/lib/iomgr/gethostname_host_name_max.cc -o python_build/temp.linux-x86_64-2.7/src/core/lib/iomgr/gethostname_host_name_max.o -std=c++11 -std=gnu99 -fvisibility=hidden -fno-wrapv -fno-exceptions -pthread
    cc1: warning: command line option ‘-std=c++11’ is valid for C++/ObjC++ but not for C [enabled by default]
    gcc -pthread -fno-strict-aliasing -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -DNDEBUG -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions-fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -fPIC -D_WIN32_WINNT=1536 -DGPR_BACKWARDS_COMPATIBILITY_MODE=1 -DHAVE_CONFIG_H=1 -DGRPC_ENABLE_FORK_SUPPORT=1 -DPyMODINIT_FUNC=extern ""C"" __attribute__((visibility (""default""))) void -DGRPC_POSIX_FORK_ALLOW_PTHREAD_ATFORK=1 -Isrc/python/grpcio -Iinclude -I. -Ithird_party/abseil-cpp -Ithird_party/address_sorting/include -Ithird_party/cares -Ithird_party/cares/cares -Ithird_party/cares/config_linux -Ithird_party/re2 -Ithird_party/boringssl-with-bazel/src/include -Ithird_party/upb -Isrc/core/ext/upb-generated -Isrc/core/ext/upbdefs-generated -Ithird_party/zlib -I/usr/include/python2.7 -c src/core/lib/iomgr/poller/eventmanager_libuv.cc -o python_build/temp.linux-x86_64-2.7/src/core/lib/iomgr/poller/eventmanager_libuv.o -std=c++11 -std=gnu99 -fvisibility=hidden -fno-wrapv -fno-exceptions -pthread
    cc1plus: warning: command line option ‘-std=gnu99’ is valid for C/ObjC but not for C++ [enabled by default]
    cc1plus: warning: command line option ‘-std=gnu99’ is valid for C/ObjC but not for C++ [enabled by default]
    cc1plus: warning: command line option ‘-std=gnu99’ is valid for C/ObjC but not for C++ [enabled by default]
    gcc -pthread -fno-strict-aliasing -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -DNDEBUG -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions-fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -fPIC -D_WIN32_WINNT=1536 -DGPR_BACKWARDS_COMPATIBILITY_MODE=1 -DHAVE_CONFIG_H=1 -DGRPC_ENABLE_FORK_SUPPORT=1 -DPyMODINIT_FUNC=extern ""C"" __attribute__((visibility (""default""))) void -DGRPC_POSIX_FORK_ALLOW_PTHREAD_ATFORK=1 -Isrc/python/grpcio -Iinclude -I. -Ithird_party/abseil-cpp -Ithird_party/address_sorting/include -Ithird_party/cares -Ithird_party/cares/cares -Ithird_party/cares/config_linux -Ithird_party/re2 -Ithird_party/boringssl-with-bazel/src/include -Ithird_party/upb -Isrc/core/ext/upb-generated -Isrc/core/ext/upbdefs-generated -Ithird_party/zlib -I/usr/include/python2.7 -c src/core/lib/iomgr/endpoint_pair_windows.cc -o python_build/temp.linux-x86_64-2.7/src/core/lib/iomgr/endpoint_pair_windows.o -std=c++11 -std=gnu99 -fvisibility=hidden -fno-wrapv -fno-exceptions -pthread
    cc1plus: warning: command line option ‘-std=gnu99’ is valid for C/ObjC but not for C++ [enabled by default]
    gcc -pthread -fno-strict-aliasing -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -DNDEBUG -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions-fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -fPIC -D_WIN32_WINNT=1536 -DGPR_BACKWARDS_COMPATIBILITY_MODE=1 -DHAVE_CONFIG_H=1 -DGRPC_ENABLE_FORK_SUPPORT=1 -DPyMODINIT_FUNC=extern ""C"" __attribute__((visibility (""default""))) void -DGRPC_POSIX_FORK_ALLOW_PTHREAD_ATFORK=1 -Isrc/python/grpcio -Iinclude -I. -Ithird_party/abseil-cpp -Ithird_party/address_sorting/include -Ithird_party/cares -Ithird_party/cares/cares -Ithird_party/cares/config_linux -Ithird_party/re2 -Ithird_party/boringssl-with-bazel/src/include -Ithird_party/upb -Isrc/core/ext/upb-generated -Isrc/core/ext/upbdefs-generated -Ithird_party/zlib -I/usr/include/python2.7 -c src/core/lib/gpr/env_linux.cc -o python_build/temp.linux-x86_64-2.7/src/core/lib/gpr/env_linux.o -std=c++11 -std=gnu99 -fvisibility=hidden -fno-wrapv -fno-exceptions -pthread
    gcc -pthread -fno-strict-aliasing -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -DNDEBUG -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions-fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -fPIC -D_WIN32_WINNT=1536 -DGPR_BACKWARDS_COMPATIBILITY_MODE=1 -DHAVE_CONFIG_H=1 -DGRPC_ENABLE_FORK_SUPPORT=1 -DPyMODINIT_FUNC=extern ""C"" __attribute__((visibility (""default""))) void -DGRPC_POSIX_FORK_ALLOW_PTHREAD_ATFORK=1 -Isrc/python/grpcio -Iinclude -I. -Ithird_party/abseil-cpp -Ithird_party/address_sorting/include -Ithird_party/cares -Ithird_party/cares/cares -Ithird_party/cares/config_linux -Ithird_party/re2 -Ithird_party/boringssl-with-bazel/src/include -Ithird_party/upb -Isrc/core/ext/upb-generated -Isrc/core/ext/upbdefs-generated -Ithird_party/zlib -I/usr/include/python2.7 -c src/core/ext/upb-generated/envoy/config/route/v3/route.upb.c -o python_build/temp.linux-x86_64-2.7/src/core/ext/upb-generated/envoy/config/route/v3/route.upb.o -std=c++11 -std=gnu99 -fvisibility=hidden -fno-wrapv -fno-exceptions -pthread
    gcc -pthread -fno-strict-aliasing -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -DNDEBUG -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions-fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches -m64 -mtune=generic -D_GNU_SOURCE -fPIC -fwrapv -fPIC -D_WIN32_WINNT=1536 -DGPR_BACKWARDS_COMPATIBILITY_MODE=1 -DHAVE_CONFIG_H=1 -DGRPC_ENABLE_FORK_SUPPORT=1 -DPyMODINIT_FUNC=extern ""C"" __attribute__((visibility (""default""))) void -DGRPC_POSIX_FORK_ALLOW_PTHREAD_ATFORK=1 -Isrc/python/grpcio -Iinclude -I. -Ithird_party/abseil-cpp -Ithird_party/address_sorting/include -Ithird_party/cares -Ithird_party/cares/cares -Ithird_party/cares/config_linux -Ithird_party/re2 -Ithird_party/boringssl-with-bazel/src/include -Ithird_party/upb -Isrc/core/ext/upb-generated -Isrc/core/ext/upbdefs-generated -Ithird_party/zlib -I/usr/include/python2.7 -c src/core/lib/iomgr/gethostname_sysconf.cc -o python_build/temp.linux-x86_64-2.7/src/core/lib/iomgr/gethostname_sysconf.o -std=c++11 -std=gnu99 -fvisibility=hidden -fno-wrapv -fno-exceptions -pthread
    cc1plus: warning: command line option ‘-std=gnu99’ is valid for C/ObjC but not for C++ [enabled by default]
    cc1: warning: command line option ‘-std=c++11’ is valid for C++/ObjC++ but not for C [enabled by default]
    cc1plus: warning: command line option ‘-std=gnu99’ is valid for C/ObjC but not for C++ [enabled by default]
    cc1plus: warning: command line option ‘-std=gnu99’ is valid for C/ObjC but not for C++ [enabled by default]
    In file included from ./src/core/ext/filters/client_channel/service_config_parser.h:28:0,
                     from ./src/core/ext/filters/message_size/message_size_filter.h:22,
                     from src/core/ext/filters/message_size/message_size_filter.cc:19:
    src/core/ext/filters/message_size/message_size_filter.cc: In function ‘void recv_message_ready(void*, grpc_error*)’:
    src/core/ext/filters/message_size/message_size_filter.cc:207:56: error: no matching function for call to ‘StrFormat(const char [45], uint32_t, int&)’
                                 calld->limits.max_recv_size)
                                                            ^
    ./src/core/lib/iomgr/error.h:158:71: note: in definition of macro‘GRPC_ERROR_CREATE_FROM_COPIED_STRING’
       grpc_error_create(__FILE__, __LINE__, grpc_slice_from_copied_string(desc), \
     ^
    src/core/ext/filters/message_size/message_size_filter.cc:207:56: note: candidate is:
                                 calld->limits.max_recv_size)
                                                            ^
    ./src/core/lib/iomgr/error.h:158:71: note: in definition of macro‘GRPC_ERROR_CREATE_FROM_COPIED_STRING’
       grpc_error_create(__FILE__, __LINE__, grpc_slice_from_copied_string(desc), \
     ^
    In file included from src/core/ext/filters/message_size/message_size_filter.cc:24:0:
    third_party/abseil-cpp/absl/strings/str_format.h:338:34: note: template<class ... Args> std::string absl::lts_2020_09_23::StrFormat(absl::lts_2020_09_23::FormatSpec<Args ...>&, const Args& ...)
     ABSL_MUST_USE_RESULT std::string StrFormat(const FormatSpec<Args...>& format,
                                      ^
    third_party/abseil-cpp/absl/strings/str_format.h:338:34: note:   template argument deduction/substitution failed:
    In file included from ./src/core/ext/filters/client_channel/service_config_parser.h:28:0,
                     from ./src/core/ext/filters/message_size/message_size_filter.h:22,
                     from src/core/ext/filters/message_size/message_size_filter.cc:19:
    src/core/ext/filters/message_size/message_size_filter.cc:207:56: note:   mismatched types ‘absl::lts_2020_09_23::FormatSpec<Args ...>’ and ‘const char [45]’
                                 calld->limits.max_recv_size)
                                                            ^
    ./src/core/lib/iomgr/error.h:158:71: note: in definition of macro‘GRPC_ERROR_CREATE_FROM_COPIED_STRING’
       grpc_error_create(__FILE__, __LINE__, grpc_slice_from_copied_string(desc), \
     ^
    src/core/ext/filters/message_size/message_size_filter.cc: In function ‘void message_size_start_transport_stream_op_batch(grpc_call_element*, grpc_transport_stream_op_batch*)’:
    src/core/ext/filters/message_size/message_size_filter.cc:269:48: error: no matching function for call to ‘StrFormat(const char [41], uint32_t, int&)’
                         calld->limits.max_send_size)
                                                    ^
    ./src/core/lib/iomgr/error.h:158:71: note: in definition of macro‘GRPC_ERROR_CREATE_FROM_COPIED_STRING’
       grpc_error_create(__FILE__, __LINE__, grpc_slice_from_copied_string(desc), \
     ^
    src/core/ext/filters/message_size/message_size_filter.cc:269:48: note: candidate is:
                         calld->limits.max_send_size)
                                                    ^
    ./src/core/lib/iomgr/error.h:158:71: note: in definition of macro‘GRPC_ERROR_CREATE_FROM_COPIED_STRING’
       grpc_error_create(__FILE__, __LINE__, grpc_slice_from_copied_string(desc), \
     ^
    In file included from src/core/ext/filters/message_size/message_size_filter.cc:24:0:
    third_party/abseil-cpp/absl/strings/str_format.h:338:34: note: template<class ... Args> std::string absl::lts_2020_09_23::StrFormat(absl::lts_2020_09_23::FormatSpec<Args ...>&, const Args& ...)
     ABSL_MUST_USE_RESULT std::string StrFormat(const FormatSpec<Args...>& format,
                                      ^
    third_party/abseil-cpp/absl/strings/str_format.h:338:34: note:   template argument deduction/substitution failed:
    In file included from ./src/core/ext/filters/client_channel/service_config_parser.h:28:0,
                     from ./src/core/ext/filters/message_size/message_size_filter.h:22,
                     from src/core/ext/filters/message_size/message_size_filter.cc:19:
    src/core/ext/filters/message_size/message_size_filter.cc:269:48: note:   mismatched types ‘absl::lts_2020_09_23::FormatSpec<Args ...>’ and ‘const char [41]’
                         calld->limits.max_send_size)
                                                    ^
    ./src/core/lib/iomgr/error.h:158:71: note: in definition of macro‘GRPC_ERROR_CREATE_FROM_COPIED_STRING’
       grpc_error_create(__FILE__, __LINE__, grpc_slice_from_copied_string(desc), \
     ^
    src/core/ext/filters/client_channel/lb_policy/grpclb/grpclb.cc: In member function ‘virtual std::string grpc_core::{anonymous}::GrpcLb::TokenAndClientStatsAttribute::ToString() const’:
    src/core/ext/filters/client_channel/lb_policy/grpclb/grpclb.cc:278:49: error: no matching function for call to ‘StrFormat(const char [30], const string&, grpc_core::GrpcLbClientStats*)’
                                  client_stats_.get());
                                                     ^
    src/core/ext/filters/client_channel/lb_policy/grpclb/grpclb.cc:278:49: note: candidate is:
    In file included from src/core/ext/filters/client_channel/lb_policy/grpclb/grpclb.cc:69:0:
    third_party/abseil-cpp/absl/strings/str_format.h:338:34: note: template<class ... Args> std::string absl::lts_2020_09_23::StrFormat(absl::lts_2020_09_23::FormatSpec<Args ...>&, const Args& ...)
     ABSL_MUST_USE_RESULT std::string StrFormat(const FormatSpec<Args...>& format,
                                      ^
    third_party/abseil-cpp/absl/strings/str_format.h:338:34: note:   template argument deduction/substitution failed:
    src/core/ext/filters/client_channel/lb_policy/grpclb/grpclb.cc:278:49: note:   mismatched types ‘absl::lts_2020_09_23::FormatSpec<Args ...>’ and ‘const char [30]’
                                  client_stats_.get());
                                                     ^
    src/core/ext/filters/client_channel/lb_policy/grpclb/grpclb.cc: In member function ‘std::string grpc_core::{anonymous}::GrpcLb::Serverlist::AsText() const’:
    src/core/ext/filters/client_channel/lb_policy/grpclb/grpclb.cc:525:72: error: no matching function for call to ‘StrFormat(const char [20], size_t&, std::string&, const char [50])’
                                           ipport, server.load_balance_token));
      ^
    src/core/ext/filters/client_channel/lb_policy/grpclb/grpclb.cc:525:72: note: candidate is:
    In file included from src/core/ext/filters/client_channel/lb_policy/grpclb/grpclb.cc:69:0:
    third_party/abseil-cpp/absl/strings/str_format.h:338:34: note: template<class ... Args> std::string absl::lts_2020_09_23::StrFormat(absl::lts_2020_09_23::FormatSpec<Args ...>&, const Args& ...)
     ABSL_MUST_USE_RESULT std::string StrFormat(const FormatSpec<Args...>& format,
                                      ^
    third_party/abseil-cpp/absl/strings/str_format.h:338:34: note:   template argument deduction/substitution failed:
    src/core/ext/filters/client_channel/lb_policy/grpclb/grpclb.cc:525:72: note:   mismatched types ‘absl::lts_2020_09_23::FormatSpec<Args ...>’ and ‘const char [20]’
                                           ipport, server.load_balance_token));
      ^
    src/core/ext/filters/client_channel/lb_policy/grpclb/grpclb.cc: In member function ‘virtual std::string grpc_core::{anonymous}::GrpcLb::TokenAndClientStatsAttribute::ToString() const’:
    src/core/ext/filters/client_channel/lb_policy/grpclb/grpclb.cc:279:5: warning: control reaches end of non-void function [-Wreturn-type]
         }
         ^
    src/python/grpcio/grpc/_cython/cygrpc.cpp: In function ‘void __pyx_f_4grpc_7_cython_6cygrpc__unified_socket_write(int)’:
    src/python/grpcio/grpc/_cython/cygrpc.cpp:94016:46: warning: ignoring return value of ‘ssize_t write(int, const void*, size_t)’, declared with attribute warn_unused_result [-Wunused-result]
       (void)(write(__pyx_v_fd, ((char *)""1""), 1));
                                                  ^
    src/python/grpcio/grpc/_cython/cygrpc.cpp: In function ‘PyObject*__pyx_pw_4grpc_7_cython_6cygrpc_7Channel_9segregated_call(PyObject*, PyObject*, PyObject*)’:
    src/python/grpcio/grpc/_cython/cygrpc.cpp:30837:76: warning: ‘__pyx_v_c_completion_queue’ may be used uninitialized in this function [-Wmaybe-uninitialized]
       __pyx_v_segregated_call->_c_completion_queue = __pyx_v_c_completion_queue;
          ^
    src/python/grpcio/grpc/_cython/cygrpc.cpp:30471:26: note: ‘__pyx_v_c_completion_queue’ was declared here
       grpc_completion_queue *__pyx_v_c_completion_queue;
                              ^
    src/python/grpcio/grpc/_cython/cygrpc.cpp: At global scope:
    src/python/grpcio/grpc/_cython/cygrpc.cpp:184131:1: warning: ‘void __Pyx_PyAsyncGen_Fini()’ defined but not used [-Wunused-function]
     __Pyx_PyAsyncGen_Fini(void)
     ^

    ----------------------------------------
Command ""/home/vagdevik/dd/bin/python -u -c ""import setuptools, tokenize;__file__='/tmp/pip-build-KkOhKw/grpcio/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\r\n', '\n');f.close();exec(compile(code, __file__, 'exec'))"" install --record /tmp/pip-vnkkCk-record/install-record.txt --single-version-externally-managed --compile --install-headers /home/vagdevik/dd/include/site/python2.7/grpcio"" failed with error code 1 in /tmp/pip-build-KkOhKw/grpcio/
You are using pip version 9.0.1, however version 20.3.1 is available.
You should consider upgrading via the 'pip install --upgrade pip' command.
"
45444,Did not get operators or tensors in subgraph 1. when using tf.lite.Interpreter,"**tf version: 2.3.1** 

I saved a model of simple RNN and after quantitation, this model can not be reloaded by `tf.lite.Interpreter`
I tried other types of model such as textCNN, it still does not work.

If I remove the `converter.optimizations = [tf.lite.Optimize.DEFAULT] `, it succeed.
However, I cannot remove this command as it can significantly reduce the size of my model.
Any hints ?
Thanks.
```
def get_model_rnn():
    inputs = layers.Input(shape=(maxlen,))
    embedding = layers.Embedding(vocab_size, 128,  trainable=True)
    title_embed = embedding(inputs)
    title_ids_mask = layers.Masking(mask_value=0, name='mask')(title_embed)
    title_gru = layers.Bidirectional(layers.GRU(128, return_sequences=False))(title_ids_mask)
    outputs = layers.Dense(1, activation='sigmoid', name='mlp2')(title_gru) 
    model = keras.Model(inputs=inputs, outputs=outputs)
    model.compile(""Adam"", ""binary_crossentropy"", metrics=[""binary_accuracy""])
    return model 
model = get_model_rnn()
model.save('./model_rnn')

converter = tf.lite.TFLiteConverter.from_saved_model('./model_rnn')
#converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]
converter.optimizations = [tf.lite.Optimize.DEFAULT] # this caused the error
tflite_quant_model = converter.convert()
open(""model_rnn.tflite"", ""wb"").write(tflite_quant_model)

interpreter = tf.lite.Interpreter(model_path=""./model_rnn.tflite"")   
```


ERROR==>
```
In [27]: interpreter = tf.lite.Interpreter(model_path=""./model_rnn.tflite"")
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
<ipython-input-27-55e82bdec7e7> in <module>
----> 1 interpreter = tf.lite.Interpreter(model_path=""./model_rnn.tflite"")

/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/interpreter.py in __init__(self, model_path, model_content, experimental_delegates, num_threads)
    196       self._interpreter = (
    197           _interpreter_wrapper.CreateWrapperFromFile(
--> 198               model_path, self._custom_op_registerers))
    199       if not self._interpreter:
    200         raise ValueError('Failed to open {}'.format(model_path))

ValueError: Did not get operators or tensors in subgraph 1.
```"
45443,error when load the model use keras.models.load_model,"
**System information**

- OS Platform: Windows10
- TensorFlow version: 2.3.1
- Python version: 3.8.4
- CPU

I used AutoKeras generate a model and saved as 'tf' format.
model.save('ak_best_model', save_format='tf')
Then i use:
keras.models.load_model('ak_best_model')   in the same script
It works well...

But i open a new script and use Keras load the same model, error occured:

RuntimeError: Unable to restore a layer of class Custom>MultiCategoryEncoding. Layers of class Custom>MultiCategoryEncoding require that the class be provided to the model loading code, either by registering the class using @keras.utils.register_keras_serializable on the class def and including that file in your program, or by passing the class in a keras.utils.CustomObjectScope that wraps this load call.

here is my script:

df = pd.read_excel('total.xlsx', dtype=np.float32)

y = df[['Static_Fric', 'Rolling_Fric']].values
x = df.drop(labels = ['Static_Fric', 'Rolling_Fric'], axis =1)

x_train, x_test, y_train, y_test = train_test_split(
    x, y,
    test_size=0.2,
    shuffle=True
    )
keras_model = load_model(r'D:\Program Files\Desktop\ML\AutoKeras\ak_best_model')



"
45441,mixed_precision make train and predict very slow when only using cpu,"tensorflow : 2.3
Here is the [colab](https://colab.research.google.com/drive/1glypA7wC988kivuGe07Qfk_XHuq1j9aS?usp=sharing)
You can see that it costs 3s to train a epoch while costs 187s to train the same epoch using ```mixed_precision ```

```
Epoch 1/5
1875/1875 [==============================] - 3s 1ms/step - loss: 0.2968 - accuracy: 0.9134
Epoch 2/5
1875/1875 [==============================] - 3s 1ms/step - loss: 0.1448 - accuracy: 0.9575
Epoch 3/5
1875/1875 [==============================] - 2s 1ms/step - loss: 0.1073 - accuracy: 0.9678
Epoch 4/5
1875/1875 [==============================] - 3s 1ms/step - loss: 0.0861 - accuracy: 0.9730
Epoch 5/5
1875/1875 [==============================] - 3s 1ms/step - loss: 0.0734 - accuracy: 0.9769
```
vs
```
Epoch 1/5
1875/1875 [==============================] - 187s 100ms/step - loss: 0.2936 - accuracy: 0.9141
Epoch 2/5
1179/1875 [=================>............] - ETA: 1:11 - loss: 0.1455 - accuracy: 0.9555
```"
45437,"Keras: inconsistent behavior of ""embedded"" models","Not sure if this a bug (I am inclined to believe so) or not, but it looks strange/inconsistent to me...
Consider the following scenario (a simple ""embedded"" model case):
```python
m1 = Sequential([
    Input((100,)),
    Dense(20),
    Dense(10),
])

m2 = Sequential([
    Input((100,)),
    m1,
    Dense(5),
])
```

Now, assume that I would like to extract features from an internal layer of the models.
The following example works as expected:

```python
test1 = Model(m1.input, m1.layers[1].output)
test2 = Model(m2.input, m2.layers[1].output)
```

However, this one fails, even though I would expect it to be equivalent to `test1` above:
```python
test3 = Model(m2.input, m2.layers[0].layers[1].output)
```
The error is:
```python
ValueError: Graph disconnected: cannot obtain value for tensor Tensor(""input_3:0"", shape=(None, 100), dtype=float32) at layer ""dense_3"". The following previous layers were accessed without issue: []
```

It seems that the following ""trick"" does the job:
```python
test4 = Model(m2.layers[0].input, m2.layers[0].layers[1].output)
```

Now, there is another peculiarity, which seems rather annoying to me:
```python
m1.summary()

Model: ""sequential_2""
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_3 (Dense)              (None, 20)                2020      
_________________________________________________________________
dense_4 (Dense)              (None, 10)                210       
=================================================================
Total params: 2,230
Trainable params: 2,230
Non-trainable params: 0
_________________________________________________________________

```
The model has two layers (no input layer), whereas this one has three layers...

```python
test4.summary()

Model: ""functional_19""
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input_3 (InputLayer)         [(None, 100)]             0         
_________________________________________________________________
dense_3 (Dense)              (None, 20)                2020      
_________________________________________________________________
dense_4 (Dense)              (None, 10)                210       
=================================================================
Total params: 2,230
Trainable params: 2,230
Non-trainable params: 0
_________________________________________________________________
```

What is interesting `tf.keras.utils.plot_model` produces identical graphs (with input layers) for both `m1` and `test4`.
"
45436,Sparse.Softmax Example,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): 2.3.1
- Python version:3.8
- CUDA/cuDNN version: unsure
- GPU model and memory: unsure

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


Executing code at the tensorflow example does not work as described.
https://www.tensorflow.org/api_docs/python/tf/sparse/softmax#returns

```
import tensorflow as tf
import numpy as np

shape = [2, 2, 2]  # 3-D SparseTensor
values = np.asarray([[[0., np.e], [1., 0.]], [[np.e, 0.], [np.e, np.e]]])
indices = np.vstack(np.where(values)).astype(np.int64).T
result = tf.sparse.softmax(tf.sparse.SparseTensor(indices, values, shape))
```

Output:
Traceback (most recent call last):
  File ""/usr/local/pycharm-2020.1.2/plugins/python/helpers/pydev/_pydevd_bundle/pydevd_exec2.py"", line 3, in Exec
    exec(exp, global_vars, local_vars)
  File ""<string>"", line 7, in <module>
  File ""/home/jsidhom1/DeepTCR/venv/lib/python3.8/site-packages/tensorflow/python/framework/sparse_tensor.py"", line 145, in __init__
    values_shape = values.shape.with_rank(1)
  File ""/home/jsidhom1/DeepTCR/venv/lib/python3.8/site-packages/tensorflow/python/framework/tensor_shape.py"", line 1034, in with_rank
    raise ValueError(""Shape %s must have rank %d"" % (self, rank))
ValueError: Shape (2, 2, 2) must have rank 1

Expected behavior from website above.

```
import tensorflow as tf
import numpy as np

shape = [2, 2, 2]  # 3-D SparseTensor
values = np.asarray([[[0., np.e], [1., 0.]], [[np.e, 0.], [np.e, np.e]]])
indices = np.vstack(np.where(values)).astype(np.int64).T
result = tf.sparse.softmax(tf.sparse.SparseTensor(indices, values, shape))
```
"
45435,"ImportError: Traceback (most recent call last):   File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 64, in <module>     from tensorflow.python._pywrap_tensorflow_internal import * ImportError: DLL load failed: The specified module could not be found.","<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version:
- Python version:
- Installed using virtualenv? pip? conda?:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:



**Describe the problem**

ImportError                               Traceback (most recent call last)
C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow.py in <module>
     63   try:
---> 64     from tensorflow.python._pywrap_tensorflow_internal import *
     65   # This try catch logic is because there is no bazel equivalent for py_extension.

ImportError: DLL load failed: The specified module could not be found.

During handling of the above exception, another exception occurred:

ImportError                               Traceback (most recent call last)
<ipython-input-1-64156d691fe5> in <module>
----> 1 import tensorflow as tf

C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\__init__.py in <module>
     39 import sys as _sys
     40 
---> 41 from tensorflow.python.tools import module_util as _module_util
     42 from tensorflow.python.util.lazy_loader import LazyLoader as _LazyLoader
     43 

C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\__init__.py in <module>
     38 # pylint: disable=wildcard-import,g-bad-import-order,g-import-not-at-top
     39 
---> 40 from tensorflow.python.eager import context
     41 
     42 # pylint: enable=wildcard-import

C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\eager\context.py in <module>
     33 from tensorflow.core.protobuf import config_pb2
     34 from tensorflow.core.protobuf import rewriter_config_pb2
---> 35 from tensorflow.python import pywrap_tfe
     36 from tensorflow.python import tf2
     37 from tensorflow.python.client import pywrap_tf_session

C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\pywrap_tfe.py in <module>
     26 
     27 # pylint: disable=invalid-import-order,g-bad-import-order, wildcard-import, unused-import
---> 28 from tensorflow.python import pywrap_tensorflow
     29 from tensorflow.python._pywrap_tfe import *

C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow.py in <module>
     81 for some common reasons and solutions.  Include the entire stack trace
     82 above this error message when asking for help."""""" % traceback.format_exc()
---> 83   raise ImportError(msg)
     84 
     85 # pylint: enable=wildcard-import,g-import-not-at-top,unused-import,line-too-long

ImportError: Traceback (most recent call last):
  File ""C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 64, in <module>
    from tensorflow.python._pywrap_tensorflow_internal import *
ImportError: DLL load failed: The specified module could not be found.


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/errors

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.


**Provide the exact sequence of commands / steps that you executed before running into the problem**
import tensorflow as tf

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
45434,Whl package not building due with a issue with sed - MacOS 11,"**System information**
- OS Platform and Distribution: Mac OS 11.0.1 Big Sur
- TensorFlow installed from (source or binary): Source - git
- TensorFlow version: 2.4.0-rc4
- Python version: 3.8.6 (macports)
- Installed using virtualenv? pip? conda?: No
- Bazel version (if compiling from source): 3.1.0
- GCC/Compiler version (if compiling from source): Apple clang version 12.0.0 (clang-1200.0.32.27) XCode 12.2
- CUDA/cuDNN version: No
- GPU model and memory: AMD Radeon Pro 555X - 4GB



**Describe the problem**
Tensorflow compiles correctly. However, when using the command:

`bazel-bin/tensorflow/tools/pip_package/build_pip_package`

the whl package is not produced and rather the following error is shown:

`sed: /var/folders/y4/85hx48054tbd2y04jkf3l6880000gn/T/tmp.XXXXXXXXXX.Ty6dzcrU/tensorflow/__init__.py: in-place editing only works for regular files`

**Provide the exact sequence of commands / steps that you executed before running into the problem**

1. Compile from source as indicated in the tensorflow manual. 
2. Run the command to build the whl package:

`bazel-bin/tensorflow/tools/pip_package/build_pip_package ..`

**Any other info / logs**
This error is not present in MacOS 10.15. All proceed as it should
"
45433,Tensorflow/Keras Endpoint layer does not work with Tensorflow dataset in eager mode,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Google Colab, Mac OS
- TensorFlow version:
2.3.1
- Python version:
3.6.9

**Describe the current behavior**
The Endpoint layer pattern described in Tensorflow documents only works with Numpy arrays and it does not work with Tensorflow dataset
**Describe the expected behavior**
The Endpoint layer is expected to work with Tensorflow dataset as well

**Standalone code to reproduce the issue**
 This code is from Tensorflow documents that works only with Numpy arrays:

```
import tensorflow as tf
from tensorflow import keras
import numpy as np

class LogisticEndpoint(keras.layers.Layer):
    def __init__(self, name=None):
        super(LogisticEndpoint, self).__init__(name=name)
        self.loss_fn = keras.losses.BinaryCrossentropy(from_logits=True)
        self.accuracy_fn = keras.metrics.BinaryAccuracy()

    def call(self, targets, logits, sample_weights=None):
        # Compute the training-time loss value and add it
        # to the layer using `self.add_loss()`.
        loss = self.loss_fn(targets, logits, sample_weights)
        self.add_loss(loss)

        # Log accuracy as a metric and add it
        # to the layer using `self.add_metric()`.
        acc = self.accuracy_fn(targets, logits, sample_weights)
        self.add_metric(acc, name=""accuracy"")

        # Return the inference-time prediction tensor (for `.predict()`).
        return tf.nn.softmax(logits)

inputs = keras.Input(shape=(3,), name=""inputs"")
targets = keras.Input(shape=(10,), name=""targets"")
logits = keras.layers.Dense(10)(inputs)
predictions = LogisticEndpoint(name=""predictions"")(logits, targets)

model = keras.Model(inputs=[inputs, targets], outputs=predictions)
model.compile(optimizer=""adam"")

data = {
    ""inputs"": np.random.random((3, 3)),
    ""targets"": np.random.random((3, 10)),
}
model.fit(data)
```
**Experiment 1: Using TF dataset in a dictionary**
```
tf_data = {
    'inputs': tf.data.Dataset.from_tensor_slices(np.random.random((3, 3))), 
    'targets': tf.data.Dataset.from_tensor_slices(np.random.random((3, 10)))
}

model.fit(tf_data)
```

![tf1](https://user-images.githubusercontent.com/62025982/101292041-09feef80-37db-11eb-8eb7-2047cde45647.png)

**Experiment 2: TF dataset that contains tuples**
```
data = {
    ""inputs"": np.random.random((3, 3)),
    ""targets"": np.random.random((3, 10)),
}
tuple_data = []
for i in range(3):
  tuple_data.append((data['inputs'][i, :], data['targets'][i, :]))

dataset = tf.data.Dataset.from_generator(lambda: tuple_data, (tf.float32, tf.float32))

# to show the dataset content
for x in dataset:
  print(x)

model.fit(dataset)
```
![tf2](https://user-images.githubusercontent.com/62025982/101292452-8397dd00-37dd-11eb-871d-71bd1c113727.png)

**Colab link:**
[https://colab.research.google.com/drive/1zaAgPZ4U49t2PkIl7qdm348ayt7Z5O-0](url)"
45432,tf.keras.model.Model-subclassed models do not serialise tf.function-ed methods,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Have not tested
- TensorFlow installed from (source or binary): pip
- TensorFlow version (use command below): 2.5.0-dev20201206
- Python version: 3.7.7
- Bazel version (if compiling from source): n/a
- GCC/Compiler version (if compiling from source): n/a
- CUDA/cuDNN version: 11.0, 8.0.4
- GPU model and memory: NVidia Quatro 5000

**Describe the current behavior**
I have a model which implements a custom training step (tf.keras.models.Model.train_step), which all works fine until serialisation. I understand that because the `train_step` is python code, it needs to be saved as a `tf.function` (graph), and for that it should be decorated including an `input_signature`. However, saving and then reloading models decorated in this way does not seem to recover the custom `train_step`.

**Describe the expected behavior**

Methods decorated by `tf.function` including an `input_signature` should be seralised and loaded along with the weights, optimisers and losses.

**Standalone code to reproduce this issue** 

[Gist](https://colab.research.google.com/drive/1hGqE_s1YFKEFjovEO9Kb-US-5nLsCx6H?usp=sharing)

Thanks you in advance."
45431,micro: port op DIV from lite,"@tensorflow/micro

This issue tracks my work porting operator DIV from lite to micro.

The port will be submitted in a number of PRs. Here's a rough flight plan per @advaitjain and @petewarden:

PR 1: Extract the code for parsing the op from a flatbuffer out of ParseOpDataTfLite in tensorflow/lite/core/api/flatbuffer_conversions.cc into a standalone function that can be called from micro's op resolver
PR 2: Extract the reference implementation out of tensorflow/lite/kernels/internal/reference/reference_ops.h into its own header which can be included without dragging in reference_ops.h's dependences
PR 3: Copy operator from lite to micro without making any changes or including in the build
PR 4: Delete extra code from the micro copy of the operator
PR 5: Port micro copy of operator as necessary and add a corresponding test

"
45430, After installing tf-nightly tensorflow is not working on GPU,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below):
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**

**Describe the expected behavior**

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
45429,Page is not visible in Desktops ,"## URL(s) with the issue:
https://www.tensorflow.org/hub/tutorials/tf2_object_detection#utilities

## Description of the issue (what needs changing):
- The `Toggle-code` button is not working.
- Below page is cut from the left side
- Screenshot from crome
![Screenshot (96)](https://user-images.githubusercontent.com/43227010/101273854-36a50e00-37bf-11eb-8a9a-a5dd318612ea.png)
- Screenshot from firefox
![Screenshot (97)](https://user-images.githubusercontent.com/43227010/101273857-3b69c200-37bf-11eb-9e42-ef93c9d0bfeb.png)


"
45428,Tensorflow Estimator passes train data through some weird normalization before entering net,"**System information**
- Have I written custom code: Yes
- OS Platform and Distribution: Linux Ubuntu 18.04
- TensorFlow installed from: anaconda
- TensorFlow version: 2.2, but some parts of the networks use tf.compat.v1
- Python version: 3

**Describe the current behavior**

I am using tensorflow Estimator API, and have encountered a weird phenomenon. I am passing the exact same input_fn to both training and evaluation, and for some reason the images which are provided to the network are not identical. I use the tf.Estimator.train_and_evaluate, and use tensorboard to display the images that are passed to the model_fn. This means that these images are those that are later fed into the network, and are not an intermediate result from the network. The two images seem similar, but after taking a closer look, it seems that evaluation images are ok, but train images are somewhat distorted.

After loading them both, I noticed that for some reason the training images go through some kind of ReLu. I affirmed it with this code:

special_relu = lambda mat: ((mat - 0.5) / 0.5) * ((mat - 0.5) / 0.5 > 0)
np.allclose(mat_train, special_relu(mat_eval))
>>> True

**Describe the expected behavior**

The expected behaviour is that the evaluation images should be the same as the train images, such that:
np.allclose(mat_train, mat_eval)
>>> True

Clarification: The input_fn I provided is one that yields the exact same image over and over again, so the images that are drawn should all be the same, theoretically.

**What I thought and tried**

My initial thought was that it is some form of BatchNormalization. But BatchNormalization is supposed to happen within the network, and not as some preprocess, shouldn't it? What I recorded (using tf.summary.image) was the features['image'] object, passed to my model_fn. And if I understand correctly, the features object is passed to model_fn by the input_fn called by the Estimator object.

Regardless, I tried to remove the parts in the code which are supposed to call the BatchNormalization. This had no effect. Of course, I might have not done that in the right way, but as I said it I don't really think it is BatchNormalization."
45426,keras.model.predict doesn't work when using multiprocessing,"I am using scipy.optimize.differential_evolution to optimize my autoencoder weights. The individuals are 20 combination of weights.

`result = differential_evolution(obj_func, bounds, args=args, strategy='best1bin', maxiter=2, popsize=20, tol=1e-6, mutation=(0.5, 1), recombination=0.3, seed=None, callback=printCurrentIteration, disp=True, polish=False, init=pop, atol=0, updating='deferred', workers=5)`

In my obj_func there is a part to get output from keras.model.predict(), here is my naive code:

```
def obj_func(x, *args):
         final_output = predict(x, data_p)
         ……
```

```
def predict(para, data_p): 
    new_weight_e1 = para[0:352].reshape(22, 16)
    new_weight_b1 = para[352:368].reshape(16, )
    new_weight_e2 = para[368:496].reshape(16, 8)
    new_weight_b2 = para[496:504].reshape(8, )
    new_weight_e3 = para[504:520].reshape(8, 2)
    new_weight_b3 = para[520:522].reshape(2, )
    new_weight_d1 = para[522:538].reshape(2, 8)
    new_weight_b4 = para[538:546].reshape(8, )
    new_weight_d2 = para[546:674].reshape(8, 16)
    new_weight_b5 = para[674:690].reshape(16, )
    new_weight_d3 = para[690:1042].reshape(16, 22)
    new_weight_b6 = para[1042:1064].reshape(22, )
    autoencoder.get_layer('e1').set_weights([(new_weight_e1), (new_weight_b1)])
    autoencoder.get_layer('e2').set_weights([(new_weight_e2), (new_weight_b2)])
    autoencoder.get_layer('out').set_weights([(new_weight_e3), (new_weight_b3)])
    autoencoder.get_layer('d1').set_weights([(new_weight_d1), (new_weight_b4)])
    autoencoder.get_layer('d2').set_weights([(new_weight_d2), (new_weight_b5)])
    autoencoder.get_layer('d3').set_weights([(new_weight_d3), (new_weight_b6)])

    output_layer_model = Model(inputs=autoencoder.input, outputs=decoded)
    final_output = output_layer_model.predict(data_p)
    
    return final_output
```

In function `predict()` I reshape the individual(weights), build the model and predict. 
In differential_evolution people can easily implement multiprocessing by setting 'workers' to more than 1. 
When I set it to 1, there is no problem. But when I set it to e.g. 5, want to predict parallel, the progress stopped here:

` final_output = output_layer_model.predict(data_p)`

No errors, it was still running but did not go further (didn't get the `final_ouput`). (The code before this line goes parallel without problem)

What I've tried:
1.
add` os.environ[""CUDA_VISIBLE_DEVICES""] = ""-1""`, only use multiple CPUs to predict, didn't work for me.
2.
compile the model inside the function, also didn't work.
3.
save the weights as .h5 file and load, also didn't work.

Again, it works well when only using 1 CPU. So I think the problem might be `keras.model.predict()` and `multiprocessing` but I didn't figure it out. I've done some search but didn't find a solution, maybe I didn't grasp the point because my English is not good. So any suggestions or guidance will be appreciated!
"
45425,XLA dumped llvm IR: how to convert the ir to assembly code?,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): 2.2
- Are you willing to contribute it (Yes/No): Yes



**Describe the feature and the current behavior/state.**

Hi,

I want to inspect the assembly code that compiled by llvm, is there any method to do that?
I have tried to using llvm-as tool to conver the .ll file to .bc file but failed:(

Best Regards,
Gary

**Will this change the current api? How?**

maybe

**Who will benefit with this feature?**

compiler engineer

**Any Other info.**
"
45424,Traceback (most recent call last):,"can any one tell what has happen here 
![Capturea](https://user-images.githubusercontent.com/75528881/101243050-9057fa80-3723-11eb-977e-fcceef6f654c.JPG)
"
45423,cuDNN issue in TF,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- I use custom code
- Windows 10 Pro
- TensorFlow installed from pip
- TensorFlow version == 2.3.1
- python == 3.8.6
- CUDA/cuDNN version: 10.1 / 7.6.5
- GPU model and memory: GeForce RTX 2080 SUPER

**Describe the current behavior**

**Describe the expected behavior**

**Standalone code to reproduce the issue**

**Other info / logs**

```python
D:\00.dev\Anaconda\envs\jh-ip\python.exe D:/02.users/jaehochang/gits/Autoencoders/main.py
2020-12-05 14:22:07.727822: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudart64_101.dll
NVIDIA GPU info.:
[{'index': '0',
  'mem_total': 8192,
  'mem_used': 2475,
  'mem_used_percent': 30.21240234375,
  'type': 'GeForce RTX 2080 SUPER',
  'uuid': '...'}]

{'videos': ['D:/20.share/jaehochang/SP2Robotics/videos\\vid1.mp4',
            'D:/20.share/jaehochang/SP2Robotics/videos\\vid2.mkv',
            'D:/20.share/jaehochang/SP2Robotics/videos\\vid3.mkv']}
Videos found correctly? */n: 
Which video? 1/2/3/...: 3
Capturing vid3.mkv ...
Volume shape: (165, 1088, 1920, 3)
Write volume array? */n: 

Capturing vid3_AGN.avi ...
Volume shape: (165, 1088, 1920, 3)
Write volume array? */n: 

2020-12-05 14:22:40.544902: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library nvcuda.dll
2020-12-05 14:22:40.605546: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:08:00.0 name: GeForce RTX 2080 SUPER computeCapability: 7.5
coreClock: 1.815GHz coreCount: 48 deviceMemorySize: 8.00GiB deviceMemoryBandwidth: 462.00GiB/s
2020-12-05 14:22:40.605721: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudart64_101.dll
2020-12-05 14:22:41.024671: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cublas64_10.dll
2020-12-05 14:22:41.268418: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cufft64_10.dll
2020-12-05 14:22:41.292114: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library curand64_10.dll
2020-12-05 14:22:41.515595: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusolver64_10.dll
2020-12-05 14:22:41.712017: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusparse64_10.dll
2020-12-05 14:22:41.917475: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudnn64_7.dll
2020-12-05 14:22:41.917629: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2020-12-05 14:22:41.918243: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-12-05 14:22:41.926740: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x26380efa3e0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-12-05 14:22:41.926862: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-12-05 14:22:41.927041: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:08:00.0 name: GeForce RTX 2080 SUPER computeCapability: 7.5
coreClock: 1.815GHz coreCount: 48 deviceMemorySize: 8.00GiB deviceMemoryBandwidth: 462.00GiB/s
2020-12-05 14:22:41.927191: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudart64_101.dll
2020-12-05 14:22:41.927267: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cublas64_10.dll
2020-12-05 14:22:41.927337: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cufft64_10.dll
2020-12-05 14:22:41.927412: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library curand64_10.dll
2020-12-05 14:22:41.927484: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusolver64_10.dll
2020-12-05 14:22:41.927554: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cusparse64_10.dll
2020-12-05 14:22:41.927623: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudnn64_7.dll
2020-12-05 14:22:41.927717: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0
2020-12-05 14:22:42.588437: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-12-05 14:22:42.588531: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 
2020-12-05 14:22:42.588582: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N 
2020-12-05 14:22:42.588761: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6598 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 SUPER, pci bus id: 0000:08:00.0, compute capability: 7.5)
2020-12-05 14:22:42.591519: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x263ae5c79c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-12-05 14:22:42.591639: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce RTX 2080 SUPER, Compute Capability 7.5
Train volume shape:
   (99, 2, 432, 768, 3)
Test volume shape: 
   (66, 2, 432, 768, 3)


===== You're trying ...
mname:      vid3-AGN-500epc-1btc
=====

Proceed? */n: 
Virtual devices cannot be modified after being initialized
Your model:
Model: ""sequential""
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d (Conv2D)              (None, 432, 768, 36)      1008      
_________________________________________________________________
batch_normalization (BatchNo (None, 432, 768, 36)      144       
_________________________________________________________________
up_sampling2d (UpSampling2D) (None, 864, 1536, 36)     0         
_________________________________________________________________
batch_normalization_1 (Batch (None, 864, 1536, 36)     144       
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 864, 1536, 36)     11700     
_________________________________________________________________
batch_normalization_2 (Batch (None, 864, 1536, 36)     144       
_________________________________________________________________
max_pooling2d (MaxPooling2D) (None, 432, 768, 36)      0         
_________________________________________________________________
batch_normalization_3 (Batch (None, 432, 768, 36)      144       
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 432, 768, 3)       975       
=================================================================
Total params: 14,259
Trainable params: 13,971
Non-trainable params: 288
_________________________________________________________________
None
Fit? */n: 
Epoch 1/500
2020-12-05 14:22:51.499832: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cudnn64_7.dll
2020-12-05 14:22:52.667191: E tensorflow/stream_executor/cuda/cuda_dnn.cc:328] Could not create cudnn handle: CUDNN_STATUS_ALLOC_FAILED
2020-12-05 14:22:52.668713: E tensorflow/stream_executor/cuda/cuda_dnn.cc:328] Could not create cudnn handle: CUDNN_STATUS_ALLOC_FAILED
2020-12-05 14:22:52.668804: W tensorflow/core/framework/op_kernel.cc:1767] OP_REQUIRES failed at conv_ops_fused_impl.h:642 : Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.
Traceback (most recent call last):
  File ""D:/02.users/jaehochang/gits/Autoencoders/main.py"", line 55, in <module>
    history = my_model.fit(train[:, 1], train[:, 0],  # noisy train, clean train
  File ""D:\00.dev\Anaconda\envs\jh-ip\lib\site-packages\tensorflow\python\keras\engine\training.py"", line 108, in _method_wrapper
    return method(self, *args, **kwargs)
  File ""D:\00.dev\Anaconda\envs\jh-ip\lib\site-packages\tensorflow\python\keras\engine\training.py"", line 1098, in fit
    tmp_logs = train_function(iterator)
  File ""D:\00.dev\Anaconda\envs\jh-ip\lib\site-packages\tensorflow\python\eager\def_function.py"", line 780, in __call__
    result = self._call(*args, **kwds)
  File ""D:\00.dev\Anaconda\envs\jh-ip\lib\site-packages\tensorflow\python\eager\def_function.py"", line 840, in _call
    return self._stateless_fn(*args, **kwds)
  File ""D:\00.dev\Anaconda\envs\jh-ip\lib\site-packages\tensorflow\python\eager\function.py"", line 2829, in __call__
    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access
  File ""D:\00.dev\Anaconda\envs\jh-ip\lib\site-packages\tensorflow\python\eager\function.py"", line 1843, in _filtered_call
    return self._call_flat(
  File ""D:\00.dev\Anaconda\envs\jh-ip\lib\site-packages\tensorflow\python\eager\function.py"", line 1923, in _call_flat
    return self._build_call_outputs(self._inference_function.call(
  File ""D:\00.dev\Anaconda\envs\jh-ip\lib\site-packages\tensorflow\python\eager\function.py"", line 545, in call
    outputs = execute.execute(
  File ""D:\00.dev\Anaconda\envs\jh-ip\lib\site-packages\tensorflow\python\eager\execute.py"", line 59, in quick_execute
    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
tensorflow.python.framework.errors_impl.UnknownError:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.
	 [[node sequential/conv2d/Relu (defined at /02.users/jaehochang/gits/Autoencoders/main.py:55) ]] [Op:__inference_train_function_2470]

Function call stack:
train_function


Process finished with exit code 1
```"
45422,While running tenosrflow object detection code i got this error.,"

2020-12-05` 10:41:45.702033: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.2
Traceback (most recent call last):
  File ""Object_detection_picamera.py"", line 44, in <module>
    od_graph_def.ParseFromString(serialized_graph)
  File ""/usr/local/lib/python3.6/dist-packages/google/protobuf/message.py"", line 199, in ParseFromString
    return self.MergeFromString(serialized)
  File ""/usr/local/lib/python3.6/dist-packages/google/protobuf/internal/python_message.py"", line 1145, in MergeFromString
    if self._InternalParse(serialized, 0, length) != length:
  File ""/usr/local/lib/python3.6/dist-packages/google/protobuf/internal/python_message.py"", line 1212, in InternalParse
    pos = field_decoder(buffer, new_pos, end, self, field_dict)
  File ""/usr/local/lib/python3.6/dist-packages/google/protobuf/internal/decoder.py"", line 754, in DecodeField
    if value._InternalParse(buffer, pos, new_pos) != new_pos:
  File ""/usr/local/lib/python3.6/dist-packages/google/protobuf/internal/python_message.py"", line 1212, in InternalParse
    pos = field_decoder(buffer, new_pos, end, self, field_dict)
  File ""/usr/local/lib/python3.6/dist-packages/google/protobuf/internal/decoder.py"", line 733, in DecodeRepeatedField
    if value.add()._InternalParse(buffer, pos, new_pos) != new_pos:
  File ""/usr/local/lib/python3.6/dist-packages/google/protobuf/internal/python_message.py"", line 1212, in InternalParse
    pos = field_decoder(buffer, new_pos, end, self, field_dict)
  File ""/usr/local/lib/python3.6/dist-packages/google/protobuf/internal/decoder.py"", line 888, in DecodeMap
    if submsg._InternalParse(buffer, pos, new_pos) != new_pos:
  File ""/usr/local/lib/python3.6/dist-packages/google/protobuf/internal/python_message.py"", line 1205, in InternalParse
    new_pos = local_SkipField(buffer, old_pos, end, tag_bytes)
  File ""/usr/local/lib/python3.6/dist-packages/google/protobuf/internal/decoder.py"", line 1053, in SkipField
    return WIRETYPE_TO_SKIPPER[wire_type](buffer, pos, end)
  File ""/usr/local/lib/python3.6/dist-packages/google/protobuf/internal/decoder.py"", line 952, in _SkipGroup
    new_pos = SkipField(buffer, pos, end, tag_bytes)
  File ""/usr/local/lib/python3.6/dist-packages/google/protobuf/internal/decoder.py"", line 1053, in SkipField
    return WIRETYPE_TO_SKIPPER[wire_type](buffer, pos, end)
  File ""/usr/local/lib/python3.6/dist-packages/google/protobuf/internal/decoder.py"", line 1009, in _SkipFixed32
    raise _DecodeError('Truncated message.')
google.protobuf.message.DecodeError: Truncated message.

"
45421,"I can build tensorflow.dll  successfully,but not  include SSE4.2,Why?","python ./configure.py    set:
build TensorFlow with ROCm support? [y/N]: n
build TensorFlow with CUDA support? [y/N]: n
Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is /arch:SSE4.2]:
Would you like to override eigen strong inline for some C++ compilation to reduce the compilation time? [Y/n]: y
Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: n
build command:  bazel build --config opt //tensorflow/tools/lib_package:libtensorflow
can you tell me
build successfully,but tensorflow.dll not include SSE4.2,Why?  "
45418,Convert float32 Image NdArray to uint8,"## URL(s) with the issue:
Couldn't find a documentation.

## Description of issue (what needs changing):
I use Tensorflow version 2.3.1 (or Nightly)

I could find tons of information on how to convert int image to float32. However, not being able to do so for the opposite case.

How do convert this normalised ndarray(0 to 1) to a 0-255 ndarray while maintaining the same shape?
![Screenshot 2020-12-04 at 21 48 11](https://user-images.githubusercontent.com/2845708/101218255-a9f13780-367a-11eb-9cb4-622dcc65a863.png)


Thank you,
Sean"
45417,Build TensorFlow Lite for Raspberry Pi: Fails at step 4b,"Attempting steps outlined in [](https://www.tensorflow.org/lite/guide/build_rpi)
https://www.tensorflow.org/lite/guide/build_rpi
using a raspberry pi zero w

--------------------------------------------------------------------
**$ cat /proc/cpuinfo**
processor       : 0
model name      : ARMv6-compatible processor rev 7 (v6l)
BogoMIPS        : 697.95
Features        : half thumb fastmult vfp edsp java tls
CPU implementer : 0x41
CPU architecture: 7
CPU variant     : 0x0
CPU part        : 0xb76
CPU revision    : 7

Hardware        : BCM2835
Revision        : 9000c1
Serial          : 00000000feea1aa3
Model           : Raspberry Pi Zero W Rev 1.1
------------------------------------------------------
 **$ cat /etc/os-release**
PRETTY_NAME=""Raspbian GNU/Linux 10 (buster)""
NAME=""Raspbian GNU/Linux""
VERSION_ID=""10""
VERSION=""10 (buster)""
VERSION_CODENAME=buster
ID=raspbian
ID_LIKE=debian
HOME_URL=""http://www.raspbian.org/""
SUPPORT_URL=""http://www.raspbian.org/RaspbianForums""
BUG_REPORT_URL=""http://www.raspbian.org/RaspbianBugs""

-------------------------------------------------------------------------- 
$ uname -a
Linux pizero 5.4.72+ #1356 Thu Oct 22 13:56:00 BST 2020 armv6l GNU/Linux
----------------------------------------------------------------------

**At step 4b I get the following error:**
pi@pizero:~/src/tensorflow_src $ PATH=../rpi_tools/arm-bcm2708/arm-rpi-4.9.3-linux-gnueabihf/bin:$PATH   ./tensorflow/lite/tools/make/                         build_rpi_lib.sh TARGET_ARCH=armv6
+ set -e
+++ dirname ./tensorflow/lite/tools/make/build_rpi_lib.sh
++ cd ./tensorflow/lite/tools/make
++ pwd
+ SCRIPT_DIR=/home/pi/src/tensorflow_src/tensorflow/lite/tools/make
+ TENSORFLOW_DIR=/home/pi/src/tensorflow_src/tensorflow/lite/tools/make/../../../..
++ awk '/^Mem/ {print $2}'
++ free -m
+ FREE_MEM=368
+ [[ FREE_MEM -gt 2000 ]]
+ NO_JOB=1
+ make -j 1 TARGET=rpi -C /home/pi/src/tensorflow_src/tensorflow/lite/tools/make/../../../.. -f tensorflow/lite/tools/make/Makefile TARGET_ARCH=a                         rmv6
make: Entering directory '/home/pi/src/tensorflow_src'
arm-linux-gnueabihf-g++ -O3 -DNDEBUG -DCPU_SETSIZE=__CPU_SETSIZE -fPIC  --std=c++11  -DTFLITE_WITHOUT_XNNPACK -march=armv6 -mfpu=vfp -funsafe-mat                         h-optimizations -ftree-vectorize -fPIC -I. -I/home/pi/src/tensorflow_src/tensorflow/lite/tools/make/../../../../../ -I/home/pi/src/tensorflow_src                         /tensorflow/lite/tools/make/../../../../../../ -I/home/pi/src/tensorflow_src/tensorflow/lite/tools/make/downloads/ -I/home/pi/src/tensorflow_src/                         tensorflow/lite/tools/make/downloads/eigen -I/home/pi/src/tensorflow_src/tensorflow/lite/tools/make/downloads/absl -I/home/pi/src/tensorflow_src/                         tensorflow/lite/tools/make/downloads/gemmlowp -I/home/pi/src/tensorflow_src/tensorflow/lite/tools/make/downloads/ruy -I/home/pi/src/tensorflow_sr                         c/tensorflow/lite/tools/make/downloads/neon_2_sse -I/home/pi/src/tensorflow_src/tensorflow/lite/tools/make/downloads/farmhash/src -I/home/pi/src/                         tensorflow_src/tensorflow/lite/tools/make/downloads/flatbuffers/include -I/home/pi/src/tensorflow_src/tensorflow/lite/tools/make/downloads/fp16/i                         nclude -I/home/pi/src/tensorflow_src/tensorflow/lite/tools/make/downloads/cpuinfo -I/home/pi/src/tensorflow_src/tensorflow/lite/tools/make/downlo                         ads/cpuinfo/include -I/home/pi/src/tensorflow_src/tensorflow/lite/tools/make/downloads/cpuinfo/src -I/home/pi/src/tensorflow_src/tensorflow/lite/                         tools/make/downloads/cpuinfo/deps/clog/include -I -I/usr/local/include -c tensorflow/lite/allocation.cc -o /home/pi/src/tensorflow_src/tensorflow                         /lite/tools/make/gen/rpi_armv6/obj/tensorflow/lite/allocation.o
/bin/bash: ../rpi_tools/arm-bcm2708/arm-rpi-4.9.3-linux-gnueabihf/bin/arm-linux-gnueabihf-g++: cannot execute binary file: Exec format error
make: *** [tensorflow/lite/tools/make/Makefile:334: /home/pi/src/tensorflow_src/tensorflow/lite/tools/make/gen/rpi_armv6/obj/tensorflow/lite/allocation.o] Error 126
make: Leaving directory '/home/pi/src/tensorflow_src'
"
45415,Micro: port op EXP from Lite,"@tensorflow/micro  @tensorflow/lite  

**System information**
- Host OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- TensorFlow installed from (source or binary): source
- Tensorflow version (commit SHA if source): master
- Target platform (e.g. Arm Mbed OS, Arduino Nano 33 etc.): Sparkfun Edge

**Describe the problem**
I am about to port The TF Lite kernel op EXP to TF Lite Micro.

**Please provide the exact sequence of commands/steps when you ran into the problem**
Below are the first steps I will take to port the op EXP:
- PR 1: refactor flatbuffer_conversions parsing function
- PR 2: refactor reference implementation from lite/kernels/internal/reference/reference_ops.h into its own header without making any changes.
- PR 3: copy the reference kernel from lite to micro without making any changes. At this point the kernel is in micro but it is not part of the build.

"
45413,Model optimization using quantization on desktop PC?,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): 2.3.1
- Are you willing to contribute it (Yes/No): Yes



**Describe the feature and the current behavior/state.**

 We are running CNN using tensorflow on desktop PC's GPU, Win 10 64 bit. We would like to do quantization of the trained model to reduce the inference time. But it seems the quantization only works for tensorflow lite. Is there a way to quantitate the model which runs on desktop PC?

**Will this change the current api? How?**
Maybe. 

**Who will benefit with this feature?**
tensorflow desktop developers

**Any Other info.**
"
45412,setup.py for object detection installs tensorflow 2.3 which is incompatible and reinstalling tensorflow 2.2 doesn't train through model_main_tf2.py,The setup.py script installs the false version of packages and rechanging it to Tensorflow 2.2 makes it worse. I can run the inference of pre-trained models but cannot train on custom data. the model_main_tf2.py gives an error always. Please check the packages which are compatible with the Tensorflow version.
45411,Issue in RECURRENT NEURAL NETWORK,"Please let us know anything wrong in below code, not getting desire result -

```
from numpy import sqrt
from numpy import asarray
from pandas import read_csv
from tensorflow.keras import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.layers import LSTM
import tensorflow as tf
from sklearn import metrics
from sklearn.model_selection import train_test_split
```

- Assign the value as 40 to the variabel **RANDOM_SEED** which will be the seed value.
- Set the random seed value using the value stored in the variable **RANDOM_SEED**.

```
RANDOM_SEED = 40
tf.random.set_seed(RANDOM_SEED)
```

**# split a univariate sequence into samples**

```
def split_sequence(sequence, n_steps):
    X, y = list(), list()
    for i in range(len(sequence)):
        # find the end of this pattern
        end_ix = i + n_steps
        # check if we are beyond the sequence
        if end_ix > len(sequence)-1:
            break
        # gather input and output parts of the pattern
        seq_x, seq_y = sequence[i:end_ix], sequence[end_ix]
        X.append(seq_x)
        y.append(seq_y)
    return asarray(X), asarray(y)
```

- Read the dataset **airline-passengers.csv** and give parameter index_col as 0 and save it in variable df.

`df = read_csv(""airline-passengers.csv"", index_col=0)
`

- Convert the data type of the values dataframe **df** to float32 and save it in variable **values**.
- Assign the value 5 to the variable **n_steps** which is the window size.
- Split the samples using the function **split_sequence** and pass the parameters **values** and **n_steps** and save it in variables **X** and **y**

```
values = df.values.astype('float32')
n_steps = 5
X, y = split_sequence(values, n_steps)

```

- Split the data **X**,**y** with the train_test_split function of sklearn with parameters test_size=0.33 and random_state=RANDOM_SEED.**

`X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=RANDOM_SEED)`

Construct a fully-connected network structure defined using dense class
- Create a sequential model
- Add a LSTM layer which has 200 nodes with activation function as relu and input shape as (n_steps,1).
- The first hidden layer has 100 nodes and uses the relu activation function.
- The second hidden layer has 50 nodes and uses the relu activation function.
- The output layer has 1 node.

```
model = Sequential()
model.add(LSTM(200, activation='relu',  input_shape=(n_steps,1)))
model.add(Dense(100, activation='relu'))
model.add(Dense(50, activation='relu'))
model.add(Dense(1))
```

- While comipling the model pass the following parameters -
           -optimizer as Adam
           -loss as mse 
           -metrics as mae

`model.compile(optimizer='Adam', loss='mse', metrics=['mae'])`

- fit the model with X_train, y_train, epochs=350, batch_size=32,verbose=0.

`model.fit(X_train, y_train, epochs=350, batch_size=32, verbose=0)`

- Perform prediction on the test data (i.e) on **X_test** and save the predictions in the variable **y_pred**.

```
row = ([X_test])
y_pred = model.predict(row)
```

- Calculate the mean squared error on the variables **y_test** and **y_pred** using the mean_squared_error function in sklearn metrics and save it in variable **MSE**.
- Calculate the Root mean squared error on the variables **y_test** and **y_pred** by performing square root on the above result and save it in variable **RMSE**.
- Calculate the mean absolute error on the variables **y_test** and **y_pred** using the mean_absolute_error function in sklearn metrics and save it in variable **MAE**.

```
MSE  = metrics.mean_squared_error(y_test,y_pred)
RMSE = sqrt(metrics.mean_squared_error(y_test,y_pred))
MAE  = metrics.mean_absolute_error(y_test,y_pred)
print('MSE: %.3f, RMSE: %.3f, MAE: %.3f' % (MSE, RMSE,MAE))
```

MSE: 665.522, RMSE: 25.798, MAE: 17.127 ... **this we getting and it is wrong.**

```
with open(""MSE.txt"", ""w"") as text_file:
        MSE=str(MSE)
        text_file.write(MSE)
with open(""RMSE.txt"", ""w"") as text_file:
        RMSE=str(RMSE)
        text_file.write(RMSE)
with open(""MAE.txt"", ""w"") as text_file:
        MAE=str(MAE)
        text_file.write(MAE)
# serialize model to JSON
model_json = model.to_json()
with open(""model.json"", ""w"") as json_file:
    json_file.write(model_json)
```
```

[airline-passengers.zip](https://github.com/tensorflow/tensorflow/files/5646361/airline-passengers.zip)
[airline-passengers.zip](https://github.com/tensorflow/tensorflow/files/5650585/airline-passengers.zip)

[RNN_Question.zip](https://github.com/tensorflow/tensorflow/files/5650599/RNN_Question.zip)
"
45410,Incorrect instructions for Tensor RT,"The install instruction: https://www.tensorflow.org/install/gpu#ubuntu_1804_cuda_101

Have this code here: 

```
# Install TensorRT
RUN apt-get install -y --no-install-recommends libnvinfer6=6.0.1-1+cuda10.1 \
    libnvinfer-dev=6.0.1-1+cuda10.1 \
    libnvinfer-plugin6=6.0.1-1+cuda10.1
```

Which returns:

```
E: Unable to locate package libnvinfer6
E: Unable to locate package libnvinfer-dev
E: Unable to locate package libnvinfer-plugin6
```
"
45406,Op to convert numeric tensor to string type faster ,"

**System information**
- TensorFlow version (you are using): 2.3
- Are you willing to contribute it (Yes/No): Yes



**Describe the feature and the current behavior/state.**


When we want to convert a tensor with numeric value to string type, there is `tf.as_string` available for us. However, its performance will become very poor along with the input tensor swelling, which is caused due to its implement by `vsnprintf` in my opinion. `vsnprintf` indeed provides a quite rich formatting features but in my case I only want to convert number to string..

According to this [benchmark](http://www.zverovich.net/2020/06/13/fast-int-to-string-revisited.html), `fmt::to_string` is 4x faster than `sprintf`. Therefore, I want to inroduce it into third_patry of tensorflow and create a new function (e.g. `tf.number_to_string`) which can simplely and fast convert numeric tensor to string type based on [`fmtlib`](https://github.com/fmtlib/fmt).

In fact, I have implemented a basic version for `tf.number_to_string`, whose performance in my case has been significantly improved than `tf.as_string`. Considering the versatility and the overall design of the framework, I am looking forward to your suggestions.
"
45405,Compilation Problems,"**System information**
- Manjaro 5.9
- TensorFlow installed from (source or binary): source
- TensorFlow version: 3.2.1
- Python version: 3.8.6
- Installed using virtualenv? pip? conda?: pip
- Bazel version (if compiling from source): 3.7
- GCC/Compiler version (if compiling from source): 10.2
- CUDA/cuDNN version: 11.1.1
- GPU model and memory: asus radeon 560 4gb



**Describe the problem**
build fail
It's the same issue like  #41362 but it's back. I didn't comment on the other one since it's pretty old now and nobody would notice...

**Provide the exact sequence of commands / steps that you executed before running into the problem**
```
pkgname=llvm-amdgpu
pkgdesc='Radeon Open Compute - LLVM toolchain (llvm, clang, lld)'
pkgver=3.10.0
pkgrel=1
arch=('x86_64')
url='https://github.com/RadeonOpenCompute/llvm-project'
license=('custom:Apache 2.0 with LLVM Exception')
depends=(z3)
makedepends=(cmake python ninja)
source=(""${pkgname}-${pkgver}.tar.gz::$url/archive/rocm-$pkgver.tar.gz"")
sha256sums=('8262aff88c1ff6c4deb4da5a4f8cda1bf90668950e2b911f93f73edaee53b370')
_dirname=""$(basename ""$url"")-$(basename ""${source[0]}"" .tar.gz)""

build() {
    cmake -GNinja -Wno-dev -S ""$_dirname/llvm"" \
          -DCMAKE_INSTALL_PREFIX='/opt/rocm/llvm' \
          -DCMAKE_BUILD_TYPE=Release \
          -DLLVM_HOST_TRIPLE=$CHOST \
          -DLLVM_BUILD_UTILS=ON \
          -DLLVM_ENABLE_BINDINGS=OFF \
          -DLLVM_ENABLE_OCAMLDOC=OFF \
          -DLLVM_ENABLE_PROJECTS='llvm;clang;compiler-rt;lld' \
          -DLLVM_TARGETS_TO_BUILD='AMDGPU;X86' \
          -DOCAMLFIND=NO
    ninja
}
```
Thanks!

"
45403,"Support RaggedTensors in Keras losses (at least MSE, CE, SCE)","**System information**
- TensorFlow version (you are using): **TF 2.4.0rc3**
- Are you willing to contribute it (Yes/No): **Yes**



**Describe the feature and the current behavior/state.**

Currently, RaggedTensors can be passed as Keras model inputs. Soon, it will be possible to use them as targets (#45060 and #45015). Therefore, it would be great if they could also be passed to standard losses.

I therefore propose to extend the losses in `tf.keras.losses` to support RaggedTensors as inputs. That is currently (TF 2.4.0rc3) not possible:
```python
tf.keras.losses.mean_squared_error(tf.ragged.constant([[1.],[2.,3.]]), tf.ragged.constant([[1.], [2., 3.]]))
```
fails with an exception `TypeError: object of type 'RaggedTensor' has no len()` because it uses https://github.com/tensorflow/tensorflow/blob/c37b2f11529182853bbf234232b4da4b5ff476d6/tensorflow/python/keras/losses.py#L1196 . Similarly for others like `(sparse_)categorical_crossentropy`, `binary_crossentropy` etc.

**Will this change the current api? How?**

RaggedTensors will be supported as arguments of `tf.keras.losses` methods and classes. The change is backward compatible.

**Who will benefit with this feature?**

Anyone wanting to use RaggedTensors as outputs. There seem to be demand for it, see for example #44988, #44112, #43591, #43093, #42320, #41810.

**Any Other info.**

Note that RaggedTensors **can be passed already to `tf.keras.metrics`**, so
```python
tf.keras.metrics.MeanSquaredError()(tf.ragged.constant([[1.],[2.,3.]]), tf.ragged.constant([[1.], [2., 4.]]))
```
returns correctly `1/3`.
"
45402,[RNN] tensorflow/lite/kernels/fully_connected.cc:119 is_optional_bias_int != true error in quantized LSTM model,"**System information**
- OS Platform and Distribution: Windows 10
- TensorFlow installed from (source or binary): pip install
- TensorFlow version (or github SHA if from source): TF2.3, TF '2.5.0-dev20201203'
- Python version: 3.7.5


I am trying to convert and fully quantize a model containing LSTM layers. I use unroll = True flag as quantization of while function is not supported yet (see https://github.com/tensorflow/tensorflow/issues/39392). 

```
import tensorflow as tf
import numpy as np

# create a simple lstm model
input_data = np.random.random_sample([1,2,3]).astype(np.float32)
lstm_model = tf.keras.models.Sequential([tf.keras.layers.LSTM(units = 5, unroll = True)])
lstm_model.build(input_data.shape)

# create a representative dataset
repr_dataset = tf.data.Dataset.from_tensor_slices(np.tile(input_data, [10, 1, 1]))
repr_dataset = repr_dataset.batch(1)
def representative_data_gen():
    for input_value in repr_dataset.take(1):
        yield [input_value]
    
# convert and quantize the model
converter = tf.lite.TFLiteConverter.from_keras_model(lstm_model)
converter.optimizations =  [tf.lite.Optimize.DEFAULT]
converter.representative_dataset = representative_data_gen
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]
tflite_model = converter.convert()
open(""lstm_model.tflite"",""wb"").write(tflite_model)

# open interpreter
interpreter = tf.lite.Interpreter(model_path=""lstm_model.tflite"")
interpreter.allocate_tensors()
```

The interpreter fails when allocating tensors:

```
Traceback (most recent call last):

  File ""test_lstm.py"", line 455, in <module>
    interpreter.allocate_tensors()

  File ""Anaconda3\envs\Automatic-Speech-Recognition\lib\site-packages\tensorflow\lite\python\interpreter.py"", line 259, in allocate_tensors
    return self._interpreter.AllocateTensors()

RuntimeError: tensorflow/lite/kernels/fully_connected.cc:119 is_optional_bias_int != true (0 != 1)Node number 4 (FULLY_CONNECTED) failed to prepare.
```

I found out that following code is converted into a fully connected node with 8int bias  as h_tm1 is a tf.zeros() tensor during the first rnn step. (https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/layers/recurrent.py#L2461)
```
      z = K.dot(inputs, self.kernel)
      z += K.dot(h_tm1, self.recurrent_kernel)
      if self.use_bias:
        z = K.bias_add(z, self.bias)
```

Is this an expected behaviour or a bug? How to get around it?

Thank you"
45401,"TF 2.4rc3 removes names from ops in Model, unlike TF 2.3.1","**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): **Yes**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **Linux Ubuntu 20.04**
- TensorFlow installed from (source or binary): **Binary**
- TensorFlow version (use command below): **2.4rc3**
- Python version: **3.8.5**

**Describe the current behavior**

In TF 2.4rc3

```python
import tensorflow as tf
from tensorflow.keras.layers import Input
from tensorflow.keras.models import Model
 
inputs = Input(shape=(1,), name='input_layer')
outputs = tf.identity(inputs, name='test_layer')
model = Model(inputs, outputs)
 
print(model.output_names)
```

```python
['tf.identity']
```


**Describe the expected behavior**

In TF 2.3.1 and earlier

```python
import tensorflow as tf
from tensorflow.keras.layers import Input
from tensorflow.keras.models import Model
 
inputs = Input(shape=(1,), name='input_layer')
outputs = tf.identity(inputs, name='test_layer')
model = Model(inputs, outputs)
 
print(model.output_names)
```

```python
['tf_op_layer_test_layer']
```

So you could create a model with a function from Tensorflow as the last layer and name it. If you needed to recover the name you can simply slice off the prefix. 

**Standalone code to reproduce the issue**
See above.

**Other info / logs**

If the output is a layer from Keras it works in both versions:

```python
import tensorflow as tf
from tensorflow.keras.layers import Input, Dense
from tensorflow.keras.models import Model
 
inputs = Input(shape=(1,), name='input_layer')
outputs = Dense(1, name='test_layer')(inputs)
model = Model(inputs, outputs)
 
print(model.output_names)
```

```python
['test_layer']
```

But that doesn't change that this is a code-breaking behavior change."
45398,Dll load failed error,"ImportError: Traceback (most recent call last):
  File ""C:\Users\parkar\Anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\parkar\Anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\parkar\Anaconda3\lib\site-packages\tensorflow\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\parkar\Anaconda3\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\parkar\Anaconda3\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: A dynamic link library (DLL) initialization routine failed.


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/errors

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help."
45397,How to create a Tensorflow Dataset without labels? Input 'filename' of 'ReadFile' Op has type float32 that does not match expected type of string,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
-Linux Ubuntu 20.04
- TensorFlow installed from (source or binary): Binary
- TensorFlow version (use command below): 2.3.1
- Python 3.8.5
- CUDA/cuDNN version: 11.0
- GPU model and memory: RTX 2060 8GB

I was trying fit my model using instances of the tf.data.Dataset class. I need the **repeat()** method to perform a custom image augmentation for every epoch.
 
Using Tensorflow 2.3.1, I'm trying to create an instance of the class **tf.data.Dataset** without labels, from the images I have stored in  **.png** files in a folder './Folder/'. For creating the minimal working sample, I think the only relevant line is the one where I am calling **tf.keras.preprocessing.image_dataset_from_directory**. 
The class definition is [here](https://github.com/tensorflow/tensorflow/blob/v2.3.0/tensorflow/python/keras/preprocessing/image_dataset.py#L34-L206):  


**Standalone code to reproduce the issue**

After storing some PNG files in the folder ./Folder/' , the minimal working sample is just this line:
   ` dataset = tf.keras.preprocessing.image_dataset_from_directory('./Folder/',label_mode=None,batch_size=100)`

I expected the tf.data.Dataset instance _dataset_ to be created, and a message:
 Found 449 files ...

Instead, I get the message:
`Found 0 files belonging to 0 classes.
`, followed by this error:
```
Traceback (most recent call last):
  File ""/home/roi/.local/lib/python3.8/site-packages/tensorflow/python/framework/op_def_library.py"", line 465, in _apply_op_helper
    values = ops.convert_to_tensor(
  File ""/home/roi/.local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py"", line 1473, in convert_to_tensor
    raise ValueError(
ValueError: Tensor conversion requested dtype string for Tensor with dtype float32: <tf.Tensor 'args_0:0' shape=() dtype=float32>

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""04-vaeAnomalyScores.py"", line 135, in <module>
    historicKLD, encoder, decoder, vae = artVAE_Instance.run_autoencoder()  # Train
  File ""/media/roi/9b168630-3b62-4215-bb7d-fed9ba179dc7/images/largePatches/artvae.py"", line 403, in run_autoencoder
    trainingDataSet = self.loadImages(self.trainingDir)
  File ""/media/roi/9b168630-3b62-4215-bb7d-fed9ba179dc7/images/largePatches/artvae.py"", line 230, in loadImages
    dataset,paths = tf.keras.preprocessing.image_dataset_from_directory(dir[:-1]+'Downscaled',label_mode=None,batch_size=self.BATCH_SIZE, 
  File ""/home/roi/.local/lib/python3.8/site-packages/tensorflow/python/keras/preprocessing/image_dataset.py"", line 192, in image_dataset_from_directory
    dataset = paths_and_labels_to_dataset(
  File ""/home/roi/.local/lib/python3.8/site-packages/tensorflow/python/keras/preprocessing/image_dataset.py"", line 219, in paths_and_labels_to_dataset
    img_ds = path_ds.map(
  File ""/home/roi/.local/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py"", line 1695, in map
    return MapDataset(self, map_func, preserve_cardinality=True)
  File ""/home/roi/.local/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py"", line 4041, in __init__
    self._map_func = StructuredFunctionWrapper(
  File ""/home/roi/.local/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py"", line 3371, in __init__
    self._function = wrapper_fn.get_concrete_function()
  File ""/home/roi/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py"", line 2938, in get_concrete_function
    graph_function = self._get_concrete_function_garbage_collected(
  File ""/home/roi/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py"", line 2906, in _get_concrete_function_garbage_collected
    graph_function, args, kwargs = self._maybe_define_function(args, kwargs)
  File ""/home/roi/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py"", line 3213, in _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)
  File ""/home/roi/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py"", line 3065, in _create_graph_function
    func_graph_module.func_graph_from_py_func(
  File ""/home/roi/.local/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py"", line 986, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File ""/home/roi/.local/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py"", line 3364, in wrapper_fn
    ret = _wrapper_helper(*args)
  File ""/home/roi/.local/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py"", line 3299, in _wrapper_helper
    ret = autograph.tf_convert(func, ag_ctx)(*nested_args)
  File ""/home/roi/.local/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py"", line 255, in wrapper
    return converted_call(f, args, kwargs, options=options)
  File ""/home/roi/.local/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py"", line 532, in converted_call
    return _call_unconverted(f, args, kwargs, options)
  File ""/home/roi/.local/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py"", line 339, in _call_unconverted
    return f(*args, **kwargs)
  File ""/home/roi/.local/lib/python3.8/site-packages/tensorflow/python/keras/preprocessing/image_dataset.py"", line 220, in <lambda>
    lambda x: path_to_image(x, image_size, num_channels, interpolation))
  File ""/home/roi/.local/lib/python3.8/site-packages/tensorflow/python/keras/preprocessing/image_dataset.py"", line 228, in path_to_image
    img = io_ops.read_file(path)
  File ""/home/roi/.local/lib/python3.8/site-packages/tensorflow/python/ops/gen_io_ops.py"", line 574, in read_file
    _, _, _op, _outputs = _op_def_library._apply_op_helper(
  File ""/home/roi/.local/lib/python3.8/site-packages/tensorflow/python/framework/op_def_library.py"", line 492, in _apply_op_helper
    raise TypeError(""%s expected type of %s."" %
TypeError: Input 'filename' of 'ReadFile' Op has type float32 that does not match expected type of string.
```

"
45396,Tensorflow-Python Environment Assertion Error ,"I tried running some Tensorflow-python code inside Graphene-SGX on Ubuntu 18.04. While the specific does not matter much. I would like to better understand what this AssertionError is and what is it trying to check? I am using the latest Tensorflow 2.3.0. 

```
[2020-12-04 05:34:34,839] - INFO - Running development server on: http://0.0.0.0:1236/
[2020-12-04 05:34:34,840] - WARNING - NOTICE! Running development server on production environment is not recommended.
2020-12-04 05:35:01.759068: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-12-04 05:35:06.357236: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 3696010000 Hz
2020-12-04 05:35:06.860466: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0xe33f4980 initialized for platform Host (this does not guarantee that XLA will be used).
 Devices:2020-12-04 05:35:06.864362: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version

2020-12-04 05:35:07.218360: F tensorflow/core/platform/env.cc:357] Check failed: -1 != cmd_length (-1 vs. -1)
```

From what I understand, it is caused by line 357 (https://fossies.org/linux/tensorflow/tensorflow/core/platform/env.cc) 
 
"
45395,Invalid argument: During Variant Host->Device Copy: non-DMA-copy attempted of tensor type: string,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below):2.4.0rc3
- Python version: 3.6.9
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: cuda11.0
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

```python
import os
import re
import shutil
import string
import tensorflow as tf

from tensorflow.keras import layers
from tensorflow.keras import losses
from tensorflow.keras import preprocessing
from tensorflow.keras.layers.experimental.preprocessing import TextVectorization

print(tf.__version__)

url = ""https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz""

dataset = tf.keras.utils.get_file(""aclImdb_v1.tar.gz"", url,
                                    untar=True, cache_dir='.',
                                    cache_subdir='')

dataset_dir = os.path.join(os.path.dirname(dataset), 'aclImdb')

os.listdir(dataset_dir)

train_dir = os.path.join(dataset_dir, 'train')
os.listdir(train_dir)

sample_file = os.path.join(train_dir, 'pos/1181_9.txt')
with open(sample_file) as f:
  print(f.read())

remove_dir = os.path.join(train_dir, 'unsup')
shutil.rmtree(remove_dir)

batch_size = 32
seed = 42

raw_train_ds = tf.keras.preprocessing.text_dataset_from_directory(
    'aclImdb/train', 
    batch_size=batch_size, 
    validation_split=0.2, 
    subset='training', 
    seed=seed)

for text_batch, label_batch in raw_train_ds.take(1):
  for i in range(3):
    print(""Review"", text_batch.numpy()[i])
    print(""Label"", label_batch.numpy()[i])

raw_val_ds = tf.keras.preprocessing.text_dataset_from_directory(
    'aclImdb/train', 
    batch_size=batch_size, 
    validation_split=0.2, 
    subset='validation', 
    seed=seed)

raw_test_ds = tf.keras.preprocessing.text_dataset_from_directory(
    'aclImdb/test', 
    batch_size=batch_size)

def custom_standardization(input_data):
  lowercase = tf.strings.lower(input_data)
  stripped_html = tf.strings.regex_replace(lowercase, '<br />', ' ')
  return tf.strings.regex_replace(stripped_html,
                                  '[%s]' % re.escape(string.punctuation),
                                  '')

max_features = 10000
sequence_length = 250

vectorize_layer = TextVectorization(
    standardize=custom_standardization,
    max_tokens=max_features,
    output_mode='int',
    output_sequence_length=sequence_length)

# Make a text-only dataset (without labels), then call adapt
train_text = raw_train_ds.map(lambda x, y: x)
vectorize_layer.adapt(train_text)

def vectorize_text(text, label):
  text = tf.expand_dims(text, -1)
  return text, label

train_ds = raw_train_ds.map(vectorize_text)
val_ds = raw_val_ds.map(vectorize_text)
test_ds = raw_test_ds.map(vectorize_text)

AUTOTUNE = tf.data.experimental.AUTOTUNE

train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)
val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)
test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)

embedding_dim = 16

strategy = tf.distribute.MirroredStrategy()
with strategy.scope():
  model = tf.keras.Sequential([
    vectorize_layer,
    layers.Embedding(max_features + 1, embedding_dim),
    layers.Dropout(0.2),
    layers.GlobalAveragePooling1D(),
    layers.Dropout(0.2),
    layers.Dense(1)])
  model.compile(loss=losses.BinaryCrossentropy(from_logits=True),
                optimizer=tf.keras.optimizers.Adam(1e-3),
                metrics=tf.metrics.BinaryAccuracy(threshold=0.0))

epochs = 10
history = model.fit(
    train_ds,
    validation_data=val_ds,
    epochs=epochs)

```

**Describe the current behavior**
```
Traceback (most recent call last):
  File ""official/nlp/bert/fasttext.py"", line 71, in <module>
    tfa.callbacks.AverageModelCheckpoint(update_weights=False, filepath=os.path.join(MODEL_DIR, 'ckpt_moving_average'))])
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py"", line 1100, in fit
    tmp_logs = self.train_function(iterator)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py"", line 828, in __call__
    result = self._call(*args, **kwds)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py"", line 956, in _call
    filtered_flat_args)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py"", line 2943, in __call__
    filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py"", line 1919, in _call_flat
    ctx, args, cancellation_manager=cancellation_manager))
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py"", line 560, in call
    ctx=ctx)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py"", line 60, in quick_execute
    inputs, attrs, num_outputs)
tensorflow.python.framework.errors_impl.InvalidArgumentError: 3 root error(s) found.
  (0) Invalid argument:  2 root error(s) found.
  (0) Invalid argument: During Variant Host->Device Copy: non-DMA-copy attempted of tensor type: string
  (1) Invalid argument: During Variant Host->Device Copy: non-DMA-copy attempted of tensor type: string
0 successful operations.
0 derived errors ignored.
         [[{{node RemoteCall}}]]
         [[cond/else/_1/cond/StatefulPartitionedCall/IteratorGetNextAsOptional_1]]
         [[ConstantFoldingCtrl/cond/else/_1/cond/StatefulPartitionedCall/cond_2/switch_pred/_432_0/_293]]
  (1) Invalid argument:  2 root error(s) found.
  (0) Invalid argument: During Variant Host->Device Copy: non-DMA-copy attempted of tensor type: string
  (1) Invalid argument: During Variant Host->Device Copy: non-DMA-copy attempted of tensor type: string
0 successful operations.
0 derived errors ignored.
         [[{{node RemoteCall}}]]
         [[cond/else/_1/cond/StatefulPartitionedCall/IteratorGetNextAsOptional_1]]
         [[cond/else/_1/cond/StatefulPartitionedCall/cond/then/_410/cond/OptionalGetValue/_196]]
  (2) Invalid argument:  2 root error(s) found.
  (0) Invalid argument: During Variant Host->Device Copy: non-DMA-copy attempted of tensor type: string
  (1) Invalid argument: During Variant Host->Device Copy: non-DMA-copy attempted of tensor type: string
0 successful operations.
0 derived errors ignored.
         [[{{node RemoteCall}}]]
         [[cond/else/_1/cond/StatefulPartitionedCall/IteratorGetNextAsOptional_1]]
0 successful operations.
0 derived errors ignored. [Op:__inference_fn_with_cond_4681]

Function call stack:
fn_with_cond -> fn_with_cond -> fn_with_cond
```
**Describe the expected behavior**

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
45394,nnapi delegate and cpu output with my QAT int8 model got Inconsistent result,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):16.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):pip
- TensorFlow version (use command below):2.3.0
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
QAT my keras model，got tflite model，when I test with CPU on my Android phone（R version），I got right result，after I set useNNapi（true），I got a wrong  result。

**Describe the expected behavior**

got the same result with CPU or nnapi

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.


**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
nnapi log:
2020-12-04 12:09:34.687 30684-30714/org.tensorflow.lite.examples.detection D/score:: 0.011764707
2020-12-04 12:09:34.689 30684-30714/org.tensorflow.lite.examples.detection D/score:: 0.003921569
2020-12-04 12:09:34.690 30684-30714/org.tensorflow.lite.examples.detection D/score:: 0.007843138
2020-12-04 12:09:34.690 30684-30714/org.tensorflow.lite.examples.detection D/score:: 0.011764707
2020-12-04 12:09:34.692 30684-30714/org.tensorflow.lite.examples.detection D/score:: 0.007843138
2020-12-04 12:09:34.693 30684-30714/org.tensorflow.lite.examples.detection D/score:: 0.011764707
2020-12-04 12:09:34.693 30684-30714/org.tensorflow.lite.examples.detection D/score:: 0.003921569
2020-12-04 12:09:34.693 30684-30714/org.tensorflow.lite.examples.detection D/score:: 0.007843138

cpu log:
2020-12-04 12:19:04.204 31252-31925/org.tensorflow.lite.examples.detection D/score:: 0.78125
2020-12-04 12:19:04.204 31252-31925/org.tensorflow.lite.examples.detection D/score:: 0.78125
2020-12-04 12:19:04.391 31252-31925/org.tensorflow.lite.examples.detection D/score:: 0.7734375
2020-12-04 12:19:04.391 31252-31925/org.tensorflow.lite.examples.detection D/score:: 0.7734375
2020-12-04 12:19:04.586 31252-31925/org.tensorflow.lite.examples.detection D/score:: 0.80859375
2020-12-04 12:19:04.587 31252-31925/org.tensorflow.lite.examples.detection D/score:: 0.80859375
2020-12-04 12:19:04.749 31252-31925/org.tensorflow.lite.examples.detection D/score:: 0.81640625
2020-12-04 12:19:04.749 31252-31925/org.tensorflow.lite.examples.detection D/score:: 0.81640625
2020-12-04 12:19:04.895 31252-31925/org.tensorflow.lite.examples.detection D/score:: 0.765625


when I use nnapi the score is always low

"
45393,Is there a tutorial and guide implement with c ？,"Since c is covered in tensorflow version compatibility . Is there any document , book or anything else which is useful to learn tensorflow with c ( or c++ ) ?"
45392,tf.sparse.reorder crashes Tensorflow if number of possible entries of dense_shape overflows 64 bit int,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): v1.12.1-38388-gea6516dcad 2.4.0
- Python version: 3.7.6
- Bazel version (if compiling from source): using bazelisk
- GCC/Compiler version (if compiling from source): 7.5.0
- CUDA/cuDNN version: 10.1
- GPU model and memory: GeForce RTX 2080Ti, 11G

**Describe the current behavior**

`tf.sparse.reorder` crashes if number of possible entries of dense_shape overflows 64 bit int.

**Describe the expected behavior**
`tf.sparse.reorder` should not crash

**Standalone code to reproduce the issue**

```
import tensorflow as tf
t = tf.SparseTensor(indices=[[0, 0, 0, 0, 0, 0]], values=[0.0], dense_shape=[4096, 4096, 4096, 4096, 4096, 4096])
tf.sparse.reorder(t)
```

https://colab.research.google.com/drive/1mfRgXxnMwskSTIZ7ctuAXXtYU430s8pg?usp=sharing

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
45387,micro: add a mechanism for excluding test and kernel sources from Makefile build,"@tensorflow/micro

When submitting a change for review which both copies and modifies a file, it's helpful to submit the copy and the modification as two separate PRs. Otherwise the PR's *files changed* tab does not show the modifications, but rather it looks as if the copied and modified file was simply added in its final form. See, for example, the sequence of PRs in the flight plan of issue #45306.

To facilitate submitting a PR which adds a file which should not yet be a part of the build (for the copy PR), add to the micro [Makefile](https://github.com/tensorflow/tensorflow/blob/5bd220564ebf66b438f09b119ae9a0bfbf59aa22/tensorflow/lite/micro/tools/make/Makefile#L246) a means to exclude kernel and test sources from the build."
45385,ValueError: Could not find matching function to call loaded from the SavedModel.,"Code:
```
import tensorflow as tf
from tensorflow.keras.layers import Input

model = tf.keras.models.load_model(""Model"")
print(model) # First line of output.

inputs = Input(shape=(1, 12, 12))
outputs = model(inputs) # Error appears on this line.
```
Output:
```
<tensorflow.python.saved_model.load.Loader._recreate_base_user_object.<locals>._UserObject object at 0x7fc5335efd00>

Traceback (most recent call last):
  File ""example.py"", line 12, in <module>
    outputs = model(inputs)
  File ""/Users/name/opt/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/saved_model/load.py"", line 509, in _call_attribute
    return instance.__call__(*args, **kwargs)
  File ""/Users/name/opt/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py"", line 780, in __call__
    result = self._call(*args, **kwds)
  File ""/Users/name/opt/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py"", line 823, in _call
    self._initialize(args, kwds, add_initializers_to=initializers)
  File ""/Users/name/opt/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py"", line 697, in _initialize
    *args, **kwds))
  File ""/Users/name/opt/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/eager/function.py"", line 2855, in _get_concrete_function_internal_garbage_collected
    graph_function, _, _ = self._maybe_define_function(args, kwargs)
  File ""/Users/name/opt/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/eager/function.py"", line 3213, in _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)
  File ""/Users/name/opt/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/eager/function.py"", line 3075, in _create_graph_function
    capture_by_value=self._capture_by_value),
  File ""/Users/name/opt/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/framework/func_graph.py"", line 986, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File ""/Users/name/opt/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py"", line 600, in wrapped_fn
    return weak_wrapped_fn().__wrapped__(*args, **kwds)
  File ""/Users/name/opt/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/saved_model/function_deserialization.py"", line 257, in restored_function_body
    ""\n\n"".join(signature_descriptions)))
ValueError: Could not find matching function to call loaded from the SavedModel. Got:
  Positional arguments (1 total):
    * Tensor(""None_0:0"", shape=(None, 1, 12, 12), dtype=float32)
  Keyword arguments: {}

Expected these arguments to match one of the following 1 option(s):

Option 1:
  Positional arguments (0 total):
    *
  Keyword arguments: {'main_input': TensorSpec(shape=(None, 1, 12, 12), dtype=tf.float32, name='main_input')}
```

**System information**
- Python 3.6.12
- Tensorflow 2.3.1 (CPU)
- Keras 2.4.3"
45383,RTX 3070 - CUBLAS_STATUS_ALLOC_FAILED,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Custom Code
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: n/A
- TensorFlow installed from (source or binary): pip
- TensorFlow version (use command below): tf-nightly 2.5.0-dev20201203
- Python version: 3.8
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 11.1 / 8.0.4.30
- GPU model and memory: RTX 3070

```
import warnings
from distutils.version import LooseVersion
import warnings
import tensorflow as tf

# Check TensorFlow Version
assert LooseVersion(tf.__version__) >= LooseVersion('1.0'), 'Please use TensorFlow version 1.0 or newer.  You are using {}'.format(tf.__version__)
print('TensorFlow Version: {}'.format(tf.__version__))

# Check for a GPU
if not tf.test.gpu_device_name():
    warnings.warn('No GPU found. Please ensure you have installed TensorFlow correctly')
else:
    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))
    
    import numpy
import csv

filename = ""jokes_plain_tweet_data.txt""
raw_text = open(filename).read()
raw_text = raw_text.lower()

# strip unwanted characters
raw_text = raw_text.replace('""', '')
raw_text = raw_text.replace('\n', '')
raw_text = raw_text.replace('#', '')

# create mapping of unique chars to integers
chars = sorted(list(set(raw_text)))
char_to_int = dict((c, i) for i, c in enumerate(chars))
print(char_to_int)

n_chars = len(raw_text)
n_vocab = len(chars)

# prepare the dataset of input to output pairs encoded as integers
seq_length = 140

dataX = []
dataY = []

# creates a sequence of 100 characters, output contains the corrosponding character that follows.
# window of 'seq_length' that increments across each character.

for i in range(0, n_chars - seq_length, 1):
    seq_in = raw_text[i:(i + seq_length)]
    seq_out = raw_text[i + seq_length]
    
    #append to training data
    dataX.append([char_to_int[char] for char in seq_in])
    dataY.append(char_to_int[seq_out])
    
    
n_patterns = len(dataX)
print(""Total Patterns: "", n_patterns)


import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.layers import Dropout
from tensorflow.keras.layers import LSTM
from tensorflow.keras.layers import Embedding
from tensorflow.keras.layers import Flatten
from tensorflow.keras.callbacks import ModelCheckpoint
from keras.utils import np_utils

physical_devices = tf.config.list_physical_devices('GPU')
tf.config.experimental.set_memory_growth(physical_devices[0], True)

# reshape X to be [samples, time steps, features]
#X = numpy.reshape(dataX, (n_patterns, seq_length, 1))
X = numpy.reshape(dataX, (n_patterns, seq_length, 1))

# normalize
X = X / float(n_vocab)

# one hot encode the output variable
y = np_utils.to_categorical(dataY)

# define the LSTM model
model = Sequential()
model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2]),return_sequences=True))
model.add(Dropout(0.25))
model.add(LSTM(128))
model.add(Dropout(0.25))
model.add(Dense(y.shape[1], activation='softmax'))
model.compile(loss='categorical_crossentropy', optimizer='adam')

# define the checkpoint
filepath=""weights\weights-improvement-{epoch:02d}-{loss:.4f}.hdf5""
checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')
callbacks_list = [checkpoint]

history = model.fit(X, y, epochs=10, batch_size=128, callbacks=callbacks_list)



```

![image](https://user-images.githubusercontent.com/66197527/101088390-7de59180-3568-11eb-8c73-cc0d47f1b296.png)

![image](https://user-images.githubusercontent.com/66197527/101091615-41686480-356d-11eb-957f-ddfc5d3c22ef.png)



files for code here:

https://ea4269d4-d326-4ad3-8762-3cd36a7b1e50.filesusr.com/archives/d9662a_32aa1694580b4fd698345293e04104b2.rar?dn=tensorflow-gpu-tutorial.rar

"
45381,micro: null-dereference warning breaks Makefile build on g++ 10.2,"@tensorflow/micro

### Description

Changes merged yesterday in 17130a8f trigger a warning treated as an error that breaks a Makefile build on g++10.2:
```
% git describe --all --long
heads/master-0-g34f2adacdbe

% make -f tensorflow/lite/micro/tools/make/Makefile test
tensorflow/lite/micro/tools/make/downloads/flatbuffers already exists, skipping the download.
tensorflow/lite/micro/tools/make/Makefile:478: warning: overriding recipe for target 'tensorflow/lite/micro/tools/make/downloads/person_model_int8'
tensorflow/lite/micro/tools/make/Makefile:478: warning: ignoring old recipe for target 'tensorflow/lite/micro/tools/make/downloads/person_model_int8'
g++ -std=c++11 -fno-rtti -fno-exceptions -fno-threadsafe-statics -fno-unwind-tables -ffunction-sections -fdata-sections -fmessage-length=0 -DTF_LITE_STATIC_MEMORY -DTF_LITE_DISABLE_X86_NEON -O3 -Werror -Wsign-compare -Wdouble-promotion -Wshadow -Wunused-variable -Wmissing-field-initializers -Wunused-function -Wswitch -Wvla -Wall -Wextra -Wstrict-aliasing -Wno-unused-parameter   -DTF_LITE_USE_CTIME -I. -Itensorflow/lite/micro/tools/make/downloads/gemmlowp -Itensorflow/lite/micro/tools/make/downloads/flatbuffers/include -Itensorflow/lite/micro/tools/make/downloads/ruy -Itensorflow/lite/micro/tools/make/downloads/kissfft -c tensorflow/lite/micro/kernels/detection_postprocess.cc -o tensorflow/lite/micro/tools/make/gen/linux_x86_64/obj/tensorflow/lite/micro/kernels/detection_postprocess.o
tensorflow/lite/micro/kernels/detection_postprocess.cc: In function ‘TfLiteStatus tflite::{anonymous}::Eval(TfLiteContext*, TfLiteNode*)’:
tensorflow/lite/micro/kernels/detection_postprocess.cc:590:58: error: potential null pointer dereference [-Werror=null-dereference]
  590 |   tflite::micro::GetTensorData<float>(num_detections)[0] =
      |   ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^
  591 |       size_of_sorted_indices;
      |       ~~~~~~~~~~~~~~~~~~~~~~
tensorflow/lite/micro/kernels/detection_postprocess.cc:686:58: error: potential null pointer dereference [-Werror=null-dereference]
  686 |   tflite::micro::GetTensorData<float>(num_detections)[0] = output_box_index;
      |   ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~
cc1plus: all warnings being treated as errors
make: *** [tensorflow/lite/micro/tools/make/Makefile:490: tensorflow/lite/micro/tools/make/gen/linux_x86_64/obj/tensorflow/lite/micro/kernels/detection_postprocess.o] Error 1
```

This does not trigger a build error on tests run via `bazel test tensorflow/lite/micro/kernels:all:`. Perhaps that uses a different compiler than the `make`-initiated build.

### System information

This is with the native g++ in Debian bullseye:
```
% g++ --version
g++ (Debian 10.2.0-19) 10.2.0
[....]
```


"
45379,Why use  (tanh(a + b)) instead of  (tanh(a) + tanh(b)) or does it not matter in some cases?,"I am not sure if this is a documentation issue or an actual problem - please advise:

In this [machine translation exercise](https://www.tensorflow.org/tutorials/text/nmt_with_attention):

Why does this `class BahdanauAttention` (see class definition at end) do the additive attention as:

`tf.nn.tanh(self.W1(query_with_time_axis) + self.W2(values))`

instead of:

`tf.nn.tanh(self.W1(query_with_time_axis) + tf.nn.tanh(self.W2(values)`

Or, in other words, why does it use: `tanh(a+b)` instead of `tanh(a) + tanh(b)`?

If both `self.W1` and `self.W2` are separate neural network layers, why don't they get their own separate activation functions?

`tanh` restricts the output between `-1` and `+1`, centered at 0 which makes learning gradient descent quicker

```
class BahdanauAttention(tf.keras.layers.Layer):
  def __init__(self, units):
    super(BahdanauAttention, self).__init__()
    self.W1 = tf.keras.layers.Dense(units)
    self.W2 = tf.keras.layers.Dense(units)
    self.V = tf.keras.layers.Dense(1)

  def call(self, query, values):
    # query hidden state shape == (batch_size, hidden size)
    # query_with_time_axis shape == (batch_size, 1, hidden size)
    # values shape == (batch_size, max_len, hidden size)
    # we are doing this to broadcast addition along the time axis to calculate the score
    query_with_time_axis = tf.expand_dims(query, 1)

    # score shape == (batch_size, max_length, 1)
    # we get 1 at the last axis because we are applying score to self.V
    # the shape of the tensor before applying self.V is (batch_size, max_length, units)
    score = self.V(tf.nn.tanh(
        self.W1(query_with_time_axis) + self.W2(values)))

    # attention_weights shape == (batch_size, max_length, 1)
    attention_weights = tf.nn.softmax(score, axis=1)

    # context_vector shape after sum == (batch_size, hidden_size)
    context_vector = attention_weights * values
    context_vector = tf.reduce_sum(context_vector, axis=1)

    return context_vector, attention_weights


```"
45378,Enable use of generators in tf lite model maker,"
**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Using Colab
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA
- TensorFlow installed from (source or binary): NA
- TensorFlow version (use command below): 2+
- Python version: Default Colab
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source): NA
- CUDA/cuDNN version: NA
- GPU model and memory: NA

**Describe the current behavior**

The current api of tensorflow model maker accepts a dataset created using following:

```
from tflite_model_maker import ImageClassifierDataLoader
data = ImageClassifierDataLoader.from_folder('path')
train_data, rest_data = data.split(0.8)
validation_data, test_data = rest_data.split(0.5)

model = image_classifier.create(train_data, model_spec=model_spec.efficientnet_lite4_spec, validation_data=validation_data, epochs=75, learning_rate=0.01, dropout_rate=0.3)
```
However it does not accept a generator which can be used to provide customized augmentation code. Here is an example of generator from this [tutorial](https://www.tensorflow.org/hub/tutorials/tf2_image_retraining#looking_for_a_tool_instead):

```
datagen_kwargs = dict(rescale=1./255, validation_split=.20)
dataflow_kwargs = dict(target_size=IMAGE_SIZE, batch_size=BATCH_SIZE,
                   interpolation=""bilinear"")

valid_datagen = tf.keras.preprocessing.image.ImageDataGenerator(
    **datagen_kwargs)
valid_generator = valid_datagen.flow_from_directory(
    data_dir, subset=""validation"", shuffle=False, **dataflow_kwargs)

do_data_augmentation = False
if do_data_augmentation:
  train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(
      rotation_range=40,
      horizontal_flip=True,
      width_shift_range=0.2, height_shift_range=0.2,
      shear_range=0.2, zoom_range=0.2,
      **datagen_kwargs)
else:
  train_datagen = valid_datagen
train_generator = train_datagen.flow_from_directory(
    data_dir, subset=""training"", shuffle=True, **dataflow_kwargs)

```
Passing train_generator and valid_generator to image_classifier.create throws an exception. 

**Describe the expected behavior**
image_classifier.create method should accept train_generator and valid_generator as created in the example above or some other method should be provided to customized augmentation code for both train and validation images.

**Standalone code to reproduce the issue**
Use https://colab.research.google.com/github/tensorflow/tensorflow/blob/master/tensorflow/lite/g3doc/tutorials/model_maker_image_classification.ipynb
and use the code provided above to create train_generator and valid_generator then run following:

model = image_classifier.create(train_generator, model_spec=model_spec.mobilenet_v2_spec, validation_data=valid_generator, epochs=75, learning_rate=0.01, dropout_rate=0.3)

**Other info / logs** 

---------------------------------------------------------------------------

AttributeError                            Traceback (most recent call last)

<ipython-input-43-a03b2f96410f> in <module>()
      1 # Train using models available in model maker
----> 2 model = image_classifier.create(original_generator, model_spec=model_spec.mobilenet_v2_spec, validation_data=validation_data, epochs=50, learning_rate=0.01, dropout_rate=0.2)

/usr/local/lib/python3.6/dist-packages/tensorflow_examples/lite/model_maker/core/task/image_classifier.py in create(train_data, model_spec, validation_data, batch_size, epochs, train_whole_model, dropout_rate, learning_rate, momentum, shuffle, use_augmentation, use_hub_library, warmup_steps, model_dir, do_train)
    116   image_classifier = ImageClassifier(
    117       model_spec,
--> 118       train_data.index_to_label,
    119       train_data.num_classes,
    120       shuffle=shuffle,

AttributeError: 'DirectoryIterator' object has no attribute 'index_to_label'
"
45377,tflite RuntimeError: Encountered unresolved custom op: StridedSlice failed to prepare. ,"**System information**
- Ubuntu 18.04
- tensorflow 2.4-rc3 and tf-nightly-2.5.0.dev20201203

**Describe the current behavior**

I'm trying to get tflite to work with a model I trained with keras using the subclassed model api.

```python
loaded_model = tf.keras.models.load_model(""foo.ckpt"")
converter = tf.lite.TFLiteConverter.from_keras_model(loaded_model)
converter.allow_custom_ops = True
converter.optimizations = [tf.lite.Optimize.DEFAULT]

tflite_quant_model = converter.convert()
model_quant_file = Path(""bar.tflite"")
model_quant_file.write_bytes(tflite_quant_model)

interpreter = tf.lite.Interpreter(model_path=""bar.tflite"")
interpreter.allocate_tensors()
```

Leads to:

```python
    257   def allocate_tensors(self):
    258     self._ensure_safe()
--> 259     return self._interpreter.AllocateTensors()
    260 
    261   def _safe_to_run(self):

RuntimeError: Encountered unresolved custom op: StridedSlice.Node number 0 (StridedSlice) failed to prepare.
```

So I guess StridedSlice ops aren't implemented yet for tflite?
"
45376,EfficientNet - Conversion to TFlite,"
**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Win 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Samsung S9
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): 2.3.0
- TensorFlow LITE version (use command below): 2.3.0
- Python version: 3.7.4


**Describe the current behavior**
I'm trying to convert the EfficientNet Model to a TFLite model. 

```python
efficientnet = tf.keras.applications.EfficientNetB0(
    include_top=True,
    weights=""imagenet"",
    input_tensor=None,
    input_shape=None,
    pooling=None,
    classes=1000,
    classifier_activation=""softmax"",
)

# Save h5 model to device
efficientnet.save('effnet_b0.h5', compile=False)
# Load h5 model from device
effNetLoaded = tf.keras.models.load_model('effnet_b0.h5')

# Convert model to .tflite format 
converter = tf.lite.TFLiteConverter.from_keras_model(efficientnet)
tflite_model = converter.convert()
open('effnet_b0.tflite', ""wb"").write(tflite_model)
```

When using `effnet_b0.tflite` in Android I'm getting the following error (GPU delegate):

`java.lang.IllegalArgumentException: Internal error: Failed to apply delegate: Attempting to use a delegate that only supports static-sized tensors with a graph that has dynamic-sized tensors.`

I couldn't find much information about this error. I noticed the input was `[None, 224, 224, 3]`, but after changing to `[1, 224, 224, 3]` problem persisted. 

Appreciate any help or info you could give. I'll be happy to provide additional info."
45374,Tensorflow Developer Certificate Exam - PyCharm Plugin Problem,
45373,Converted TensorFlow Lite model is not a valid model in Android Studio,"**System information**

Issue encountered with own model but can also reproduced using the example code found here:

https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/examples/experimental_new_converter/Keras_LSTM_fusion_Codelab.ipynb

Running in a Colaboratory notebook

TensorFlow v2.3.0-0-gb36436b087 2.3.0

Android Studio 4.1.1

**Describe the current behavior**

The notebook runs as expected and the TensorFlow Lite model produces the expected output in Colaboratory.

Importing the downloaded model into Android Studio 4.1.1 gives the error
'Not a valid TensorFlow Lite model'


**Describe the expected behavior**

A successfully converted TensorFlow Lite LSTM model should be valid and usable in Android Studio

**Standalone code to reproduce the issue**

The code used to reproduce is the example LSTM model
https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/examples/experimental_new_converter/Keras_LSTM_fusion_Codelab.ipynb

**Other info / logs** 
"
45372,TextVectorization layer together with TensorBoard fails when trying to log the weights,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 Version 2004 & Windows 10 Pro Version 20H2
- TensorFlow installed from (source or binary): PyPi
- TensorFlow version (use command below):  v2.3.1 & v2.4.0-rc3 & 2.5.0-dev20201203
- Python version: 3.6.6
- CUDA/cuDNN version: 10.1.243
- GPU model and memory: GeForce GTX 1050 Ti (notebook) & GeForce GTX 980 Ti

**Describe the current behavior**
When trying to use TensorBoard with a model, which has a TextVectorization layer, the log_weights function in callbacks.py of tensorflow/python/keras runs into an exception when it tries to get the name of the layer where the weights reside - which I guess might be because the TextVectorization layer is still experimental, and as such this might be why.

**Describe the expected behavior**
Either the weights would have a name, or they would be skipped when TensorBoard tries to log them.

**Standalone code to reproduce the issue**
I've made an example showing the issue using Google Colab, and it can be accessed through this link: https://colab.research.google.com/drive/1wRbFp-O6txoUv01GA_thlwJu_VxkPeyX

**Other info / logs**
For now I've added a few lines of code to TensorFlow locally, to just skip the layer if it's a TextVectorization layer - I don't know much about the internals of the layer, so I'm pretty much just shooting blindly there.
![image](https://user-images.githubusercontent.com/15278940/101026115-c906a100-3576-11eb-9f76-e97e19db43cf.png)

Traceback at the exception:
```
Traceback (most recent call last):
  File ""D:/Projekter/Git/HeroAI/hero_ai.py"", line 334, in <module>
    model = run()
  File ""D:/Projekter/Git/HeroAI/hero_ai.py"", line 283, in run
    history = train(model, train_dataset, test_dataset, callbacks)
  File ""D:/Projekter/Git/HeroAI/hero_ai.py"", line 228, in train
    callbacks=callbacks)
  File ""C:\Users\marcu\AppData\Roaming\Python\Python36\site-packages\tensorflow\python\keras\engine\training.py"", line 1145, in fit
    callbacks.on_epoch_end(epoch, epoch_logs)
  File ""C:\Users\marcu\AppData\Roaming\Python\Python36\site-packages\tensorflow\python\keras\callbacks.py"", line 428, in on_epoch_end
    callback.on_epoch_end(epoch, logs)
  File ""C:\Users\marcu\AppData\Roaming\Python\Python36\site-packages\tensorflow\python\keras\callbacks.py"", line 2339, in on_epoch_end
    self._log_weights(epoch)
  File ""C:\Users\marcu\AppData\Roaming\Python\Python36\site-packages\tensorflow\python\keras\callbacks.py"", line 2397, in _log_weights
    weight_name = weight.name.replace(':', '_')
AttributeError: 'TrackableWeightHandler' object has no attribute 'name'

Process finished with exit code 1
```"
45371,TimeDistributed Layer Applied to Masked Layer (Functional API) not working under TF 2.2+,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04
- TensorFlow installed from (source or binary): pip
- TensorFlow version (use command below): 2.3.1
- Python version: 3.8.5
- CUDA/cuDNN version: 10.1
- GPU model and memory: GForce GTX 1060 (6BG)

**Describe the current behavior**
The following implementation of a model using the Keras functional API worked under TF2.0 and TF2.1 (reduced example from a bigger project, reproduces error though)

```python
import tensorflow as tf
from tensorflow.python.keras.layers import TimeDistributed

shared = False
bs = 1
layer_sizes = (64, 64)

state_dimensionality, n_actions = 8, 4
rnn_choice = tf.keras.layers.SimpleRNN

sequence_length = None
inputs = tf.keras.Input(shape=(sequence_length, state_dimensionality,), batch_size=bs)
masked = tf.keras.layers.Masking()(inputs)

# build encoder
encoder_inputs = tf.keras.Input(shape=state_dimensionality, batch_size=bs)
encoder_x = encoder_inputs
for i in range(len(layer_sizes)):
    encoder_x = tf.keras.layers.Dense(layer_sizes[i],
                                      kernel_initializer=tf.keras.initializers.Orthogonal(gain=tf.sqrt(2.0)),
                                      bias_initializer=tf.constant_initializer(0.0))(encoder_x)
    encoder_x = tf.keras.layers.Activation(""tanh"")(encoder_x)

encoder = tf.keras.Model(inputs=encoder_inputs, outputs=encoder_x, name=""policy_encoder"")

# policy network; stateful, so batch size needs to be known
x = TimeDistributed(encoder, name=""TD_policy"")(masked)
x.set_shape([bs] + x.shape[1:])

x, *_ = rnn_choice(layer_sizes[-1],
                   stateful=True,
                   return_sequences=True,
                   return_state=True,
                   batch_size=bs,
                   name=""policy_recurrent_layer"")(x)

means = tf.keras.layers.Dense(n_actions, name=""means"",
                              kernel_initializer=tf.keras.initializers.Orthogonal(0.01),
                              bias_initializer=tf.keras.initializers.Constant(0.0))(x)

policy = tf.keras.Model(inputs=inputs, outputs=means, name=""simple_rnn_policy"")
```

However when I run this under TF2.2.0+ I receive the following error: 
`ValueError: Input tensor 'policy_recurrent_layer/zeros_like:0' enters the loop with shape (1, 64), but has shape (None, 64) after one iteration. To allow the shape to vary across iterations, use the `shape_invariants` argument of tf.while_loop to specify a less-specific shape.`

I can prevent this error in the following ways:
- not using `stateful=True` and removing the line `x.set_shape([bs] + x.shape[1:])`
- removing the Masking layer
- setting `bs=2` or higher

Sadly, none of these options would work with the remainder of our project.

**Describe the expected behavior**
Given that this was working under TF2.0 I would also expect this to work under 2.3.1 or at least to throw a useful error message hinting towards a breaking change.
"
45370,TensorFlow 1.15.4 artifacts on Maven Central?,"Hello TensorFlow team!

Are you planning to upload a patch for TensorFlow 1.15.4  ( https://github.com/tensorflow/tensorflow/releases/tag/v1.15.4 ) to Maven Central? The latest available version on Maven is 1.15.0 ( https://mvnrepository.com/artifact/org.tensorflow/tensorflow )"
45368,Detection postprocess operator output differs between TFL and TFLM,"@tensorflow/micro

**System information**
- Host OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- TensorFlow installed from (source or binary):
- Tensorflow version (commit SHA if source): 6c0245b27c3b5dd319d3021b05c89a0cd17beb20
- Target platform (e.g. Arm Mbed OS, Arduino Nano 33 etc.):

**Describe the problem**
Detection post process operator output differs between TFL and TFLM because of floating point imprecision on different platforms. It can be fixed by e.g. this change in both kernels:

#if 1

float ycenter = static_cast<float>(
    static_cast<double>(box_centersize.y) /
    static_cast<double>(scale_values.y) *
    static_cast<double>(anchor.h) + static_cast<double>(anchor.y));
float xcenter = static_cast<float>(
    static_cast<double>(box_centersize.x) /
    static_cast<double>(scale_values.x) *
    static_cast<double>(anchor.w) + static_cast<double>(anchor.x));
float half_h = static_cast<float>(
    0.5 * (std::exp(static_cast<double>(box_centersize.h) /
                    static_cast<double>(scale_values.h))) *
    static_cast<double>(anchor.h));
float half_w = static_cast<float>(
    0.5 * (std::exp(static_cast<double>(box_centersize.w) /
                    static_cast<double>(scale_values.w))) *
    static_cast<double>(anchor.w));

#else

float ycenter = box_centersize.y / scale_values.y * anchor.h + anchor.y;
float xcenter = box_centersize.x / scale_values.x * anchor.w + anchor.x;
float half_h =
    0.5f * static_cast<float>(std::exp(box_centersize.h / scale_values.h)) *
    anchor.h;
float half_w =
    0.5f * static_cast<float>(std::exp(box_centersize.w / scale_values.w)) *
    anchor.w;

#endif
**Please provide the exact sequence of commands/steps when you ran into the problem**

"
45367,could I build  both amd and nvidia support?,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version:
- Python version:
- Installed using virtualenv? pip? conda?:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:



**Describe the problem**

**Provide the exact sequence of commands / steps that you executed before running into the problem**


**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
45364, 有关tensorflow estimator   About tensorflow estimator,"I am using the estimator model to process some financial data. The API is tf.estimator.DNNLinearCombinedRegressor However, the document does not provide a detailed description of the use of this API. I would like to ask: 1. If I set 960 lines of batch data for input and use ten batches for prediction. Do different batches affect the prediction results? For example, will batch 1 affect the calculation of batch 2? If you still can't understand my question, let me give another example. Suppose that the correct results can be obtained by inputting batch 1 and batch 2. But now, due to data error, all data of batch 1 become 0, while batch 2 has not changed. In this case, can you still get correct results by inputting batch 1 and batch 2? 2. If I set 960 rows of data for a batch, does the data in the first row affect the data calculation in the second row? This problem is similar to the first one, except that different batches are changed into different lines. Please answer my question, thank you!"
45363,RuntimeError: The layer has never been called and thus has no defined output shape.,"when i used this code :
def blinear_efficient__atten_model(img_rows, img_cols):
    K.clear_session()

    in_lay = Input(shape=(img_rows, img_cols, 3))
    base_model = EfficientNetB3(weights=""imagenet"", include_top=False,input_shape=(224, 224, 3))

    pt_depth = base_model.get_output_shape_at(0)[-1]

    cnn_features_a = base_model(in_lay)
    cnn_bn_features_a = BatchNormalization()(cnn_features_a)

    # attention mechanism
    # here we do an attention mechanism to turn pixels in the GAP on an off
    atten_layer = Conv2D(64, kernel_size=(1, 1), padding=""same"", activation=""relu"")(Dropout(0.5)(cnn_bn_features_a))
    atten_layer = Conv2D(16, kernel_size=(1, 1), padding=""same"", activation=""relu"")(atten_layer)
    atten_layer = Conv2D(8, kernel_size=(1, 1), padding=""same"", activation=""relu"")(atten_layer)
    atten_layer = Conv2D(1, kernel_size=(1, 1), padding=""valid"", activation=""sigmoid"")(atten_layer)  # H,W,1
    # fan it out to all of the channels
    up_c2_w = np.ones((1, 1, 1, pt_depth))  # 1,1,C
    up_c2 = Conv2D(pt_depth, kernel_size=(1, 1), padding=""same"", activation=""linear"", use_bias=False, weights=[up_c2_w])
    up_c2.trainable = True
    atten_layer = up_c2(atten_layer)  # H,W,C

    cnn_atten_out_a = multiply([atten_layer, cnn_bn_features_a])  # H,W,C

    cnn_atten_out_b = cnn_atten_out_a

    cnn_out_dot = multiply([cnn_atten_out_a, cnn_atten_out_b])
    gap_features = GlobalAveragePooling2D()(cnn_out_dot)
    gap_dr = Dropout(0.25)(gap_features)
    dr_steps = Dropout(0.25)(Dense(2048, activation=""relu"")(gap_dr))
    out_layer = Dense(n_classes, activation=""softmax"")(dr_steps)

    b_eff_atten_model = Model(inputs=base_model.input, outputs=out_layer, name=""blinear_efficient_atten"")

    return b_eff_atten_model


Traceback (most recent call last):
  File ""双线性eff.py"", line 407, in <module>
    eB_model = blinear_efficient__atten_model(img_rows, img_cols)  # 输入图像的高度，宽度
  File ""双线性eff.py"", line 184, in blinear_efficient__atten_model
    pt_depth = base_model.get_output_shape_at(0)[-1]
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py"", line 2030, in get_output_shape_at
    'output shape')
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py"", line 2603, in _get_node_attribute_at_index
    'and thus has no defined ' + attr_name + '.')
RuntimeError: The layer has never been called and thus has no defined output shape."
45362,"ValueError: Input 0 of layer dense_2 is incompatible with the layer: expected axis -1 of input shape to have value 50176 but received input with shape [None, 57600]","System information

I have written codes similar to that in the Tensorflow page for checking the label on my image based on the model that I trained
- OS Platform and Distribution : Windows 10
- TensorFlow installed from: pip, tf 2.3.0, gpu
- Python version: - 3.6.8

I had run a simple code to test the model with the images
```
model = tf.keras.models.load_model(
            ""D:\\Python Projects\\Final Year Project\\assets\\resource\\micro.h5"")
path_img = pathlib.Path(""D:/Python Projects/Final Year Project/assets/resource/train_images/Acinetobacter.baumanii/edited/img0.png"")
image = keras.preprocessing.image.load_img(path_img, target_size=(244, 244)
image_array = keras.preprocessing.image.img_to_array(image)
image_array = tf.expand_dims(image_array, 0)
prediction = model.predict(image_array )
```

Error Info
```
WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input Tensor(""sequential_1_input:0"", shape=(None, 224, 224, 3), dtype=float32), but it was called on an input with incompatible shape (None, 244, 244, 3).
WARNING:tensorflow:Model was constructed with shape (None, 224, 224, 3) for input Tensor(""random_flip_input:0"", shape=(None, 224, 224, 3), dtype=float32), but it was called on an input with incompatible shape (None, 244, 244, 3).
Traceback (most recent call last):
  File ""d:\Python Projects\Final Year Project\controller\Image_Recognition.py"", line 136, in toProcess
    prediction = self.imgReg.model.predict(img_array)
  File ""c:\Users\User\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\keras\engine\training.py"", line 130, in _method_wrapper
    return method(self, *args, **kwargs)
  File ""c:\Users\User\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\keras\engine\training.py"", line 1599, in predict
    tmp_batch_outputs = predict_function(iterator)
  File ""c:\Users\User\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\eager\def_function.py"", line 780, in __call__
    result = self._call(*args, **kwds)
  File ""c:\Users\User\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\eager\def_function.py"", line 823, in _call
    self._initialize(args, kwds, add_initializers_to=initializers)
  File ""c:\Users\User\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\eager\def_function.py"", line 697, in _initialize
    *args, **kwds))
  File ""c:\Users\User\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\eager\function.py"", line 2855, in _get_concrete_function_internal_garbage_collected
    graph_function, _, _ = self._maybe_define_function(args, kwargs)
  File ""c:\Users\User\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\eager\function.py"", line 3213, in _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)
  File ""c:\Users\User\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\eager\function.py"", line 3075, in _create_graph_function
    capture_by_value=self._capture_by_value),
  File ""c:\Users\User\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\framework\func_graph.py"", line 986, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File ""c:\Users\User\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\eager\def_function.py"", line 600, in wrapped_fn
    return weak_wrapped_fn().__wrapped__(*args, **kwds)
  File ""c:\Users\User\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\framework\func_graph.py"", line 973, in wrapper
    raise e.ag_error_metadata.to_exception(e)
ValueError: in user code:

    c:\Users\User\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\keras\engine\training.py:1462 predict_function  *
        return step_function(self, iterator)
    c:\Users\User\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\keras\engine\training.py:1452 step_function  **
        outputs = model.distribute_strategy.run(run_step, args=(data,))
    c:\Users\User\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\distribute\distribute_lib.py:1211 run
        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)
    c:\Users\User\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\distribute\distribute_lib.py:2585 call_for_each_replica
        return self._call_for_each_replica(fn, args, kwargs)
    c:\Users\User\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\distribute\distribute_lib.py:2945 _call_for_each_replica
        return fn(*args, **kwargs)
    c:\Users\User\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\keras\engine\training.py:1445 run_step  **
        outputs = model.predict_step(data)
    c:\Users\User\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\keras\engine\training.py:1418 predict_step
        return self(x, training=False)
    c:\Users\User\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\keras\engine\base_layer.py:985 __call__
        outputs = call_fn(inputs, *args, **kwargs)
    c:\Users\User\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\keras\engine\sequential.py:372 call
        return super(Sequential, self).call(inputs, training=training, mask=mask)
    c:\Users\User\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\keras\engine\functional.py:386 call
        inputs, training=training, mask=mask)
    c:\Users\User\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\keras\engine\functional.py:508 _run_internal_graph
        outputs = node.layer(*args, **kwargs)
    c:\Users\User\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\keras\engine\base_layer.py:976 __call__
        self.name)
    c:\Users\User\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\keras\engine\input_spec.py:216 assert_input_compatibility
        ' but received input with shape ' + str(shape))

    ValueError: Input 0 of layer dense_2 is incompatible with the layer: expected axis -1 of input shape to have value 50176 but received input with shape [None, 57600]
```
I had run the code on Google Colab with the same model and image and it works there, but it doesn't on my local computer"
45361,TFLite Converter for BiLSTM based architecture,"**System information**: Default configuration of Google Colab. I ran this experiment on Colab and I am attaching the self-contained notebook.

I have been working on the conversion of [EasyOCR](https://github.com/JaidedAI/EasyOCR) to TFLite . I have been getting this error while converting to TFLite.
> ConverterError: input resource[0] expected type resource != float, the type of assignvariableop_resource_0[0]
	In {{node AssignVariableOp}}

I successfully converted the PyTorch Model to ONNX and ran the inference with sample data and the results are matching correctly. So I hope there are no issues in PyTorch --> ONNX conversion. Even there are no issues in converting to TensorFlow SavedModel. I am getting the error while converting the SavedModel to TFLite. 

**FYI:** Model consists of 2 layer Bi-Directional LSTM cells.

I have attached all the mentioned details in this [Notebook](https://colab.research.google.com/github/tulasiram58827/ocr_tflite/blob/main/colabs/easyocr_tflite_report.ipynb). To reproduce the above error you can use the same [Notebook](https://colab.research.google.com/github/tulasiram58827/ocr_tflite/blob/main/colabs/easyocr_tflite_report.ipynb).

The notebook provided itself is self-contained and will download and install all the necessary modules and files.

@amahendrakar "
45360,No matching distribution found for Tensorflow for pip-20.3,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution: Arch Linux
- TensorFlow version: N/A (pip-20.3 can't install any version of Tensorflow)
- Python version: 3.9.0
- CUDA/cuDNN version: N/A (running on CPU)
- GPU model and memory: N/A (running on CPU)

**Describe the problem**
When trying to install Tensorflow from pip-20.3, pip says:

> ERROR: Could not find a version that satisfies the requirement tensorflow (from versions: none)
> ERROR: No matching distribution found for tensorflow

**Provide the exact sequence of commands / steps that you executed before running into the problem**
> pip install tensorflow
> pip3 install tensorflow
> pip3.9 install tensorflow
(All of these commands yield the same error message)

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
45359,"Unable to load libcurdart.so.10.1, libcuda.so.1","**System information**
- OS Platform and Distribution:  Amazon Linux 2 AMI on tc2 micro EC2 instance
- TensorFlow installed from (source or binary):  binary
- TensorFlow version: 2.3.1
- Python version: 3.7.9
- Installed using virtualenv? pip? conda?: pip
- CUDA/cuDNN version: Unknown/does not exist
- GPU model and memory: None



**Describe the problem**

When attempting to run Tensorflow on an EC2 instance, the following error occurs:
`$ python3 -c ""import tensorflow as tf; print(tf.reduce_sum(tf.random.normal([1000, 1000])))""
2020-12-02 23:53:45.322002: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory
2020-12-02 23:53:45.322135: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2020-12-02 23:53:46.627216: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2020-12-02 23:53:46.627358: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)
2020-12-02 23:53:46.627417: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-172-31-19-184.us-east-2.compute.internal): /proc/driver/nvidia/version does not exist
2020-12-02 23:53:46.627871: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-12-02 23:53:46.634896: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2400085000 Hz
2020-12-02 23:53:46.635090: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x3a194e0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-12-02 23:53:46.635120: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
tf.Tensor(-963.18164, shape=(), dtype=float32)`

As you can see, the commands still _work_.  However, there is about a 3-5 second delay before it finally executes while it searches for the CUDA files.

**Provide the exact sequence of commands / steps that you executed before running into the problem**
Spin up a tc2 micro instance on EC2 using the Amazon Linux 2 AMI
Connect to EC2 instance
`sudo yum groupinstall ""Development Tools""`
`sudo yum install python37`
`curl -O https://bootstrap.pypa.io/get-pip.py`
`python3 get-pip.py --user`
Pip install numpy and pandas as usual
`pip install --no-cache-dir tensorflow`




**Any other info / logs**
The instance does not contain a GPU, being a simple tc2 micro CPU instance.
Attempting to fix with `sudo yum install libcudart10.1` (as recommended in other issues) returns the following error: 
`No package libcudart10.1 available.
Error: Nothing to do`
A GPU is unnecessary.  Acceptable solutions would prevent it from returning the errors by either:
-Preventing it from trying to load libcudart and going straight to CPU execution
-Installing the necessary files so it doesn't return errors before going to CPU execution
If all else fails, the installation still seems to work, albeit with major lag time as tensorflow searches for nonexistent files.  My primary concern is eliminating this lag time, NOT getting a GPU to work."
45357,how to understand handling val data with keras in tf2.1,"I apply model.fit to handle val data.
model.fit(dataset,
                    epochs=4,
                    steps_per_epoch=32,  
                    validation_data=val_dataset, 
                    validation_steps=8,
                    callbacks=callbacks,
                    verbose=1
                    )
Steps respectively set are above, but logs only contain the training steps:
```
...
28/32 [=========================>....] - ETA: 4s - loss: 0.0045 - accuracy: 0.8959
29/32 [==========================>...] - ETA: 3s - loss: 0.0045 - accuracy: 0.8935
30/32 [===========================>..] - ETA: 2s - loss: 0.0045 - accuracy: 0.8940
31/32 [============================>.] - ETA: 1s - loss: 0.0045 - accuracy: 0.8926
2020-12-03 09:35:34.813262: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled
2020-12-03 09:35:34.818206: W tensorflow/core/kernels/data/generator_dataset_op.cc:103] Error occurred when finalizing GeneratorDataset iterator: Cancelled: Operation was cancelled

Epoch 00002: saving model to .\log-output\saved_models\model_epoch02_val_acc0.89.ckpt

32/32 [==============================] - 181s 6s/step - loss: 0.0045 - accuracy: 0.8930 - val_loss: 0.0043 - val_accuracy: 0.8913

Epoch 3/4
...
```
It seems that only the first 31 steps are related to train data and the last step also includes the extra 8 validation steps. Is that right?
By th way, how to deal with the error ""Cancelled: Operation was cancelled""?

tf 2.1
cuda 10.1
python 3.7
win10
GPU 2080Ti"
45354,WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7ff4c27f98c0> and will run it as-is.,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
NO

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
NAME=""Ubuntu""
VERSION=""18.10 (Cosmic Cuttlefish)""

- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
N/A
- TensorFlow installed from (source or binary):
tf installed via conda

- TensorFlow version (use command below):
 2.3.0
- Python version:
Python 3.7.6
- Bazel version (if compiling from source):
N/A
- GCC/Compiler version (if compiling from source):
n/a
- CUDA/cuDNN version:
n/a
- GPU model and memory:
n/a

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**

> Epoch 1/100
> WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0089s vs `on_train_batch_end` time: 0.0245s). Check your callbacks.
> WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7ff4c27f98c0> and will run it as-is.
> Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
> Cause: 'arguments' object has no attribute 'posonlyargs'
> To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
> WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7ff4c27f98c0> and will run it as-is.
> Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
> Cause: 'arguments' object has no attribute 'posonlyargs'
> To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
> INFO:tensorflow:Assets written to: saved_models/ruh_best_stackedAE.hd5/assets
> Epoch 2/100
> WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7ff4c2208e60> and will run it as-is.
> Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
> Cause: 'arguments' object has no attribute 'posonlyargs'
> To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
> WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7ff4c2208e60> and will run it as-is.
> Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
> Cause: 'arguments' object has no attribute 'posonlyargs'
> To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
> INFO:tensorflow:Assets written to: saved_models/ruh_best_stackedAE.hd5/assets
> Epoch 3/100
> WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7ff4c0ad8b90> and will run it as-is.
> Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
> Cause: 'arguments' object has no attribute 'posonlyargs'
> To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
> WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7ff4c0ad8b90> and will run it as-is.
> Please report this to the TensorFlow team. When 

**Describe the expected behavior**
No warning

**Standalone code to reproduce the issue**
```
## to tensorflow github page bug report

import random
import numpy as np
import pandas as pd


df_trial_train = pd.read_csv('df_trial_train_sample.txt' , sep = '\t', index_col=0) 

xyz_coor_trial_train = pd.read_csv('xyz_coor_trial_train_sample.txt',sep = '\t', index_col=0) 


n_train = len(df_trial_train)
n_valid = int(n_train*.2)


index_valid = random.sample(range(n_train)  , n_valid)
mask = np.zeros(n_train, dtype = bool)

mask[index_valid] = True

###############################################

### Stacked AE
import matplotlib.pyplot as plt


## corr coeff:
from tensorflow.keras import backend as K
import tensorflow as tf
import tensorflow.keras as kr
import scipy as sp
def func_correlation_coefficient(y_true, y_pred):
    x = y_true
    y = y_pred
    mx = K.mean(x)
    my = K.mean(y)
    xm, ym = x-mx, y-my
    r_num = K.sum(tf.multiply(xm,ym))
    r_den = K.sqrt( tf.multiply(  K.sum(K.square(xm)), K.sum(K.square(ym))  ) )
    r = r_num / r_den
#     r = sp.stats.pearsonr(x.numpy(),y.numpy())
    r = K.maximum(K.minimum(r, 1.0), -1.0)
    return r

### end corr coeff



## create root log dir for TensorBoard
import os
root_logdir = os.path.join(os.curdir, 'ruh_rootdir_logs')

def get_run_logdir(subdir_name):
    import time
    run_id = time.strftime(subdir_name+'_%Y_%m_%d_%H_%M_%S')
    return os.path.join(root_logdir, run_id)

ruh_run_logdir = get_run_logdir(subdir_name = 'stacked_ae')


my_batch_size = 128
my_lr = .001
my_ngenes_train = df_trial_train.shape[1]
my_ncube_train = df_trial_train[~mask].shape[0]
nunit_output = xyz_coor_trial_train.shape[1]

my_nepochs = 100

n_neurons = my_ngenes_train # #not iterable
n_neurons_latent = 32
n_neurons1 = n_neurons_latent * 4 #int(n_neurons/2)
n_neurons2 = n_neurons_latent * 2 #int(n_neurons/16)



## input layer
my_Input_layer = kr.layers.Input(shape=(n_neurons,)) #shape=df_trial_train.shape[1:])

## encoder:
encoder_layer = kr.layers.Dense(n_neurons1, activation = 'relu')(my_Input_layer)
encoder_layer = kr.layers.Dense(n_neurons2, activation = 'relu')(encoder_layer)

## latent space
latent_layer = kr.layers.Dense(n_neurons_latent, activation = 'relu')(encoder_layer)

## decoder:
#decoder_input = kr.layers.Input(shape=(n_neurons_latent,))
decoder_layer = kr.layers.Dense(n_neurons2 , activation = 'relu')(latent_layer)
decoder_layer = kr.layers.Dense(n_neurons1 , activation = 'relu')(decoder_layer)
decoder_layer = kr.layers.Dense(n_neurons  , activation = 'relu')(decoder_layer)

# my_outputs = kr.layers.Dense(n_neurons)(decoder_layer)

## stacked ae
stacked_ae = kr.models.Model(my_Input_layer, decoder_layer) #kr.models.Model(encoder_layer, my_outputs)
stacked_ae.summary()

## optimization + loss + metrics
myoptimizer = kr.optimizers.SGD(lr = my_lr, momentum=.9, nesterov=True) #, momentum=.01)
myoptimizer = kr.optimizers.Adam(lr = my_lr, beta_1=.9, beta_2=.999)

stacked_ae.compile(loss = 'mse', optimizer = myoptimizer,metrics=[func_correlation_coefficient])


print('#samples/epoch = ', df_trial_train[~mask].shape[0]/my_batch_size, '\n')

earlystopping_stackedAE = kr.callbacks.EarlyStopping(patience=10, restore_best_weights=True)                   
tensorboard_stackedAE = kr.callbacks.TensorBoard(ruh_run_logdir)
checkpoint_stackedAE = kr.callbacks.ModelCheckpoint('saved_models/ruh_best_stackedAE.hd5', save_best_only=True)
history = stacked_ae.fit( x = df_trial_train[~mask]
                         ,y = df_trial_train[~mask] #df_trial_train[~mask]#xyz_coor_trial_train[~mask]             
                         ,epochs=100              
                         ,validation_data=(df_trial_train[mask], df_trial_train[mask])#[df_trial_train[mask], df_trial_train[mask]]#(df_trial_train[mask], xyz_coor_trial_train[mask])              
                         ,callbacks=[ earlystopping_stackedAE
                                     ,tensorboard_stackedAE
                                     ,checkpoint_stackedAE
                                    ] 
                         ,batch_size = my_batch_size
                         , verbose = 10
                        )


```

Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
45351,2.3.1 runs in jupyter but python script,"
my code runs in jupyter but when I use python script. It gives me gpu oom error.
"
45350,Contributing to TFlite Micro,"Hi,
I want to contribute to TFlite Micro. Please help me with getting started.
I have some hardware which might be useful for me to contribute, it includes: STM32 Nucleo-L476RG, Arduino Uno, Nano, Micro, Esp8266, and Esp32
I know Python and C programming.


P.S. - I am a hobbyist and want to contribute.
Thanks."
45348,"""bluepill"" target fails run in Renode emulator robot","@tensorflow/micro
@petewarden

**System information**
- Host OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
  - Linux Ubuntu 18.04.5
- TensorFlow installed from (source or binary):
  - source
- Tensorflow version (commit SHA if source):
  - commit 7537865 (HEAD -> master, origin/master, origin/HEAD)
- Target platform (e.g. Arm Mbed OS, Arduino Nano 33 etc.):
  - bluepill (ARM emulator)

**Describe the problem**

Building a test for use with the emulator (TARGET=bluepill) fails within the Renode emulator robot execution.  A failure message about a missing directory is given.  However, the directory path provided by the failure, is actually the binary the emulator was supposed to execute.

**Please provide the exact sequence of commands/steps when you ran into the problem**

```
make -f tensorflow/lite/micro/tools/make/Makefile TARGET=bluepill test_kernel_mul_test
tensorflow/lite/micro/tools/make/downloads/flatbuffers already exists, skipping the download.
tensorflow/lite/micro/tools/make/Makefile:476: warning: overriding recipe for target 'tensorflow/lite/micro/tools/make/downloads/person_model_int8'
tensorflow/lite/micro/tools/make/Makefile:476: warning: ignoring old recipe for target 'tensorflow/lite/micro/tools/make/downloads/person_model_int8'
tensorflow/lite/micro/testing/test_bluepill_binary.sh tensorflow/lite/micro/tools/make/gen/bluepill_cortex-m3/bin/kernel_mul_test '~~~ALL TESTS PASSED~~~'
/media/ddavis/WETU_Repo/git/tensorflow/tensorflow/lite/micro/testing/../tools/make/downloads/renode/test.sh /media/ddavis/WETU_Repo/git/tensorflow/tensorflow/lite/micro/testing/../testing/bluepill.robot   -r /tmp/renode_bluepill_logs   --variable RESC:/media/ddavis/WETU_Repo/git/tensorflow/tensorflow/lite/micro/testing/../testing/bluepill.resc   --variable RENODE_LOG:/tmp/renode_bluepill_logs/renode_log.txt   --variable DIR_WITH_TESTS:tensorflow/lite/micro/tools/make/gen/bluepill_cortex-m3/bin/kernel_mul_test
Preparing suites
Started Renode instance on port 9999; pid 7612
Starting suites
Running /media/ddavis/WETU_Repo/git/tensorflow/tensorflow/lite/micro/testing/../testing/bluepill.robot
+++++ Starting test 'bluepill.Run All Bluepill Tests'
+++++ Finished test 'bluepill.Run All Bluepill Tests' in 0.00 seconds with status failed
      ╔═
      ║ Parent suite setup failed:
      ║ Directory '/media/ddavis/WETU_Repo/git/tensorflow/tensorflow/lite/micro/tools/make/gen/bluepill_cortex-m3/bin/kernel_mul_test' does not exist.
      ╚═
Cleaning up suites
Closing Renode pid 7612
Aggregating all robot results
Output:  /tmp/renode_bluepill_logs/robot_output.xml
Log:     /tmp/renode_bluepill_logs/log.html
Report:  /tmp/renode_bluepill_logs/report.html
Some tests failed :( See logs for details!
UART LOGS:
cat: /tmp/renode_bluepill_logs/renode_log.txt: No such file or directory
tensorflow/lite/micro/tools/make/Makefile:532: recipe for target 'test_kernel_mul_test' failed
make: *** [test_kernel_mul_test] Error 1
```

```
ls -l /media/ddavis/WETU_Repo/git/tensorflow/tensorflow/lite/micro/tools/make/gen/bluepill_cortex-m3/bin/kernel_mul_test 
-rwxr-xr-x 1 ddavis ddavis 103580 Dec  2 10:14 /media/ddavis/WETU_Repo/git/tensorflow/tensorflow/lite/micro/tools/make/gen/bluepill_cortex-m3/bin/kernel_mul_test
```

```
file /media/ddavis/WETU_Repo/git/tensorflow/tensorflow/lite/micro/tools/make/gen/bluepill_cortex-m3/bin/kernel_mul_test
/media/ddavis/WETU_Repo/git/tensorflow/tensorflow/lite/micro/tools/make/gen/bluepill_cortex-m3/bin/kernel_mul_test: ELF 32-bit LSB executable, ARM, EABI5 version 1 (SYSV), statically linked, not stripped
```

"
45347,Feed batch of images in Java,"Seems like documentation is missing for providing multiple inputs for tensorflow model (.pb) in Java. Could you help how to provide multiple jpg byte[] images to model? Version of Tensorflow java is 2.3. Type of model input is type float32[?,100,100,1]

```
      private static final int SIZE = 100;
      private static final float MEAN = 256f;

        Graph graph = new Graph();
        GraphBuilder b = new GraphBuilder(graph);
        final Output<String> input = b.placeholder(""input"", DataType.STRING);      
  Output<Float> graphOutput =
                b.div(
                        b.resizeBilinear( // Resize using bilinear interpolation
                                b.expandDims(
                                        b.cast(b.decodeJpeg(input, 1), Float.class),
                                        b.constant(""make_batch"", 0)),
                                b.constant(""size"", new int[]{SIZE, SIZE})),
                        b.constant(""scale"", MEAN));
        byte[] image = ....;
        Tensor inputTensor = Tensor.create(image);
        List<Tensor<?>> tensorList = session.runner()
                .feed(inputOp, inputTensor)
                .fetch(graphOutput.op().name()).run();
       // get image tensor
        Tensor<Float> imageTensor = tensorList.get(0).expect(Float.class);
        for (int i = 1; i < tensorList.size(); i++) {
            tensorList.get(i).close();
        }
        inputTensor.close();
```

"
45346,"""bluepill"" target build fails if repository pathname contains spaces","@tensorflow/micro
@petewarden 

**System information**
- Host OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
  - Linux Ubuntu 18.04.5
- TensorFlow installed from (source or binary):
  - source
- Tensorflow version (commit SHA if source):
  - commit 753786571eb24b08f06506e2ff397358974a8c1d (HEAD -> master, origin/master, origin/HEAD)
- Target platform (e.g. Arm Mbed OS, Arduino Nano 33 etc.):
  - bluepill (ARM emulator)

**Describe the problem**

Building a test for use with the emulator (TARGET=bluepill) fails in the shell script.  This is due to the repository pathname having a space character in it.  The following scripts do not have sufficient quote escapes:
- line 33 of tensorflow/lite/micro/testing/test_bluepill_binary.sh
- line 12 of tensorflow/lite/micro/tools/make/downloads/renode/test.sh

**Please provide the exact sequence of commands/steps when you ran into the problem**

```
make -f tensorflow/lite/micro/tools/make/Makefile TARGET=bluepill test_kernel_mul_test
tensorflow/lite/micro/tools/make/downloads/flatbuffers already exists, skipping the download.
tensorflow/lite/micro/tools/make/Makefile:476: warning: overriding recipe for target 'tensorflow/lite/micro/tools/make/downloads/person_model_int8'
tensorflow/lite/micro/tools/make/Makefile:476: warning: ignoring old recipe for target 'tensorflow/lite/micro/tools/make/downloads/person_model_int8'
tensorflow/lite/micro/testing/test_bluepill_binary.sh tensorflow/lite/micro/tools/make/gen/bluepill_cortex-m3/bin/kernel_mul_test '~~~ALL TESTS PASSED~~~'
The following command failed: /media/ddavis/WETU Repo/git/tensorflow/tensorflow/lite/micro/testing/../tools/make/downloads/renode/test.sh. Please  make sure that you have correctly installed Renode for TFLM. See  tensorflow/lite/micro/docs/renode.md for more details.
tensorflow/lite/micro/tools/make/Makefile:532: recipe for target 'test_kernel_mul_test' failed
make: *** [test_kernel_mul_test] Error 1
```"
45341,.ckpt to .pb,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below):
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
No OpKernel was registered to support Op 'TPUReplicatedInput' used by {{node input0}} with these attrs: [N=16, is_packed=false, T=DT_INT32, index=0, is_mirrored_variable=false]
Registered devices: [CPU, GPU, XLA_CPU, XLA_GPU]
Registered kernels:
  <no registered kernels>

	 [[input0]]

During handling of the above exception, another exception occurred:

InvalidArgumentError                      Traceback (most recent call last)

During handling of the above exception, another exception occurred:

InvalidArgumentError                      Traceback (most recent call last)
/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py in restore(self, sess, save_path)
   1333       # We add a more reasonable error message here to help users (b/110263146)
   1334       raise _wrap_restore_error_with_msg(
-> 1335           err, ""a mismatch between the current graph and the graph"")
   1336 
   1337   @staticmethod

**Describe the expected behavior**
the actual model contains .meta,.data,.index files
the model should be converted from .ckpt to .pb

**Standalone code to reproduce the issue**
import os
import tensorflow as tf

trained_checkpoint_prefix = 'models/model.ckpt-49491'
export_dir = os.path.join('export_dir', '0')

graph = tf.Graph()
with tf.compat.v1.Session(graph=graph) as sess:
    # Restore from checkpoint
    loader = tf.compat.v1.train.import_meta_graph(trained_checkpoint_prefix + '.meta')
    loader.restore(sess, trained_checkpoint_prefix)

    # Export checkpoint to SavedModel
    builder = tf.compat.v1.saved_model.builder.SavedModelBuilder(export_dir)
    builder.add_meta_graph_and_variables(sess,
                                         [tf.saved_model.TRAINING, tf.saved_model.SERVING],
                                         strip_default_attrs=True)
    builder.save()                
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
45340,tf.ragged.boolean_mask not working in symbolic mode,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS 10.15.7
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): v2.3.0-rc2-23-gb36436b087 2.3.0
- Python version: 3.6.8

**Describe the current behavior**
```python
x = tf.keras.Input(shape=(101,), dtype=tf.float32)
mask = tf.where(tf.math.greater(x, 1.), True, False)
ragged_x = tf.ragged.boolean_mask(x, mask)
```
throws
```
ValueError: Tensor conversion requested dtype int32 for Tensor with dtype int64: <tf.Tensor 'Cumsum_1:0' shape=(None,) dtype=int64>
```

**Describe the expected behavior**

The above should work. 
It works if x is an eager tensor.

**Standalone code to reproduce the issue**
See above.

**Other info / logs** Include any logs or source code that would be helpful to
---------------------------------------------------------------------------

> ValueError                                Traceback (most recent call last)
> <ipython-input-2-9d996c714f77> in <module>()
>       1 x = tf.keras.Input(shape=(101,), dtype=tf.float32)
>       2 mask = tf.where(tf.math.greater(x, 1.), True, False)
> ----> 3 ragged_x = tf.ragged.boolean_mask(x, mask)
> 
> 9 frames
> /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py in wrapper(*args, **kwargs)
>     199     """"""Call target, and fall back on dispatchers if there is a TypeError.""""""
>     200     try:
> --> 201       return target(*args, **kwargs)
>     202     except (TypeError, ValueError):
>     203       # Note: convert_to_eager_tensor currently raises a ValueError, not a
> 
> /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/ragged/ragged_array_ops.py in boolean_mask(data, mask, name)
>     191         flattened_masked_lengths = array_ops.reshape(masked_lengths, [-1])
>     192         masked_values = ragged_tensor.RaggedTensor.from_row_lengths(
> --> 193             masked_values, flattened_masked_lengths, validate=False)
>     194 
>     195         # Wrap remaining ragged dimensions.
> 
> /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/ragged/ragged_tensor.py in from_row_lengths(cls, values, row_lengths, name, validate)
>     473           row_lengths=row_lengths,
>     474           validate=validate,
> --> 475           preferred_dtype=_get_optional_partition_dtype(values))
>     476       return cls._from_row_partition(values, row_partition, validate=validate)
>     477 
> 
> /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/ragged/row_partition.py in from_row_lengths(cls, row_lengths, validate, preferred_dtype)
>     392 
>     393       row_limits = math_ops.cumsum(row_lengths)
> --> 394       row_splits = array_ops.concat([[0], row_limits], axis=0)
>     395       return cls(
>     396           row_splits=row_splits,
> 
> /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py in wrapper(*args, **kwargs)
>     199     """"""Call target, and fall back on dispatchers if there is a TypeError.""""""
>     200     try:
> --> 201       return target(*args, **kwargs)
>     202     except (TypeError, ValueError):
>     203       # Note: convert_to_eager_tensor currently raises a ValueError, not a
> 
> /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py in concat(values, axis, name)
>    1652           dtype=dtypes.int32).get_shape().assert_has_rank(0)
>    1653       return identity(values[0], name=name)
> -> 1654   return gen_array_ops.concat_v2(values=values, axis=axis, name=name)
>    1655 
>    1656 
> 
> /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_array_ops.py in concat_v2(values, axis, name)
>    1210     try:
>    1211       return concat_v2_eager_fallback(
> -> 1212           values, axis, name=name, ctx=_ctx)
>    1213     except _core._SymbolicException:
>    1214       pass  # Add nodes to the TensorFlow graph.
> 
> /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_array_ops.py in concat_v2_eager_fallback(values, axis, name, ctx)
>    1240         ""'concat_v2' Op, not %r."" % values)
>    1241   _attr_N = len(values)
> -> 1242   _attr_T, values = _execute.args_to_matching_eager(list(values), ctx)
>    1243   _attr_Tidx, (axis,) = _execute.args_to_matching_eager([axis], ctx, _dtypes.int32)
>    1244   _inputs_flat = list(values) + [axis]
> 
> /usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py in args_to_matching_eager(l, ctx, default_dtype)
>     261       ret.append(
>     262           ops.convert_to_tensor(
> --> 263               t, dtype, preferred_dtype=default_dtype, ctx=ctx))
>     264       if dtype is None:
>     265         dtype = ret[-1].dtype
> 
> /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py in convert_to_tensor(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)
>    1473       raise ValueError(
>    1474           ""Tensor conversion requested dtype %s for Tensor with dtype %s: %r"" %
> -> 1475           (dtype.name, value.dtype.name, value))
>    1476     return value
>    1477 
> 
> ValueError: Tensor conversion requested dtype int32 for Tensor with dtype int64: <tf.Tensor 'Cumsum:0' shape=(None,) dtype=int64>"
45337,tf.while_loop how to create a nested loop,"I need to write a loop like this one:
`for i in range(N):
    for j in range(M):
        data[i, j] = 2i+3j`
I've read the documentation and found a way ro write a simple loop:
`def condI(i, _):
    return i < 10`
The next:
`def bodyI(i, out):
    j = tf.constant(0)
    i = i + 1
    return [i, out]`
And the main loop:
`with tf.compat.v1.Session(config=config) as session:
    hl = tf.constant('Hello')
    out = tf.Variable([])
    i = tf.constant(0)
    _, out = tf.while_loop(condI, bodyI, [i, out], shape_invariants=[i.get_shape(), tf.TensorShape([None])])
    session.run(tf.compat.v1.global_variables_initializer())
    result = session.run([_, out])#result = session.run(loss_function(8))
    print(""TF APPEND GPU: "")
    print(result[1])
   session.close()`
The problem is to write a nested cycle. "
45336,built wheel is not complete,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows Server 2019
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA
- TensorFlow installed from (source or binary): Source
- TensorFlow version: 2.3.1
- Python version: 3.7.7.1
- Installed using virtualenv? pip? conda?: NA
- Bazel version (if compiling from source): 3.1.0
- GCC/Compiler version (if compiling from source): 
- CUDA/cuDNN version: 10.1
- GPU model and memory: Gforce MX940



**Describe the problem**

I Build Tensorflow 2.3.1 from source, because my graphic card (Compute Capabiliy 5) is not anymore supported by the binary releases. The Build process as such works ok, but when building the wheel and I install it to another system I miss some components.

e.g all the models under keras.applications are just not part of the wheel.

**Provide the exact sequence of commands / steps that you executed before running into the problem**
Basically I follow the instructions from here:

https://www.tensorflow.org/install/source_windows

bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package --define=no_tensorflow_py_deps=true

bazel-bin\tensorflow\tools\pip_package\build_pip_package ..\tensorflow_pkg

The wheel is created and it is functional ... just parts of the python sources is missing

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

Please let me know which logs you need, and I will provide."
45335,Tensorboard ignores --prefix_path,"**Describe the current behavior**

Some tensorboards installed with tensorflow couldn't access the right URLs.

Reproducible steps

1. install a tf 2.3.1
2. start tensorboard with prefix

```
tensorboard --logdir logs --port 5001 --bind_all  --path_prefix /abc/def
```

We got `failed to fetch runs`

![image](https://user-images.githubusercontent.com/193223/100859743-93a47980-34ca-11eb-9fe8-74ac99ca12f6.png)

Because some requests did not add `abc/def` prefix to the base URL:

![image](https://user-images.githubusercontent.com/193223/100860177-22b19180-34cb-11eb-9150-97855bf88f5e.png)

 
**Describe the expected behavior**

All tensorboard requests should add prefix to the base URL if `--path_prefix` has given.


**Standalone code to reproduce the issue**

I created a regression tests project to investigate the problem

https://github.com/qrtt1/tensorboard-regression/runs/1487646153

It got worse after tf 2.3.0 (they use tensorboard `2.4.0`):

![image](https://user-images.githubusercontent.com/193223/100905996-a1c2bc00-3503-11eb-9f60-27407e10d947.png)



"
45333,MLIR,"**System information**
- Windows 10 Pro
- TensorFlow source, 2.3.1
- targeting Cortex-M4, Cortex-M7, Cortex-M33, ARM CortexM flavors

**Describe the problem**
I'd like to know if there any connection between TensorFlow-MLIR and TensorFlow Lite for Microcontrollers?
Can TensorFlow-MLIR support TensorFlow Lite for Microcontrollers for ARM Cortex M flavors?

Thank you for your insight.


"
45332,Didn't find op for builtin opcode 'SOFTMAX' version '1' error on Cortex-M7,"@tensorflow/micro

**System information**
- Host OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- TensorFlow installed from (source or binary): source
- Target platform (e.g. Arm Mbed OS, Arduino Nano 33 etc.): i.MX8MP's Cortex-M7 core

**Describe the problem**
I am running tflite micro on i.MX8MP's Cortex-M7 core with mobilenet_v1_1.0_224_quant.tflite. I also enable cmsis-nn in the building. According to the following log, the operators CONV_2D, DEPTHWISE_CONV_2D, SOFTMAX.. are all registered. But SOFTMAX isn't found. It is the last operator for the loop in PrepareNodeAndRegistrationDataFromFlatbuffer().

My test code is very simple,

const tflite::Model *model = ::tflite::GetModel(job.networkModel.data);
tflite::AllOpsResolver micro_op_resolver;
 
tflite::MicroInterpreter interpreter(model, micro_op_resolver, inferenceProcessTensorArena, TENSOR_ARENA_SIZE, reporter);
TfLiteStatus allocate_status = interpreter.AllocateTensors();
...

Log:
..
Register cmsis-nn CONV_2D
Register cmsis-nn DEPTHWISE_CONV_2D
Register Kernel common RESHAPE
Register cmsis-nn SOFTMAX
..
micro_interpreter.cc AllocateTensors
micro_allocator.cc: subgraph->operators()->size() 31
..
micro_allocator.cc: PrepareNodeAndRegistrationDataFromFlatbuffer i: 30
micro_allocator.cc: To run GetRegistrationFromOpCode for op code SOFTMAX
op_solver.cc: GetRegistrationFromOpCode
Didn't find op for builtin opcode 'SOFTMAX' version '1'
Failed to get registration from op code SOFTMAX
 
AllocateTensors failed for inference job: job, status 1
"
45331,ImportError: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:NA
- TensorFlow installed from (source or binary):binary
- TensorFlow version:2.3.1
- Python version:3.8.5
- Installed using virtualenv? pip? conda?: pip
- Bazel version (if compiling from source):?
- GCC/Compiler version (if compiling from source):?
- CUDA/cuDNN version:?
- GPU model and memory: Intel(R) UHD Graphics 600


Error when trying to import TensorFlow

**Provide the exact sequence of commands / steps that you executed before running into the problem**
I have just installed TensorFlow via cmd command: pip install tensorflow
When I try to use it in Pycharm and check if everything is working:

import tensorflow as tf

print(tf.__version__)

It gives this error:

Traceback (most recent call last):
  File ""C:\Users\Elève\AppData\Local\Programs\Python\Python38\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 64, in <module>
    from tensorflow.python._pywrap_tensorflow_internal import *
ImportError: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""C:/Users/Elève/PycharmProjects/pythonProject1/main.py"", line 1, in <module>
    import tensorflow as tf
  File ""C:\Users\Elève\AppData\Local\Programs\Python\Python38\lib\site-packages\tensorflow\__init__.py"", line 41, in <module>
    from tensorflow.python.tools import module_util as _module_util
  File ""C:\Users\Elève\AppData\Local\Programs\Python\Python38\lib\site-packages\tensorflow\python\__init__.py"", line 40, in <module>
    from tensorflow.python.eager import context
  File ""C:\Users\Elève\AppData\Local\Programs\Python\Python38\lib\site-packages\tensorflow\python\eager\context.py"", line 35, in <module>
    from tensorflow.python import pywrap_tfe
  File ""C:\Users\Elève\AppData\Local\Programs\Python\Python38\lib\site-packages\tensorflow\python\pywrap_tfe.py"", line 28, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\Users\Elève\AppData\Local\Programs\Python\Python38\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 83, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""C:\Users\Elève\AppData\Local\Programs\Python\Python38\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 64, in <module>
    from tensorflow.python._pywrap_tensorflow_internal import *
ImportError: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed.


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/errors

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.

Process finished with exit code 1"
45330,Post-training quantization same model get different result for tf.concat,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Linux Ubuntu 16.04 in docker
- TensorFlow installed from (source or binary): binary pip install
- TensorFlow version (or github SHA if from source):2.3.0


**Command used to run the converter or code if you’re using the Python API**
If possible, please share a link to Colab/Jupyter/any notebook.

```
def representative_dataset_gen_img(imgCnt=20):
    imgDir = os.path.abspath(FLAGS.quan_images)
    imgNameList = glob.glob(os.path.join(imgDir, '*.jpg'))
    imgIndex = random.sample(range(len(imgNameList)), len(imgNameList) if imgCnt == 0 else imgCnt)
    for i in imgIndex:
        imgMat = cv2.imread(imgNameList[i])
        imgMat = utils.image_preporcess(np.copy(imgMat), [FLAGS.input_size[0], FLAGS.input_size[1]])
        imgMat = imgMat[np.newaxis,:,:,:]
        yield [imgMat.astype(np.float32)]

def convert_tflite_from_keras():
	#converter = tf.lite.TFLiteConverter.from_keras_model(model)
	converter = tf.compat.v1.lite.TFLiteConverter.from_keras_model_file(kerasH5File)
	converter.optimizations = [tf.lite.Optimize.DEFAULT]
	converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]
	converter.inference_input_type = tf.uint8
	converter.inference_output_type = tf.uint8
	converter.representative_dataset = representative_dataset_gen_img
	TFLiteModel = converter.convert()
	open(TFLiteFile, ""wb"").write(TFLiteModel)

```
**Also, please include a link to the saved model or GraphDef**
[bad.h5](https://drive.google.com/file/d/11301633Tl5pUjq6DXC8p-VPPECVGYjM3/view?usp=sharing)
[good.h5](https://drive.google.com/file/d/1VsQZ-tfaxmouYo3fNdYFZT-mG_FSEqmx/view?usp=sharing)
[bad.tflite](https://drive.google.com/file/d/15ReLcnSGqz67j8KSZdHCMG-hTRj-KWPO/view?usp=sharing)
[good.tflite](https://drive.google.com/file/d/1910F-erSpyLUXIO6m6nvvxfXJCacn-2f/view?usp=sharing)

**Failure details**
I use the same tiny-yolov3 network to train two different target detection tasks, and use the same tflite Python API to quantify the model to get the tflite model.However, one result of the two models after quantization is correct and the other is wrong. After comparison, I found that the branch of ""Quantize ""node for concat OP quantization is different (as shown in the figure below).letf is ok, and right is bad.
![1](https://user-images.githubusercontent.com/20400418/100845353-0c4e0a80-34b8-11eb-836f-8ae8ad9411b7.png)
--Why does the same model have different quantization results?
--I've tried several versions of tensorflow, such as tf2.3, tf-nightly-2.5.0 and the problem remains"
45329,variable_scope inherits attributes,"```python
import tensorflow
def _custom_getter(getter, *args, **kwargs):
  return getter(*args, **kwargs) 
with tf.compat.v1.variable_scope('', custom_getter=_custom_getter):
  scope = tf.compat.v1.get_variable_scope()
  scope2 = tf.compat.v1.variable_scope(scope)
  print(scope2._custom_getter) # return None
```
New ```variable_scope``` doesn't inherit last ```variable_scope```'s attributes. Is it expected behavior?"
45328,"RuntimeError: Quantization not yet supported for op: 'DEQUANTIZE', after QAT quantize_apply()","**System information**
- OS Platform and Distribution: Windows 10
- TensorFlow installed from (source or binary): binary
- TensorFlow version (or github SHA if from source): 2.5.0.dev20201130

I'm trying to apply quantization on a keras model for quantization aware training and then int8 quantize the model with tflite.
I successfully annotated only the supported layers and use tfmot.quantization.keras.quantize_apply. But, when I try to quantize the quant aware model I get this error multiple times:
RuntimeError: Quantization not yet supported for op: 'DEQUANTIZE'.
Am I doing something wrong?

**Code**
(Just need to change ```directory``` to a folder with some calibration images from COCO)
```
import cv2
import numpy as np
import os
import tensorflow as tf
import tensorflow_model_optimization as tfmot
from tensorflow import keras


def apply_quantization_to_supported_layers(layer):
    if isinstance(layer, tf.keras.layers.ReLU):
        return tfmot.quantization.keras.quantize_annotate_layer(layer)
    elif isinstance(layer, tf.keras.layers.Activation):
        if not layer.activation.__name__ == 'sigmoid':
            return tfmot.quantization.keras.quantize_annotate_layer(layer)
    elif isinstance(layer, tf.keras.layers.DepthwiseConv2D):
        return tfmot.quantization.keras.quantize_annotate_layer(layer)
    elif isinstance(layer, tf.keras.layers.Conv2D) and not isinstance(layer, tf.keras.layers.Conv2DTranspose):
        # Conv2DTranspose inherits from Conv2D
        return tfmot.quantization.keras.quantize_annotate_layer(layer)
    return layer


def read_and_process_image(fname):
    img = cv2.imread(fname)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    img = cv2.resize(img, dsize=(224, 224), interpolation=cv2.INTER_LANCZOS4)
    img = img / 127.5
    img = img - 1
    img = img.astype(np.float32)
    img = img.reshape(1, 224, 224, 3)
    return img


def representative_data_gen():
    directory = r'C:\user\calibrationsImages'
    for filename in os.listdir(directory):
        if filename.endswith("".jpg""):
            image_path = os.path.join(directory, filename)
            img = read_and_process_image(image_path)
            img_in = np.array(img)
            yield [img_in]
        else:
            continue


if __name__ == ""__main__"":

    print(tf.version.VERSION)
    orig_model_path = ""model.hdf5""

    # load regularly trained model
    model = keras.models.load_model(orig_model_path)
    model.summary()  # print model layers

    # convert supported layers to quantization aware
    annotated_model = tf.keras.models.clone_model(
        model,
        clone_function=apply_quantization_to_supported_layers,
    )

    quant_aware_model = tfmot.quantization.keras.quantize_apply(annotated_model)
    quant_aware_model.summary()

    adam = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, decay=0.0, amsgrad=False)
    quant_aware_model.compile(optimizer=adam,
                              loss=""binary_crossentropy"")

    quant_aware_model.summary()

    # quantize quantization aware model to int8
    converter = tf.lite.TFLiteConverter.from_keras_model(quant_aware_model)
    converter.optimizations = [tf.lite.Optimize.DEFAULT]
    converter.representative_dataset = representative_data_gen
    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]

    tflite_quant_model = converter.convert()

    open('model.tflite', 'wb').write(tflite_quant_model)

```

**The error I'm getting**

```
Traceback (most recent call last):
  File ""C:/REPOSITORIES/QuantizationAwareTraining/forTfIssue.py"", line 78, in <module>
    tflite_quant_model = converter.convert()
  File ""C:\Users\limorb\Anaconda3\envs\QuantizationAwareTraining\lib\site-packages\tensorflow\lite\python\lite.py"", line 895, in convert
    self).convert(graph_def, input_tensors, output_tensors)
  File ""C:\Users\limorb\Anaconda3\envs\QuantizationAwareTraining\lib\site-packages\tensorflow\lite\python\lite.py"", line 653, in convert
    result = self._calibrate_quantize_model(result, **flags)
  File ""C:\Users\limorb\Anaconda3\envs\QuantizationAwareTraining\lib\site-packages\tensorflow\lite\python\lite.py"", line 481, in _calibrate_quantize_model
    inference_output_type, allow_float, activations_type)
  File ""C:\Users\limorb\Anaconda3\envs\QuantizationAwareTraining\lib\site-packages\tensorflow\lite\python\optimize\calibrator.py"", line 104, in calibrate_and_quantize
    np.dtype(activations_type.as_numpy_dtype()).num)
RuntimeError: Quantization not yet supported for op: 'DEQUANTIZE'.
Quantization not yet supported for op: 'DEQUANTIZE'.
Quantization not yet supported for op: 'DEQUANTIZE'.
Quantization not yet supported for op: 'DEQUANTIZE'.
Quantization not yet supported for op: 'DEQUANTIZE'.
. 
.
.
```

**Link to model**

[model.zip](https://drive.google.com/file/d/1eopi5IdNKPTJimK0Bb1q-8TYZc7IY5sp/view?usp=sharing)"
45327,"Training in Colab always gives an error of ""FailedPreconditionError""","<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Google Colab

Started training in Colab but unfortunately, I am always having this error:
`
WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.10.moving_mean
W1202 07:14:44.360409 139666145298304 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.10.moving_mean
WARNING:tensorflow:Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.10.moving_variance
W1202 07:14:44.360842 139666145298304 util.py:150] Unresolved object in checkpoint: (root).model._box_predictor._base_tower_layers_for_heads.class_predictions_with_background.4.10.moving_variance
WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.
W1202 07:14:44.361112 139666145298304 util.py:158] A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.
WARNING:tensorflow:FailedPreconditionError: models/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/checkpoint; Is a directory
W1202 07:14:44.364649 139666145298304 checkpoint_management.py:295] FailedPreconditionError: models/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/checkpoint; Is a directory
WARNING:tensorflow:models/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/checkpoint: Checkpoint ignored
W1202 07:14:44.364827 139666145298304 checkpoint_management.py:296] models/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/checkpoint: Checkpoint ignored
WARNING:tensorflow:FailedPreconditionError: models/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/checkpoint; Is a directory
W1202 07:14:44.365584 139666145298304 checkpoint_management.py:295] FailedPreconditionError: models/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/checkpoint; Is a directory
WARNING:tensorflow:models/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/checkpoint: Checkpoint ignored
W1202 07:14:44.365750 139666145298304 checkpoint_management.py:296] models/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/checkpoint: Checkpoint ignored
Traceback (most recent call last):
  File ""model_main_tf2.py"", line 113, in <module>
    tf.compat.v1.app.run()
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 300, in run
    _run_main(main, args)
  File ""/usr/local/lib/python3.6/dist-packages/absl/app.py"", line 251, in _run_main
    sys.exit(main(argv))
  File ""model_main_tf2.py"", line 110, in main
    record_summaries=FLAGS.record_summaries)
  File ""/usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/model_lib_v2.py"", line 627, in train_loop
    manager.save()
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/checkpoint_management.py"", line 819, in save
    self._record_state()
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/checkpoint_management.py"", line 728, in _record_state
    save_relative_paths=True)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/checkpoint_management.py"", line 248, in update_checkpoint_state_internal
    text_format.MessageToString(ckpt))
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/lib/io/file_io.py"", line 570, in atomic_write_string_to_file
    rename(temp_pathname, filename, overwrite)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/lib/io/file_io.py"", line 529, in rename
    rename_v2(oldname, newname, overwrite)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/lib/io/file_io.py"", line 546, in rename_v2
    compat.as_bytes(src), compat.as_bytes(dst), overwrite)
tensorflow.python.framework.errors_impl.FailedPreconditionError: models/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/checkpoint.tmp1e96a55bc7b14447b94ca71713ebdea9; Is a directory
`

I don't have any idea why it keeps saying the checkpoint.tmp is a directory?

Appreciate your help.

This is my [pipeline.config](https://gist.github.com/androuino/200aa56039b1cfeb02ed6bb301ffa51a)"
45326,tf.keras.preprocessing.image.random_shear raises TypeError when it is mapped to a tf dataset.,"```
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
<ipython-input-5-3819cfbfb025> in <module>()
----> 1 for i in tfd.map(test):
      2   print(i.shape)

10 frames
/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py in wrapper(*args, **kwargs)
    256       except Exception as e:  # pylint:disable=broad-except
    257         if hasattr(e, 'ag_error_metadata'):
--> 258           raise e.ag_error_metadata.to_exception(e)
    259         else:
    260           raise

TypeError: in user code:

    <ipython-input-4-bf71d3ba553f>:3 test  *
        image_5 = tf.keras.preprocessing.image.random_shear(image_4, intensity = shear_angle, row_axis=0, col_axis=1, channel_axis=2)
    /usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/affine_transformations.py:114 random_shear  *
        shear = np.random.uniform(-intensity, intensity)
    mtrand.pyx:1083 numpy.random.mtrand.RandomState.uniform  **
        

    TypeError: __array__() takes 1 positional argument but 2 were given
```

Please check **this Colab notebook:**
https://colab.research.google.com/drive/1SWl5cGiSTa_ML2zmQFpTvs6SIqOH7qNW?usp=sharing

When editing some part of code got it work, but it can't be used for map method of tfdataset."
45325,tf.keras.preprocessing.image.random_shift consistently failing in graph mode,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): v2.3.0-54-gfcc4b966f1 2.3.1
- Python version: 3.7
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 7.6.5
- GPU model and memory: 32G V100, 4G GTX 1650 with Max-Q Design

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
```
tf.compat.v1.disable_eager_execution()
image = tf.random.uniform([3,32,32])
img = tf.keras.preprocessing.image.random_shift(image, hrg=0.3, wrg=0.3)
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/home/dz/.conda/envs/py37cu101/lib/python3.7/site-packages/keras_preprocessing/image/affine_transformations.py"", line 89, in random_shift
    order=interpolation_order)
  File ""/home/dz/.conda/envs/py37cu101/lib/python3.7/site-packages/keras_preprocessing/image/affine_transformations.py"", line 323, in apply_affine_transform
    x = np.rollaxis(x, channel_axis, 0)
  File ""<__array_function__ internals>"", line 6, in rollaxis
  File ""/home/dz/.conda/envs/py37cu101/lib/python3.7/site-packages/numpy/core/numeric.py"", line 1259, in rollaxis
    n = a.ndim
AttributeError: 'Tensor' object has no attribute 'ndim'
```
**Describe the expected behavior**
Random shift the image with no error
**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.
```
import tensorflow as tf
tf.compat.v1.disable_eager_execution()
image = tf.random.uniform([3,32,32])
img = tf.keras.preprocessing.image.random_shift(image, hrg=0.3, wrg=0.3)
```
**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
45324,"When tf.image.central_crop taking a tensor as `central_fraction` argument, it raises OperatorNotAllowedInGraphError.","<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): win10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): 2.4.0-rc3
- Python version: 3.8.5
- Bazel version (if compiling from source): 3.1
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 11.1 / 8
- GPU model and memory: rtx 3080 10GB


Colab notebook : https://colab.research.google.com/drive/1owELtE9_mTh1HCx20Yt3fJ3ynXLvds_x#scrollTo=rrehHBjoLUpT

**Is it prohibited to pass a tensor to `central_fraction` argument of tf.image.central_crop function?**
It raises OperatorNotAllowedInGraphError.

When used with map of tfdataset, the function raises the error. But using it with a eager tensor doesn't.




"
45323,illegal hardware instruction  python while import tensorflow2.2.0,"**My System information**
- OS Platform and Distribution (e.g.MacOS Bigsur 11.0 M1 Chip):
- TensorFlow installed from (pip3 install tensorflow==2.2.0):
- TensorFlow version (tf2.2.0):

I use pip3 install tensorflow==2.2.0,but when i import tensorflow as tf, it gave me an error ""illegal hardware instruction  python3"", my MacOS is BigSur 11.0,M1 chip. is this problem from BigSur or M1 chip? how to solve it ?"
45322,Memory leak using nested name_scope in eager mode,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Both Windows 10 and Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Using desktop only
- TensorFlow installed from (source or binary): tf-nightly
- TensorFlow version (use command below): 2.5.0-dev20201201
- Python version: Both 3.7 and 3.8
- Bazel version (if compiling from source): Not compiling from source
- GCC/Compiler version (if compiling from source): Not compiling from source
- CUDA/cuDNN version: 11
- GPU model and memory: RTX 2070

**Describe the current behavior**
It seems using nested name_scope can lead to memory leak. For example, in my setup, the memory grows indefinitely using this code.
```
import tensorflow as tf
for i in range(int(1e7)):
    with tf.name_scope(""first""):
        with tf.name_scope(""second""):
            pass
```
I'm actually not sure this is valid usage of name_scope. However, it seems this king of nested usage of name_scope is used in Tensorflow Probability ([here for example](https://github.com/tensorflow/probability/blob/master/tensorflow_probability/python/distributions/distribution.py#L1542)). Another minimal example leading to memory leak is:
```
import tensorflow_probability as tfp
distr = tfp.distributions.Normal(loc=1.0, scale=2)
for i in range(int(1e7)):
    distr.sample()
```

I don't know why, but appending ""/"" to the name of the scope seems to fix the leak. Here are samples without memory leaks:
```
import tensorflow as tf
for i in range(int(1e7)):
    with tf.name_scope(""first/""):
        with tf.name_scope(""second""):
            pass
```
or
```
import tensorflow_probability as tfp
distr = tfp.distributions.Normal(loc=1.0, scale=2, name=""foo/"")
distr._name += ""/""  # Force ""/"" because it's removed in the constructor
for i in range(int(1e7)):
    distr.sample(name=""sample/"")
```
It seems like ctx.name_scope is now using a C++ Safe_PyObjectPtr. I'm not sure why but maybe the reference counter is incorrect.
"
45321,TensorFlow Lite conversion fails due to tf.linalg.diag_part,"**System information**
- OS Platform and Distribution: google colab (same issue locally on Debian GNU/Linux 10)
- TensorFlow installed from: PyPI (`pip install`)
- TensorFlow version: 2.3.0 (google colab), and 2.3.1 (locally)

**Command used to run the converter or code if you’re using the Python API**
I am trying to convert a model that uses [tf.linalg.diag_part](https://www.tensorflow.org/api_docs/python/tf/linalg/diag_part) to TensorFlow Lite. As far as I understand, `tf.linalg.diag_part` is not directly supported, but it should be possible to convert the model by setting `converter.target_spec.supported_ops` (as described [here](https://www.tensorflow.org/lite/guide/ops_select#convert_a_model). `tf.linalg.diag_part` seems to rely on `MatrixDiagPartV3`, which is included in the [list](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/delegates/flex/allowlisted_flex_ops.cc) of operations that can be enabled. Here is a minimal example ([colab notebook](https://colab.research.google.com/drive/1-sYbh6In8Dubki0UtcnzjmEZuMiMa-Gd?usp=sharing)):
```python
import tensorflow as tf

model_input = tf.keras.Input(shape=(3, 3), batch_size=1)

diagonal = tf.linalg.diag_part(model_input)

model = tf.keras.models.Model(inputs=model_input, outputs=diagonal)

converter = tf.lite.TFLiteConverter.from_keras_model(model)

# Enable TensorFlow ops that are not directly supported by tf lite
# https://www.tensorflow.org/lite/guide/ops_select#convert_a_model
converter.target_spec.supported_ops = [
    tf.lite.OpsSet.TFLITE_BUILTINS,
    tf.lite.OpsSet.SELECT_TF_OPS,
    ]

tflite_model = converter.convert()
```

**The output from the converter invocation**

```bash
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
INFO:tensorflow:Assets written to: /tmp/tmpkg1mi0e5/assets

---------------------------------------------------------------------------

Exception                                 Traceback (most recent call last)

/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/convert.py in toco_convert_protos(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)
    198                                                  debug_info_str,
--> 199                                                  enable_mlir_converter)
    200       return model_str

5 frames

Exception: /usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py:1073:0: error: 'tf.MatrixDiagPartV3' op is neither a custom op nor a flex op
/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py:1167:0: note: called from
/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/lite.py:804:0: note: called from
<ipython-input-1-9932e84c0ae3>:23:0: note: called from
/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2882:0: note: called from
/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2822:0: note: called from
/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718:0: note: called from
/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py:537:0: note: called from
/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py:208:0: note: called from
/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py:399:0: note: called from
/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py:1073:0: note: see current operation: %0 = ""tf.MatrixDiagPartV3""(%arg0, %cst, %cst_0) {T = f32, _cloned = true, align = ""RIGHT_LEFT"", device = """"} : (tensor<1x3x3xf32>, tensor<i32>, tensor<f32>) -> tensor<1x3xf32>
<unknown>:0: error: failed while converting: 'main': Ops that need custom implementation (enabled via setting the -emit-custom-ops flag):
	tf.MatrixDiagPartV3 {T = f32, _cloned = true, align = ""RIGHT_LEFT"", device = """"}
<unknown>:0: note: see current operation: ""func""() ( {
^bb0(%arg0: tensor<1x3x3xf32>):  // no predecessors
  %cst = ""std.constant""() {value = dense<0> : tensor<i32>} : () -> tensor<i32>
  %cst_0 = ""std.constant""() {value = dense<0.000000e+00> : tensor<f32>} : () -> tensor<f32>
  %0 = ""tf.MatrixDiagPartV3""(%arg0, %cst, %cst_0) {T = f32, _cloned = true, align = ""RIGHT_LEFT"", device = """"} : (tensor<1x3x3xf32>, tensor<i32>, tensor<f32>) -> tensor<1x3xf32>
  ""std.return""(%0) : (tensor<1x3xf32>) -> ()
}) {sym_name = ""main"", tf.entry_function = {control_outputs = """", inputs = ""input_1"", outputs = ""Identity""}, type = (tensor<1x3x3xf32>) -> tensor<1x3xf32>} : () -> ()


During handling of the above exception, another exception occurred:

ConverterError                            Traceback (most recent call last)

/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/convert.py in toco_convert_protos(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)
    200       return model_str
    201     except Exception as e:
--> 202       raise ConverterError(str(e))
    203 
    204   if distutils.spawn.find_executable(_toco_from_proto_bin) is None:

ConverterError: /usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py:1073:0: error: 'tf.MatrixDiagPartV3' op is neither a custom op nor a flex op
/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py:1167:0: note: called from
/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/lite.py:804:0: note: called from
<ipython-input-1-9932e84c0ae3>:23:0: note: called from
/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2882:0: note: called from
/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2822:0: note: called from
/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718:0: note: called from
/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py:537:0: note: called from
/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py:208:0: note: called from
/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py:399:0: note: called from
/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py:1073:0: note: see current operation: %0 = ""tf.MatrixDiagPartV3""(%arg0, %cst, %cst_0) {T = f32, _cloned = true, align = ""RIGHT_LEFT"", device = """"} : (tensor<1x3x3xf32>, tensor<i32>, tensor<f32>) -> tensor<1x3xf32>
<unknown>:0: error: failed while converting: 'main': Ops that need custom implementation (enabled via setting the -emit-custom-ops flag):
	tf.MatrixDiagPartV3 {T = f32, _cloned = true, align = ""RIGHT_LEFT"", device = """"}
<unknown>:0: note: see current operation: ""func""() ( {
^bb0(%arg0: tensor<1x3x3xf32>):  // no predecessors
  %cst = ""std.constant""() {value = dense<0> : tensor<i32>} : () -> tensor<i32>
  %cst_0 = ""std.constant""() {value = dense<0.000000e+00> : tensor<f32>} : () -> tensor<f32>
  %0 = ""tf.MatrixDiagPartV3""(%arg0, %cst, %cst_0) {T = f32, _cloned = true, align = ""RIGHT_LEFT"", device = """"} : (tensor<1x3x3xf32>, tensor<i32>, tensor<f32>) -> tensor<1x3xf32>
  ""std.return""(%0) : (tensor<1x3xf32>) -> ()
}) {sym_name = ""main"", tf.entry_function = {control_outputs = """", inputs = ""input_1"", outputs = ""Identity""}, type = (tensor<1x3x3xf32>) -> tensor<1x3xf32>} : () -> ()
```

**Also, please include a link to the saved model or GraphDef**

The minimal example does not include a saved model, but see here for the [colab notebook](https://colab.research.google.com/drive/1-sYbh6In8Dubki0UtcnzjmEZuMiMa-Gd?usp=sharing).

**Failure details**
n/a

**RNN conversion support**
n/a

**Any other info / logs**

I encountered this conversion problem both in TensorFlow 2.3.0 (google colab), and in 2.3.1 (locally, installed via `pip`). Taking the diagonal of matrix is an operation that can be relevant when trying to build lightweight models, e.g. for use in resource constrained environments. In my use case, I am trying to take the diagonal of a Gram matrix in an image style application."
45320,Why do you want to ruin go's library?,"The only I want to say is ""for_core_protos_go_proto""!
I am very, very disappointed"
45319,Support for CUDA 11.1 and RTX 3090,"**System information**
- TensorFlow version: tf-nightly-gpu-2.5.0.dev20201201
- System: Ubuntu 18.04
- CUDA: 11.1
- NVIDIA Driver: 455.23.05

I just installed `tf-nightly-gpu-2.5.0.dev20201201` on my machine, and trying to run a test script, and errors shows below:

![image](https://user-images.githubusercontent.com/13287220/100816986-3dabe380-3482-11eb-9ffc-e2691251940c.png)

"
45317,tf.shape is broken when drop_remainder=True on TPUs,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04.3 LTS
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: n/a
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.3.0
- Python version: 3.7.7
- Bazel version (if compiling from source): n/a
- GCC/Compiler version (if compiling from source): n/a
- CUDA/cuDNN version: n/a
- GPU model and memory: n/a

**Describe the current behavior**
tf.shape gives incorrect tensor shapes when used with `drop_remainder=False` while batching a Dataset on TPUs.

**Describe the expected behavior**
tf.shape should always return the correct tensor shape regardless of the value of `drop_remainder`.

**Standalone code to reproduce the issue**
https://colab.research.google.com/drive/1EcQMGADKDdVTo5yETzYr3IUfqHjDMzX0?usp=sharing
"
45315,BUILD_TYPE=release broken for xtensa hifimini,"@tensorflow/micro

```
make -f tensorflow/lite/micro/tools/make/Makefile -j8 TARGET=xtensa OPTIMIZED_KERNEL_DIR=xtensa TARGET_ARCH=hifimini XTENSA_CORE=mini1m1m_RG keyword_benchmark BUILD_TYPE=release
```

fails with:
```
In file included from tensorflow/lite/micro/micro_profiler.cc:16:
./tensorflow/lite/micro/micro_profiler.h:63:26: error: private field 'reporter_' is not used [-Werror,-Wunused-private-field]
  tflite::ErrorReporter* reporter_;
                         ^
1 error generated.
make: *** [tensorflow/lite/micro/tools/make/Makefile:488: tensorflow/lite/micro/tools/make/gen/xtensa_hifimini/obj/tensorflow/lite/micro/micro_profiler.o] Error 1
make: *** Waiting for unfinished jobs....
tensorflow/lite/micro/micro_allocator.cc:187:18: error: private field 'reporter_' is not used [-Werror,-Wunused-private-field]
  ErrorReporter* reporter_ = nullptr;
                 ^
1 error generated.
make: *** [tensorflow/lite/micro/tools/make/Makefile:487: tensorflow/lite/micro/tools/make/gen/xtensa_hifimini/obj/tensorflow/lite/micro/micro_allocator.o] Error 1
In file included from tensorflow/lite/micro/micro_interpreter.cc:15:
./tensorflow/lite/micro/micro_interpreter.h:65:18: error: private field 'error_reporter_' is not used [-Werror,-Wunused-private-field]
  ErrorReporter* error_reporter_ = nullptr;

```
"
45313,"TFLite: Did not get operators, tensors, or buffers in subgraph 0. Error running on Android","**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Pixel 4a 5g
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.3.1
- Python version: 3.7
- CUDA/cuDNN version: Not using GPU

**Describe the current behavior**
I am able to convert a concrete function to a TensorFlow Lite model without errors.  I do get errors when trying to run the model on Android.  The error occurs when running this line on Android: tflite = new Interpreter(buffer, opt);


I don't believe this has to do with the Android code because I am able to run a TFLite model that I converted using a Keras model with this Android code.

I've been trying to convert a larger model with more operations and tensors but have gotten stuck on this error, I simplified the code to this but error remains.


**Android Error**

```
java.lang.IllegalArgumentException: Internal error: Cannot create interpreter: Did not get operators, tensors, or buffers in subgraph 0.
    
        at org.tensorflow.lite.NativeInterpreterWrapper.createInterpreter(Native Method)
        at org.tensorflow.lite.NativeInterpreterWrapper.init(NativeInterpreterWrapper.java:72)
        at org.tensorflow.lite.NativeInterpreterWrapper.<init>(NativeInterpreterWrapper.java:63)
        at org.tensorflow.lite.Interpreter.<init>(Interpreter.java:266)
        at arl.testnmt.MainActivity.loadModel(MainActivity.java:127)
        at arl.testnmt.MainActivity$2.run(MainActivity.java:108)
        at android.os.Handler.handleCallback(Handler.java:938)
        at android.os.Handler.dispatchMessage(Handler.java:99)
        at android.os.Looper.loop(Looper.java:223)
        at android.os.HandlerThread.run(HandlerThread.java:67)
```

**Standalone code to reproduce the issue (Python TFLite conversion)**

```
import tensorflow as tf
import os


class SimpleModel:
    def infer_tflite(self, features):
        return tf.zeros(shape=(250, 1), dtype=tf.dtypes.int32)


def tf_lite_convert():
    print('TensorFlow version')
    print(tf.__version__)
    model = SimpleModel()

    single_elem = tf.zeros(shape=[1, 20], dtype=tf.dtypes.int64)
    print('Running predictions using tflite inference')
    preds = model.infer_tflite(single_elem)
    print('TFlite inference results')
    print(preds)
    print('Turning to Concrete function')
    new_infer_fn = tf.function(model.infer_tflite, input_signature=[tf.TensorSpec((1, None), dtype=tf.int64)])
    infer_concrete = new_infer_fn.get_concrete_function()

    print('Running inference with concrete function')
    preds = infer_concrete(single_elem)
    print('Concrete Output prediction')
    print(preds)

    print('Saving to Tflite')
    converter = tf.lite.TFLiteConverter.from_concrete_functions([new_infer_fn.get_concrete_function()])

    converter.target_spec.supported_ops = [
      tf.lite.OpsSet.TFLITE_BUILTINS,  # enable TensorFlow Lite ops.
      tf.lite.OpsSet.SELECT_TF_OPS  # enable TensorFlow ops.
    ]
    converter.optimizations = [tf.lite.Optimize.DEFAULT]
    converter.target_spec.supported_types = [tf.float16]
    tflite_model_path = os.path.join('', 'lite_model.tflite')

    tflite_model = converter.convert()
    with tf.io.gfile.GFile(tflite_model_path, 'wb') as f:
        f.write(tflite_model)


if __name__ == '__main__':
    tf_lite_convert()
```

**Standalone code to reproduce the issue (Android)**
```
@WorkerThread
    public synchronized void loadModel(String modelPath) {
        AssetManager assetManager = this.context.getResources().getAssets();
        ByteBuffer buffer = loadModelFile(assetManager, modelPath);
        if (buffer == null){
            return;
        }
        Interpreter.Options opt = new Interpreter.Options();
        opt.setNumThreads(NUM_LITE_THREADS);
        tflite = new Interpreter(buffer, opt);
    }
```

**Gradle Dependencies**
```
dependencies {
    implementation fileTree(dir: 'libs', include: ['*.jar'])
    androidTestImplementation('androidx.test.espresso:espresso-core:3.1.0', {
        exclude group: 'com.android.support', module: 'support-annotations'
    })
    implementation 'androidx.appcompat:appcompat:1.2.0'
    implementation 'org.tensorflow:tensorflow-lite:2.3.0'
    implementation 'org.tensorflow:tensorflow-lite-select-tf-ops:2.3.0'
    implementation 'org.tensorflow:tensorflow-lite-support:0.1.0-rc1'
    implementation 'androidx.legacy:legacy-support-v4:1.0.0'
    implementation 'com.google.android.material:material:1.2.0'
    implementation 'androidx.constraintlayout:constraintlayout:1.1.3'
    implementation 'org.apache.commons:commons-io:1.3.2'
}
```

Any help would be greatly appreciated!
"
45312,TFlite gets the incorrect value dividing by zero or computing tf.log(x),"**System information**
- OS Platform and Distribution: MacOS Catalina 10.15.6
- TensorFlow installed: from binary
- TensorFlow version: The issue could be reproduced by TF1.x (TF 1.15.2) and TF2.x (TF 2.3.1)
- Python version: 3.6.5

**Describe the current behavior**
I have the following code that simply creates a TF graph whose output tensor is an input placeholder divided by a float32 constant 0. I would expect the evaluation value of the output tensor to be always ""Inf"" no matter which value is fed into the input placeholder. However, what I got from the following example is, the result from Tensorflow is expected, while the one from TFlite is the max limit of float32.

```
import os
import re
import tempfile

import numpy as np
import tensorflow as tf

is_tf_2 = bool(re.match(""2\.[0-9]+\.[0-9]+"", tf.version.VERSION))
if is_tf_2:
    print(""using TF2.x"")
    import tensorflow.compat.v1 as tf

    tf.compat.v1.disable_eager_execution()


def run_tf_ops():
    input_tensor = tf.placeholder(dtype=tf.float32, shape=[None])
    b = tf.constant(0.0, dtype=tf.float32)
    output_tensor = tf.divide(input_tensor, b)

    tf_session = tf.Session()

    with tempfile.TemporaryDirectory("""") as tempdir:
        converter = tf.lite.TFLiteConverter.from_session(
            sess=tf_session,
            input_tensors=[input_tensor],
            output_tensors=[output_tensor],
        )
        tflite_model = converter.convert()
        tflite_saved_model_path = os.path.join(tempdir, ""saved_model.tflite"")
        with open(tflite_saved_model_path, ""wb"") as f:
            f.write(tflite_model)

        # Test TFLite load
        # Load the TFLite model and allocate tensors.
        interpreter = tf.lite.Interpreter(model_path=tflite_saved_model_path)
        interpreter.allocate_tensors()
        # Get input and output tensors.
        input_details = interpreter.get_input_details()
        output_details = interpreter.get_output_details()

        # Test the model on random input data.
        # get output from tflite model
        interpreter.set_tensor(input_details[0][""index""], [np.float32(1.0)])
        interpreter.invoke()
        output_data_from_tflite = interpreter.get_tensor(output_details[0][""index""])

    print(
        f""Tensorflow result: {tf_session.run(output_tensor, feed_dict={input_tensor: [np.float32(1.0)]})}""
    )
    print(f""TFLite result: {output_data_from_tflite}"")


if __name__ == ""__main__"":
    run_tf_ops()
```
The interesting behavior is if I replace the input placeholder `input_tensor` with a constant float32 tensor like `input_tensor = tf.constant(value=[1.0], dtype=tf.float32)`(also remove the code on feeding data), both Tensorflow and TFlite get the correct result `Inf` in TF 1.15.2, but would have the same issue in TF 2.3.1.

**NOTE** The same behavior happens for other operations such as ""tf.log(x)"" when we feed x with run time data 0.

**Standalone code to reproduce the issue**
The issue could be 100% reproduced by running the above code with the system info.

"
45310,Segmentation fault during training simple decision tree classifier,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Mac Catalina 10.15.7
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): v2.3.0-54-gfcc4b966f1 2.3.1
- Python version: 3.8.6
- CUDA/cuDNN version: NA?
- GPU model and memory: using CPU

**Describe the current behavior**

I was trying to train a boosted tree, got a seg fault, and ultimately replicated it with this canned example from https://www.tensorflow.org/tutorials/estimator/boosted_trees .

What I get is a segmentation fault detailed below.

**Describe the expected behavior**

I would expect this to run and print the result, rather than giving a segmentation fault.

**Standalone code to reproduce the issue**
```
import numpy as np
import pandas as pd

# Load dataset.
dftrain = pd.read_csv('https://storage.googleapis.com/tf-datasets/titanic/train.csv')
dfeval = pd.read_csv('https://storage.googleapis.com/tf-datasets/titanic/eval.csv')
y_train = dftrain.pop('survived')
y_eval = dfeval.pop('survived')

import tensorflow as tf
tf.random.set_seed(123)

CATEGORICAL_COLUMNS = ['sex', 'n_siblings_spouses', 'parch', 'class', 'deck',
                       'embark_town', 'alone']
NUMERIC_COLUMNS = ['age', 'fare']

def one_hot_cat_column(feature_name, vocab):
  return tf.feature_column.indicator_column(
      tf.feature_column.categorical_column_with_vocabulary_list(feature_name,
                                                 vocab))
feature_columns = []
for feature_name in CATEGORICAL_COLUMNS:
  # Need to one-hot encode categorical features.
  vocabulary = dftrain[feature_name].unique()
  feature_columns.append(one_hot_cat_column(feature_name, vocabulary))

for feature_name in NUMERIC_COLUMNS:
  feature_columns.append(tf.feature_column.numeric_column(feature_name,
                                           dtype=tf.float32))

# Use entire batch since this is such a small dataset.
NUM_EXAMPLES = len(y_train)

def make_input_fn(X, y, n_epochs=None, shuffle=True):
  def input_fn():
    dataset = tf.data.Dataset.from_tensor_slices((dict(X), y))
    if shuffle:
      dataset = dataset.shuffle(NUM_EXAMPLES)
    # For training, cycle thru dataset as many times as need (n_epochs=None).
    dataset = dataset.repeat(n_epochs)
    # In memory training doesn't use batching.
    dataset = dataset.batch(NUM_EXAMPLES)
    return dataset
  return input_fn

# Training and evaluation input functions.
train_input_fn = make_input_fn(dftrain, y_train)
eval_input_fn = make_input_fn(dfeval, y_eval, shuffle=False, n_epochs=1)

# Since data fits into memory, use entire dataset per layer. It will be faster.
# Above one batch is defined as the entire dataset.
n_batches = 1
est = tf.estimator.BoostedTreesClassifier(feature_columns,
                                          n_batches_per_layer=n_batches)

# The model will stop training once the specified number of trees is built, not
# based on the number of steps.
est.train(train_input_fn, max_steps=100)

# Eval.
result = est.evaluate(eval_input_fn)
print(pd.Series(result))
```

**Other info / logs**
```
WARNING:tensorflow:Using temporary folder as model directory: /var/folders/97/twhbc2yn6l77_rh7vn94hf7c0000gp/T/tmptaagswd_
WARNING:tensorflow:From /Users/martinl/PyVenvs/tf/lib/python3.8/site-packages/tensorflow_estimator/python/estimator/canned/boosted_trees.py:398: VocabularyListCategoricalColumn._num_buckets (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.
Instructions for updating:
The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.
WARNING:tensorflow:From /Users/martinl/PyVenvs/tf/lib/python3.8/site-packages/tensorflow/python/training/training_util.py:235: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
WARNING:tensorflow:Issue encountered when serializing resources.
Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.
'_Resource' object has no attribute 'name'
2020-12-01 16:40:43.597377: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-12-01 16:40:43.614731: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f8d8e78c990 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-12-01 16:40:43.614747: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
WARNING:tensorflow:Issue encountered when serializing resources.
Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.
'_Resource' object has no attribute 'name'
WARNING:tensorflow:Issue encountered when serializing resources.
Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.
'_Resource' object has no attribute 'name'
WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.
WARNING:tensorflow:Issue encountered when serializing resources.
Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.
'_Resource' object has no attribute 'name'
WARNING:tensorflow:From /Users/martinl/PyVenvs/tf/lib/python3.8/site-packages/tensorflow_estimator/python/estimator/canned/head.py:637: auc (from tensorflow.python.ops.metrics_impl) is deprecated and will be removed in a future version.
Instructions for updating:
The value of AUC returned by this may race with the update so this is deprecated. Please use tf.keras.metrics.AUC instead.
WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to ""careful_interpolation"" instead.
WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to ""careful_interpolation"" instead.
zsh: segmentation fault  python temp2.py
```"
45308,Docs for install cuda 11.0 and cudnn 8,"Now that tensorflow 2.4.0 is almost out with cuda 11.0 and cudnn 8 support, it would be nice to have the instructions updated for GPU installation."
45306,micro: port op FILL from lite,"@tensorflow/micro

This issue tracks my work porting operator FILL from lite to micro.

The port will be submitted in a number of PRs. Here's a rough flight plan per @advaitjain and @petewarden:

- PR 1: Extract the code for parsing the op from a flatbuffer out of ParseOpDataTfLite in tensorflow/lite/core/api/flatbuffer_conversions.cc into a standalone function that can be called from micro's op resolver
- PR 2: Extract the reference implementation out of tensorflow/lite/kernels/internal/reference/reference_ops.h into its own header which can be included without dragging in reference_ops.h's dependences
- PR 3: Copy operator from lite to micro without making any changes or including in the build
- PR 4: Delete extra code from the micro copy of the operator
- PR 5: Port micro copy of operator as necessary and add a corresponding test

"
45305,Tensorflow 2.3 Conversion to .tflite fails if last layer is Reshape (tf.keras.functional API),"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04 or Colab
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.3
- Python version: 3.6 or 3.7

**Describe the current behavior**
I made an easily reproducible example in this notebook
https://colab.research.google.com/drive/12Wj60KVP-cMxteiZXdZRmSxJaPX37D4c?usp=sharing

I'm currently porting my framework for ML on the edge, aXeleRate to tf.keras. You can find the code for converters here
https://github.com/AIWintermuteAI/aXeleRate/blob/8e66a39dadb469998a62c365c37c39984b30de4d/axelerate/networks/common_utils/convert.py#L180

Currently the issue is that when converting Keras model to .tflite, if last layer of the model is Reshape, the conversion fails silently. It doesn't output any errors, but the resulting model is not usable by Coral Edge TPU converter and also is deipalyed as wrong file type in Ubuntu, see the screenshot:
![Screenshot from 2020-12-02 01-27-06](https://user-images.githubusercontent.com/32562299/100774882-8ab99680-343d-11eb-972a-99188a0247d8.png)
This conversion works fine with Tensorflow 1.15. I think I can make it work by using old converter, but I'd like to report the issue regardless, in case it affects other users.

**Describe the expected behavior**
Keras model converting properly to .tflite format regardless of last layer used in the model.

**Standalone code to reproduce the issue**
https://colab.research.google.com/drive/12Wj60KVP-cMxteiZXdZRmSxJaPX37D4c?usp=sharing

For converter code, refer to 
https://github.com/AIWintermuteAI/aXeleRate/blob/8e66a39dadb469998a62c365c37c39984b30de4d/axelerate/networks/common_utils/convert.py#L180

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
Possibly has relation to
https://stackoverflow.com/questions/62783988/reshape-cc55-stretch-dim-1-node-number-x-reshape-failed-to-prepare"
45303,"KeyError: ""The name 'import/final_result' refers to an Operation not in the graph.""","Traceback (most recent call last):
  File ""D:/xcr/human-action-classification-master/human-action-classification-master/run_webcam.py"", line 65, in <module>
    pose_class = label_img.classify(image)
  File ""D:\xcr\human-action-classification-master\human-action-classification-master\scripts\label_image.py"", line 99, in classify
    output_operation = graph.get_operation_by_name(output_name)
  File ""C:\Anaconda3\envs\tensorflow-gpu\lib\site-packages\tensorflow\python\framework\ops.py"", line 3606, in get_operation_by_name
    return self.as_graph_element(name, allow_tensor=False, allow_operation=True)
  File ""C:\Anaconda3\envs\tensorflow-gpu\lib\site-packages\tensorflow\python\framework\ops.py"", line 3478, in as_graph_element
    return self._as_graph_element_locked(obj, allow_tensor, allow_operation)
  File ""C:\Anaconda3\envs\tensorflow-gpu\lib\site-packages\tensorflow\python\framework\ops.py"", line 3538, in _as_graph_element_locked
    ""graph."" % repr(name))
KeyError: ""The name 'import/final_result' refers to an Operation not in the graph."""
45302,error in converting ssdlite_mobilenet_v2_coco_2018_05_09 tflite_graph.pb to tflite,"Windows10 , tensorflow 1.15.0
I want to trained a tflite model base on `ssdlite_mobilenet_v2_coco_2018_05_09` pretrained model, and this is the resulted [tflite_graph.pb](https://drive.google.com/file/d/10ejimZpsIOrtL_FR-DnsbVaa_cxDTwxj/view?usp=sharing), then i used below script to convert it to tflite format :
```
import os
import cv2
import numpy as np
import tensorflow as tf

print(tf.__version__)

Representative_Dataset_Dir = r""D:\MachineLearning\DataSet\iGuardDataset\IMAGE\Rider-384-484-images\""
Image_Names = os.listdir(Representative_Dataset_Dir)

def representative_dataset_gen():
    n = 0
    NORM_H = 300
    NORM_W = 300
    ncalib = 100
    assert ncalib <= len(Image_Names), ""ncalib should smaller than the number of dataset""
    for i in range(ncalib):
        n += 1
        img0 = cv2.imread(Representative_Dataset_Dir + Image_Names[i])
        img = cv2.resize(img0, (NORM_H, NORM_W))
        img = img[:, :, ::-1].transpose(2, 0, 1)  # BGR to RGB, to 3x300x300
        img = np.ascontiguousarray(img)
        input = np.transpose(img, [1, 2, 0])
        input = np.expand_dims(input, axis=0).astype(np.float32)
        input /= 255.0
        yield [input]

graph_def_file = r""E:\iGuard\TrainedModel\tflite\2020121ssdlite_mobilenet_v2_coco_2018_05_09\tflite_graph.pb""
input_arrays=[""normalized_input_image_tensor""]
output_arrays=['TFLite_Detection_PostProcess', 'TFLite_Detection_PostProcess:1', 'TFLite_Detection_PostProcess:2', 'TFLite_Detection_PostProcess:3']
input_shape={""normalized_input_image_tensor"": [1, 300, 300, 3]}

converter = tf.compat.v1.lite.TFLiteConverter.from_frozen_graph(graph_def_file, input_arrays, output_arrays, input_shape)
converter.optimizations = [tf.lite.Optimize.DEFAULT]
converter.representative_dataset = representative_dataset_gen
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]
converter.inference_input_type = tf.uint8  # or tf.int8
converter.inference_output_type = tf.uint8
tflite_uint8_model = converter.convert()
open(""uint8_model_converted_from_""+os.path.basename(os.path.dirname(graph_def_file))+"".tflite"", ""wb"").write(tflite_uint8_model)
```
The output log is ：
```
C:\Users\wadew\.conda\envs\tf1.15\python.exe C:/MachineLearning/CV/TFLiteConverter_uint8-new.py
2020-12-01 23:37:07.472348: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_100.dll
1.15.0
2020-12-01 23:37:10.963739: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library nvcuda.dll
2020-12-01 23:37:11.014012: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: GeForce GTX 1660 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.59
pciBusID: 0000:01:00.0
2020-12-01 23:37:11.014441: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_100.dll
2020-12-01 23:37:11.026263: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_100.dll
2020-12-01 23:37:11.040675: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_100.dll
2020-12-01 23:37:11.046711: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_100.dll
2020-12-01 23:37:11.064293: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_100.dll
2020-12-01 23:37:11.074437: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_100.dll
2020-12-01 23:37:11.120022: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll
2020-12-01 23:37:11.120884: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2020-12-01 23:37:11.121677: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2
2020-12-01 23:37:11.126202: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: GeForce GTX 1660 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.59
pciBusID: 0000:01:00.0
2020-12-01 23:37:11.126612: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_100.dll
2020-12-01 23:37:11.127010: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_100.dll
2020-12-01 23:37:11.127368: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_100.dll
2020-12-01 23:37:11.127708: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_100.dll
2020-12-01 23:37:11.128043: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_100.dll
2020-12-01 23:37:11.128405: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_100.dll
2020-12-01 23:37:11.128748: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll
2020-12-01 23:37:11.129582: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2020-12-01 23:37:11.981571: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-12-01 23:37:11.981937: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 
2020-12-01 23:37:11.982171: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N 
2020-12-01 23:37:11.985844: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 4629 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1660 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5)
Traceback (most recent call last):
  File ""C:/MachineLearning/CV/TFLiteConverter_uint8-new.py"", line 67, in <module>
    tflite_uint8_model = converter.convert()
  File ""C:\Users\wadew\.conda\envs\tf1.15\lib\site-packages\tensorflow_core\lite\python\lite.py"", line 989, in convert
    **converter_kwargs)
  File ""C:\Users\wadew\.conda\envs\tf1.15\lib\site-packages\tensorflow_core\lite\python\convert.py"", line 412, in toco_convert_graph_def
    enable_mlir_converter=enable_mlir_converter)
  File ""C:\Users\wadew\.conda\envs\tf1.15\lib\site-packages\tensorflow_core\lite\python\convert.py"", line 200, in toco_convert_protos
    raise ConverterError(""See console for info.\n%s\n%s\n"" % (stdout, stderr))
tensorflow.lite.python.convert.ConverterError: See console for info.
2020-12-01 23:37:12.759297: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_100.dll
2020-12-01 23:37:16.367452: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TFLite_Detection_PostProcess
2020-12-01 23:37:16.742053: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 1895 operators, 2800 arrays (0 quantized)
2020-12-01 23:37:16.960765: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 1895 operators, 2800 arrays (0 quantized)
2020-12-01 23:37:17.515990: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 213 operators, 407 arrays (0 quantized)
2020-12-01 23:37:17.530260: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Group bidirectional sequence lstm/rnn: 213 operators, 407 arrays (0 quantized)
2020-12-01 23:37:17.540882: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before dequantization graph transformations: 213 operators, 407 arrays (0 quantized)
2020-12-01 23:37:17.561096: I tensorflow/lite/toco/allocate_transient_arrays.cc:345] Total transient array allocated size: 20160000 bytes, theoretical optimal value: 17280000 bytes.
2020-12-01 23:37:17.563117: I tensorflow/lite/toco/toco_tooling.cc:439] Estimated count of arithmetic ops: 837311268 ops, equivalently 418655634 MACs
2020-12-01 23:37:17.563500: I tensorflow/lite/toco/toco_tooling.cc:454] Number of parameters: 1733299
2020-12-01 23:37:17.566015: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/Conv/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.
2020-12-01 23:37:17.566827: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/expanded_conv/depthwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.
2020-12-01 23:37:17.567687: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/expanded_conv/project/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.
2020-12-01 23:37:17.568541: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/expanded_conv_1/expand/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.
2020-12-01 23:37:17.569396: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.
2020-12-01 23:37:17.570257: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/expanded_conv_1/project/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.
2020-12-01 23:37:17.571181: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/expanded_conv_2/expand/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.
2020-12-01 23:37:17.572052: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.
2020-12-01 23:37:17.572922: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/expanded_conv_2/project/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.
2020-12-01 23:37:17.573788: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/expanded_conv_2/post_activation_bypass_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.
2020-12-01 23:37:17.574672: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/expanded_conv_3/expand/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.
2020-12-01 23:37:17.575528: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.
2020-12-01 23:37:17.576390: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/expanded_conv_3/project/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.
2020-12-01 23:37:17.577248: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/expanded_conv_4/expand/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.
2020-12-01 23:37:17.578103: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.
2020-12-01 23:37:17.578969: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/expanded_conv_4/project/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.
2020-12-01 23:37:17.579826: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/expanded_conv_4/post_activation_bypass_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.
2020-12-01 23:37:17.580705: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/expanded_conv_5/expand/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.
2020-12-01 23:37:17.581562: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.
2020-12-01 23:37:17.582425: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/expanded_conv_5/project/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.
2020-12-01 23:37:17.583286: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/expanded_conv_5/post_activation_bypass_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.
2020-12-01 23:37:17.584175: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/expanded_conv_6/expand/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.
2020-12-01 23:37:17.585030: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.
2020-12-01 23:37:17.585890: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/expanded_conv_6/project/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.
2020-12-01 23:37:17.586746: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/expanded_conv_7/expand/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.
2020-12-01 23:37:17.587606: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.
2020-12-01 23:37:17.588559: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/expanded_conv_7/project/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.
2020-12-01 23:37:17.589429: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/expanded_conv_7/post_activation_bypass_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.
2020-12-01 23:37:17.590323: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/expanded_conv_8/expand/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.
2020-12-01 23:37:17.591182: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.
2020-12-01 23:37:17.592045: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/expanded_conv_8/project/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.
2020-12-01 23:37:17.592902: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/expanded_conv_8/post_activation_bypass_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.
2020-12-01 23:37:17.593785: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/expanded_conv_9/expand/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.
2020-12-01 23:37:17.594642: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.
2020-12-01 23:37:17.595600: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/expanded_conv_9/project/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.
2020-12-01 23:37:17.596492: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/expanded_conv_9/post_activation_bypass_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.
2020-12-01 23:37:17.597399: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/expanded_conv_10/expand/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.
2020-12-01 23:37:17.598271: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.
2020-12-01 23:37:17.599142: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/expanded_conv_10/project/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.
2020-12-01 23:37:17.600004: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/expanded_conv_11/expand/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.
2020-12-01 23:37:17.600865: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.
2020-12-01 23:37:17.601753: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/expanded_conv_11/project/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.
2020-12-01 23:37:17.602624: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/expanded_conv_11/post_activation_bypass_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.
2020-12-01 23:37:17.603517: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/expanded_conv_12/expand/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.
2020-12-01 23:37:17.604386: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.
2020-12-01 23:37:17.605258: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/expanded_conv_12/project/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.
2020-12-01 23:37:17.606125: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/expanded_conv_12/post_activation_bypass_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.
2020-12-01 23:37:17.607018: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/expanded_conv_13/expand/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.
2020-12-01 23:37:17.607885: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.
2020-12-01 23:37:17.608741: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/expanded_conv_13/project/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.
2020-12-01 23:37:17.609605: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/expanded_conv_14/expand/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.
2020-12-01 23:37:17.610465: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.
2020-12-01 23:37:17.611330: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/expanded_conv_14/project/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.
2020-12-01 23:37:17.612197: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/expanded_conv_14/post_activation_bypass_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.
2020-12-01 23:37:17.613080: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/expanded_conv_15/expand/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.
2020-12-01 23:37:17.613943: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.
2020-12-01 23:37:17.614803: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/expanded_conv_15/project/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.
2020-12-01 23:37:17.615736: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/expanded_conv_15/post_activation_bypass_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.
2020-12-01 23:37:17.616639: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/expanded_conv_16/expand/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.
2020-12-01 23:37:17.617509: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.
2020-12-01 23:37:17.618375: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/expanded_conv_16/project/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.
2020-12-01 23:37:17.619234: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/Conv_1/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.
2020-12-01 23:37:17.620055: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_192/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.
2020-12-01 23:37:17.620928: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_384_depthwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.
2020-12-01 23:37:17.621822: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_384/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.
2020-12-01 23:37:17.622696: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_96/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.
2020-12-01 23:37:17.623562: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_192_depthwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.
2020-12-01 23:37:17.624546: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_192/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.
2020-12-01 23:37:17.625449: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_96/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.
2020-12-01 23:37:17.626324: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_192_depthwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.
2020-12-01 23:37:17.627230: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_192/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.
2020-12-01 23:37:17.628108: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_48/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.
2020-12-01 23:37:17.628974: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_96_depthwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.
2020-12-01 23:37:17.629868: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_96/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.
2020-12-01 23:37:17.630741: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output BoxPredictor_0/BoxEncodingPredictor_depthwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.
2020-12-01 23:37:17.631601: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output BoxPredictor_0/ClassPredictor_depthwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.
2020-12-01 23:37:17.632431: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output BoxPredictor_1/BoxEncodingPredictor_depthwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.
2020-12-01 23:37:17.633275: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output BoxPredictor_1/ClassPredictor_depthwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.
2020-12-01 23:37:17.634102: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output BoxPredictor_2/BoxEncodingPredictor_depthwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.
2020-12-01 23:37:17.634945: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output BoxPredictor_2/ClassPredictor_depthwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.
2020-12-01 23:37:17.635774: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output BoxPredictor_3/BoxEncodingPredictor_depthwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.
2020-12-01 23:37:17.636614: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output BoxPredictor_3/ClassPredictor_depthwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.
2020-12-01 23:37:17.637442: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output BoxPredictor_4/BoxEncodingPredictor_depthwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.
2020-12-01 23:37:17.638287: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output BoxPredictor_4/ClassPredictor_depthwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.
2020-12-01 23:37:17.639115: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output BoxPredictor_5/BoxEncodingPredictor_depthwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.
2020-12-01 23:37:17.639956: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output BoxPredictor_5/ClassPredictor_depthwise/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.
2020-12-01 23:37:17.640781: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output BoxPredictor_0/BoxEncodingPredictor/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.
2020-12-01 23:37:17.641604: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output BoxPredictor_0/ClassPredictor/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.
2020-12-01 23:37:17.642405: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output BoxPredictor_1/BoxEncodingPredictor/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.
2020-12-01 23:37:17.643225: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output BoxPredictor_1/ClassPredictor/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.
2020-12-01 23:37:17.644033: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output BoxPredictor_2/BoxEncodingPredictor/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.
2020-12-01 23:37:17.644852: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output BoxPredictor_2/ClassPredictor/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.
2020-12-01 23:37:17.645656: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output BoxPredictor_3/BoxEncodingPredictor/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.
2020-12-01 23:37:17.646475: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output BoxPredictor_3/ClassPredictor/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.
2020-12-01 23:37:17.647284: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output BoxPredictor_4/BoxEncodingPredictor/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.
2020-12-01 23:37:17.648102: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output BoxPredictor_4/ClassPredictor/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.
2020-12-01 23:37:17.648905: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output BoxPredictor_5/BoxEncodingPredictor/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.
2020-12-01 23:37:17.649725: W tensorflow/lite/toco/tflite/export.cc:502] FAKE_QUANT operation {FakeQuant operator with output BoxPredictor_5/ClassPredictor/act_quant/FakeQuantWithMinMaxVars} was not converted. If running quantized make sure you are passing --inference_type=QUANTIZED_UINT8 and values for --std_values and --mean_values.
2020-12-01 23:37:17.651419: E tensorflow/lite/toco/toco_tooling.cc:481] We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md
 and pasting the following:

Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: ADD, CONCATENATION, CONV_2D, DEPTHWISE_CONV_2D, FAKE_QUANT, LOGISTIC, RESHAPE. Here is a list of operators for which you will need custom implementations: TFLite_Detection_PostProcess.
Traceback (most recent call last):
  File ""C:\Users\wadew\.conda\envs\tf1.15\Scripts\toco_from_protos-script.py"", line 10, in <module>
    sys.exit(main())
  File ""C:\Users\wadew\.conda\envs\tf1.15\lib\site-packages\tensorflow_core\lite\toco\python\toco_from_protos.py"", line 89, in main
    app.run(main=execute, argv=[sys.argv[0]] + unparsed)
  File ""C:\Users\wadew\.conda\envs\tf1.15\lib\site-packages\tensorflow_core\python\platform\app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""C:\Users\wadew\.conda\envs\tf1.15\lib\site-packages\absl\app.py"", line 299, in run
    _run_main(main, args)
  File ""C:\Users\wadew\.conda\envs\tf1.15\lib\site-packages\absl\app.py"", line 250, in _run_main
    sys.exit(main(argv))
  File ""C:\Users\wadew\.conda\envs\tf1.15\lib\site-packages\tensorflow_core\lite\toco\python\toco_from_protos.py"", line 52, in execute
    enable_mlir_converter)
Exception: We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md
 and pasting the following:

Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: ADD, CONCATENATION, CONV_2D, DEPTHWISE_CONV_2D, FAKE_QUANT, LOGISTIC, RESHAPE. Here is a list of operators for which you will need custom implementations: TFLite_Detection_PostProcess.

Process finished with exit code 1
```
"
45301,"I am trying to convert yolov3 to a full uint8 tflite model after, i got this error : Quantized not yet supported for op : 'EXP'","**System information**
- I used Google Colab.
- TensorFlow installed from google colab :
- TensorFlow version 2.3.0, after I tried 2.3.1 and 2.4.0-rc2 (it gives the same error):

**I'm using the Python API**
If possible, please share a link to Colab/Jupyter/any notebook
https://colab.research.google.com/drive/1i1gXJyVpiu9qngAiQEhMZoU1Q6LFKf0j#scrollTo=3CPc8AYBxa1U
import tensorflow as tf
converter = tf.lite.TFLiteConverter.from_saved_model(""yolov3-416"")
def representative_dataset_gen():
    for _ in range(250):
        yield [tf.random.uniform(shape=[1, 416, 416, 3], minval=0.0, maxval=1.0, dtype=tf.dtypes.float32)]

converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]    
converter.optimizations = [tf.lite.Optimize.DEFAULT]
converter.allow_custom_ops = True
converter.representative_dataset = representative_dataset_gen
converter.inference_input_type = tf.int8  # or tf.uint8
converter.inference_output_type = tf.int8  # or tf.uint8
tflite_quant_model_uint8_io = converter.convert()
# Save the model.
with open('tflite_quant_model_uint8_io.tflite', 'wb') as f:
  f.write(tflite_quant_model_uint8_io)

**The output from the converter invocation**
Traceback (most recent call last):
  File ""convertToTflite_uint8_io.py"", line 15, in <module>
    tflite_quant_model_uint8_io = converter.convert()
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/lite.py"", line 742, in convert
    result = self._calibrate_quantize_model(result, **flags)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/lite.py"", line 461, in _calibrate_quantize_model
    inference_output_type, allow_float, activations_type)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/optimize/calibrator.py"", line 104, in calibrate_and_quantize
    np.dtype(activations_type.as_numpy_dtype()).num)
RuntimeError: Quantization not yet supported for op: 'EXP'.
Quantization not yet supported for op: 'EXP'.
Quantization not yet supported for op: 'EXP'.
Quantization not yet supported for op: 'EXP'.
Quantization not yet supported for op: 'EXP'.
Quantization not yet supported for op: 'EXP'.
Quantization not yet supported for op: 'EXP'.
Quantization not yet supported for op: 'EXP'.
Quantization not yet supported for op: 'EXP'
"
45300,TF 2.4.0-rc3: Mismatched protobuf version in setup.py and workspace.bzl,"Protobuf version in `tensorflow/workspace.bzl` and `tensorflow/tools/pip_package/setup.py` aren't same in TF 2.4.0-rc3.
setup.py has protobuf 3.13 and workspace.bzl still fetches 3.9.2 during the build. Same is the case with master branch.
Is this intentional or to be done item?

"
45299,Tensorflow GPU stuck at epoch 1 on rtx3070 gpu,"tensorflow is not running corectly on rtx3070 gpu same code is running well on gtx1050 ti and on cpu but when i run it on gpu it take 5 min than print last 2 line saying Epoch 1/1 and it stucks there please help


2020-12-01 18:08:04.785338: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll
Using TensorFlow backend.
2020-12-01 18:08:06.705948: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library nvcuda.dll
2020-12-01 18:08:06.732000: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce RTX 3070 computeCapability: 8.6
coreClock: 1.725GHz coreCount: 46 deviceMemorySize: 8.00GiB deviceMemoryBandwidth: 417.29GiB/s
2020-12-01 18:08:06.732171: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll
2020-12-01 18:08:06.735229: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll
2020-12-01 18:08:06.738060: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_10.dll
2020-12-01 18:08:06.739052: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_10.dll
2020-12-01 18:08:06.742158: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_10.dll
2020-12-01 18:08:06.743937: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_10.dll
2.1.0
2020-12-01 18:08:06.751015: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll
2020-12-01 18:08:06.751155: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-12-01 18:08:06.795732: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2
2020-12-01 18:08:06.798286: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce RTX 3070 computeCapability: 8.6
coreClock: 1.725GHz coreCount: 46 deviceMemorySize: 8.00GiB deviceMemoryBandwidth: 417.29GiB/s
2020-12-01 18:08:06.798450: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll
2020-12-01 18:08:06.798533: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll
2020-12-01 18:08:06.798613: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_10.dll
2020-12-01 18:08:06.798693: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_10.dll
2020-12-01 18:08:06.798774: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_10.dll
2020-12-01 18:08:06.798858: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_10.dll
2020-12-01 18:08:06.798941: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll
2020-12-01 18:08:06.799044: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-12-01 18:10:40.051239: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-12-01 18:10:40.051340: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 
2020-12-01 18:10:40.051396: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N 
2020-12-01 18:10:40.052361: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6254 MB memory) -> physical GPU (device: 0, name: GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6)
2940 2940 1260 1260
Epoch 1/1
2020-12-01 18:10:41.127488: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll


**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): 
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): 
- TensorFlow version (use command below): conda install tensorflow-gpu==2.1.0
- Python version:3.6
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:cuda 10.1 , cudnn 7.6
- GPU model and memory: rtx 3070 8 gb

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

2020-12-01 18:15:14.820555: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll
unknown 2.1.0



**Describe the current behavior**

**Describe the expected behavior**

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
45297,randomly discontinuation when model training with tf.keras in tf-gpu-2.1,"When I use model.fit to train my model, I get the below errors randomly at the beginning of the steps, or the code and gpus suddenly shut down without any error. Even sometimes self-reset occurs. 

Python Version: 3.7
Tesorflow Version: 2.1
OS: Windows 10
GPU Card: RTX 2080Ti * 4
CUDA: 10.1
CUDNN: 7.6.5.32

errors as follows
 E tensorflow/stream_executor/cuda/cuda_event.cc:29] Error polling for event status: failed to query event: CUDA_ERROR_LAUNCH_FAILED: unspecified launch failure
 F tensorflow/core/common_runtime/gpu/gpu_event_mgr.cc:273] Unexpected Event status: 1"
45295,module 'gast' has no attribute 'Ellipsis',"``` python
import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
from tqdm.autonotebook import tqdm
%matplotlib inline
from IPython import display
import pandas as pd
import tensorflow_probability as tfp
ds = tfp.distribution
```

![image](https://user-images.githubusercontent.com/46621519/100713763-c0379300-33ef-11eb-81ea-3938e2204309.png)



"
45294,Resource Excuted error while training object detection model in google colab,i try to train model  Google  Colab using gpu . while training at one time i got error like rosirce exvuted error  OMM like this. i don't understand why i got this error. Please help me to sort it out this error.
45293,Tensorflow Runtime error,"Traceback (most recent call last):
  File ""C:\Users\raj\anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\raj\anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\raj\anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\raj\anaconda3\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\raj\anaconda3\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: A dynamic link library (DLL) initialization routine failed.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""model_main_tf2.py"", line 31, in <module>
    import tensorflow.compat.v2 as tf
  File ""C:\Users\raj\anaconda3\lib\site-packages\tensorflow\__init__.py"", line 101, in <module>
    from tensorflow_core import *
  File ""C:\Users\raj\anaconda3\lib\site-packages\tensorflow_core\__init__.py"", line 40, in <module>
    from tensorflow.python.tools import module_util as _module_util
  File ""C:\Users\raj\anaconda3\lib\site-packages\tensorflow\__init__.py"", line 50, in __getattr__
    module = self._load()
  File ""C:\Users\raj\anaconda3\lib\site-packages\tensorflow\__init__.py"", line 44, in _load
    module = _importlib.import_module(self.__name__)
  File ""C:\Users\raj\anaconda3\lib\importlib\__init__.py"", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""C:\Users\raj\anaconda3\lib\site-packages\tensorflow_core\python\__init__.py"", line 49, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""C:\Users\raj\anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 74, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""C:\Users\raj\anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow.py"", line 58, in <module>
    from tensorflow.python.pywrap_tensorflow_internal import *
  File ""C:\Users\raj\anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 28, in <module>
    _pywrap_tensorflow_internal = swig_import_helper()
  File ""C:\Users\raj\anaconda3\lib\site-packages\tensorflow_core\python\pywrap_tensorflow_internal.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)
  File ""C:\Users\raj\anaconda3\lib\imp.py"", line 242, in load_module
    return load_dynamic(name, filename, file)
  File ""C:\Users\raj\anaconda3\lib\imp.py"", line 342, in load_dynamic
    return _load(spec)
ImportError: DLL load failed: A dynamic link library (DLL) initialization routine failed.


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/errors

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help."
45292,[mbed] ERROR: Unable to write build ignore file ,"hi,guys, when I compile the example project ""image_recognition_experimental"", a mbed error occurs.
```
salt@ubuntu:/usr/local/project/tensorflow/tensorflow/lite/micro/tools/make/gen/linux_x86_64/prj/image_recognition/mbed$ sudo mbed compile -m auto -t GCC_ARM --profile release
[sudo] password for salt: 
[mbed] Working path ""/usr/local/project/tensorflow/tensorflow/lite/micro/tools/make/gen/linux_x86_64/prj/image_recognition/mbed"" (program)
[mbed] Detected ""DISCO_F746NG"" connected to ""/media/salt/DIS_F746NG"" and using com port ""/dev/ttyACM0""
[mbed] ERROR: Unable to write build ignore file in ""/usr/local/project/tensorflow/BUILD/.mbedignore""
---
But the ""BUILD"" is not a folder, and does have write permission, just as follows,

root@ubuntu:/usr/local/project/tensorflow# ll
total 580
drwxr-xr-x  8 root root   4096 Nov 30 17:08 ./
drwxr-xr-x  3 root root   4096 Nov 30 17:02 ../
-rw-r--r--  1 root root   2219 Nov 30 17:02 ACKNOWLEDGMENTS
-rw-r--r--  1 root root   1174 Nov 30 17:02 arm_compiler.BUILD
-rw-r--r--  1 root root    349 Nov 30 17:02 AUTHORS
-rw-r--r--  1 root root  32964 Nov 30 17:02 .bazelrc
-rw-r--r--  1 root root      6 Nov 30 17:02 .bazelversion
-rw-rw-rw-  1 root root    122 Nov 30 17:02 BUILD
-rw-r--r--  1 root root   5360 Nov 30 17:02 CODE_OF_CONDUCT.md
-rw-r--r--  1 root root    573 Nov 30 17:02 CODEOWNERS
-rwxr-xr-x  1 root root    285 Nov 30 17:02 configure*
-rw-r--r--  1 root root    782 Nov 30 17:02 configure.cmd
-rw-r--r--  1 root root  53321 Nov 30 17:02 configure.py
-rw-r--r--  1 root root   9906 Nov 30 17:02 CONTRIBUTING.md
drwxrwxrwx  8 root root   4096 Nov 30 17:08 .git/
drwxr-xr-x  4 root root   4096 Nov 30 17:02 .github/
-rw-r--r--  1 root root    896 Nov 30 17:02 .gitignore
-rw-r--r--  1 root root    606 Nov 30 17:02 ISSUES.md
-rw-r--r--  1 root root   2232 Nov 30 17:02 ISSUE_TEMPLATE.md
-rw-r--r--  1 root root  11419 Nov 30 17:02 LICENSE
-rw-r--r--  1 root root      7 Nov 30 17:10 .mbed
drwxr-xr-x 19 root root   4096 Nov 30 17:07 mbed-os/
-rw-r--r--  1 root root     77 Nov 30 17:07 mbed-os.lib
-rw-r--r--  1 root root   1339 Nov 30 17:08 mbed_settings.py
-rw-r--r--  1 root root    328 Nov 30 17:02 models.BUILD
-rw-r--r--  1 root root     34 Nov 30 17:02 .pylintrc
-rw-r--r--  1 root root  21169 Nov 30 17:02 README.md
-rw-r--r--  1 root root 319193 Nov 30 17:02 RELEASE.md
-rw-r--r--  1 root root  13158 Nov 30 17:02 SECURITY.md
drwxr-xr-x 16 root root   4096 Nov 30 17:02 tensorflow/
drwxr-xr-x 46 root root   4096 Nov 30 17:02 third_party/
drwxr-xr-x  2 root root   4096 Nov 30 17:02 tools/
-rw-r--r--  1 root root   4246 Nov 30 17:02 WORKSPACE
root@ubuntu:/usr/local/project/tensorflow# cd BUILD 
bash: cd: BUILD: Not a directory

The content of BUILD is 

exports_files(
    [
        ""LICENSE"",
        ""ACKNOWLEDGEMENTS"",
        ""configure"",
        ""configure.py"",
    ],
)
```
So I really don't know why this error occurs, and how to solve it. I hope someone of you have a good idea about this, 
                                                                                                                                                                               Thanks a lot!"
45291,Unbalanced workload distribution on parameter server replicas in distributed tensorflow (parameter-server strategy),"
Hello everyone, i have been running various experiments using the parameter-server strategy for distributed tensorflow. My shows uneven distribution on workload for parameter servers replicas (some replicas get more work than others).  For example, i ran distributed job having (1master, 2parameter-servers, 1worker) using resnet50 model and observed the network traffic on the parameter servers. From the graph.pbtxt file i can see near balanced task assignments on both parameter-servers (3823 for `ps/task:0` & 3993 for `ps/task:1`) but from monitoring network activity, it seems like only 1 of the 2 parameter servers is actively participating in the training process. (see the network logs below in MBytes).

Upon some preliminary searching i found that this problem stems from the fact that tensors are of different sizes and since tensorflow uses round-robin assignment, this could lead to unbalanced parameter assignments (https://github.com/tensorflow/tensorflow/issues/24953). However, this would have made sense if 1 parameter-server was facing 2x or 3x the traffic in comparison but my results show no activity at all for the second parameter-server which makes me wonder if its simply sitting idle?

  

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- TensorFlow version (v2.3):
- Python version: v3.6
- GPU model and memory: N/A (running on CPU cores)

**Describe the current behavior**
Only one of the 2 parameter servers is showing network activity.

**Describe the expected behavior**
Both parameter servers show be having near balanced network activity.


`ps0`
```
-timeStamp -incomingTraffic -outgoingTraffic -totalTraffic
1606778918 0 0 0
1606778918 0 0 0
1606778919 0 0 0
1606778919 0 0 0
1606778920 0 0 0
1606778920 0 0 0
1606778921 0 0 0
1606778921 0 0 0
1606778922 0 0 0
1606778922 0 0 0
1606778923 0 0 0
1606778923 0 0 0
1606778924 0 0 0
1606778924 0 0 0
1606778925 0 0 0
1606778925 0 0 0
1606778926 0 0 0
1606778926 0 0 0
1606778927 0 0 0
1606778927 0 0 0
1606778928 0 0 0
1606778928 0 0 0
1606778929 0 0 0
1606778929 0 0 0
1606778930 0 0 0
1606778930 0 0 0
1606778931 0 0 0
1606778931 0 0 0
1606778932 0 0 0
1606778932 0 0 0
1606778933 0 0 0
1606778933 0 0 0
1606778934 0 0 0
1606778934 0 0 0
1606778935 0 0 0
1606778935 0 0 0
1606778936 0 0 0
1606778936 0 0 0
1606778937 0 0 0
1606778937 0 0 0
1606778938 0 0 0
1606778938 0 0 0
1606778939 0 0 0
1606778939 0 0 0
1606778940 0 0 0
1606778940 0 0 0
1606778941 0 0 0
1606778941 0 0 0
1606778942 0 0 0
1606778942 0 0 0
1606778943 0 0 0
1606778943 0 0 0
1606778944 0 0 0
1606778944 0 0 0
1606778945 0 0 0
1606778945 0 0 0
1606778946 0 0 0
1606778946 0 0 0
1606778947 0 0 0
1606778947 0 0 0
1606778948 0 0 0
1606778948 0 0 0
1606778949 0 0 0
1606778949 0 0 0
1606778950 0 0 0
1606778950 0 0 0
1606778951 0 0 0
1606778951 0 0 0
1606778952 0 0 0
1606778952 0 0 0
1606778953 0 0 0
1606778953 0 0 0
1606778954 0 0 0
1606778954 0 0 0
1606778955 0 0 1
1606778955 1 0 1
1606778956 0 0 0
1606778956 0 0 1
1606778957 0 0 0
1606778957 0 0 0
1606778958 0 0 0
1606778958 0 0 0
1606778959 0 0 0
1606778959 0 0 0
1606778960 0 0 1
1606778960 0 0 0
1606778961 1 0 2
1606778961 0 0 0
1606778962 0 0 0
1606778962 0 0 0
1606778963 0 0 1
1606778963 0 0 0
1606778964 0 0 0
1606778964 0 0 0
1606778965 0 0 0
1606778965 0 0 0
1606778966 0 0 0
1606778966 1 0 1
1606778967 0 0 0
1606778967 1 0 1
1606778968 2 0 2
1606778968 0 0 0
1606778969 0 0 0
1606778969 0 0 0
1606778970 0 0 0
1606778970 1 0 1
1606778971 0 0 0
1606778971 0 0 0
1606778972 0 0 0
1606778972 1 0 1
1606778973 0 0 0
1606778973 0 0 0
1606778974 1 0 1
1606778974 0 0 0
1606778975 0 0 0
1606778975 0 0 0
1606778976 0 0 0
1606778976 2 1 3
1606778977 0 0 0
1606778977 0 0 0
1606778978 0 0 0
1606778978 1 0 1
1606778979 0 0 0
1606778979 0 0 0
1606778980 1 0 1
1606778980 1 0 1
1606778981 0 0 0
1606778981 0 0 0
1606778982 0 0 0
1606778982 0 0 0
1606778983 0 0 0
1606778983 1 0 1
1606778984 0 0 0
1606778984 0 0 0
1606778985 0 0 0
1606778985 0 0 0
1606778986 1 0 1
1606778986 0 0 0
1606778987 0 0 0
1606778987 1 0 1
1606778988 1 0 1
1606778988 0 0 0
1606778989 0 1 1
1606778989 0 0 0
1606778990 0 0 0
1606778990 0 0 0
1606778991 0 0 0
1606778991 0 0 0
1606778992 1 0 1
1606778992 0 0 0
1606778993 1 0 1
1606778993 0 0 0
1606778994 0 0 0
1606778994 0 0 0
1606778995 1 0 1
1606778995 0 0 0
1606778996 1 0 1
1606778996 0 0 0
1606778997 0 0 0
1606778997 1 0 1
1606778998 1 1 2
1606778998 0 0 0
1606778999 1 1 2
1606778999 0 0 0
1606779000 0 0 0
1606779000 0 0 0
1606779001 1 0 1
1606779001 0 0 0
1606779002 0 0 0
1606779002 1 0 1
1606779003 0 0 0
1606779003 0 0 0
1606779004 0 0 0
1606779004 0 0 0
1606779005 0 0 0
1606779005 1 0 2
1606779006 0 0 0
1606779006 0 0 0
1606779007 0 0 0
1606779007 0 0 0
1606779008 0 0 0
1606779008 1 0 1
1606779009 0 1 1
1606779009 1 0 1
1606779010 0 1 1
1606779010 0 0 0
1606779011 1 0 1
1606779011 0 0 0
1606779012 0 0 0
1606779012 0 0 0
1606779013 0 0 0
1606779013 0 0 0
1606779014 0 0 0
1606779014 0 0 0
1606779015 0 0 0
1606779015 0 0 0
1606779016 1 0 1
1606779016 0 0 0
1606779017 1 0 1
1606779017 0 0 1
1606779018 1 0 1
1606779018 0 0 0
1606779019 0 0 0
1606779019 0 0 0
1606779020 0 0 0
1606779020 0 0 0
1606779021 0 0 0
1606779021 0 0 0
1606779022 0 0 0
1606779022 0 0 0
1606779023 0 0 0
1606779023 0 1 1
1606779024 0 0 0
1606779024 0 0 0
1606779025 0 0 0
1606779025 0 0 0
1606779026 0 0 0
1606779026 0 0 0
1606779027 0 0 0
1606779027 0 0 0
1606779028 0 0 0
1606779028 0 0 0
1606779029 0 0 0
1606779029 0 0 0
1606779030 0 0 0
1606779030 0 0 0
1606779031 0 0 0
1606779031 0 0 0
1606779032 1 0 1
1606779032 0 0 0
1606779033 0 0 0
1606779033 0 0 0
1606779034 0 0 0
1606779034 0 0 0
1606779035 0 0 0
1606779035 0 0 0
1606779036 0 0 0
1606779036 0 0 0
1606779037 0 0 0
1606779037 0 0 0
1606779038 0 0 0
1606779038 0 1 1
1606779039 0 0 1
1606779039 0 0 0
1606779040 0 0 0
1606779040 0 0 0
1606779041 0 0 0
1606779041 0 0 0
1606779042 0 0 0
1606779042 0 0 0
1606779043 0 0 0
1606779043 0 0 0
1606779044 0 0 0
1606779044 0 0 0
1606779045 0 0 0
1606779045 0 0 0
1606779046 0 0 0
1606779046 0 0 0
1606779047 0 0 0
1606779047 0 1 1
1606779048 0 0 0
1606779048 0 0 0
1606779049 0 0 0
1606779049 0 0 1
1606779050 0 0 0
1606779050 0 0 0
1606779051 0 0 0
1606779051 0 0 0
1606779052 0 0 0
1606779052 0 0 0
1606779053 0 1 1
1606779053 0 0 0
1606779054 0 0 1
1606779054 0 0 0
1606779055 0 0 0
1606779055 0 0 0
1606779056 0 0 0
1606779056 0 0 0
1606779057 0 0 1
1606779057 0 0 0
1606779058 0 0 0
1606779058 0 0 0
1606779059 0 0 0
1606779059 0 0 0
1606779060 0 0 0
1606779060 0 0 0
1606779061 0 0 0
1606779061 0 0 0
1606779062 0 0 0
1606779062 0 0 0
1606779063 0 0 0
1606779063 0 0 1
1606779064 0 0 1
1606779064 0 0 0
1606779065 0 0 0
1606779065 0 0 0
1606779066 0 0 0
1606779066 0 0 0
1606779067 0 0 0
1606779067 0 0 0
1606779068 0 0 0
1606779068 0 0 0
1606779069 0 0 0
1606779069 0 0 0
1606779070 0 0 0
1606779070 0 0 0
1606779071 0 0 0
1606779071 0 0 1
1606779072 0 0 0
1606779072 0 0 0
1606779073 0 0 0
1606779073 0 0 0
1606779074 0 0 0
1606779074 0 0 0
1606779075 0 0 0
1606779075 0 0 0
1606779076 0 0 0
1606779076 0 0 0
1606779077 0 0 0
1606779077 0 0 0
1606779078 0 0 0
1606779078 0 0 0
1606779079 0 0 0
1606779079 0 0 0
1606779080 0 0 0
1606779080 0 0 0
1606779081 0 0 0
1606779081 0 0 0
1606779082 0 0 0
1606779082 0 0 0
1606779083 0 0 0
1606779083 0 0 0
1606779084 0 0 0
1606779084 0 0 0
1606779085 0 1 1
1606779085 0 0 0
1606779086 0 0 0
1606779086 0 0 0
1606779087 0 0 0
1606779087 0 0 0
1606779088 0 0 0
1606779088 0 0 1
1606779089 0 0 1
1606779089 0 0 0
1606779090 0 0 0
1606779090 0 0 0
1606779091 0 0 0
1606779091 0 0 0
1606779092 0 0 0
1606779092 0 0 0
1606779093 0 0 0
1606779093 0 1 1
1606779094 0 0 0
1606779094 0 0 0
1606779095 0 0 0
1606779095 0 0 0
1606779096 0 0 0
1606779096 0 0 0
1606779097 0 0 0
1606779097 0 0 0
1606779098 0 0 0
1606779098 0 1 1
1606779099 0 0 0
1606779099 0 0 0
1606779100 0 0 0
1606779100 0 0 0
1606779101 0 0 0
1606779101 0 0 0
1606779102 0 0 1
1606779102 0 0 0
1606779103 0 0 0
1606779103 0 0 0
1606779104 0 0 0
1606779104 0 0 0
1606779105 0 0 0
1606779105 0 0 0
1606779106 0 0 0
1606779106 0 0 0
1606779107 0 0 0
1606779107 0 0 0
1606779108 0 0 0
1606779108 0 0 0
1606779109 0 1 1
1606779109 0 1 1
1606779110 0 0 0
1606779110 0 0 0
1606779111 0 0 0
1606779111 0 0 0
1606779112 0 0 0
1606779112 0 0 0
1606779113 0 0 0
1606779113 0 0 0
1606779114 0 0 0
1606779114 0 0 0
1606779115 0 0 0
1606779115 0 0 0
1606779116 0 0 0
1606779116 0 0 0
1606779117 0 0 0
1606779117 0 0 0
1606779118 0 0 0
1606779118 0 0 0
1606779119 0 0 0
1606779119 0 0 0
1606779120 0 0 0
1606779120 0 0 1
1606779121 0 0 1
1606779121 0 0 0
1606779122 0 0 0
1606779122 0 0 0
1606779123 0 0 0
1606779123 0 0 0
1606779124 0 0 0
1606779124 0 0 0
1606779125 0 0 0
1606779125 0 0 1
1606779126 0 0 1
1606779126 0 0 0
1606779127 0 0 0
1606779127 0 0 0
1606779128 0 0 0
1606779128 0 0 0
1606779129 1 0 1
1606779129 0 0 0
1606779130 0 0 0
1606779130 0 0 0
1606779131 0 0 0
1606779131 0 0 0
1606779132 0 0 0
1606779132 0 0 0
1606779133 0 0 0
1606779133 0 0 0
1606779134 0 0 0
1606779134 0 1 1
1606779135 0 0 0
1606779135 0 0 0
1606779136 0 0 0
1606779136 0 0 0
1606779137 0 0 1
1606779137 0 0 0
1606779138 0 0 0
1606779138 0 0 0
1606779139 0 0 0
1606779139 0 0 0
1606779140 0 0 0
1606779140 0 1 1
1606779141 0 0 0
1606779141 0 0 0
1606779142 0 0 0
1606779142 0 0 0
1606779143 0 0 0
1606779143 0 0 0
1606779144 0 0 0
1606779144 0 0 0
1606779145 0 0 0
1606779145 0 0 0
1606779146 0 0 0
1606779146 0 0 0
1606779147 0 0 0
1606779147 0 0 0
1606779148 0 0 0
1606779148 0 0 1
1606779149 0 0 0
1606779149 0 0 1
1606779150 0 0 0
1606779150 0 0 0
1606779151 0 0 0
1606779151 0 0 0
1606779152 0 0 0
1606779152 0 0 0
1606779153 0 0 0
1606779153 0 0 1
```
`ps1`
```
-timeStamp -incomingTraffic -outgoingTraffic -totalTraffic
1606778918 0 0 0
1606778919 0 0 0
1606778919 0 0 0
1606778920 0 0 0
1606778920 0 0 0
1606778921 0 0 0
1606778921 0 0 0
1606778922 0 0 0
1606778922 0 0 0
1606778923 0 0 0
1606778923 0 0 0
1606778924 0 0 0
1606778924 0 0 0
1606778925 0 0 0
1606778925 0 0 0
1606778926 0 0 0
1606778926 0 0 0
1606778927 0 0 0
1606778927 0 0 0
1606778928 0 0 0
1606778928 0 0 0
1606778929 0 0 0
1606778929 0 0 0
1606778930 0 0 0
1606778930 0 0 0
1606778931 0 0 0
1606778931 0 0 0
1606778932 0 0 0
1606778932 0 0 0
1606778933 0 0 0
1606778933 0 0 0
1606778934 0 0 0
1606778934 0 0 0
1606778935 0 0 0
1606778935 0 0 0
1606778936 0 0 0
1606778936 0 0 0
1606778937 0 0 0
1606778937 0 0 0
1606778938 0 0 0
1606778938 0 0 0
1606778939 0 0 0
1606778939 0 0 0
1606778940 0 0 0
1606778940 0 0 0
1606778941 0 0 0
1606778941 0 0 0
1606778942 0 0 0
1606778942 0 0 0
1606778943 0 0 0
1606778943 0 0 0
1606778944 0 0 0
1606778944 0 0 0
1606778945 0 0 0
1606778945 0 0 0
1606778946 0 0 0
1606778946 0 0 0
1606778947 0 0 0
1606778947 0 0 0
1606778948 0 0 0
1606778948 0 0 0
1606778949 0 0 0
1606778949 0 0 0
1606778950 0 0 0
1606778950 0 0 0
1606778951 0 0 0
1606778951 0 0 0
1606778952 0 0 0
1606778952 0 0 0
1606778953 0 0 0
1606778953 0 0 0
1606778954 0 0 0
1606778954 0 0 0
1606778955 1 0 1
1606778955 1 0 1
1606778956 0 0 1
1606778956 0 0 0
1606778957 0 0 0
1606778957 0 183 183
1606778958 42 6 49
1606778958 137 0 137
1606778959 8 0 8
1606778959 0 0 0
1606778960 0 0 1
1606778960 0 0 0
1606778961 1 109 111
1606778961 0 78 79
1606778962 148 0 149
1606778962 38 0 38
1606778963 2 27 30
1606778963 0 319 320
1606778964 15 30 46
1606778964 165 0 166
1606778965 141 0 141
1606778965 45 0 45
1606778966 9 0 9
1606778966 2 0 2
1606778967 0 186 187
1606778967 46 1 48
1606778968 133 0 134
1606778968 10 210 221
1606778969 1 96 97
1606778969 9 215 224
1606778970 91 43 134
1606778970 88 18 107
1606778971 153 28 182
1606778971 104 55 160
1606778972 59 86 146
1606778972 31 0 32
1606778973 27 19 46
1606778973 8 150 158
1606778974 12 20 32
1606778974 70 17 88
1606778975 98 170 269
1606778975 86 2 88
1606778976 56 0 56
1606778976 47 135 183
1606778977 71 136 208
1606778977 59 105 165
1606778978 31 0 31
1606778978 34 0 34
1606778979 44 150 195
1606778979 85 39 124
1606778980 82 0 83
1606778980 95 24 120
1606778981 52 278 331
1606778981 89 74 163
1606778982 57 0 57
1606778982 20 0 20
1606778983 29 8 37
1606778983 31 139 171
1606778984 71 92 163
1606778984 75 23 98
1606778985 104 51 155
1606778985 58 77 136
1606778986 95 129 225
1606778986 50 44 95
1606778987 52 0 52
1606778987 55 11 66
1606778988 47 177 224
1606778988 33 0 33
1606778989 57 61 118
1606778989 62 287 349
1606778990 73 28 101
1606778990 49 6 55
1606778991 38 163 201
1606778991 43 19 63
1606778992 55 3 58
1606778992 119 29 149
1606778993 90 27 118
1606778993 95 34 130
1606778994 62 93 156
1606778994 84 75 160
1606778995 80 112 193
1606778995 70 0 70
1606778996 28 0 28
1606778996 31 0 31
1606778997 20 0 20
1606778997 32 0 32
1606778998 24 95 119
1606778998 53 199 252
1606778999 76 156 233
1606778999 58 277 335
1606779000 58 123 182
1606779000 41 111 153
1606779001 23 150 173
1606779001 41 105 147
1606779002 24 31 56
1606779002 74 45 120
1606779003 97 31 128
1606779003 135 0 136
1606779004 102 0 103
1606779004 109 0 109
1606779005 101 0 101
1606779005 99 93 193
1606779006 122 94 216
1606779006 59 2 61
1606779007 91 0 92
1606779007 53 0 53
1606779008 43 0 43
1606779008 74 0 74
1606779009 22 98 121
1606779009 39 127 167
1606779010 35 177 213
1606779010 48 315 364
1606779011 37 41 79
1606779011 20 105 125
1606779012 42 112 155
1606779012 14 114 129
1606779013 18 46 64
1606779013 62 182 245
1606779014 70 0 70
1606779014 71 0 71
1606779015 91 0 91
1606779015 95 0 95
1606779016 128 0 129
1606779016 124 36 161
1606779017 152 94 246
1606779017 152 199 351
1606779018 130 114 245
1606779018 68 132 200
1606779019 51 144 196
1606779019 44 38 82
1606779020 22 0 22
1606779020 28 0 29
1606779021 36 22 58
1606779021 19 113 132
1606779022 8 52 61
1606779022 34 6 40
1606779023 15 117 132
1606779023 65 221 286
1606779024 89 219 309
1606779024 93 0 93
1606779025 83 67 151
1606779025 108 187 295
1606779026 84 122 207
1606779026 92 0 92
1606779027 80 0 80
1606779027 77 0 78
1606779028 86 0 86
1606779028 91 0 91
1606779029 95 0 95
1606779029 156 0 157
1606779030 120 0 120
1606779030 80 0 80
1606779031 104 0 104
1606779031 86 13 100
1606779032 65 130 195
1606779032 59 121 181
1606779033 41 163 205
1606779033 31 144 175
1606779034 23 161 184
1606779034 25 47 73
1606779035 9 77 86
1606779035 5 85 91
1606779036 6 0 6
1606779036 3 21 24
1606779037 29 258 287
1606779037 46 152 198
1606779038 45 97 142
1606779038 149 191 341
1606779039 109 159 268
1606779039 98 156 255
1606779040 90 85 175
1606779040 107 9 117
1606779041 94 0 94
1606779041 104 0 105
1606779042 122 0 122
1606779042 108 0 108
1606779043 107 0 107
1606779043 111 0 112
1606779044 123 0 123
1606779044 132 137 269
1606779045 115 51 166
1606779045 80 0 80
1606779046 84 0 84
1606779046 30 0 30
1606779047 37 0 37
1606779047 41 61 102
1606779048 47 201 248
1606779048 28 115 144
1606779049 12 60 72
1606779049 41 152 194
1606779050 26 202 228
1606779050 40 150 191
1606779051 42 144 186
1606779051 13 207 221
1606779052 17 25 43
1606779052 12 0 12
1606779053 71 134 205
1606779053 81 148 230
1606779054 128 138 267
1606779054 152 64 217
1606779055 100 80 180
1606779055 93 0 94
1606779056 148 0 149
1606779056 100 0 101
1606779057 113 78 191
1606779057 122 76 198
1606779058 87 36 123
1606779058 53 0 54
1606779059 79 0 79
1606779059 63 0 63
1606779060 74 0 74
1606779060 72 117 189
1606779061 68 70 139
1606779061 43 0 43
1606779062 57 30 87
1606779062 61 102 163
1606779063 81 160 241
1606779063 42 145 187
1606779064 63 207 270
1606779064 41 185 227
1606779065 43 102 146
1606779065 68 12 81
1606779066 45 0 45
1606779066 90 24 114
1606779067 45 110 156
1606779067 65 152 218
1606779068 68 89 157
1606779068 73 0 74
1606779069 68 11 79
1606779069 93 149 242
1606779070 123 28 151
1606779070 72 123 195
1606779071 91 68 160
1606779071 71 10 82
1606779072 95 116 211
1606779072 105 45 150
1606779073 78 108 187
1606779073 64 97 161
1606779074 81 2 83
1606779074 43 81 125
1606779075 45 107 152
1606779075 62 34 97
1606779076 81 153 234
1606779076 57 0 58
1606779077 88 0 88
1606779077 93 1 95
1606779078 44 141 185
1606779078 85 45 131
1606779079 65 53 118
1606779079 86 113 199
1606779080 87 70 157
1606779080 104 111 215
1606779081 66 138 205
1606779081 86 80 167
1606779082 65 0 65
1606779082 50 53 104
1606779083 23 127 151
1606779083 61 8 70
1606779084 30 0 30
1606779084 84 29 114
1606779085 59 220 280
1606779085 62 267 329
1606779086 71 49 121
1606779086 98 80 179
1606779087 96 86 182
1606779087 77 24 101
1606779088 69 0 69
1606779088 61 26 88
1606779089 94 199 294
1606779089 95 150 245
1606779090 114 0 114
1606779090 80 0 80
1606779091 113 0 113
1606779091 85 0 85
1606779092 68 0 68
1606779092 82 0 82
1606779093 65 0 65
1606779093 97 47 144
1606779094 54 292 346
1606779094 47 207 255
1606779095 46 21 67
1606779095 70 0 70
1606779096 39 61 101
1606779096 39 56 95
1606779097 38 87 125
1606779097 49 256 306
1606779098 35 104 140
1606779098 29 63 92
1606779099 65 178 244
1606779099 71 136 207
1606779100 74 0 74
1606779100 83 0 84
1606779101 91 0 91
1606779101 135 14 150
1606779102 136 338 474
1606779102 130 26 156
1606779103 140 0 140
1606779103 88 0 88
1606779104 102 0 102
1606779104 80 0 81
1606779105 71 27 99
1606779105 59 102 162
1606779106 63 59 122
1606779106 48 0 48
1606779107 25 0 25
1606779107 37 0 37
1606779108 61 47 109
1606779108 59 91 150
1606779109 71 159 231
1606779109 42 261 303
1606779110 53 239 292
1606779110 59 188 247
1606779111 49 188 238
1606779111 39 127 166
1606779112 36 16 52
1606779112 40 0 40
1606779113 80 0 80
1606779113 74 0 74
1606779114 129 0 130
1606779114 116 1 118
1606779115 152 27 179
1606779115 169 135 304
1606779116 124 188 313
1606779116 110 25 136
1606779117 70 0 70
1606779117 99 18 117
1606779118 98 141 239
1606779118 45 29 75
1606779119 36 0 36
1606779119 39 0 39
1606779120 28 0 28
1606779120 28 5 34
1606779121 44 142 186
1606779121 54 262 317
1606779122 45 155 201
1606779122 47 106 154
1606779123 27 125 153
1606779123 38 90 128
1606779124 60 55 116
1606779124 29 0 29
1606779125 67 0 67
1606779125 49 116 166
1606779126 109 154 263
1606779126 121 73 194
1606779127 129 32 162
1606779127 164 33 197
1606779128 115 105 220
1606779128 109 50 160
1606779129 106 4 110
1606779129 107 143 250
1606779130 52 41 94
1606779130 66 0 66
1606779131 55 0 55
1606779131 80 0 80
1606779132 55 101 156
1606779132 35 103 139
1606779133 63 170 234
1606779133 30 1 31
1606779134 24 61 86
1606779134 69 169 238
1606779135 65 260 325
1606779135 66 163 230
1606779136 36 98 134
1606779136 29 0 29
1606779137 36 17 53
1606779137 39 79 118
1606779138 62 91 153
1606779138 119 0 119
1606779139 108 0 109
1606779139 133 0 133
1606779140 148 66 214
1606779140 160 212 372
1606779141 122 186 308
1606779141 98 101 200
1606779142 66 0 66
1606779142 52 0 52
1606779143 48 0 49
1606779143 49 0 49
1606779144 48 0 48
1606779144 50 7 57
1606779145 27 164 192
1606779145 36 17 54
1606779146 82 110 192
1606779146 72 156 228
1606779147 70 204 275
1606779147 75 81 156
1606779148 41 13 55
1606779148 81 116 198
1606779149 63 199 263
1606779149 53 202 255
1606779150 66 46 113
1606779150 103 0 103
1606779151 126 0 126
1606779151 113 0 113
1606779152 98 0 98
1606779152 71 0 71
1606779153 80 44 125
1606779153 85 175 260
```
"
45290,tflite 2.4 build benchmark_model error on ubuntu 16.04 (cmake),"when i build tflite2.4 on Ubuntu, i encount the problem:
i can success build libtensorflow-lite.a with CMakeLists.txt use CMake, but when i buildbenchmark-model i got these errors:
my build command is : make benchmark-model
errors:

[ 98%] Linking CXX executable benchmark_model
_deps/xnnpack-build/libXNNPACK.a(4x16c8-minmax-avx512skx.c.o): In function `xnn_qs8_gemm_minmax_ukernel_4x16c8__avx512skx':
4x16c8-minmax-avx512skx.c:(.text+0x720): undefined reference to `_kshiftli_mask64'
4x16c8-minmax-avx512skx.c:(.text+0x753): undefined reference to `_kshiftli_mask64'
4x16c8-minmax-avx512skx.c:(.text+0x785): undefined reference to `_kshiftli_mask64'
_deps/xnnpack-build/libXNNPACK.a(4x16c8-minmax-avx512skx.c.o): In function `xnn_qs8_igemm_minmax_ukernel_4x16c8__avx512skx':
4x16c8-minmax-avx512skx.c:(.text+0x7a2): undefined reference to `_kshiftri_mask64'
4x16c8-minmax-avx512skx.c:(.text+0x7d4): undefined reference to `_kshiftri_mask64'
4x16c8-minmax-avx512skx.c:(.text+0x80d): undefined reference to `_kshiftri_mask64'
collect2: error: ld returned 1 exit status
CMakeFiles/benchmark_model.dir/build.make:382: recipe for target 'benchmark_model' failed
make[3]: *** [benchmark_model] Error 1
CMakeFiles/Makefile2:2012: recipe for target 'CMakeFiles/benchmark_model.dir/all' failed
make[2]: *** [CMakeFiles/benchmark_model.dir/all] Error 2
CMakeFiles/Makefile2:2019: recipe for target 'CMakeFiles/benchmark_model.dir/rule' failed
make[1]: *** [CMakeFiles/benchmark_model.dir/rule] Error 2
Makefile:199: recipe for target 'benchmark_model' failed
make: *** [benchmark_model] Error 2

this puzzled me for a long time , appreciate your reply!

the CMakeLists.txt help me much ,but also has some errors i think , for example the xnnpack delegate switch to control build with xnnpack delegate. i found use TFLITE_ENABLE_XNNPACK  to control xnnpack delegate will get errors when i build shared library in windows x64. so i change the source code.


email:   lxiao217@163.com"
45289,resnet50 inference is slower when use tensorflow with onednn,"> @zhangqiang-hf
> 
> I think your issue is new one for Resnet50 model.
> This issue topic is LSTM.
> 
> Is it possible to create a new github issue for your model?
> You could @me in the new issue, so I can continue following it.
> 
> Thank you!

ok！I will assign a new bug for you！when one pic, why it is slower when use onednn, this  still a issue? am I right?
also, I have checked when bs=100, it is quicker when onednn. but this 100 pictures is the same, when the100 pictures are different, how about?

_Originally posted by @zhangqiang-hf in https://github.com/tensorflow/tensorflow/issues/33138#issuecomment-736168560_"
45288,load_model in tf>=2.3.0 raises TypeError when loading a model saved in tf 2.2.0,"**System information**
- Have I written custom code: Yes
- OS Platform and Distribution: Google Colab
- TensorFlow version: 2.2.0 vs 2.3.1 or tf-nightly (2.5.0.dev20201130)
- Python version: 3.6.9
- GPU model and memory: None (Colab CPU)

**Describe the current behavior**
When I saved a model using `tf.keras.models.Model(...).save` in tf 2.2.0, I am unable to load the model back using `tf.keras.models.load_model` in tf 2.3.1 or the latest tf-nightly. See abbreviated error message below:
```
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
<ipython-input-1-8326baccad65> in <module>()
      1 # Restart the runtime, then run
      2 import tensorflow as tf
----> 3 model = tf.keras.models.load_model('hidden_net')

9 frames
/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/functional.py in reconstruct_from_config(config, custom_objects, created_layers)
   1234     layer = created_layers[layer_name]
   1235     node_index = get_node_index(layer, node_index)
-> 1236     layer_output_tensors = layer._inbound_nodes[node_index].output_tensors
   1237     output_tensors.append(nest.flatten(layer_output_tensors)[tensor_index])
   1238 

TypeError: list indices must be integers or slices, not NoneType
```

**Describe the expected behavior**
Should be able to load the model back

**Standalone code to reproduce the issue**
See [gist](https://colab.research.google.com/gist/shengpu1126/5d4674a9475590ef2fe46565f0641b12/untitled2.ipynb)

**Other info / logs**
- Maybe related to #42890. I could not find a newer issue related to this so I created a new one; please close it if it's a duplicate. 
- This may have to do with the way I defined my model, where I used a combination of Keras sequential and functional API. Could it be related to the recent Keras functional refactoring in 2.4.0? "
45287,Import Error DLL failed,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 (64bit)
- TensorFlow installed from (source or binary): install using conda in command window as admin
- TensorFlow version: 2.3.1
- Python version: 3.8.5
- Installed using virtualenv? pip? conda?: installed using conda then created virtual env
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory: RTX 2060 16GB



**Describe the problem**
I have installed tensorflow on my windows desktop with anaconda. As a result I followed the steps from a youtube video by Jeff Heaton. Now I would like to run Tensorflow in  VS code and it will not work. I get an import error that says the following ImportError: DLL load failed while importing _pywrap_tensorflow_internal: %1 is not a valid Win32 application. 

**Provide the exact sequence of commands / steps that you executed before running into the problem**
The only code I have is an import line ""import tensorflow as tf"" when I run the script by using ctl+F5, I get the error. When I type ""python test.py"" in the no errors are thrown. (test.py is the name of my file)


**Creating and install packages and tensorflow for environment steps**
1. Run CMD as admin
2. conda create -n tensorflow-cpu python=3.8
3. conda activate tensorflow-cpu 
4. conda install jupyter matplotlib numpy pandas scipy
5. pip install tensorflow 
     got lots of messages that the requirement was already met.
6. python 
7. import tensorflow as tf
8. tf.__version__
9. 2.3.1
10. quit()
11. code (opens VS code)
12. create new file
13. import tensorflow as tf (autofill in works)
14. run
15. no error
16. add other packages (import matplotlib, pandas etc...)
17. autofill no longer works
18. create new file
19. import tensorflow as tf (autofill doesn't work)
20. run (error outputted in terminal)
21. run python test.py in terminal (no error)

**Any other info / logs**
Jeff heaton video link: https://www.youtube.com/watch?v=RgO8BBNGB8w&t=474s


"
45285,Tensorflow gpu does not work with RTX 3000 series card.,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 Home
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): Binary (pip install tf-nightly-gpu)
- TensorFlow version (use command below): tf-nightly-gpu==2.5.0.dev20201111
- Python version: 3.8
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: CUDA 11.1 CUDNN 8.0.5.39
- GPU model and memory: RTX 3070 8GB

**Describe the current behavior**
The GPU is successfully detected and the anaconda prompt does not show any errors or warnings but whenever the model starts training it uses the CPU. 
When running ```tf.config.experimental.list_physical_devices('GPU')``` I get ```[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]```
When running ```print(device_lib.list_local_devices())``` I get 
```
[name: ""/device:CPU:0""
device_type: ""CPU""
memory_limit: 268435456
locality {
}
incarnation: 12958882941219838237
, name: ""/device:GPU:0""
device_type: ""GPU""
memory_limit: 6910041152
locality {
  bus_id: 1
  links {
  }
}
incarnation: 16296908220344189432
physical_device_desc: ""device: 0, name: GeForce RTX 3070, pci bus id: 0000:08:00.0, compute capability: 8.6""
]
```
when running ```tf.config.list_physical_devices('GPU')``` I get
```[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]```
and when running ```tf.test.is_gpu_available()```  I get 
```True```
**Describe the expected behavior**
The model should use the GPU to train.
**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.
**My Model Code**
```
import pandas as pd
import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.preprocessing.text import Tokenizer

for device in tf.config.experimental.list_physical_devices(""GPU""):
    tf.config.experimental.set_memory_growth(device, True)

max_features = 1000000
maxlen = 200
train_size=442598
updatedtrainsize = 5;

my_data = pd.read_csv('mydata.csv')
y = my_data[""label""]
x = my_data[""url""]
z = np.array(x)
w = np.array(y)
x_train = z[0:train_size]
x_val = z[train_size:]
y_train = w[0:train_size]
y_val = w[train_size:]

for x in range(len(y_train)): 
  if ""good"" in y_train[x]:
    y_train[x] = 0
  else:
    y_train[x] = 1

for x in range(len(y_val)): 
  if ""good"" in y_val[x]:
    y_val[x] = 0
  else:
    y_val[x] = 1

tokenizer = Tokenizer(filters='/-.+',
                      lower=True,
                      split=' ',
                      char_level=False,
                      oov_token='<OOV>')
tokenizer.fit_on_texts(x_train)
tokenizer.fit_on_texts(x_val)
word_index = tokenizer.word_index

x_train = tokenizer.texts_to_sequences(x_train)
x_val = tokenizer.texts_to_sequences(x_val)
x_train = keras.preprocessing.sequence.pad_sequences(x_train, maxlen=maxlen)
x_val = keras.preprocessing.sequence.pad_sequences(x_val, maxlen=maxlen)
x_train = np.array(x_train).astype('float32')
x_val = np.array(x_val).astype('float32')
y_train = np.array(y_train).astype('float32')
y_val = np.array(y_val).astype('float32')

inputs = keras.Input(shape=(None,), dtype=""int32"")
x = layers.Embedding(max_features, 128)(inputs)
x = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(x)
x = layers.Bidirectional(layers.LSTM(64))(x)
outputs = layers.Dense(1, activation=""sigmoid"")(x)
model = keras.Model(inputs, outputs)

model.compile(""adam"", ""binary_crossentropy"", metrics=[""accuracy""])

# with tf.device(""/GPU:0""):
model.fit(x_train, y_train, batch_size=32, epochs=2, validation_data=(x_val, y_val))
```
**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
**My Anaconda Prompt**
```
2020-11-30 17:47:00.576296: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudart64_110.dll
2020-11-30 17:47:01.757077: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2020-11-30 17:47:01.757826: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library nvcuda.dll
2020-11-30 17:47:01.778881: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties:
pciBusID: 0000:08:00.0 name: GeForce RTX 3070 computeCapability: 8.6
coreClock: 1.725GHz coreCount: 46 deviceMemorySize: 8.00GiB deviceMemoryBandwidth: 417.29GiB/s
2020-11-30 17:47:01.778947: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudart64_110.dll
2020-11-30 17:47:01.784571: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublas64_11.dll
2020-11-30 17:47:01.784619: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublasLt64_11.dll
2020-11-30 17:47:01.787759: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cufft64_10.dll
2020-11-30 17:47:01.788668: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library curand64_10.dll
2020-11-30 17:47:01.795255: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusolver64_10.dll
2020-11-30 17:47:01.797702: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusparse64_11.dll
2020-11-30 17:47:01.798214: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudnn64_8.dll
2020-11-30 17:47:01.798304: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2020-11-30 17:47:09.856239: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-11-30 17:47:09.856839: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties:
pciBusID: 0000:08:00.0 name: GeForce RTX 3070 computeCapability: 8.6
coreClock: 1.725GHz coreCount: 46 deviceMemorySize: 8.00GiB deviceMemoryBandwidth: 417.29GiB/s
2020-11-30 17:47:09.857285: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudart64_110.dll
2020-11-30 17:47:09.857609: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublas64_11.dll
2020-11-30 17:47:09.857858: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublasLt64_11.dll
2020-11-30 17:47:09.858083: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cufft64_10.dll
2020-11-30 17:47:09.858310: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library curand64_10.dll
2020-11-30 17:47:09.858534: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusolver64_10.dll
2020-11-30 17:47:09.858766: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusparse64_11.dll
2020-11-30 17:47:09.858991: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudnn64_8.dll
2020-11-30 17:47:09.859247: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2020-11-30 17:47:10.265547: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-11-30 17:47:10.265630: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0
2020-11-30 17:47:10.266448: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N
2020-11-30 17:47:10.266885: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6589 MB memory) -> physical GPU (device: 0, name: GeForce RTX 3070, pci bus id: 0000:08:00.0, compute capability: 8.6)
2020-11-30 17:47:10.267361: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2020-11-30 17:47:11.146901: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2020-11-30 17:47:13.898501: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublas64_11.dll
2020-11-30 17:47:14.736090: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublasLt64_11.dll
2020-11-30 17:47:14.881003: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudnn64_8.dll
2020-11-30 17:47:21.167001: I tensorflow/stream_executor/cuda/cuda_blas.cc:1838] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
```
**Additional Note**
I have already tried compiling tf-nightly-gpu from source on Ubuntu 20.04, using tensorflow docker images, and other versions of tensorflow (2.4 rcs) but all of them result in the same situation I am stuck in now. 
**GPU utilization during training: 0%** **CPU utilization during training: 50-60%**
The CPU I am using is the AMD Ryzen 3800x.
Link to my [stack question](https://stackoverflow.com/questions/65056018/tensorflow-trains-on-cpu-instead-of-rtx-3000-series-gpu)"
45284,how  optimize a noise image with tensorflow?,"
how to apply sgd to an image with tensorflow?

I have these elements:
* image noise
* target image
* optimizer
* loss function
Is there a way to optimize a noise image so that it looks more like a target image?
first it starts with noise then we calculate the difference or error between image noise and target image, then we calculate the gradient and apply it to the noise image."
45281,"I am trying to convert yolov3 to a full uint8 tflite model after, i got this error : Quantized not yet supported for op : 'EXP'","Quantized not yet supported for op : 'EXP'
Quantized not yet supported for op : 'EXP'
Quantized not yet supported for op : 'EXP'"
45279,Error building graph with `@tf.function` decorator for recursive function with strided slices,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux version 5.9.8-arch1-1
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): pip install tensorflow --user 
- TensorFlow version (use command below): v2.3.0-54-gfcc4b966f1 2.3.1
- Python version: python 3.8.6-1
- Bazel version (if compiling from source): 
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: None
- GPU model and memory: None

**Describe the current behavior**

I coded my own 3 dimensional FFT with TensorFlow, translated from the algorithm `In[4]` of [https://jakevdp.github.io/blog/2013/08/28/understanding-the-fft/](https://jakevdp.github.io/blog/2013/08/28/understanding-the-fft/).

I know there is already an FFT coded in TensorFlow, but it does not have a gradient implemented, which I need.

The code works without the decorators `@tf.function` and gives results coherent with `numpy`. However it crashes while building the graph if they are present, invoking an error on dimensions (ill computed in the case of graph computation). I have not been able to trace the problem to its core. 

**Describe the expected behavior**

I would expect the code to work with decorators, however I must admit that the use of strided slices in a recursive function might be not be compatible with automatic graph building (lines 30 and 31).

**Standalone code to reproduce the issue**

```
#!/usr/bin/env python3

import numpy as np
import tensorflow as tf

dtype = 'float32'
cdtype = 'complex64'
c_pi = tf.constant(np.pi, cdtype)

# Leaves of the FFT algorithm : DFT of 32
# Just building a 32 x 32 complex matrix
tf_Nmin = 32
tf_rg = tf.range(tf_Nmin)
tf_k = tf.broadcast_to(tf_rg, (tf_Nmin, tf_Nmin))
tf_n = tf.transpose(tf_k)
tf_M = tf.exp(-2j * c_pi * tf.cast(tf_k * tf_n / tf_Nmin, cdtype))


# Matrix product between M and x with shape = [32, 128, 128] 
# Works without the decorator
# Fails with the decorator, invoking that the shapes are [32,32] and [128,16384]. 
@tf.function
def _tf_FFT0_leaf(x):
    return (tf.tensordot(tf_M, x, axes=[[1], [0]]))


# Nodes of the FFT algorithm
@tf.function
def _tf_FFT0_node(x, N):
    N2 = N // 2
    XE = tf_FFT0(x[::2, :, :], N2)
    XO = tf_FFT0(x[1::2, :, :], N2)
    fac = tf.exp(-2j * c_pi * tf.cast(tf.range(N2) / N, cdtype))
    fac = tf.transpose(tf.broadcast_to(fac, [tf_N, tf_N, N2]), perm=(2, 0, 1))
    fXO = fac * XO
    return (tf.concat([XE + fXO, XE - fXO], axis=0))


# Recursive function of the FFT algorithm
@tf.function
def tf_FFT0(x, N):
    return (tf.cond(N <= tf_Nmin, lambda: _tf_FFT0_leaf(x),
                    lambda: _tf_FFT0_node(x, N)))


# Run the code
nx = 128
x = np.random.random((nx, nx, nx))
tf_x = tf.cast(x, cdtype)
tf_N = tf.constant(x.shape[0], 'int32')

y = tf_FFT0(tf_x, tf_N)
z = np.fft.fft(x, axis=0)
print()
print('DIFF WITH NUMPY', np.mean(np.abs(y - z) / np.abs(z)))
```
**Other info / logs** 

Output **without** decorator:
```
2020-11-30 19:51:41.195663: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory
2020-11-30 19:51:41.195690: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2020-11-30 19:51:42.046458: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2020-11-30 19:51:42.046475: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)
2020-11-30 19:51:42.046485: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (lyonovae21.in2p3.fr): /proc/driver/nvidia/version does not exist
2020-11-30 19:51:42.046697: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-11-30 19:51:42.066848: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 1900610000 Hz
2020-11-30 19:51:42.067237: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5590a7465cf0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-11-30 19:51:42.067308: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version

DIFF WITH NUMPY 4.81155889723075e-06
```

Output **with** decorator:
```
2020-11-30 20:13:22.743043: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory
2020-11-30 20:13:22.743073: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2020-11-30 20:13:23.540001: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2020-11-30 20:13:23.540022: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)
2020-11-30 20:13:23.540035: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (lyonovae21.in2p3.fr): /proc/driver/nvidia/version does not exist
2020-11-30 20:13:23.540281: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-11-30 20:13:23.560290: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 1900610000 Hz
2020-11-30 20:13:23.560760: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5602b27b1590 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-11-30 20:13:23.560786: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
Traceback (most recent call last):
  File ""crash_tf.py"", line 54, in <module>
    y = tf_FFT0(tf_x, tf_N)
  File ""/home/valade/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py"", line 780, in __call__
    result = self._call(*args, **kwds)
  File ""/home/valade/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py"", line 823, in _call
    self._initialize(args, kwds, add_initializers_to=initializers)
  File ""/home/valade/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py"", line 696, in _initialize
    self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access
  File ""/home/valade/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py"", line 2855, in _get_concrete_function_internal_garbage_collected
    graph_function, _, _ = self._maybe_define_function(args, kwargs)
  File ""/home/valade/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py"", line 3213, in _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)
  File ""/home/valade/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py"", line 3065, in _create_graph_function
    func_graph_module.func_graph_from_py_func(
  File ""/home/valade/.local/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py"", line 986, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File ""/home/valade/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py"", line 600, in wrapped_fn
    return weak_wrapped_fn().__wrapped__(*args, **kwds)
  File ""/home/valade/.local/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py"", line 973, in wrapper
    raise e.ag_error_metadata.to_exception(e)
ValueError: in user code:

    crash_tf.py:43 tf_FFT0  *
        return (tf.cond(N <= tf_Nmin, lambda: _tf_FFT0_leaf(x),
    crash_tf.py:21 _tf_FFT0_leaf  *
        return (tf.tensordot(tf_M, x, axes=[[1], [0]]))
    /home/valade/.local/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:201 wrapper  **
        return target(*args, **kwargs)
    /home/valade/.local/lib/python3.8/site-packages/tensorflow/python/ops/math_ops.py:4518 tensordot
        ab_matmul = matmul(a_reshape, b_reshape)
    /home/valade/.local/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:201 wrapper
        return target(*args, **kwargs)
    /home/valade/.local/lib/python3.8/site-packages/tensorflow/python/ops/math_ops.py:3253 matmul
        return gen_math_ops.mat_mul(
    /home/valade/.local/lib/python3.8/site-packages/tensorflow/python/ops/gen_math_ops.py:5640 mat_mul
        _, _, _op, _outputs = _op_def_library._apply_op_helper(
    /home/valade/.local/lib/python3.8/site-packages/tensorflow/python/framework/op_def_library.py:742 _apply_op_helper
        op = g._create_op_internal(op_type_name, inputs, dtypes=None,
    /home/valade/.local/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py:591 _create_op_internal
        return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access
    /home/valade/.local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:3477 _create_op_internal
        ret = Operation(
    /home/valade/.local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:1974 __init__
        self._c_op = _create_c_op(self._graph, node_def, inputs,
    /home/valade/.local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py:1815 _create_c_op
        raise ValueError(str(e))

    ValueError: Dimensions must be equal, but are 32 and 128 for '{{node Tensordot/MatMul}} = MatMul[T=DT_COMPLEX64, transpose_a=false, transpose_b=false](Tensordot/a, Tensordot/Reshape)' with input shapes: [32,32], [128,16384].
```"
45274,Initial step for TensorBoard Callback,"**System information**
- TensorFlow version (you are using): 2.3.1
- Are you willing to contribute it (Yes/No): No

**Describe the feature and the current behavior/state.**
Add ```initial_train_step``` and ```initial_test_step``` as ```__init__``` arguments.
Currently, TensorBoard callback starts writing metrics from step 0 for both train and test, but it breaks the graphs if model.fit() was used in tandem with loaded checkpoint. *STEP* horizontal axis does not provide graph consistency, *RELATIVE* and *WALL* horizontal axis provides metrics consistency, but horizontal axis has huge value gaps in it. Each subsequent run starts writing from step 0

![image](https://user-images.githubusercontent.com/42458049/100635373-81e39a80-3341-11eb-8082-13c2d966e468.png)
*STEP horizontal axis*

![image](https://user-images.githubusercontent.com/42458049/100635480-a0499600-3341-11eb-85c8-3834de3759b5.png)
*RELATIVE horizontal axis, first small gap is from testing after epoch*

**Will this change the current api? How?**
No

**Who will benefit with this feature?**
People who use model.fit() with checkpoints
"
45273,DLL load failed while importing _pywrap_tensorflow_internal,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1.  It must be a bug, a feature request, or a significant problem with the
    documentation (for small docs fixes please send a PR instead).
2.  The form below must be filled out.
3.  It shouldn't be a TensorBoard issue. Those go
    [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information

-   **Have I written custom code (as opposed to using a stock example script
    provided in TensorFlow)**:
-   **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
-   **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue
    happens on a mobile device**:
-   **TensorFlow installed from (source or binary)**:
-   **TensorFlow version (use command below)**:
-   **Python version**:
-   **Bazel version (if compiling from source)**:
-   **GCC/Compiler version (if compiling from source)**:
-   **CUDA/cuDNN version**:
-   **GPU model and memory**:
-   **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with:

```bash
python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""
```

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
45272,Namerror when loading model,"OS: Ubuntu 18.04
Tensorflow version : 2.2.0


I am trying to load a model saved in h5 format for a model with a custom layer but getting a Namerror.

This is the implementation of the custom layer (Dropout) :
```
class myDropout(keras.layers.Dropout):
   """"""Applies Dropout to the input.
     Dropout consists in randomly setting
     a fraction `rate` of input units to 0 at each update during training time,
     which helps prevent overfitting.
     # Arguments
         rate: float between 0 and 1. Fraction of the input units to drop.
         noise_shape: 1D integer tensor representing the shape of the
             binary dropout mask that will be multiplied with the input.
             For instance, if your inputs have shape
             `(batch_size, timesteps, features)` and
             you want the dropout mask to be the same for all timesteps,
             you can use `noise_shape=(batch_size, 1, features)`.
         seed: A Python integer to use as random seed.
     # References
         - [Dropout: A Simple Way to Prevent Neural Networks from Overfitting](
            http://www.jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf)
     """"""
     def __init__(self, rate, training=True, noise_shape=None, seed=None, name=None, **kwargs):
         super(myDropout, self).__init__(rate, noise_shape=None, seed=None,name = name,**kwargs)
         self.training = training

     def get_config(self):
         config = super(myDropout, self).get_config()
         config.update({""rate"": self.rate})
         # return config
         return {""output"": config, ""name"": self.name}


     def call(self, inputs, training=None):
         if 0. < self.rate < 1.:
             noise_shape = self._get_noise_shape(inputs)

             def dropped_inputs():
                 return K.dropout(inputs, self.rate, noise_shape,
                                  seed=self.seed)
             if not training:
                 return K.in_train_phase(dropped_inputs, inputs, training=self.training)
             return K.in_train_phase(dropped_inputs, inputs, training=training)
         return inputs)
```
and the command I use to load the model is:

loaded_model = tf.keras.models.load_model(path, custom_objects={'myDropout': myDropout})

and the error message is:

NameError: name 'myDropout' is not defined

"
45271,Use pretrained weight for another smaller model,"Is it possible to possible to use a pretrained weight of a large model (for example ResNet151) and cut a part out of it to fit a custom, rather small model?
If it is the case, how can it be managed?
Thanks for any ideas!
"
45270,torch.nn.functional.grid_smaple tensorflow2.0 how to recurrence?,torch.nn.functional.grid_smaple tensorflow2.0 how to recurrence?
45269,tf.saved_model.save does not work using uint8 Input-Layer,"System information:
- Testted on colab.research.google.com
- Tensorflow 2.3.1

The following minimal Model cannot be saved using `tf.saved_model.save`:
```
import tensorflow as tf
from tensorflow.keras import backend as K
from tensorflow.keras import layers
from tensorflow.keras.layers.experimental.preprocessing import Rescaling
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.utils import Sequence
filters = (40, 60, 80)
p = dict(padding=""same"",
          activation=""selu"",
          kernel_size=(3, 3),
          kernel_initializer=""lecun_normal"",
          bias_initializer=""zeros"")
ALPHABET = ""asdf4711""
i = layers.Input((None, None, 3), name='input', dtype='uint8')
x = layers.Permute((2, 1, 3))(i)
x = Rescaling(1. / 255.)(x)
x = layers.LayerNormalization(axis=1, center=False, scale=False)(x)
x = layers.Conv2D(filters[0], **p)(x)
x = layers.Conv2D(filters[0], **p)(x)
x = layers.Conv2D(filters[1], strides=(2, 3), **p)(x)
x = layers.Conv2D(filters[1], **p)(x)
x = layers.Conv2D(filters[1], **p)(x)
x = layers.Conv2D(filters[2], strides=(2, 3), **p)(x)
x = layers.Conv2D(filters[2], **p)(x)
x = layers.Conv2D(filters[2], **p)(x)

x = layers.Lambda(lambda t: tf.math.reduce_max(t, axis=2))(x)
x = layers.Bidirectional(layers.GRU(x.shape[-1], return_sequences=True), 'sum')(x)
x = layers.Bidirectional(layers.GRU(x.shape[-1], return_sequences=True), 'sum')(x)
x = layers.Conv1D(len(ALPHABET) + 1, 1, activation=""softmax"")(x)
m = Model(inputs=i, outputs=x)
```
Instead of saving the model, i get the following error:
`
ValueError: Python inputs incompatible with input_signature: inputs ((<tf.Tensor 'input:0' shape=(None, None, None, 3) dtype=uint8>,)), input_signature ((TensorSpec(shape=(None, None, None, None), dtype=tf.float32, name=None),))`

When I change the type of the input layer to `'float32'`,  the export works fine. However, when deployed in tensorflow-serving and calling it via grpc, using uint8 instead of float32 significantly reduces network io in this use case.

"
45268,What is the difference between Keras Attention and “Scaled dot product attention” as in the TF Transformer tutorial,"I am going through the TF Transformer tutorial: https://www.tensorflow.org/tutorials/text/transformer#scaled_dot_product_attention

And I was comparing the output from their defined Attention to the one from Keras (https://www.tensorflow.org/api_docs/python/tf/keras/layers/Attention there you can also see the code).

Testing on basic examples, they produce slightly different results.

For example, given the following input x:

```
In [311]: x
Out[311]: 
<tf.Tensor: shape=(1, 2, 4), dtype=float32, numpy=
array([[[0.3020829 , 0.38190305, 0.48654556, 0.6720122 ],
        [0.04044473, 0.04240108, 0.19330955, 0.01818049]]], dtype=float32)>
```

Which was generated as

`x = tf.random.uniform((1, 2, 4))`

if I run this through the tutorial attention function, I get:

```
In [312]: scaled_dot_product_attention(x, x, x, None)
Out[312]: 
(<tf.Tensor: shape=(1, 2, 4), dtype=float32, numpy=
 array([[[0.19679338, 0.24527925, 0.36854032, 0.40889454],
         [0.17432278, 0.21612138, 0.34335595, 0.35274068]]], dtype=float32)>
```

But if I use keras attention function, everything default, I get:

```
In [309]: model.predict([x,x,x])
Out[309]: 
array([[[0.22044972, 0.27597573, 0.39505363, 0.46801156],
        [0.17737839, 0.22008634, 0.34678057, 0.3603766 ]]], dtype=float32)
```

where model is just

`model = tf.keras.models.Model(inputs=[query, value, key], outputs=tf.keras.layers.Attention()([value,value,value]))`

As you can see, the values are very similar, but not exactly the same.

I wonder where this difference is coming from. Checking through the keras github I don't see them doing a scaling factor, such as in the tutorial:

```
  # scale matmul_qk
  dk = tf.cast(tf.shape(k)[-1], tf.float32)
  scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)
```

but if I define ""use_scale"" in keras attention, it doesnt make a difference:

```
In [313]: model = tf.keras.models.Model(inputs=[query, value, key], outputs=tf.keras.layers.Attention(use_scale=True)([value,value,value]))
In [315]: model.predict([x,x,x])
Out[315]: 
array([[[0.22044972, 0.27597573, 0.39505363, 0.46801156],
        [0.17737839, 0.22008634, 0.34678057, 0.3603766 ]]], dtype=float32)
```

I would really appreciate if someone could tell me what's the difference between keras attention and the attention from the tutorial. Thanks
"
45267,ERROR: Could not find a version that satisfies the requirement tensorflow==1.2.1 ? pip cannot find tensroflow 1 versions,"I cannot install any tensorflow 1 version in my virtual env.. it is required by a project that I'm trying to run..


    pip install tensorflow==1.2.1
    ERROR: Could not find a version that satisfies the requirement tensorflow==1.2.1 (from versions: 2.2.0rc1, 2.2.0rc2, 2.2.0rc3, 2.2.0rc4, 2.2.0, 2.2.1, 2.3.0rc0, 2.3.0rc1, 2.3.0rc2, 2.3.0, 2.3.1, 2.4.0rc0, 2.4.0rc1, 2.4.0rc2, 2.4.0rc3)
    ERROR: No matching distribution found for tensorflow==1.2.1

Tried things suggested here :

https://stackoverflow.com/questions/42317075/tensorflow-r1-0-could-not-a-find-a-version-that-satisfies-the-requirement-tens


my python version is not old : 3.8.5

my pip version is OK : 20.0.2


i still CANNOT install tensorflow 1.2.1 ...


what i gotta do.. I am using ubuntu 20"
45266,tf.gather behavior depends on dtype,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): sort of
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: -
- TensorFlow installed from (source or binary): pip
- TensorFlow version (use command below): 2.2
- Python version: 3.8
- Bazel version (if compiling from source): -
- GCC/Compiler version (if compiling from source): -
- CUDA/cuDNN version: -
- GPU model and memory: -

**Describe the current behavior**
```
a = tf.ones((2, 3), dtype=tf.int32)
b = tf.constant([0, 1])
print(  tf.gather(a, b, batch_dims=-1).shape )
```
returns a shape of (2, ) whereas

```
a = tf.ones((2, 3), dtype=tf.int64)
b = tf.constant([0, 1])
print(  tf.gather(a, b, batch_dims=-1).shape )
```
returns a shape of (2, 2).

**Describe the expected behavior**
I'm not 100% which should be the expected behavior of tf.gather, but it seems like it should not depend on the dtype of a.

**Standalone code to reproduce the issue**
See above

**Other info / logs** Include any logs or source code that would be helpful to
–
"
45263,libcusolver.so.10? ,"```
coreClock: 1.755GHz coreCount: 68 deviceMemorySize: 10.74GiB deviceMemoryBandwidth: 573.69GiB/s
2020-11-30 17:36:59.367782: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2020-11-30 17:36:59.369653: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2020-11-30 17:36:59.369702: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2020-11-30 17:36:59.370388: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2020-11-30 17:36:59.370548: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2020-11-30 17:36:59.370610: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcusolver.so.10'; dlerror: libcusolver.so.10: cannot open shared object file: No such file or directory
2020-11-30 17:36:59.371080: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2020-11-30 17:36:59.371185: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2020-11-30 17:36:59.371200: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1764] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2020-11-30 17:36:59.475119: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-11-30 17:36:59.475153: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1273]      0 
2020-11-30 17:36:59.475162: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1286] 0:   N 
```

but we should have
```
libcusolverMg.so.11 (libc6,x86-64) => /opt/cuda/lib64/libcusolverMg.so.11
libcusolverMg.so (libc6,x86-64) => /opt/cuda/lib64/libcusolverMg.so
libcusolver.so.11 (libc6,x86-64) => /opt/cuda/lib64/libcusolver.so.11
libcusolver.so (libc6,x86-64) => /opt/cuda/lib64/libcusolver.so
```

"
45261,ReduceLROnPlateau forced casting on integer learning rates,"**Issue in `ReduceLROnPlateau`**
- `ReduceLROnPlateau` relies of the function: `Keras.set_value`
- When using `ReduceLROnPlateau`, this ensures the reduced LR is of the same type as input LR
- This is an issue if the learning rate is specified as an integer. I.e. different behaviour for LR = 1 and LR = 1.0

**Describe the current behavior**
Example 1: Initial learning rate 1, factor 0.5. First reduction should drop to 0.5.
Example 2:Initial learning rate 5, factor 0.5. First reduction should drop to 2.5.

**Describe the expected behavior**
Example 1: First reduction drops to 0.
Example 2: First reduction drops to 2.

**Standalone code to reproduce the issue**
```
import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import ReduceLROnPlateau

n = 100

model = keras.Sequential()
model.add(keras.layers.Dense(n, activation='linear')

model.compile(optimizer = keras.optimizers.Adam(lr=1), loss =  ['mse'])

x = np.random.rand(2, n)
y = np.random.rand(2, n)

reduce_lr = ReduceLROnPlateau(monitor='loss', min_lr=1e-6, patience = 1, factor = 0.1, verbose = 1)

history = model.fit(x, y, epochs = 10, callbacks = [reduce_lr,], verbose = 0)

history.history['lr']
```
**Outputs**
Epoch 00002: ReduceLROnPlateau reducing learning rate to 0.1.


[1, 1, 0, 0, 0, 0, 0, 0, 0, 0]
"
45259,SeparableConv documention missing argument constraint,"The documentation of the SeparableConv layers does not mention that the strides must be equal length.

Trying to use different lengths produces an InvalidArgumentError: Current implementation only supports equal length strides in the row and column dimensions."
45258,Unable to install CUDA 11.1 and cuDNN 8.05 for tensorflow 2.3,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version: 2.3
- Python version: 3.8.5
- Installed using virtualenv? pip? conda?: pip
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 11.1 and 8.05
- GPU model and memory: GeForce GTX 1650 4GB



**Describe the problem**
Unable to detect GPU
**Provide the exact sequence of commands / steps that you executed before running into the problem**
Installed tensorflow 2.3
Installed CUDA 11.1
Downloaded cuDNN 8.05
added files from cuDNN to the respective folders in CUDA directory
added CUDA to the path
imported tensorflow-gpu in python shows error that gpu not found
**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
45257,module 'tensorflow._api.v2.data' has no attribute 'dataset',"Code written:
batch_size = 32
dataset = tf.data.dataset.from_tensor_slices(x_train).shuffle(1000)
dataset = dataset.batch(batch_size, drop_remainder=True).prefetch(1)

Error:
---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
<ipython-input-4-fba98a470002> in <module>
      1 batch_size = 32
----> 2 dataset = tf.data.dataset.from_tensor_slices(x_train).shuffle(1000)
      3 dataset = dataset.batch(batch_size, drop_remainder=True).prefetch(1)

AttributeError: module 'tensorflow._api.v2.data' has no attribute 'dataset'

Tensorflow version: 2.3.1

Solved

The code should be:
dataset = tf.data.Dataset.from_tensor_slices(x_train).shuffle(1000)"
45256,Barrier in implementing demo: SHAPE -> STRIDED_SLICE impossible?,"@tensorflow/micro

**System information**
- TensorFlow installed from (source or binary): source
- Tensorflow version (commit SHA if source): 4d2124d19daffa088aca8c2485b56c8f1717ec0e
- Target platform (e.g. Arm Mbed OS, Arduino Nano 33 etc.): ESP32

**Describe the problem**

After training/converting a Keras MobileNetV1 model, running inference on the ESP32 produces this error:
```
Type INT32 (2) not supported.
Processing Node STRIDED_SLICE (number 34) failed to invoke with status 1
Node STRIDED_SLICE (number 34) failed to invoke with status 1
```

**Please provide the exact sequence of commands/steps when you ran into the problem**

Steps are based on the [person detector](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/examples/person_detection/training_a_model.md
) tutorial. 

I build the model with keras: 
```model = tf.keras.applications.mobilenet.MobileNet(weights=None, input_shape=(96, 96, 1), alpha = 0.25, classes=6)```

Then successfully convert:
```
converter = tf.lite.TFLiteConverter.from_saved_model(""..."")
converter.optimizations = [tf.lite.Optimize.DEFAULT]
converter.representative_dataset = representative_dataset_gen
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8] # removing these lines does not fix the error
converter.inference_input_type = tf.int8 # removing these lines does not fix the error
converter.inference_output_type = tf.int8 # removing these lines does not fix the error
tflite_model = converter.convert()
open(""model_out.tflite"", ""wb"").write(tflite_model)
```

And finally run:
```
xxd -i model_out.tflite > custom_model_data.cc
```


I am running a slightly modified version of the person_detection demo project. Some additional layers need to be registered compared to the demo code (not sure why):
```
static tflite::MicroMutableOpResolver<10> micro_op_resolver(error_reporter);
  micro_op_resolver.AddAveragePool2D();
  micro_op_resolver.AddConv2D();
  micro_op_resolver.AddDepthwiseConv2D();
  micro_op_resolver.AddPad();
  micro_op_resolver.AddMean();
  micro_op_resolver.AddShape();
  micro_op_resolver.AddStridedSlice();
  micro_op_resolver.AddPack();
  micro_op_resolver.AddReshape();
  micro_op_resolver.AddSoftmax();
```

Any inference attempts result in the original error I posted above. I believe that this is the inevitable result of a SHAPE layer layer (which outputs an int32 type), followed by a STRIDED_SLICE layer (which doesn't support int32 as input). 

Is there any way to get around this? Or alternatively, how did the authors of the tutorial successfully produce a mobilenetv1 model that required such few operations to be registered? I am taking the same quantization steps, and believe the model is the same.

Thanks!

"
45255,"Universal support for bfloat16 data, ie saving results of float32 operations as bfloat16 to memory by truncating","<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): 2 (google colab)
- Are you willing to contribute it (Yes/No): ?



**Describe the feature and the current behavior/state.**

bfloat16 is a truncated float32. That means that any float32 value can be cast to bfloat16 by simply discarding the high two bytes, for example by a 16bit-shift or mask and saving the remaining bits into a 2-byte type, or packing two truncated floats into a 4-byte type. Such operations are available universally. Currently, bfloat16 is only supported on TPUs and some CPUs, which makes sense because those also accelerate computation on bfloat16 values.

But all devices can benefit from bfloat16 data even when there is no half-precision computation support of any form: By doing calculations in float32, but truncating the results to 16bits (""casting"" to bfloat16) before saving to memory, and expanding back to 32bits after loading from memory, one can improve memory utilization (allowing larger models) and also increase the effective memory bandwidth.
This would not utilize fast half-precision _processing_, but that is effectively unusable for training anyways when there is no fast mixed-precision support.

Because bfloat16 has the same range of values as float32 but at a lower precision, it can solve the problem of underruns/overflows arising when using pure float16 when training on devices that do not support mixed precision, while still providing the memory size and bandwidth benefits of 16-bit data.

Currently, setting the dtype policy to ""bfloat16"" like so:
`policy = tf.keras.mixed_precision.experimental.Policy('bfloat16')
tf.keras.mixed_precision.experimental.set_policy(policy)`
Does not raise errors immediately, but results in type errors when building the model:
`Value for attr 'T' of bfloat16 is not in the list of allowed values: double, float, half, complex64, complex128 [...]`
Some tensorflow operations and layers do not support bfloat16 on the Tesla T4 used in colab, notably LSTMs. Removing such layers allows building the model, but will raise another type error when attempting to train the model via model.fit().

**Will this change the current api? How?**
No change, support for bfloat16 already exists for certain devices. Implementing this feature could be done via creating another mixed-precision policy, like ""data-bfloat16"".

**Who will benefit from this feature?**
Everybody that uses devices without mixed precision or even any half precision support (for reference, only Volta, Turing, and Ampere GPUs support fast mixed precision. The still widely-used Pascal GPUs like the P100 don't support it), by allowing to take advantage of improved memory utilization and effective memory bandwidth without the disabling underrun issues when attempting to train using pure float16. CPUs that are often bandwidth-limited in vector operations might benefit the most from 16-bit data.

**Any Other info.**

This feature would not benefit anyone that uses the most cutting-edge hardware. But for reference, even the P100 used in google colab services would benefit from a feature like this. While it would make no difference to researchers and companies with access to expensive cutting-edge hardware, those make up only a part of tensorflow's users. Enabling everyone to experiment with models with up to twice the size given their current hardware would be an obvious benefit for most users of tensorflow."
45254,model.save fails to create directories on Windows,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 2004
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.1.0
- Python version: 3.7
- CUDA/cuDNN version: cudart64_101.dll
- GPU model and memory: GeForce GTX 1070


**Steps to reproduce**
First make sure the current directory doesn't have `saved_model` folder.

![dopus_fJLqMA2WiE](https://user-images.githubusercontent.com/614159/100533710-53cb6100-3242-11eb-992a-b78539462db1.png)

Then run the following code

```
import os

import tensorflow as tf
from tensorflow import keras

print(tf.version.VERSION)


(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()

train_labels = train_labels[:1000]
test_labels = test_labels[:1000]

train_images = train_images[:1000].reshape(-1, 28 * 28) / 255.0
test_images = test_images[:1000].reshape(-1, 28 * 28) / 255.0

def create_model():
	model = tf.keras.models.Sequential([
		keras.layers.Dense(512, activation='relu', input_shape=(train_images.shape[1],)),
		keras.layers.Dropout(0.2),
		keras.layers.Dense(10)
	])

	model.compile(optimizer='adam',
				  loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),
				  metrics=['accuracy'])

	return model


model = create_model()

model.summary()

# Create and train a new model instance.
model = create_model()
model.fit(train_images, train_labels, epochs=5)

# Save the entire model as a SavedModel.
model.save('saved_model/my_model')
```

**Describe the current behavior**

model.save throws exception:
> Traceback (most recent call last):
>   File ""D:/renaming/neural network/tensorflow/6.save_and_load.py"", line 124, in <module>
>     model.save('saved_model/my_model')
>   File ""C:\ProgramData\Miniconda3\envs\tf\lib\site-packages\tensorflow_core\python\keras\engine\network.py"", line 1008, in save
>     signatures, options)
>   File ""C:\ProgramData\Miniconda3\envs\tf\lib\site-packages\tensorflow_core\python\keras\saving\save.py"", line 115, in save_model
>     signatures, options)
>   File ""C:\ProgramData\Miniconda3\envs\tf\lib\site-packages\tensorflow_core\python\keras\saving\saved_model\save.py"", line 78, in save
>     save_lib.save(model, filepath, signatures, options)
>   File ""C:\ProgramData\Miniconda3\envs\tf\lib\site-packages\tensorflow_core\python\saved_model\save.py"", line 915, in save
>     utils_impl.get_or_create_variables_dir(export_dir)
>   File ""C:\ProgramData\Miniconda3\envs\tf\lib\site-packages\tensorflow_core\python\saved_model\utils_impl.py"", line 214, in get_or_create_variables_dir
>     file_io.recursive_create_dir(variables_dir)
>   File ""C:\ProgramData\Miniconda3\envs\tf\lib\site-packages\tensorflow_core\python\lib\io\file_io.py"", line 440, in recursive_create_dir
>     recursive_create_dir_v2(dirname)
>   File ""C:\ProgramData\Miniconda3\envs\tf\lib\site-packages\tensorflow_core\python\lib\io\file_io.py"", line 455, in recursive_create_dir_v2
>     pywrap_tensorflow.RecursivelyCreateDir(compat.as_bytes(path))
> tensorflow.python.framework.errors_impl.NotFoundError: Failed to create a directory: saved_model/my_model\variables; No such file or directory

Folder saved_model is created, but it contains nothing.

![dopus_K6JLvfsHQ7](https://user-images.githubusercontent.com/614159/100533801-54b0c280-3243-11eb-8600-0dc81f526fc6.png)

**Describe the expected behavior**

If model.save requires the presence of the path, the method should fail in  the first place, without creating the `saved_model` folder

If the method is able to create folders, why doesn't it create `my_model` subfolder as well?"
45253,"Eager Gradients C api is C++, along with a few others","A few files in `tensorflow/c/eager` expose C++ APIs instead of C.  [gradients.h](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/c/eager/gradients.h), [tape.h](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/c/eager/tape.h), and the `abstract_.h` files (i.e.  [abstract_context.h](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/c/eager/abstract_context.h))  do this, and possibly more.  There are no C apis exposed for most of these, either, just the C++.   Has the design changed or is this just an oversight?

cc @karllessard"
45252,"""error: 'tf.Conv2D' op is neither a custom op nor a flex op"" when converting a basic MNIST network","

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux, Ubuntu 20.04
- TensorFlow installed from (source or binary): binary from pip3 install tensorflow
- TensorFlow version (or github SHA if from source): 2.3.1 and tf-nightly 2.5.0-dev20201128


**Command used to run the converter or code if you’re using the Python API**
If possible, please share a link to Colab/Jupyter/any notebook.

```
import tensorflow as tf
from tensorflow import keras

print(tf.__version__)

model = keras.models.load_model(""mnist.h5"")
# tf.saved_model.save(model, ""new_mnist"")

converter = tf.lite.TFLiteConverter.from_keras_model(model)

# converter = tf.lite.TFLiteConverter.from_saved_model(""mnist.h5"")
converter.optimizations = [tf.lite.Optimize.DEFAULT]

num_calibration_steps = 10

def representative_dataset_gen():
  for _ in range(num_calibration_steps):
    # Get sample input data as a numpy array in a method of your choosing.
    yield [input]
    
converter.representative_dataset = representative_dataset_gen
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]
converter.inference_input_type = tf.int8  # or tf.uint8
converter.inference_output_type = tf.int8  # or tf.uint8
tflite_quant_model = converter.convert()

open(""quantized.tflite"", ""wb"").write(tflite_quant_model)
# Copy and paste here the exact command
```

**The output from the converter invocation**

```
# Copy and paste the output here.   (Full log is attached at the end)
cx872@T460p:~/Desktop/temp$ python3 quantize.py 
2020-11-28 15:28:02.571351: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory
2020-11-28 15:28:02.571375: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2020-11-28 15:28:03.736827: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2020-11-28 15:28:03.736848: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)
2020-11-28 15:28:03.736865: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (T460p): /proc/driver/nvidia/version does not exist
2020-11-28 15:28:03.737083: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-11-28 15:28:03.762679: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2599990000 Hz
2020-11-28 15:28:03.763178: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4878980 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-11-28 15:28:03.763205: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
WARNING:tensorflow:From /home/cx872/.local/lib/python3.8/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
2020-11-28 15:28:03.973359: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
WARNING:tensorflow:From /home/cx872/.local/lib/python3.8/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
2020-11-28 15:28:04.369274: I tensorflow/core/grappler/devices.cc:69] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0
2020-11-28 15:28:04.369473: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session
2020-11-28 15:28:04.374144: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: graph_to_optimize
2020-11-28 15:28:04.374171: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.003ms.
2020-11-28 15:28:04.374181: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0ms.
2020-11-28 15:28:04.398758: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:313] Ignored output_format.
2020-11-28 15:28:04.398813: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:316] Ignored drop_control_dependency.
loc(callsite(""sequential/conv2d/Conv2D""(""/home/cx872/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py"":1073:0) at callsite(""/home/cx872/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py"":1167:0 at callsite(""/home/cx872/.local/lib/python3.8/site-packages/tensorflow/lite/python/lite.py"":804:0 at ""quantize.py"":23:0)))): error: 'tf.Conv2D' op is neither a custom op nor a flex op
loc(callsite(""sequential/conv2d_1/Conv2D""(""/home/cx872/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py"":1073:0) at callsite(""/home/cx872/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py"":1167:0 at callsite(""/home/cx872/.local/lib/python3.8/site-packages/tensorflow/lite/python/lite.py"":804:0 at ""quantize.py"":23:0)))): error: 'tf.Conv2D' op is neither a custom op nor a flex op
loc(callsite(""sequential/conv2d_2/Conv2D""(""/home/cx872/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py"":1073:0) at callsite(""/home/cx872/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py"":1167:0 at callsite(""/home/cx872/.local/lib/python3.8/site-packages/tensorflow/lite/python/lite.py"":804:0 at ""quantize.py"":23:0)))): error: 'tf.Conv2D' op is neither a custom op nor a flex op
error: failed while converting: 'main': Ops that can be supported by the flex runtime (enabled via setting the -emit-select-tf-ops flag):
	tf.Conv2D {data_format = ""NCHW"", device = """", dilations = [1, 1, 1, 1], explicit_paddings = [], padding = ""VALID"", strides = [1, 1, 1, 1], use_cudnn_on_gpu = true}
Traceback (most recent call last):
  File ""/home/cx872/.local/lib/python3.8/site-packages/tensorflow/lite/python/convert.py"", line 196, in toco_convert_protos
    model_str = wrap_toco.wrapped_toco_convert(model_flags_str,
  File ""/home/cx872/.local/lib/python3.8/site-packages/tensorflow/lite/python/wrap_toco.py"", line 32, in wrapped_toco_convert
    return _pywrap_toco_api.TocoConvert(
Exception: /home/cx872/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:1073:0: error: 'tf.Conv2D' op is neither a custom op nor a flex op
/home/cx872/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:1167:0: note: called from
/home/cx872/.local/lib/python3.8/site-packages/tensorflow/lite/python/lite.py:804:0: note: called from
quantize.py:23:0: note: called from
/home/cx872/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:1073:0: note: see current operation: %0 = ""tf.Conv2D""(%arg0, %cst) {data_format = ""NCHW"", device = """", dilations = [1, 1, 1, 1], explicit_paddings = [], padding = ""VALID"", strides = [1, 1, 1, 1], use_cudnn_on_gpu = true} : (tensor<?x1x28x28xf32>, tensor<3x3x1x4xf32>) -> tensor<?x4x26x26xf32>
/home/cx872/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:1073:0: error: 'tf.Conv2D' op is neither a custom op nor a flex op
/home/cx872/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:1167:0: note: called from
/home/cx872/.local/lib/python3.8/site-packages/tensorflow/lite/python/lite.py:804:0: note: called from
quantize.py:23:0: note: called from
/home/cx872/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:1073:0: note: see current operation: %2 = ""tf.Conv2D""(%1, %cst_0) {data_format = ""NCHW"", device = """", dilations = [1, 1, 1, 1], explicit_paddings = [], padding = ""VALID"", strides = [1, 1, 1, 1], use_cudnn_on_gpu = true} : (tensor<?x4x26x26xf32>, tensor<3x3x4x4xf32>) -> tensor<?x4x24x24xf32>
/home/cx872/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:1073:0: error: 'tf.Conv2D' op is neither a custom op nor a flex op
/home/cx872/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:1167:0: note: called from
/home/cx872/.local/lib/python3.8/site-packages/tensorflow/lite/python/lite.py:804:0: note: called from
quantize.py:23:0: note: called from
/home/cx872/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:1073:0: note: see current operation: %4 = ""tf.Conv2D""(%3, %cst_1) {data_format = ""NCHW"", device = """", dilations = [1, 1, 1, 1], explicit_paddings = [], padding = ""VALID"", strides = [1, 1, 1, 1], use_cudnn_on_gpu = true} : (tensor<?x4x24x24xf32>, tensor<3x3x4x4xf32>) -> tensor<?x4x22x22xf32>
<unknown>:0: error: failed while converting: 'main': Ops that can be supported by the flex runtime (enabled via setting the -emit-select-tf-ops flag):
	tf.Conv2D {data_format = ""NCHW"", device = """", dilations = [1, 1, 1, 1], explicit_paddings = [], padding = ""VALID"", strides = [1, 1, 1, 1], use_cudnn_on_gpu = true}
<unknown>:0: note: see current operation: ""func""() ( {
^bb0(%arg0: tensor<?x1x28x28xf32>):  // no predecessors
  %cst = ""std.constant""() {value = dense<[[[[0.0649565831, -0.0746282786, 0.162961558, 0.0248589013]], [[-0.200302526, -0.296956897, -0.191993952, 0.220391616]], [[-0.239433467, 0.189716026, -0.311748624, 0.0287476946]]], [[[0.161856413, 0.14310281, 0.234080926, 0.183344632]], [[-0.0514137745, -0.209035754, -0.103884049, 0.158034727]], [[0.193658769, -0.0461433418, 0.327664047, -0.0481641293]]], [[[0.0117518231, 3.49453388E-4, -0.232930154, -0.24110195]], [[0.134880558, 0.145225272, 0.0606381223, 0.157407314]], [[-0.0305803325, -0.0580686741, -0.210291281, -1.786370e-01]]]]> : tensor<3x3x1x4xf32>} : () -> tensor<3x3x1x4xf32>
  %cst_0 = ""std.constant""() {value = dense<""0x246BA8BCE77820BE3ED7853ED4B554BD4EC87D3E204B0D3D6F2A883E3EE48C3D16D285BEF12B14BD519BEABDEF5E0DBD338DBCBDE90A0E3E999006BE4312993D9BFC22BDB9C0BD3D29AD97BEF97BE53D66BB98BD88E1783E8A50393EBBA648BE7B81A13CB9D46CBEB74C5B3E93CAAEBD04965DBE4FBEAD3D8279103DC15460BD2E503A3C867E10BE45275ABEEA3303BE1AA21A3E8AB858BE91E1D93DE4B185BCA5ED8DBEBB99A83D623B6DBDDB1A7B3C4A93653DDFC1013E75D25CBE934A6CBC6E48133E83671EBE5BF1013D6DCF8CBD844862BEE79AA13EC8806BBE06A623BE02164D3B2A95E43DD7E6843C49857D3EF202B2BD7873B7BE068EB2BD06E264BDBB6B243DEA4AA5BD28B1803EDF99AE3DAD55A7BDA1BC17BEDC55933EC1C3CDBD55DFF23DBCD6DDBD3412E6BDA3A471BDB4EAAFBD06B582BDC60CB0BE1FDEB43D5CCF4BBC2300523E7E86803E8969ED3D718C25BE6094373E555D6A3E2AE034BD7E7E2A3D92E3CABD188D95BECB4FCF3C0CEE2EBE91CAA9BE085C8F3ED8B81BBEBE85913E95A4B4BD5937E4BD284C333E4C1E5BBDAD9A7ABC3D2425BD6B0DE33D2E251DBE49AC923E785F903DD0E247BD4639033E626897BEECE708BC6D803A3ED3F9093E700C48BE938BC2BDB65061BDFEC42C3E53EB353BA75E0F3E39749E3C3C3F9E3D61CD243EB8688ABE0724C73D818E9BBC1366A5BEB0D903BEA71BB13B918C323C49E4353E6FABF33D871B743EDDEF0BBCDA56E9BC1629603D92B76A3EC6CEFABD2092EEBDB0629DBC1AE468BEED54E13DFEEE2CBDCAB957BE37C0FFBC""> : tensor<3x3x4x4xf32>} : () -> tensor<3x3x4x4xf32>
  %cst_1 = ""std.constant""() {value = dense<""0x6C8307BED9C6833D1EF6B9BE24D236BE24CCC8BD350DB33D1CD3A53DC392D2BD6B81AA3DF53DBCBD19550E3DC69422BC1F9686BE743FF1BC581808BE723E15BD5917E9BDB12A683C0FEEAFBEC192C4BBA881F3BCB8FF7FBE74FA063E8FFBE7BD5727AD3C012EDFBE82FB303D7E64923D391B49BE569BA7BD6C4FB1BDCC09BE3C4488993D078E03BFA8A5F43C1F65BFBDBE8C263E438998BD551AF53D6E4FBABD398069BE90D9863DA99E03BF22FE0D3C8984E9BD921D54BE1FE1343EAF04363EF79618BD3975C9BD6FE32EBE099BA2BEF717C3BD77AF16BE0810E4BD9FBDE5BCB3BDB1BDB24AF23A19009BBE4EC58D3E0AD125BECADB273E33D91F3E56C489BDD87DB73D48D55BBEA7089DBE13B1C4BC50990E3D75A0173EA137A83EF18756BEFCA212BE504710BE9968C8BE5E858ABEE50F4EBD08EA0DBDE8F803BE4D9017BEE151E5BC80E61E3E5E19BCBD77EF1CBE1DA7B13DC209A8BD72FDDFBD71A0D7BD4C14103ECEE162BE4B05783DBEF02A3D8B49C1BC460EA4BC80C977BE09F09CBD62754C3DF12585BD4708243EC9C5543EB1952FBEE2E7B2BECE570A3EDDE9DE3D28C5AA3D8B329B3D7C8462BCE647E43D5FE10B3E5F47DC3D2DA6773DDFE493BE1111793C85ADF0BD56A055BC6D6D913D50A694BC3B4702BE4698373D02B983BE7DEDD9BC9F4012BEC26F103D53000F3E51B704BEFAE88F3D9136783C4683EEBD26141E3E23F0013DF5C1E0BD91A232BDA4EC14BCDBFA8ABEC0E506BE50223BBEF810323E559D983C9E8F573EB53FB3BE5C156A3D2D64BC3D631959BD046EB13D""> : tensor<3x3x4x4xf32>} : () -> tensor<3x3x4x4xf32>
  %cst_2 = ""std.constant""() {value = dense<[0.0515903942, 0.674950719, 1.961430e-03, -0.249269262, 0.172605708, -0.0643907487, 0.0460773893, 0.245695099, -0.507323146, -0.116961144]> : tensor<10xf32>} : () -> tensor<10xf32>
  %cst_3 = ""std.constant""() {value = dense<[-1, 1936]> : tensor<2xi32>} : () -> tensor<2xi32>
  %cst_4 = ""std.constant""() {value = dense<""0x4BA6EFBC1D3EE5BCC63F83BC0A188BBD0E055C3D1BC2853B9C074EBCF42E07BD2F21193DB9AC443D842D453D27C931BC3EDF7E3D58647F3D33F419BDF336A63D6511E63C8A4E593D01ACBB3C3607B93D2C5B2BBD52099F3C6844D93D334FEBBCD3A71D3DF321333CF847A43C5CC9863CC5B8FC3CE8B9653CD0006BBC0BA2D03CA7814A3CDCACAB3C91B9873DFCBD93BC394EC23DB9AC02BDCD5F703BAA1EEBBCE1F35A3D40ACAF3D2EDF993DA0AF223D27E1A0BD18978E3DC88BCF3B9269B73D397B443DF363E63C134BB83C624E9BBC493C92BD8EA6E3BC230A43BD08C75EBC2EBF87BD5FB7903C25E0D93C1431D33D96E6823D3F07E83D73E0A43BB59BED3D32C0D43D10AAB73DAB01DDBC39D1EB3D717AA4BB3002893DBC2E5D3C461C913B966E8ABD9F85DDBC99668D3D0A152B3DE5E0093D6629A43D3F39FBBC6045763D03C3723DB816AE3CAD5E65BDD2AC60BBBAE709BDFD1E31BB4AA3B33DB502793D97D63E3ECC9A143D20088E3D7ABBB5BDFF0D02BD865AF93C35EEC53C473F36BDBA79693DA2FC773B1241D33C4E49BC3C859896BDA1D8E7BCCD9B153C1EE20EBCB502FC3CE7C3CABD76413D3B9E936B3DCC64E9BCF5A9EC3D096D963CF535E83D9945CFBCC7DB06BED9F0D1BD033F08BE3EFCA3BD05044CBD288E693D574BE6BD56C076BDA7B9ACBD483831BBF3BA74BD2676D4BD1DAC053CAF08263C40A5A53C20CFA83C7BC00CBD22F5933D84BF173EE2A18A3C6735BE3B6E9982BD81E6623B929544BE1F53E93BF6FAEC3CA16CEE3DB10E04BE8358783D316910BE23873EBEA1D524BE50CF70BE62AD02BE32FC32BECB5101BC7B0F42BDBFD8F93C11883C3D907278BC8805F


The rest is similar hex values like the above.
```

**Also, please include a link to the saved model or GraphDef**

```
# Put link here or attach to the issue.
This is a basic MNIST model in keras format. Model summary is listed below.
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d (Conv2D)              (None, 4, 26, 26)         36        
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 4, 24, 24)         144       
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 4, 22, 22)         144       
_________________________________________________________________
flatten (Flatten)            (None, 1936)              0         
_________________________________________________________________
dense (Dense)                (None, 10)                19370     
=================================================================
Total params: 19,694
Trainable params: 19,694
Non-trainable params: 0
_________________________________________________________________

https://drive.google.com/file/d/12HM4mRhYnN-CZuqk1zEwRWkIyQr0RTUC/view?usp=sharing
```

**Failure details**
If the conversion is successful, but the generated model is wrong,
state what is wrong:

The converter prompts `tf.Conv2D` is not supported. But I think this op is written in your allowlist for sure. 


**Any other info / logs**
[error with tf 2.3.1.log](https://github.com/tensorflow/tensorflow/files/5611223/error.with.tf.2.3.1.log)

Running on tf-nightly build 2.5.0-dev20201128 throws an error as well, but the error message is different. I tried this in Google Colab.
```
AttributeError                            Traceback (most recent call last)
<ipython-input-3-ec82a6e4977e> in <module>()
     23 converter.inference_input_type = tf.int8  # or tf.uint8
     24 converter.inference_output_type = tf.int8  # or tf.uint8
---> 25 tflite_quant_model = converter.convert()
     26 
     27 open(""quantized.tflite"", ""wb"").write(tflite_quant_model)

4 frames
/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/lite.py in convert(self)
    893 
    894     return super(TFLiteKerasModelConverterV2,
--> 895                  self).convert(graph_def, input_tensors, output_tensors)
    896 
    897 

/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/lite.py in convert(self, graph_def, input_tensors, output_tensors)
    651     calibrate_and_quantize, flags = quant_mode.quantizer_flags()
    652     if calibrate_and_quantize:
--> 653       result = self._calibrate_quantize_model(result, **flags)
    654 
    655     flags_modify_model_io_type = quant_mode.flags_modify_model_io_type(

/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/lite.py in _calibrate_quantize_model(self, result, inference_input_type, inference_output_type, activations_type, allow_float)
    479       return calibrate_quantize.calibrate_and_quantize(
    480           self.representative_dataset.input_gen, inference_input_type,
--> 481           inference_output_type, allow_float, activations_type)
    482 
    483   def _is_unknown_shapes_allowed(self):

/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/optimize/calibrator.py in calibrate_and_quantize(self, dataset_gen, input_type, output_type, allow_float, activations_type, resize_input)
     95         initialized = True
     96         if resize_input:
---> 97           self._calibrator.Prepare([list(s.shape) for s in sample])
     98         else:
     99           self._calibrator.Prepare()

/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/optimize/calibrator.py in <listcomp>(.0)
     95         initialized = True
     96         if resize_input:
---> 97           self._calibrator.Prepare([list(s.shape) for s in sample])
     98         else:
     99           self._calibrator.Prepare()

AttributeError: 'function' object has no attribute 'shape'
```
"
45250,build from master branch with --config=v1 can not output tensorflow 1.x version,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No
- TensorFlow installed from (source or binary): source
- TensorFlow version: master ( git clone from source)
- Python version: 3.8.5
- Installed using virtualenv? pip? conda?: pip3
- Bazel version (if compiling from source): 3.1.0
- GCC/Compiler version (if compiling from source): 9.3.0
- CUDA/cuDNN version: 11.1, 8.0.5
- GPU model and memory: RTX 3090


**Describe the problem**
I tried to build tensorflow 1.x from source code with param`--config=v1`. But the output is always `tensorflow-2.5.0-xxx`.
So I wonder how to build tensorflow 1.x version from master branch of the source code? Is the `--cofing=v1` param not supposed to build tensorflow 1.x version? 

**Provide the exact sequence of commands / steps that you executed before running into the problem**
`bazel build --config=v1 --config=cuda //tensorflow/tools/pip_package:build_pip_package`


**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
45249,"Validation data generator yields 2 times, but should only 1","**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04
- TensorFlow installed from (source or binary): pip
- TensorFlow version (use command below): 2.3.1
- Python version: 3.8

**Describe the current behavior**
Train process yields validation_data more than I defined in `.fit` function in each epoch. I'm using `.fit` function with two generators for train and validation datasets, which length is the same. I defined learn process for 10 epochs, but after 5 I had warning about there is not more validation_data. You can see more details in colab link below.

**Describe the expected behavior**
Train process should yields `validation_data` only `validation_steps` times. 

**Standalone code to reproduce the issue**
https://colab.research.google.com/drive/1INO5UfPDr_7Jvx6xM4FVBYkGnLG6IFUf?usp=sharing

**Logs**
```
Epoch 1/10
train [0 1 2 3]
1/1 [==============================] - ETA: 0s - loss: 17.7931 - mae: 2.8934
val [4]
1/1 [==============================] - 0s 105ms/step - loss: 17.7931 - mae: 2.8934 - val_loss: 205.8619 - val_mae: 14.3479

Epoch 2/10
train [5 6 7 8]
1/1 [==============================] - ETA: 0s - loss: 1865.1838 - mae: 40.8180
val [9]
val [14]
1/1 [==============================] - 0s 37ms/step - loss: 1865.1838 - mae: 40.8180 - val_loss: 36154.7812 - val_mae: 190.1441

Epoch 3/10
train [10 11 12 13]
1/1 [==============================] - ETA: 0s - loss: 17199.1582 - mae: 128.6884
val [19]
val [24]
1/1 [==============================] - 0s 32ms/step - loss: 17199.1582 - mae: 128.6884 - val_loss: 320162.5000 - val_mae: 565.8290

Epoch 4/10
train [15 16 17 18]
1/1 [==============================] - ETA: 0s - loss: 72351.9141 - mae: 266.5040
val [29]
val [34]
1/1 [==============================] - 0s 40ms/step - loss: 72351.9141 - mae: 266.5040 - val_loss: 1302790.6250 - val_mae: 1141.3986

Epoch 5/10
train [20 21 22 23]
 1/1 [==============================] - ETA: 0s - loss: 208619.7188 - mae: 454.2613
val [39]
val [44]
1/1 [==============================] - 0s 36ms/step - loss: 208619.7188 - mae: 454.2613 - val_loss: 3674302.5000 - val_mae: 1916.8470

Epoch 6/10
train [25 26 27 28]
1/1 [==============================] - ETA: 0s - loss: 482259.9688 - mae: 691.9575
val [49]
WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 1 batches). You may need to use the repeat() function when building your dataset.
1/1 [==============================] - 0s 44ms/step - loss: 482259.9688 - mae: 691.9575

Epoch 7/10
train [30 31 32 33]
1/1 [==============================] - 0s 18ms/step - loss: 964487.8750 - mae: 979.5891

Epoch 8/10
train [35 36 37 38]
1/1 [==============================] - 0s 25ms/step - loss: 1741474.2500 - mae: 1317.1534

Epoch 9/10
train [40 41 42 43]
1/1 [==============================] - 0s 16ms/step - loss: 2914341.0000 - mae: 1704.6472

Epoch 10/10
train [45 46 47 48]
1/1 [==============================] - 0s 16ms/step - loss: 4599159.5000 - mae: 2142.0679
```"
45248,Fail to find the dnn implementation while using recurrent layers,"**System information**
- OS Platform and Distribution: Ubuntu 18.04 running in WSL2
- TensorFlow version): 2.3.1
- Python version: 3.6.9
- CUDA/cuDNN version: CUDA 10.1/ cuDNN 7.6.5.32
- GPU model and memory: RTX 2060 6GB

**Current behavior**
I want to train a model containing Keras LSTM layers, however the following error occurs:  

**Jupyter output:**
`UnknownError:    Fail to find the dnn implementation.
	 [[{{node CudnnRNN}}]]
	 [[sequential_2/lstm_1/PartitionedCall]] [Op:__inference_train_function_5270]`

**Console output:**
`OP_REQUIRES failed at cudnn_rnn_ops.cc:1510 : Unknown: Fail to find the dnn implementation.`


**Expected behavior**
I expect the code to run since I am able to run Conv2D layers wich are properly accelerated by the GPU.  
I have already tried multiple things such as using different Tensorflow/Cuda/cuDNN versions.
I also tried to enable the memory growth as described in #36508 but it did not work either.


**Standalone code to reproduce the issue**
The environment was set up by following the installation instructions (without installing the nvidia driver inside the VM as mentioned in the nvidia documentation ): https://www.tensorflow.org/install/gpu#install_cuda_with_apt

I was able to reproduce this issue by running the RNN tutorial available on the online Tensorflow documentation : https://www.tensorflow.org/guide/keras/rnn

I would appreciate any help to solve this issue.
"
45247,Unable to provide constant input tensors to keras functional API for TF2.0+,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux
- TensorFlow installed from (source or binary): pip
- TensorFlow version (use command below): 2.3.0
- Python version: 3.6
- CUDA/cuDNN version: 10.0

**Describe the current behavior**
Under eager execution, Keras cannot use an existing tensor as a constant input. It returns the following error:

> ValueError: You should not pass an EagerTensor to `Input`. For example, instead of creating an InputLayer, you should instantiate your model and directly call it on your input.

**Describe the expected behavior**
Keras should be able to wrap an optional existing tensor  into the Input layer, using `tf.keras.Input(tensor=existing_tensor)`


**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

```
import tensorflow as tf
from tensorflow.keras import layers
import numpy as np
const_np = np.random.rand(2,10,3)
const_tf = tf.convert_to_tensor(const_np, dtype=tf.float32)
const_k = tf.keras.Input(tensor=const_tf)
```

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

```
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
<ipython-input-1-ba2f0cbae65f> in <module>()
      4 const_np = np.random.rand(2,10,3)
      5 const_tf = tf.convert_to_tensor(const_np, dtype=tf.float32)
----> 6 const_k = tf.keras.Input(tensor=const_tf)

1 frames
/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/input_layer.py in Input(shape, batch_size, name, dtype, sparse, tensor, ragged, **kwargs)
    309     input_layer_config.update(
    310         {'batch_size': batch_size, 'input_shape': shape})
--> 311   input_layer = InputLayer(**input_layer_config)
    312 
    313   # Return tensor including `_keras_history`.

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/input_layer.py in __init__(self, input_shape, batch_size, dtype, input_tensor, sparse, name, ragged, **kwargs)
    171           raise_eager_tensor_error = True
    172       if raise_eager_tensor_error:
--> 173         raise ValueError('You should not pass an EagerTensor to `Input`. '
    174                          'For example, instead of creating an '
    175                          'InputLayer, you should instantiate your model and '

ValueError: You should not pass an EagerTensor to `Input`. For example, instead of creating an InputLayer, you should instantiate your model and directly call it on your input.
```
"
45245,Build for FMA AVX always shows cpu compatibility warnings,"**System information**
- OS: Linux Ubuntu 18.04
- TensorFlow installed from (source or binary): source
- TensorFlow version: commit `fab3f85`:
- Python version: Python 3.6.9
- Installed using virtualenv? pip? conda?: No
- Bazel version (if compiling from source): bazel 3.1.0
- GCC/Compiler version (if compiling from source): gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
- CUDA/cuDNN version: Cuda 11.1 cuDNN 8.0.5
- GPU model and memory: 7.5, 3.8Gb

**Describe the problem**
I have compiled tensorflow from source many times attempting to add support for FMA, AVX and AVX 2 and no matter how many times or different ways I try to add support for these instruction sets I always get the message: 
```
Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
```

**Provide the exact sequence of commands / steps that you executed before running into the problem**
Here is my bazelrc
```
build --action_env PYTHON_BIN_PATH=""/usr/bin/python3""
build --action_env PYTHON_LIB_PATH=""/usr/lib/python3/dist-packages""
build --python_path=""/usr/bin/python3""
build --config=xla
build --action_env CUDA_TOOLKIT_PATH=""/usr/local/cuda-11.1""
build --action_env TF_CUDA_COMPUTE_CAPABILITIES=""7.5""
build --action_env GCC_HOST_COMPILER_PATH=""/usr/bin/x86_64-linux-gnu-gcc-7""
build --config=cuda
build:opt --copt=-march=native
build:opt --copt=-Wno-sign-compare
build:opt --copt=-mavx
build:opt --copt=-mavx2
build:opt --copt=-mfma
build:opt --host_copt=-march=native
build:opt --define with_default_optimizations=true
test --flaky_test_attempts=3
test --test_size_filters=small,medium
test --test_env=LD_LIBRARY_PATH
test:v1 --test_tag_filters=-benchmark-test,-no_oss,-no_gpu,-oss_serial
test:v1 --build_tag_filters=-benchmark-test,-no_oss,-no_gpu
test:v2 --test_tag_filters=-benchmark-test,-no_oss,-no_gpu,-oss_serial,-v1only
test:v2 --build_tag_filters=-benchmark-test,-no_oss,-no_gpu,-v1only
build --action_env TF_CONFIGURE_IOS=""0""
```

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

<details>
<pre>
josh@cryptex00005:~/tensorflow$ bazel build --config=v2 --config=monolithic //tensorflow/tools/lib_package:libtensorflow
WARNING: The following configs were expanded more than once: [v2]. For repeatable flags, repeats are counted twice and may lead to unexpected behavior.
INFO: Options provided by the client:
  Inherited 'common' options: --isatty=1 --terminal_columns=265
INFO: Reading rc options for 'build' from /home/josh/tensorflow/.bazelrc:
  Inherited 'common' options: --experimental_repo_remote_exec
INFO: Reading rc options for 'build' from /home/josh/tensorflow/.bazelrc:
  'build' options: --apple_platform_type=macos --define framework_shared_object=true --define open_source_build=true --java_toolchain=//third_party/toolchains/java:tf_java_toolchain --host_java_toolchain=//third_party/toolchains/java:tf_java_toolchain --define=tensorflow_enable_mlir_generated_gpu_kernels=0 --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --noincompatible_prohibit_aapt1 --enable_platform_specific_config --config=short_logs --config=v2
INFO: Reading rc options for 'build' from /home/josh/tensorflow/.tf_configure.bazelrc:
  'build' options: --action_env PYTHON_BIN_PATH=/usr/bin/python3 --action_env PYTHON_LIB_PATH=/usr/lib/python3/dist-packages --python_path=/usr/bin/python3 --config=xla --action_env CUDA_TOOLKIT_PATH=/usr/local/cuda-11.1 --action_env TF_CUDA_COMPUTE_CAPABILITIES=7.5 --action_env GCC_HOST_COMPILER_PATH=/usr/bin/x86_64-linux-gnu-gcc-7 --config=cuda --action_env TF_CONFIGURE_IOS=0
INFO: Found applicable config definition build:short_logs in file /home/josh/tensorflow/.bazelrc: --output_filter=DONT_MATCH_ANYTHING
INFO: Found applicable config definition build:v2 in file /home/josh/tensorflow/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1
INFO: Found applicable config definition build:xla in file /home/josh/tensorflow/.bazelrc: --define=with_xla_support=true
INFO: Found applicable config definition build:cuda in file /home/josh/tensorflow/.bazelrc: --config=using_cuda --define=using_cuda_nvcc=true
INFO: Found applicable config definition build:using_cuda in file /home/josh/tensorflow/.bazelrc: --define=using_cuda=true --action_env TF_NEED_CUDA=1 --crosstool_top=@local_config_cuda//crosstool:toolchain --define=tensorflow_enable_mlir_generated_gpu_kernels=1
INFO: Found applicable config definition build:v2 in file /home/josh/tensorflow/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1
INFO: Found applicable config definition build:monolithic in file /home/josh/tensorflow/.bazelrc: --define framework_shared_object=false
INFO: Found applicable config definition build:linux in file /home/josh/tensorflow/.bazelrc: --copt=-w --host_copt=-w --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --define=PROTOBUF_INCLUDE_PATH=$(PREFIX)/include --cxxopt=-std=c++14 --host_cxxopt=-std=c++14 --config=dynamic_kernels
INFO: Found applicable config definition build:dynamic_kernels in file /home/josh/tensorflow/.bazelrc: --define=dynamic_loaded_kernels=true --copt=-DAUTOLOAD_DYNAMIC_KERNELS
DEBUG: /home/josh/.cache/bazel/_bazel_josh/bbb24127b68cff8e4647a298dd3f5a01/external/bazel_tools/tools/cpp/lib_cc_configure.bzl:118:5: 
Auto-Configuration Warning: 'TMP' environment variable is not set, using 'C:\Windows\Temp' as default
INFO: Analyzed target //tensorflow/tools/lib_package:libtensorflow (233 packages loaded, 22913 targets configured).
</pre>
</details>

Here is the resulting build: https://s3-us-west-2.amazonaws.com/bin.cryptexlabs.com/tensorflow/cuda-11.1_cudnn8.0.5_75_fma-avx-avx2.tar.gz"
45244,tflite was crashed randomly on Android 9 arm64 device.,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution: Android 9 arm64 device
- TensorFlow installed from: source
- TensorFlow version (use command below): v1.14.0
- GCC/Compiler version: android-ndk-r20

**Describe the current behavior**
Random crash

**Other info / logs**
```
11-25 19:26:28.025 22053 22146 E CRASH   : signal 4 (SIGILL), code 1 (ILL_ILLOPC), fault addr 0x70ef20b4e4 (*pc=0x4e8296d5)
11-25 19:26:28.025 22053 22146 E CRASH   :     x0  000000710159f888  x1  000000710159d000  x2  00000070ec7dc750  x3  00000070ec7dca50
11-25 19:26:28.025 22053 22146 E CRASH   :     x4  00000070ec7dc6d0  x5  0000000000000004  x6  0000000000000002  x7  00000070ec7de6b8
11-25 19:26:28.025 22053 22146 E CRASH   :     x8  0000000000000001  x9  0000000000000080  x10 0000000000000008  x11 0000000000000020
11-25 19:26:28.025 22053 22146 E CRASH   :     x12 0000000000000010  x13 000000710159fb08  x14 0000000000000001  x15 0000000000000040
11-25 19:26:28.025 22053 22146 E CRASH   :     x16 00000070ef370700  x17 00000070ef20b478  x18 0000000000000004  x19 0000000000000040
11-25 19:26:28.025 22053 22146 E CRASH   :     x20 0000000000000001  x21 0000000000000000  x22 0000000000000005  x23 0000000000000000
11-25 19:26:28.025 22053 22146 E CRASH   :     x24 0000000000000000  x25 000000000000000a  x26 000000000000000d  x27 0000000000000a00
11-25 19:26:28.025 22053 22146 E CRASH   :     x28 0000000000000001  x29 00000070ec7de4d0
11-25 19:26:28.025 22053 22146 E CRASH   :     sp  00000070ec7dc520  lr  00000070ef2082c8  pc  00000070ef20b4e4
11-25 19:26:28.025 22053 22146 E CRASH   : 
11-25 19:26:28.025 22053 22146 E CRASH   : backtrace:
11-25 19:26:28.025 22053 22146 E CRASH   :       #00 pc 00000000000c84e4  /data/app/fun.gostudy.android.phygital-QHoCDLpSJXY1hPYpBkyg_A==/lib/arm64/libtensorflowlite.so (tflite::optimized_ops::depthwise_conv::ProcessPerDepth<(tflite::DepthwiseConvImplementation)3>::Run(unsigned char const*, int const*, signed char*, int*, tflite::optimized_ops::depthwise_conv::DepthwiseConvDotProdParams const*)+108)
11-25 19:26:28.026 22053 22146 E CRASH   :       #01 pc 00000000000c52c4  /data/app/fun.gostudy.android.phygital-QHoCDLpSJXY1hPYpBkyg_A==/lib/arm64/libtensorflowlite.so (void tflite::optimized_ops::depthwise_conv::DepthwiseConvDotProduct3x3<(tflite::DepthwiseConvImplementation)3>(tflite::DepthwiseParams const&, tflite::RuntimeShape const&, unsigned char const*, tflite::RuntimeShape const&, unsigned char const*, tflite::RuntimeShape const&, int const*, tflite::RuntimeShape const&, unsigned char*)+2116)
11-25 19:26:28.026 22053 22146 E CRASH   :       #02 pc 00000000000d0b98  /data/app/fun.gostudy.android.phygital-QHoCDLpSJXY1hPYpBkyg_A==/lib/arm64/libtensorflowlite.so (tflite::optimized_ops::DepthwiseConvWorkerTask<unsigned char, int>::Run()+60)
11-25 19:26:28.026 22053 22146 E CRASH   :       #03 pc 00000000000d0ea8  /data/app/fun.gostudy.android.phygital-QHoCDLpSJXY1hPYpBkyg_A==/lib/arm64/libtensorflowlite.so (void gemmlowp::WorkersPool::Execute<tflite::optimized_ops::DepthwiseConvWorkerTask<unsigned char, int> >(int, tflite::optimized_ops::DepthwiseConvWorkerTask<unsigned char, int>*)+208)
11-25 19:26:28.026 22053 22146 E CRASH   :       #04 pc 00000000000c43ec  /data/app/fun.gostudy.android.phygital-QHoCDLpSJXY1hPYpBkyg_A==/lib/arm64/libtensorflowlite.so (void tflite::optimized_ops::DepthwiseConv<unsigned char, int>(tflite::DepthwiseParams const&, tflite::RuntimeShape const&, unsigned char const*, tflite::RuntimeShape const&, unsigned char const*, tflite::RuntimeShape const&, int const*, tflite::RuntimeShape const&, unsigned char*, tflite::CpuBackendContext*)+980)
11-25 19:26:28.027 22053 22146 E CRASH   :       #05 pc 00000000000d7cc4  /data/app/fun.gostudy.android.phygital-QHoCDLpSJXY1hPYpBkyg_A==/lib/arm64/libtensorflowlite.so (void tflite::ops::builtin::depthwise_conv::EvalQuantized<(tflite::ops::builtin::depthwise_conv::KernelType)2>(TfLiteContext*, TfLiteNode*, TfLiteDepthwiseConvParams*, tflite::ops::builtin::depthwise_conv::OpData*, TfLiteTensor const*, TfLiteTensor const*, TfLiteTensor const*, TfLiteTensor*)+556)
11-25 19:26:28.027 22053 22146 E CRASH   :       #06 pc 00000000000bd9e8  /data/app/fun.gostudy.android.phygital-QHoCDLpSJXY1hPYpBkyg_A==/lib/arm64/libtensorflowlite.so (TfLiteStatus tflite::ops::builtin::depthwise_conv::Eval<(tflite::ops::builtin::depthwise_conv::KernelType)2>(TfLiteContext*, TfLiteNode*)+136)
11-25 19:26:28.027 22053 22146 E CRASH   :       #07 pc 00000000001aae40  /data/app/fun.gostudy.android.phygital-QHoCDLpSJXY1hPYpBkyg_A==/lib/arm64/libtensorflowlite.so (tflite::Subgraph::Invoke()+504)
11-25 19:26:28.028 22053 22146 E CRASH   :       #08 pc 00000000001ae508  /data/app/fun.gostudy.android.phygital-QHoCDLpSJXY1hPYpBkyg_A==/lib/arm64/libtensorflowlite.so (tflite::Interpreter::Invoke()+32)
```
"
45243,tf.keras.applications.mobilenet_v3.preprocess_input documentation not according source code ,"
In https://www.tensorflow.org/api_docs/python/tf/keras/applications/mobilenet_v3/preprocess_input
[Said ](https://www.tensorflow.org/api_docs/python/tf/keras/applications/mobilenet_v3/preprocess_input#returns) that:

Preprocessed numpy.array or a tf.Tensor with type float32.
The inputs pixel values are scaled between -1 and 1, sample-wise.

However in source code in GitHub you find this:

@keras_export('keras.applications.mobilenet_v3.preprocess_input')
def preprocess_input(x, data_format=None):  # pylint: disable=unused-argument
  return x

And if you check it in a notebook you see that as source code state it is doing nothing. Do not scale and do not change dtype to float32 of the input.

"
45241, InvalidArgumentError:  assertion failed: [predictions must be <= 1] [Condition x <= y did not hold element-wise:] [x (model/dense_3/Relu:0) = ] [[0.179184318 1.62250423 0...]...] [y (metrics/auc/Cast_2/x:0) = ] [1] 	 [[{{node metrics/auc/assert_less_equal/Assert/AssertGuard/else/_11/Assert}}]] [Op:__inference_distributed_function_8508],"Updated version of issue https://github.com/tensorflow/tensorflow/issues/45219
I'm trying a new model involving word embedding for labels as well as Image classification in order to increase accuracy of the Image classifier. 
I'm using tensorflow Version 2.
Here is the code of the model and summary.
```
def build_mobilenet_embedd_model(img_input ):
    input_x = Input(shape = (img_input.shape[1:]), name='feature')
    base_model = MobileNet(include_top= False, input_shape=img_input.shape[1:], weights='imagenet')(input_x)
    avgpool_x = GlobalAveragePooling2D()(base_model)
    dense1_x = Dense(2048, activation='relu')(avgpool_x)
    batch1_x = BatchNormalization()(dense1_x)
    dropout1_x = Dropout(0.2)(batch1_x)
    dense2_x = Dense(512, activation='relu')(dropout1_x)
    batch2_x = BatchNormalization()(dense2_x)
    dropout2_x = Dropout(0.2)(batch2_x)
    predictions = Dense(len(all_labels), activation='relu')(dropout2_x)
    embedd_layer = Embedding(13, 100, weights=[embedding_matrix], trainable=False,name = ""embedding_1"")(predictions)
    flatten = Flatten(name=""flatten"")(embedd_layer)
    final_predictions = Dense(13, activation='relu')(flatten)
    model = keras.models.Model(inputs= input_x, outputs = final_predictions)
    model.compile(optimizer='adam', loss='binary_crossentropy', metrics= METRICS
    model.summary()
    return model
```
and here is the summary:-
```
Model: ""model_4""
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
feature (InputLayer)         [(None, 128, 128, 3)]     0         
_________________________________________________________________
mobilenet_1.00_128 (Model)   (None, 4, 4, 1024)        3228864   
_________________________________________________________________
global_average_pooling2d_5 ( (None, 1024)              0         
_________________________________________________________________
dense_16 (Dense)             (None, 2048)              2099200   
_________________________________________________________________
batch_normalization_10 (Batc (None, 2048)              8192      
_________________________________________________________________
dropout_10 (Dropout)         (None, 2048)              0         
_________________________________________________________________
dense_17 (Dense)             (None, 512)               1049088   
_________________________________________________________________
batch_normalization_11 (Batc (None, 512)               2048      
_________________________________________________________________
dropout_11 (Dropout)         (None, 512)               0         
_________________________________________________________________
dense_18 (Dense)             (None, 13)                6669      
_________________________________________________________________
embedding_1 (Embedding)      (None, 13, 100)           1300      
_________________________________________________________________
flatten (Flatten)            (None, 1300)              0         
_________________________________________________________________
dense_19 (Dense)             (None, 13)                16913     
=================================================================
Total params: 6,412,274
Trainable params: 6,383,966
Non-trainable params: 28,308
_________________________________________________________________
```
Adding `embedd_layer ` and `flatten layer` after the layer `prediction` resulted in this error to pop-up,
when I run the model fit I'll get this warning  & error message.
```
WARNING:tensorflow:From <ipython-input-23-65f5e4d4075d>:6: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
Please use Model.fit, which supports generators.
WARNING:tensorflow:sample_weight modes were coerced from
  ...
    to  
  ['...']
Train for 660 steps, validate on 1024 samples
Epoch 1/30
WARNING:tensorflow:Gradients do not exist for variables ['conv1/kernel:0', 'conv1_bn/gamma:0', 'conv1_bn/beta:0', 'conv_dw_1/depthwise_kernel:0', 'conv_dw_1_bn/gamma:0', 'conv_dw_1_bn/beta:0', 'conv_pw_1/kernel:0', 'conv_pw_1_bn/gamma:0', 'conv_pw_1_bn/beta:0', 'conv_dw_2/depthwise_kernel:0', 'conv_dw_2_bn/gamma:0', 'conv_dw_2_bn/beta:0', 'conv_pw_2/kernel:0', 'conv_pw_2_bn/gamma:0', 'conv_pw_2_bn/beta:0', 'conv_dw_3/depthwise_kernel:0', 'conv_dw_3_bn/gamma:0', 'conv_dw_3_bn/beta:0', 'conv_pw_3/kernel:0', 'conv_pw_3_bn/gamma:0', 'conv_pw_3_bn/beta:0', 'conv_dw_4/depthwise_kernel:0', 'conv_dw_4_bn/gamma:0', 'conv_dw_4_bn/beta:0', 'conv_pw_4/kernel:0', 'conv_pw_4_bn/gamma:0', 'conv_pw_4_bn/beta:0', 'conv_dw_5/depthwise_kernel:0', 'conv_dw_5_bn/gamma:0', 'conv_dw_5_bn/beta:0', 'conv_pw_5/kernel:0', 'conv_pw_5_bn/gamma:0', 'conv_pw_5_bn/beta:0', 'conv_dw_6/depthwise_kernel:0', 'conv_dw_6_bn/gamma:0', 'conv_dw_6_bn/beta:0', 'conv_pw_6/kernel:0', 'conv_pw_6_bn/gamma:0', 'conv_pw_6_bn/beta:0', 'conv_dw_7/depthwise_kernel:0', 'conv_dw_7_bn/gamma:0', 'conv_dw_7_bn/beta:0', 'conv_pw_7/kernel:0', 'conv_pw_7_bn/gamma:0', 'conv_pw_7_bn/beta:0', 'conv_dw_8/depthwise_kernel:0', 'conv_dw_8_bn/gamma:0', 'conv_dw_8_bn/beta:0', 'conv_pw_8/kernel:0', 'conv_pw_8_bn/gamma:0', 'conv_pw_8_bn/beta:0', 'conv_dw_9/depthwise_kernel:0', 'conv_dw_9_bn/gamma:0', 'conv_dw_9_bn/beta:0', 'conv_pw_9/kernel:0', 'conv_pw_9_bn/gamma:0', 'conv_pw_9_bn/beta:0', 'conv_dw_10/depthwise_kernel:0', 'conv_dw_10_bn/gamma:0', 'conv_dw_10_bn/beta:0', 'conv_pw_10/kernel:0', 'conv_pw_10_bn/gamma:0', 'conv_pw_10_bn/beta:0', 'conv_dw_11/depthwise_kernel:0', 'conv_dw_11_bn/gamma:0', 'conv_dw_11_bn/beta:0', 'conv_pw_11/kernel:0', 'conv_pw_11_bn/gamma:0', 'conv_pw_11_bn/beta:0', 'conv_dw_12/depthwise_kernel:0', 'conv_dw_12_bn/gamma:0', 'conv_dw_12_bn/beta:0', 'conv_pw_12/kernel:0', 'conv_pw_12_bn/gamma:0', 'conv_pw_12_bn/beta:0', 'conv_dw_13/depthwise_kernel:0', 'conv_dw_13_bn/gamma:0', 'conv_dw_13_bn/beta:0', 'conv_pw_13/kernel:0', 'conv_pw_13_bn/gamma:0', 'conv_pw_13_bn/beta:0', 'dense/kernel:0', 'dense/bias:0', 'batch_normalization/gamma:0', 'batch_normalization/beta:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'batch_normalization_1/gamma:0', 'batch_normalization_1/beta:0', 'dense_2/kernel:0', 'dense_2/bias:0'] when minimizing the loss.
WARNING:tensorflow:Gradients do not exist for variables ['conv1/kernel:0', 'conv1_bn/gamma:0', 'conv1_bn/beta:0', 'conv_dw_1/depthwise_kernel:0', 'conv_dw_1_bn/gamma:0', 'conv_dw_1_bn/beta:0', 'conv_pw_1/kernel:0', 'conv_pw_1_bn/gamma:0', 'conv_pw_1_bn/beta:0', 'conv_dw_2/depthwise_kernel:0', 'conv_dw_2_bn/gamma:0', 'conv_dw_2_bn/beta:0', 'conv_pw_2/kernel:0', 'conv_pw_2_bn/gamma:0', 'conv_pw_2_bn/beta:0', 'conv_dw_3/depthwise_kernel:0', 'conv_dw_3_bn/gamma:0', 'conv_dw_3_bn/beta:0', 'conv_pw_3/kernel:0', 'conv_pw_3_bn/gamma:0', 'conv_pw_3_bn/beta:0', 'conv_dw_4/depthwise_kernel:0', 'conv_dw_4_bn/gamma:0', 'conv_dw_4_bn/beta:0', 'conv_pw_4/kernel:0', 'conv_pw_4_bn/gamma:0', 'conv_pw_4_bn/beta:0', 'conv_dw_5/depthwise_kernel:0', 'conv_dw_5_bn/gamma:0', 'conv_dw_5_bn/beta:0', 'conv_pw_5/kernel:0', 'conv_pw_5_bn/gamma:0', 'conv_pw_5_bn/beta:0', 'conv_dw_6/depthwise_kernel:0', 'conv_dw_6_bn/gamma:0', 'conv_dw_6_bn/beta:0', 'conv_pw_6/kernel:0', 'conv_pw_6_bn/gamma:0', 'conv_pw_6_bn/beta:0', 'conv_dw_7/depthwise_kernel:0', 'conv_dw_7_bn/gamma:0', 'conv_dw_7_bn/beta:0', 'conv_pw_7/kernel:0', 'conv_pw_7_bn/gamma:0', 'conv_pw_7_bn/beta:0', 'conv_dw_8/depthwise_kernel:0', 'conv_dw_8_bn/gamma:0', 'conv_dw_8_bn/beta:0', 'conv_pw_8/kernel:0', 'conv_pw_8_bn/gamma:0', 'conv_pw_8_bn/beta:0', 'conv_dw_9/depthwise_kernel:0', 'conv_dw_9_bn/gamma:0', 'conv_dw_9_bn/beta:0', 'conv_pw_9/kernel:0', 'conv_pw_9_bn/gamma:0', 'conv_pw_9_bn/beta:0', 'conv_dw_10/depthwise_kernel:0', 'conv_dw_10_bn/gamma:0', 'conv_dw_10_bn/beta:0', 'conv_pw_10/kernel:0', 'conv_pw_10_bn/gamma:0', 'conv_pw_10_bn/beta:0', 'conv_dw_11/depthwise_kernel:0', 'conv_dw_11_bn/gamma:0', 'conv_dw_11_bn/beta:0', 'conv_pw_11/kernel:0', 'conv_pw_11_bn/gamma:0', 'conv_pw_11_bn/beta:0', 'conv_dw_12/depthwise_kernel:0', 'conv_dw_12_bn/gamma:0', 'conv_dw_12_bn/beta:0', 'conv_pw_12/kernel:0', 'conv_pw_12_bn/gamma:0', 'conv_pw_12_bn/beta:0', 'conv_dw_13/depthwise_kernel:0', 'conv_dw_13_bn/gamma:0', 'conv_dw_13_bn/beta:0', 'conv_pw_13/kernel:0', 'conv_pw_13_bn/gamma:0', 'conv_pw_13_bn/beta:0', 'dense/kernel:0', 'dense/bias:0', 'batch_normalization/gamma:0', 'batch_normalization/beta:0', 'dense_1/kernel:0', 'dense_1/bias:0', 'batch_normalization_1/gamma:0', 'batch_normalization_1/beta:0', 'dense_2/kernel:0', 'dense_2/bias:0'] when minimizing the loss.
  1/660 [..............................] - ETA: 8:05:51WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.
WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: lr
```
Error:
```
E:\anaconda\envs\gputest\lib\site-packages\tensorflow_core\python\util\deprecation.py in new_func(*args, **kwargs)
    322               'in a future version' if date is None else ('after %s' % date),
    323               instructions)
--> 324       return func(*args, **kwargs)
    325     return tf_decorator.make_decorator(
    326         func, new_func, 'deprecated',

E:\anaconda\envs\gputest\lib\site-packages\tensorflow_core\python\keras\engine\training.py in fit_generator(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)
   1304         use_multiprocessing=use_multiprocessing,
   1305         shuffle=shuffle,
-> 1306         initial_epoch=initial_epoch)
   1307 
   1308   @deprecation.deprecated(

E:\anaconda\envs\gputest\lib\site-packages\tensorflow_core\python\keras\engine\training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)
    817         max_queue_size=max_queue_size,
    818         workers=workers,
--> 819         use_multiprocessing=use_multiprocessing)
    820 
    821   def evaluate(self,

E:\anaconda\envs\gputest\lib\site-packages\tensorflow_core\python\keras\engine\training_v2.py in fit(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)
    340                 mode=ModeKeys.TRAIN,
    341                 training_context=training_context,
--> 342                 total_epochs=epochs)
    343             cbks.make_logs(model, epoch_logs, training_result, ModeKeys.TRAIN)
    344 

E:\anaconda\envs\gputest\lib\site-packages\tensorflow_core\python\keras\engine\training_v2.py in run_one_epoch(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)
    126         step=step, mode=mode, size=current_batch_size) as batch_logs:
    127       try:
--> 128         batch_outs = execution_function(iterator)
    129       except (StopIteration, errors.OutOfRangeError):
    130         # TODO(kaftan): File bug about tf function and errors.OutOfRangeError?

E:\anaconda\envs\gputest\lib\site-packages\tensorflow_core\python\keras\engine\training_v2_utils.py in execution_function(input_fn)
     96     # `numpy` translates Tensors to values in Eager mode.
     97     return nest.map_structure(_non_none_constant_value,
---> 98                               distributed_function(input_fn))
     99 
    100   return execution_function

E:\anaconda\envs\gputest\lib\site-packages\tensorflow_core\python\eager\def_function.py in __call__(self, *args, **kwds)
    566         xla_context.Exit()
    567     else:
--> 568       result = self._call(*args, **kwds)
    569 
    570     if tracing_count == self._get_tracing_count():

E:\anaconda\envs\gputest\lib\site-packages\tensorflow_core\python\eager\def_function.py in _call(self, *args, **kwds)
    630         # Lifting succeeded, so variables are initialized and we can run the
    631         # stateless function.
--> 632         return self._stateless_fn(*args, **kwds)
    633     else:
    634       canon_args, canon_kwds = \

E:\anaconda\envs\gputest\lib\site-packages\tensorflow_core\python\eager\function.py in __call__(self, *args, **kwargs)
   2361     with self._lock:
   2362       graph_function, args, kwargs = self._maybe_define_function(args, kwargs)
-> 2363     return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access
   2364 
   2365   @property

E:\anaconda\envs\gputest\lib\site-packages\tensorflow_core\python\eager\function.py in _filtered_call(self, args, kwargs)
   1609          if isinstance(t, (ops.Tensor,
   1610                            resource_variable_ops.BaseResourceVariable))),
-> 1611         self.captured_inputs)
   1612 
   1613   def _call_flat(self, args, captured_inputs, cancellation_manager=None):

E:\anaconda\envs\gputest\lib\site-packages\tensorflow_core\python\eager\function.py in _call_flat(self, args, captured_inputs, cancellation_manager)
   1690       # No tape is watching; skip to running the function.
   1691       return self._build_call_outputs(self._inference_function.call(
-> 1692           ctx, args, cancellation_manager=cancellation_manager))
   1693     forward_backward = self._select_forward_and_backward_functions(
   1694         args,

E:\anaconda\envs\gputest\lib\site-packages\tensorflow_core\python\eager\function.py in call(self, ctx, args, cancellation_manager)
    543               inputs=args,
    544               attrs=(""executor_type"", executor_type, ""config_proto"", config),
--> 545               ctx=ctx)
    546         else:
    547           outputs = execute.execute_with_cancellation(

E:\anaconda\envs\gputest\lib\site-packages\tensorflow_core\python\eager\execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)
     65     else:
     66       message = e.message
---> 67     six.raise_from(core._status_to_exception(e.code, message), None)
     68   except TypeError as e:
     69     keras_symbolic_tensors = [

E:\anaconda\envs\gputest\lib\site-packages\six.py in raise_from(value, from_value)

InvalidArgumentError:  assertion failed: [predictions must be <= 1] [Condition x <= y did not hold element-wise:] [x (model/dense_3/Relu:0) = ] [[0.179184318 1.62250423 0...]...] [y (metrics/auc/Cast_2/x:0) = ] [1]
	 [[{{node metrics/auc/assert_less_equal/Assert/AssertGuard/else/_11/Assert}}]] [Op:__inference_distributed_function_8508]

Function call stack:
distributed_function
```"
45240,"InvalidArgumentError: Input to DecodeRaw has length 1080022 that is not a multiple of 4, the size of int32 [Op:DecodeRaw]","<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): win 10 x64
- TensorFlow installed from (source or binary): pip
- TensorFlow version (use command below): 2.4.0rc3
- Python version: 3.8
- CUDA/cuDNN version: 11, 8.0.2
- GPU model and memory: RTX  3080 10 GB


**Code:**
```
import tensorflow as tf # version = 2.4.0rc3
from tensorflow.train import BytesList, FloatList, Int64List
from tensorflow.train import Feature, Features, Example

im = tf.random.uniform((300, 300, 3), minval=0, maxval=256, dtype=tf.int32)
mask_1 = tf.random.uniform((300, 300, 3), minval=0, maxval=2, dtype=tf.int32)

if1 = Feature(bytes_list = BytesList(value = [tf.io.serialize_tensor(im).numpy()]))
mf1 = Feature(bytes_list = BytesList(value = [tf.io.serialize_tensor(mask_1).numpy()]))
sf1 = Feature(bytes_list = BytesList(value = [""eisp12ie"".encode()]))

data_example = Example(features = Features(feature = {""image"": if1, ""mask"":mf1, ""sample_id"": sf1}))

with tf.io.TFRecordWriter(""data_example_1.tfrecord"") as f:
    f.write(data_example.SerializeToString())

feature_description = {
    ""image"" : tf.io.FixedLenFeature([], tf.string),
    ""mask"" : tf.io.FixedLenFeature([], tf.string),
    ""sample_id"" : tf.io.FixedLenFeature([], tf.string)
}

for serialized_example in tf.data.TFRecordDataset([""data_example_1.tfrecord""]):
    parsed_example = tf.io.parse_single_example(serialized_example,
                                                feature_description)

tf.io.decode_raw(parsed_example[""image""], out_type = tf.int32)
```

**Error:**
```
---------------------------------------------------------------------------
InvalidArgumentError                      Traceback (most recent call last)
<ipython-input-81-1950f51902b7> in <module>
----> 1 tf.io.decode_raw(parsed_example[""image""], out_type = tf.int32)

~\anaconda3\envs\hk2\lib\site-packages\tensorflow\python\util\dispatch.py in wrapper(*args, **kwargs)
    199     """"""Call target, and fall back on dispatchers if there is a TypeError.""""""
    200     try:
--> 201       return target(*args, **kwargs)
    202     except (TypeError, ValueError):
    203       # Note: convert_to_eager_tensor currently raises a ValueError, not a

~\anaconda3\envs\hk2\lib\site-packages\tensorflow\python\ops\parsing_ops.py in decode_raw(input_bytes, out_type, little_endian, fixed_length, name)
    881         name=name)
    882   else:
--> 883     return gen_parsing_ops.decode_raw(
    884         input_bytes, out_type, little_endian=little_endian, name=name)
    885 

~\anaconda3\envs\hk2\lib\site-packages\tensorflow\python\ops\gen_parsing_ops.py in decode_raw(bytes, out_type, little_endian, name)
    416       return _result
    417     except _core._NotOkStatusException as e:
--> 418       _ops.raise_from_not_ok_status(e, name)
    419     except _core._FallbackException:
    420       pass

~\anaconda3\envs\hk2\lib\site-packages\tensorflow\python\framework\ops.py in raise_from_not_ok_status(e, name)
   6860   message = e.message + ("" name: "" + name if name is not None else """")
   6861   # pylint: disable=protected-access
-> 6862   six.raise_from(core._status_to_exception(e.code, message), None)
   6863   # pylint: enable=protected-access
   6864 

~\anaconda3\envs\hk2\lib\site-packages\six.py in raise_from(value, from_value)

InvalidArgumentError: Input to DecodeRaw has length 1080022 that is not a multiple of 4, the size of int32 [Op:DecodeRaw]
```



I set the dtype of im variable to tf.int32, and decode_raw with dtype = tf.int32.
But it raised an error.
When i set the out_type = tf.uint8, it was okay."
45239,tf.image.extract_patches argument description,"https://www.tensorflow.org/api_docs/python/tf/image/extract_patches

There is only one argument description for this function.

Maybe typo? some tags like `<tr>` are in the description."
45238,Resource exhausted: MemoryError: Unable to allocate,"For similar questions see: #38414 

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): YES
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- TensorFlow installed from (source or binary): `pip install tensorflow-gpu==2.4.0rc3`
- TensorFlow version (use command below): v2.4.0-rc2-20-g68f236364c 2.4.0-rc3
- Python version: 3.7.9
- CUDA/cuDNN version: CUDA 11.1 
- GPU model and memory: GeForce RTX 3090 24GiB

**Describe the current behavior**

An error occurs when training to the second epoch, `MemoryError: Unable to allocate 184. MiB for an array with shape (64, 26, 26, 3, 371) and data type float32`
When the problem occurred, I had 70GB of RAM and 5GB of video memory left on my system. But ""Unable to allocate 184. MiB"".
To hide this problem, simply reduce frozen_batch_size from 64 to 32, i.e., reduce the batch size.

**Describe the expected behavior**

There should be no errors.

**Standalone code to reproduce the issue**
For code and data, please see: https://github.com/liasece/tf-38414

**Other info / logs** 

15/15 [==============================] - ETA: 0s - loss: 7711.74822020-11-28 09:40:12.434912: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:592] layout failed: Invalid argument: Subshape must have computed start >= end since stride is negative, but is 0 and 2 (computed from start 0 and end 9223372036854775807 over shape with rank 2 and stride-1)
2020-11-28 09:40:12.449082: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:592] remapper failed: Invalid argument: Subshape must have computed start >= end since stride is negative, but is 0 and 2 (computed from start 0 and end 9223372036854775807 over shape with rank 2 and stride-1)
2020-11-28 09:40:12.582863: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:592] remapper failed: Invalid argument: Subshape must have computed start >= end since stride is negative, but is 0 and 2 (computed from start 0 and end 9223372036854775807 over shape with rank 2 and stride-1)
2020-11-28 09:40:14.685870: W tensorflow/core/framework/op_kernel.cc:1763] OP_REQUIRES failed at cast_op.cc:109 : Resource exhausted: OOM when allocating tensor with shape[1,512,647,3] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu
2020-11-28 09:40:14.686045: W tensorflow/core/framework/op_kernel.cc:1763] OP_REQUIRES failed at image_resizer_state.h:142 : Resource exhausted: OOM when allocating tensor with shape[1,416,416,3] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu
2020-11-28 09:40:14.686110: W tensorflow/core/framework/op_kernel.cc:1763] OP_REQUIRES failed at image_resizer_state.h:142 : Resource exhausted: OOM when allocating tensor with shape[1,416,416,3] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu
2020-11-28 09:40:14.686801: W tensorflow/core/framework/op_kernel.cc:1763] OP_REQUIRES failed at image_resizer_state.h:142 : Resource exhausted: OOM when allocating tensor with shape[1,416,416,3] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu
2020-11-28 09:40:14.687007: W tensorflow/core/framework/op_kernel.cc:1763] OP_REQUIRES failed at cast_op.cc:109 : Resource exhausted: OOM when allocating tensor with shape[1,512,826,3] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu
2020-11-28 09:40:14.686816: W tensorflow/core/framework/op_kernel.cc:1763] OP_REQUIRES failed at image_resizer_state.h:142 : Resource exhausted: OOM when allocating tensor with shape[1,416,416,3] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu
2020-11-28 09:40:14.687972: W tensorflow/core/framework/op_kernel.cc:1763] OP_REQUIRES failed at cast_op.cc:109 : Resource exhausted: OOM when allocating tensor with shape[1,769,512,3] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu
2020-11-28 09:40:14.689583: W tensorflow/core/framework/op_kernel.cc:1763] OP_REQUIRES failed at cast_op.cc:109 : Resource exhausted: OOM when allocating tensor with shape[1,768,512,3] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu
2020-11-28 09:40:14.689721: W tensorflow/core/framework/op_kernel.cc:1763] OP_REQUIRES failed at cast_op.cc:109 : Resource exhausted: OOM when allocating tensor with shape[1,512,678,3] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu
2020-11-28 09:40:14.690045: W tensorflow/core/framework/op_kernel.cc:1763] OP_REQUIRES failed at cast_op.cc:109 : Resource exhausted: OOM when allocating tensor with shape[1,512,768,3] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu
2020-11-28 09:40:14.690171: W tensorflow/core/framework/op_kernel.cc:1763] OP_REQUIRES failed at cast_op.cc:109 : Resource exhausted: OOM when allocating tensor with shape[1,512,683,3] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu
2020-11-28 09:40:14.772685: W tensorflow/core/framework/op_kernel.cc:1763] OP_REQUIRES failed at cast_op.cc:109 : Resource exhausted: OOM when allocating tensor with shape[1,512,770,3] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu
2020-11-28 09:40:14.775723: W tensorflow/core/framework/op_kernel.cc:1763] OP_REQUIRES failed at cast_op.cc:109 : Resource exhausted: OOM when allocating tensor with shape[1,640,640,3] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu
2020-11-28 09:40:14.776161: W tensorflow/core/framework/op_kernel.cc:1763] OP_REQUIRES failed at image_resizer_state.h:142 : Resource exhausted: OOM when allocating tensor with shape[1,416,416,3] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu
2020-11-28 09:40:14.777899: W tensorflow/core/framework/op_kernel.cc:1763] OP_REQUIRES failed at cast_op.cc:109 : Resource exhausted: OOM when allocating tensor with shape[1,512,776,3] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu
2020-11-28 09:40:14.782664: W tensorflow/core/framework/op_kernel.cc:1763] OP_REQUIRES failed at cast_op.cc:109 : Resource exhausted: OOM when allocating tensor with shape[1,512,683,3] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu
2020-11-28 09:40:14.791474: W tensorflow/core/framework/op_kernel.cc:1763] OP_REQUIRES failed at cast_op.cc:109 : Resource exhausted: OOM when allocating tensor with shape[1,512,932,3] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu
2020-11-28 09:40:14.791955: W tensorflow/core/framework/op_kernel.cc:1763] OP_REQUIRES failed at image_resizer_state.h:142 : Resource exhausted: OOM when allocating tensor with shape[1,416,416,3] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu
2020-11-28 09:40:14.792808: W tensorflow/core/framework/op_kernel.cc:1763] OP_REQUIRES failed at image_resizer_state.h:142 : Resource exhausted: OOM when allocating tensor with shape[1,416,416,3] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu
2020-11-28 09:40:14.793188: W tensorflow/core/framework/op_kernel.cc:1763] OP_REQUIRES failed at cast_op.cc:109 : Resource exhausted: OOM when allocating tensor with shape[1,559,512,3] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu
2020-11-28 09:40:14.793469: W tensorflow/core/framework/op_kernel.cc:1763] OP_REQUIRES failed at cast_op.cc:109 : Resource exhausted: OOM when allocating tensor with shape[1,640,494,3] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu
2020-11-28 09:40:14.793868: W tensorflow/core/framework/op_kernel.cc:1763] OP_REQUIRES failed at image_resizer_state.h:142 : Resource exhausted: OOM when allocating tensor with shape[1,416,416,3] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu
2020-11-28 09:40:14.816077: W tensorflow/core/framework/op_kernel.cc:1751] Resource exhausted: MemoryError: Unable to allocate 184. MiB for an array with shape (64, 26, 26, 3, 371) and data type float32
Traceback (most recent call last):

  File ""R:\ProgramData\Anaconda3\envs\ml\lib\site-packages\tensorflow\python\ops\script_ops.py"", line 247, in __call__
    return func(device, token, args)

  File ""R:\ProgramData\Anaconda3\envs\ml\lib\site-packages\tensorflow\python\ops\script_ops.py"", line 135, in __call__
    ret = self._func(*args)

  File ""R:\ProgramData\Anaconda3\envs\ml\lib\site-packages\tensorflow\python\autograph\impl\api.py"", line 620, in wrapper
    return func(*args, **kwargs)

  File ""R:\ml\bug-test\xyolo\yolo3\utils.py"", line 358, in preprocess_true_boxes_xyolo
    dtype='float32') for l in range(num_layers)]

  File ""R:\ml\bug-test\xyolo\yolo3\utils.py"", line 358, in <listcomp>
    dtype='float32') for l in range(num_layers)]

MemoryError: Unable to allocate 184. MiB for an array with shape (64, 26, 26, 3, 371) and data type float32"
45237,Enabling XNNPACK changes the output.,"**System information**
- OS Platform and Distribution: Android
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: All android
- TensorFlow installed from (source or binary): Binary
- TensorFlow version (use command below): v2.3
- Python version: N/A
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A

**Describe the current behavior**
Running a computer vision model for emotion detection. The output is as expected when XNN is disabled but if I enable **tfliteOptions.setUseXNNPACK(true)** then the output is incorrect and totally different.

**Describe the expected behavior**
Output should be same for both XNN enabled and non-XNN option.

I have attached inference class files and model files below.

[ClassFiles.zip](https://github.com/tensorflow/tensorflow/files/5609851/Archive.zip)
[emotion_fp16t.tflite.zip](https://github.com/tensorflow/tensorflow/files/5609852/emotion_fp16t.tflite.zip)
"
45236,WARNING: function Model.make_predict_function.<locals>.predict_function,"I'm facing the following warning message in `tf 2.3` in my local machine. This error probably doesn't impact on the model performance (or do). 

> WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002424DCD6678> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has an experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.

The issue is, I can't reproduce it in **Colab** or **Kaggle** either with the same version of tensorflow `tf 2.3`. What makes it prevent to show this warning message logs on colab or kaggle? I tried to disable the warning on my local machine but didn't work. Below is the reproducible code. In short, I've tried to train a subclassed model and saved a few checkpoints, and ended up with inference iteratively. This is actually a mimic version of my original code. 

```python
import tensorflow as tf 
import numpy as np
from glob import glob
import gc

class Classifier(tf.keras.Model):
    def __init__(self, dim):
        super(Classifier, self).__init__()
        # define all layers in init
        # Layer of Block 1
        self.Base  = tf.keras.layers.Conv2D(32, 3, strides=2, activation=""relu"")

        self.GAP   = tf.keras.layers.GlobalAveragePooling2D()
        self.OUT   = tf.keras.layers.Dense(10, activation='softmax')
    
    def call(self, input_tensor, training=False):
        x  = self.Base(input_tensor)
        x  = self.GAP(x)
        return self.OUT(x)

# train set / data
(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()
x_train = np.expand_dims(x_train, axis=-1)
x_train = np.repeat(x_train, 3, axis=-1)
x_train = x_train.astype('float32') / 255
# train set / target 
y_train = tf.keras.utils.to_categorical(y_train, num_classes=10)

# compile 
print('Model Sub-Classing API')
sub_classing_model = Classifier((28,28,3))
sub_classing_model.compile(loss = tf.keras.losses.CategoricalCrossentropy(),
              metrics = tf.keras.metrics.CategoricalAccuracy(),
              optimizer = tf.keras.optimizers.Adam())
# fit 
sub_classing_model.fit(x_train, y_train,
         batch_size=128, epochs=1);

# few checkpoints
sub_classing_model.save_weights('sub1.h5')
sub_classing_model.save_weights('sub2.h5')
sub_classing_model.save_weights('sub3.h5')

for i in sorted(glob('./sub*.h5')):
    sub_classing_model = Classifier((28,28,3))
    sub_classing_model.build((None, *(28,28,3)))
    sub_classing_model.load_weights(i)
    z = sub_classing_model.predict(x_train) # <------ Perhaps something makes it happen 
    del sub_classing_model
    gc.collect()
```"
45235,[TF-1.14] Batch Cholesky Decomposition No Parallelism ? ,"Hi, I am profiling the batch Cholesky decompositions of tensorflow. 

**System information**
- OS Platform and Distribution: Linux Ubuntu 18.04.4 LTS (Bionic Beaver)
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 1.14.0
- Python version: 3.6.7
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: cuda-10.0; cudnn-10.0-v7.6.3.30
- GPU model and memory: Tesla P100-PCIE-12GB

I noticed that there seems no parallelism speedups for the batch operations. The running code is as in the following. When **B=1**, the printing time is **0.036327**, when **B=10**, the printing time is **0.2908551**. It seems there are basically no parallelisms for the batch operations. Is there a way to fix this issue?

```
import time
import tensorflow as tf

B, N, N = 1, 1024, 1024

a = tf.random_normal(shape=[B, N, N], dtype=tf.float64)
a = tf.matmul(a, a, transpose_b=True) + 1e-8 * tf.eye(N, dtype=a.dtype)
b = tf.linalg.cholesky(a)

sess = tf.Session(config=tf.ConfigProto(intra_op_parallelism_threads=10,
                                 inter_op_parallelism_threads=10))

for _ in range(20):
    sess.run(b)

start = time.time()
for _ in range(21, 30):
    sess.run(b)
print(time.time() - start)
```"
45234,[TF 2.3] Hessian of vector field in eager mode,"**System information**
- TensorFlow version: 2.3.0

**Describe the feature and the current behavior/state.**
Calculate hessians in eager mode.

**Will this change the current api? How?**
There should be `tf.batch_hessian()`, or something similar for eager mode; `tf.hessians()` does not work in eager mode.

**Additional info**
I am trying to compute the hessian of an embedding. Currently calling `tf.batch_jacobian()` twice, but this results in a tensor filled with 0s. 

**Code to reproduce issue.**
```python
  with tf.GradientTape(persistent=True) as tape:
    tape.watch(x)
    y = model(x)
  grads = tape.batch_jacobian(y, x)
  hessian = tape.batch_jacobian(grads, x)
  hessian.numpy().any() > 0

Output: False

```"
45233,Trying to deploy hello_world on KW41Z (M0) device,"@tensorflow/micro

**System information**
- Host OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Linux Ubuntu 16.04
- TensorFlow installed from (source or binary): `pip install tensorflow`
- Tensorflow version (commit SHA if source): 2.1.0 (py2.7) 2.3.1 (py3.7)
- Target platform (e.g. Arm Mbed OS, Arduino Nano 33 etc.): mbed

- gcc-arm-none-eabi v9.3.1
- mbed-cli v1.10.5

**Describe the problem**

Trying to deploy the hello_world example project to the [KW41Z](https://os.mbed.com/platforms/FRDM-KW41Z/) device using mbed and cannot get the project to compile for various reasons.

I have a hunch that mbed is not configured correctly, but I'm unsure how to fix the issues properly. I'll continue working on this but any advice is appreciated!

**Please provide the exact sequence of commands/steps when you ran into the problem**
Under Python 2.7 as recommended, but I also tried under Python 3.7 with similar results.

```
# setup env
conda create -n tflm-2.7 ""python=2.7""
conda activate tflm-2.7
pip install tensorflow mbed-cli

# setup project
make -f tensorflow/lite/micro/tools/make/Makefile TARGET_ARCH=cortex-m0plus TARGET=mbed TAGS=""CMSIS"" generate_hello_world_mbed_project
cd tensorflow/lite/micro/tools/make/gen/mbed_cortex-m0plus/prj/hello_world/mbed
mbed config root .
mbed deploy

# Note all the json files have -std=gnu++14 so I omitted the 98 -> 11 update
mbed compile -m KW41Z -t GCC_ARM -v
```
(partial) output:
```
[Fatal Error] NanostackRfPhyKw41z.cpp@17,10: common_functions.h: No such file or directory 
[DEBUG] Return: 1 
[DEBUG] Output: ./mbed-os/features/nanostack/targets/TARGET_NXP/TARGET_KW41Z/NanostackRfPhyKw41z.cpp:17:10: fatal error: common_functions.h: No such file or directory 
[DEBUG] Output:    17 | #include ""common_functions.h"" 
[DEBUG] Output:       |          ^~~~~~~~~~~~~~~~~~~~ 
[DEBUG] Output: compilation terminated. 
Traceback (most recent call last): 
  File ""/home/ben/git/tensorflow/tensorflow/lite/micro/tools/make/gen/mbed_cortex-m0plus/prj/hello_world/mbed/mbed-os/tools/make.py"", line 78, in wrapped_build_project 
    *args, **kwargs 
  File ""/home/ben/git/tensorflow/tensorflow/lite/micro/tools/make/gen/mbed_cortex-m0plus/prj/hello_world/mbed/mbed-os/tools/build_api.py"", line 607, in build_project 
    objects = toolchain.compile_sources(resources, sorted(resources.get_file_paths(FileType.INC_DIR))) 
  File ""/home/ben/git/tensorflow/tensorflow/lite/micro/tools/make/gen/mbed_cortex-m0plus/prj/hello_world/mbed/mbed-os/tools/toolchains/mbed_toolchain.py"", line 418, in compile_sources 
    return self._compile_sources(resources, inc_dirs=inc_dirs) 
  File ""/home/ben/git/tensorflow/tensorflow/lite/micro/tools/make/gen/mbed_cortex-m0plus/prj/hello_world/mbed/mbed-os/tools/toolchains/mbed_toolchain.py"", line 495, in _compile_sources 
    return self.compile_queue(queue, objects) 
  File ""/home/ben/git/tensorflow/tensorflow/lite/micro/tools/make/gen/mbed_cortex-m0plus/prj/hello_world/mbed/mbed-os/tools/toolchains/mbed_toolchain.py"", line 566, in compile_queue 
    raise ToolException(err) 
ToolException: ./mbed-os/features/nanostack/targets/TARGET_NXP/TARGET_KW41Z/NanostackRfPhyKw41z.cpp:17:10: fatal error: common_functions.h: No such file or directory 
   17 | #include ""common_functions.h"" 
      |          ^~~~~~~~~~~~~~~~~~~~ 
compilation terminated. 
```
I located this file: `find . -name ""common_functions.h""` and tried again:
```
mbed compile -m KW41Z -t GCC_ARM -v \
  --source ./mbed-os/features/frameworks/nanostack-libservice/mbed-client-libservice
```
(partial) output:
```
Could not compile for KW41Z: No Linker Script found 
```
I located the KW41Z linker script: `find . -name ""*KW41Z*.ld""`
```
mbed compile -m KW41Z -t GCC_ARM -v \
  --source ./mbed-os/features/frameworks/nanostack-libservice/mbed-client-libservice \
  --source ./mbed-os/targets/TARGET_Freescale/TARGET_MCUXpresso_MCUS/TARGET_KW41Z/device/TOOLCHAIN_GCC_ARM 
```
(partial) output:
```
[DEBUG] Errors: /usr/bin/../lib/gcc/arm-none-eabi/9.3.1/../../../../arm-none-eabi/bin/ld: BUILD/KW41Z/GCC_ARM/mbed-os/targets/TARGET_Freescale/TARGET_MCUXpresso_MCUS/TARGET_KW41Z/device/TOOLCHAIN_GCC_ARM/startup_MKW41Z4.o: in function `Reset_Handler': 
[DEBUG] Errors: /home/ben/git/tensorflow/tensorflow/lite/micro/tools/make/gen/mbed_cortex-m0plus/prj/hello_world/mbed/./mbed-os/targets/TARGET_Freescale/TARGET_MCUXpresso_MCUS/TARGET_KW41Z/device/TOOLCHAIN_GCC_ARM/startup_MKW41Z4.S:124: undefined reference to `SystemInit' 
[DEBUG] Errors: /usr/bin/../lib/gcc/arm-none-eabi/9.3.1/../../../../arm-none-eabi/bin/ld: /usr/bin/../lib/gcc/arm-none-eabi/9.3.1/../../../../arm-none-eabi/lib/thumb/v6-m/nofp/crt0.o: in function `_mainCRTStartup': 
[DEBUG] Errors: (.text+0x56): undefined reference to `__wrap_main' 
[DEBUG] Errors: /usr/bin/../lib/gcc/arm-none-eabi/9.3.1/../../../../arm-none-eabi/bin/ld: (.text+0x5a): undefined reference to `__wrap_exit' 
[DEBUG] Errors: collect2: error: ld returned 1 exit status 
Traceback (most recent call last): 
  File ""/home/ben/git/tensorflow/tensorflow/lite/micro/tools/make/gen/mbed_cortex-m0plus/prj/hello_world/mbed/mbed-os/tools/make.py"", line 78, in wrapped_build_project 
    *args, **kwargs 
  File ""/home/ben/git/tensorflow/tensorflow/lite/micro/tools/make/gen/mbed_cortex-m0plus/prj/hello_world/mbed/mbed-os/tools/build_api.py"", line 610, in build_project 
    res = toolchain.link_program(resources, build_path, name) 
  File ""/home/ben/git/tensorflow/tensorflow/lite/micro/tools/make/gen/mbed_cortex-m0plus/prj/hello_world/mbed/mbed-os/tools/toolchains/mbed_toolchain.py"", line 778, in link_program 
    self.link(elf, objects, libraries, lib_dirs, linker_script) 
  File ""/home/ben/git/tensorflow/tensorflow/lite/micro/tools/make/gen/mbed_cortex-m0plus/prj/hello_world/mbed/mbed-os/tools/toolchains/gcc.py"", line 357, in link 
    self.default_cmd(cmd) 
  File ""/home/ben/git/tensorflow/tensorflow/lite/micro/tools/make/gen/mbed_cortex-m0plus/prj/hello_world/mbed/mbed-os/tools/toolchains/mbed_toolchain.py"", line 830, in default_cmd 
    raise ToolException(stderr) 
ToolException: /usr/bin/../lib/gcc/arm-none-eabi/9.3.1/../../../../arm-none-eabi/bin/ld: BUILD/KW41Z/GCC_ARM/mbed-os/targets/TARGET_Freescale/TARGET_MCUXpresso_MCUS/TARGET_KW41Z/device/TOOLCHAIN_GCC_ARM/startup_MKW41Z4.o: in function `Reset_Handler': 
/home/ben/git/tensorflow/tensorflow/lite/micro/tools/make/gen/mbed_cortex-m0plus/prj/hello_world/mbed/./mbed-os/targets/TARGET_Freescale/TARGET_MCUXpresso_MCUS/TARGET_KW41Z/device/TOOLCHAIN_GCC_ARM/startup_MKW41Z4.S:124: undefined reference to `SystemInit' 
/usr/bin/../lib/gcc/arm-none-eabi/9.3.1/../../../../arm-none-eabi/bin/ld: /usr/bin/../lib/gcc/arm-none-eabi/9.3.1/../../../../arm-none-eabi/lib/thumb/v6-m/nofp/crt0.o: in function `_mainCRTStartup': 
(.text+0x56): undefined reference to `__wrap_main' 
/usr/bin/../lib/gcc/arm-none-eabi/9.3.1/../../../../arm-none-eabi/bin/ld: (.text+0x5a): undefined reference to `__wrap_exit' 
```
"
45231,Unable to restore a layer of class TextVectorization - Text Classification ,"
**System information**
Google Colab


**When I run the example provided by official tensorflow Basic text classification, everything runs fine until model  save. But when I load the model it gives me this error. 

RuntimeError: Unable to restore a layer of class TextVectorization. Layers of class TextVectorization require that the class be provided to the model loading code, either by registering the class using @keras.utils.register_keras_serializable on the class def and including that file in your program, or by passing the class in a keras.utils.CustomObjectScope that wraps this load call.
**

**Model should be loaded successfully and process raw input**

**https://colab.research.google.com/gist/amahendrakar/8b65a688dc87ce9ca07ffb0ce50b84c7/44199.ipynb#scrollTo=fEjmSrKIqiiM**

**Example Link: https://tensorflow.google.cn/tutorials/keras/text_classification** 

There is another issue [(#44199)](https://github.com/tensorflow/tensorflow/issues/44199) like this but it was closed abruptly without any solution so that's why I have to create a new issue as I did not receive any response. Thank you
"
45229,Problems for accessing CLA ,"It seems there is no response for cla-submissions@google.com,

Per for [Contributor License Agreements FAQs](https://cla.developers.google.com/about)
 
What if I lose access to my contributor group or don't know the group for my company?
If you need help with your corporate contributor group, email cla-submissions@google.com.

No response (yet)."
45228,Building tests fails on POWER,"Very short: There is an issue in the currently used abseil (as of TF 2.4-rc3 and master) which prevents abseil being built but which is required for running the tests (using `bazel test`)

This is happening on POWER only and fixed in https://github.com/abseil/abseil-cpp/commit/ea8a689cf5e71f31f96af78859eccc11161fa36a, see the error message there.

So I'd like TF to increase the currently used abseil version or add that commit as a patch please."
45226,Slower prediction of tflite model then expected,"Hi,

Why trained object detection model quantized via tf.lite converter works more then 2 seconds per 1 sample on 1 CPU instance,
while expected time ~20 ms mentioned in tf2 detection zoo? Is it normal? What can be wrong?

I completed all necessary steps:

1) Fine tuned model according to tensorflow-object-detection manual 
[https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/training.html#exporting-a-trained-model](url)

   finetuned model: ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz
   [https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md](url)

2) Then froze tf graph using export_tflite_graph_tf2.py from [https://github.com/tensorflow/models/tree/master/research/object_detection](url)

3) Converted model via tf.lite.TFLiteConverter. 
It doesn't work for tf.2.3 version  (the same problems as in #(42065), #(41877)) , therefore I used tf-nightly==2.5.0.dev20201126

4) Made a prediction from tflite model in Jupyter Notebook on 1 CPU instance

`interpreter = tf.lite.Interpreter(model_path=str(tflite_model_file), num_threads=1)`
`interpreter.allocate_tensors()`
`input_details = interpreter.get_input_details()`
`output_details = interpreter.get_output_details()`

`interpreter.set_tensor(input_details[0][""index""], features)`
`interpreter.invoke()`
`res = interpreter.get_tensor(output_details[0][""index""])`
`interpreter.reset_all_variables()`

I expect to get ~20 ms per one sample, but got ~2 seconds:
CPU times: user 2.1 s, sys: 2.78 ms, total: 2.11 s
Wall time: 2.11 s

And for ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8 - the latency is more then 2 **minutes**.

**System information**
- OS Platform and Distribution: RHEL 7.7
- TensorFlow installed from (source or binary): from binary
- TensorFlow version (or github SHA if from source): tensorflow-gpu==2.3.0


**Command used to run the converter or code if you’re using the Python API**
`converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir=SAVED_MODEL_PATH)`
`converter.optimizations = [tf.lite.Optimize.DEFAULT]`
`tflite_model = converter.convert()`

**Failure details**
- Producing correct results, but the model is slower than expected

**Any other info / logs**

Running export_tflite_graph_tf2.py i got many info messages like this:
```
INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f1bf30107b8>, TensorSpec(shape=(None, 40, 40, 32), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f1bf3010748>, TensorSpec(shape=(None, 20, 20, 96), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f1bf3010780>, TensorSpec(shape=(None, 10, 10, 1280), dtype=tf.float32, name='image_features/2/1'))], True), {}).
I1127 11:49:05.573841 139763811198784 def_function.py:1038] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f1bf30107b8>, TensorSpec(shape=(None, 40, 40, 32), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f1bf3010748>, TensorSpec(shape=(None, 20, 20, 96), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f1bf3010780>, TensorSpec(shape=(None, 10, 10, 1280), dtype=tf.float32, name='image_features/2/1'))], True), {}).
INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f1bf2fd4400>, TensorSpec(shape=(None, 40, 40, 32), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f1bf2fd4470>, TensorSpec(shape=(None, 20, 20, 96), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f1bf2fd4780>, TensorSpec(shape=(None, 10, 10, 1280), dtype=tf.float32, name='image_features/2/1'))], False), {}).
I1127 11:49:05.574001 139763811198784 def_function.py:1038] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f1bf2fd4400>, TensorSpec(shape=(None, 40, 40, 32), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f1bf2fd4470>, TensorSpec(shape=(None, 20, 20, 96), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f1bf2fd4780>, TensorSpec(shape=(None, 10, 10, 1280), dtype=tf.float32, name='image_features/2/1'))], False), {}).
INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f1bf2f95b70>, TensorSpec(shape=(None, 40, 40, 32), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f1bf2f95be0>, TensorSpec(shape=(None, 20, 20, 96), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f1bf2f95ef0>, TensorSpec(shape=(None, 10, 10, 1280), dtype=tf.float32, name='image_features/2/1'))], True), {}).
I1127 11:49:10.198460 139763811198784 def_function.py:1038] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f1bf2f95b70>, TensorSpec(shape=(None, 40, 40, 32), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f1bf2f95be0>, TensorSpec(shape=(None, 20, 20, 96), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f1bf2f95ef0>, TensorSpec(shape=(None, 10, 10, 1280), dtype=tf.float32, name='image_features/2/1'))], True), {}).
INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f1bf2fac898>, TensorSpec(shape=(None, 40, 40, 32), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f1bf2fac908>, TensorSpec(shape=(None, 20, 20, 96), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f1bf2facc18>, TensorSpec(shape=(None, 10, 10, 1280), dtype=tf.float32, name='image_features/2/1'))], False), {}).
I1127 11:49:10.198984 139763811198784 def_function.py:1038] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f1bf2fac898>, TensorSpec(shape=(None, 40, 40, 32), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f1bf2fac908>, TensorSpec(shape=(None, 20, 20, 96), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f1bf2facc18>, TensorSpec(shape=(None, 10, 10, 1280), dtype=tf.float32, name='image_features/2/1'))], False), {}).
INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f1bf30107b8>, TensorSpec(shape=(None, 40, 40, 32), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f1bf3010748>, TensorSpec(shape=(None, 20, 20, 96), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f1bf3010780>, TensorSpec(shape=(None, 10, 10, 1280), dtype=tf.float32, name='image_features/2/1'))], True), {}).
I1127 11:49:10.199471 139763811198784 def_function.py:1038] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f1bf30107b8>, TensorSpec(shape=(None, 40, 40, 32), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f1bf3010748>, TensorSpec(shape=(None, 20, 20, 96), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f1bf3010780>, TensorSpec(shape=(None, 10, 10, 1280), dtype=tf.float32, name='image_features/2/1'))], True), {}).
INFO:tensorflow:Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f1bf2fd4400>, TensorSpec(shape=(None, 40, 40, 32), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f1bf2fd4470>, TensorSpec(shape=(None, 20, 20, 96), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f1bf2fd4780>, TensorSpec(shape=(None, 10, 10, 1280), dtype=tf.float32, name='image_features/2/1'))], False), {}).
I1127 11:49:10.199697 139763811198784 def_function.py:1038] Unsupported signature for serialization: (([(<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f1bf2fd4400>, TensorSpec(shape=(None, 40, 40, 32), dtype=tf.float32, name='image_features/0/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f1bf2fd4470>, TensorSpec(shape=(None, 20, 20, 96), dtype=tf.float32, name='image_features/1/1')), (<tensorflow.python.framework.func_graph.UnknownArgument object at 0x7f1bf2fd4780>, TensorSpec(shape=(None, 10, 10, 1280), dtype=tf.float32, name='image_features/2/1'))], False), {}).
INFO:tensorflow:Assets written to: exported-model/saved_model/assets
I1127 11:49:11.159580 139763811198784 builder_impl.py:775] Assets written to: exported-model/saved_model/assets
INFO:tensorflow:Writing pipeline config file to exported-model/pipeline.config
```

Quantization logs:
```
2020-11-27 15:22:43.446327: I tensorflow/cc/saved_model/loader.cc:277] SavedModel load for tags {serve}; Status: success: OK. Took 1257095 microseconds.                                                    
2020-11-27 15:22:45.713440: I tensorflow/lite/tools/optimize/quantize_weights.cc:224] Skipping quantization of tensor ssd_mobile_net_v2fpn_keras_feature_extractor/functional_1/Conv1/Conv2D because it has fewer than 1024 elements (864).                                                                          
2020-11-27 15:22:45.713525: I tensorflow/lite/tools/optimize/quantize_weights.cc:224] Skipping quantization of tensor ssd_mobile_net_v2fpn_keras_feature_extractor/functional_1/expanded_conv_depthwise_BN/FusedBatchNormV3;ssd_mobile_net_v2fpn_keras_feature_extractor/functional_1/expanded_conv_depthwise/depthwise;ssd_mobile_net_v2fpn_keras_feature_extractor/functional_1/block_5_project/Conv2D because it has fewer than 1024 elements (288).                                                                            
2020-11-27 15:22:45.713543: I tensorflow/lite/tools/optimize/quantize_weights.cc:224] Skipping quantization of tensor ssd_mobile_net_v2fpn_keras_feature_extractor/functional_1/expanded_conv_project/Conv2D because it has fewer than 1024 elements (512).                                                          
2020-11-27 15:22:45.713561: I tensorflow/lite/tools/optimize/quantize_weights.cc:224] Skipping quantization of tensor ssd_mobile_net_v2fpn_keras_feature_extractor/functional_1/block_1_depthwise_BN/FusedBatchNormV3;ssd_mobile_net_v2fpn_keras_feature_extractor/functional_1/block_1_depthwise/depthwise;ssd_mobil
e_net_v2fpn_keras_feature_extractor/functional_1/block_12_project/Conv2D because it has fewer than 1024 elements (864).
```
"
45225,A hierarchical model for device placement.,Whether the technology mentioned in the paper—A hierarchical model for device placement is open source？and what are the related APIs
45224,Unable to deserialize custom RNN cell decorated via register_keras_serializable when used inside tf.keras.layers.RNN,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- Ubuntu 18.04:
- TensorFlow 2.3.1
- Python 3.6:
- CUDA 10.2, cuDNN 7.6.5.32
- GeForce GTX 1080 Ti

**Describe the current behavior**

Custom RNNCell layer decorated by ```tf.keras.utils.register_keras_serializable``` are not found when deserializing a ```tf.keras.layers.RNN``` object via ```tf.keras.models.load_model```

**Describe the expected behavior**
Custom layers decorated by ```register_keras_serializable``` should be able to be deserialized when used inside ```tf.keras.layers.RNN```. 

**Standalone code to reproduce the issue**
```python
import numpy as np
import tensorflow as tf

data_x = np.random.default_rng().normal(size=(100, 16, 10))
data_y = np.random.default_rng().normal(size=(100, 16, 1))

@tf.keras.utils.register_keras_serializable(package=""Custom"")
class CustomLayer(tf.keras.layers.Layer):
    def __init__(self, units, outputs, **kwargs):
        self.units = units
        self.outputs = outputs
        super(CustomLayer, self).__init__(**kwargs)

    @property
    def state_size(self):
        return self.units

    def build(self, input_shape):
        self.w = self.add_weight(""w"", shape=(input_shape[-1], self.units))
        self.o = self.add_weight(""o"", shape=(self.units, self.outputs))
        self.r = self.add_weight(""r"", shape=(self.units, self.units))
        self.built = True

    def call(self, inputs, states):
        next_hidden = tf.nn.tanh(
            tf.matmul(inputs, self.w) + tf.matmul(states[0], self.r)
        )
        output = tf.matmul(next_hidden, self.o)
        return output, [next_hidden]

    def get_config(self):
        return {""units"": self.units, ""outputs"": self.outputs}

model = tf.keras.models.Sequential(
    [
        tf.keras.Input((16, 10,)),
        tf.keras.layers.RNN(CustomLayer(10, 1), return_sequences=True),
    ]
)
model.compile(optimizer=""adam"", loss=""mean_squared_error"")

model.fit(x=data_x, y=data_y, batch_size=25, epochs=1)
model.evaluate(x=data_x, y=data_y)
model.save(""test_2.h5"")

model = tf.keras.models.load_model(""test_2.h5"")  ## Crashes here
model.evaluate(x=data_x, y=data_y)
```"
45223,DataLossError: Unable to parse tensor from stored proto when loading saved large tf dataset.,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Win 10 x64
- TensorFlow installed from (source or binary): pip
- TensorFlow version (use command below): 2.4.0rc3
- Python version: 3.8
- CUDA/cuDNN version: 11, 8.0.2
- GPU model and memory: RTX 3080 10GB



**Code:**
https://drive.google.com/file/d/1oIjXa-gH-g8SB4jGisu8nPxMd5TJgoDa/view?usp=sharing



**Full error log:**
```
---------------------------------------------------------------------------
DataLossError                             Traceback (most recent call last)
~\anaconda3\envs\hk2\lib\site-packages\tensorflow\python\eager\context.py in execution_mode(mode)
   2112       ctx.executor = executor_new
-> 2113       yield
   2114     finally:

~\anaconda3\envs\hk2\lib\site-packages\tensorflow\python\data\ops\iterator_ops.py in _next_internal(self)
    729     with context.execution_mode(context.SYNC):
--> 730       ret = gen_dataset_ops.iterator_get_next(
    731           self._iterator_resource,

~\anaconda3\envs\hk2\lib\site-packages\tensorflow\python\ops\gen_dataset_ops.py in iterator_get_next(iterator, output_types, output_shapes, name)
   2577     except _core._NotOkStatusException as e:
-> 2578       _ops.raise_from_not_ok_status(e, name)
   2579     except _core._FallbackException:

~\anaconda3\envs\hk2\lib\site-packages\tensorflow\python\framework\ops.py in raise_from_not_ok_status(e, name)
   6861   # pylint: disable=protected-access
-> 6862   six.raise_from(core._status_to_exception(e.code, message), None)
   6863   # pylint: enable=protected-access

~\anaconda3\envs\hk2\lib\site-packages\six.py in raise_from(value, from_value)

DataLossError: Unable to parse tensor from stored proto. [Op:IteratorGetNext]

During handling of the above exception, another exception occurred:

DataLossError                             Traceback (most recent call last)
<ipython-input-6-a2ce188c35b6> in <module>
----> 1 tds1_1 = next(iter(tds1_loaded.take(1)))

~\anaconda3\envs\hk2\lib\site-packages\tensorflow\python\data\ops\iterator_ops.py in __next__(self)
    745   def __next__(self):
    746     try:
--> 747       return self._next_internal()
    748     except errors.OutOfRangeError:
    749       raise StopIteration

~\anaconda3\envs\hk2\lib\site-packages\tensorflow\python\data\ops\iterator_ops.py in _next_internal(self)
    737         return self._element_spec._from_compatible_tensor_list(ret)  # pylint: disable=protected-access
    738       except AttributeError:
--> 739         return structure.from_compatible_tensor_list(self._element_spec, ret)
    740 
    741   @property

~\anaconda3\envs\hk2\lib\contextlib.py in __exit__(self, type, value, traceback)
    129                 value = type()
    130             try:
--> 131                 self.gen.throw(type, value, traceback)
    132             except StopIteration as exc:
    133                 # Suppress StopIteration *unless* it's the same exception that

~\anaconda3\envs\hk2\lib\site-packages\tensorflow\python\eager\context.py in execution_mode(mode)
   2114     finally:
   2115       ctx.executor = executor_old
-> 2116       executor_new.wait()
   2117 
   2118 

~\anaconda3\envs\hk2\lib\site-packages\tensorflow\python\eager\executor.py in wait(self)
     67   def wait(self):
     68     """"""Waits for ops dispatched in this executor to finish.""""""
---> 69     pywrap_tfe.TFE_ExecutorWaitForAllPendingNodes(self._handle)
     70 
     71   def clear_error(self):

DataLossError: Unable to parse tensor from stored proto.
```"
45221,[Old Link to NVIDIA Driver] Ubuntu 16.04 (CUDA 10.1),"## URL(s) with the issue
- https://www.tensorflow.org/install/gpu

## Description of the issue:
In the section `Ubuntu 16.04 (CUDA 10.1)`, the following command is used to download the driver

```bash
wget http://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1604/x86_64/nvidia-machine-learning-repo-ubuntu1604_1.0.0-1_amd64.deb
```

But the link specified is actually outdated and invalid so that it has to be replaced as follows
- Old: http://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1604/x86_64/nvidia-machine-learning-repo-ubuntu1604_1.0.0-1_amd64.deb
- New: https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1604/x86_64/nvidia-machine-learning-repo-ubuntu1604_1.0.0-1_amd64.deb"
45219,"ValueError: Variable <tf.Variable 'conv1_5/kernel:0' shape=(3, 3, 3, 32) dtype=float32> has `None` for gradient. Please make sure that all of your ops have a gradient defined (i.e. are differentiable). Common ops without gradient: K.argmax, K.round, K.eval.","I'm trying a new model involving word embedding for labels as well as Image classification in order to increase accuracy of the Image classifier. 
I'm using tensorflow 1.15.0 Version.
Here is the code of the model and summary.
```
def build_mobilenet_embedd_model(img_input ):
    input_x = Input(shape = (img_input.shape[1:]), name='feature')
    base_model = MobileNet(include_top= False, input_shape=img_input.shape[1:], weights='imagenet')(input_x)
    avgpool_x = GlobalAveragePooling2D()(base_model)
    dense1_x = Dense(2048, activation='relu')(avgpool_x)
    batch1_x = BatchNormalization()(dense1_x)
    dropout1_x = Dropout(0.2)(batch1_x)
    dense2_x = Dense(512, activation='relu')(dropout1_x)
    batch2_x = BatchNormalization()(dense2_x)
    dropout2_x = Dropout(0.2)(batch2_x)
    predictions = Dense(len(all_labels), activation='relu')(dropout2_x)
    embedd_layer = Embedding(13, 100, weights=[embedding_matrix], trainable=False,name = ""embedding_1"")(predictions)
    flatten = Flatten(name=""flatten"")(embedd_layer)
    final_predictions = Dense(13, activation='relu')(flatten)
    model = keras.models.Model(inputs= input_x, outputs = final_predictions)
    model.compile(optimizer='adam', loss='binary_crossentropy', metrics= METRICS
    model.summary()
    return model
```
and here is the summary:-
```
Model: ""model_4""
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
feature (InputLayer)         [(None, 128, 128, 3)]     0         
_________________________________________________________________
mobilenet_1.00_128 (Model)   (None, 4, 4, 1024)        3228864   
_________________________________________________________________
global_average_pooling2d_5 ( (None, 1024)              0         
_________________________________________________________________
dense_16 (Dense)             (None, 2048)              2099200   
_________________________________________________________________
batch_normalization_10 (Batc (None, 2048)              8192      
_________________________________________________________________
dropout_10 (Dropout)         (None, 2048)              0         
_________________________________________________________________
dense_17 (Dense)             (None, 512)               1049088   
_________________________________________________________________
batch_normalization_11 (Batc (None, 512)               2048      
_________________________________________________________________
dropout_11 (Dropout)         (None, 512)               0         
_________________________________________________________________
dense_18 (Dense)             (None, 13)                6669      
_________________________________________________________________
embedding_1 (Embedding)      (None, 13, 100)           1300      
_________________________________________________________________
flatten (Flatten)            (None, 1300)              0         
_________________________________________________________________
dense_19 (Dense)             (None, 13)                16913     
=================================================================
Total params: 6,412,274
Trainable params: 6,383,966
Non-trainable params: 28,308
_________________________________________________________________
```
Adding `embedd_layer ` and `flatten layer` after the layer `prediction` resulted in this error to pop-up,
when I run the model fit I'll get this error message.
```
ValueError: Variable <tf.Variable 'conv1_5/kernel:0' shape=(3, 3, 3, 32) dtype=float32> has `None` for gradient. Please make sure that all of your ops have a gradient defined (i.e. are differentiable). Common ops without gradient: K.argmax, K.round, K.eval.

```"
45218,need a  quantized model for posenet tensorflow lite,"System information

TensorFlow version (you are using): 2.3.1
Are you willing to contribute it (Yes/No): Yes
Describe the feature and the current behavior/state.
There is no quantized model for posenet

Will this change the current api? How?
No

Who will benefit with this feature?
People who need to run pose detection on edge IOT NPUs.

Any Other info.
tensorflow js has a quantized model already, https://github.com/tensorflow/tfjs-models/tree/master/posenet , can we get it in tensorflow lite?"
45217,"tokenizer = tfds.features.text.Tokenizer(),error is has no attribute 'text'.","<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):windowns10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):binary
- TensorFlow version (use command below):tf.2.3
- Python version:3.7
- Bazel version (if compiling from source):none
- GCC/Compiler version (if compiling from source):none
- CUDA/cuDNN version:none
- GPU model and memory:CPU ,16G

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
AttributeError: module 'tensorflow_datasets.core.features' has no attribute 'text'
**Describe the expected behavior**
run program to use.
**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

**the code is that, run it in the google colab, Can you tell me the reason?**

tokenizer = tfds.features.text.Tokenizer()

vocabulary_set = set()
for text_tensor, _ in all_labeled_data:
  some_tokens = tokenizer.tokenize(text_tensor.numpy())
  vocabulary_set.update(some_tokens)

vocab_size = len(vocabulary_set)
vocab_size
"
45216,Groups parameter of Conv2d and Conv2dTranpose ('deconvolution') not Working ?,"Hello Authors

I'm a user of tensorflow. Someday i have use Deconvolution and i know it called ""Conv2dTranpose"" in tensorflow. But I want to reduce parameters of model by groups. I found groups property at Pytorch and I see it in Conv2D class (Conv2dTranspose inheritance Conv2d). But when i use i get result which i don't want 
This is my code 

`
import tensorflow as tf
from tensorflow.keras.layers import Conv2D, Conv2DTranspose, BatchNormalization, ReLU, MaxPool2D
model = tf.keras.Sequential([
    Conv2D(512,
           kernel_size=(3, 3),
           strides=(1, 1),
           padding='same',
           use_bias=False,
           name='conv'),
    BatchNormalization(),
    ReLU(),
    Conv2DTranspose(256, kernel_size=(4, 4), strides=(2, 2),
                    padding='same', use_bias=False,
                    groups=256,
                    kernel_initializer='he_normal'),
    BatchNormalization(),
    ReLU()
])

model.build((32, 256, 192, 3))
model.summary()
`

This is summary when i received 
>
Layer (type)                 Output Shape              Param #   
conv (Conv2D)                (32, 256, 192, 512)       13824     
batch_normalization (BatchNo (32, 256, 192, 512)       2048      
re_lu (ReLU)                 (32, 256, 192, 512)       0         
conv2d_transpose (Conv2DTran (32, 512, 384, 256)       2097152   
batch_normalization_1 (Batch (32, 512, 384, 256)       1024      
re_lu_1 (ReLU)               (32, 512, 384, 256)       0         
Total params: 2,114,048
Trainable params: 2,112,512
Non-trainable params: 1,536

I think conv2d_transpose will: 2097152 / 256(groups) = 8192 params ? 

Sorry for my writer is not good 
Thanks you for reading 
Thai Hoc
"
45214,"disable ""Successfully opened dynamic library libcudart.so"" logger","**Describe the current behavior**


Please kindly turn off this logger:
```
$ python -c ""import tensorflow""
2020-11-26 12:14:41.249276: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
```

**Describe the expected behavior**

Should not log by default unless requested to. 

If this log line is important in some situation please make it configurable with the default being silent.

Thank you!

Using tf-nightly-gpu-2.5.0.dev20201120"
45213,Tensorflow lite int8 quantisation for depth_to_space() op,"**System information**
- TensorFlow version (you are using): 2.3.1
- Are you willing to contribute it (Yes/No): No(t now)

**Describe the feature and the current behavior/state.**
The operation depth_to_space() currently seems to not be supported for quantisation to 8-bit in tensorflow lite.

**Who will benefit with this feature?**
depth_to_space() is frequently used in super-resolution models and sometimes in models that do upsampling. 
These models are usually more computationally expensive than traditional classifiers because of their massive intermediate feature maps; hence, they would greatly benefit from int8 quantisation when deployed on mobile hardware, but that's not possible without int8 support for depth_to_space().
Is this in the works? Has it been planned for a release?

Best
"
45212,Very poor results from GPU implementation using CNN Tutorial,"**System information**
- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No, I have used the stock code provided by [The CNN Tutorial](https://www.tensorflow.org/tutorials/images/cnn).
- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04):** Windows 10 Pro, Version 20H2
- **TensorFlow installed from (source or binary):** TensorFlow installed via pip command `pip install tensorflow`
- **TensorFlow version (use command below):** v2.3.0-54-gfcc4b966f1 2.3.1
- **Python version:** 3.8.6
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- **CUDA/cuDNN version:** CUDA v10.1, cuDNN v7.6.0.64
- **GPU model and memory:** NVIDIA GeForce RTX 3080, 10GB


**Describe the current behaviour**
I followed the CNN tutorial linked above, using both GPU and CPU implementations. Whilst the CPU implementation produced very similar results to the graphs displayed on the tutorial, the GPU implementation never surpassed 0.1 accuracy in training.

I enabled the CPU implementation by the following line of code:
```python
import os
os.environ['CUDA_VISIBLE_DEVICES'] = '-1'
```

I discovered this bug by testing and training my own implementation which, similarly, had good results using CPU and terrible results using GPU.

**Describe the expected behaviour**
I expect the GPU implementation results to closely match that of the CPU implementation results.

**Standalone code to reproduce the issue**
Link to the jupyter notebook can be found [here](https://drive.google.com/file/d/1C6bnXhBqHCv-rNqS1QWWf4yZx-6x-qte/view?usp=sharing).

With minimal code below:
```python
import os
import tensorflow as tf
from tensorflow.keras import datasets, layers, models

(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()

train_images, test_images = train_images / 255.0, test_images / 255.0

model = models.Sequential()
model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(64, (3, 3), activation='relu'))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(64, (3, 3), activation='relu'))
model.add(layers.Flatten())
model.add(layers.Dense(64, activation='relu'))
model.add(layers.Dense(10))

model.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

history = model.fit(train_images, train_labels, epochs=10, 
                    validation_data=(test_images, test_labels))
```

**Other info / logs**
Below is the output from the `model.fit` step in the code provided above.

> Epoch 1/10
1563/1563 [==============================] - 4s 3ms/step - loss: 2.3028 - accuracy: 0.0960 - val_loss: 2.3026 - val_accuracy: 0.1000
Epoch 2/10
1563/1563 [==============================] - 4s 2ms/step - loss: 2.3028 - accuracy: 0.0975 - val_loss: 2.3026 - val_accuracy: 0.1000
Epoch 3/10
1563/1563 [==============================] - 4s 2ms/step - loss: 2.3028 - accuracy: 0.0968 - val_loss: 2.3026 - val_accuracy: 0.1000
Epoch 4/10
1563/1563 [==============================] - 4s 2ms/step - loss: 2.3028 - accuracy: 0.0967 - val_loss: 2.3026 - val_accuracy: 0.1000
Epoch 5/10
1563/1563 [==============================] - 4s 3ms/step - loss: 2.3027 - accuracy: 0.0990 - val_loss: 2.3026 - val_accuracy: 0.1000
Epoch 6/10
1563/1563 [==============================] - 4s 3ms/step - loss: 2.3028 - accuracy: 0.0970 - val_loss: 2.3026 - val_accuracy: 0.1000
Epoch 7/10
1563/1563 [==============================] - 4s 3ms/step - loss: 2.3028 - accuracy: 0.0972 - val_loss: 2.3026 - val_accuracy: 0.1000
Epoch 8/10
1563/1563 [==============================] - 4s 2ms/step - loss: 2.3028 - accuracy: 0.0980 - val_loss: 2.3026 - val_accuracy: 0.1000
Epoch 9/10
1563/1563 [==============================] - 4s 2ms/step - loss: 2.3028 - accuracy: 0.1002 - val_loss: 2.3026 - val_accuracy: 0.1000
Epoch 10/10
1563/1563 [==============================] - 4s 2ms/step - loss: 2.3028 - accuracy: 0.1007 - val_loss: 2.3026 - val_accuracy: 0.1000

The python process that was running the jupyter notebook displayed this warning:
> 2020-11-26 17:44:27.891143: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library cublas64_10.dll
library cudnn64_7.dll
ation is supported on Cuda non-Windows platforms only
Relying on driver to perform ptx compilation.
Modify $PATH to customize ptxas location.
This message will be only logged once.

"
45211,Tensor data is stored in BE format on s390x in flatbuffer model in a certain scenario,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): 2.3.1
- Python version: 3.6.9
- Bazel version (if compiling from source): 3.4.1
- GCC/Compiler version (if compiling from source): Ubuntu 7.5.0-3ubuntu1~18.04
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A


**Describe the current behavior**
`tfl_while_op.mlir.test` test is failing on s390x.
On debugging a little, I found that during the building of flatbuffer model, the data is first represented in Big Endian format, then we flat it to a `absl::string_view` in [flatbuffer_export.cc](https://github.com/tensorflow/tensorflow/blob/d5b2156e4e5367cc336d26fbbac3a6e76781de05/tensorflow/compiler/mlir/lite/flatbuffer_export.cc#L638). 
This data , in some cases, is directly stored in a vector of bytes and inserted into a flatbuffer in `CreateVector`. As flatbuffer only support Little Endian format, this TC fails as FileCheck on mlir file expects the data in LE format.

The code that is causing the issue in `CreateVector` function is:
```
      if (sizeof(T) == 1) {
        PushBytes(reinterpret_cast<const uint8_t *>(v), len);
```

If the `sizeof(T)` is greater than 1, then the data is reversed before storing it into a vector of bytes, i.e., the data gets stored in LE format in flatbuffer model. 
```
      } else {
        for (auto i = len; i > 0; ) {
          PushElement(v[--i]);
        }
```

As the flatbuffer only support LE format, it seems that the data must be byte-swapped into LE format from BE before storing is into the vector of bytes. But, since I am not sure of the functionality being tested here, maybe we can update the expected result in mlir file from ```// CHECK-NEXT:     data: [ 1, 0, 0, 0 ]``` to ```// CHECK-NEXT:     data: [ 0, 0, 0, 1 ]```. 
Please suggest what would be the best way to proceed here. There are multiple compiler related test cases which have similar failure errors.

**Describe the expected behavior**
The tensor data must be stored in LE format in flatbuffer model.

**Standalone code to reproduce the issue**
To reproduce the issue, please use this command:
```bazel --host_jvm_args=""-Xms1024m"" --host_jvm_args=""-Xmx2048m"" test --host_javabase=""@local_jdk//:jdk"" --test_tag_filters=-gpu,-benchmark-test,-v1only,-no_oss,-oss_serial -k --test_timeout 300,450,1200,3600 --build_tests_only  -c dbg --copt=-O -c opt --copt=-g --strip never --color=yes --curses=yes --test_output=errors --verbose_failures -- //tensorflow/compiler/mlir/lite/tests/mlir2flatbuffer:tfl_while_op.mlir.test```

**Other info / logs** "
45210,Tensor shape signature is not parsed safely with `ParseTensors` of TF Lite InterpreterBuilder on Big Endian machines,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): N
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 20.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): 2.3.1
- Python version: 3.8.5
- Bazel version (if compiling from source): 3.1.0
- GCC/Compiler version (if compiling from source): gcc (Ubuntu 9.3.0-17ubuntu1~20.04) 9.3.0
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A

**Describe the current behavior**
Currently, `InterpreterBuilder` is retrieving the `shape_signature` field of a flatbuffer tensor in the following way:
```
    size_t dims_signature_rank = 0;
    const int* dims_signature_data = nullptr;
    if (tensor->shape_signature()) {
      dims_signature_rank = tensor->shape_signature()->size();
      dims_signature_data = tensor->shape_signature()->data();
    }
```
The type of `tensor->shape_signature()` is a flatbuffer int array (`flatbuffers::Vector`), and accessing it using `data()` method is not safe as the data is always stored in Little Endian format, which will break for Big Endian machines. So whenever this optional `shape_signature` field is set in a TF Lite model, the interpreter will break on Big Endian machines.

To access the data correctly, we should use the `Get()` method of the flatbuffer array. There actually is a handy function defined in `InterpreterBuilder` already, `FlatBufferIntArrayToVector`, which is used for retrieving the `tensor->shape()` field as follow:
```
std::vector<int> dims = FlatBufferIntArrayToVector(tensor->shape());
```
This helper function definitely could work for `tensor->shape_signature()` as well because they both are integer array fields. The only issue is that currently, we are expecting two variables `dims_signature_rank` and `dims_signature_data` in the `SetTensorParametersReadWrite` function that we need to call later rather than an `std::vector`.

I have also tried some other methods to use `Get()` to retrieve the data, but it is a bit tricky as we need the shape signature data to live long enough for the `SetTensorParametersReadWrite` to finish writing the data into `tensor.dims_signature` field. To avoid making lot of changes and introducing new variables, I wonder if we could change the `SetTensorParametersReadWrite` function signature to make it accept one `dims_signature` vector instead of one size variable and one data variable. This could work because in `tensorflow/lite/core/subgraph.h`, the expected input arguement is like this:
```
inline TfLiteStatus SetTensorParametersReadWrite(
      int tensor_index, TfLiteType type, const char* name,
      const std::vector<int>& dims, TfLiteQuantization quantization,
      bool is_variable = false, const size_t rank_dims_signature = 0,
      const int* dims_signature = nullptr) {
    return SetTensorParametersReadWrite(tensor_index, type, name, dims.size(),
                                        dims.data(), quantization, is_variable,
                                        rank_dims_signature, dims_signature);
  }
  TfLiteStatus SetTensorParametersReadWrite(
      int tensor_index, TfLiteType type, const char* name, const size_t rank,
      const int* dims, TfLiteQuantization quantization,
      bool is_variable = false, const size_t rank_dims_signature = 0,
      const int* dims_signature = nullptr);
```
Here we are using a reference to the `dims` vector and pass its size and data respectively to the function so that it will outlive the function call - the exact same thing could be done for `dims_signature` as well. If we get rid of `dims_signature_rank` and `dims_signature_data` and pass on a vector of `dims_signature`, we only need to make changes to these two places.

If such solution could work I will likely start a PR to it. Otherwise, please let me know if there are some other convenient ways to fix the parsing of `shape_signature`, thanks.

**Describe the expected behavior**
The `shape_signature` field should be parsed correctly on Big Endian machine.

**Standalone code to reproduce the issue**
```
bazel test --host_javabase=""@local_jdk//:jdk"" --cache_test_results=no --build_tests_only --test_output=errors -- //tensorflow/lite/python:lite_v2_test
```
This test will fail on Big Endian machines.

**Other info / logs** 
"
45209,"Pretrained Xception takes more memory than an InceptionResNetV2, despite having half of the parameters","**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- TensorFlow installed from (source or binary): with pip
- TensorFlow version (use command below): 2.2.0
- Python version: 3.8
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10.1
- GPU model and memory: Nvidia Quadro T2000 

**Describe the current behavior**
I'll attach the script below. 
So, the problem is that if i am using pre-trained InceptionResNetV2 and Xception from keras, turns out that with allow_memory_growth, Inception takes ~ 1GB of my GPU memory when predictiong and Xception takes ~2.8GB, despite being 2x smaller than inception. Is this an expected behaviour?

**Describe the expected behavior**
Xception should be less memory consuming compared to InceptionResNetV2 

**Standalone code to reproduce the issue**

Code for Inception:

```

import tensorflow as tf
from tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2
from tensorflow.keras.models import load_model
import numpy as np

gpu_devices = tf.config.list_physical_devices('GPU')
tf.config.experimental.set_memory_growth(gpu_devices[0], True)
logical_gpu_devices = tf.config.list_logical_devices('GPU')

model = InceptionResNetV2()
img = np.zeros([299,299,3],dtype=np.uint8)

print(model.predict(np.array([tf.keras.applications.inception_resnet_v2.preprocess_input(img)])))

```

Code for Xception:


```

import tensorflow as tf
from tensorflow.keras.applications.xception import Xception
from tensorflow.keras.models import load_model
import numpy as np


gpu_devices = tf.config.list_physical_devices('GPU')
tf.config.experimental.set_memory_growth(gpu_devices[0], True)
logical_gpu_devices = tf.config.list_logical_devices('GPU')

model = Xception()
img = np.zeros([299,299,3],dtype=np.uint8)

print(model.predict(np.array([tf.keras.applications.xception.preprocess_input(img)])))

```


**Other info / logs** 
Screenshots for memory consumption:
Inception:
![image](https://user-images.githubusercontent.com/9899064/100369665-dfa87780-300d-11eb-8989-4f4e9e34888d.png)
Xception
![image](https://user-images.githubusercontent.com/9899064/100369597-c30c3f80-300d-11eb-9399-0fe7866f1603.png)

"
45207,ResizeBilinear op with half_pixel_centers true not support by nnapi,"**System information**android 11
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):16.04
- TensorFlow installed from (source or binary):pip
- TensorFlow version (or github SHA if from source):2.3-2.4


**Command used to run the converter or code if you’re using the Python API**
If possible, please share a link to Colab/Jupyter/any notebook.

```
   kerasmodel=tf.keras.models.load_model('./log',compile=False)
    input_name = kerasmodel.input_names[0]
    index = kerasmodel.input_names.index(input_name)
    kerasmodel.inputs[index].set_shape([1, 320, 320,1])
    ind =0
    for layer in kerasmodel.layers:
        print(layer.name)
        if layer.name==""up_p3"" or layer.name==""up_p4"":
            print(""###############################"")
            
            kerasmodel.layers[ind].half_pixel_centers=False
            print(kerasmodel.layers[ind].half_pixel_centers)
         
        ind+=1
    
  
#     kerasmodel.summary()
#     exit()
    
    converter = tf.lite.TFLiteConverter.from_keras_model(kerasmodel)   
    #converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir=""./log"")
    converter.target_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]#tf.lite.OpsSet.SELECT_TF_OPS]
    converter.optimizations = [tf.lite.Optimize.DEFAULT]
    converter.representative_dataset = tf.lite.RepresentativeDataset(representative_dataset_gen) 
    converter.inference_input_type = tf.int8
    converter.inference_output_type = tf.int8
    converter.experimental_new_converter = True
    tflite_model_quant = converter.convert()
    import pathlib
    tflite_model_quant_file = pathlib.Path(""./"")/""test2.4.tflite""
    tflite_model_quant_file.write_bytes(tflite_model_quant)
```

**The output from the converter invocation**

```
# Copy and paste the output here.
![image](https://user-images.githubusercontent.com/30410113/100355529-e692b280-302c-11eb-8f54-1f49c3646d90.png)
when i test it with benchmark abort occur!so i find the log with:
11-26 19:53:25.830  1061 27513 E hta-unnhal: {PAD, TENSOR_QUANT8} is not supported.
11-26 19:53:25.830  1061 27513 E hta-unnhal: Doesn't support half pixel centers for RESIZE_BILINEAR
11-26 19:53:25.830  1061 27513 E hta-unnhal: {RESIZE_BILINEAR, TENSOR_QUANT8} is not supported.
11-26 19:53:25.830  1061 27513 E hta-unnhal: Doesn't support half pixel centers for RESIZE_BILINEAR
11-26 19:53:25.830  1061 27513 E hta-unnhal: {RESIZE_BILINEAR, TENSOR_QUANT8} is not supported.
![image](https://user-images.githubusercontent.com/30410113/100355495-d7136980-302c-11eb-88cf-5002c60428f9.png)
I set the half_pixel_centers with False before convert but when i get tflite it is still true
```

**Also, please include a link to the saved model or GraphDef**
![image](https://user-images.githubusercontent.com/30410113/100355786-5143ee00-302d-11eb-88ae-c1804ddabf10.png)

```
# Put link here or attach to the issue.
```

**Failure details**
If the conversion is successful, but the generated model is wrong,
state what is wrong:
- Producing wrong results and/or decrease in accuracy
- Producing correct results, but the model is slower than expected (model generated from old converter)


**RNN conversion support**
If converting TF RNN to TFLite fused RNN ops, please prefix [RNN] in the title.

**Any other info / logs**

Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
45206,How can i increase number of timeseries feature when building Encoder-Decoder model(seq2seq) using ConvLSTM2D,"- TensorFlow version: 2.1.0
- Python version: 3.7.4

I could build one timeseries feature input , one time series predict using Encoder-Decoder model like below
```python
def build_model(input_timesteps, output_timesteps, num_links):
    model = tf.keras.Sequential()
    model.add(tf.keras.layers.BatchNormalization(name = 'batch_norm_0', input_shape = (input_timesteps, num_links, 1, 1)))
    
    #Encoder
    model.add(tf.keras.layers.ConvLSTM2D(name ='conv_lstm_1',
                         filters = num_filters, kernel_size = (kernel_size[0], 1),                       
                         padding = 'same', 
                         return_sequences = True))
    
    model.add(tf.keras.layers.Dropout(dropout_rate, name = 'dropout_1'))
    model.add(tf.keras.layers.BatchNormalization(name = 'batch_norm_1'))

    model.add(tf.keras.layers.ConvLSTM2D(name ='conv_lstm_2',
                         filters = num_filters, kernel_size = (kernel_size[1], 1), 
                         padding='same',
                         return_sequences = False))
    
    model.add(tf.keras.layers.Dropout(dropout_rate, name = 'dropout_2'))
    model.add(tf.keras.layers.BatchNormalization(name = 'batch_norm_2'))
    
    model.add(tf.keras.layers.Flatten())
    
    #Decoder
    model.add(tf.keras.layers.RepeatVector(output_timesteps))
    model.add(tf.keras.layers.Reshape((output_timesteps, num_links, 1, 64)))
    
    model.add(tf.keras.layers.ConvLSTM2D(name ='conv_lstm_3',
                         filters = num_filters, kernel_size = (kernel_size[0], 1), 
                         padding='same',
                         return_sequences = True))
    
    model.add(tf.keras.layers.Dropout(dropout_rate, name = 'dropout_3'))
    model.add(tf.keras.layers.BatchNormalization(name = 'batch_norm_3'))
    
    model.add(tf.keras.layers.ConvLSTM2D(name ='conv_lstm_4',
                         filters = num_filters, kernel_size = (kernel_size[1], 1), 
                         padding='same',
                         return_sequences = True))
    
    model.add(tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(units=1, name = 'dense_1', activation = 'relu')))
    #model.add(Dense(units=1, name = 'dense_2'))

    optimizer = tf.keras.optimizers.RMSprop() #lr=0.0001, rho=0.9, epsilon=1e-08, decay=0.9)
    model.compile(loss = ""mse"", optimizer = optimizer)
    return model


_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
batch_norm_0 (BatchNormaliza (None, 8, 4, 1, 1)        4         
_________________________________________________________________
conv_lstm_1 (ConvLSTM2D)     (None, 8, 4, 1, 64)       166656    
_________________________________________________________________
dropout_1 (Dropout)          (None, 8, 4, 1, 64)       0         
_________________________________________________________________
batch_norm_1 (BatchNormaliza (None, 8, 4, 1, 64)       256       
_________________________________________________________________
conv_lstm_2 (ConvLSTM2D)     (None, 4, 1, 64)          164096    
_________________________________________________________________
dropout_2 (Dropout)          (None, 4, 1, 64)          0         
_________________________________________________________________
batch_norm_2 (BatchNormaliza (None, 4, 1, 64)          256       
_________________________________________________________________
flatten_2 (Flatten)          (None, 256)               0         
_________________________________________________________________
repeat_vector_2 (RepeatVecto (None, 3, 256)            0         
_________________________________________________________________
reshape_2 (Reshape)          (None, 3, 4, 1, 64)       0         
_________________________________________________________________
conv_lstm_3 (ConvLSTM2D)     (None, 3, 4, 1, 64)       327936    
_________________________________________________________________
dropout_3 (Dropout)          (None, 3, 4, 1, 64)       0         
_________________________________________________________________
batch_norm_3 (BatchNormaliza (None, 3, 4, 1, 64)       256       
_________________________________________________________________
conv_lstm_4 (ConvLSTM2D)     (None, 3, 4, 1, 64)       164096    
_________________________________________________________________
time_distributed_2 (TimeDist (None, 3, 4, 1, 1)        65        
=================================================================
```
About train data and test data shape.
This shape means each 8 time steps have one time series feature of length 4.
Predict is next 3 time step.
```python
- X_train shape : (198, 8, 4, 1, 1)    X_test shape : (150, 8, 4, 1, 1)
- Y_train shape : (198, 3, 4, 1, 1)    Y_test shape : (150, 3, 4, 1, 1)
```
I want to increase number of timeseries feature of length 4 like below.
```python
- multi_X_train shape : (198, 8, 2, 4, 1)   multi_X_test shape : (150, 8, 2, 4, 1)
- Y_train shape : (198, 3, 4, 1, 1)    Y_test shape : (150, 3, 4, 1, 1)
```
```python
def build_multi_model(input_timesteps, output_timesteps, num_links):
    model = tf.keras.Sequential()
#     model.add(tf.keras.layers.BatchNormalization(name = 'batch_norm_0', input_shape = (input_timesteps, num_links, 2, 1)))
    model.add(tf.keras.layers.BatchNormalization(name = 'batch_norm_0', input_shape = (input_timesteps, 2, 4 ,1)))
    
    #Encoder
    model.add(tf.keras.layers.ConvLSTM2D(name ='conv_lstm_1',
                         filters = num_filters, kernel_size = (kernel_size[0], 2),                       
                         padding = 'same', 
                         return_sequences = True))
    
    model.add(tf.keras.layers.Dropout(dropout_rate, name = 'dropout_1'))
    model.add(tf.keras.layers.BatchNormalization(name = 'batch_norm_1'))

    model.add(tf.keras.layers.ConvLSTM2D(name ='conv_lstm_2',
                         filters = num_filters, kernel_size = (kernel_size[1], 2),
                         padding='same',
                         return_sequences = False))
    
    model.add(tf.keras.layers.Dropout(dropout_rate, name = 'dropout_2'))
    model.add(tf.keras.layers.BatchNormalization(name = 'batch_norm_2'))
    
    model.add(tf.keras.layers.Flatten())
    
    #Decoder
    model.add(tf.keras.layers.RepeatVector(output_timesteps))
    model.add(tf.keras.layers.Reshape((output_timesteps, num_links, 1, 64)))
    
    model.add(tf.keras.layers.ConvLSTM2D(name ='conv_lstm_3',
                         filters = num_filters, kernel_size = (kernel_size[0], 2),
                         padding='same',
                         return_sequences = True))
    
    model.add(tf.keras.layers.Dropout(dropout_rate, name = 'dropout_3'))
    model.add(tf.keras.layers.BatchNormalization(name = 'batch_norm_3'))
    
    model.add(tf.keras.layers.ConvLSTM2D(name ='conv_lstm_4',
                         filters = num_filters, kernel_size = (kernel_size[1], 2),
                         padding='same',
                         return_sequences = True))
    
    model.add(tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(units=1, name = 'dense_1', activation = 'relu')))
    #model.add(Dense(units=1, name = 'dense_2'))

    optimizer = tf.keras.optimizers.RMSprop() #lr=0.0001, rho=0.9, epsilon=1e-08, decay=0.9)
    model.compile(loss = ""mse"", optimizer = optimizer)
    return model

Model: ""sequential_23""
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
batch_norm_0 (BatchNormaliza (None, 8, 2, 4, 1)        4         
_________________________________________________________________
conv_lstm_1 (ConvLSTM2D)     (None, 8, 2, 4, 64)       333056    
_________________________________________________________________
dropout_1 (Dropout)          (None, 8, 2, 4, 64)       0         
_________________________________________________________________
batch_norm_1 (BatchNormaliza (None, 8, 2, 4, 64)       256       
_________________________________________________________________
conv_lstm_2 (ConvLSTM2D)     (None, 2, 4, 64)          327936    
_________________________________________________________________
dropout_2 (Dropout)          (None, 2, 4, 64)          0         
_________________________________________________________________
batch_norm_2 (BatchNormaliza (None, 2, 4, 64)          256       
_________________________________________________________________
flatten_22 (Flatten)         (None, 512)               0         
_________________________________________________________________
repeat_vector_22 (RepeatVect (None, 3, 512)            0         
_________________________________________________________________
reshape_22 (Reshape)         (None, 3, 4, 1, 64)       0         
_________________________________________________________________
conv_lstm_3 (ConvLSTM2D)     (None, 3, 4, 1, 64)       655616    
_________________________________________________________________
dropout_3 (Dropout)          (None, 3, 4, 1, 64)       0         
_________________________________________________________________
batch_norm_3 (BatchNormaliza (None, 3, 4, 1, 64)       256       
_________________________________________________________________
conv_lstm_4 (ConvLSTM2D)     (None, 3, 4, 1, 64)       327936    
_________________________________________________________________
time_distributed_22 (TimeDis (None, 3, 4, 1, 1)        65        
=================================================================
```
I could't understand why below error occurred when i tried model fit.
```python
model = build_multi_model(8, 3, 4)
history = model.fit(multi_X_train, Y_train,
                    batch_size = batch_size, epochs = epoch,
                    shuffle = False, validation_data = (multi_X_test, Y_test),
                    verbose = 2, callbacks = [call_back])
```
```sh
---------------------------------------------------------------------------
InvalidArgumentError                      Traceback (most recent call last)
<ipython-input-559-7b082bf34abc> in <module>
      6                     batch_size = batch_size, epochs = epoch,
      7                     shuffle = False, validation_data = (multi_X_test, Y_test),
----> 8                     verbose = 2, callbacks = [call_back])
      9 
     10 print(""early_stopping"")

/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)
    817         max_queue_size=max_queue_size,
    818         workers=workers,
--> 819         use_multiprocessing=use_multiprocessing)
    820 
    821   def evaluate(self,

/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/engine/training_v2.py in fit(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)
    340                 mode=ModeKeys.TRAIN,
    341                 training_context=training_context,
--> 342                 total_epochs=epochs)
    343             cbks.make_logs(model, epoch_logs, training_result, ModeKeys.TRAIN)
    344 

/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/engine/training_v2.py in run_one_epoch(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)
    126         step=step, mode=mode, size=current_batch_size) as batch_logs:
    127       try:
--> 128         batch_outs = execution_function(iterator)
    129       except (StopIteration, errors.OutOfRangeError):
    130         # TODO(kaftan): File bug about tf function and errors.OutOfRangeError?

/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/engine/training_v2_utils.py in execution_function(input_fn)
     96     # `numpy` translates Tensors to values in Eager mode.
     97     return nest.map_structure(_non_none_constant_value,
---> 98                               distributed_function(input_fn))
     99 
    100   return execution_function

/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/eager/def_function.py in __call__(self, *args, **kwds)
    566         xla_context.Exit()
    567     else:
--> 568       result = self._call(*args, **kwds)
    569 
    570     if tracing_count == self._get_tracing_count():

/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/eager/def_function.py in _call(self, *args, **kwds)
    630         # Lifting succeeded, so variables are initialized and we can run the
    631         # stateless function.
--> 632         return self._stateless_fn(*args, **kwds)
    633     else:
    634       canon_args, canon_kwds = \

/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/eager/function.py in __call__(self, *args, **kwargs)
   2361     with self._lock:
   2362       graph_function, args, kwargs = self._maybe_define_function(args, kwargs)
-> 2363     return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access
   2364 
   2365   @property

/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/eager/function.py in _filtered_call(self, args, kwargs)
   1609          if isinstance(t, (ops.Tensor,
   1610                            resource_variable_ops.BaseResourceVariable))),
-> 1611         self.captured_inputs)
   1612 
   1613   def _call_flat(self, args, captured_inputs, cancellation_manager=None):

/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/eager/function.py in _call_flat(self, args, captured_inputs, cancellation_manager)
   1690       # No tape is watching; skip to running the function.
   1691       return self._build_call_outputs(self._inference_function.call(
-> 1692           ctx, args, cancellation_manager=cancellation_manager))
   1693     forward_backward = self._select_forward_and_backward_functions(
   1694         args,

/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/eager/function.py in call(self, ctx, args, cancellation_manager)
    543               inputs=args,
    544               attrs=(""executor_type"", executor_type, ""config_proto"", config),
--> 545               ctx=ctx)
    546         else:
    547           outputs = execute.execute_with_cancellation(

/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/eager/execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)
     65     else:
     66       message = e.message
---> 67     six.raise_from(core._status_to_exception(e.code, message), None)
     68   except TypeError as e:
     69     keras_symbolic_tensors = [

~/.local/lib/python3.7/site-packages/six.py in raise_from(value, from_value)

InvalidArgumentError:  Input to reshape is a tensor with 98304 values, but the requested shape has 49152
	 [[node sequential_23/reshape_22/Reshape (defined at <ipython-input-559-7b082bf34abc>:8) ]] [Op:__inference_distributed_function_126239]

Function call stack:
distributed_function
```


"
45205,Tensorflow 2.3.0 Bazel 3.1.0 compile ERROR,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform: Ubuntu 16.04:
- TensorFlow installed from (source or binary):source
- TensorFlow version:2.3.0
- Python version:3.5
- Bazel version (if compiling from source):3.1.0
- GCC/Compiler version (if compiling from source):5.4.0 / 7.3.0 / 7.5.0
- CUDA/cuDNN version:10.1
- GPU model and memory:V100
- cudnn version:7.6.5

Compile Config:
build --action_env PYTHON_BIN_PATH=""/home/anaconda3/bin/python3""
build --action_env PYTHON_LIB_PATH=""/home/anaconda3/lib/python3.5/site-packages""
build --python_path=""/home/anaconda3/bin/python3""
build --config=xla
build --action_env CUDA_TOOLKIT_PATH=""/usr/local/cuda-10.1""
build --action_env TF_CUDA_COMPUTE_CAPABILITIES=""3.5,7.0""
build --action_env LD_LIBRARY_PATH=""/home/install/gcc-7.3.0/lib
build --action_env GCC_HOST_COMPILER_PATH=""/home/install/gcc-7.3.0/bin/gcc""
build --config=cuda
build:opt --copt=-march=native
build:opt --copt=-Wno-sign-compare
build:opt --host_copt=-march=native
build:opt --define with_default_optimizations=true
test --flaky_test_attempts=3
test --test_size_filters=small,medium
test --test_env=LD_LIBRARY_PATH
test:v1 --test_tag_filters=-benchmark-test,-no_oss,-no_gpu,-oss_serial
test:v1 --build_tag_filters=-benchmark-test,-no_oss,-no_gpu
test:v2 --test_tag_filters=-benchmark-test,-no_oss,-no_gpu,-oss_serial,-v1only
test:v2 --build_tag_filters=-benchmark-test,-no_oss,-no_gpu,-v1only
build --action_env TF_CONFIGURE_IOS=""0""

**Describe the problem**
I tried to build tensorflow 2.3.0 from source using bazel. I also checked the requirements of GCC, CUDA, and CUDNN. 
But the error still occured:

ERROR: /home/code/release/tensorflow-2.3.0/tensorflow/stream_executor/cuda/BUILD:457:1: C++ compilation of rule '//tensorflow/stream_executor/cuda:cusparse_stub' failed (Exit 1)
In file included from tensorflow/stream_executor/cuda/cusparse_stub.cc:59:0:
./tensorflow/stream_executor/cuda/cusparse_10_1.inc:7786:21: error: 'cusparseSpVecDescr_t' was not declared in this scope
 cusparseCreateSpVec(cusparseSpVecDescr_t *spVecDescr, int64_t size, int64_t nnz,
                     ^
./tensorflow/stream_executor/cuda/cusparse_10_1.inc:7786:43: error: 'spVecDescr' was not declared in this scope
 cusparseCreateSpVec(cusparseSpVecDescr_t *spVecDescr, int64_t size, int64_t nnz,
                                           ^
./tensorflow/stream_executor/cuda/cusparse_10_1.inc:7786:63: error: expected primary-expression before 'size'
 cusparseCreateSpVec(cusparseSpVecDescr_t *spVecDescr, int64_t size, int64_t nnz,
                                                               ^
./tensorflow/stream_executor/cuda/cusparse_10_1.inc:7786:77: error: expected primary-expression before 'nnz'
 cusparseCreateSpVec(cusparseSpVecDescr_t *spVecDescr, int64_t size, int64_t nnz,
                                                                             ^
./tensorflow/stream_executor/cuda/cusparse_10_1.inc:7787:21: error: expected primary-expression before 'void'
                     void *indices, void *values, cusparseIndexType_t idxType,
                     ^
./tensorflow/stream_executor/cuda/cusparse_10_1.inc:7787:36: error: expected primary-expression before 'void'
                     void *indices, void *values, cusparseIndexType_t idxType,
                                    ^
./tensorflow/stream_executor/cuda/cusparse_10_1.inc:7787:70: error: expected primary-expression before 'idxType'
                     void *indices, void *values, cusparseIndexType_t idxType,
                                                                      ^
./tensorflow/stream_executor/cuda/cusparse_10_1.inc:7788:41: error: expected primary-expression before 'idxBase'
                     cusparseIndexBase_t idxBase, cudaDataType valueType) {
                                         ^
./tensorflow/stream_executor/cuda/cusparse_10_1.inc:7788:63: error: expected primary-expression before 'valueType'
                     cusparseIndexBase_t idxBase, cudaDataType valueType) {
                                                               ^
./tensorflow/stream_executor/cuda/cusparse_10_1.inc:7788:72: error: expression list treated as compound expression in initializer [-fpermissive]
                     cusparseIndexBase_t idxBase, cudaDataType valueType) {
                                                                        ^
./tensorflow/stream_executor/cuda/cusparse_10_1.inc:7788:74: error: expected ',' or ';' before '{' token
                     cusparseIndexBase_t idxBase, cudaDataType valueType) {
                                                                          ^
./tensorflow/stream_executor/cuda/cusparse_10_1.inc:7799:22: error: 'cusparseSpVecDescr_t' was not declared in this scope
 cusparseDestroySpVec(cusparseSpVecDescr_t spVecDescr) {
                      ^
./tensorflow/stream_executor/cuda/cusparse_10_1.inc:7799:55: error: expected ',' or ';' before '{' token
 cusparseDestroySpVec(cusparseSpVecDescr_t spVecDescr) {
                                                       ^
./tensorflow/stream_executor/cuda/cusparse_10_1.inc:7807:11: error: 'cusparseSpVecDescr_t' does not name a type
     const cusparseSpVecDescr_t spVecDescr, int64_t *size, int64_t *nnz,
           ^
./tensorflow/stream_executor/cuda/cusparse_10_1.inc: In function 'cusparseStatus_t cusparseSpVecGet(int, int64_t*, int64_t*, void**, void**, cusparseIndexType_t*, cusparseIndexBase_t*, cudaDataType*)':
./tensorflow/stream_executor/cuda/cusparse_10_1.inc:7811:13: error: 'cusparseSpVecDescr_t' does not name a type
       const cusparseSpVecDescr_t, int64_t *, int64_t *, void **, void **,
             ^
./tensorflow/stream_executor/cuda/cusparse_10_1.inc: At global scope:
./tensorflow/stream_executor/cuda/cusparse_10_1.inc:7820:11: error: 'cusparseSpVecDescr_t' does not name a type
     const cusparseSpVecDescr_t spVecDescr, cusparseIndexBase_t *idxBase) {
           ^
./tensorflow/stream_executor/cuda/cusparse_10_1.inc: In function 'cusparseStatus_t cusparseSpVecGetIndexBase(int, cusparseIndexBase_t*)':
./tensorflow/stream_executor/cuda/cusparse_10_1.inc:7821:57: error: 'cusparseSpVecDescr_t' does not name a type
   using FuncPtr = cusparseStatus_t(CUSPARSEAPI *)(const cusparseSpVecDescr_t,
                                                         ^
./tensorflow/stream_executor/cuda/cusparse_10_1.inc: At global scope:
./tensorflow/stream_executor/cuda/cusparse_10_1.inc:7829:30: error: 'cusparseSpVecDescr_t' does not name a type
 cusparseSpVecGetValues(const cusparseSpVecDescr_t spVecDescr, void **values) {
                              ^
./tensorflow/stream_executor/cuda/cusparse_10_1.inc: In function 'cusparseStatus_t cusparseSpVecGetValues(int, void**)':
./tensorflow/stream_executor/cuda/cusparse_10_1.inc:7831:45: error: 'cusparseSpVecDescr_t' does not name a type
       cusparseStatus_t(CUSPARSEAPI *)(const cusparseSpVecDescr_t, void **);
                                             ^
./tensorflow/stream_executor/cuda/cusparse_10_1.inc: At global scope:
./tensorflow/stream_executor/cuda/cusparse_10_1.inc:7838:24: error: 'cusparseSpVecDescr_t' was not declared in this scope
 cusparseSpVecSetValues(cusparseSpVecDescr_t spVecDescr, void *values) {
                        ^
./tensorflow/stream_executor/cuda/cusparse_10_1.inc:7838:57: error: expected primary-expression before 'void'
 cusparseSpVecSetValues(cusparseSpVecDescr_t spVecDescr, void *values) {
                                                         ^
./tensorflow/stream_executor/cuda/cusparse_10_1.inc:7838:69: error: expression list treated as compound expression in initializer [-fpermissive]
 cusparseSpVecSetValues(cusparseSpVecDescr_t spVecDescr, void *values) {
                                                                     ^
./tensorflow/stream_executor/cuda/cusparse_10_1.inc:7838:71: error: expected ',' or ';' before '{' token
 cusparseSpVecSetValues(cusparseSpVecDescr_t spVecDescr, void *values) {
                                                                       ^
./tensorflow/stream_executor/cuda/cusparse_10_1.inc:7846:21: error: 'cusparseDnVecDescr_t' was not declared in this scope
 cusparseCreateDnVec(cusparseDnVecDescr_t *dnVecDescr, int64_t size,
                     ^
./tensorflow/stream_executor/cuda/cusparse_10_1.inc:7846:43: error: 'dnVecDescr' was not declared in this scope
 cusparseCreateDnVec(cusparseDnVecDescr_t *dnVecDescr, int64_t size,
                                           ^
./tensorflow/stream_executor/cuda/cusparse_10_1.inc:7846:63: error: expected primary-expression before 'size'
 cusparseCreateDnVec(cusparseDnVecDescr_t *dnVecDescr, int64_t size,
                                                               ^
./tensorflow/stream_executor/cuda/cusparse_10_1.inc:7847:21: error: expected primary-expression before 'void'
                     void *values, cudaDataType valueType) {
                     ^
./tensorflow/stream_executor/cuda/cusparse_10_1.inc:7847:48: error: expected primary-expression before 'valueType'
                     void *values, cudaDataType valueType) {
                                                ^
./tensorflow/stream_executor/cuda/cusparse_10_1.inc:7847:57: error: expression list treated as compound expression in initializer [-fpermissive]
                     void *values, cudaDataType valueType) {
                                                         ^
./tensorflow/stream_executor/cuda/cusparse_10_1.inc:7847:59: error: expected ',' or ';' before '{' token
                     void *values, cudaDataType valueType) {
                                                           ^
./tensorflow/stream_executor/cuda/cusparse_10_1.inc:7856:22: error: 'cusparseDnVecDescr_t' was not declared in this scope
 cusparseDestroyDnVec(cusparseDnVecDescr_t dnVecDescr) {
                      ^
./tensorflow/stream_executor/cuda/cusparse_10_1.inc:7856:55: error: expected ',' or ';' before '{' token
 cusparseDestroyDnVec(cusparseDnVecDescr_t dnVecDescr) {
                                                       ^
./tensorflow/stream_executor/cuda/cusparse_10_1.inc:7864:24: error: 'cusparseDnVecDescr_t' does not name a type
 cusparseDnVecGet(const cusparseDnVecDescr_t dnVecDescr, int64_t *size,
                        ^
./tensorflow/stream_executor/cuda/cusparse_10_1.inc: In function 'cusparseStatus_t cusparseDnVecGet(int, int64_t*, void**, cudaDataType*)':
./tensorflow/stream_executor/cuda/cusparse_10_1.inc:7867:13: error: 'cusparseDnVecDescr_t' does not name a type
       const cusparseDnVecDescr_t, int64_t *, void **, cudaDataType *);
             ^
./tensorflow/stream_executor/cuda/cusparse_10_1.inc: At global scope:
./tensorflow/stream_executor/cuda/cusparse_10_1.inc:7874:30: error: 'cusparseDnVecDescr_t' does not name a type
 cusparseDnVecGetValues(const cusparseDnVecDescr_t dnVecDescr, void **values) {
                              ^
./tensorflow/stream_executor/cuda/cusparse_10_1.inc: In function 'cusparseStatus_t cusparseDnVecGetValues(int, void**)':
./tensorflow/stream_executor/cuda/cusparse_10_1.inc:7876:45: error: 'cusparseDnVecDescr_t' does not name a type
       cusparseStatus_t(CUSPARSEAPI *)(const cusparseDnVecDescr_t, void **);
                                             ^
./tensorflow/stream_executor/cuda/cusparse_10_1.inc: At global scope:
./tensorflow/stream_executor/cuda/cusparse_10_1.inc:7883:24: error: 'cusparseDnVecDescr_t' was not declared in this scope
 cusparseDnVecSetValues(cusparseDnVecDescr_t dnVecDescr, void *values) {
                        ^
./tensorflow/stream_executor/cuda/cusparse_10_1.inc:7883:57: error: expected primary-expression before 'void'
 cusparseDnVecSetValues(cusparseDnVecDescr_t dnVecDescr, void *values) {
                                                         ^
./tensorflow/stream_executor/cuda/cusparse_10_1.inc:7883:69: error: expression list treated as compound expression in initializer [-fpermissive]
 cusparseDnVecSetValues(cusparseDnVecDescr_t dnVecDescr, void *values) {
                                                                     ^
./tensorflow/stream_executor/cuda/cusparse_10_1.inc:7883:71: error: expected ',' or ';' before '{' token
 cusparseDnVecSetValues(cusparseDnVecDescr_t dnVecDescr, void *values) {
                                                                       ^
./tensorflow/stream_executor/cuda/cusparse_10_1.inc: In function 'cusparseStatus_t cusparseCreateCoo(cusparseSpMatDescr**, int64_t, int64_t, int64_t, void*, void*, void*, cusparseIndexType_t, cusparseIndexBase_t, cudaDataType)':
./tensorflow/stream_executor/cuda/cusparse_10_1.inc:7896:70: error: conflicting declaration of C function 'cusparseStatus_t cusparseCreateCoo(cusparseSpMatDescr**, int64_t, int64_t, int64_t, void*, void*, void*, cusparseIndexType_t, cusparseIndexBase_t, cudaDataType)'
                                                cudaDataType valueType) {
                                                                      ^
In file included from tensorflow/stream_executor/cuda/cusparse_stub.cc:16:0:
bazel-out/host/bin/external/local_config_cuda/cuda/_virtual_includes/cuda_headers_virtual/third_party/gpus/cuda/include/cusparse.h:6971:1: note: previous declaration 'cusparseStatus_t cusparseCreateCoo(cusparseSpMatDescr**, int, int, int, void*, void*, void*, cusparseIndexType_t, cusparseIndexBase_t, cudaDataType)'
 cusparseCreateCoo(cusparseSpMatDescr_t* spMatDescr,
 ^
In file included from tensorflow/stream_executor/cuda/cusparse_stub.cc:59:0:
./tensorflow/stream_executor/cuda/cusparse_10_1.inc: In function 'cusparseStatus_t cusparseCooGet(cusparseSpMatDescr_t, int64_t*, int64_t*, int64_t*, void**, void**, void**, cusparseIndexType_t*, cusparseIndexBase_t*, cudaDataType*)':
./tensorflow/stream_executor/cuda/cusparse_10_1.inc:7950:39: error: conflicting declaration of C function 'cusparseStatus_t cusparseCooGet(cusparseSpMatDescr_t, int64_t*, int64_t*, int64_t*, void**, void**, void**, cusparseIndexType_t*, cusparseIndexBase_t*, cudaDataType*)'
                cudaDataType *valueType) {
                                       ^
In file included from tensorflow/stream_executor/cuda/cusparse_stub.cc:16:0:
bazel-out/host/bin/external/local_config_cuda/cuda/_virtual_includes/cuda_headers_virtual/third_party/gpus/cuda/include/cusparse.h:6986:1: note: previous declaration 'cusparseStatus_t cusparseCooGet(cusparseSpMatDescr_t, int*, int*, int*, void**, void**, void**, cusparseIndexType_t*, cusparseIndexBase_t*, cudaDataType*)'
 cusparseCooGet(const cusparseSpMatDescr_t spMatDescr,
 ^
In file included from tensorflow/stream_executor/cuda/cusparse_stub.cc:59:0:
./tensorflow/stream_executor/cuda/cusparse_10_1.inc: In function 'cusparseStatus_t cusparseCreateDnMat(cusparseDnMatDescr**, int64_t, int64_t, int64_t, void*, cudaDataType, cusparseOrder_t)':
./tensorflow/stream_executor/cuda/cusparse_10_1.inc:8047:64: error: conflicting declaration of C function 'cusparseStatus_t cusparseCreateDnMat(cusparseDnMatDescr**, int64_t, int64_t, int64_t, void*, cudaDataType, cusparseOrder_t)'
     void *values, cudaDataType valueType, cusparseOrder_t order) {
                                                                ^
In file included from tensorflow/stream_executor/cuda/cusparse_stub.cc:16:0:
bazel-out/host/bin/external/local_config_cuda/cuda/_virtual_includes/cuda_headers_virtual/third_party/gpus/cuda/include/cusparse.h:7017:1: note: previous declaration 'cusparseStatus_t cusparseCreateDnMat(cusparseDnMatDescr**, size_t, size_t, int64_t, void*, cudaDataType, cusparseOrder_t)'
 cusparseCreateDnMat(cusparseDnMatDescr_t* dnMatDescr,
 ^
In file included from tensorflow/stream_executor/cuda/cusparse_stub.cc:59:0:
./tensorflow/stream_executor/cuda/cusparse_10_1.inc: In function 'cusparseStatus_t cusparseDnMatGet(cusparseDnMatDescr_t, int64_t*, int64_t*, int64_t*, void**, cudaDataType*, cusparseOrder_t*)':
./tensorflow/stream_executor/cuda/cusparse_10_1.inc:8066:75: error: conflicting declaration of C function 'cusparseStatus_t cusparseDnMatGet(cusparseDnMatDescr_t, int64_t*, int64_t*, int64_t*, void**, cudaDataType*, cusparseOrder_t*)'
     int64_t *ld, void **values, cudaDataType *type, cusparseOrder_t *order) {
                                                                           ^
In file included from tensorflow/stream_executor/cuda/cusparse_stub.cc:16:0:
bazel-out/host/bin/external/local_config_cuda/cuda/_virtual_includes/cuda_headers_virtual/third_party/gpus/cuda/include/cusparse.h:7029:1: note: previous declaration 'cusparseStatus_t cusparseDnMatGet(cusparseDnMatDescr_t, size_t*, size_t*, int64_t*, void**, cudaDataType*, cusparseOrder_t*)'
 cusparseDnMatGet(const cusparseDnMatDescr_t dnMatDescr,
 ^
In file included from tensorflow/stream_executor/cuda/cusparse_stub.cc:59:0:
./tensorflow/stream_executor/cuda/cusparse_10_1.inc: In function 'cusparseStatus_t cusparseDnMatSetStridedBatch(cusparseDnMatDescr_t, int, int64_t)':
./tensorflow/stream_executor/cuda/cusparse_10_1.inc:8093:73: error: conflicting declaration of C function 'cusparseStatus_t cusparseDnMatSetStridedBatch(cusparseDnMatDescr_t, int, int64_t)'
     cusparseDnMatDescr_t dnMatDescr, int batchCount, int64_t batchStride) {
                                                                         ^
In file included from tensorflow/stream_executor/cuda/cusparse_stub.cc:16:0:
bazel-out/host/bin/external/local_config_cuda/cuda/_virtual_includes/cuda_headers_virtual/third_party/gpus/cuda/include/cusparse.h:7038:1: note: previous declaration 'cusparseStatus_t cusparseDnMatSetStridedBatch(cusparseDnMatDescr_t, int, size_t)'
 cusparseDnMatSetStridedBatch(cusparseDnMatDescr_t dnMatDescr,
 ^
In file included from tensorflow/stream_executor/cuda/cusparse_stub.cc:59:0:
./tensorflow/stream_executor/cuda/cusparse_10_1.inc: In function 'cusparseStatus_t cusparseDnMatGetStridedBatch(cusparseDnMatDescr_t, int*, int64_t*)':
./tensorflow/stream_executor/cuda/cusparse_10_1.inc:8103:67: error: conflicting declaration of C function 'cusparseStatus_t cusparseDnMatGetStridedBatch(cusparseDnMatDescr_t, int*, int64_t*)'
                              int *batchCount, int64_t *batchStride) {
                                                                   ^
In file included from tensorflow/stream_executor/cuda/cusparse_stub.cc:16:0:
bazel-out/host/bin/external/local_config_cuda/cuda/_virtual_includes/cuda_headers_virtual/third_party/gpus/cuda/include/cusparse.h:7043:1: note: previous declaration 'cusparseStatus_t cusparseDnMatGetStridedBatch(cusparseDnMatDescr_t, int*, size_t*)'
 cusparseDnMatGetStridedBatch(const cusparseDnMatDescr_t dnMatDescr,
 ^
In file included from tensorflow/stream_executor/cuda/cusparse_stub.cc:59:0:
./tensorflow/stream_executor/cuda/cusparse_10_1.inc: At global scope:
./tensorflow/stream_executor/cuda/cusparse_10_1.inc:8113:20: error: 'cusparseSpVecDescr_t' does not name a type
              const cusparseSpVecDescr_t vecX, const cusparseDnVecDescr_t vecY,
                    ^
./tensorflow/stream_executor/cuda/cusparse_10_1.inc:8113:53: error: 'cusparseDnVecDescr_t' does not name a type
              const cusparseSpVecDescr_t vecX, const cusparseDnVecDescr_t vecY,
                                                     ^
./tensorflow/stream_executor/cuda/cusparse_10_1.inc: In function 'cusparseStatus_t cusparseSpVV(cusparseHandle_t, cusparseOperation_t, int, int, void*, cudaDataType, void*)':
./tensorflow/stream_executor/cuda/cusparse_10_1.inc:8116:52: error: 'cusparseSpVecDescr_t' does not name a type
       cusparseHandle_t, cusparseOperation_t, const cusparseSpVecDescr_t,
                                                    ^
./tensorflow/stream_executor/cuda/cusparse_10_1.inc:8117:13: error: 'cusparseDnVecDescr_t' does not name a type
       const cusparseDnVecDescr_t, void *, cudaDataType, void *);
             ^
./tensorflow/stream_executor/cuda/cusparse_10_1.inc: At global scope:
./tensorflow/stream_executor/cuda/cusparse_10_1.inc:8125:11: error: 'cusparseSpVecDescr_t' does not name a type
     const cusparseSpVecDescr_t vecX, const cusparseDnVecDescr_t vecY,
           ^
./tensorflow/stream_executor/cuda/cusparse_10_1.inc:8125:44: error: 'cusparseDnVecDescr_t' does not name a type
     const cusparseSpVecDescr_t vecX, const cusparseDnVecDescr_t vecY,
                                            ^
./tensorflow/stream_executor/cuda/cusparse_10_1.inc: In function 'cusparseStatus_t cusparseSpVV_bufferSize(cusparseHandle_t, cusparseOperation_t, int, int, const void*, cudaDataType, size_t*)':
./tensorflow/stream_executor/cuda/cusparse_10_1.inc:8128:52: error: 'cusparseSpVecDescr_t' does not name a type
       cusparseHandle_t, cusparseOperation_t, const cusparseSpVecDescr_t,
                                                    ^
./tensorflow/stream_executor/cuda/cusparse_10_1.inc:8129:13: error: 'cusparseDnVecDescr_t' does not name a type
       const cusparseDnVecDescr_t, const void *, cudaDataType, size_t *);
             ^
./tensorflow/stream_executor/cuda/cusparse_10_1.inc: At global scope:
./tensorflow/stream_executor/cuda/cusparse_10_1.inc:8137:44: error: 'cusparseDnVecDescr_t' does not name a type
     const cusparseSpMatDescr_t matA, const cusparseDnVecDescr_t vecX,
                                            ^
./tensorflow/stream_executor/cuda/cusparse_10_1.inc:8138:29: error: 'cusparseDnVecDescr_t' does not name a type
     const void *beta, const cusparseDnVecDescr_t vecY, cudaDataType computeType,
                             ^
./tensorflow/stream_executor/cuda/cusparse_10_1.inc:8139:5: error: 'cusparseSpMVAlg_t' has not been declared
     cusparseSpMVAlg_t alg, void *externalBuffer) {
     ^
./tensorflow/stream_executor/cuda/cusparse_10_1.inc: In function 'cusparseStatus_t cusparseSpMV(cusparseHandle_t, cusparseOperation_t, const void*, cusparseSpMatDescr_t, int, const void*, int, cudaDataType, int, void*)':
./tensorflow/stream_executor/cuda/cusparse_10_1.inc:8142:41: error: 'cusparseDnVecDescr_t' does not name a type
       const cusparseSpMatDescr_t, const cusparseDnVecDescr_t, const void *,
                                         ^
./tensorflow/stream_executor/cuda/cusparse_10_1.inc:8143:13: error: 'cusparseDnVecDescr_t' does not name a type
       const cusparseDnVecDescr_t, cudaDataType, cusparseSpMVAlg_t, void *);
             ^
./tensorflow/stream_executor/cuda/cusparse_10_1.inc:8143:49: error: 'cusparseSpMVAlg_t' has not been declared
       const cusparseDnVecDescr_t, cudaDataType, cusparseSpMVAlg_t, void *);
                                                 ^
./tensorflow/stream_executor/cuda/cusparse_10_1.inc: At global scope:
./tensorflow/stream_executor/cuda/cusparse_10_1.inc:8152:44: error: 'cusparseDnVecDescr_t' does not name a type
     const cusparseSpMatDescr_t matA, const cusparseDnVecDescr_t vecX,
                                            ^
./tensorflow/stream_executor/cuda/cusparse_10_1.inc:8153:29: error: 'cusparseDnVecDescr_t' does not name a type
     const void *beta, const cusparseDnVecDescr_t vecY, cudaDataType computeType,
                             ^
./tensorflow/stream_executor/cuda/cusparse_10_1.inc:8154:5: error: 'cusparseSpMVAlg_t' has not been declared
     cusparseSpMVAlg_t alg, size_t *bufferSize) {
     ^
./tensorflow/stream_executor/cuda/cusparse_10_1.inc: In function 'cusparseStatus_t cusparseSpMV_bufferSize(cusparseHandle_t, cusparseOperation_t, const void*, cusparseSpMatDescr_t, int, const void*, int, cudaDataType, int, size_t*)':
./tensorflow/stream_executor/cuda/cusparse_10_1.inc:8157:41: error: 'cusparseDnVecDescr_t' does not name a type
       const cusparseSpMatDescr_t, const cusparseDnVecDescr_t, const void *,
                                         ^
./tensorflow/stream_executor/cuda/cusparse_10_1.inc:8158:13: error: 'cusparseDnVecDescr_t' does not name a type
       const cusparseDnVecDescr_t, cudaDataType, cusparseSpMVAlg_t, size_t *);
             ^
./tensorflow/stream_executor/cuda/cusparse_10_1.inc:8158:49: error: 'cusparseSpMVAlg_t' has not been declared
       const cusparseDnVecDescr_t, cudaDataType, cusparseSpMVAlg_t, size_t *);
                                                 ^
Target //tensorflow/tools/pip_package:build_pip_package failed to build
Use --verbose_failures to see the command lines of failed build steps.
ERROR: /home/code/release/tensorflow-2.3.0/tensorflow/tools/pip_package/BUILD:66:1 C++ compilation of rule '//tensorflow/stream_executor/cuda:cusparse_stub' failed (Exit 1)
INFO: Elapsed time: 678.697s, Critical Path: 218.52s
INFO: 11196 processes: 11196 local.
FAILED: Build did NOT complete successfully


**Provide the exact sequence of commands / steps that you executed before running into the problem**
bazel build --config=opt --config=cuda --copt=-fstack-protector-strong --copt=-fPIC --copt=-U_FORTIFY_SOURCE --copt=-D_FORTIFY_SOURCE=2 --copt=-O3 --linkopt=-Wl,-z,relro --linkopt=-Wl,-z,now --linkopt=-Wl,-z,noexecstack --linkopt=-Wl,--strip-all --cxxopt=""-D_GLIBCXX_USE_CXX11_ABI=0"" //tensorflow/tools/pip_package:build_pip_package

And I also tried:
bazel build --config=opt --config=cuda --cxxopt=""-D_GLIBCXX_USE_CXX11_ABI=0"" //tensorflow/tools/pip_package:build_pip_package

Thank you.


"
45203,tf.linalg.diag_part does not use matrix_diag_part_v2,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 20.04
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): v1.15.3-68-gdf8c55c 1.15.4
- Python version: 3.6.12

**Describe the current behavior**

In tensorflow v1, `tf.linalg.diag_part` does not use `matrix_diag_part_v2`, making impossible to get sub-diagonal or a superdiagonal. 

**Describe the expected behavior**

`tf.linalg.diag_part` should call `matrix_diag_part_v2` for the argument `k` to be considered. 


**Standalone code to reproduce the issue**

```python
import tensorflow as tf
import numpy as np
from tensorflow.python.ops.gen_array_ops import matrix_diag_part_v2

a = tf.reshape(tf.range(1,10),(3,3))
diag =  tf.linalg.diag_part(a,k=0,padding_value=0)
superdiag = tf.linalg.diag_part(a,k=1,padding_value=0)
with tf.Session() as sess:
    d = sess.run(diag)
    sd = sess.run(superdiag)
    assert (d == np.array([1,5,9])).all()
    assert (sd == np.array([2,6])), f""sd:{sd} != [2,6]""
```

Using directly `matrix_diag_part_v2` produces the correct behavior : 

```python
import tensorflow as tf
import numpy as np
from tensorflow.python.ops.gen_array_ops import matrix_diag_part_v2

a = tf.reshape(tf.range(1,10),(3,3))
diag =  matrix_diag_part_v2(a,k=0,padding_value=0)
superdiag = matrix_diag_part_v2(a,k=1,padding_value=0)
with tf.Session() as sess:
    d = sess.run(diag)
    sd = sess.run(superdiag)
    assert (d == np.array([1,5,9])).all()
    assert (sd == np.array([2,6])).all(), f""sd:{sd} != [2,6]""
```


**Other info / logs**

`matrix_diag_v2` seems to be disabled by this line : https://github.com/tensorflow/tensorflow/blob/v1.15.0/tensorflow/python/ops/array_ops.py#L2174

Is it intentional to disable that behavior? If yes, the doc should be updated accordingly. 

"
45202,model.inputs and model.outputs are None when creating a sub-classed model,"### System information

-   **Have I written custom code (as opposed to using a stock example script
    provided in TensorFlow)**: no
-   **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux 4.19.112+ x86_64 - running in Google Colab
-   **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue
    happens on a mobile device**: N/A
-   **TensorFlow installed from (source or binary)**: binary (pip)
-   **TensorFlow version (use command below)**: v2.3.0-0-gb36436b087 2.3.0
-   **Python version**: 3.6.9
-   **Bazel version (if compiling from source)**: N/A
-   **GCC/Compiler version (if compiling from source)**: N/A
-   **CUDA/cuDNN version**: N/A
-   **GPU model and memory**: N/A

### Describe the problem
I created a model using the [sub-classing method](https://www.tensorflow.org/guide/keras/custom_layers_and_models). As I wanted to examine the model inputs and outputs (using `model.inputs` and `model.outputs`), I found them to be `None`. On the contrary, when I created the same model using the [Sequential API](https://www.tensorflow.org/guide/keras/sequential_model), I do manage to see the inputs and outputs (using the aforementioned `inputs/outputs` attributes). 
I also checked these attributes after predicting with the model, and calling to `model.compile` - nothing works, the outputs are still `None`. 

I'd like to know how (or if?) it's possible to examine a sub-classed model's inputs and outputs this way.

### Source code / logs
You can play with the code in this Colab notebook: 
https://colab.research.google.com/drive/1Oq0oF9aITXNGI9iI3mTsJkmDBoKacDB8?usp=sharing

The model creating code is taken from the official TF 2 quickstart guides (with some minor modifications):
https://www.tensorflow.org/tutorials/quickstart/beginner
https://www.tensorflow.org/tutorials/quickstart/advanced

#### example 1 - Sequential API:
```python
import TensorFlow as tf

model = tf.keras.models.Sequential([
  tf.keras.layers.Flatten(input_shape=(28, 28, 1)),
  tf.keras.layers.Dense(128, activation='relu'),
  tf.keras.layers.Dense(10)
])

print(model.inputs)
print(model.outputs)
```
The output:
```
[<tf.Tensor 'flatten_5_input:0' shape=(None, 28, 28, 1) dtype=float32>]
[<tf.Tensor 'dense_11/BiasAdd:0' shape=(None, 10) dtype=float32>]
```

#### example 2 - Sub-Classed Model:
```python
from tensorflow.keras.layers import Dense, Flatten, Conv2D
from tensorflow.keras import Model

class MyModel(Model):
  def __init__(self):
    super(MyModel, self).__init__()
    self.flatten = Flatten(input_shape=(28, 28, 1))
    self.d1 = Dense(128, activation='relu')
    self.d2 = Dense(10)

  def call(self, x):
    x = self.flatten(x)
    x = self.d1(x)
    return self.d2(x)

# Create an instance of the model
model = MyModel()
print(model.inputs)
print(model.outputs)
```
The output:
```
None
None
```

Note: 
I noticed that when I run this code locally, I get `[]` instead of `None`, but the principle still exists. "
45201,"Is there a tool for XLA to convert XLA-HLO-IR to a graph (such as dot for graphviz, or html)?","<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): TF-2.3rc2
- Are you willing to contribute it (Yes/No):Yes



**Describe the feature and the current behavior/state.**
I have noticed that in the path (tensorflow/compiler/xla/tools), many tools are available for debugging the system.
Is there a tool for XLA to convert XLA-HLO-IR to a graph (such as dot for graphviz, or html)? 

**What we have:** I have dumped a XLA-HLO, in the format of text;
**What We want:** I want to convert it to a visualized format, such as dot, and html.
It was noted that I have just found that there is an  interactive tool, namely ""interactive_graphviz"", but it can not convert the data to a dot or html format as we expected.


**Will this change the current api? How?**
No
**Who will benefit with this feature?**
helpful to profile the runtime feature of XLA optimizations
**Any Other info.**
"
45200,Could not load dynamic library 'libcudnn.so.8',"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): CentOS 7.9
- TensorFlow installed from (source or binary): binary
- TensorFlow version: tf-nightly-gpu 2.5.0.dev20201125
- Python version: 3.6
- Installed using virtualenv? pip? conda?: pip
- Bazel version (if compiling from source): ---
- GCC/Compiler version (if compiling from source): ---
- CUDA/cuDNN version: 11.1
- GPU model and memory: 10 x 1080Ti 11GB


I want to create keras model using multiple GPUs.

I have prepared simple code to display visible devices:

```
import os
import tensorflow as tf

os.environ[""CUDA_VISIBLE_DEVICES""]=""7, 8, 9""
tf.config.experimental.list_logical_devices('GPU')
```


But my output is:


```
2020-11-26 10:23:19.183104: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2020-11-26 10:23:22.087731: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2020-11-26 10:23:22.089534: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2020-11-26 10:23:22.894765: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1727] Found device 0 with properties:
pciBusID: 0000:0d:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s
2020-11-26 10:23:22.901688: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1727] Found device 1 with properties:
pciBusID: 0000:0e:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s
2020-11-26 10:23:22.908844: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1727] Found device 2 with properties:
pciBusID: 0000:0f:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s
2020-11-26 10:23:22.908893: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2020-11-26 10:23:22.913327: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2020-11-26 10:23:22.913376: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2020-11-26 10:23:22.914897: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2020-11-26 10:23:22.915190: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2020-11-26 10:23:22.917940: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2020-11-26 10:23:22.918885: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2020-11-26 10:23:22.919011: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory
2020-11-26 10:23:22.919038: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1764] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
```
"
45199,maskrcnn convert error,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Ubuntu 20.04
- TensorFlow installed from (source or binary):binary
- TensorFlow version (or github SHA if from source):2.3.1

**tflite_convert code**

```
import tensorflow as tf

# Convert the model
converter = tf.lite.TFLiteConverter.from_saved_model(""./saved/"")

converter.target_spec.supported_ops = [
    tf.lite.OpsSet.TFLITE_BUILTINS, # enable TensorFlow Lite ops.
    tf.lite.OpsSet.SELECT_TF_OPS] # enable TensorFlow ops.

converter.experimental_new_converter = True
#converter.allow_custom_ops=True
tflite_model = converter.convert()

# Save the model.
with open('model.tflite', 'wb') as f:
  f.write(tflite_model)
```

**the issue information** 
```
2020-11-26 00:41:12.251078: I tensorflow/cc/saved_model/reader.cc:32] Reading SavedModel from: ./saved/
2020-11-26 00:41:12.272903: I tensorflow/cc/saved_model/reader.cc:55] Reading meta graph with tags { serve }
2020-11-26 00:41:12.272975: I tensorflow/cc/saved_model/reader.cc:93] Reading SavedModel debug info (if present) from: ./saved/
2020-11-26 00:41:12.273052: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2020-11-26 00:41:12.342434: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:252] None of the MLIR optimization passes are enabled (registered 0 passes)
2020-11-26 00:41:12.432545: I tensorflow/cc/saved_model/loader.cc:206] Restoring SavedModel bundle.
2020-11-26 00:41:12.978910: I tensorflow/cc/saved_model/loader.cc:277] SavedModel load for tags { serve }; Status: success: OK. Took 727829 microseconds.
2020-11-26 00:41:13.202547: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:194] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2020-11-26 00:41:13.703742: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
loc(""mrcnn_detection/DenseToDenseSetOperation""): error: 'tf.DenseToDenseSetOperation' op is neither a custom op nor a flex op
loc(""mrcnn_detection/DenseToDenseSetOperation_1""): error: 'tf.DenseToDenseSetOperation' op is neither a custom op nor a flex op
2020-11-26 00:41:21.116517: W tensorflow/compiler/mlir/lite/flatbuffer_export.cc:1670] Graph contains TensorArrayGatherV3, TensorArrayReadV3, TensorArrayScatterV3, TensorArraySizeV3, TensorArrayV3, TensorArrayWriteV3 op(s), that use(s) resource type. Currently, the resource type is not natively supported in TFLite. Please consider not using the resource type if there are issues with either TFLite converter or TFLite runtime.
error: failed while converting: 'main': Ops that need custom implementation (enabled via setting the -emit-custom-ops flag):
	tf.DenseToDenseSetOperation {T = i64, device = """", set_operation = ""intersection"", validate_indices = true}
Traceback (most recent call last):
  File ""/usr/local/lib/python3.8/dist-packages/tensorflow/lite/python/convert.py"", line 210, in toco_convert_protos
    model_str = wrap_toco.wrapped_toco_convert(model_flags_str,
  File ""/usr/local/lib/python3.8/dist-packages/tensorflow/lite/python/wrap_toco.py"", line 32, in wrapped_toco_convert
    return _pywrap_toco_api.TocoConvert(
Exception: <unknown>:0: error: loc(""mrcnn_detection/DenseToDenseSetOperation""): 'tf.DenseToDenseSetOperation' op is neither a custom op nor a flex op
<unknown>:0: error: loc(""mrcnn_detection/DenseToDenseSetOperation_1""): 'tf.DenseToDenseSetOperation' op is neither a custom op nor a flex op
<unknown>:0: error: failed while converting: 'main': Ops that need custom implementation (enabled via setting the -emit-custom-ops flag):
	tf.DenseToDenseSetOperation {T = i64, device = """", set_operation = ""intersection"", validate_indices = true}


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""convert.py"", line 13, in <module>
    tflite_model = converter.convert()
  File ""/usr/local/lib/python3.8/dist-packages/tensorflow/lite/python/lite.py"", line 745, in convert
    result = _convert_saved_model(**converter_kwargs)
  File ""/usr/local/lib/python3.8/dist-packages/tensorflow/lite/python/convert.py"", line 636, in convert_saved_model
    data = toco_convert_protos(
  File ""/usr/local/lib/python3.8/dist-packages/tensorflow/lite/python/convert.py"", line 216, in toco_convert_protos
    raise ConverterError(str(e))
tensorflow.lite.python.convert.ConverterError: <unknown>:0: error: loc(""mrcnn_detection/DenseToDenseSetOperation""): 'tf.DenseToDenseSetOperation' op is neither a custom op nor a flex op
<unknown>:0: error: loc(""mrcnn_detection/DenseToDenseSetOperation_1""): 'tf.DenseToDenseSetOperation' op is neither a custom op nor a flex op
<unknown>:0: error: failed while converting: 'main': Ops that need custom implementation (enabled via setting the -emit-custom-ops flag):
	tf.DenseToDenseSetOperation {T = i64, device = """", set_operation = ""intersection"", validate_indices = true}

```

Looking forward to your prompt reply，thanks！"
45198,Tflite pod lint error,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOs 10.15.7
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: 
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): 2.4.0 rc3
- Python version: 
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source): Apple clang version 12.0.0
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
Execute:
1. git checkout v2.4.0-rc3
2. pod lib lint tensorflow/lite/experimental/ios/TensorFlowLiteC.podspec

Error Message:
    - ERROR | [TensorFlowLiteC/Core, TensorFlowLiteC/CoreML, TensorFlowLiteC/Metal, and more...] file patterns: The `vendored_frameworks` pattern did not match any file.

**Describe the expected behavior**
Linter should not have any errors. 

When working on my private podspec, I saw the same error and went back to check the original source code and found this issues. 

I also downloaded the source file `TensorFlowLiteC.tar.gz` specified in the podspec. The root folder of the unzipped data is not `Frameworks` but `TensorFlowLiteC-2.3.0`.

The document [here](https://www.tensorflow.org/lite/guide/build_ios) is outdated. The process of combining `TensorFlowLiteC.framework`, `TensorFlowLiteCCoreML.framework` and `TensorflowLiteCMetal.framework` is not documented. Definitely need some help.

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

1. git checkout v2.4.0-rc3
2. pod lib lint tensorflow/lite/experimental/ios/TensorFlowLiteC.podspec

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
45197,model doesn't learn when using shuffle='batch',"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 20.04
- TensorFlow installed from (source or binary): pip install tf-nightly-gpu==2.5.0.dev20201108
- TensorFlow version (use command below): 2.5.0
- Python version:3.8
- GCC/Compiler version (if compiling from source):9.3.0
- CUDA/cuDNN version:11.1.1/8.0.5
- GPU model and memory:RTX 3090 (24GMiB) driver 455.38



**Describe the current behavior**
Becasue I train my model with data from HDF5 files, so I used model.fit(, , , shuffle='batch'). 

https://www.tensorflow.org/api_docs/python/tf/keras/Sequential: 
""shuffle | Boolean (whether to shuffle the training data before each epoch) or str (for 'batch'). This argument is ignored when x is a generator. 'batch' is a special option for dealing with the limitations of HDF5 data; it shuffles in batch-sized chunks. Has no effect when steps_per_epoch is not None.""

Before I upgrade my hardware, I used tensorflow 1.x as Keras 2.x's backend. My model used shuffle='batch' without any problems. Now, I have a new machine, so I need to transfer my codes. However, the new code doesn't work anymore. 

**Describe the expected behavior**
I used MNIST dataset to show what happended: Code from (https://www.machinecurve.com/index.php/2020/04/13/how-to-use-h5py-and-keras-to-train-with-data-from-hdf5-files/)

**Standalone code to reproduce the issue**
```python
import h5py
from tensorflow.keras.datasets import cifar10
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Flatten, Conv2D
from tensorflow.keras.losses import sparse_categorical_crossentropy
from tensorflow.keras.optimizers import Adam

# Model configuration
batch_size = 50
img_width, img_height, img_num_channels = 28, 28, 1
loss_function = sparse_categorical_crossentropy
no_classes = 10
no_epochs = 25
optimizer = Adam()
validation_split = 0.2
verbosity = 1

# Load MNIST data
f = h5py.File('train.hdf5', 'r')
input_train = f['image'][...]
label_train = f['label'][...]
f.close()
f = h5py.File('test.hdf5', 'r')
input_test = f['image'][...]
label_test = f['label'][...]
f.close()

# Reshape data
input_train = input_train.reshape((len(input_train), img_width, img_height, img_num_channels))
input_test  = input_test.reshape((len(input_test), img_width, img_height, img_num_channels))

# Determine shape of the data
input_shape = (img_width, img_height, img_num_channels)

# Create the model
model = Sequential()
model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))
model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))
model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))
model.add(Flatten())
model.add(Dense(128, activation='relu'))
model.add(Dense(no_classes, activation='softmax'))

# Display a model summary
model.summary()

# Compile the model
model.compile(loss=loss_function,
              optimizer=optimizer,
              metrics=['accuracy'])

# Fit data to model
history = model.fit(input_train, label_train,
            batch_size=batch_size,
            epochs=no_epochs,
            verbose=verbosity,shuffle='batch',
            validation_split=validation_split)

# Generate generalization metrics
score = model.evaluate(input_test, label_test, verbose=0)
print(f'Test loss: {score[0]} / Test accuracy: {score[1]}')


**Other info / logs** Include any logs or source code that would be helpful to
The output is like this 
Model: ""sequential_3""
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_9 (Conv2D)            (None, 26, 26, 32)        320       
_________________________________________________________________
conv2d_10 (Conv2D)           (None, 24, 24, 64)        18496     
_________________________________________________________________
conv2d_11 (Conv2D)           (None, 22, 22, 128)       73856     
_________________________________________________________________
flatten_3 (Flatten)          (None, 61952)             0         
_________________________________________________________________
dense_6 (Dense)              (None, 128)               7929984   
_________________________________________________________________
dense_7 (Dense)              (None, 10)                1290      
=================================================================
Total params: 8,023,946
Trainable params: 8,023,946
Non-trainable params: 0
_________________________________________________________________
Epoch 1/25
960/960 [==============================] - 3s 3ms/step - loss: 6.4279 - accuracy: 0.1099 - val_loss: 2.3022 - val_accuracy: 0.1060
Epoch 2/25
960/960 [==============================] - 3s 3ms/step - loss: 2.3012 - accuracy: 0.1141 - val_loss: 2.3012 - val_accuracy: 0.1060
Epoch 3/25
960/960 [==============================] - 3s 3ms/step - loss: 2.3011 - accuracy: 0.1149 - val_loss: 2.3020 - val_accuracy: 0.1060
Epoch 4/25
960/960 [==============================] - 3s 3ms/step - loss: 2.3010 - accuracy: 0.1142 - val_loss: 2.3021 - val_accuracy: 0.1060
Epoch 5/25
960/960 [==============================] - 3s 3ms/step - loss: 2.3010 - accuracy: 0.1141 - val_loss: 2.3019 - val_accuracy: 0.1060
Epoch 6/25
960/960 [==============================] - 3s 3ms/step - loss: 2.3010 - accuracy: 0.1162 - val_loss: 2.3019 - val_accuracy: 0.1060
Epoch 7/25
960/960 [==============================] - 3s 3ms/step - loss: 2.3012 - accuracy: 0.1139 - val_loss: 2.3020 - val_accuracy: 0.1060
Epoch 8/25
960/960 [==============================] - 3s 3ms/step - loss: 2.3013 - accuracy: 0.1128 - val_loss: 2.3025 - val_accuracy: 0.1060
Epoch 9/25
960/960 [==============================] - 3s 3ms/step - loss: 2.3013 - accuracy: 0.1131 - val_loss: 2.3020 - val_accuracy: 0.1060
Epoch 10/25
960/960 [==============================] - 3s 3ms/step - loss: 2.3011 - accuracy: 0.1156 - val_loss: 2.3021 - val_accuracy: 0.1060
Epoch 11/25
960/960 [==============================] - 3s 3ms/step - loss: 2.3013 - accuracy: 0.1127 - val_loss: 2.3022 - val_accuracy: 0.1060
Epoch 12/25
960/960 [==============================] - 3s 3ms/step - loss: 2.3010 - accuracy: 0.1143 - val_loss: 2.3024 - val_accuracy: 0.1060
Epoch 13/25
960/960 [==============================] - 3s 3ms/step - loss: 2.3012 - accuracy: 0.1131 - val_loss: 2.3025 - val_accuracy: 0.1060
Epoch 14/25
960/960 [==============================] - 3s 3ms/step - loss: 2.3009 - accuracy: 0.1148 - val_loss: 2.3019 - val_accuracy: 0.1060
Epoch 15/25
960/960 [==============================] - 3s 3ms/step - loss: 2.3012 - accuracy: 0.1152 - val_loss: 2.3019 - val_accuracy: 0.1060
Epoch 16/25
960/960 [==============================] - 3s 3ms/step - loss: 2.3009 - accuracy: 0.1149 - val_loss: 2.3020 - val_accuracy: 0.1060
Epoch 17/25
960/960 [==============================] - 3s 3ms/step - loss: 2.3009 - accuracy: 0.1143 - val_loss: 2.3020 - val_accuracy: 0.1060
Epoch 18/25
960/960 [==============================] - 3s 3ms/step - loss: 2.3014 - accuracy: 0.1125 - val_loss: 2.3022 - val_accuracy: 0.1060
Epoch 19/25
960/960 [==============================] - 3s 3ms/step - loss: 2.3011 - accuracy: 0.1147 - val_loss: 2.3019 - val_accuracy: 0.1060
Epoch 20/25
960/960 [==============================] - 3s 3ms/step - loss: 2.3011 - accuracy: 0.1144 - val_loss: 2.3020 - val_accuracy: 0.1060
Epoch 21/25
960/960 [==============================] - 3s 3ms/step - loss: 2.3013 - accuracy: 0.1128 - val_loss: 2.3022 - val_accuracy: 0.1060
Epoch 22/25
960/960 [==============================] - 3s 3ms/step - loss: 2.3012 - accuracy: 0.1122 - val_loss: 2.3024 - val_accuracy: 0.1060
Epoch 23/25
960/960 [==============================] - 3s 3ms/step - loss: 2.3003 - accuracy: 0.1163 - val_loss: 2.3021 - val_accuracy: 0.1060
Epoch 24/25
960/960 [==============================] - 3s 3ms/step - loss: 2.3011 - accuracy: 0.1151 - val_loss: 2.3021 - val_accuracy: 0.1060
Epoch 25/25
960/960 [==============================] - 3s 3ms/step - loss: 2.3012 - accuracy: 0.1131 - val_loss: 2.3021 - val_accuracy: 0.1060
Test loss: 2.3010358810424805 / Test accuracy: 0.11349999904632568


If I changed shuffle='batch' to shuffle=True or shuffle=False
I got convergent results like this

Model: ""sequential""
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d (Conv2D)              (None, 26, 26, 32)        320       
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 24, 24, 64)        18496     
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 22, 22, 128)       73856     
_________________________________________________________________
flatten (Flatten)            (None, 61952)             0         
_________________________________________________________________
dense (Dense)                (None, 128)               7929984   
_________________________________________________________________
dense_1 (Dense)              (None, 10)                1290      
=================================================================
Total params: 8,023,946
Trainable params: 8,023,946
Non-trainable params: 0
_________________________________________________________________
Epoch 1/25
960/960 [==============================] - 5s 3ms/step - loss: 2.3020 - accuracy: 0.9032 - val_loss: 0.0738 - val_accuracy: 0.9786
Epoch 2/25
960/960 [==============================] - 3s 3ms/step - loss: 0.0502 - accuracy: 0.9853 - val_loss: 0.0621 - val_accuracy: 0.9824
Epoch 3/25
960/960 [==============================] - 3s 3ms/step - loss: 0.0333 - accuracy: 0.9896 - val_loss: 0.0811 - val_accuracy: 0.9792
Epoch 4/25
960/960 [==============================] - 3s 3ms/step - loss: 0.0216 - accuracy: 0.9936 - val_loss: 0.0851 - val_accuracy: 0.9805
Epoch 5/25
960/960 [==============================] - 3s 3ms/step - loss: 0.0244 - accuracy: 0.9922 - val_loss: 0.0757 - val_accuracy: 0.9832
Epoch 6/25
960/960 [==============================] - 3s 3ms/step - loss: 0.0139 - accuracy: 0.9956 - val_loss: 0.1344 - val_accuracy: 0.9752
Epoch 7/25
960/960 [==============================] - 3s 3ms/step - loss: 0.0202 - accuracy: 0.9935 - val_loss: 0.1379 - val_accuracy: 0.9779
Epoch 8/25
960/960 [==============================] - 3s 3ms/step - loss: 0.0141 - accuracy: 0.9956 - val_loss: 0.0919 - val_accuracy: 0.9818
Epoch 9/25
960/960 [==============================] - 3s 3ms/step - loss: 0.0125 - accuracy: 0.9962 - val_loss: 0.1184 - val_accuracy: 0.9811
Epoch 10/25
960/960 [==============================] - 3s 3ms/step - loss: 0.0154 - accuracy: 0.9956 - val_loss: 0.1157 - val_accuracy: 0.9832
Epoch 11/25
960/960 [==============================] - 3s 3ms/step - loss: 0.0176 - accuracy: 0.9952 - val_loss: 0.1221 - val_accuracy: 0.9803
Epoch 12/25
960/960 [==============================] - 3s 3ms/step - loss: 0.0101 - accuracy: 0.9976 - val_loss: 0.1170 - val_accuracy: 0.9822
Epoch 13/25
960/960 [==============================] - 3s 3ms/step - loss: 0.0124 - accuracy: 0.9969 - val_loss: 0.1216 - val_accuracy: 0.9846
Epoch 14/25
960/960 [==============================] - 3s 3ms/step - loss: 0.0094 - accuracy: 0.9974 - val_loss: 0.1048 - val_accuracy: 0.9848
Epoch 15/25
960/960 [==============================] - 3s 3ms/step - loss: 0.0067 - accuracy: 0.9982 - val_loss: 0.1130 - val_accuracy: 0.9835
Epoch 16/25
960/960 [==============================] - 3s 3ms/step - loss: 0.0122 - accuracy: 0.9974 - val_loss: 0.1463 - val_accuracy: 0.9835
Epoch 17/25
960/960 [==============================] - 3s 3ms/step - loss: 0.0091 - accuracy: 0.9976 - val_loss: 0.1685 - val_accuracy: 0.9833
Epoch 18/25
960/960 [==============================] - 3s 3ms/step - loss: 0.0110 - accuracy: 0.9977 - val_loss: 0.1224 - val_accuracy: 0.9840
Epoch 19/25
960/960 [==============================] - 3s 3ms/step - loss: 0.0036 - accuracy: 0.9989 - val_loss: 0.1733 - val_accuracy: 0.9838
Epoch 20/25
960/960 [==============================] - 3s 3ms/step - loss: 0.0109 - accuracy: 0.9978 - val_loss: 0.1539 - val_accuracy: 0.9859
Epoch 21/25
960/960 [==============================] - 3s 3ms/step - loss: 0.0074 - accuracy: 0.9982 - val_loss: 0.1791 - val_accuracy: 0.9826
Epoch 22/25
960/960 [==============================] - 3s 3ms/step - loss: 0.0085 - accuracy: 0.9986 - val_loss: 0.2264 - val_accuracy: 0.9830
Epoch 23/25
960/960 [==============================] - 3s 3ms/step - loss: 0.0124 - accuracy: 0.9979 - val_loss: 0.1722 - val_accuracy: 0.9840
Epoch 24/25
960/960 [==============================] - 3s 3ms/step - loss: 0.0089 - accuracy: 0.9984 - val_loss: 0.1472 - val_accuracy: 0.9851
Epoch 25/25
960/960 [==============================] - 3s 3ms/step - loss: 0.0048 - accuracy: 0.9988 - val_loss: 0.2005 - val_accuracy: 0.9847
Test loss: 0.18761441111564636 / Test accuracy: 0.9829999804496765
```"
45196,Didn't find op for builtin opcode 'GATHER' version '1',"@tensorflow/micro

**System information**
- Host OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu Linux 20.04
- TensorFlow installed from (source or binary): binary python3 pip3
- Tensorflow version (commit SHA if source): 2.4-rc3
- Target platform (e.g. Arm Mbed OS, Arduino Nano 33 etc.): arm mbed-os disco_f746ng 

**Describe the problem**
```
  TfLiteStatus allocate_status = interpreter->AllocateTensors();
```
fails with
```
Didn't find op for builtin opcode 'GATHER' version '1'                                                
Failed to get registration from op code GATHER                                               
Failed starting model allocation.
AllocateTensors() failed
```
**Please provide the exact sequence of commands/steps when you ran into the problem**

All attachments can be found at: [https://github.com/crumpf-sdsu/gath-op-bug-report](https://github.com/crumpf-sdsu/gath-op-bug-report)
Basically, I used https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/time_series.ipynb to create a split window single step (+1hr predictive) linear model using the NOAA dataset (a weather data localized to my zip code).  The model performs adequately for my needs in Jupyter.  The model is successfully converted to tflite (no quant).   Standard tflite micro interpreter setup() (from hello world) fails to AllocateTensors with  missing GATHER op using AllOpsResolver.  

```
void setup() {
...
  // This pulls in all the operation implementations we need.
  // NOLINTNEXTLINE(runtime-global-variables)
  static tflite::AllOpsResolver resolver;

  // Build an interpreter to run the model with.
  static tflite::MicroInterpreter static_interpreter(
      model, resolver, tensor_arena, kTensorArenaSize, error_reporter);
  interpreter = &static_interpreter;

  // Allocate memory from the tensor_arena for the model's tensors.
  TfLiteStatus allocate_status = interpreter->AllocateTensors();
  if (allocate_status != kTfLiteOk) {
    TF_LITE_REPORT_ERROR(error_reporter, ""AllocateTensors() failed"");
    return;
  }
```
Aside from AllOpsResolver documentation/customizations, I didn't find much information about missing ops such as this and figured I'd ask to triple check my approach and get some advice here."
45195,//tensorflow/lite/python:lite_v2_test failed,"
With current master branch (commit 38d042b105bf06c89cfc2a5c0412983215b4faf3), TEST //tensorflow/lite/python:lite_v2_test failed.

> bazelisk test //tensorflow/lite/python:lite_v2_test

> ERROR: /mirror-tensorflow/tensorflow/lite/python/BUILD:205:1: in deps attribute of py_test rule //tensorflow/lite/python:lite_v2_test: '//tenso
rflow/lite/kernels/hashtable:hashtable_op_kernels' does not have mandatory providers: 'py' or 'PyInfo'
ERROR: Analysis of target '//tensorflow/lite/python:lite_v2_test' failed; build aborted: Analysis of target '//tensorflow/lite/python:lite_v2_test' failed

"
45194,tf.data.experimental.make_csv_dataset changes list of column names if it is not hard coded,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): CentOS release 6.10
- TensorFlow version (use command below): Version: 2.2.0
- Python version: Python 3.8.3 (default, Jul  2 2020, 16:21:59)
- GPU model and memory: NVIDIA, 64 GB RAM



**Describe the current behavior**
I am trying to use tf.data.experimental.make_csv_dataset to read data from a very large csv file (million rows and million columns). If I hard code select_columns in the following sample code with select_columns=['col1','col2','col3']) then tf.data.experimental.make_csv_dataset works fine. But, when I extract column names and put them in a python list, My_Variables in the following line of code, then tf.data.experimental.make_csv_dataset changes My_Variables python list and it can not find label_name anymore:

    def get_dataset(file_path):
      dataset = tf.data.experimental.make_csv_dataset(
          file_path,
          batch_size=64, # Artificially small to make examples easier to show.
          select_columns=My_Variables,
          label_name= 'outcome',
          na_value=""?"",
          num_epochs=1,
          num_rows_for_inference=64,
         ignore_errors=True)
      return dataset



**Describe the expected behavior**

Expected behavior after running tf.data.experimental.make_csv_dataset: 

    My_Variables=['col1','col2','col3',...,'outcome']

current behavior after running tf.data.experimental.make_csv_dataset: 

    My_Variables=[1,2,3,4,5,6,7,...,10345]

Error message:

    raise ValueError(""`label_name` provided must be one of the columns."")
    ValueError: `label_name` provided must be one of the columns.


I can not hard code variables in tf.data.experimental.make_csv_dataset function. I need to extract column names, put them in a python list and then used it inside tf.data.experimental.make_csv_dataset but this method breaks tf.data.experimental.make_csv_dataset"
45192,"Migrating from TF1 to TF2, loss not going down using F-RCNN Resnet50","So I've been trying to migrate from Tensorflow Version 1.14 to 2.3.0. My work usually involves performing transfer learning on Faster R-CNN Resnet 50 Coco Trained Models for object detection. When I used to train on Tensorflow 1.14 using the adam optimizer, I would see the loss go down after 30k steps of training. However, on TF2, the loss seems to be more of a straight line. 


It would help me greatly if someone could help me figure out why the loss is not going down. Thanks in advance. :)

TF2 Tensorboard Total Loss on [faster_rcnn_resnet50_v1_1024x1024_coco17_tpu-8](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md)
![image](https://user-images.githubusercontent.com/32026314/100305789-6e000780-2fd4-11eb-8c23-2599a735b480.png)



TF1 Tensorboard Total Loss on [faster_rcnn_resnet50_coco_2018_01_28](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf1_detection_zoo.md)
![Screenshot from 2020-11-23 10-49-57](https://user-images.githubusercontent.com/32026314/100306629-6c374380-2fd6-11eb-9279-a75a8f01c5b5.png)





**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): NO
- OS Platform and Distribution: Ubuntu 20.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NO
- TensorFlow installed from (source or binary): PIP3
- TensorFlow version (use command below): 2.3.0
- Python version: 3.8
- CUDA/cuDNN version: 10.1
- GPU model and memory: 980 Ti, 6GB

"
45191,TFLite Interpreter crashes with null TfLiteDelegatePtr,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): r2.3 but consistent with latter versions
- Are you willing to contribute it (Yes/No): Yes

**Describe the feature and the current behavior/state.**
`tflite::Interpreter` does not check nullity of `TfLiteDelegate*`.
It would be better to check it and return ErrorCode for `null`.

https://github.com/tensorflow/tensorflow/blob/595d575c237368c925229c05e933d62808330ca2/tensorflow/lite/core/subgraph.cc#L1486-L1513

**Will this change the current api? How?**

https://github.com/tensorflow/tensorflow/blob/595d575c237368c925229c05e933d62808330ca2/tensorflow/lite/core/subgraph.cc#L1486

or

https://github.com/tensorflow/tensorflow/blob/595d575c237368c925229c05e933d62808330ca2/tensorflow/lite/interpreter.cc#L385

or (for r2.3 I am using)

https://github.com/tensorflow/tensorflow/blob/r2.3/tensorflow/lite/interpreter.cc#L358

returns `TfLiteError` for `null` input.

**Who will benefit with this feature?**

App developers who are using TensorflowLite SDK would find bugs more quickly.
Thanks!

**Any Other info.**
"
45188,443,"Thank you for submitting a TensorFlow documentation issue. Per our GitHub
policy, we only address code/doc bugs, performance issues, feature requests, and
build/installation issues on GitHub.

The TensorFlow docs are open source! To get involved, read the documentation
contributor guide: https://www.tensorflow.org/community/contribute/docs

## URL(s) with the issue:

Please provide a link to the documentation entry, for example:
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/MyMethod

## Description of issue (what needs changing):

### Clear description

For example, why should someone use this method? How is it useful?

### Correct links

Is the link to the source code correct?

### Parameters defined

Are all parameters defined and formatted correctly?

### Returns defined

Are return values defined?

### Raises listed and defined

Are the errors defined? For example,
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises

### Usage example

Is there a usage example?

See the API guide: https://www.tensorflow.org/community/contribute/docs_ref
on how to write testable usage examples.

### Request visuals, if applicable

Are there currently visuals? If not, will it clarify the content?

### Submit a pull request?

Are you planning to also submit a pull request to fix the issue? See the docs
contributor guide: https://www.tensorflow.org/community/contribute/docs,
docs API guide: https://www.tensorflow.org/community/contribute/docs_ref and the
docs style guide: https://www.tensorflow.org/community/contribute/docs_style
"
45187,EarlyStopping with baseline doesn't set weights,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Manjaro latest
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.3.1
- Python version: 3.8.6

**Describe the current behavior**

When passing an `EarlyStopping` callback to `model.fit()` with `baseline` parameter set and `restore_best_weights=True`, if the monitored quantity doesn't reach the baseline, best weights are never set and an exception is thrown when trying to restore them.

**Describe the expected behavior**

Something a bit more sensible like not trying to restore best weights if those are `None`, or throwing an exception that explicitly indicates the problem.

**Standalone code to reproduce the issue**
```python
from tensorflow.keras.optimizers import SGD
import numpy as np
from tensorflow import keras
from tensorflow.keras.layers import Dense, Softmax

from tensorflow.keras.callbacks import EarlyStopping

x_train = np.array([[0, 0],
                    [0, 1],
                    [1, 0],
                    [1, 1]])
y_train = np.array([0, 1, 1, 0])

x_val = np.array([[0, 0], [0, 1]])
y_val = np.array([1, 0])

model = keras.Sequential([
    Dense(20),
    Dense(1),
    Softmax()
])

model.compile(optimizer=SGD(), loss='mse')
model.fit(x_train, y_train,
          validation_data=(x_val, y_val),
          epochs=5,
          callbacks=[
              EarlyStopping(monitor='val_loss',
                            baseline=0.5,
                            patience=3,
                            restore_best_weights=True)
          ])
```

**Other info / logs**
Traceback:
``` File ""early_stopping.py"", line 24, in <module>
    model.fit(x_train, y_train,
  File ""/usr/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py"", line 108, in _method_wrapper
    return method(self, *args, **kwargs)
  File ""/usr/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py"", line 1137, in fit
    callbacks.on_epoch_end(epoch, epoch_logs)
  File ""/usr/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py"", line 416, in on_epoch_end
    callback.on_epoch_end(epoch, numpy_logs)
  File ""/usr/lib/python3.8/site-packages/tensorflow/python/keras/callbacks.py"", line 1677, in on_epoch_end
    self.model.set_weights(self.best_weights)
  File ""/usr/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py"", line 1805, in set_weights
    if expected_num_weights != len(weights):
TypeError: object of type 'NoneType' has no len()
```"
45186,Optimizing a custom loss in TF1 vs TF2,"I'm trying to migrate from TF1 to TF2 and encountering performance issues. The plan is to optimize a custom loss function (without neural networks), but it is much faster on TF1 compared to TF2. Am I doing something wrong?

Below I tried to include a minimum reproducible example. On Colab TF1 takes 0.061 seconds, while TF2 takes 0.277 seconds.

[TF1 colab notebook](https://colab.research.google.com/drive/1H0bPxIrSvD9V0IHppNpeQRwzHP4qbal9?usp=sharing)

[TF2 colab notebook](https://colab.research.google.com/drive/1tZ9aHXc9EA6otTyRIVBFhK8ez3yjXaA2?usp=sharing)


(Adding the actual code for future reference)

```
#TF1 version
%tensorflow_version 1.x
import tensorflow as tf
print(tf.__version__)


import time

vocabulary_size = int(1e3) #must be bigger than 8


def calculateloss(in1, in2):
  vectors1 = tf.nn.embedding_lookup(embeddings, in1)
  vectors2 = tf.nn.embedding_lookup(embeddings, in2)
  #
  rep1 = tf.reduce_mean(vectors1, axis=0)
  rep2 = tf.reduce_mean(vectors2, axis=0)
  #
  return tf.norm(rep1-rep2)
  
 
graph = tf.Graph()

with graph.as_default():
  with tf.name_scope('MainVariable') as scope:
    embeddings = tf.Variable(   
    tf.random_uniform([vocabulary_size, 100], -1, 1),
    dtype=tf.float32)
  #
  with tf.name_scope('CalculateLoss') as scope:
    inputdata1 = [1,2,3,4]
    inputdata2 = [5,6,7,8]
    #
    loss = calculateloss(inputdata1, inputdata2)
    optimizer = tf.train.AdagradOptimizer(1).minimize(loss)


#Training


niter = 100

with tf.Session(graph=graph) as sess: #
  sess.run(tf.global_variables_initializer())
  start_time = time.time()
  for i in range(niter):
    _, new_loss  = sess.run([optimizer, loss])
    #print(i, ""\t"", new_loss)


print('Elapsed time: ' + str(time.time() - start_time))
```

```
#TF2 version

import tensorflow as tf
import time


vocabulary_size = int(1e3) #must be bigger than 8
niter = 100


@tf.function
def calculateloss(in1, in2):
  vectors1 = tf.nn.embedding_lookup(embeddings, in1)
  vectors2 = tf.nn.embedding_lookup(embeddings, in2)
  #
  rep1 = tf.reduce_mean(vectors1, axis=0)
  rep2 = tf.reduce_mean(vectors2, axis=0)
  #
  return tf.norm(rep1-rep2)
  
  
with tf.name_scope('MainVariable') as scope:
  embeddings = tf.Variable( 
    tf.random.uniform([vocabulary_size, 100], -1, 1),
    dtype=tf.float32)



@tf.function
def train_step(inputdata1, inputdata2, inputvars, optimizer):
  with tf.GradientTape() as tape:
    loss = calculateloss(inputdata1, inputdata2)
  gradients = tape.gradient(loss, inputvars)
  opt.apply_gradients(zip(gradients, inputvars))
  return loss


trainable_variables = [embeddings]
opt = tf.keras.optimizers.Adagrad(learning_rate=1)



#Start Training run
start_time = time.time()

inputdata1 = [1,2,3,4]
inputdata2 = [5,6,7,8]

for i in range(niter):
  loss = train_step(inputdata1, inputdata2, trainable_variables, opt)
  #tf.print(i, "" loss:"", loss)


print('Elapsed time: ' + str(time.time() - start_time))
```"
45185,ESP32 LyraT: Audio data/I2S issue,"@tensorflow/micro

**System information**
- Host OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS 10.15.7
- TensorFlow installed from (source or binary): source
- Tensorflow version (commit SHA if source): 2.x
- Target platform (e.g. Arm Mbed OS, Arduino Nano 33 etc.): ESP32 LyraT v4.3

Hello :) 

I try to get the micro_speech example running on the LyraT v4.3. The esp toolchain is set up and running. The model works (at least if I feed it the `g_yes_micro_f2e59fea_nohash_1_data`) and I was able to replace the model and use my own with different words and stuff. But I can't get it to work using a microphone.

I printed the `GenerateMicroFeatures`-function results to the console. Most of the time, all frequencies are 0 (or -128). When I printed the absolute sum of the `g_audio_output_buffer` (printing the entire buffer would be too slow), this is also often times 0. 

The only thing I really tried to change was the `pin_config` of the `audio_provider`:
```
  i2s_pin_config_t pin_config = {
      // .bck_io_num = 26,    // IIS_SCLK
      // .ws_io_num = 32,     // IIS_LCLK
      // .data_out_num = -1,  // IIS_DSIN
      // .data_in_num = 33,   // IIS_DOUT
      .bck_io_num = GPIO_NUM_5,
      .ws_io_num = GPIO_NUM_25,
      .data_out_num = GPIO_NUM_26,
      .data_in_num = GPIO_NUM_35,
  };
```
These should be the pins for the LyraT v4.3 but it resulted the warning ""No new slices"".
I also tried to change the `I2S_NUM` from 1 to 0, which made no difference either.

Any idea on what's going wrong or how to check the incoming audio data?

I hope I provided some useful information. If there's anything else of interest, please let me know!

Thanks in advance :)"
45184,how to modify the input shape of existing model file again？,"tensorflow version: 2.3.0

When there is an existing model file, how to modify its input shape again?
Sometimes an existing pre-trained language model has a fixed input final dimension, but changing the final dimension has no effect.
an example in this link：
https://colab.research.google.com/drive/1BtOSLKYbElZ2EUEtLW3ahTZWeGN8QC3r?usp=sharing"
45181,"Possible problematic example in the guide ""Automatic Differentiation""","## URL(s) with the issue: 

https://www.tensorflow.org/guide/autodiff

## Description of issue (what needs changing):

In the calculation of gradient by passing a dictionary of variables, 

```python
my_vars = {
    'w': tf.Variable(tf.random.normal((3, 2)), name='w'),
    'b': tf.Variable(tf.zeros(2, dtype=tf.float32), name='b')
}

grad = tape.gradient(loss, my_vars)
grad['b']
```

It seems inappropriate since `my_vars` creates two new variables, but the pre-defined `loss` is not calculated from these two variables, and it turns out that no output from `grab['b']`. 

I think there might be two possible modifications,

- use the pre-define `w` and `b` in the dictionary

```python
my_vars = {
    'w': w,
    'b': b
}
grad = tape.gradient(loss, my_vars)
grad['b']
```

- define a new loss using `my_vars`

```python
with tf.GradientTape(persistent=True) as tape:
    y = x @ my_vars['w'] + my_vars['b']
    loss = tf.reduce_mean(y**2)
grad = tape.gradient(loss, my_vars)
grad['b']
```

Note that `persistent=True` is particularly specified, so I guess the first choice might more agree with the author's initial purpose.
"
45180,Errors when loading a model having keras.Lambda,"**System information**
- Linux Ubuntu 16.04
- TensorFlow 2.3.0
- Python version: 3.6

## Problem description
While creating function for model creation using Functional API I noticed an interesting behaviour on how the graph is saved and loaded when you use keras.layers.Lambda as one of the layers. 

Currently, tf2 makes it impossible to change batch_size within the model definition, so let's say you have multiple images and you want to make a decision based on these images from different points. 

E.g. You have 10 different shots from the camera (always the same point of view for corresponding shots) and you want to decide whether a phone is damaged. 

### Current behaviour
When creating model within the scope of notebook within it is saved it is possible to save model (`keras.save_model()`) and load it (`keras.load_model()`) in a different notebook. 

When extracting a function to another file (let's say model.py) and performing the same scope: create->train->`keras.save_model()` and then loading the model in a different notebook, model throws errors. 

### Expected behaviour 
Working saving and loading for a model defined in a different location. I also tried that with model subclassing and I am almost certain that it also does not work. 

### Reproduced problem with a proposed solution
https://colab.research.google.com/drive/16LfnXVFHs9jNTOm0FUGjjnwAUczmOYdC?usp=sharing

## Proposed solution/ My workaround
From what I found the issue occurs partly because of keras.layers.Lambda is saving bytecode of the inner function. As the function is simple Python lambda not using any 3rd party functions it is only needed to focus on serialization and override module value of the function: 
```python
def _serialize_function_to_config(self, inputs, allow_raw=False):
    if isinstance(inputs, python_types.LambdaType):
      output = generic_utils.func_dump(inputs)
      output_type = 'lambda'
      module = inputs.__module__
    elif callable(inputs):
      output = inputs.__name__
      output_type = 'function'
      module = inputs.__module__
    elif allow_raw:
      output = inputs
      output_type = 'raw'
      module = None
    else:
      raise ValueError(
          'Invalid input for serialization, type: %s ' % type(inputs))

    return output, output_type, module
```

by subclassing:
```python
class SafeSaveLambda(keras.layers.Lambda):
    def _serialize_function_to_config(self, inputs, allow_raw=False):
        output, output_type, module = super()._serialize_function_to_config(inputs, allow_raw)
        
        return output, output_type, ""__main__""
```
and using SafeSaveLambda in place of ``keras.layers.Lambda``. Solution and investigation are available in GoogleColab. "
45179,Lamda Layer seems to ignore output_shape parameter,"Hello Tensorflow/Keras - Team,

I noticed some strange behaviour when I tried to create a simple sequential model with a lambda layer in it. In my example below I tried to make the code as simple as possible to clearify the problem.

My Lambda function is as simple as the minimal example from keras page:

```
def square_it(x):
    return (x ** 2)
```

To calculate the output shape I defined the following function (please note that I tried to explicit set an output shape that is wrong in my example. But from my understanding this value should overwrite any shape calculation from the lambda layer and return the output shape I defined):

```
def output_of_lambda(input_shape):
    return (None, None, 10, 20)
```

Creating the lambda layer as follows:

`lambda_layer = layers.Lambda(square_it, output_shape=output_of_lambda)`


creating an example model:

```
model_2 = keras.Sequential(
    [
        layers.Input(shape=(784)),
        layers.Dense(2, activation=""relu"", name=""layer1""),
        lambda_layer,
        layers.Dense(4, name=""layer5""),
    ]
)
```


And finally call the summary

`model_2.summary()`



Now I would expect to find my customized shape inside the summary or at least an error that the shape is wrong but instead it gives me:

```

Layer (type)                 Output Shape              Param #   
=================================================================
layer1 (Dense)               (None, 2)                 1570      
_________________________________________________________________
lambda (Lambda)              (None, 2)                 0         
_________________________________________________________________
layer5 (Dense)               (None, 4)                 12        
=================================================================
```



But I would have expected something like this:

```

Layer (type)                 Output Shape              Param #   
=================================================================
layer1 (Dense)               (None, 2)                 1570      
_________________________________________________________________
lambda (Lambda)              (None, None, 10, 20)                 0         
_________________________________________________________________
layer5 (Dense)               (None, 4)                 12        
=================================================================
```

For me it seems that the output_shape parameter has no effect at all but instead the value will always be automatically calculated.

I am using POP OS 20.04 
Tensorflow: 2.3.1
Python: 3.8.2
No Cuda was used in this example."
45178,tensorflow.keras MirroredStrategy hangs without error message,"Unexpected hangs occurs, running adapted https://keras.io/guides/distributed_training/
**System information**
- Have I written custom code : https://keras.io/guides/distributed_training/ 
- OS Platform and Distribution : Windows 10 pro (build 19041) 
- CPU Intel: 2x Intel Xeon 6140 18 Cores (36 logical) 
- System Memory : 384 GB
- TensorFlow installed from (source or binary): pip installed
- TensorFlow version (use command below): v2.3.0-54-gfcc4b966f1 2.3.1
- Python version: 3.8.5
- CUDA/cuDNN version: CUDA 10.1 / cuDNN 7
- GPU model and memory: 4 x Tesla V100-SXM2-32GB 

**Describe the current behavior**
Training hangs without any message when starting the learning, when large dataset are used as inputs.

**Describe the expected behavior**

Training is expected to work in the same circumstances even with large dataset

**Standalone code to reproduce the issue**
Changing the get_dataset() to get a larger dataset from sample dataset following:

num_val_samples = 1000
and then adding the 2 lines:
    x_train = x_train[:-num_val_samples]
    y_train = y_train[:-num_val_samples]
    x_train = np.concatenate([x_train for i in range(50)])    
    y_train = np.concatenate([y_train for i in range(50)])    
    return (
        tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(batch_size),
        tf.data.Dataset.from_tensor_slices((x_val, y_val)).batch(batch_size),
        tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(batch_size),
    )

When the oversize is 46 it runs flawlessly, when setting to 47 or higher it just hangs with no error messages

The stragegy is defined with, to work on our Windows HPC : 
cross_tower_ops = tf.distribute. ReductionToOneDevice()
strategy = tf.distribute.MirroredStrategy(devices=['/gpu:0','/gpu:1','/gpu:2','gpu:3'],
                                            cross_device_ops=cross_tower_ops)
"
45177,Output of tflite is not correct,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Arch Linux
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No
- TensorFlow installed from (source or binary):   package manager
- TensorFlow version (use command below): 2.3.0
- Python version: 3.8.5
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
The output of tflite is not correct.
**Describe the expected behavior**
The output should match the result of equation.

**Standalone code to reproduce the issue**
```
# Original model definition
""""""
model = tf.keras.Sequential([
  tf.keras.layers.InputLayer(input_shape=(2, 2, 1)),
  tf.keras.layers.Conv2D(filters=1, kernel_size=(2, 2), use_bias = True, name = 'EX_Conv_1')
])
""""""

# Run tflite model
import tensorflow as tf
import numpy as np

img = np.array([[-2,2],
                [3,1]],dtype = np.int8)

img = np.expand_dims(img, axis = -1)

interpreter = tf.lite.Interpreter(model_path = 'xx.tflite') # you may download the file in attachment

interpreter.allocate_tensors()

img = img / 255.
input_scale, input_zero_point = interpreter.get_tensor_details()[0][""quantization""]
resized_image = img / input_scale + input_zero_point
interpreter.set_tensor(0, np.expand_dims(resized_image, axis = 0).astype(interpreter.get_tensor_details()[0][""dtype""]))

interpreter.invoke()
```
[model.zip](https://github.com/tensorflow/tensorflow/files/5595639/model.zip)


**Other info / logs**
By using interpreter.get_tensor_details() and  interpreter.get_tensor(k), we should get following info:
Input:
array([[[[-86],
         [ 84]],
        [[126],
         [ 41]]]], dtype=int8)

Intput scale:   x_s = 9.22722028917633e-05
Input zero point: x_zp = -1

CNN weight:
array([[[[1],
         [3]],
        [[5],
         [7]]]], dtype=int8)

CNN weight scale: w_s = 0.0005354330642148852
CNN weight zero point: w_zp = 0

CNN bias:
array([3441], dtype=int32)
CNN bias scale: b_s = 2.906211049591434e-09
CNN bias zero point: b_zp = 0

Output scale: z_s = 2.7681662118084205e-07
Output zero point: z_zp =  -122

If I understand correctly, the quantized output should be calculated as:
output_quant =  {(x_s * w_s) \*[(-86 - x_zp)\*(1-w_zp) + (84-x_zp)\*(3-w_zp) +(126-x_zp)\*(5-w_zp) + (41-x_zp)\*(7-w_zp)] + b_s\*(3441-b_zp)} / z_s - z_zp 
= [(x_s*w_s)\*(-85\*1+85\*3+127\*5+42\*7)+b_s\*(3441)] / z_s-122 = 110.2729521400995 ->(int)-> 110

While the actual output of tflite shows 127."
45176,How can I build tensorflow C++ API on x86 platform,"Thanks, I have compiled tensorflow C++ API on window10. But, the tensorflow_cc.dll is x64, it could not be used on my project. Is any methods to build a x86 version? I'm appreciating for your reply.
"
45175,Google Colab with TPU Compilation failure: Dynamic Spatial Convolution is not supported,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Google Colab
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): v2.3.0-0-gb36436b087 2.3.0
- Python version: Python 3.6.9
- Bazel version (if compiling from source): -
- GCC/Compiler version (if compiling from source):-
- CUDA/cuDNN version:-
- GPU model and memory:-

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
Here is Colab notebook to reproduce the issue. I am trying to train MobileFaceNet model, which I modified to use MobileNet v1. It trains fine on my local computer with 1070 Ti, but the speed is too slow. I am using MSRA dataset, truncated to 1763749 entries. So, I wanted to try using TPU in Colab. I can run the code now, but on the beginning of the first epoch I get the following error:

  (6) Invalid argument: {{function_node __inference_train_function_230773}} Compilation failure: Dynamic Spatial Convolution is not supported: lhs shape is f32[32,<=114,<=114,<=3] 
	 [[{{node mobile_face_net/conv1/Conv2D}}]]
	TPU compilation failed
	 [[tpu_compile_succeeded_assert/_18136726471139321858/_5]]
	 [[tpu_compile_succeeded_assert/_18136726471139321858/_5/_185]]
  (7) Invalid argument: {{function_node __inference_train_function_230773}} Compilation failure: Dynamic Spatial Convolution is not supported: lhs shape is f32[32,<=114,<=114,<=3] 
	 [[{{node mobile_face_net/conv1/Conv2D}}]]
	TPU compilation failed
	 [[tpu_compile_succeeded_assert/_18136726471139321858/_5]]
	 [[tpu_compile_succeeded_assert/_18136726471139321858/_5/_199]]
  (8) Invalid argument: {{function_node __inference_train_function_2307 ... [truncated]

You can see the full output in the Colab notebook 
https://colab.research.google.com/drive/1mwWbgA__rHpnEJK82Ih5acAv4aM_nRKE?usp=sharing

**Describe the expected behavior**
Model training and evaluating properly with TPU in Colab,

**Standalone code to reproduce the issue**
https://colab.research.google.com/drive/1mwWbgA__rHpnEJK82Ih5acAv4aM_nRKE?usp=sharing
"
45173,TPUEstimator does not update meta-weights,"**System information**

- OS Platform and Distribution: Debian GNU/Linux 9.11 (stretch)
- TensorFlow version: 2.1.0
- Python version: 3.5.3

I train a neural network using `TPUEstimator`. In `model_fn`, losses are stored in `losses` list. After the end of an epoch, meta-weights `theta` should be updated using `losses`. But for the entire epoch, only one tensor is added to `losses` (`len(losses) = 1`) and `theta` remains the same (`theta==theta_prev = True`).

Here is [gist](https://gist.github.com/KirillAI/ed88ac43b3da1643629b08e76bd0db5c) with the complete code. Part of `model_fn`:

```
...

    def update_theta():
        global losses
        if len(losses) > 1:
            losses_by_updates = [[] for _ in range(num_updates)]
            for i in range(num_tasks):
                for j in range(num_updates):
                    losses_by_updates[j].append(losses[i*num_updates+j])
            losses_by_updates = [tf.reduce_sum(loss) / tf.to_float(num_tasks) for loss in losses_by_updates]
            gradients = theta_optimizer.compute_gradients(losses_by_updates[-1])
            with tf.variable_scope(tf.get_variable_scope(), reuse=tf.AUTO_REUSE):
                theta_op = theta_optimizer.apply_gradients(gradients)
            weights = copy_theta_to_weights()
            return theta_op
        else:
            return tf.no_op()
...

    loss = 0.0
    for key in logits_train_dic:
        logit_train = logits_train_dic[key]
        loss += tf.square(labels[key]-logit_train)
    loss_op = tf.reduce_mean(loss)
    losses.append(loss_op)

...
```

Is there any way to write loss to a list inside `model_fn`? Or maybe there is some other way to update the meta-weights using `TPUEstimator`?
"
45171,GFile does not create file when nothing is written.,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS Catalina
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA
- TensorFlow installed from (source or binary): binary (pip3)
- TensorFlow version (use command below): v2.3.0-54-gfcc4b966f1 2.3.1
- Python version: 3.8.2
- Bazel version (if compiling from source): NA
- GCC/Compiler version (if compiling from source): NA
- CUDA/cuDNN version: NA
- GPU model and memory: NA

**Describe the current behavior**

`tf.io.gfile.GFile` does nothing to the filesystem when it is closed without any write operations:
```python
with tf.io.gfile.GFile('foo', 'wb') as fp:
  fp.write('test')  # 'foo' is created.

with tf.io.gfile.GFile('bar', 'wb'):
  pass  # 'bar' is not created.
```

**Describe the expected behavior**

The same behavior with builtin `open`: creates a file even if no write operation is invoked.

**Standalone code to reproduce the issue**
Already described above.

**Other info / logs**
NA"
45170,SubProcess ended with return code: 4294967295 with tensorflow-gpu 2.4.0rc cuda11.0 cudnn8.0.2 on windows 10,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: --
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.4.0rc3
- Python version: 3.8.5
- Bazel version (if compiling from source): --
- GCC/Compiler version (if compiling from source): -- 
- CUDA/cuDNN version: CUDA11.0 cudnn-11.0-windows-x64-v8.0.2.39 graphics driver version: 457.30
- GPU model and memory: RTX 3070 8G

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
A lot of **I tensorflow/core/platform/windows/subprocess.cc:308] SubProcess ended with return code: 4294967295** are printed when run tf code on windows 10.
**Describe the expected behavior**
I have no idea of what the meaning of these logs. And when I ran the same code on other machines with RTX2070s or RTX 2080Ti or GTX1080Ti and tensorflow-gpu 2.3,   these logs hadn't been shown.

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.
```python
import tensorflow as tf
import numpy as np
from tensorflow.keras import layers
from tensorflow.keras.models import Sequential

physical_devices = tf.config.list_physical_devices('GPU')
tf.config.experimental.set_memory_growth(physical_devices[0], True)

x = np.random.normal(size=(100, 28, 28, 1)).astype(np.float32)
y = np.zeros([100, 10], dtype=np.float32)
y[:, 1] = 1.

train_ds = tf.data.Dataset.from_tensor_slices((x, y)).shuffle(buffer_size=100).batch(32)
num_classes = 10

model = Sequential([
  layers.Conv2D(16, 3, padding='same', activation='relu'),
  layers.MaxPooling2D(),
  layers.Conv2D(32, 3, padding='same', activation='relu'),
  layers.MaxPooling2D(),
  layers.Conv2D(64, 3, padding='same', activation='relu'),
  layers.MaxPooling2D(),
  layers.Flatten(),
  layers.Dense(128, activation='relu'),
  layers.Dense(num_classes)
])
model.compile(optimizer='adam',
              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])
epochs=3
history = model.fit(
  train_ds,
  epochs=epochs
)
```

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

Here is the logs:
```
C:\Users\dell\Anaconda3\envs\tf24rcpy38\python.exe F:/python_ws/helloworld/main.py
2020-11-25 13:14:29.035547: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudart64_110.dll
2020-11-25 13:14:31.301152: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2020-11-25 13:14:31.301719: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library nvcuda.dll
2020-11-25 13:14:31.330039: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:65:00.0 name: GeForce RTX 3070 computeCapability: 8.6
coreClock: 1.815GHz coreCount: 46 deviceMemorySize: 8.00GiB deviceMemoryBandwidth: 417.29GiB/s
2020-11-25 13:14:31.330233: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudart64_110.dll
2020-11-25 13:14:31.338262: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublas64_11.dll
2020-11-25 13:14:31.338376: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublasLt64_11.dll
2020-11-25 13:14:31.341810: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cufft64_10.dll
2020-11-25 13:14:31.342848: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library curand64_10.dll
2020-11-25 13:14:31.350072: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusolver64_10.dll
2020-11-25 13:14:31.352437: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusparse64_11.dll
2020-11-25 13:14:31.353100: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudnn64_8.dll
2020-11-25 13:14:31.353270: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2020-11-25 13:14:31.357024: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-11-25 13:14:31.357735: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:65:00.0 name: GeForce RTX 3070 computeCapability: 8.6
coreClock: 1.815GHz coreCount: 46 deviceMemorySize: 8.00GiB deviceMemoryBandwidth: 417.29GiB/s
2020-11-25 13:14:31.357961: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudart64_110.dll
2020-11-25 13:14:31.358056: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublas64_11.dll
2020-11-25 13:14:31.358145: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublasLt64_11.dll
2020-11-25 13:14:31.358240: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cufft64_10.dll
2020-11-25 13:14:31.358335: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library curand64_10.dll
2020-11-25 13:14:31.358452: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusolver64_10.dll
2020-11-25 13:14:31.358577: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusparse64_11.dll
2020-11-25 13:14:31.358702: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudnn64_8.dll
2020-11-25 13:14:31.358878: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2020-11-25 13:14:32.004910: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-11-25 13:14:32.005024: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2020-11-25 13:14:32.005085: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2020-11-25 13:14:32.005286: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6177 MB memory) -> physical GPU (device: 0, name: GeForce RTX 3070, pci bus id: 0000:65:00.0, compute capability: 8.6)
2020-11-25 13:14:32.006266: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
Epoch 1/3
2020-11-25 13:14:32.533116: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2020-11-25 13:14:32.625497: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublas64_11.dll
2020-11-25 13:14:33.613410: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublasLt64_11.dll
2020-11-25 13:14:33.619608: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudnn64_8.dll
2020-11-25 13:14:35.296892: I tensorflow/core/platform/windows/subprocess.cc:308] SubProcess ended with return code: 0

2020-11-25 13:14:35.310216: I tensorflow/core/platform/windows/subprocess.cc:308] SubProcess ended with return code: 4294967295

2020-11-25 13:14:35.310607: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Internal: ptxas exited with non-zero error code -1, output: 
Relying on driver to perform ptx compilation. 
Modify $PATH to customize ptxas location.
This message will be only logged once.
2020-11-25 13:14:35.320291: I tensorflow/core/platform/windows/subprocess.cc:308] SubProcess ended with return code: 4294967295

2020-11-25 13:14:35.331970: I tensorflow/core/platform/windows/subprocess.cc:308] SubProcess ended with return code: 4294967295

# ...(lots of SubProcess ended with return code: 4294967295)

2020-11-25 13:14:36.014622: I tensorflow/core/platform/windows/subprocess.cc:308] SubProcess ended with return code: 4294967295

2020-11-25 13:14:36.230275: I tensorflow/core/platform/windows/subprocess.cc:308] SubProcess ended with return code: 4294967295

2020-11-25 13:14:36.231899: I tensorflow/stream_executor/cuda/cuda_blas.cc:1838] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
2020-11-25 13:14:36.289355: I tensorflow/core/platform/windows/subprocess.cc:308] SubProcess ended with return code: 4294967295

2020-11-25 13:14:36.302906: I tensorflow/core/platform/windows/subprocess.cc:308] SubProcess ended with return code: 4294967295

2020-11-25 13:14:36.315136: I tensorflow/core/platform/windows/subprocess.cc:308] SubProcess ended with return code: 4294967295

# ...(lots of SubProcess ended with return code: 4294967295)

1/4 [======>.......................] - ETA: 16s - loss: 2.3410 - accuracy: 0.0000e+002020-11-25 13:14:37.514428: I tensorflow/core/platform/windows/subprocess.cc:308] SubProcess ended with return code: 4294967295

# ...(lots of SubProcess ended with return code: 4294967295)

4/4 [==============================] - 7s 591ms/step - loss: 1.7706 - accuracy: 0.5053
Epoch 2/3
4/4 [==============================] - 0s 6ms/step - loss: 0.0604 - accuracy: 1.0000
Epoch 3/3
4/4 [==============================] - 0s 5ms/step - loss: 8.0053e-05 - accuracy: 1.0000

Process finished with exit code 0
```

I use **...(lots of SubProcess ended with return code: 4294967295)** to represents many lines of ""SubProcess ended with return code: 4294967295"" for saving space.
"
45169,Compile label_wav.cc file for speech recognition,"This is the file location location: tensorflow/examples/speech_recognition/label_wav.cc

Can you please provide steps to compile this file and run for speech recognition."
45168,TFlite minimal failed ,"I have already build TFlite minimal from [here ](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/examples/minimal) with cmake in vscode.
And I download the model **mobilenet** from [here](https://www.tensorflow.org/lite/models/image_classification/overview) .

When I try to use ./minimal like this  `./minimal mobilenet_v1_1.0_224_quant.tflite`,it raised an error: Could not open './mobilenet_v1_1.0_224_quant.tflite'.

It happened in Mmap_Allocation.cc:
```
MMAPAllocation::MMAPAllocation(const char* filename,
                               ErrorReporter* error_reporter)
    : Allocation(error_reporter, Allocation::Type::kMMap),
      mmapped_buffer_(MAP_FAILED) {
  mmap_fd_ = open(filename, O_RDONLY);
  if (mmap_fd_ == -1) {
    error_reporter_->Report(""Could not open '%s'."", filename);
    return;
  }
```

any advice is helpful,thx."
45167,tensorflow linear regression error blows up,"I am trying to fit a very simple linear regression model using tensorflow. However, the loss (mean squared error) blows up instead of reducing to zero.

First, I generate my data:
`x_data = np.random.uniform(high=10,low=0,size=100)
y_data = 3.5 * x_data -4 + np.random.normal(loc=0, scale=2,size=100)`

Then, I define the computational graph:
`X = tf.placeholder(dtype=tf.float32, shape=100)
Y = tf.placeholder(dtype=tf.float32, shape=100)
m = tf.Variable(1.0)
c = tf.Variable(1.0)
Ypred = m*X + c
loss = tf.reduce_mean(tf.square(Ypred - Y))
optimizer = tf.train.GradientDescentOptimizer(learning_rate=.1)
train = optimizer.minimize(loss)`

Finally, run it for 100 epochs:
`steps = {}
steps['m'] = []
steps['c'] = []

losses=[]

for k in range(100):
    _m = session.run(m)
    _c = session.run(c)
    _l = session.run(loss, feed_dict={X: x_data, Y:y_data})
    session.run(train, feed_dict={X: x_data, Y:y_data})
    steps['m'].append(_m)
    steps['c'].append(_c)
    losses.append(_l)`

However, when I plot the losses, I get:
![image](https://user-images.githubusercontent.com/42157989/100177859-6de50680-2f05-11eb-9232-11fef76ae197.png)
"
45165,how to handle non-tail recursive in tf when using control flow,"This template is for miscellaneous issues not covered by the other issue categories.

For questions on how to work with TensorFlow, or support for problems that are not verified bugs in TensorFlow, please go to [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).

If you are reporting a vulnerability, please use the [dedicated reporting process](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md).

For high-level discussions about TensorFlow, please post to discuss@tensorflow.org, for questions about the development or internal workings of TensorFlow, or if you would like to know how to contribute to TensorFlow, please post to developers@tensorflow.org.

Hi,  I am learning tensorflow and I am curious whether there is non-tail recursion in tf when using control flow
The forward prop is generally loop, tail recursion, etc., but after the derivation, will there be non-tail recursion in the backprop?  How to deal with it？
Very much looking forward to your reply."
45164,mbed build broken with upgrade to Python 3.9 as part of CI,"@tensorflow/micro

https://github.com/tensorflow/tensorflow/commit/bdde0e95363f7799dc9d59eb9e01d66b3ad836e2 updated the docker image used for TFLM for the CI servers. This update to Python 3.9 resulted in the mbed failing with the following error:
```
[mbed] Auto-installing missing Python modules (jsonschema, mbed_cloud_sdk, jinja2, mbed_ls, mbed_host_tests, mbed_greentea, pyelftools, manifest_tool, icetea, pycryptodome, pyusb, cmsis_pack_manager, cryptography, click, cbor)...
Traceback (most recent call last):
  File ""/workspace/tensorflow/lite/micro/tools/make/gen/mbed_cortex-m4/prj/hello_world/mbed/mbed-os/tools/make.py"", line 30, in <module>
    from tools.utils import args_error
  File ""/workspace/tensorflow/lite/micro/tools/make/gen/mbed_cortex-m4/prj/hello_world/mbed/mbed-os/tools/utils.py"", line 33, in <module>
    from intelhex import IntelHex
  File ""/usr/local/lib/python3.9/site-packages/intelhex/__init__.py"", line 44, in <module>
    from intelhex.compat import (
  File ""/usr/local/lib/python3.9/site-packages/intelhex/compat.py"", line 60, in <module>
    array_tobytes = getattr(array.array, ""tobytes"", array.array.tostring)
AttributeError: type object 'array.array' has no attribute 'tostring'
[mbed] ERROR: ""/usr/local/bin/python"" returned error.
       Code: 1
       Path: ""/workspace/tensorflow/lite/micro/tools/make/gen/mbed_cortex-m4/prj/hello_world/mbed""
       Command: ""/usr/local/bin/python -u /workspace/tensorflow/lite/micro/tools/make/gen/mbed_cortex-m4/prj/hello_world/mbed/mbed-os/tools/make.py -t GCC_ARM -m DISCO_F746NG --source . --build ./BUILD/DISCO_F746NG/GCC_ARM""
       Tip: You could retry the last command with ""-v"" flag for verbose output
---
```
"
45163,MirrorStrategy incompatible with tf.Estimator when pulling model from tf hub,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): 
Yes

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Linux Ubuntu 16.04

- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
binary Docker image - tensorflow/tensorflow:2.3.1-gpu

- TensorFlow version (use command below):
v2.3.0-54-gfcc4b966f1 2.3.1

- Python version:
Python 3.6.9

- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
cuda: 10.1, V10.1.243
CUDNN_MAJOR 7
CUDNN_MINOR 6
CUDNN_PATCHLEVEL 5

- GPU model and memory:
GeForce GTX 1060 6GB x 2


**Describe the current behavior**
When running estimator which has a hub.KerasLayer defined in the model_fn, using a mirrored strategy to train fails with a ""TypeError: Expected tf.group() expected Tensor arguments not 'None' with type '<class 'NoneType'>"". 

Some other notes:
* Using a single device strategy trains without issue.
* Running without a hub.KerasLayer defined in the model_fn using mirrored strategy also trains without issue.
* Tried using a a couple different hub.KerasLayers and both failed in mirrored strategy - 
   * https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/3
   * https://tfhub.dev/google/nnlm-en-dim50/2

It seems to an issue with how the weights are being initialized when using a hub.KerasLayer in the model_fn when using a mirrored strategy. Maybe global_variables() isn't pulling in the relevant variables?


**Describe the expected behavior**
The estimator should train in both the one device strategy and the mirrored strategy.

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

Dockerfile:
```
FROM tensorflow/tensorflow:2.3.1-gpu AS tf_build
RUN python3 -m pip install tensorflow-hub==0.10.0
```

temp.py:
```python
import tensorflow as tf
import tensorflow_hub as hub
import numpy as np

num_examples = 100
str_len = 5
num_labels = 3
batch_size = 4


def model_fn(features, labels, mode):
  bert_layer = hub.KerasLayer(
    'https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/3',
    trainable=True
  )
  encoder_inputs = dict(
    input_word_ids=features['input_word_ids'],
    input_mask=features['input_mask'],
    input_type_ids=features['input_type_ids']
  )
  encoder_outputs = bert_layer(encoder_inputs)
  logits = encoder_outputs['pooled_output']

  dense_layer = tf.keras.layers.Dense(
    num_labels, activation=None, dtype=tf.float32)
  logits = dense_layer(logits)

  loss = tf.nn.softmax_cross_entropy_with_logits(
    labels=features['labels'], logits=logits)
  loss = tf.reduce_mean(loss)

  global_step = tf.compat.v1.train.get_or_create_global_step()
  optimizer = tf.compat.v1.train.AdamOptimizer()
  train_op = optimizer.minimize(loss=loss, global_step=global_step)

  probs = tf.nn.softmax(logits)

  return tf.estimator.EstimatorSpec(
    mode=mode,
    loss=loss,
    train_op=train_op,
    predictions={'probs': probs}
  )


strategy = tf.distribute.MirroredStrategy()
# strategy = tf.distribute.OneDeviceStrategy(device='/gpu:0')
run_config = tf.estimator.RunConfig(
  model_dir='./tmp',
  save_summary_steps=1000,
  log_step_count_steps=1,
  save_checkpoints_secs=1000,
  keep_checkpoint_max=1,
  train_distribute=strategy,
)

est = tf.estimator.Estimator(model_fn=model_fn, config=run_config)


def input_fn():
  labels = np.zeros((num_examples, num_labels))
  labels[np.arange(num_examples), np.random.randint(low=0, high=num_labels)] = 1

  features = dict(
    input_word_ids=np.random.randint(
      low=1, high=100, size=(num_examples, str_len), dtype='int32'),
    input_mask=np.zeros((num_examples, str_len), dtype='int32'),
    input_type_ids=np.zeros((num_examples, str_len), dtype='int32'),
    labels=labels.astype('float32'),
  )

  dataset = tf.data.Dataset.from_tensor_slices(features)
  return dataset.repeat().batch(batch_size)


est.train(input_fn, steps=500)
```

to run:
build docker image:
```
docker build . -t temp_image/temp_image:latest
```
run script:
```
docker run --gpus all -it -v ${PWD}:/tmp -w /tmp --rm temp_image/temp_image:latest python temp.py
```
**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

stack trace:
```
2020-11-25 01:06:04.045230: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-11-25 01:06:05.718785: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-11-25 01:06:05.762730: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:04:00.0 name: GeForce GTX 1060 6GB computeCapability: 6.1
coreClock: 1.7085GHz coreCount: 10 deviceMemorySize: 5.93GiB deviceMemoryBandwidth: 178.99GiB/s
2020-11-25 01:06:05.763811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 1 with properties: 
pciBusID: 0000:81:00.0 name: GeForce GTX 1060 6GB computeCapability: 6.1
coreClock: 1.7085GHz coreCount: 10 deviceMemorySize: 5.94GiB deviceMemoryBandwidth: 178.99GiB/s
2020-11-25 01:06:05.763864: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-11-25 01:06:05.766507: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-11-25 01:06:05.768582: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-11-25 01:06:05.768936: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-11-25 01:06:05.771694: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-11-25 01:06:05.773286: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-11-25 01:06:05.778866: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2020-11-25 01:06:05.782227: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0, 1
2020-11-25 01:06:05.795975: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2100095000 Hz
2020-11-25 01:06:05.806344: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5b3c870 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-11-25 01:06:05.806381: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-11-25 01:06:06.064338: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5ba86c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-11-25 01:06:06.064388: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce GTX 1060 6GB, Compute Capability 6.1
2020-11-25 01:06:06.064401: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): GeForce GTX 1060 6GB, Compute Capability 6.1
2020-11-25 01:06:06.065488: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:04:00.0 name: GeForce GTX 1060 6GB computeCapability: 6.1
coreClock: 1.7085GHz coreCount: 10 deviceMemorySize: 5.93GiB deviceMemoryBandwidth: 178.99GiB/s
2020-11-25 01:06:06.066152: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 1 with properties: 
pciBusID: 0000:81:00.0 name: GeForce GTX 1060 6GB computeCapability: 6.1
coreClock: 1.7085GHz coreCount: 10 deviceMemorySize: 5.94GiB deviceMemoryBandwidth: 178.99GiB/s
2020-11-25 01:06:06.066202: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-11-25 01:06:06.066235: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10
2020-11-25 01:06:06.066257: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-11-25 01:06:06.066278: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-11-25 01:06:06.066298: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-11-25 01:06:06.066324: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-11-25 01:06:06.066346: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2020-11-25 01:06:06.068886: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0, 1
2020-11-25 01:06:06.068937: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-11-25 01:06:07.467433: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-11-25 01:06:07.467507: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 1 
2020-11-25 01:06:07.467523: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N N 
2020-11-25 01:06:07.467533: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 1:   N N 
2020-11-25 01:06:07.469936: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5547 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1060 6GB, pci bus id: 0000:04:00.0, compute capability: 6.1)
2020-11-25 01:06:07.472078: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 5548 MB memory) -> physical GPU (device: 1, name: GeForce GTX 1060 6GB, pci bus id: 0000:81:00.0, compute capability: 6.1)
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/multi_device_iterator_ops.py:339: get_next_as_optional (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Iterator.get_next_as_optional()` instead.
WARNING:tensorflow:Efficient allreduce is not supported for 1 IndexedSlices
WARNING:tensorflow:Efficient allreduce is not supported for 1 IndexedSlices
WARNING:tensorflow:AutoGraph could not transform <function _combine_distributed_scaffold.<locals>.<lambda> at 0x7fa56ae5a158> and will run it as-is.
Cause: could not parse the source code:

      lambda scaffold: scaffold.ready_op, args=(grouped_scaffold,))

This error may be avoided by creating the lambda in a standalone statement.

To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
WARNING:tensorflow:AutoGraph could not transform <function _combine_distributed_scaffold.<locals>.<lambda> at 0x7fa56ae5a158> and will run it as-is.
Cause: could not parse the source code:

      lambda scaffold: scaffold.ready_op, args=(grouped_scaffold,))

This error may be avoided by creating the lambda in a standalone statement.

To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
WARNING:tensorflow:Issue encountered when serializing variables.
Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.
'NoneType' object has no attribute 'name'
WARNING:tensorflow:Issue encountered when serializing variables.
Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.
'NoneType' object has no attribute 'name'
WARNING:tensorflow:Issue encountered when serializing trainable_variables.
Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.
'NoneType' object has no attribute 'name'
WARNING:tensorflow:Issue encountered when serializing trainable_variables.
Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.
'NoneType' object has no attribute 'name'
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/util.py:96: DistributedIteratorV1.initialize (from tensorflow.python.distribute.input_lib) is deprecated and will be removed in a future version.
Instructions for updating:
Use the iterator's `initializer` property instead.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/util.py:96: DistributedIteratorV1.initialize (from tensorflow.python.distribute.input_lib) is deprecated and will be removed in a future version.
Instructions for updating:
Use the iterator's `initializer` property instead.
Traceback (most recent call last):
  File ""temp.py"", line 76, in <module>
    est.train(input_fn, steps=500)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 349, in train
    loss = self._train_model(input_fn, hooks, saving_listeners)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1173, in _train_model
    return self._train_model_distributed(input_fn, hooks, saving_listeners)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1235, in _train_model_distributed
    self._config._train_distribute, input_fn, hooks, saving_listeners)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1349, in _actual_train_model_distributed
    saving_listeners)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py"", line 1507, in _train_with_estimator_spec
    log_step_count_steps=log_step_count_steps) as mon_sess:
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py"", line 604, in MonitoredTrainingSession
    stop_grace_period_secs=stop_grace_period_secs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py"", line 1038, in __init__
    stop_grace_period_secs=stop_grace_period_secs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py"", line 749, in __init__
    self._sess = _RecoverableSession(self._coordinated_creator)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py"", line 1231, in __init__
    _WrappedSession.__init__(self, self._create_session())
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py"", line 1236, in _create_session
    return self._sess_creator.create_session()
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py"", line 902, in create_session
    self.tf_sess = self._session_creator.create_session()
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py"", line 660, in create_session
    self._scaffold.finalize()
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py"", line 200, in finalize
    default_init_op)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py"", line 297, in get_or_default
    op = default_constructor()
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py"", line 196, in default_init_op
    variables.global_variables_initializer(),
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py"", line 3290, in global_variables_initializer
    return variables_initializer(global_variables())
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py"", line 3267, in variables_initializer
    return control_flow_ops.group(*[v.initializer for v in var_list], name=name)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_ops.py"", line 2923, in group
    ""'%s' with type '%s'"" % (inp, type(inp)))
TypeError: Expected tf.group() expected Tensor arguments not 'None' with type '<class 'NoneType'>'
```
"
45162,"Training a tf.keras.Model, with a tf.data.Dataset mapped with a randomly selected action from a large list of actions (callables provided by the user) takes a lot of time to start, if it ever does.","**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):

Yes, I have, there's a colab notebook below with the custom code.

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):

colab notebook
- TensorFlow installed from (source or binary):

colab default version 2.3.0

- TensorFlow version (use command below):

2.3.0

- Python version:

3.6.9

- GPU model and memory:

It happens using any of the GPUs available in Colab : Nvidia K80s, T4s, P4s and P100s, or even when I'm not using GPU

**Describe the current behavior**

Training a tf.keras.Model, with a tf.data.Dataset mapped with a custom augmentator, which randomly selects an action from a large list of actions (callables provided during the instantiation of the augmentator) takes a lot of time to start, if it ever does.

If it ever manages to start training (more than 20 minutes), then it takes even more time to start the epoch 3, epoch 5, epoch 7, etc.



**Describe the expected behavior**

Training should start fast as usual, and shouldn't have overhead to start in some epochs.

**Standalone code to reproduce the issue**
I have created a colab with about 40 lines of code in which the code can be reproduced: 

https://colab.research.google.com/drive/1FyNuTlX6puKIosWPNojcEN9zZi9-60Ve?usp=sharing

**Other info**


A little bit more information about the colab contents and the issue here: 


- Context a RandomAugmentationPolicy object can be instantiated with a list of callables, and is used to map a dataset with tf.data.Dataset.map. For each img in the dataset, it randomly samples one of its actions, and augments the img.

- Problem : When the length of the list of actions provided to instantiate a RandomAugmentationPolicy object is about 24 or more, training a tf.keras.Model using model.fit never starts the epoch 3 when running on colab.  When running on an ubuntu machine (aws p3.2xlarge) with a CPU that has 8 cores it never starts epoch 7.

- Sample code to reproduce the issue : The code in the colab first defines the RandomAugmentationPolicy class previously mentioned, then it created a mocked dataset, and it then tries to train a model tf.keras.Model.fit.

- Note : The only reasonable way I found to apply the 'selected_action' (L22 class definition), is to iterate over all the actions and augment the img when the action idx is equal to the desired action.



Thank you in advance for your help with this issue.



"
45158,int32 instead of int32_t in  tensorflow/tensorflow/lite/kernels/internal/common.h ,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Devuan Beowulf (Debian 10)
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): 2.5.0
- Python version: 3.7.3
- Bazel version (if compiling from source): 3.6.0
- GCC/Compiler version (if compiling from source): (Debian 8.3.0-6) 8.3.0
- CUDA/cuDNN version: NA
- GPU model and memory: NA

**Describe the current behavior**

Line 192 of  tensorflow/tensorflow/lite/kernels/internal/common.h  references int_32

     int32x4x4_t input_val, int32 quantized_multiplier, int shift) { 
                                              ^^^^^
compilation shows int32 is undefined 

**Describe the expected behavior**

It should use int32_t
    int32x4x4_t input_val, int32_t quantized_multiplier, int shift) {
                                             ^^^^^^
**Standalone code to reproduce the issue**

Any compilation attempt should fail

**Other info / logs** 

NA
"
45157,"""Error: Found an unshardable source dataset"" when using Mirrored Strategy with train on batch","**System information**
- Have I written custom code: Custom
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 20.04
- TensorFlow installed from (source or binary): Tested from compiled source and binary
- TensorFlow version (use command below): 2.4.0rc2
- Python version: 3.9/3.8/3.7
- Bazel version (if compiling from source): 3.7.0
- GCC/Compiler version (if compiling from source): 9.3.0/7
- CUDA/cuDNN version: 11.1/10.1
- GPU model and memory: RTX 3090/ RTX 2080

**Describe the current behavior**
When using MirroredStrategy with Keras, it produces a lot of outputs (see below) as described in this issue #42146. For each batch, it keeps printing the same logs with the error `Error: Found an unshardable source dataset`
I tried to disable the `tf.data.experimental.AutoShardPolicy.OFF` on `train_dataset` or to set it to DATA, but it seems to not have any effect (probable because the `for loop` unpack the train dataset)
It works without any problem on TF 2.3.1

**Describe the expected behavior**
I expect to have the same behavior as on TF 2.3.1: no extensive printed log, no error. Have it works with the default shard policy.
Or at least, to find a way to apply the shard policy on the two subset train_images, train_labels

**Standalone code to reproduce the issue**
```
from tensorflow.keras import datasets, layers, models
import tensorflow as tf

options = tf.data.Options()
options.experimental_distribute.auto_shard_policy = tf.data.experimental.AutoShardPolicy.DATA
(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()
train_images, test_images = train_images / 255.0, test_images / 255.0
train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))
train_dataset = train_dataset.with_options(options)
train_dataset = train_dataset.batch(32)

strategy = tf.distribute.MirroredStrategy()
with strategy.scope():
    model = models.Sequential()
    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))
    model.add(layers.MaxPooling2D((2, 2)))
    model.add(layers.Conv2D(64, (3, 3), activation='relu'))
    model.add(layers.MaxPooling2D((2, 2)))
    model.add(layers.Conv2D(64, (3, 3), activation='relu'))
    model.add(layers.Flatten())
    model.add(layers.Dense(64, activation='relu'))
    model.add(layers.Dense(10))

    model.compile(optimizer='adam',
                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
                  metrics=['accuracy'])


for train_images, train_labels in train_dataset:
    history = model.train_on_batch(train_images, train_labels)
```

**Other info / logs** 
```
2020-11-24 17:17:49.116426: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2020-11-24 17:17:49.885169: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2020-11-24 17:17:49.885621: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2020-11-24 17:17:49.917150: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1727] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce RTX 3090 computeCapability: 8.6
coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.69GiB deviceMemoryBandwidth: 871.81GiB/s
2020-11-24 17:17:49.917174: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2020-11-24 17:17:49.918707: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2020-11-24 17:17:49.918727: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2020-11-24 17:17:49.919263: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2020-11-24 17:17:49.919382: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2020-11-24 17:17:49.920901: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.11
2020-11-24 17:17:49.921285: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2020-11-24 17:17:49.921350: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2020-11-24 17:17:49.922684: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1869] Adding visible gpu devices: 0
2020-11-24 17:17:49.923076: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-11-24 17:17:49.924740: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2020-11-24 17:17:49.925430: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1727] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce RTX 3090 computeCapability: 8.6
coreClock: 1.695GHz coreCount: 82 deviceMemorySize: 23.69GiB deviceMemoryBandwidth: 871.81GiB/s
2020-11-24 17:17:49.925441: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2020-11-24 17:17:49.925448: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2020-11-24 17:17:49.925455: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2020-11-24 17:17:49.925462: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2020-11-24 17:17:49.925468: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2020-11-24 17:17:49.925474: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.11
2020-11-24 17:17:49.925480: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2020-11-24 17:17:49.925486: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2020-11-24 17:17:49.926781: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1869] Adding visible gpu devices: 0
2020-11-24 17:17:49.926800: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2020-11-24 17:17:50.236484: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-11-24 17:17:50.236514: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1273]      0 
2020-11-24 17:17:50.236519: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1286] 0:   N 
2020-11-24 17:17:50.238508: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1413] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 22185 MB memory) -> physical GPU (device: 0, name: GeForce RTX 3090, pci bus id: 0000:01:00.0, compute capability: 8.6)
2020-11-24 17:17:51.610137: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:656] In AUTO-mode, and switching to DATA-based sharding, instead of FILE-based sharding as we cannot find appropriate reader dataset op(s) to shard. Error: Found an unshardable source dataset: name: ""TensorDataset/_2""
op: ""TensorDataset""
input: ""Placeholder/_0""
input: ""Placeholder/_1""
attr {
  key: ""Toutput_types""
  value {
    list {
      type: DT_DOUBLE
      type: DT_UINT8
    }
  }
}
attr {
  key: ""output_shapes""
  value {
    list {
      shape {
        dim {
          size: 32
        }
        dim {
          size: 32
        }
        dim {
          size: 32
        }
        dim {
          size: 3
        }
      }
      shape {
        dim {
          size: 32
        }
        dim {
          size: 1
        }
      }
    }
  }
}


```
Thank you!"
45156,"""NotFoundError: No CPU devices are available in this process"" when trying to use GPU / Cuda","**System information**
- OS: Windows 10, build 1904:
- TensorFlow installed from: conda
- TensorFlow version: tensorflow-gpu 2.1.0
- Python version: 3.7.9
- Installed using: conda
- CUDA version: cudatoolkit 10.1.243
- cdNN version: cudnn 7.6.5
- GPU model and memory: GeForce RTX 2070

When I run a script that imports tensorflow, I got the initial message that says that we are good to go:

```
2020-11-24 10:34:33.383215: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll
2020-11-24 10:34:35.172255: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library nvcuda.dll
2020-11-24 10:34:35.201507: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties:
pciBusID: 0000:01:00.0 name: GeForce RTX 2070 computeCapability: 7.5
coreClock: 1.62GHz coreCount: 36 deviceMemorySize: 8.00GiB deviceMemoryBandwidth: 417.29GiB/s
2020-11-24 10:34:35.201929: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll
2020-11-24 10:34:35.205687: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll
2020-11-24 10:34:35.208452: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_10.dll
2020-11-24 10:34:35.209263: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_10.dll
2020-11-24 10:34:35.212090: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_10.dll
2020-11-24 10:34:35.213642: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_10.dll
2020-11-24 10:34:35.219337: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll
2020-11-24 10:34:35.219630: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
```

And the code runs well until the point a NN structure is to be fit(). There, I get the following error:

`tensorflow.python.framework.errors_impl.NotFoundError: No CPU devices are available in this process`

From what I understand, tensorflow is trying to use my CPU when it should be using my GPUs, correct?

If so, **is there something I should do in my installation to deactivate the usage of CPUs and only force it to use GPUs?**
Or **is it missing some line of code here/there to make this forcing?**

Thanks.

Full error stack:

```
Traceback (most recent call last):
  File ""postProc01_QRNN_win10.py"", line 280, in <module>
    _cur_nn_model, _cur_model_custom_objs = create_empty_model(_li_df[X_COLS], [20, 20], [0.25, 0.5, 0.75])
  File ""postProc01_QRNN_win10.py"", line 189, in create_empty_model
    output_activation=""relu"", input_normalization=True, metrics=[])
  File ""D:\andre\git_repos\tibagi_codes\coding_playground\TK_proj_downscalingComparisons\lib\my_quantile_mapping_lib_v2.py"", line 54, in build_mqnn
    normalizer.adapt(training_x_values)
  File ""C:\Users\dellalia\Anaconda_3_7\envs\ai_geo_gpu_3_7\lib\site-packages\tensorflow_core\python\keras\engine\base_preprocessing_layer.py"", line 180, in adapt
    self.build(shape)
  File ""C:\Users\dellalia\Anaconda_3_7\envs\ai_geo_gpu_3_7\lib\site-packages\tensorflow_core\python\keras\layers\preprocessing\normalization.py"", line 94, in build
    initializer=init_ops.zeros_initializer)
  File ""C:\Users\dellalia\Anaconda_3_7\envs\ai_geo_gpu_3_7\lib\site-packages\tensorflow_core\python\keras\engine\base_preprocessing_layer.py"", line 107, in _add_state_variable
    **kwargs)
  File ""C:\Users\dellalia\Anaconda_3_7\envs\ai_geo_gpu_3_7\lib\site-packages\tensorflow_core\python\keras\engine\base_layer.py"", line 446, in add_weight
    caching_device=caching_device)
  File ""C:\Users\dellalia\Anaconda_3_7\envs\ai_geo_gpu_3_7\lib\site-packages\tensorflow_core\python\training\tracking\base.py"", line 744, in _add_variable_with_custom_getter
    **kwargs_for_getter)
  File ""C:\Users\dellalia\Anaconda_3_7\envs\ai_geo_gpu_3_7\lib\site-packages\tensorflow_core\python\keras\engine\base_layer_utils.py"", line 142, in make_variable
    shape=variable_shape if variable_shape else None)
  File ""C:\Users\dellalia\Anaconda_3_7\envs\ai_geo_gpu_3_7\lib\site-packages\tensorflow_core\python\ops\variables.py"", line 258, in __call__
    return cls._variable_v1_call(*args, **kwargs)
  File ""C:\Users\dellalia\Anaconda_3_7\envs\ai_geo_gpu_3_7\lib\site-packages\tensorflow_core\python\ops\variables.py"", line 219, in _variable_v1_call
    shape=shape)
  File ""C:\Users\dellalia\Anaconda_3_7\envs\ai_geo_gpu_3_7\lib\site-packages\tensorflow_core\python\ops\variables.py"", line 197, in <lambda>
    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)
  File ""C:\Users\dellalia\Anaconda_3_7\envs\ai_geo_gpu_3_7\lib\site-packages\tensorflow_core\python\ops\variable_scope.py"", line 2596, in default_variable_creator
    shape=shape)
  File ""C:\Users\dellalia\Anaconda_3_7\envs\ai_geo_gpu_3_7\lib\site-packages\tensorflow_core\python\ops\variables.py"", line 262, in __call__
    return super(VariableMetaclass, cls).__call__(*args, **kwargs)
  File ""C:\Users\dellalia\Anaconda_3_7\envs\ai_geo_gpu_3_7\lib\site-packages\tensorflow_core\python\ops\resource_variable_ops.py"", line 1411, in __init__
    distribute_strategy=distribute_strategy)
  File ""C:\Users\dellalia\Anaconda_3_7\envs\ai_geo_gpu_3_7\lib\site-packages\tensorflow_core\python\ops\resource_variable_ops.py"", line 1542, in _init_from_args
    initial_value() if init_from_fn else initial_value,
  File ""C:\Users\dellalia\Anaconda_3_7\envs\ai_geo_gpu_3_7\lib\site-packages\tensorflow_core\python\keras\engine\base_layer_utils.py"", line 122, in <lambda>
    init_val = lambda: initializer(shape, dtype=dtype)
  File ""C:\Users\dellalia\Anaconda_3_7\envs\ai_geo_gpu_3_7\lib\site-packages\tensorflow_core\python\ops\init_ops.py"", line 114, in __call__
    return array_ops.zeros(shape, dtype)
  File ""C:\Users\dellalia\Anaconda_3_7\envs\ai_geo_gpu_3_7\lib\site-packages\tensorflow_core\python\ops\array_ops.py"", line 2434, in zeros
    output = _constant_if_small(zero, shape, dtype, name)
  File ""C:\Users\dellalia\Anaconda_3_7\envs\ai_geo_gpu_3_7\lib\site-packages\tensorflow_core\python\ops\array_ops.py"", line 2392, in _constant_if_small
    return constant(value, shape=shape, dtype=dtype, name=name)
  File ""C:\Users\dellalia\Anaconda_3_7\envs\ai_geo_gpu_3_7\lib\site-packages\tensorflow_core\python\framework\constant_op.py"", line 258, in constant
    allow_broadcast=True)
  File ""C:\Users\dellalia\Anaconda_3_7\envs\ai_geo_gpu_3_7\lib\site-packages\tensorflow_core\python\framework\constant_op.py"", line 266, in _constant_impl
    t = convert_to_eager_tensor(value, ctx, dtype)
  File ""C:\Users\dellalia\Anaconda_3_7\envs\ai_geo_gpu_3_7\lib\site-packages\tensorflow_core\python\framework\constant_op.py"", line 95, in convert_to_eager_tensor
    ctx.ensure_initialized()
  File ""C:\Users\dellalia\Anaconda_3_7\envs\ai_geo_gpu_3_7\lib\site-packages\tensorflow_core\python\eager\context.py"", line 509, in ensure_initialized
    context_handle = pywrap_tensorflow.TFE_NewContext(opts)
tensorflow.python.framework.errors_impl.NotFoundError: No CPU devices are available in this process
```

"
45155,TFLite - Java - Executing models on JVM not Android,"**System information**
- Linux Ubuntu 16.04, Windows
- Not mobile device. JDK or JRE.

**Example application using maven to compile and run an tensorflow lite project on JVM**

In the examples I only find bindings for Android. Which jar files (with maven coordinates) would I need
to run / evaluate tensorflow models on a JVM.

Thanks,
Dieter"
45153,Android tensorflow-lite-select-tf-ops.aar generated from tflite model build and deploy error,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version: 
- Python version: 3.6
- Installed using virtualenv? pip? conda?:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:



**Describe the problem**

I am following [this](https://www.tensorflow.org/lite/guide/build_android) guide to reduce my apk size. I followed the `Set up build environment using Docker` process to generate, `tensorflow-lite.aar`, `tensorflow-lite-select-tf-ops.aar` with my tflite model. 

After running, `bash tensorflow/lite/tools/build_aar.sh --input_models=custom_model.tflite --target_archs=arm64-v8a,armeabi-v7a` I found the `aar` files in tmp folder of docker container in `/tensorflow_src/bazel-bin/tmp/tensorflow-lite.aar` and `/tensorflow_src/bazel-bin/tmp/tensorflow-lite-select-tf-ops.aar`.

I followed the part below by making `libs` folder and copying the aar files.

```
allprojects {
    repositories {
        jcenter()
        flatDir {
            dirs 'libs'
        }
    }
}

dependencies {
    compile(name:'tensorflow-lite', ext:'aar')
}
```


My current code and model requires implementations below to work correctly.

```
implementation 'org.tensorflow:tensorflow-lite:2.3.0'
implementation 'org.tensorflow:tensorflow-lite-gpu:2.3.0'
implementation 'org.tensorflow:tensorflow-lite-select-tf-ops:0.0.0-nightly'
```

The problem comes when the above three implementation or commenting two except `implementation 'org.tensorflow:tensorflow-lite-gpu:2.3.0'` gives errors,

```
cannot find symbol class Interpreter`
cannot find symbol class NnApiDelegate
error: package org.tensorflow.lite.nnapi does not exist
``` 

This error is not show when `fat_apk` is built using command, `bazel build -c opt --fat_apk_cpu=arm64-v8a,armeabi-v7a --host_crosstool_top=@bazel_tools//tools/cpp:toolchain tensorflow/lite/java:tensorflow-lite`. But using this method there is no `tensorflow-lite-select-tf-ops.aar` in `/tensorflow_src/bazel-bin/tensorflow/lite/java/` folder.

Using the previous with above fat_apk tensorflow-lite aar it crashes with error,

```
java.lang.UnsatisfiedLinkError: dlopen failed: cannot locate symbol ""_ZNK6google8protobuf7Message11GetTypeNameEv"" referenced by ""/data/app/com.example.myapp-PkLKD5MHuq9TB2R3mDgNcA==/base.apk!/lib/arm64-v8a/libtensorflowlite_flex_jni.so""...
```

My main goal is reduce size of `select-ft-ops` as I noticed it reduces app size by 60+mb. If there is an alternate method please suggest. Also looking for building instructions of tensorflow-lite-gpu aar.



**Provide the exact sequence of commands / steps that you executed before running into the problem**

- Setup docker in Ubuntu 18.04 and download dockerfile from [here](https://raw.githubusercontent.com/tensorflow/tensorflow/master/tensorflow/tools/dockerfiles/tflite-android.Dockerfile). 
- Follow commands from `Set up build environment using Docker` section from [here](https://www.tensorflow.org/lite/guide/build_android#set_up_build_environment_using_docker).
- Run `./configure`.
- Use command, `bash tensorflow/lite/tools/build_aar.sh --input_models=custom_model.tflite --target_archs=arm64-v8a,armeabi-v7a`.
- Get the `aar` files from `tmp` folder as mentioned [here](https://www.tensorflow.org/lite/guide/ops_select) in section `Building the Android AAR` and paste in `libs` folder of android project.
- Paste following, 
```
allprojects {
    repositories {
        jcenter()
        flatDir {
            dirs 'libs'
        }
    }
}

dependencies {
    compile(name:'tensorflow-lite', ext:'aar')
    compile(name:'tensorflow-lite-select-tf-ops', ext:'aar')
}
```
- Commenting out following,
```
//implementation 'org.tensorflow:tensorflow-lite:2.3.0'
//implementation 'org.tensorflow:tensorflow-lite-select-tf-ops:0.0.0-nightly'
```


**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
45152,Loading a Custom Model TFlite into Flutter ,"I follow along this [Colab](https://colab.research.google.com/drive/1qXn9q6m5ug7EWJsJov6mHaotHhCUY-wG?usp=sharing)  to  train a custom model.

[Conversion process Colab](https://colab.research.google.com/drive/1VRH4K_LPXlTv-YvobWjvxOAowxTYIli8?usp=sharing) 

After completing the training process I converted the .pb to .tflite and I got [these files](https://drive.google.com/drive/folders/1I8pU34M9gagLFdImmrpS8qUY6Wge0jds?usp=sharing). When I loaded the model into the [official Android demo](https://github.com/tensorflow/examples/tree/master/lite/examples/object_detection/android)  I got the following error:


```
 java.lang.RuntimeException: Unable to start activity ComponentInfo{com.example.sd_detect/com.example.sd_detect.MainActivity}: java.lang.IllegalStateException: This model does not contain associated files, and is not a Zip file.
```
The solution to that error is discussed in [this issue](https://github.com/tensorflow/tensorflow/issues/44431)

I followed the solution:

Installing the metadata library with:
```
pip install tflite-support

```
and then executing the following command into python
```
>>> from tflite_support import metadata as _metadata
>>> populator = _metadata.MetadataPopulator.with_model_file('final_model.tflite')
>>> populator.load_associated_files([""final_model.txt""])
>>> populator.populate() 
```


And I got the following warning:

    /home/username/.local/lib/python3.8/site-packages/tensorflow_lite_support/metadata/python/metadata.py:342: UserWarning: File, 'final_model.txt', does not exsit in the metadata. But packing it to tflite model is still allowed.
      warnings.warn(

Back to Android Studio example I was able to run the model successfully, by just modifying this information:

    private static final String TF_OD_API_MODEL_FILE = ""final_model.tflite"";  
    private static final String TF_OD_API_LABELS_FILE = ""final_model.txt"";  

But my main goal is to use this model into a Flutter application, but when I try to run into Flutter I got the following exeption:

    /// Throws a [StateError] if the given [expression] is `false`.
    
    void  checkState(bool expression, {message}) {
    
    if (!expression) {
    
    throw  StateError(_resolveMessage(message, 'failed precondition'));
    
    }
    
    }
The flutter [project](https://github.com/am15h/object_detection_flutter) is fully working with coco_ssd_mobilenet_v1_1.0_quant_2018_06_29


I also tried to re-run the metadata commands on my flutter application assets but still the same issue.

What am I missing?"
45151,Allow --cpu=x64_arm64_windows as a compilation target on Windows,"Compilation of TensorFlow on Windows currently assumes x64 as a target CPU architecture. Searching .bzl files for ""x64_windows"" shows the many places in TF where this assumption is made. 

In principle, though, nothing should prevent compiling TensorFlow to target ARM64 on Windows (--cpu=x64_arm64_windows, see the [bazel doc](https://github.com/bazelbuild/bazel/blob/master/site/docs/windows.md)).

This feature request is about adding support for '--cpu=x64_arm64_windows' to produce ARM64 binaries. The goal is to be able to use TF on Windows on ARM 64 bits."
45150,How to generate a Reshape TFLite model with the new shape as attributes?,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- TensorFlow installed from (source or binary): binary
- TensorFlow version (or github SHA if from source): v2.3.0


**Command used to run the converter or code if you’re using the Python API**

```py
import tensorflow as tf  # tf 2.3.0
import numpy as np

ISHAPE = (1, 2, 3, 4)
OSHAPE = (int(np.product(ISHAPE)),)


def genWithKeras():
  data = tf.keras.Input(dtype='float32', name='input', batch_size=ISHAPE[0], shape=ISHAPE[1:])
  reshape = tf.keras.layers.Reshape(OSHAPE, name='reshaped')(data)
  model = tf.keras.Model(inputs=[data], outputs=[reshape])
  return tf.lite.TFLiteConverter.from_keras_model(model)


def genWithTFModel():
  class ReshapeModule(tf.Module):
    def __init__(self):
      super(ReshapeModule, self).__init__()

    @tf.function(input_signature=[tf.TensorSpec(ISHAPE, tf.float32)])
    def __call__(self, data):
      return tf.reshape(data, OSHAPE)

  module = ReshapeModule()
  tf.saved_model.save(module, 'reshape.saved_model')
  return tf.lite.TFLiteConverter.from_saved_model('reshape.saved_model')

converter = genWithKeras()
# converter = genWithTFModel()
tflite_model = converter.convert()
with open('model.tflite', 'wb') as f:
  f.write(tflite_model)
```

**The output from the converter invocation**

![](https://user-images.githubusercontent.com/4936589/99535868-78bf0900-29e4-11eb-86e9-8482d57e5a4b.png)

**Also, please include a link to the saved model or GraphDef**

```
None
```

**Failure details**
May I know the details of how the TFLite models are generated, in particular, the code path to produce the TFLite models? **Should be irrelevant to the model detail**.

We are working on [`tflite2onnx`](https://github.com/jackwish/tflite2onnx) which can convert TFLite models to ONNX. When converting the [palm_detection](https://github.com/google/mediapipe/blob/master/mediapipe/modules/palm_detection/palm_detection.tflite) model from [MediaPipe](https://github.com/google/mediapipe), we noticed that the `Reshape` of it accepts **only one input** - the output shape is as the attribute of `Reshape` as the figure below.

<img width=""528"" alt=""palm-detect"" src=""https://user-images.githubusercontent.com/4936589/99535493-ee76a500-29e3-11eb-829f-30239911b9fd.png"">

We tried to build a standalone case for `Reshape` (a model which contains `Reshape` only), but there are **always two inputs** in our model with either Keras API or TensorFlow API (as the repro code above). We are curious about how to generate a Reshape TFLite model with the new shape as attributes?


**RNN conversion support**
None

**Any other info / logs**

The source issue we have is: https://github.com/jackwish/tflite2onnx/issues/23#issuecomment-725070754 and we are moved from [this MediaPipe issue](https://github.com/google/mediapipe/issues/1310)"
45148,tf-trained model not working after converting to tf-lite for raspi,"**System information**
Laptop: 
Linux Ubuntu
Tensorflow 1.15.0

Raspi:
Raspberry Pi 4
tflite-runtime 2.5.0
tensorflow-estimator 1.14.0
Coral Edge TPU

Hello everybody, I am stuck at getting my trained model running on raspi. I trained ssd_mobilenet_v2_coco model from tensorflow 1 modelzoo with my own custom dataset on google cloud with this config file where I did few changes:
[ssd_mobilenet_v2_coco_config.zip](https://github.com/tensorflow/tensorflow/files/5589151/ssd_mobilenet_v2_coco_config.zip)

After training I exported the frozen_inference_graph which worked pretty well on my laptop, so I exported the tflite graph (tflite_graph.pb and tflite_graph.pbtxt) with the following command:
`python export_tflite_ssd_graph.py \ 
--pipeline_config_path=gs://objects1119/ssd_mobilenet_v2_coco.config \ 
--trained_checkpoint_prefix=gs://objects1119/model.ckpt-189879 \ 
--output_directory=tflite \
--add_postprocessing_op=true`

after that I converted it to detect.tflite file with:
`tflite_convert --graph_def_file=tflite/tflite_graph.pb  --output_file=tflite/detect.tflite  --output_format=TFLITE --input_arrays=normalized_input_image_tensor --output_arrays='TFLite_Detection_PostProcess','TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3'  --inference_type=QUANTIZED_UINT8 --mean_values=128 --std_dev_values=127 --change_concat_input_ranges=false --allow_custom_ops`

You can see the file here:
[detect_tflite.zip](https://github.com/tensorflow/tensorflow/files/5589264/detect_tflite.zip)

After that I converted it to edgetpu-file with this google colab: https://colab.research.google.com/drive/1o6cNNNgGhoT7_DR4jhpMKpq3mZZ6Of4N?usp=sharing 
while using the EdjeElectronics Tutorial: 
https://github.com/EdjeElectronics/TensorFlow-Lite-Object-Detection-on-Android-and-Raspberry-Pi/blob/master/Raspberry_Pi_Guide.md 
 everything worked without errors and I gut this file:
[detect_edgetpu.zip](https://github.com/tensorflow/tensorflow/files/5589397/detect_edgetpu.zip)

But when I finally try to run it on the raspi with this file
[TFLite_detection_webcam.zip](https://github.com/tensorflow/tensorflow/files/5589323/TFLite_detection_webcam.zip)
I am always facing the same output, no matter what input. There is always Class Zero predicted on the same areas of the image with prediction of 50%. What am I doing wrong? Is it because of the changed input shapes in the config file for training? In my case it would be really complicated to train again so I try to avoid this if its possible.
Thank you very much in advance.
"
45147,python3.6 Mac OS X 11.0.1  Could not find a version that satisfies the requirement tensorflow,"ERROR: Could not find a version that satisfies the requirement tensorflow (from versions: none)
ERROR: No matching distribution found for tensorflow"
45146,Missing call to model.optimizer._clip_gradients(grads)?,"Hi,

I've been having problems training a model and, after reading the keras training loop code, it seems that the call to 
model.optimizer._clip_gradients(grads) introduced in 69da929ad4d5ba605507efa1f52b382a55b6a969 is missing again.

Has it been moved somewhere else?

https://github.com/tensorflow/tensorflow/blob/ab953ab8c5612c67b07e4159fb9eed9edef089ff/tensorflow/python/keras/engine/training_eager_v1.py#L278"
45143,RuntimeError: Regular TensorFlow ops are not supported by this interpreter. Make sure you apply/link the Flex delegate before inference.Node number 51 (FlexResizeNearestNeighbor) failed to prepare.,"Hello.,sorry to bother you. I am learning to build Android programs using tflite. The environment I use is
tensorflow-2.2,SDK 29.0.3,NDK 21.
When I use the model.tflite to build app,I get an error:

```
java.lang.RuntimeException: java.lang.IllegalArgumentException: Internal error: Cannot create interpreter: Didn't find op for builtin opcode 'RESIZE_NEAREST_NEIGHBOR' version '3'  Registration failed.
``` 
I don't know how to solve this problem,maybe the conversion failed？
The program  of yolo-tiny I used  is https://github.com/bubbliiiing/yolov4-tiny-tf2.
The model of yolo-tiny can be used for detecting correctly.
I have build tensorflow-lite-select-tf-ops.aar in Android project.
My English is poor,please excuse me.


**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Linux Ubuntu 16.04
- TensorFlow installed from (source or binary):source
- TensorFlow version (or github SHA if from source):tensorflow2.2


**Command used to run the converter or code if you’re using the Python API**
If possible, please share a link to Colab/Jupyter/any notebook.

```
import tensorflow as tf
from tensorflow.keras.models import load_model
from nets.yolo4_tiny import yolo_body,yolo_eval

from tensorflow.keras.layers import Input
from tensorflow.keras.layers import Input, Lambda
from train import get_anchors
from train import get_classes

model=load_model('yolo_voc.h5')
converter = tf.lite.TFLiteConverter.from_keras_model(model)
converter.target_spec.supported_types = [tf.float16]
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, 
                                      tf.lite.OpsSet.SELECT_TF_OPS]
tflite_model = converter.convert()
with tf.io.gfile.GFile('fmodel.tflite', 'wb') as f:
  f.write(tflite_model)
 
from tflite_support import metadata as _metadata
populator = _metadata.MetadataPopulator.with_model_file(""fmodel.tflite"")
populator.load_associated_files([""model_data/voc_classes.txt""])
populator.populate() 
```

**The output from the converter invocation**

When I run the code above,the terminal prints:
```
UserWarning: File, 'voc_classes.txt', does not exsit in the metadata. But packing it to tflite model is still allowed.
  ""tflite model is still allowed."".format(f)
```
If I use tf2.2 to get the details of tflite_model,I would get the error:

```
RuntimeError: Regular TensorFlow ops are not supported by this interpreter. Make sure you apply/link the Flex delegate before inference.Node number 51 (FlexResizeNearestNeighbor) failed to prepare.

```

if I use tf2.3,I would get:

```
TfLiteFlexDelegate delegate: 1 nodes delegated out of 56 nodes with 1 partitions.
[  1 416 416  3]
<class 'numpy.float32'>
[ 1 13 13 75]
<class 'numpy.float32'>

```

**Also, please include a link to the saved model or GraphDef**

```
https://drive.google.com/drive/folders/1sXTFLk5xkFSao7edJXFIsFIcojtR8wjK?usp=sharing
```

**Failure details**
If the conversion is successful, but the generated model is wrong,
state what is wrong:
- Producing wrong results and/or decrease in accuracy
- Producing correct results, but the model is slower than expected (model generated from old converter)


**RNN conversion support**
If converting TF RNN to TFLite fused RNN ops, please prefix [RNN] in the title.

**Any other info / logs**

"
45142,"tflite android gpu delegate init error, what does it mean? MEAN: Index for axis out of range","error log:
java.lang.IllegalArgumentException: Internal error: Failed to apply delegate: TfLiteGpuDelegate Init: MEAN: Index for axis out of range
    TfLiteGpuDelegate Prepare: delegate is not initialized
    Node number 58 (TfLiteGpuDelegateV2) failed to prepare.

when i run my own model producing by tensorflow 2.3, all keras layers.

device: xiaomi 8 se
dependence: 
 implementation('org.tensorflow:tensorflow-lite:0.0.0-nightly')
 implementation('org.tensorflow:tensorflow-lite-gpu:0.0.0-nightly')
 implementation('org.tensorflow:tensorflow-lite-support:0.0.0-nightly')"
45141,TFLITE Flower Classification codelab not working on own model it's always crashed,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (Ubuntu 20.04 ):
- Mobile device (OPPO A37fw) 
- TensorFlow installed from (source or binary):
- TensorFlow version (2.2.0):
- Python version:3.7


**Describe the current behavior**
I changed the model.tflite and label.txt on my own model and labels but it's not working. Using the default tflite model and label.txt work though.

**Describe the expected behavior**


"
45140,Some QUESTION about tflite（Node number 51 (FlexResizeNearestNeighbor) failed to prepare.）,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- TensorFlow installed from (source or binary):
- TensorFlow version (or github SHA if from source):


**Command used to run the converter or code if you’re using the Python API**
If possible, please share a link to Colab/Jupyter/any notebook.

```
# Copy and paste here the exact command
```

**The output from the converter invocation**

```
# Copy and paste the output here.
```

**Also, please include a link to the saved model or GraphDef**

```
# Put link here or attach to the issue.
```

**Failure details**
If the conversion is successful, but the generated model is wrong,
state what is wrong:
- Producing wrong results and/or decrease in accuracy
- Producing correct results, but the model is slower than expected (model generated from old converter)


**RNN conversion support**
If converting TF RNN to TFLite fused RNN ops, please prefix [RNN] in the title.

**Any other info / logs**

Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
45139,label_image build fail on x86,"**System information**
- OS Platform and Distribution: Linux Ubuntu 18.04
- TensorFlow installed from: source (Branch: Master, Commit Id: b0d40302ec4ce301e841eb58fc7e6937e4624ab7)
- TensorFlow version: 3.1.0


**Provide the text output from tflite_convert**

```
# Copy and paste here
```

**Standalone code to reproduce the issue** 
After cloning tensorflow sources:
$ cd tensorflow/tensorflow/lite/tools/make
$ ./download_dependencies.sh
$ ./build_lib.sh label_image

Also, please include a link to a GraphDef or the model if possible.

**Any other info / logs**
ar: creating /home/khan/vaibhav/review/tensorflow/tensorflow/lite/tools/make/gen/linux_x86_64/lib/libtensorflow-lite.a
g++ -O3 -DNDEBUG -DCPU_SETSIZE=__CPU_SETSIZE -fPIC  --std=c++11  -DTFLITE_HAVE_CPUINFO -DTFLITE_WITHOUT_XNNPACK -fPIC -DGEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK -pthread -I. -I/home/khan/vaibhav/review/tensorflow/tensorflow/lite/tools/make/../../../../../ -I/home/khan/vaibhav/review/tensorflow/tensorflow/lite/tools/make/../../../../../../ -I/home/khan/vaibhav/review/tensorflow/tensorflow/lite/tools/make/downloads/ -I/home/khan/vaibhav/review/tensorflow/tensorflow/lite/tools/make/downloads/eigen -I/home/khan/vaibhav/review/tensorflow/tensorflow/lite/tools/make/downloads/absl -I/home/khan/vaibhav/review/tensorflow/tensorflow/lite/tools/make/downloads/gemmlowp -I/home/khan/vaibhav/review/tensorflow/tensorflow/lite/tools/make/downloads/ruy -I/home/khan/vaibhav/review/tensorflow/tensorflow/lite/tools/make/downloads/neon_2_sse -I/home/khan/vaibhav/review/tensorflow/tensorflow/lite/tools/make/downloads/farmhash/src -I/home/khan/vaibhav/review/tensorflow/tensorflow/lite/tools/make/downloads/flatbuffers/include -I/home/khan/vaibhav/review/tensorflow/tensorflow/lite/tools/make/downloads/fp16/include -I/home/khan/vaibhav/review/tensorflow/tensorflow/lite/tools/make/downloads/cpuinfo -I/home/khan/vaibhav/review/tensorflow/tensorflow/lite/tools/make/downloads/cpuinfo/include -I/home/khan/vaibhav/review/tensorflow/tensorflow/lite/tools/make/downloads/cpuinfo/src -I/home/khan/vaibhav/review/tensorflow/tensorflow/lite/tools/make/downloads/cpuinfo/deps/clog/include -I -I/usr/local/include \
-o /home/khan/vaibhav/review/tensorflow/tensorflow/lite/tools/make/gen/linux_x86_64/bin/label_image /home/khan/vaibhav/review/tensorflow/tensorflow/lite/tools/make/gen/linux_x86_64/obj/tensorflow/lite/examples/label_image/bitmap_helpers.o /home/khan/vaibhav/review/tensorflow/tensorflow/lite/tools/make/gen/linux_x86_64/obj/tensorflow/lite/examples/label_image/label_image.o /home/khan/vaibhav/review/tensorflow/tensorflow/lite/tools/make/gen/linux_x86_64/obj/tensorflow/lite/tools/evaluation/utils.o \
 /home/khan/vaibhav/review/tensorflow/tensorflow/lite/tools/make/gen/linux_x86_64/lib/libtensorflow-lite.a  -lstdc++ -lpthread -lm -lz -ldl -ldl
/home/khan/vaibhav/review/tensorflow/tensorflow/lite/tools/make/gen/linux_x86_64/obj/tensorflow/lite/examples/label_image/label_image.o: In function `tflite::label_image::Main(int, char**)':
label_image.cc:(.text+0x907d): undefined reference to `tflite::tools::ToolParams::Merge(tflite::tools::ToolParams const&, bool)'
label_image.cc:(.text+0x921d): undefined reference to `tflite::Flags::Parse(int*, char const**, std::vector<tflite::Flag, std::allocator<tflite::Flag> > const&)'
label_image.cc:(.text+0x92a9): undefined reference to `tflite::Flags::Usage(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::vector<tflite::Flag, std::allocator<tflite::Flag> > const&)'
collect2: error: ld returned 1 exit status
tensorflow/lite/tools/make/Makefile:367: recipe for target '/home/khan/vaibhav/review/tensorflow/tensorflow/lite/tools/make/gen/linux_x86_64/bin/label_image' failed
make: *** [/home/khan/vaibhav/review/tensorflow/tensorflow/lite/tools/make/gen/linux_x86_64/bin/label_image] Error 1
make: Leaving directory '/home/khan/vaibhav/review/tensorflow'

"
45138,keras doesn't pickle the correct layer in model Sequential,"**System information**
- OS Platform: Windows, Linux
- TensorFlow version ('v2.3.0-54-gfcc4b966f1', '2.3.1')
- Python version: 3.8.6

**Current behavior**
I need to test two versions of `BatchNormalization` for making sure that moving to from `tf1` to `tf2` doesn't cause any dramatic change in the model performance. 

I have two alternatives in `tf2`:
```
from tensorflow.python.keras.layers.normalization import BatchNormalization as BatchNormalization1
from tensorflow.python.keras.layers.normalization_v2 import BatchNormalization as BatchNormalization2
```
The first option replicates `tf1` behavior whereas the second one replicates `tf2` behavior (the second import is also equivalent to `from tensorflow.keras.layers import BatchNormalization as BatchNormalization2`)
Now I create two simple sequential models containing only one layer each

```
from tensorflow.keras.models import Sequential, load_model

batch_norm1 = BatchNormalization1(input_shape=[28, 28])
batch_norm2 = BatchNormalization2(input_shape=[28, 28])

model1 = Sequential([batch_norm1])
model2 = Sequential([batch_norm2])
```
If I print the models layers I get:

```
print(model1.layers)
[<tensorflow.python.keras.layers.normalization.BatchNormalization object at 0x0000022446319160>]

print(model2.layers)
[<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x0000022446319460>]

```
So far so good, nothing unexpected. 
However, if I now save the two models and then load them in a different session (or also in the same one) the first model mysteriously changes its class meaning that is loaded as `tensorflow.python.keras.layers.normalization_v2.BatchNormalization object`
 instead of `tensorflow.python.keras.layers.normalization.BatchNormalization object`

```
model1.save('m1.h5')
model2.save('m2.h5')

model1 = load_model('m1.h5')
model2 = load_model('m2.h5')

print(model1.layers)
[<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x00000224463C5DC0>]

print(model2.layers)
[<tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x0000022446360C40>]
```

I believe this is a bug. 

**Useful info for isolating the problem**
- The same behavior is present if I test `tensorflow.python.keras.layers.recurrent.GRU` and `tensorflow.python.keras.layers.recurrent_v2.GRU`
- This problem is only present if I use the layer inside a `keras Model`, but if try to pickle the layer directly everything works as expected.

Many thanks
Gio"
45137,TextLineDataset stops after first segment of multiple gzip'ed files concatenated together,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Debian sid
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below):v1.12.1-38511-ge95a955af8 2.4.0
- Python version: 3.8.5
- Bazel version (if compiling from source): 3.7.0
- GCC/Compiler version (if compiling from source):  10.2.0
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A

**Describe the current behavior**
Creating a TextLineDataset with the 'GZIP' compression type stops returning lines if the datafile consists of multiple gzipped files concatenated together.  This method of concatenating compressed files is explicitly called out in the gzip manpage as supported behavior.  And indeed, zcat, gunzip, and others do return all the uncompressed data.  Even Python's gzip.decompress() method does so, so it is confusing that Tensorflow does not.  The alternative is to decompress the files, concatenate them, then recompress, but this is undesirable due to the time required.

**Standalone code to reproduce the issue**
```
#!/usr/bin/python3

import tensorflow as tf
import gzip

f = open('data.gz', 'wb')
for i in range(10):
        line = str(i) + '\n' + str(i + 100) + '\n'
        f.write(gzip.compress(line.encode('utf-8')))
f.close()

ds = tf.data.TextLineDataset('data.gz', compression_type='GZIP')
for i in ds:
        print(i)
```

tf.Tensor(b'0', shape=(), dtype=string)
tf.Tensor(b'100', shape=(), dtype=string)

This only returns 2 of the 20 expected items."
45136,[TF2.4rc2] linalg.svd missing kernel for DT_HALF,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Colab (Ubuntu)
- TensorFlow installed from (source or binary): Binary
- TensorFlow version (use command below): 2.4.0rc2
- Python version: 3.6 (probably all)

**Describe the current behavior**
tf.linalg.svd fails on tf.half dtypes in TF2.4
https://colab.research.google.com/drive/1Y3FRV5qmQnnGUVHBX2wsFa0hC2PVDUON?usp=sharing
```
NotFoundError: Could not find device for node: {{node Svd}} = Svd[T=DT_HALF, compute_uv=true, full_matrices=false]
All kernels registered for op Svd:
  device='GPU'; T in [DT_DOUBLE]
  device='GPU'; T in [DT_FLOAT]
  device='CPU'; T in [DT_FLOAT]
  device='CPU'; T in [DT_DOUBLE]
  device='CPU'; T in [DT_COMPLEX64]
  device='CPU'; T in [DT_COMPLEX128]
 [Op:Svd]
```

**Describe the expected behavior**
tf.linalg.svd works on tf.half dtypes in TF2.3
https://colab.research.google.com/drive/1Gf_C6SAQgUHzEQfkZPXD8PITL8lW17-I?usp=sharing
"
45135,Save model to json on TF 2.3 and TF 2.2,"Hi, I'm Jerry Kim in Korea of Republic.

I faced difference between TF 2.3 and TF 2.2.

After training model using tf 2.3, I saved model using `.to_json()`.

At loading model time, I got error about `Value error:unknown layer : functional`.

If you want to correct this, Edit 

`{""class_name"": ""Functional"", ""config"": {""name"": ""functional_1"", ""layers"": [{""class_name"": ""InputLayer"" ...`

to 

`{""class_name"": ""Model"", ""config"": {""name"": ""model_1"", ""layers"": [{""class_name"": ""InputLayer"" ...`

After If you get error like `('Keyword argument not understood:', 'groups')`, 

![image](https://user-images.githubusercontent.com/25097024/100039069-e38a9d00-2e47-11eb-8c8a-ed76840b7072.png)

Erase all `""groups"":1, `


After then, loading model will work.

Thank you."
45134,How to create multi-timeseries dataset input ? (a list of tf.tensor),"## URL(s) with the issue:

Examples doesn't contain my case : 
https://www.tensorflow.org/tutorials/structured_data/time_series#1_indexes_and_offsets
https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/timeseries_dataset_from_array


## Description of issue (what needs changing):

For example, I want to

1. feed 3 timeseries to 3 individual lstm t1,t2,t3
2. concat t1,t2,t3 , then pass to dense or conv layers

To achieve that , I have to use functional api , which need :
- input :  [ tf.Tensor(..), tf.Tensor(..), tf.Tensor(..)]   # must be list or tuple
- target: tf.Tensor(..)

The problem is : official api `tf.keras.preprocessing.timeseries_dataset_from_array` would return tensor , not list of tensor . 


# Dummy code:

### # Model Stucture

```

import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers

data = pd.DataFrame(np.random.uniform(size=(1000,3)), columns=['Sales', 'SalesDiff7', 'SalesAggMean7'])

multi_inputs = []
multi_outputs = []
window_size = 1

for i in range(data.shape[1]):
    ti = keras.Input(shape=(window_size, 1), name=f't{i}')
    tlstm = layers.LSTM(32)(ti)
    tp = keras.layers.Dense(units=1)(tlstm)
    multi_inputs.append(ti)
    multi_outputs.append(tp)
    
r = tf.concat(multi_outputs, -1)
c = keras.layers.Flatten()(r)
result = keras.layers.Dense(units=1)(c)
```
### # WindowGenerator

Mainly copy from https://www.tensorflow.org/tutorials/structured_data/time_series#1_indexes_and_offsets
```
n = len(data)
train_df = data[0:int(n*0.7)]
val_df = data[int(n*0.7):int(n*0.9)]
test_df = data[int(n*0.9):]

default_batch_size = 32

class WindowGenerator():
  def __init__(self, input_width, label_width, shift,
               train_df=train_df, val_df=val_df, test_df=test_df,
               label_columns=None):
    # Store the raw data.
    self.train_df = train_df
    self.val_df = val_df
    self.test_df = test_df

    # Work out the label column indices.
    self.label_columns = label_columns
    if label_columns is not None:
      self.label_columns_indices = {name: i for i, name in
                                    enumerate(label_columns)}
    self.column_indices = {name: i for i, name in
                           enumerate(train_df.columns)}

    # Work out the window parameters.
    self.input_width = input_width
    self.label_width = label_width
    self.shift = shift

    self.total_window_size = input_width + shift

    self.input_slice = slice(0, input_width)
    self.input_indices = np.arange(self.total_window_size)[self.input_slice]

    self.label_start = self.total_window_size - self.label_width
    self.labels_slice = slice(self.label_start, None)
    self.label_indices = np.arange(self.total_window_size)[self.labels_slice]

  def __repr__(self):
    return '\n'.join([
        f'Total window size: {self.total_window_size}',
        f'Input indices: {self.input_indices}',
        f'Label indices: {self.label_indices}',
        f'Label column name(s): {self.label_columns}'])


@property
def train(self):
  return self.make_dataset(self.train_df)

@property
def val(self):
  return self.make_dataset(self.val_df)

@property
def test(self):
  return self.make_dataset(self.test_df)

WindowGenerator.train = train
WindowGenerator.val = val
WindowGenerator.test = test

```

### # Dataset generator

```

def split_multi_window(self, features):
  inputs = features[:, self.input_slice, :]
  labels = features[:, self.labels_slice, :]
  if self.label_columns is not None:
    labels = tf.stack(
        [labels[:, :, self.column_indices[name]] for name in self.label_columns],
        axis=-1)

  # Slicing doesn't preserve static shape information, so set the shapes
  # manually. This way the `tf.data.Datasets` are easier to inspect.
  inputs.set_shape([None, self.input_width, None])

  # split to multi-timeseries
  inputs = tf.split(inputs, num_or_size_splits=features.shape[-1], axis=len(features.shape)-1)
  labels.set_shape([None, self.label_width, None])

  return inputs, labels

WindowGenerator.split_multi_window = split_multi_window

def make_dataset(self, data):
  data = np.array(data, dtype=np.float32)
  ds = tf.keras.preprocessing.timeseries_dataset_from_array(
      data=data,
      targets=None,
      sequence_length=self.total_window_size,
      sequence_stride=1,
      shuffle=True,
      batch_size=default_batch_size,)

  ds = ds.map(self.split_multi_window)  # here is the problem

  return ds

WindowGenerator.make_dataset = make_dataset

```

### Trainning


```
single_step_window = WindowGenerator(
    input_width=1, label_width=1, shift=1,
    label_columns=['Sales'])

model = keras.Model(
    inputs=multi_inputs,
    outputs=result,
)
model.compile(loss=tf.losses.MeanSquaredError(),
            optimizer=tf.optimizers.Adam(),
            metrics=[tf.metrics.MeanAbsoluteError()])

history = model.fit( single_step_window.train ,  epochs=MAX_EPOCHS,
                  validation_data=single_step_window.val,
                  callbacks=[early_stopping])


```


### got error 

```

AssertionError: in user code:

    /home/ufo/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:806 train_function  *
        return step_function(self, iterator)
    /home/ufo/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:796 step_function  **
        outputs = model.distribute_strategy.run(run_step, args=(data,))
    /home/ufo/anaconda3/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:1211 run
        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)
    /home/ufo/anaconda3/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2585 call_for_each_replica
        return self._call_for_each_replica(fn, args, kwargs)
    /home/ufo/anaconda3/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2945 _call_for_each_replica
        return fn(*args, **kwargs)
    /home/ufo/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:789 run_step  **
        outputs = model.train_step(data)
    /home/ufo/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:747 train_step
        y_pred = self(x, training=True)
    /home/ufo/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:985 __call__
        outputs = call_fn(inputs, *args, **kwargs)
    /home/ufo/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/functional.py:385 call
        return self._run_internal_graph(
    /home/ufo/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/functional.py:517 _run_internal_graph
        assert x_id in tensor_dict, 'Could not compute output ' + str(x)

    AssertionError: Could not compute output Tensor(""dense_37/BiasAdd:0"", shape=(None, 1), dtype=float32)

```


After some debug , I found `single_step_window.train` became `[3, 32, 1, 1]` tensor instead of a list of 3 `[32, 1, 1]` tensor . 

I tried :
```
def make_dataset(self, data):
  data = np.array(data, dtype=np.float32)
  ds = tf.keras.preprocessing.timeseries_dataset_from_array(
      data=data,
      targets=None,
      sequence_length=self.total_window_size,
      sequence_stride=1,
      shuffle=True,
      batch_size=default_batch_size,)

  def gen_ds():
    for features in ds:
      yield self.split_3d_window(ds)

  ds = tf.data.Dataset.from_generator(gen_ds, (list, tf.float32))
    
  return ds
```

But it complain `from_generator` can not return list . What should I do ??? It better provides an example for this case. 

"
45123,Metadata writer for custom TFLite object detection model,"I would like to see more detail on how to add metadata to **custom** models, e.g. for object detection and segmentation models.

The new TFLite file format includes metadata, like input/ouput node info, normalization, and labels in a zip file that is appended after the .tflite binary.   This was **very** confusing, and makes it hard for those of us making custom models.   Documentation on adding metadata is available here:

https://www.tensorflow.org/lite/convert/metadata

The web page includes a script to add metadata to a classifier:

https://github.com/tensorflow/examples/blob/master/lite/examples/image_classification/metadata/metadata_writer_for_image_classifier.py

However I haven't found any docs or scripts on how to do this for custom object detection or segmentation models.   I've modified the script above for object detection, trying to match relevant metadata in the TFHub SSD model below:

https://tfhub.dev/tensorflow/lite-model/ssd_mobilenet_v1/1/metadata/2

I believe the metadata, combined with TFHub models, make it easier for beginners to get started.   However, it complicates things for those of us creating custom models from scratch, and not using TFHub models.

"
45121,Implementations 2/3 of LocallyConnected1D layer don't work with saved_model.save(),"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Linux Ubuntu 16.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
N/A
- TensorFlow installed from (source or binary):
binary
- TensorFlow version (use command below):
2.3.0
- Python version:
3.6 
- Bazel version (if compiling from source):
N/A
- GCC/Compiler version (if compiling from source):
N/A
- CUDA/cuDNN version:
N/A
- GPU model and memory:
N/A

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
ValueError: Tried to convert 'shape' to a tensor and failed. Error: None values not supported.

**Describe the expected behavior**
Successfully saving the model (as with implementation=1)

**Standalone code to reproduce the issue**
```
import tensorflow as tf
input = tf.keras.Input(
            shape=(10,1),
)
output = tf.keras.layers.LocallyConnected1D(
            1,
            5,
            5,
            implementation=3,  # implementation=1 does not cause error
)(input)
model = tf.keras.Model(
            inputs=input,
            outputs=output,
)
tf.saved_model.save(model, ""tmp"")
```

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
45120,Missing wheels tagged for macosx_11_x,"Current wheels are built for `macosx_10_9_*` .e.g `tensorflow-2.3.1-cp37-cp37m-macosx_10_9_x86_64.whl`. Pip attempts to build a list of compat tags that includes previous minor releases of macOS, however macOS Big Sur is a major release, which prevents those wheels from being installed:

```
$ pip install ~/Downloads/tensorflow-2.3.1-cp37-cp37m-macosx_10_9_x86_64.whl
ERROR: tensorflow-2.3.1-cp37-cp37m-macosx_10_9_x86_64.whl is not a supported wheel on this platform.
```

Solution: since the package itself is compatible for both macOS 10 and 11, the tagging needs to include both 10_x and 11_x major versions. Following installs without issues on Big Sur.
```
$ pip install ~/Downloads/tensorflow-2.3.1-cp37-cp37m-macosx_10_9_x86_64.macosx_11_0_x86_64.whl
```

List of wheels for TensorFlow 2.3.1: https://pypi.org/project/tensorflow/2.3.1/#files"
45119,Tflite Model gives same output for every input,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Google Colab
- TensorFlow installed from (source or binary): Source
- TensorFlow version (or github SHA if from source): 2.3.0


**Command used to run the converter or code if you’re using the Python API**
If possible, please share a link to Colab/Jupyter/any notebook. [Link for my Google Colab Notebook](https://colab.research.google.com/drive/1f0394NZJ-Jjt1bJ6eILTS1qH6hamvkEr?usp=sharing)

```
# Convert the model.
converter = tf.lite.TFLiteConverter.from_keras_model(model)
tflite_model = converter.convert()

# Save the model.
with open('/content/drive/MyDrive/model.tflite', 'wb') as f:
  f.write(tflite_model)
```

My goal is to develop an app that does image classification. Keras model seems to work good but after i try to convert to Tensorflow Lite, output is always the same.

**Code that I use to use to feed the tflite model random data**
```
# Load TFLite model and allocate tensors.
interpreter = tf.lite.Interpreter(model_path=""/content/drive/MyDrive/my_model.tflite"")
interpreter.allocate_tensors()

# Get input and output tensors.
input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()

# Test model on random input data.
input_shape = input_details[0]['shape']
input_data = np.array(np.random.random_sample(input_shape), dtype=np.float32)
interpreter.set_tensor(input_details[0]['index'], input_data)

interpreter.invoke()

output_data = interpreter.get_tensor(output_details[0]['index'])
print(output_data)
```
The output of the model is always something like this
```
[[ 1.5353261   0.5791437  -0.00934554 -1.5525526 ]]
```
Keras model seems to classify correct the images but I can't understand what is wrong after the conversion.

Many thanks in advance!

"
45114,GPU and CPU utilization slashed after first epoch using tf.data and tf.keras,"<em>Please make sure that this is an issue related to performance of TensorFlow.
As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:performance_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: n/a
- TensorFlow installed from (source or binary): Binary
- TensorFlow version (use command below): v1.12.1-46274-g410a6d8f46 2.5.0-dev20201121
- Python version: 3.8.6
- Bazel version (if compiling from source): n/a
- GCC/Compiler version (if compiling from source): n/a
- CUDA/cuDNN version: CUDA 11.1/cuDNN-11.1-8.0.5.39
- GPU model and memory: Nvidia RTX 3090 24GB

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

Training performance of a 16-layer CNN (VGG16) decreases dramatically after the first epoch. I am using tf.data to load ImageNet. The first epoch performs as well as can be expected on my machine (training time ~1hr), with CPU utilization of 65% and GPU at 88%. 

Epoch 2 has CPU utilization of 40.5% with the GPU at ~35% (usage appears spiky, indicating some sort of bottle neck that is idling the GPU). Data is being loaded from an NVMe SSD and there is no discernable reason for performance to be reduced on the second epoch (i.e., SSD temperature is not abnormally high). I suspect tf.data is the culprit but I don't know why -- this code works on a different system (read on below).

The dataset is ImageNet. 

**Describe the expected behavior**

There should be no performance difference between Epoch 1 and subsequent epochs (subject to thermal throttling, which I have confirmed is not an issue on my system). When running this same code on a different system (w/ Titan V GPU and HDD), performance is sustained. The version of TF there is different: v2.2.0-rc4-8-g2b96f3662b 2.2.0

The official TF2 package does not appear to support RTX 3090 GPUs on Windows, which require CUDA 11.1. Hence, I used a tf-nightly-gpu release.

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

Complete code is attached.

The relevant bit is probably the tf.data dataset construction and how the fit command is executed:

```
# Construct tf.data.Dataset
paths_ds = tf.data.Dataset.from_tensor_slices(image_paths)
paths_ds = paths_ds.shuffle(buffer_size=len(image_paths), reshuffle_each_iteration=True)  # reshuffle each epoch
dataset = paths_ds.map(
  lambda path: (self.load_image(path), self.get_onehot_label(path, tf_class_index_by_image, self.num_classes)),
  num_parallel_calls=num_threads
)
dataset = dataset.batch(batch_size)
dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)  #TODO: why does this sometimes slow things down?
self.dataset = dataset
```

The intent of this pipeline is to shuffle the dataset completely each epoch by shuffling the file names. Then, I would like to prefetch and load -- in parallel -- as many images as possible.

```
model.fit(callbacks=callbacks_list, x=data.dataset, epochs=options.epochs)
```


**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

Windows performance monitoring screenshots are attached. Please note the difference between CPU_Epoch1 / GPU_Epoch1 and CPU_Epoch2 / GPU_Epoch2 image sets.


Sample code: [VGG_Bug_Sample_Code.txt](https://github.com/tensorflow/tensorflow/files/5585368/VGG_Bug_Sample_Code.txt)

CPU Epoch 1:

![CPU_Epoch1](https://user-images.githubusercontent.com/1285573/100008084-d3a88580-2d81-11eb-85bf-0f85b413ceff.jpg)

GPU Epoch 1:

![GPU_Epoch1](https://user-images.githubusercontent.com/1285573/100008115-dc00c080-2d81-11eb-8eff-0db5be3e4297.jpg)

CPU Epoch 2 (reduced utilization):

![CPU_Epoch2](https://user-images.githubusercontent.com/1285573/100008098-d73c0c80-2d81-11eb-99cc-bdf9026ca071.jpg)

GPU Epoch 2 (substantial bottleneck visible):

![GPU_Epoch2](https://user-images.githubusercontent.com/1285573/100008137-e0c57480-2d81-11eb-9d34-3eae6ba67d59.jpg)
"
45113,Documentation for using a private CocoaPod spec for TensorFlow Lite is not correct,"## URL(s) with the issue:

https://www.tensorflow.org/lite/guide/build_ios#using_local_tensorflow_lite_core

## Description of issue (what needs changing):

### Clear description

The documentation linked above says to change the following line in the TensorFlowLiteC.podspec file:

```
  s.source       = { :http => ""file://<path_to_TensorFlowLiteC_framework.zip>"" }
```

It then asks you to follow the instructions on [creating a private CocoaPod repo](https://guides.cocoapods.org/making/private-cocoapods.html) to use this pod in your project.

That guide asks you to run the following:

```
pod repo push tfliteswift TensorFlowLiteC.podspec
```

But when you do this, you get an error message about the podspec line:

```
[!] Error installing TensorFlowLiteC
 -> TensorFlowLiteC (2.3.0)
    - ERROR | [iOS] unknown: Encountered an unknown error ([!] /usr/local/anaconda3/bin/curl -f -L -o /var/folders/5j/wwtlv8lx0m5fmhc3hy5w5_000000gp/T/d20201123-17126-1ko7ol4/file.zip file://<redacted>/tensorflow/bazel-bin/tensorflow/lite/experimental/ios/TensorFlowLiteC_framework.zip --create-dirs --netrc-optional --retry 2 -A 'CocoaPods/1.10.0 cocoapods-downloader/1.4.0'

curl: (3) URL using bad/illegal format or missing URL
```
I don't believe the `:http => ""file://<path_to_TensorFlowLiteC_framework.zip>""` line makes sense, because you're specifying a local file path for the `http` key. It's clearly not an http URL. Therefore I believe this documentation is incorrect / incomplete.

I have yet to get my app compiling with a custom build of TensorFlowLite, so I don't know the solution. Any help appreciated."
45112,Tensorflow 2.x can't feed data with non-uniform shapes to a multi-input multi-output model,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): 2.3.1
- Are you willing to contribute it (Yes/No): Yes



**Describe the feature and the current behavior/state.**
There are currently no documentations on feeding data with non-uniform shape to a multi-input multi-output model with a tf.data.dataset.generator. When I tried to do so, I will receive such an error: `Data is expected to be in format x, (x,), (x, y), or (x, y, sample_weight)`.

Because each piece of data has the shape of (None,5), it is not possible to convert it to numpy arrays, which can be easily feed into the model. Moreover, tf.ragged_tensor can't be fed into the model, so I couldn't figure out a way to feed my data. I understand I can probably solve this with paddings, but that's going to be my last choice. Is there a way to feed data with non-uniform shape to a multi-input multi-output model regardless of what method being used?

Thanks to all in advance!

Here's the code to reproduce my issues:

```
import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers

dummy_1 = [[[1.1,2,3,4,5],[2,3,4,5,6],[3,4,5,6,7]],
           [[1.2,2,3,4,5],[2,3,4,5,6.8]],
           [[1.3,2,3,4,5],[2,3,4,5,6],[3,4,5,6,7],[4,5,6,7,8.9]]]

dummy_2 = [[[1.1,2,3,4,5],[2,3,4,5,6]],
           [[1.1,2,3,4,5],[2,3,4,5,6]],[3,4,5,6,7],
           [[1.3,2,3,4,5],[2,3,4,5,6]]]

dummy_3 = [[[1.5,2,3,4,5],[2,3,4,5,6]],
           [[1.6,2,3,4,5],[2,3,4,5,6]],[3,4,5,6,7],
           [[1.7,2,3,4,5],[2,3,4,5,6]]]

def gen():
    for i in range(len(dummy_1)):
        yield(dummy_1[i],dummy_2[i],dummy_2[i],dummy_3[i])

def custom_loss(y_true, y_pred):
    return tf.reduce_mean(tf.abs(y_pred - y_true))

class network():
    def __init__(self):
        input_1 = keras.Input(shape=(None,5))
        input_2 = keras.Input(shape=(None,5))
        output_1 = layers.Conv1DTranspose(16, 3, padding='same', activation='relu')(input_1)
        output_2 = layers.Conv1DTranspose(16, 3, padding='same', activation='relu')(input_2)

        self.model = keras.Model(inputs=[input_1, input_2],
                                 outputs=[output_1, output_2])
        
        # compile model
        self.model.compile(optimizer=keras.optimizers.SGD(learning_rate=0.001),
                           loss={""mel_loss"":custom_loss, ""mag_loss"":custom_loss})
    
    def train(self):
        self.dataset = tf.data.Dataset.from_generator(gen, 
                                                      (tf.float32, tf.float32, tf.float32, tf.float32))
        self.dataset.batch(32).repeat()
        self.model.fit(self.dataset,epochs=3)
        #self.model.fit([dummy_1, dummy_2],
        #               [dummy_2, dummy_3],
        #               epochs=3)

net = network()
net.train()
```

**Will this change the current api? How?**
Yes, if there are currently no support for feeding data with non-uniform shape to a multi-input multi-output model.

**Who will benefit with this feature?**
People who are working with time-series data that has an inconsistent dimension that represent the timesteps.

**Any Other info.**
"
45110,Perhaps TF graph connectivity issues in keras-based Model containing Masking layers,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
[gist](https://gist.github.com/klausk55/b2a9117989d32b8f55ad6aeb99532728)
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Ubuntu-20.04 on a Windows Subsystem for Linux (WSL)
- TensorFlow version (use command below):
2.3.1 v2.3.0-54-gfcc4b966f1
- Python version:
3.8.2 64-bit using a venv
- Ray[rllib] version (RL framework):
1.0.1.post1
- Text editor (development environment):
Visual Studio Code

**Describe the current behavior**
Get `InvalidArgumentError: You must feed a value for placeholder tensor` if line 73 in _articleSchedulingModel.py_ is active, instead comment in line 74 and comment out line 73 then there is no error.
It seems to me that perhaps there might be an issue with connectivity of the TF graph similar to a former related issue mentioned in this [annotation](https://github.com/ray-project/ray/blob/084f03797b7a88e4ba491b329eb6e1634905fb72/rllib/examples/models/batch_norm_model.py#L81):

> IMPORTANT NOTE: This model will not work with PPO due to a bug in keras
    that surfaces when having more than one input placeholder (here: `inputs`
    and `is_training`) AND using the `make_tf_callable` helper (e.g. used by
    PPO), in which auto-placeholders are generated, then passed through the
    tf.keras. models.Model. In this last step, the connection between 1) the
    provided value in the auto-placeholder and 2) the keras `is_training`
    Input is broken and keras complains.

My assumption is that some connection gets lost in the tf.keras.Model caused by the masking layer defined in line 64 and further connected to the concatenate layer defined in line 73 (in _articleSchedulingModel.py_).

Is the assumption appropriate or what else might cause this error?

**Standalone code to reproduce the issue**
Link to [gist](https://gist.github.com/klausk55/b2a9117989d32b8f55ad6aeb99532728)

**Other info / logs**
Traceback also in [gist](https://gist.github.com/klausk55/b2a9117989d32b8f55ad6aeb99532728)
"
45109,Intermediate-level guide in Time Series Forecasting example,"## URL(s) with the issue:

https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/time_series.ipynb

## Description of issue (what needs changing):

### Clear description

I believe this guide is overly complex for most basic time-series forecasting measures. Due to the introduction of a class for windowing, while this makes it easy to re-use code between examples, it doesn't do a very good job of creating basic windows that users might benefit from for a basic use case.

For example, I only want some basic windowing, I found more help setting this up in the keras preprocessing docs here https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/timeseries_dataset_from_array than I did in this help page.

While this page demonstrates many potential use cases quite simply, I believe another page is required which outlines the very basic steps just to get one of these working with an intro to windowing as well.
"
45106,Error during building examples for ARC target in TFLM.,"@tensorflow/micro

**System information**
- Host OS Platform and Distribution (e.g., Linux Ubuntu 16.04): all
- TensorFlow installed from (source or binary): source
- Tensorflow version (commit SHA if source): master
- Target platform (e.g. Arm Mbed OS, Arduino Nano 33 etc.): ARC

During building generated for ARC target project, user gets the following error:
```
In file included from tensorflow/lite/micro/kernels/arc_mli/fully_connected.cc:27:
.\tensorflow/lite/micro/kernels/arc_mli/mli_tf_utils.h:99:16: error: static_cast from 'const int *' to 'void *' is not allowed
  mliT->data = static_cast<void*>(tflite::micro::GetTensorData<datatype>(tfT));
               ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
```
Need to fix mli_tf_utils.h file.
"
45105,ValueError: Input tensors to a Functional must come from `tf.keras.Input`. Received: 0 (missing previous layer metadata).,"from tensorflow.keras import backend as K
get_activations = K.function([model.layers[0].input,model.layers[1].input,model.layers[2].input,model.layers[3].input, K.learning_phase()],[model.layers[layer_idx].output,])

TF 2.3.1

Windows 10 in anaconda python 3.8 environment

Got error while executing(four stream architecture)
ValueError: Input tensors to a Functional must come from `tf.keras.Input`. Received: 0 (missing previous layer metadata)."
45104,Missing dependency on PowerPCCodeGen leads to undefined references in tf_to_kernel,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): RHEL 7.4, PPC

**Describe the problem**

Running the tests with `bazel test ...` leads to undefined reference errors, see below log extract.
The reason is that `InitializeNativeTarget` is called which seemingly is a generated function and while the x86 dependency lib is linked via `@llvm-project//llvm:X86CodeGen`, the PPC equivalent is not.

The same problem may also affect ARM and arch64. Compare https://github.com/tensorflow/tensorflow/blob/15f4bda049539dd41c6dd9d0737d33da86cc32cf/tensorflow/compiler/aot/BUILD#L73-L83
with https://github.com/tensorflow/tensorflow/blob/15f4bda049539dd41c6dd9d0737d33da86cc32cf/tensorflow/compiler/mlir/tools/kernel_gen/BUILD#L122-L123

I think those lists should be pretty much identical.

**Provide the exact sequence of commands / steps that you executed before running into the problem**

`bazel test //tensorflow/...`

**Any other info / logs**

```
SUBCOMMAND: # //tensorflow/core/kernels/mlir_generated:invert_i32_kernel_cubin [action 'compile tensorflow/core/kernels/mlir_generated/invert_i32_kernel_cubin.sm_37.bin', configuration: 18b45a5a4afc1ae33c4d05
7c86644439e6ecd019473065d664167c1910aff23b, execution platform: @local_execution_config_platform//:platform]
...
bazel-out/ppc-opt/bin/tensorflow/compiler/mlir/tools/kernel_gen/_objs/tf_to_kernel/tf_to_kernel.o:tf_to_kernel.cc:function main: error: undefined reference to 'LLVMInitializePowerPCTargetInfo'
bazel-out/ppc-opt/bin/tensorflow/compiler/mlir/tools/kernel_gen/_objs/tf_to_kernel/tf_to_kernel.o:tf_to_kernel.cc:function main: error: undefined reference to 'LLVMInitializePowerPCTarget'
bazel-out/ppc-opt/bin/tensorflow/compiler/mlir/tools/kernel_gen/_objs/tf_to_kernel/tf_to_kernel.o:tf_to_kernel.cc:function main: error: undefined reference to 'LLVMInitializePowerPCTargetMC'
bazel-out/ppc-opt/bin/tensorflow/compiler/mlir/tools/kernel_gen/_objs/tf_to_kernel/tf_to_kernel.o:tf_to_kernel.cc:function main: error: undefined reference to 'LLVMInitializePowerPCAsmPrinter'
collect2: error: ld returned 1 exit status
```
"
45103,TFLiteConverter.from_saved_model runs on an error,"**System information**
- using colab


**Command used to run the converter or code if you’re using the Python API**

Trained model:
https://colab.research.google.com/drive/1PRuBCtkp8WIQn66IbGjgvfr-kLMpA3P5?usp=sharing (just in case you want to see, that the model actually works)

Colab with the tfLite-Converter:
https://colab.research.google.com/drive/1up5goKZLY6rfTTt98mg7KRqZoUAeEaIO?usp=sharing

```
model_dir=""./saved_model""
converter = tf.lite.TFLiteConverter.from_saved_model(model_dir)
tflite_model = converter.convert()
open('detect.tflite','wb').write(tflite_model)
```

**The output from the converter invocation**

```
ValueError: None is only supported in the 1st dimension. Tensor 'image_tensor' has invalid shape '[None, None, None, 3]'.
```

**Also, please include a link to the saved model or GraphDef**

```
https://github.com/SerQuicky/shoe-dataset/tree/master/models/stock_shoe_model
```

**Any other info / logs**

Hello guys, I actually trained a Mobilenet SSD v1 model and it works fine in Colab (test it through the first Colab link).
Now I am trying to convert the model to a tflite model so I can use it on my android phone.

I am using tensorflow version 1.15.0. The [documentation](https://www.tensorflow.org/versions/r1.15/api_docs/python/tf/lite/TFLiteConverter) has an example for the conversion from a saved model to tflite, sadly it does not work.   

Complete stacktrace

```
ValueError                                Traceback (most recent call last)
<ipython-input-10-40156df8e12f> in <module>()
      8 #converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]
      9 
---> 10 tflite_model = converter.convert()
     11 open('detect.tflite','wb').write(tflite_model)

/tensorflow-1.15.2/python3.6/tensorflow_core/lite/python/lite.py in convert(self)
    894               ""None is only supported in the 1st dimension. Tensor '{0}' has ""
    895               ""invalid shape '{1}'."".format(
--> 896                   _get_tensor_name(tensor), shape_list))
    897         elif shape_list and shape_list[0] is None:
    898           self._set_batch_size(batch_size=1)

ValueError: None is only supported in the 1st dimension. Tensor 'image_tensor' has invalid shape '[None, None, None, 3]'.
```

"
45101,TFRecords writing and reading,"Hi,
i have a very huge data and which I want to convert to tfrecords before sending it to neural network. My writing code is 
`for n, pat in tqdm(enumerate(pats)):
    cache_file = cache_dir+f'{pat}.tfrecords'
    writer = tf.io.TFRecordWriter(cache_file)
    files = os.listdir(pat_dir+pat+'/')
    files.sort()
    X_train = []
    for i, file in enumerate(files):
        byte_image = tf.io.read_file(pat_dir+pat+'/'+file)
        image = tfio.image.decode_dicom_image(byte_image, dtype=tf.uint16)
        image = image.numpy()
        image = image/(image.max())
        X_train.append(image)
    X_train = np.array(X_train).reshape((180, 256, 256, 1))
    Y_train = imread(lab_dir+lab_files[n], as_gray=True)
    Y_train = tf.keras.utils.to_categorical(Y_train, num_classes=3)
    # plt.imshow(Y_train)
    # plt.show()
    feature = { 'train/label'  : _bytes_feature(tf.compat.as_bytes(Y_train.tostring())),
                 'train/images' : _bytes_feature(tf.compat.as_bytes(X_train.tostring()))
               }
    example = tf.train.Example(features=tf.train.Features(feature=feature))
    writer.write(example.SerializeToString())
    writer.close()
    del writer
    gc.collect()`
which i think is working perfectly fine but when i follow the example given on keras page to read tfrecords [https://keras.io/examples/keras_recipes/tfrecord/](url) it reads all the files fine but for last two files it gives a dimension error. My reading code is 
`def read_tfrecord(example):
    tfrecord_format ={'train/label'  : tf.io.FixedLenFeature([], tf.string),
            'train/images' : tf.io.FixedLenFeature([], tf.string)}
    example = tf.io.parse_single_example(example, tfrecord_format)
    tr_images = tf.io.decode_raw(example['train/images'], tf.float32)
    tr_label = tf.io.decode_raw(example['train/label'], tf.float32)
    tr_images = tf.reshape(tr_images, [180, 256, 256, 1])
    tr_label = tf.reshape(tr_label, [1, 256, 256, 3])
    return tr_images, tr_label`
the problem is that it reads all the fines just fine but last two files are merged together and when gives this error
`Cannot reshape a tensor with 2949120 elements to shape [180,256,256,1] (11796480 elements) for '{{node Reshape}} = Reshape[T=DT_FLOAT, Tshape=DT_INT32](DecodePaddedRaw, Reshape/shape)' with input shapes: [2949120], [4] and with input tensors computed as partial shapes: input[1] = [180,256,256,1].`
please help!
sorry for my English it's not good but i hope that someone gets my point and will reply me soon. and also this is my 1st time with any issue so forgive me if i have not follow the pattern."
45100,C and Java perfomance differences under Android,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS Catalina 10.15.7
- Mobile device: Android with MT8512 processor
- TensorFlow installed from (source or binary): Source (C code) and binary (Java)
- TensorFlow version (use command below): v1.12.1-45356-g73272ab087 2.5.0-dev20201107
- Python version: 3.7
- Bazel version: 3.1
- Android NDK version: r21d with API level 22
- Target architecture: armv7

**Describe the current behavior**

I have 2 different models running under TFLite and implementations in Java and C for benchmarking. First model runs about 10% slower using TFLite in C code than Java equivalent. Second model runs about 4-5% faster in C than in Java. Copying to and from input/output buffers is neglible in terms of execution time. Going multithreaded causes both models to run slower in C with bigger gaps.

**Describe the expected behavior**

Inference in plain C should've been at least as fast as in Java in every case.


TFLite in C is built with bazel command:
`bazel build -c opt --config=android_arm --verbose_failures //tensorflow/lite/c:tensorflowlite_c`
Binaries needed for Java are pulled from Tensorflow's provided repositories.

Are there any compile options different for C and Java binaries that may cause performance differences? What else can cause it?

Thanks in advance
"
45097,installation of any version on python 3.9 and installation of v1.x on python 3.8,"**System information**
- OS Platform and Distribution: Fedora 32 and Fedora 33
- TensorFlow installed from (source or binary): pip/wheel
- TensorFlow version: any
- Python version: python 3.9 on Fedora 33 and python 3.8 on Fedora 32

**Describe the problem**

No version at all available for python 3.9

```
$ python3 --version
Python 3.9.0
$ pip3 install --user tensorflow
ERROR: Could not find a version that satisfies the requirement tensorflow (from versions: none)
ERROR: No matching distribution found for tensorflow
```

no 1.x available on python 3.8

```
$ python3 --version
Python 3.8.3
$ pip3 install --user tensorflow==1.15
WARNING: Running pip install with root privileges is generally not a good idea. Try `pip3 install --user` instead.
ERROR: Could not find a version that satisfies the requirement tensorflow==1.15 (from versions: 2.2.0rc1, 2.2.0rc2, 2.2.0rc3, 2.2.0rc4, 2.2.0, 2.2.1, 2.3.0rc0, 2.3.0rc1, 2.3.0rc2, 2.3.0, 2.3.1, 2.4.0rc0, 2.4.0rc1, 2.4.0rc2)
ERROR: No matching distribution found for tensorflow==1.15

```

**Provide the exact sequence of commands / steps that you executed before running into the problem**

above

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

above
"
45096,How to save a keras.Model with an embedded hub.KerasLayer ?,"**System information**
- Have I written custom code: No
- OS Platform and Distribution: [Google Colab](https://colab.research.google.com/drive/18VmYP7Q5GmdToZCX3mx5Msmby0WfEMRE?usp=sharing)
- TensorFlow installed from (source or binary): [Google Colab](https://colab.research.google.com/drive/18VmYP7Q5GmdToZCX3mx5Msmby0WfEMRE?usp=sharing)
- TensorFlow version (use command below): 2.3.0
- Python version: 3.7

**Describe the current behavior**
Method 1
```python
model = tf.keras.Sequential([
    hub.KerasLayer(""https://tfhub.dev/google/bit/s-r50x1/1""),
])

model.build(input_shape=(None, 224, 224, 3))
model.save(""/tmp"")
# Success
```

Method 2
```python
class DummyModel(tf.keras.Model):

  def __init__(self):
    super(DummyModel, self).__init__()
    self.model = hub.KerasLayer(""https://tfhub.dev/google/bit/s-r50x1/1"")

  def call(self, inputs):
    return self.model(inputs)


model = DummyModel()
model.build((None, 224, 224, 3))
model.save(""/tmp"")
# Error
```

**Describe the expected behavior**
How can I properly build a Model with an embedded KerasLayer? 

Method 1 succeeds, but method 2 fails with `ValueError: Model cannot be saved because the input shapes have not been set.`

This is a minimized version. I explicitly need a design like method #2 for my more complicated problem.

**Standalone code to reproduce the issue**
[Google Colab](https://colab.research.google.com/drive/18VmYP7Q5GmdToZCX3mx5Msmby0WfEMRE?usp=sharing)
"
45095,Failed to build wheel on MacOS Big Sur,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS Big Sur 11.0.1
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NONE
- TensorFlow installed from (source or binary): source
- TensorFlow version: latest from tensorflow:master
- Python version: 3.8.2
- Installed using virtualenv? pip? conda?: NONE
- Bazel version (if compiling from source): 3.1.0
- GCC/Compiler version (if compiling from source): Apple clang version 12.0.0 (clang-1200.0.32.27)
- CUDA/cuDNN version: NONE
- GPU model and memory: NONE

Hello, 

after successfuly compiled tensorflow by the Bazel, I try to make a wheel file. I used './bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg', but the result folder /tmp/tensorflow_pkg didn't exist. I send screenshot with output from building wheel.

<img width=""1074"" alt=""Snímka obrazovky 2020-11-23 o 10 04 34"" src=""https://user-images.githubusercontent.com/74611856/99944598-71488880-2d73-11eb-9d04-550bce91f38c.png"">
<img width=""1074"" alt=""Snímka obrazovky 2020-11-23 o 10 04 49"" src=""https://user-images.githubusercontent.com/74611856/99944607-74437900-2d73-11eb-81fe-48cc9d9f87dc.png"">

"
45094,ModuleNotFoundError: No module named 'tensorflow.contrib.keras.python',"When I run the following code, I met the error as written above
`from tensorflow.contrib.keras.python.keras.initializers import TruncatedNormal`  
Is this bug caused by the tensorflow version?

**System information**
- OS Platform and Distribution: Linux Ubuntu 16.04
- TensorFlow installed from (source or binary): pip
- TensorFlow version (use command below): tensorflow -gpu1.14.0
- Python version: 3.6"
45093,AttributeError: 'TensorArray' object has no attribute 'mark_used' with tf.function,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): colab
- TensorFlow version (use command below):  v2.3.0-54-gfcc4b966f1 2.3.1


You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:

**Describe the current behavior**

```python
import tensorflow as tf
import tensorflow_probability as tfp
tfd = tfp.distributions 

class Test(tf.Module):
  def __init__(self):
    self.log_likes_list = None
    self.i = tf.constant(0)

  @tf.function
  def __call__(self, samples):

    @tf.function
    def rnd():
        return tfd.Normal(0,1).sample()+ tfd.Normal(3,1).sample()
      
    if self.log_likes_list is None:
        self.log_likes_list = tf.TensorArray(tf.float32, size=samples) 

    def cond(x,i):
        return tf.less(i, samples) 

    def body(x,i):
        #x=x.write(i,tfm.reduce_sum(tfd.Normal(rnd(), 1).log_prob(0.4)))
        # AttributeError: 'TensorArray' object has no attribute 'mark_used'
        x.write(i,tfm.reduce_sum(tfd.Normal(rnd(), 1).log_prob(0.4))).mark_used()
        return x, i+1 

    self.log_likes_list, i = tf.while_loop(cond, body, [self.log_likes_list, self.i])

    self.log_likes = self.log_likes_list.stack()

    self.log_like = tfm.reduce_mean(self.log_likes)

    loss = self.log_like

    return loss


T= Test()
t= T(5)

T.log_likes, T.log_like, 
# the code in below is not running 
T.log_likes_list.stack()
```


**Describe the expected behavior**
How can get values in t.log_likes, and t.log_like, and t.log_likes_list?


**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.
https://colab.research.google.com/drive/1ddlIXUBOHd5umTaCW-xghWk3bTOIKhVf#scrollTo=-yj19j0eC_cj

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
45092,manylinux2010 compatible libtensorflow for TF 2.x,"The official TF 2.x libtensorflow binaries for linux are built in a manylinux2010 sysroot only when using CUDA.

https://github.com/tensorflow/tensorflow/blob/fcc4b966f1265f466e82617020af93670141b009/tensorflow/tools/ci_build/builds/libtensorflow.sh#L54-L59

Ideally CPU libtensorflow builds would be built in a manylinux2010 compatible way as well.

Happy to put up a PR if this makes sense.
"
45091,Adding a Lite flag to tf.keras.applications.EfficientNetBX,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): 2.4.0-rc2
- Are you willing to contribute it (Yes/No): No


**Describe the feature and the current behavior/state.**
Currently, EfficientNetB0 to B7 are available via keras.applications.
In May, tensorflow released a [blog entry](https://blog.tensorflow.org/2020/03/higher-accuracy-on-vision-models-with-efficientnet-lite.html) that 'Lite' variants of EfficientNet are available on [tensorflow/tpu](https://github.com/tensorflow/tpu/tree/master/models/official/efficientnet/lite). 
The models can in addition be used from tensorflow [Hub](https://tfhub.dev/tensorflow/efficientnet/lite0/classification/2) and tfLite model maker. Yet, these models are created as TF1 graphs and cannot be readily used for fine-tuning etc. in tensorflow 2.X.

Is it possible to introduce a flag in tf.keras.applications.EfficientNet that will load the 'lite' variant, similar to the 'minimalistic' flag of MobileNetV3?

**Will this change the current api? How?**
Yes, tensorflow/python/keras/applications/efficientnet.py would get an additional flag that will load the corresponding weight file, and will remove squeeze&excite modules and substitute swish by relu6 

**Who will benefit with this feature?**
Everyone who wants to use EfficientNet Lite in tensorflow2, for fine-tuning or layer-wise custom actions.

**Any Other info.**
"
45090,tf keras upsample2d operator produces wrong results on tflite conversion,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- TensorFlow installed from (source or binary): source and binary
- TensorFlow version (or github SHA if from source): 2.3.0, tf-nightly, 2.5.0(latest source)


**Command used to run the converter or code if you’re using the Python API**
If possible, please share a link to Colab/Jupyter/any notebook.
Colab Link: https://colab.research.google.com/drive/1QZo8QZubmiiXIxc0O8SZEfEsfaxN5kxR?usp=sharing

```
converter = tf.lite.TFLiteConverter.from_keras_model(model)
tflite_model = converter.convert()
open(""mnv3_test.tflite"", ""wb"").write(tflite_model)
```

**Failure details**
The conversion is successful, but the generated model is wrong,

The tf keras model with **upsample2d layers(bilinear interpolation)** correctly produces a h5 file; but the converted tflite model has **extra layers** and there is **shape mismatch**.The **output shape becomes 1x1** instead of original upsampled size. The error occurs in tf 2.3.0, tf nightly and latesr source (dev 2.5.0). The conversion produces **additonal shape, mul and strided slice** layer(not supported by hardware accelerators).

The problem persists even if we use  **ResizeNearestNeighbo**r interpolation.

**Minimal Example**

```
import tensorflow as tf
from tensorflow.keras.layers import Input, Conv2D, UpSampling2D
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam

def get_model():
    
    ip = Input(shape=(256,256,3))
    x= Conv2D(kernel_size=3, filters=32, padding ='same')(ip)
    x = UpSampling2D( size=(2, 2), interpolation='bilinear')(x)
    x= Conv2D(kernel_size=3, filters=32, padding ='same')(x)
    
    
    model = Model(inputs=ip, outputs=x)
    
    model.compile(optimizer=Adam(lr=1e-4),
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy']) # Ensure you have sparse labels
    return model

model=get_model()
converter = tf.lite.TFLiteConverter.from_keras_model(model)
tflite_model = converter.convert()
open(""bilinear.tflite"", ""wb"").write(tflite_model)
```

**Models**
[mnv3_resize_bilinear_test.zip](https://github.com/tensorflow/tensorflow/files/5581389/mnv3_resize_bilinear_test.zip)"
45089,Tensorflow 2. x not recognizing RTX 3090 GPU,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): 16.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): Binary
- TensorFlow version: 2.2 / 2.3/ 2.5.0.dev20201028
- Python version: 3.8
- Installed using virtualenv? pip? conda?: Pip
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 11.1/8.0.4
- GPU model and memory: RTX 3090


I have installed T.F. 2.2 using conda install -C anaconda TensorFlow-gpu, it is installed properly but it is not able to recognize the GPU, I have checked using:-

from tensorflow.python.client import device_lib
device_lib.list_local_devices()

It gives output CPU only.

I have also checked by installing T.F. 2.3 and 2.5 nightly build using pip install but all of them are failed to recognize GPU. Does anyone know the cause and solution?
"
45088,worker go to endless loop when ps send a UnavailableError to worker.,"TF version: tf1.15 & master
I want to implement a small function that is worker blacklist in ps.
PS check worker-blacklist when worker create session on ps.
If PS find an unexpected worker, ps return a errors.UnavailableError to this worker, then refused worker go to endless loop(bug).

I check codes and logs, I find a while(True) when worker recv errors.UnavailableError.
**I think worker should have max retry time and sleep when worker recv errors.UnavailableError.(pr)**
of course, I will add retrun permission error when ps frequently recv new connection from refused worker .
pseudo code:https://github.com/zhaozheng09/tensorflow/pull/1/files

Should we change endless-loop to max_retry-loop when worker create session ?"
45086,Create makefile targets to expose file lists to enable separate scripting,"As the first step in the project generation process described in https://docs.google.com/document/d/1gfbpBtiivYMenCDIvJb-m5RIV4rKAR5dvdAJC5LLv8o/edit?usp=sharing we need to expose the file lists held within the makefile through an API. This bug is to track the work involved in that process.
"
45083,Which version of Protobuf do I need to compile the TensorFlow2.0 source code ？,Which version of Protobuf do I need to compile the TensorFlow2.0 source code ？
45082,mnasnet with squeeze and excite can not be quantized," I wrote a Colab document with Mnasnet in keras and added a squeeze and excite block
TensorFlow was 2.3.0
I have been able to generate the .h5 file correctly 
However when I apply the post training quantization procedure, I have this error
RuntimeError: Unsupported output type INT8 for output tensor 'Identity' of type FLOAT32.
Without the squeeze and excite block it works nicely generating int8 version
Attached the notebook
[Quantize_procedure_mnasnet_se.zip](https://github.com/tensorflow/tensorflow/files/5580189/Quantize_procedure_mnasnet_se.zip)
Thanks and kind regards
Danilo
"
45081,Management of Gpu memory by fit method to avoid memory errors,"
**System information**
- Colab GPU kernel (Tf : 2.3.0 , GPUs Available : 1)

**Describe the current behavior**
There are memory errors when:
- I fit models with huge value for batch size ;
- I fit CNN models with large images ;

**Describe the expected behavior**
Update the fit method so that the training of models can according to the memory available on the GPU and automatically define the best mini-batch size (split the batch into several parts) to avoid the memory errors so that users no longer have to reduce batch size or image size.
For large images, the fit method should be able to split the image into several parts to try to reduce the risk of memory errors."
45079,Custom loss function always throws: TypeError: __init__() takes 1 positional argument but 3 were given,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution : Linux Ubuntu 20.04
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.3.1
- Python version: 3.8.5
- CUDA/cuDNN version: 10.1 / 7.6.5
- GPU model and memory: GTX 1060 (6gb)

**Describe the current behavior**
I've created a custom loss function by subclassing from `tf.keras.losses.Loss` and a model using the functional API and specified its outputs to be that of two layers, I need one of them to passed to the loss function and another is the actual output that should print out to the user. Since there are two outputs I pass a list of the same loss when compiling the model and specify the loss weights as `[1.0, 0.0]` because I only care about the loss of one output. When I try the model using on of the basic losses like `categorical_crossentropy` it runs fine. But when I use the loss function I wrote it throws me `TypeError: __init__() takes 1 positional argument but 3 were given`. Furthermore, when building the model, I tried specifying the output to be only one value instead of two, and the same issue arises.

**Describe the expected behavior**
The loss function should work normally since I wrote it according to the docs.

**Standalone code to reproduce the issue**
[Colab link](https://colab.research.google.com/drive/1nB2kVk_e_Mj3dy8mJ0kka2gHHLUSwiHn?usp=sharing)
"
45078,Model weights using the HDF5 format are not saved,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Yes
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): Not on mobile device
- TensorFlow version (use command below): 2.3
- Python version: 3.6.9
- Bazel version (if compiling from source): Not compiling from source
- GCC/Compiler version (if compiling from source): Not compiling from source
- CUDA/cuDNN version: No GPU
- GPU model and memory: No GPU

**Describe the current behavior**

When using the HDF5 format to save the weights of a model (directly added in the model class), the value of the weights I get when loading the model are not the same as the ones of the saved model.

**Describe the expected behavior**

The value of the weights of the loaded model should be the same as that of the saved model.

**Standalone code to reproduce the issue**

This is [the colab](https://colab.research.google.com/drive/1TAitBc7wM_5jj0vi3V00xoH7paFxy2YP?usp=sharing) I used to illustrate this issue.

**Other info / logs**

When using layers in the model, instead of weights added via (`self.add_weight`), the values of the layers' weights are correctly saved. So it's really a problem of the weights of a `Model` not being saved (or loaded correctly)."
45077,Model saving using the tf format uses the wrong TensorSpec for convolutions,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Yes
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Not on mobile device
- TensorFlow installed from (source or binary): Colab
- TensorFlow version (use command below): 2.3
- Python version: 3.6.9
- Bazel version (if compiling from source): Not compiling from source
- GCC/Compiler version (if compiling from source): Not compiling from source
- CUDA/cuDNN version: No GPU
- GPU model and memory: No GPU


**Describe the current behavior**

When saving a subclassed model, using the SavedModel format, the inputs specifications for a convolution layer are not correctly infered.

The error is the following:
```
ValueError: Python inputs incompatible with input_signature:
  inputs: (
    tf.Tensor(
[[[[1.]
   [1.]
   [1.]
   ...
   [1.]
   [1.]
   [1.]]

  [[1.]
   [1.]
   [1.]
   ...
   [1.]
   [1.]
   [1.]]

  [[1.]
   [1.]
   [1.]
   ...
   [1.]
   [1.]
   [1.]]

  ...

  [[1.]
   [1.]
   [1.]
   ...
   [1.]
   [1.]
   [1.]]

  [[1.]
   [1.]
   [1.]
   ...
   [1.]
   [1.]
   [1.]]

  [[1.]
   [1.]
   [1.]
   ...
   [1.]
   [1.]
   [1.]]]], shape=(1, 32, 32, 1), dtype=float32))
  input_signature: (
    TensorSpec(shape=(None, 96, 96, 1), dtype=tf.float32, name='input_1'))
```

Using the solution from [the documentation on how to specify the signature during export](https://www.tensorflow.org/guide/saved_model#specifying_signatures_during_export) didn't work.

The error I got was the following:
```
AttributeError: 'function' object has no attribute 'get_concrete_function'
```

**Describe the expected behavior**

I would like to be able to save my convolutional model and be able to reuse it on inputs with arbitrary batch size (already the case), width and height (not the case).

**Standalone code to reproduce the issue**
This is [the colab](https://colab.research.google.com/drive/1YBSOmfNMFkmA_t1hyjCA0dG9vUiYxQNt?usp=sharing) I did to illustrate this bug.

**Other info / logs** 

The full stack trace for the inputs spec mismatch is the following:

```
ValueError                                Traceback (most recent call last)
<ipython-input-9-bba6984211c7> in <module>()
----> 1 other_model(tf.ones([1, 32, 32, 1]))

5 frames
/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py in __call__(self, *args, **kwargs)
    983 
    984         with ops.enable_auto_cast_variables(self._compute_dtype_object):
--> 985           outputs = call_fn(inputs, *args, **kwargs)
    986 
    987         if self._activity_regularizer:

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model/utils.py in return_outputs_and_add_losses(*args, **kwargs)
     69     inputs = args[inputs_arg_index]
     70     args = args[inputs_arg_index + 1:]
---> 71     outputs, losses = fn(inputs, *args, **kwargs)
     72     layer.add_loss(losses, inputs=inputs)
     73 

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py in __call__(self, *args, **kwds)
    778       else:
    779         compiler = ""nonXla""
--> 780         result = self._call(*args, **kwds)
    781 
    782       new_tracing_count = self._get_tracing_count()

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py in _call(self, *args, **kwds)
    842       canon_args, canon_kwds = \
    843           self._stateful_fn._function_spec.canonicalize_function_inputs(  # pylint: disable=protected-access
--> 844               *args, **kwds)
    845       # If we did not create any variables the trace we have is good enough.
    846       return self._concrete_stateful_fn._filtered_call(canon_args, canon_kwds)  # pylint: disable=protected-access

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py in canonicalize_function_inputs(self, *args, **kwargs)
   2620           inputs,
   2621           self._input_signature,
-> 2622           self._flat_input_signature)
   2623       return inputs, {}
   2624 

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py in _convert_inputs_to_signature(inputs, input_signature, flat_input_signature)
   2711       flatten_inputs)):
   2712     raise ValueError(""Python inputs incompatible with input_signature:\n%s"" %
-> 2713                      format_error_message(inputs, input_signature))
   2714 
   2715   if need_packing:

ValueError: Python inputs incompatible with input_signature:
  inputs: (
    tf.Tensor(
[[[[1.]
   [1.]
   [1.]
   ...
   [1.]
   [1.]
   [1.]]

  [[1.]
   [1.]
   [1.]
   ...
   [1.]
   [1.]
   [1.]]

  [[1.]
   [1.]
   [1.]
   ...
   [1.]
   [1.]
   [1.]]

  ...

  [[1.]
   [1.]
   [1.]
   ...
   [1.]
   [1.]
   [1.]]

  [[1.]
   [1.]
   [1.]
   ...
   [1.]
   [1.]
   [1.]]

  [[1.]
   [1.]
   [1.]
   ...
   [1.]
   [1.]
   [1.]]]], shape=(1, 32, 32, 1), dtype=float32))
  input_signature: (
    TensorSpec(shape=(None, 96, 96, 1), dtype=tf.float32, name='input_1'))
```

The full stack trace for the signature specification error is the following:
```
AttributeError                            Traceback (most recent call last)
<ipython-input-12-f5c9e67f3a76> in <module>()
----> 1 call = model.__call__.get_concrete_function(tf.TensorSpec([None, None, None, 1], tf.float32))

AttributeError: 'function' object has no attribute 'get_concrete_function'
```"
45074,"Deploy micro_speech to ESP32 , is running ,but do not get any output,how to modify?where is wrong","I deplay micro_speech to esp32,when I say ""yes"" or ""no"" ,there is any output,
how to where is wrong?

below is informtion..
I (32) boot: ESP-IDF v4.1-dirty 2nd stage bootloader
I (32) boot: compile time 17:06:37
I (32) boot: chip revision: 3
I (35) boot_comm: chip revision: 3, min. bootloader chip revision: 0
I (42) qio_mode: Enabling default flash chip QIO
I (48) boot.esp32: SPI Speed      : 80MHz
I (52) boot.esp32: SPI Mode       : QIO
I (57) boot.esp32: SPI Flash Size : 2MB
I (61) boot: Enabling RNG early entropy source...
I (67) boot: Partition Table:
I (70) boot: ## Label            Usage          Type ST Offset   Length
I (78) boot:  0 nvs              WiFi data        01 02 00009000 00006000
I (85) boot:  1 phy_init         RF data          01 01 0000f000 00001000
I (93) boot:  2 factory          factory app      00 00 00010000 00100000
I (100) boot: End of partition table
I (104) boot_comm: chip revision: 3, min. application chip revision: 0
I (112) esp_image: segment 0: paddr=0x00010020 vaddr=0x3f400020 size=0x0d604 ( 54788) map
I (137) esp_image: segment 1: paddr=0x0001d62c vaddr=0x3ffb0000 size=0x01970 (  6512) load
I (139) esp_image: segment 2: paddr=0x0001efa4 vaddr=0x40080000 size=0x00404 (  1028) load
0x40080000: _WindowOverflow4 at C:/Users/Administrator.1-PC/Desktop/esp-idf/components/freertos/xtensa_vectors.S:1778

I (144) esp_image: segment 3: paddr=0x0001f3b0 vaddr=0x40080404 size=0x00c68 (  3176) load
I (154) esp_image: segment 4: paddr=0x00020020 vaddr=0x400d0020 size=0x23be0 (146400) map
0x400d0020: _stext at ??:?

I (204) esp_image: segment 5: paddr=0x00043c08 vaddr=0x4008106c size=0x084b8 ( 33976) load
0x4008106c: esp_crosscore_isr at C:/Users/Administrator.1-PC/Desktop/esp-idf/components/esp32/crosscore_int.c:69

I (222) boot: Loaded app from partition at offset 0x10000
I (222) boot: Disabling RNG early entropy source...
I (222) cpu_start: Pro cpu up.
I (226) cpu_start: Application information:
I (231) cpu_start: Project name:     micro_speech
I (236) cpu_start: App version:      v4.1-dirty
I (241) cpu_start: Compile time:     Nov 22 2020 17:05:27
I (247) cpu_start: ELF file SHA256:  00472dcd8c03272a...
I (253) cpu_start: ESP-IDF:          v4.1-dirty
I (258) cpu_start: Single core mode
I (263) heap_init: Initializing. RAM available for dynamic allocation:
I (270) heap_init: At 3FFAE6E0 len 00001920 (6 KiB): DRAM
I (276) heap_init: At 3FFB5980 len 0002A680 (169 KiB): DRAM
I (282) heap_init: At 3FFE0440 len 0001FBC0 (126 KiB): D/IRAM
I (289) heap_init: At 40078000 len 00008000 (32 KiB): IRAM
I (295) heap_init: At 40089524 len 00016ADC (90 KiB): IRAM
I (301) cpu_start: Pro cpu start user code
I (318) spi_flash: detected chip: generic
I (318) spi_flash: flash io: qio
W (318) spi_flash: Detected size(4096k) larger than the size in the binary image header(2048k). Using the size in the binary image header.
I (330) cpu_start: Starting scheduler on PRO CPU.
I (418) I2S: DMA Malloc info, datalen=blocksize=2400, dma_buf_count=3
I (418) I2S: PLL_D2: Req RATE: 16000, real rate: 16025.000, BITS: 32, CLKM: 39, BCK: 4, MCLK: 4096000.000, SCLK: 1025600.000000, diva: 64, divb: 4
I (468) TF_LITE_AUDIO_PROVIDER: Audio Recording started"
45073,Quantization differences from TensorFlow 1.9 to 2.3,"An issue I found is in regards to INT8 or UINT8 weights on Conv / Dense (trainable) layers during quantization.  Namely, there does not seem to be any way to support UINT8 weights on these layers.  With version 1.9 this was supported as I have implemented my own runtime.  Currently, it seems to only support INT8, Float32, and Float16.  My runtime has to change as a result of this, and it would be nice to know if I am correct in my findings so far on this issue.  I would prefer UINT8 weights on the Conv2D / Dense layers but as mentioned, I cannot see any feasible solution to this problem.  If I am wrong please point me to the correct API usage.

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): OS X
- TensorFlow installed from (source or binary): 2.3.0 GPU (Docker image)

```

# Example code taken from Post-Training Quantization documentation
# https://www.tensorflow.org/lite/performance/post_training_quantization

import tensorflow as tf
converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)
converter.optimizations = [tf.lite.Optimize.DEFAULT]
def representative_dataset_gen():
  for _ in range(num_calibration_steps):
    # Get sample input data as a numpy array in a method of your choosing.
    yield [input]
converter.representative_dataset = representative_dataset_gen
# there is no such tf.lite.OpsSet.TFLITE_BUILTINS_UINT8
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]
converter.inference_input_type = tf.uint8  # or tf.int8 ( note this has zero effect on the tensors produced for Conv2D operations -- all of which include signed int8 unless you were to output the model as float16/32 )
converter.inference_output_type = tf.uint8  # or tf.int8
tflite_quant_model = converter.convert()
```

"
45072,Physical devices not shown when I do have one,"I first import TensorFlow and try to find a GPU configure but it shows nothing.
`physical_devices = tf.config.list_physical_devices(""GPU"")`
![image](https://user-images.githubusercontent.com/68514251/99892785-b91dc180-2c46-11eb-9ad1-0d2173704169.png)
"
45071,Missing DLL when importing (but which one?),"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Win 10 20H2
- TensorFlow installed from (source or binary): pip
- TensorFlow version: 2 (latest as of Nov 22 2020)
- Python version: 3.8
- Installed using virtualenv? pip? conda?: Installed via pip in a conda env
- GPU model and memory: GeForce 1050Ti 4GB



**I run into an issue where I cannot import Tensorflow when using Jupyter from a Conda environment*

**Provide the exact sequence of commands / steps that you executed before running into the problem**
-Fresh Anaconda install
-Fresh C++ redist install
-Create new Conda environment with Python 3.8
-Activate said environment
-Install TF via pip (important, as I need 2.3.0+)
- Install Jupyter notebook
-Open Jupyter notebook
-Try to import TF with `import tensorflow as tf`
-Get error saying I'm missing a DLL, not sure which one

What I noticed and is curious that my _pywrap_tensorflow_internal.py file is completely empty even after multiple reinstalls, and it doesn't matter if I use a brand-new Conda environment or just install on Windows ""manually"" via pip. Both options make the file empty and I run into this issue.

Trace:
---------------------------------------------------------------------------
ImportError                               Traceback (most recent call last)
~\.conda\envs\wtf\lib\site-packages\tensorflow\python\pywrap_tensorflow.py in <module>
     63   try:
---> 64     from tensorflow.python._pywrap_tensorflow_internal import *
     65   # This try catch logic is because there is no bazel equivalent for py_extension.

ImportError: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed.

During handling of the above exception, another exception occurred:

ImportError                               Traceback (most recent call last)
<ipython-input-3-6dadb603fc7c> in <module>
      2 import datetime
      3 
----> 4 import tensorflow as tf
      5 import IPython
      6 import IPython.display

~\.conda\envs\wtf\lib\site-packages\tensorflow\__init__.py in <module>
     39 import sys as _sys
     40 
---> 41 from tensorflow.python.tools import module_util as _module_util
     42 from tensorflow.python.util.lazy_loader import LazyLoader as _LazyLoader
     43 

~\.conda\envs\wtf\lib\site-packages\tensorflow\python\__init__.py in <module>
     38 # pylint: disable=wildcard-import,g-bad-import-order,g-import-not-at-top
     39 
---> 40 from tensorflow.python.eager import context
     41 
     42 # pylint: enable=wildcard-import

~\.conda\envs\wtf\lib\site-packages\tensorflow\python\eager\context.py in <module>
     33 from tensorflow.core.protobuf import config_pb2
     34 from tensorflow.core.protobuf import rewriter_config_pb2
---> 35 from tensorflow.python import pywrap_tfe
     36 from tensorflow.python import tf2
     37 from tensorflow.python.client import pywrap_tf_session

~\.conda\envs\wtf\lib\site-packages\tensorflow\python\pywrap_tfe.py in <module>
     26 
     27 # pylint: disable=invalid-import-order,g-bad-import-order, wildcard-import, unused-import
---> 28 from tensorflow.python import pywrap_tensorflow
     29 from tensorflow.python._pywrap_tfe import *

~\.conda\envs\wtf\lib\site-packages\tensorflow\python\pywrap_tensorflow.py in <module>
     81 for some common reasons and solutions.  Include the entire stack trace
     82 above this error message when asking for help."""""" % traceback.format_exc()
---> 83   raise ImportError(msg)
     84 
     85 # pylint: enable=wildcard-import,g-import-not-at-top,unused-import,line-too-long

ImportError: Traceback (most recent call last):
  File ""C:\Users\csana\.conda\envs\wtf\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 64, in <module>
    from tensorflow.python._pywrap_tensorflow_internal import *
ImportError: DLL load failed while importing _pywrap_tensorflow_internal: A dynamic link library (DLL) initialization routine failed.


Failed to load the native TensorFlow runtime.

See https://www.tensorflow.org/install/errors

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.
"
45070,v2.0.4rc2 CUBLAS_STATUS_NOT_INITIALIZED,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): Source
- TensorFlow version (use command below): v2.4.0-rc2-0-g0b06f2927b 2.4.0-rc2
- Python version: 3.8.5
- Bazel version (if compiling from source): bazel 3.7.0
- GCC/Compiler version (if compiling from source): gcc (Ubuntu 9.3.0-17ubuntu1~20.04) 9.3.0
- CUDA/cuDNN version: CUDA 11.1 - 8.0.5
- GPU model and memory: RTX 3080 10016MiB

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**

CUBLAS_STATUS_NOT_INITIALIZED

**Describe the expected behavior**

Cublas to be initialized

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

```
pip install ai-benchmark
```

```python
 from ai_benchmark import AIBenchmark
results = AIBenchmark().run() 
```

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

```
2020-11-22 00:03:17.085732: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2020-11-22 00:03:17.086649: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2020-11-22 00:03:17.125644: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-11-22 00:03:17.126133: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:08:00.0 name: GeForce RTX 3080 computeCapability: 8.6
coreClock: 1.71GHz coreCount: 68 deviceMemorySize: 9.78GiB deviceMemoryBandwidth: 707.88GiB/s
2020-11-22 00:03:17.126162: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2020-11-22 00:03:17.127890: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2020-11-22 00:03:17.127926: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2020-11-22 00:03:17.128494: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2020-11-22 00:03:17.128616: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2020-11-22 00:03:17.130269: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.11
2020-11-22 00:03:17.130675: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2020-11-22 00:03:17.130775: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2020-11-22 00:03:17.130855: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-11-22 00:03:17.131377: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-11-22 00:03:17.131924: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2020-11-22 00:03:17.131946: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2020-11-22 00:03:17.478652: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-11-22 00:03:17.478689: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2020-11-22 00:03:17.478696: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2020-11-22 00:03:17.478871: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-11-22 00:03:17.479349: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-11-22 00:03:17.479796: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-11-22 00:03:17.480226: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/device:GPU:0 with 8754 MB memory) -> physical GPU (device: 0, name: GeForce RTX 3080, pci bus id: 0000:08:00.0, compute capability: 8.6)
2020-11-22 00:03:17.480578: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2020-11-22 00:03:17.480629: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-11-22 00:03:17.481050: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:08:00.0 name: GeForce RTX 3080 computeCapability: 8.6
coreClock: 1.71GHz coreCount: 68 deviceMemorySize: 9.78GiB deviceMemoryBandwidth: 707.88GiB/s
2020-11-22 00:03:17.481073: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2020-11-22 00:03:17.481090: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2020-11-22 00:03:17.481099: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2020-11-22 00:03:17.481107: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2020-11-22 00:03:17.481116: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2020-11-22 00:03:17.481124: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.11
2020-11-22 00:03:17.481132: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2020-11-22 00:03:17.481141: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2020-11-22 00:03:17.481176: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-11-22 00:03:17.481614: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-11-22 00:03:17.482021: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2020-11-22 00:03:17.482036: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-11-22 00:03:17.482041: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2020-11-22 00:03:17.482048: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2020-11-22 00:03:17.482103: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-11-22 00:03:17.482553: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-11-22 00:03:17.482975: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/device:GPU:0 with 8754 MB memory) -> physical GPU (device: 0, name: GeForce RTX 3080, pci bus id: 0000:08:00.0, compute capability: 8.6)
2020-11-22 00:03:17.483019: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2020-11-22 00:03:17.483063: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-11-22 00:03:17.483473: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:08:00.0 name: GeForce RTX 3080 computeCapability: 8.6
coreClock: 1.71GHz coreCount: 68 deviceMemorySize: 9.78GiB deviceMemoryBandwidth: 707.88GiB/s
2020-11-22 00:03:17.483487: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2020-11-22 00:03:17.483496: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2020-11-22 00:03:17.483504: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2020-11-22 00:03:17.483512: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2020-11-22 00:03:17.483520: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2020-11-22 00:03:17.483527: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.11
2020-11-22 00:03:17.483536: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2020-11-22 00:03:17.483543: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2020-11-22 00:03:17.483578: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-11-22 00:03:17.484013: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-11-22 00:03:17.484420: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2020-11-22 00:03:17.484433: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-11-22 00:03:17.484439: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2020-11-22 00:03:17.484443: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2020-11-22 00:03:17.484496: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-11-22 00:03:17.484935: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-11-22 00:03:17.485350: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/device:GPU:0 with 8754 MB memory) -> physical GPU (device: 0, name: GeForce RTX 3080, pci bus id: 0000:08:00.0, compute capability: 8.6)
*  TF Version: 2.4.0-rc2
*  Platform: Linux-5.4.0-54-generic-x86_64-with-glibc2.29
*  CPU: N/A
*  CPU RAM: 16 GB
*  GPU/0: GeForce RTX 3080
*  GPU RAM: 8.5 GB
*  CUDA Version: 11.1
*  CUDA Build: V11.1.105

The benchmark is running...
The tests might take up to 20 minutes
Please don't interrupt the script

1/19. MobileNet-V2

2020-11-22 00:03:24.434737: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2020-11-22 00:03:24.434977: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-11-22 00:03:24.436277: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:08:00.0 name: GeForce RTX 3080 computeCapability: 8.6
coreClock: 1.71GHz coreCount: 68 deviceMemorySize: 9.78GiB deviceMemoryBandwidth: 707.88GiB/s
2020-11-22 00:03:24.436333: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2020-11-22 00:03:24.436375: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2020-11-22 00:03:24.436400: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2020-11-22 00:03:24.436426: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2020-11-22 00:03:24.436451: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2020-11-22 00:03:24.436476: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.11
2020-11-22 00:03:24.436501: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2020-11-22 00:03:24.436525: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2020-11-22 00:03:24.436619: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-11-22 00:03:24.437700: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-11-22 00:03:24.438732: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2020-11-22 00:03:24.439178: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2020-11-22 00:03:24.439311: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-11-22 00:03:24.440332: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:08:00.0 name: GeForce RTX 3080 computeCapability: 8.6
coreClock: 1.71GHz coreCount: 68 deviceMemorySize: 9.78GiB deviceMemoryBandwidth: 707.88GiB/s
2020-11-22 00:03:24.440369: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2020-11-22 00:03:24.440397: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2020-11-22 00:03:24.440419: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2020-11-22 00:03:24.440441: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2020-11-22 00:03:24.440463: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2020-11-22 00:03:24.440486: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.11
2020-11-22 00:03:24.440507: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2020-11-22 00:03:24.440530: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2020-11-22 00:03:24.440621: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-11-22 00:03:24.441695: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-11-22 00:03:24.442723: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2020-11-22 00:03:24.442781: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-11-22 00:03:24.442797: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2020-11-22 00:03:24.442810: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2020-11-22 00:03:24.442957: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-11-22 00:03:24.443970: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-11-22 00:03:24.444408: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 8754 MB memory) -> physical GPU (device: 0, name: GeForce RTX 3080, pci bus id: 0000:08:00.0, compute capability: 8.6)
2020-11-22 00:03:24.730375: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:196] None of the MLIR optimization passes are enabled (registered 0 passes)
2020-11-22 00:03:24.782653: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3193620000 Hz
2020-11-22 00:03:25.752569: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2020-11-22 00:03:26.979335: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2020-11-22 00:03:26.985894: E tensorflow/stream_executor/cuda/cuda_blas.cc:226] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED
```"
45069,AttributeError: module 'tensorflow.python.framework.ops' has no attribute 'register_tensor_conversion_function',"AttributeError: module 'tensorflow.python.framework.ops' has no attribute 'register_tensor_conversion_function'

I got this error when I run the file in cmd. But when I run in spyder, I did not get the error
**Code**
```
from tensorflow.keras.models import load_model
model=load_model('tf_model.h5')
print(model.summary())
```

**Packages**
absl-py==0.11.0
alabaster==0.7.12
appdirs==1.4.4
astor==0.8.1
astroid==2.4.2
astunparse==1.6.3
async-generator==1.10
atomicwrites==1.4.0
attrs==20.3.0
autopep8==1.5.4
Babel==2.9.0
backcall==0.2.0
bcrypt==3.2.0
black==20.8b1
bleach==3.2.1
cached-property==1.5.2
cachetools==4.1.1
certifi==2020.11.8
cffi==1.14.3
chardet==3.0.4
click==7.1.2
cloudpickle==1.6.0
colorama==0.4.4
cryptography==3.2.1
decorator==4.4.2
defusedxml==0.6.0
diff-match-patch==20200713
docutils==0.16
entrypoints==0.3
flake8==3.8.4
gast==0.3.3
google-auth==1.23.0
google-auth-oauthlib==0.4.2
google-pasta==0.2.0
grpcio==1.33.2
h5py==2.10.0
helpdev==0.7.1
idna==2.10
imagesize==1.2.0
importlib-metadata==2.0.0
intervaltree==3.1.0
ipykernel==5.3.4
ipython==7.19.0
ipython-genutils==0.2.0
isort==5.6.4
jedi==0.17.2
Jinja2==2.11.2
joblib==0.17.0
jsonschema==3.2.0
jupyter-client==6.1.7
jupyter-core==4.7.0
jupyterlab-pygments==0.1.2
Keras-Applications==1.0.8
Keras-Preprocessing==1.1.2
keyring==21.5.0
lazy-object-proxy==1.4.3
Markdown==3.3.3
MarkupSafe==1.1.1
mccabe==0.6.1
mistune==0.8.4
mypy-extensions==0.4.3
nbclient==0.5.1
nbconvert==6.0.7
nbformat==5.0.8
nest-asyncio==1.4.3
numpy==1.19.4
numpydoc==1.1.0
oauthlib==3.1.0
opt-einsum==3.3.0
packaging==20.4
pandas==1.1.4
pandocfilters==1.4.3
paramiko==2.7.2
parso==0.7.0
pathspec==0.8.1
pathtools==0.1.2
pexpect==4.8.0
pickleshare==0.7.5
Pillow==8.0.1
pluggy==0.13.1
prompt-toolkit==3.0.8
protobuf==3.14.0
psutil==5.7.3
ptyprocess==0.6.0
pyasn1==0.4.8
pyasn1-modules==0.2.8
pycodestyle==2.6.0
pycparser==2.20
pydocstyle==5.1.1
pyflakes==2.2.0
Pygments==2.7.2
pylint==2.6.0
pyls-black==0.4.6
pyls-spyder==0.1.1
PyNaCl==1.4.0
pyparsing==2.4.7
PyQt5==5.12.3
PyQt5-sip==12.8.1
PyQtWebEngine==5.12.1
pyrsistent==0.17.3
python-dateutil==2.8.1
python-jsonrpc-server==0.4.0
python-language-server==0.36.1
pytz==2020.4
pywin32==300
pywin32-ctypes==0.2.0
pyzmq==20.0.0
QDarkStyle==2.8.1
QtAwesome==1.0.1
qtconsole==4.7.7
QtPy==1.9.0
regex==2020.11.13
requests==2.25.0
requests-oauthlib==1.3.0
rope==0.18.0
rsa==4.6
scikit-learn==0.23.2
scipy==1.4.1
six==1.15.0
snowballstemmer==2.0.0
sortedcontainers==2.3.0
Sphinx==3.3.1
sphinxcontrib-applehelp==1.0.2
sphinxcontrib-devhelp==1.0.2
sphinxcontrib-htmlhelp==1.0.3
sphinxcontrib-jsmath==1.0.1
sphinxcontrib-qthelp==1.0.3
sphinxcontrib-serializinghtml==1.1.4
spyder==4.2.0
spyder-kernels==1.10.0
tensorboard==2.2.2
tensorboard-plugin-wit==1.7.0
tensorflow-cpu==2.2.0
tensorflow-estimator==2.2.0
termcolor==1.1.0
testpath==0.4.4
threaded==4.1.0
threadpoolctl==2.1.0
three-merge==0.1.1
toml==0.10.2
tornado==6.1
traitlets==5.0.5
typed-ast==1.4.1
typing-extensions==3.7.4.3
ujson==4.0.1
urllib3==1.26.2
watchdog==0.10.4
wcwidth==0.2.5
webencodings==0.5.1
Werkzeug==1.0.1
wrapt==1.12.1
yapf==0.30.0
zipp==3.4.0


**Error**
```
Traceback (most recent call last):
  File ""code3.py"", line 77, in <module>
    from tensorflow.keras.models import load_model
  File ""D:\fiverr\traffic\gui\venv\lib\site-packages\tensorflow\__init__.py"", line 41, in <module>
    from tensorflow.python.tools import module_util as _module_util
  File ""D:\fiverr\traffic\gui\venv\lib\site-packages\tensorflow\python\__init__.py"", line 64, in <module>
    from tensorflow.python.framework.framework_lib import *  # pylint: disable=redefined-builtin
  File ""D:\fiverr\traffic\gui\venv\lib\site-packages\tensorflow\python\framework\framework_lib.py"", line 25, in <module>
    from tensorflow.python.framework.ops import Graph
  File ""D:\fiverr\traffic\gui\venv\lib\site-packages\tensorflow\python\framework\ops.py"", line 64, in <module>
    from tensorflow.python.platform import app
  File ""D:\fiverr\traffic\gui\venv\lib\site-packages\tensorflow\python\platform\app.py"", line 23, in <module>
    from absl.app import run as _run
  File ""D:\fiverr\traffic\gui\venv\lib\site-packages\absl\app.py"", line 35, in <module>
    import pdb
  File ""C:\Anaconda3\lib\pdb.py"", line 76, in <module>
    import code
  File ""D:\fiverr\traffic\gui\code.py"", line 107, in <module>
    from tensorflow.keras.models import load_model
  File ""D:\fiverr\traffic\gui\venv\lib\site-packages\tensorflow\keras\__init__.py"", line 14, in <module>
    from . import activations
  File ""D:\fiverr\traffic\gui\venv\lib\site-packages\tensorflow\keras\activations\__init__.py"", line 10, in <module>
    from tensorflow.python.keras.activations import deserialize
  File ""D:\fiverr\traffic\gui\venv\lib\site-packages\tensorflow\python\keras\__init__.py"", line 27, in <module>
    from tensorflow.python.keras import models
  File ""D:\fiverr\traffic\gui\venv\lib\site-packages\tensorflow\python\keras\models.py"", line 23, in <module>
    from tensorflow.python.keras import backend as K
  File ""D:\fiverr\traffic\gui\venv\lib\site-packages\tensorflow\python\keras\backend.py"", line 36, in <module>
    from tensorflow.python.client import session as session_module
  File ""D:\fiverr\traffic\gui\venv\lib\site-packages\tensorflow\python\client\session.py"", line 38, in <module>
    from tensorflow.python.framework import sparse_tensor
  File ""D:\fiverr\traffic\gui\venv\lib\site-packages\tensorflow\python\framework\sparse_tensor.py"", line 29, in <module>
    from tensorflow.python.framework import constant_op
  File ""D:\fiverr\traffic\gui\venv\lib\site-packages\tensorflow\python\framework\constant_op.py"", line 324, in <module>
    ops.register_tensor_conversion_function(
AttributeError: module 'tensorflow.python.framework.ops' h
```as no attribute 'register_tensor_conversion_function'"
45068,2.4.0rc2 RTX3080 cuda 11.1 OP_REQUIRES failed at conv_ops_fused_impl.h:697 : Not found: No algorithm worked!,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): Source
- TensorFlow version (use command below): v2.4.0-rc2-0-g0b06f2927b 2.4.0-rc2
- Python version:Python 3.8.5
- Bazel version (if compiling from source): bazel 3.7.0
- GCC/Compiler version (if compiling from source): gcc (Ubuntu 9.3.0-17ubuntu1~20.04) 9.3.0
- CUDA/cuDNN version: 11.1 / 8.0.5
- GPU model and memory: RTX 3080 10016MiB

**Describe the current behavior**

Throws an error : 
OP_REQUIRES failed at conv_ops_fused_impl.h:697 : Not found: No algorithm worked!

**Describe the expected behavior**

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

```python
import tensorflow as tf

from tensorflow.keras import datasets, layers, models
import matplotlib.pyplot as plt

(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()

# Normalize pixel values to be between 0 and 1
train_images, test_images = train_images / 255.0, test_images / 255.0

model = models.Sequential()
model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(64, (3, 3), activation='relu'))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(64, (3, 3), activation='relu'))

model.add(layers.Flatten())
model.add(layers.Dense(64, activation='relu'))
model.add(layers.Dense(10))

model.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

history = model.fit(train_images, train_labels, epochs=10,
                    validation_data=(test_images, test_labels))
```


**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
```
/usr/bin/python3.8 /home/noobzik/Documents/deep_learning_day2/hello_conv_nets.py
2020-11-21 23:53:23.135241: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2020-11-21 23:53:25.040004: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2020-11-21 23:53:25.040526: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2020-11-21 23:53:25.075627: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-11-21 23:53:25.076103: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:08:00.0 name: GeForce RTX 3080 computeCapability: 8.6
coreClock: 1.71GHz coreCount: 68 deviceMemorySize: 9.78GiB deviceMemoryBandwidth: 707.88GiB/s
2020-11-21 23:53:25.076117: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2020-11-21 23:53:25.077747: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2020-11-21 23:53:25.077778: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2020-11-21 23:53:25.078373: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2020-11-21 23:53:25.078508: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2020-11-21 23:53:25.080174: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.11
2020-11-21 23:53:25.080608: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2020-11-21 23:53:25.080689: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2020-11-21 23:53:25.080776: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-11-21 23:53:25.081276: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-11-21 23:53:25.081708: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2020-11-21 23:53:25.082535: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2020-11-21 23:53:25.082603: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-11-21 23:53:25.083044: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:08:00.0 name: GeForce RTX 3080 computeCapability: 8.6
coreClock: 1.71GHz coreCount: 68 deviceMemorySize: 9.78GiB deviceMemoryBandwidth: 707.88GiB/s
2020-11-21 23:53:25.083059: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2020-11-21 23:53:25.083071: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2020-11-21 23:53:25.083078: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2020-11-21 23:53:25.083086: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2020-11-21 23:53:25.083093: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2020-11-21 23:53:25.083101: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.11
2020-11-21 23:53:25.083107: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2020-11-21 23:53:25.083115: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2020-11-21 23:53:25.083149: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-11-21 23:53:25.083611: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-11-21 23:53:25.084038: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2020-11-21 23:53:25.084060: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2020-11-21 23:53:25.474941: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-11-21 23:53:25.474969: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2020-11-21 23:53:25.474975: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2020-11-21 23:53:25.475140: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-11-21 23:53:25.475614: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-11-21 23:53:25.476058: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-11-21 23:53:25.476486: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 8680 MB memory) -> physical GPU (device: 0, name: GeForce RTX 3080, pci bus id: 0000:08:00.0, compute capability: 8.6)
2020-11-21 23:53:26.015884: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 614400000 exceeds 10% of free system memory.
2020-11-21 23:53:26.199466: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2020-11-21 23:53:26.218389: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3193620000 Hz
Epoch 1/10
2020-11-21 23:53:26.594301: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2020-11-21 23:53:27.057102: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2020-11-21 23:53:27.073390: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2020-11-21 23:53:27.767718: W tensorflow/core/framework/op_kernel.cc:1763] OP_REQUIRES failed at conv_ops_fused_impl.h:697 : Not found: No algorithm worked!
Traceback (most recent call last):
  File ""/home/noobzik/Documents/deep_learning_day2/hello_conv_nets.py"", line 26, in <module>
    history = model.fit(train_images, train_labels, epochs=10,
  File ""/home/noobzik/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py"", line 1100, in fit
    tmp_logs = self.train_function(iterator)
  File ""/home/noobzik/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py"", line 828, in __call__
    result = self._call(*args, **kwds)
  File ""/home/noobzik/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py"", line 888, in _call
    return self._stateless_fn(*args, **kwds)
  File ""/home/noobzik/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py"", line 2942, in __call__
    return graph_function._call_flat(
  File ""/home/noobzik/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py"", line 1918, in _call_flat
    return self._build_call_outputs(self._inference_function.call(
  File ""/home/noobzik/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py"", line 555, in call
    outputs = execute.execute(
  File ""/home/noobzik/.local/lib/python3.8/site-packages/tensorflow/python/eager/execute.py"", line 59, in quick_execute
    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
tensorflow.python.framework.errors_impl.NotFoundError:  No algorithm worked!
	 [[node sequential/conv2d/Relu (defined at /Documents/deep_learning_day2/hello_conv_nets.py:26) ]] [Op:__inference_train_function_800]

Function call stack:
train_function


Process finished with exit code 1
```"
45067,Trying to perform feature engineering and data processing in tf.data pipeline,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): 2.3.1
- Python version:3.7.6
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
Hi Team, 
Here, I have taken an example from tensorflow.org. I have built my model as similar as below example, but then as I am dealing with
a bit enormous data. I thought I can perform preprocessing and feature engineer task inside tf.data pipeline. Unfortunately, I haven't
found any examples yet. Hence why, I reached out you, and apologies for disturbing during the weekend. 


### example model I have built now similar to this ###
import pathlib
import numpy as np
import pandas as pd
import tensorflow as tf
import logging
tf.get_logger().setLevel(logging.ERROR)
from tensorflow import feature_column
from tensorflow.keras import layers
from sklearn.model_selection import train_test_split

dataset_url = 'http://storage.googleapis.com/download.tensorflow.org/data/petfinder-mini.zip'
csv_file = 'datasets/petfinder-mini/petfinder-mini.csv'

tf.keras.utils.get_file('petfinder_mini.zip', dataset_url,
                        extract=True, cache_dir='.')
dataframe = pd.read_csv(csv_file)
# In the original dataset ""4"" indicates the pet was not adopted.
dataframe['target'] = np.where(dataframe['AdoptionSpeed']==4, 0, 1)

# Drop un-used columns.
dataframe = dataframe.drop(columns=['AdoptionSpeed', 'Description'])

train, test = train_test_split(dataframe, test_size=0.2)
train, val = train_test_split(train, test_size=0.2)
print(len(train), 'train examples')
print(len(val), 'validation examples')
print(len(test), 'test examples')

def df_to_dataset(dataframe, shuffle=True, batch_size=32):
  dataframe = dataframe.copy()
  labels = dataframe.pop('target')
  ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))
  if shuffle:
    ds = ds.shuffle(buffer_size=len(dataframe))
  ds = ds.batch(batch_size)
  ds = ds.prefetch(tf.data.experimental.AUTOTUNE)
  return ds

batch_size = 32
train_ds = df_to_dataset(train, batch_size=batch_size)
val_ds = df_to_dataset(val, shuffle=False, batch_size=batch_size)
test_ds = df_to_dataset(test, shuffle=False, batch_size=batch_size)

feature_columns = []

# numeric cols
for header in ['PhotoAmt', 'Fee', 'Age']:
  feature_columns.append(feature_column.numeric_column(header))
# bucketized cols
age = feature_column.numeric_column('Age')
age_buckets = feature_column.bucketized_column(age, boundaries=[1, 2, 3, 4, 5])
feature_columns.append(age_buckets)

# indicator_columns
indicator_column_names = ['Type', 'Color1', 'Color2', 'Gender', 'MaturitySize',
                          'FurLength', 'Vaccinated', 'Sterilized', 'Health']
for col_name in indicator_column_names:
  categorical_column = feature_column.categorical_column_with_vocabulary_list(
      col_name, dataframe[col_name].unique())
  indicator_column = feature_column.indicator_column(categorical_column)
  feature_columns.append(indicator_column)

# embedding columns
breed1 = feature_column.categorical_column_with_vocabulary_list(
      'Breed1', dataframe.Breed1.unique())
breed1_embedding = feature_column.embedding_column(breed1, dimension=8)
feature_columns.append(breed1_embedding)

feature_layer = tf.keras.layers.DenseFeatures(feature_columns)

model = tf.keras.Sequential([
  feature_layer,
  layers.Dense(128, activation='relu'),
  layers.Dense(128, activation='relu'),
  layers.Dropout(.1),
  layers.Dense(1)
])

model.compile(optimizer='adam',
              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),
              metrics=['accuracy'])

model.fit(train_ds,
          validation_data=val_ds,
          epochs=10)
This is my current code. This methods works perfectly.

**Describe the expected behavior**

Expected way:

Here, I am trying to perform feature engineer and data pre-processing inside tf.data pipeline. So I would require your guidance to perform these actions. I have tried scikit learn for feature engineer, but I want to completely perform every single step using TensorFlow 2

### trying to perform data preprocessing and feature engineering inside tf.data pipeline ###
import pathlib
import numpy as np
import pandas as pd
import tensorflow as tf
import logging
tf.get_logger().setLevel(logging.ERROR)
from tensorflow import feature_column
from tensorflow.keras import layers
from sklearn.model_selection import train_test_split

dataset_url = 'http://storage.googleapis.com/download.tensorflow.org/data/petfinder-mini.zip'
csv_file = 'datasets/petfinder-mini/petfinder-mini.csv'

tf.keras.utils.get_file('petfinder_mini.zip', dataset_url,
                        extract=True, cache_dir='.')
dataframe = pd.read_csv(csv_file)
# In the original dataset ""4"" indicates the pet was not adopted.
dataframe['target'] = np.where(dataframe['AdoptionSpeed']==4, 0, 1)

# Drop un-used columns.
dataframe = dataframe.drop(columns=['AdoptionSpeed', 'Description'])

train, test = train_test_split(dataframe, test_size=0.2)
train, val = train_test_split(train, test_size=0.2)
print(len(train), 'train examples')
print(len(val), 'validation examples')
print(len(test), 'test examples')

### here I have a doubt to performe preprocessing and feature engineer ### not sure how to output the data after these process.
def preprocessing_and_feat_engg(x):
    feature_columns = []

    # numeric cols
    for header in ['PhotoAmt', 'Fee', 'Age']:
    feature_columns.append(feature_column.numeric_column(header))
    # bucketized cols
    age = feature_column.numeric_column('Age')
    age_buckets = feature_column.bucketized_column(age, boundaries=[1, 2, 3, 4, 5])
    feature_columns.append(age_buckets)

    # indicator_columns
    indicator_column_names = ['Type', 'Color1', 'Color2', 'Gender', 'MaturitySize',
                            'FurLength', 'Vaccinated', 'Sterilized', 'Health']
    for col_name in indicator_column_names:
    categorical_column = feature_column.categorical_column_with_vocabulary_list(
        col_name, dataframe[col_name].unique())
    indicator_column = feature_column.indicator_column(categorical_column)
    feature_columns.append(indicator_column)

    # embedding columns
    breed1 = feature_column.categorical_column_with_vocabulary_list(
        'Breed1', dataframe.Breed1.unique())
    breed1_embedding = feature_column.embedding_column(breed1, dimension=8)
    feature_columns.append(breed1_embedding)
    ### not sure how to return the value from function.
    return x

def df_to_dataset(dataframe, shuffle=True, batch_size=32):
  dataframe = dataframe.copy()
  labels = dataframe.pop('target')
  ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))
  ds = ds.map(preprocessing_and_feat_engg,num_parallel_calls=tf.data.experimental.AUTOTUNE)
  if shuffle:
    ds = ds.shuffle(buffer_size=len(dataframe))
  ds = ds.batch(batch_size)
  ds = ds.prefetch(tf.data.experimental.AUTOTUNE)
  return ds

batch_size = 32
train_ds = df_to_dataset(train, batch_size=batch_size)
val_ds = df_to_dataset(val, shuffle=False, batch_size=batch_size)
test_ds = df_to_dataset(test, shuffle=False, batch_size=batch_size)


feature_layer = tf.keras.layers.DenseFeatures(feature_columns)

model = tf.keras.Sequential([
  feature_layer,
  layers.Dense(128, activation='relu'),
  layers.Dense(128, activation='relu'),
  layers.Dropout(.1),
  layers.Dense(1)
])

model.compile(optimizer='adam',
              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),
              metrics=['accuracy'])

model.fit(train_ds,
          validation_data=val_ds,
          epochs=10)


**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
45065,importing tensorflow,"---------------------------------------------------------------------------
ImportError                               Traceback (most recent call last)
~\AppData\Roaming\Python\Python37\site-packages\tensorflow\python\pywrap_tensorflow.py in <module>
     63   try:
---> 64     from tensorflow.python._pywrap_tensorflow_internal import *
     65   # This try catch logic is because there is no bazel equivalent for py_extension.

ImportError: DLL load failed: The specified module could not be found.

During handling of the above exception, another exception occurred:

ImportError                               Traceback (most recent call last)
<ipython-input-2-64156d691fe5> in <module>
----> 1 import tensorflow as tf

~\AppData\Roaming\Python\Python37\site-packages\tensorflow\__init__.py in <module>
     39 import sys as _sys
     40 
---> 41 from tensorflow.python.tools import module_util as _module_util
     42 from tensorflow.python.util.lazy_loader import LazyLoader as _LazyLoader
     43 

~\AppData\Roaming\Python\Python37\site-packages\tensorflow\python\__init__.py in <module>
     38 # pylint: disable=wildcard-import,g-bad-import-order,g-import-not-at-top
     39 
---> 40 from tensorflow.python.eager import context
     41 
     42 # pylint: enable=wildcard-import

~\AppData\Roaming\Python\Python37\site-packages\tensorflow\python\eager\context.py in <module>
     33 from tensorflow.core.protobuf import config_pb2
     34 from tensorflow.core.protobuf import rewriter_config_pb2
---> 35 from tensorflow.python import pywrap_tfe
     36 from tensorflow.python import tf2
     37 from tensorflow.python.client import pywrap_tf_session

~\AppData\Roaming\Python\Python37\site-packages\tensorflow\python\pywrap_tfe.py in <module>
     26 
     27 # pylint: disable=invalid-import-order,g-bad-import-order, wildcard-import, unused-import
---> 28 from tensorflow.python import pywrap_tensorflow
     29 from tensorflow.python._pywrap_tfe import *

~\AppData\Roaming\Python\Python37\site-packages\tensorflow\python\pywrap_tensorflow.py in <module>
     81 for some common reasons and solutions.  Include the entire stack trace
     82 above this error message when asking for help."""""" % traceback.format_exc()
---> 83   raise ImportError(msg)
     84 
     85 # pylint: enable=wildcard-import,g-import-not-at-top,unused-import,line-too-long

ImportError: Traceback (most recent call last):
  File ""C:\Users\Customer\AppData\Roaming\Python\Python37\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 64, in <module>
    from tensorflow.python._pywrap_tensorflow_internal import *
ImportError: DLL load failed: The specified module could not be found."
45064,importing tensorflow,"---------------------------------------------------------------------------
ImportError                               Traceback (most recent call last)
~\AppData\Roaming\Python\Python37\site-packages\tensorflow\python\pywrap_tensorflow.py in <module>
     63   try:
---> 64     from tensorflow.python._pywrap_tensorflow_internal import *
     65   # This try catch logic is because there is no bazel equivalent for py_extension.

ImportError: DLL load failed: The specified module could not be found.

During handling of the above exception, another exception occurred:

ImportError                               Traceback (most recent call last)
<ipython-input-2-64156d691fe5> in <module>
----> 1 import tensorflow as tf

~\AppData\Roaming\Python\Python37\site-packages\tensorflow\__init__.py in <module>
     39 import sys as _sys
     40 
---> 41 from tensorflow.python.tools import module_util as _module_util
     42 from tensorflow.python.util.lazy_loader import LazyLoader as _LazyLoader
     43 

~\AppData\Roaming\Python\Python37\site-packages\tensorflow\python\__init__.py in <module>
     38 # pylint: disable=wildcard-import,g-bad-import-order,g-import-not-at-top
     39 
---> 40 from tensorflow.python.eager import context
     41 
     42 # pylint: enable=wildcard-import

~\AppData\Roaming\Python\Python37\site-packages\tensorflow\python\eager\context.py in <module>
     33 from tensorflow.core.protobuf import config_pb2
     34 from tensorflow.core.protobuf import rewriter_config_pb2
---> 35 from tensorflow.python import pywrap_tfe
     36 from tensorflow.python import tf2
     37 from tensorflow.python.client import pywrap_tf_session

~\AppData\Roaming\Python\Python37\site-packages\tensorflow\python\pywrap_tfe.py in <module>
     26 
     27 # pylint: disable=invalid-import-order,g-bad-import-order, wildcard-import, unused-import
---> 28 from tensorflow.python import pywrap_tensorflow
     29 from tensorflow.python._pywrap_tfe import *

~\AppData\Roaming\Python\Python37\site-packages\tensorflow\python\pywrap_tensorflow.py in <module>
     81 for some common reasons and solutions.  Include the entire stack trace
     82 above this error message when asking for help."""""" % traceback.format_exc()
---> 83   raise ImportError(msg)
     84 
     85 # pylint: enable=wildcard-import,g-import-not-at-top,unused-import,line-too-long

ImportError: Traceback (most recent call last):
  File ""C:\Users\Customer\AppData\Roaming\Python\Python37\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 64, in <module>
    from tensorflow.python._pywrap_tensorflow_internal import *
ImportError: DLL load failed: The specified module could not be found."
45063,KeyError when taking derivative to input of Conv2D with tf.function only,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes, see below
- OS Platform and distribution: Fedora
- TensorFlow installed from: binary
- TensorFlow version: 2.3.1
- Python version: 3.8.6
- CUDA/cuDNN version: 10.0
- GPU model and memory: GeForce GTX 1080 Ti

**Describe the current behavior**
Crashes with a stacktrace: `KeyError: 'strides'`.

<details><summary>code</summary>
<p>

```python
import tensorflow as tf
import tensorflow_probability as tfp
import tensorflow_datasets as tfds

data, data_info = tfds.load(""mnist"", split=""train"", as_supervised=True, with_info=True)
data = data.map(lambda x, _: tf.cast(x, tf.float32) / 255.)
data_shape = data_info.features[""image""].shape
dimension = tf.reduce_prod(data_shape).numpy()

latent_distribution = tfp.distributions.MultivariateNormalDiag(
    loc=[0.] * dimension,
    scale_diag=[1.] * dimension,
)

input = tf.keras.Input(shape=data_shape)
state = input
state = tf.keras.layers.Conv2D(64, kernel_size=4, strides=2, use_bias=False)(state)
state = tf.keras.layers.Conv2D(128, kernel_size=4, strides=2, padding=""same"", use_bias=False)(state)
state = tf.keras.layers.Conv2D(256, kernel_size=4, strides=2, padding=""same"", use_bias=False)(state)
state = tf.keras.layers.Activation(tf.nn.softplus)(state)  # Essential to trigger bug
state = tf.keras.layers.Conv2D(1, kernel_size=4, strides=1, use_bias=False)(state)
state = tf.keras.layers.Flatten()(state)
f = tf.keras.Model(inputs=input, outputs=state)

optimizer = tf.keras.optimizers.Adam()

@tf.function  # Essential to trigger bug
def train_step(data):
    with tf.GradientTape() as tape:
        tape.watch(f.trainable_variables)

        with tf.GradientTape() as c_tape:
            c_tape.watch(data)

            with tf.GradientTape() as a_tape:
                a_tape.watch(data)
                b = f(data)
            a = a_tape.gradient(b, data)
            a_flat = tf.reshape(a, (-1, dimension))

        c = c_tape.batch_jacobian(a, data)
        c = tf.reshape(c, (-1, dimension, dimension))

        d = latent_distribution.log_prob(a_flat)
        _, e = tf.linalg.slogdet(c)
        ff = tf.reduce_mean(d + e)

        loss = -ff

    gradients = tape.gradient(loss, f.trainable_variables)
    optimizer.apply_gradients(zip(gradients, f.trainable_variables))

train_data = data.batch(1)
for batch in train_data:
    train_step(batch)
```

</p>
</details>

<details><summary>log</summary>
<p>

```
---------------------------------------------------------------------------
KeyError                                  Traceback (most recent call last)
<ipython-input-11-aa3781dddb11> in <module>
      1 for batch in train_data:
----> 2     train_step(batch)

.../python3.8/site-packages/tensorflow/python/eager/def_function.py in __call__(self, *args, **kwds)
    778       else:
    779         compiler = ""nonXla""
--> 780         result = self._call(*args, **kwds)
    781 
    782       new_tracing_count = self._get_tracing_count()

.../python3.8/site-packages/tensorflow/python/eager/def_function.py in _call(self, *args, **kwds)
    821       # This is the first call of __call__, so we have to initialize.
    822       initializers = []
--> 823       self._initialize(args, kwds, add_initializers_to=initializers)
    824     finally:
    825       # At this point we know that the initialization is complete (or less

.../python3.8/site-packages/tensorflow/python/eager/def_function.py in _initialize(self, args, kwds, add_initializers_to)
    694     self._graph_deleter = FunctionDeleter(self._lifted_initializer_graph)
    695     self._concrete_stateful_fn = (
--> 696         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access
    697             *args, **kwds))
    698 

.../python3.8/site-packages/tensorflow/python/eager/function.py in _get_concrete_function_internal_garbage_collected(self, *args, **kwargs)
   2853       args, kwargs = None, None
   2854     with self._lock:
-> 2855       graph_function, _, _ = self._maybe_define_function(args, kwargs)
   2856     return graph_function
   2857 

.../python3.8/site-packages/tensorflow/python/eager/function.py in _maybe_define_function(self, args, kwargs)
   3211 
   3212       self._function_cache.missed.add(call_context_key)
-> 3213       graph_function = self._create_graph_function(args, kwargs)
   3214       self._function_cache.primary[cache_key] = graph_function
   3215       return graph_function, args, kwargs

.../python3.8/site-packages/tensorflow/python/eager/function.py in _create_graph_function(self, args, kwargs, override_flat_arg_shapes)
   3063     arg_names = base_arg_names + missing_arg_names
   3064     graph_function = ConcreteFunction(
-> 3065         func_graph_module.func_graph_from_py_func(
   3066             self._name,
   3067             self._python_function,

.../python3.8/site-packages/tensorflow/python/framework/func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)
    984         _, original_func = tf_decorator.unwrap(python_func)
    985 
--> 986       func_outputs = python_func(*func_args, **func_kwargs)
    987 
    988       # invariant: `func_outputs` contains only Tensors, CompositeTensors,

.../python3.8/site-packages/tensorflow/python/eager/def_function.py in wrapped_fn(*args, **kwds)
    598         # __wrapped__ allows AutoGraph to swap in a converted function. We give
    599         # the function a weak reference to itself to avoid a reference cycle.
--> 600         return weak_wrapped_fn().__wrapped__(*args, **kwds)
    601     weak_wrapped_fn = weakref.ref(wrapped_fn)
    602 

.../python3.8/site-packages/tensorflow/python/framework/func_graph.py in wrapper(*args, **kwargs)
    971           except Exception as e:  # pylint:disable=broad-except
    972             if hasattr(e, ""ag_error_metadata""):
--> 973               raise e.ag_error_metadata.to_exception(e)
    974             else:
    975               raise

KeyError: in user code:

    <ipython-input-9-5c54f4064666>:24 train_step  *
        gradients = tape.gradient(loss, f.trainable_variables)
    .../python3.8/site-packages/tensorflow/python/eager/backprop.py:1067 gradient  **
        flat_grad = imperative_grad.imperative_grad(
    .../python3.8/site-packages/tensorflow/python/eager/imperative_grad.py:71 imperative_grad
        return pywrap_tfe.TFE_Py_TapeGradient(
    .../python3.8/site-packages/tensorflow/python/eager/backprop.py:162 _gradient_function
        return grad_fn(mock_op, *out_grads)
    .../python3.8/site-packages/tensorflow/python/ops/nn_grad.py:50 _Conv2DBackpropInputGrad
        strides=op.get_attr(""strides""),
    .../python3.8/site-packages/tensorflow/python/eager/backprop.py:121 get_attr
        raise KeyError(attr)

    KeyError: 'strides'
```
</p>
</details>

And log on a different setup:
- OS Platform and distribution: Arch
- TensorFlow installed from: source
- TensorFlow version: 2.5.0, 2cad9d750cadd825910b61351a731eb0e8031608
- Python version: 3.8.6-1
- CUDA/cuDNN version: 11.1.1-1 / 8.0.5.39-1
- GPU model and memory: GeForce GTX 960M

<details><summary>log</summary>
<p>

```
2020-12-01 22:58:30.236554: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2020-12-01 22:58:31.813385: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2020-12-01 22:58:31.814170: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2020-12-01 22:58:33.296576: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-01 22:58:33.296901: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1727] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce GTX 960M computeCapability: 5.0
coreClock: 1.0975GHz coreCount: 5 deviceMemorySize: 1.96GiB deviceMemoryBandwidth: 74.65GiB/s
2020-12-01 22:58:33.296923: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2020-12-01 22:58:33.321243: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2020-12-01 22:58:33.321345: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2020-12-01 22:58:33.335247: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2020-12-01 22:58:33.339668: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2020-12-01 22:58:33.359017: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.11
2020-12-01 22:58:33.365850: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2020-12-01 22:58:33.367723: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2020-12-01 22:58:33.367855: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-01 22:58:33.368285: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-01 22:58:33.368606: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1869] Adding visible gpu devices: 0
2020-12-01 22:58:33.369722: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2020-12-01 22:58:33.369860: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-01 22:58:33.370218: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1727] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce GTX 960M computeCapability: 5.0
coreClock: 1.0975GHz coreCount: 5 deviceMemorySize: 1.96GiB deviceMemoryBandwidth: 74.65GiB/s
2020-12-01 22:58:33.370243: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2020-12-01 22:58:33.370266: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2020-12-01 22:58:33.370284: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2020-12-01 22:58:33.370301: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2020-12-01 22:58:33.370316: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2020-12-01 22:58:33.370330: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.11
2020-12-01 22:58:33.370344: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2020-12-01 22:58:33.370362: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2020-12-01 22:58:33.370428: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-01 22:58:33.370793: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-01 22:58:33.371107: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1869] Adding visible gpu devices: 0
2020-12-01 22:58:33.371882: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2020-12-01 22:58:34.128469: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-12-01 22:58:34.128514: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1273]      0 
2020-12-01 22:58:34.128520: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1286] 0:   N 
2020-12-01 22:58:34.129295: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-01 22:58:34.129675: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-01 22:58:34.130039: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-12-01 22:58:34.130359: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1413] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 1635 MB memory) -> physical GPU (device: 0, name: GeForce GTX 960M, pci bus id: 0000:01:00.0, compute capability: 5.0)
2020-12-01 22:58:34.278962: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:127] None of the MLIR optimization passes are enabled (registered 2)
2020-12-01 22:58:34.293661: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2601325000 Hz
2020-12-01 22:58:35.392106: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2020-12-01 22:58:36.093824: I tensorflow/stream_executor/cuda/cuda_dnn.cc:334] Loaded cuDNN version 8005
2020-12-01 22:58:40.021160: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2020-12-01 22:58:40.920336: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2020-12-01 22:58:42.314731: I tensorflow/core/util/cuda_solvers.cc:180] Creating CudaSolver handles for stream 0x55ae4f348220
2020-12-01 22:58:42.315311: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.11
2020-12-01 22:58:43.103484: F tensorflow/core/util/cuda_solvers.cc:115] Check failed: cusolverDnCreate(&cusolver_dn_handle) == CUSOLVER_STATUS_SUCCESS Failed to create cuSolverDN instance.
[1]    2834 abort (core dumped)  python bug.py
```
</p>
</details>"
45062,Not working GeForce GTX 1070 on Tensorflow 2.3.1,"System characteristics:

```
Ubuntu 20.04
NVIDIA Corporation GP104BM [GeForce GTX 1070 Mobile]
Intel® Core™ i7-7700HQ CPU @ 2.80GHz × 8
RAM: 31,3 GiB
Cuda Driver Version: 450.80.02 
tensorflow-2.3.1
CUDA Version: 11.0
cudnn-11.0
```

user@Linux:~$ nvidia-smi

```
Sat Nov 21 15:52:38 2020       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 450.80.02    Driver Version: 450.80.02    CUDA Version: 11.0     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  GeForce GTX 1070    Off  | 00000000:01:00.0  On |                  N/A |
| N/A   50C    P8     9W /  N/A |    297MiB /  8111MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|    0   N/A  N/A       932      G   /usr/lib/xorg/Xorg                 92MiB |
|    0   N/A  N/A      1295      G   /usr/bin/gnome-shell              111MiB |
|    0   N/A  N/A      3277      G   /usr/lib/firefox/firefox            1MiB |
|    0   N/A  N/A      3828      C   /usr/bin/python3                   87MiB |
+-----------------------------------------------------------------------------+

```
user@Linux:~$ nvcc -V

```
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2019 NVIDIA Corporation
Built on Sun_Jul_28_19:07:16_PDT_2019
Cuda compilation tools, release 10.1, V10.1.243
```

from tensorflow.python.client import device_lib print(device_lib.list_local_devices())


```
[name: ""/device:CPU:0""
device_type: ""CPU""
memory_limit: 268435456
locality {
}
incarnation: 11676041203334616666
, name: ""/device:XLA_CPU:0""
device_type: ""XLA_CPU""
memory_limit: 17179869184
locality {
}
incarnation: 9716226955421748203
physical_device_desc: ""device: XLA_CPU device""
, name: ""/device:XLA_GPU:0""
device_type: ""XLA_GPU""
memory_limit: 17179869184
locality {
}
incarnation: 1948208650029266498
physical_device_desc: ""device: XLA_GPU device""
]

```
When I run the code, I get an error:

```
with tf.device('/device:XLA_GPU:0'):
    history=model.fit(train_generator,
                      epochs=10,
                      validation_data=valid_generator,
                      validation_steps=test.shape[0]//batch_size,
                      steps_per_epoch=train.shape[0]//batch_size
                        )

Epoch 1/10

---------------------------------------------------------------------------
InvalidArgumentError                      Traceback (most recent call last)
<ipython-input-15-cc03ad3613b3> in <module>
      1 with tf.device('/device:XLA_GPU:0'):
----> 2     history=model.fit(train_generator,
      3                       epochs=10,
      4                       validation_data=valid_generator,
      5                       validation_steps=test.shape[0]//batch_size,
...

Epoch 1/10

---------------------------------------------------------------------------
InvalidArgumentError                      Traceback (most recent call last)
<ipython-input-15-cc03ad3613b3> in <module>
      1 with tf.device('/device:XLA_GPU:0'):
----> 2     history=model.fit(train_generator,
      3                       epochs=10,
      4                       validation_data=valid_generator,
      5                       validation_steps=test.shape[0]//batch_size,
```

without code: with tf.device('/device:XLA_GPU:0') everything works well, but for a very long time (no GPU work...)
"
45059,build tensorflow_cc failed with cycle dependency graph,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): win10
- TensorFlow installed from (source or binary): source
- TensorFlow version: 2.3.1

- Python version: 3.7.7
- bazelisk version: 1.7.4
- Bazel version (if compiling from source): 3.1.0
- CUDA/cuDNN version: 10.1/7.6.5
- GPU model and memory: rtx 2080ti



**Describe the problem**
in order to build tensorflow_cc.dll with tensorrt support on win10,  I add **--config=tensorrt** option on build command,  it failed with cycle dependency graph.
did I miss any environment variables? or is TF-TRT currently not supported by windows?


**Provide the exact sequence of commands / steps that you executed before running into the problem**

no **--define=with_xla_support=false**:  
```
bazel build --config=opt --config=v2 --config=tensorrt //tensorflow:tensorflow_cc //tensorflow:tensorflow_cc_dll_import_lib //tensorflow:install_headers
```

with  **--define=with_xla_support=false**:  
```
bazel build --config=opt --config=v2 --config=tensorrt --define=with_xla_support=false //tensorflow:tensorflow_cc //tensorflow:tensorflow_cc_dll_import_lib //tensorflow:install_headers
```


**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

no **--define=with_xla_support=false**:  

```log
D:\Project\cpp\tf\tensorflow-2.3.1>bazel build --config=opt --config=v2 --config=tensorrt //tensorflow:tensorflow_cc //tensorflow:tensorflow_cc_dll_import_lib //tensorflow:install_headers
Starting local Bazel server and connecting to it...
WARNING: The following configs were expanded more than once: [v2]. For repeatable flags, repeats are counted twice and may lead to unexpected behavior.
INFO: Options provided by the client:
  Inherited 'common' options: --isatty=1 --terminal_columns=125
INFO: Reading rc options for 'build' from d:\project\cpp\tf\tensorflow-2.3.1\.bazelrc:
  Inherited 'common' options: --experimental_repo_remote_exec
INFO: Options provided by the client:
  'build' options: --python_path=C:/Users/ihual/AppData/Local/Microsoft/WindowsApps/python.exe
INFO: Reading rc options for 'build' from d:\project\cpp\tf\tensorflow-2.3.1\.bazelrc:
  'build' options: --apple_platform_type=macos --define framework_shared_object=true --define open_source_build=true --java_toolchain=//third_party/toolchains/java:tf_java_toolchain --host_java_toolchain=//third_party/toolchains/java:tf_java_toolchain --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --noincompatible_prohibit_aapt1 --enable_platform_specific_config --config=v2
INFO: Reading rc options for 'build' from d:\project\cpp\tf\tensorflow-2.3.1\.tf_configure.bazelrc:
  'build' options: --action_env PYTHON_BIN_PATH=D:/SoftInstall/Anaconda3/envs/tf2_p37/python.exe --action_env PYTHON_LIB_PATH=D:/SoftInstall/Anaconda3/envs/tf2_p37/lib/site-packages --python_path=D:/SoftInstall/Anaconda3/envs/tf2_p37/python.exe --config=xla --action_env CUDA_TOOLKIT_PATH=C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v10.2 --action_env TF_CUDA_COMPUTE_CAPABILITIES=7.5 --config=cuda --define=override_eigen_strong_inline=true --action_env TF_CONFIGURE_IOS=0
INFO: Found applicable config definition build:v2 in file d:\project\cpp\tf\tensorflow-2.3.1\.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1
INFO: Found applicable config definition build:xla in file d:\project\cpp\tf\tensorflow-2.3.1\.bazelrc: --action_env=TF_ENABLE_XLA=1 --define=with_xla_support=true
INFO: Found applicable config definition build:cuda in file d:\project\cpp\tf\tensorflow-2.3.1\.bazelrc: --config=using_cuda --define=using_cuda_nvcc=true
INFO: Found applicable config definition build:using_cuda in file d:\project\cpp\tf\tensorflow-2.3.1\.bazelrc: --define=using_cuda=true --action_env TF_NEED_CUDA=1 --crosstool_top=@local_config_cuda//crosstool:toolchain
INFO: Found applicable config definition build:opt in file d:\project\cpp\tf\tensorflow-2.3.1\.tf_configure.bazelrc: --copt=/arch:AVX2 --define with_default_optimizations=true
INFO: Found applicable config definition build:v2 in file d:\project\cpp\tf\tensorflow-2.3.1\.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1
INFO: Found applicable config definition build:tensorrt in file d:\project\cpp\tf\tensorflow-2.3.1\.bazelrc: --action_env TF_NEED_TENSORRT=1
INFO: Found applicable config definition build:windows in file d:\project\cpp\tf\tensorflow-2.3.1\.bazelrc: --copt=/w --copt=/D_USE_MATH_DEFINES --host_copt=/D_USE_MATH_DEFINES --cxxopt=/std:c++14 --host_cxxopt=/std:c++14 --config=monolithic --copt=-DWIN32_LEAN_AND_MEAN --host_copt=-DWIN32_LEAN_AND_MEAN --copt=-DNOGDI --host_copt=-DNOGDI --linkopt=/DEBUG --host_linkopt=/DEBUG --linkopt=/OPT:REF --host_linkopt=/OPT:REF --linkopt=/OPT:ICF --host_linkopt=/OPT:ICF --experimental_strict_action_env=true --verbose_failures --distinct_host_configuration=false
INFO: Found applicable config definition build:monolithic in file d:\project\cpp\tf\tensorflow-2.3.1\.bazelrc: --define framework_shared_object=false
WARNING: D:/project/cpp/tf/tensorflow-2.3.1/tensorflow/core/BUILD:1840:1: in linkstatic attribute of cc_library rule //tensorflow/core:lib_internal: setting 'linkstatic=1' is recommended if there are no object files. Since this rule was created by the macro 'cc_library', the error might have been caused by the macro implementation
WARNING: D:/project/cpp/tf/tensorflow-2.3.1/tensorflow/core/BUILD:2252:1: in linkstatic attribute of cc_library rule //tensorflow/core:framework_internal: setting 'linkstatic=1' is recommended if there are no object files. Since this rule was created by the macro 'tf_cuda_library', the error might have been caused by the macro implementation
ERROR: D:/project/cpp/tf/tensorflow-2.3.1/tensorflow/core/BUILD:1110:1: in cc_library rule //tensorflow/core:all_kernels: cycle in dependency graph:
    //tensorflow:tensorflow_cc
    //tensorflow:tensorflow_cc.dll
    //tensorflow/cc/profiler:profiler
    //tensorflow/core/profiler/internal:tfprof_stats
    //tensorflow/core/profiler/internal:tfprof_code
    //tensorflow/c:c_api
    //tensorflow/compiler/jit:jit
    //tensorflow/compiler/jit:xla_cpu_jit
    //tensorflow/compiler/jit:xla_kernel_creator
    //tensorflow/compiler/jit:jit_compilation_passes
    //tensorflow/compiler/jit:compilation_passes
.-> //tensorflow/core:all_kernels
|   //tensorflow/core:all_kernels_impl
|   //tensorflow/compiler/tf2tensorrt:trt_engine_resource_op_kernels
|   //tensorflow/python:pywrap_tensorflow_import_lib
|   //tensorflow/python:pywrap_tensorflow_import_lib_file
|   //tensorflow/python:get_pywrap_tensorflow_import_lib_file
|   //tensorflow/python:_pywrap_tensorflow_internal.so
|   //tensorflow/core/distributed_runtime/rpc:grpc_server_lib
|   //tensorflow/core/distributed_runtime:local_master
|   //tensorflow/core/distributed_runtime:master
|   //tensorflow/core/distributed_runtime:master_session
|   //tensorflow/core/distributed_runtime:scheduler
|   //tensorflow/core:tensorflow_opensource
`-- //tensorflow/core:all_kernels
This cycle occurred because of a configuration option
ERROR: Analysis of target '//tensorflow:tensorflow_cc' failed; build aborted
INFO: Elapsed time: 8.539s
INFO: 0 processes.
```


with  **--define=with_xla_support=false**:  

```log
D:\Project\cpp\tf\tensorflow-2.3.1>bazel build --config=opt --config=v2 --config=tensorrt --define=with_xla_support=false //tensorflow:tensorflow_cc //tensorflow:tensorflow_cc_dll_import_lib //tensorflow:install_headers
WARNING: The following configs were expanded more than once: [v2]. For repeatable flags, repeats are counted twice and may lead to unexpected behavior.
INFO: Options provided by the client:
  Inherited 'common' options: --isatty=1 --terminal_columns=125
INFO: Reading rc options for 'build' from d:\project\cpp\tf\tensorflow-2.3.1\.bazelrc:
  Inherited 'common' options: --experimental_repo_remote_exec
INFO: Options provided by the client:
  'build' options: --python_path=C:/Users/ihual/AppData/Local/Microsoft/WindowsApps/python.exe
INFO: Reading rc options for 'build' from d:\project\cpp\tf\tensorflow-2.3.1\.bazelrc:
  'build' options: --apple_platform_type=macos --define framework_shared_object=true --define open_source_build=true --java_toolchain=//third_party/toolchains/java:tf_java_toolchain --host_java_toolchain=//third_party/toolchains/java:tf_java_toolchain --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --noincompatible_prohibit_aapt1 --enable_platform_specific_config --config=v2
INFO: Reading rc options for 'build' from d:\project\cpp\tf\tensorflow-2.3.1\.tf_configure.bazelrc:
  'build' options: --action_env PYTHON_BIN_PATH=D:/SoftInstall/Anaconda3/envs/tf2_p37/python.exe --action_env PYTHON_LIB_PATH=D:/SoftInstall/Anaconda3/envs/tf2_p37/lib/site-packages --python_path=D:/SoftInstall/Anaconda3/envs/tf2_p37/python.exe --config=xla --action_env CUDA_TOOLKIT_PATH=C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v10.2 --action_env TF_CUDA_COMPUTE_CAPABILITIES=7.5 --config=cuda --define=override_eigen_strong_inline=true --action_env TF_CONFIGURE_IOS=0
INFO: Found applicable config definition build:v2 in file d:\project\cpp\tf\tensorflow-2.3.1\.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1
INFO: Found applicable config definition build:xla in file d:\project\cpp\tf\tensorflow-2.3.1\.bazelrc: --action_env=TF_ENABLE_XLA=1 --define=with_xla_support=true
INFO: Found applicable config definition build:cuda in file d:\project\cpp\tf\tensorflow-2.3.1\.bazelrc: --config=using_cuda --define=using_cuda_nvcc=true
INFO: Found applicable config definition build:using_cuda in file d:\project\cpp\tf\tensorflow-2.3.1\.bazelrc: --define=using_cuda=true --action_env TF_NEED_CUDA=1 --crosstool_top=@local_config_cuda//crosstool:toolchain
INFO: Found applicable config definition build:opt in file d:\project\cpp\tf\tensorflow-2.3.1\.tf_configure.bazelrc: --copt=/arch:AVX2 --define with_default_optimizations=true
INFO: Found applicable config definition build:v2 in file d:\project\cpp\tf\tensorflow-2.3.1\.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1
INFO: Found applicable config definition build:tensorrt in file d:\project\cpp\tf\tensorflow-2.3.1\.bazelrc: --action_env TF_NEED_TENSORRT=1
INFO: Found applicable config definition build:windows in file d:\project\cpp\tf\tensorflow-2.3.1\.bazelrc: --copt=/w --copt=/D_USE_MATH_DEFINES --host_copt=/D_USE_MATH_DEFINES --cxxopt=/std:c++14 --host_cxxopt=/std:c++14 --config=monolithic --copt=-DWIN32_LEAN_AND_MEAN --host_copt=-DWIN32_LEAN_AND_MEAN --copt=-DNOGDI --host_copt=-DNOGDI --linkopt=/DEBUG --host_linkopt=/DEBUG --linkopt=/OPT:REF --host_linkopt=/OPT:REF --linkopt=/OPT:ICF --host_linkopt=/OPT:ICF --experimental_strict_action_env=true --verbose_failures --distinct_host_configuration=false
INFO: Found applicable config definition build:monolithic in file d:\project\cpp\tf\tensorflow-2.3.1\.bazelrc: --define framework_shared_object=false
INFO: Build option --define has changed, discarding analysis cache.
WARNING: D:/project/cpp/tf/tensorflow-2.3.1/tensorflow/core/BUILD:1840:1: in linkstatic attribute of cc_library rule //tensorflow/core:lib_internal: setting 'linkstatic=1' is recommended if there are no object files. Since this rule was created by the macro 'cc_library', the error might have been caused by the macro implementation
WARNING: D:/project/cpp/tf/tensorflow-2.3.1/tensorflow/core/BUILD:2252:1: in linkstatic attribute of cc_library rule //tensorflow/core:framework_internal: setting 'linkstatic=1' is recommended if there are no object files. Since this rule was created by the macro 'tf_cuda_library', the error might have been caused by the macro implementation
ERROR: D:/project/cpp/tf/tensorflow-2.3.1/tensorflow/compiler/tf2tensorrt/BUILD:91:1: in cc_library rule //tensorflow/compiler/tf2tensorrt:trt_op_kernels: cycle in dependency graph:
    //tensorflow:tensorflow_cc
    //tensorflow:tensorflow_cc.dll
    //tensorflow/core:tensorflow
    //tensorflow/core:tensorflow_opensource_wrap_all_kernels
.-> //tensorflow/compiler/tf2tensorrt:trt_op_kernels
|   //tensorflow/compiler/tf2tensorrt:trt_conversion
|   //tensorflow/python:pywrap_tensorflow_import_lib
|   //tensorflow/python:pywrap_tensorflow_import_lib_file
|   //tensorflow/python:get_pywrap_tensorflow_import_lib_file
|   //tensorflow/python:_pywrap_tensorflow_internal.so
|   //tensorflow/python:safe_ptr
|   //tensorflow/c/eager:c_api
|   //tensorflow/core/distributed_runtime/rpc:grpc_server_lib
|   //tensorflow/core/distributed_runtime:master_session
|   //tensorflow/core/distributed_runtime:scheduler
|   //tensorflow/core:tensorflow_opensource
|   //tensorflow/core:all_kernels
|   //tensorflow/core:all_kernels_impl
`-- //tensorflow/compiler/tf2tensorrt:trt_op_kernels
This cycle occurred because of a configuration option
ERROR: Analysis of target '//tensorflow:tensorflow_cc' failed; build aborted
INFO: Elapsed time: 2.397s
INFO: 0 processes.
FAILED: Build did NOT complete successfully (0 packages loaded, 19577 targets configured)
```
"
45058,Training model with VGGloss  on TPU gives tcmalloc warning and training time significantly increases.,"I am using colab tpu with tensorflow version 2.3.0
![image](https://user-images.githubusercontent.com/18486587/99874097-02e8b680-2c0b-11eb-9f2b-f04f4799c798.png)

Code for VGG loss is:

```
def vgg_layers(layer_names):
	vgg = tf.keras.applications.VGG19(include_top=False, weights='imagenet')
	outputs = [vgg.get_layer(name).output for name in layer_names]
	model = tf.keras.Model([vgg.input], outputs)
	return model

class VGGloss(Model):
	def __init__(self):
		super(VGGloss, self).__init__()
		layers = [f'block{i+1}_conv1' for i in range(5)]
		self.layerweights = [1./32, 1./16, 1./8, 1./4, 1.]
		self.vgg = vgg_layers(layers)
		self.vgg.trainable = False
		self.l1_loss = tf.keras.losses.MeanAbsoluteError('auto')

	def call(self, x, y):
		x_vgg, y_vgg = self.vgg(x), self.vgg(y), 
		loss = 0
		for w, xi, yi in zip(self.layerweights, x_vgg, y_vgg):
			loss += w*self.l1_loss(xi, yi)
		return loss
```
"
45056, Custom loop training of tacotron2 with MultiWorkerMirroredStrategy - Exceptions and failures when use MultiWorkerMirroredStrategy -,"When I use tf.distribute.experimental.MultiWorkerMirroredStrategy to run training on multiple machines (custom loop) I face following errors. Please advise when other necessary changes are needed. I am trying to run the training for tacotron2 (https://github.com/TensorSpeech/TensorFlowTTS/blob/master/examples/tacotron2/train_tacotron2.py).

Errors and exceptions are:

2020-11-16 12:03:50,968 (cross_device_ops:1130) INFO: Collective batch_all_reduce for IndexedSlices: 1 all-reduces, group_size = 2
2020-11-16 12:03:56.443402: W tensorflow/core/grappler/optimizers/scoped_allocator_optimizer.cc:439] error: Internal: Complete shape not known for AdamWeightDecay/allreduce/CollectiveReduce_23
2020-11-16 12:03:56.443474: W tensorflow/core/grappler/optimizers/scoped_allocator_optimizer.cc:1121] error: Internal: Complete shape not known for AdamWeightDecay/allreduce/CollectiveReduce_23
2020-11-16 12:03:56.443606: E tensorflow/core/grappler/optimizers/scoped_allocator_optimizer.cc:1138] ScopedAllocatorOptimizer: Internal: Complete shape not known for AdamWeightDecay/allreduce/CollectiveReduce_23"
45055, W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution Windows 10 x64
- TensorFlow installed using pip
- TensorFlow version 2.5.0-dev20201028
- Python version: Python  3.8.6 (tags/v3.8.6:db45529, Sep 23 2020, 15:52:53) [MSC v.1927 64 bit (AMD64)] on win32
- Installed using virtualenv? pip? conda?: pip
- CUDA/cuDNN version: cuda 11.1/cudnn 80.04
- GPU model and memory: NVIDIA RTX3080


Hi,
I got this issues when I am trying to import tensorflow from  command line.
Currently I am using NVIDIA RTX3080, with cuda 11.1, cudnn 8.04, python 64 bit, and nvidia driver 456.43. 
I follow the instruction on https://www.tensorflow.org/install, and install tf-nightly 2.5.0.dev and tf-nightly-gpu 2.5.0.dev. 
I also have try the solution on this discussion but it didn't work me https://github.com/tensorflow/tensorflow/issues/43193. 
But I am still getting this error
![error](https://user-images.githubusercontent.com/12694360/99868899-bea4e880-2c01-11eb-90d9-c8d1e80638f6.PNG)

![program_file](https://user-images.githubusercontent.com/12694360/99868905-d1b7b880-2c01-11eb-86c5-4ff7affa7886.PNG)
![path](https://user-images.githubusercontent.com/12694360/99868808-d465de00-2c00-11eb-82f8-4a1532bf2618.PNG)
![nvcc](https://user-images.githubusercontent.com/12694360/99868809-d7f96500-2c00-11eb-91db-1af79086e982.PNG)
![python](https://user-images.githubusercontent.com/12694360/99868829-0e36e480-2c01-11eb-81b1-8635d52a9790.PNG)
"
45054,"Concatenating sparse keras input layers results in None shape, preventing use in Dense layer","**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Colab
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No
- TensorFlow installed from (source or binary): Colab
- TensorFlow version (use command below): 2.3
- Python version: 3.6.9
- Bazel version (if compiling from source): None
- GCC/Compiler version (if compiling from source): None
- CUDA/cuDNN version: None
- GPU model and memory: None

**Describe the current behavior**

Using the Keras functional API, when concatenating together multiple instances of `tensorflow.keras.layers.Input` with `sparse=True`, the resulting `SparseTensor` has a `None` shape (even when `batch_size` is specified). Feeding the merged layer with shape `None` into a dense layer results in an error:
```
ValueError: The last dimension of the inputs to `Dense` should be defined. Found `None`.
```

**Describe the expected behavior**

Concatenating *non-sparse* instances of `tensorflow.keras.layers.Input` (i.e. `sparse=False`) results in a tensor which has a defined shape (if `batch_size` is specified) and can be fed into a dense layer successfully. Additionally a single sparse input layer has a shape and can be fed into a dense layer. I would expect concatenated sparse input layers to act similarly.

The dense shape of the merged sparse tensor should already be known as we set the shapes of the individual input layers.

**Standalone code to reproduce the issue**

```
sp_a = tf.keras.layers.Input(shape=(1,), batch_size=2, sparse=True)
sp_b = tf.keras.layers.Input(shape=(2,), batch_size=2, sparse=True)

sp_merged = tf.keras.layers.concatenate(inputs=[sp_a, sp_b], axis=1)

print(sp_merged.shape) # prints ""(None, None)""

sp_result = tf.keras.layers.Dense(4, activation='relu', name='dense1')(sp_merged) # fails with above ValueError
```

Also tried concatenating with `tf.keras.layers.Concatenate` and `tf.sparse.concat` instead. Same result.

Reproduced success (non-sparse input) and failure (sparse input) cases in Colab:
https://colab.research.google.com/drive/1g9a9lzpw28NqIPI1Z3-fYLJke1fa10Af?usp=sharing
"
45053,Add support for ragged tensors to tf.keras.layers.experimental.preprocessing.Resizing,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): 2.4.0rc2
- Are you willing to contribute it (Yes/No): Yes, though I am not sure of the best way to implement this

**Describe the feature and the current behavior/state.** tf.keras includes [experimental layers](https://www.tensorflow.org/api_docs/python/tf/keras/layers/experimental/preprocessing) for bringing preprocessing operations, such as resizing, inside the model. Users may want to use this functionality in place of resizing in a `tf.data` pipeline, enabling them to bring in a batch of multiple differently sized images and make them a uniform size. However, `tf.keras.layers.experimental.preprocessing.Resizing` does not currently support RaggedTensors, and as such all inputs within a batch must be the same dimensions.


Attempting to pass in a ragged tensor (as shown below) gives an error. Adding support for ragged tensors would be helpful as it would allow for a batch to contain images of different sizes, thus reducing the need for external preprocessing code.

**Will this change the current api? How?**
Yes, API changes will be required as one or more functions will need to be updated with support for ragged tensors.

The API for `tf.keras.layers.experimental.preprocessing.Resizing` would change, though all existing code using it should continue to work.

Additionally, if the feature is implemented by updating `tf.image.resize` to accept `images` as a ragged tensor instead of only a 4-D Tensor of shape [batch, height, width, channels], this will result in an API change, though it shouldn't be breaking.

**Who will benefit with this feature?**
Users looking to move more of their preprocessing inside their model that want to resize multiple differently sized images in one batch.

**Any Other info.**

Ideal flow (currently failing):

```python
import tensorflow as tf
import numpy as np

a = np.random.rand(512, 512, 3)
b = np.random.rand(1080, 1920, 3)

values = tf.ragged.stack([a, b])
labels = np.asarray([0, 1])

print(values.shape)
# NHWC format
# TensorShape([2, None, None, 3])

print(labels.shape)
# (2,)

# Highly simplified image model
model = tf.keras.models.Sequential()
# The output of this layer will always be (Batch, 224, 224, 3), so adding support for
# ragged tensors shouldn't require updates for downstream ops
model.add(
  tf.keras.layers.experimental.preprocessing.Resizing(
    224,
    224,
    input_shape=(None, None, 3), 
    name=""resize""))
model.add(tf.keras.layers.Conv2D(kernel_size=3, filters=24, name=""kernel""))
model.add(tf.keras.layers.GlobalMaxPool2D(name=""pool""))
model.add(tf.keras.layers.Dense(1, name=""dense_second""))

model.compile()

model.fit(values, labels)
```

Error message available in [this gist](https://gist.github.com/TylerADavis/ab693b3d10d618612186f9553c919fbc).
"
45045,XLA tests compiled even when XLA is not enabled,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): RHEL 7.5
- TensorFlow installed from (source or binary): source
- TensorFlow version: 2.4.0-rc2
- Python version: 3.7.4

**Describe the problem**

In my efforts in getting the TF unit tests to run I ran into a problem where the tests seem to require XLA but that isn't available and hence the tests fail with
`ImportError: Unable to import _pywrap_tfcompile; you must build TensorFlow with XLA.  You may need to build tensorflow with flag --define=with_xla_support=true.  Original error: cannot import name '_pywrap_tfcompile' from 'tensorflow.python'`

Checking this further it seems to be a call to `saved_model_compile_aot` with `name = ""aot_compiled_vars_and_arithmetic"",` and `force_without_xla_support_flag = False,` so that looks all fine.

Is there any advice or solution you can provide? Some bug in the TF bazel files?

**Provide the exact sequence of commands / steps that you executed before running into the problem**

```
bazel  test --compilation_mode=opt --config=opt --subcommands --verbose_failures --config=noaws --jobs=64 --copt=""-fPIC"" --action_env=PYTHONPATH --action_env=PYTHONNOUSERSITE=1 --distinct_host_configuration=false --local_test_jobs=1  -- //tensorflow/python/... -//tensorflow/python/integration_testing/...
```

**Any other info / logs**

Error from log (paths shortened):

```
ERROR: /tmp/tensorflow-r2.4/tensorflow/python/tools/BUILD:461:24: Executing genrule //tensorflow/python/tools:aot_compiled_vars_and_arithmetic_gen failed (Exit 1): bash failed: error executing command 
  (cd /tmp/output_base/execroot/org_tensorflow && \
  exec env - \
    [env vars] \
  /bin/bash -c 'source external/bazel_tools/tools/genrule/genrule-setup.sh; bazel-out/ppc-opt/bin/tensorflow/python/tools/saved_model_cli aot_compile_cpu --dir ""$(dirname tensorflow/cc/saved_model/testdata/VarsAndArithmeticObjectGraph/saved_model.pb)"" --output_prefix bazel-out/ppc-opt/bin/tensorflow/python/tools/aot_compiled_vars_and_arithmetic --cpp_class VarsAndArithmetic --variables_to_feed variable_x --signature_def_key serving_default --multithreading False --target_triple ppc64le-ibm-linux-gnu --tag_set serve ')
Execution platform: @local_execution_config_platform//:platform
2020-11-20 15:36:23.668303: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
Traceback (most recent call last):
  File ""/tmp/output_base/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/python/tools/saved_model_cli.runfiles/org_tensorflow/tensorflow/python/tools/saved_model_cli.py"", line 1196, in <module>
    sys.exit(main())
  File ""/tmp/output_base/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/python/tools/saved_model_cli.runfiles/org_tensorflow/tensorflow/python/tools/saved_model_cli.py"", line 1192, in main
    args.func(args)
  File ""/tmp/output_base/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/python/tools/saved_model_cli.runfiles/org_tensorflow/tensorflow/python/tools/saved_model_cli.py"", line 835, in aot_compile_cpu
    multithreading=args.multithreading.lower() not in ('f', 'false', '0'))
  File ""/tmp/output_base/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/python/tools/saved_model_cli.runfiles/org_tensorflow/tensorflow/python/tools/saved_model_aot_compile.py"", line 259, in aot_compile_cpu_meta_graph_def
    raise _pywrap_tfcompile_import_error  # pylint: disable=raising-bad-type
ImportError: Unable to import _pywrap_tfcompile; you must build TensorFlow with XLA.  You may need to build tensorflow with flag --define=with_xla_support=true.  Original error: cannot import name '_pywrap_tfcompile' from 'tensorflow.python' (/tmp/output_base/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/python/tools/saved_model_cli.runfiles/org_tensorflow/tensorflow/python/__init__.py)
```

There is also no mentioning of XLA (like `--config=xla`) in the log/output"
45044,OP_REQUIRES failed at conv_ops.cc:1106 : Not found: No algorithm worked!,"**System information**
- Linux Ubuntu 20.04
- TensorFlow installed from Docker tensorflow/tensorflow:2.4.0rc1
- TensorFlow version: 2.4.0rc2
- Python version: 3.6.9
- Installed using [Docker](https://hub.docker.com/layers/tensorflow/tensorflow/2.4.0rc1-gpu/images/sha256-6e74a947ed5bc7b64c87575a3824427e462aaafb6bf7c9664e8154cc57f1d1a4?context=explore)
- CUDA/cuDNN version: CUDA 11.1 cuDNN v8
- GPU model and memory: RTX 3080 FE 10GB



**Describe the problem**
While training custom resnet 50 model I get the following build error:
```
2020-11-20 12:05:01.826720: W tensorflow/core/framework/op_kernel.cc:1763] OP_REQUIRES failed at conv_ops.cc:1106 : Not found: No algorithm worked!
```
I don't think the code has any issues. It works fine when training with CPU.

**Any other info / logs**
```
2020-11-20 12:04:55.291380: I tensorflow/core/profiler/lib/profiler_session.cc:136] Profiler session initializing.
2020-11-20 12:04:55.291414: I tensorflow/core/profiler/lib/profiler_session.cc:155] Profiler session started.
2020-11-20 12:04:55.291455: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1365] Profiler found 1 GPUs
2020-11-20 12:04:55.360280: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcupti.so.11.0
2020-11-20 12:04:55.491657: I tensorflow/core/profiler/lib/profiler_session.cc:172] Profiler session tear down.
2020-11-20 12:04:55.491780: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1487] CUPTI activity buffer flushed
2020-11-20 12:04:56.592756: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2020-11-20 12:04:56.610956: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3899970000 Hz
Epoch 1/30
2020-11-20 12:04:58.010569: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2020-11-20 12:04:58.802284: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2020-11-20 12:04:58.807134: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2020-11-20 12:05:01.826720: W tensorflow/core/framework/op_kernel.cc:1763] OP_REQUIRES failed at conv_ops.cc:1106 : Not found: No algorithm worked!
Traceback (most recent call last):
  File ""custom_resnet.py"", line 131, in <module>
    train_model()
  File ""custom_resnet.py"", line 105, in train_model
    callbacks=[tensorboard_callback]
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py"", line 1100, in fit
    tmp_logs = self.train_function(iterator)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py"", line 828, in __call__
    result = self._call(*args, **kwds)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py"", line 888, in _call
    return self._stateless_fn(*args, **kwds)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py"", line 2943, in __call__
    filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py"", line 1919, in _call_flat
    ctx, args, cancellation_manager=cancellation_manager))
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py"", line 560, in call
    ctx=ctx)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py"", line 60, in quick_execute
    inputs, attrs, num_outputs)
tensorflow.python.framework.errors_impl.NotFoundError:  No algorithm worked!
	 [[node model/conv1/Conv2D (defined at custom_resnet.py:105) ]] [Op:__inference_train_function_8452]

Function call stack:
train_function

2020-11-20 12:05:01.905250: W tensorflow/core/kernels/data/generator_dataset_op.cc:107] Error occurred when finalizing GeneratorDataset iterator: Failed precondition: Python interpreter state is not initialized. The process may be terminated.
	 [[{{node PyFunc}}]]
```

nvidia-smi
```
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 455.32.00    Driver Version: 455.32.00    CUDA Version: 11.1     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  GeForce RTX 3080    On   | 00000000:2B:00.0  On |                  N/A |
|  0%   43C    P8    25W / 320W |    857MiB /  9995MiB |      1%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
+-----------------------------------------------------------------------------+
```
nvcc --version
```
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2020 NVIDIA Corporation
Built on Wed_Jul_22_19:09:09_PDT_2020
Cuda compilation tools, release 11.0, V11.0.221
Build cuda_11.0_bu.TC445_37.28845127_0
```
tf.test.is_gpu_available()
```
WARNING:tensorflow:From <stdin>:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.config.list_physical_devices('GPU')` instead.
2020-11-20 12:10:11.234638: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2020-11-20 12:10:11.235502: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2020-11-20 12:10:11.269174: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-11-20 12:10:11.269569: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:2b:00.0 name: GeForce RTX 3080 computeCapability: 8.6
coreClock: 1.71GHz coreCount: 68 deviceMemorySize: 9.76GiB deviceMemoryBandwidth: 707.88GiB/s
2020-11-20 12:10:11.269584: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2020-11-20 12:10:11.271142: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2020-11-20 12:10:11.271167: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2020-11-20 12:10:11.271830: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2020-11-20 12:10:11.271954: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2020-11-20 12:10:11.273538: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2020-11-20 12:10:11.273878: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2020-11-20 12:10:11.273963: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2020-11-20 12:10:11.274040: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-11-20 12:10:11.274432: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-11-20 12:10:11.274959: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2020-11-20 12:10:11.274975: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2020-11-20 12:10:11.593266: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-11-20 12:10:11.593303: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2020-11-20 12:10:11.593309: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2020-11-20 12:10:11.593483: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-11-20 12:10:11.593857: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-11-20 12:10:11.594195: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-11-20 12:10:11.594517: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/device:GPU:0 with 8743 MB memory) -> physical GPU (device: 0, name: GeForce RTX 3080, pci bus id: 0000:2b:00.0, compute capability: 8.6)
True
```


Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
45043,use hooks to fine_tune in Estimator,"**System information**
- TensorFlow version (you are using):tf.1.14
- Are you willing to contribute it (Yes/No):yes

**1. Describe the feature and the current behavior/state.**

when I use hook to fine_tune in estimator, I got such a error:RuntimeError: Graph is finalized and cannot be modified.

My hooks is defined as follows:
class RestoreHook(tf.train.SessionRunHook):
    def __init__(self, checkpoint_path, include=None, exclude=None):
        self.checkpoint_path =  tf.train.latest_checkpoint(checkpoint_path)
        self.include = include
        self.exclude = exclude

    def after_create_session(self, session, coord=None):
        var_list = tf.contrib.framework.get_variables_to_restore(include=self.include, exclude=self.exclude)

        self.init_fn = tf.contrib.framework.assign_from_checkpoint_fn(
            self.checkpoint_path,
            var_list=var_list,
            ignore_missing_vars=True
        )
        if session.run(tf.train.get_or_create_global_step()) == 0:
            # suppress WARN
            log_level = tf.logging.get_verbosity()
            tf.logging.set_verbosity(tf.logging.ERROR)
            self.init_fn(session)
            tf.logging.set_verbosity(log_level)

2、My calling method：

init_checkpoint = './my_model/'
        from finetune import get_tvars
        assignment_map ,assignment_map_keys = get_tvars(init_checkpoint)
        for dict in assignment_map:
            if ""global"" in dict:
                assignment_map.pop(dict)
        include_var = list(assignment_map_keys)
        checkpoint_path = init_checkpoint
        restore_hook = RestoreHook(checkpoint_path, include=include_var)
    else:
        restore_hook = None
    train_spec = tf.estimator.TrainSpec(
        input_fn=input_fn
        max_steps=100000,
        hooks=[restore_hook]
)


"
45041,tf2.3  keras model can't save  big embedding:  tensorflow.SavedModel exceeds maximum protobuf size of 2GB," # what
When we try to save a simple keras model with  embedding layer,which shape is (1e7,16),  we got error `ValueError: Message tensorflow.SavedModel exceeds maximum protobuf size of 2GB: 9789558077` .
We want to save it as SavedModel format ,so that we can use tf serving to serve the model. 

# related problems
[Tensorflow graph bigger than 2GB](https://stackoverflow.com/questions/59558170/tensorflow-graph-bigger-than-2gb)

# simple code that reproduce the error
```python

import tensorflow as tf
from tensorflow import keras

import numpy as np
vocab_size = 10**7
emb_dim = 16
global_emb_weights = np.random.random(size=(vocab_size,emb_dim))
emb = keras.layers.Embedding( mask_zero=True, input_dim=vocab_size, output_dim=emb_dim,
                                     embeddings_initializer=keras.initializers.Constant(
                                         global_emb_weights),trainable=True)

x = keras.Input((100,))
out = emb(x)
model = keras.Model(inputs=x,outputs=out)
model.save(""/tmp/test_tf"",save_format=""tf"",overwrite=True)

``` 
# error
>    File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/saving/saved_model/save.py"", line 80, in save
>     save_lib.save(model, filepath, signatures, options)
>   File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/save.py"", line 1006, in save
>     path, saved_model.SerializeToString(deterministic=True))
> ValueError: Message tensorflow.SavedModel exceeds maximum protobuf size of 2GB: 9789558077

"
45038,[TFLite] Experimental new quantizer calculates the wrong scaling when the input range doesn't include 0,"Hello,

When creating a quantized network with the new experimental quantizer it seems there is a problem with the scaling of the nodes when the input range provided by the representative dataset doesn't include 0 (e.g. [2.3, 5.4] or [-1.2, -0.4] range). 

The small example below creates a network with a single multiply operator and the representative dataset provides a [1.3, 1.4] input range. The expected result, and the one provided with the stable quantizer, of the 1.4*1.4 multiplication is 1.96 but the returned result is 0.00952942. 

The new experimental quantizer seems to calculate the input scaling of the multiply node as (1.4 - 1.3)/255 with a -128 zero-point instead of (1.4 - 0.0)/255 with the same zero-point as done by the stable quantizer. Changing the input range of the representative dataset to [0.0, 1.4] solves the problem. 

I know the new quantizer is experimental so it isn't too much of a problem yet but it's mainly to report the problem if it isn't already known.

Tested version: tf-nightly-2.5.0.dev20201119

```python
import numpy as np
import tensorflow as tf


input = tf.keras.Input(shape=(1))
output = tf.keras.layers.Multiply()([input, input])
model = tf.keras.Model(inputs=input, outputs=output)


def representative_data_gen():
    yield [np.array([[1.3]], dtype=np.float32)]
    yield [np.array([[1.4]], dtype=np.float32)]
    # It works with this line if _experimental_new_quantizer=True
    # yield [np.array([[0.0]], dtype=np.float32)]


converter = tf.lite.TFLiteConverter.from_keras_model(model)
converter.representative_dataset = representative_data_gen
converter.optimizations = [tf.lite.Optimize.DEFAULT]
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]
converter._experimental_new_quantizer = True

tflite_model = converter.convert()

interpreter = tf.lite.Interpreter(model_content=tflite_model)
interpreter.allocate_tensors()

input = np.array([[1.4]], dtype=np.float32)
interpreter.set_tensor(interpreter.get_input_details()[0][""index""], input)
interpreter.invoke()
output = interpreter.get_tensor(interpreter.get_output_details()[0][""index""])

print(""input "", input)
print(""output "", output)
```"
45037,"tensorflow version 2.2.0 ;question:WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000023B864321F8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.","Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1.  It must be a bug, a feature request, or a significant problem with the
    documentation (for small docs fixes please send a PR instead).
2.  The form below must be filled out.
3.  It shouldn't be a TensorBoard issue. Those go
    [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information

-   **Have I written custom code (as opposed to using a stock example script
    provided in TensorFlow)**:
-   **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
-   **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue
    happens on a mobile device**:
-   **TensorFlow installed from (source or binary)**:
-   **TensorFlow version (use command below)**:
-   **Python version**:
-   **Bazel version (if compiling from source)**:
-   **GCC/Compiler version (if compiling from source)**:
-   **CUDA/cuDNN version**:
-   **GPU model and memory**:
-   **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with:

```bash
python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""
```

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
45036,UnicodeDecodeError: 'utf-8' codec can't decode byte 0xc1 in position 50: invalid start byte,"`Traceback (most recent call last):
  File ""object_detection/train.py"", line 167, in <module>
    tf.compat.v1.app.run()
  File ""C:\Users\info\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow\python\platform\app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""C:\Users\info\Anaconda3\envs\tensorflow\lib\site-packages\absl\app.py"", line 303, in run
    _run_main(main, args)
  File ""C:\Users\info\Anaconda3\envs\tensorflow\lib\site-packages\absl\app.py"", line 251, in _run_main
    sys.exit(main(argv))
  File ""object_detection/train.py"", line 163, in main
    worker_job_name, is_chief, FLAGS.train_dir)
  File ""C:\Users\info\Anaconda3\envs\tensorflow\lib\site-packages\object_detection-0.1-py3.7.egg\object_detection\legacy\trainer.py"", line 279, in train
    train_config.prefetch_queue_capacity, data_augmentation_options)
  File ""C:\Users\info\Anaconda3\envs\tensorflow\lib\site-packages\object_detection-0.1-py3.7.egg\object_detection\legacy\trainer.py"", line 58, in create_input_queue
    tensor_dict = create_tensor_dict_fn()
  File ""object_detection/train.py"", line 120, in get_next
    dataset_builder.build(config)).get_next()
  File ""C:\Users\info\Anaconda3\envs\tensorflow\lib\site-packages\object_detection-0.1-py3.7.egg\object_detection\builders\dataset_builder.py"", line 231, in build
    config.input_path[:], input_reader_config, filename_shard_fn=shard_fn)
  File ""C:\Users\info\Anaconda3\envs\tensorflow\lib\site-packages\object_detection-0.1-py3.7.egg\object_detection\builders\dataset_builder.py"", line 150, in read_dataset
    filename_shard_fn)
  File ""C:\Users\info\Anaconda3\envs\tensorflow\lib\site-packages\object_detection-0.1-py3.7.egg\object_detection\builders\dataset_builder.py"", line 76, in _read_dataset_internal
    filenames = tf.gfile.Glob(input_files)
  File ""C:\Users\info\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow\python\lib\io\file_io.py"", line 350, in get_matching_files
    return get_matching_files_v2(filename)
  File ""C:\Users\info\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow\python\lib\io\file_io.py"", line 415, in get_matching_files_v2
    for single_filename in pattern
  File ""C:\Users\info\Anaconda3\envs\tensorflow\lib\site-packages\tensorflow\python\lib\io\file_io.py"", line 417, in <listcomp>
    compat.as_bytes(single_filename))
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xc1 in position 50: invalid start byte
[ERROR|main.py:37] 2020-11-20 18:26:38,251 > Transfer leaarning Error
`

I can't find what is the problem.
I set tf_example_decoder.py > dct_method='INTEGER_FAST'  (NOT WORK)
When read TFRecord and Make TFRecord, I can see this error.
help me!

I used Anaconda 4.3 / Tensorflow 2.3.0 / Python 3.7"
45035,tf.keras.layers.LSTM don't check mask shape(tensorflow-gpu with cuda),"use tensorflow-gpu with cuda, LSTM don't check mask shape。but it check in tensorflow-cpu. it cause the code below failed in cpu but work in GPU.
error information:  tensorflow.python.framework.errors_impl.OutOfRangeError: Tried to read from index 5 but array size is: 5
```
inputs = tf.random.normal([4, 6, 4])
lstm=tf.keras.layers.LSTM(4,return_sequences=True)
masks=tf.sequence_mask(
    [1,2,3,4],
    maxlen=5,
    dtype=tf.bool
)
# or 
# masks=tf.sequence_mask(
#     [1,2,3,4,4],
#     maxlen=5,
#     dtype=tf.bool
# )
output=lstm(inputs,mask=masks)
```
"
45034,setup.py is missing tblib dependency,"As the title says: tblib is used at https://github.com/tensorflow/tensorflow/blob/5e48683fe0983d5f35f1305f426d1b06904329a4/tensorflow/python/distribute/multi_process_runner.py but not declared as a dependency in setup.py

This is for current master and 2.4rc2"
45033,tensorflow/lite/micro/tools/make/Makefile:403: *** Something went wrong with the flatbuffers download: .  Stop.,"

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Windows
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:N
- TensorFlow installed from (source or binary):source
- TensorFlow version:2.3.1
- Python version:3.8.3
- Installed using virtualenv? pip? conda?:pip
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:



**Describe the problem**
The code I entered is：
PS E:\tensorflow> make -f tensorflow/lite/micro/tools/make/Makefile test_hello_world_test
The output result is：
process_begin: CreateProcess(NULL, uname -m, ...) failed.
process_begin: CreateProcess(NULL, bash E:\tensorflow\tensorflow\lite\micro\tools\make\flatbuffers_download.sh tensorflow/lite/micro/tools/make/downloads, ...) failed.
tensorflow/lite/micro/tools/make/Makefile:403: *** Something went wrong with the flatbuffers download: .  Stop.

What is the reason?"
45032,Wheel repairing broken when using tensorflow/tensorflow:custom-op-gpu-ubuntu16 docker image,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04
- TensorFlow installed from (source or binary): source
- TensorFlow version: nightly (master branch)
- Python version: 3.6
- Installed using virtualenv? pip? conda?: n/a
- Bazel version (if compiling from source): 3.1.0 (installed by bazelisk v1.3.0 using install_bazelisk from tensorflow/tools/ci_build/release/common.sh)
- GCC/Compiler version (if compiling from source): gcc7_manylinux2010-nvcc-cuda10.1
- CUDA/cuDNN version: n/a
- GPU model and memory: n/a

When building ""manylinux2010"" TensorFlow wheel package using custom-op-gpu-ubuntu16 docker image, the repair step using auditwheel package fails with the following stack trace:

> Traceback (most recent call last):
>   File ""/usr/local/bin/auditwheel"", line 8, in <module>
>     sys.exit(main())
>   File ""/usr/local/lib/python3.6/dist-packages/auditwheel/main.py"", line 47, in main
>     rval = args.func(args, p)
>   File ""/usr/local/lib/python3.6/dist-packages/auditwheel/main_repair.py"", line 45, in execute
>     from .repair import repair_wheel
>   File ""/usr/local/lib/python3.6/dist-packages/auditwheel/repair.py"", line 14, in <module>
>     from .wheeltools import InWheelCtx, add_platforms
>   File ""/usr/local/lib/python3.6/dist-packages/auditwheel/wheeltools.py"", line 15, in <module>
>     from wheel.util import urlsafe_b64encode, open_for_csv, native  # type: ignore
> ImportError: cannot import name 'open_for_csv' 
> 

The exact command that causes the error is
auditwheel repair --plat manylinux2010_x86_64 -w . tf_nightly_v2-2.5.0-cp36-cp36m-linux_x86_64.whl 

It appears that the failure may be related to [this change](https://github.com/tensorflow/tensorflow/commit/38bc69da9c441e9811d0364fe5cad576c654db3f) that pins down the version of wheel package to a relatively new 0.35 while auditwheel version stayed at 2.0.0, as installed in the docker image using [install_auditwheel.sh](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/ci_build/install/install_auditwheel.sh).

It is possible to work around this problem by, for example, installing a newer version of auditwheel after calling [install_ubuntu_16_pip_deps](https://github.com/tensorflow/tensorflow/blob/84d0c4e84036e24fe5bd2765428c1624300cc8b4/tensorflow/tools/ci_build/release/common.sh#L106), but a proper fix should probably be done. I am not a specialist in TensorFlow build system and I would not be able to test such a fix thoroughly, but I could provide the initial patch to update the version of auditwheel in [install_auditwheel.sh](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/ci_build/install/install_auditwheel.sh). Would that be the right course of action, or am I doing something wrong?
"
45030,Request implementation of SSE regularization,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): 2.3 (also used 1.14 before)
- Are you willing to contribute it (Yes/No): 
I would like to help but I am not too familiar with tensorflow operator level coding.


**Describe the feature and the current behavior/state.**
SSE (stochastic shared embedding) has been proven to be a very useful embedding level regularization techniques in deep learning when dropout and weight decay do not work well enough for embeddings. 

See paper: ""Stochastic Shared Embeddings: Data-driven Regularization of Embedding Layers"": https://papers.nips.cc/paper/2019/file/37693cfc748049e45d87b8c7d8b9aacd-Paper.pdf; ""SSE-PT: Sequential Recommendation Via Personalized Transformer""(https://dl.acm.org/doi/10.1145/3383313.3412258); ""Multimodal Categorization of Crisis Events in Social Media"" (https://openaccess.thecvf.com/content_CVPR_2020/papers/Abavisani_Multimodal_Categorization_of_Crisis_Events_in_Social_Media_CVPR_2020_paper.pdf). 

But this feature is largely missing in tensorflow implementation and makes it hard for users to use SSE, unlike dropout. Ideally it should be as easy to use SSE as using dropout or l2.

**Will this change the current api? How?**
Yes, this would require a new embedding_lookup operator that supports embeddings stochastic transitioning according to a predefined sparse probability transition matrix or a uniform transition mechanism at default. The uniform case is implemented at https://github.com/wuliwei9278/SSE-PT as a simple example but this is largely a hack. 

**Who will benefit with this feature?**
I work at Linkedin and when training embeddings using this regularization technique in addition to dropout and l2 would lead to faster convergence of neural nets and better performance but I had to use it using a hack by duplicating training data with embedding ids masked into different ids, which is not very efficient and cannot be scaled when dataset size is large. Including this would make my life much easier, and likewise for my colleagues and many researchers, whose models also suffer from model embedding layer overfitting.

**Any Other info.**
Please contact liwwu@linkedin.com for more information."
45028,CUDNN_STATUS_NOT_INITIALIZED error with tensorflow-gpu 2.4.0-rc2 RTX3070 CUDA11.0 cudnn8.0.2 windows10 and pip,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): windows10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: --
- TensorFlow installed from (source or binary): binary
- TensorFlow version: 2.4.0rc2
- Python version :3.8.5
- Installed using virtualenv? pip? conda?: pip
- Bazel version (if compiling from source): --
- GCC/Compiler version (if compiling from source): --
- CUDA/cuDNN version: CUDA11.0 cudnn-11.0-windows-x64-v8.0.2.39  graphics driver version: 457.30
- GPU model and memory: RTX 3070 8G



**Describe the problem**
I install cuda cudnn following the requirement for TensorFlow-gpu 2.4.0-rc2 as shown in https://github.com/tensorflow/tensorflow/releases, but get cudnn initialization error. I have uninstalled and reinstalled for several times, and I also tried TensorFlow-gpu 2.4.0-rc1 several days ago, the same errer was raised.

**Provide the exact sequence of commands / steps that you executed before running into the problem**
The following is the code to re produce the error:
```python
import tensorflow as tf
import numpy as np
from tensorflow.keras import layers
from tensorflow.keras.models import Sequential


x = np.random.normal(size=(100, 28, 28, 1)).astype(np.float32)
y = np.zeros([100, 10], dtype=np.float32)
y[:, 1] = 1.

train_ds = tf.data.Dataset.from_tensor_slices((x, y)).shuffle(buffer_size=100).batch(32)
num_classes = 10

model = Sequential([
  layers.Conv2D(16, 3, padding='same', activation='relu'),
  layers.MaxPooling2D(),
  layers.Conv2D(32, 3, padding='same', activation='relu'),
  layers.MaxPooling2D(),
  layers.Conv2D(64, 3, padding='same', activation='relu'),
  layers.MaxPooling2D(),
  layers.Flatten(),
  layers.Dense(128, activation='relu'),
  layers.Dense(num_classes)
])
model.compile(optimizer='adam',
              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])
epochs=10
history = model.fit(
  train_ds,
  epochs=epochs
)
```
**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
logs:
```
2020-11-20 11:38:38.097262: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudart64_110.dll
2020-11-20 11:38:40.566842: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2020-11-20 11:38:40.568068: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library nvcuda.dll
2020-11-20 11:38:40.604223: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:65:00.0 name: GeForce RTX 3070 computeCapability: 8.6
coreClock: 1.815GHz coreCount: 46 deviceMemorySize: 8.00GiB deviceMemoryBandwidth: 417.29GiB/s
2020-11-20 11:38:40.604439: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudart64_110.dll
2020-11-20 11:38:40.618831: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublas64_11.dll
2020-11-20 11:38:40.618938: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublasLt64_11.dll
2020-11-20 11:38:40.622412: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cufft64_10.dll
2020-11-20 11:38:40.623498: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library curand64_10.dll
2020-11-20 11:38:40.631377: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusolver64_10.dll
2020-11-20 11:38:40.633911: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusparse64_11.dll
2020-11-20 11:38:40.634568: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudnn64_8.dll
2020-11-20 11:38:40.634734: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2020-11-20 11:38:40.635316: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-11-20 11:38:40.636515: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:65:00.0 name: GeForce RTX 3070 computeCapability: 8.6
coreClock: 1.815GHz coreCount: 46 deviceMemorySize: 8.00GiB deviceMemoryBandwidth: 417.29GiB/s
2020-11-20 11:38:40.637060: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudart64_110.dll
2020-11-20 11:38:40.637713: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublas64_11.dll
2020-11-20 11:38:40.638072: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublasLt64_11.dll
2020-11-20 11:38:40.638277: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cufft64_10.dll
2020-11-20 11:38:40.638448: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library curand64_10.dll
2020-11-20 11:38:40.638724: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusolver64_10.dll
2020-11-20 11:38:40.638921: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusparse64_11.dll
2020-11-20 11:38:40.639189: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudnn64_8.dll
2020-11-20 11:38:40.639443: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2020-11-20 11:38:41.262522: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-11-20 11:38:41.262635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2020-11-20 11:38:41.262694: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2020-11-20 11:38:41.262900: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6177 MB memory) -> physical GPU (device: 0, name: GeForce RTX 3070, pci bus id: 0000:65:00.0, compute capability: 8.6)
2020-11-20 11:38:41.263873: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
Epoch 1/10
2020-11-20 11:38:42.052106: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2020-11-20 11:38:42.135350: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublas64_11.dll
2020-11-20 11:38:42.994775: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublasLt64_11.dll
2020-11-20 11:38:43.000109: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudnn64_8.dll
2020-11-20 11:38:43.875475: E tensorflow/stream_executor/cuda/cuda_dnn.cc:336] Could not create cudnn handle: CUDNN_STATUS_NOT_INITIALIZED
2020-11-20 11:38:43.875620: E tensorflow/stream_executor/cuda/cuda_dnn.cc:340] Error retrieving driver version: Unimplemented: kernel reported driver version not implemented on Windows
2020-11-20 11:38:43.877456: E tensorflow/stream_executor/cuda/cuda_dnn.cc:336] Could not create cudnn handle: CUDNN_STATUS_NOT_INITIALIZED
2020-11-20 11:38:43.877755: E tensorflow/stream_executor/cuda/cuda_dnn.cc:340] Error retrieving driver version: Unimplemented: kernel reported driver version not implemented on Windows
Traceback (most recent call last):
  File ""F:/python_ws/helloworld/main.py"", line 29, in <module>
    history = model.fit(
  File ""C:\Users\dell\Anaconda3\envs\tf24rcpy38\lib\site-packages\tensorflow\python\keras\engine\training.py"", line 1100, in fit
    tmp_logs = self.train_function(iterator)
  File ""C:\Users\dell\Anaconda3\envs\tf24rcpy38\lib\site-packages\tensorflow\python\eager\def_function.py"", line 828, in __call__
    result = self._call(*args, **kwds)
  File ""C:\Users\dell\Anaconda3\envs\tf24rcpy38\lib\site-packages\tensorflow\python\eager\def_function.py"", line 888, in _call
    return self._stateless_fn(*args, **kwds)
  File ""C:\Users\dell\Anaconda3\envs\tf24rcpy38\lib\site-packages\tensorflow\python\eager\function.py"", line 2942, in __call__
    return graph_function._call_flat(
  File ""C:\Users\dell\Anaconda3\envs\tf24rcpy38\lib\site-packages\tensorflow\python\eager\function.py"", line 1918, in _call_flat
    return self._build_call_outputs(self._inference_function.call(
  File ""C:\Users\dell\Anaconda3\envs\tf24rcpy38\lib\site-packages\tensorflow\python\eager\function.py"", line 555, in call
    outputs = execute.execute(
  File ""C:\Users\dell\Anaconda3\envs\tf24rcpy38\lib\site-packages\tensorflow\python\eager\execute.py"", line 59, in quick_execute
    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
tensorflow.python.framework.errors_impl.UnknownError:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.
	 [[node sequential/conv2d/Conv2D (defined at F:/python_ws/helloworld/main.py:29) ]] [Op:__inference_train_function_830]

Function call stack:
train_function


Process finished with exit code 1
```"
45026,Reduce on MirroredVariable,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution: Ubuntu 16.04
- TensorFlow installed from (source or binary): pip
- TensorFlow version (use command below): 2.4.0rc2
- Python version: 3.8.3
- CUDA/cuDNN version:  11.0
- GPU model and memory: 4*1080Ti




**Describe the current behavior**

Run the following code:
```python
import tensorflow as tf

s = tf.distribute.MirroredStrategy()

with s.scope():
    v = tf.Variable(tf.ones((5,)))
for x in v.values:
    print(x, x.device)

# @tf.function
def run():
    def fn(value):
        ctx = tf.distribute.get_replica_context()
        # value = 0.0 + value
        return ctx.all_reduce(tf.distribute.ReduceOp.SUM, value)
    return s.run(fn, args=(v,))

print(run())
```

Outputs:
```
PerReplica:{
  0: tf.Tensor([1. 1. 1. 1. 1.], shape=(5,), dtype=float32),
  1: tf.Tensor([1. 1. 1. 1. 1.], shape=(5,), dtype=float32),
  2: tf.Tensor([1. 1. 1. 1. 1.], shape=(5,), dtype=float32),
  3: tf.Tensor([1. 1. 1. 1. 1.], shape=(5,), dtype=float32)
}
```

Which is clearly wrong.

**Describe the expected behavior**

Expect output:
```
PerReplica:{
  0: tf.Tensor([4. 4. 4. 4. 4.], shape=(5,), dtype=float32),
  1: tf.Tensor([4. 4. 4. 4. 4.], shape=(5,), dtype=float32),
  2: tf.Tensor([4. 4. 4. 4. 4.], shape=(5,), dtype=float32),
  3: tf.Tensor([4. 4. 4. 4. 4.], shape=(5,), dtype=float32)
}
```

Uncomment the line `# value = 0.0 + value` will make the result correct."
45025,AttributeError: 'TFLiteConverter' object has no attribute 'target_spec'," URL(s) with the issue:

https://www.tensorflow.org/lite/performance/post_training_quantization

## Description of issue:

i want to quant my model with int8, my code like this:


import tensorflow as tf

converter = tf.lite.TFLiteConverter.from_keras_model_file(""./tf_keras_mnist_model/cifar10_vgg16.h5"")
converter.optimizations = [tf.lite.Optimize.DEFAULT]
def representative_dataset_gen():
  for _ in range(10):
    # Get sample input data as a numpy array in a method of your choosing.
    yield [input]
converter.representative_dataset = representative_dataset_gen
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]
converter.inference_input_type = tf.int8  # or tf.uint8
converter.inference_output_type = tf.int8  # or tf.uint8
tflite_quant_model = converter.convert()
open(""./tf_keras_mnist_model/cifar10_vgg16_quant8.tflite"", ""wb"").write(tflite_quant_model)

this code is also in your example provided, but I get the error like the title.
 my tf is 1.14.
how can i solute this problem?

the second question is :
when i use   tf.lite.TFLiteConverter.from_keras_model,   i got the error TFLiteConverter has no attribute from_keras_model, i also encount the problem   TFLiteConverter has no attribute from_saved_model?

this two api need the tf version?

thanks 

appreciate to get your apply!
"
45024,Could not create TensorFlow Graph: Not found: Op type not registered 'AddV2'  IOS,"Using tensorFlow_gpu==1.15.0, ssD_mobilenet_V1 is trained through TensorFlow API. Then  
models-master\research\object_detection>python export_inference_graph.py
 --input_type image_tensor 
--pipeline_config_path  /data/pipeline.config 
--trained_checkpoint_prefix  /training/model.ckpt-200000 
--output_directory  convert_pb/
 Get frozen_inference_graph.pb,
This frozen_inference_graph.pb file is applied to IOS to report an error,
/Users/zhao/Desktop/tensorflow-1.15.0/tensorflow/examples/ios/camera/tensorflow_utils.mm:140] Could not create TensorFlow Graph: Not found: Op type not registered 'AddV2'
"
45023,"Invalid argument:  assertion failed: [Unable to decode bytes as JPEG, PNG, GIF, or BMP]","2020-11-19 17:13:14.386367: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:172] Filling up shuffle buffer (this may take a while): 168 of 256
2020-11-19 17:13:24.373184: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:172] Filling up shuffle buffer (this may take a while): 213 of 256
2020-11-19 17:13:26.240500: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:221] Shuffle buffer filled.
 6/83 [=>............................] - ETA: 1:13 - loss: 1.0636 - accuracy: 0.4635Traceback (most recent call last):
  File ""model_vgg.py"", line 241, in <module>
    loss0, accuracy0 = model.evaluate(validation_dataset)
  File ""/gpfs/data/ahsan-lab/Sameep/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py"", line 108, in _method_wrapper
    return method(self, *args, **kwargs)
  File ""/gpfs/data/ahsan-lab/Sameep/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py"", line 1379, in evaluate
    tmp_logs = test_function(iterator)
  File ""/gpfs/data/ahsan-lab/Sameep/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py"", line 780, in __call__
    result = self._call(*args, **kwds)
  File ""/gpfs/data/ahsan-lab/Sameep/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py"", line 807, in _call
    return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable
  File ""/gpfs/data/ahsan-lab/Sameep/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/eager/function.py"", line 2829, in __call__
    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access
  File ""/gpfs/data/ahsan-lab/Sameep/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/eager/function.py"", line 1848, in _filtered_call
    cancellation_manager=cancellation_manager)
  File ""/gpfs/data/ahsan-lab/Sameep/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/eager/function.py"", line 1924, in _call_flat
    ctx, args, cancellation_manager=cancellation_manager))
  File ""/gpfs/data/ahsan-lab/Sameep/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/eager/function.py"", line 550, in call
    ctx=ctx)
  File ""/gpfs/data/ahsan-lab/Sameep/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/eager/execute.py"", line 60, in quick_execute
    inputs, attrs, num_outputs)
tensorflow.python.framework.errors_impl.InvalidArgumentError: 2 root error(s) found.
  (0) Invalid argument:  assertion failed: [Unable to decode bytes as JPEG, PNG, GIF, or BMP]
	 [[{{node decode_image/cond_jpeg/else/_1/decode_image/cond_jpeg/cond_png/else/_20/decode_image/cond_jpeg/cond_png/cond_gif/else/_39/decode_image/cond_jpeg/cond_png/cond_gif/Assert/Assert}}]]
	 [[IteratorGetNext]]
	 [[IteratorGetNext/_4]]
  (1) Invalid argument:  assertion failed: [Unable to decode bytes as JPEG, PNG, GIF, or BMP]
	 [[{{node decode_image/cond_jpeg/else/_1/decode_image/cond_jpeg/cond_png/else/_20/decode_image/cond_jpeg/cond_png/cond_gif/else/_39/decode_image/cond_jpeg/cond_png/cond_gif/Assert/Assert}}]]
	 [[IteratorGetNext]]
0 successful operations.
0 derived errors ignored. [Op:__inference_test_function_1802]

Function call stack:
test_function -> test_function"
45021,execution_profile_test_with_xla_hlo_profile_cpu fails on s390x,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): 2.3.1
- Python version: 3.6.9
- Bazel version (if compiling from source): 3.4.1
- GCC/Compiler version (if compiling from source): Ubuntu 7.5.0-3ubuntu1~18.04
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A

**Describe the current behavior**
When running test case  `//tensorflow/compiler/xla/tests:execution_profile_test_with_xla_hlo_profile_cpu` on s390x, the test case fails with following error:
```
[ RUN      ] ExecutionProfileTest.ExecuteWithExecutionProfile
2020-10-29 23:11:59.065069: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 1555500000 Hz
2020-10-29 23:11:59.065621: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2aa54027e20 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-10-29 23:11:59.065633: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-10-29 23:11:59.077512: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2aa54028350 initialized for platform Interpreter (this does not guarantee that XLA will be used). Devices:
2020-10-29 23:11:59.077526: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Interpreter, <undefined>
tensorflow/compiler/xla/tests/execution_profile_test.cc:60: Failure
Expected: (execution_profile.compute_cycle_count()) > (0), actual: 0 vs 0
[  FAILED  ] ExecutionProfileTest.ExecuteWithExecutionProfile (36 ms)
[----------] 1 test from ExecutionProfileTest (36 ms total)
```

On debugging this test case a little, I found that the Test case is able to call `RecordCycleDelta` and registering values in `new_cycle_count` but on calling `compute_function_`, the `profile_counters` are not filled.
The compute function here is returning a valid value in `profile_counters` for x86 but returning 0 for s390x.
https://github.com/tensorflow/tensorflow/blob/21f5c12e3d9c5b0c2f4c45c70a3da08b4edf212d/tensorflow/compiler/xla/service/cpu/cpu_executable.cc#L188

**Describe the expected behavior**
The `profile_counters` should be populated with a valid value and test case should pass.

**Standalone code to reproduce the issue**
```bazel --host_jvm_args=""-Xms1024m"" --host_jvm_args=""-Xmx2048m"" test --host_javabase=""@local_jdk//:jdk"" --test_tag_filters=-gpu,-benchmark-test,-v1only,-no_oss,-oss_serial -k --test_timeout 300,450,1200,3600 --build_tests_only --test_output=errors --verbose_failures -- //tensorflow/compiler/xla/tests:execution_profile_test_with_xla_hlo_profile_cpu```
"
45020,Building r2.3 branch fails on Windows 10 x64,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 x64 build 19041.630
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): source
- TensorFlow version: 2.3 (commit 5681c179eff80bce00e526303950b67b23cad14c)
- Python version: 3.6.8
- Installed using virtualenv? pip? conda?: N/A
- Bazel version (if compiling from source): 3.7.0
- GCC/Compiler version (if compiling from source): msvc 19.28.29333
- CUDA/cuDNN version: CUDA 10.1.243; cuDNN version 8
- GPU model and memory: GTX 1080 8GB

**Describe the problem**
TensorFlow branch r2.3 fails to compile on Windows 10 (see log section)

**Provide the exact sequence of commands / steps that you executed before running into the problem**
Setup as per https://www.tensorflow.org/install/source_windows. Every setting set to default, except for CUDA support which was enabled.
`bazel build //tensorflow/tools/pip_package:build_pip_package`

**Any other info / logs**
(Most of the log skipped as it is a normal build until around this point)
```
external/com_google_absl\absl/time/clock.h(70): error C2065: 'Duration': undeclared identifier
external/com_google_absl\absl/time/clock.h(70): error C2146: syntax error: missing ')' before identifier 'duration'
external/com_google_absl\absl/time/clock.h(70): error C2143: syntax error: missing ';' before '{'
external/com_google_absl\absl/time/clock.h(70): error C2447: '{': missing function header (old-style formal list?)
Target //tensorflow/tools/pip_package:build_pip_package failed to build
INFO: Elapsed time: 720.763s, Critical Path: 176.43s
INFO: 860 processes: 860 local.
FAILED: Build did NOT complete successfully
```

Bonus: I get an entirely different error in the current master as of this writing (6de8d69b23ebc26c7f364ce4bc775aa45a063937):
```
this rule is missing dependency declarations for the following files included by 'tensorflow/lite/tools/optimize/model_utils.cc':
  'external/com_google_absl/absl/strings/string_view.h'
  'external/com_google_absl/absl/base/internal/throw_delegate.h'
```"
45019,Error while loading .jpg images. Please help,"Traceback (most recent call last):
  File ""/gpfs/data/ahsan-lab/Sameep/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/eager/context.py"", line 2102, in execution_mode
    yield
  File ""/gpfs/data/ahsan-lab/Sameep/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/data/ops/iterator_ops.py"", line 758, in _next_internal
    output_shapes=self._flat_output_shapes)
  File ""/gpfs/data/ahsan-lab/Sameep/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/ops/gen_dataset_ops.py"", line 2610, in iterator_get_next
    _ops.raise_from_not_ok_status(e, name)
  File ""/gpfs/data/ahsan-lab/Sameep/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 6843, in raise_from_not_ok_status
    six.raise_from(core._status_to_exception(e.code, message), None)
  File ""<string>"", line 3, in raise_from
tensorflow.python.framework.errors_impl.InvalidArgumentError: Expected image (JPEG, PNG, or GIF), got unknown format starting with '\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000'
	 [[{{node DecodeJpeg}}]] [Op:IteratorGetNext]

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""model_vgg.py"", line 212, in <module>
    model, base_model = make_model(IMG_SIZE = IMG_SIZE, num_classes=3)
  File ""model_vgg.py"", line 161, in make_model
    image_batch, label_batch = next(iter(train_ds))
  File ""/gpfs/data/ahsan-lab/Sameep/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/data/ops/iterator_ops.py"", line 736, in __next__
    return self.next()
  File ""/gpfs/data/ahsan-lab/Sameep/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/data/ops/iterator_ops.py"", line 772, in next
    return self._next_internal()
  File ""/gpfs/data/ahsan-lab/Sameep/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/data/ops/iterator_ops.py"", line 764, in _next_internal
    return structure.from_compatible_tensor_list(self._element_spec, ret)
  File ""/gpfs/data/ahsan-lab/Sameep/tensorflow-gpu/lib/python3.6/contextlib.py"", line 99, in __exit__
    self.gen.throw(type, value, traceback)
  File ""/gpfs/data/ahsan-lab/Sameep/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/eager/context.py"", line 2105, in execution_mode
    executor_new.wait()
  File ""/gpfs/data/ahsan-lab/Sameep/tensorflow-gpu/lib/python3.6/site-packages/tensorflow/python/eager/executor.py"", line 67, in wait
    pywrap_tfe.TFE_ExecutorWaitForAllPendingNodes(self._handle)
tensorflow.python.framework.errors_impl.InvalidArgumentError: Expected image (JPEG, PNG, or GIF), got unknown format starting with '\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000\000'
	 [[{{node DecodeJpeg}}]]
2020-11-19 13:35:49.049747: W tensorflow/core/kernels/data/cache_dataset_ops.cc:798] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead."
45017,Filling values when rotating an image using functions like tfa.image.rotate() and tfa.image.translate(),"**System information**
- TensorFlow version (you are using): 2.3.0
- Are you willing to contribute it (Yes/No): Yes. I'm not a great programmer, but I'm willing to help in any way I can.

**Describe the feature and the current behavior/state.**

_This feature request stems from a separate issue that was described [here](https://github.com/tensorflow/tensorflow/issues/44059)._

When you use skimage to [rotate](https://scikit-image.org/docs/dev/api/skimage.transform.html#skimage.transform.rotate) or translate an image, you are given the option to fill in the values that the image loses by performing these operations with reflected values or symmetric values, for example. I used to have an augmentation function that used this functionality successfully, but then the functionality stopped. 

I updated the augmentation to use the functions from tensorflow_addons listed in the title. However, I've now lost this ability to fill in lost values to utilize some of the original information. I think it'd be a good idea to add this as an option to these functions in tfa.

**Will this change the current api? How?**

Not sure.

**Who will benefit with this feature?**

ML practitioners, remote sensing practitioners, geospatial professionals in general.

**Any Other info.**

The modes that skimage includes for these fill values are in line with the behavior of [numpy.pad](https://numpy.org/doc/stable/reference/generated/numpy.pad.html#numpy.pad).
"
45016,"Memory leak with tf.GradientTape, tf.while_loop and tf.function","**System information**
- I have a minimal working example of some custom code which highlights the bug. My code is just a very trimmed down scematic of a larger code I have written, that functions perfectly, it just has a memory leak that requires restarting the process regularly.
- The platform is Linux. Python version 3.8
3.6.8 (default, Nov  3 2020, 19:58:28)
[GCC 7.2.1 20170829 (Red Hat 7.2.1-1)]

- I did not install TensorFlow on this system, so I'm unsure of the details.
- Tensorflow version is 2.3.0
- I'm not using GPU, I typically get this kind of message reported to my python session when running TensorFlow
This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX512F
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.

I have written a short piece of code that performs a basic regression.
I'm forming a prediction y_hat using an input of dimension = 100 and 100 trainable variables stored in ""w"".

I have two ways of forming the prediction vector with which I calculate my loss (MSE).

1. One method is the standard way that you would expect any sane person to do it: exploit vector arithmitic. If I evaluate the gradient of the loss calculated this way, and iterate, I see no growth in the memory footprint of my process over time.

2. If however, I use a tf.while_loop and build the MSE loss by summing increments then each time I evaluate a gradient, the memory footprint of my process grows and I don't know how to clear it.

Finally, note that if you remove the @tf.function decorator then the memory leak vanishes. Suggesting the problem arises somehow through autograph applied to loops.

Note: I have tried reformulating my code as both an (autographed) for loop as well as tf.scan, and I see the same memory growth in all cases.

Although in the example I have shown, there is no need for the loop, and I can easily avoid this memory leak by not using it. I can also avoid the memory leak by not using tf.function and running my code in eager mode. In reality my original code is significantly more complex and I do many operations inside the loop and depend on TensorArrays to do further operations on the output. Furthermore, performance is critical, so running in eager mode is not an option.

```
import tensorflow as tf
import os
import psutil

# simulate a basic loop
def get_loss(w, x, y, use_loop=True):

    # infer the length of our loop form the size of our inputs
    T = tf.shape(y)[0]

    # creating the vector of predictions is unnecessarily complicated
    # when using the tensor array, but this is just a minimal use case
    # that exposes exposes the memory leak
    if use_loop:

        # what we do at each iteration of the loop
        def body(t, loss):

            # get the prediction
            y_hat = tf.reduce_sum(x[t] * w, axis=-1)

            # into the next
            return t+1, loss + tf.square(y[t,0] - y_hat)

        # run the while loop
        t, loss = tf.while_loop(lambda t, *args: t < T,
                                 body,
                                 [tf.constant(0), tf.constant(0.)],
                                 name='main_loop')

        # unstack the tensor array to get the vector of predictions
        loss /= tf.cast(T, tf.float32)

        # return the loss
        return loss

    else:

        # other wise just broadcast
        y_hat_vector = tf.reduce_sum(x * w, axis=1, keepdims=True)

        # minimize some loss
        return tf.reduce_mean(tf.square(y - y_hat_vector))

# get the gradient
@tf.function
def get_gradient(w, x, y, use_loop):

    with tf.GradientTape() as g:
        loss = get_loss(w, x, y, use_loop)
    return g.gradient(loss, w)

# function to get memory usage
def get_memory_usage():
    pid = os.getpid()
    py = psutil.Process(pid)
    return py.memory_info()[0]/2.**30  # memory use in GB...I think

# now run the training loop
w = tf.Variable(tf.random.normal((100,)))
x = tf.constant(tf.random.normal((1024, 100)))
y = tf.constant(tf.random.normal((1024, 1)))

# simulate a training loop
# don't actually apply the gradients, just calculate them on the same data
# over and over again
# this loop produces no memory leak
for i in range(20):

    # each iteration we calculate the gradient of our loss
    grad = get_gradient(w, x, y, use_loop=False)
    tf.print('avg. grad:', tf.reduce_mean(grad),
             '\tmem usage:', get_memory_usage())

# but if we use the while loop
# the memory footprint of this process just grows and grows and goes
# until eventually a training loop would be killed by the operating system
for i in range(20):
	# each iteration we calculate the gradient of our loss
	grad = get_gradient(w, x, y, use_loop=True)
	tf.print('avg. grad:', tf.reduce_mean(grad),
		  '\tmem usage:', get_memory_usage())
```

"
45014,Cannot use Hexagon delegate in Oneplus 6t. Failed to fetch Hexagon NN version. Not working since 18-Nov-2020.,"
2020-11-18 23:49:31.577 10150-10267/org.tensorflow.lite.examples.alerts.debug E/org.tensorflow.lite.examples.alerts.debug: vendor/qcom/proprietary/commonsys-intf/adsprpc/src/apps_std_imp.c:728:Error 45: fopen failed for libhexagon_nn_skel_v65.so. (No such file or directory)

2020-11-18 23:49:31.578 929-961/? E//vendor/bin/cdsprpcd: vendor/qcom/proprietary/commonsys-intf/adsprpc/src/apps_std_imp.c:728:Error 45: fopen failed for libhexagon_nn_skel_v65.so. (No such file or directory)

2020-11-18 23:49:31.578 10150-10232/org.tensorflow.lite.examples.alerts.debug D/org.tensorflow.lite.examples.alerts.debug: vendor/qcom/proprietary/commonsys-intf/adsprpc/src/fastrpc_apps_user.c:921: Error fffffffb: remote handle open domain failed. domain 3, name file:///libhexagon_nn_skel_v65.so?hexagon_nn_domains_skel_handle_invoke&_modver=1.0&_dom=cdsp, dlerror cannot open libhexagon_nn_skel_v65.so

2020-11-18 23:49:31.578 10150-10232/org.tensorflow.lite.examples.alerts.debug D/org.tensorflow.lite.examples.alerts.debug: vendor/qcom/proprietary/commonsys-intf/adsprpc/src/fastrpc_apps_user.c:958: Error fffffffb: remote handle64 open failed. name file:///libhexagon_nn_skel_v65.so?hexagon_nn_domains_skel_handle_invoke&_modver=1.0&_dom=cdsp

2020-11-18 23:49:31.578 10150-10232/org.tensorflow.lite.examples.alerts.debug W/tflite: Failed to fetch Hexagon NN version. This might be because you're using incompatible versions of libhexagon_interface and libhexagon_nn_skel. You must use compatible versions. Refer to Tensorflow Lite Hexagon Delegate Guide.

2020-11-18 23:49:31.578 10150-10232/org.tensorflow.lite.examples.alerts.debug I/tflite: Hexagon Delegate is not supported.
"
45013,Test linking fails due to missing ldl,"
**System information**
- TensorFlow installed from (source or binary): source
- TensorFlow version: 2.4.0-rc2

**Describe the problem**

Building the tests `//tensorflow/python/...` fails with a link error on `//tensorflow/python/tools:aot_compiled_test` due to stacktrace.h using `dladdr` but nothing in the chain links against `-ldl`.

Chain: aot_compiled_test -> ""//tensorflow/core:test_main"" -> ""//tensorflow/core/platform:test_main"" -> "":stacktrace_handler""

**Any other info / logs**
Looks like the issue can simply be fixed by adding the ldl flag to the ls test_main rule
"
45011,Cannot run GPU on tensorflow Docker Image with Tensorflow 2.3.1,"**System information**
- OS Platform and Distribution: **[Tensorflow Docker Image](https://hub.docker.com/r/tensorflow/tensorflow/)**:
- TensorFlow installed from (source or binary): **`python3 -m pip install tensorflow-gpu`**
- TensorFlow version: **2.3.1**
- Python version: **3.7.5**
- Installed using virtualenv? pip? conda?: **pip (but it comes by default on docker image as far as I know)**
- GCC/Compiler version (if compiling from source): `7.5.0`
- CUDA/cuDNN version: ```nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2019 NVIDIA Corporation
Built on Sun_Jul_28_19:07:16_PDT_2019
Cuda compilation tools, release 10.1, V10.1.243```
- GPU model and memory: **NVIDIA Tesla T4, 16GB. Created using `Compute Engine Deep Learning VM API` on Google Cloud Platform.**



After deploying a GCP Compute Engine Deep Learning VM, I am trying to use docker-compose to train a model using GPU.

Inside docker, I execute:
```
python3 -c ""import tensorflow as tf; tf.test.is_gpu_available()""
```

Which in output (`False`), there is this line: (Full output available at the end)

`Could not load dynamic library 'libcublas.so.10'; dlerror: libcublas.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64`

Something is happening that TensorFlow GPU 2.3.1 cannot lead this `libcublas.so.10` library.

Outside docker, this command returns `True`.

Here's my docker-compose and Dockerfile:


**docker-compose**, `version: 2.3`:
```
    analyses-gpu:
        container_name: analyses-gpu
        runtime: nvidia
        build:
            context: .
            dockerfile: .dockerfiles/DockerfileGPU
        working_dir: /app
        volumes:
            - ./:/app
        environment:
            - NVIDIA_VISIBLE_DEVICES=all
        command: ""bash -c 'cd analyses/; make run'""
```

**Dockerfile**:
```
FROM tensorflow/tensorflow:latest-gpu

WORKDIR /app

RUN apt-get update && apt-get upgrade -y
RUN apt-get install -y git g++ && \
    apt-get install -y build-essential

# Update Python
RUN apt-get install -y python3.7 python3-dev
RUN update-alternatives --install /usr/local/bin/python python /usr/bin/python3.7 1
RUN update-alternatives --install /usr/local/bin/python3 python3 /usr/bin/python3.7 1
```

Full output mentioned:
```
2020-11-19 15:04:46.263566: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
WARNING:tensorflow:From <string>:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.config.list_physical_devices('GPU')` instead.
2020-11-19 15:04:47.399117: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-11-19 15:04:47.409370: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2300000000 Hz
2020-11-19 15:04:47.411095: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56755c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-11-19 15:04:47.411130: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-11-19 15:04:47.414750: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-11-19 15:04:48.394486: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-11-19 15:04:48.395282: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x56e3690 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-11-19 15:04:48.395322: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5
2020-11-19 15:04:48.395600: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-11-19 15:04:48.396263: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: 
pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5
coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s
2020-11-19 15:04:48.396307: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-11-19 15:04:48.396762: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcublas.so.10'; dlerror: libcublas.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64
2020-11-19 15:04:48.398793: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10
2020-11-19 15:04:48.399183: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10
2020-11-19 15:04:48.401310: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10
2020-11-19 15:04:48.402616: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10
2020-11-19 15:04:48.407285: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7
2020-11-19 15:04:48.407319: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1753] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2020-11-19 15:04:48.407350: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-11-19 15:04:48.407369: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 
2020-11-19 15:04:48.407384: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N 
False
```
"
45009,TF Lite issue when loading a saved TF Lite model on platforms with different endianness,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): UB18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): 2.2.1
- Python version: 3.6.9
- Bazel version (if compiling from source): bazel 2.0.0- (@non-git)
- GCC/Compiler version (if compiling from source): gcc version 7.5.0 (Ubuntu 7.5.0-3ubuntu1~18.04)
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A

**Describe the current behavior**
This issue is created for tracking purposes in respect to the discussion done in PR request #44063 
@jdduke Thank you for offering to look into this issue and letting me tag you here.

The problem is that the TfLite saved models only support Little Endian format by default. When loading these model, flatbuffer is not able to handle some non-native data types like Tensor. We need some extra efforts on both the saving side and loading side to manually do the byte-swap on Big-Endian machine. 

**Describe the expected behavior**
We should be able to address the endianness issue while keeping the saved model in Little-Endian format. 

"
45008,Chinese docs on .org site should not link to .cn site,"https://github.com/tensorflow/docs/blob/master/tools/tensorflow_docs/tools/nblint/style/tensorflow_docs_l10n.py sets up a rule that in Chinese docs, replace links from .org to .cn. (the change is from https://github.com/tensorflow/docs/commit/07608d0e273157c104920286ebd596f1b766909f)

I always browse Chinese docs on https://www.tensorflow.org , there are so many traps in the docs that extradites me to the .cn site.

Though I'm a Chinese reader, I may or may not have associations with China. Remember Malaysian, Singapore people use Simplified Chinese, as well as American (or wherever) born Chinese. I hope to use the international site.

I think the establishment of the .cn site is a call from the company strategies, but this should be mainly for readers who are in China. For those who are visiting the international site, they can keep visiting the international site, you don't need to take them back to China.

If Google wants to keep letting people in China visiting the .cn site, can you use relative URL?"
45007,Mistakes in the documentation of UniqueWithCountsV2 API,"## URL(s) with the issue: 

Please provide a link to the documentation entry, for example:
https://www.tensorflow.org/api_docs/python/tf/raw_ops/UniqueWithCountsV2?hl=ca#for_example

## Description of issue (what needs changing): 
1. The Argument, `Axis` is provided directly as a `Scalar` but it should be a `Tensor`. 
`y, idx, count = unique_with_counts(x, axis=0)`
2. The argument, `Axis` is missing in the **`Example`** but it is Mandatory
`y, idx, count = unique_with_counts(x)`
3. Name of the API, `unique_with_counts` is confusing. It can be changed to `UniqueWithCountsV2`
y, idx, count = unique_with_counts(x)

Please find the [Colab Gist](https://colab.research.google.com/gist/rmothukuru/1e10fb3b9006d3ea8735b950f87e5667/44788.ipynb) which demonstrates all the errors.

### Clear description

For example, why should someone use this method? How is it useful?

### Correct links

Is the link to the source code correct? : Link is not mentioned
 
### Parameters defined

Are all parameters defined and formatted correctly? : Yes

### Returns defined

Are return values defined? : Yes

### Raises listed and defined

Are the errors defined? For example,
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises : No

### Usage example

Is there a usage example? : Yes

See the API guide: https://www.tensorflow.org/community/contribute/docs_ref
on how to write testable usage examples.

### Request visuals, if applicable

Are there currently visuals? If not, will it clarify the content?

### Submit a pull request?

Are you planning to also submit a pull request to fix the issue? See the docs
contributor guide: https://www.tensorflow.org/community/contribute/docs,
docs API guide: https://www.tensorflow.org/community/contribute/docs_ref and the
docs style guide: https://www.tensorflow.org/community/contribute/docs_style
"
45006,Building custom op failed,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes, I'm building custom op
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu server 20.04 ( connected by SSH from windows 10 )
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): v2.3.0-54-gfcc4b966f1 2.3.1
- Python version: Python 3.8.5
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): g++ (Ubuntu 9.3.0-17ubuntu1~20.04) 9.3.0
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A

**Describe the current behavior**
When I compile, I have error ( it's tensorflow error ). Command I use: 
`
g++ -std=c++11 -shared ops.cc -o ops.so -fPIC ${TF_CFLAGS[@]} ${TF_LFLAGS[@]} -O2
`
**Describe the expected behavior**
Just compile ops.cc ( ops_kernel.h ) to ops.so and use it in my custom layer
**Other info / logs** 
Error:
![image](https://user-images.githubusercontent.com/27022263/99662085-75239480-2a6d-11eb-915a-71840cfed526.png)
My code:
ops.cc
```cpp
#include ""tensorflow/core/framework/op.h""
#include ""tensorflow/core/framework/shape_inference.h""
#include ""ops_kernel.h""

using namespace tensorflow;

REGISTER_OP(""ConvBuild"")
	.Input(""input: float32"")
	.Input(""shape: int32"")
	.Output(""output: int32"")
	.SetShapeFn([](::tensorflow::shape_inference::InferenceContext* c) {
    	auto input = c->input(0);
    	auto output = c->MakeShape({
    		c->Dim(input, 1), 
    		c->kUnknownDim, 
    		c->kUnknownDim, 
    		c->Dim(input, 4)
    	});
		c->set_output(0, output);
		return Status::OK();
	})

REGISTER_KERNEL_BUILDER(Name(""ConvBuild"").Device(DEVICE_CPU), ConvBuildOp);
```
ops_kernel.h
```cpp
#include ""tensorflow/core/framework/op_kernel.h""

using namespace tensorflow;

class ConvBuildOp : public OpKernel {
 public:
  explicit ConvBuildOp(OpKernelConstruction* context) : OpKernel(context) {}

  void Compute(OpKernelContext* context) override {
    // Grab the inputs
    const Tensor& input_tensor = context->input(0);
    const auto input = input_tensor.flat<float>();
    const Tensor& shape_tensor = context->input(1);
    const auto shape = shape_tensor.flat<int32>();

    // Create an output tensor
    Tensor* output_tensor = NULL;
    OP_REQUIRES_OK(context, context->allocate_output(0, {input_tensor.dim_size(1), input_tensor.dim_size(2)*shape(0), input_tensor.dim_size(3)*shape(1), input_tensor.dim_size(4)},
                                                     &output_tensor));

    auto output = output_tensor -> flat<float>();

    // Compute
    for (int batch = 0; batch < input_tensor.dim_size(1); batch++) {
      for (int yMain = 0; yMain < input_tensor.dim_size(2); yMain++) {
        for (int xMain = 0; xMain < input_tensor.dim_size(3); xMain++) {
          for (int ySub = 0; ySub < shape(0); ySub++) {
            for (int xSub = 0; xSub < shape(1); xSub++) {
              for (int channel = 0; channel < input_tensor.dim_size(4); channel++){
                int offset_in = (ySub*shape(0) + xSub) * input_tensor.dim_size(1) * input_tensor.dim_size(2) * input_tensor.dim_size(3) * input_tensor.dim_size(4) +
                    batch * input_tensor.dim_size(2) * input_tensor.dim_size(3) * input_tensor.dim_size(4) +
                    yMain * input_tensor.dim_size(3) * input_tensor.dim_size(4) +
                    xMain * input_tensor.dim_size(4) +
                    channel;
                int offset_out = batch * (input_tensor.dim_size(2) * shape(0)) * (input_tensor.dim_size(3) * shape(1)) * input_tensor.dim_size(4) +
                       (yMain*shape(0)+ySub) * (input_tensor.dim_size(3) * shape(1)) * input_tensor.dim_size(4) +
                       (xMain*shape(1)+xSub) * input_tensor.dim_size(4) +
                       channel;
                output(offset_out) = input(offset_in);
              }
            }
          }
        }
      }
    }
  }
};
```"
45005,Unable to perform subsampling using tf.data.Dataset map() method.,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): 2.3.0
- Are you willing to contribute it (Yes/No): No



**Describe the feature and the current behavior/state.**
The preprocessing of sequences can easily be a bottleneck in the Deep Learning pipeline. And tf.data.Dataset provides us ways to optimize the input pipeline. But there are limitations to using a custom python function as a preprocessing step. For example, I am trying to train a model to predict the next item(an item can be a movie, song, book etc), given a history of the items consumed. And I want to use a subsampling function to be passed in the map method. The main challenge here is that I can not pass the item2prob dictionary to my custom subsampling function through the map method. And I am not sure if there are any methods available to pull this off.

**Will this change the current api? How?**
The current API will support python dictionaries to be passed into a custom python function through the map method.

**Who will benefit with this feature?**
This feature will open up possibilities for people trying to optimize their input pipeline using custom preprocessing functions.

**Any Other info.**
Here is what I have trying to do-

```
# make a python generator

def get_generator_random():
    '''
    yields 10 sequences of varying lengths (3 to 7) with values ranging from 0, 5
    '''
    num_seq = 10
    seq_count = 0
    while seq_count < num_seq:
        rand_seq_len = np.random.randint(3, 8)
        seq = np.random.randint(0,6,rand_seq_len)
        yield seq
        seq_count += 1

py_gen = get_generator_random()
for i in py_gen:
    print(i)

```

Output:

```
[2 2 2 3 5 4]
[3 2 0]
[0 2 1 3 4]
[2 4 4 2 2 4 2]
[5 1 3 0 4 5 4]
[2 5 4 5]
[0 2 2 2 0]
[0 2 3]
[0 4 0]
[2 2 1 4 0 1 0]
```

```
# make tf dataset from python generator 

def get_tf_gen():
    tf_gen = tf.data.Dataset.from_generator(
        get_generator,
        output_types=tf.int32, 
        output_shapes = (None, )
    )

    return tf_gen


tf_gen = get_tf_gen()
for i in tf_gen:
  print(i)
```

Output:

```
tf.Tensor([2 2], shape=(2,), dtype=int32)
tf.Tensor([5 1 2 3 4], shape=(5,), dtype=int32)
tf.Tensor([5 1 2 3 4 5], shape=(6,), dtype=int32)
tf.Tensor([5 1 2 2 4 5], shape=(6,), dtype=int32)
tf.Tensor([3 1 2 2 4 2], shape=(6,), dtype=int32)
tf.Tensor([1 1 2 3 3 5], shape=(6,), dtype=int32)
tf.Tensor([2 1 5 3 1 5], shape=(6,), dtype=int32)
tf.Tensor([5 2 2 4 4 2], shape=(6,), dtype=int32)
```


```
# define item2prob (prob of removing an item)

item2prob = {}
for i in range(1, 9):
    if i < 5:
        item2prob[i] = 1
    else:
        item2prob[i] = 0.0

print(item2prob)
```

`{1: 1, 2: 1, 3: 1, 4: 1, 5: 0.0, 6: 0.0, 7: 0.0, 8: 0.0}`

```
def subsample(seq):
    seq_new = []
    random_numbers = tf.random.uniform(shape=(len(seq), ), minval=0, maxval=1, dtype=tf.dtypes.float32,).numpy()
    for s_idx, s in enumerate(seq):
        if random_numbers[s_idx] >= item2prob[s]: # this is where the error occurs
            seq_new.append(s)
    return seq_new  

def tf_subsample(seq):  
    seq_new = tf.py_function(subsample, inp=[seq], Tout=tf.int32)
    return seq_new

tf_gen = get_tf_gen()
tf_gen = tf_gen.map(tf_subsample)
tf_gen = tf_gen.padded_batch(4, padded_shapes=5)

print('\nGenerating data...')
for i in tf_gen:
    print(i)
```

Following is the error message-

```
Generating data...
---------------------------------------------------------------------------
InvalidArgumentError                      Traceback (most recent call last)
/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/context.py in execution_mode(mode)
   2101       ctx.executor = executor_new
-> 2102       yield
   2103     finally:

10 frames
/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/iterator_ops.py in _next_internal(self)
    757             output_types=self._flat_output_types,
--> 758             output_shapes=self._flat_output_shapes)
    759 

/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_dataset_ops.py in iterator_get_next(iterator, output_types, output_shapes, name)
   2609     except _core._NotOkStatusException as e:
-> 2610       _ops.raise_from_not_ok_status(e, name)
   2611     except _core._FallbackException:

/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py in raise_from_not_ok_status(e, name)
   6842   # pylint: disable=protected-access
-> 6843   six.raise_from(core._status_to_exception(e.code, message), None)
   6844   # pylint: enable=protected-access

/usr/local/lib/python3.6/dist-packages/six.py in raise_from(value, from_value)

InvalidArgumentError: TypeError: Tensor is unhashable. Instead, use tensor.ref() as the key.
Traceback (most recent call last):

  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/script_ops.py"", line 242, in __call__
    return func(device, token, args)

  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/script_ops.py"", line 131, in __call__
    ret = self._func(*args)

  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py"", line 302, in wrapper
    return func(*args, **kwargs)

  File ""<ipython-input-79-e5206ab2321d>"", line 5, in subsample
    if random_numbers[s_idx] >= item2prob[s]: # this is where the error occurs

  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py"", line 823, in __hash__
    raise TypeError(""Tensor is unhashable. ""

TypeError: Tensor is unhashable. Instead, use tensor.ref() as the key.


	 [[{{node EagerPyFunc}}]] [Op:IteratorGetNext]

During handling of the above exception, another exception occurred:

InvalidArgumentError                      Traceback (most recent call last)
<ipython-input-79-e5206ab2321d> in <module>()
     16 
     17 print('\nGenerating data...')
---> 18 for i in tf_gen:
     19     print(i)

/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/iterator_ops.py in __next__(self)
    734 
    735   def __next__(self):  # For Python 3 compatibility
--> 736     return self.next()
    737 
    738   def _next_internal(self):

/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/iterator_ops.py in next(self)
    770   def next(self):
    771     try:
--> 772       return self._next_internal()
    773     except errors.OutOfRangeError:
    774       raise StopIteration

/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/iterator_ops.py in _next_internal(self)
    762         return self._element_spec._from_compatible_tensor_list(ret)  # pylint: disable=protected-access
    763       except AttributeError:
--> 764         return structure.from_compatible_tensor_list(self._element_spec, ret)
    765 
    766   @property

/usr/lib/python3.6/contextlib.py in __exit__(self, type, value, traceback)
     97                 value = type()
     98             try:
---> 99                 self.gen.throw(type, value, traceback)
    100             except StopIteration as exc:
    101                 # Suppress StopIteration *unless* it's the same exception that

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/context.py in execution_mode(mode)
   2103     finally:
   2104       ctx.executor = executor_old
-> 2105       executor_new.wait()
   2106 
   2107 

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/executor.py in wait(self)
     65   def wait(self):
     66     """"""Waits for ops dispatched in this executor to finish.""""""
---> 67     pywrap_tfe.TFE_ExecutorWaitForAllPendingNodes(self._handle)
     68 
     69   def clear_error(self):

InvalidArgumentError: TypeError: Tensor is unhashable. Instead, use tensor.ref() as the key.
Traceback (most recent call last):

  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/script_ops.py"", line 242, in __call__
    return func(device, token, args)

  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/script_ops.py"", line 131, in __call__
    ret = self._func(*args)

  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py"", line 302, in wrapper
    return func(*args, **kwargs)

  File ""<ipython-input-79-e5206ab2321d>"", line 5, in subsample
    if random_numbers[s_idx] >= item2prob[s]: # this is where the error occurs

  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py"", line 823, in __hash__
    raise TypeError(""Tensor is unhashable. ""

TypeError: Tensor is unhashable. Instead, use tensor.ref() as the key.


	 [[{{node EagerPyFunc}}]]
```"
45003,ResourceExhaustedError,"Can somebody help me with this code
![Screenshot 2020-11-19 045638](https://user-images.githubusercontent.com/74709388/99650677-b3946180-2a23-11eb-8015-b40159cf5064.png)
 "
45002,Leak memory on ios,"I need virtual background on video call and I use image segmentation on frame by frame. 
I use Twilio to create video call and get frame video, opencv to edit Image and Tensorflow-lite to use model deeplabv3

But memory leak on some iPhone . To free up memory, I destroy the model and interpreter  after I add background to frame and  allocate a new Interpreter each time when I see a new frame. it’s bad ideal. How can I release memory??
*sorry about my english, it's bad*
"
45001,Error when trying to build from source on on CUDA 11 & Cudnn 8,"
**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubunutu 20.04
- TensorFlow installed from (source or binary): source
- TensorFlow version: 2.3
- Python version: 3.8
- Installed using virtualenv? pip? conda?: pip
- Bazel version (if compiling from source): 3.1
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 11.1, 8.0.5
- GPU model and memory: RTX 3070 8gb

**Describe the problem**
Cannot build tensorflow 2.3 from source on with CUDA 11.1 and cudnn 8

**Provide the exact sequence of commands / steps that you executed before running into the problem**

followed the instructions from: https://www.tensorflow.org/install/source

./config options are all default except cuda which was enabled 

**Any other info / logs**
bazel build --config=cuda --config=v2 //tensorflow/tools/pip_package:build_pip_package
WARNING: The following configs were expanded more than once: [cuda, using_cuda, v2]. For repeatable flags, repeats are counted twice and may lead to unexpected behavior.
INFO: Options provided by the client:
  Inherited 'common' options: --isatty=1 --terminal_columns=80
INFO: Reading rc options for 'build' from /home/michael/tensorflow/.bazelrc:
  Inherited 'common' options: --experimental_repo_remote_exec
INFO: Reading rc options for 'build' from /home/michael/tensorflow/.bazelrc:
  'build' options: --apple_platform_type=macos --define framework_shared_object=true --define open_source_build=true --java_toolchain=//third_party/toolchains/java:tf_java_toolchain --host_java_toolchain=//third_party/toolchains/java:tf_java_toolchain --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --noincompatible_prohibit_aapt1 --enable_platform_specific_config --config=v2
INFO: Reading rc options for 'build' from /home/michael/tensorflow/.tf_configure.bazelrc:
  'build' options: --action_env PYTHON_BIN_PATH=/usr/bin/python3 --action_env PYTHON_LIB_PATH=/usr/lib/python3/dist-packages --python_path=/usr/bin/python3 --config=xla --action_env CUDA_TOOLKIT_PATH=/usr/local/cuda-11.1 --action_env TF_CUDA_COMPUTE_CAPABILITIES=8.6 --action_env LD_LIBRARY_PATH=/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64: --action_env GCC_HOST_COMPILER_PATH=/usr/bin/x86_64-linux-gnu-gcc-9 --config=cuda --action_env TF_CONFIGURE_IOS=0
INFO: Found applicable config definition build:v2 in file /home/michael/tensorflow/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1
INFO: Found applicable config definition build:xla in file /home/michael/tensorflow/.bazelrc: --action_env=TF_ENABLE_XLA=1 --define=with_xla_support=true
INFO: Found applicable config definition build:cuda in file /home/michael/tensorflow/.bazelrc: --config=using_cuda --define=using_cuda_nvcc=true
INFO: Found applicable config definition build:using_cuda in file /home/michael/tensorflow/.bazelrc: --define=using_cuda=true --action_env TF_NEED_CUDA=1 --crosstool_top=@local_config_cuda//crosstool:toolchain
INFO: Found applicable config definition build:cuda in file /home/michael/tensorflow/.bazelrc: --config=using_cuda --define=using_cuda_nvcc=true
INFO: Found applicable config definition build:using_cuda in file /home/michael/tensorflow/.bazelrc: --define=using_cuda=true --action_env TF_NEED_CUDA=1 --crosstool_top=@local_config_cuda//crosstool:toolchain
INFO: Found applicable config definition build:v2 in file /home/michael/tensorflow/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1
INFO: Found applicable config definition build:linux in file /home/michael/tensorflow/.bazelrc: --copt=-w --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --cxxopt=-std=c++14 --host_cxxopt=-std=c++14 --config=dynamic_kernels
INFO: Found applicable config definition build:dynamic_kernels in file /home/michael/tensorflow/.bazelrc: --define=dynamic_loaded_kernels=true --copt=-DAUTOLOAD_DYNAMIC_KERNELS
INFO: Repository local_config_cuda instantiated at:
  no stack (--record_rule_instantiation_callstack not enabled)
Repository rule cuda_configure defined at:
  /home/michael/tensorflow/third_party/gpus/cuda_configure.bzl:1399:18: in <toplevel>
ERROR: An error occurred during the fetch of repository 'local_config_cuda':
   Traceback (most recent call last):
	File ""/home/michael/tensorflow/third_party/gpus/cuda_configure.bzl"", line 1369
		_create_local_cuda_repository(<1 more arguments>)
	File ""/home/michael/tensorflow/third_party/gpus/cuda_configure.bzl"", line 1051, in _create_local_cuda_repository
		_find_libs(repository_ctx, <2 more arguments>)
	File ""/home/michael/tensorflow/third_party/gpus/cuda_configure.bzl"", line 598, in _find_libs
		_check_cuda_libs(repository_ctx, <2 more arguments>)
	File ""/home/michael/tensorflow/third_party/gpus/cuda_configure.bzl"", line 500, in _check_cuda_libs
		execute(repository_ctx, <1 more arguments>)
	File ""/home/michael/tensorflow/third_party/remote_config/common.bzl"", line 208, in execute
		fail(<1 more arguments>)
Repository command failed
No library found under: /usr/local/cuda-11.1/targets/x86_64-linux/lib/libcudart.so.11.1
INFO: Repository rules_cc instantiated at:
  no stack (--record_rule_instantiation_callstack not enabled)
Repository rule tf_http_archive defined at:
  /home/michael/tensorflow/third_party/repo.bzl:134:19: in <toplevel>
ERROR: Skipping '//tensorflow/tools/pip_package:build_pip_package': no such package '@local_config_cuda//cuda': Traceback (most recent call last):
	File ""/home/michael/tensorflow/third_party/gpus/cuda_configure.bzl"", line 1369
		_create_local_cuda_repository(<1 more arguments>)
	File ""/home/michael/tensorflow/third_party/gpus/cuda_configure.bzl"", line 1051, in _create_local_cuda_repository
		_find_libs(repository_ctx, <2 more arguments>)
	File ""/home/michael/tensorflow/third_party/gpus/cuda_configure.bzl"", line 598, in _find_libs
		_check_cuda_libs(repository_ctx, <2 more arguments>)
	File ""/home/michael/tensorflow/third_party/gpus/cuda_configure.bzl"", line 500, in _check_cuda_libs
		execute(repository_ctx, <1 more arguments>)
	File ""/home/michael/tensorflow/third_party/remote_config/common.bzl"", line 208, in execute
		fail(<1 more arguments>)
Repository command failed
No library found under: /usr/local/cuda-11.1/targets/x86_64-linux/lib/libcudart.so.11.1
WARNING: Target pattern parsing failed.
ERROR: no such package '@local_config_cuda//cuda': Traceback (most recent call last):
	File ""/home/michael/tensorflow/third_party/gpus/cuda_configure.bzl"", line 1369
		_create_local_cuda_repository(<1 more arguments>)
	File ""/home/michael/tensorflow/third_party/gpus/cuda_configure.bzl"", line 1051, in _create_local_cuda_repository
		_find_libs(repository_ctx, <2 more arguments>)
	File ""/home/michael/tensorflow/third_party/gpus/cuda_configure.bzl"", line 598, in _find_libs
		_check_cuda_libs(repository_ctx, <2 more arguments>)
	File ""/home/michael/tensorflow/third_party/gpus/cuda_configure.bzl"", line 500, in _check_cuda_libs
		execute(repository_ctx, <1 more arguments>)
	File ""/home/michael/tensorflow/third_party/remote_config/common.bzl"", line 208, in execute
		fail(<1 more arguments>)
Repository command failed
No library found under: /usr/local/cuda-11.1/targets/x86_64-linux/lib/libcudart.so.11.1
INFO: Elapsed time: 0.456s
INFO: 0 processes.
FAILED: Build did NOT complete successfully (0 packages loaded)
    currently loading: tensorflow/tools/pip_package


"
44999,"I tried installing tensor flow 2 on new MacBook Air (M1), but getting this error ""zsh: illegal hardware instruction  python"" when I import it","<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below):
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**

**Describe the expected behavior**

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
44997,"TensorFlow Lite error on iOS: ""Make sure you apply/link the Flex delegate before inference.""","**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS 10.15, iPhone Simulator 12
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: iPhone Simulator 12
- TensorFlow installed from (source or binary): Installed from Cocoa Pod using the following specification:

  ```
  pod 'TensorFlowLiteSwift', '0.0.1-nightly.20200916', :subspecs => ['CoreML', 'Metal'] 
  pod 'TensorFlowLiteSelectTfOps', '0.0.1-nightly.20200916'
  ```

**Describe the current behavior**

When I load my model using TensorFlow Lite and attempt to invoke it (`interpreter.invoke()`), I get the following error:

```
2020-11-18 16:08:54.145490-0800 OpenRDTCV[13328:3534503] Initialized TensorFlow Lite runtime.
2020-11-18 16:08:56.458094-0800 OpenRDTCV[13328:3534503] Regular TensorFlow ops are not supported by this interpreter. Make sure you apply/link the Flex delegate before inference.
2020-11-18 16:08:56.458232-0800 OpenRDTCV[13328:3534503] Node number 312 (FlexSize) failed to prepare.
```

I have read and followed [Select TensorFlow operators](https://www.tensorflow.org/lite/guide/ops_select) and added the `-force_load` flag (see screenshot below).

![Screen Shot 2020-11-18 at 4 19 39 PM](https://user-images.githubusercontent.com/926408/99604269-eb66bf00-29b9-11eb-9d51-5664451759a6.png)

I have also tried a variety of versions of TensorFlowLiteSwift/TensorFlowLiteSelectTfOps. However, the error persists. Any help appreciated!

Here is the relevant Swift source up until the failing `invoke()` line:

```swift
    guard let pixelBuffer = CVPixelBuffer.buffer(from: image) else {
      print(""Could not convert image to CV buffer"")
      return []
    }
    
    let sourcePixelFormat = CVPixelBufferGetPixelFormatType(pixelBuffer)
    assert(sourcePixelFormat == kCVPixelFormatType_32ARGB ||
             sourcePixelFormat == kCVPixelFormatType_32BGRA ||
               sourcePixelFormat == kCVPixelFormatType_32RGBA)

    let imageChannels = 4
    assert(imageChannels >= 3)

    let scaledSize = CGSize(width: self.inputSize.width, height: self.inputSize.height)
    guard let thumbnailPixelBuffer = pixelBuffer.centerThumbnail(ofSize: scaledSize) else {
      print(""Error: could not crop image"")
      return []
    }

    let interval: TimeInterval
    let outputTensor: Tensor
    do {
      let inputTensor = try interpreter.input(at: 0)

      // Remove the alpha component from the image buffer to get the RGB data.
      guard let rgbData = rgbDataFromBuffer(
        thumbnailPixelBuffer,
        isModelQuantized: isModelQuantized
      ) else {
        print(""Failed to convert the image buffer to RGB data."")
        return []
      }

      // Copy the RGB data to the input `Tensor`.
      try interpreter.copy(rgbData, toInputAt: 0)

      // Run inference by invoking the `Interpreter`.
      let startDate = Date()
      try interpreter.invoke()
```

cc @jdduke who I believe wrote [this commit](https://github.com/tensorflow/tensorflow/commit/05ed82f0f4c00982cd274a2ebc5d0aeb759eebcb) that seems to be relevant."
44996,Dedicated tosa-opt for testing legalization/passes,"I strongly suspect that we are going to want a dedicated tosa-opt of some form eventually, but we don't need to start there if it is not convenient. We will eventually have a dedicated/minimal binary for importing from TFLite Flatbuffers at least, and I'm keeping an eye on how we can keep the build boundaries sufficient to meet that end.

_Originally posted by @stellaraccident in https://github.com/tensorflow/tensorflow/pull/44851#discussion_r523237473_"
44995,TF_RegisterLogListener in C API does not seem to work,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No
- TensorFlow installed from (source or binary): Binary
- TensorFlow version (use command below): 2.3.0
- Python version: N/A
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A

**Describe the current behavior**

When I call TF_RegisterLogListener in the C API, it doesn't seem to work as described. My listener is never called, and TensorFlow log messages still go to the console.  The API description is:

// Register a listener method that processes printed messages.
//
// If any listeners are registered, the print operator will call all listeners
// with the printed messages and immediately return without writing to the
// logs.

**Describe the expected behavior**

My listener should be called and the messages should not be written to the console.

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

extern ""C""
{
  void logListener(const char *message)
  {
    // This is never called and TensorFlow log messages go to the console instead.
    std::cout << ""TensorFlow: "" << message << std::endl;
  }
}

TF_RegisterLogListener(logListener);


**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
44990,tf-gpu 2.3.1 get initial low accuracy compare to tf-gpu 2.1,"I installed tf-gpu 2.3.1 and ran with gpu 1080ti , it get much lower accuracy 0.35 to begin with comparing 0.7 on my previous tf-gpu 2.1,   the loss value are similar to begin with around 1.4
in 2.3.1 reporting 
1670/1670 - 312s - loss: 1.3193 - accuracy: 0.3429
Epoch 2/12
1670/1670 - 295s - loss: 0.9801 - accuracy: 0.4468
Epoch 3/12
1670/1670 - 295s - loss: 0.9100 - accuracy: 0.4869
Epoch 4/12
1670/1670 - 295s - loss: 0.8578 - accuracy: 0.5113

in 2.1 reporting,
418830/418830 - 271s - loss: 1.4756 - accuracy: 0.6926
Epoch 2/12
418830/418830 - 229s - loss: 1.0229 - accuracy: 0.7290
Epoch 3/12
418830/418830 - 230s - loss: 0.9297 - accuracy: 0.7491
Epoch 4/12
418830/418830 - 229s - loss: 0.8621 - accuracy: 0.7627
Epoch 5/12

So anything like that was noticed? and anything is wrong ? or any explanation?

Thank you for any clues!
 


"
44989,"ValueError: Cannot feed value of shape (1, 384, 513, 3) for Tensor","I am new to tensorflow,
I have generated graph using colab.
For using the graph further, 
I am following this code snippet --[https://gist.github.com/averdones/b94e4eb335be356482f1bc1b7f7b15f3](url)

If I run this, I am getting following error:

**WARNING:tensorflow:From C:\Users\SRX9ZY1\.conda\envs\tf\lib\site-packages\tensorflow_core\python\compat\v2_compat.py:88: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.
Instructions for updating:
non-resource variables are not supported in the long term
2020-11-18 19:31:03.098960: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2
Traceback (most recent call last):
  File ""deeplab_demo_webcam_v2.py"", line 171, in <module>
    resized_im, seg_map = model.run(pil_im)
  File ""deeplab_demo_webcam_v2.py"", line 152, in run
    feed_dict={self.INPUT_TENSOR_NAME: [np.asarray(resized_image)]})
  File ""C:\Users\xxx\.conda\envs\tf\lib\site-packages\tensorflow_core\python\client\session.py"", line 960, in run
    run_metadata_ptr)
  File ""C:\Users\xxx\.conda\envs\tf\lib\site-packages\tensorflow_core\python\client\session.py"", line 1159, in _run
    (np_val.shape, subfeed_t.name, str(subfeed_t.get_shape())))
ValueError: Cannot feed value of shape (1, 384, 513, 3) for Tensor 'train_step/Equal:0', which has shape '()'**

can't find fix to this!!!

Hope someone will help!!!"
44988,keras model fit with ragged tensors fails in LossesContainer.__call__,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):

https://colab.research.google.com/drive/1KL1d47PVpXNFNfpOl-COeqP8g_t5ESHS?usp=sharing

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
colab and OSX

- TensorFlow version (use command below):
2.3.1

- Python version:
3.7

- Bazel version (if compiling from source):
N/A

- GCC/Compiler version (if compiling from source):
N/A

- CUDA/cuDNN version:
N/A

- GPU model and memory:
N/A

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

```
python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""
v2.3.0-54-gfcc4b966f1 2.3.1
```

**Describe the current behavior**

When a ragged tensor is used as the output of a model, model fit generates an exception while evaluating the loss function.

LossesContainer.__call__ generates a backtrace when attempting to determine the batch_size since tf.shape() cannot be called on a ragged tensor.

**Describe the expected behavior**
model.fit() should support ragged tensors as outputs.

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

https://colab.research.google.com/drive/1KL1d47PVpXNFNfpOl-COeqP8g_t5ESHS?usp=sharing

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

I've modified my local copy of compile_utils.py:212 so that the batch_dim is obtained as:
```
     if batch_dim is None:
        if isinstance(y_t, ragged_tensor.RaggedTensor):
          batch_dim = y_t.bounding_shape()[0]
        else:
          batch_dim = array_ops.shape(y_t)[0]
```

With this change, my code example executes and the model trains.

- traceback:
```
TypeError: in user code:

    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:806 train_function  *
        return step_function(self, iterator)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:796 step_function  **
        outputs = model.distribute_strategy.run(run_step, args=(data,))
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:1211 run
        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2585 call_for_each_replica
        return self._call_for_each_replica(fn, args, kwargs)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2945 _call_for_each_replica
        return fn(*args, **kwargs)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:789 run_step  **
        outputs = model.train_step(data)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:749 train_step
        y, y_pred, sample_weight, regularization_losses=self.losses)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/compile_utils.py:212 __call__
        batch_dim = array_ops.shape(y_t)[0]
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py:201 wrapper
        return target(*args, **kwargs)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py:628 shape
        return shape_internal(input, name, optimize=True, out_type=out_type)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/array_ops.py:652 shape_internal
        input = ops.convert_to_tensor(input)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:1499 convert_to_tensor
        ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py:338 _constant_tensor_conversion_function
        return constant(v, dtype=dtype, name=name)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py:264 constant
        allow_broadcast=True)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py:282 _constant_impl
        allow_broadcast=allow_broadcast))
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/tensor_util.py:552 make_tensor_proto
        ""supported type."" % (type(values), values))

    TypeError: Failed to convert object of type <class 'tensorflow.python.ops.ragged.ragged_tensor.RaggedTensor'> to Tensor. Contents: tf.RaggedTensor(values=tf.RaggedTensor(values=Tensor(""Cast_1:0"", shape=(None, 1), dtype=float32), row_splits=Tensor(""RaggedFromVariant_1/RaggedTensorFromVariant:1"", shape=(None,), dtype=int64)), row_splits=Tensor(""RaggedFromVariant_1/RaggedTensorFromVariant:0"", shape=(None,), dtype=int64)). Consider casting elements to a supported type.

```"
44987,"Necessity of ""strategy.run"" and ""distribute_datasets_from_function"" for ParameterServers","Thank you for submitting a TensorFlow documentation issue. Per our GitHub
policy, we only address code/doc bugs, performance issues, feature requests, and
build/installation issues on GitHub.

The TensorFlow docs are open source! To get involved, read the documentation
contributor guide: https://www.tensorflow.org/community/contribute/docs

## URL(s) with the issue:
https://www.tensorflow.org/api_docs/python/tf/distribute/experimental/coordinator/ClusterCoordinator

## Description of issue (what needs changing):

### Clear description
1)
In the example code for `create_per_worker_dataset`, we use the following code snippet:
```
def per_worker_dataset_fn():
  return strategy.distribute_datasets_from_function(
      lambda x: tf.data.Dataset.from_tensor_slices([3] * 3))

per_worker_dataset = coordinator.create_per_worker_dataset(
    per_worker_dataset_fn)
```
Notice the usage of `strategy.distribute_datasets_from_function`.  In the example for `fetch`, we do it as follows
```
def dataset_fn():
  return tf.data.Dataset.from_tensor_slices([1, 1, 1])

distributed_dataset = coordinator.create_per_worker_dataset(dataset_fn)
```

So in the first example, we use our strategy, while in the second example, we directly plug the dataset into the coordinator. Both works for me when trying it out, but it's not documented what the difference is (or I could not find it). 

2)
Again, consider the example for `fetch`:
```
strategy = ...
coordinator = tf.distribute.experimental.coordinator.ClusterCoordinator(
    strategy)

def dataset_fn():
  return tf.data.Dataset.from_tensor_slices([1, 1, 1])

with strategy.scope():
  v = tf.Variable(initial_value=0)

@tf.function
def worker_fn(iterator):
  def replica_fn(x):
    v.assign_add(x)
    return v.read_value()
  return strategy.run(replica_fn, args=(next(iterator),))

distributed_dataset = coordinator.create_per_worker_dataset(dataset_fn)
distributed_iterator = iter(distributed_dataset)
result = coordinator.schedule(worker_fn, args=(distributed_iterator,))
assert coordinator.fetch(result) == 1
```

It's not clearly documented why we need the `strategy.run` indirection of `replica_fn`. For example, in the example code for `create_per_worker_dataset`, we do not use this indirection and instead just return the element. I've also tried the upper example without `strategy.run` and the addition worked fine. So I'm not sure why we need this. Would be great to add this to the documentation.

### Correct links

Is the link to the source code correct? Yes

### Parameters defined

Are all parameters defined and formatted correctly? Yes

### Returns defined

Are return values defined? Yes

### Raises listed and defined

Are the errors defined? For example,
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises

### Usage example

Is there a usage example?

See the API guide: https://www.tensorflow.org/community/contribute/docs_ref
on how to write testable usage examples.

### Request visuals, if applicable

Are there currently visuals? If not, will it clarify the content?

### Submit a pull request?

Are you planning to also submit a pull request to fix the issue? No"
44986,Resource exhausted error when running tf.keras.Model.predict on large tensor,"I'm trying to run `tf.keras.Model.predict` on a complex tensor with shape: (1532, 128, 2049, 2). With a batch size of 4, the model throws a ResourceExhaustedError after the predictions on all the separate batches have been completed, when it is concating the predictions together.

However, if I perform the batching manually, feeding one batch at a time through the model, there is no error. It seems the problem is that the concating at the end of the prediction loop is occurring on the GPU and not on the CPU.

Here's the error.

```
~//lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py in _method_wrapper(self, *args, **kwargs)
    128       raise ValueError('{} is not supported in multi-worker mode.'.format(
    129           method.__name__))
--> 130     return method(self, *args, **kwargs)
    131 
    132   return tf_decorator.make_decorator(

~//lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py in predict(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)
   1612             callbacks.on_predict_batch_end(end_step, {'outputs': batch_outputs})
   1613       callbacks.on_predict_end()
-> 1614     all_outputs = nest.map_structure_up_to(batch_outputs, concat, outputs)
   1615     return tf_utils.to_numpy_or_python_type(all_outputs)
   1616 

~//lib/python3.7/site-packages/tensorflow/python/util/nest.py in map_structure_up_to(shallow_tree, func, *inputs, **kwargs)
   1137       lambda _, *values: func(*values),  # Discards the path arg.
   1138       *inputs,
-> 1139       **kwargs)
   1140 
   1141 

~//lib/python3.7/site-packages/tensorflow/python/util/nest.py in map_structure_with_tuple_paths_up_to(shallow_tree, func, *inputs, **kwargs)
   1233                     in _yield_flat_up_to(shallow_tree, inputs[0], is_seq)]
   1234   results = [func(*args, **kwargs) for args in zip(flat_path_list,
-> 1235                                                    *flat_value_lists)]
   1236   return pack_sequence_as(structure=shallow_tree, flat_sequence=results,
   1237                           expand_composites=expand_composites)

~/lib/python3.7/site-packages/tensorflow/python/util/nest.py in <listcomp>(.0)
   1232   flat_path_list = [path for path, _
   1233                     in _yield_flat_up_to(shallow_tree, inputs[0], is_seq)]
-> 1234   results = [func(*args, **kwargs) for args in zip(flat_path_list,
   1235                                                    *flat_value_lists)]
   1236   return pack_sequence_as(structure=shallow_tree, flat_sequence=results,

~/lib/python3.7/site-packages/tensorflow/python/util/nest.py in <lambda>(_, *values)
   1135   return map_structure_with_tuple_paths_up_to(
   1136       shallow_tree,
-> 1137       lambda _, *values: func(*values),  # Discards the path arg.
   1138       *inputs,
   1139       **kwargs)

~/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py in concat(tensors, axis)
   2671   if isinstance(tensors[0], ragged_tensor.RaggedTensor):
   2672     return ragged_concat_ops.concat(tensors, axis=axis)
-> 2673   return array_ops.concat(tensors, axis=axis)
   2674 
   2675 

~/lib/python3.7/site-packages/tensorflow/python/util/dispatch.py in wrapper(*args, **kwargs)
    199     """"""Call target, and fall back on dispatchers if there is a TypeError.""""""
    200     try:
--> 201       return target(*args, **kwargs)
    202     except (TypeError, ValueError):
    203       # Note: convert_to_eager_tensor currently raises a ValueError, not a

~/lib/python3.7/site-packages/tensorflow/python/ops/array_ops.py in concat(values, axis, name)
   1652           dtype=dtypes.int32).get_shape().assert_has_rank(0)
   1653       return identity(values[0], name=name)
-> 1654   return gen_array_ops.concat_v2(values=values, axis=axis, name=name)
   1655 
   1656 

~/lib/python3.7/site-packages/tensorflow/python/ops/gen_array_ops.py in concat_v2(values, axis, name)
   1205       return _result
   1206     except _core._NotOkStatusException as e:
-> 1207       _ops.raise_from_not_ok_status(e, name)
   1208     except _core._FallbackException:
   1209       pass

~/lib/python3.7/site-packages/tensorflow/python/framework/ops.py in raise_from_not_ok_status(e, name)
   6841   message = e.message + ("" name: "" + name if name is not None else """")
   6842   # pylint: disable=protected-access
-> 6843   six.raise_from(core._status_to_exception(e.code, message), None)
   6844   # pylint: enable=protected-access
   6845 

~/lib/python3.7/site-packages/six.py in raise_from(value, from_value)

ResourceExhaustedError: OOM when allocating tensor with shape[1532,128,2049,2] and type complex64 on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:ConcatV2] name: concat
```
"
44984,Incorrect error handling for invalid input names on SavedModel export,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Any
- TensorFlow installed from (source or binary): Binary
- TensorFlow version (use command below): 2.3.1
- Python version: 3.7.6

**Describe the current behavior**

```
import tensorflow as tf

A_FEATURE_NAME = 'a feature'
B_FEATURE_NAME = 'b_feature'

class MyModel(tf.keras.Model):

    def call(self, inputs):
        return inputs[A_FEATURE_NAME] + inputs[B_FEATURE_NAME]

inputs = {
    A_FEATURE_NAME: tf.constant([1.]),
    B_FEATURE_NAME: tf.constant([2.]),
}

model = MyModel()
outputs = model(inputs)

model.save('test')
```

Saving this model gives the following error message

```
ValueError: Got non-flat/non-unique argument names for SavedModel signature 'serving_default': more than one argument to '__inference_signature_wrapper_48' was named 'a feature'. Signatures have one Tensor per named input, so to have predictable names Python functions used to generate these signatures should avoid *args and Tensors in nested structures unless unique names are specified for each. Use tf.TensorSpec(..., name=...) to provide a name for a Tensor input.
```

The reason however is that `A_FEATURE_NAME` has an invalid name due to it containing whitespace, so it ends up not matching the placeholder name when tracing the graph for saving: https://github.com/tensorflow/tensorflow/blob/5d8b439eb41fb2373c5b5c5f33c51313cfd9e57f/tensorflow/python/saved_model/save.py#L494

**Describe the expected behavior**
TensorFlow checks for valid names elsewhere (such as when [declaring an op](https://github.com/tensorflow/tensorflow/blob/00d1dc082eb0fde33e5d8944e4f203248be335f7/tensorflow/python/framework/ops.py#L1804)), so the same logic should be used to return a more relevant error e.g., `ValueError: 'a feature' is not a valid input name` "
44983,tf.image.per_image_standardization unexpected behavior with unsigned integer input,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04.4
- TensorFlow installed from (source or binary): pip
- TensorFlow version (use command below): v2.2.0-57-g25fba035f3 2.2.1
- Python version: 3.7.7
- CUDA/cuDNN version: 10.1.243
- GPU model and memory: Nvidia Tesla V100-DGXS-32GB, 

**Describe the current behavior**
`tf.image.per_image_standardization` has no special handling for unsigned integers but still converts back to unsigned before returning. Thus uint inputs get saturated at zero (fully half of the data!) and at their maximum value. Currently no explanation of uint behavior is given in the docstring, and no warning or other indication that behavior might be unexpected is shown.

**Describe the expected behavior**
In previous versions of TensorFlow (I believe changed after 1.14), `per_image_standardization` just returned a float rather than converting back to the original datatype, so it didn't have this problem. I would expect something safe like that, leaving it up to the developer to decide how they want this conversion handled, or at least a warning printed in the event a uint input is given. Some documentation specifying that uints are not handled differently and will be saturated might be nice too.

**Standalone code to reproduce the issue**
[Colab notebook link][0].

**Other info / logs** 
No tracebacks or logs because it doesn't throw an error. I would call this a failure mode, but it fails silently. I suspect it's an edge case that isn't tested.

[0]: https://colab.research.google.com/drive/1PqjTWtgLPE7hb5Dza2fZdFNbhlyW3mKl?usp=sharing"
44982,TF Lite LSH Projection returns different results on Big Endian and Little Endian Machines,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): N
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 20.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): 2.3.1
- Python version: 3.8.5
- Bazel version (if compiling from source): 3.1.0
- GCC/Compiler version (if compiling from source): gcc (Ubuntu 9.3.0-17ubuntu1~20.04) 9.3.0
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A

**Describe the current behavior**
The LSH Projection defined in `tensorflow/lite/kernels/lsh_projection.cc` has different outputs on Big Endian and Little Endian machines for the same input. The issue is caused by the fact that the input array is flattened into a string in this [line](https://github.com/tensorflow/tensorflow/blob/402d28705e426fea7aad6bbbe405a11daa6b6cd5/tensorflow/lite/kernels/lsh_projection.cc#L130). When the elements in the array are more than 1 byte long, the same array will be represented differently in bytes for LE and BE, and that will cause the string it converts to - `key` here - be different. Thus the `Fingerprint64()` will return differently for LE and BE.

**Describe the expected behavior**
Since `Fingerprint64` function returns the same results for the same input string across all platforms, I am actually not sure whether we are expecting the results of `lsh_projection` to be consistent across all platforms as well. In other words, I wonder when the `lsh_projection` op is called, are we expecting to see a specific output for a specific input, or it will be okay as long as different inputs have different outputs.

If it is the former one, I have a patch ready that could make Big Endian machine flatten the array into the same string as Little Endian ones, and the output will be the same on both platforms with the same input array.

If it is the latter one, then we could keep the way it is then.

**Standalone code to reproduce the issue**
The following test case will fail on Big Endian machine:
```
bazel --host_javabase=""@local_jdk//:jdk"" --cache_test_results=no --test_timeout 300,900,1200,3600 --build_tests_only --test_output=errors -- //tensorflow/lite/kernels:lsh_projection_test
```

**Other info / logs** 
"
44981,Gives error on dumping images to the tensorboard when training with TPU using gradient tape.,"I am using colab_tpu with tensorflow version 2.3.0
Dumping of scalars work good, but on dumping images it gives error. Inputs and Output are in tf.float32. The code is present [here](https://github.com/coreqode/tboard_issue/blob/master/base_module.py)

1.  When, I call ```_train_dump_images```  function inside the ```train_step_zero```, it gives following error ([here](https://github.com/coreqode/tboard_issue/blob/b0af0c08e03e8c2ba6912a07cd0d5028d4f6725f/base_module.py#L108)):

```
Traceback (most recent call last):
  File ""grapy.py"", line 156, in <module>
    main()
  File ""grapy.py"", line 152, in main
    grapy.train()
  File ""/content/TensorFlow-TryOn/base_module.py"", line 237, in train
    losses = self.tpu_train_step_zero(train_iterator)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py"", line 780, in __call__
    result = self._call(*args, **kwds)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py"", line 823, in _call
    self._initialize(args, kwds, add_initializers_to=initializers)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py"", line 697, in _initialize
    *args, **kwds))
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py"", line 2855, in _get_concrete_function_internal_garbage_collected
    graph_function, _, _ = self._maybe_define_function(args, kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py"", line 3213, in _maybe_define_function
    graph_function = self._create_graph_function(args, kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py"", line 3075, in _create_graph_function
    capture_by_value=self._capture_by_value),
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py"", line 986, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py"", line 600, in wrapped_fn
    return weak_wrapped_fn().__wrapped__(*args, **kwds)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py"", line 3735, in bound_method_wrapper
    return wrapped_fn(*args, **kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py"", line 973, in wrapper
    raise e.ag_error_metadata.to_exception(e)
tensorflow.python.framework.errors_impl.InaccessibleTensorError: in user code:

    /content/TensorFlow-TryOn/base_module.py:287 tpu_train_step_zero  *
        losses = self.strategy.run(self.train_step_zero, args=(next(iterator)))
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/tpu_strategy.py:346 run  **
        return self.extended.tpu_run(fn, args, kwargs, options)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/tpu_strategy.py:1095 tpu_run
        return func(args, kwargs)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/tpu_strategy.py:1162 tpu_function
        padding_spec=padding_spec)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/tpu/tpu.py:915 replicate
        padding_spec=padding_spec)[1]
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/tpu/tpu.py:1380 split_compile_and_replicate
        outputs = computation(*computation_inputs)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/tpu_strategy.py:1124 replicated_fn
        result[0] = fn(*replica_args, **replica_kwargs)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py:780 __call__
        result = self._call(*args, **kwds)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py:840 _call
        return self._stateless_fn(*args, **kwds)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py:2829 __call__
        return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py:1848 _filtered_call
        cancellation_manager=cancellation_manager)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py:1938 _call_flat
        flat_outputs = forward_function.call(ctx, args_with_tangents)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py:579 call
        executor_type=executor_type)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/functional_ops.py:1207 partitioned_call
        op = graph.create_op(op_name, args, tout, name=op_name, attrs=op_attrs)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py:507 new_func
        return func(*args, **kwargs)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py:3416 create_op
        attrs, op_def, compute_device)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py:589 _create_op_internal
        inp = self.capture(inp)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py:639 capture
        % (tensor, tensor.graph, self))

    InaccessibleTensorError: The tensor 'Tensor(""model_inputs:0"", shape=(16, 512, 256, 3), dtype=float32)' cannot be accessed here: it is defined in another function or code block. Use return values, explicit Python locals or TensorFlow collections to access it. Defined in: FuncGraph(name=train_step_zero, id=140465465202672); accessed from: FuncGraph(name=tpu_train_step_zero, id=140465463508440).
```
2.  When, I call ```_train_dump_images```  function outside the ```train_step_zero``` from the training loop (similar to [this](https://github.com/coreqode/tboard_issue/blob/b0af0c08e03e8c2ba6912a07cd0d5028d4f6725f/base_module.py#L47)), it gives following error:
```
Traceback (most recent call last):
  File ""grapy.py"", line 156, in <module>
    main()
  File ""grapy.py"", line 152, in main
    grapy.train()
  File ""/content/TensorFlow-TryOn/base_module.py"", line 253, in train
    self._train_dump_images(tf.constant(self.step, dtype=tf.int64))
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py"", line 780, in __call__
    result = self._call(*args, **kwds)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py"", line 846, in _call
    return self._concrete_stateful_fn._filtered_call(canon_args, canon_kwds)  # pylint: disable=protected-access
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py"", line 1848, in _filtered_call
    cancellation_manager=cancellation_manager)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py"", line 1924, in _call_flat
    ctx, args, cancellation_manager=cancellation_manager))
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py"", line 550, in call
    ctx=ctx)
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py"", line 75, in quick_execute
    raise e
  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py"", line 60, in quick_execute
    inputs, attrs, num_outputs)
TypeError: An op outside of the function building code is being passed
a ""Graph"" tensor. It is possible to have Graph tensors
leak out of the function building context by including a
tf.init_scope in your function building code.
For example, the following function will fail:
  @tf.function
  def has_init_scope():
    my_constant = tf.constant(1.)
    with tf.init_scope():
      added = my_constant * 2
The graph tensor has name: model_inputs:0
```"
44980,Changing self properties does not trigger retracing,"
**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Colab and Mac
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.5.0-dev20201118
- Python version: 3.6.9 (default, Oct  8 2020, 12:12:24) 

**Describe the current behavior**

Eager and graph mode give different results. This gives rise to bugs very difficult to detect: one just sees a different MSE when switching to graph mode!

**Describe the expected behavior**

Both eager and graph mode should give the same results or raise an error. If `tf.function` uses a variable through `self`, it should also be retraced using the same policy as with input arguments. Else, using properties of `self` should be disallowed in `tf.function`s.

**Standalone code to reproduce the issue**

Colab: [here](https://colab.research.google.com/drive/1SCcqXjBx8bivziz5592eW60UKTN9cWWX?usp=sharing).

````python

import tensorflow as tf

class Network:
    def call(self, x):
        self.weights = tf.zeros((4,5), dtype=tf.double)
        self.encoder_graph(x)
        self.weights = tf.zeros((2,3), dtype=tf.double)

        return (self.encoder_graph(x).shape == self.encoder_eager(x).shape)

    @tf.function
    def encoder_graph(self, x):
        return self.weights 
        
    def encoder_eager(self, x):
        return self.weights

N = Network()

tf.config.run_functions_eagerly(False)
print(""Graph mode: "", N.call(tf.zeros((1,1))))
tf.config.run_functions_eagerly(True)
print(""Eager mode: "", N.call(tf.zeros((1,1))))

````

**Other info / logs** 

Output:

````
Graph mode:  False
Eager mode:  True
````"
44979,tf.keras.Model.fit() fails with RaggedTensor if using validation_split,"
**System information**
- I am using Arch Linux at 5.9.1-arch1-1
- Tensorflow as installed using pip in a conda virtual environment
- I am using tensorflow on CPU only
- I have tested the code provided here in a jupyter-lab notebook

Tensorflow version: 2.2.0

**Describe the current behavior**
Trying to fit a keras model using a RaggedTensor as input fails if validation_split > 0.0 is used.

**Describe the expected behavior**
Training would work the same way it does setting validation_split to 0.0.

**Standalone code to reproduce the issue**
```python
from tensorflow.compat.v1.keras.layers import Dense, Dropout, concatenate
from tensorflow.keras.layers import LSTM, Input, concatenate
from tensorflow.keras.initializers import glorot_uniform, Constant
from tensorflow.keras.models import Model
from tensorflow.keras import activations
import tensorflow as tf

DS_SIZE=4
SEQ_LENGTH=5
MAX_SEQ_LENGTH=5


def prepare_data(subjects, seq_lengths, max_seq_length):
    # Define the sub sequence lenghts
    seq_lengths = np.random.randint(max_seq_length, size=(subjects))
    
    # Get the values
    seq_values = np.random.randint(100, size=(sum(seq_lengths)), dtype=np.int32)

    # Create a nested ragged tensor, of shape [subjects, (seq_length), (0...max_seq_length)]
    X = tf.expand_dims(tf.RaggedTensor.from_row_lengths(values=seq_values, row_lengths=seq_lengths), 2)
    
    Y = tf.math.reduce_sum(X, axis=(2, 1))

    return (X, Y)
    
X, Y = prepare_data(DS_SIZE, SEQ_LENGTH, MAX_SEQ_LENGTH)

print(f'Tensorflow version: {(tf.version.GIT_VERSION, tf.version.VERSION)}')
print(f'Input data:\nX.shape = {X.shape}\nX={X}')

from tensorflow.keras.layers import Lambda

inputs = Input(shape=(None,1), name=""Input"", ragged=True)
lstm = LSTM(5, return_sequences=False, name='LSTM')(inputs)
predictor = Dense(1, activation=activations.linear, name='Predictor')(lstm)

model = Model(inputs=inputs, outputs=predictor)
model.summary()

model.compile(
    loss='mse',
    optimizer=tf.keras.optimizers.Adam(learning_rate=0.2),
    metrics=[tf.keras.metrics.MeanSquaredError()],
    run_eagerly=True  # Enable eager mode!
)

history = model.fit(
    X,
    Y,
    validation_split = 0.1,
    epochs = 1,
    batch_size = 2,
)
```

**Other info / logs**
```
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
<ipython-input-37-31ef63a3e7dd> in <module>
     50     validation_split = 0.1,
     51     epochs = 1,
---> 52     batch_size = 2,
     53 )

~/miniconda3/envs/MAI/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py in _method_wrapper(self, *args, **kwargs)
     64   def _method_wrapper(self, *args, **kwargs):
     65     if not self._in_multi_worker_mode():  # pylint: disable=protected-access
---> 66       return method(self, *args, **kwargs)
     67 
     68     # Running inside `run_distribute_coordinator` already.

~/miniconda3/envs/MAI/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)
    795           data_adapter.train_validation_split((x, y, sample_weight),
    796                                               validation_split=validation_split,
--> 797                                               shuffle=False))
    798 
    799     with self.distribute_strategy.scope(), \

~/miniconda3/envs/MAI/lib/python3.7/site-packages/tensorflow/python/keras/engine/data_adapter.py in train_validation_split(arrays, validation_split, shuffle)
   1309     raise ValueError(
   1310         ""`validation_split` is only supported for Tensors or NumPy ""
-> 1311         ""arrays, found: {}"".format(arrays))
   1312 
   1313   if all(t is None for t in flat_arrays):

ValueError: `validation_split` is only supported for Tensors or NumPy arrays, found: (<tf.RaggedTensor [[[55], [39], [36], [38]], [[45], [15], [84], [38]], [[51], [20], [44], [28]], [[38], [98]]]>, <tf.Tensor: shape=(4,), dtype=int32, numpy=array([168, 182, 143, 136], dtype=int32)>, None)
```
"
44978,error when compute gradients,"This is a pytorch version code, I want to implement it in tensorflow.
```
gradients = []
for i, loss in enumerate(self.losses):
    # forward pass
    model_output = self.model(x)
    # calculate loss
    if self.anneal:
        L = loss.compute_loss(y, model_output, anneal=beta)
    else:
        L = loss.compute_loss(y, model_output)
    # zero gradient
    self.optimizer.zero_grad()
    # backward pass
    L.backward()
    # get gradient for correctness objective
    gradients.append(self._get_gradient_np())

# calculate the losses
losses_computed = []
# forward pass
model_output = self.model(x)

for i, loss in enumerate(self.losses):
    if self.anneal:
        L = loss.compute_loss(y, model_output, anneal=beta)
    else:
        L = loss.compute_loss(y, model_output)
    losses_computed.append(L)

# get the final loss to compute the common descent vector
final_loss, alphas = self.common_descent_vector.get_descent_vector(
    losses_computed, gradients)
# zero gradient
self.optimizer.zero_grad()
# backward pass
final_loss.backward()
# update parameters
self.optimizer.step()

```
Here is my tensorflow 1.14.0 version.

```
optimizer = tf.train.AdamOptimizer(lr)

gradients_a = optimizer.compute_gradients(loss_a, var_a)
gradients_b = optimizer.compute_gradients(loss_b, var_b)

grad_a = [tf.reshape(g, (1, -1)) for g, v in gradients_a]
grad_b = [tf.reshape(g, (1, -1)) for g, v in gradients_b]

grad_a = tf.concat(grad_a, axis=-1, name=""concat_grad_a"")
grad_b = tf.concat(grad_b, axis=-1, name=""concat_grad_b"")

loss_weight = tf.py_function(solve, inp=[grad_a, grad_b], Tout=[tf.float32, tf.float32])

final_loss = loss_weight[0] * loss_a + loss_weight[1] * loss_b

optimizer.minimize(loss)
```

This code could run at first setp, but throw exception at second step.
**tensorflow.python.freamework.errors_impl.InvalidArgumentError: Expected begin and size arguments to be 1-D tensors of size 0, but got shape [2] and [2] instead.  [[{{ node gradients_2/concat_grad_b_grad/Slice}}]]**

I guess the gradient_a and gradient_b as nodes of the graph, so when compute the gradients of final_loss, it may raise error.
Is there any solution to solve this problem? THX
"
44977,What is the difference between two data generation methods？,"<em>Please make sure that this is an issue related to performance of TensorFlow.
As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:performance_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 1.14
- Python version: python3.6
- Bazel version (if compiling from source): No
- GCC/Compiler version (if compiling from source): No
- CUDA/cuDNN version: CUDA 10.2
- GPU model and memory: V100 32 GB

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
I use two different methods to generate data in `input_fn` with `tf.estimator` API
~~~
def input_fn(batch_size, num_epochs):
    # Method1: generate one batch data and repeat
    #train_data = tf.truncated_normal((batch_size, 300, 150), 0.5, 0.1)
    #train_label = tf.random_uniform((batch_size,1),minval=0,maxval=1,dtype=tf.float32)
    #ds = tf.data.Dataset.from_tensors((train_data, train_label)).repeat(num_epochs)
    #Method2: generate data repeat then batch
    train_data = tf.truncated_normal([300, 150], 0.5, 0.1)
    train_label = tf.random_uniform([1],minval=0,maxval=1,dtype=tf.float32)
    ds = tf.data.Dataset.from_tensors((train_data, train_label)).repeat().batch(batch_size)
    ds = ds.prefetch(buffer_size=tf.contrib.data.AUTOTUNE)

    return ds
~~~
And I got two different performances. When I use Method1, the GPU utilization is not very stable, however, when I use Method2, the GPU utilization is very stable. Besides, when I use `tf.data.Dataset.from_tensors` API, the data generation time will be very long, however, if I use `tf.data.Dataset.from_tensor_slices` API, the generation time is very short.
**Describe the expected behavior**
I expect the performances should be same or similar when I use Methods 1 and 2. And it is also should be the same when I use different APIs `tf.data.Dataset.from_tensors` and `tf.data.Dataset.from_tensor_slices`.
**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
44976,```tf.distribute.MirroredStrategy``` is stuck.,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu20.04
- TensorFlow installed from (source or binary): pip install tensorflow
- TensorFlow version (use command below): 2.3.1
- Python version: 3.8.3
- CUDA/cuDNN version: 10.1
- GPU model and memory: gtx1070 * 2

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
```
== check python ===================================================
python version: 3.8.3
python branch:
python build version: ('default', 'Jul  2 2020 16:21:59')
python compiler version: GCC 7.3.0
python implementation: CPython


== check os platform ===============================================

== are we in docker =============================================
No

== compiler =====================================================
c++ (Ubuntu 7.5.0-6ubuntu2) 7.5.0
Copyright (C) 2017 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.


== check pips ===================================================
numpy                              1.18.5
numpydoc                           1.1.0
protobuf                           3.13.0
tensorflow                         2.3.1
tensorflow-estimator               2.3.0
tensorflow-serving-api             2.3.0

== check for virtualenv =========================================
False

== tensorflow import ============================================
tf.version.VERSION = 2.3.1
tf.version.GIT_VERSION = v2.3.0-54-gfcc4b966f1
tf.version.COMPILER_VERSION = 7.3.1 20180303
    194729:     find library=libpthread.so.0 [0]; searching
    194729:      search path=/home/zhaodachuan/anaconda3/bin/../lib/tls/x86_64/x86_64:/home/zhaodachuan/anaconda3/bin/../lib/tls/x86_64:/home/zhaodachuan/anaconda3/bin/../lib/tls/x86_64:/home/zhaodachuan/anaconda3/bin/../lib/tls:/home/zhaodachuan/anaconda3/bin/../lib/x86_64/x86_64:/home/zhaodachuan/anaconda3/bin/../lib/x86_64:/home/zhaodachuan/anaconda3/bin/../lib/x86_64:/home/zhaodachuan/anaconda3/bin/../lib         (RPATH from file /home/zhaodachuan/anaconda3/bin/python)
    194729:       trying file=/home/zhaodachuan/anaconda3/bin/../lib/tls/x86_64/x86_64/libpthread.so.0
    194729:       trying file=/home/zhaodachuan/anaconda3/bin/../lib/tls/x86_64/libpthread.so.0
    194729:       trying file=/home/zhaodachuan/anaconda3/bin/../lib/tls/x86_64/libpthread.so.0
    194729:       trying file=/home/zhaodachuan/anaconda3/bin/../lib/tls/libpthread.so.0
== env ==========================================================
LD_LIBRARY_PATH /usr/local/cuda/lib64
DYLD_LIBRARY_PATH is unset

== nvidia-smi ===================================================
Wed Nov 18 19:10:46 2020
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 450.80.02    Driver Version: 450.80.02    CUDA Version: 11.0     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  GeForce GTX 1070    Off  | 00000000:23:00.0 Off |                  N/A |
| 42%   53C    P2    55W / 180W |   7709MiB /  8119MiB |    100%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   1  GeForce GTX 1070    Off  | 00000000:2D:00.0  On |                  N/A |
| 47%   65C    P2    60W / 180W |   7716MiB /  8111MiB |    100%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+

+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|    0   N/A  N/A      1041      G   /usr/lib/xorg/Xorg                  4MiB |
|    0   N/A  N/A    171379      G   /usr/lib/xorg/Xorg                  4MiB |
|    0   N/A  N/A    193747      C   ...huan/anaconda3/bin/python     7695MiB |
|    1   N/A  N/A      1041      G   /usr/lib/xorg/Xorg                 35MiB |
|    1   N/A  N/A    171379      G   /usr/lib/xorg/Xorg                 77MiB |
|    1   N/A  N/A    171513      G   /usr/bin/gnome-shell              119MiB |
|    1   N/A  N/A    177947      G   /usr/bin/nvidia-settings            3MiB |
|    1   N/A  N/A    193747      C   ...huan/anaconda3/bin/python     7461MiB |
+-----------------------------------------------------------------------------+

== cuda libs  ===================================================
/usr/local/cuda-10.1/targets/x86_64-linux/lib/libcudart_static.a
/usr/local/cuda-10.1/targets/x86_64-linux/lib/libcudart.so.10.1.243
/usr/local/cuda-10.1/doc/man/man7/libcudart.so.7
/usr/local/cuda-10.1/doc/man/man7/libcudart.7

== tensorflow installed from info ==================
Name: tensorflow
Version: 2.3.1
Summary: TensorFlow is an open source machine learning framework for everyone.
Home-page: https://www.tensorflow.org/
Author-email: packages@tensorflow.org
License: Apache 2.0
Location: /home/zhaodachuan/anaconda3/lib/python3.8/site-packages
Required-by: tensorflow-serving-api

== python version  ==============================================
(major, minor, micro, releaselevel, serial)
(3, 8, 3, 'final', 0)

== bazel version  ===============================================
```
You can also obtain the TensorFlow version with:
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
```
2020-11-18 19:09:31.423127: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
v2.3.0-54-gfcc4b966f1 2.3.1
```

**Describe the current behavior**
When I run the code 
```Python
import tensorflow as tf
gpus = tf.config.experimental.list_physical_devices('GPU')
tf.config.experimental.set_visible_devices(gpus, 'GPU')
print(gpus)
# output : 
# [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]
loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)
model.compile(optimizer='adam',
              loss=loss_fn,
              metrics=['accuracy'])
model.fit(x_train, y_train, epochs=500)
```
, it's stuck in 
```
Epoch 1/500
INFO:tensorflow:batch_all_reduce: 4 all-reduces with algorithm = nccl, num_packs = 1
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:batch_all_reduce: 4 all-reduces with algorithm = nccl, num_packs = 1
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
```
When I change to 
```Python
mirrored_strategy = tf.distribute.MirroredStrategy(cross_device_ops=tf.distribute.ReductionToOneDevice())
```
 , it can work but it runs slower than one gpu and the loss will become nan quickly
```
Epoch 1/500
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1').
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1').
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1').
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1').
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1').
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1').
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1').
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1').
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
  15/1875 [..............................] - ETA: 13:46 - loss: nan - accuracy: 0.1583

```
May the  same issue : 
[https://github.com/tensorflow/tensorflow/issues/37561](https://github.com/tensorflow/tensorflow/issues/37561)
[https://github.com/tensorflow/tensorflow/issues/38982](https://github.com/tensorflow/tensorflow/issues/38982)"
44975,Conversion to TFLite fails with 2.4.0-rc1,"**System information**
- OS - Windows
- TensorFlow installed from binary
- TensorFlow version (or github SHA if from source): v2.4.0-rc1


**Command used to run the converter or code if you’re using the Python API**
Running the following set of commands to do the conversion to tf-lite
```
graph_def = tf.compat.v1.GraphDef()
graph_def.ParseFromString(open('resnet.pb', 'rb').read())
concrete_func = wrap_frozen_graph(graph_def, inputs=[""input:0""], outputs=[""output:0""])
converter = tf.lite.TFLiteConverter.from_concrete_functions([concrete_func])
converter.experimental_new_converter = True
converter.optimizations = [tf.compat.v1.lite.Optimize.DEFAULT]
converter.target_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8, tf.lite.OpsSet.SELECT_TF_OPS]
tflite_model = converter.convert()
```

**The output from the converter invocation**

```
--------------------------------------------------
Frozen model layers: 
--------------------------------------------------

INFO:absl:Using new converter: If you encounter a problem please file a bug. You can opt-out by setting experimental_new_converter=False

---------------------------------------------------------------------------
Exception                                 Traceback (most recent call last)
~\Anaconda3\envs\arcgis_1_8_3_tensorflow_test\lib\site-packages\tensorflow\lite\python\convert.py in toco_convert_protos(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)
    212                                                  debug_info_str,
--> 213                                                  enable_mlir_converter)
    214       return model_str

~\Anaconda3\envs\arcgis_1_8_3_tensorflow_test\lib\site-packages\tensorflow\lite\python\wrap_toco.py in wrapped_toco_convert(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)
     37       debug_info_str,
---> 38       enable_mlir_converter)
     39 

Exception: C:\Users\kar11081\Anaconda3\envs\arcgis_1_8_3_tensorflow_test\lib\site-packages\tensorflow\python\eager\lift_to_graph.py:339:0: error: operand #0 does not dominate this use
C:\Users\kar11081\Anaconda3\envs\arcgis_1_8_3_tensorflow_test\lib\site-packages\tensorflow\python\eager\wrap_function.py:338:0: note: called from
<ipython-input-5-1fc724505eae>:18:0: note: called from
<ipython-input-9-dd55b0fa94e3>:3:0: note: called from
C:\Users\kar11081\Anaconda3\envs\arcgis_1_8_3_tensorflow_test\lib\site-packages\IPython\core\interactiveshell.py:3417:0: note: called from
C:\Users\kar11081\Anaconda3\envs\arcgis_1_8_3_tensorflow_test\lib\site-packages\IPython\core\interactiveshell.py:3337:0: note: called from
C:\Users\kar11081\Anaconda3\envs\arcgis_1_8_3_tensorflow_test\lib\site-packages\IPython\core\interactiveshell.py:3146:0: note: called from
C:\Users\kar11081\Anaconda3\envs\arcgis_1_8_3_tensorflow_test\lib\site-packages\IPython\core\async_helpers.py:68:0: note: called from
C:\Users\kar11081\Anaconda3\envs\arcgis_1_8_3_tensorflow_test\lib\site-packages\IPython\core\interactiveshell.py:2922:0: note: called from
C:\Users\kar11081\Anaconda3\envs\arcgis_1_8_3_tensorflow_test\lib\site-packages\IPython\core\interactiveshell.py:2877:0: note: called from
C:\Users\kar11081\Anaconda3\envs\arcgis_1_8_3_tensorflow_test\lib\site-packages\tensorflow\python\eager\lift_to_graph.py:339:0: note: operand defined here


During handling of the above exception, another exception occurred:

ConverterError                            Traceback (most recent call last)
<ipython-input-9-dd55b0fa94e3> in <module>
      6 converter.optimizations = [tf.compat.v1.lite.Optimize.DEFAULT]
      7 converter.target_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8, tf.lite.OpsSet.SELECT_TF_OPS]
----> 8 tflite_model = converter.convert()

~\Anaconda3\envs\arcgis_1_8_3_tensorflow_test\lib\site-packages\tensorflow\lite\python\lite.py in convert(self)
   1115         Invalid quantization parameters.
   1116     """"""
-> 1117     return super(TFLiteConverterV2, self).convert()
   1118 
   1119 

~\Anaconda3\envs\arcgis_1_8_3_tensorflow_test\lib\site-packages\tensorflow\lite\python\lite.py in convert(self)
    941 
    942     return super(TFLiteFrozenGraphConverterV2,
--> 943                  self).convert(graph_def, input_tensors, output_tensors)
    944 
    945 

~\Anaconda3\envs\arcgis_1_8_3_tensorflow_test\lib\site-packages\tensorflow\lite\python\lite.py in convert(self, graph_def, input_tensors, output_tensors)
    626         input_tensors=input_tensors,
    627         output_tensors=output_tensors,
--> 628         **converter_kwargs)
    629 
    630     calibrate_and_quantize, flags = quant_mode.quantizer_flags()

~\Anaconda3\envs\arcgis_1_8_3_tensorflow_test\lib\site-packages\tensorflow\lite\python\convert.py in toco_convert_impl(input_data, input_tensors, output_tensors, enable_mlir_converter, *args, **kwargs)
    611       input_data.SerializeToString(),
    612       debug_info_str=debug_info_str,
--> 613       enable_mlir_converter=enable_mlir_converter)
    614   return data
    615 

~\Anaconda3\envs\arcgis_1_8_3_tensorflow_test\lib\site-packages\tensorflow\lite\python\convert.py in toco_convert_protos(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)
    214       return model_str
    215     except Exception as e:
--> 216       raise ConverterError(str(e))
    217 
    218   if distutils.spawn.find_executable(_toco_from_proto_bin) is None:

ConverterError: C:\Users\kar11081\Anaconda3\envs\arcgis_1_8_3_tensorflow_test\lib\site-packages\tensorflow\python\eager\lift_to_graph.py:339:0: error: operand #0 does not dominate this use
C:\Users\kar11081\Anaconda3\envs\arcgis_1_8_3_tensorflow_test\lib\site-packages\tensorflow\python\eager\wrap_function.py:338:0: note: called from
<ipython-input-5-1fc724505eae>:18:0: note: called from
<ipython-input-9-dd55b0fa94e3>:3:0: note: called from
C:\Users\kar11081\Anaconda3\envs\arcgis_1_8_3_tensorflow_test\lib\site-packages\IPython\core\interactiveshell.py:3417:0: note: called from
C:\Users\kar11081\Anaconda3\envs\arcgis_1_8_3_tensorflow_test\lib\site-packages\IPython\core\interactiveshell.py:3337:0: note: called from
C:\Users\kar11081\Anaconda3\envs\arcgis_1_8_3_tensorflow_test\lib\site-packages\IPython\core\interactiveshell.py:3146:0: note: called from
C:\Users\kar11081\Anaconda3\envs\arcgis_1_8_3_tensorflow_test\lib\site-packages\IPython\core\async_helpers.py:68:0: note: called from
C:\Users\kar11081\Anaconda3\envs\arcgis_1_8_3_tensorflow_test\lib\site-packages\IPython\core\interactiveshell.py:2922:0: note: called from
C:\Users\kar11081\Anaconda3\envs\arcgis_1_8_3_tensorflow_test\lib\site-packages\IPython\core\interactiveshell.py:2877:0: note: called from
C:\Users\kar11081\Anaconda3\envs\arcgis_1_8_3_tensorflow_test\lib\site-packages\tensorflow\python\eager\lift_to_graph.py:339:0: note: operand defined here
```

**Also, please include a link to the saved model or GraphDef**

```
[Link to the model](https://drive.google.com/file/d/1RSmk7zdqmHHBjkE-KPY3BNrW5q0Txv-P/view?usp=sharing)
```

**Failure details**
The failure is observed only in the v2.4.0-rc1. The conversion works fine when I switch to nightly version tf-nightly==2.4.0.dev20200901

"
44974,Error LNK2005 when linking in debug mode.,"**System information**
- OS Platform and Distribution : windows 10
- TensorFlow installed from: source and binary
- TensorFlow version: 2.3.0
- Python version: 3.7
- Installed using virtualenv: using c API
- Bazel version: 3.7.0
- GCC/Compiler version: msvc 2019
- CUDA/cuDNN version: None
- GPU model and memory: None



**Describe the problem**
I have a c++ shared library that links both tensorflow and protobuf.
* In release everything works and as expected.
* In debug mode I got a linking issue:
```
libprotobufd.lib(common.obj) : error LNK2005: ""public: __cdecl google::protobuf::internal::LogMessage::LogMessage(enum google::protobuf::LogLevel,char const *,int)"" (??0LogMessage@internal@protobuf@google@@QEAA@W4LogLevel@23@PEBDH@Z) already defined in tensorflow.lib(tensorflow.dll)
```

I got this error when using precompiled binaries from: https://www.tensorflow.org/install/lang_c
I tried to compile tensorflow myself in both release and debug mode but still I get the same linking error.


**Any other info / logs**
```
00:23:39  libprotobufd.lib(common.obj) : error LNK2005: ""public: __cdecl google::protobuf::internal::LogMessage::LogMessage(enum google::protobuf::LogLevel,char const *,int)"" (??0LogMessage@internal@protobuf@google@@QEAA@W4LogLevel@23@PEBDH@Z) already defined in tensorflow.lib(tensorflow.dll)

00:23:39  libprotobufd.lib(common.obj) : error LNK2005: ""public: __cdecl google::protobuf::internal::LogMessage::~LogMessage(void)"" (??1LogMessage@internal@protobuf@google@@QEAA@XZ) already defined in tensorflow.lib(tensorflow.dll)

00:23:39  libprotobufd.lib(common.obj) : error LNK2005: ""public: class google::protobuf::internal::LogMessage & __cdecl google::protobuf::internal::LogMessage::operator<<(char const *)"" (??6LogMessage@internal@protobuf@google@@QEAAAEAV0123@PEBD@Z) already defined in tensorflow.lib(tensorflow.dll)

00:23:39  libprotobufd.lib(common.obj) : error LNK2005: ""public: void __cdecl google::protobuf::internal::LogFinisher::operator=(class google::protobuf::internal::LogMessage &)"" (??4LogFinisher@internal@protobuf@google@@QEAAXAEAVLogMessage@123@@Z) already defined in tensorflow.lib(tensorflow.dll)

00:23:39     Creating library lib\pmi_common_d.lib and object lib\pmi_common_d.exp
00:23:39  bin\pmi_common_d.dll : fatal error LNK1169: one or more multiply defined symbols found
```"
44973,"When training on the TPU, loss  is in PerReplica dictionary format. Any way to convert it in normal numpy/tensor format?","![image](https://user-images.githubusercontent.com/18486587/99510460-1dbdef80-29ad-11eb-9b81-ce211054c542.png)

I am returning the loss, from train_step function like this:

    def train_step(self, data, model_inputs):
        with tf.GradientTape() as tape:
            predictions = self.model(model_inputs['inputs'], training=True)
            losses = self.loss_func(data,  predictions)
            loss = sum(losses.values()) / self.train_batch_size
        
        gradients = tape.gradient(loss, self.model.trainable_variables)
        self.optimizer.apply_gradients(
            list(zip(gradients, self.model.trainable_variables))
        )

        self.update_metrics_meter(data, predictions)
        self.update_loss_meter(losses, self.train_batch_size)
        return losses"
44972,Moving average not supported in eager mode,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below):
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**

**Describe the expected behavior**

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

when I enable ""use_moving_average: true"" I encountered this error,
 File ""/xxxxxxxx/models/research/object_detection/builders/optimizer_builder.py"", line 150, in build_optimizers_tf_v2
    raise ValueError('Moving average not supported in eager mode.')
ValueError: Moving average not supported in eager mode.

"
44971,Flexbuffers patching causing -Wnull-dereference,"@tensorflow/micro

**System information**
- Host OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- TensorFlow installed from (source or binary):
- Tensorflow version (commit SHA if source): 41dc09029c39777b3be83e6cc00853be7c5f0674
- Target platform (e.g. Arm Mbed OS, Arduino Nano 33 etc.):

**Describe the problem**
tensorflow/lite/micro/tools/make/flatbuffers_download.sh is patching Flexbuffers. The original code is replaced with:
// Introduce a segfault for an unsupported code path for TFLM.
return *(static_cast<double*>(nullptr));
This is causing a compile issue for us, i.e. it triggers:
error: indirection of non-volatile null pointer will be deleted, not trap [-Werror,-Wnull-dereference]

Perhaps we could generate a segfault in another way or maybe just log an error and return 0.

**Please provide the exact sequence of commands/steps when you ran into the problem**

"
44970,Why tf.data.Dataset.map() still unknown TensorShape?,"System information

Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
OS Platform and Distribution (e.g., Linux Ubuntu 18.04):
TensorFlow installed from (source or binary): binary
TensorFlow version (use command below): tf-nightly-2.5.0
Python version:
Bazel version (if compiling from source): 3.7.4
GCC/Compiler version (if compiling from source): 7.3.0
CUDA/cuDNN version: CUDA 11.0 / cuDNN 8.0.4
GPU model and memory: RTX3090 24GB
RAM: 32GB
```
def parse(img_path, label, resolution, class_num):
    label = tf.one_hot(label, depth=class_num)
    image = tf.io.read_file(img_path)
    image = tf.image.decode_jpeg(image)
    image = tf.image.resize(image, [resolution, resolution])
    image /= 255.

    return image, label


def make_datasets(image, label, resolution, class_num, batch_size, mode):

    dataset = tf.data.Dataset.from_tensor_slices((image, label))
    if mode == 'train':
        dataset = dataset.shuffle(buffer_size=len(label))
        dataset = dataset.map(lambda x, y: tf.py_function(func=parse,
                                                          inp=[x, y, resolution, class_num],
                                                          Tout=[tf.float32, tf.float32]))
        dataset = dataset.repeat()
        dataset = dataset.batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)

...variables define...

train_dataset = make_datasets(train_images, train_labels, 224, num_classes, batch_size, mode='train')
val_dataset = make_datasets(val_images, val_labels, 224, num_classes, batch_size, mode='val')

train_step = len(train_images) // batch_size
val_step = len(val_images) // batch_size

model = any_model()
model.compile(optimizer=optimizers.Adam(lr),
                         loss=losses.CategoricalCrossentropy(from_logits=True),
                         metrics=['accuracy'])

model.fit(train_dataset,
                steps_per_epoch=train_step,
                epochs=epochs,
                validation_data=val_dataset,
                validation_steps=val_step,
                verbose=1)
```
When I run it.It excetion:
```
ValueError: as_list() is not defined on an unknown TensorShape.
```
I know I can avoid this problem by using **image.set_shape([h, w, 3])**, but I don't want to do it.Beacause I need my code concise and using lambda function.If using **image.set_shape([h, w, 3])** I should write other function.
So I think it is bug."
44969,2.4.0rc1 not supporting RTX 3090? ,"
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Docker image `tensorflow/tensorflow:2.4.0rc1-gpu-jupyter`




**Describe the current behavior**
I checked the cuda version in the container which is cuda 11.1. I also have nvidia driver 455.38 installed on my host machine. I have a custom built of tf 2.3.0 working with this setup. But when I pull the docker image of `tensorflow/tensorflow:2.4.0rc1-gpu-jupyter` it's raising CUDNN errors like below: 

```
2020-11-18 07:54:42.398846: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2020-11-18 07:54:42.417594: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3693205000 Hz
2020-11-18 07:54:43.206492: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2020-11-18 07:54:44.092906: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2020-11-18 07:54:44.097015: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2020-11-18 07:54:44.422337: E tensorflow/stream_executor/cuda/cuda_dnn.cc:336] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR
2020-11-18 07:54:44.429661: E tensorflow/stream_executor/cuda/cuda_dnn.cc:336] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR
---------------------------------------------------------------------------
UnknownError                              Traceback (most recent call last)
<ipython-input-6-976a0a33b022> in <module>
----> 1 m.predict(np.zeros((1, 256, 256, 3), dtype=np.float32))

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py in predict(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)
   1627           for step in data_handler.steps():
   1628             callbacks.on_predict_batch_begin(step)
-> 1629             tmp_batch_outputs = self.predict_function(iterator)
   1630             if data_handler.should_sync:
   1631               context.async_wait()

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py in __call__(self, *args, **kwds)
    826     tracing_count = self.experimental_get_tracing_count()
    827     with trace.Trace(self._name) as tm:
--> 828       result = self._call(*args, **kwds)
    829       compiler = ""xla"" if self._experimental_compile else ""nonXla""
    830       new_tracing_count = self.experimental_get_tracing_count()

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py in _call(self, *args, **kwds)
    893       # If we did not create any variables the trace we have is good enough.
    894       return self._concrete_stateful_fn._call_flat(
--> 895           filtered_flat_args, self._concrete_stateful_fn.captured_inputs)  # pylint: disable=protected-access
    896 
    897     def fn_with_cond(inner_args, inner_kwds, inner_filtered_flat_args):

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py in _call_flat(self, args, captured_inputs, cancellation_manager)
   1917       # No tape is watching; skip to running the function.
   1918       return self._build_call_outputs(self._inference_function.call(
-> 1919           ctx, args, cancellation_manager=cancellation_manager))
   1920     forward_backward = self._select_forward_and_backward_functions(
   1921         args,

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py in call(self, ctx, args, cancellation_manager)
    558               inputs=args,
    559               attrs=attrs,
--> 560               ctx=ctx)
    561         else:
    562           outputs = execute.execute_with_cancellation(

/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)
     58     ctx.ensure_initialized()
     59     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
---> 60                                         inputs, attrs, num_outputs)
     61   except core._NotOkStatusException as e:
     62     if name is not None:

UnknownError:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.
	 [[node efficientnetb0/stem_conv/Conv2D (defined at <ipython-input-6-976a0a33b022>:1) ]] [Op:__inference_predict_function_5650]

Function call stack:
predict_function
```

code to replicate:
```
from tensorflow.python.keras.applications.efficientnet import EfficientNetB0
m = EfficientNetB0(weights=None, input_shape=(256, 256, 3))
import numpy as np
m.predict(np.zeros((1, 256, 256, 3)))
```


**Describe the expected behavior**
Should be able to run on RTX3090 without any issue. 



"
44967,Why is the first inference Extremely Slow?,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
YES, as custom ops in the network.
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No.
- TensorFlow installed from (source or binary): Source, 2.3.1
- TensorFlow version (use command below): 2.3.1
- Python version: 3.5
- Bazel version (if compiling from source): Bazel 3.1
- GCC/Compiler version (if compiling from source): 7
- CUDA/cuDNN version: 10.2
- GPU model and memory: 2080 Ti

**Describe the current behavior**

So I'm using Tensorflow C++ APIs to do inference using `CallableHandle` with `Session`.
I used `RunMetadata` to dump the full trace for the first inference in C++. Part of the timeline showed in Chrome://tracing

I ran this model freezed using TF 1.15, and it ran in TF 2.3 without obvious issues.

![Screenshot from 2020-11-17 22-03-05](https://user-images.githubusercontent.com/2466188/99491865-65973500-2921-11eb-8f8e-533c12b1fa7d.png)

As you could see, every convolution layer here took EXTREMELY long to do, and it's showing they are also running on GPU.
After couple of inferences, the inference time for the model is super short. So this makes me wonder what's happening in the first inference.

**Describe the expected behavior**

I know the first inference is usually slower than following ones, but this is extremely slow compared to how long it usually take.
The first inference here took 200s, while it was expected to run around 0.1s.

As one more reference data point, the same model running with TF 1.15 inference stack, the first inference would take around 10s to finish. TF 2.3 seems to be super slow for the same model.


**Other info / logs**

RunMetadata dumped tracing json (had to change to txt suffix):
Truncated, only showing part of the entire timeline.
[github_2.3_profile.txt](https://github.com/tensorflow/tensorflow/files/5558191/github_2.3_profile.txt)
"
44966,"tensorflow.python.framework.errors_impl.UnknownError:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above","<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
    centos7.4
- TensorFlow installed from (source or binary):binary
- TensorFlow version (use command below):2.2.0
- Python version:3.6.12
- CUDA/cuDNN version:10.1/7.6.5

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**

**Describe the expected behavior**

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
44965,How to run TFLite on specific CPUs?,"@tensorflow/micro

Dear Authors:
     I'm running TFLite on RK3399 with BIG.LITTLE architecture, which contains 2 ARM Cortex A72 cores (BIG cores) and 4 ARM Cortex-A53 cores (LITTLE cores),  and the tflite is installed through source.  I use the example code of [benchmark](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/tools/benchmark) and the tflite model is converted from keras model. 
     When I run tflite with 2 threads (through the interpreter.SetNumThreads interface), it is expected that it should run on the 2 BIG cores. However, it seems that in some cases it runs on 2 of the LITTLE cores, which will largely degrade performance. So is there any way to run tflite on specific CPUs?"
44964,What does TODO(b/XXX) mean?,"There are a lot of TODO comments in the code that include a reference to.... something.

Examples:
- https://github.com/tensorflow/tensorflow/blob/3061483034ce0196ca7ec0576668c41e5f4424c9/tensorflow/compiler/tests/BUILD#L81
- https://github.com/tensorflow/tensorflow/blob/0650101e05ef1ad56bfaadcd63ab775b25ecdd16/tensorflow/python/keras/saving/saved_model/metric_serialization.py#L44
- https://github.com/tensorflow/tensorflow/blob/1ba764b368daa5a6f34b556f2a44e2e222a18855/tensorflow/python/ops/risc/risc_grad.py#L27

What do these numbers mean?
"
44963,AttributeError: module 'tensorflow.keras.layers.experimental.preprocessing' has no attribute 'StringLookup'?,"cannot import StringLookup?

Environment:
TF 2.1.0
keras 2.3.1
Windows 10

Is there any suggestion please?
"
44961,Quantization op for Reshape is not supported in keras,"Tensorflow version 2.2.0
For the experiment, I build a simple model and try to quantized aware training with reshape function.

```
def test_model(final_depth = 24):
    inputs = layers.Input(shape=(None, None,24))
    input_shape = tf.shape(inputs)
    rs_1 = tf.reshape(inputs, [input_shape[0], input_shape[1] * input_shape[2], input_shape[3], 1])
    conv1 = layers.ReLU(negative_slope = 0.2)(layers.Conv2D(1, (1,3), activation = None, padding = 'same', kernel_initializer = 'glorot_uniform')(rs_1))
    out = tf.reshape(conv1, [input_shape[0], input_shape[1], input_shape[2], input_shape[3]])
    model = tf.keras.Model(inputs = inputs, outputs = out)
    return model
```

Then I got an error like this:

```
Traceback (most recent call last):
  File ""/root/anaconda3/envs/tf2/lib/python3.8/site-packages/tensorflow_model_optimization/python/core/quantization/keras/quantize.py"", line 383, in quantize_apply
    model_copy = _clone_model_with_weights(model)
  File ""/root/anaconda3/envs/tf2/lib/python3.8/site-packages/tensorflow_model_optimization/python/core/quantization/keras/quantize.py"", line 332, in _clone_model_with_weights
    cloned_model = keras.models.clone_model(model_to_clone)
  File ""/root/anaconda3/envs/tf2/lib/python3.8/site-packages/tensorflow/python/keras/models.py"", line 426, in clone_model
    return _clone_functional_model(
  File ""/root/anaconda3/envs/tf2/lib/python3.8/site-packages/tensorflow/python/keras/models.py"", line 199, in _clone_functional_model
    network.reconstruct_from_config(model_config,
  File ""/root/anaconda3/envs/tf2/lib/python3.8/site-packages/tensorflow/python/keras/engine/network.py"", line 2029, in reconstruct_from_config
    process_node(layer, node_data)
  File ""/root/anaconda3/envs/tf2/lib/python3.8/site-packages/tensorflow/python/keras/engine/network.py"", line 1977, in process_node
    output_tensors = layer(input_tensors, **kwargs)
  File ""/root/anaconda3/envs/tf2/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py"", line 897, in __call__
    self._maybe_build(inputs)
  File ""/root/anaconda3/envs/tf2/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py"", line 2416, in _maybe_build
    self.build(input_shapes)  # pylint:disable=not-callable
  File ""/root/anaconda3/envs/tf2/lib/python3.8/site-packages/tensorflow/python/keras/layers/wrappers.py"", line 58, in build
    self.layer.build(input_shape)
  File ""/root/anaconda3/envs/tf2/lib/python3.8/site-packages/tensorflow/python/keras/layers/convolutional.py"", line 153, in build
    input_channel = self._get_input_channel(input_shape)
  File ""/root/anaconda3/envs/tf2/lib/python3.8/site-packages/tensorflow/python/keras/layers/convolutional.py"", line 293, in _get_input_channel
    raise ValueError('The channel dimension of the inputs '
ValueError: The channel dimension of the inputs should be defined. Found `None`.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""./tools/train_oppo_template_yuv_24pack.py"", line 227, in <module>
    main()
  File ""./tools/train_oppo_template_yuv_24pack.py"", line 114, in main
    model = tfmot.quantization.keras.quantize_apply(annotated_model)
  File ""/root/anaconda3/envs/tf2/lib/python3.8/site-packages/tensorflow_model_optimization/python/core/quantization/keras/quantize.py"", line 385, in quantize_apply
    raise ValueError(
ValueError: Unable to clone model. This generally happens if you used custom Keras layers or objects in your model. Please specify them via `quantize_scope` for your calls to `quantize_model` and `quantize_apply`.
```


It looks like the reshape operation is not supported. So I try to skip the quantized reshape op just as the other unsupported operations. Stil got the same error

```
def annotate(layer):
    if layer._name.startswith('tf_op_layer_Reshape'):
      return layer
    # quantize everything else
    return tfmot.quantization.keras.quantize_annotate_layer(layer)

annotated_model = tf.keras.models.clone_model(model, clone_function=annotate)
model = tfmot.quantization.keras.quantize_apply(annotated_model)
```

**I did another experiment with the simple model for the reshape function. I directly connect the reshape function to the output (did not skip the quantized reshape op)**
```
def test_model(final_depth = 24):
    inputs = layers.Input(shape=(None, None,24))
    input_shape = tf.shape(inputs)
   conv1 = layers.ReLU(negative_slope = 0.2)(layers.Conv2D(final_depth, 3, activation = None, padding = 'same', kernel_initializer = 'glorot_uniform')(inputs))
    out = tf.reshape(conv1, [input_shape[0], input_shape[1], input_shape[2], input_shape[3]])
    model = tf.keras.Model(inputs = inputs, outputs = out)
    return model
```
Got the error like this:
```
Traceback (most recent call last):
  File ""./tools/train_oppo_template_yuv_24pack.py"", line 227, in <module>
    main()
  File ""./tools/train_oppo_template_yuv_24pack.py"", line 114, in main
    model = tfmot.quantization.keras.quantize_apply(annotated_model)
  File ""/root/anaconda3/envs/tf2/lib/python3.8/site-packages/tensorflow_model_optimization/python/core/quantization/keras/quantize.py"", line 420, in quantize_apply
    return keras.models.clone_model(
  File ""/root/anaconda3/envs/tf2/lib/python3.8/site-packages/tensorflow/python/keras/models.py"", line 426, in clone_model
    return _clone_functional_model(
  File ""/root/anaconda3/envs/tf2/lib/python3.8/site-packages/tensorflow/python/keras/models.py"", line 195, in _clone_functional_model
    model_config, created_layers = _clone_layers_and_model_config(
  File ""/root/anaconda3/envs/tf2/lib/python3.8/site-packages/tensorflow/python/keras/models.py"", line 246, in _clone_layers_and_model_config
    config = network.get_network_config(model, serialize_layer_fn=_copy_layer)
  File ""/root/anaconda3/envs/tf2/lib/python3.8/site-packages/tensorflow/python/keras/engine/network.py"", line 2119, in get_network_config
    layer_config = serialize_layer_fn(layer)
  File ""/root/anaconda3/envs/tf2/lib/python3.8/site-packages/tensorflow/python/keras/models.py"", line 243, in _copy_layer
    created_layers[layer.name] = layer_fn(layer)
  File ""/root/anaconda3/envs/tf2/lib/python3.8/site-packages/tensorflow_model_optimization/python/core/quantization/keras/quantize.py"", line 370, in _quantize
    raise RuntimeError(
RuntimeError: Layer tf_op_layer_Reshape/shape:<class 'tensorflow.python.keras.engine.base_layer.TensorFlowOpLayer'> is not supported. You can quantize this layer by passing a `tfmot.quantization.keras.QuantizeConfig` instance to the `quantize_annotate_layer` API.
```

If I do skip the quantized reshape op like above, I can run the model. But I found out that the channel dimension after reshape becomes ""None"", Therefore I can't connect reshape layer to any other layer e.g. conv2d
```
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            [(None, None, None,  0                                            
__________________________________________________________________________________________________
quantize_layer (QuantizeLayer)  (None, None, None, 2 3           input_1[0][0]                    
__________________________________________________________________________________________________
tf_op_layer_Shape (TensorFlowOp (4,)                 0           quantize_layer[1][0]             
__________________________________________________________________________________________________
quant_conv2d (QuantizeWrapper)  (None, None, None, 2 5259        quantize_layer[1][0]             
__________________________________________________________________________________________________
tf_op_layer_strided_slice (Tens ()                   0           tf_op_layer_Shape[1][0]          
__________________________________________________________________________________________________
tf_op_layer_strided_slice_1 (Te ()                   0           tf_op_layer_Shape[1][0]          
__________________________________________________________________________________________________
tf_op_layer_strided_slice_2 (Te ()                   0           tf_op_layer_Shape[1][0]          
__________________________________________________________________________________________________
tf_op_layer_strided_slice_3 (Te ()                   0           tf_op_layer_Shape[1][0]          
__________________________________________________________________________________________________
quant_re_lu (QuantizeWrapper)   (None, None, None, 2 3           quant_conv2d[0][0]               
__________________________________________________________________________________________________
tf_op_layer_Reshape/shape (Tens (4,)                 0           tf_op_layer_strided_slice[1][0]  
                                                                 tf_op_layer_strided_slice_1[1][0]
                                                                 tf_op_layer_strided_slice_2[1][0]
                                                                 tf_op_layer_strided_slice_3[1][0]
__________________________________________________________________________________________________
tf_op_layer_Reshape (TensorFlow (None, None, None, N 0           quant_re_lu[0][0]                
                                                                 tf_op_layer_Reshape/shape[1][0]  
==================================================================================================
Total params: 5,265
Trainable params: 5,208
Non-trainable params: 57
__________________________________________________________________________________________________
```
I think the problem is that quantized reshape is unsupported. Even if I skip quantizing the reshape function, the channel dimension of output become 'None' so I can't connect it to the other conv function
"
44960,Avoid call to cuCtxSynchronize() when moving from graph execution to eager execution,"Hi,

While running TF-2.x on nvidia gpu machine, tensorflow calls `cuCtxSynchronize()` API whenever programs enter eager execution. I.e. when program exits `@tf.function` code block. E.g. please take a look at code block [here](https://github.com/tensorflow/tensorflow/blob/642db2faf55e3ca7acd06ea236e9d47f63190718/tensorflow/stream_executor/cuda/cuda_gpu_executor.cc#L546-L548).

This essentially adds a device wide synchronization barrier and blocks until all gpu execution is complete even if some of the work is not related to TF library. I would like to use GPU to do some other work in parallel while TF is executing. Is there any way to achieve this without having to block TF due to this API call? If not, does it make sense to avoid device wide synchronization (which is bit hard restriction) and only synchronize on resources (such as cudaStream, etc.) created by TF? 

"
44959,GeForce 3090 incompatibility with Nightly,"**System information**
- Using a stock example script provided in TensorFlow
- Linux Ubuntu 18.04
- TensorFlow installed from Nightly
- TensorFlow version v1.12.1-45908-g9af48cb079
- Python version 3.8
- CUDA 11.1 cuDNN 8.0.5.39
- GeForce RTX 3090 with 24265MiB

**Describe the current behavior**
Training does not run on the GPU, shows ""warning"":

`Your CUDA software stack is old. We fallback to the NVIDIA driver for some compilation. Update your CUDA version to get the best performance. The ptxas error was: ptxas fatal   : Value 'sm_86' is not defined for option 'gpu-name'`

**Describe the expected behavior**
Training should run on the GPU

**Standalone code to reproduce the issue**
Install GeForce 3090 then install nightly GPU:

```
conda create -n tf-n-gpu python=3.8
conda activate tf-n-gpu
pip install tf-nightly-gpu
pip install matplotlib
pip install IPython
```

Run:
https://www.tensorflow.org/tutorials/generative/pix2pix

"
44953,How does classifier predict a class?,"I want to implement the model by myself and thus have to know how does it classify the data. I build a model for 12-class classifier and it predicts fine. But the last conv layer just outputs 12 floating point value and I don't know how it suddenly predicts the right class. Can someone explain for me? Like is it depend on some threshold or it chooses the max value or something? Thanks!

PS. I've searched in STACKOVERFLOW before but couldn't get any information. I've tried to choose the index with max value but it seemed that model just predicts randomly. So I guess it doesn't work like that. 

**The model**

> first_conv (Conv2D)          (None, 63, 1, 24)         984       
> _________________________________________________________________
> first_act (Activation)       (None, 63, 1, 24)         0         
> _________________________________________________________________
> dw0 (DepthwiseConv2D)        (None, 61, 1, 24)         96        
> _________________________________________________________________
> pw0 (Conv2D)                 (None, 61, 1, 24)         600       
> _________________________________________________________________
> act0 (Activation)            (None, 61, 1, 24)         0         
> _________________________________________________________________
> dw1 (DepthwiseConv2D)        (None, 59, 1, 24)         96        
> _________________________________________________________________
> pw1 (Conv2D)                 (None, 59, 1, 24)         600       
> _________________________________________________________________
> act1 (Activation)            (None, 59, 1, 24)         0         
> _________________________________________________________________
> dw2 (DepthwiseConv2D)        (None, 57, 1, 24)         96        
> _________________________________________________________________
> pw2 (Conv2D)                 (None, 57, 1, 24)         600       
> _________________________________________________________________
> act2 (Activation)            (None, 57, 1, 24)         0         
> _________________________________________________________________
> dw3 (DepthwiseConv2D)        (None, 55, 1, 24)         96        
> _________________________________________________________________
> pw3 (Conv2D)                 (None, 55, 1, 24)         600       
> _________________________________________________________________
> act3 (Activation)            (None, 55, 1, 24)         0         
> _________________________________________________________________
> pool (AveragePooling2D)      (None, 1, 1, 24)          0         
> _________________________________________________________________
> last_conv (Conv2D)           (None, 1, 1, 12)          300       
> _________________________________________________________________
> tf_op_layer_reshape_3 (Tenso [(None, 12)]              0         "
44952,Issue with tf.math.conj function,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): v2.2.0-rc4-8-g2b96f3662b 2.2.0 (also tried on 2.3.1)
- Python version: 3.7.8
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: 10.1 / 7.6.5
- GPU model and memory: RTX2060 8GB

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
I have been having problems with the tensorflow function tensorflow.math.conj, which is supposed to return the complex conjugate (1+1j -> 1-1j) of a tensor. The error that occurs is the following:

tensorflow/stream_executor/cuda/cuda_driver.cc:939] could not synchronize on CUDA context: CUDA_ERROR_LAUNCH_FAILED: unspecified launch failure :: 0x00007FFF94A28E85 tensorflow::CurrentStackTrace

However, it seems that tf.math.real and tf.math.imag work as expected.

**Describe the expected behavior**
I expect the function to output the the complex conjugate (1+1j -> 1-1j).

**Standalone code to reproduce the issue**
`import tensorflow as tf
a = tf.constant(1+1.j, dtype=tf.complex64)
b = tf.math.conj(a)'

**Other info / logs** Include any logs or source code that would be helpful to
I am able to perform every other tensorflow operation that I've tried, it's really only this issue that is giving me problems...
"
44948,Can't load GRUCell weights from TensorFlow 1 to TensorFlow 2,"# Issue 💻 

## System information
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): `True`
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): `Windows 10`
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: `False`
- TensorFlow installed from (source or binary): `pip install tensorflow`
- TensorFlow version (use command below): `v2.3.0-rc2-23-gb36436b087 2.3.0`
- Python version: `3.8.3`
- Bazel version (if compiling from source): `None`
- GCC/Compiler version (if compiling from source): `None`
- CUDA/cuDNN version: `None`
- GPU model and memory: `None`

## Current Behavior

I migrated a code written with **tensorflow 1** to **tensorflow 2**. In addition I would like to convert the checkpoints of my **tensorflow 1** model too. However, the `GRUCell` seems really different from **tensorflow 1** to **tensorflow 2** implementation, and can't load the saved weights from a `compat.v1.nn.rnn_cell.GRUCell` to a `keras.layers.GRUCell`.
The error is:
```
W tensorflow/core/framework/op_kernel.cc:1767] OP_REQUIRES failed at save_restore_v2_ops.cc:184 : Not found: Key gru_cell_1/bias:0 not found in checkpoint
```

So the error comes from the weights initialization. By looking closer to the structure of the `GRUCell` from the **1** and **2** versions, I noticed major differences:

1. The `compat.v1.rnn_cell.GRUCell` has **four weights**:
    * `gru_cell/gates/kernel:0` of shape `(S + H, 2 x H)`, 
    * `gru_cell/gates/bias:0` of shape `(2 x H, )`, 
    * `gru_cell/candidate/kernel:0` of shape `(S + H, H)`,  
    * `gru_cell/candidate/bias:0` of shape `(H, )`

2. The `tf.keras.layers.GRUCell` has **three weights**:
    * `gru_cell/kernel:0` of shape `(S, 3 x H)`
    * `gru_cell/recurrent_kernel:0` of shape `(H, 3 x H)`
    * `gru_cell/bias:0` of shape `(2, 3 x H)`

So the issue is that **tensorflow** struggles to load weights from the first version to a `keras.layers.GRUCell` - of course, the shape and length of the weights are different. 
Is there a function to migrate `compat.v1.nn.rnn_cell.GRUCell` weights to `keras.layers.GRUCell` ? I have not seen in the documentation.

## To illustrate

### 1. Weights of `compat.v1.nn.rnn_cell.GRUCell` layer

```python
import tensorflow as tf

SEQ_LENGTH = 4
HIDDEN_SIZE = 512
BATCH_SIZE = 1
inputs = tf.random.normal([BATCH_SIZE, SEQ_LENGTH])

# GRU cell
gru = tf.compat.v1.nn.rnn_cell.GRUCell(HIDDEN_SIZE)
# Hidden state
state = gru.zero_state(BATCH_SIZE, tf.float32)
# Forward
output, state = gru(inputs, state)

for weight in gru.weights:
    print(weight.name, weight.shape)
```

Output:
```raw
gru_cell/gates/kernel:0 (516, 1024)
gru_cell/gates/bias:0 (1024,)
gru_cell/candidate/kernel:0 (516, 512)
gru_cell/candidate/bias:0 (512,)
```

### 2. Weights of `keras.layers.GRUCell` layer

```python
import tensorflow as tf

SEQ_LENGTH = 4
HIDDEN_SIZE = 512
BATCH_SIZE = 1
inputs = tf.random.normal([BATCH_SIZE , SEQ_LENGTH])

# GRU cell
gru = tf.keras.layers.GRUCell(HIDDEN_SIZE)
# Hidden state
state = tf.zeros((BATCH_SIZE, HIDDEN_SIZE), dtype=tf.float32)
# Forward
output, state = gru(inputs, state)

# Display the weigths
for weight in gru.weights:
    print(weight.name, weight.shape)
```

Output:
```raw
gru_cell/kernel:0 (4, 1536)
gru_cell/recurrent_kernel:0 (512, 1536)
gru_cell/bias:0 (2, 1536)
```

## Note

I tried [`_convert_rnn_weights` tensorflow function](https://github.com/tensorflow/tensorflow/blob/c52ee536c045186476450cf76461d47fb2667e7d/tensorflow/python/keras/saving/hdf5_format.py#L404-L568) to convert the desired weights. It works but only for `CuDNN` weights, so I can't use it in my case."
44947,How to save a TensorFlow model to use in ML.NET,"I have posted this question [here](https://stackoverflow.com/questions/64794378/correct-pb-file-to-move-tensorflow-model-into-ml-net) on Stack Overflow, but it hasn't received a response so I'll ask here (**please look at the link before commenting** as you will see that the problem is explained in greater detail).

I have a 1D CNN in TensorFlow and I am trying to save it so I can use it in ML.NET (by use I mean predict only).  Examples of using TF in .NET show that it is saved in a manner similar to the [SavedModel](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/python/saved_model); however, the saved_model.pb is not correct when comparing it in [Netron](https://netron.app/) (shown in my question on Stack Overflow.

For example the following TensorFlow [code](https://www.tensorflow.org/tfx/tutorials/serving/rest_simple), if you examine the model in Netron, it looks like it only has 1 node (and is really confusing).  If you save it as a .h5 and load it into Netron, it looks normal (but ML.NET requires that it be in the SavedModel format such as this [example](https://docs.microsoft.com/en-us/dotnet/machine-learning/tutorials/text-classification-tf)).

It should also be noted that there are instances where ML.NET does not require the SavedModel format such as [here](https://github.com/dotnet/machinelearning-samples/tree/master/samples/csharp/getting-started/DeepLearning_ImageClassification_TensorFlow/ImageClassification/assets/inputs/inception) where the inception pb is quite small.  I'm not sure why it's needed sometimes and other times it is not needed.  @Oceania2018 are these meta [graphs](https://github.com/SciSharp/TensorFlow.NET/tree/master/graph) similar to this situation?

So my question is simple.  How can I save a TensorFlow model in the correct format so I can pull it into ML.NET to make predictions.
"
44946,"ValueError: Shapes (None, 1) and (None, 10) are incompatible","I have 40 rows and 15000 columns 
EEG data with attaching lebel  
```
Epoch 1/10
WARNING:tensorflow:Layer dense_2 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.

If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.

To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.

---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
<ipython-input-33-601f7224d647> in <module>()
----> 1 model.fit(X_train, y_train, epochs=10, batch_size=32)

10 frames
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py in wrapper(*args, **kwargs)
    971           except Exception as e:  # pylint:disable=broad-except
    972             if hasattr(e, ""ag_error_metadata""):
--> 973               raise e.ag_error_metadata.to_exception(e)
    974             else:
    975               raise

ValueError: in user code:

    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:806 train_function  *
        return step_function(self, iterator)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:796 step_function  **
        outputs = model.distribute_strategy.run(run_step, args=(data,))
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:1211 run
        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2585 call_for_each_replica
        return self._call_for_each_replica(fn, args, kwargs)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2945 _call_for_each_replica
        return fn(*args, **kwargs)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:789 run_step  **
        outputs = model.train_step(data)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:749 train_step
        y, y_pred, sample_weight, regularization_losses=self.losses)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/compile_utils.py:204 __call__
        loss_value = loss_obj(y_t, y_p, sample_weight=sw)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/losses.py:149 __call__
        losses = ag_call(y_true, y_pred)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/losses.py:253 call  **
        return ag_fn(y_true, y_pred, **self._fn_kwargs)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py:201 wrapper
        return target(*args, **kwargs)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/losses.py:1535 categorical_crossentropy
        return K.categorical_crossentropy(y_true, y_pred, from_logits=from_logits)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py:201 wrapper
        return target(*args, **kwargs)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py:4687 categorical_crossentropy
        target.shape.assert_is_compatible_with(output.shape)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/tensor_shape.py:1134 assert_is_compatible_with
        raise ValueError(""Shapes %s and %s are incompatible"" % (self, other))

    ValueError: Shapes (None, 1) and (None, 10) are incompatible
```"
44945,[FIX ME!] Matrix computaion in custom-ops got partly correct result.,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):YES
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):UBUNTU16.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below):
- Python version:3.6
- Bazel version (if compiling from source): Build label: 0.19.1
- GCC/Compiler version (if compiling from source):gcc version 5.4.0
- CUDA/cuDNN version: 10.1/7.0
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
tensorflow 1.13.2
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
Only the first row of the matrix got correct result.
**Describe the expected behavior**
All row in matrix have the crrect result.
**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

you can clone this [repo](https://github.com/shipleyxie/custom-ops.git) ,By using  `bash build_install.py`  and run following code to reproduce this error.
```shell
import tensorflow as tf
import tensorflow_zero_out
input = [[1.0,2.0,3.0,4.0],[1.0,2.0,3.0,4.0],[1.0,2.0,3.0,4.0],[1.0,2.0,3.0,4.0],[1.0,2.0,3.0,4.0],[1.0,2.0,3.0,4.0],[1.0,2.0,3.0,4.0],[1.0,2.0,3.0,4.0],[1.0,2.0,3.0,4.0]]
filter = [[0.025], [0.975]]
print(tensorflow_zero_out.zero_out(input, filter))
```


**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

```
2020-11-17 22:49:08.034150: I tensorflow_time_two/cc/kernels/time_two_kernels.cc:39] batch_size is 4 data_len is 4
2020-11-17 22:49:08.034178: I tensorflow_time_two/cc/kernels/time_two_kernels.cc:41] weights_tensor[0,0]0.025weights_tensor[0,1]0.975
2020-11-17 22:49:08.034188: I tensorflow_time_two/cc/kernels/time_two_kernels.cc:48] output_tensor[0, 0] = 0.025*1+0.975*0;
2020-11-17 22:49:08.034195: I tensorflow_time_two/cc/kernels/time_two_kernels.cc:51] output_tensor result is 0.025
2020-11-17 22:49:08.034204: I tensorflow_time_two/cc/kernels/time_two_kernels.cc:60] output_tensor[0,1 ] = 0.025*1+0.975*0.025;
2020-11-17 22:49:08.034211: I tensorflow_time_two/cc/kernels/time_two_kernels.cc:63] output_tensor result is 0.049375
2020-11-17 22:49:08.034220: I tensorflow_time_two/cc/kernels/time_two_kernels.cc:60] output_tensor[0,2 ] = 0.025*1+0.975*0.049375;
2020-11-17 22:49:08.034228: I tensorflow_time_two/cc/kernels/time_two_kernels.cc:63] output_tensor result is 0.0731406
2020-11-17 22:49:08.034236: I tensorflow_time_two/cc/kernels/time_two_kernels.cc:60] output_tensor[0,3 ] = 0.025*1+0.975*0.0731406;
2020-11-17 22:49:08.034243: I tensorflow_time_two/cc/kernels/time_two_kernels.cc:63] output_tensor result is 0.0963121
2020-11-17 22:49:08.034252: I tensorflow_time_two/cc/kernels/time_two_kernels.cc:48] output_tensor[1, 0] = 0.025*1+0.975*0;
2020-11-17 22:49:08.034259: I tensorflow_time_two/cc/kernels/time_two_kernels.cc:51] output_tensor result is 0.025
2020-11-17 22:49:08.034267: I tensorflow_time_two/cc/kernels/time_two_kernels.cc:60] output_tensor[1,1 ] = 0.025*1+0.975*0.025;
2020-11-17 22:49:08.034274: I tensorflow_time_two/cc/kernels/time_two_kernels.cc:63] output_tensor result is 0.049375
2020-11-17 22:49:08.034283: I tensorflow_time_two/cc/kernels/time_two_kernels.cc:60] output_tensor[1,2 ] = 0.025*1+0.975*0.049375;
2020-11-17 22:49:08.034290: I tensorflow_time_two/cc/kernels/time_two_kernels.cc:63] output_tensor result is 0.0731406
2020-11-17 22:49:08.034299: I tensorflow_time_two/cc/kernels/time_two_kernels.cc:60] output_tensor[1,3 ] = 0.025*1+0.975*0.0731406;
2020-11-17 22:49:08.034306: I tensorflow_time_two/cc/kernels/time_two_kernels.cc:63] output_tensor result is 0.0963121
2020-11-17 22:49:08.034314: I tensorflow_time_two/cc/kernels/time_two_kernels.cc:48] output_tensor[2, 0] = 0.025*1+0.975*0;
2020-11-17 22:49:08.034321: I tensorflow_time_two/cc/kernels/time_two_kernels.cc:51] output_tensor result is 0.025
2020-11-17 22:49:08.034330: I tensorflow_time_two/cc/kernels/time_two_kernels.cc:60] output_tensor[2,1 ] = 0.025*1+0.975*0.025;
2020-11-17 22:49:08.034337: I tensorflow_time_two/cc/kernels/time_two_kernels.cc:63] output_tensor result is 0.049375
2020-11-17 22:49:08.034345: I tensorflow_time_two/cc/kernels/time_two_kernels.cc:60] output_tensor[2,2 ] = 0.025*1+0.975*0.049375;
2020-11-17 22:49:08.034352: I tensorflow_time_two/cc/kernels/time_two_kernels.cc:63] output_tensor result is 0.0731406
2020-11-17 22:49:08.034362: I tensorflow_time_two/cc/kernels/time_two_kernels.cc:60] output_tensor[2,3 ] = 0.025*1+0.975*0.0731406;
2020-11-17 22:49:08.034370: I tensorflow_time_two/cc/kernels/time_two_kernels.cc:63] output_tensor result is 0.0963121
2020-11-17 22:49:08.034379: I tensorflow_time_two/cc/kernels/time_two_kernels.cc:48] output_tensor[3, 0] = 0.025*1+0.975*0;
2020-11-17 22:49:08.034387: I tensorflow_time_two/cc/kernels/time_two_kernels.cc:51] output_tensor result is 0.025
2020-11-17 22:49:08.034395: I tensorflow_time_two/cc/kernels/time_two_kernels.cc:60] output_tensor[3,1 ] = 0.025*1+0.975*0.025;
2020-11-17 22:49:08.034403: I tensorflow_time_two/cc/kernels/time_two_kernels.cc:63] output_tensor result is 0.049375
2020-11-17 22:49:08.034412: I tensorflow_time_two/cc/kernels/time_two_kernels.cc:60] output_tensor[3,2 ] = 0.025*1+0.975*0.049375;
2020-11-17 22:49:08.034420: I tensorflow_time_two/cc/kernels/time_two_kernels.cc:63] output_tensor result is 0.0731406
2020-11-17 22:49:08.034429: I tensorflow_time_two/cc/kernels/time_two_kernels.cc:60] output_tensor[3,3 ] = 0.025*1+0.975*0.0731406;
2020-11-17 22:49:08.034436: I tensorflow_time_two/cc/kernels/time_two_kernels.cc:63] output_tensor result is 0.0963121
2020-11-17 22:49:08.034449: I tensorflow_time_two/cc/kernels/time_two_kernels.cc:116] debug out_tensor <<<<< 0.0250.0493750.07314060.09631210.0250.0493750.09631210.0250.0493750.07314060.0963121
2020-11-17 22:49:08.034463: I tensorflow/core/framework/log_memory.cc:35] __LOG_MEMORY__ MemoryLogTensorDeallocation { allocator_name: ""cpu"" }
2020-11-17 22:49:08.034493: I tensorflow/core/framework/log_memory.cc:35] __LOG_MEMORY__ MemoryLogTensorDeallocation { allocator_name: ""cpu"" }
tf.Tensor(
[[2.5000000e-02 4.9375001e-02 7.3140629e-02 9.6312113e-02]
 [1.4873783e+24 4.5570226e-41 1.4873783e+24 4.5570226e-41]
 [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]
 [2.6221498e+20 1.8523601e+28 1.2714611e+31 1.7322379e+19]], shape=(4, 4), dtype=float32)

```"
44944,"tflite_runtime got installed successfully, however getting error while importing interpreter.","Environment:
Python 3.7
armv7l (ARM 32).
tflite_runtime (installed version) : 2.5.0

Issues:

Steps followed:
1. Followed steps from Python Quickstart document available on tensorflow site , below is the document.
      https://www.tensorflow.org/lite/guide/python

2. it was stated in the above document To quickly run TensorFlow Lite models with Python, you can install just the TensorFlow Lite interpreter, instead of all TensorFlow packages.

3. So I didn't install the whole tensorflow package , indeed just installed the wheel available for my armv7l (ARM 32) machine having Python 3.7.

Steps to reproduce the issue:

1. Have ARM 32 (armv7l) system with Python 3.7.
2. pip3 install --install-option=""/mnt/persistent_data/tfinter"" tflite_runtime-2.5.0-cp37-cp37m-linux_armv7l.whl
3. wheel package installed: https://github.com/google-coral/pycoral/releases/download/release-frogfish/tflite_runtime-2.5.0-cp37-cp37m-linux_armv7l.whl
3. Install tflite_rutime only (not the whole tensorflow) using above command.
4. tflite_runtime got installed correctly (no error while installation).
5. tflute_runtime version 2.5.0.

Expected Behaviour:

import tflite_runtime.interpreter as tflite
Above command should get executed without error.

Error:
However trying to import  tflite_runtime.interpreter returns following error:

>>> import tflite_runtime.interpreter
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/usr/lib/python3.7/site-packages/tflite_runtime/interpreter.py"", line 36, in <module>
    from tflite_runtime import _pywrap_tensorflow_interpreter_wrapper as _interpreter_wrapper
ImportError: cannot import name '_pywrap_tensorflow_interpreter_wrapper' from 'tflite_runtime' (/usr/lib/python3.7/site-packages/tflite_runtime/__init__.py).

Note:
Doing ls in installed tflite_runtime folder returns following files:

[nilesh_kumar@localhost tflite_runtime]$ ls
__init__.py
__pycache
interpreter.py
_pywrap_tensorflow_interpreter_wrapper.cpython-37m-arm-linux-gnueabihf.so
"
44943,UnrecognizedFlagError: Unknown command line flag 'pdb_post_mortem',"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): https://pypi.tuna.tsinghua.edu.cn
- TensorFlow version (use command below):1.14.0
- Python version: 3.7.6
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:CUDA 10.0,cuDNN
- GPU model and memory: 6GB

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
i successfully installed tensorflow-gpu==1.14.0,when i import tensorflow as tf, raise the flowing exception,how can i sovle it?
my cuda version si 10.0, and cudnn  is cudnn64_7.dll


import tensorflow as tf
D:\ProgramFile\python\lib\site-packages\tensorflow\python\framework\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([(""qint8"", np.int8, 1)])
D:\ProgramFile\python\lib\site-packages\tensorflow\python\framework\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([(""quint8"", np.uint8, 1)])
D:\ProgramFile\python\lib\site-packages\tensorflow\python\framework\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([(""qint16"", np.int16, 1)])
D:\ProgramFile\python\lib\site-packages\tensorflow\python\framework\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([(""quint16"", np.uint16, 1)])
D:\ProgramFile\python\lib\site-packages\tensorflow\python\framework\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([(""qint32"", np.int32, 1)])
D:\ProgramFile\python\lib\site-packages\tensorflow\python\framework\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([(""resource"", np.ubyte, 1)])
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""D:\ProgramFile\python\lib\site-packages\tensorflow\__init__.py"", line 28, in <module>
    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import
  File ""D:\ProgramFile\python\lib\site-packages\tensorflow\python\__init__.py"", line 63, in <module>
    from tensorflow.python.framework.framework_lib import *  # pylint: disable=redefined-builtin
  File ""D:\ProgramFile\python\lib\site-packages\tensorflow\python\framework\framework_lib.py"", line 25, in <module>
    from tensorflow.python.framework.ops import Graph
  File ""D:\ProgramFile\python\lib\site-packages\tensorflow\python\framework\ops.py"", line 54, in <module>
    from tensorflow.python.platform import app
  File ""D:\ProgramFile\python\lib\site-packages\tensorflow\python\platform\app.py"", line 23, in <module>
    from absl.app import run as _run
  File ""D:\ProgramFile\python\lib\site-packages\absl\app.py"", line 54, in <module>
    flags.DEFINE_alias('pdb', 'pdb_post_mortem')
  File ""D:\ProgramFile\python\lib\site-packages\absl\flags\_defines.py"", line 754, in DEFINE_alias
    raise _exceptions.UnrecognizedFlagError(original_name)
absl.flags._exceptions.UnrecognizedFlagError: Unknown command line flag 'pdb_post_mortem'


**Describe the expected behavior**

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
44942,Keras Model.compile() exception text is unclear when a loss method is not specified during compile(),"**System information**
- TensorFlow version (you are using): 2.3.1
- Are you willing to contribute it (Yes/No): Yes

**Describe the feature and the current behavior/state.** User is not given an obvious error message when  tensorflow.keras.models.Sequential.compile() is called and a loss function is omitted.

```
# Build the model
tf_model = Sequential()
tf_model.add(LSTM(
    units=32,
    input_shape=[window, 1],    
))
tf_model.add(Dense(units=1))
tf_model.compile()
tf_model.fit(rolling_x, rolling_y, epochs=100)
```

Triggers the following exception:

```
\env\lib\site-packages\tensorflow\python\keras\optimizer_v2\optimizer_v2.py:1270 _filter_grads
        raise ValueError(""No gradients provided for any variable: %s."" %
```

**Will this change the current api? How?** No

**Who will benefit with this feature?** New users"
44941,Learn ML,<removed as it was spam>
44940,TF 2.3.1. Custom Metrics are not shown,"
**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: no
- TensorFlow installed from (source or binary):Docker tag 2.3.1
- TensorFlow version (use command below): 2.3.1
- Python version: 3.7
- Bazel version (if compiling from source):x
- GCC/Compiler version (if compiling from source):x
- CUDA/cuDNN version:
- GPU model and memory: K80

**Describe the current behavior**
I used to be able _(TF 2.0.0)_ to log custom metrics using a Callback, putting the calculated logs into the `logs` variable. Now _(using TF 2.3.1)_ it seems these are not displayed anymore. Is this adjusted? It seems all that is visualized now is: 
```
I 2020-11-17T12:47:08.315319004Z master-replica-0 Epoch 1/150
 master-replica-0 
I 2020-11-17T12:47:08.315363796Z master-replica-0 160/160 - 532s - loss: 29.2287 - val_loss: 15.1582
 master-replica-0 
I 2020-11-17T12:55:48.016732616Z master-replica-0 Epoch 2/150
 master-replica-0 
I 2020-11-17T12:55:48.016795954Z master-replica-0 160/160 - 519s - loss: 10.9081 - val_loss: 18.8457
 master-replica-0 
I 2020-11-17T13:04:21.477356137Z master-replica-0 Epoch 3/150
 master-replica-0 
I 2020-11-17T13:04:21.477408088Z master-replica-0 160/160 - 513s - loss: 9.3685 - val_loss: 8.4681
 master-replica-0 
I 2020-11-17T13:12:53.997353683Z master-replica-0 Epoch 4/150
 master-replica-0 
I 2020-11-17T13:12:53.997419829Z master-replica-0 160/160 - 512s - loss: 10.4035 - val_loss: 8.9458
 master-replica-0 
I 2020-11-17T13:21:18.459229170Z master-replica-0 Epoch 5/150
 master-replica-0 
I 2020-11-17T13:21:18.459279180Z master-replica-0 160/160 - 504s - loss: 9.8809 - val_loss: 9.3682
 master-replica-0 
I 2020-11-17T13:29:43.330040354Z master-replica-0 Epoch 6/150
 master-replica-0 
I 2020-11-17T13:29:43.330108120Z master-replica-0 160/160 - 504s - loss: 9.5458 - val_loss: 8.8212
 master-replica-0 
```

"
44938,RuntimeError: tensorflow/lite/kernels/concatenation.cc:76 t->dims->data[d] != t0->dims->data[d] (32 != 1)Node number 23 (CONCATENATION) failed to prepare. Node number 30 (WHILE) failed to invoke.,"**System information**
-  Linux Ubuntu 16.04
- TensorFlow installed from 2.3:
- Tf-nightly: 2..4.0a20201112
- Keras = 2.4.3

** I am able to convert to the tflite model but i am getting error while conversion.
Error: ""Traceback (most recent call last):
  File ""/home/PycharmProjects/keras-ctpn/test.py"", line 74, in <module>
    interpreter.invoke()
  File ""/home/anaconda3/envs/sentiment_analysis/lib/python3.7/site-packages/tensorflow/lite/python/interpreter.py"", line 540, in invoke
    self._interpreter.Invoke()
RuntimeError: tensorflow/lite/kernels/concatenation.cc:76 t->dims->data[d] != t0->dims->data[d] (32 != 1)Node number 23 (CONCATENATION) failed to prepare.
Node number 30 (WHILE) failed to invoke.""



My python Script:
##
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function
import cv2
import keras
import numpy as np
import tensorflow as tf
import keras.backend as K
import keras.layers as KL
import keras.models as KM
from keras.applications.vgg16 import VGG16 as vgg
from keras.layers import TimeDistributed
from keras.models import Sequential


input_image = KL.Input(shape=[512, 512, 3], name=""input_image"")
vgg = vgg(input_tensor=input_image, include_top=False)
x = vgg.get_layer('block5_conv3').output
x = KL.Conv2D(512, 3, padding='same', activation='relu', kernel_initializer='he_normal')(x)
temp = KL.Bidirectional(KL.LSTM(128, return_sequences=True))
x = KL.TimeDistributed(temp)(x)
new_output = KL.Dense(10, activation=""sigmoid"")(x)
headModel = KL.Flatten(name=""flatten"")(new_output)
headModel = KL.Dense(2, activation=""softmax"")(headModel)
print(K.int_shape(x))
model = KM.Model(inputs=input_image, outputs=headModel )
model.compile(loss='mean_squared_error', optimizer='adam')
model.save('i_bilstm.h5')

model = keras.models.load_model('i_bilstm.h5')

converter = tf.lite.TFLiteConverter.from_keras_model(model)
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]
converter.experimental_new_converter = True
tflite_model = converter.convert()
open(""i_bilstm.tflite"", ""wb"").write(tflite_model)

interpreter = tf.lite.Interpreter(
    model_path='i_bilstm.tflite')
interpreter.allocate_tensors()
input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()
print(input_details)
print(output_details)
floating_model = input_details[0]['dtype'] == np.float32
height = input_details[0]['shape'][1]
width = input_details[0]['shape'][2]
img = cv2.imread('006.jpg')
img = cv2.resize(img, (512, 512))
input_data = np.expand_dims(img, axis=0)

print(img.shape)
img = img.reshape(1, 512, 512, 3)
print('shape ', img.shape)
if floating_model:
    img = (np.float32(img) - 127.5) / 127.5

print('input_details[0]', input_details[0]['index'])
interpreter.set_tensor(input_details[0]['index'], img)
interpreter.invoke()
rects = interpreter.get_tensor(
    output_details[0]['index'])
print('score ', rects)
scores = interpreter.get_tensor(
    output_details[0]['index'])
print('score ', scores)

##
Also I have attached the file:

# Full console log:

/home/anaconda3/envs/sentiment_analysis/bin/python /home/PycharmProjects/keras-ctpn/test.py
2020-11-17 16:55:41.346730: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2020-11-17 16:55:41.346748: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2020-11-17 16:55:42.364414: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2020-11-17 16:55:42.364557: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2020-11-17 16:55:42.364568: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)
2020-11-17 16:55:42.364584: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (PC13): /proc/driver/nvidia/version does not exist
2020-11-17 16:55:42.364708: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-11-17 16:55:42.365362: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set

WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.
/home/anaconda3/envs/sentiment_analysis/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:2342: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.
  warnings.warn('`Model.state_updates` will be removed in a future version. '
2020-11-17 16:55:44.987273: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
/home/anaconda3/envs/sentiment_analysis/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:1395: UserWarning: `layer.updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.
  warnings.warn('`layer.updates` will be removed in a future version. '
WARNING:absl:Found untraced functions such as bidirectional_layer_call_fn, bidirectional_layer_call_and_return_conditional_losses, forward_lstm_layer_call_fn, forward_lstm_layer_call_and_return_conditional_losses, backward_lstm_layer_call_fn while saving (showing 5 of 25). These functions will not be directly callable after loading.
2020-11-17 16:55:49.339432: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:319] Ignored output_format.
2020-11-17 16:55:49.339456: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:322] Ignored drop_control_dependency.
2020-11-17 16:55:49.340091: I tensorflow/cc/saved_model/reader.cc:32] Reading SavedModel from: /tmp/tmp9mpttm0t
2020-11-17 16:55:49.353959: I tensorflow/cc/saved_model/reader.cc:55] Reading meta graph with tags { serve }
2020-11-17 16:55:49.353980: I tensorflow/cc/saved_model/reader.cc:93] Reading SavedModel debug info (if present) from: /tmp/tmp9mpttm0t
2020-11-17 16:55:49.354016: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2020-11-17 16:55:49.391851: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:251] None of the MLIR optimization passes are enabled (registered 0 passes)
2020-11-17 16:55:49.404005: I tensorflow/cc/saved_model/loader.cc:206] Restoring SavedModel bundle.
2020-11-17 16:55:49.433978: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2899885000 Hz
2020-11-17 16:55:49.540582: I tensorflow/cc/saved_model/loader.cc:190] Running initialization op on SavedModel bundle at path: /tmp/tmp9mpttm0t
2020-11-17 16:55:49.598145: I tensorflow/cc/saved_model/loader.cc:277] SavedModel load for tags { serve }; Status: success: OK. Took 258055 microseconds.
2020-11-17 16:55:49.758440: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:194] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2020-11-17 16:55:49.921397: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
[{'name': 'serving_default_input_image:0', 'index': 0, 'shape': array([  1, 512, 512,   3], dtype=int32), 'shape_signature': array([ -1, 512, 512,   3], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]
[{'name': 'StatefulPartitionedCall:0', 'index': 87, 'shape': array([  1,  32,  32, 256], dtype=int32), 'shape_signature': array([ -1,  32,  32, 256], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]
Traceback (most recent call last):
  File ""/home/PycharmProjects/keras-ctpn/test.py"", line 71, in <module>
    interpreter.invoke()
  File ""/home/anaconda3/envs/sentiment_analysis/lib/python3.7/site-packages/tensorflow/lite/python/interpreter.py"", line 540, in invoke
    self._interpreter.Invoke()
RuntimeError: tensorflow/lite/kernels/concatenation.cc:76 t->dims->data[d] != t0->dims->data[d] (32 != 1)Node number 23 (CONCATENATION) failed to prepare.
Node number 30 (WHILE) failed to invoke.


Process finished with exit code 1

[tflite_conv.py.txt](https://github.com/tensorflow/tensorflow/files/5553142/tflite_conv.py.txt)

"
44937,model.evaluate() and keras.losses.MSE() returning significantly different values,"**System information**
- custom code 
- macOS High Sierra 10.13.6
- TensorFlow installed from binary
- TensorFlow version: 2.3.0
- Python version: 3.8.1


**Describe the current behavior**
After training a LSTM Sequential model for univariate time series prediction, the values returned by model.evaluate(test_set) and tf.keras.losses.MSE(y, model.predict(test_set)), where y is the ground truth and test_set is tf.data.Dataset structure, are different in scale: mode.evaluate() returns a value around a unit or two, whereas tf.keras.losses.MSE returns a value of hundreds.

Differently from apparently similar issues, I am not performing Transfer Learning, I am not using Dropout layers and I am not doing batch normalisation.

**Describe the expected behavior**
After training a LSTM Sequential model for univariate time series prediction on the training set in the format of tf.data.Dataset, the evaluation with model.evaluate(test_set), where test_set is a tf.data.Dataset structure, is expected to give the same result of tf.keras.losses.MSE(y, y_hat) where y is the ground truth and y_hat are the values returned by model.predict(test_set)

**Standalone code to reproduce the issue**
```
import tensorflow as tf
import numpy as np
import datetime
from pandas_datareader import data;
from sklearn.model_selection import train_test_split

#get data
everSince = datetime.date(1980, 1, 1)
today = datetime.date(2020, 11, 16)
df = data.get_data_yahoo(""CORN"", start=everSince,
        end=today);

# extract only 'Close' column
df_close = df[['Close']]

#Convert to TFDataset
WINDOW_SIZE = 10
dataset = tf.data.Dataset.from_tensor_slices((df_close.values))
d = dataset.window(WINDOW_SIZE, shift=1, drop_remainder=True)
d2 = d.flat_map(lambda window: window.batch(WINDOW_SIZE))
len_ds = 0
for item in d2:
    len_ds +=1
d3 = d2.map(lambda window: (window[:-1], window[-1:]))
d_shuffled = d3.shuffle(buffer_size=len_ds, reshuffle_each_iteration=False)

#Split train/val/test
y_targets = np.array([ target.numpy() for _, target in iter(d_shuffled) ])
X_indices = np.arange(len(y_targets))

y_targets = y_targets.reshape((-1,))

#stratify array-like, default=None If not None, data is split in a stratified
#fashion, using this as the class labels.
X_train_indices, X_val_indices, y_train_targets, y_val_targets = train_test_split(
    X_indices, y_targets, test_size=0.15, stratify=None, random_state=53)

X_test_indices, X_val_indices, y_test_targets, y_val_targets = train_test_split(
    X_val_indices, y_val_targets, test_size=0.5, stratify=None, random_state=53)

def get_selected_dataset(ds, X_indices_np):
    # Make a tensor of type tf.int64 to match the one by Dataset.enumerate().
    X_indices_ts = tf.constant(X_indices_np, dtype=tf.int64)

    def is_index_in(index, rest):
        # Returns True if the specified index value is included in X_indices_ts.
        #
        # '==' compares the specified index value with each values in X_indices_ts.
        # The result is a boolean tensor, looks like [ False, True, ..., False ].
        # reduce_any() returns Ture if True is included in the specified tensor.
        return tf.math.reduce_any(index == X_indices_ts)

    def drop_index(index, rest):
        return rest

    # Dataset.enumerate() is similter to Python's enumerate().
    # The method adds indices to each elements. Then, the elements are filtered
    # by using the specified indices. Finally unnecessary indices are dropped.
    selected_ds = ds.enumerate().filter(is_index_in).map(drop_index)
    return selected_ds

splitted_train_ds = get_selected_dataset(d_shuffled, X_train_indices)
splitted_val_ds   = get_selected_dataset(d_shuffled, X_val_indices)
splitted_test_ds  = get_selected_dataset(d_shuffled, X_test_indices)


def create_model():
    MODEL_ARCH = [
        tf.keras.layers.GRU(50, return_sequences=True, input_shape=( WINDOW_SIZE-1, 1)),
        tf.keras.layers.GRU(50,),
        tf.keras.layers.Dense(10, activation='tanh'),
        tf.keras.layers.Dense(1, activation='tanh'),
        tf.keras.layers.Lambda(lambda x: x*100)

    ]
    model = tf.keras.models.Sequential(MODEL_ARCH)
    return model


model = create_model()
LR = 1e-3
optimizer = tf.keras.optimizers.Adagrad(lr=LR)
model.compile(loss='mse', optimizer=optimizer)

history = model.fit(splitted_train_ds.batch(32), epochs=5,
    validation_data=splitted_val_ds.batch(32), batch_size=32)
model_err = model.evaluate(splitted_test_ds.batch(1), verbose=2)
y_hat = model.predict(splitted_test_ds.batch(1))
y_hat = y_hat.reshape((-1,))
print(""model.evaluate(): "", model_err )
print(""tf.keras.losses.MSE: "", tf.keras.losses.MSE(y_test_targets, y_hat).numpy())

```

link to Colab/Jupyter/any notebook:
https://colab.research.google.com/drive/1PFGXNpAn2NC53LR9vK40lTO0Fw-dFnZK?usp=sharing


"
44936,Performance issue with 3070,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.10
- TensorFlow installed from (source or binary): pip install tf-nightly-gpu
- TensorFlow version (use command below): tf-nightly-gpu==2.5.0.dev20201117
- Python version: 3.8.5
- CUDA/cuDNN version: CUDA 11.1.0 / cuDNN 8.0.4
- GPU model and memory: 3070 driver 455.38

Hi, 

I recently bought an RTX 3070 and, after some struggling I managed to install tf-nightly-gpu with all dependencies (following issue #43947), but the performances compared to my previous 1050 are way worse.

Is this something relating CUDA and/or NVIDIA drivers (for which I must just wait) or there is something I need to do?

I also noticed that, in nvidia-smi, the percentage of Volatile GPU-Util is very low
"
44935,tf.TensorArray not working,"
**System information**
tf version- 2.3
system - colab

```
@tf.function
def blah():
  stackin=tf.TensorArray(tf.float32,size=1,dynamic_size=True)
  i=tf.Variable(0,tf.float32)
  for i,(x,y) in test.take(10).enumerate():
    if True:
      y_=model(tf.expand_dims(x,axis=0))
      y_=tf.squeeze(y_,axis=0)
    else :
      y_=model(x)
    stackin.write(i,y_)
```
on running
```
TypeError: in user code:

    <ipython-input-146-3e5e999f0677>:11 blah  *
        stackin.write(i,y_)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/tf_should_use.py:247 wrapped  **
        return _add_should_use_warning(fn(*args, **kwargs),
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/tensor_array_ops.py:1159 write
        return self._implementation.write(index, value, name=name)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/tensor_array_ops.py:543 write
        name=name)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/list_ops.py:166 tensor_list_set_item
        index >= input_list_size,
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_math_ops.py:4076 greater_equal
        ""GreaterEqual"", x=x, y=y, name=name)
    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:506 _apply_op_helper
        inferred_from[input_arg.type_attr]))

    TypeError: Input 'y' of 'GreaterEqual' Op has type int32 that does not match type int64 of argument 'x'.
```"
44933,Dataset.unbatch() sets cardinality to -2 when batch remainder is not explicitly dropped,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): windows 10
- TensorFlow installed from (source or binary): pip
- TensorFlow version (use command below): 2.3.1
- Python version: 3.8.5


**Describe the current behavior**
Using `tf.data.experimental.cardinality()` yields `-2` (unknown), when batching (without explicitly dropping the remainder) and unbatching a dataset.

**Describe the expected behavior**
`tf.data.experimental.cardinality()` yields the same result as `len(list(tf.data.Dataset.as_numpy_iterator()))`.

**Standalone code to reproduce the issue**

```python
    import tensorflow as tf

    print(tf.version.VERSION)  # 2.3.1
    ds = tf.data.Dataset.range(10)  # shape=()
    ds = ds.batch(2)  # shape=(2,)
    print(tf.data.experimental.cardinality(ds))  # 5
    ds = ds.unbatch()  # shape=()
    print(len(list(ds.as_numpy_iterator()))) # 10
    print(tf.data.experimental.cardinality(ds))  # Should be 10, but is -2 (unknown)
```

**Other info / logs**
The issue does not occur (anymore), when using `drop_remainder=True` (see #39136)
"
44932,ERROR: tensorflow,"
**System information**
tf version =2.3.0-rc
System- colab-gpu

Reproduce error
`y=tf.TensorArray(tf.float32,size=1,dynamic_size=True)`
```
y.write(0,[[20,1,10]])
y.write(1,[[22,1,10]])
y.write(2,[[23,1,10]])
y.write(3,[[24,1,10]])
```

ERROR
```
ERROR:tensorflow:==================================
Object was never used (type <class 'tensorflow.python.ops.tensor_array_ops.TensorArray'>):
<tensorflow.python.ops.tensor_array_ops.TensorArray object at 0x7f6e013e9d68>
If you want to mark it as used call its ""mark_used()"" method.
It was originally created here:
  File ""/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py"", line 2718, in run_cell
    interactivity=interactivity, compiler=compiler, result=result)  File ""/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py"", line 2822, in run_ast_nodes
    if self.run_code(code, result):  File ""/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py"", line 2882, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)  File ""<ipython-input-38-cf79ca55289e>"", line 1, in <module>
    y.write(0,[[20,1,10]])  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/tf_should_use.py"", line 249, in wrapped
    error_in_function=error_in_function)
==================================
ERROR:tensorflow:==================================
Object was never used (type <class 'tensorflow.python.ops.tensor_array_ops.TensorArray'>):
<tensorflow.python.ops.tensor_array_ops.TensorArray object at 0x7f6e013e9d68>
If you want to mark it as used call its ""mark_used()"" method.
It was originally created here:
  File ""/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py"", line 2718, in run_cell
    interactivity=interactivity, compiler=compiler, result=result)  File ""/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py"", line 2822, in run_ast_nodes
    if self.run_code(code, result):  File ""/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py"", line 2882, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)  File ""<ipython-input-38-cf79ca55289e>"", line 2, in <module>
    y.write(1,[[22,1,10]])  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/tf_should_use.py"", line 249, in wrapped
    error_in_function=error_in_function)
==================================
ERROR:tensorflow:==================================
Object was never used (type <class 'tensorflow.python.ops.tensor_array_ops.TensorArray'>):
<tensorflow.python.ops.tensor_array_ops.TensorArray object at 0x7f6e013e9d68>
If you want to mark it as used call its ""mark_used()"" method.
It was originally created here:
  File ""/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py"", line 2718, in run_cell
    interactivity=interactivity, compiler=compiler, result=result)  File ""/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py"", line 2822, in run_ast_nodes
    if self.run_code(code, result):  File ""/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py"", line 2882, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)  File ""<ipython-input-38-cf79ca55289e>"", line 3, in <module>
    y.write(2,[[23,1,10]])  File ""/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/tf_should_use.py"", line 249, in wrapped
    error_in_function=error_in_function)
==================================
<tensorflow.python.ops.tensor_array_ops.TensorArray at 0x7f6e011c99e8>
```"
44931,Inconsistent code logic for Model.build,"In this function [`Model.build`](https://github.com/tensorflow/tensorflow/blob/b858de3779cab56d9788b0e87ff437d5dffbd942/tensorflow/python/keras/engine/training.py#L324), the code logic seems buggy. It says that it does not accept `dict` as the type of `input_shape`, and reject the `dict` type [here](https://github.com/tensorflow/tensorflow/blob/b858de3779cab56d9788b0e87ff437d5dffbd942/tensorflow/python/keras/engine/training.py#L359).

But then it has [further code](https://github.com/tensorflow/tensorflow/blob/fcc4b966f1265f466e82617020af93670141b009/tensorflow/python/keras/engine/training.py#L397) to check for the `dict` type, which makes me wonder that the purpose is to actually allow the usage of `dict` type...

I post this issue because I want to use `dict` type for the `input_shape` in my project. Right now, I have to override this function in my subclassed model and transform `dict` to `list` in a hard-coded order."
44929,UnimplementedError:  Fused conv implementation does not support grouped convolutions for now. 	,"I am using the FERN 2013 dataset from kaggle for the emojify project. The dataset consists of 48X48 grayscale images. 
When I go to train the model, I get an error as shown below. I am using tensorflow version 2.3.0

UnimplementedError:  Fused conv implementation does not support grouped convolutions for now.
	 [[node sequential_3/conv2d_6/Relu (defined at <ipython-input-16-994f59dc933f>:1) ]] [Op:__inference_train_function_3421]

Function call stack:
train_function



My code is as follows : 

import numpy as np
import tensorflow as tf
from keras.preprocessing.image import ImageDataGenerator


train_datagen = ImageDataGenerator(horizontal_flip=True)
training_set = train_datagen.flow_from_directory('train/', batch_size=32, class_mode='categorical')

test_datagen = ImageDataGenerator(horizontal_flip=True)
test_set = test_datagen.flow_from_directory('test/', batch_size=32, class_mode='categorical')



cnn = tf.keras.models.Sequential()

cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=(48, 48, 1)))

cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))

cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=(48, 48, 1)))

cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))


cnn.add(tf.keras.layers.Flatten())

cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))

cnn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))

cnn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

cnn.fit(x=training_set, validation_data=test_set, epochs=25)


"
44928,1.15: Can't write summaries in eager mode,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): v1.15.0-rc3-22-g590d6eef7e 1.15.0
- Python version: 3.7.6
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10.0
- GPU model and memory: N/A

**Describe the current behavior**

Writing summaries does not seem to be working. A 40 byte `*.tfevents.*.v2` is created. It does no grow when I call `scalar`. TensorBoard does not see any data in it.

**Describe the expected behavior**

The summary file should get the scalars I am trying to write.

**Standalone code to reproduce the issue**
```python
import tensorflow as tf

tf.enable_eager_execution()

from tensorflow.python.ops import summary_ops_v2

writer = summary_ops_v2.create_file_writer('.')
for i in range(10):
    with writer.as_default():
        summary_ops_v2.scalar('i', tf.constant(i), step=tf.constant(i))

writer.flush()
writer.close()
```

**Other info / logs**
No errors reported"
44926,bazel build TFLite C++ libtensorflowlite_gpu_delegate.so on OSX clang: error: unsupported option '--linkopt',"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): OSX 10.15.3
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): source
- TensorFlow version: v2.4.0-rc0
- Python version:
- Installed using virtualenv? pip? conda?:
- Bazel version (if compiling from source): bazel 3.1.0
- GCC/Compiler version (if compiling from source):
#### clang --version
```
clang version 9.0.0 (tags/RELEASE_900/final)
Target: x86_64-apple-darwin19.3.0
Thread model: posix
InstalledDir: /usr/local/opt/llvm/bin
```
#### gcc --version
```
Configured with: --prefix=/Applications/Xcode.app/Contents/Developer/usr --with-gxx-include-dir=/Applications/Xcode.app/Contents/Developer/Platforms/MacOSX.platform/Developer/SDKs/MacOSX.sdk/usr/include/c++/4.2.1
Apple clang version 11.0.0 (clang-1100.0.33.17)
Target: x86_64-apple-darwin19.3.0
Thread model: posix
InstalledDir: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin
```
- CUDA/cuDNN version: n/a
- GPU model and memory: n/a



**Describe the problem**
```
clang: error: unsupported option '--linkopt'
```

**Provide the exact sequence of commands / steps that you executed before running into the problem**
```
bazel build --verbose_failures -c opt --config android_arm64 --copt -Os --copt -DTFLITE_GPU_BINARY_RELEASE --copt --linkopt -s --strip never //tensorflow/lite/delegates/gpu:libtensorflowlite_gpu_delegate.so
```

**Any other info / logs**
```
✗ bazel build --verbose_failures -c opt --config android_arm64 --copt -Os --copt -DTFLITE_GPU_BINARY_RELEASE --copt --linkopt -s --strip never //tensorflow/lite/delegates/gpu:libtensorflowlite_gpu_delegate.so
INFO: Options provided by the client:
  Inherited 'common' options: --isatty=1 --terminal_columns=308
INFO: Reading rc options for 'build' from /Users/corey/Desktop/tensorflow/.bazelrc:
  Inherited 'common' options: --experimental_repo_remote_exec
INFO: Reading rc options for 'build' from /Users/corey/Desktop/tensorflow/.bazelrc:
  'build' options: --apple_platform_type=macos --define framework_shared_object=true --define open_source_build=true --java_toolchain=//third_party/toolchains/java:tf_java_toolchain --host_java_toolchain=//third_party/toolchains/java:tf_java_toolchain --define=tensorflow_enable_mlir_generated_gpu_kernels=0 --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --noincompatible_prohibit_aapt1 --enable_platform_specific_config --config=short_logs --config=v2
INFO: Reading rc options for 'build' from /Users/corey/Desktop/tensorflow/.tf_configure.bazelrc:
  'build' options: --action_env PYTHON_BIN_PATH=/Users/corey/.pyenv/versions/3.7.3/bin/python3 --action_env PYTHON_LIB_PATH=/Users/corey/.pyenv/versions/3.7.3/lib/python3.7/site-packages --python_path=/Users/corey/.pyenv/versions/3.7.3/bin/python3 --config=xla --action_env ANDROID_NDK_HOME=/Users/corey/library/Android/sdk/ndk-bundle --action_env ANDROID_NDK_API_LEVEL=21 --action_env ANDROID_BUILD_TOOLS_VERSION=29.0.3 --action_env ANDROID_SDK_API_LEVEL=29 --action_env ANDROID_SDK_HOME=/Users/corey/library/Android/sdk --action_env TF_CONFIGURE_IOS=0
INFO: Found applicable config definition build:short_logs in file /Users/corey/Desktop/tensorflow/.bazelrc: --output_filter=DONT_MATCH_ANYTHING
INFO: Found applicable config definition build:v2 in file /Users/corey/Desktop/tensorflow/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1
INFO: Found applicable config definition build:xla in file /Users/corey/Desktop/tensorflow/.bazelrc: --define=with_xla_support=true
INFO: Found applicable config definition build:android_arm64 in file /Users/corey/Desktop/tensorflow/.bazelrc: --config=android --cpu=arm64-v8a --fat_apk_cpu=arm64-v8a
INFO: Found applicable config definition build:android in file /Users/corey/Desktop/tensorflow/.bazelrc: --crosstool_top=//external:android/crosstool --host_crosstool_top=@bazel_tools//tools/cpp:toolchain --noenable_platform_specific_config --copt=-w --cxxopt=-std=c++14 --host_cxxopt=-std=c++14
INFO: Analyzed target //tensorflow/lite/delegates/gpu:libtensorflowlite_gpu_delegate.so (0 packages loaded, 0 targets configured).
INFO: Found 1 target...
SUBCOMMAND: # //tensorflow/lite/delegates/gpu/gl:api2 [action 'Compiling tensorflow/lite/delegates/gpu/gl/api2.cc', configuration: 7ab3a9e96e211481cebfba359b7531e15ff9d0e0380f290f06ff67087303939c]
(cd /private/var/tmp/_bazel_corey/6bb215c8674322829f14595e4a3d366c/execroot/org_tensorflow && \
  exec env - \
    ANDROID_BUILD_TOOLS_VERSION=29.0.3 \
    ANDROID_NDK_API_LEVEL=21 \
    ANDROID_NDK_HOME=/Users/corey/library/Android/sdk/ndk-bundle \
    ANDROID_SDK_API_LEVEL=29 \
    ANDROID_SDK_HOME=/Users/corey/library/Android/sdk \
    PATH=/Users/corey/.pub-cache/bin:/Users/corey/Workspace/depot_tools:/usr/local/opt/llvm/bin:/Users/corey/.rbenv/shims:/Users/corey/Library/Android/sdk/platform-tools:/Users/corey/Library/Android/sdk/tools:/Users/corey/.fastlane/bin:/Users/corey/.local/bin:/Library/Frameworks/GStreamer.framework/Versions/Current/bin/:/Users/corey/.poetry/bin:/Users/corey/Library/Android/sdk/tools/bin/:/Applications/Postgres.app/Contents/Versions/10/bin:/Users/corey/.pyenv/shims:/usr/local/bin:/Users/corey/local/bin:/Users/corey/.npm-global/node/bin:/Users/corey/.npm-global/bin:/Users/corey/.poetry/bin:/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin:/Users/corey/.ebcli-virtual-env/executables:/Users/corey/.pub-cache/bin:/Users/corey/Workspace/depot_tools:/usr/local/opt/llvm/bin:/Users/corey/Downloads/google-cloud-sdk/bin:/Users/corey/.rbenv/shims:/Users/corey/Library/Android/sdk/platform-tools:/Users/corey/Library/Android/sdk/tools:/Users/corey/.fastlane/bin:/Users/corey/.local/bin:/Library/Frameworks/GStreamer.framework/Versions/Current/bin/:/Users/corey/.poetry/bin:/Users/corey/Library/Android/sdk/tools/bin/:/Applications/Postgres.app/Contents/Versions/10/bin:/Users/corey/.pyenv/shims:/Users/corey/local/bin:/Users/corey/.npm-global/node/bin:/Users/corey/.npm-global/bin:/Users/corey/flutter/bin:/Users/corey/bin:/Users/corey/flutter/bin:/Users/corey/bin \
    PWD=/proc/self/cwd \
    PYTHON_BIN_PATH=/Users/corey/.pyenv/versions/3.7.3/bin/python3 \
    PYTHON_LIB_PATH=/Users/corey/.pyenv/versions/3.7.3/lib/python3.7/site-packages \
    TF2_BEHAVIOR=1 \
    TF_CONFIGURE_IOS=0 \
  external/androidndk/ndk/toolchains/llvm/prebuilt/darwin-x86_64/bin/clang -gcc-toolchain external/androidndk/ndk/toolchains/aarch64-linux-android-4.9/prebuilt/darwin-x86_64 -target aarch64-none-linux-android -fpic -isystemexternal/androidndk/ndk/sysroot/usr/include/aarch64-linux-android '-D__ANDROID_API__=21' -no-canonical-prefixes -Wno-invalid-command-line-argument -Wno-unused-command-line-argument -funwind-tables -fstack-protector-strong -fno-addrsig '-Werror=return-type' '-Werror=int-to-pointer-cast' '-Werror=pointer-to-int-cast' '-Werror=implicit-function-declaration' -O2 -g -DNDEBUG -MD -MF bazel-out/arm64-v8a-opt/bin/tensorflow/lite/delegates/gpu/gl/_objs/api2/api2.pic.d '-frandom-seed=bazel-out/arm64-v8a-opt/bin/tensorflow/lite/delegates/gpu/gl/_objs/api2/api2.pic.o' -fPIC -DVK_NO_PROTOTYPES -D__CLANG_SUPPORT_DYN_ANNOTATION__ -iquote . -iquote bazel-out/arm64-v8a-opt/bin -iquote external/com_google_absl -iquote bazel-out/arm64-v8a-opt/bin/external/com_google_absl -iquote external/FP16 -iquote bazel-out/arm64-v8a-opt/bin/external/FP16 -iquote external/opencl_headers -iquote bazel-out/arm64-v8a-opt/bin/external/opencl_headers -iquote external/vulkan_headers -iquote bazel-out/arm64-v8a-opt/bin/external/vulkan_headers -Ibazel-out/arm64-v8a-opt/bin/external/FP16/_virtual_includes/FP16 -isystem external/FP16/include -isystem bazel-out/arm64-v8a-opt/bin/external/FP16/include -isystem external/opencl_headers -isystem bazel-out/arm64-v8a-opt/bin/external/opencl_headers -isystem external/vulkan_headers/include -isystem bazel-out/arm64-v8a-opt/bin/external/vulkan_headers/include -w -Os -DTFLITE_GPU_BINARY_RELEASE --linkopt '-std=c++14' '--sysroot=external/androidndk/ndk/platforms/android-21/arch-arm64' -isystem external/androidndk/ndk/sources/cxx-stl/llvm-libc++/include -isystem external/androidndk/ndk/sources/cxx-stl/llvm-libc++abi/include -isystem external/androidndk/ndk/sources/android/support/include -isystemexternal/androidndk/ndk/sysroot/usr/include -c tensorflow/lite/delegates/gpu/gl/api2.cc -o bazel-out/arm64-v8a-opt/bin/tensorflow/lite/delegates/gpu/gl/_objs/api2/api2.pic.o)
SUBCOMMAND: # @ruy//ruy:system_aligned_alloc [action 'Compiling external/ruy/ruy/system_aligned_alloc.cc', configuration: 7ab3a9e96e211481cebfba359b7531e15ff9d0e0380f290f06ff67087303939c]
(cd /private/var/tmp/_bazel_corey/6bb215c8674322829f14595e4a3d366c/execroot/org_tensorflow && \
  exec env - \
    ANDROID_BUILD_TOOLS_VERSION=29.0.3 \
    ANDROID_NDK_API_LEVEL=21 \
    ANDROID_NDK_HOME=/Users/corey/library/Android/sdk/ndk-bundle \
    ANDROID_SDK_API_LEVEL=29 \
    ANDROID_SDK_HOME=/Users/corey/library/Android/sdk \
    PATH=/Users/corey/.pub-cache/bin:/Users/corey/Workspace/depot_tools:/usr/local/opt/llvm/bin:/Users/corey/.rbenv/shims:/Users/corey/Library/Android/sdk/platform-tools:/Users/corey/Library/Android/sdk/tools:/Users/corey/.fastlane/bin:/Users/corey/.local/bin:/Library/Frameworks/GStreamer.framework/Versions/Current/bin/:/Users/corey/.poetry/bin:/Users/corey/Library/Android/sdk/tools/bin/:/Applications/Postgres.app/Contents/Versions/10/bin:/Users/corey/.pyenv/shims:/usr/local/bin:/Users/corey/local/bin:/Users/corey/.npm-global/node/bin:/Users/corey/.npm-global/bin:/Users/corey/.poetry/bin:/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin:/Users/corey/.ebcli-virtual-env/executables:/Users/corey/.pub-cache/bin:/Users/corey/Workspace/depot_tools:/usr/local/opt/llvm/bin:/Users/corey/Downloads/google-cloud-sdk/bin:/Users/corey/.rbenv/shims:/Users/corey/Library/Android/sdk/platform-tools:/Users/corey/Library/Android/sdk/tools:/Users/corey/.fastlane/bin:/Users/corey/.local/bin:/Library/Frameworks/GStreamer.framework/Versions/Current/bin/:/Users/corey/.poetry/bin:/Users/corey/Library/Android/sdk/tools/bin/:/Applications/Postgres.app/Contents/Versions/10/bin:/Users/corey/.pyenv/shims:/Users/corey/local/bin:/Users/corey/.npm-global/node/bin:/Users/corey/.npm-global/bin:/Users/corey/flutter/bin:/Users/corey/bin:/Users/corey/flutter/bin:/Users/corey/bin \
    PWD=/proc/self/cwd \
    PYTHON_BIN_PATH=/Users/corey/.pyenv/versions/3.7.3/bin/python3 \
    PYTHON_LIB_PATH=/Users/corey/.pyenv/versions/3.7.3/lib/python3.7/site-packages \
    TF2_BEHAVIOR=1 \
    TF_CONFIGURE_IOS=0 \
  external/androidndk/ndk/toolchains/llvm/prebuilt/darwin-x86_64/bin/clang -gcc-toolchain external/androidndk/ndk/toolchains/aarch64-linux-android-4.9/prebuilt/darwin-x86_64 -target aarch64-none-linux-android -fpic -isystemexternal/androidndk/ndk/sysroot/usr/include/aarch64-linux-android '-D__ANDROID_API__=21' -no-canonical-prefixes -Wno-invalid-command-line-argument -Wno-unused-command-line-argument -funwind-tables -fstack-protector-strong -fno-addrsig '-Werror=return-type' '-Werror=int-to-pointer-cast' '-Werror=pointer-to-int-cast' '-Werror=implicit-function-declaration' -O2 -g -DNDEBUG -MD -MF bazel-out/arm64-v8a-opt/bin/external/ruy/ruy/_objs/system_aligned_alloc/system_aligned_alloc.pic.d '-frandom-seed=bazel-out/arm64-v8a-opt/bin/external/ruy/ruy/_objs/system_aligned_alloc/system_aligned_alloc.pic.o' -fPIC -iquote external/ruy -iquote bazel-out/arm64-v8a-opt/bin/external/ruy -w -Os -DTFLITE_GPU_BINARY_RELEASE --linkopt '-std=c++14' -Wall -Wextra -Wc++14-compat -Wundef -O3 '--sysroot=external/androidndk/ndk/platforms/android-21/arch-arm64' -isystem external/androidndk/ndk/sources/cxx-stl/llvm-libc++/include -isystem external/androidndk/ndk/sources/cxx-stl/llvm-libc++abi/include -isystem external/androidndk/ndk/sources/android/support/include -isystemexternal/androidndk/ndk/sysroot/usr/include -c external/ruy/ruy/system_aligned_alloc.cc -o bazel-out/arm64-v8a-opt/bin/external/ruy/ruy/_objs/system_aligned_alloc/system_aligned_alloc.pic.o)
SUBCOMMAND: # //tensorflow/lite/delegates/gpu:delegate [action 'Compiling tensorflow/lite/delegates/gpu/delegate.cc', configuration: 7ab3a9e96e211481cebfba359b7531e15ff9d0e0380f290f06ff67087303939c]
(cd /private/var/tmp/_bazel_corey/6bb215c8674322829f14595e4a3d366c/execroot/org_tensorflow && \
  exec env - \
    ANDROID_BUILD_TOOLS_VERSION=29.0.3 \
    ANDROID_NDK_API_LEVEL=21 \
    ANDROID_NDK_HOME=/Users/corey/library/Android/sdk/ndk-bundle \
    ANDROID_SDK_API_LEVEL=29 \
    ANDROID_SDK_HOME=/Users/corey/library/Android/sdk \
    PATH=/Users/corey/.pub-cache/bin:/Users/corey/Workspace/depot_tools:/usr/local/opt/llvm/bin:/Users/corey/.rbenv/shims:/Users/corey/Library/Android/sdk/platform-tools:/Users/corey/Library/Android/sdk/tools:/Users/corey/.fastlane/bin:/Users/corey/.local/bin:/Library/Frameworks/GStreamer.framework/Versions/Current/bin/:/Users/corey/.poetry/bin:/Users/corey/Library/Android/sdk/tools/bin/:/Applications/Postgres.app/Contents/Versions/10/bin:/Users/corey/.pyenv/shims:/usr/local/bin:/Users/corey/local/bin:/Users/corey/.npm-global/node/bin:/Users/corey/.npm-global/bin:/Users/corey/.poetry/bin:/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin:/Users/corey/.ebcli-virtual-env/executables:/Users/corey/.pub-cache/bin:/Users/corey/Workspace/depot_tools:/usr/local/opt/llvm/bin:/Users/corey/Downloads/google-cloud-sdk/bin:/Users/corey/.rbenv/shims:/Users/corey/Library/Android/sdk/platform-tools:/Users/corey/Library/Android/sdk/tools:/Users/corey/.fastlane/bin:/Users/corey/.local/bin:/Library/Frameworks/GStreamer.framework/Versions/Current/bin/:/Users/corey/.poetry/bin:/Users/corey/Library/Android/sdk/tools/bin/:/Applications/Postgres.app/Contents/Versions/10/bin:/Users/corey/.pyenv/shims:/Users/corey/local/bin:/Users/corey/.npm-global/node/bin:/Users/corey/.npm-global/bin:/Users/corey/flutter/bin:/Users/corey/bin:/Users/corey/flutter/bin:/Users/corey/bin \
    PWD=/proc/self/cwd \
    PYTHON_BIN_PATH=/Users/corey/.pyenv/versions/3.7.3/bin/python3 \
    PYTHON_LIB_PATH=/Users/corey/.pyenv/versions/3.7.3/lib/python3.7/site-packages \
    TF2_BEHAVIOR=1 \
    TF_CONFIGURE_IOS=0 \
  external/androidndk/ndk/toolchains/llvm/prebuilt/darwin-x86_64/bin/clang -gcc-toolchain external/androidndk/ndk/toolchains/aarch64-linux-android-4.9/prebuilt/darwin-x86_64 -target aarch64-none-linux-android -fpic -isystemexternal/androidndk/ndk/sysroot/usr/include/aarch64-linux-android '-D__ANDROID_API__=21' -no-canonical-prefixes -Wno-invalid-command-line-argument -Wno-unused-command-line-argument -funwind-tables -fstack-protector-strong -fno-addrsig '-Werror=return-type' '-Werror=int-to-pointer-cast' '-Werror=pointer-to-int-cast' '-Werror=implicit-function-declaration' -O2 -g -DNDEBUG -MD -MF bazel-out/arm64-v8a-opt/bin/tensorflow/lite/delegates/gpu/_objs/delegate/delegate.pic.d '-frandom-seed=bazel-out/arm64-v8a-opt/bin/tensorflow/lite/delegates/gpu/_objs/delegate/delegate.pic.o' -fPIC -DEGL_EGLEXT_PROTOTYPES -DVK_NO_PROTOTYPES -D__CLANG_SUPPORT_DYN_ANNOTATION__ -DTFLITE_WITH_RUY -DEIGEN_MPL2_ONLY '-DEIGEN_MAX_ALIGN_BYTES=64' '-DEIGEN_HAS_TYPE_TRAITS=0' -iquote . -iquote bazel-out/arm64-v8a-opt/bin -iquote external/com_google_absl -iquote bazel-out/arm64-v8a-opt/bin/external/com_google_absl -iquote external/FP16 -iquote bazel-out/arm64-v8a-opt/bin/external/FP16 -iquote external/opencl_headers -iquote bazel-out/arm64-v8a-opt/bin/external/opencl_headers -iquote external/vulkan_headers -iquote bazel-out/arm64-v8a-opt/bin/external/vulkan_headers -iquote external/flatbuffers -iquote bazel-out/arm64-v8a-opt/bin/external/flatbuffers -iquote external/farmhash_archive -iquote bazel-out/arm64-v8a-opt/bin/external/farmhash_archive -iquote external/gemmlowp -iquote bazel-out/arm64-v8a-opt/bin/external/gemmlowp -iquote external/eigen_archive -iquote bazel-out/arm64-v8a-opt/bin/external/eigen_archive -iquote external/ruy -iquote bazel-out/arm64-v8a-opt/bin/external/ruy -iquote external/cpuinfo -iquote bazel-out/arm64-v8a-opt/bin/external/cpuinfo -iquote external/clog -iquote bazel-out/arm64-v8a-opt/bin/external/clog -Ibazel-out/arm64-v8a-opt/bin/external/FP16/_virtual_includes/FP16 -Ibazel-out/arm64-v8a-opt/bin/external/flatbuffers/_virtual_includes/runtime_cc -Ibazel-out/arm64-v8a-opt/bin/external/flatbuffers/_virtual_includes/flatbuffers -Ibazel-out/arm64-v8a-opt/bin/external/flatbuffers/src/_virtual_includes/flatbuffers -Ibazel-out/arm64-v8a-opt/bin/external/clog/_virtual_includes/clog -isystem external/FP16/include -isystem bazel-out/arm64-v8a-opt/bin/external/FP16/include -isystem external/opencl_headers -isystem bazel-out/arm64-v8a-opt/bin/external/opencl_headers -isystem external/vulkan_headers/include -isystem bazel-out/arm64-v8a-opt/bin/external/vulkan_headers/include -isystem tensorflow/lite/delegates/gpu/cl -isystem bazel-out/arm64-v8a-opt/bin/tensorflow/lite/delegates/gpu/cl -isystem external/farmhash_archive/src -isystem bazel-out/arm64-v8a-opt/bin/external/farmhash_archive/src -isystem external/eigen_archive -isystem bazel-out/arm64-v8a-opt/bin/external/eigen_archive -isystem tensorflow/lite/schema -isystem bazel-out/arm64-v8a-opt/bin/tensorflow/lite/schema -w -Os -DTFLITE_GPU_BINARY_RELEASE --linkopt '-std=c++14' '--sysroot=external/androidndk/ndk/platforms/android-21/arch-arm64' -isystem external/androidndk/ndk/sources/cxx-stl/llvm-libc++/include -isystem external/androidndk/ndk/sources/cxx-stl/llvm-libc++abi/include -isystem external/androidndk/ndk/sources/android/support/include -isystemexternal/androidndk/ndk/sysroot/usr/include -c tensorflow/lite/delegates/gpu/delegate.cc -o bazel-out/arm64-v8a-opt/bin/tensorflow/lite/delegates/gpu/_objs/delegate/delegate.pic.o)
SUBCOMMAND: # //tensorflow/lite/delegates/gpu/gl/compiler:preprocessor [action 'Compiling tensorflow/lite/delegates/gpu/gl/compiler/preprocessor.cc', configuration: 7ab3a9e96e211481cebfba359b7531e15ff9d0e0380f290f06ff67087303939c]
(cd /private/var/tmp/_bazel_corey/6bb215c8674322829f14595e4a3d366c/execroot/org_tensorflow && \
  exec env - \
    ANDROID_BUILD_TOOLS_VERSION=29.0.3 \
    ANDROID_NDK_API_LEVEL=21 \
    ANDROID_NDK_HOME=/Users/corey/library/Android/sdk/ndk-bundle \
    ANDROID_SDK_API_LEVEL=29 \
    ANDROID_SDK_HOME=/Users/corey/library/Android/sdk \
    PATH=/Users/corey/.pub-cache/bin:/Users/corey/Workspace/depot_tools:/usr/local/opt/llvm/bin:/Users/corey/.rbenv/shims:/Users/corey/Library/Android/sdk/platform-tools:/Users/corey/Library/Android/sdk/tools:/Users/corey/.fastlane/bin:/Users/corey/.local/bin:/Library/Frameworks/GStreamer.framework/Versions/Current/bin/:/Users/corey/.poetry/bin:/Users/corey/Library/Android/sdk/tools/bin/:/Applications/Postgres.app/Contents/Versions/10/bin:/Users/corey/.pyenv/shims:/usr/local/bin:/Users/corey/local/bin:/Users/corey/.npm-global/node/bin:/Users/corey/.npm-global/bin:/Users/corey/.poetry/bin:/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin:/Users/corey/.ebcli-virtual-env/executables:/Users/corey/.pub-cache/bin:/Users/corey/Workspace/depot_tools:/usr/local/opt/llvm/bin:/Users/corey/Downloads/google-cloud-sdk/bin:/Users/corey/.rbenv/shims:/Users/corey/Library/Android/sdk/platform-tools:/Users/corey/Library/Android/sdk/tools:/Users/corey/.fastlane/bin:/Users/corey/.local/bin:/Library/Frameworks/GStreamer.framework/Versions/Current/bin/:/Users/corey/.poetry/bin:/Users/corey/Library/Android/sdk/tools/bin/:/Applications/Postgres.app/Contents/Versions/10/bin:/Users/corey/.pyenv/shims:/Users/corey/local/bin:/Users/corey/.npm-global/node/bin:/Users/corey/.npm-global/bin:/Users/corey/flutter/bin:/Users/corey/bin:/Users/corey/flutter/bin:/Users/corey/bin \
    PWD=/proc/self/cwd \
    PYTHON_BIN_PATH=/Users/corey/.pyenv/versions/3.7.3/bin/python3 \
    PYTHON_LIB_PATH=/Users/corey/.pyenv/versions/3.7.3/lib/python3.7/site-packages \
    TF2_BEHAVIOR=1 \
    TF_CONFIGURE_IOS=0 \
  external/androidndk/ndk/toolchains/llvm/prebuilt/darwin-x86_64/bin/clang -gcc-toolchain external/androidndk/ndk/toolchains/aarch64-linux-android-4.9/prebuilt/darwin-x86_64 -target aarch64-none-linux-android -fpic -isystemexternal/androidndk/ndk/sysroot/usr/include/aarch64-linux-android '-D__ANDROID_API__=21' -no-canonical-prefixes -Wno-invalid-command-line-argument -Wno-unused-command-line-argument -funwind-tables -fstack-protector-strong -fno-addrsig '-Werror=return-type' '-Werror=int-to-pointer-cast' '-Werror=pointer-to-int-cast' '-Werror=implicit-function-declaration' -O2 -g -DNDEBUG -MD -MF bazel-out/arm64-v8a-opt/bin/tensorflow/lite/delegates/gpu/gl/compiler/_objs/preprocessor/preprocessor.pic.d '-frandom-seed=bazel-out/arm64-v8a-opt/bin/tensorflow/lite/delegates/gpu/gl/compiler/_objs/preprocessor/preprocessor.pic.o' -fPIC -D__CLANG_SUPPORT_DYN_ANNOTATION__ -iquote . -iquote bazel-out/arm64-v8a-opt/bin -iquote external/com_google_absl -iquote bazel-out/arm64-v8a-opt/bin/external/com_google_absl -w -Os -DTFLITE_GPU_BINARY_RELEASE --linkopt '-std=c++14' '--sysroot=external/androidndk/ndk/platforms/android-21/arch-arm64' -isystem external/androidndk/ndk/sources/cxx-stl/llvm-libc++/include -isystem external/androidndk/ndk/sources/cxx-stl/llvm-libc++abi/include -isystem external/androidndk/ndk/sources/android/support/include -isystemexternal/androidndk/ndk/sysroot/usr/include -c tensorflow/lite/delegates/gpu/gl/compiler/preprocessor.cc -o bazel-out/arm64-v8a-opt/bin/tensorflow/lite/delegates/gpu/gl/compiler/_objs/preprocessor/preprocessor.pic.o)
SUBCOMMAND: # //tensorflow/lite/delegates/gpu/gl/workgroups:ideal_workgroup_picker [action 'Compiling tensorflow/lite/delegates/gpu/gl/workgroups/ideal_workgroup_picker.cc', configuration: 7ab3a9e96e211481cebfba359b7531e15ff9d0e0380f290f06ff67087303939c]
(cd /private/var/tmp/_bazel_corey/6bb215c8674322829f14595e4a3d366c/execroot/org_tensorflow && \
  exec env - \
    ANDROID_BUILD_TOOLS_VERSION=29.0.3 \
    ANDROID_NDK_API_LEVEL=21 \
    ANDROID_NDK_HOME=/Users/corey/library/Android/sdk/ndk-bundle \
    ANDROID_SDK_API_LEVEL=29 \
    ANDROID_SDK_HOME=/Users/corey/library/Android/sdk \
    PATH=/Users/corey/.pub-cache/bin:/Users/corey/Workspace/depot_tools:/usr/local/opt/llvm/bin:/Users/corey/.rbenv/shims:/Users/corey/Library/Android/sdk/platform-tools:/Users/corey/Library/Android/sdk/tools:/Users/corey/.fastlane/bin:/Users/corey/.local/bin:/Library/Frameworks/GStreamer.framework/Versions/Current/bin/:/Users/corey/.poetry/bin:/Users/corey/Library/Android/sdk/tools/bin/:/Applications/Postgres.app/Contents/Versions/10/bin:/Users/corey/.pyenv/shims:/usr/local/bin:/Users/corey/local/bin:/Users/corey/.npm-global/node/bin:/Users/corey/.npm-global/bin:/Users/corey/.poetry/bin:/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin:/Users/corey/.ebcli-virtual-env/executables:/Users/corey/.pub-cache/bin:/Users/corey/Workspace/depot_tools:/usr/local/opt/llvm/bin:/Users/corey/Downloads/google-cloud-sdk/bin:/Users/corey/.rbenv/shims:/Users/corey/Library/Android/sdk/platform-tools:/Users/corey/Library/Android/sdk/tools:/Users/corey/.fastlane/bin:/Users/corey/.local/bin:/Library/Frameworks/GStreamer.framework/Versions/Current/bin/:/Users/corey/.poetry/bin:/Users/corey/Library/Android/sdk/tools/bin/:/Applications/Postgres.app/Contents/Versions/10/bin:/Users/corey/.pyenv/shims:/Users/corey/local/bin:/Users/corey/.npm-global/node/bin:/Users/corey/.npm-global/bin:/Users/corey/flutter/bin:/Users/corey/bin:/Users/corey/flutter/bin:/Users/corey/bin \
    PWD=/proc/self/cwd \
    PYTHON_BIN_PATH=/Users/corey/.pyenv/versions/3.7.3/bin/python3 \
    PYTHON_LIB_PATH=/Users/corey/.pyenv/versions/3.7.3/lib/python3.7/site-packages \
    TF2_BEHAVIOR=1 \
    TF_CONFIGURE_IOS=0 \
  external/androidndk/ndk/toolchains/llvm/prebuilt/darwin-x86_64/bin/clang -gcc-toolchain external/androidndk/ndk/toolchains/aarch64-linux-android-4.9/prebuilt/darwin-x86_64 -target aarch64-none-linux-android -fpic -isystemexternal/androidndk/ndk/sysroot/usr/include/aarch64-linux-android '-D__ANDROID_API__=21' -no-canonical-prefixes -Wno-invalid-command-line-argument -Wno-unused-command-line-argument -funwind-tables -fstack-protector-strong -fno-addrsig '-Werror=return-type' '-Werror=int-to-pointer-cast' '-Werror=pointer-to-int-cast' '-Werror=implicit-function-declaration' -O2 -g -DNDEBUG -MD -MF bazel-out/arm64-v8a-opt/bin/tensorflow/lite/delegates/gpu/gl/workgroups/_objs/ideal_workgroup_picker/ideal_workgroup_picker.pic.d '-frandom-seed=bazel-out/arm64-v8a-opt/bin/tensorflow/lite/delegates/gpu/gl/workgroups/_objs/ideal_workgroup_picker/ideal_workgroup_picker.pic.o' -fPIC -D__CLANG_SUPPORT_DYN_ANNOTATION__ -iquote . -iquote bazel-out/arm64-v8a-opt/bin -iquote external/com_google_absl -iquote bazel-out/arm64-v8a-opt/bin/external/com_google_absl -iquote external/FP16 -iquote bazel-out/arm64-v8a-opt/bin/external/FP16 -Ibazel-out/arm64-v8a-opt/bin/external/FP16/_virtual_includes/FP16 -isystem external/FP16/include -isystem bazel-out/arm64-v8a-opt/bin/external/FP16/include -w -Os -DTFLITE_GPU_BINARY_RELEASE --linkopt '-std=c++14' '--sysroot=external/androidndk/ndk/platforms/android-21/arch-arm64' -isystem external/androidndk/ndk/sources/cxx-stl/llvm-libc++/include -isystem external/androidndk/ndk/sources/cxx-stl/llvm-libc++abi/include -isystem external/androidndk/ndk/sources/android/support/include -isystemexternal/androidndk/ndk/sysroot/usr/include -c tensorflow/lite/delegates/gpu/gl/workgroups/ideal_workgroup_picker.cc -o bazel-out/arm64-v8a-opt/bin/tensorflow/lite/delegates/gpu/gl/workgroups/_objs/ideal_workgroup_picker/ideal_workgroup_picker.pic.o)
SUBCOMMAND: # //tensorflow/lite/delegates/gpu/gl/compiler:fuse_inline [action 'Compiling tensorflow/lite/delegates/gpu/gl/compiler/fuse_inline.cc', configuration: 7ab3a9e96e211481cebfba359b7531e15ff9d0e0380f290f06ff67087303939c]
(cd /private/var/tmp/_bazel_corey/6bb215c8674322829f14595e4a3d366c/execroot/org_tensorflow && \
  exec env - \
    ANDROID_BUILD_TOOLS_VERSION=29.0.3 \
    ANDROID_NDK_API_LEVEL=21 \
    ANDROID_NDK_HOME=/Users/corey/library/Android/sdk/ndk-bundle \
    ANDROID_SDK_API_LEVEL=29 \
    ANDROID_SDK_HOME=/Users/corey/library/Android/sdk \
    PATH=/Users/corey/.pub-cache/bin:/Users/corey/Workspace/depot_tools:/usr/local/opt/llvm/bin:/Users/corey/.rbenv/shims:/Users/corey/Library/Android/sdk/platform-tools:/Users/corey/Library/Android/sdk/tools:/Users/corey/.fastlane/bin:/Users/corey/.local/bin:/Library/Frameworks/GStreamer.framework/Versions/Current/bin/:/Users/corey/.poetry/bin:/Users/corey/Library/Android/sdk/tools/bin/:/Applications/Postgres.app/Contents/Versions/10/bin:/Users/corey/.pyenv/shims:/usr/local/bin:/Users/corey/local/bin:/Users/corey/.npm-global/node/bin:/Users/corey/.npm-global/bin:/Users/corey/.poetry/bin:/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin:/Users/corey/.ebcli-virtual-env/executables:/Users/corey/.pub-cache/bin:/Users/corey/Workspace/depot_tools:/usr/local/opt/llvm/bin:/Users/corey/Downloads/google-cloud-sdk/bin:/Users/corey/.rbenv/shims:/Users/corey/Library/Android/sdk/platform-tools:/Users/corey/Library/Android/sdk/tools:/Users/corey/.fastlane/bin:/Users/corey/.local/bin:/Library/Frameworks/GStreamer.framework/Versions/Current/bin/:/Users/corey/.poetry/bin:/Users/corey/Library/Android/sdk/tools/bin/:/Applications/Postgres.app/Contents/Versions/10/bin:/Users/corey/.pyenv/shims:/Users/corey/local/bin:/Users/corey/.npm-global/node/bin:/Users/corey/.npm-global/bin:/Users/corey/flutter/bin:/Users/corey/bin:/Users/corey/flutter/bin:/Users/corey/bin \
    PWD=/proc/self/cwd \
    PYTHON_BIN_PATH=/Users/corey/.pyenv/versions/3.7.3/bin/python3 \
    PYTHON_LIB_PATH=/Users/corey/.pyenv/versions/3.7.3/lib/python3.7/site-packages \
    TF2_BEHAVIOR=1 \
    TF_CONFIGURE_IOS=0 \
  external/androidndk/ndk/toolchains/llvm/prebuilt/darwin-x86_64/bin/clang -gcc-toolchain external/androidndk/ndk/toolchains/aarch64-linux-android-4.9/prebuilt/darwin-x86_64 -target aarch64-none-linux-android -fpic -isystemexternal/androidndk/ndk/sysroot/usr/include/aarch64-linux-android '-D__ANDROID_API__=21' -no-canonical-prefixes -Wno-invalid-command-line-argument -Wno-unused-command-line-argument -funwind-tables -fstack-protector-strong -fno-addrsig '-Werror=return-type' '-Werror=int-to-pointer-cast' '-Werror=pointer-to-int-cast' '-Werror=implicit-function-declaration' -O2 -g -DNDEBUG -MD -MF bazel-out/arm64-v8a-opt/bin/tensorflow/lite/delegates/gpu/gl/compiler/_objs/fuse_inline/fuse_inline.pic.d '-frandom-seed=bazel-out/arm64-v8a-opt/bin/tensorflow/lite/delegates/gpu/gl/compiler/_objs/fuse_inline/fuse_inline.pic.o' -fPIC -D__CLANG_SUPPORT_DYN_ANNOTATION__ -iquote . -iquote bazel-out/arm64-v8a-opt/bin -iquote external/com_google_absl -iquote bazel-out/arm64-v8a-opt/bin/external/com_google_absl -iquote external/FP16 -iquote bazel-out/arm64-v8a-opt/bin/external/FP16 -Ibazel-out/arm64-v8a-opt/bin/external/FP16/_virtual_includes/FP16 -isystem external/FP16/include -isystem bazel-out/arm64-v8a-opt/bin/external/FP16/include -w -Os -DTFLITE_GPU_BINARY_RELEASE --linkopt '-std=c++14' '--sysroot=external/androidndk/ndk/platforms/android-21/arch-arm64' -isystem external/androidndk/ndk/sources/cxx-stl/llvm-libc++/include -isystem external/androidndk/ndk/sources/cxx-stl/llvm-libc++abi/include -isystem external/androidndk/ndk/sources/android/support/include -isystemexternal/androidndk/ndk/sysroot/usr/include -c tensorflow/lite/delegates/gpu/gl/compiler/fuse_inline.cc -o bazel-out/arm64-v8a-opt/bin/tensorflow/lite/delegates/gpu/gl/compiler/_objs/fuse_inline/fuse_inline.pic.o)
SUBCOMMAND: # //tensorflow/lite/delegates/gpu/gl:runtime [action 'Compiling tensorflow/lite/delegates/gpu/gl/runtime.cc', configuration: 7ab3a9e96e211481cebfba359b7531e15ff9d0e0380f290f06ff67087303939c]
(cd /private/var/tmp/_bazel_corey/6bb215c8674322829f14595e4a3d366c/execroot/org_tensorflow && \
  exec env - \
    ANDROID_BUILD_TOOLS_VERSION=29.0.3 \
    ANDROID_NDK_API_LEVEL=21 \
    ANDROID_NDK_HOME=/Users/corey/library/Android/sdk/ndk-bundle \
    ANDROID_SDK_API_LEVEL=29 \
    ANDROID_SDK_HOME=/Users/corey/library/Android/sdk \
    PATH=/Users/corey/.pub-cache/bin:/Users/corey/Workspace/depot_tools:/usr/local/opt/llvm/bin:/Users/corey/.rbenv/shims:/Users/corey/Library/Android/sdk/platform-tools:/Users/corey/Library/Android/sdk/tools:/Users/corey/.fastlane/bin:/Users/corey/.local/bin:/Library/Frameworks/GStreamer.framework/Versions/Current/bin/:/Users/corey/.poetry/bin:/Users/corey/Library/Android/sdk/tools/bin/:/Applications/Postgres.app/Contents/Versions/10/bin:/Users/corey/.pyenv/shims:/usr/local/bin:/Users/corey/local/bin:/Users/corey/.npm-global/node/bin:/Users/corey/.npm-global/bin:/Users/corey/.poetry/bin:/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin:/Users/corey/.ebcli-virtual-env/executables:/Users/corey/.pub-cache/bin:/Users/corey/Workspace/depot_tools:/usr/local/opt/llvm/bin:/Users/corey/Downloads/google-cloud-sdk/bin:/Users/corey/.rbenv/shims:/Users/corey/Library/Android/sdk/platform-tools:/Users/corey/Library/Android/sdk/tools:/Users/corey/.fastlane/bin:/Users/corey/.local/bin:/Library/Frameworks/GStreamer.framework/Versions/Current/bin/:/Users/corey/.poetry/bin:/Users/corey/Library/Android/sdk/tools/bin/:/Applications/Postgres.app/Contents/Versions/10/bin:/Users/corey/.pyenv/shims:/Users/corey/local/bin:/Users/corey/.npm-global/node/bin:/Users/corey/.npm-global/bin:/Users/corey/flutter/bin:/Users/corey/bin:/Users/corey/flutter/bin:/Users/corey/bin \
    PWD=/proc/self/cwd \
    PYTHON_BIN_PATH=/Users/corey/.pyenv/versions/3.7.3/bin/python3 \
    PYTHON_LIB_PATH=/Users/corey/.pyenv/versions/3.7.3/lib/python3.7/site-packages \
    TF2_BEHAVIOR=1 \
    TF_CONFIGURE_IOS=0 \
  external/androidndk/ndk/toolchains/llvm/prebuilt/darwin-x86_64/bin/clang -gcc-toolchain external/androidndk/ndk/toolchains/aarch64-linux-android-4.9/prebuilt/darwin-x86_64 -target aarch64-none-linux-android -fpic -isystemexternal/androidndk/ndk/sysroot/usr/include/aarch64-linux-android '-D__ANDROID_API__=21' -no-canonical-prefixes -Wno-invalid-command-line-argument -Wno-unused-command-line-argument -funwind-tables -fstack-protector-strong -fno-addrsig '-Werror=return-type' '-Werror=int-to-pointer-cast' '-Werror=pointer-to-int-cast' '-Werror=implicit-function-declaration' -O2 -g -DNDEBUG -MD -MF bazel-out/arm64-v8a-opt/bin/tensorflow/lite/delegates/gpu/gl/_objs/runtime/runtime.pic.d '-frandom-seed=bazel-out/arm64-v8a-opt/bin/tensorflow/lite/delegates/gpu/gl/_objs/runtime/runtime.pic.o' -fPIC -D__CLANG_SUPPORT_DYN_ANNOTATION__ -iquote . -iquote bazel-out/arm64-v8a-opt/bin -iquote external/com_google_absl -iquote bazel-out/arm64-v8a-opt/bin/external/com_google_absl -iquote external/FP16 -iquote bazel-out/arm64-v8a-opt/bin/external/FP16 -Ibazel-out/arm64-v8a-opt/bin/external/FP16/_virtual_includes/FP16 -isystem external/FP16/include -isystem bazel-out/arm64-v8a-opt/bin/external/FP16/include -w -Os -DTFLITE_GPU_BINARY_RELEASE --linkopt '-std=c++14' '--sysroot=external/androidndk/ndk/platforms/android-21/arch-arm64' -isystem external/androidndk/ndk/sources/cxx-stl/llvm-libc++/include -isystem external/androidndk/ndk/sources/cxx-stl/llvm-libc++abi/include -isystem external/androidndk/ndk/sources/android/support/include -isystemexternal/androidndk/ndk/sysroot/usr/include -c tensorflow/lite/delegates/gpu/gl/runtime.cc -o bazel-out/arm64-v8a-opt/bin/tensorflow/lite/delegates/gpu/gl/_objs/runtime/runtime.pic.o)
SUBCOMMAND: # //tensorflow/lite/delegates/gpu/cl/kernels:converter [action 'Compiling tensorflow/lite/delegates/gpu/cl/kernels/converter.cc', configuration: 7ab3a9e96e211481cebfba359b7531e15ff9d0e0380f290f06ff67087303939c]
(cd /private/var/tmp/_bazel_corey/6bb215c8674322829f14595e4a3d366c/execroot/org_tensorflow && \
  exec env - \
    ANDROID_BUILD_TOOLS_VERSION=29.0.3 \
    ANDROID_NDK_API_LEVEL=21 \
    ANDROID_NDK_HOME=/Users/corey/library/Android/sdk/ndk-bundle \
    ANDROID_SDK_API_LEVEL=29 \
    ANDROID_SDK_HOME=/Users/corey/library/Android/sdk \
    PATH=/Users/corey/.pub-cache/bin:/Users/corey/Workspace/depot_tools:/usr/local/opt/llvm/bin:/Users/corey/.rbenv/shims:/Users/corey/Library/Android/sdk/platform-tools:/Users/corey/Library/Android/sdk/tools:/Users/corey/.fastlane/bin:/Users/corey/.local/bin:/Library/Frameworks/GStreamer.framework/Versions/Current/bin/:/Users/corey/.poetry/bin:/Users/corey/Library/Android/sdk/tools/bin/:/Applications/Postgres.app/Contents/Versions/10/bin:/Users/corey/.pyenv/shims:/usr/local/bin:/Users/corey/local/bin:/Users/corey/.npm-global/node/bin:/Users/corey/.npm-global/bin:/Users/corey/.poetry/bin:/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin:/Users/corey/.ebcli-virtual-env/executables:/Users/corey/.pub-cache/bin:/Users/corey/Workspace/depot_tools:/usr/local/opt/llvm/bin:/Users/corey/Downloads/google-cloud-sdk/bin:/Users/corey/.rbenv/shims:/Users/corey/Library/Android/sdk/platform-tools:/Users/corey/Library/Android/sdk/tools:/Users/corey/.fastlane/bin:/Users/corey/.local/bin:/Library/Frameworks/GStreamer.framework/Versions/Current/bin/:/Users/corey/.poetry/bin:/Users/corey/Library/Android/sdk/tools/bin/:/Applications/Postgres.app/Contents/Versions/10/bin:/Users/corey/.pyenv/shims:/Users/corey/local/bin:/Users/corey/.npm-global/node/bin:/Users/corey/.npm-global/bin:/Users/corey/flutter/bin:/Users/corey/bin:/Users/corey/flutter/bin:/Users/corey/bin \
    PWD=/proc/self/cwd \
    PYTHON_BIN_PATH=/Users/corey/.pyenv/versions/3.7.3/bin/python3 \
    PYTHON_LIB_PATH=/Users/corey/.pyenv/versions/3.7.3/lib/python3.7/site-packages \
    TF2_BEHAVIOR=1 \
    TF_CONFIGURE_IOS=0 \
  external/androidndk/ndk/toolchains/llvm/prebuilt/darwin-x86_64/bin/clang -gcc-toolchain external/androidndk/ndk/toolchains/aarch64-linux-android-4.9/prebuilt/darwin-x86_64 -target aarch64-none-linux-android -fpic -isystemexternal/androidndk/ndk/sysroot/usr/include/aarch64-linux-android '-D__ANDROID_API__=21' -no-canonical-prefixes -Wno-invalid-command-line-argument -Wno-unused-command-line-argument -funwind-tables -fstack-protector-strong -fno-addrsig '-Werror=return-type' '-Werror=int-to-pointer-cast' '-Werror=pointer-to-int-cast' '-Werror=implicit-function-declaration' -O2 -g -DNDEBUG -MD -MF bazel-out/arm64-v8a-opt/bin/tensorflow/lite/delegates/gpu/cl/kernels/_objs/converter/converter.pic.d '-frandom-seed=bazel-out/arm64-v8a-opt/bin/tensorflow/lite/delegates/gpu/cl/kernels/_objs/converter/converter.pic.o' -fPIC -D__CLANG_SUPPORT_DYN_ANNOTATION__ -DVK_NO_PROTOTYPES -iquote . -iquote bazel-out/arm64-v8a-opt/bin -iquote external/com_google_absl -iquote bazel-out/arm64-v8a-opt/bin/external/com_google_absl -iquote external/FP16 -iquote bazel-out/arm64-v8a-opt/bin/external/FP16 -iquote external/opencl_headers -iquote bazel-out/arm64-v8a-opt/bin/external/opencl_headers -iquote external/vulkan_headers -iquote bazel-out/arm64-v8a-opt/bin/external/vulkan_headers -iquote external/flatbuffers -iquote bazel-out/arm64-v8a-opt/bin/external/flatbuffers -iquote external/farmhash_archive -iquote bazel-out/arm64-v8a-opt/bin/external/farmhash_archive -Ibazel-out/arm64-v8a-opt/bin/external/FP16/_virtual_includes/FP16 -Ibazel-out/arm64-v8a-opt/bin/external/flatbuffers/_virtual_includes/runtime_cc -Ibazel-out/arm64-v8a-opt/bin/external/flatbuffers/_virtual_includes/flatbuffers -Ibazel-out/arm64-v8a-opt/bin/external/flatbuffers/src/_virtual_includes/flatbuffers -isystem external/FP16/include -isystem bazel-out/arm64-v8a-opt/bin/external/FP16/include -isystem external/opencl_headers -isystem bazel-out/arm64-v8a-opt/bin/external/opencl_headers -isystem external/vulkan_headers/include -isystem bazel-out/arm64-v8a-opt/bin/external/vulkan_headers/include -isystem tensorflow/lite/delegates/gpu/cl -isystem bazel-out/arm64-v8a-opt/bin/tensorflow/lite/delegates/gpu/cl -isystem external/farmhash_archive/src -isystem bazel-out/arm64-v8a-opt/bin/external/farmhash_archive/src -w -Os -DTFLITE_GPU_BINARY_RELEASE --linkopt '-std=c++14' '--sysroot=external/androidndk/ndk/platforms/android-21/arch-arm64' -isystem external/androidndk/ndk/sources/cxx-stl/llvm-libc++/include -isystem external/androidndk/ndk/sources/cxx-stl/llvm-libc++abi/include -isystem external/androidndk/ndk/sources/android/support/include -isystemexternal/androidndk/ndk/sysroot/usr/include -c tensorflow/lite/delegates/gpu/cl/kernels/converter.cc -o bazel-out/arm64-v8a-opt/bin/tensorflow/lite/delegates/gpu/cl/kernels/_objs/converter/converter.pic.o)
ERROR: /Users/corey/Desktop/tensorflow/tensorflow/lite/delegates/gpu/gl/BUILD:48:1: C++ compilation of rule '//tensorflow/lite/delegates/gpu/gl:api2' failed (Exit 1): clang failed: error executing command 
  (cd /private/var/tmp/_bazel_corey/6bb215c8674322829f14595e4a3d366c/execroot/org_tensorflow && \
  exec env - \
    ANDROID_BUILD_TOOLS_VERSION=29.0.3 \
    ANDROID_NDK_API_LEVEL=21 \
    ANDROID_NDK_HOME=/Users/corey/library/Android/sdk/ndk-bundle \
    ANDROID_SDK_API_LEVEL=29 \
    ANDROID_SDK_HOME=/Users/corey/library/Android/sdk \
    PATH=/Users/corey/.pub-cache/bin:/Users/corey/Workspace/depot_tools:/usr/local/opt/llvm/bin:/Users/corey/.rbenv/shims:/Users/corey/Library/Android/sdk/platform-tools:/Users/corey/Library/Android/sdk/tools:/Users/corey/.fastlane/bin:/Users/corey/.local/bin:/Library/Frameworks/GStreamer.framework/Versions/Current/bin/:/Users/corey/.poetry/bin:/Users/corey/Library/Android/sdk/tools/bin/:/Applications/Postgres.app/Contents/Versions/10/bin:/Users/corey/.pyenv/shims:/usr/local/bin:/Users/corey/local/bin:/Users/corey/.npm-global/node/bin:/Users/corey/.npm-global/bin:/Users/corey/.poetry/bin:/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin:/Users/corey/.ebcli-virtual-env/executables:/Users/corey/.pub-cache/bin:/Users/corey/Workspace/depot_tools:/usr/local/opt/llvm/bin:/Users/corey/Downloads/google-cloud-sdk/bin:/Users/corey/.rbenv/shims:/Users/corey/Library/Android/sdk/platform-tools:/Users/corey/Library/Android/sdk/tools:/Users/corey/.fastlane/bin:/Users/corey/.local/bin:/Library/Frameworks/GStreamer.framework/Versions/Current/bin/:/Users/corey/.poetry/bin:/Users/corey/Library/Android/sdk/tools/bin/:/Applications/Postgres.app/Contents/Versions/10/bin:/Users/corey/.pyenv/shims:/Users/corey/local/bin:/Users/corey/.npm-global/node/bin:/Users/corey/.npm-global/bin:/Users/corey/flutter/bin:/Users/corey/bin:/Users/corey/flutter/bin:/Users/corey/bin \
    PWD=/proc/self/cwd \
    PYTHON_BIN_PATH=/Users/corey/.pyenv/versions/3.7.3/bin/python3 \
    PYTHON_LIB_PATH=/Users/corey/.pyenv/versions/3.7.3/lib/python3.7/site-packages \
    TF2_BEHAVIOR=1 \
    TF_CONFIGURE_IOS=0 \
  external/androidndk/ndk/toolchains/llvm/prebuilt/darwin-x86_64/bin/clang -gcc-toolchain external/androidndk/ndk/toolchains/aarch64-linux-android-4.9/prebuilt/darwin-x86_64 -target aarch64-none-linux-android -fpic -isystemexternal/androidndk/ndk/sysroot/usr/include/aarch64-linux-android '-D__ANDROID_API__=21' -no-canonical-prefixes -Wno-invalid-command-line-argument -Wno-unused-command-line-argument -funwind-tables -fstack-protector-strong -fno-addrsig '-Werror=return-type' '-Werror=int-to-pointer-cast' '-Werror=pointer-to-int-cast' '-Werror=implicit-function-declaration' -O2 -g -DNDEBUG -MD -MF bazel-out/arm64-v8a-opt/bin/tensorflow/lite/delegates/gpu/gl/_objs/api2/api2.pic.d '-frandom-seed=bazel-out/arm64-v8a-opt/bin/tensorflow/lite/delegates/gpu/gl/_objs/api2/api2.pic.o' -fPIC -DVK_NO_PROTOTYPES -D__CLANG_SUPPORT_DYN_ANNOTATION__ -iquote . -iquote bazel-out/arm64-v8a-opt/bin -iquote external/com_google_absl -iquote bazel-out/arm64-v8a-opt/bin/external/com_google_absl -iquote external/FP16 -iquote bazel-out/arm64-v8a-opt/bin/external/FP16 -iquote external/opencl_headers -iquote bazel-out/arm64-v8a-opt/bin/external/opencl_headers -iquote external/vulkan_headers -iquote bazel-out/arm64-v8a-opt/bin/external/vulkan_headers -Ibazel-out/arm64-v8a-opt/bin/external/FP16/_virtual_includes/FP16 -isystem external/FP16/include -isystem bazel-out/arm64-v8a-opt/bin/external/FP16/include -isystem external/opencl_headers -isystem bazel-out/arm64-v8a-opt/bin/external/opencl_headers -isystem external/vulkan_headers/include -isystem bazel-out/arm64-v8a-opt/bin/external/vulkan_headers/include -w -Os -DTFLITE_GPU_BINARY_RELEASE --linkopt '-std=c++14' '--sysroot=external/androidndk/ndk/platforms/android-21/arch-arm64' -isystem external/androidndk/ndk/sources/cxx-stl/llvm-libc++/include -isystem external/androidndk/ndk/sources/cxx-stl/llvm-libc++abi/include -isystem external/androidndk/ndk/sources/android/support/include -isystemexternal/androidndk/ndk/sysroot/usr/include -c tensorflow/lite/delegates/gpu/gl/api2.cc -o bazel-out/arm64-v8a-opt/bin/tensorflow/lite/delegates/gpu/gl/_objs/api2/api2.pic.o)
Execution platform: @local_execution_config_platform//:platform
clang: error: unsupported option '--linkopt'
Target //tensorflow/lite/delegates/gpu:libtensorflowlite_gpu_delegate.so failed to build
INFO: Elapsed time: 0.500s, Critical Path: 0.09s
INFO: 0 processes.
FAILED: Build did NOT complete successfully
```
"
44921,tensorflow.keras.layers.Softmax axis parameter not behaving as described in documentation.,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS: Archlinux
- TensorFlow installed from: archlinux repository
- TensorFlow version: 2.3.1
- Python version: 3.8.6
- CUDA/cuDNN version: not relevant
- GPU model and memory: not relevant

**Current behavior:**
The example code raises TypeError: '<=' not supported between instances of 'int' and 'tuple'

**Expected behavior**
No error in example code. Both softmax layer and activation from softmax should have the same result (within eps). 

According to [documentation](https://keras.io/api/layers/activation_layers/softmax/) axis can be a single value or list of values. keras.activations.softmax is customly written to handle many axis, while the layer uses tensorflow.nn.softmax which treats axis parameter as a single value. I report it as a bug, since I think it should behave as described in documentation, and not the other way around.

**Standalone code to reproduce the issue**

```python
import tensorflow as tf
import numpy as np
t = tf.convert_to_tensor(np.random.rand(4,2,2))
assert np.all(tf.keras.layers.Softmax(axis=(1,2))(t) - tf.keras.activations.softmax(t, axis=(1,2)) < tf.keras.backend.epsilon()) 
```

"
44918,Problems to convert a tensorflow model to TFLite,"HI there, 
I am having problems when I transformed my trained model into a TFLite model:

**System information**
- OS Platform and Distribution: CentOS Linux 7 (Core)
- TensorFlow installed from (source or binary): binary

**Command used to run the converter or code if you’re using the Python API**

```
import numpy as np
#from google.colab import files
import tensorflow as tf
from tensorflow import keras
from keras.preprocessing import image
import glob
import pickle

model_path = '/home/mymodel.h5'

# convert the model
model = keras.models.load_model(model_path)
print('model loaded!')
converter = tf.lite.TFLiteConverter.from_keras_model(model)
tflite_model = converter.convert()
print('model converted!')

print('saving model...')
# save the lite model
with open('mymodel.tflite','wb') as f:
    f.write(tflite_model)

# done
print('convertion finished!')

```

**Failure details**
If the conversion is successful, but the generated model is wrong,
state what is wrong:
- Producing wrong results and/or decrease in accuracy
The model is transformed successfully but the converted model does not have the same input dimensions (instead the dimensions are transposed):

**Any other info / logs**
I am running the converted model using the interpreter (https://dl.google.com/coral/python/tflite_runtime-2.1.0.post1-cp35-cp35m-linux_armv7l.whl) in a Raspberry Pi B+

'''
from tflite_runtime.interpreter import Interpreter

  self.input_details = self.interpreter.get_input_details()
  self.output_details = self.interpreter.get_output_details()
  # check the type of the input tensor
  self.floating_model = self.input_details[0]['dtype'] == np.float32
  # details about the input image
  self.height = self.input_details[0]['shape'][1]
  self.width = self.input_details[0]['shape'][2]
  self.interpreter.set_tensor(self.input_details[0]['index'],input_data)  
  img = Image.open(path)
  print(img.size)
  input_data = np.expand_dims(img, axis=0)
  print(input_data.shape)
  if self.floating_model:
      input_data = (np.float32(input_data) - input_mean) / input_std

  self.interpreter.set_tensor(self.input_details[0]['index'], input_data)
  print('tensor set!')
  self.interpreter.invoke()
'''

This is the output:

'''
INFO: Initialized TensorFlow Lite runtime.
model loaded!
allocating tensors...
[{'quantization': (0.0, 0), 'shape': array([  1, 640, 480,   3]), 'index': 0, 'name': 'conv2d_input', 'dtype': <class 'numpy.float32'>}]
(640, 480)
(480, 640, 3)
image expanded shape:
(1, 480, 640, 3)
'''

and I get this error
'''
ValueError: Cannot set tensor: Dimension mismatch. Got 480 but expected 640 for dimension 1 of input 0.
'''
This error is not present if I run the same code using the original model.

- If I transpose the image to meet the input expectations of the converted model (480x640 instead of the 640x480 in the original), I can run the model but the output of the model is always [0 1. 0 0 0] regardless of the input (the original model works 
well).

Many thanks in advance for any idea about how to solve this.

Best,
Edgar"
44917,Slowdown training LSTM on TensorFlow 2.4+,"We are noticing a significant slowdown during training with TensorFlow when using the Tensorflow-Privacy LSTM and GRU optimizers on TF 2.4. In tetsing, this only happens when using the TF-privacy optimizers, but it appears related to a change in the recurrent_v2 module of TensorFlow. 

Doing some testing, it looks like the slowdown was introduced in between these two tf-nightly builds.

**Describe the expected behavior**
Training can go from 15 sec/epoch to 2 mins+ per epoch with the latest TF release candidate (tensorflow==2.4.0rc1).
tf-nightly==2.4.0.dev20201019 - 15 sec/epoch

**Describe the current behavior**
tf-nightly==2.4.0.dev20201020 and TensorFlow RC1 - 2 mins+/epoch

**System information**
GCP, running on Tesla V100, 16GB RAM, Ubuntu, 8 vCPU, Python 3.8, cuda11, TensorFlow 2.4.0rc0 and nightly installed via PIP. 

**Standalone code to reproduce the issue**
https://gist.github.com/zredlined/72305ab04670197869e470b232d22ed4

In tensorflow/python/keras/layers/recurrent_v2.py 
I think this TensorFlow commit is the culprit-- changing use_new_code() back to True speeds the code back up. The only reference I can find is in the issue above for what looks like an internal Google issue? Any help would be hugely appreciated, on most datasets we have tested with slowdowns are 10-20x. Thanks!

tensorflow/tensorflow@73b7097.
```
def _use_new_code():
  return False  # NOTE: changed to False in @73b7097. Changing back to True speeds training up.

```

**Other notes/logs**
Originally posted at https://github.com/tensorflow/privacy/issues/141, opening an issue here as it appears to be an issue within TensorFlow.





"
44916,undefined reference in tensorflow-lite shared library generated by cmake,"**System information**
- OS Platform and Distribution: macOS
- TensorFlow installed from (source or binary): source
- TensorFlow version: 2.5.0 (from git clone latest)
- Python version: Python 3.8.6
- Installed using virtualenv? pip? conda?: 
- CMake version (if compiling from source): 3.18.0
- GCC/Compiler version (if compiling from source): Android ndk r21
- CUDA/cuDNN version:
- GPU model and memory: Radeon Pro 555X 4 GB



**Describe the problem**
I compiled tensorflow-lite with cmake on android. I created an android JNI project. In this application I tried to link together all .a files (compiled by tensorflow-lite) into an .so shared library. In the cpp code I just get the version of the tensorflow-lite lib.
I got this linker error:
```
libtensorflow-lite.a(platform_profiler.cc.o): In function `tflite::profiling::MaybeCreatePlatformProfiler()':
tensorflow/tensorflow/lite/profiling/platform_profiler.cc:30: undefined reference to
`tflite::profiling::MaybeCreateATraceProfiler()'
```


**Provide the exact sequence of commands / steps that you executed before running into the problem**

```
git clone --recursive git@github.com:tensorflow/tensorflow.git
cd tensorflow
mkdir tf_build
cd tf_build
cmake -DCMAKE_TOOLCHAIN_FILE=~/Library/Android/sdk/ndk-bundle/build/cmake/android.toolchain.cmake -DANDROID_ABI=arm64-v8a ../tensorflow/lite
cmake --build . -j
```

In the cpp source I just get the version of the lib:
```
#include <tensorflow/lite/c/c_api.h>
```
```
printf(""TensorFlow C library version %s\n"", TfLiteVersion());
```

**Any other info / logs**
I think the problem is in the `tensorflow/tensorflow/lite/CMakeLists.txt`:
```
# TFLite library
add_library(tensorflow-lite
  ${TFLITE_CORE_API_SRCS}
  ${TFLITE_CORE_SRCS}
  ${TFLITE_C_SRCS}
  ${TFLITE_DELEGATES_FLEX_SRCS}
  ${TFLITE_DELEGATES_GPU_SRCS}
  ${TFLITE_DELEGATES_NNAPI_SRCS}
  ${TFLITE_DELEGATES_SRCS}
  ${TFLITE_DELEGATES_XNNPACK_SRCS}
  ${TFLITE_EXPERIMENTAL_RESOURCE_SRCS}
  ${TFLITE_EXPERIMENTAL_RUY_PROFILER_SRCS}
  ${TFLITE_EXPERIMENTAL_RUY_SRCS}
  ${TFLITE_KERNEL_INTERNAL_OPT_INTEGER_OPS_SRCS}
  ${TFLITE_KERNEL_INTERNAL_OPT_SPARSE_OPS_SRCS}
  ${TFLITE_KERNEL_INTERNAL_OPT_SRCS}
  ${TFLITE_KERNEL_INTERNAL_REF_INTEGER_OPS_SRCS}
  ${TFLITE_KERNEL_INTERNAL_REF_SPARSE_OPS_SRCS}
  ${TFLITE_KERNEL_INTERNAL_REF_SRCS}
  ${TFLITE_KERNEL_INTERNAL_SRCS}
  ${TFLITE_KERNEL_SRCS}
  ${TFLITE_NNAPI_SRCS}
  ${TFLITE_SRCS}
  ${TFLITE_SOURCE_DIR}/profiling/platform_profiler.cc
  ${TFLITE_SOURCE_DIR}/schema/schema_utils.cc
  ${TFLITE_SOURCE_DIR}/tools/optimize/sparsity/format_converter.cc
)
```

It includes `${TFLITE_SOURCE_DIR}/profiling/platform_profiler.cc` and this file uses `MaybeCreateATraceProfiler` function. But the implementation of this function is not added to the tensorflow-lite library.
I think a solution can be adding  `${TFLITE_SOURCE_DIR}/profiling/atrace_profiler.cc` to the tensorflow-lite library."
44914,podman tensorflow doesn't work,"I'm using the latest tensorflow image, but the gpu support doesn't work.

configs:
```bash
$ cat /etc/nvidia-container-runtime/config.toml
disable-require = false
#swarm-resource = ""DOCKER_RESOURCE_GPU""
#accept-nvidia-visible-devices-envvar-when-unprivileged = true
#accept-nvidia-visible-devices-as-volume-mounts = false

[nvidia-container-cli]
#root = ""/run/nvidia/driver""
#path = ""/usr/bin/nvidia-container-cli""
environment = []
#debug = ""/var/log/nvidia-container-toolkit.log""
#ldcache = ""/etc/ld.so.cache""
load-kmods = true
no-cgroups = true
#user = ""root:video""
ldconfig = ""@/sbin/ldconfig.real""

[nvidia-container-runtime]
#debug = ""/var/log/nvidia-container-runtime.log""
```
```bash
$ ls /usr/share/containers/oci/hooks.d
01-nvhook.json
```
```bash
$ cat /usr/share/containers/oci/hooks.d/01-nvhook.json
{
  ""version"": ""1.0.0"",
  ""hook"": {
    ""path"": ""/usr/bin/nvidia-container-toolkit"",
    ""args"": [""nvidia-container-toolkit"", ""prestart""],
    ""env"": [""NVIDIA_REQUIRE_CUDA=cuda>=10.1""]
  },
  ""when"": {
    ""always"": true
  },
  ""stages"": [""prestart""]
}
```
Installed software:
```bash
$ uname -a
Linux pop-os 5.8.0-7630-generic #32~1605108806~20.10~7e52b13-Ubuntu SMP Wed Nov 11 19:10:30 UTC  x86_64 x86_64 x86_64 GNU/Linux
```

```bash
$ nvidia-container-cli -V
version: 1.3.0
build date: 2020-10-02T22:32+00:00
build revision: 0000000000000000000000000000000000000000
build compiler: x86_64-linux-gnu-gcc-10 10.2.0
build platform: x86_64
build flags: -D_GNU_SOURCE -D_FORTIFY_SOURCE=2 -Wdate-time -D_FORTIFY_SOURCE=2 -DNDEBUG -std=gnu11 -O2 -g -fdata-sections -ffunction-sections -fstack-protector -fno-strict-aliasing -fvisibility=hidden -Wall -Wextra -Wcast-align -Wpointer-arith -Wmissing-prototypes -Wnonnull -Wwrite-strings -Wlogical-op -Wformat=2 -Wmissing-format-attribute -Winit-self -Wshadow -Wstrict-prototypes -Wunreachable-code -Wconversion -Wsign-conversion -Wno-unknown-warning-option -Wno-format-extra-args -Wno-gnu-alignof-expression -I/usr/include/tirpc -g -O2 -fdebug-prefix-map=/build/libnvidia-container-M6TLiQ/libnvidia-container-1.3.0=. -fstack-protector-strong -Wformat -Werror=format-security -Wl,-zrelro -Wl,-znow -Wl,-zdefs -Wl,--gc-sections -Wl,-Bsymbolic-functions -Wl,-z,relro
```

```bash
$podman --version
podman version 2.0.6
```
What i've tried:
nvidia/cuda (works):
```bash
$ sudo podman run --rm nvidia/cuda nvidia-smi
Mon Nov 16 19:31:00 2020       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 455.38       Driver Version: 455.38       CUDA Version: 11.1     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  GeForce GTX 107...  Off  | 00000000:01:00.0 Off |                  N/A |
| N/A   32C    P8     5W /  N/A |      6MiB /  8119MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
+-----------------------------------------------------------------------------+
```

Tensorflow CPU(works), GPU (doesn't work): 
1:
```bash
$ podman run -it -p 8888:8888 tensorflow/tensorflow:latest-jupyter
[I 19:31:42.533 NotebookApp] Writing notebook server cookie secret to /root/.local/share/jupyter/runtime/notebook_cookie_secret
jupyter_http_over_ws extension initialized. Listening on /http_over_websocket
[I 19:31:42.918 NotebookApp] Serving notebooks from local directory: /tf
[I 19:31:42.918 NotebookApp] Jupyter Notebook 6.1.4 is running at:
[I 19:31:42.918 NotebookApp] http://ca7653f39cdb:8888/?token=bdd8e07d71755fb10e280b7f9e963fa775ddcea587230ebe
[I 19:31:42.918 NotebookApp]  or http://127.0.0.1:8888/?token=bdd8e07d71755fb10e280b7f9e963fa775ddcea587230ebe
[I 19:31:42.918 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).
[C 19:31:42.924 NotebookApp] 
    
    To access the notebook, open this file in a browser:
        file:///root/.local/share/jupyter/runtime/nbserver-1-open.html
    Or copy and paste one of these URLs:
        http://ca7653f39cdb:8888/?token=bdd8e07d71755fb10e280b7f9e963fa775ddcea587230ebe
     or http://127.0.0.1:8888/?token=bdd8e07d71755fb10e280b7f9e963fa775ddcea587230ebe
[I 19:31:46.360 NotebookApp] 302 GET /?token=bdd8e07d71755fb10e280b7f9e963fa775ddcea587230ebe (127.0.0.1) 1.37ms
[I 19:31:49.905 NotebookApp] Writing notebook-signing key to /root/.local/share/jupyter/notebook_secret
[W 19:31:49.909 NotebookApp] Notebook tensorflow-tutorials/classification.ipynb is not trusted
[I 19:31:51.178 NotebookApp] Kernel started: 84611cfd-ff0b-402c-a665-e1ba49828a5f, name: python3
[I 19:31:51.945 NotebookApp] Adapting from protocol version 5.1 (kernel 84611cfd-ff0b-402c-a665-e1ba49828a5f) to 5.3 (client).
2020-11-16 19:31:54.837001: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory
2020-11-16 19:31:54.837110: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
[I 19:33:52.000 NotebookApp] Saving file at /tensorflow-tutorials/classification.ipynb
```
2:
```bash
$ podman run --gpus all -it -p 8888:8888 tensorflow/tensorflow:latest-jupyter
Error: unknown flag: --gpus
```
3:
```bash
$ podman run --device /dev/nvidia0:/dev/nvidia0 --device /dev/nvidiactl:/dev/nvidiactl --device /dev/nvidia-uvm:/dev/nvidia-uv -it -p 8888:8888 tensorflow/tensorflow:latest-jupyter
[I 20:00:04.852 NotebookApp] Writing notebook server cookie secret to /root/.local/share/jupyter/runtime/notebook_cookie_secret
jupyter_http_over_ws extension initialized. Listening on /http_over_websocket
[I 20:00:05.145 NotebookApp] Serving notebooks from local directory: /tf
[I 20:00:05.145 NotebookApp] Jupyter Notebook 6.1.4 is running at:
[I 20:00:05.146 NotebookApp] http://0c86b063117d:8888/?token=150f5836cd4cd98327de940ac9625bc9649b70bf8ca2b9cf
[I 20:00:05.146 NotebookApp]  or http://127.0.0.1:8888/?token=150f5836cd4cd98327de940ac9625bc9649b70bf8ca2b9cf
[I 20:00:05.146 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).
[C 20:00:05.150 NotebookApp] 
    
    To access the notebook, open this file in a browser:
        file:///root/.local/share/jupyter/runtime/nbserver-1-open.html
    Or copy and paste one of these URLs:
        http://0c86b063117d:8888/?token=150f5836cd4cd98327de940ac9625bc9649b70bf8ca2b9cf
     or http://127.0.0.1:8888/?token=150f5836cd4cd98327de940ac9625bc9649b70bf8ca2b9cf
[I 20:00:10.034 NotebookApp] 302 GET /?token=150f5836cd4cd98327de940ac9625bc9649b70bf8ca2b9cf (127.0.0.1) 1.16ms
[I 20:00:13.545 NotebookApp] Writing notebook-signing key to /root/.local/share/jupyter/notebook_secret
[W 20:00:13.547 NotebookApp] Notebook tensorflow-tutorials/classification.ipynb is not trusted
[I 20:00:14.779 NotebookApp] Kernel started: 07ad74de-a8a8-451e-a579-af2a04dd54ca, name: python3
[I 20:00:15.596 NotebookApp] Adapting from protocol version 5.1 (kernel 07ad74de-a8a8-451e-a579-af2a04dd54ca) to 5.3 (client).
2020-11-16 20:00:17.797706: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory
2020-11-16 20:00:17.797761: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
```
4:
```bash
podman run --hooks-dir /usr/share/containers/oci/hooks.d  -it -p 8888:8888 tensorflow/tensorflow:latest-jupyter
[I 20:43:01.225 NotebookApp] Writing notebook server cookie secret to /root/.local/share/jupyter/runtime/notebook_cookie_secret
jupyter_http_over_ws extension initialized. Listening on /http_over_websocket
[I 20:43:01.535 NotebookApp] Serving notebooks from local directory: /tf
[I 20:43:01.535 NotebookApp] Jupyter Notebook 6.1.4 is running at:
[I 20:43:01.535 NotebookApp] http://91398c24ef54:8888/?token=fab994e5e527d14bfb5f5ca25d8492237e395cc7ae0336a6
[I 20:43:01.535 NotebookApp]  or http://127.0.0.1:8888/?token=fab994e5e527d14bfb5f5ca25d8492237e395cc7ae0336a6
[I 20:43:01.535 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).
[C 20:43:01.540 NotebookApp] 
    
    To access the notebook, open this file in a browser:
        file:///root/.local/share/jupyter/runtime/nbserver-1-open.html
    Or copy and paste one of these URLs:
        http://91398c24ef54:8888/?token=fab994e5e527d14bfb5f5ca25d8492237e395cc7ae0336a6
     or http://127.0.0.1:8888/?token=fab994e5e527d14bfb5f5ca25d8492237e395cc7ae0336a6
[I 20:43:08.599 NotebookApp] 302 GET /?token=fab994e5e527d14bfb5f5ca25d8492237e395cc7ae0336a6 (127.0.0.1) 0.62ms
[I 20:43:11.836 NotebookApp] Writing notebook-signing key to /root/.local/share/jupyter/notebook_secret
[W 20:43:11.845 NotebookApp] Notebook tensorflow-tutorials/classification.ipynb is not trusted
[I 20:43:13.118 NotebookApp] Kernel started: 686ca286-3d4f-4323-b2c2-dbb27f5ad297, name: python3
[I 20:43:13.897 NotebookApp] Adapting from protocol version 5.1 (kernel 686ca286-3d4f-4323-b2c2-dbb27f5ad297) to 5.3 (client).
2020-11-16 20:43:16.871350: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory
2020-11-16 20:43:16.871395: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
```
Problem:
```bash
Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory
```
Question:
What am i doing wrong?

PS: I've never made a support ticket so I don't know if i shared enough information."
44913,Issue in Bazel build for CUDA 11.1,"
**System information**
- OS Platform and Distribution: Windows 10
- TensorFlow installed from (source or binary): source
- TensorFlow version: 2.5.0 (from git clone latest)
- Python version: 3.8.5
- Installed using virtualenv? pip? conda?: conda
- Bazel version (if compiling from source): bazel 3.7.0
- CUDA/cuDNN version: 11.1 with CuDNN 8.0.5
- GPU model and memory: GTX 1070

Since I want PTX compilation in Windows (available with CUDA 11.1), I was building TensorFlow with Bazel. I get the following error after a while
```
ERROR: C:/users/joehr/_bazel_joehr/6zdjxw7k/external/com_google_protobuf/BUILD:866:17: ProtoCompile external/com_google_protobuf/python/google/protobuf/compiler/plugin_pb2.py failed (Exit -1073741795): protoc.exe failed: error executing command
  cd C:/users/joehr/_bazel_joehr/6zdjxw7k/execroot/org_tensorflow
  SET CUDA_TOOLKIT_PATH=C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v11.1
    SET PATH=C:\msys64\usr\bin;C:\msys64\bin;C:\Windows;C:\Windows\System32;C:\Windows\System32\WindowsPowerShell\v1.0
    SET PYTHON_BIN_PATH=C:/Users/joehr/anaconda3/envs/bleedingEdge38/python.exe
    SET PYTHON_LIB_PATH=C:/Users/joehr/anaconda3/envs/bleedingEdge38/lib/site-packages
    SET RUNFILES_MANIFEST_ONLY=1
    SET TF2_BEHAVIOR=1
    SET TF_CONFIGURE_IOS=0
    SET TF_CUDA_COMPUTE_CAPABILITIES=7.0
    SET TF_NEED_CUDA=1
  bazel-out/x64_windows-opt/bin/external/com_google_protobuf/protoc.exe --python_out=bazel-out/x64_windows-opt/bin/external/com_google_protobuf/python -Iexternal/com_google_protobuf/python -Ibazel-out/x64_windows-opt/bin/external/com_google_protobuf/python bazel-out/x64_windows-opt/bin/external/com_google_protobuf/python/google/protobuf/compiler/plugin.proto
Execution platform: @local_execution_config_platform//:platform
Target //tensorflow/tools/pip_package:build_pip_package failed to build
INFO: Elapsed time: 19.771s, Critical Path: 2.68s
INFO: 11 processes: 10 internal, 1 local.
FAILED: Build did NOT complete successfully
```

I tried to install protoc windows thinking that the protoc is not working but there's no difference. 

I used [this](https://medium.com/@dev.ashurai/protoc-protobuf-installation-on-windows-linux-mac-d70d5380489d) link for installing protoc and it tested fine as below
```
protobuf:x64-windows                               3.13.0#2         Protocol Buffers - Google's data interchange format
protobuf:x86-windows                               3.13.0#2         Protocol Buffers - Google's data interchange format
```

I looked up the section mentioned by the code ""866:17"" and got this particular function
```
py_proto_library(
    name = ""protobuf_python"",
    srcs = COPIED_WELL_KNOWN_PROTOS,
    include = ""python"",
    data = select({
        ""//conditions:default"": [],
        "":use_fast_cpp_protos"": [
            "":python/google/protobuf/internal/_api_implementation.so"",
            "":python/google/protobuf/pyext/_message.so"",
        ],
    }),
    default_runtime = """",
    protoc = "":protoc"",
    py_libs = [
        "":python_srcs"",
        ""//external:six"",
    ],
    py_extra_srcs = glob([""python/**/__init__.py""]),
    srcs_version = ""PY2AND3"",
    visibility = [""//visibility:public""],
)
```
 
To my knowledge, it looks fine and no broken links. Please help."
44910,[Question] Adding More Outputs in tflite Interpreter.get_output_details(),"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Windows 10, Python 3.7.7, 
- TensorFlow installed from (source or binary):
Source
- TensorFlow version (or github SHA if from source):
Tensorflow 2.3.0-rc0

Hello, this is more of a question rather than an issue report.
I am trying to convert a yolov4 model into a tflite to no avail.

After reading through:
- https://www.tensorflow.org/lite/convert
- https://www.tensorflow.org/api_docs/python/tf/lite/TFLiteConverter
- https://www.tensorflow.org/lite/inference_with_metadata/lite_support
- https://www.tensorflow.org/api_docs/python/tf/lite/Interpreter

I am unable to find any details regarding appending data in the `interpreter.get_output_details()`.
There are guides that require more than 1 output details, [here's an example](https://github.com/vardanagarwal/Proctoring-AI/blob/master/coco%20models/tflite%20mobnetv1%20ssd/seg_tflite.py#L64-L69); which then can be translated into bbox, classes, scores, and number of detections respectively.

Are there any documentations that can give me a lead on this question?"
44909,"Simpler integration of TFLM with external IDEs / build systems: add ability to get list of sources, headers etc. from the TFLM Makefile","@tensorflow/micro

The goal here is to make it easier to integrate TFLM as part of external IDEs or build systems.

The current approach involves adding project generation logic to the TFLM Makefiles which is both awkward to do and harder to maintain.

An alternative approach (being developed in collaboration with the CMSIS team at ARM) is to have the makefile output the necessry information on the terminal and then keep all the integration logic external to the TFLM Makefiles.

Moving forward, this will be the preferred method of integration."
44908,Multiple models sequentially with TFLu,"@tensorflow/micro

**System information**
- Host OS Platform and Distribution (e.g., Linux Ubuntu 16.04): N/A
- TensorFlow installed from (source or binary): N/A
- Tensorflow version (commit SHA if source): 2.3.0
- Target platform (e.g. Arm Mbed OS, Arduino Nano 33 etc.): N/A

**Describe the problem**
Is there any example of how to run multiple models sequentially while sharing the same tensor arena and what are the limitations? I could not find anything in the current documentation.

Currently I have an interpreter for each model and I have one shared tensor arena but I have to re-initialize the interpreters between each inference otherwise I get the following error:

Type Unknown type (1617751660) not supported.
Node CONV_2D (number 2) failed to invoke with status 1

Is there a way to do this without having to re-initialize each time?"
44906,RecursionError with `dynamic=True` when using a `Lambda` layer ,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 20.04
- TensorFlow installed from (source or binary): binary 
- TensorFlow version (use command below): v2.3.0-rc2-23-gb36436b087 2.3.0
- Python version: 3.8.5

**Describe the current behavior**

When running a `Lambda` layer with `dynamic=True`, the code crashes with a `RecursionError`.

**Describe the expected behavior**

No crash. 

**Standalone code to reproduce the issue**

```python
import tensorflow as tf
inp = tf.keras.Input(shape=(10,))
out = tf.keras.layers.Lambda(
        lambda x_input: x_input,
        dynamic=True,
)(inp)
model = tf.keras.Model(inputs=inp, outputs=out)
```

**Other info / logs** 

[traceback_recursion_error.log](https://github.com/tensorflow/tensorflow/files/5546954/traceback_recursion_error.log)

"
44905,"Conv2dTranspose layer creates additional operators on tflite conversion (Shape, Pack and Strided Slice)","**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- TensorFlow installed from (source or binary):  Binary
- TensorFlow version (or github SHA if from source):  TF 2..3.0, TF Nightly


**Command used to run the converter or code if you’re using the Python API**
If possible, please share a link to Colab/Jupyter/any notebook.

```
model=tf.keras.models.load_model('amnv3seg.h5')

converter = tf.lite.TFLiteConverter.from_keras_model(model)
tflite_model = converter.convert()
open(""mnv3_seg_mew_2.3.tflite"", ""wb"").write(tflite_model)
```

**The output from the converter invocation**


```
# Copy and paste the output here.

# In Tf 2.3.0
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
This property should not be used in TensorFlow 2.0, as updates are applied automatically.
INFO:tensorflow:Assets written to: /tmp/tmpc0xpp5l1/assets
10776624



# In TF-Nightly
INFO:tensorflow:Assets written to: /tmp/tmpqt986x_h/assets
INFO:tensorflow:Assets written to: /tmp/tmpqt986x_h/assets
10775140
```

**Failure details**
 The converted tflite model creates additonal **shape , pack and strided slice** operators and they are not supported by **gpu delegate** in android. The issue persists in TF 2.3 and TF Nightly.  The issue happens with or without bias parameter in Conv2dTranspose layer.

**Any other info / logs**

The original tf model is based on mobilenetv3 pretrained model and is available only in tf-nightly
[conv2dmodels.zip](https://github.com/tensorflow/tensorflow/files/5546200/conv2dmodels.zip)"
44904,Boolean_mask can't be compiled by XLA on CPU,"

**System information**
- Ubuntu 18.04, Python 3.6, Tensorflow 2.4.0, compiled on my own:

**Describe the current behavior**

Boolean_mask can't be compiled by XLA on CPU:

```
repl_used = tf.constant([1., 1.])
sigma = tf.constant(tf.ones((4,1,2,1)))

@tf.function(experimental_compile=True)
def repl_example(repl_used, sigma):
    res = tf.boolean_mask(sigma, repl_used, axis=2)
    return res
        
repl_example(repl_used, sigma)
```

results in 

```
---------------------------------------------------------------------------
InvalidArgumentError                      Traceback (most recent call last)
<ipython-input-33-24b6292aa5a3> in <module>
      7     return res
      8 
----> 9 repl_example(repl_used, sigma)

~/.virtualenvs/py36/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py in __call__(self, *args, **kwds)
    784     tracing_count = self._get_tracing_count()
    785     with trace.Trace(self._name) as tm:
--> 786       result = self._call(*args, **kwds)
    787       compiler = ""xla"" if self._experimental_compile else ""nonXla""
    788       new_tracing_count = self._get_tracing_count()

~/.virtualenvs/py36/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py in _call(self, *args, **kwds)
    851       # If we did not create any variables the trace we have is good enough.
    852       return self._concrete_stateful_fn._call_flat(
--> 853           filtered_flat_args, self._concrete_stateful_fn.captured_inputs)  # pylint: disable=protected-access
    854 
    855     def fn_with_cond(inner_args, inner_kwds, inner_filtered_flat_args):

~/.virtualenvs/py36/lib/python3.6/site-packages/tensorflow/python/eager/function.py in _call_flat(self, args, captured_inputs, cancellation_manager)
   1918       # No tape is watching; skip to running the function.
   1919       return self._build_call_outputs(self._inference_function.call(
-> 1920           ctx, args, cancellation_manager=cancellation_manager))
   1921     forward_backward = self._select_forward_and_backward_functions(
   1922         args,

~/.virtualenvs/py36/lib/python3.6/site-packages/tensorflow/python/eager/function.py in call(self, ctx, args, cancellation_manager)
    559               inputs=args,
    560               attrs=attrs,
--> 561               ctx=ctx)
    562         else:
    563           outputs = execute.execute_with_cancellation(

~/.virtualenvs/py36/lib/python3.6/site-packages/tensorflow/python/eager/execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)
     58     ctx.ensure_initialized()
     59     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
---> 60                                         inputs, attrs, num_outputs)
     61   except core._NotOkStatusException as e:
     62     if name is not None:

InvalidArgumentError: Function invoked by the following node is not compilable: {{node __inference_repl_example_77940}} = __inference_repl_example_77940[_XlaMustCompile=true, config_proto=""\n\007\n\003CPU\020\001\n\007\n\003GPU\020\0002\002J\0008\001\202\001\000"", executor_type=""""](dummy_input, dummy_input).
Uncompilable nodes:
boolean_mask/Where: unsupported op: No registered 'Where' OpKernel for XLA_CPU_JIT devices compatible with node {{node boolean_mask/Where}}
	Stacktrace:
		Node: __inference_repl_example_77940, function: 
		Node: boolean_mask/Where, function: __inference_repl_example_77940
 [Op:__inference_repl_example_77940]
```

**Describe the expected behavior**

Boolean_mask should be compiled by XLA
"
44903,tflite: why using mali gpu will cause memory leak?,"

**System information**

- OS Android 10.0
- Mobile device: mate 30 pro:
- tflite build from source:
- gpu：mali g76:

I noticed there are some comments about reducing memory leak for mali gpu in tflite opencl and opengl context. And I also observed memory leak on my mate30 pro when using opencl, which does not happens with my previous adreno phone.
mate30 pro
![image](https://user-images.githubusercontent.com/21992233/99243764-162b0900-283c-11eb-98f0-ace9fa61def5.png)

mi8
![image](https://user-images.githubusercontent.com/21992233/99243935-5a1e0e00-283c-11eb-961a-65c041c473e8.png)

So can anyone explain why there may be memory leak for mali gpu? 

Thanks!
"
44900,Use correctly shuffle=False in fit_generator() function,"Shuffle parameter in fit_generator function can take two boolean values: True or False. I want to execute fit_generator without altering the order of the batches at each epoch of the training, so I have to assign 'shuffle=False'. Also, I want to specify the number of steps per epoch, but shuffle parameter has effect when 'steps_per_epoch=None'.

- Is there any way to solve that?
- How can I use correctly shuffle parameter in fit_generator function?
- Is there any way to check batches at each epoch are not being shuffling?

"
44899,SaveModelBundle in TensorFlow is generating error,"someone else also face the same bug.
https://stackoverflow.com/questions/63848415/savemodelbundle-in-tensorflow-is-generating-error

similar bug
https://github.com/tensorflow/tensorflow/issues/40004

LInux 18.04
TF 2.3

```
#include <tensorflow/core/platform/env.h>
#include <tensorflow/core/public/session.h>
#include ""tensorflow/cc/saved_model/tag_constants.h""// kSavedModelTagServe
#include ""tensorflow/cc/saved_model/loader.h""//savedmodelbundle
#include <tensorflow/core/public/session_options.h>
#include <tensorflow/core/framework/tensor.h>

#include <iostream>

using namespace std;
using namespace tensorflow;

// TODO: unfinished.

int main()
{
    std::string model_path = ""/boosted_trees_model/output/1605514073"";
    std::cout << ""Found model: "" << tensorflow::MaybeSavedModelDirectory(model_path) << std::endl;

    tensorflow::SavedModelBundle model_bundle_;
    tensorflow::SessionOptions session_options;
    tensorflow::RunOptions run_options;
    std::unordered_set<std::string> saved_model_tags;
    saved_model_tags.insert(tensorflow::kSavedModelTagServe);
    tensorflow::Status status = tensorflow::LoadSavedModel(session_options,
                                                           run_options,
                                                           model_path,
                                                           saved_model_tags,
                                                           &model_bundle_);
    if (!status.ok()) {
        std::cout << ""LoadSavedModel Failed: "" << status.ToString() << std::endl;
    }
    return 0;
}
```

```
ubuntu@ip-172-31-14-28:~/tf_cpp/build$ cmake .. && make
-- Configuring done
-- Generating done
-- Build files have been written to: /home/ubuntu/tf_cpp/build
Scanning dependencies of target example
[ 50%] Building CXX object CMakeFiles/example.dir/example1.cpp.o
[100%] Linking CXX executable example
CMakeFiles/example.dir/example1.cpp.o: In function `google::protobuf::internal::MapField<tensorflow::MetaGraphDef_SignatureDefEntry_DoNotUse, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, tensorflow::SignatureDef, (google::protobuf::internal::WireFormatLite::FieldType)9, (google::protobuf::internal::WireFormatLite::FieldType)11, 0>::GetMap() const':
example1.cpp:(.text._ZNK6google8protobuf8internal8MapFieldIN10tensorflow39MetaGraphDef_SignatureDefEntry_DoNotUseENSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEENS3_12SignatureDefELNS1_14WireFormatLite9FieldTypeE9ELSD_11ELi0EE6GetMapEv[_ZNK6google8protobuf8internal8MapFieldIN10tensorflow39MetaGraphDef_SignatureDefEntry_DoNotUseENSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEENS3_12SignatureDefELNS1_14WireFormatLite9FieldTypeE9ELSD_11ELi0EE6GetMapEv]+0x14): undefined reference to `google::protobuf::internal::MapFieldBase::SyncMapWithRepeatedField() const'
collect2: error: ld returned 1 exit status
CMakeFiles/example.dir/build.make:95: recipe for target 'example' failed
```"
44898,tf-gpu 1.14 - Enabling eager execution not working.,"Hello guys,

I am using tf-gpu 1.14 version.

I want to apply the following loss [BinaryCrossentropy](https://www.tensorflow.org/versions/r1.15/api_docs/python/tf/keras/losses/BinaryCrossentropy) . But I am getting the error called ""**Tensor object cannot be converted to numpy**"".

When I searched this error on stackoverflow, I found out that I have to enable eager_execution. So I tried doing that but I get the error "" **AttributeError: module 'tensorflow._api.v1.config' has no attribute 'run_functions_eagerly'**"".

Note that I cannot upgrade tensorflow and I want to convert the tensor to numpy array. Is there a way around this? or is this a bug? 

I appreciate your help.
"
44897,Cuda verision not documents,"There is no information about which cuda version required for pip packages
i think must be document as an table for old relases and 
for recent release mustbe selection gui something like pytorch 
![resim](https://user-images.githubusercontent.com/8981828/99224100-b8280280-27f6-11eb-9511-44237b0a45a0.png)

"
44896,Convert using integer-only quantization problem,"This program is an example of tensorflow integer quantization：

def representative_data_gen():
  for input_value in tf.data.Dataset.from_tensor_slices(train_images).batch(1).take(100):
    yield [input_value]

converter = tf.lite.TFLiteConverter.from_keras_model(model)
converter.optimizations = [tf.lite.Optimize.DEFAULT]
converter.representative_dataset = representative_data_gen
# Ensure that if any ops can't be quantized, the converter throws an error
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]
# Set the input and output tensors to uint8 (APIs added in r2.3)
converter.inference_input_type = tf.uint8
converter.inference_output_type = tf.uint8

tflite_model_quant = converter.convert()


What does (1) and (100) in this line mean?
  [for input_value in tf.data.Dataset.from_tensor_slices(train_images).batch(1).take(100):]
"
44895,Empty folder,"Hi!
I try to undeertand why the app doesn't work i almost read the FAQ and applyed the olutions but it didn't work, the message said something like: RUN but the  folder is empty

I hace a Core i7 PC
with window 10. 
I tried to know if the AVX works, i downloaded thee programe to know and it say YES...
I tried the 2.8 version and it was OK but then when i dowload the last one.. the programe never run again T.T 

Please help!!"
44893,model.fit trains on (# of training samples)/batch_size,"This template is for miscellaneous issues not covered by the other issue categories.

For questions on how to work with TensorFlow, or support for problems that are not verified bugs in TensorFlow, please go to [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).

If you are reporting a vulnerability, please use the [dedicated reporting process](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md).

For high-level discussions about TensorFlow, please post to discuss@tensorflow.org, for questions about the development or internal workings of TensorFlow, or if you would like to know how to contribute to TensorFlow, please post to developers@tensorflow.org.
"
44891,"While implementing SEGNET, getting error of ""python3.7/site-packages/tensorflow/python/keras/layers/convolutional.py"", line 293, in _get_input_channel     raise ValueError('The channel dimension of the inputs ' ValueError: The channel dimension of the inputs should be defined. Found `None`.""","I am implementing SEGNET segmentation Network in python but getting the following error, 

**_Traceback (most recent call last):
  File ""/scratch/pkasar.dbatu/training/NEW_SEGNET_updated_on_16_11_20.py"", line 370, in <module>
    model=segnet(input_shape=(256,256,3),n_labels=1)
  File ""/scratch/pkasar.dbatu/training/NEW_SEGNET_updated_on_16_11_20.py"", line 161, in segnet
    conv_14 = Convolution2D(512, (kernel, kernel), padding=""same"")(unpool_1)
  File ""/home/pkasar.dbatu/.conda/envs/dl/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py"", line 897, in __call__
    self._maybe_build(inputs)
  File ""/home/pkasar.dbatu/.conda/envs/dl/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py"", line 2416, in _maybe_build
    self.build(input_shapes)  # pylint:disable=not-callable
  File ""/home/pkasar.dbatu/.conda/envs/dl/lib/python3.7/site-packages/tensorflow/python/keras/layers/convolutional.py"", line 153, in build
    input_channel = self._get_input_channel(input_shape)
  File ""/home/pkasar.dbatu/.conda/envs/dl/lib/python3.7/site-packages/tensorflow/python/keras/layers/convolutional.py"", line 293, in _get_input_channel
    raise ValueError('The channel dimension of the inputs '
ValueError: The channel dimension of the inputs should be defined. Found `None`._**

Tensorflow image is:-
tensorflow                2.2.0 
tensorflow-gpu            2.2.0
keras-base                2.4.3                
keras-gpu                 2.4.3     
python                    3.7.9
Please help me out
Thank you in advance

@tensorflow-copybara  , @tensorflow-jenkins  @TensorFlow-MKL @tensorflowbutler @tensorflower-gardener 





The code snippet is as follows:-


```from keras.layers import Input
from keras.layers.convolutional import Convolution2D
from keras.layers.core import Activation, Reshape
from keras.layers.normalization import BatchNormalization
from keras.models import Model
from keras import backend as K
from keras.layers import Layer
class MaxPoolingWithArgmax2D(Layer):
    def __init__(self, pool_size=(2, 2), strides=(2, 2), padding=""same"", **kwargs):
        super(MaxPoolingWithArgmax2D, self).__init__(**kwargs)
        self.padding = padding
        self.pool_size = pool_size
        self.strides = strides

    def call(self, inputs, **kwargs):
        padding = self.padding
        pool_size = self.pool_size
        strides = self.strides
        if K.backend() == ""tensorflow"":
            ksize = [1, pool_size[0], pool_size[1], 1]
            padding = padding.upper()
            strides = [1, strides[0], strides[1], 1]
            output, argmax = K.tf.nn.max_pool_with_argmax(
                inputs, ksize=ksize, strides=strides, padding=padding
            )
        else:
            errmsg = ""{} backend is not supported for layer {}"".format(
                K.backend(), type(self).__name__
            )
            raise NotImplementedError(errmsg)
        argmax = K.cast(argmax, K.floatx())
        return [output, argmax]

    def compute_output_shape(self, input_shape):
        ratio = (1, 2, 2, 1)
        output_shape = [
            dim // ratio[idx] if dim is not None else None
            for idx, dim in enumerate(input_shape)
        ]
        output_shape = tuple(output_shape)
        return [output_shape, output_shape]

    def compute_mask(self, inputs, mask=None):
        return 2 * [None]
class MaxUnpooling2D(Layer):
    def __init__(self, size=(2, 2), **kwargs):
        super(MaxUnpooling2D, self).__init__(**kwargs)
        self.size = size
    def call(self, inputs, output_shape=None):
        updates, mask = inputs[0], inputs[1]
        with K.tf.variable_scope(self.name):
            mask = K.cast(mask, ""int32"")
            input_shape = K.tf.shape(updates, out_type=""int32"")
            #  calculation new shape
            if output_shape is None:
                output_shape = (
                    input_shape[0],
                    input_shape[1] * self.size[0],
                    input_shape[2] * self.size[1],
                    input_shape[3],
                )
            self.output_shape1 = output_shape
            # calculation indices for batch, height, width and feature maps
            one_like_mask = K.ones_like(mask, dtype=""int32"")
            batch_shape = K.concatenate([[input_shape[0]], [1], [1], [1]], axis=0)
            batch_range = K.reshape(
                K.tf.range(output_shape[0], dtype=""int32""), shape=batch_shape
            )
            b = one_like_mask * batch_range
            y = mask // (output_shape[2] * output_shape[3])
            x = (mask // output_shape[3]) % output_shape[2]
            feature_range = K.tf.range(output_shape[3], dtype=""int32"")
            f = one_like_mask * feature_range
            # transpose indices & reshape update values to one dimension
            updates_size = K.tf.size(updates)
            indices = K.transpose(K.reshape(K.stack([b, y, x, f]), [4, updates_size]))
            values = K.reshape(updates, [updates_size])
            ret = K.tf.scatter_nd(indices, values, output_shape)
            return ret
    def compute_output_shape(self, input_shape):
        mask_shape = input_shape[1]
        return (
            mask_shape[0],
            mask_shape[1] * self.size[0],
            mask_shape[2] * self.size[1],
            mask_shape[3],
        )
def segnet(input_shape, n_labels, kernel=3, pool_size=(2, 2), output_mode=""softmax""):
    # encoder
    inputs = Input(shape=input_shape)

    conv_1 = Convolution2D(64, (kernel, kernel), padding=""same"")(inputs)
    conv_1 = BatchNormalization()(conv_1)
    conv_1 = Activation(""relu"")(conv_1)
    conv_2 = Convolution2D(64, (kernel, kernel), padding=""same"")(conv_1)
    conv_2 = BatchNormalization()(conv_2)
    conv_2 = Activation(""relu"")(conv_2)
    pool_1, mask_1 = MaxPoolingWithArgmax2D(pool_size)(conv_2)
    conv_3 = Convolution2D(128, (kernel, kernel), padding=""same"")(pool_1)
    conv_3 = BatchNormalization()(conv_3)
    conv_3 = Activation(""relu"")(conv_3)
    conv_4 = Convolution2D(128, (kernel, kernel), padding=""same"")(conv_3)
    conv_4 = BatchNormalization()(conv_4)
    conv_4 = Activation(""relu"")(conv_4)

    pool_2, mask_2 = MaxPoolingWithArgmax2D(pool_size)(conv_4)

    conv_5 = Convolution2D(256, (kernel, kernel), padding=""same"")(pool_2)
    conv_5 = BatchNormalization()(conv_5)
    conv_5 = Activation(""relu"")(conv_5)
    conv_6 = Convolution2D(256, (kernel, kernel), padding=""same"")(conv_5)
    conv_6 = BatchNormalization()(conv_6)
    conv_6 = Activation(""relu"")(conv_6)
    conv_7 = Convolution2D(256, (kernel, kernel), padding=""same"")(conv_6)
    conv_7 = BatchNormalization()(conv_7)
    conv_7 = Activation(""relu"")(conv_7)

    pool_3, mask_3 = MaxPoolingWithArgmax2D(pool_size)(conv_7)

    conv_8 = Convolution2D(512, (kernel, kernel), padding=""same"")(pool_3)
    conv_8 = BatchNormalization()(conv_8)
    conv_8 = Activation(""relu"")(conv_8)
    conv_9 = Convolution2D(512, (kernel, kernel), padding=""same"")(conv_8)
    conv_9 = BatchNormalization()(conv_9)
    conv_9 = Activation(""relu"")(conv_9)
    conv_10 = Convolution2D(512, (kernel, kernel), padding=""same"")(conv_9)
    conv_10 = BatchNormalization()(conv_10)
    conv_10 = Activation(""relu"")(conv_10)

    pool_4, mask_4 = MaxPoolingWithArgmax2D(pool_size)(conv_10)

    conv_11 = Convolution2D(512, (kernel, kernel), padding=""same"")(pool_4)
    conv_11 = BatchNormalization()(conv_11)
    conv_11 = Activation(""relu"")(conv_11)
    conv_12 = Convolution2D(512, (kernel, kernel), padding=""same"")(conv_11)
    conv_12 = BatchNormalization()(conv_12)
    conv_12 = Activation(""relu"")(conv_12)
    conv_13 = Convolution2D(512, (kernel, kernel), padding=""same"")(conv_12)
    conv_13 = BatchNormalization()(conv_13)
    conv_13 = Activation(""relu"")(conv_13)

    pool_5, mask_5 = MaxPoolingWithArgmax2D(pool_size)(conv_13)
    print(""Build enceder done.."")

    # decoder

    unpool_1 = MaxUnpooling2D(pool_size)([pool_5, mask_5])

    conv_14 = Convolution2D(512, (kernel, kernel), padding=""same"")(unpool_1)
    conv_14 = BatchNormalization()(conv_14)
    conv_14 = Activation(""relu"")(conv_14)
    conv_15 = Convolution2D(512, (kernel, kernel), padding=""same"")(conv_14)
    conv_15 = BatchNormalization()(conv_15)
    conv_15 = Activation(""relu"")(conv_15)
    conv_16 = Convolution2D(512, (kernel, kernel), padding=""same"")(conv_15)
    conv_16 = BatchNormalization()(conv_16)
    conv_16 = Activation(""relu"")(conv_16)

    unpool_2 = MaxUnpooling2D(pool_size)([conv_16, mask_4])

    conv_17 = Convolution2D(512, (kernel, kernel), padding=""same"")(unpool_2)
    conv_17 = BatchNormalization()(conv_17)
    conv_17 = Activation(""relu"")(conv_17)
    conv_18 = Convolution2D(512, (kernel, kernel), padding=""same"")(conv_17)
    conv_18 = BatchNormalization()(conv_18)
    conv_18 = Activation(""relu"")(conv_18)
    conv_19 = Convolution2D(256, (kernel, kernel), padding=""same"")(conv_18)
    conv_19 = BatchNormalization()(conv_19)
    conv_19 = Activation(""relu"")(conv_19)

    unpool_3 = MaxUnpooling2D(pool_size)([conv_19, mask_3])

    conv_20 = Convolution2D(256, (kernel, kernel), padding=""same"")(unpool_3)
    conv_20 = BatchNormalization()(conv_20)
    conv_20 = Activation(""relu"")(conv_20)
    conv_21 = Convolution2D(256, (kernel, kernel), padding=""same"")(conv_20)
    conv_21 = BatchNormalization()(conv_21)
    conv_21 = Activation(""relu"")(conv_21)
    conv_22 = Convolution2D(128, (kernel, kernel), padding=""same"")(conv_21)
    conv_22 = BatchNormalization()(conv_22)
    conv_22 = Activation(""relu"")(conv_22)

    unpool_4 = MaxUnpooling2D(pool_size)([conv_22, mask_2])

    conv_23 = Convolution2D(128, (kernel, kernel), padding=""same"")(unpool_4)
    conv_23 = BatchNormalization()(conv_23)
    conv_23 = Activation(""relu"")(conv_23)
    conv_24 = Convolution2D(64, (kernel, kernel), padding=""same"")(conv_23)
    conv_24 = BatchNormalization()(conv_24)
    conv_24 = Activation(""relu"")(conv_24)

    unpool_5 = MaxUnpooling2D(pool_size)([conv_24, mask_1])

    conv_25 = Convolution2D(64, (kernel, kernel), padding=""same"")(unpool_5)
    conv_25 = BatchNormalization()(conv_25)
    conv_25 = Activation(""relu"")(conv_25)

    conv_26 = Convolution2D(n_labels, (1, 1), padding=""valid"")(conv_25)
    conv_26 = BatchNormalization()(conv_26)
    conv_26 = Reshape(
        (input_shape[0] * input_shape[1], n_labels),
        input_shape=(input_shape[0], input_shape[1], n_labels),
    )(conv_26)

    outputs = Activation(output_mode)(conv_26)
    print(""Build decoder done.."")

    model = Model(inputs=inputs, outputs=outputs, name=""SegNet"")

    return model

model=segnet(input_shape=(256,256,3),n_labels=1)```

"
44890,"yolov3-tiny tflite model of shape [1, 2535, 85] representation","I found a tflite model of shape [1, 2535, 85] with 80 classes.

I am aware that each item in the array represents each bounding box information.

So yolo-v3 tiny model uses two scales `13 x 13` and` 26 x 26`

3 * (13 * 13) = 507
3 * (26 * 26)  = 2028 +
                       = 2535

Each cell has 3 bounding box information.

I'm not sure how are this information arranged in the array of 2535. 


If the 0th index represents the first cell (0,0) of 13 scale for the first bounding box

what does the 1st index represent then?

**Does it represent the second bounding box information for the first cell (0,0) of 13 scale**

or

**Does it represent the first bounding box information for the second cell (0,1) of 13 scale?**"
44889,Make tf.debugging.assert_shapes support agnostic comparisons,"**System information**
- TensorFlow version (you are using): 2.3.1
- Are you willing to contribute it (Yes/No): No

**Describe the feature and the current behavior/state.**
`tf.debugging.assert_shapes` currently states that the tensors must have the shape specified by the constraints e.g.
```
>>> tf.debugging.assert_shapes([([0, 0], [1])])
ValueError: .  Specified explicitly.  Tensor shape=(2,) dtype=int32 dimension 0 must have size 1.  Received size 2, shape (2,)
```
This design makes sense, but doesn't allow for when you want to compare the shapes of two tensors, and you don't know if either of them is right, you just know they have to be the same. If I have two tensors `x` and `y`, and I do `tf.debugging.assert_shapes([(x, y.shape)])`, the error message states that `x` should have the shape of `y` at the call site, but it might be that `y` is wrong as well/instead, in which case the message is misleading. The argument `message` can help here, but it would have to contradict the default message.

**Will this change the current api? How?**
Only if we consider error messages public API.

**Who will benefit with this feature?**
Users? Not sure I can say anything more useful here"
44888,tf.debugging.assert_shapes inconsistent behaviour for scalars,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: n/a
- TensorFlow installed from (source or binary): pip install tensorflow
- TensorFlow version (use command below): 2.3.1
- Python version: 3.7
- Bazel version (if compiling from source): n/a
- GCC/Compiler version (if compiling from source): n/a
- CUDA/cuDNN version: n/a
- GPU model and memory: n/a

**Describe the current behavior**
`tf.debugging.assert_shapes` has seemingly inconsistent behaviour for scalars
```
import tensorflow as tf

tf.debugging.assert_shapes([(0, ())])  # passes as expected
tf.debugging.assert_shapes([(0, (1,))])  # passes unexpectedly
```
I think this is inconsistent, because `tf.constant(0)` does not have shape `(1,)`.

**Describe the expected behavior**
I would expect `tf.debugging.assert_shapes` to error if the `.shape` attribute is different from the shape constraint"
44887,Enable TensorFloat32 with XLA,"**System information**
- TensorFlow version (you are using): `2.5.0-dev20201115`
- Are you willing to contribute it (Yes/No): No (don't know how to)

**Describe the feature and the current behavior/state.**
Currently, TF32 works in the normal run time but not with XLA.

**Will this change the current api? How?**
No.

**Who will benefit with this feature?**
Anyone using Ampere GPUs and XLA compilation.

**Any Other info.**
I checked the TF32 was not being used with XLA using the following script:
```python
import tensorflow as tf
tf.debugging.set_log_device_placement(True)
tf.config.experimental.enable_tensor_float_32_execution(True)

@tf.function(experimental_compile=True)
def f(x):
    return x @ x
with tf.device(""/GPU:0""):
    x = tf.cast(tf.random.uniform(shape=(16,16)), tf.float32)
f(x)
```

I ran this on an A100 with dlprof. With `experimental_compile=False`, the following kernel ran:
![image](https://user-images.githubusercontent.com/12474257/99198812-fb3b9480-2768-11eb-9a39-a417e072a064.png)

With `experimental_compile=False` and `tf.config.experimental.enable_tensor_float_32_execution(False)`, the following kernel ran:
![image](https://user-images.githubusercontent.com/12474257/99198825-0c84a100-2769-11eb-8785-599f0527526e.png)

With  `experimental_compile=True` and `tf.config.experimental.enable_tensor_float_32_execution(True)`, the same kernel ran:
![image](https://user-images.githubusercontent.com/12474257/99198832-1b6b5380-2769-11eb-93fc-dce2e695d5d3.png)

This indicates to me that the TF32 is not enabled with XLA. Please let me know if I'm doing something wrong. Thanks!
"
44886,Bazel Build Issue,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Kubuntu 20.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): Source
- TensorFlow version: 2.3.1
- Python version: 3.8
- Installed using virtualenv? pip? conda?:
- Bazel version (if compiling from source): 3.1.0
- GCC/Compiler version (if compiling from source): 8.4
- CUDA/cuDNN version: 11.1/8
- GPU model and memory: 2070 / 8GB



**Describe the problem**
Trying to install tensorflow from source, I get the following error

ERROR: /home/pablo/.cache/bazel/_bazel_pablo/73a3c430b087017173c0bbcfb3b9758b/external/llvm-project/llvm/BUILD:1852:1: C++ compilation of rule '@llvm-project//llvm:Core' failed (Exit 1)
external/llvm-project/llvm/lib/IR/Function.cpp:46:10: fatal error: llvm/IR/IntrinsicsVE.h: No such file or directory
 #include ""llvm/IR/IntrinsicsVE.h""
          ^~~~~~~~~~~~~~~~~~~~~~~~
compilation terminated.
Target //tensorflow/tools/pip_package:build_pip_package failed to build
Use --verbose_failures to see the command lines of failed build steps.
INFO: Elapsed time: 64.162s, Critical Path: 26.84s
INFO: 593 processes: 593 local.
FAILED: Build did NOT complete successfully





**Provide the exact sequence of commands / steps that you executed before running into the problem**

Tensorflow configuration went ok, no problems. I compile with Bazel, and I get the error: bazel build --config=cuda //tensorflow/tools/pip_package:build_pip_package


**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
44885,Could not create cudnn handle TF2 GPU,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below): 2.1.0
- Python version: 3.7.9
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: cudart64_101.dll / 7.6.0.64
- GPU model and memory: RTX 2080


**Describe the current behavior**
2020-11-15 16:46:03.303728: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_ALLOC_FAILED
2020-11-15 16:46:03.307912: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_ALLOC_FAILED
2020-11-15 16:46:03.308022: W tensorflow/core/common_runtime/base_collective_executor.cc:217] BaseCollectiveExecutor::StartAbort Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.

I checked some ""Could not create cudnn handle"" errors but I couldn't find any solutions yet. And I installed also exactly same edition as tf mentioned in their sites.
-NVIDIA® GPU drivers —CUDA® 10.1 requires 418.x or higher.
-CUDA® Toolkit —TensorFlow supports CUDA® 10.1 (TensorFlow >= 2.1.0)
-CUPTI ships with the CUDA® Toolkit.
-cuDNN SDK 7.6 (see cuDNN versions).
-(Optional) TensorRT 6.0 to improve latency and throughput for inference on some models.

I'm trying to use my simple CNN code;

```
# Convolutional Neural Network

# Importing Libraries

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# Part 1 - Data Preprocessing

train_datagen = ImageDataGenerator(rescale = 1./255,
                                   shear_range = 0.2,
                                   zoom_range = 0.2,
                                   horizontal_flip = True)

training_set = train_datagen.flow_from_directory('C:/Users/batuh/OneDrive/Masaüstü/Udemy Courses/Deep Learning A-Z/Volume 1 - Supervised Deep Learning/Part 2 - Convolutional Neural Networks (CNN)/dataset/training_set',
                                                 target_size = (64, 64),
                                                 batch_size = 32,
                                                 class_mode = 'binary')

## Preprocessing the Test set

test_datagen = ImageDataGenerator(rescale = 1./255)
test_set = test_datagen.flow_from_directory('C:/Users/batuh/OneDrive/Masaüstü/Udemy Courses/Deep Learning A-Z/Volume 1 - Supervised Deep Learning/Part 2 - Convolutional Neural Networks (CNN)/dataset/test_set',
                                                 target_size = (64, 64),
                                                 batch_size = 32,
                                                 class_mode = 'binary')

# Part 2 - Building the CNN
## Initializing the CNN

cnn = tf.keras.models.Sequential()

## Step 1 - Convolution

cnn.add(tf.keras.layers.Conv2D(filters = 32, kernel_size = 3, activation = 'relu', 
                               input_shape = [64, 64, 3]))

## Step 2 - Pooling

cnn.add(tf.keras.layers.MaxPooling2D(pool_size = 2, strides = 2))

### Adding Second Conv. Layer

cnn.add(tf.keras.layers.Conv2D(filters = 32, kernel_size = 3, activation = 'relu'))
cnn.add(tf.keras.layers.MaxPooling2D(pool_size = 2, strides = 2))

## Step 3 - Flattening

cnn.add(tf.keras.layers.Flatten())

## Step 4 - Full Connection

cnn.add(tf.keras.layers.Dense(units = 128, activation = 'relu'))

## Step 5 - Output Layer

cnn.add(tf.keras.layers.Dense(units = 1, activation = 'sigmoid'))

# Part 3 - Training the CNN
## Compiling the CNN
#with tf.device('/GPU:0'):
cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])

## Training the CNN
cnn.fit(x = training_set, validation_data = test_set, epochs = 50)
```"
44884,tf.io.gfile can read but can't write file ,"**System information**

Running on Ai Platform using Tensorflow Cloud.
- Docker container: tensorflow/tensorflow:2.3.1
- Python version: 3.8

**Describe the current behavior**
Using tf.io to read/write files to Google Cloud Storage. I can listdir, read files but not write.

**Standalone code to reproduce the issue**

Assuming ""gs://bucket/folder"" existes, and ""gs://bucket/folder/folder1"" doesn't exist.

```
import tensorflow as tf

print(tf.io.gfile.exists(""gs://bucket/folder/folder1""))  # prints false
tf.io.gfile.makedirs(""gs://bucket/folder/folder1"")
print(tf.io.gfile.exists(""gs://bucket/folder/folder1""))  # prints true
```

So it seems like the code worked, but when I have a look at the bucket, I can't find the file. and when I run the script again, it has the same output, meaning it didn't find the file.

I did not touch the permissions as Ai Platform has required permissions. Also, the Ai Platform job and the bucket are in the same region.

I'll be happy to provide more information or any logs if relevant. I also did a small test on Compute Engine and had the same issue.
"
44883,Can you please provide Nvidia Driver version for all tensorflow version? Is tensorflow 1.15.0 compatible with 410 Driver version?,"Reusing code across different machines is difficult. The problem is that even if one could install a compatible tensorflow version, it's challenging to run code due to, `RuntimeError: cudaGetDevice() failed. Status: CUDA driver version is insufficient for CUDA runtime version` error.
The driver update is not accessible if one is using a remote server and I cant run the code in the server. Wastage of resources.
In my case, `nvidia-smi` says the driver version is 410 and has tensorflow version 1.12.0 which is an older version compared to my code developed. Unfortunately, I can't run my code developed in my local drive belonging to tensorflow version 1.14.0 or above. "
44882,AttributeError: module 'tensorflow.lite.python.schema_py_generated' has no attribute 'Model',"I have a problem with the conversion model using template code.
I am running on Jupyter Notebook
This is the template code：

# Convert the model to the TensorFlow Lite format without quantization
converter = tf.lite.TFLiteConverter.from_saved_model(MODEL_TF)
model_no_quant_tflite = converter.convert()

# Save the model to disk
open(MODEL_NO_QUANT_TFLITE, ""wb"").write(model_no_quant_tflite)
# Convert the model to the TensorFlow Lite format with quantization
def representative_dataset():
  for i in range(500):
    yield([x_train[i].reshape(1, 1)])
# Set the optimization flag.
converter.optimizations = [tf.lite.Optimize.DEFAULT]
# Enforce integer only quantization
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]
converter.inference_input_type = tf.int8
converter.inference_output_type = tf.int8
# Provide a representative dataset to ensure we quantize correctly.
converter.representative_dataset = representative_dataset
model_tflite = converter.convert()

# Save the model to disk
open(MODEL_TFLITE, ""wb"").write(model_tflite)

Output result：


AttributeError                            Traceback (most recent call last)
<ipython-input-50-0b17c299ecad> in <module>()
     18 # Provide a representative dataset to ensure we quantize correctly.
     19 converter.representative_dataset = representative_dataset
---> 20 model_tflite = converter.convert()
     21 
     22 # Save the model to disk

F:\anaconda3\lib\site-packages\tensorflow\lite\python\lite.py in convert(self)
    745         self.inference_input_type, self.inference_output_type)
    746     if flags_modify_model_io_type:
--> 747       result = _modify_model_io_type(result, **flags_modify_model_io_type)
    748 
    749     if self._experimental_sparsify_model:

F:\anaconda3\lib\site-packages\tensorflow\lite\python\util.py in modify_model_io_type(model, inference_input_type, inference_output_type)
    833     return model
    834 
--> 835   model_object = _convert_model_from_bytearray_to_object(model)
    836 
    837   if len(model_object.subgraphs) > 1:

F:\anaconda3\lib\site-packages\tensorflow\lite\python\util.py in _convert_model_from_bytearray_to_object(model_bytearray)
    570 def _convert_model_from_bytearray_to_object(model_bytearray):
    571   """"""Converts a tflite model from a bytearray into a parsable object.""""""
--> 572   model_object = schema_fb.Model.GetRootAsModel(model_bytearray, 0)
    573   model_object = schema_fb.ModelT.InitFromObj(model_object)
    574   model_object = copy.deepcopy(model_object)

AttributeError: module 'tensorflow.lite.python.schema_py_generated' has no attribute 'Model'
I want to know the reason"
44881,"Exception: Some of the operators in the model are not supported by TensorFlow Flex runtime: Enter, Exit.","**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Amazon Linux 2
- TensorFlow installed from (source or binary):
- TensorFlow version (or github SHA if from source): 1.15

**Provide the text output from tflite_convert**
```
Exception: Some of the operators in the model are not supported by TensorFlow Flex runtime: Enter, Exit.
```

**Any other info / logs**
Trying to convert a LSTM model trained in TensorFlow 1.15 to TFLite 1.15; however, cannot resolve the error message for these two control ops - Enter and Exit. I have tried the following settings, and can only resolve the problems with Switch and Merge operators. Any idea whether Enter and Exit will be supported in TFLite 1.15?  Thanks.

```
converter.target_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]
converter.post_training_quantize = True
converter.allow_custom_ops = True
converter.experimental_new_converter = True
tflite_model = converter.convert()
```
"
44879,TensorFlowLiteSelectTfOps: Interpreter creation fails on iOS when scheme is set to Release,"**System information**

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
iOS 14.1. Development environment is Xcode 12.2 (12B45b), macOS Big Sur 11.0.1.

- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
iPhone SE 2016

- TensorFlow installed from (source or binary) / TensorFlow version (use command below):
pod 'TensorFlowLiteSwift', '~> 0.0.1-nightly.20201107', :subspecs => ['CoreML', 'Metal']
pod 'TensorFlowLiteSelectTfOps', '0.0.1-nightly.20201031'

**Describe the current behavior**

Interpreter is created successfully when target scheme's build configuration is set to Debug. When build configuration is set to Release, it fails with:

> TensorFlow Lite Error: Regular TensorFlow ops are not supported by this interpreter. Make sure you apply/link the Flex delegate before inference.
> TensorFlow Lite Error: Node number 6 (FlexRFFT) failed to prepare.

**Describe the expected behavior**

Interpreter should be created successfully in Release builds.

**Standalone code to reproduce the issue**
```
import TensorFlowLite
...
let modelPath = Bundle.main.bundleURL.appendingPathComponent(""model.tflite"").path
do {
    let interpreter = try Interpreter(modelPath: modelPath)
    try interpreter.allocateTensors()
} catch {
    NSLog(""\(error)"")
}
```

**Other info / logs**

**Can work around by going to target > Build Settings and changing Dead Code Stripping to No.**"
44878,tf.data.Dataset.list_files result in segfault,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Not really
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No
- TensorFlow installed from (source or binary):from pip install tf-nightly
- TensorFlow version (use command below):tf-nightly==2.5.0.dev20201114
- Python version:3.7.0
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: Irrelevant
- GPU model and memory: GTX680, compute capability too low to be used (3.0)

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:

2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
v1.12.1-45796-gbefea92a3d 2.5.0-dev20201114


**Describe the current behavior**
```
In [1]: import tensorflow as tf
2020-11-14 21:20:53.955783: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: 
2020-11-14 21:20:53.955823: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.

In [2]: list_ds = tf.data.Dataset.list_files(""/"")
2020-11-14 21:20:58.154084: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2020-11-14 21:20:58.155020: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2020-11-14 21:20:58.193006: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-11-14 21:20:58.193331: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1724] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce GTX 680 computeCapability: 3.0
coreClock: 1.176GHz coreCount: 8 deviceMemorySize: 1.95GiB deviceMemoryBandwidth: 179.05GiB/s
2020-11-14 21:20:58.193434: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: 
2020-11-14 21:20:58.193503: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: 
2020-11-14 21:20:58.193567: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: 
2020-11-14 21:20:58.195053: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2020-11-14 21:20:58.195400: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2020-11-14 21:20:58.197271: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2020-11-14 21:20:58.197427: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: 
2020-11-14 21:20:58.197525: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: 
2020-11-14 21:20:58.197545: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1761] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2020-11-14 21:20:58.198519: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2020-11-14 21:20:58.198566: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1265] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-11-14 21:20:58.198579: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1271]      
Erreur de segmentation (core dumped)

```
**Describe the expected behavior**

Would just work and produce a dataset object

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

```
import tensorflow as tf 
list_ds = tf.data.Dataset.list_files(""/"")

```
**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

I initially thought I could use my GTX680 GPU, so I installed cuda libraries and cudnn with tensorflow-gpu. When I realized compute capability was too low, I just intalled tensorflow, in the hope that I would not experience any gpu related issue. Eventually I still got errors.

I also tried a bit of gdb:

Thread 30 ""python"" received signal SIGSEGV, Segmentation fault.
[Switching to Thread 0x7fff2b7fe700 (LWP 561116)]
__strnlen_sse2 () at ../sysdeps/x86_64/multiarch/../strlen.S:117

backtrace gives:
#0  __strnlen_sse2 () at ../sysdeps/x86_64/multiarch/../strlen.S:117
#1  0x00007ffff7e7f1a6 in __fnmatch (pattern=<optimized out>, string=<optimized out>, flags=1) at fnmatch.c:342
#2  0x00007fffd5869ff7 in tensorflow::FileSystem::Match(std::string const&, std::string const&) ()
   from /home/gnthibault/Documents/tests/python/tf_install/venv/lib/python3.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#3  0x00007fffd586f2e4 in std::_Function_handler<void (int), tensorflow::internal::GetMatchingPaths(tensorflow::FileSystem*, tensorflow::Env*, std::string const&, std::vector<std::string, std::allocator<std::string> >*)::{lambda(int)#1}::operator()(int) const::{lambda(int)#1}>::_M_invoke(std::_Any_data const&, int&&) ()
   from /home/gnthibault/Documents/tests/python/tf_install/venv/lib/python3.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#4  0x00007fffd586ed62 in std::_Function_handler<void (), tensorflow::internal::(anonymous namespace)::ForEach(int, int, std::function<void (int)> const&)::{lambda()#1}>::_M_invoke(std::_Any_data const&) () from /home/gnthibault/Documents/tests/python/tf_install/venv/lib/python3.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#5  0x00007fffd5876021 in Eigen::ThreadPoolTempl<tensorflow::thread::EigenEnvironment>::WorkerLoop(int) ()
   from /home/gnthibault/Documents/tests/python/tf_install/venv/lib/python3.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#6  0x00007fffd5872d33 in std::_Function_handler<void (), tensorflow::thread::EigenEnvironment::CreateThread(std::function<void ()>)::{lambda()#1}>::_M_invoke(std::_Any_data const&) ()
   from /home/gnthibault/Documents/tests/python/tf_install/venv/lib/python3.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#7  0x00007fffd1008335 in tensorflow::(anonymous namespace)::PThread::ThreadFn(void*) ()
   from /home/gnthibault/Documents/tests/python/tf_install/venv/lib/python3.7/site-packages/tensorflow/python/../libtensorflow_framework.so.2
#8  0x00007ffff7f8b609 in start_thread (arg=<optimized out>) at pthread_create.c:477
#9  0x00007ffff7eb2293 in clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:95
"
44877,Error while import tensorflow module,"I've installed TensorFlow by command (in power shell). It works
`python -m pip install --upgrade tensorflow`

then
`import tensorflow as tf`

I get this errors
`Traceback (most recent call last): File ""C:\Users\Asus\AppData\Local\Programs\Python\Python36\lib\site-packages\tensorflow\python\pywrap_tensorflow.py"", line 18, in swig_import_helper fp, pathname, description = imp.find_module('_pywrap_tensorflow', [dirname(file)]) File ""C:\Users\Asus\AppData\Local\Programs\Python\Python36\lib\imp.py"", line 296, in find_module raise ImportError(_ERR_MSG.format(name), name=name) ImportError: No module named '_pywrap_tensorflow'`
"
44876,"""FAILED: Build did NOT complete successfully (1 packages loaded)""","<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04.1
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA
- TensorFlow installed from (source or binary): Source
- TensorFlow version: I am not sure. I cloned it from the Github repository so it should be the latest version
- Python version: 3.7
- Installed using virtualenv? pip? conda?: Trying to install with Pip, but I am getting an error when I try to build a pip package via Bazel.
- Bazel version (if compiling from source): 3.1.0
- GCC/Compiler version (if compiling from source): 9.3.0
- CUDA/cuDNN version: NA
- GPU model and memory: Radeon RX 5700XT, G.Skill Trident-Z 2x16GB


**Describe the problem**
I am trying to build Tensorflow from the source since my training sessions are performing really slow and barely utilizing my hardware. I read that I can get better performance by building it from the source for my machine. However, I am getting an error when I tried to build a pip package via Bazel as according to the steps from the link:
https://www.tensorflow.org/install/source

This is the output I am getting when I try to build the package with Bazel:
```
root@weapon-of-mass-instruction:/home/chris/tensorflow# bazel build [--config=option] //tensorflow/tools/pip_package:build_pip_package
Extracting Bazel installation...
Starting local Bazel server and connecting to it...
INFO: Options provided by the client:
  Inherited 'common' options: --isatty=1 --terminal_columns=140
INFO: Reading rc options for 'build' from /home/chris/tensorflow/.bazelrc:
  Inherited 'common' options: --experimental_repo_remote_exec
INFO: Reading rc options for 'build' from /home/chris/tensorflow/.bazelrc:
  'build' options: --apple_platform_type=macos --define framework_shared_object=true --define open_source_build=true --java_toolchain=//third_party/toolchains/java:tf_java_toolchain --host_java_toolchain=//third_party/toolchains/java:tf_java_toolchain --define=tensorflow_enable_mlir_generated_gpu_kernels=0 --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --noincompatible_prohibit_aapt1 --enable_platform_specific_config --config=short_logs --config=v2
INFO: Reading rc options for 'build' from /home/chris/tensorflow/.tf_configure.bazelrc:
  'build' options: --action_env PYTHON_BIN_PATH=/usr/bin/python3 --action_env PYTHON_LIB_PATH=/usr/lib/python3/dist-packages --python_path=/usr/bin/python3 --config=xla --action_env TF_CONFIGURE_IOS=0
INFO: Found applicable config definition build:short_logs in file /home/chris/tensorflow/.bazelrc: --output_filter=DONT_MATCH_ANYTHING
INFO: Found applicable config definition build:v2 in file /home/chris/tensorflow/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1
INFO: Found applicable config definition build:xla in file /home/chris/tensorflow/.bazelrc: --define=with_xla_support=true
INFO: Found applicable config definition build:linux in file /home/chris/tensorflow/.bazelrc: --copt=-w --host_copt=-w --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --define=PROTOBUF_INCLUDE_PATH=$(PREFIX)/include --cxxopt=-std=c++14 --host_cxxopt=-std=c++14 --config=dynamic_kernels
INFO: Found applicable config definition build:dynamic_kernels in file /home/chris/tensorflow/.bazelrc: --define=dynamic_loaded_kernels=true --copt=-DAUTOLOAD_DYNAMIC_KERNELS
DEBUG: Rule 'io_bazel_rules_go' indicated that a canonical reproducible form can be obtained by modifying arguments shallow_since = ""1557349968 -0400""
DEBUG: Repository io_bazel_rules_go instantiated at:
  no stack (--record_rule_instantiation_callstack not enabled)
Repository rule git_repository defined at:
  /root/.cache/bazel/_bazel_root/a819f6789d392dd47d3107e5934b6ad1/external/bazel_tools/tools/build_defs/repo/git.bzl:195:18: in <toplevel>
ERROR: Skipping '[--config=option]': no such target '//:[--config=option]': target '[--config=option]' not declared in package '' defined by /home/chris/tensorflow/BUILD
ERROR: no such target '//:[--config=option]': target '[--config=option]' not declared in package '' defined by /home/chris/tensorflow/BUILD
INFO: Elapsed time: 8.402s
INFO: 0 processes.
FAILED: Build did NOT complete successfully (1 packages loaded)
    currently loading: tensorflow/tools/pip_package
    Fetching @local_config_cuda; Restarting.
```

**Provide the exact sequence of commands / steps that you executed before running into the problem**
```
1. git clone https://github.com/tensorflow/tensorflow.git
2. cd tensorflow
3. ./configure
4. Left everything default and chose no for ROCM/CUDA/Clang/etc.
5. bazel build [--config=option] //tensorflow/tools/pip_package:build_pip_package
```

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

I do not have an ROCM compatible GPU (at least as far as I am aware. If I am wrong, I would definitely appreciate some advice on making Tensorflow work with my card) so I am trying to optimize Tensorflow to run on my CPU, which is a Ryzen R9 3900X. When I run Tensorflow, it appears to barely utilize my CPU as according to my process monitor, so I am looking to build Tensorflow for my machine in hopes that it will make a difference in performance.

All advice and help with issue will be greatly appreciated!"
44875,Tensor flow: append tensor operation,"Hello. 
I have the following operation with **numpy** array:
`data.append(dataset[indices])`
**dataset[indices]** -  numpy.ndarray array with data [0.0345, 0.0522, -0.234, 0.118, -0.568, 0.772,...]
The number of data is big, so it takes a long time for calculation on CPU. To make calculations faster I used TensorFlow.
I found out that only tensor operations can be performed on GPU. 
That's why I needed such operation as `tf.append(...)` that could be add an element to an array inside of the tensor, declared by the following way: `tf.Variable([],tf.float32)` And after certain number of these operations an inside array of the tensor should be changed from empty to [0.0345, 0.0522, -0.234, 0.118, -0.568, 0.772,...]. After reading of documentation I didn't find such operation in TensorFlow

And the question is following: What is the way to make what I want, using Tensor operations?"
44874,Tensorflow degrading performance throughout training,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No not really
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- TensorFlow version (use command below): TensorFlow 2.4.0-rc1
(Ive also tried using tf-nightly-gpu 2.4.0.dev20201023 and tf-nightly-gpu 2.5.0.dev20201111 but nothing changed)
- Python version: python 3.8.5
- CUDA/cuDNN version: CUDA 11.1 / cuDNN 8.05
- GPU model and memory: RTX 3070 / 16GB RAM

**Describe the current behavior**
Each epoch takes longer and longer to complete. The first epoch started out at 50 seconds and on epoch 90 it was at almost at 1000 seconds an epoch. In the task manager, I can see that it slowly stops using the GPU after training for a while.

**Describe the expected behavior**
Each epoch should take the same amount of time.

**Standalone code to reproduce the issue**
```
import numpy as np
import os
import tensorflow as tf
from keras.callbacks import EarlyStopping
from keras.layers.core import Dense, Dropout, Activation, Flatten
from keras.layers import Conv2D, MaxPooling2D, BatchNormalization, LeakyReLU
from keras.models import Sequential
from keras.preprocessing.image import ImageDataGenerator
from keras.regularizers import l2

config = tf.compat.v1.ConfigProto(gpu_options = tf.compat.v1.GPUOptions(per_process_gpu_memory_fraction=0.70))
for device in tf.config.experimental.list_physical_devices(""GPU""):
    tf.config.experimental.set_memory_growth(device, True)
session = tf.compat.v1.Session(config=config)
tf.compat.v1.keras.backend.set_session(session)

IMG_SIZE = 350
Version = 1
batch_size = 8

val_aug = ImageDataGenerator(rescale=1/255)
aug = ImageDataGenerator(
        rescale=1/255, 
        rotation_range=30, 
        width_shift_range=0.1, 
        height_shift_range=0.1, 
        shear_range=0.2, 
        zoom_range=0.2, 
        channel_shift_range=25, 
        horizontal_flip=True, 
        fill_mode='constant')

train_gen = aug.flow_from_directory('F:/Storage/DataSet_Bal/Train', 
        target_size=(IMG_SIZE, IMG_SIZE), 
        batch_size=batch_size,
        class_mode='binary',
        shuffle=True)
val_gen = val_aug.flow_from_directory('F:/Storage/DataSet_Bal/Val', 
        target_size=(IMG_SIZE, IMG_SIZE), 
        batch_size=batch_size,
        class_mode='binary',
        shuffle=True)

model = Sequential()
model.add(Conv2D(64, 3, strides=(1,1), padding = 'same', activation = 'relu', input_shape = (IMG_SIZE, IMG_SIZE, 3)))
model.add(BatchNormalization())
model.add(Conv2D(64, 3, strides=(1,1), activation = 'relu'))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2, 2), strides=2))
model.add(BatchNormalization())

model.add(Conv2D(128, 3, strides=(1,1), activation = 'relu'))
model.add(BatchNormalization())
model.add(Conv2D(128, 3, strides=(1,1), activation = 'relu'))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2, 2), strides=2))
model.add(BatchNormalization())

model.add(Conv2D(256, 3, strides=(1,1), activation = 'relu'))
model.add(BatchNormalization())
model.add(Conv2D(256, 3, strides=(1,1), activation = 'relu'))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2, 2), strides=2))
model.add(BatchNormalization())

model.add(Conv2D(512, 3, strides=(1,1), activation = 'relu'))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(BatchNormalization())

model.add(Flatten())
model.add(Dense(128, activation = 'relu'))
model.add(BatchNormalization())
model.add(Dropout(0.5))
model.add(Dense(32, activation = 'relu'))
model.add(BatchNormalization())
model.add(Dropout(0.5))

model.add(Dense(1, activation = 'sigmoid'))


model.compile(loss = ""binary_crossentropy"", optimizer = 'adam', metrics = ['accuracy'])
#model.summary()

earlyStop = EarlyStopping(monitor = 'val_accuracy', min_delta = 0.0001, patience = 50, restore_best_weights = True)
model.fit(
    train_gen,
    workers=8,
    epochs= 250,
    validation_data=val_gen,
    callbacks=earlyStop,
    verbose=2)

model.save(f'F:/Storage/TrainedVersions/YiffModel{Version}')
```

**Other info / logs** 
Here is my output before it started training, maybe it reveals an issue:

```
2020-11-13 23:10:49.880564: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudart64_110.dll
2020-11-13 23:10:51.936872: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2020-11-13 23:10:51.937643: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library nvcuda.dll
2020-11-13 23:10:51.962681: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce RTX 3070 computeCapability: 8.6
coreClock: 1.725GHz coreCount: 46 deviceMemorySize: 8.00GiB deviceMemoryBandwidth: 417.29GiB/s
2020-11-13 23:10:51.963072: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudart64_110.dll
2020-11-13 23:10:51.976456: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublas64_11.dll
2020-11-13 23:10:51.976652: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublasLt64_11.dll
2020-11-13 23:10:51.981390: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cufft64_10.dll
2020-11-13 23:10:51.982700: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library curand64_10.dll
2020-11-13 23:10:51.991145: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusolver64_10.dll
2020-11-13 23:10:51.994156: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusparse64_11.dll
2020-11-13 23:10:51.994790: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudnn64_8.dll
2020-11-13 23:10:51.995118: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2020-11-13 23:10:51.996157: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-11-13 23:10:51.997339: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce RTX 3070 computeCapability: 8.6
coreClock: 1.725GHz coreCount: 46 deviceMemorySize: 8.00GiB deviceMemoryBandwidth: 417.29GiB/s
2020-11-13 23:10:51.997838: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudart64_110.dll
2020-11-13 23:10:51.998134: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublas64_11.dll
2020-11-13 23:10:51.998336: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublasLt64_11.dll
2020-11-13 23:10:51.998569: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cufft64_10.dll
2020-11-13 23:10:51.998775: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library curand64_10.dll
2020-11-13 23:10:51.998939: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusolver64_10.dll
2020-11-13 23:10:51.999074: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusparse64_11.dll
2020-11-13 23:10:51.999208: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudnn64_8.dll
2020-11-13 23:10:51.999393: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2020-11-13 23:10:52.570125: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-11-13 23:10:52.570326: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2020-11-13 23:10:52.570464: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2020-11-13 23:10:52.570786: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5734 MB memory) -> physical GPU (device: 0, name: GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6)
2020-11-13 23:10:52.571767: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
WARNING:tensorflow:From e:\PYTHON\YiffMiner\TrainYIFF.py:15: The name tf.keras.backend.set_session is deprecated. Please use tf.compat.v1.keras.backend.set_session instead.

2020-11-13 23:10:52.698623: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce RTX 3070 computeCapability: 8.6
coreClock: 1.725GHz coreCount: 46 deviceMemorySize: 8.00GiB deviceMemoryBandwidth: 417.29GiB/s
2020-11-13 23:10:52.699014: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudart64_110.dll
2020-11-13 23:10:52.699212: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublas64_11.dll
2020-11-13 23:10:52.699429: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublasLt64_11.dll
2020-11-13 23:10:52.699644: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cufft64_10.dll
2020-11-13 23:10:52.699843: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library curand64_10.dll
2020-11-13 23:10:52.700071: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusolver64_10.dll
2020-11-13 23:10:52.700276: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusparse64_11.dll
2020-11-13 23:10:52.700484: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudnn64_8.dll
2020-11-13 23:10:52.700719: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2020-11-13 23:10:52.700911: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-11-13 23:10:52.701114: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2020-11-13 23:10:52.701242: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2020-11-13 23:10:52.701519: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5734 MB memory) -> physical GPU (device: 0, name: GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6)
2020-11-13 23:10:52.701888: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2020-11-13 23:10:53.763226: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2020-11-13 23:10:55.655709: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublas64_11.dll
2020-11-13 23:10:56.552988: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublasLt64_11.dll
2020-11-13 23:10:57.143012: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudnn64_8.dll
2020-11-13 23:10:59.117292: I tensorflow/core/platform/windows/subprocess.cc:308] SubProcess ended with return code: 0

2020-11-13 23:10:59.160112: I tensorflow/core/platform/windows/subprocess.cc:308] SubProcess ended with return code: 0

2020-11-13 23:11:00.955185: I tensorflow/stream_executor/cuda/cuda_blas.cc:1838] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
Found 3266 images belonging to 2 classes.
Found 86 images belonging to 2 classes.
```"
44873,TF Dataset performance regression / best practices for data augmentation on the accelerator,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Win 10
- TensorFlow version (use command below): 2.3.0
- Python version: 3.6.9
- CUDA/cuDNN version: 10.1
- GPU model and memory: P100 (colab)

**Describe the current behaviour**
Iterating over a simple Dataset is very slow (even when using a @tf.function). It is 4 (CPU) - 6 (GPU) times slower than a comparable iteration using numpy.

**Describe the expected behaviour**
I would expect much faster execution of such a simple code, especially because of the optimisations that could be done on the computational graph. It should at least be on par with iterating in Python over numpy data / operations. I can imagine some share of the GPU overhead is attributable to the CUDA kernel launch overhead. I am working on a much more complex dataset structure (dealing witch random sequences + a batch of random additional data per sequence) and was surprised that a big part of the slowness of my structure can be attributed to the simple example presented here. 

I could probably create a dense dataset (with 100x or more (depending on sequence length) in memory footprint) to increase the speed but I believe this kind of data augmentation (different sequence offsets) should be done on the accelerator to not blow up the memory footprint unnecessary. I did not find any best practices regarding this very common problem I am very much following the philosophy (would rather call it ""hacking"") in the tensorflow function ""timeseries_dataset_from_array"": https://github.com/tensorflow/tensorflow/blob/fcc4b966f1265f466e82617020af93670141b009/tensorflow/python/keras/preprocessing/timeseries.py#L30

**Standalone code to reproduce the issue**
https://colab.research.google.com/drive/1j14DvChu7FJDyD6D8aZPb7w-h4mdTEVZ?usp=sharing

```
import tensorflow as tf
import numpy as np

d = 1000
z = tf.zeros((d, d), dtype=tf.float32)
ds = tf.data.Dataset.range(100).map(lambda x: z[:10, :10]).repeat().batch(256).take(1000)
@tf.function
def run():
  s = 0
  for x in ds:
    s = tf.reduce_sum(x)
    pass

run()

a = np.ones((d, d), dtype=np.float32)
s = 0
for _ in range(1000):
  for __ in range(256):
    s += np.sum(a[:10, :10])
```

"
44871,golang tensorflow issue,"go: finding module for package github.com/tensorflow/tensorflow/tensorflow/go/core/protobuf/for_core_protos_go_proto
../../go/pkg/mod/github.com/tensorflow/tensorflow@v2.3.1+incompatible/tensorflow/go/saved_model.go:25:2: module github.com/tensorflow/tensorflow@latest found (v2.3.1+incompatible), but does not contain package github.com/tensorflow/tensorflow/tensorflow/go/core/protobuf/for_core_protos_go_proto
"
44870," InvalidArgumentError: 2 root error(s) found.   (0) Invalid argument: You must feed a value for placeholder tensor 'dense_1_target_3' with dtype float and shape [?,?] 	 [[{{node dense_1_target_3}}]] 	 [[metrics_10/top_k_categorical_accuracy/Identity/_13387]]   (1) Invalid argument: You must feed a value for placeholder tensor 'dense_1_target_3' with dtype float and shape [?,?] 	 [[{{node dense_1_target_3}}]] 0 successful operations. 0 derived errors ignored.","This is the code where I have trained a single model 3 times.
```
def build_mobilenet(img_vec):
        print(""mobilenet loading.........."")
        model = Sequential()
        base_mobilenet_model = MobileNet(input_shape = img_vec.shape[1:], 
                                 include_top = False, weights = None)
        model.add(Input(shape = img_vec.shape[1:], name='input_layer'))
        model.add(base_mobilenet_model)
        model.add(GlobalAveragePooling2D())
        model.add(Dropout(0.5))
        model.add(Dense(len(all_labels), activation = 'sigmoid'))
        METRICS = [""binary_accuracy"", ""top_k_categorical_accuracy"", hn_multilabel_loss, tf.keras.metrics.AUC(), 'mae']
        model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = METRICS)
        model.summary()
        return model
```
The above-mentioned model was trained and saved 3 times and will be used for the ensemble as follows
```
def build_ensemble(img_vec):
    model_input = Input(shape = img_vec.shape[1:], name='input_layer_main')
    ## define fuctional blocks
    mobilenet1 = keras.models.load_model(""models/mobilenet_1_30epochs_multi-label.augmented.h5"", \
                                    custom_objects = {""hn_multilabel_loss"" : hn_multilabel_loss})
    mobilenet1._name , mobilenet1.trainable = ""model_1"", False
    ###
    mobilenet2 = keras.models.load_model(""models/mobilenet_2_30epochs_multi-label.augmented.h5"", \
                                    custom_objects = {""hn_multilabel_loss"" : hn_multilabel_loss})
    mobilenet2._name , mobilenet2.trainable = ""model_2"", False
    ###
    mobilenet3 = keras.models.load_model(""models/mobilenet_3_30epochs_multi-label.augmented.h5"", \
                                    custom_objects = {""hn_multilabel_loss"" : hn_multilabel_loss})
    mobilenet3._name , mobilenet3.trainable = ""model_3"", False

    #merge 3 models
    model1, model2, model3=(mobilenet1(model_input), mobilenet2(model_input), mobilenet3(model_input))
    merge = concatenate([model1, model2, model3], name=""concat_merge_123"")
    output_layer = Dense(len(all_labels), activation = 'sigmoid', name = ""output_layer"")(merge)
    
    model = keras.models.Model(inputs= model_input, outputs= output_layer)## model assign

    OPTIMIZER = Adam(learning_rate=0.001,beta_1=0.9, beta_2=0.999)

    METRICS = [""binary_accuracy"", ""top_k_categorical_accuracy"", hn_multilabel_loss, tf.keras.metrics.AUC(), 'mae']
    model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = METRICS)
    model.summary()
    return model
```
`model summary()`,
```
Model: ""model_3""
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_layer_main (InputLayer)   [(None, 128, 128, 1) 0                                            
__________________________________________________________________________________________________
model_1 (Sequential)            (None, 13)           3241613     input_layer_main[0][0]           
__________________________________________________________________________________________________
model_2 (Sequential)            (None, 13)           3241613     input_layer_main[0][0]           
__________________________________________________________________________________________________
model_3 (Sequential)            (None, 13)           3241613     input_layer_main[0][0]           
__________________________________________________________________________________________________
concat_merge_123 (Concatenate)  (None, 39)           0           model_1[1][0]                    
                                                                 model_2[1][0]                    
                                                                 model_3[1][0]                    
__________________________________________________________________________________________________
output_layer (Dense)            (None, 13)           520         concat_merge_123[0][0]           
==================================================================================================
Total params: 9,725,359
Trainable params: 520
Non-trainable params: 9,724,839
__________________________________________________________________________________________________
```
then during fitting, It gives the error

```
weight_path=""models/ensemble_model_multilabel.best.h5""

patience_reduce_lr=1
min_lr=1e-8
output_dir=""models/""
callbacks_list = [
            ModelCheckpoint(weight_path, monitor='val_accuracy', verbose=1, 
                             save_best_only=True, save_weights_only=False, mode='auto'),
            ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=patience_reduce_lr,
                              verbose=1, mode=""min"", min_lr=min_lr),
            ]
ensemble_model = build_ensemble(t_x)
hist3 = ensemble_model.fit_generator(train_gen, 
                              steps_per_epoch=100,
                              validation_data = (test_X, test_Y), 
                              epochs = 30, 
                              callbacks = callbacks_list)
```
I'm getting error,
```
Epoch 1/30
---------------------------------------------------------------------------
InvalidArgumentError                      Traceback (most recent call last)
<ipython-input-18-fe1e7c41d9e6> in <module>
     18                               validation_data = (test_X, test_Y),
     19                               epochs = 30,
---> 20                               callbacks = callbacks_list)
     21 
     22 ensemble_model.save(""models/ensemble_model_30epochs_multilabel-label.augmented.h5"")

~\anaconda3\lib\site-packages\tensorflow\python\keras\engine\training.py in fit_generator(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)
   1431         shuffle=shuffle,
   1432         initial_epoch=initial_epoch,
-> 1433         steps_name='steps_per_epoch')
   1434 
   1435   def evaluate_generator(self,

~\anaconda3\lib\site-packages\tensorflow\python\keras\engine\training_generator.py in model_iteration(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)
    262 
    263       is_deferred = not model._is_compiled
--> 264       batch_outs = batch_function(*batch_data)
    265       if not isinstance(batch_outs, list):
    266         batch_outs = [batch_outs]

~\anaconda3\lib\site-packages\tensorflow\python\keras\engine\training.py in train_on_batch(self, x, y, sample_weight, class_weight, reset_metrics)
   1173       self._update_sample_weight_modes(sample_weights=sample_weights)
   1174       self._make_train_function()
-> 1175       outputs = self.train_function(ins)  # pylint: disable=not-callable
   1176 
   1177     if reset_metrics:

~\anaconda3\lib\site-packages\tensorflow\python\keras\backend.py in __call__(self, inputs)
   3290 
   3291     fetched = self._callable_fn(*array_vals,
-> 3292                                 run_metadata=self.run_metadata)
   3293     self._call_fetch_callbacks(fetched[-len(self._fetches):])
   3294     output_structure = nest.pack_sequence_as(

~\anaconda3\lib\site-packages\tensorflow\python\client\session.py in __call__(self, *args, **kwargs)
   1456         ret = tf_session.TF_SessionRunCallable(self._session._session,
   1457                                                self._handle, args,
-> 1458                                                run_metadata_ptr)
   1459         if run_metadata:
   1460           proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)

InvalidArgumentError: 2 root error(s) found.
  (0) Invalid argument: You must feed a value for placeholder tensor 'dense_1_target_3' with dtype float and shape [?,?]
	 [[{{node dense_1_target_3}}]]
	 [[metrics_10/top_k_categorical_accuracy/Identity/_13387]]
  (1) Invalid argument: You must feed a value for placeholder tensor 'dense_1_target_3' with dtype float and shape [?,?]
	 [[{{node dense_1_target_3}}]]
0 successful operations.
0 derived errors ignored.
```"
44869,CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected,"CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected

```
$ export LD_LIBRARY_PATH=/usr/local/cuda-10.1/compat/:$LD_LIBRARY_PATH
python3 -c ""import tensorflow as tf; hello = tf.constant('hello world')""
2020-11-11 10:46:36.362374: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1
2020-11-11 10:46:37.459527: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1
2020-11-11 10:46:37.467224: E tensorflow/stream_executor/cuda/cuda_driver.cc:314] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2020-11-11 10:46:37.467270: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (16c54693e7f2): /proc/driver/nvidia/version does not exist
2020-11-11 10:46:37.467664: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-11-11 10:46:37.493842: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2300060000 Hz
2020-11-11 10:46:37.494252: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55dd7ef8bc70 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
```"
44868,Micro_speech error when given new model,"
**System information**
- Have I written custom code : Only changed the model and everything the model requires (size of it)
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Nano 33 BLE Sense 
- TensorFlow installed from (source or binary): Arduino Library
- TensorFlow Version: 2.1.0-ALPHA

When ran I get this error:
```
Feature generation failed
Requested feature_data_ size 536907080 doesn't match 1960

```
It should be the basic micro_speech output with words found and time of them found.
It was originally working with this model, but for some reason, it is not longer working. 

Code: https://github.com/michealcarac/TempMicroSpeech

In micro_speechwithfinal.ino:
```
int8_t feature_buffer[kFeatureElementCount];

 kFeatureElementCount = (kFeatureSliceSize * kFeatureSliceCount);

```
in micro_features_micro_model_settings.h

However, 
when 
```
static FeatureProvider static_feature_provider(kFeatureElementCount,
                                                 feature_buffer);
```
in  micro_speechwithfinal.ino

then in feature_provider.cpp
```

FeatureProvider::FeatureProvider(int feature_size, int8_t* feature_data)
    : feature_size_(feature_size),
      feature_data_(feature_data),
      is_first_run_(true) {
  // Initialize the feature data to default values.
  for (int n = 0; n < feature_size_; ++n) {
    feature_data_[n] = 0;
  }
}

```

BUT for some reason, feature_size_ is 536907080 yet kFeatureElementCount was 1960 in the beginning..."
44865,tensorflow gradient update does not match torch gradient update? ,"```python
import os
import sys

os.environ[
    ""KMP_DUPLICATE_LIB_OK""
] = ""True""  # uncomment this line if omp error occurs on OSX for python 3
os.environ[""MKL_NUM_THREADS""] = ""1""  # set number of MKL threads to run in parallel
os.environ[""OMP_NUM_THREADS""] = ""4""

import numpy as np
import tensorflow as tf
import torch
from tensorflow.keras import Sequential, datasets, layers, metrics, optimizers

# parameters
N, D_in, H, D_out = 40, 120, 1, 25
learning_rate = 0.1
opt = ""adam""  # 'adam'
# opt = 'sgd'


# helper utilies
def detach(tensor):
    if isinstance(tensor, torch.Tensor):
        if tensor.device.type == ""cuda"":
            tensor = tensor.cpu()
        if tensor.requires_grad:
            tensor = tensor.detach()
        tensor = tensor.numpy()

    return tensor


# Create random Tensors to hold inputs and outputs
x = torch.randn(N, D_in)
y = torch.randn(N, D_out)

x_tf = tf.convert_to_tensor(detach(x))
y_tf = tf.convert_to_tensor(detach(y))

####### tensorflow
network = Sequential([layers.Dense(D_out, activation=""relu"")])
network.build(input_shape=(None, D_in))
network.summary()


if opt == ""adam"":
    optimizer = optimizers.Adam(lr=learning_rate)
elif opt == ""sgd"":
    optimizer = optimizers.SGD(lr=learning_rate)
else:
    raise NotImplementedError(opt + "" not implemented."")


####### torch
# Use the nn package to define our model and loss function.
model = torch.nn.Sequential(
    torch.nn.Linear(D_in, D_out),
    torch.nn.ReLU(),
)
loss_fn = torch.nn.MSELoss(reduction=""mean"")

if opt == ""adam"":
    optimizer_th = torch.optim.Adam(model.parameters(), lr=learning_rate)
elif opt == ""sgd"":
    optimizer_th = torch.optim.SGD(model.parameters(), lr=learning_rate)
else:
    raise NotImplementedError(opt + "" not implemented."")


params_torch = list(model.parameters())

weights = params_torch[0]
biases = params_torch[1]

network.layers[0].set_weights([detach(weights).T, detach(biases)])


for t in range(10):
    with tf.GradientTape() as tape:

        out = network(x_tf)
        loss = tf.square(out - y_tf)
        loss = tf.reduce_sum(loss) / N / D_out

    grads = tape.gradient(loss, network.trainable_variables)
    optimizer.apply_gradients(zip(grads, network.trainable_variables))

    # torch
    optimizer_th.zero_grad()
    # Forward pass: compute predicted y by passing x to the model.
    y_pred = model(x)

    # Compute and print loss.
    loss_th = loss_fn(y_pred, y)

    loss_th.backward()

    params_torch = list(model.parameters())

    weights = params_torch[0]
    biases = params_torch[1]

    weights_grad = weights.grad
    biases_grad = biases.grad
    optimizer_th.step()

    print(
        ""check output diff:"", np.linalg.norm(y_pred.detach().numpy() - np.asarray(out))
    )

    print(t, ""loss: diff = {0:0.14f}."".format(loss_th.item() - np.asarray(loss)))

    print(
        ""check weights/biases grads diff:"",
        np.linalg.norm(weights_grad.detach().numpy() - np.asarray(grads[0]).T),
        np.linalg.norm(biases_grad.detach().numpy() - np.asarray(grads[1])),
    )

    print()
```

This is my comparison between torch and tensorflow but they don't match. 


```bash
check output diff: 2.6182365e-06
0 loss: diff = 0.00000000000000.
check weights/biases grads diff: 1.1457902e-07 2.150125e-08

check output diff: 0.17770502
1 loss: diff = 0.00141370296478.
check weights/biases grads diff: 0.031174246 0.002777245

check output diff: 1.8508035
2 loss: diff = 0.00122940540314.
check weights/biases grads diff: 0.0800667 0.0038902021

check output diff: 1.8711921
3 loss: diff = -0.00223851203918.
check weights/biases grads diff: 0.05721609 0.0050597424

check output diff: 1.6562314
4 loss: diff = 0.00020694732666.
check weights/biases grads diff: 0.031922814 0.0016808284

check output diff: 1.6612757
5 loss: diff = -0.00040757656097.
check weights/biases grads diff: 0.03356902 0.0019494247

check output diff: 1.9143565
6 loss: diff = -0.00022947788239.
check weights/biases grads diff: 0.055081423 0.005770285

check output diff: 2.6084518
7 loss: diff = 0.00054198503494.
check weights/biases grads diff: 0.032326505 0.0040451903

check output diff: 2.745288
8 loss: diff = -0.00023376941681.
check weights/biases grads diff: 0.030059196 0.002589117

check output diff: 2.4303644
9 loss: diff = 0.00073283910751.
check weights/biases grads diff: 0.018728718 0.0017236237

```
"
44864,Save and load models tutorial uses deprecated argument `period`,"

## URL(s) with the issue:

Please provide a link to the documentation entry, for example:
https://www.tensorflow.org/tutorials/keras/save_and_load#checkpoint_callback_options

## Description of issue (what needs changing):

Save and load tutorial uses deprecated argument `period`. This needs to be updated with `save_freq`.

```
# Create a callback that saves the model's weights every 5 epochs
cp_callback = tf.keras.callbacks.ModelCheckpoint(
    filepath=checkpoint_path, 
    verbose=1, 
    save_weights_only=True,
    period=5)
```

It also throws several warning as shown below

```
WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay
WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate
WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.
```

Please check the [gist here](https://colab.research.google.com/gist/jvishnuvardhan/66c6d0ead7f02600f7b0c67dc63bbd16/save_and_load.ipynb). Thanks!



"
44861,"TypeError: An op outside of the function building code is being passed a ""Graph"" tensor","**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution: Windows 10
- TensorFlow installed from (source or binary): Source
- TensorFlow version (use command below): 2.4-RC0
- Python version: 3.8
- CUDA/cuDNN version: 11/8.0.4
- GPU model and memory: RTX 3080, 10GB 

**Describe the current behavior**
I am trying to build a custom RNN cell, based on this paper:

> Using Fast Weights to Attend to the Recent Past
> Jimmy Ba, Geoffrey Hinton, Volodymyr Mnih, Joel Z. Leibo, Catalin Ionescu
> NIPS 2016, https://arxiv.org/abs/1610.06258

However, my implementation returns this error, but I have no clue what this means:

```
TypeError: An op outside of the function building code is being passed
a ""Graph"" tensor. It is possible to have Graph tensors
leak out of the function building context by including a
tf.init_scope in your function building code.
For example, the following function will fail:
  @tf.function
  def has_init_scope():
    my_constant = tf.constant(1.)
    with tf.init_scope():
      added = my_constant * 2
The graph tensor has name: FW-RNN/while/fw_rnn_cell_2/add_2:0

```


**Describe the expected behavior**
The model should simply start training.

**Standalone code to reproduce the issue**
Code:  https://gist.github.com/ion-elgreco/cc6fed29a4f6fb6813b71d5e7e8f2c87#file-fw_rnn-py

**Other info / logs** 
Error log: https://gist.github.com/ion-elgreco/cc6fed29a4f6fb6813b71d5e7e8f2c87#file-fw_rnn_error-txt
"
44858,"Error: ""tensorflow.python.framework.errors_impl.InvalidArgumentError"" when training Mask RCNN Inception Resnet V2 1024x1024 model","I am training a Mask R-CNN Inception ResNet V2 1024x1024 algorithm using my computer's GPU. This was downloaded from the TensorFlow Detection Model Zoo, and I labeled my images (dimensions of 1100x1100 pixels) with Label-img. Here is what I am working with:

 - GPU: NVIDIA GEFORCE RTX 2060
 - GPU: 16GB RAM, 6 processor cores
 - TensorFlow: 2.3.1
 - Python: 3.8.6
 - CUDA: 10.1
 - cuDNN: 7.6
 - Anaconda 3 command prompt

All tfrecord files have been generated, and when I start to train my model using ```python model_main_tf2.py --model_dir=models/my_faster_rcnn --pipeline_config_path=models/my_faster_rcnn/pipeline.config```, I get the following errors:

```
Traceback (most recent call last):
  File ""model_main_tf2.py"", line 113, in <module>
    tf.compat.v1.app.run()
  File ""C:\user\anaconda3\envs\object_detection_api\lib\site-packages\tensorflow\python\platform\app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""C:\user\anaconda3\envs\object_detection_api\lib\site-packages\absl\app.py"", line 303, in run
    _run_main(main, args)
  File ""C:\user\anaconda3\envs\object_detection_api\lib\site-packages\absl\app.py"", line 251, in _run_main
    sys.exit(main(argv))
  File ""model_main_tf2.py"", line 104, in main
    model_lib_v2.train_loop(
  File ""C:\user\anaconda3\envs\object_detection_api\lib\site-packages\object_detection\model_lib_v2.py"", line 564, in train_loop
    load_fine_tune_checkpoint(detection_model,
  File ""C:\user\anaconda3\envs\object_detection_api\lib\site-packages\object_detection\model_lib_v2.py"", line 350, in load_fine_tune_checkpoint
    features, labels = iter(input_dataset).next()
  File ""C:\user\anaconda3\envs\object_detection_api\lib\site-packages\tensorflow\python\distribute\input_lib.py"", line 645, in next
    return self.__next__()
  File ""C:\user\anaconda3\envs\object_detection_api\lib\site-packages\tensorflow\python\distribute\input_lib.py"", line 649, in __next__
    return self.get_next()
  File ""C:\user\anaconda3\envs\object_detection_api\lib\site-packages\tensorflow\python\distribute\input_lib.py"", line 694, in get_next
    self._iterators[i].get_next_as_list_static_shapes(new_name))
  File ""C:\user\anaconda3\envs\object_detection_api\lib\site-packages\tensorflow\python\distribute\input_lib.py"", line 1474, in get_next_as_list_static_shapes
    return self._iterator.get_next()
  File ""C:\user\anaconda3\envs\object_detection_api\lib\site-packages\tensorflow\python\data\ops\multi_device_iterator_ops.py"", line 581, in get_next
    result.append(self._device_iterators[i].get_next())
  File ""C:\user\anaconda3\envs\object_detection_api\lib\site-packages\tensorflow\python\data\ops\iterator_ops.py"", line 825, in get_next
    return self._next_internal()
  File ""C:\user\anaconda3\envs\object_detection_api\lib\site-packages\tensorflow\python\data\ops\iterator_ops.py"", line 764, in _next_internal
    return structure.from_compatible_tensor_list(self._element_spec, ret)
  File ""C:\user\anaconda3\envs\object_detection_api\lib\contextlib.py"", line 131, in __exit__
    self.gen.throw(type, value, traceback)
  File ""C:\user\anaconda3\envs\object_detection_api\lib\site-packages\tensorflow\python\eager\context.py"", line 2105, in execution_mode
    executor_new.wait()
  File ""C:\user\anaconda3\envs\object_detection_api\lib\site-packages\tensorflow\python\eager\executor.py"", line 67, in wait
    pywrap_tfe.TFE_ExecutorWaitForAllPendingNodes(self._handle)
tensorflow.python.framework.errors_impl.InvalidArgumentError: indices[16] = 16 is not in [0, 0)
         [[{{node GatherV2_7}}]]
         [[MultiDeviceIteratorGetNextFromShard]]
         [[RemoteCall]]
```

The config file that was used to run the model is:
```
# Mask R-CNN with Inception Resnet v2 (no atrous)
# Sync-trained on COCO (with 8 GPUs) with batch size 16 (1024x1024 resolution)
# Initialized from Imagenet classification checkpoint
#
# Train on GPU-8
#
# Achieves 40.4 box mAP and 35.5 mask mAP on COCO17 val

model {
  faster_rcnn {
    number_of_stages: 3
    num_classes: 1
    image_resizer {
      fixed_shape_resizer {
        height: 1024
        width: 1024
      }
    }
    feature_extractor {
      type: 'faster_rcnn_inception_resnet_v2_keras'
    }
    first_stage_anchor_generator {
      grid_anchor_generator {
        scales: [0.25, 0.5, 1.0, 2.0]
        aspect_ratios: [0.5, 1.0, 2.0]
        height_stride: 16
        width_stride: 16
      }
    }
    first_stage_box_predictor_conv_hyperparams {
      op: CONV
      regularizer {
        l2_regularizer {
          weight: 0.0
        }
      }
      initializer {
        truncated_normal_initializer {
          stddev: 0.01
        }
      }
    }
    first_stage_nms_score_threshold: 0.0
    first_stage_nms_iou_threshold: 0.7
    first_stage_max_proposals: 300
    first_stage_localization_loss_weight: 2.0
    first_stage_objectness_loss_weight: 1.0
    initial_crop_size: 17
    maxpool_kernel_size: 1
    maxpool_stride: 1
    second_stage_box_predictor {
      mask_rcnn_box_predictor {
        use_dropout: false
        dropout_keep_probability: 1.0
        fc_hyperparams {
          op: FC
          regularizer {
            l2_regularizer {
              weight: 0.0
            }
          }
          initializer {
            variance_scaling_initializer {
              factor: 1.0
              uniform: true
              mode: FAN_AVG
            }
          }
        }
        mask_height: 33
        mask_width: 33
        mask_prediction_conv_depth: 0
        mask_prediction_num_conv_layers: 4
        conv_hyperparams {
          op: CONV
          regularizer {
            l2_regularizer {
              weight: 0.0
            }
          }
          initializer {
            truncated_normal_initializer {
              stddev: 0.01
            }
          }
        }
        predict_instance_masks: true
      }
    }
    second_stage_post_processing {
      batch_non_max_suppression {
        score_threshold: 0.0
        iou_threshold: 0.6
        max_detections_per_class: 100
        max_total_detections: 100
      }
      score_converter: SOFTMAX
    }
    second_stage_localization_loss_weight: 2.0
    second_stage_classification_loss_weight: 1.0
    second_stage_mask_prediction_loss_weight: 4.0
    resize_masks: false
  }
}

train_config: {
  batch_size: 1
  num_steps: 200000
  optimizer {
    momentum_optimizer: {
      learning_rate: {
        cosine_decay_learning_rate {
          learning_rate_base: 0.008
          total_steps: 200000
          warmup_learning_rate: 0.0
          warmup_steps: 5000
        }
      }
      momentum_optimizer_value: 0.9
    }
    use_moving_average: false
  }
  gradient_clipping_by_norm: 10.0
  fine_tune_checkpoint_version: V2
  fine_tune_checkpoint: ""pre-trained-models/mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu-8/checkpoint/ckpt-0""
  fine_tune_checkpoint_type: ""detection""
  data_augmentation_options {
    random_horizontal_flip {
    }
  }
}

train_input_reader: {
  label_map_path: ""annotations/label_map.pbtxt""
  tf_record_input_reader {
    input_path: ""annotations/train.record""
  }
  load_instance_masks: true
  mask_type: PNG_MASKS
}

eval_config: {
  metrics_set: ""coco_detection_metrics""
  metrics_set: ""coco_mask_metrics""
  eval_instance_masks: true
  use_moving_averages: false
  batch_size: 1
  include_metrics_per_category: true
}

eval_input_reader: {
  label_map_path: ""annotations/label_map.pbtxt""
  shuffle: false
  num_epochs: 1
  tf_record_input_reader {
    input_path: ""annotations/test.record""
  }
  load_instance_masks: true
  mask_type: PNG_MASKS
}
```

**What can be done to fix this?**




##############################################

Below are the scripts that are referenced in the error:

File ""model_main_tf2.py"", line 113:
```
#Lines 74-113:
def main(unused_argv):
  flags.mark_flag_as_required('model_dir')
  flags.mark_flag_as_required('pipeline_config_path')
  tf.config.set_soft_device_placement(True)

  if FLAGS.checkpoint_dir:
    model_lib_v2.eval_continuously(
        pipeline_config_path=FLAGS.pipeline_config_path,
        model_dir=FLAGS.model_dir,
        train_steps=FLAGS.num_train_steps,
        sample_1_of_n_eval_examples=FLAGS.sample_1_of_n_eval_examples,
        sample_1_of_n_eval_on_train_examples=(
            FLAGS.sample_1_of_n_eval_on_train_examples),
        checkpoint_dir=FLAGS.checkpoint_dir,
        wait_interval=300, timeout=FLAGS.eval_timeout)
  else:
    if FLAGS.use_tpu:
      # TPU is automatically inferred if tpu_name is None and
      # we are running under cloud ai-platform.
      resolver = tf.distribute.cluster_resolver.TPUClusterResolver(
          FLAGS.tpu_name)
      tf.config.experimental_connect_to_cluster(resolver)
      tf.tpu.experimental.initialize_tpu_system(resolver)
      strategy = tf.distribute.experimental.TPUStrategy(resolver)
    elif FLAGS.num_workers > 1:
      strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()
    else:
      strategy = tf.compat.v2.distribute.MirroredStrategy()

    with strategy.scope():
      model_lib_v2.train_loop(
          pipeline_config_path=FLAGS.pipeline_config_path,
          model_dir=FLAGS.model_dir,
          train_steps=FLAGS.num_train_steps,
          use_tpu=FLAGS.use_tpu,
          checkpoint_every_n=FLAGS.checkpoint_every_n,
          record_summaries=FLAGS.record_summaries)

if __name__ == '__main__':
  tf.compat.v1.app.run()
```

File ""C:\user\anaconda3\envs\object_detection_api\lib\site-packages\tensorflow\python\platform\app.py"", line 40:
```
#Lines 17-40:
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import sys as _sys

from absl.app import run as _run

from tensorflow.python.platform import flags
from tensorflow.python.util.tf_export import tf_export


def _parse_flags_tolerate_undef(argv):
  """"""Parse args, returning any unknown flags (ABSL defaults to crashing).""""""
  return flags.FLAGS(_sys.argv if argv is None else argv, known_only=True)


@tf_export(v1=['app.run'])
def run(main=None, argv=None):
  """"""Runs the program with an optional 'main' function and 'argv' list.""""""

  main = main or _sys.modules['__main__'].main

  _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
```


File ""C:\user\anaconda3\envs\object_detection_api\lib\site-packages\absl\app.py"", line 303:
```
#Lines 294-328:
try:
    args = _run_init(
        sys.argv if argv is None else argv,
        flags_parser,
    )
    while _init_callbacks:
      callback = _init_callbacks.popleft()
      callback()
    try:
      _run_main(main, args)
    except UsageError as error:
      usage(shorthelp=True, detailed_error=error, exitcode=error.exitcode)
    except:
      exc = sys.exc_info()[1]
      # Don't try to post-mortem debug successful SystemExits, since those
      # mean there wasn't actually an error. In particular, the test framework
      # raises SystemExit(False) even if all tests passed.
      if isinstance(exc, SystemExit) and not exc.code:
        raise

      # Check the tty so that we don't hang waiting for input in an
      # non-interactive scenario.
      if FLAGS.pdb_post_mortem and sys.stdout.isatty():
        traceback.print_exc()
        print()
        print(' *** Entering post-mortem debugging ***')
        print()
        pdb.post_mortem()
      raise
  except Exception as e:
    _call_exception_handlers(e)
    raise

# Callbacks which have been deferred until after _run_init has been called.
_init_callbacks = collections.deque()
```


File ""C:\user\anaconda3\envs\object_detection_api\lib\site-packages\absl\app.py"", line 251:
```
#Lines 231-251:
def _run_main(main, argv):
  """"""Calls main, optionally with pdb or profiler.""""""
  if FLAGS.run_with_pdb:
    sys.exit(pdb.runcall(main, argv))
  elif FLAGS.run_with_profiling or FLAGS.profile_file:
    # Avoid import overhead since most apps (including performance-sensitive
    # ones) won't be run with profiling.
    import atexit
    if FLAGS.use_cprofile_for_profiling:
      import cProfile as profile
    else:
      import profile
    profiler = profile.Profile()
    if FLAGS.profile_file:
      atexit.register(profiler.dump_stats, FLAGS.profile_file)
    else:
      atexit.register(profiler.print_stats)
    retval = profiler.runcall(main, argv)
    sys.exit(retval)
  else:
    sys.exit(main(argv))
```


File ""model_main_tf2.py"", line 104:
```
#Lines 74-113:
def main(unused_argv):
  flags.mark_flag_as_required('model_dir')
  flags.mark_flag_as_required('pipeline_config_path')
  tf.config.set_soft_device_placement(True)

  if FLAGS.checkpoint_dir:
    model_lib_v2.eval_continuously(
        pipeline_config_path=FLAGS.pipeline_config_path,
        model_dir=FLAGS.model_dir,
        train_steps=FLAGS.num_train_steps,
        sample_1_of_n_eval_examples=FLAGS.sample_1_of_n_eval_examples,
        sample_1_of_n_eval_on_train_examples=(
            FLAGS.sample_1_of_n_eval_on_train_examples),
        checkpoint_dir=FLAGS.checkpoint_dir,
        wait_interval=300, timeout=FLAGS.eval_timeout)
  else:
    if FLAGS.use_tpu:
      # TPU is automatically inferred if tpu_name is None and
      # we are running under cloud ai-platform.
      resolver = tf.distribute.cluster_resolver.TPUClusterResolver(
          FLAGS.tpu_name)
      tf.config.experimental_connect_to_cluster(resolver)
      tf.tpu.experimental.initialize_tpu_system(resolver)
      strategy = tf.distribute.experimental.TPUStrategy(resolver)
    elif FLAGS.num_workers > 1:
      strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()
    else:
      strategy = tf.compat.v2.distribute.MirroredStrategy()

    with strategy.scope():
      model_lib_v2.train_loop(
          pipeline_config_path=FLAGS.pipeline_config_path,
          model_dir=FLAGS.model_dir,
          train_steps=FLAGS.num_train_steps,
          use_tpu=FLAGS.use_tpu,
          checkpoint_every_n=FLAGS.checkpoint_every_n,
          record_summaries=FLAGS.record_summaries)

if __name__ == '__main__':
  tf.compat.v1.app.run()
```


File ""C:\user\anaconda3\envs\object_detection_api\lib\site-packages\object_detection\model_lib_v2.py"", line 564:
```
#Line 545-569:
if record_summaries:
    summary_writer = tf.compat.v2.summary.create_file_writer(
        summary_writer_filepath)
  else:
    summary_writer = tf2.summary.create_noop_writer()

  if use_tpu:
    num_steps_per_iteration = 100
  else:
    # TODO(b/135933080) Explore setting to 100 when GPU performance issues
    # are fixed.
    num_steps_per_iteration = 1

  with summary_writer.as_default():
    with strategy.scope():
      with tf.compat.v2.summary.record_if(
          lambda: global_step % num_steps_per_iteration == 0):
        # Load a fine-tuning checkpoint.
        if train_config.fine_tune_checkpoint:
          load_fine_tune_checkpoint(detection_model,
                                    train_config.fine_tune_checkpoint,
                                    fine_tune_checkpoint_type,
                                    fine_tune_checkpoint_version,
                                    train_input,
                                    unpad_groundtruth_tensors)
```


File ""C:\user\anaconda3\envs\object_detection_api\lib\site-packages\object_detection\model_lib_v2.py"", line 350:
```
#Lines 312-350:
def load_fine_tune_checkpoint(
    model, checkpoint_path, checkpoint_type, checkpoint_version, input_dataset,
    unpad_groundtruth_tensors):
  """"""Load a fine tuning classification or detection checkpoint.

  To make sure the model variables are all built, this method first executes
  the model by computing a dummy loss. (Models might not have built their
  variables before their first execution)

  It then loads an object-based classification or detection checkpoint.

  This method updates the model in-place and does not return a value.

  Args:
    model: A DetectionModel (based on Keras) to load a fine-tuning
      checkpoint for.
    checkpoint_path: Directory with checkpoints file or path to checkpoint.
    checkpoint_type: Whether to restore from a full detection
      checkpoint (with compatible variable names) or to restore from a
      classification checkpoint for initialization prior to training.
      Valid values: `detection`, `classification`.
    checkpoint_version: train_pb2.CheckpointVersion.V1 or V2 enum indicating
      whether to load checkpoints in V1 style or V2 style.  In this binary
      we only support V2 style (object-based) checkpoints.
    input_dataset: The tf.data Dataset the model is being trained on. Needed
      to get the shapes for the dummy loss computation.
    unpad_groundtruth_tensors: A parameter passed to unstack_batch.

  Raises:
    IOError: if `checkpoint_path` does not point at a valid object-based
      checkpoint
    ValueError: if `checkpoint_version` is not train_pb2.CheckpointVersion.V2
  """"""
  if not is_object_based_checkpoint(checkpoint_path):
    raise IOError('Checkpoint is expected to be an object-based checkpoint.')
  if checkpoint_version == train_pb2.CheckpointVersion.V1:
    raise ValueError('Checkpoint version should be V2')

  features, labels = iter(input_dataset).next()
```


File ""C:\user\anaconda3\envs\object_detection_api\lib\site-packages\tensorflow\python\distribute\input_lib.py"", issues with line 645, 645, 694:

```
#Lines 615-728:
class DistributedIteratorBase(DistributedIteratorInterface):
  """"""Common implementation for all input iterators.""""""

  # pylint: disable=super-init-not-called
  def __init__(self, input_workers, iterators, strategy):
    static_shape = _get_static_shape(iterators)

    # TODO(b/133073708): we currently need a flag to control the usage because
    # there is a performance difference between get_next() and
    # get_next_as_optional(). And we only enable get_next_as_optional when the
    # output shapes are not static.
    #
    # TODO(rxsang): We want to always enable the get_next_as_optional behavior
    # when user passed input_fn instead of dataset.
    if getattr(
        strategy.extended, ""experimental_enable_get_next_as_optional"", False):
      self._enable_get_next_as_optional = (
          not static_shape) or strategy.extended._in_multi_worker_mode()
    else:
      self._enable_get_next_as_optional = False

    assert isinstance(input_workers, InputWorkers)
    if not input_workers.worker_devices:
      raise ValueError(""Should have at least one worker for input iterator."")

    self._iterators = iterators
    self._input_workers = input_workers
    self._strategy = strategy

  def next(self):
    return self.__next__()

  def __next__(self):
    try:
      return self.get_next()
    except errors.OutOfRangeError:
      raise StopIteration

  def __iter__(self):
    return self

  def get_next_as_optional(self):
    global_has_value, replicas = _get_next_as_optional(self, self._strategy)

    def return_none():
      return optional_ops.Optional.empty(self._element_spec)

    def return_value(replicas):
      """"""Wraps the inputs for replicas in an `tf.experimental.Optional`.""""""
      results = []
      for i, worker in enumerate(self._input_workers.worker_devices):
        with ops.device(worker):
          devices = self._input_workers.compute_devices_for_worker(i)
          for j, device in enumerate(devices):
            with ops.device(device):
              result = replicas[i][j]
              results.append(result)
      replicas = results

      return optional_ops.Optional.from_value(
          distribute_utils.regroup(replicas))

    return control_flow_ops.cond(global_has_value,
                                 lambda: return_value(replicas),
                                 lambda: return_none())  # pylint: disable=unnecessary-lambda

  def get_next(self, name=None):
    """"""Returns the next input from the iterator for all replicas.""""""
    if not self._enable_get_next_as_optional:
      replicas = []
      for i, worker in enumerate(self._input_workers.worker_devices):
        if name is not None:
          d = tf_device.DeviceSpec.from_string(worker)
          new_name = ""%s_%s_%d"" % (name, d.job, d.task)
        else:
          new_name = None
        with ops.device(worker):
          # Make `replicas` a flat list of values across all replicas.
          replicas.extend(
              self._iterators[i].get_next_as_list_static_shapes(new_name))
      return distribute_utils.regroup(replicas)

    out_of_range_replicas = []
    def out_of_range_fn(worker_index, device):
      """"""This function will throw an OutOfRange error.""""""
      # As this will be only called when there is no data left, so calling
      # get_next() will trigger an OutOfRange error.
      data = self._iterators[worker_index].get_next(device)
      out_of_range_replicas.append(data)
      return data

    global_has_value, replicas = _get_next_as_optional(self, self._strategy)
    results = []
    for i, worker in enumerate(self._input_workers.worker_devices):
      with ops.device(worker):
        devices = self._input_workers.compute_devices_for_worker(i)
        for j, device in enumerate(devices):
          with ops.device(device):
            # pylint: disable=undefined-loop-variable
            # pylint: disable=cell-var-from-loop
            # It is fine for the lambda to capture variables from the loop as
            # the lambda is executed in the loop as well.
            result = control_flow_ops.cond(
                global_has_value,
                lambda: replicas[i][j],
                lambda: out_of_range_fn(i, device),
                strict=True,
            )
            # pylint: enable=cell-var-from-loop
            # pylint: enable=undefined-loop-variable
            results.append(result)
    replicas = results

    return distribute_utils.regroup(replicas)
```



File ""C:\user\anaconda3\envs\object_detection_api\lib\site-packages\tensorflow\python\distribute\input_lib.py"", line 1474
```
#Lines 1459-1474:
def get_next_as_list_static_shapes(self, name=None):
    """"""Get next element from the underlying iterator.

    Runs the iterator get_next() within a device scope. Since this doesn't use
    get_next_as_optional(), is is considerably faster than get_next_as_list()
    (but can only be used when the shapes are static).

    Args:
      name: not used.

    Returns:
      A list consisting of the next data from each device.
    """"""
    del name
    with ops.device(self._worker):
      return self._iterator.get_next()
```


File ""C:\user\anaconda3\envs\object_detection_api\lib\site-packages\tensorflow\python\data\ops\multi_device_iterator_ops.py"", line 581:
```
#Lines 572-588:
def get_next(self, device=None):
    """"""Returns the next element given a `device`, else returns all in a list.""""""
    if device is not None:
      index = self._devices.index(device)
      return self._device_iterators[index].get_next()

    result = []
    for i, device in enumerate(self._devices):
      with ops.device(device):
        result.append(self._device_iterators[i].get_next())
    return result

  def __iter__(self):
    return self

  def __next__(self):
    return self.next()
```


File ""C:\user\anaconda3\envs\object_detection_api\lib\site-packages\tensorflow\python\data\ops\iterator_ops.py"", line 764 and 825:
```
#Lines 750-834:
with context.execution_mode(context.SYNC):
      with ops.device(self._device):
        # TODO(ashankar): Consider removing this ops.device() context manager
        # and instead mimic ops placement in graphs: Operations on resource
        # handles execute on the same device as where the resource is placed.
        ret = gen_dataset_ops.iterator_get_next(
            self._iterator_resource,
            output_types=self._flat_output_types,
            output_shapes=self._flat_output_shapes)

      try:
        # Fast path for the case `self._structure` is not a nested structure.
        return self._element_spec._from_compatible_tensor_list(ret)  # pylint: disable=protected-access
      except AttributeError:
        return structure.from_compatible_tensor_list(self._element_spec, ret)

  @property
  def _type_spec(self):
    return IteratorSpec(self.element_spec)

  def next(self):
    try:
      return self._next_internal()
    except errors.OutOfRangeError:
      raise StopIteration

  @property
  @deprecation.deprecated(
      None, ""Use `tf.compat.v1.data.get_output_classes(iterator)`."")
  def output_classes(self):
    """"""Returns the class of each component of an element of this iterator.

    The expected values are `tf.Tensor` and `tf.sparse.SparseTensor`.

    Returns:
      A nested structure of Python `type` objects corresponding to each
      component of an element of this dataset.
    """"""
    return nest.map_structure(
        lambda component_spec: component_spec._to_legacy_output_classes(),  # pylint: disable=protected-access
        self._element_spec)

  @property
  @deprecation.deprecated(
      None, ""Use `tf.compat.v1.data.get_output_shapes(iterator)`."")
  def output_shapes(self):
    """"""Returns the shape of each component of an element of this iterator.

    Returns:
      A nested structure of `tf.TensorShape` objects corresponding to each
      component of an element of this dataset.
    """"""
    return nest.map_structure(
        lambda component_spec: component_spec._to_legacy_output_shapes(),  # pylint: disable=protected-access
        self._element_spec)

  @property
  @deprecation.deprecated(
      None, ""Use `tf.compat.v1.data.get_output_types(iterator)`."")
  def output_types(self):
    """"""Returns the type of each component of an element of this iterator.

    Returns:
      A nested structure of `tf.DType` objects corresponding to each component
      of an element of this dataset.
    """"""
    return nest.map_structure(
        lambda component_spec: component_spec._to_legacy_output_types(),  # pylint: disable=protected-access
        self._element_spec)

  @property
  def element_spec(self):
    return self._element_spec

  def get_next(self):
    return self._next_internal()

  def get_next_as_optional(self):
    # pylint: disable=protected-access
    return optional_ops._OptionalImpl(
        gen_dataset_ops.iterator_get_next_as_optional(
            self._iterator_resource,
            output_types=structure.get_flat_tensor_types(self.element_spec),
            output_shapes=structure.get_flat_tensor_shapes(
                self.element_spec)), self.element_spec)
```


File ""C:\user\anaconda3\envs\object_detection_api\lib\contextlib.py"", line 131:
```
#Lines 97-162:
class _GeneratorContextManager(_GeneratorContextManagerBase,
                               AbstractContextManager,
                               ContextDecorator):
    """"""Helper for @contextmanager decorator.""""""

    def _recreate_cm(self):
        # _GCM instances are one-shot context managers, so the
        # CM must be recreated each time a decorated function is
        # called
        return self.__class__(self.func, self.args, self.kwds)

    def __enter__(self):
        # do not keep args and kwds alive unnecessarily
        # they are only needed for recreation, which is not possible anymore
        del self.args, self.kwds, self.func
        try:
            return next(self.gen)
        except StopIteration:
            raise RuntimeError(""generator didn't yield"") from None

    def __exit__(self, type, value, traceback):
        if type is None:
            try:
                next(self.gen)
            except StopIteration:
                return False
            else:
                raise RuntimeError(""generator didn't stop"")
        else:
            if value is None:
                # Need to force instantiation so we can reliably
                # tell if we get the same exception back
                value = type()
            try:
                self.gen.throw(type, value, traceback)
            except StopIteration as exc:
                # Suppress StopIteration *unless* it's the same exception that
                # was passed to throw().  This prevents a StopIteration
                # raised inside the ""with"" statement from being suppressed.
                return exc is not value
            except RuntimeError as exc:
                # Don't re-raise the passed in exception. (issue27122)
                if exc is value:
                    return False
                # Likewise, avoid suppressing if a StopIteration exception
                # was passed to throw() and later wrapped into a RuntimeError
                # (see PEP 479).
                if type is StopIteration and exc.__cause__ is value:
                    return False
                raise
            except:
                # only re-raise if it's *not* the exception that was
                # passed to throw(), because __exit__() must not raise
                # an exception unless __exit__() itself failed.  But throw()
                # has to raise the exception to signal propagation, so this
                # fixes the impedance mismatch between the throw() protocol
                # and the __exit__() protocol.
                #
                # This cannot use 'except BaseException as exc' (as in the
                # async implementation) to maintain compatibility with
                # Python 2, where old-style class exceptions are not caught
                # by 'except BaseException'.
                if sys.exc_info()[1] is value:
                    return False
                raise
            raise RuntimeError(""generator didn't stop after throw()"")
```



File ""C:\user\anaconda3\envs\object_detection_api\lib\site-packages\tensorflow\python\eager\context.py"", line 2105:
```
#Lines 2001-2013:
def graph_mode():
  """"""Context-manager to disable eager execution for the current thread.""""""
  return context()._mode(GRAPH_MODE)  # pylint: disable=protected-access


def eager_mode():
  """"""Context-manager to enable eager execution for the current thread.""""""
  return context()._mode(EAGER_MODE)  # pylint: disable=protected-access


def scope_name():
  """"""Name of the current scope.""""""
  return context().scope_name
```


File ""C:\user\anaconda3\envs\object_detection_api\lib\site-packages\tensorflow\python\eager\executor.py"", line 67:
```
#Lines 24-76:
class Executor(object):
  """"""A class for handling eager execution.

  The default behavior for asynchronous execution is to serialize all ops on
  a single thread. Having different `Executor` objects in different threads
  enables executing ops asynchronously in parallel:

  ```python
  def thread_function():
    executor = executor.Executor(enable_async=True):
    context.set_executor(executor)

  a = threading.Thread(target=thread_function)
  a.start()
  b = threading.Thread(target=thread_function)
  b.start()
  
  """"""

  def __init__(self, handle):
    self._handle = handle

  def __del__(self):
    try:
      # pywrap_tfe.TFE_ExecutorWaitForAllPendingNodes(self._handle)
      pywrap_tfe.TFE_DeleteExecutor(self._handle)
    except TypeError:
      # Suppress some exceptions, mainly for the case when we're running on
      # module deletion. Things that can go wrong include the pywrap module
      # already being unloaded, self._handle. no longer being
      # valid, and so on. Printing warnings in these cases is silly
      # (exceptions raised from __del__ are printed as warnings to stderr).
      pass  # 'NoneType' object is not callable when the handle has been
      # partially unloaded.

  def is_async(self):
    return pywrap_tfe.TFE_ExecutorIsAsync(self._handle)

  def handle(self):
    return self._handle

  def wait(self):
    """"""Waits for ops dispatched in this executor to finish.""""""
    pywrap_tfe.TFE_ExecutorWaitForAllPendingNodes(self._handle)

  def clear_error(self):
    """"""Clears errors raised in this executor during execution.""""""
    pywrap_tfe.TFE_ExecutorClearError(self._handle)


def new_executor(enable_async):
  handle = pywrap_tfe.TFE_NewExecutor(enable_async)
  return Executor(handle)
```
"
44857,RuntimeError: The layer has never been called and thus has no defined output shape.,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): Used Google Colab
- TensorFlow version (use command below): 2.3.0
- Python version: 3.6.9
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: Doesn't matter
- GPU model and memory: Doesn't matter

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
I used to run below mentioned code in the tensorflow version 1.15 but since the time I have upgraded it fails to run.
I have already gone through similar bugs, but they all mention that I should have provided the input shape, I have done that, so I am not sure where the problem lies.
```
model = DenseNet121(input_shape=(810, 1440, 3),
                                         include_top=False,
                                         weights='imagenet'
                                         )

depth = model.get_output_shape_at(0)[-1]
```

**Describe the expected behavior**
Expected behaviour should be that I should be able to get the output shape of the last layer.

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

Everyone can recreate the issue using the below colab link.
https://colab.research.google.com/drive/1TPYkETG8szsCvut6SdzY345jEnqOrgsg?usp=sharing

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

```
---------------------------------------------------------------------------
RuntimeError                              Traceback (most recent call last)
<ipython-input-4-c67805c58fe0> in <module>()
----> 1 depth = model.get_output_shape_at(0)[-1]

1 frames
/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py in get_output_shape_at(self, node_index)
   2028     """"""
   2029     return self._get_node_attribute_at_index(node_index, 'output_shapes',
-> 2030                                              'output shape')
   2031 
   2032   @doc_controls.do_not_doc_inheritable

/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py in _get_node_attribute_at_index(self, node_index, attr, attr_name)
   2601     if not self._inbound_nodes:
   2602       raise RuntimeError('The layer has never been called '
-> 2603                          'and thus has no defined ' + attr_name + '.')
   2604     if not len(self._inbound_nodes) > node_index:
   2605       raise ValueError('Asked to get ' + attr_name + ' at node ' +

RuntimeError: The layer has never been called and thus has no defined output shape.
```
"
44856,No Operation named [input] in the Graph running in React-Native,"**System information**
- Environment:
  OS: macOS High Sierra 10.13.6
  Node: 14.12.0
  Yarn: 1.22.5
  npm: 6.14.8
  Watchman: 4.9.0
  Xcode: Not Found
  Android Studio: 4.0 AI-193.6911.18.40.6626763

- Packages: (wanted => installed)
  react: 16.0.0 => 16.0.0
  react-native: 0.51.0 => 0.51.0

- TensorFlow installed from (source or binary): danjarvis/tensorflow-android:1.0.0
- TensorFlow version (or github SHA if from source): danjarvis/tensorflow-android:1.0.0


**Command used to run the converter or code if you’re using the Python API**
If possible, please share a link to Colab/Jupyter/any notebook.
```
# Copy and paste here the exact command
```
python /tensorflow/tensorflow/examples/image_retraining/retrain.py \
--bottleneck_dir=/tf_files/bottlenecks \
--how_many_training_steps 500 \
--model_dir=/tf_files_inception  \
--output_graph=/tf_files/star_wars_graph.pb \
--output_labels=/tf_files/star_wars_labels.txt \
--image_dir /tf_files/star_wars

This command will generate the .pb and txt using inception-v3, but and the tutorial said i have to do the following to ""convert"" to inception-v1.

python /tensorflow/tensorflow/python/tools/optimize_for_inference.py \
--input=/tf_files/star_wars_graph.pb \
--output=/tf_files/star_wars_graph_optimized.pb \
--frozen_graph=True \
--input_names=Mul \
--output_names=final_result

and then

python /tensorflow/tensorflow/tools/quantization/quantize_graph.py \
--input=/tf_files/star_wars_graph_optimized.pb \
--output=/tf_files/star_wars_rounded_graph.pb \
--output_node_names=final_result \
--mode=weights_rounded

**The output from the converter invocation**

```
# Copy and paste the output here.
```
No out put is showen

**Also, please include a link to the saved model or GraphDef**

```
# Put link here or attach to the issue.
```
The link is this, but is in portuguese [http://www.davifelipe.com.br/tensorflow-gerando-model-para-dispositivo-movel](url)

**Failure details**
If the conversion is successful, but the generated model is wrong,
state what is wrong:
- Producing wrong results and/or decrease in accuracy
- Producing correct results, but the model is slower than expected (model generated from old converter)


**RNN conversion support**
If converting TF RNN to TFLite fused RNN ops, please prefix [RNN] in the title.

**Any other info / logs**

Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

Everythings runs fine, but an alert saying the error is showed
![Captura de Tela 2020-11-13 às 16 27 59](https://user-images.githubusercontent.com/2678092/99112982-4620a500-25cd-11eb-908f-f3641c97fa08.png)

"
44854,Keras custom data generator giving dimension errors with multi input and multi output( functional api model),"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 20.04 and Colab):
- TensorFlow installed from; Pip3 install ..
- Tensorflow version: v2.3.0-54-gfcc4b966f1 2.3.1

Colab Code to reproduce: https://colab.research.google.com/drive/1bSJm44MMDCWDU8IrG2GXKBvXNHCuY70G?usp=sharing

Note: I have updated the issue at the end as well.


I have written a generator function with Keras, before returning X,y from `__getitem__` I have double check the shapes of the X's and Y's and they are alright, but generator is giving dimension mismatch array and warnings.

I suspect that the problem is relating multiple input, which is being cosidered one by the input layer of tf.keras. Each input features is of shape (32,10,1) but yielding `[input_array_1,input_array_2,input_array_3]` makes it (3,32,10,1)

My training and validation generators are pretty musch same as

    class ValidGenerator(Sequence):
        def __init__(self, df, batch_size=64):
            self.batch_size = batch_size
            self.df = df
            self.indices = self.df.index.tolist()
            self.num_classes = num_classes
            self.shuffle = shuffle
            self.on_epoch_end()
    
        def __len__(self):
            return int(len(self.indices) // self.batch_size)
    
        def __getitem__(self, index):
            index = self.index[index * self.batch_size:(index + 1) * self.batch_size]
            batch = [self.indices[k] for k in index]
            
            X, y = self.__get_data(batch)
            return X, y
    
        def on_epoch_end(self):
            self.index = np.arange(len(self.indices))
            if self.shuffle == True:
                np.random.shuffle(self.index)
    
        def __get_data(self, batch):
            #some logic is written here
            #hat prepares 3 X features and 3 Y outputs 
            X = [input_array_1,input_array_2,input_array_3]
            y = [out_1,out_2,out_3]
            #print(len(X))
            
            return X, y

I am returning tuple of X,y from which has 3 input features and 3 output features each, so shape of X is `(3,32,10,1)`

I am using functional api to build model(I have things like concatenation, multi input/output, which isnt possible with sequential)  with following structure

[![enter image description here][1]][1]

When I try to fit the model with generator with following code

    train_datagen = TrainGenerator(df=train_df,  batch_size=32, num_classes=None, shuffle=True)
    valid_datagen = ValidGenerator(df=train_df,  batch_size=32, num_classes=None, shuffle=True)
    model.fit(train_datagen, epochs=2,verbose=1,callbacks=[checkpoint,es])

I get these warnings and errors, that dont go away

>Epoch 1/2
>WARNING:tensorflow:Model was constructed with shape (None, 10) for input >Tensor(""input_1:0"", shape=(None, 10), dtype=float32), but it was called >on an input with incompatible shape (None, None, None).

>WARNING:tensorflow:Model was constructed with shape (None, 10) for input 
> Tensor(""input_2:0"", shape=(None, 10), dtype=float32), but it was
> called on an input with incompatible shape (None, None, None).
> WARNING:tensorflow:Model was constructed with shape (None, 10) for
> input Tensor(""input_3:0"", shape=(None, 10), dtype=float32), but it was
> called on an input with incompatible shape (None, None, None).
> ...
>...
> __call__
>         return super(RNN, self).__call__(inputs, **kwargs)
>     /home/eduardo/.virtualenvs/kgpu3/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:975
> __call__
>         input_spec.assert_input_compatibility(self.input_spec, inputs,
>     /home/eduardo/.virtualenvs/kgpu3/lib/python3.8/site-packages/tensorflow/python/keras/engine/input_spec.py:176
> assert_input_compatibility
>         raise ValueError('Input ' + str(input_index) + ' of layer ' +
> 
>     ValueError: Input 0 of layer lstm is incompatible with the layer: expected ndim=3, found ndim=4. Full shape received: [None, None, None, 88]

I have rechecked whole code and it isnt possible to have input (None,None,None) like in warning or in error, my input dimension is `(3,32,10,1)`
  
**Update**

I have also tried to write a generator function with python and got exactly same error. 

My generator function


    def generate_arrays_from_file(batchsize,df):
        #print(bat)
        inputs = []
        targets = []
        batchcount = 0
        while True:
                
                df3 = df.loc[np.arange(batchcount*batchsize,(batchcount*batchsize)+batchsize)]
                #Some pre processing
                X = [input_array_1,input_array_2,input_array_3]
                y = [out_1,out_2,out_3]
                yield X,y 
                batchcount = batchcount +1

It seems like it is something wrong internally wit keras (may be due to the fact I am using functional API)

**Update 2**

I also tried to output tuple 

              X = (input1_X,input2_X,input3_X)
              y = (output1_y,output2_y,output3_y)

and also named input/output, but it doesnt work

            X =  {""input_1"": input1_X, ""input_2"": input2_X,""input_3"": input3_X}
            y = {""output_1"": output1_y, ""output_2"": output2_y,""output_3"": output3_y}

**Note about problem formulation:**

Changing the individual X features to shape (32,10) instead of (32,10,1) might help to get rid of this error but that is not what I want, it changes my problem(I no longer have 10 time steps with one feature each)

  [1]: https://i.stack.imgur.com/EaShF.png

"
44852,`GetIntPtr` in `tensorflow/lite/tools/verifier.cc` do not get correct value on Big Endian machine,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): N
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 20.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): 2.3.1
- Python version: 3.8.5
- Bazel version (if compiling from source): 3.1.0
- GCC/Compiler version (if compiling from source): gcc (Ubuntu 9.3.0-17ubuntu1~20.04) 9.3.0
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A

**Describe the current behavior**
The [GetIntPtr](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/tools/verifier.cc#L53) in `tensorflow/lite/tools/verifier.cc` is retrieving the `int` value from a typed `const char*` buffer. However, since flatbuffers always stores the data in Little Endian format regardless of host machine endianness, the direct `reinterpret_cast<const uint32_t*>` call will retrieve the wrong value on Big Endian platforms (as `reinterpret_cast` will assume the data is in host endianness), so the retrieved value needs to be byte-swapped.

**Describe the expected behavior**
`GetIntPtr` function should byteswap the value on Big Endian platform.

**Standalone code to reproduce the issue**
```
bazel test --host_javabase=""@local_jdk//:jdk"" --cache_test_results=no --build_tests_only --test_output=errors -- //tensorflow/lite/tools:verifier_test
```
This test will fail due to this reason on Big Endian systems.

**Other info / logs** 
Usually, to solve this issue we could simply add a guard for `__ORDER_BIG_ENDIAN__` and byteswap accordingly. The issue here is that the input type is `const char*` and the output type is `const uint32_t*`. Apparently, we do not want to make the change in-place, so at least we need to get a copy of the data then byteswap it and return it. Also, since we need to return a pointer, we have to allocate a new variable then return the address of it. The change could look like:
```diff
diff --git a/tensorflow/lite/tools/verifier.cc b/tensorflow/lite/tools/verifier.cc
index 1d0b813a2c..063246dcf2 100644
--- a/tensorflow/lite/tools/verifier.cc
+++ b/tensorflow/lite/tools/verifier.cc
@@ -40,7 +40,13 @@ void ReportError(ErrorReporter* error_reporter, const char* format, ...) {
 
 // Returns the int32_t value pointed by ptr.
 const uint32_t* GetIntPtr(const char* ptr) {
+#if __BYTE_ORDER__ == __ORDER_BIG_ENDIAN__
+  uint32_t ret_val = flatbuffers::EndianScalar(*reinterpret_cast<const uint32_t*>(ptr));
+  const uint32_t ret = &ret_val;
+  return ret;
+#else
   return reinterpret_cast<const uint32_t*>(ptr);
+#endif
 }
 
 // Verifies flatbuffer format of the model contents and returns the in-memory
```

The problem with this approach is the local variable `ret_val` will not live long enough for its value to be retrieved - so what we can get from `*GetIntPtr(buffer_ptr)` is basically a deallocated memory space. Since it is unavoidable that we need to allocate new memory space, we have to make it outlive the function call. I also tried `static uint32_t ret_val`, and it worked for the first function call but fail for the following ones. Seems like the `const uint32_t*` return type makes the compiler believe `static uint32_t ret_val` is const after the first call.

Due to these reasons, seems like we could not make a simple modification to the function `GetIntPtr()` to fix the issue; it seems that we have to take care of the issue every time the function is called (by either create a new static variable for each function call or simply deal with the value manually after the function returns) if we keep the current signature of the function.

However, I do have another solution here, which is to change the return type from `const uint32_t*` to `const uint32_t`. This change is applicable because this function is only used within `verifier.cc`, and every time it is called we simply need the value of it (i.e. we only need `*GetIntPtr(buffer_ptr)`). So it actually does not incur any issue if we make the change. The endianness issue will also be easily solved by something like this (plus change from `*GetIntPtr` to `GetIntPtr` wherever it is called):
```diff
diff --git a/tensorflow/lite/tools/verifier.cc b/tensorflow/lite/tools/verifier.cc
index 1d0b813a2c..bb71f1228e 100644
--- a/tensorflow/lite/tools/verifier.cc
+++ b/tensorflow/lite/tools/verifier.cc
@@ -39,8 +39,12 @@ void ReportError(ErrorReporter* error_reporter, const char* format, ...) {
 }
 
 // Returns the int32_t value pointed by ptr.
-const uint32_t* GetIntPtr(const char* ptr) {
-  return reinterpret_cast<const uint32_t*>(ptr);
+const uint32_t GetIntPtr(const char* ptr) {
+#if __BYTE_ORDER__ == __ORDER_BIG_ENDIAN__
+  return flatbuffers::EndianScalar(*reinterpret_cast<const uint32_t*>(ptr));
+#else
+  return *reinterpret_cast<const uint32_t*>(ptr);
+#endif
 }
 
 // Verifies flatbuffer format of the model contents and returns the in-memory
```

I could submit a PR for such a change if it is considered valid, and I will appreciate it if there are any other simple solutions or suggestions."
44844,Confusing results from tf.math.mod. An issue with precision?,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MACOS 10.14.5
- TensorFlow installed from (source or binary): installed using pip
- TensorFlow version (use command below): 2.2.0
- Python version: 3.7.7

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:

2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

```
v2.2.0-rc4-8-g2b96f3662b 2.2.0
```


**Describe the current behavior**

I am attempting to use tensorflow to compute the modulus of two numbers and seeing some strange behaviour that seems to be related to the precision being used.

I have attached an example block of code and two example outputs below.
The example code simply computes the modulus of the two input numbers (x, y) and as you can see, depending on the precision that the inputs are cast to the output can be quite different.

As a cross check the code example also computes the modulus using numpy (and casts to the equivalent? dtypes).
I find that the higher precision numpy results are much closer to the true answer.

Interestingly, we find that the results for
 numpy.float16 and tf.float16 agree
 numpy.float32 and tf.float32 agree

but
numpy.float64 and tf.float64 *disagree*

Instead tf.float32 and tf.float64 actually agree with each other though. Does this point to a bug with the tf.float64?

Thanks in advance!

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

```python
import numpy as np
import tensorflow as tf

def example_for_git(x, y):
    print(""tensorflow\n"")
    print(f""tf fl16: {tf.math.mod(tf.cast(x, tf.float16), tf.cast(y, tf.float16)).numpy()}"")
    print(f""tf fl32: {tf.math.mod(tf.cast(x, tf.float32), tf.cast(y, tf.float32)).numpy()}"")
    print(f""tf fl64: {tf.math.mod(tf.cast(x, tf.float64), tf.cast(y, tf.float64)).numpy()}"")
    print(""\nnumpy\n"")
    print(f""np fl16: {np.mod(np.float16(x), np.float16(y))}"")
    print(f""np fl32: {np.mod(np.float32(x), np.float32(y))}"")
    print(f""np fl64: {np.mod(np.float64(x), np.float64(y))}"")
    print(f""np fl128: {np.mod(np.float128(x), np.float128(y))}"")

example_for_git(80002.2, 1)
"""""" output: the expected result of mod(80002.2, 1) is 0.2
tensorflow

tf fl16: nan
tf fl32: 0.203125
tf fl64: 0.203125

numpy

np fl16: nan
np fl32: 0.203125
np fl64: 0.19999999999708962
np fl128: 0.19999999999708962
""""""


example_for_git(851839.8270638183, 2*np.pi)
"""""" output
tensorflow

tf fl16: nan
tf fl32: 3.2239599227905273
tf fl64: 3.2239599227905273

numpy

np fl16: nan
np fl32: 3.2239599227905273
np fl64: 3.262228253121961
np fl128: 3.262228253121961
""""""
```


"
44843,ValueError: Checkpoint version should be V2,"GPU: NVIDIA GEFORCE RTX 2060
CPU: 16GB RAM, 6 processor cores
TensorFlow: 2.3.1
Python: 3.8.6
CUDA: 10.1
cuDNN: 7.6

I am training a Mask R-CNN Inception ResNet V2 1024x1024 algorithm, as downloaded from the [TensorFlow 2 Detection Model Zoo](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md) . I am training this algorithm on my custom dataset, which I have labeled using [Label-img](https://github.com/tzutalin/labelImg) . When I train the model using the Anaconda command ```python model_main_tf2.py --model_dir=models/my_faster_rcnn --pipeline_config_path=models/my_faster_rcnn/pipeline.config```, I get the following error:

```
Traceback (most recent call last):
  File ""model_main_tf2.py"", line 113, in <module>
    tf.compat.v1.app.run()
  File ""C:\user\anaconda3\envs\object_detection_api\lib\site-packages\tensorflow\python\platform\app.py"", line 40, in run
    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
  File ""C:\user\anaconda3\envs\object_detection_api\lib\site-packages\absl\app.py"", line 303, in run
    _run_main(main, args)
  File ""C:\user\anaconda3\envs\object_detection_api\lib\site-packages\absl\app.py"", line 251, in _run_main
    sys.exit(main(argv))
  File ""model_main_tf2.py"", line 104, in main
    model_lib_v2.train_loop(
  File ""C:\user\anaconda3\envs\object_detection_api\lib\site-packages\object_detection\model_lib_v2.py"", line 564, in train_loop
    load_fine_tune_checkpoint(detection_model,
  File ""C:\user\anaconda3\envs\object_detection_api\lib\site-packages\object_detection\model_lib_v2.py"", line 348, in load_fine_tune_checkpoint
    raise ValueError('Checkpoint version should be V2')
ValueError: Checkpoint version should be V2
```

**How can I resolve this error?** Below are the scripts referenced in the error:

model_main_tf2.py
```
# Lint as: python3
# Copyright 2020 The TensorFlow Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ==============================================================================

r""""""Creates and runs TF2 object detection models.

For local training/evaluation run:
PIPELINE_CONFIG_PATH=path/to/pipeline.config
MODEL_DIR=/tmp/model_outputs
NUM_TRAIN_STEPS=10000
SAMPLE_1_OF_N_EVAL_EXAMPLES=1
python model_main_tf2.py -- \
  --model_dir=$MODEL_DIR --num_train_steps=$NUM_TRAIN_STEPS \
  --sample_1_of_n_eval_examples=$SAMPLE_1_OF_N_EVAL_EXAMPLES \
  --pipeline_config_path=$PIPELINE_CONFIG_PATH \
  --alsologtostderr
""""""
from absl import flags
import tensorflow.compat.v2 as tf
from object_detection import model_lib_v2

flags.DEFINE_string('pipeline_config_path', None, 'Path to pipeline config '
                    'file.')
flags.DEFINE_integer('num_train_steps', None, 'Number of train steps.')
flags.DEFINE_bool('eval_on_train_data', False, 'Enable evaluating on train '
                  'data (only supported in distributed training).')
flags.DEFINE_integer('sample_1_of_n_eval_examples', None, 'Will sample one of '
                     'every n eval input examples, where n is provided.')
flags.DEFINE_integer('sample_1_of_n_eval_on_train_examples', 5, 'Will sample '
                     'one of every n train input examples for evaluation, '
                     'where n is provided. This is only used if '
                     '`eval_training_data` is True.')
flags.DEFINE_string(
    'model_dir', None, 'Path to output model directory '
                       'where event and checkpoint files will be written.')
flags.DEFINE_string(
    'checkpoint_dir', None, 'Path to directory holding a checkpoint.  If '
    '`checkpoint_dir` is provided, this binary operates in eval-only mode, '
    'writing resulting metrics to `model_dir`.')

flags.DEFINE_integer('eval_timeout', 3600, 'Number of seconds to wait for an'
                     'evaluation checkpoint before exiting.')

flags.DEFINE_bool('use_tpu', False, 'Whether the job is executing on a TPU.')
flags.DEFINE_string(
    'tpu_name',
    default=None,
    help='Name of the Cloud TPU for Cluster Resolvers.')
flags.DEFINE_integer(
    'num_workers', 1, 'When num_workers > 1, training uses '
    'MultiWorkerMirroredStrategy. When num_workers = 1 it uses '
    'MirroredStrategy.')
flags.DEFINE_integer(
    'checkpoint_every_n', 1000, 'Integer defining how often we checkpoint.')
flags.DEFINE_boolean('record_summaries', True,
                     ('Whether or not to record summaries during'
                      ' training.'))

FLAGS = flags.FLAGS


def main(unused_argv):
  flags.mark_flag_as_required('model_dir')
  flags.mark_flag_as_required('pipeline_config_path')
  tf.config.set_soft_device_placement(True)

  if FLAGS.checkpoint_dir:
    model_lib_v2.eval_continuously(
        pipeline_config_path=FLAGS.pipeline_config_path,
        model_dir=FLAGS.model_dir,
        train_steps=FLAGS.num_train_steps,
        sample_1_of_n_eval_examples=FLAGS.sample_1_of_n_eval_examples,
        sample_1_of_n_eval_on_train_examples=(
            FLAGS.sample_1_of_n_eval_on_train_examples),
        checkpoint_dir=FLAGS.checkpoint_dir,
        wait_interval=300, timeout=FLAGS.eval_timeout)
  else:
    if FLAGS.use_tpu:
      # TPU is automatically inferred if tpu_name is None and
      # we are running under cloud ai-platform.
      resolver = tf.distribute.cluster_resolver.TPUClusterResolver(
          FLAGS.tpu_name)
      tf.config.experimental_connect_to_cluster(resolver)
      tf.tpu.experimental.initialize_tpu_system(resolver)
      strategy = tf.distribute.experimental.TPUStrategy(resolver)
    elif FLAGS.num_workers > 1:
      strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()
    else:
      strategy = tf.compat.v2.distribute.MirroredStrategy()

    with strategy.scope():
      model_lib_v2.train_loop(
          pipeline_config_path=FLAGS.pipeline_config_path,
          model_dir=FLAGS.model_dir,
          train_steps=FLAGS.num_train_steps,
          use_tpu=FLAGS.use_tpu,
          checkpoint_every_n=FLAGS.checkpoint_every_n,
          record_summaries=FLAGS.record_summaries)

if __name__ == '__main__':
  tf.compat.v1.app.run()
```

pipeline.config file:
```
# Mask R-CNN with Inception Resnet v2 (no atrous)
# Sync-trained on COCO (with 8 GPUs) with batch size 16 (1024x1024 resolution)
# Initialized from Imagenet classification checkpoint
# TF2-Compatible, *Not* TPU-Compatible
#
# Achieves XXX mAP on COCO

model {
  faster_rcnn {
    number_of_stages: 3
    num_classes: 1
    image_resizer {
      fixed_shape_resizer {
        height: 1024
        width: 1024
        # pad_to_max_dimension: true
      }
    }
    feature_extractor {
      type: 'faster_rcnn_inception_resnet_v2_keras'
    }
    first_stage_anchor_generator {
      grid_anchor_generator {
        scales: [0.25, 0.5, 1.0, 2.0]
        aspect_ratios: [0.5, 1.0, 2.0]
        height_stride: 16
        width_stride: 16
      }
    }
    first_stage_box_predictor_conv_hyperparams {
      op: CONV
      regularizer {
        l2_regularizer {
          weight: 0.0
        }
      }
      initializer {
        truncated_normal_initializer {
          stddev: 0.01
        }
      }
    }
    first_stage_nms_score_threshold: 0.0
    first_stage_nms_iou_threshold: 0.7
    first_stage_max_proposals: 300
    first_stage_localization_loss_weight: 2.0
    first_stage_objectness_loss_weight: 1.0
    initial_crop_size: 17
    maxpool_kernel_size: 1
    maxpool_stride: 1
    second_stage_box_predictor {
      mask_rcnn_box_predictor {
        use_dropout: false
        dropout_keep_probability: 1.0
        fc_hyperparams {
          op: FC
          regularizer {
            l2_regularizer {
              weight: 0.0
            }
          }
          initializer {
            variance_scaling_initializer {
              factor: 1.0
              uniform: true
              mode: FAN_AVG
            }
          }
        }
        mask_height: 33
        mask_width: 33
        mask_prediction_conv_depth: 0
        mask_prediction_num_conv_layers: 4
        conv_hyperparams {
          op: CONV
          regularizer {
            l2_regularizer {
              weight: 0.0
            }
          }
          initializer {
            truncated_normal_initializer {
              stddev: 0.01
            }
          }
        }
        predict_instance_masks: true
      }
    }
    second_stage_post_processing {
      batch_non_max_suppression {
        score_threshold: 0.0
        iou_threshold: 0.6
        max_detections_per_class: 100
        max_total_detections: 100
      }
      score_converter: SOFTMAX
    }
    second_stage_localization_loss_weight: 2.0
    second_stage_classification_loss_weight: 1.0
    second_stage_mask_prediction_loss_weight: 4.0
    resize_masks: false
  }
}

train_config: {
  batch_size: 1
  num_steps: 200000
  optimizer {
    momentum_optimizer: {
      learning_rate: {
        cosine_decay_learning_rate {
          learning_rate_base: 0.008
          total_steps: 200000
          warmup_learning_rate: 0.0
          warmup_steps: 5000
        }
      }
      momentum_optimizer_value: 0.9
    }
    use_moving_average: false
  }
  gradient_clipping_by_norm: 10.0
  fine_tune_checkpoint: ""pre-trained-models/mask_rcnn_inception_resnet_v2_1024x1024_coco17_gpu-8/checkpoint/ckpt-0""
  data_augmentation_options {
    random_horizontal_flip {
    }
  }
}

train_input_reader: {
  tf_record_input_reader {
    input_path: ""annotations/train.record""
  }
  load_instance_masks: true
  mask_type: PNG_MASKS
}

eval_config: {
  metrics_set: ""coco_detection_metrics""
  metrics_set: ""coco_mask_metrics""
  eval_instance_masks: true
  use_moving_averages: false
  batch_size: 1
  include_metrics_per_category: true
}

eval_input_reader: {
  label_map_path: ""annotations/label_map.pbtxt""
  shuffle: false
  num_epochs: 1
  tf_record_input_reader {
    input_path: ""annotations/test.record""
  }
  load_instance_masks: true
  mask_type: PNG_MASKS
}
```

app.py (first reference):
```
# Copyright 2015 The TensorFlow Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ==============================================================================

""""""Generic entry point script.""""""
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import sys as _sys

from absl.app import run as _run

from tensorflow.python.platform import flags
from tensorflow.python.util.tf_export import tf_export


def _parse_flags_tolerate_undef(argv):
  """"""Parse args, returning any unknown flags (ABSL defaults to crashing).""""""
  return flags.FLAGS(_sys.argv if argv is None else argv, known_only=True)


@tf_export(v1=['app.run'])
def run(main=None, argv=None):
  """"""Runs the program with an optional 'main' function and 'argv' list.""""""

  main = main or _sys.modules['__main__'].main

  _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)
```

app.py (second and third reference):
```
# Copyright 2017 The Abseil Authors.
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

""""""Generic entry point for Abseil Python applications.

To use this module, define a 'main' function with a single 'argv' argument and
call app.run(main). For example:

    def main(argv):
      if len(argv) > 1:
        raise app.UsageError('Too many command-line arguments.')

    if __name__ == '__main__':
      app.run(main)
""""""

from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import collections
import errno
import os
import pdb
import sys
import traceback

from absl import command_name
from absl import flags
from absl import logging

try:
  import faulthandler
except ImportError:
  faulthandler = None

FLAGS = flags.FLAGS

flags.DEFINE_boolean('run_with_pdb', False, 'Set to true for PDB debug mode')
flags.DEFINE_boolean('pdb_post_mortem', False,
                     'Set to true to handle uncaught exceptions with PDB '
                     'post mortem.')
flags.DEFINE_alias('pdb', 'pdb_post_mortem')
flags.DEFINE_boolean('run_with_profiling', False,
                     'Set to true for profiling the script. '
                     'Execution will be slower, and the output format might '
                     'change over time.')
flags.DEFINE_string('profile_file', None,
                    'Dump profile information to a file (for python -m '
                    'pstats). Implies --run_with_profiling.')
flags.DEFINE_boolean('use_cprofile_for_profiling', True,
                     'Use cProfile instead of the profile module for '
                     'profiling. This has no effect unless '
                     '--run_with_profiling is set.')
flags.DEFINE_boolean('only_check_args', False,
                     'Set to true to validate args and exit.',
                     allow_hide_cpp=True)


# If main() exits via an abnormal exception, call into these
# handlers before exiting.
EXCEPTION_HANDLERS = []


class Error(Exception):
  pass


class UsageError(Error):
  """"""Exception raised when the arguments supplied by the user are invalid.

  Raise this when the arguments supplied are invalid from the point of
  view of the application. For example when two mutually exclusive
  flags have been supplied or when there are not enough non-flag
  arguments. It is distinct from flags.Error which covers the lower
  level of parsing and validating individual flags.
  """"""

  def __init__(self, message, exitcode=1):
    super(UsageError, self).__init__(message)
    self.exitcode = exitcode


class HelpFlag(flags.BooleanFlag):
  """"""Special boolean flag that displays usage and raises SystemExit.""""""
  NAME = 'help'
  SHORT_NAME = '?'

  def __init__(self):
    super(HelpFlag, self).__init__(
        self.NAME, False, 'show this help',
        short_name=self.SHORT_NAME, allow_hide_cpp=True)

  def parse(self, arg):
    if self._parse(arg):
      usage(shorthelp=True, writeto_stdout=True)
      # Advertise --helpfull on stdout, since usage() was on stdout.
      print()
      print('Try --helpfull to get a list of all flags.')
      sys.exit(1)


class HelpshortFlag(HelpFlag):
  """"""--helpshort is an alias for --help.""""""
  NAME = 'helpshort'
  SHORT_NAME = None


class HelpfullFlag(flags.BooleanFlag):
  """"""Display help for flags in the main module and all dependent modules.""""""

  def __init__(self):
    super(HelpfullFlag, self).__init__(
        'helpfull', False, 'show full help', allow_hide_cpp=True)

  def parse(self, arg):
    if self._parse(arg):
      usage(writeto_stdout=True)
      sys.exit(1)


class HelpXMLFlag(flags.BooleanFlag):
  """"""Similar to HelpfullFlag, but generates output in XML format.""""""

  def __init__(self):
    super(HelpXMLFlag, self).__init__(
        'helpxml', False, 'like --helpfull, but generates XML output',
        allow_hide_cpp=True)

  def parse(self, arg):
    if self._parse(arg):
      flags.FLAGS.write_help_in_xml_format(sys.stdout)
      sys.exit(1)


def parse_flags_with_usage(args):
  """"""Tries to parse the flags, print usage, and exit if unparseable.

  Args:
    args: [str], a non-empty list of the command line arguments including
        program name.

  Returns:
    [str], a non-empty list of remaining command line arguments after parsing
    flags, including program name.
  """"""
  try:
    return FLAGS(args)
  except flags.Error as error:
    sys.stderr.write('FATAL Flags parsing error: %s\n' % error)
    sys.stderr.write('Pass --helpshort or --helpfull to see help on flags.\n')
    sys.exit(1)


_define_help_flags_called = False


def define_help_flags():
  """"""Registers help flags. Idempotent.""""""
  # Use a global to ensure idempotence.
  global _define_help_flags_called

  if not _define_help_flags_called:
    flags.DEFINE_flag(HelpFlag())
    flags.DEFINE_flag(HelpshortFlag())  # alias for --help
    flags.DEFINE_flag(HelpfullFlag())
    flags.DEFINE_flag(HelpXMLFlag())
    _define_help_flags_called = True


def _register_and_parse_flags_with_usage(
    argv=None,
    flags_parser=parse_flags_with_usage,
):
  """"""Registers help flags, parses arguments and shows usage if appropriate.

  This also calls sys.exit(0) if flag --only_check_args is True.

  Args:
    argv: [str], a non-empty list of the command line arguments including
        program name, sys.argv is used if None.
    flags_parser: Callable[[List[Text]], Any], the function used to parse flags.
        The return value of this function is passed to `main` untouched.
        It must guarantee FLAGS is parsed after this function is called.

  Returns:
    The return value of `flags_parser`. When using the default `flags_parser`,
    it returns the following:
    [str], a non-empty list of remaining command line arguments after parsing
    flags, including program name.

  Raises:
    Error: Raised when flags_parser is called, but FLAGS is not parsed.
    SystemError: Raised when it's called more than once.
  """"""
  if _register_and_parse_flags_with_usage.done:
    raise SystemError('Flag registration can be done only once.')

  define_help_flags()

  original_argv = sys.argv if argv is None else argv
  args_to_main = flags_parser(original_argv)
  if not FLAGS.is_parsed():
    raise Error('FLAGS must be parsed after flags_parser is called.')

  # Exit when told so.
  if FLAGS.only_check_args:
    sys.exit(0)
  # Immediately after flags are parsed, bump verbosity to INFO if the flag has
  # not been set.
  if FLAGS['verbosity'].using_default_value:
    FLAGS.verbosity = 0
  _register_and_parse_flags_with_usage.done = True

  return args_to_main

_register_and_parse_flags_with_usage.done = False


def _run_main(main, argv):
  """"""Calls main, optionally with pdb or profiler.""""""
  if FLAGS.run_with_pdb:
    sys.exit(pdb.runcall(main, argv))
  elif FLAGS.run_with_profiling or FLAGS.profile_file:
    # Avoid import overhead since most apps (including performance-sensitive
    # ones) won't be run with profiling.
    import atexit
    if FLAGS.use_cprofile_for_profiling:
      import cProfile as profile
    else:
      import profile
    profiler = profile.Profile()
    if FLAGS.profile_file:
      atexit.register(profiler.dump_stats, FLAGS.profile_file)
    else:
      atexit.register(profiler.print_stats)
    retval = profiler.runcall(main, argv)
    sys.exit(retval)
  else:
    sys.exit(main(argv))


def _call_exception_handlers(exception):
  """"""Calls any installed exception handlers.""""""
  for handler in EXCEPTION_HANDLERS:
    try:
      if handler.wants(exception):
        handler.handle(exception)
    except:  # pylint: disable=bare-except
      try:
        # We don't want to stop for exceptions in the exception handlers but
        # we shouldn't hide them either.
        logging.error(traceback.format_exc())
      except:  # pylint: disable=bare-except
        # In case even the logging statement fails, ignore.
        pass


def run(
    main,
    argv=None,
    flags_parser=parse_flags_with_usage,
):
  """"""Begins executing the program.

  Args:
    main: The main function to execute. It takes an single argument ""argv"",
        which is a list of command line arguments with parsed flags removed.
        The return value is passed to `sys.exit`, and so for example
        a return value of 0 or None results in a successful termination, whereas
        a return value of 1 results in abnormal termination.
        For more details, see https://docs.python.org/3/library/sys#sys.exit
    argv: A non-empty list of the command line arguments including program name,
        sys.argv is used if None.
    flags_parser: Callable[[List[Text]], Any], the function used to parse flags.
        The return value of this function is passed to `main` untouched.
        It must guarantee FLAGS is parsed after this function is called.
  - Parses command line flags with the flag module.
  - If there are any errors, prints usage().
  - Calls main() with the remaining arguments.
  - If main() raises a UsageError, prints usage and the error message.
  """"""
  try:
    args = _run_init(
        sys.argv if argv is None else argv,
        flags_parser,
    )
    while _init_callbacks:
      callback = _init_callbacks.popleft()
      callback()
    try:
      _run_main(main, args)
    except UsageError as error:
      usage(shorthelp=True, detailed_error=error, exitcode=error.exitcode)
    except:
      exc = sys.exc_info()[1]
      # Don't try to post-mortem debug successful SystemExits, since those
      # mean there wasn't actually an error. In particular, the test framework
      # raises SystemExit(False) even if all tests passed.
      if isinstance(exc, SystemExit) and not exc.code:
        raise

      # Check the tty so that we don't hang waiting for input in an
      # non-interactive scenario.
      if FLAGS.pdb_post_mortem and sys.stdout.isatty():
        traceback.print_exc()
        print()
        print(' *** Entering post-mortem debugging ***')
        print()
        pdb.post_mortem()
      raise
  except Exception as e:
    _call_exception_handlers(e)
    raise

# Callbacks which have been deferred until after _run_init has been called.
_init_callbacks = collections.deque()


def call_after_init(callback):
  """"""Calls the given callback only once ABSL has finished initialization.

  If ABSL has already finished initialization when `call_after_init` is
  called then the callback is executed immediately, otherwise `callback` is
  stored to be executed after `app.run` has finished initializing (aka. just
  before the main function is called).

  If called after `app.run`, this is equivalent to calling `callback()` in the
  caller thread. If called before `app.run`, callbacks are run sequentially (in
  an undefined order) in the same thread as `app.run`.

  Args:
    callback: a callable to be called once ABSL has finished initialization.
      This may be immediate if initialization has already finished. It
      takes no arguments and returns nothing.
  """"""
  if _run_init.done:
    callback()
  else:
    _init_callbacks.append(callback)


def _run_init(
    argv,
    flags_parser,
):
  """"""Does one-time initialization and re-parses flags on rerun.""""""
  if _run_init.done:
    return flags_parser(argv)
  command_name.make_process_name_useful()
  # Set up absl logging handler.
  logging.use_absl_handler()
  args = _register_and_parse_flags_with_usage(
      argv=argv,
      flags_parser=flags_parser,
  )
  if faulthandler:
    try:
      faulthandler.enable()
    except Exception:  # pylint: disable=broad-except
      # Some tests verify stderr output very closely, so don't print anything.
      # Disabled faulthandler is a low-impact error.
      pass
  _run_init.done = True
  return args


_run_init.done = False


def usage(shorthelp=False, writeto_stdout=False, detailed_error=None,
          exitcode=None):
  """"""Writes __main__'s docstring to stderr with some help text.

  Args:
    shorthelp: bool, if True, prints only flags from the main module,
        rather than all flags.
    writeto_stdout: bool, if True, writes help message to stdout,
        rather than to stderr.
    detailed_error: str, additional detail about why usage info was presented.
    exitcode: optional integer, if set, exits with this status code after
        writing help.
  """"""
  if writeto_stdout:
    stdfile = sys.stdout
  else:
    stdfile = sys.stderr

  doc = sys.modules['__main__'].__doc__
  if not doc:
    doc = '\nUSAGE: %s [flags]\n' % sys.argv[0]
    doc = flags.text_wrap(doc, indent='       ', firstline_indent='')
  else:
    # Replace all '%s' with sys.argv[0], and all '%%' with '%'.
    num_specifiers = doc.count('%') - 2 * doc.count('%%')
    try:
      doc %= (sys.argv[0],) * num_specifiers
    except (OverflowError, TypeError, ValueError):
      # Just display the docstring as-is.
      pass
  if shorthelp:
    flag_str = FLAGS.main_module_help()
  else:
    flag_str = FLAGS.get_help()
  try:
    stdfile.write(doc)
    if flag_str:
      stdfile.write('\nflags:\n')
      stdfile.write(flag_str)
    stdfile.write('\n')
    if detailed_error is not None:
      stdfile.write('\n%s\n' % detailed_error)
  except IOError as e:
    # We avoid printing a huge backtrace if we get EPIPE, because
    # ""foo.par --help | less"" is a frequent use case.
    if e.errno != errno.EPIPE:
      raise
  if exitcode is not None:
    sys.exit(exitcode)


class ExceptionHandler(object):
  """"""Base exception handler from which other may inherit.""""""

  def wants(self, exc):
    """"""Returns whether this handler wants to handle the exception or not.

    This base class returns True for all exceptions by default. Override in
    subclass if it wants to be more selective.

    Args:
      exc: Exception, the current exception.
    """"""
    del exc  # Unused.
    return True

  def handle(self, exc):
    """"""Do something with the current exception.

    Args:
      exc: Exception, the current exception

    This method must be overridden.
    """"""
    raise NotImplementedError()


def install_exception_handler(handler):
  """"""Installs an exception handler.

  Args:
    handler: ExceptionHandler, the exception handler to install.

  Raises:
    TypeError: Raised when the handler was not of the correct type.

  All installed exception handlers will be called if main() exits via
  an abnormal exception, i.e. not one of SystemExit, KeyboardInterrupt,
  FlagsError or UsageError.
  """"""
  if not isinstance(handler, ExceptionHandler):
    raise TypeError('handler of type %s does not inherit from ExceptionHandler'
                    % type(handler))
  EXCEPTION_HANDLERS.append(handler)
```

model_lib_v2.py:
```
# Copyright 2019 The TensorFlow Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ==============================================================================
r""""""Constructs model, inputs, and training environment.""""""

from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

import copy
import os
import time

import tensorflow.compat.v1 as tf
import tensorflow.compat.v2 as tf2

from object_detection import eval_util
from object_detection import inputs
from object_detection import model_lib
from object_detection.builders import optimizer_builder
from object_detection.core import standard_fields as fields
from object_detection.protos import train_pb2
from object_detection.utils import config_util
from object_detection.utils import label_map_util
from object_detection.utils import ops
from object_detection.utils import visualization_utils as vutils

# pylint: disable=g-import-not-at-top
try:
  from tensorflow.contrib import tpu as contrib_tpu
except ImportError:
  # TF 2.0 doesn't ship with contrib.
  pass
# pylint: enable=g-import-not-at-top

MODEL_BUILD_UTIL_MAP = model_lib.MODEL_BUILD_UTIL_MAP


RESTORE_MAP_ERROR_TEMPLATE = (
    'Since we are restoring a v2 style checkpoint'
    ' restore_map was expected to return a (str -> Model) mapping,'
    ' but we received a ({} -> {}) mapping instead.'
)


def _compute_losses_and_predictions_dicts(
    model, features, labels,
    add_regularization_loss=True):
  """"""Computes the losses dict and predictions dict for a model on inputs.

  Args:
    model: a DetectionModel (based on Keras).
    features: Dictionary of feature tensors from the input dataset.
      Should be in the format output by `inputs.train_input` and
      `inputs.eval_input`.
        features[fields.InputDataFields.image] is a [batch_size, H, W, C]
          float32 tensor with preprocessed images.
        features[HASH_KEY] is a [batch_size] int32 tensor representing unique
          identifiers for the images.
        features[fields.InputDataFields.true_image_shape] is a [batch_size, 3]
          int32 tensor representing the true image shapes, as preprocessed
          images could be padded.
        features[fields.InputDataFields.original_image] (optional) is a
          [batch_size, H, W, C] float32 tensor with original images.
    labels: A dictionary of groundtruth tensors post-unstacking. The original
      labels are of the form returned by `inputs.train_input` and
      `inputs.eval_input`. The shapes may have been modified by unstacking with
      `model_lib.unstack_batch`. However, the dictionary includes the following
      fields.
        labels[fields.InputDataFields.num_groundtruth_boxes] is a
          int32 tensor indicating the number of valid groundtruth boxes
          per image.
        labels[fields.InputDataFields.groundtruth_boxes] is a float32 tensor
          containing the corners of the groundtruth boxes.
        labels[fields.InputDataFields.groundtruth_classes] is a float32
          one-hot tensor of classes.
        labels[fields.InputDataFields.groundtruth_weights] is a float32 tensor
          containing groundtruth weights for the boxes.
        -- Optional --
        labels[fields.InputDataFields.groundtruth_instance_masks] is a
          float32 tensor containing only binary values, which represent
          instance masks for objects.
        labels[fields.InputDataFields.groundtruth_keypoints] is a
          float32 tensor containing keypoints for each box.
        labels[fields.InputDataFields.groundtruth_dp_num_points] is an int32
          tensor with the number of sampled DensePose points per object.
        labels[fields.InputDataFields.groundtruth_dp_part_ids] is an int32
          tensor with the DensePose part ids (0-indexed) per object.
        labels[fields.InputDataFields.groundtruth_dp_surface_coords] is a
          float32 tensor with the DensePose surface coordinates.
        labels[fields.InputDataFields.groundtruth_group_of] is a tf.bool tensor
          containing group_of annotations.
        labels[fields.InputDataFields.groundtruth_labeled_classes] is a float32
          k-hot tensor of classes.
        labels[fields.InputDataFields.groundtruth_track_ids] is a int32
          tensor of track IDs.
    add_regularization_loss: Whether or not to include the model's
      regularization loss in the losses dictionary.

  Returns:
    A tuple containing the losses dictionary (with the total loss under
    the key 'Loss/total_loss'), and the predictions dictionary produced by
    `model.predict`.

  """"""
  model_lib.provide_groundtruth(model, labels)
  preprocessed_images = features[fields.InputDataFields.image]

  prediction_dict = model.predict(
      preprocessed_images,
      features[fields.InputDataFields.true_image_shape],
      **model.get_side_inputs(features))
  prediction_dict = ops.bfloat16_to_float32_nested(prediction_dict)

  losses_dict = model.loss(
      prediction_dict, features[fields.InputDataFields.true_image_shape])
  losses = [loss_tensor for loss_tensor in losses_dict.values()]
  if add_regularization_loss:
    # TODO(kaftan): As we figure out mixed precision & bfloat 16, we may
    ## need to convert these regularization losses from bfloat16 to float32
    ## as well.
    regularization_losses = model.regularization_losses()
    if regularization_losses:
      regularization_losses = ops.bfloat16_to_float32_nested(
          regularization_losses)
      regularization_loss = tf.add_n(
          regularization_losses, name='regularization_loss')
      losses.append(regularization_loss)
      losses_dict['Loss/regularization_loss'] = regularization_loss

  total_loss = tf.add_n(losses, name='total_loss')
  losses_dict['Loss/total_loss'] = total_loss

  return losses_dict, prediction_dict


# TODO(kaftan): Explore removing learning_rate from this method & returning
## The full losses dict instead of just total_loss, then doing all summaries
## saving in a utility method called by the outer training loop.
# TODO(kaftan): Explore adding gradient summaries
def eager_train_step(detection_model,
                     features,
                     labels,
                     unpad_groundtruth_tensors,
                     optimizer,
                     learning_rate,
                     add_regularization_loss=True,
                     clip_gradients_value=None,
                     global_step=None,
                     num_replicas=1.0):
  """"""Process a single training batch.

  This method computes the loss for the model on a single training batch,
  while tracking the gradients with a gradient tape. It then updates the
  model variables with the optimizer, clipping the gradients if
  clip_gradients_value is present.

  This method can run eagerly or inside a tf.function.

  Args:
    detection_model: A DetectionModel (based on Keras) to train.
    features: Dictionary of feature tensors from the input dataset.
      Should be in the format output by `inputs.train_input.
        features[fields.InputDataFields.image] is a [batch_size, H, W, C]
          float32 tensor with preprocessed images.
        features[HASH_KEY] is a [batch_size] int32 tensor representing unique
          identifiers for the images.
        features[fields.InputDataFields.true_image_shape] is a [batch_size, 3]
          int32 tensor representing the true image shapes, as preprocessed
          images could be padded.
        features[fields.InputDataFields.original_image] (optional, not used
          during training) is a
          [batch_size, H, W, C] float32 tensor with original images.
    labels: A dictionary of groundtruth tensors. This method unstacks
      these labels using model_lib.unstack_batch. The stacked labels are of
      the form returned by `inputs.train_input` and `inputs.eval_input`.
        labels[fields.InputDataFields.num_groundtruth_boxes] is a [batch_size]
          int32 tensor indicating the number of valid groundtruth boxes
          per image.
        labels[fields.InputDataFields.groundtruth_boxes] is a
          [batch_size, num_boxes, 4] float32 tensor containing the corners of
          the groundtruth boxes.
        labels[fields.InputDataFields.groundtruth_classes] is a
          [batch_size, num_boxes, num_classes] float32 one-hot tensor of
          classes. num_classes includes the background class.
        labels[fields.InputDataFields.groundtruth_weights] is a
          [batch_size, num_boxes] float32 tensor containing groundtruth weights
          for the boxes.
        -- Optional --
        labels[fields.InputDataFields.groundtruth_instance_masks] is a
          [batch_size, num_boxes, H, W] float32 tensor containing only binary
          values, which represent instance masks for objects.
        labels[fields.InputDataFields.groundtruth_keypoints] is a
          [batch_size, num_boxes, num_keypoints, 2] float32 tensor containing
          keypoints for each box.
        labels[fields.InputDataFields.groundtruth_dp_num_points] is a
          [batch_size, num_boxes] int32 tensor with the number of DensePose
          sampled points per instance.
        labels[fields.InputDataFields.groundtruth_dp_part_ids] is a
          [batch_size, num_boxes, max_sampled_points] int32 tensor with the
          part ids (0-indexed) for each instance.
        labels[fields.InputDataFields.groundtruth_dp_surface_coords] is a
          [batch_size, num_boxes, max_sampled_points, 4] float32 tensor with the
          surface coordinates for each point. Each surface coordinate is of the
          form (y, x, v, u) where (y, x) are normalized image locations and
          (v, u) are part-relative normalized surface coordinates.
        labels[fields.InputDataFields.groundtruth_labeled_classes] is a float32
          k-hot tensor of classes.
        labels[fields.InputDataFields.groundtruth_track_ids] is a int32
          tensor of track IDs.
    unpad_groundtruth_tensors: A parameter passed to unstack_batch.
    optimizer: The training optimizer that will update the variables.
    learning_rate: The learning rate tensor for the current training step.
      This is used only for TensorBoard logging purposes, it does not affect
       model training.
    add_regularization_loss: Whether or not to include the model's
      regularization loss in the losses dictionary.
    clip_gradients_value: If this is present, clip the gradients global norm
      at this value using `tf.clip_by_global_norm`.
    global_step: The current training step. Used for TensorBoard logging
      purposes. This step is not updated by this function and must be
      incremented separately.
    num_replicas: The number of replicas in the current distribution strategy.
      This is used to scale the total loss so that training in a distribution
      strategy works correctly.

  Returns:
    The total loss observed at this training step
  """"""
  # """"""Execute a single training step in the TF v2 style loop.""""""
  is_training = True

  detection_model._is_training = is_training  # pylint: disable=protected-access
  tf.keras.backend.set_learning_phase(is_training)

  labels = model_lib.unstack_batch(
      labels, unpad_groundtruth_tensors=unpad_groundtruth_tensors)

  with tf.GradientTape() as tape:
    losses_dict, _ = _compute_losses_and_predictions_dicts(
        detection_model, features, labels, add_regularization_loss)

    total_loss = losses_dict['Loss/total_loss']

    # Normalize loss for num replicas
    total_loss = tf.math.divide(total_loss,
                                tf.constant(num_replicas, dtype=tf.float32))
    losses_dict['Loss/normalized_total_loss'] = total_loss

  for loss_type in losses_dict:
    tf.compat.v2.summary.scalar(
        loss_type, losses_dict[loss_type], step=global_step)

  trainable_variables = detection_model.trainable_variables

  gradients = tape.gradient(total_loss, trainable_variables)

  if clip_gradients_value:
    gradients, _ = tf.clip_by_global_norm(gradients, clip_gradients_value)
  optimizer.apply_gradients(zip(gradients, trainable_variables))
  tf.compat.v2.summary.scalar('learning_rate', learning_rate, step=global_step)
  tf.compat.v2.summary.image(
      name='train_input_images',
      step=global_step,
      data=features[fields.InputDataFields.image],
      max_outputs=3)
  return total_loss


def validate_tf_v2_checkpoint_restore_map(checkpoint_restore_map):
  """"""Ensure that given dict is a valid TF v2 style restore map.

  Args:
    checkpoint_restore_map: A nested dict mapping strings to
      tf.keras.Model objects.

  Raises:
    ValueError: If they keys in checkpoint_restore_map are not strings or if
      the values are not keras Model objects.

  """"""

  for key, value in checkpoint_restore_map.items():
    if not (isinstance(key, str) and
            (isinstance(value, tf.Module)
             or isinstance(value, tf.train.Checkpoint))):
      if isinstance(key, str) and isinstance(value, dict):
        validate_tf_v2_checkpoint_restore_map(value)
      else:
        raise TypeError(
            RESTORE_MAP_ERROR_TEMPLATE.format(key.__class__.__name__,
                                              value.__class__.__name__))


def is_object_based_checkpoint(checkpoint_path):
  """"""Returns true if `checkpoint_path` points to an object-based checkpoint.""""""
  var_names = [var[0] for var in tf.train.list_variables(checkpoint_path)]
  return '_CHECKPOINTABLE_OBJECT_GRAPH' in var_names


def load_fine_tune_checkpoint(
    model, checkpoint_path, checkpoint_type, checkpoint_version, input_dataset,
    unpad_groundtruth_tensors):
  """"""Load a fine tuning classification or detection checkpoint.

  To make sure the model variables are all built, this method first executes
  the model by computing a dummy loss. (Models might not have built their
  variables before their first execution)

  It then loads an object-based classification or detection checkpoint.

  This method updates the model in-place and does not return a value.

  Args:
    model: A DetectionModel (based on Keras) to load a fine-tuning
      checkpoint for.
    checkpoint_path: Directory with checkpoints file or path to checkpoint.
    checkpoint_type: Whether to restore from a full detection
      checkpoint (with compatible variable names) or to restore from a
      classification checkpoint for initialization prior to training.
      Valid values: `detection`, `classification`.
    checkpoint_version: train_pb2.CheckpointVersion.V1 or V2 enum indicating
      whether to load checkpoints in V1 style or V2 style.  In this binary
      we only support V2 style (object-based) checkpoints.
    input_dataset: The tf.data Dataset the model is being trained on. Needed
      to get the shapes for the dummy loss computation.
    unpad_groundtruth_tensors: A parameter passed to unstack_batch.

  Raises:
    IOError: if `checkpoint_path` does not point at a valid object-based
      checkpoint
    ValueError: if `checkpoint_version` is not train_pb2.CheckpointVersion.V2
  """"""
  if not is_object_based_checkpoint(checkpoint_path):
    raise IOError('Checkpoint is expected to be an object-based checkpoint.')
  if checkpoint_version == train_pb2.CheckpointVersion.V1:
    raise ValueError('Checkpoint version should be V2')

  features, labels = iter(input_dataset).next()

  @tf.function
  def _dummy_computation_fn(features, labels):
    model._is_training = False  # pylint: disable=protected-access
    tf.keras.backend.set_learning_phase(False)

    labels = model_lib.unstack_batch(
        labels, unpad_groundtruth_tensors=unpad_groundtruth_tensors)

    return _compute_losses_and_predictions_dicts(
        model,
        features,
        labels)

  strategy = tf.compat.v2.distribute.get_strategy()
  if hasattr(tf.distribute.Strategy, 'run'):
    strategy.run(
        _dummy_computation_fn, args=(
            features,
            labels,
        ))
  else:
    strategy.experimental_run_v2(
        _dummy_computation_fn, args=(
            features,
            labels,
        ))

  restore_from_objects_dict = model.restore_from_objects(
      fine_tune_checkpoint_type=checkpoint_type)
  validate_tf_v2_checkpoint_restore_map(restore_from_objects_dict)
  ckpt = tf.train.Checkpoint(**restore_from_objects_dict)
  ckpt.restore(checkpoint_path).assert_existing_objects_matched()


def get_filepath(strategy, filepath):
  """"""Get appropriate filepath for worker.

  Args:
    strategy: A tf.distribute.Strategy object.
    filepath: A path to where the Checkpoint object is stored.

  Returns:
    A temporary filepath for non-chief workers to use or the original filepath
    for the chief.
  """"""
  if strategy.extended.should_checkpoint:
    return filepath
  else:
    # TODO(vighneshb) Replace with the public API when TF exposes it.
    task_id = strategy.extended._task_id  # pylint:disable=protected-access
    return os.path.join(filepath, 'temp_worker_{:03d}'.format(task_id))


def clean_temporary_directories(strategy, filepath):
  """"""Temporary directory clean up for MultiWorker Mirrored Strategy.

  This is needed for all non-chief workers.

  Args:
    strategy: A tf.distribute.Strategy object.
    filepath: The filepath for the temporary directory.
  """"""
  if not strategy.extended.should_checkpoint:
    if tf.io.gfile.exists(filepath) and tf.io.gfile.isdir(filepath):
      tf.io.gfile.rmtree(filepath)


def train_loop(
    pipeline_config_path,
    model_dir,
    config_override=None,
    train_steps=None,
    use_tpu=False,
    save_final_config=False,
    checkpoint_every_n=1000,
    checkpoint_max_to_keep=7,
    record_summaries=True,
    **kwargs):
  """"""Trains a model using eager + functions.

  This method:
    1. Processes the pipeline configs
    2. (Optionally) saves the as-run config
    3. Builds the model & optimizer
    4. Gets the training input data
    5. Loads a fine-tuning detection or classification checkpoint if requested
    6. Loops over the train data, executing distributed training steps inside
       tf.functions.
    7. Checkpoints the model every `checkpoint_every_n` training steps.
    8. Logs the training metrics as TensorBoard summaries.

  Args:
    pipeline_config_path: A path to a pipeline config file.
    model_dir:
      The directory to save checkpoints and summaries to.
    config_override: A pipeline_pb2.TrainEvalPipelineConfig text proto to
      override the config from `pipeline_config_path`.
    train_steps: Number of training steps. If None, the number of training steps
      is set from the `TrainConfig` proto.
    use_tpu: Boolean, whether training and evaluation should run on TPU.
    save_final_config: Whether to save final config (obtained after applying
      overrides) to `model_dir`.
    checkpoint_every_n:
      Checkpoint every n training steps.
    checkpoint_max_to_keep:
      int, the number of most recent checkpoints to keep in the model directory.
    record_summaries: Boolean, whether or not to record summaries.
    **kwargs: Additional keyword arguments for configuration override.
  """"""
  ## Parse the configs
  get_configs_from_pipeline_file = MODEL_BUILD_UTIL_MAP[
      'get_configs_from_pipeline_file']
  merge_external_params_with_configs = MODEL_BUILD_UTIL_MAP[
      'merge_external_params_with_configs']
  create_pipeline_proto_from_configs = MODEL_BUILD_UTIL_MAP[
      'create_pipeline_proto_from_configs']

  configs = get_configs_from_pipeline_file(
      pipeline_config_path, config_override=config_override)
  kwargs.update({
      'train_steps': train_steps,
      'use_bfloat16': configs['train_config'].use_bfloat16 and use_tpu
  })
  configs = merge_external_params_with_configs(
      configs, None, kwargs_dict=kwargs)
  model_config = configs['model']
  train_config = configs['train_config']
  train_input_config = configs['train_input_config']

  unpad_groundtruth_tensors = train_config.unpad_groundtruth_tensors
  add_regularization_loss = train_config.add_regularization_loss
  clip_gradients_value = None
  if train_config.gradient_clipping_by_norm > 0:
    clip_gradients_value = train_config.gradient_clipping_by_norm

  # update train_steps from config but only when non-zero value is provided
  if train_steps is None and train_config.num_steps != 0:
    train_steps = train_config.num_steps

  if kwargs['use_bfloat16']:
    tf.compat.v2.keras.mixed_precision.experimental.set_policy('mixed_bfloat16')

  if train_config.load_all_detection_checkpoint_vars:
    raise ValueError('train_pb2.load_all_detection_checkpoint_vars '
                     'unsupported in TF2')

  config_util.update_fine_tune_checkpoint_type(train_config)
  fine_tune_checkpoint_type = train_config.fine_tune_checkpoint_type
  fine_tune_checkpoint_version = train_config.fine_tune_checkpoint_version

  # Write the as-run pipeline config to disk.
  if save_final_config:
    pipeline_config_final = create_pipeline_proto_from_configs(configs)
    config_util.save_pipeline_config(pipeline_config_final, model_dir)

  # Build the model, optimizer, and training input
  strategy = tf.compat.v2.distribute.get_strategy()
  with strategy.scope():
    detection_model = MODEL_BUILD_UTIL_MAP['detection_model_fn_base'](
        model_config=model_config, is_training=True)

    def train_dataset_fn(input_context):
      """"""Callable to create train input.""""""
      # Create the inputs.
      train_input = inputs.train_input(
          train_config=train_config,
          train_input_config=train_input_config,
          model_config=model_config,
          model=detection_model,
          input_context=input_context)
      train_input = train_input.repeat()
      return train_input

    train_input = strategy.experimental_distribute_datasets_from_function(
        train_dataset_fn)


    global_step = tf.Variable(
        0, trainable=False, dtype=tf.compat.v2.dtypes.int64, name='global_step',
        aggregation=tf.compat.v2.VariableAggregation.ONLY_FIRST_REPLICA)
    optimizer, (learning_rate,) = optimizer_builder.build(
        train_config.optimizer, global_step=global_step)

    if callable(learning_rate):
      learning_rate_fn = learning_rate
    else:
      learning_rate_fn = lambda: learning_rate

  ## Train the model
  # Get the appropriate filepath (temporary or not) based on whether the worker
  # is the chief.
  summary_writer_filepath = get_filepath(strategy,
                                         os.path.join(model_dir, 'train'))
  if record_summaries:
    summary_writer = tf.compat.v2.summary.create_file_writer(
        summary_writer_filepath)
  else:
    summary_writer = tf2.summary.create_noop_writer()

  if use_tpu:
    num_steps_per_iteration = 100
  else:
    # TODO(b/135933080) Explore setting to 100 when GPU performance issues
    # are fixed.
    num_steps_per_iteration = 1

  with summary_writer.as_default():
    with strategy.scope():
      with tf.compat.v2.summary.record_if(
          lambda: global_step % num_steps_per_iteration == 0):
        # Load a fine-tuning checkpoint.
        if train_config.fine_tune_checkpoint:
          load_fine_tune_checkpoint(detection_model,
                                    train_config.fine_tune_checkpoint,
                                    fine_tune_checkpoint_type,
                                    fine_tune_checkpoint_version,
                                    train_input,
                                    unpad_groundtruth_tensors)

        ckpt = tf.compat.v2.train.Checkpoint(
            step=global_step, model=detection_model, optimizer=optimizer)

        manager_dir = get_filepath(strategy, model_dir)
        if not strategy.extended.should_checkpoint:
          checkpoint_max_to_keep = 1
        manager = tf.compat.v2.train.CheckpointManager(
            ckpt, manager_dir, max_to_keep=checkpoint_max_to_keep)

        # We use the following instead of manager.latest_checkpoint because
        # manager_dir does not point to the model directory when we are running
        # in a worker.
        latest_checkpoint = tf.train.latest_checkpoint(model_dir)
        ckpt.restore(latest_checkpoint)

        def train_step_fn(features, labels):
          """"""Single train step.""""""
          loss = eager_train_step(
              detection_model,
              features,
              labels,
              unpad_groundtruth_tensors,
              optimizer,
              learning_rate=learning_rate_fn(),
              add_regularization_loss=add_regularization_loss,
              clip_gradients_value=clip_gradients_value,
              global_step=global_step,
              num_replicas=strategy.num_replicas_in_sync)
          global_step.assign_add(1)
          return loss

        def _sample_and_train(strategy, train_step_fn, data_iterator):
          features, labels = data_iterator.next()
          if hasattr(tf.distribute.Strategy, 'run'):
            per_replica_losses = strategy.run(
                train_step_fn, args=(features, labels))
          else:
            per_replica_losses = strategy.experimental_run_v2(
                train_step_fn, args=(features, labels))
          # TODO(anjalisridhar): explore if it is safe to remove the
          ## num_replicas scaling of the loss and switch this to a ReduceOp.Mean
          return strategy.reduce(tf.distribute.ReduceOp.SUM,
                                 per_replica_losses, axis=None)

        @tf.function
        def _dist_train_step(data_iterator):
          """"""A distributed train step.""""""

          if num_steps_per_iteration > 1:
            for _ in tf.range(num_steps_per_iteration - 1):
              # Following suggestion on yaqs/5402607292645376
              with tf.name_scope(''):
                _sample_and_train(strategy, train_step_fn, data_iterator)

          return _sample_and_train(strategy, train_step_fn, data_iterator)

        train_input_iter = iter(train_input)

        if int(global_step.value()) == 0:
          manager.save()

        checkpointed_step = int(global_step.value())
        logged_step = global_step.value()

        last_step_time = time.time()
        for _ in range(global_step.value(), train_steps,
                       num_steps_per_iteration):

          loss = _dist_train_step(train_input_iter)

          time_taken = time.time() - last_step_time
          last_step_time = time.time()

          tf.compat.v2.summary.scalar(
              'steps_per_sec', num_steps_per_iteration * 1.0 / time_taken,
              step=global_step)

          if global_step.value() - logged_step >= 100:
            tf.logging.info(
                'Step {} per-step time {:.3f}s loss={:.3f}'.format(
                    global_step.value(), time_taken / num_steps_per_iteration,
                    loss))
            logged_step = global_step.value()

          if ((int(global_step.value()) - checkpointed_step) >=
              checkpoint_every_n):
            manager.save()
            checkpointed_step = int(global_step.value())

  # Remove the checkpoint directories of the non-chief workers that
  # MultiWorkerMirroredStrategy forces us to save during sync distributed
  # training.
  clean_temporary_directories(strategy, manager_dir)
  clean_temporary_directories(strategy, summary_writer_filepath)


def eager_eval_loop(
    detection_model,
    configs,
    eval_dataset,
    use_tpu=False,
    postprocess_on_cpu=False,
    global_step=None):
  """"""Evaluate the model eagerly on the evaluation dataset.

  This method will compute the evaluation metrics specified in the configs on
  the entire evaluation dataset, then return the metrics. It will also log
  the metrics to TensorBoard.

  Args:
    detection_model: A DetectionModel (based on Keras) to evaluate.
    configs: Object detection configs that specify the evaluators that should
      be used, as well as whether regularization loss should be included and
      if bfloat16 should be used on TPUs.
    eval_dataset: Dataset containing evaluation data.
    use_tpu: Whether a TPU is being used to execute the model for evaluation.
    postprocess_on_cpu: Whether model postprocessing should happen on
      the CPU when using a TPU to execute the model.
    global_step: A variable containing the training step this model was trained
      to. Used for logging purposes.

  Returns:
    A dict of evaluation metrics representing the results of this evaluation.
  """"""
  train_config = configs['train_config']
  eval_input_config = configs['eval_input_config']
  eval_config = configs['eval_config']
  add_regularization_loss = train_config.add_regularization_loss

  is_training = False
  detection_model._is_training = is_training  # pylint: disable=protected-access
  tf.keras.backend.set_learning_phase(is_training)

  evaluator_options = eval_util.evaluator_options_from_eval_config(
      eval_config)
  batch_size = eval_config.batch_size

  class_agnostic_category_index = (
      label_map_util.create_class_agnostic_category_index())
  class_agnostic_evaluators = eval_util.get_evaluators(
      eval_config,
      list(class_agnostic_category_index.values()),
      evaluator_options)

  class_aware_evaluators = None
  if eval_input_config.label_map_path:
    class_aware_category_index = (
        label_map_util.create_category_index_from_labelmap(
            eval_input_config.label_map_path))
    class_aware_evaluators = eval_util.get_evaluators(
        eval_config,
        list(class_aware_category_index.values()),
        evaluator_options)

  evaluators = None
  loss_metrics = {}

  @tf.function
  def compute_eval_dict(features, labels):
    """"""Compute the evaluation result on an image.""""""
    # For evaling on train data, it is necessary to check whether groundtruth
    # must be unpadded.
    boxes_shape = (
        labels[fields.InputDataFields.groundtruth_boxes].get_shape().as_list())
    unpad_groundtruth_tensors = (boxes_shape[1] is not None
                                 and not use_tpu
                                 and batch_size == 1)
    labels = model_lib.unstack_batch(
        labels, unpad_groundtruth_tensors=unpad_groundtruth_tensors)

    losses_dict, prediction_dict = _compute_losses_and_predictions_dicts(
        detection_model, features, labels, add_regularization_loss)

    def postprocess_wrapper(args):
      return detection_model.postprocess(args[0], args[1])

    # TODO(kaftan): Depending on how postprocessing will work for TPUS w/
    ## TPUStrategy, may be good to move wrapping to a utility method
    if use_tpu and postprocess_on_cpu:
      detections = contrib_tpu.outside_compilation(
          postprocess_wrapper,
          (prediction_dict, features[fields.InputDataFields.true_image_shape]))
    else:
      detections = postprocess_wrapper(
          (prediction_dict, features[fields.InputDataFields.true_image_shape]))

    class_agnostic = (
        fields.DetectionResultFields.detection_classes not in detections)
    # TODO(kaftan) (or anyone): move `_prepare_groundtruth_for_eval to eval_util
    ## and call this from there.
    groundtruth = model_lib._prepare_groundtruth_for_eval(  # pylint: disable=protected-access
        detection_model, class_agnostic, eval_input_config.max_number_of_boxes)
    use_original_images = fields.InputDataFields.original_image in features
    if use_original_images:
      eval_images = features[fields.InputDataFields.original_image]
      true_image_shapes = tf.slice(
          features[fields.InputDataFields.true_image_shape], [0, 0], [-1, 3])
      original_image_spatial_shapes = features[
          fields.InputDataFields.original_image_spatial_shape]
    else:
      eval_images = features[fields.InputDataFields.image]
      true_image_shapes = None
      original_image_spatial_shapes = None

    keys = features[inputs.HASH_KEY]
    if eval_input_config.include_source_id:
      keys = features[fields.InputDataFields.source_id]
    eval_dict = eval_util.result_dict_for_batched_example(
        eval_images,
        keys,
        detections,
        groundtruth,
        class_agnostic=class_agnostic,
        scale_to_absolute=True,
        original_image_spatial_shapes=original_image_spatial_shapes,
        true_image_shapes=true_image_shapes)

    return eval_dict, losses_dict, class_agnostic

  agnostic_categories = label_map_util.create_class_agnostic_category_index()
  per_class_categories = label_map_util.create_category_index_from_labelmap(
      eval_input_config.label_map_path)
  keypoint_edges = [
      (kp.start, kp.end) for kp in eval_config.keypoint_edge]

  for i, (features, labels) in enumerate(eval_dataset):
    eval_dict, losses_dict, class_agnostic = compute_eval_dict(features, labels)

    if class_agnostic:
      category_index = agnostic_categories
    else:
      category_index = per_class_categories

    if i % 100 == 0:
      tf.logging.info('Finished eval step %d', i)

    use_original_images = fields.InputDataFields.original_image in features
    if (use_original_images and i < eval_config.num_visualizations
        and batch_size == 1):
      sbys_image_list = vutils.draw_side_by_side_evaluation_image(
          eval_dict,
          category_index=category_index,
          max_boxes_to_draw=eval_config.max_num_boxes_to_visualize,
          min_score_thresh=eval_config.min_score_threshold,
          use_normalized_coordinates=False,
          keypoint_edges=keypoint_edges or None)
      sbys_images = tf.concat(sbys_image_list, axis=0)
      tf.compat.v2.summary.image(
          name='eval_side_by_side_' + str(i),
          step=global_step,
          data=sbys_images,
          max_outputs=eval_config.num_visualizations)
      if eval_util.has_densepose(eval_dict):
        dp_image_list = vutils.draw_densepose_visualizations(
            eval_dict)
        dp_images = tf.concat(dp_image_list, axis=0)
        tf.compat.v2.summary.image(
            name='densepose_detections_' + str(i),
            step=global_step,
            data=dp_images,
            max_outputs=eval_config.num_visualizations)

    if evaluators is None:
      if class_agnostic:
        evaluators = class_agnostic_evaluators
      else:
        evaluators = class_aware_evaluators

    for evaluator in evaluators:
      evaluator.add_eval_dict(eval_dict)

    for loss_key, loss_tensor in iter(losses_dict.items()):
      if loss_key not in loss_metrics:
        loss_metrics[loss_key] = tf.keras.metrics.Mean()
      # Skip the loss with value equal or lower than 0.0 when calculating the
      # average loss since they don't usually reflect the normal loss values
      # causing spurious average loss value.
      if loss_tensor <= 0.0:
        continue
      loss_metrics[loss_key].update_state(loss_tensor)

  eval_metrics = {}

  for evaluator in evaluators:
    eval_metrics.update(evaluator.evaluate())
  for loss_key in loss_metrics:
    eval_metrics[loss_key] = loss_metrics[loss_key].result()

  eval_metrics = {str(k): v for k, v in eval_metrics.items()}
  tf.logging.info('Eval metrics at step %d', global_step)
  for k in eval_metrics:
    tf.compat.v2.summary.scalar(k, eval_metrics[k], step=global_step)
    tf.logging.info('\t+ %s: %f', k, eval_metrics[k])

  return eval_metrics


def eval_continuously(
    pipeline_config_path,
    config_override=None,
    train_steps=None,
    sample_1_of_n_eval_examples=1,
    sample_1_of_n_eval_on_train_examples=1,
    use_tpu=False,
    override_eval_num_epochs=True,
    postprocess_on_cpu=False,
    model_dir=None,
    checkpoint_dir=None,
    wait_interval=180,
    timeout=3600,
    eval_index=None,
    **kwargs):
  """"""Run continuous evaluation of a detection model eagerly.

  This method builds the model, and continously restores it from the most
  recent training checkpoint in the checkpoint directory & evaluates it
  on the evaluation data.

  Args:
    pipeline_config_path: A path to a pipeline config file.
    config_override: A pipeline_pb2.TrainEvalPipelineConfig text proto to
      override the config from `pipeline_config_path`.
    train_steps: Number of training steps. If None, the number of training steps
      is set from the `TrainConfig` proto.
    sample_1_of_n_eval_examples: Integer representing how often an eval example
      should be sampled. If 1, will sample all examples.
    sample_1_of_n_eval_on_train_examples: Similar to
      `sample_1_of_n_eval_examples`, except controls the sampling of training
      data for evaluation.
    use_tpu: Boolean, whether training and evaluation should run on TPU.
    override_eval_num_epochs: Whether to overwrite the number of epochs to 1 for
      eval_input.
    postprocess_on_cpu: When use_tpu and postprocess_on_cpu are true,
      postprocess is scheduled on the host cpu.
    model_dir: Directory to output resulting evaluation summaries to.
    checkpoint_dir: Directory that contains the training checkpoints.
    wait_interval: The mimmum number of seconds to wait before checking for a
      new checkpoint.
    timeout: The maximum number of seconds to wait for a checkpoint. Execution
      will terminate if no new checkpoints are found after these many seconds.
    eval_index: int, optional If give, only evaluate the dataset at the given
      index.

    **kwargs: Additional keyword arguments for configuration override.
  """"""
  get_configs_from_pipeline_file = MODEL_BUILD_UTIL_MAP[
      'get_configs_from_pipeline_file']
  merge_external_params_with_configs = MODEL_BUILD_UTIL_MAP[
      'merge_external_params_with_configs']

  configs = get_configs_from_pipeline_file(
      pipeline_config_path, config_override=config_override)
  kwargs.update({
      'sample_1_of_n_eval_examples': sample_1_of_n_eval_examples,
      'use_bfloat16': configs['train_config'].use_bfloat16 and use_tpu
  })
  if train_steps is not None:
    kwargs['train_steps'] = train_steps
  if override_eval_num_epochs:
    kwargs.update({'eval_num_epochs': 1})
    tf.logging.warning(
        'Forced number of epochs for all eval validations to be 1.')
  configs = merge_external_params_with_configs(
      configs, None, kwargs_dict=kwargs)
  model_config = configs['model']
  train_input_config = configs['train_input_config']
  eval_config = configs['eval_config']
  eval_input_configs = configs['eval_input_configs']
  eval_on_train_input_config = copy.deepcopy(train_input_config)
  eval_on_train_input_config.sample_1_of_n_examples = (
      sample_1_of_n_eval_on_train_examples)
  if override_eval_num_epochs and eval_on_train_input_config.num_epochs != 1:
    tf.logging.warning('Expected number of evaluation epochs is 1, but '
                       'instead encountered `eval_on_train_input_config'
                       '.num_epochs` = '
                       '{}. Overwriting `num_epochs` to 1.'.format(
                           eval_on_train_input_config.num_epochs))
    eval_on_train_input_config.num_epochs = 1

  if kwargs['use_bfloat16']:
    tf.compat.v2.keras.mixed_precision.experimental.set_policy('mixed_bfloat16')

  detection_model = MODEL_BUILD_UTIL_MAP['detection_model_fn_base'](
      model_config=model_config, is_training=True)

  # Create the inputs.
  eval_inputs = []
  for eval_input_config in eval_input_configs:
    next_eval_input = inputs.eval_input(
        eval_config=eval_config,
        eval_input_config=eval_input_config,
        model_config=model_config,
        model=detection_model)
    eval_inputs.append((eval_input_config.name, next_eval_input))

  if eval_index is not None:
    eval_inputs = [eval_inputs[eval_index]]

  global_step = tf.compat.v2.Variable(
      0, trainable=False, dtype=tf.compat.v2.dtypes.int64)

  for latest_checkpoint in tf.train.checkpoints_iterator(
      checkpoint_dir, timeout=timeout, min_interval_secs=wait_interval):
    ckpt = tf.compat.v2.train.Checkpoint(
        step=global_step, model=detection_model)

    ckpt.restore(latest_checkpoint).expect_partial()

    for eval_name, eval_input in eval_inputs:
      summary_writer = tf.compat.v2.summary.create_file_writer(
          os.path.join(model_dir, 'eval', eval_name))
      with summary_writer.as_default():
        eager_eval_loop(
            detection_model,
            configs,
            eval_input,
            use_tpu=use_tpu,
            postprocess_on_cpu=postprocess_on_cpu,
            global_step=global_step)
```
"
44842,Error while trying to load model's weights for fine-tuning (transfer learning),"**System information**

Have I written custom code (as opposed to using a stock example script provided in TensorFlow): NO
OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
TensorFlow installed from (source or binary): binary (no errors during installation)
TensorFlow version: 2.3.1 (with GPU support)
Python version: 3.7.5
CUDA/cuDNN version: 10.1
GPU model and memory: RTX 1660 Ti 6.00GB

**Describe the current behavior**
I reproduce my issue on oversimplified code.
I'm trying to train model for one dataset (say, on MNIST) and then fine-tune it on another (with different number of classes, say 5).
After I have created model for '5 classes task' I'm trying to load the weights from original model using 
`model.load_weights(path, by_name=True, skip_mismatch=True)`

But I got an error:
`ValueError: Shapes (5,) and (10,) are incompatible`

I hoped that setting the params `by_name=True, skip_mismatch=True `will be enough to handle differences between the models.
How to correct load weights for slightly different model?

**Standalone code to reproduce the issue**
Oversimplified script to recreate the trouble

```
import tensorflow as tf
import numpy as np
import os

mnist = tf.keras.datasets.mnist
(x_train, y_train), (x_test, y_test) = mnist.load_data()
x_train, x_test = x_train / 255.0, x_test / 255.0
y_train = tf.keras.utils.to_categorical(y_train, 10)
y_test = tf.keras.utils.to_categorical(y_test, 10)
x_train = np.expand_dims(x_train, -1)
x_test = np.expand_dims(x_test, -1)

model = tf.keras.models.Sequential([
    tf.keras.layers.Input(shape=(28, 28, 1)),
    tf.keras.layers.Conv2D(32, 3, activation='relu', padding='same'),
    tf.keras.layers.AveragePooling2D(),
    tf.keras.layers.Conv2D(64, 3, activation='relu', padding='same'),
    tf.keras.layers.AveragePooling2D(),
    tf.keras.layers.Conv2D(128, 3, activation='relu', padding='same'),
    tf.keras.layers.AveragePooling2D(),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(10, activation='softmax')])

model.compile(loss=tf.keras.losses.CategoricalCrossentropy(), optimizer=tf.keras.optimizers.Adam())

batch_size = 128
epochs = 3
model.fit(x_train, y_train, batch_size, epochs, validation_data=(x_test, y_test))

ver = 0
path = os.path.join(os.getcwd(), str(ver))
model.save_weights(path)


different_model = tf.keras.models.Sequential([
    tf.keras.layers.Input(shape=(28, 28, 1)),
    tf.keras.layers.Conv2D(32, 3, activation='relu', padding='same'),
    tf.keras.layers.AveragePooling2D(),
    tf.keras.layers.Conv2D(64, 3, activation='relu', padding='same'),
    tf.keras.layers.AveragePooling2D(),
    tf.keras.layers.Conv2D(128, 3, activation='relu', padding='same'),
    tf.keras.layers.AveragePooling2D(),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(5, activation='softmax')]) # say, we change the number of classes here for further fine-tuning

# here I got an error!!!!!!! isn't by_name=True, skip_mismatch=True not enough?
different_model.load_weights(path, by_name=True, skip_mismatch=True)

# fine-tuning/transfer learning is supposed here for some application where we classify 5 cls

print('loaded!')
```

It's a serious and urgent problem for my project!
Any help is appreciated!!!
"
44841,No rule to make target 'hello_world_bin'.  Stop,"ake: *** No rule to make target 'third_party_download'.  Stop.
lenovo :: F:\tensorflow <master> » make -f tensorflow/lite/micro/tools/make/Makefile TARGET=sparkfun_edge hello_world_bin
FIND: 参数格式不正确
FIND: 参数格式不正确
make: *** No rule to make target 'hello_world_bin'.  Stop.

why？
I am a novice and can't solve this problem"
44840,"""An op outside of the function building code is being passed a ""Graph"" tensor"" when using custom loss","Hi, i made a code with subclass api(https://www.tensorflow.org/guide/keras/custom_layers_and_models#putting_it_all_together_an_end-to-end_example) and custom loss for a model.

The problem is when using custom loss in addition to main loss, this error is raised:
```
TypeError: An op outside of the function building code is being passed
a ""Graph"" tensor. It is possible to have Graph tensors
leak out of the function building context by including a
tf.init_scope in your function building code.
For example, the following function will fail:
  @tf.function
  def has_init_scope():
    my_constant = tf.constant(1.)
    with tf.init_scope():
      added = my_constant * 2
The graph tensor has name: add_1:0
```

If i comment `self.add_loss(lambda: tf.reduce_mean(VAE_loss))` the error is not raised.

Colab notebook : https://colab.research.google.com/drive/17zKRFQsPCpKjHkmMJqMC4EuDDhOLvuVy?usp=sharing

"
44839,"Extracting information from yolov3 tflite model of output shape [1,2535,15] is giving weird results","I tried using my yolov3-tiny.tflite. I'm not sure why but I'm getting something like this

[![enter image description here][1]][1]


  [1]: https://i.stack.imgur.com/c5Ypq.jpg


Here is my code


    private  float[][][] getBoxes(float [][][] map){
        float[][][] bboxes = new float[map.length][map[0].length][5];
        for(int i = 0; i < map.length; i++){
            for(int j = 0; j < map[i].length; j++){
                for(int k = 0; k < 5; k++){
                    bboxes[i][j][k] = map[i][j][k];
                }
            }
        }
        return bboxes;
    }
    
    
    private  float[][][] getScore(float [][][] map){
        float[][][] scores = new float[map.length][map[0].length][labels.size()];
        for(int i = 0; i < map.length; i++){
            for(int j = 0; j < map[i].length; j++){
                for(int k = 0; k < labels.size(); k++){
                    scores[i][j][k] = map[i][j][k+5];
                }
            }
        }
        return scores;
    }
    
    private ArrayList<Recognition> getDetectionsForTiny(ByteBuffer byteBuffer, Bitmap bitmap) {
        ArrayList<Recognition> detections = new ArrayList<Recognition>();
        Map<Integer, Object> outputMap = new HashMap<>();
        outputMap.put(0, new float[1][OUTPUT_WIDTH_TINY[0]][5 + labels.size()]);
        //outputMap.put(1, new float[1][OUTPUT_WIDTH_TINY[1]][labels.size()]);
        Object[] inputArray = {byteBuffer};
        tfLite.runForMultipleInputsOutputs(inputArray, outputMap);
    
        int gridWidth = OUTPUT_WIDTH_TINY[0];
        float[][][] bboxes = getBoxes((float[][][])outputMap.get(0));
        float[][][] out_score = getScore((float[][][]) outputMap.get(0));
    
        int detectedClass = -1;
        float maxClass = 0;
    
        for (int i = 0; i < gridWidth;i++){
            final float[] classes = new float[labels.size()];
            for (int c = 0;c< labels.size();c++){
                classes [c] = out_score[0][i][c];
            }
            for (int c = 0;c<labels.size();++c){
                if (classes[c] > maxClass){
                    detectedClass = c;
                    maxClass = classes[c];
                }
            }
            final float score = maxClass;
            if (score > getObjThresh()){
                final float xPos = bboxes[0][i][0];
                final float yPos = bboxes[0][i][1];
                final float w = bboxes[0][i][2];
                final float h = bboxes[0][i][3];
                final RectF rectF = new RectF(
                        Math.max(0, xPos - w / 2),
                        Math.max(0, yPos - h / 2),
                        Math.min(bitmap.getWidth() - 1, xPos + w / 2),
                        Math.min(bitmap.getHeight() - 1, yPos + h / 2));
                detections.add(new Recognition("""" + i, labels.get(detectedClass),score,rectF,detectedClass ));
                Log.d(""Title ****************"","" ""+labels.get(detectedClass));
    
            }
        }
    
        return detections;
    }

I don't know where I'm going wrong. Thank you!"
44838,Strange behavior for tf.keras.backend.function in tf 2.3.1 for intermediate values,"I was training an Xception model with custom output layers. So, clasic Xception model + dropout layer + dense layer alpha + dropout layer alpha + softmax dense layer for output.
After training, my goal is to split the model in half: Xception+dropout and dense layer alpha...softmax output.
For this, i am doing>
```
model = load_model(path)
base_model= Model(inputs=model.input, outputs=model.get_layer('base_drop').output) - Works fine
second_half = K.function([model.get_layer('dense_alpha').input, K.learning_phase()],
                            [model.get_layer('dense_out').output]) - Error
```
The error is:
```
WARNING:tensorflow:Functional inputs must come from `tf.keras.Input` (thus holding past layer metadata), they cannot be the output of a previous non-Input layer. Here, a tensor specified as input to ""functional_4"" was not an Input tensor, it was generated by layer base_drop.
Note that input tensors are instantiated via `tensor = tf.keras.Input(shape)`.
The tensor that caused the issue was: base_drop/cond/Identity:0

ValueError: Input tensors to a Functional must come from `tf.keras.Input`. Received: 0 (missing previous layer metadata).

```
Also, if i am doing
```
second_half  = Model(inputs=model.get_layer('dense_alpha').input,
                            outputs=model.get_layer('dense_out').output)
```
I get the following error

`Graph disconnected: cannot obtain value for tensor Tensor(""input_1:0"", shape=(None, 300, 480, 3), dtype=float32) at layer ""xception"". The following previous layers were accessed without issue: []`

I didn't got these errors with tf 2.2.0 + i have read that the behavior of tf.keras.backend.function has changed in the 2.3.0
Is this a bug or it's something expected. In the second case, what should i change in order to achieve previous functionality?

I need this split in order to run base_model only one time with my test dataset and pass the results through the function multiple times with active second dropout
                "
44836,How to accelerate tensor transferring from host to device (GPU) in TF 2.x?,"**Describe the current behavior**
Hi, I want to train my DNN model with TF. And now the input is from `tf.data.Dataset.from_tensor_slices`, which will prefetch the numpy value into TF tensors. 

Because the training is on GPU, therefore tensor transferring from CPU to GPU is triggerd automatically, which results in bad performance in my training process.

Specifically, one iteration is about 205 ms, while data transfering from CPU to GPU will spend 136 ms.
![image](https://user-images.githubusercontent.com/69858819/99072211-8cd2c700-25ee-11eb-946d-e017575b586f.png)


**Describe the expected behavior**
Is there any way to change the memory used by `tf.data.Dataset` to CPU pinned memory rather than pageable? So that tensor transferring from CPU to GPU will be much faster.

Or any other methods I can try to accelerate data reading from numpy to TF tensors on GPU? 
"
44834,NotFoundError when using an optimizer on complex variables,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes (minimal working example provided)
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux-3.10.0-1127.19.1.el7.x86_64-x86_64-with-glibc2.10
- TensorFlow installed from (source or binary): Binary (installed using conda)
- TensorFlow version (use command below): 2.2.0
- Python version: 3.8.5
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10.1/7.6.5
- GPU model and memory: Quadro P1000 96GB

**Describe the current behavior**
When I attempt to optimise a loss function in complex variables, I get a NotFoundError when using the apply_gradients function. The error persists for all optimisers that I have tried (SGD is shown in the example). If I replace the complex variable with a float there are no issues.

**Describe the expected behavior**
Apply_gradients should carry out an SGD step.

**Standalone code to reproduce the issue**
```
import tensorflow as tf
import numpy as np

print(tf.config.list_physical_devices('GPU'))

# Initialise a complex matrix
mat = tf.random.uniform([1000, 1000], dtype=tf.float64)
mat = tf.complex(mat, mat)

var = tf.Variable(mat, trainable=True)

# Return the squared norm of this matrix as the loss function
def lossFn():
    return tf.math.abs(tf.linalg.trace(var @ tf.linalg.adjoint(var)))

# SGD optimizer
opt = tf.keras.optimizers.SGD(learning_rate=0.01)

numSteps=0
while numSteps < 100:
    with tf.GradientTape() as tape:
        loss = lossFn()
    grads = tape.gradient(loss, [var])

    # This is the step that fails
    opt.apply_gradients(zip(grads, [var]))
    numSteps += 1
    print(loss.numpy())
```

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

Traceback (most recent call last):
  File ""gpuTest.py"", line 25, in <module>
    opt.apply_gradients(zip(grads, [var]))
  File ""/rds/general/user/dlh16/home/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py"", line 504, in apply_gradients
    return distribute_ctx.get_replica_context().merge_call(
  File ""/rds/general/user/dlh16/home/anaconda3/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py"", line 2420, in merge_call
    return self._merge_call(merge_fn, args, kwargs)
  File ""/rds/general/user/dlh16/home/anaconda3/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py"", line 2427, in _merge_call
    return merge_fn(self._strategy, *args, **kwargs)
  File ""/rds/general/user/dlh16/home/anaconda3/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py"", line 282, in wrapper
    return func(*args, **kwargs)
  File ""/rds/general/user/dlh16/home/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py"", line 591, in _distributed_apply
    update_ops.extend(distribution.extended.update(
  File ""/rds/general/user/dlh16/home/anaconda3/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py"", line 2013, in update
    return self._update(var, fn, args, kwargs, group)
  File ""/rds/general/user/dlh16/home/anaconda3/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py"", line 2659, in _update
    return self._update_non_slot(var, fn, (var,) + tuple(args), kwargs, group)
  File ""/rds/general/user/dlh16/home/anaconda3/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py"", line 2665, in _update_non_slot
    result = fn(*args, **kwargs)
  File ""/rds/general/user/dlh16/home/anaconda3/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py"", line 282, in wrapper
    return func(*args, **kwargs)
  File ""/rds/general/user/dlh16/home/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py"", line 567, in apply_grad_to_update_var
    update_op = self._resource_apply_dense(grad, var, **apply_kwargs)
  File ""/rds/general/user/dlh16/home/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/gradient_descent.py"", line 143, in _resource_apply_dense
    return training_ops.resource_apply_gradient_descent(
  File ""/rds/general/user/dlh16/home/anaconda3/lib/python3.8/site-packages/tensorflow/python/training/gen_training_ops.py"", line 1908, in resource_apply_gradient_descent
    _ops.raise_from_not_ok_status(e, name)
  File ""/rds/general/user/dlh16/home/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/ops.py"", line 6653, in raise_from_not_ok_status
    six.raise_from(core._status_to_exception(e.code, message), None)
  File ""<string>"", line 3, in raise_from
tensorflow.python.framework.errors_impl.NotFoundError: No registered 'ResourceApplyGradientDescent' OpKernel for 'GPU' devices compatible with node {{node ResourceApplyGradientDescent}}
         (OpKernel was found, but attributes didn't match) Requested Attributes: T=DT_COMPLEX128, use_locking=true
        .  Registered:  device='XLA_GPU'; T in [DT_FLOAT, DT_DOUBLE, DT_COMPLEX64, DT_BFLOAT16, DT_COMPLEX128, DT_HALF]
  device='XLA_CPU'; T in [DT_FLOAT, DT_DOUBLE, DT_COMPLEX64, DT_BFLOAT16, DT_COMPLEX128, DT_HALF]
  device='XLA_CPU_JIT'; T in [DT_FLOAT, DT_DOUBLE, DT_COMPLEX64, DT_BFLOAT16, DT_COMPLEX128, DT_HALF]
  device='GPU'; T in [DT_DOUBLE]
  device='GPU'; T in [DT_FLOAT]
  device='GPU'; T in [DT_HALF]
  device='CPU'; T in [DT_COMPLEX128]
  device='CPU'; T in [DT_COMPLEX64]
  device='CPU'; T in [DT_DOUBLE]
  device='CPU'; T in [DT_FLOAT]
  device='CPU'; T in [DT_BFLOAT16]
  device='CPU'; T in [DT_HALF]
  device='XLA_GPU_JIT'; T in [DT_FLOAT, DT_DOUBLE, DT_COMPLEX64, DT_BFLOAT16, DT_COMPLEX128, DT_HALF]
 [Op:ResourceApplyGradientDescent]
"
44833,Optimize Tensorflow for Cortex-R MCUs,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using):
- Are you willing to contribute it (Yes/No):



**Describe the feature and the current behavior/state.**
Most of the Automative sensors uses Cortex-R MCU. To run Tensorflow on Cortex-R MCU, can you please optimize Tensorflow for Cortex-R MCUs as well similar to what you have done for Cortex-M?

**Will this change the current api? How?**

**Who will benefit with this feature?**
Building Intelligent sensors for automotive applications as well.

**Any Other info.**
"
44832,Blas xGEMM launch failed: RTX3080 with CUDA 10.0,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04 LTS, used within a Docker container 
- TensorFlow installed from (source or binary): from Docker image tensorflow/tensorflow:1.14.0-gpu-py3
- TensorFlow version (use command below): 1.14.0-gpu
- Python version: 3.7
- CUDA/cuDNN version: 10.0/7.6.0.64
- GPU model and memory: 2xRTX 3080

**Describe the current behavior**
While loading a PointCNN model I got the following error (snippet): 
`(0) Internal: Blas xGEMM launch failed : a.shape=[1,20000,3], b.shape=[1,3,20000], m=20000, n=20000, k=3`

Tensorflow is run with the following config options:
`  config.gpu_options.allow_growth = True`
`  config.allow_soft_placement = True`

I also tried setting them to false.

**Describe the expected behavior**
The same model is successfully loaded on another machine with Ubuntu 20.04 LTS within the same Docker container but with Nvidia 970GTX.

I think this may be related to CUDA 10.0 support on RTX 3080? 

Full error log:

`Exception has occurred: InternalError`
`2 root error(s) found.`
`  (0) Internal: Blas xGEMM launch failed : a.shape=[1,20000,3], b.shape=[1,3,20000], m=20000, n=20000, k=3`
`	 [[node while/generator_ops/PointCNN/MatMul (defined at src/src/tf_utils/pointfly.py:572) ]]`
`  (1) Internal: Blas xGEMM launch failed : a.shape=[1,20000,3], b.shape=[1,3,20000], m=20000, n=20000, k=3`
`	 [[node while/generator_ops/PointCNN/MatMul (defined at src/src/tf_utils/pointfly.py:572) ]]`
`	 [[while/preprocessing_ops/batch_nonuniform_sample/while/concat_1/_807]]`
`0 successful operations.`
`0 derived errors ignored.`

`Errors may have originated from an input operation.`
`Input Source operations connected to node while/generator_ops/PointCNN/MatMul:`
` while/preprocessing_ops/batch_nonuniform_sample/Reshape (defined at src/src/tf_utils/pointfly.py:370)`

`Input Source operations connected to node while/generator_ops/PointCNN/MatMul:`
` while/preprocessing_ops/batch_nonuniform_sample/Reshape (defined at src/src/tf_utils/pointfly.py:370)`
"
44831,"The TFLite Android app throws Fatal Error: ""Buffer Overflow Exception""","Hi there! 
I recerntly tried to build an Object Detection Android App using TFLite model. I built my own custom model (a Keras Model in HDF5 format) and converted the model succesfully into a custom TFLite model using the following command:

`tflite_convert --keras_model_file=detect.h5 --output_file=detect.tflite --output_format=TFLITE --input_shapes=1,300,300,3 --input_arrays=normalized_input_image_tensor --output_arrays='TFLite_Detection_PostProcess','TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3' --inference_type=QUANTIZED_UINT8 --mean_values=128 --std_dev_values=127 --change_concat_input_ranges=false --allow_custom_ops`

I further added the associated MetaData to this particular model using this code:

`import tensorflow as tf
from tflite_support import metadata as _metadata`

`populator = _metadata.MetadataPopulator.with_model_file(""detect.tflite"")
populator.load_associated_files([""labelmap.txt""])
populator.populate()`


I then configured this model in the Android Package [Example](https://github.com/tensorflow/examples/tree/master/lite/examples/object_detection/android) by tensorflow and made some tweaks to the _Build.gradle_ file, _DetectorActivity.java_ and _TFLiteObjectDetectionAPIModel.java_, respectively. I also made some UI changes according to what and how I needed it to look like. Additionally, I had to change the _'numBytesPerChannel'_
 value for Float model from '4' to '3' since I was getting an error like this:

`Cannot convert between a TensorFlowLite buffer with XYZ bytes and a ByteBuffer with ABC bytes`


The build is successful yet the debugger throws me a fatal exception of ""BufferOverFlowError"". 

`11/13 14:57:02: Launching 'app' on Physical Device.
Install successfully finished in 16 s 851 ms.
$ adb shell am start -n ""org.tensorflow.lite.examples.detection/org.tensorflow.lite.examples.detection.DetectorActivity"" -a android.intent.action.MAIN -c android.intent.category.LAUNCHER -D
Waiting for application to come online: org.tensorflow.lite.examples.detection.test | org.tensorflow.lite.examples.detection
Waiting for application to come online: org.tensorflow.lite.examples.detection.test | org.tensorflow.lite.examples.detection
Connected to process 22667 on device 'samsung-sm_m315f-RZ8N50B0M5K'.
Waiting for application to come online: org.tensorflow.lite.examples.detection.test | org.tensorflow.lite.examples.detection
Connecting to org.tensorflow.lite.examples.detection
Connected to the target VM, address: 'localhost:46069', transport: 'socket'
Capturing and displaying logcat messages from application. This behavior can be disabled in the ""Logcat output"" section of the ""Debugger"" settings page.
I/mples.detectio: Late-enabling -Xcheck:jni
E/mples.detectio: Unknown bits set in runtime_flags: 0x8000
D/ActivityThread: setConscryptValidator
    setConscryptValidator - put
W/ActivityThread: Application org.tensorflow.lite.examples.detection is waiting for the debugger on port 8100...
I/System.out: Sending WAIT chunk
I/System.out: Debugger has connected
    waiting for debugger to settle...
I/chatty: uid=10379(org.tensorflow.lite.examples.detection) identical 1 line
I/System.out: waiting for debugger to settle...
I/System.out: waiting for debugger to settle...
I/System.out: waiting for debugger to settle...
I/System.out: waiting for debugger to settle...
I/System.out: waiting for debugger to settle...
I/System.out: waiting for debugger to settle...
I/chatty: uid=10379(org.tensorflow.lite.examples.detection) identical 2 lines
I/System.out: waiting for debugger to settle...
I/System.out: waiting for debugger to settle...
I/System.out: debugger has settled (1478)
I/mples.detectio: Waiting for a blocking GC ClassLinker
I/mples.detectio: WaitForGcToComplete blocked ClassLinker on ClassLinker for 7.502ms
D/tensorflow: CameraActivity: onCreate org.tensorflow.lite.examples.detection.DetectorActivity@4d5b875
D/PhoneWindow: forceLight changed to true [] from com.android.internal.policy.PhoneWindow.updateForceLightNavigationBar:4274 com.android.internal.policy.DecorView.updateColorViews:1547 com.android.internal.policy.PhoneWindow.dispatchWindowAttributesChanged:3252 android.view.Window.setFlags:1153 com.android.internal.policy.PhoneWindow.generateLayout:2474 
I/MultiWindowDecorSupport: [INFO] isPopOver = false
I/MultiWindowDecorSupport: updateCaptionType >> DecorView@59812d[], isFloating: false, isApplication: true, hasWindowDecorCaption: false, hasWindowControllerCallback: true
D/MultiWindowDecorSupport: setCaptionType = 0, DecorView = DecorView@59812d[]
W/mples.detectio: Accessing hidden method Landroid/view/View;->computeFitSystemWindows(Landroid/graphics/Rect;Landroid/graphics/Rect;)Z (greylist, reflection, allowed)
W/mples.detectio: Accessing hidden method Landroid/view/ViewGroup;->makeOptionalFitsSystemWindows()V (greylist, reflection, allowed)
I/CameraManagerGlobal: Connecting to camera service
D/VendorTagDescriptor: addVendorDescriptor: vendor tag id 3854507339 added
I/CameraManagerGlobal: Camera 0 facing CAMERA_FACING_BACK state now CAMERA_STATE_CLOSED for client com.snapchat.android API Level 1
I/CameraManagerGlobal: Camera 1 facing CAMERA_FACING_FRONT state now CAMERA_STATE_CLOSED for client com.dolby.dolby234 API Level 2
I/CameraManagerGlobal: Camera 2 facing CAMERA_FACING_BACK state now CAMERA_STATE_CLOSED for client com.whatsapp API Level 1
I/CameraManagerGlobal: Camera 20 facing CAMERA_FACING_BACK state now CAMERA_STATE_CLOSED for client android.system API Level 2
I/CameraManagerGlobal: Camera 23 facing CAMERA_FACING_BACK state now CAMERA_STATE_CLOSED for client android.system API Level 2
I/CameraManagerGlobal: Camera 3 facing CAMERA_FACING_FRONT state now CAMERA_STATE_CLOSED for client com.sec.android.app.camera API Level 2
I/CameraManagerGlobal: Camera 4 facing CAMERA_FACING_FRONT state now CAMERA_STATE_CLOSED for client vendor.client.pid<4503> API Level 2
I/CameraManagerGlobal: Camera 50 facing CAMERA_FACING_BACK state now CAMERA_STATE_CLOSED for client com.sec.android.app.camera API Level 2
I/CameraManagerGlobal: Camera 52 facing CAMERA_FACING_BACK state now CAMERA_STATE_CLOSED for client android.system API Level 2
I/CameraManagerGlobal: Camera 54 facing CAMERA_FACING_BACK state now CAMERA_STATE_CLOSED for client android.system API Level 2
I/tensorflow: CameraActivity: Camera API lv2?: false
D/tensorflow: CameraActivity: onStart org.tensorflow.lite.examples.detection.DetectorActivity@4d5b875
D/tensorflow: CameraActivity: onResume org.tensorflow.lite.examples.detection.DetectorActivity@4d5b875
I/ViewRootImpl@a101c3c[DetectorActivity]: setView = com.android.internal.policy.DecorView@59812d TM=true MM=false
I/ViewRootImpl@a101c3c[DetectorActivity]: Relayout returned: old=(0,0,1080,2340) new=(0,0,1080,2340) req=(1080,2340)0 dur=31 res=0x7 s={true 532883185664} ch=true
D/OpenGLRenderer: createReliableSurface : 0x7c1211ecc0(0x7c12502000)
D/OpenGLRenderer: makeCurrent EglSurface : 0x0 -> 0x0
I/mali_winsys: new_window_surface() [1080x2340] return: 0x3000
D/OpenGLRenderer: eglCreateWindowSurface : 0x7c120c3600
I/CameraManagerGlobal: Camera 0 facing CAMERA_FACING_BACK state now CAMERA_STATE_OPEN for client org.tensorflow.lite.examples.detection API Level 1
I/tensorflow: CameraConnectionFragment: Desired size: 640x480, min size: 480x480
I/tensorflow: CameraConnectionFragment: Valid preview sizes: [1920x1080, 1440x1080, 1280x720, 1088x1088, 1024x768, 960x720, 720x720, 720x480, 640x480]
I/tensorflow: CameraConnectionFragment: Rejected preview sizes: [800x450, 640x360, 352x288, 320x240, 256x144, 176x144]
    CameraConnectionFragment: Exact size match found.
W/Gralloc3: mapper 3.x is not supported
I/gralloc: Arm Module v1.0
W/Gralloc3: allocator 3.x is not supported
D/OpenGLRenderer: makeCurrent EglSurface : 0x0 -> 0x7c120c3600
I/Choreographer: Skipped 34 frames!  The application may be doing too much work on its main thread.
I/ViewRootImpl@a101c3c[DetectorActivity]: MSG_WINDOW_FOCUS_CHANGED 1 1
D/InputMethodManager: prepareNavigationBarInfo() DecorView@59812d[DetectorActivity]
D/InputMethodManager: getNavigationBarColor() -855310
D/InputMethodManager: prepareNavigationBarInfo() DecorView@59812d[DetectorActivity]
D/InputMethodManager: getNavigationBarColor() -855310
V/InputMethodManager: Starting input: tba=org.tensorflow.lite.examples.detection ic=null mNaviBarColor -855310 mIsGetNaviBarColorSuccess true , NavVisible : true , NavTrans : false
D/InputMethodManager: startInputInner - Id : 0
I/InputMethodManager: startInputInner - mService.startInputOrWindowGainedFocus
I/ViewRootImpl@a101c3c[DetectorActivity]: MSG_RESIZED: frame=(0,0,1080,2340) ci=(0,83,0,39) vi=(0,83,0,39) or=1
D/InputMethodManager: prepareNavigationBarInfo() DecorView@59812d[DetectorActivity]
    getNavigationBarColor() -855310
V/InputMethodManager: Starting input: tba=org.tensorflow.lite.examples.detection ic=null mNaviBarColor -855310 mIsGetNaviBarColorSuccess true , NavVisible : true , NavTrans : false
D/InputMethodManager: startInputInner - Id : 0
I/CameraManagerGlobal: Camera 0 facing CAMERA_FACING_BACK state now CAMERA_STATE_ACTIVE for client org.tensorflow.lite.examples.detection API Level 1
W/TFLiteObjectDetectionAPIModelWithInterpreter: cow1
    cow2
    cow3
    cow4
W/TFLiteObjectDetectionAPIModelWithInterpreter: cow5
    cow6
I/tflite: Initialized TensorFlow Lite runtime.
I/tensorflow: DetectorActivity: Camera orientation relative to screen canvas: 90
I/tensorflow: DetectorActivity: Initializing at size 640x480
I/tensorflow: DetectorActivity: Preparing image 1 for detection in bg thread.
W/System: A resource failed to call close. 
I/tensorflow: DetectorActivity: Running detection on image 1`

**E/AndroidRuntime: FATAL EXCEPTION: inference
    Process: org.tensorflow.lite.examples.detection, PID: 22667
    java.nio.BufferOverflowException
        at java.nio.Buffer.nextPutIndex(Buffer.java:542)
        at java.nio.DirectByteBuffer.putFloat(DirectByteBuffer.java:809)
        at org.tensorflow.lite.examples.detection.tflite.TFLiteObjectDetectionAPIModel.recognizeImage(TFLiteObjectDetectionAPIModel.java:187)
        at org.tensorflow.lite.examples.detection.DetectorActivity$2.run(DetectorActivity.java:183)
        at android.os.Handler.handleCallback(Handler.java:883)
        at android.os.Handler.dispatchMessage(Handler.java:100)
        at android.os.Looper.loop(Looper.java:237)
        at android.os.HandlerThread.run(HandlerThread.java:67)
I/Process: Sending signal. PID: 22667 SIG: 9
Disconnected from the target VM, address: 'localhost:46069', transport: 'socket'**



The error suggests a change in these lines:
1. In TFLiteObjectDetectionAPIModel.java:
  private static final float IMAGE_MEAN = 127.5f;
  private static final float IMAGE_STD = 127.5f;

  //...

@Override
  protected void addPixelValue(int pixelValue) {
    **imgData.putFloat((((pixelValue >> 16) & 0xFF) - IMAGE_MEAN) / IMAGE_STD);**
    imgData.putFloat((((pixelValue >> 8) & 0xFF) - IMAGE_MEAN) / IMAGE_STD);
    imgData.putFloat(((pixelValue & 0xFF) - IMAGE_MEAN) / IMAGE_STD);
  }

2. DetectorActivity.java:
 @Override
   public void run() {
   LOGGER.i(""Running detection on image "" + currTimestamp);
   final long startTime = SystemClock.uptimeMillis();
  
 **final List<Detector.Recognition> results = detector.recognizeImage(croppedBitmap);**

   lastProcessingTimeMs = SystemClock.uptimeMillis() - startTime;


Please let me know if I missed any step or did anything wrong.

P. S. - I used a dull-trained model before this and the app worked just fine, except for the fact that it showed all the boundary boxes at once with negligible changes in any detections. I am currently using a well trained model which looks like this (via netron):

![detect tflite](https://user-images.githubusercontent.com/38679773/99057523-e83a9000-25c1-11eb-8fb2-e9515ced1187.png)
"
44830,The TFLite test reported an error,"The Tflite model failed to test Android on the development board
Compiled tflite library:
![15b3b25151b93f1da414d6f36260ac7](https://user-images.githubusercontent.com/54087172/99056074-bb43a880-25d4-11eb-8226-44a1fb8d058d.jpg)
error:
![a2e375014e28b2d18f295e065cd6e3d](https://user-images.githubusercontent.com/54087172/99056182-e3cba280-25d4-11eb-9fda-727686fa1f51.jpg)

why not librk_codec.so? what is  librk_codec.so ?
"
44829,Incorrect File Formats mentioned and Raises Section is missing in ImageDataGenerator Documentation,"The TensorFlow docs are open source! To get involved, read the documentation
contributor guide: https://www.tensorflow.org/community/contribute/docs

## URL(s) with the issue:

Please provide a link to the documentation entry, for example:
https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator

## Description of issue (what needs changing): 

1. In the description corresponding to `Save Format` argument in [ImageDataGenerator.flow](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator#flow), the statement,

> one of ""png"", ""jpeg"" (only relevant if save_to_dir is set). Default: ""png"" 

should be changed to 

> one of ""png"", ""jpeg"", ""jpg"", ""bmp"", ""pdf"", ""gif"" (only relevant if save_to_dir is set). Default: ""png"" 

Please find the [Github Gist](https://colab.research.google.com/gist/rmothukuru/a7b57e5dffaa290dd440ba26b33ea041/file_format_imagedatagenerator.ipynb) that demonstrates acceptance of other formats.

2. **`Raises`** Error section is missing for `ImageDataGenerator`, `ImageDataGenerator.flow`, `ImageDataGenerator.flow_from_directory`, `ImageDataGenerator.flow_from_dataframe`, etc..

### Clear description

**`ImageDataGenerator`** is extremely useful for Computer Vision tasks. So, the more clear and better its documentation is, the more it will help developers.

### Correct links

Is the link to the source code correct? : Yes

### Parameters defined

Are all parameters defined and formatted correctly? : Yes

### Returns defined

Are return values defined? : Yes

### Raises listed and defined : No

Are the errors defined? For example,
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises : No

### Usage example

Is there a usage example? : Missing for `ImageDataGenerator.flow_from_dataframe`

See the API guide: https://www.tensorflow.org/community/contribute/docs_ref
on how to write testable usage examples.

### Request visuals, if applicable

Are there currently visuals? If not, will it clarify the content? : Yes

### Submit a pull request?

Are you planning to also submit a pull request to fix the issue? See the docs
contributor guide: https://www.tensorflow.org/community/contribute/docs,
docs API guide: https://www.tensorflow.org/community/contribute/docs_ref and the
docs style guide: https://www.tensorflow.org/community/contribute/docs_style
"
44825,Add loss raises InaccessibleTensorError,"I made a code for a model reffering to [https://www.tensorflow.org/guide/keras/custom_layers_and_models](https://www.tensorflow.org/guide/keras/custom_layers_and_models)

But the code raised this error:
```
    InaccessibleTensorError: The tensor 'Tensor(""add_1:0"", shape=(2,), dtype=float32)' cannot be accessed here: it is defined in another function or code block. Use return values, explicit Python locals or TensorFlow collections to access it. Defined in: FuncGraph(name=build_graph, id=140714038692944); accessed from: FuncGraph(name=train_function, id=140714048668056).
```
The code has making custom model part using subclass api.<br>

Custom model's call method  includes:
```
        ### VAE loss
        loss_L2 = tf.reduce_mean(tf.square(Z - out_VAE), axis=(1, 2, 3, 4)) # original axis value is (1,2,3,4).
        loss_KL = (1 / self.n) * tf.reduce_sum(
            tf.exp(z_var) + tf.square(z_mean) - 1. - z_var,
            axis=-1
        )

        VAE_loss = self.weight_L2 * loss_L2 + self.weight_KL * loss_KL
        self.add_loss(VAE_loss)
```
When i commented this block, the error was not raised.

Full reproducible code : https://colab.research.google.com/drive/1IpGEGSRP2c6AroCTvualVspqp-4Rnifr#scrollTo=8rFNHMCBpnIo"
44824,ERROR:tensorflow:   Failed to close session after error.Other threads may hang.,"I am trying to pretrain my ELECTRA base, I keep getting this output:

Running training
================================================================================
2020-11-13 08:00:18.044763: W tensorflow/core/distributed_runtime/rpc/grpc_session.cc:370] GrpcSession::ListDevices will initialize the session with an empty graph and other defaults because the session has not yet been created.
Model is built!
2020-11-13 08:00:48.956655: W tensorflow/core/distributed_runtime/rpc/grpc_session.cc:370] GrpcSession::ListDevices will initialize the session with an empty graph and other defaults because the session has not yet been created.
ERROR:tensorflow:Error recorded from infeed: From /job:worker/replica:0/task:0:
{{function_node __inference_tf_data_experimental_map_and_batch_<lambda>_69}} Key: segment_ids.  Can't parse serialized Example.
	 [[{{node ParseSingleExample/ParseSingleExample}}]]
	 [[input_pipeline_task0/while/IteratorGetNext]]
ERROR:tensorflow:Closing session due to error From /job:worker/replica:0/task:0:
{{function_node __inference_tf_data_experimental_map_and_batch_<lambda>_69}} Key: segment_ids.  Can't parse serialized Example.
	 [[{{node ParseSingleExample/ParseSingleExample}}]]
	 [[input_pipeline_task0/while/IteratorGetNext]]
2020-11-13 08:01:08.642776: W tensorflow/core/distributed_runtime/rpc/grpc_remote_master.cc:157] RPC failed with status = ""Unavailable: Socket closed"" and grpc_error_string = ""{""created"":""@1605254468.642525410"",""description"":""Error received from peer"",""file"":""external/grpc/src/core/lib/surface/call.cc"",""file_line"":1039,""grpc_message"":""Socket closed"",""grpc_status"":14}"", maybe retrying the RPC
2020-11-13 08:01:08.642779: W tensorflow/core/distributed_runtime/rpc/grpc_remote_master.cc:157] RPC failed with status = ""Unavailable: Socket closed"" and grpc_error_string = ""{""created"":""@1605254468.642549072"",""description"":""Error received from peer"",""file"":""external/grpc/src/core/lib/surface/call.cc"",""file_line"":1039,""grpc_message"":""Socket closed"",""grpc_status"":14}"", maybe retrying the RPC
ERROR:tensorflow:Error recorded from outfeed: Step was cancelled by an explicit call to `Session::Close()`.
ERROR:tensorflow:


Failed to close session after error.Other threads may hang.



2020-11-13 08:01:50.857700: W tensorflow/core/distributed_runtime/rpc/grpc_session.cc:370] GrpcSession::ListDevices will initialize the session with an empty graph and other defaults because the session has not yet been created.
ERROR:tensorflow:Error recorded from infeed: From /job:worker/replica:0/task:0:
{{function_node __inference_tf_data_experimental_map_and_batch_<lambda>_69}} Key: segment_ids.  Can't parse serialized Example.
	 [[{{node ParseSingleExample/ParseSingleExample}}]]
	 [[input_pipeline_task0/while/IteratorGetNext]]"
44822,Weirdly cannot import tensorflow today (ImportError: cannot import name 'torch' from partially initialized module 'opt_einsum.backends' (most likely due to a circular import)),"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS Catalina and Big Sur
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA
- TensorFlow installed from (source or binary): `pipenv install tensorflow` and `pip install tensorflow`
- TensorFlow version: 2.3.1
- Python version: 3.8.5
- Installed using virtualenv? pip? conda?: pip and pipenv install inside virtual environment
- Bazel version (if compiling from source): NA
- GCC/Compiler version (if compiling from source): NA
- CUDA/cuDNN version: Not using CUDA
- GPU model and memory: NA



**Describe the problem**

Cannot import tensorflow today. I searched my error, but nothing helps. I also searched ""circular import"", but I don't know how to fix it.

**Provide the exact sequence of commands / steps that you executed before running into the problem**
1. pipenv shell
2. pipenv install tensorflow
3. jupyter lab
4. import tensorflow as tf
5. Error!


**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

```python
---------------------------------------------------------------------------
ImportError                               Traceback (most recent call last)
<ipython-input-1-64156d691fe5> in <module>
----> 1 import tensorflow as tf

~/Documents/Academic/USC/Fall 2020/DSCI 510/DSCI510-Final-Project/.venv/lib/python3.8/site-packages/tensorflow/__init__.py in <module>
     39 import sys as _sys
     40 
---> 41 from tensorflow.python.tools import module_util as _module_util
     42 from tensorflow.python.util.lazy_loader import LazyLoader as _LazyLoader
     43 

~/Documents/Academic/USC/Fall 2020/DSCI 510/DSCI510-Final-Project/.venv/lib/python3.8/site-packages/tensorflow/python/__init__.py in <module>
     43 
     44 # Bring in subpackages.
---> 45 from tensorflow.python import data
     46 from tensorflow.python import distribute
     47 from tensorflow.python import keras

~/Documents/Academic/USC/Fall 2020/DSCI 510/DSCI510-Final-Project/.venv/lib/python3.8/site-packages/tensorflow/python/data/__init__.py in <module>
     23 
     24 # pylint: disable=unused-import
---> 25 from tensorflow.python.data import experimental
     26 from tensorflow.python.data.ops.dataset_ops import Dataset
     27 from tensorflow.python.data.ops.dataset_ops import INFINITE as INFINITE_CARDINALITY

~/Documents/Academic/USC/Fall 2020/DSCI 510/DSCI510-Final-Project/.venv/lib/python3.8/site-packages/tensorflow/python/data/experimental/__init__.py in <module>
    123 from tensorflow.python.data.experimental.ops.optimization_options import MapVectorizationOptions
    124 from tensorflow.python.data.experimental.ops.optimization_options import OptimizationOptions
--> 125 from tensorflow.python.data.experimental.ops.parsing_ops import parse_example_dataset
    126 from tensorflow.python.data.experimental.ops.prefetching_ops import copy_to_device
    127 from tensorflow.python.data.experimental.ops.prefetching_ops import prefetch_to_device

~/Documents/Academic/USC/Fall 2020/DSCI 510/DSCI510-Final-Project/.venv/lib/python3.8/site-packages/tensorflow/python/data/experimental/ops/parsing_ops.py in <module>
     24 from tensorflow.python.framework import tensor_spec
     25 from tensorflow.python.ops import gen_experimental_dataset_ops
---> 26 from tensorflow.python.ops import parsing_ops
     27 from tensorflow.python.ops.ragged import ragged_tensor
     28 from tensorflow.python.util.tf_export import tf_export

~/Documents/Academic/USC/Fall 2020/DSCI 510/DSCI510-Final-Project/.venv/lib/python3.8/site-packages/tensorflow/python/ops/parsing_ops.py in <module>
     25 from tensorflow.python.ops import gen_parsing_ops
     26 from tensorflow.python.ops import math_ops
---> 27 from tensorflow.python.ops import parsing_config
     28 # go/tf-wildcard-import
     29 # pylint: disable=wildcard-import,undefined-variable

~/Documents/Academic/USC/Fall 2020/DSCI 510/DSCI510-Final-Project/.venv/lib/python3.8/site-packages/tensorflow/python/ops/parsing_config.py in <module>
     29 from tensorflow.python.ops import check_ops
     30 from tensorflow.python.ops import math_ops
---> 31 from tensorflow.python.ops import sparse_ops
     32 from tensorflow.python.ops.ragged import ragged_math_ops
     33 from tensorflow.python.ops.ragged import ragged_tensor

~/Documents/Academic/USC/Fall 2020/DSCI 510/DSCI510-Final-Project/.venv/lib/python3.8/site-packages/tensorflow/python/ops/sparse_ops.py in <module>
     40 from tensorflow.python.ops import gen_sparse_ops
     41 from tensorflow.python.ops import math_ops
---> 42 from tensorflow.python.ops import special_math_ops
     43 # go/tf-wildcard-import
     44 # pylint: disable=wildcard-import

~/Documents/Academic/USC/Fall 2020/DSCI 510/DSCI510-Final-Project/.venv/lib/python3.8/site-packages/tensorflow/python/ops/special_math_ops.py in <module>
     28 
     29 import numpy as np
---> 30 import opt_einsum
     31 import six
     32 

~/Documents/Academic/USC/Fall 2020/DSCI 510/DSCI510-Final-Project/.venv/lib/python3.8/site-packages/opt_einsum/__init__.py in <module>
      7 from . import paths
      8 from . import path_random
----> 9 from .contract import contract, contract_path, contract_expression
     10 from .parser import get_symbol
     11 from .sharing import shared_intermediates

~/Documents/Academic/USC/Fall 2020/DSCI 510/DSCI510-Final-Project/.venv/lib/python3.8/site-packages/opt_einsum/contract.py in <module>
      8 import numpy as np
      9 
---> 10 from . import backends, blas, helpers, parser, paths, sharing
     11 
     12 __all__ = [""contract_path"", ""contract"", ""format_const_einsum_str"", ""ContractExpression"", ""shape_only""]

~/Documents/Academic/USC/Fall 2020/DSCI 510/DSCI510-Final-Project/.venv/lib/python3.8/site-packages/opt_einsum/backends/__init__.py in <module>
      5 # Backends
      6 from .cupy import to_cupy
----> 7 from .dispatch import (get_func, has_einsum, has_tensordot, build_expression, evaluate_constants, has_backend)
      8 from .tensorflow import to_tensorflow
      9 from .theano import to_theano

~/Documents/Academic/USC/Fall 2020/DSCI 510/DSCI510-Final-Project/.venv/lib/python3.8/site-packages/opt_einsum/backends/dispatch.py in <module>
     14 from . import tensorflow as _tensorflow
     15 from . import theano as _theano
---> 16 from . import torch as _torch
     17 
     18 __all__ = [""get_func"", ""has_einsum"", ""has_tensordot"", ""build_expression"", ""evaluate_constants"", ""has_backend""]

ImportError: cannot import name 'torch' from partially initialized module 'opt_einsum.backends' (most likely due to a circular import) (/Users/anthony/Documents/Academic/USC/Fall 2020/DSCI 510/DSCI510-Final-Project/.venv/lib/python3.8/site-packages/opt_einsum/backends/__init__.py)


```
"
44821,postnet  android,"
How to detect the actions of multiple people in android, there is only one person's behavior detection in the current demo"
44820,Parallelization of tf.DistributedDataset Prefetch? ,"<em>Please make sure that this is an issue related to performance of TensorFlow.
As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:performance_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04 - DGX OS 4
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): Pip
- TensorFlow version (use command below): 2.3.1
- Python version: 3.7
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10.1
- GPU model and memory: 4x V100 32GB

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
DistributedDataset doesnt seem to keep up with input - CPU utilization is low but docs only provide information for tf.Dataset, not tf.DistributedDataset. Curious if there are ways to use AUTOTUNE on a DiatributedDataset to parallelize the prefetching operations. 

**Describe the expected behavior**
Prefetch allows for the data to come off host RAM quick enough to be utilized rapidly.

**Standalone code to reproduce the issue**

This is part of a package I'm developing, so standalone code is rather difficult. Below is the fit function for the model to be trained. Unfortunately it wont be possible to reproduce it standalone. 

obj is a class that is being passed in. This contains the loss, etc. Really the question lies in the first ~30 lines where the dataset is turned into a tf.distributeddataset and then in the last bit where it is iterated

```
def fit_dist(obj, tf_iter, newton_iter, batch_sz = None, newton_eager = True):

    BUFFER_SIZE = len(obj.x_f)
    EPOCHS = tf_iter
    obj.strategy = tf.distribute.MirroredStrategy(cross_device_ops = tf.distribute.NcclAllReduce())
    print(""number of devices: {}"".format(obj.strategy.num_replicas_in_sync))

    if batch_sz is not None:
        obj.batch_sz = batch_sz
    else:
        obj.batch_sz = len(obj.x_f)

    N_f = len(obj.x_f)
    n_batches =  N_f // obj.batch_sz

    BATCH_SIZE_PER_REPLICA = obj.batch_sz
    GLOBAL_BATCH_SIZE = BATCH_SIZE_PER_REPLICA * obj.strategy.num_replicas_in_sync

    train_dataset = tf.data.Dataset.from_tensor_slices((obj.x_f, obj.t_f)).batch(GLOBAL_BATCH_SIZE)

    #print(GLOBAL_BATCH_SIZE)
    obj.train_dist_dataset = obj.strategy.experimental_distribute_dataset(train_dataset)


    start_time = time.time()

    with obj.strategy.scope():
        obj.u_model = neural_net(obj.layer_sizes)
        obj.tf_optimizer = tf.keras.optimizers.Adam(lr = 0.005, beta_1=.99)
        obj.tf_optimizer_weights = tf.keras.optimizers.Adam(lr = 0.005, beta_1=.99)
        #Can adjust batch size for collocation points, here we set it to N_f

        if obj.isAdaptive:
            obj.col_weights = tf.Variable(tf.random.uniform([50000, 1]))
            obj.u_weights = tf.Variable(100*tf.random.uniform([200, 1]))


    print(""starting Adam training"")
    STEPS = np.max((n_batches // obj.strategy.num_replicas_in_sync,1))
    
    for epoch in range(tf_iter):
            train_loss = train_epoch(obj, obj.train_dist_dataset, obj.col_weights, STEPS)
            if epoch == 2:
                tf.profiler.experimental.start('../cache/tblogdir1')
            if epoch % 10 == 0:
                elapsed = time.time() - start_time
                print('It: %d, Time: %.2f' % (epoch, elapsed))
                tf.print(f""total loss: {train_loss}"")
                start_time = time.time()

    tf.profiler.experimental.stop()
    #l-bfgs-b optimization
    print(""Starting L-BFGS training"")
    lbfgs_train(obj, newton_iter)

@tf.function
def train_epoch(obj, dataset, col_weights, STEPS):
    total_loss = 0.0
    num_batches = 0.0
    #dist_col_weights = iter(col_weights)
    dist_dataset_iterator = iter(dataset)
    for _ in range(STEPS):
        total_loss += distributed_train_step(obj, next(dist_dataset_iterator), col_weights)
        num_batches += 1
    train_loss = total_loss / num_batches
    return train_loss

def train_step(obj, inputs, col_weights):
    obj.dist_x_f, obj.dist_t_f = inputs
    obj.dist_col_weights = col_weights
    if obj.isAdaptive:
        obj.variables = obj.u_model.trainable_variables
        obj.variables.extend([obj.u_weights, obj.dist_col_weights])
        loss_value, mse_0, mse_b, mse_f, grads = obj.grad()
        obj.tf_optimizer.apply_gradients(zip(grads[:-2], obj.u_model.trainable_variables))
        obj.tf_optimizer_weights.apply_gradients(zip([-grads[-2], -grads[-1]], [obj.u_weights, obj.dist_col_weights]))
    else:
        obj.variables = obj.u_model.trainable_variables
        loss_value, mse_0, mse_b, mse_f, grads = obj.grad()
        obj.tf_optimizer.apply_gradients(zip(grads, obj.u_model.trainable_variables))
    return loss_value

def distributed_train_step(obj, dataset_inputs, col_weights):
    per_replica_losses = obj.strategy.run(train_step, args=(obj, dataset_inputs, col_weights))
    return obj.strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_losses,
                         axis=None)
```

**What I have tried**
I have been through the docs in custom training loops with mirrored strategy, distributed dataset training, distributed training with Keras, as well as optimizing on GPU with the profiler, better performance with tf.data API, and Optimize TensorFlow performance using the Profiler, most of the associated how-tos and self helps.

Really my question is about more support with tf.DistributedDataset - It prefetches alright (I checked the traces) but it doesn't really utilize the CPU fully (it would appear) and the ops on GPU outrun the data fetching. There is no data preprocessing for my training, all it has to do is pull the points (literally coordinates, a tuple of 2 tf.float32 values) from memory. They're not images or anything large. This is why I think the GPU processing is simply outrunning the data fetching, but I wanted to see if there was a way to better parallelize the tf.DistributedDataset memory fetches on CPU, etc to help get more data in the GPU faster. Like is there an ""autotune"" that I need to enable to do that better in tf.distributedDataset?

I'm attaching my profile traces. Another question would be why only 9% of my ops live on the GPU. When I run on a single GPU without mirrored strategy all the ops live on GPU, here only 9% do. These two event are likely related, but I cant seem to coerce tf into putting more ops on GPU. 



**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

[2020_11_13_04_12_22.zip](https://github.com/tensorflow/tensorflow/files/5534766/2020_11_13_04_12_22.zip)"
44819,How to pass the seq length in the LSTMs in tfLite,"Is there an option to pass seq length in LSTM tfLite ?
Is batch size option suffice seq length ?
Does seq length required during training ?
Can we pass variable seq length during inference ? If we can , How we can do that ?"
44814,what is the difference between tf.nn.fixed_unigram_candidate_sampler and  tf.random.log_uniform_candidate_sampler,"# Problem
There are two functions for the same problem, negative sampling.

# detail
In many examples without your official documentation, we use tf.nn.fixed_unigram_candidate_sampler for negative sampling.
refs:
- https://github.com/carpedm20/practice-tensorflow/blob/master/embedding/word2vec.py#L226-L234
- https://github.com/chao-ji/tf-word2vec/blob/master/word2vec.py#L146-L153

but you want to use tf.random.log_uniform_candidate_sampler for its problem.

So, users confused about which is the better one.
and also, tf.rando.log_uniform_candidate_sampler may not serve correct negative sampling #44758

We need the correct documentation and tutorial for beginners and researchers."
44813,eager execution and gradients,"I tried to visualize CNN activations but faced with the next error:

`RuntimeError: tf.gradients is not supported when eager execution is enabled. Use tf.GradientTape instead.
<img width=""588"" alt=""zi80a"" src=""https://user-images.githubusercontent.com/74381598/98996923-835f3700-24e8-11eb-866e-cfc9e1e5780e.png"">
`

```
layer_dict = dict([(layer.name,layer) for layer in baseline_model.layers[1:]])
img_input = baseline_model.input
neuron_index = 1
layer_output = layer_dict['co[enter image description here][1]nv2d_171'].output
loss = keras.backend.mean(layer_output[:,neuron_index,:,:])
gradients = keras.backend.gradients(loss,img_input)[0]
gradients = tf.linalg.normalize(gradients)
iterate = keras.function([img_input],[loss,gradents])
```"
44811,XNNPACK Delegate error,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): 20
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Redmi 7
- TensorFlow installed from (source or binary): source
- TensorFlow version: 2.3.0
- Python version: 3.8
- Installed using virtualenv? pip? conda?: conda
- Bazel version (if compiling from source): 3.1.0
- GCC/Compiler version (if compiling from source): ndk builder for android-28 API version 20.0.5594570
- CUDA/cuDNN version: 10.1
- GPU model and memory:



**Describe the problem**
How do I get XNNPACK as an optional delegate for my application purely in c++? I tried building with ""define xnnpack=true"" but then it won't allow me to modify the graph with other delegates saying ```ERROR:Graph is immutable"". I tried building XNNPACK separately and link it as required by ""evaluations;:utils"" header, to no avail. Help?

**Provide the exact sequence of commands / steps that you executed before running into the problem**

* I built the tensorflowlite using ```bazel build -c opt --config android_arm64 --define tflite_with_xnnpack=true tensorflow/lite:libtensorflowlite.so ```, I compiled the libraries for Hexagon and GPU and linked them as required by ```evaluation::utils``` header. 
* When runing the application it automatically creates XNNPACK Delegate for me. But when I try to modify graph with GPU delegate, I get 
```
INFO: Created TensorFlow Lite XNNPACK delegate for CPU.
INFO: Created TensorFlow Lite delegate for GPU.
INFO: Initialized OpenCL-based API.
INFO: Created 1 GPU delegate kernels.
ERROR: ModifyGraphWithDelegate is disallowed when graph is immutable.

```

How do I allow changing delegates in XNNPACK support or how do I add optional XNNPACK support? I checked the README.md, following which I got an ```.lo``` file which I'm not sure what to do with. Help

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
44808,Questions regarding tensorflow code (trying to learn and understand),"Hi everyone,

Sorry if this is not the right place, if it's not please remove.

But I have some questions regarding the source code of TensorFlow. I am trying to get a better understanding of the way TF is build up.

- What is the difference between `@keras_export('keras.layers.LSTMCell', v1=[]) `and `@keras_export(v1=['keras.layers.LSTMCell'])`. In the second on it's pointing to version 1, so if you using v1 of keras you will use that class?

- I am also curious about what the best way is to import things from tensorflow. I want to import stuff from the `tensorflow.python.keras.layers.recurrent` I need to import for example `ops, tensor_shape`, but these functions are imported in this recurrent.py file: `from tensorflow.python.framework import ops`, and `from tensorflow.python.framework import tensor_shape`. So what is the best approach, import them straight from the corresponding locations, so `tensorflow.python.framework`, or just import them from `tensorflow.python.keras.layers.recurrent`? 

Importing them from `tensorflow.python.keras.layers.recurrent` really simplifies the code, because you are importing it from one location, but I do not know what the standard approach is.




"
44806,[TFLite] Quantization and unfolding of the ADD_N operator,"Hello,

When adding multiple tensors (> 2) in a NN we can either use `tf.keras.layers.Add` or `tf.math.add_n`. The first one is quantizable but not the second one as unfortunatly even if both have the same high-level functionality they aren't converted in the same way when using the TFLiteConverter.

The `tf.keras.layers.Add` layer is converted to a cascade of binary ADD operators:
![add_cascade](https://user-images.githubusercontent.com/21028116/98962583-b14f7600-24fe-11eb-8d54-589aa5fd64f7.png)

The `tf.math.add_n` on the other hand is converted to a single not yet quantizabe ADD_N operator:
![add_n](https://user-images.githubusercontent.com/21028116/98962472-93821100-24fe-11eb-83f0-36977c558704.png)

It seems there is an existing [`LowerAddNOp`](https://github.com/tensorflow/tensorflow/blob/47f87c040292b2038cd807cd60109d44dd6b5b4d/tensorflow/compiler/mlir/tensorflow/transforms/lower_tf.cc#L186) transformation to lower the ADD_N operator into an adder tree of binary ADD operators (instead of a cascade) but for some reasons it doesn't seem to apply during the tests I did.

As both functions provide the same functionality it would be ideal for them to be exported in the same way in TFLite to avoid any output difference which could occur due to different kernel implementations and additions order as the floating-point and quantized additions are not associative. Unfolding the ADD_N operator would also allow to easily reuse the optimized ADD kernels (both for HW and SW kernels).

As we would like to add support for the quantization of models with `tf.math.add_n` I was wondering what were the plans regarding the ADD_N kernel. Would it be alright to unfold it into a cascade of adds? Or was the plan to unfold it into an adder tree (which would then produce different results than `tf.keras.layers.Add` as the order of additions would not be the same)?

Thanks,
Thibaut

"
44802,TFLite: GPU delegate (OpenCL) not copying output data from GPU to CPU.,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Android
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Samsung Galaxy
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): 2.3
- Python version: -
- Bazel version (if compiling from source): 2.0.0
- GCC/Compiler version (if compiling from source): 
- CUDA/cuDNN version: -
- GPU model and memory: -

**Describe the current behavior**
I have a problem with GPU delegate (OpenCL) not copying output data from GPU to CPU.
In my model I have two outputs. One of them is consumed by the other but I need to know both both results.
The problem is that `std::vector<Value*> GraphFloat32::outputs() const` https://github.com/tensorflow/tensorflow/blob/5681c179eff80bce00e526303950b67b23cad14c/tensorflow/lite/delegates/gpu/common/model.cc#L35 returns nodes that do not have any consumers. This is how outputs are defined by this function which means one of my outputs is not recgonized.
What follows from that is (in order):
- InferenceBuilderImpl having only one output in outputs_ variable https://github.com/tensorflow/tensorflow/blob/5681c179eff80bce00e526303950b67b23cad14c/tensorflow/lite/delegates/gpu/gl/api2.cc#L478
- InitializeGraph placing only one output in output_refs https://github.com/tensorflow/tensorflow/blob/5681c179eff80bce00e526303950b67b23cad14c/tensorflow/lite/delegates/gpu/delegate.cc#L274
- Prepare creating only one output object definition https://github.com/tensorflow/tensorflow/blob/5681c179eff80bce00e526303950b67b23cad14c/tensorflow/lite/delegates/gpu/delegate.cc#L170
- InferenceRunner having only one output https://github.com/tensorflow/tensorflow/blob/5681c179eff80bce00e526303950b67b23cad14c/tensorflow/lite/delegates/gpu/gl/api2.cc#L425
- InferenceRunner copying only one (out of two) outputs from the GPU to CPU-accessible memory https://github.com/tensorflow/tensorflow/blob/5681c179eff80bce00e526303950b67b23cad14c/tensorflow/lite/delegates/gpu/cl/api.cc#L475
Note: I have tested it without the GPU delegate and I have both outputs available so the inference itself works well apparently.

**Describe the expected behavior**
Memory is copied from GPU to CPU memory.
"
44801,Tutorial code freezes indefinitely on TF 2.4 with tf.function,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 Education 1909 64 bit

- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Not used
- TensorFlow installed from (source or binary): pip install tensorflow==2.4.0rc1
- TensorFlow version (use command below): 2.4.0-rc1(v2.4.0-rc0-30-gef82f4c66c)
- Python version: 3.7.9
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: CUDA 11.0.3/cuDNN 8.0.2
- GPU model and memory: RTX 2080ti 11 GB


**Describe the current behavior**
When running the [cyclegan tutorial](https://www.tensorflow.org/tutorials/generative/cyclegan) on a local machine the program freezes during the training loop. It successfully executes two _train_step_ before freezing indefinitely during the third _train_step_. This does not happen with TF 2.3.1 and if @tf.function is removed from the function _train_step_ it also does not happen.


**Describe the expected behavior**
The program should not freeze.

**Standalone code to reproduce the issue**
Download the notebook from https://www.tensorflow.org/tutorials/generative/cyclegan and run it on jupyter notebook with TF 2.4 on Windows. 

**Other info / logs** 
I also tried using python versions 3.6 and 3.8 as well as cuDNN version 8.0.5 and tensorflow versions 2.4.0rc0 and 2.5.0-dev20201029 with the same results.

No errors are printed when the program halts, this is the complete log:
`
2020-11-12 13:23:14.333154: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudart64_110.dll
2020-11-12 13:23:22.692189: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2020-11-12 13:23:22.695520: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library nvcuda.dll
2020-11-12 13:23:22.764684: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties:
pciBusID: 0000:21:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 11.00GiB deviceMemoryBandwidth: 573.69GiB/s
2020-11-12 13:23:22.770470: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties:
pciBusID: 0000:4a:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 11.00GiB deviceMemoryBandwidth: 573.69GiB/s
2020-11-12 13:23:22.776596: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudart64_110.dll
2020-11-12 13:23:23.156041: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublas64_11.dll
2020-11-12 13:23:23.159089: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublasLt64_11.dll
2020-11-12 13:23:23.197670: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cufft64_10.dll
2020-11-12 13:23:23.224469: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library curand64_10.dll
2020-11-12 13:23:23.423940: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusolver64_10.dll
2020-11-12 13:23:23.606110: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusparse64_11.dll
2020-11-12 13:23:24.736751: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudnn64_8.dll
2020-11-12 13:23:24.739994: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1
2020-11-12 13:23:24.742445: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-11-12 13:23:25.086293: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties:
pciBusID: 0000:21:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 11.00GiB deviceMemoryBandwidth: 573.69GiB/s
2020-11-12 13:23:25.091969: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 1 with properties:
pciBusID: 0000:4a:00.0 name: GeForce RTX 2080 Ti computeCapability: 7.5
coreClock: 1.545GHz coreCount: 68 deviceMemorySize: 11.00GiB deviceMemoryBandwidth: 573.69GiB/s
2020-11-12 13:23:25.098150: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudart64_110.dll
2020-11-12 13:23:25.101109: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublas64_11.dll
2020-11-12 13:23:25.104096: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublasLt64_11.dll
2020-11-12 13:23:25.107660: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cufft64_10.dll
2020-11-12 13:23:25.110613: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library curand64_10.dll
2020-11-12 13:23:25.114070: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusolver64_10.dll
2020-11-12 13:23:25.117107: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusparse64_11.dll
2020-11-12 13:23:25.120321: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudnn64_8.dll
2020-11-12 13:23:25.124087: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0, 1
2020-11-12 13:23:25.855306: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-11-12 13:23:25.858740: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 1
2020-11-12 13:23:25.860826: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N N
2020-11-12 13:23:25.862739: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 1:   N N
2020-11-12 13:23:25.865414: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 8581 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:21:00.0, compute capability: 7.5)
2020-11-12 13:23:25.871513: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 8581 MB memory) -> physical GPU (device: 1, name: GeForce RTX 2080 Ti, pci bus id: 0000:4a:00.0, compute capability: 7.5)
2020-11-12 13:23:25.877802: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2020-11-12 13:23:26.305762: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2020-11-12 13:23:26.553589: W tensorflow/core/kernels/data/cache_dataset_ops.cc:757] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to dataset.cache().take(k).repeat(). You should use dataset.take(k).cache().repeat() instead.
2020-11-12 13:23:26.563266: W tensorflow/core/kernels/data/cache_dataset_ops.cc:757] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to dataset.cache().take(k).repeat(). You should use dataset.take(k).cache().repeat() instead.
2020-11-12 13:23:26.940273: W tensorflow/core/kernels/data/cache_dataset_ops.cc:757] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to dataset.cache().take(k).repeat(). You should use dataset.take(k).cache().repeat() instead.
2020-11-12 13:23:26.951226: W tensorflow/core/kernels/data/cache_dataset_ops.cc:757] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to dataset.cache().take(k).repeat(). You should use dataset.take(k).cache().repeat() instead.
2020-11-12 13:23:30.401325: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudnn64_8.dll
2020-11-12 13:23:33.790176: I tensorflow/core/platform/windows/subprocess.cc:308] SubProcess ended with return code: 0
2020-11-12 13:23:33.839252: I tensorflow/core/platform/windows/subprocess.cc:308] SubProcess ended with return code: 0
2020-11-12 13:23:33.852673: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublas64_11.dll
2020-11-12 13:23:34.345317: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublasLt64_11.dll
`"
44800,Undefined symbols for architecture arm64 _TFE_*,"
**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS Catilina 10.15.7
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: iOS 14
- TensorFlow installed from (source or binary): source
- TensorFlow version: TF 2.0.0
- Python version: 3.8
- Installed using virtualenv? pip? conda?: conda
- Bazel version (if compiling from source): 0.26.1
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:



**Describe the problem**
Hi,

I am not used to build tensorflow from source for iOS so I'm probably doing something wrong. I used the instructions in tensorflow/contrib/makefile to build a static library for iOS architectures. But when I import it into Xcode I get link errors like:

`Undefined symbols for architecture arm64: _TFE_TensorHandleResolve`

What am I missing?

Moreover, I saw that for newer versions of tensorflow there is no contrib folder: how can I build a static library with newer tensorflow, for example 2.3, for iOS?

"
44799,TFRecord add total_num,"**System information**
- TensorFlow version (you are using): tf2.3.1

example:
```python
data = tf.data.TFRecordDataset('./data/train.tfrecord').map(parse_function).batch(100)
print(len(data))
```
I want to get `len(data) = total_num/batch_size`

I suggest to auto add `total_num` in `train.tfrecord` when created train.tfrecord. Then the TFRecordDataset can direct  to get `len(data) = total_num/batch_size`



"
44798,ambiguity of data type of weight,"
**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Ubuntu 18.04.4 LTS
- TensorFlow installed from (source or binary):source
- TensorFlow version (use command below):v2.3.1
- Bazel version (if compiling from source):3.1.0


**Current and expected  behavior**
I am supporting our delegete for tensorflow Lite. when I do the uint test, I found some cases(e.g.,SimpleTestHybridUint8) in
tensorflow/lite/kernel/conv_test.cc. they describe their weight type as Uint8, but quantize and calculate as Int8. This kind of behavior doesn't make sense. we can't handle this behavior because it makes ambiguity to our delegate.
So I hope you guys to delete this kind of cases or unify their data type.


"
44797,set_visible_devices with MirroredStrategy causes NCCL warnings,"**System information**
- I have written custom code
- OS Platform and Distribution: Linux Ubuntu 18.04
- TensorFlow installed `FROM tensorflow/tensorflow:2.3.0-gpu`
- TensorFlow version 2.3.0 
- Python version 3.6.9
- CUDA/cuDNN version: 10.1
- GPU model and memory: nvidia dgx, 8xV100, volta architecture, 8x16GB

**Describe the current behavior**

If `tf.config.set_visible_devices` is used presumably ""Virtual GPUs"" are created, which when combined with default `MirroredStrategy` leads to the following warning:

> WARNING:tensorflow:NCCL is not supported when using virtual GPUs, falling back to reduction to one device

I started setting the `CUDA_VISIBLE_DEVICES` env variable to go around the need for `set_visible_devices` but that is not ideal:
- it defeats the purpose of the `set_visible_devices`  
- it is not convenient
- my tensorboard profiler plugin started to crash with segfault after the `keras.fit` training session is over but before profiling data buffer is flushed (perhaps this is fair game as it seems that CUDA 10.2 is needed for that to officially work for multi-GPU)

**Describe the expected behavior**

I would like to use `set_visible_devices` without causing any problems listed above.

**Standalone code to reproduce the issue**

I will provide this at a later stage if necessary, but I believe just using a combination of 2 APIs above should reproduce the issue."
44796,Issue in building tensorflow r2.3 from source,"Hi, I am having issue compiling tensorflow r2.3 for CPU from the source on ubuntu I am using following flags 

```--config=opt --copt=-march=native --copt=-Wno-sign-compare --copt=-mfpmath=both --copt=-mavx --copt=-mavx2 --copt=-mfma
 --copt=-msse4.1 --copt=-msse4.2 //tensorflow/tools/pip_package:build_pip_package --verbose_failures
```
------------------------

### System information

-   **Have I written custom code (as opposed to using a stock example script
    provided in TensorFlow)**: No - I git clone the code
-   **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: ubuntu 20.04 docker image
-   **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue
    happens on a mobile device**: No
-   **TensorFlow installed from (source or binary)**:  Source
-   **TensorFlow version (use command below)**: 2.3
-   **Python version**: 3.8.5
-   **Bazel version (if compiling from source)**: 3.1.0
-   **GCC/Compiler version (if compiling from source)**: 9.3.0
-   **CUDA/cuDNN version**: Not applicable
-   **GPU model and memory**: Not applicable
-   **Exact command to reproduce**:

`bazel build --config=opt --copt=-march=native --copt=-Wno-sign-compare --copt=-mfpmath=both --copt=-mavx --copt=-mavx2 --copt=-mfma --copt=-msse4.1 --copt=-msse4.2 //tensorflow/tools/pip_package:build_pip_package --verbose_failures`

Attaching tf_env.txt for the reference.


### Describe the problem
While building the tensorflow from the source, build fails with error
ERROR: /tensorflow_src/tensorflow/python/BUILD:501:1: C++ compilation of rule '//tensorflow/python:bfloat16_lib' failed (Exit 1): gcc failed: error executing command 
  (cd /root/.cache/bazel/_bazel_root/43801f1e35f242fb634ebbc6079cf6c5/execroot/org_tensorflow && \
  exec env - \
    PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/.local/bin \
    PWD=/proc/self/cwd \

<long string>

ERROR: /tensorflow_src/tensorflow/python/tools/BUILD:99:1 C++ compilation of rule '//tensorflow/python:bfloat16_lib' failed (Exit 1): gcc failed: error executing command 
  (cd /root/.cache/bazel/_bazel_root/43801f1e35f242fb634ebbc6079cf6c5/execroot/org_tensorflow && \
  exec env - \
    PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/.local/bin \
    PWD=/proc/self/cwd \

<long string>
INFO: Elapsed time: 2497.566s, Critical Path: 187.54s
INFO: 10577 processes: 10577 local.
FAILED: Build did NOT complete successfully

Attaching error.txt for detailed error log

### Source code / logs
attaching error.txt for detailed error log
[error.txt](https://github.com/tensorflow/tensorflow/files/5529073/error.txt)
[tf_env.txt](https://github.com/tensorflow/tensorflow/files/5529075/tf_env.txt)

"
44795,Python returns multiple errors on using gTTS module,"`from gtts import gTTS`
`test=gTTS(text=""Hello World"", lang='en')`
`test.save('sample.mp3')`

### **Error:**
C:\Program Files\Python37\lib\http\cookiejar.py:1623: UserWarning: http.cookiejar bug!
Traceback (most recent call last):
  File ""C:\Program Files\Python37\lib\http\cookiejar.py"", line 1621, in make_cookies
    parse_ns_headers(ns_hdrs), request)
  File ""C:\Program Files\Python37\lib\http\cookiejar.py"", line 1577, in _cookies_from_attrs_set
    cookie = self._cookie_from_cookie_tuple(tup, request)
  File ""C:\Program Files\Python37\lib\http\cookiejar.py"", line 1570, in _cookie_from_cookie_tuple
    rest)
  File ""C:\Program Files\Python37\lib\http\cookiejar.py"", line 793, in __init__
    self._rest = copy.copy(rest)
AttributeError: module 'copy' has no attribute 'copy'

  _warn_unhandled_exception()
C:\Program Files\Python37\lib\http\cookiejar.py:1623: UserWarning: http.cookiejar bug!
Traceback (most recent call last):
  File ""C:\Program Files\Python37\lib\http\cookiejar.py"", line 1621, in make_cookies
    parse_ns_headers(ns_hdrs), request)
  File ""C:\Program Files\Python37\lib\http\cookiejar.py"", line 1577, in _cookies_from_attrs_set
    cookie = self._cookie_from_cookie_tuple(tup, request)
  File ""C:\Program Files\Python37\lib\http\cookiejar.py"", line 1570, in _cookie_from_cookie_tuple
    rest)
  File ""C:\Program Files\Python37\lib\http\cookiejar.py"", line 793, in __init__
    self._rest = copy.copy(rest)
AttributeError: module 'copy' has no attribute 'copy'

  _warn_unhandled_exception()
Traceback (most recent call last):
  File ""c:\Users\Benison\OneDrive\Programs\Python\XII\test.py"", line 5, in <module>
    tts.save(""synthesized.mp3"")
    prepared_requests = self._prepare_requests()                                        e 295, in save
  File ""C:\Users\Benison\AppData\Roaming\Python\Python37\site-packages\gtts\tts.py"", line 194, in _prepare_requests                                                             e 251, in write_to_fp
    part_tk = self.token.calculate_token(part)
  File ""C:\Users\Benison\AppData\Roaming\Python\Python37\site-packages\gtts_token\gtts_te 194, in _prepare_requestsoken.py"", line 28, in calculate_token
    seed = self._get_token_key()                                                        oken.py"", line 28, in calculate_token  
  File ""C:\Users\Benison\AppData\Roaming\Python\Python37\site-packages\gtts_token\gtts_token.py"", line 59, in _get_token_key                                                    oken.py"", line 59, in _get_token_key   
    ""Unable to find token seed! Did https://translate.google.com change?""
ValueError: Unable to find token seed! Did https://translate.google.com change?
PS C:\Users\Benison\OneDrive\Programs\Python>  cd 'c:\Users\Benison\OneDrive\Programs\Python'; & 'C:\Program Files\Python37\python.exe' 'c:\Users\Benison\.vscode\extensions\ms-python.python-2020.11.358366026\pythonFiles\lib\python\debugpy\launcher' '59434' '--' 'c:\Users\Benison\OneDrive\Programs\Python\XII\test.py' 
C:\Program Files\Python37\lib\http\cookiejar.py:1623: UserWarning: http.cookiejar bug!
Traceback (most recent call last):
  File ""C:\Program Files\Python37\lib\http\cookiejar.py"", line 1621, in make_cookies    
    parse_ns_headers(ns_hdrs), request)
  File ""C:\Program Files\Python37\lib\http\cookiejar.py"", line 1577, in _cookies_from_attrs_set
    cookie = self._cookie_from_cookie_tuple(tup, request)
  File ""C:\Program Files\Python37\lib\http\cookiejar.py"", line 1570, in _cookie_from_cookie_tuple
    rest)
  File ""C:\Program Files\Python37\lib\http\cookiejar.py"", line 793, in __init__
    self._rest = copy.copy(rest)
AttributeError: module 'copy' has no attribute 'copy'

  _warn_unhandled_exception()
C:\Program Files\Python37\lib\http\cookiejar.py:1623: UserWarning: http.cookiejar bug!
Traceback (most recent call last):
  File ""C:\Program Files\Python37\lib\http\cookiejar.py"", line 1621, in make_cookies    
    parse_ns_headers(ns_hdrs), request)
  File ""C:\Program Files\Python37\lib\http\cookiejar.py"", line 1577, in _cookies_from_attrs_set
    cookie = self._cookie_from_cookie_tuple(tup, request)
  File ""C:\Program Files\Python37\lib\http\cookiejar.py"", line 1570, in _cookie_from_cookie_tuple
    rest)
  File ""C:\Program Files\Python37\lib\http\cookiejar.py"", line 793, in __init__
    self._rest = copy.copy(rest)
AttributeError: module 'copy' has no attribute 'copy'

  _warn_unhandled_exception()"
44792,How to fastly convert numpy array into TensorFlow tensor in TF 2.x,"**Describe the current behavior**

I want to train TF DNN model, and the input data is from numpy array.

When inputting data from numpy to TensorFlow, converting to tensor will be triggered no matter which ways I used.
Specifically, I tried these 4 methods:
1) tf.constant(numpy_value)
2) tf.convert_to_tensor(numpy_value)
3) create a tf.Variable, then Variable.assign
4) tf.keras.backend.set_value(variable, numpy_value)

when profiling, there will be `TF_NewTensor` triggered, which might convert numpy value into tensor format. And it is too slow.
![image](https://user-images.githubusercontent.com/69858819/98893834-602f8a00-24de-11eb-807d-ae5b07aa4ca2.png)


**Describe the expected behavior**
1) how to fastly converting numpy array to TF tensor?
2) Or how can I convert numpy array to TF tensor in advance, then I just need give that tensor to TF ops rather than waiting for converting is done then begin forward propagation.

BTW, because batchsize is too large, so `tf.data.TFRecordDataset` is not fast enough to do the profiling, therefore I need to directly input binary value to TF ops.
"
44791,Dynamic Batching for Text Vectorization,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): Tensorflow-2.3.0, tf-nightly
- Are you willing to contribute it (Yes/No): Yes



**Describe the feature and the current behavior/state.**

Currently tensorflow.keras.layers.experimental.preprocessing.Text Vectorization automatically pad each sentence vector to max_tokens. I was wondering if it is possible to add an dynamic batching option so that the layer only pad the each batch to longest vector in each batch. This could improve the performance of TensorFlow RNNs. Currently, the only way to do this is to clip batches after this layer, wasting computational resources.

**Will this change the current api? How?**
Yes, an additional parameter should be passed. However, existing users would not be affected. 
**Who will benefit with this feature?**
Anyone who use dynamic RNN. 
**Any Other info.**
"
44790,"Exception: <unknown>:0: error: loc(""batch_normalization/moving_mean""): is not immutable, try running tf-saved-model-optimize-global-tensors to prove tensors are immutable","**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Both Linux 20.04 and Windows 10
- TensorFlow installed from (source or binary): Binary (pip install tf-nightly)
- TensorFlow version (or github SHA if from source): 2.5.0-dev20201111


**Command used to run the converter or code if you’re using the Python API**
If possible, please share a link to Colab/Jupyter/any notebook.

Command
```
(tf25) ubuntu@ubuntu-TFG257XS:~/yolo_tf/tensorflow-yolov4-tflite$ python convert_tflite.py --weights ./checkpoints/yolov4-416-tflite --output ./checkpoints/yolov4-416.tflite
```
Code
```
import tensorflow as tf
from absl import app, flags, logging
from absl.flags import FLAGS
import numpy as np
import cv2
from core.yolov4 import YOLOv4, YOLOv3, YOLOv3_tiny, decode
import core.utils as utils
import os
from core.config import cfg

flags.DEFINE_string('weights', './checkpoints/yolov4-416', 'path to weights file')
flags.DEFINE_string('output', './checkpoints/yolov4-416-fp32.tflite', 'path to output')
flags.DEFINE_integer('input_size', 416, 'path to output')
flags.DEFINE_string('quantize_mode', 'float32', 'quantize mode (int8, float16, float32)')
flags.DEFINE_string('dataset', ""/Volumes/Elements/data/coco_dataset/coco/5k.txt"", 'path to dataset')

def representative_data_gen():
  fimage = open(FLAGS.dataset).read().split()
  for input_value in range(10):
    if os.path.exists(fimage[input_value]):
      original_image=cv2.imread(fimage[input_value])
      original_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)
      image_data = utils.image_preprocess(np.copy(original_image), [FLAGS.input_size, FLAGS.input_size])
      img_in = image_data[np.newaxis, ...].astype(np.float32)
      print(""calibration image {}"".format(fimage[input_value]))
      yield [img_in]
    else:
      continue

def save_tflite():
  converter = tf.lite.TFLiteConverter.from_saved_model(FLAGS.weights)

  if FLAGS.quantize_mode == 'float16':
    converter.optimizations = [tf.lite.Optimize.DEFAULT]
    converter.target_spec.supported_types = [tf.compat.v1.lite.constants.FLOAT16]
    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]
    converter.allow_custom_ops = True
  elif FLAGS.quantize_mode == 'int8':
    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]
    converter.optimizations = [tf.lite.Optimize.DEFAULT]
    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]
    converter.allow_custom_ops = True
    converter.representative_dataset = representative_data_gen

  tflite_model = converter.convert()
  open(FLAGS.output, 'wb').write(tflite_model)

  logging.info(""model saved to: {}"".format(FLAGS.output))

def demo():
  interpreter = tf.lite.Interpreter(model_path=FLAGS.output)
  interpreter.allocate_tensors()
  logging.info('tflite model loaded')

  input_details = interpreter.get_input_details()
  print(input_details)
  output_details = interpreter.get_output_details()
  print(output_details)

  input_shape = input_details[0]['shape']

  input_data = np.array(np.random.random_sample(input_shape), dtype=np.float32)

  interpreter.set_tensor(input_details[0]['index'], input_data)
  interpreter.invoke()
  output_data = [interpreter.get_tensor(output_details[i]['index']) for i in range(len(output_details))]

  print(output_data)

def main(_argv):
  save_tflite()
  demo()

if __name__ == '__main__':
    try:
        app.run(main)
    except SystemExit:
        pass
```

**The output from the converter invocation**

```
(tf25) ubuntu@ubuntu-TFG257XS:~/yolo_tf/tensorflow-yolov4-tflite$ python convert_tflite.py --weights ./checkpoints/yolov4-416-tflite --output ./checkpoints/yolov4-416.tflite
2020-11-12 10:51:14.591438: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2020-11-12 10:51:14.591714: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-11-12 10:51:21.071335: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:319] Ignored output_format.
2020-11-12 10:51:21.071397: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:322] Ignored drop_control_dependency.
2020-11-12 10:51:21.071417: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:328] Ignored change_concat_input_ranges.
2020-11-12 10:51:21.072230: I tensorflow/cc/saved_model/reader.cc:32] Reading SavedModel from: ./checkpoints/yolov4-416-tflite
2020-11-12 10:51:21.126090: I tensorflow/cc/saved_model/reader.cc:55] Reading meta graph with tags { serve }
2020-11-12 10:51:21.126129: I tensorflow/cc/saved_model/reader.cc:93] Reading SavedModel debug info (if present) from: ./checkpoints/yolov4-416-tflite
2020-11-12 10:51:21.270211: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:251] None of the MLIR optimization passes are enabled (registered 0 passes)
2020-11-12 10:51:21.307128: I tensorflow/cc/saved_model/loader.cc:206] Restoring SavedModel bundle.
2020-11-12 10:51:21.354451: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2299965000 Hz
2020-11-12 10:51:21.867525: I tensorflow/cc/saved_model/loader.cc:190] Running initialization op on SavedModel bundle at path: ./checkpoints/yolov4-416-tflite
2020-11-12 10:51:22.030647: I tensorflow/cc/saved_model/loader.cc:277] SavedModel load for tags { serve }; Status: success: OK. Took 958418 microseconds.
2020-11-12 10:51:22.617404: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:194] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
loc(""batch_normalization/moving_mean""): error: is not immutable, try running tf-saved-model-optimize-global-tensors to prove tensors are immutable
Traceback (most recent call last):
  File ""/home/ubuntu/anaconda3/envs/tf25/lib/python3.7/site-packages/tensorflow/lite/python/convert.py"", line 213, in toco_convert_protos
    enable_mlir_converter)
  File ""/home/ubuntu/anaconda3/envs/tf25/lib/python3.7/site-packages/tensorflow/lite/python/wrap_toco.py"", line 38, in wrapped_toco_convert
    enable_mlir_converter)
Exception: <unknown>:0: error: loc(""batch_normalization/moving_mean""): is not immutable, try running tf-saved-model-optimize-global-tensors to prove tensors are immutable


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""convert_tflite.py"", line 76, in <module>
    app.run(main)
  File ""/home/ubuntu/anaconda3/envs/tf25/lib/python3.7/site-packages/absl/app.py"", line 303, in run
    _run_main(main, args)
  File ""/home/ubuntu/anaconda3/envs/tf25/lib/python3.7/site-packages/absl/app.py"", line 251, in _run_main
    sys.exit(main(argv))
  File ""convert_tflite.py"", line 71, in main
    save_tflite()
  File ""convert_tflite.py"", line 45, in save_tflite
    tflite_model = converter.convert()
  File ""/home/ubuntu/anaconda3/envs/tf25/lib/python3.7/site-packages/tensorflow/lite/python/lite.py"", line 745, in convert
    result = _convert_saved_model(**converter_kwargs)
  File ""/home/ubuntu/anaconda3/envs/tf25/lib/python3.7/site-packages/tensorflow/lite/python/convert.py"", line 637, in convert_saved_model
    enable_mlir_converter=True)
  File ""/home/ubuntu/anaconda3/envs/tf25/lib/python3.7/site-packages/tensorflow/lite/python/convert.py"", line 216, in toco_convert_protos
    raise ConverterError(str(e))
tensorflow.lite.python.convert.ConverterError: <unknown>:0: error: loc(""batch_normalization/moving_mean""): is not immutable, try running tf-saved-model-optimize-global-tensors to prove tensors are immutable
```

**Also, please include a link to the saved model or GraphDef**

Saved Model : yolov4-416-tflite.zip
```
https://drive.google.com/file/d/1JXAUuRRfkpp5h-6NA7SXduKMAeMQBssG/view?usp=sharing
```

**Failure details**
When I tried to get .tflite file from saved model(tflite), failed to generate .tflite file with Error message
This problem happens regardless of quantization (FP32, FP16, INT8)


**Any other info / logs**
When I tried to get .tflite with Tensorflow 2.3.0rc0, it worked well (could generate .tflite file and execute it with tflite interpreter)
But I failed to generate .tflite file with tf-nightly 2.5.0-dev2020111
How can I solve this problem?"
44789,"TF Lite Micro : Hosted Model: ""Didn't find op for builtin opcode 'SQUEEZE'""","@tensorflow/micro

**System information**
- Host OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS, Programming via PlatformIO
- TensorFlow installed from (source or binary): Followed Hello-World example, copied TF Lite dependencies into PlatformIO project
- Tensorflow version (commit SHA if source): Downloaded today ; aab9c69b692904df384f0e2a1b4f31cfc21fee42
- Target platform (e.g. Arm Mbed OS, Arduino Nano 33 etc.): ESP32

**Describe the problem**
I have setup a PlatformIO project, based on the Hello World example, that simply loads in model.cc. 

The project runs fine for the supplied model, but replacing it with **mobilenet_v1_0.25_128 (hosted tf lite model)** results in the following error when `AllocateTensors()` is called:

```Calling AllocateTensors
Didn't find op for builtin opcode 'SQUEEZE' version '1'

Failed to get registration from op code SQUEEZE
 
Failed starting model allocation.

AllocateTensors() failed
```

 Any help would be appreciated!



**Please provide the exact sequence of commands/steps when you ran into the problem**
Simply deployed the project I defined in PlatformIO, that was previously working with a different model. My main class looks like this, using `g_model` defined within `model.cc`: 

```#include ""tensorflow/lite/micro/all_ops_resolver.h""
#include ""constants.h""
#include ""model.h""
#include ""output_handler.h""
#include ""tensorflow/lite/micro/micro_error_reporter.h""
#include ""tensorflow/lite/micro/micro_interpreter.h""
#include ""tensorflow/lite/schema/schema_generated.h""
#include ""tensorflow/lite/version.h""
#include <Arduino.h>

// Globals, used for compatibility with Arduino-style sketches.
//namespace {
tflite::ErrorReporter* error_reporter = nullptr;
const tflite::Model* model = nullptr;
tflite::MicroInterpreter* interpreter = nullptr;
TfLiteTensor* input = nullptr;
TfLiteTensor* output = nullptr;
int inference_count = 0;

// Create an area of memory to use for input, output, and intermediate arrays.
// Minimum arena size, at the time of writing. After allocating tensors
// you can retrieve this value by invoking interpreter.arena_used_bytes().
const int kModelArenaSize = 754;
// Extra headroom for model + alignment + future interpreter changes.
const int kExtraArenaSize = 554 + 16 + 100;
const int kTensorArenaSize = 9*1024; //kModelArenaSize + kExtraArenaSize;
uint8_t * tensor_arena;
//}  // namespace

// The name of this function is important for Arduino compatibility.
void setup() {
  tensor_arena = (uint8_t*) heap_caps_calloc(kTensorArenaSize, 1, MALLOC_CAP_SPIRAM | MALLOC_CAP_8BIT);
  //tensor_arena = (uint8_t*) heap_caps_calloc(kTensorArenaSize, 1, MALLOC_CAP_SPIRAM | MALLOC_CAP_8BIT);
  // Set up logging. Google style is to avoid globals or statics because of
  // lifetime uncertainty, but since this has a trivial destructor it's okay.
  // NOLINTNEXTLINE(runtime-global-variables)
  static tflite::MicroErrorReporter micro_error_reporter;
  error_reporter = &micro_error_reporter;

  // Map the model into a usable data structure. This doesn't involve any
  // copying or parsing, it's a very lightweight operation.
  model = tflite::GetModel(g_model);
  if (model->version() != TFLITE_SCHEMA_VERSION) {
    TF_LITE_REPORT_ERROR(error_reporter,
                         ""Model provided is schema version %d not equal ""
                         ""to supported version %d."",
                         model->version(), TFLITE_SCHEMA_VERSION);
    return;
  }

  // This pulls in all the operation implementations we need.
  // NOLINTNEXTLINE(runtime-global-variables)
  static tflite::AllOpsResolver resolver;

  // Build an interpreter to run the model with.
  static tflite::MicroInterpreter static_interpreter(
      model, resolver, tensor_arena, kTensorArenaSize, error_reporter);
  interpreter = &static_interpreter;

  TF_LITE_REPORT_ERROR(error_reporter, ""Calling AllocateTensors"");
  // Allocate memory from the tensor_arena for the model's tensors.
  TfLiteStatus allocate_status = interpreter->AllocateTensors();
  if (allocate_status != kTfLiteOk) {
    TF_LITE_REPORT_ERROR(error_reporter, ""AllocateTensors() failed"");
    return;
  }
  TF_LITE_REPORT_ERROR(error_reporter, ""Successful Allocation"");

  // Obtain pointers to the model's input and output tensors.
  input = interpreter->input(0);
  output = interpreter->output(0);

  // Keep track of how many inferences we have performed.
  inference_count = 0;
}

// The name of this function is important for Arduino compatibility.
void loop() {
  delay(10);
}
```

"
44788,bad shape of index returned by UniqueWithCountsV2 in graph mode,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.2.0
- Python version: 3.6.9
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`


**Describe the current behavior**
The index returned by `tf.raw_ops.UniqueWithCountsV2` does not have the right shape when used in graph mode.

**Describe the expected behavior**
The index returned by `tf.raw_ops.UniqueWithCountsV2` should have the right shape when used iin graph mode.

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.


Here's some simple code to illustrate the problem:

```python
import tensorflow as tf

# The same function: decorated with tf.function (will be executed in graph mode) and 
# not decorated (will be executed in eager mode)

@tf.function
def graph_func(x):
    unique_input_ids, idx, counts = tf.raw_ops.UniqueWithCountsV2(x=x, axis=[0])
    tf.print('idx shape', tf.shape(idx), 'idx', idx)
    return x

def eager_func(x):
    unique_input_ids, idx, counts = tf.raw_ops.UniqueWithCountsV2(x=x, axis=[0])
    tf.print('idx shape', tf.shape(idx), 'idx', idx)
    return x

c = tf.constant([[0,0,1], 
                 [0,0,1], 
                 [0,0,2], 
                 [0,0,1]])
_ = graph_func(c)
_ = eager_func(c)
```
Prints this:
```
idx shape [4 3] idx [0 0 1 0]
idx shape [4] idx [0 0 1 0]
```
The first output doesn’t make sense. The shape doesn’t even match the printed tensor.

Investigating further with a dataset:

```python
ds = tf.data.Dataset.from_tensor_slices(c).repeat(40).batch(4)
_ = graph_func(next(iter(ds)))
_ = eager_func(next(iter(ds)))
```
Prints this:
```
idx shape [4 3] idx [0 0 1 0]
idx shape [4] idx [0 0 1 0]
```
`graph_func` is executed in graph mode. The behavior is still unexpect (shape `[4 3]` instead of `[4]`).

But if we the data comes from the dataset through a `map` function for example (both functions are executed in graph mode), it works as expected:
```
_ = next(iter(ds.map(graph_func)))
_ = next(iter(ds.map(eager_func)))
```

This time, prints the expected result:
```
idx shape [4] idx [0 0 1 0]
idx shape [4] idx [0 0 1 0]
```


**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
44787,Newer version of tf nightly has changed the index order for the tensor output array,"when reading in the TFlite model for EfficientDet D0 there are 8 values to the 1st index and their meaning is defined. Older version had the below order and for the newer tfnighly version,the order has changed and couldn't find documentation for the newer order, and using the tflite converted with newer version of tf nightly breaks the android code

Please refer the image below
![image](https://user-images.githubusercontent.com/47469211/98880127-e8a91e80-243b-11eb-8a34-86aa403aaf53.png)

Colab that used older version of tfnightly (tf-nightly==2.4.0-dev20200929) for tflite conversion: 
https://colab.research.google.com/drive/1Ss4ZaO52gOBvhr-5DRXiiuPQ7I_vIt-Y?usp=sharing
https://github.com/grewe/covidID_mask/blob/master/maskDetect/MaskDetectTflite.ipynb

	INPUT DETAILS: 
		 [{'name': 'serving_default_input_tensor:0', 'index': 0, 'shape': array([  1, 512, 512,   3], dtype=int32), 'shape_signature': array([  1, 512, 512,   3], dtype=int32), 'dtype': <class 'numpy.uint8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]
		OUTPUT DETAILS: 
		 [{'name': 'StatefulPartitionedCall:4', 'index': 66563, 'shape': array([1, 1], dtype=int32), 'shape_signature': array([ 1, -1], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'StatefulPartitionedCall:6', 'index': 66384, 'shape': array([    1, 49104,     4], dtype=int32), 'shape_signature': array([    1, 49104,     4], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'StatefulPartitionedCall:5', 'index': 66546, 'shape': array([1], dtype=int32), 'shape_signature': array([1], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'StatefulPartitionedCall:1', 'index': 66642, 'shape': array([1, 1, 1], dtype=int32), 'shape_signature': array([ 1, -1, -1], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'StatefulPartitionedCall:2', 'index': 66620, 'shape': array([1, 1], dtype=int32), 'shape_signature': array([ 1, -1], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'StatefulPartitionedCall:7', 'index': 66405, 'shape': array([    1, 49104,     3], dtype=int32), 'shape_signature': array([    1, 49104,     3], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'StatefulPartitionedCall:3', 'index': 66603, 'shape': array([1, 1, 1], dtype=int32), 'shape_signature': array([ 1, -1, -1], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'StatefulPartitionedCall:0', 'index': 66581, 'shape': array([1, 1], dtype=int32), 'shape_signature': array([ 1, -1], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]


**Output array:**

(1, 512, 512, 3)
[[0.9609589  0.0873408  0.06809524 0.05999154 0.05568287 0.03616852
  0.03515935 0.03388214 0.02964088 0.02917778 0.02844885 0.02752271
  0.02532643 0.02329737 0.02278286 0.0213418  0.0210638  0.02019128
  0.01916748 0.01763159 0.01730308 0.0164015  0.01632011 0.01615366
  0.01609802 0.01606014 0.01520342 0.01478559 0.01420614 0.0132328
  0.01292685 0.01276404 0.01265842 0.01264325 0.01245722 0.01230013
  0.01227069 0.01221645 0.01210919 0.01204768 0.01181906 0.01178762
  0.01154467 0.01148716 0.01128137 0.01100454 0.01090339 0.01090035
  0.01056659 0.01046374 0.01039562 0.01035801 0.0101763  0.01016143
  0.01015401 0.0101212  0.00995958 0.00986671 0.00980252 0.00979534
  0.00976944 0.00947464 0.00944296 0.00930616 0.00917202 0.00895733
  0.00894633 0.00891778 0.00886655 0.00885886 0.00849381 0.00849113
  0.00848216 0.00847018 0.00844333 0.00835618 0.00833991 0.00832459
  0.00819856 0.0081273  0.00803497 0.00802234 0.00790223 0.0078285
  0.0078209  0.00782064 0.00778884 0.00771174 0.00768062 0.00766596
  0.0076198  0.00758222 0.00756696 0.00753024 0.00749895 0.00749457
  0.00748292 0.00745744 0.00744084 0.00738394]]
output array length: 100

Colab that used later version of tfnightly(tf-nightly==2.4.0-dev20201019) for tflite conversion:
https://colab.research.google.com/drive/1LVkk8aclpoxwmfdYeanpu6YKSEMoWxRJ?usp=sharing


INPUT DETAILS: 
 [{'name': 'serving_default_input_tensor:0', 'index': 0, 'shape': array([  1, 512, 512,   3], dtype=int32), 'shape_signature': array([  1, 512, 512,   3], dtype=int32), 'dtype': <class 'numpy.uint8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]
OUTPUT DETAILS: 
 [{'name': 'StatefulPartitionedCall:5', 'index': 66546, 'shape': array([1], dtype=int32), 'shape_signature': array([1], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'StatefulPartitionedCall:1', 'index': 66642, 'shape': array([1, 1, 1], dtype=int32), 'shape_signature': array([ 1, -1, -1], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'StatefulPartitionedCall:2', 'index': 66620, 'shape': array([1, 1], dtype=int32), 'shape_signature': array([ 1, -1], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'StatefulPartitionedCall:7', 'index': 66405, 'shape': array([    1, 49104,     3], dtype=int32), 'shape_signature': array([    1, 49104,     3], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'StatefulPartitionedCall:4', 'index': 66563, 'shape': array([1, 1], dtype=int32), 'shape_signature': array([ 1, -1], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'StatefulPartitionedCall:6', 'index': 66384, 'shape': array([    1, 49104,     4], dtype=int32), 'shape_signature': array([    1, 49104,     4], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'StatefulPartitionedCall:3', 'index': 66603, 'shape': array([1, 1, 1], dtype=int32), 'shape_signature': array([ 1, -1, -1], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'StatefulPartitionedCall:0', 'index': 66581, 'shape': array([1, 1], dtype=int32), 'shape_signature': array([ 1, -1], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]

[  1 512 512   3]
[100.]"
44784,gradient_transformers throw autograph errors when trying to maintain state in tensorarray,"I'm trying to implement automatic gradient clipping, where the norm of the gradient is stored on each train step, and the gradient is clipped based off the accumulated distribution of gradient norms. However, I seem to be running into some autograph issue.

Here's the code to reproduce the issue

```python
import tensorflow as tf
import tensorflow_probability as tfp

class AutoClipper:
    def __init__(self, clip_percentile):
        self.clip_percentile = clip_percentile
        self.grad_history = None
        self.i = None

    def __call__(self, grads_and_vars):
        if self.grad_history is None:
            self.grad_history = tf.TensorArray(dtype=tf.float32, size=0, dynamic_size=True)
            self.i = 0

        grad_norms = [_get_grad_norm(g) for g, _ in grads_and_vars]
        total_norm = tf.norm(grad_norms)
        self.grad_history = self.grad_history.write(self.i, total_norm)
        self.i += 1
        clip_value = tfp.stats.percentile(self.grad_history.stack(), q=self.clip_percentile)
        return [(tf.clip_by_norm(g, clip_value), v) for g, v in grads_and_vars]

def _get_grad_norm(t, axes=None, name=None):
    values = tf.convert_to_tensor(t.values if isinstance(t, tf.IndexedSlices) else t, name=""t"")

    # Calculate L2-norm, clip elements by ratio of clip_norm to L2-norm
    l2sum = tf.math.reduce_sum(values * values, axes, keepdims=True)
    pred = l2sum > 0
    # Two-tap tf.where trick to bypass NaN gradients
    l2sum_safe = tf.where(pred, l2sum, tf.ones_like(l2sum))
    return tf.squeeze(tf.where(pred, tf.math.sqrt(l2sum_safe), l2sum))


model = tf.keras.models.Sequential(
        [
            tf.keras.layers.Flatten(input_shape=(28, 28)),
            tf.keras.layers.Dense(128, activation=""relu""),
            tf.keras.layers.Dropout(0.2),
            tf.keras.layers.Dense(10),
        ]
    )

    model.compile(
        optimizer=tf.keras.optimizers.Adam(
            learning_rate=0.001,
            gradient_transformers=[AutoClipper(10)],
        ),
        loss=""mean_absolute_error"",
        metrics=[""accuracy""],
    )

    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()
    x_train, x_test = x_train / 255.0, x_test / 255.0

    model.fit(x_train, y_train)
```

It seems to fail when trying to update the tensorarray, but I thought tensorarrays could be created outside `tf.function`:
```python
op_name = '__inference_train_function_13337', num_outputs = 4
inputs = [<tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=variant, numpy=<unprintable>>...ensor: shape=(), dtype=resource, numpy=<unprintable>>, <tf.Tensor: shape=(), dtype=resource, numpy=<unprintable>>, ...]
attrs = ('executor_type', '', 'config_proto', b'\n\x07\n\x03CPU\x10\x01\n\x07\n\x03GPU\x10\x002\x02J\x008\x01\x82\x01\x00')
ctx = <tensorflow.python.eager.context.Context object at 0x7fa34a9b2f50>
name = None

    def quick_execute(op_name, num_outputs, inputs, attrs, ctx, name=None):
      """"""Execute a TensorFlow operation.
    
      Args:
        op_name: Name of the TensorFlow operation (see REGISTER_OP in C++ code) to
          execute.
        num_outputs: The number of outputs of the operation to fetch.
                     (Explicitly provided instead of being inferred for performance
                     reasons).
        inputs: A list of inputs to the operation. Each entry should be a Tensor, or
          a value which can be passed to the Tensor constructor to create one.
        attrs: A tuple with alternating string attr names and attr values for this
          operation.
        ctx: The value of context.context().
        name: Customized name for the operation.
    
      Returns:
        List of output Tensor objects. The list is empty if there are no outputs
    
      Raises:
        An exception on error.
      """"""
      device_name = ctx.device_name
      # pylint: disable=protected-access
      try:
        ctx.ensure_initialized()
        tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
>                                           inputs, attrs, num_outputs)
E                                           TypeError: An op outside of the function building code is being passed
E                                           a ""Graph"" tensor. It is possible to have Graph tensors
E                                           leak out of the function building context by including a
E                                           tf.init_scope in your function building code.
E                                           For example, the following function will fail:
E                                             @tf.function
E                                             def has_init_scope():
E                                               my_constant = tf.constant(1.)
E                                               with tf.init_scope():
E                                                 added = my_constant * 2
E                                           The graph tensor has name: Adam/TensorArrayV2Write/TensorListSetItem:0

./lib/python3.7/site-packages/tensorflow/python/eager/execute.py:60: TypeError
```

**System information**
- tensorflow 2.4.0-rc1
- python 3.5
- ubuntu 20.04"
44783,boringssl: cc1plus: error: command line option '-Wmissing-prototypes' is valid for C/ObjC but not for C++ [-Werror],"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): CentOS 8
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): source
- TensorFlow version: r2.4
- Python version: 3.6
- Installed using virtualenv? pip? conda?: venv
- Bazel version (if compiling from source): 3.5.0
- GCC/Compiler version (if compiling from source): 9.1
- CUDA/cuDNN version: 7
- GPU model and memory: N/A (build issue)



**Describe the problem**

Compiling the r2.4 branch from source on CentOS 8 using gcc-toolset-9, the build fails like so:

```
/opt/rh/gcc-toolset-9/root/usr/bin/g++ -U_FORTIFY_SOURCE -fstack-protector -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections -fdata-sections -MD -MF bazel-out/k8-opt/bin/external/boringssl/_objs/crypto/socket.pic.d '-frandom-seed=bazel-out/k8-opt/bin/external/boringssl/_objs/crypto/socket.pic.o' -fPIC -iquote external/boringssl -iquote bazel-out/k8-opt/bin/external/boringssl -isystem external/boringssl/src/include -isystem bazel-out/k8-opt/bin/external/boringssl/src/include -w -DAUTOLOAD_DYNAMIC_KERNELS '-march=broadwell' -Wno-sign-compare -fpermissive -Wa,--noexecstack '-D_XOPEN_SOURCE=700' -Wall -Werror '-Wformat=2' -Wsign-compare -Wmissing-field-initializers -Wwrite-strings -Wshadow -fno-common '-std=c11' -Wmissing-prototypes -Wold-style-definition -Wstrict-prototypes -fno-canonical-system-headers -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' -c external/boringssl/src/crypto/bio/socket.c -o bazel-out/k8-opt/bin/external/boringssl/_objs/crypto/socket.pic.o)
Execution platform: @local_execution_config_platform//:platform
cc1plus: error: command line option '-Wmissing-prototypes' is valid for C/ObjC but not for C++ [-Werror]
cc1plus: error: command line option '-Wold-style-definition' is valid for C/ObjC but not for C++ [-Werror]
cc1plus: error: command line option '-Wstrict-prototypes' is valid for C/ObjC but not for C++ [-Werror]
cc1plus: all warnings being treated as errors
```


**Provide the exact sequence of commands / steps that you executed before running into the problem**

scl enable gcc-toolset-9 -- bash
bazel build --action_env=CC=$(which g++) //tensorflow/tools/pip_package:build_pip_package

**Any other info / logs**

The third-party boringssl compilation passes options that are not valid for C++, and GCC 9 calls them out with a warning. Since the compilation also passes -Werror, it fails."
44779,Defect in code example,"Thank you for submitting a TensorFlow documentation issue. Per our GitHub
policy, we only address code/doc bugs, performance issues, feature requests, and
build/installation issues on GitHub.

The TensorFlow docs are open source! To get involved, read the documentation
contributor guide: https://www.tensorflow.org/community/contribute/docs

## URL(s) with the issue:

https://www.tensorflow.org/guide/data

## Description of issue (what needs changing):

The code example has problems:

```
To allow some overlap between the features of one batch and the labels of another, use Dataset.zip:

feature_length = 10
label_length = 5

features = range_ds.batch(feature_length, drop_remainder=True)
labels = range_ds.batch(feature_length).skip(1).map(lambda labels: labels[:-5])

predict_5_steps = tf.data.Dataset.zip((features, labels))

for features, label in predict_5_steps.take(3):
  print(features.numpy(), "" => "", label.numpy())
```

1. The ``label_length`` variable is never used.
2. The slicing ``labels[:-5]`` is wrong. The only reason it works is because 10-5 is 5.

### Clear description

Let's illustrate the problem by slightly modifying the defective code.

```python
feature_length = 10
label_length = 3

features = range_ds.batch(feature_length, drop_remainder=True)
labels = range_ds.batch(feature_length).skip(1).map(lambda labels: labels[:-label_length])

predict_5_steps = tf.data.Dataset.zip((features, labels))

for features, label in predict_5_steps.take(3):
  print(features.numpy(), "" => "", label.numpy())
```

This prints:

```
[0 1 2 3 4 5 6 7 8 9]  =>  [10 11 12 13 14 15 16]
[10 11 12 13 14 15 16 17 18 19]  =>  [20 21 22 23 24 25 26]
[20 21 22 23 24 25 26 27 28 29]  =>  [30 31 32 33 34 35 36]
```

This is wrong because the label sequence length is not 3.

The correct code is below. This will work as long as ``label_length <= feature_length``.

```python
feature_length = 10
label_length = 3

features = range_ds.batch(feature_length, drop_remainder=True)
labels = range_ds.batch(feature_length).skip(1).map(lambda labels: labels[:label_length])

predict_5_steps = tf.data.Dataset.zip((features, labels))

for features, label in predict_5_steps.take(3):
  print(features.numpy(), "" => "", label.numpy())
```

This will correctly print:

```
[0 1 2 3 4 5 6 7 8 9]  =>  [10 11 12]
[10 11 12 13 14 15 16 17 18 19]  =>  [20 21 22]
[20 21 22 23 24 25 26 27 28 29]  =>  [30 31 32]
```

A better and more generic code should avoid using names like ``predict_5_steps``:

```python
feature_length = 10
label_length = 3

features = range_ds.batch(feature_length, drop_remainder=True)
labels = range_ds.batch(feature_length).skip(1).map(lambda labels: labels[:label_length])

input_ds = tf.data.Dataset.zip((features, labels))

for features, label in input_ds.take(3):
  print(features.numpy(), "" => "", label.numpy())
```



### Submit a pull request?

"
44777,"Could not load dynamic library 'libcusolver.so.10' - TF-2.4.0RC, Cuda,CudNN, RTX 3080","<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): pip
- TensorFlow version: 2.4.0-rc1
- Python version: 3.8
- Installed using virtualenv? pip? conda?:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 11.1 & 8.0.5
- GPU model and memory: RTX 3080

**Describe the problem**
Downloading everything per instructions, all GPU libs are being read except the one in the title. No idea why. 

`2020-11-11 14:48:06.269458: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2020-11-11 14:48:06.269897: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2020-11-11 14:48:06.303715: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-11-11 14:48:06.304046: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1724] Found device 0 with properties: 
pciBusID: 0000:08:00.0 name: GeForce RTX 3080 computeCapability: 8.6
coreClock: 1.71GHz coreCount: 68 deviceMemorySize: 9.78GiB deviceMemoryBandwidth: 707.88GiB/s
2020-11-11 14:48:06.304061: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
2020-11-11 14:48:06.305025: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2020-11-11 14:48:06.305052: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
2020-11-11 14:48:06.305398: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2020-11-11 14:48:06.305501: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2020-11-11 14:48:06.305583: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcusolver.so.10'; dlerror: libcusolver.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:/usr/lib/cuda/include:/usr/lib/cuda/lib64:
2020-11-11 14:48:06.305805: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11
2020-11-11 14:48:06.305877: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2020-11-11 14:48:06.305883: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1761] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2020-11-11 14:48:06.306061: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2020-11-11 14:48:06.306326: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set
2020-11-11 14:48:06.306336: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1265] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-11-11 14:48:06.306340: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1271]      `
"
