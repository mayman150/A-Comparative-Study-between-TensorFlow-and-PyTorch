Issue Number,Issue Title,Issue Body
56110,Bert ModelSpec Export to TFLITE does not work,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

2.8.0

### Custom Code

Yes

### OS Platform and Distribution

Ubuntu 20.04.3 LTS

### Mobile device

_No response_

### Python version

3.8.10

### Bazel version

_No response_

### GCC/Compiler version

GCC 9.3.0

### CUDA/cuDNN version

V11.6.55

### GPU model and memory

RTX5000, 16 GB

### Current Behaviour?

```shell
The trained Bert Model with the Tensorflow Lite Model Maker works fine, but I cannot export the Model to TFLITE-file. The code window keeps running, but nothing happens (even after 6h waiting). The issue does not appear with the models 'average_word_spec' and 'mobileBert'.
```


### Standalone code to reproduce the issue

```shell
batch_sizes=[512,256,128,64,32,16]
sequence_lengths= [16,32,64,128,256,512]
training_ratio= 0.66

spec = text_classifier.BertClassifierSpec(
                     uri='https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1',seq_len=sequence_lengths[index],dropout_rate=0.5,default_batch_size=batch_sizes[index],name='Bert')

                data = DataLoader.from_csv(
                      filename='fake_new_dateset_new.csv',
                      text_column='Content',
                      label_column='label',
                      model_spec=spec,
                      is_training=True,
                      shuffle= False)

                train_data,test_data=data.split(training_ratio)
                train_data,validation_data= train_data.split(training_ratio)

                model = text_classifier.create(train_data, model_spec=spec, validation_data=validation_data, epochs=epoch)

                loss_test,acc_test= model.evaluate(test_data)
                loss_val,acc_val= model.evaluate(validation_data)

                model.export(export_dir='Bert_dataset1/', export_format=ExportFormat.TFLITE)
                accuracy_file = model.evaluate_tflite('Bert_dataset1/model.tflite', test_data)

                file_size = os.path.getsize('Bert_dataset1/model.tflite')
```


### Relevant log output

```shell
WARNING:absl:Found untraced functions such as restored_function_body, restored_function_body, restored_function_body, restored_function_body, restored_function_body while saving (showing 5 of 815). These functions will not be directly callable after loading.
```
</details>"
56109,no such attribute 'shared_lib_name' in 'cc_shared_library' rule,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

tf master 

### Custom Code

No

### OS Platform and Distribution

5.15.32-1-MANJARO

### Mobile device

5.15.32-1-MANJARO

### Python version

3.10

### Bazel version

bazel 5.0.0

### GCC/Compiler version

gcc-10.2

### CUDA/cuDNN version

11.6

### GPU model and memory

RTX3090 24G

### Current Behaviour?

```shell
ERROR: /home/liushuai/tensorflow/tensorflow/BUILD:993:21: //tensorflow:libtensorflow_framework.so.2.10.0: no such attribute 'shared_lib_name' in 'cc_shared_library' rule
ERROR: /home/liushuai/tensorflow/tensorflow/BUILD:993:21: //tensorflow:libtensorflow_framework.so.2.10.0: no such attribute 'win_def_file' in 'cc_shared_library' rule
ERROR: /home/liushuai/tensorflow/tensorflow/BUILD:993:21: //tensorflow:libtensorflow_framework.2.10.0.dylib: no such attribute 'shared_lib_name' in 'cc_shared_library' rule
ERROR: /home/liushuai/tensorflow/tensorflow/BUILD:993:21: //tensorflow:libtensorflow_framework.2.10.0.dylib: no such attribute 'win_def_file' in 'cc_shared_library' rule
ERROR: /home/liushuai/tensorflow/tensorflow/BUILD:993:21: //tensorflow:tensorflow_framework.dll: no such attribute 'shared_lib_name' in 'cc_shared_library' rule
ERROR: /home/liushuai/tensorflow/tensorflow/BUILD:993:21: //tensorflow:tensorflow_framework.dll: no such attribute 'win_def_file' in 'cc_shared_library' rule
ERROR: /home/liushuai/tensorflow/tensorflow/BUILD:1115:21: //tensorflow:libtensorflow_cc.so.2.10.0: no such attribute 'shared_lib_name' in 'cc_shared_library' rule
ERROR: /home/liushuai/tensorflow/tensorflow/BUILD:1115:21: //tensorflow:libtensorflow_cc.so.2.10.0: no such attribute 'win_def_file' in 'cc_shared_library' rule
ERROR: /home/liushuai/tensorflow/tensorflow/BUILD:1115:21: //tensorflow:libtensorflow_cc.2.10.0.dylib: no such attribute 'shared_lib_name' in 'cc_shared_library' rule
ERROR: /home/liushuai/tensorflow/tensorflow/BUILD:1115:21: //tensorflow:libtensorflow_cc.2.10.0.dylib: no such attribute 'win_def_file' in 'cc_shared_library' rule
ERROR: /home/liushuai/tensorflow/tensorflow/BUILD:1115:21: //tensorflow:tensorflow_cc.dll: no such attribute 'shared_lib_name' in 'cc_shared_library' rule
ERROR: /home/liushuai/tensorflow/tensorflow/BUILD:1115:21: //tensorflow:tensorflow_cc.dll: no such attribute 'win_def_file' in 'cc_shared_library' rule
ERROR: /home/liushuai/tensorflow/tensorflow/tools/pip_package/BUILD:275:10: errors encountered resolving select() keys for //tensorflow/tools/pip_package:build_pip_package
```


### Standalone code to reproduce the issue

```shell
bazel build --config=cuda  //tensorflow/tools/pip_package:build_pip_package
```


### Relevant log output

_No response_</details>"
56108,PortAudio library not found ,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

Latest 

### Custom Code

No

### OS Platform and Distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
Now cant import anything it's showing ""PortAudio library not found"" error while importing
```


### Standalone code to reproduce the issue

```shell
Resolve asap
```


### Relevant log output

_No response_</details>"
56107,tensorflow local_init_op use all GPUs,"### System information

-   **Have I written custom code (as opposed to using a stock example script
    provided in TensorFlow)**: No
-   **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 20.04 LTS
-   **TensorFlow installed from (source or binary)**: miniconda with conda-forge channel
-   **TensorFlow version (use command below)**: 2.7.0
-   **Python version**: 3.8.13 | packaged by conda-forge | (default, Mar 25 2022, 06:04:10) 
[GCC 10.3.0]
-   **CUDA/cuDNN version**: 11.5
-   **GPU model and memory**: 

```
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 495.29.05    Driver Version: 495.29.05    CUDA Version: 11.5     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  NVIDIA RTX A5000    On   | 00000000:3D:00.0 Off |                  Off |
| 30%   35C    P8    17W / 230W |   3910MiB / 24256MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   1  NVIDIA RTX A5000    On   | 00000000:61:00.0 Off |                  Off |
| 30%   58C    P2   153W / 230W |  18558MiB / 24256MiB |    100%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   2  NVIDIA GeForce ...  On   | 00000000:B2:00.0 Off |                  N/A |
| 30%   34C    P8    23W / 350W |   8207MiB / 24268MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   3  NVIDIA GeForce ...  On   | 00000000:DA:00.0 Off |                  N/A |
| 31%   27C    P8    25W / 350W |  23108MiB / 24268MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
```

-   **Exact command to reproduce**:

```py
from __future__ import absolute_import, print_function, unicode_literals

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from IPython.display import clear_output
from six.moves import urllib

import tensorflow.feature_column as fc
import tensorflow as tf

_GPU = tf.config.list_physical_devices('GPU')[1]
tf.config.experimental.set_memory_growth(_GPU, True)
tf.config.set_visible_devices([_GPU], device_type='GPU')

os.environ[""CUDA_DEVICE_ORDER""]=""PCI_BUS_ID""
os.environ[""CUDA_VISIBLE_DEVICES""]=""1""
    
print(tf.config.list_logical_devices('GPU'))
print(tf.config.get_visible_devices('GPU'))

dftrain = pd.read_csv('https://storage.googleapis.com/tf-datasets/titanic/train.csv')
dfeval = pd.read_csv('https://storage.googleapis.com/tf-datasets/titanic/eval.csv')
y_train = dftrain.pop('survived')
y_eval = dfeval.pop('survived')

print(dict(dftrain)['age'])

CATEGORICAL_COLUMNS = ['sex','n_siblings_spouses', 'parch','class','deck','embark_town','alone']
NUMERIC_COLUMNS = ['age','fare']
feature_columns = []

for feature_name in CATEGORICAL_COLUMNS:
    vocabulary = dftrain[feature_name].unique()
    feature_columns.append(fc.categorical_column_with_vocabulary_list(feature_name,vocabulary))

for feature_name in NUMERIC_COLUMNS:
    feature_columns.append(fc.numeric_column(feature_name, dtype=tf.float32))

def make_input_fn(data_df, label_df, num_epochs=10, shuffle=True, batch_size=32):
    def input_function():
        ds = tf.data.Dataset.from_tensor_slices((dict(data_df), label_df))
        if shuffle:
            ds = ds.shuffle(1000)
        ds = ds.batch(batch_size).repeat(num_epochs)
        return ds
    return input_function

train_input_fn = make_input_fn(dftrain, y_train)
eval_input_fn = make_input_fn(dfeval, y_eval, num_epochs=1, shuffle=False)

with tf.device('/gpu:0'):

    linear_est = tf.estimator.LinearClassifier(feature_columns=feature_columns)
    linear_est.train(train_input_fn)
    result = linear_est.evaluate(eval_input_fn)

    print(result['accuracy'])
```

### Describe the problem

I have restrict it to use only one GPU, but the console logs showing that all 4 GPUs are allocated with some memory. 

### Source code / logs

```
INFO:tensorflow:Using default config.
WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmph9kh9yb0
INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmph9kh9yb0', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true
graph_options {
  rewrite_options {
    meta_optimizer_iterations: ONE
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
WARNING:tensorflow:From /home/user1/miniconda3/envs/py38-paper/lib/python3.8/site-packages/tensorflow/python/training/training_util.py:400: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
INFO:tensorflow:Calling model_fn.
/home/user1/miniconda3/envs/py38-paper/lib/python3.8/site-packages/tensorflow_estimator/python/estimator/canned/linear.py:1468: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.
  self.bias = self.add_variable(
WARNING:tensorflow:From /home/user1/miniconda3/envs/py38-paper/lib/python3.8/site-packages/keras/optimizer_v2/ftrl.py:148: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Create CheckpointSaverHook.
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
2022-05-14 19:37:01.177652: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14874 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:b2:00.0, compute capability: 8.6
2022-05-14 19:37:01.178063: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 934 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:da:00.0, compute capability: 8.6
2022-05-14 19:37:01.178874: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 18809 MB memory:  -> device: 2, name: NVIDIA RTX A5000, pci bus id: 0000:3d:00.0, compute capability: 8.6
2022-05-14 19:37:01.179490: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 4161 MB memory:  -> device: 3, name: NVIDIA RTX A5000, pci bus id: 0000:61:00.0, compute capability: 8.6
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...
INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmph9kh9yb0/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...
INFO:tensorflow:loss = 0.6931472, step = 0
INFO:tensorflow:global_step/sec: 71.4523
INFO:tensorflow:loss = 0.55276275, step = 100 (1.402 sec)
INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 200...
INFO:tensorflow:Saving checkpoints for 200 into /tmp/tmph9kh9yb0/model.ckpt.
INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 200...
INFO:tensorflow:Loss for final step: 0.63703924.
INFO:tensorflow:Calling model_fn.
INFO:tensorflow:Done calling model_fn.
INFO:tensorflow:Starting evaluation at 2022-05-14T19:37:06
INFO:tensorflow:Graph was finalized.
INFO:tensorflow:Restoring parameters from /tmp/tmph9kh9yb0/model.ckpt-200
INFO:tensorflow:Running local_init_op.
INFO:tensorflow:Done running local_init_op.
2022-05-14 19:37:06.388820: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14874 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:b2:00.0, compute capability: 8.6
2022-05-14 19:37:06.389190: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 934 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:da:00.0, compute capability: 8.6
2022-05-14 19:37:06.389511: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 18809 MB memory:  -> device: 2, name: NVIDIA RTX A5000, pci bus id: 0000:3d:00.0, compute capability: 8.6
2022-05-14 19:37:06.389832: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 4161 MB memory:  -> device: 3, name: NVIDIA RTX A5000, pci bus id: 0000:61:00.0, compute capability: 8.6
INFO:tensorflow:Inference Time : 0.56921s
INFO:tensorflow:Finished evaluation at 2022-05-14-19:37:06
INFO:tensorflow:Saving dict for global step 200: accuracy = 0.71590906, accuracy_baseline = 0.625, auc = 0.8113867, auc_precision_recall = 0.7737763, average_loss = 0.59804714, global_step = 200, label/mean = 0.375, loss = 0.5963856, precision = 0.5882353, prediction/mean = 0.55224097, recall = 0.8080808
INFO:tensorflow:Saving 'checkpoint_path' summary for global step 200: /tmp/tmph9kh9yb0/model.ckpt-200
0.71590906
```
"
56105,How does TensorflowLite manage memory for GPU?,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Support

### Source

binary

### Tensorflow Version

tf 2.4?

### Custom Code

Yes

### OS Platform and Distribution

Linux Ubuntu 20.04.3 LTS

### Mobile device

Unibap ix5

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

9.3.0

### CUDA/cuDNN version

_No response_

### GPU model and memory

AMD GX-412HC SOC with Radeon(TM) R3E Graphics

### Current Behaviour?
Hello! 
I am wondering how TFLite is handling memory during inference. There are three main questions.

In the code below I have included two methods for putting the tiled image into the input tensor:
- using memcpy
- putting the values one by one

Question 1:
The memcpy-method is however getting an error when I try to use a model with batch size 3, but batch size 1 and 2 works. All batch sizes work for the second method. Why is this and how do I make the memcpy work? 

Question 2:
When does TFLite copy over the image values to the GPU? Is it during the invoke-command or is it when I copy the values to the input tensor (method 1 or 2)? 

Question 3:
What happens during the overall program? When I use top, I see the following behavior on a 10000x10000 image with 1x480x480x3 as model input size:
- During preprocess
  Virual memory: 1.843236 GB
  Resident size: 0.123656 GB
  Shared memory: 71736 KB
  CPU power: 100% 
- During loop for inference
  Virual memory: 2.146136 GB
  Resident size: 0.419956 GB
  Shared memory: 72488 KB
  CPU power: 19.1%

Best regards
Sara Larsson


### Standalone code to reproduce the issue

```shell
#include ""tensorflow/lite/interpreter.h""
#include ""tensorflow/lite/kernels/register.h""
#include ""tensorflow/lite/model.h""
#include ""tensorflow/lite/tools/gen_op_registration.h""
#include ""tensorflow/lite/delegates/gpu/delegate.h""

#include <iostream>
#include <opencv2/opencv.hpp>

int main(int argc, char **argv) {
    if (argc != 4) {
        throw std::invalid_argument(""Required arguments: \n            ""
                                    ""-path to TFLite model file \n            ""
                                    ""-path to image input\n            ""
                                    ""-method (1 or 2)"");
    }
    const char *modelFileName = argv[1];
    const char *imageFileName = argv[2];
    const int method = std::stoi(argv[3]);

    std::unique_ptr< tflite::FlatBufferModel > model;
    tflite::ops::builtin::BuiltinOpResolver resolver;
    std::unique_ptr<tflite::Interpreter> interpreter;

    model = tflite::FlatBufferModel::BuildFromFile(modelFileName);
    if (model == nullptr) {
        throw std::runtime_error(""The model was not able to build to tflite::FlatBufferModel"");
    }
    
    tflite::InterpreterBuilder(*model, resolver)(&interpreter);
    if (interpreter == nullptr){
        throw std::runtime_error(""Failed to initiate the interpreter"");
    }

    // Enable use of the GPU delegate, remove below lines to get cpu
    // After TFlite >=2.6, initiate the gpu options
    TfLiteGpuDelegateOptionsV2 gpu_options = TfLiteGpuDelegateOptionsV2Default();

    TfLiteDelegate* delegate = TfLiteGpuDelegateV2Create(&gpu_options);
    if (interpreter->ModifyGraphWithDelegate(delegate) != kTfLiteOk) {
        throw std::runtime_error(""Failed to create GPU deligate"");
        exit(-1);
    }

    // Allocating tensors
    if (interpreter->AllocateTensors() != kTfLiteOk){
        throw std::runtime_error(""Failed to allocate tensor"");
    }
    

    // Read image
    cv::Mat image = cv::imread(imageFileName);
    if (image.empty())
    {
        throw std::runtime_error(""Failed to load image"");
        exit(-1);
    }
    
    int input = interpreter->inputs()[0];
    int* inDims = interpreter->tensor(input)->dims->data;
    std::vector<cv::Rect> tiles;
    int currentTile;

    // Calculate how to tile image
    for (int x=0; x < image.size().width; x += inDims[2]) {
        for (int y=0; y < image.size().height; y += inDims[1]) {
        // Handle edges
        if (x + inDims[2] >= image.size().width && y + inDims[1] >= image.size().height) {
            tiles.push_back(cv::Rect(image.size().width - inDims[2], image.size().height - inDims[1], inDims[2], inDims[1]));
        } else {
            if (x + inDims[2] >= image.size().width) {
            tiles.push_back(cv::Rect(image.size().width - inDims[2], y, inDims[2], inDims[1]));
            } else if (y + inDims[1] >= image.size().height) {
            tiles.push_back(cv::Rect(x, image.size().height - inDims[1], inDims[2], inDims[1]));
            } else {
            tiles.push_back(cv::Rect(x, y, inDims[2], inDims[1]));
            }
        }
        }
    }

    //Invoke
    while (currentTile != -1) {
        if (method == 1) {
            int tileByteSize = inDims[1] * inDims[2] * inDims[3] * 4;

            for (int i=0; i < inDims[0]; i++) {
                cv::Mat tile = image(tiles[currentTile]);
                tile.convertTo(tile, CV_32F, 1.0 / 255, 0);
                memcpy(interpreter->typed_tensor<float>(0)+tileByteSize*i, tile.data, tileByteSize); 
            }
        } else if (method == 2) {
            for (int i=0; i < inDims[0]; i++) {
                cv::Mat tile = image(tiles[currentTile]);
                float* input_tensor_float = interpreter->typed_tensor<float>(0);
            
                for (int idx = 0; idx < tile.size[1] * tile.size[0]; idx++){
                    int col = idx % tile.size[0];
                    int row = idx / tile.size[0];
                    cv::Vec3b intensity = image.at<cv::Vec3b>(row, col);
                    
                    input_tensor_float[(inDims[1] * inDims[2] * inDims[3]*i+idx*3+0)] = float(intensity.val[0])/ 255; //R <- B
                    input_tensor_float[(inDims[1] * inDims[2] * inDims[3]*i+idx*3+1)] = float(intensity.val[1])/ 255; //G <- G
                    input_tensor_float[(inDims[1] * inDims[2] * inDims[3]*i+idx*3+2)] = float(intensity.val[2])/ 255; //B <- R
                }
            }
        }

        currentTile = inDims[0] + currentTile;
        if (currentTile != -1 && currentTile >= tiles.size()) {
            currentTile = -1;
        }
        m_interpreter->Invoke();
    }
}
```
"
56104,Type Error in Conversion From Saved Model to TFLite model,"When I tried to convert a custom saved model (faster rcnn with custom data) to TFLite model I am receiving the following error. What is the possible reason and solution?

ConverterError: <unknown>:0: error: loc(callsite(callsite(fused[""Mul:"", ""MultiLevelMatMulCropAndResize/MultiLevelRoIAlign/mul_17@__inference_call_func_16203""] at fused[""StatefulPartitionedCall:"", ""StatefulPartitionedCall@__inference_signature_wrapper_19429""]) at fused[""StatefulPartitionedCall:"", ""StatefulPartitionedCall""])): 'tfl.reshape' op operand #1 must be tensor of 32-bit signless integer values, but got 'tensor<6xi64>'
<unknown>:0: note: loc(fused[""StatefulPartitionedCall:"", ""StatefulPartitionedCall""]): called from

Model original is trained with TF2 object detection API 

### Source code / logs
import tensorflow as tf

saved_model_path = ""/home/exx/TensorFlow/train/models/faster-rcnn-clr/exported-models/saved_model""

converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_path) # path to the SavedModel directory
tflite_model = converter.convert()

with open('model_R1.tflite', 'wb') as f:
  f.write(tflite_model)
"
56100,Tensorboard does not match keras loss output for custom model,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

2.6.0

### Custom Code

Yes

### OS Platform and Distribution

Linux Ubuntu 20.04

### Mobile device

_No response_

### Python version

3.8.10

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

8204

### GPU model and memory

_No response_

### Current Behaviour?

```shell
Loss values in callbacks and tensorboard do not match output from loss_dict output in shell.
```


### Standalone code to reproduce the issue

```shell
class LearningRateLogger(tf.keras.callbacks.Callback):
    def on_epoch_end(self, epoch, logs=None):
        logs[""learning_rate""] = self.model.optimizer.lr
    def on_batch_end(self, batch, logs=None):
        print('\n loss from on_batch_end callback: {}'.format(logs['loss']))


from subclassed Model:

    def train_step(self, data):
        with tf.GradientTape() as tape:
            y_pred = self(data.images, training=True)
            loss = self.loss_fn(y_pred, data.gt)
        gradients = tape.gradient(loss, self.trainable_variables)
        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))

        loss_dict = {
            'center_classification_loss': loss,
            'loss': loss
        }
        return loss_dict
```


### Relevant log output

```shell
36/955 [>.............................] - ETA: 11:03 - center_classification_loss: 764.4570 - loss: 764.4570
 loss from on_batch_end callback: 27.19649314880371
 37/955 [>.............................] - ETA: 10:59 - center_classification_loss: 745.5407 - loss: 745.5407
 loss from on_batch_end callback: 64.55301666259766
 38/955 [>.............................] - ETA: 10:56 - center_classification_loss: 727.1075 - loss: 727.1075
 loss from on_batch_end callback: 45.08071517944336
 39/955 [>.............................] - ETA: 10:55 - center_classification_loss: 710.0048 - loss: 710.0048
 loss from on_batch_end callback: 60.10035705566406
 40/955 [>.............................] - ETA: 10:53 - center_classification_loss: 694.1853 - loss: 694.1853
 loss from on_batch_end callback: 77.22644805908203
 41/955 [>.............................] - ETA: 10:51 - center_classification_loss: 678.0594 - loss: 678.0594
 loss from on_batch_end callback: 33.022945404052734
 42/955 [>.............................] - ETA: 10:49 - center_classification_loss: 662.8418 - loss: 662.8418
 loss from on_batch_end callback: 38.92039489746094
 43/955 [>.............................] - ETA: 10:49 - center_classification_loss: 649.2812 - loss: 649.2812
 loss from on_batch_end callback: 79.73693084716797
 44/955 [>.............................] - ETA: 10:46 - center_classification_loss: 636.5957 - loss: 636.5957
 loss from on_batch_end callback: 91.1175765991211
 45/955 [>.............................] - ETA: 10:45 - center_classification_loss: 623.2176 - loss: 623.2176
 loss from on_batch_end callback: 34.58213424682617
 46/955 [>.............................] - ETA: 10:44 - center_classification_loss: 612.0084 - loss: 612.0084
 loss from on_batch_end callback: 107.5921401977539
 47/955 [>.............................] - ETA: 10:43 - center_classification_loss: 600.4400 - loss: 600.4400
 loss from on_batch_end callback: 68.297607421875
 48/955 [>.............................] - ETA: 10:40 - center_classification_loss: 589.0859 - loss: 589.0859
 loss from on_batch_end callback: 55.439815521240234
 49/955 [>.............................] - ETA: 10:37 - center_classification_loss: 578.3141 - loss: 578.3141
 loss from on_batch_end callback: 61.2695426940918
 50/955 [>.............................] - ETA: 10:36 - center_classification_loss: 567.3053 - loss: 567.3053
 loss from on_batch_end callback: 27.87373924255371
 51/955 [>.............................] - ETA: 10:36 - center_classification_loss: 559.1129 - loss: 559.1129
 loss from on_batch_end callback: 149.49432373046875
 52/955 [>.............................] - ETA: 10:34 - center_classification_loss: 550.9732 - loss: 550.9732
 loss from on_batch_end callback: 135.84913635253906
 53/955 [>.............................] - ETA: 10:31 - center_classification_loss: 541.7439 - loss: 541.7439
 loss from on_batch_end callback: 61.8183479309082
 54/955 [>.............................] - ETA: 10:29 - center_classification_loss: 532.4198 - loss: 532.4198
```
</details>"
56099,Fonts do not load properly under Firefox,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Documentation Bug

### Source

source

### Tensorflow Version

tf 2.8

### Custom Code

No

### OS Platform and Distribution

Firefox on Windows 11

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
Docs page can not load Google Fonts (503 service unavailable) under Firefox, even with all extensions disabled. It only succeeds to load properly under an Incognito Window.
```


### Standalone code to reproduce the issue

```shell
Open any page on tensorflow.org under Firefox 100 (problem was there before FF 100, but I didn't take note of when it started). The problem will appear. Clearing cookies or using incognito solves the issue.

Further note: the issue can be solved by blocking cookies for tensorflow.org, but a server-side solution would help a lot of people.
```


### Relevant log output

_No response_</details>"
56095,File size & memory constantly increasing for keras models with StringLookup layer after reloading & resaving,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1.  It must be a bug, a feature request, or a significant problem with the
    documentation (for small docs fixes please send a PR instead).
2.  The form below must be filled out.
3.  It shouldn't be a TensorBoard issue. Those go
    [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information

-   **Have I written custom code (as opposed to using a stock example script
    provided in TensorFlow)**: No
-   **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: macOS 12.3.1
-   **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue
    happens on a mobile device**: N/A
-   **TensorFlow installed from (source or binary)**: binary from pip
-   **TensorFlow version (use command below)**: 2.8.0
-   **Python version**: 3.8.3
-   **Bazel version (if compiling from source)**: N/A
-   **GCC/Compiler version (if compiling from source)**: N/A
-   **CUDA/cuDNN version**: N/A
-   **GPU model and memory**: Intel UHD Graphics 630 1536MB
-   **Exact command to reproduce**: 1) pip install psutil 2) python test.py train 3) python test.py

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with:

```bash
python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""
```

### Describe the problem
When a keras Model has a StringLookup layer, and saved as SaveModel format, the file size and the memory usage keeps increasing after reloading & resaving.

I have created an MVP in the following code. To assess the memory usage, I used psutil package so please install it if you do not have it.

Running `python test.py train` will create a very simple model with only a StringLookup layer and a Dense layer, and save it.

And then you can run `python test.py` many times to see the file size and the memory usage every time. On my laptop, file size increased by roughly 4K/run and memory usage increased by 3MB/run. No matter how many times you run it, they never converge.

Interestingly, if the model is saved as H5 format this issue is gone.


### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.

The script has been attached:
[test.py.zip](https://github.com/tensorflow/tensorflow/files/8685088/test.py.zip)

The `build_model()` function creates a model with a StringLookup layer and a Dense layer.

The `train_model()` function trains the model with a randomly generated array of size (16, 800000) as input.

The `save_model()` function saves the model in SaveModel format, and prints the file & memory usage.

The `load_model()` function loads it.

Running `python test.py train` will train the model and save it.

Running `python test.py` will reload and resave the model. Run it enough times to see the increasing trend.

Pasting the code of test.py for easier reading as well:

```python
import numpy as np
import os
import psutil
import sys
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.layers import Input, StringLookup, Dense
from tensorflow.keras import Model


vocabulary = list('ABCDEFGHIJKLMN')
seq_length = 800000
batch_size = 16


def build_model():
    # Build a simple model with only the StringLookup and activation
    input_layer = Input(shape=(seq_length,), dtype='string', name='input')

    output_layer = StringLookup(
        vocabulary=vocabulary,
        mask_token='',
        output_mode='multi_hot',
        name='string_lookup'
    )(input_layer)
    
    output_layer = Dense(1, activation='sigmoid')(output_layer)
    return Model(inputs=input_layer, outputs=output_layer)


def train_model(model):
    # Train the model with batch_size x seq_length batches
    x_arr = np.array([np.random.choice(vocabulary, size=(seq_length,)) for _ in range(batch_size)])
    y_arr = np.random.choice([0, 1], size=(batch_size,))

    model = build_model()
    model.compile(optimizer='adam', loss='binary_crossentropy', metrics='AUC')
    model.fit(x_arr, y_arr, batch_size=1, epochs=1)

    return model


def save_model(model):
    # Save the model and print the saved model file size & memory usage
    tf.keras.models.save_model(model, 'models/test/')
    print(os.path.getsize('models/test/saved_model.pb'), psutil.Process().memory_info().rss)

    
def load_model():
    return tf.keras.models.load_model('models/test/')


if __name__ == '__main__':
    if len(sys.argv) > 1 and sys.argv[1] == 'train':
        save_model(train_model(build_model()))
    else:
        save_model(load_model())
```"
56094,'tf.FakeQuantWithMinMaxVarsPerChannel' op : illegal op still exists,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

tf2.8

### Custom Code

No

### OS Platform and Distribution

ubuntu 20.04

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
Actually tried below python code to create model.then used iree tool to lower it to mlir.
used following command: iree/integrations/tensorflow/bazel-bin/iree_tf_compiler/iree-import-tf -tf-import-type=savedmodel_v1 -tf-savedmodel-exported-names=serving_default $PWD --print-ir-before=iree-tf-convert-to-mhlo &>quant_tf.mlir -o hlo.mlir
```


### Standalone code to reproduce the issue

```shell
# baseline cnn model for mnist
from numpy import mean
from numpy import std
from matplotlib import pyplot as plt
from tensorflow.keras.datasets import mnist
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D
from tensorflow.keras.layers import MaxPooling2D
from tensorflow.keras.layers import Dense
from tensorflow.keras.layers import Flatten
from tensorflow.keras.optimizers import SGD
import tensorflow as tf
# load train and test dataset

# load dataset
(trainX, trainY), (testX, testY) = mnist.load_data()
# reshape dataset to have a single channel
trainX = trainX.reshape((trainX.shape[0], 28, 28, 1))
testX = testX.reshape((testX.shape[0], 28, 28, 1))
# one hot encode target values
trainY = to_categorical(trainY)
testY = to_categorical(testY)



# convert from integers to floats
train_norm = trainX.astype('float32')
test_norm = testX.astype('float32')
# normalize to range 0-1
train_norm = train_norm / 255.0
test_norm = test_norm / 255.0

model = Sequential()
model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(28, 28, 1),batch_size=32))
model.add(MaxPooling2D((2, 2)))
model.add(Flatten())
model.add(Dense(20, activation='relu'))
model.add(Dense(10,activation='sigmoid'))
        # compile model
opt = SGD(learning_rate=0.01, momentum=0.9)
model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])
model.fit(trainX, trainY, epochs=10, batch_size=32, verbose=0)

import tensorflow_model_optimization as tfmot

quantize_model = tfmot.quantization.keras.quantize_model

# q_aware stands for for quantization aware.
q_aware_model = quantize_model(model)

# `quantize_model` requires a recompile.
q_aware_model.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

q_aware_model.summary()

q_aware_model.save(""/home/aruna/quant/quant_model"")
```


### Relevant log output

```shell
<unknown>:0: error: loc(callsite(callsite(fused[""FakeQuantWithMinMaxVarsPerChannel:"", ""sequential/quant_conv2d/LastValueQuant/FakeQuantWithMinMaxVarsPerChannel@__inference__wrapped_model_76682""] at fused[""StatefulPartitionedCall:"", ""StatefulPartitionedCall@__inference_signature_wrapper_77849""]) at fused[""StatefulPartitionedCall:"", ""StatefulPartitionedCall""])): 'tf.FakeQuantWithMinMaxVarsPerChannel' op : illegal op still exists
<unknown>:0: note: loc(fused[""StatefulPartitionedCall:"", ""StatefulPartitionedCall""]): called from
<unknown>:0: note: loc(callsite(callsite(fused[""FakeQuantWithMinMaxVarsPerChannel:"", ""sequential/quant_conv2d/LastValueQuant/FakeQuantWithMinMaxVarsPerChannel@__inference__wrapped_model_76682""] at fused[""StatefulPartitionedCall:"", ""StatefulPartitionedCall@__inference_signature_wrapper_77849""]) at fused[""StatefulPartitionedCall:"", ""StatefulPartitionedCall""])): see current operation: %12 = ""tf.FakeQuantWithMinMaxVarsPerChannel""(%11, %9, %10) {device = """", narrow_range = true, num_bits = 8 : i64} : (tensor<3x3x1x32xf32>, tensor<32xf32>, tensor<32xf32>) -> tensor<3x3x1x32xf32>
<unknown>:0: error: The following illegal operations still remain: 
	tf.FakeQuantWithMinMaxVarsPerChannel (count: 1)

Running iree-import-tf TF import pass pipeline failed (see diagnostics)
```
</details>"
56093,cuDNN path,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Build/Install

### Source

source

### Tensorflow Version

tf 2.7

### Custom Code

No

### OS Platform and Distribution

RHEL 7

### Mobile device

_No response_

### Python version

3.9.5

### Bazel version

3.7.2

### GCC/Compiler version

10.3.0

### CUDA/cuDNN version

11.2.1/8.2.1.39

### GPU model and memory

2 nvidia v100 32gb each

### Current Behaviour?

```shell
This is more of a question: on the remote server I'm working on cuDNN libraries are not installed under CUDA/11.2/include but rather they have the following paths:
for cuda: `/usr/local/easybuild/software/CUDAcore/11.2.1`
for cuDNN: `/usr/local/easybuild/software/cuDNN/8.2.1.32-CUDA-11.3.1`
When I am trying to configure by tensorflow build, I get the following message:

Could not find any cudnn.h, cudnn_version.h matching version '8.2.1' in any subdirectory:
        ''
        'include'
        'include/cuda'
        'include/*-linux-gnu'
        'extras/CUPTI/include'
        'include/cuda/CUPTI'
        'local/cuda/extras/CUPTI/include'
of:
        '/usr/local/easybuild/software/CUDAcore/11.2.1/'

```

I do not have `sudo` access to generate symlinks. I was wondering if there is a way to specify the cuDNN library path separately to the CUDA library path.
```


### Standalone code to reproduce the issue

```shell
##Have cuDNN and CUDA installed in separate directories
$ git clone https://github.com/tensorflow/tensorflow.git
$ cd tensorflow
$ git checkout v2.7.0
$ ./configure
You have bazel 3.7.2 installed.
Please specify the location of python. [Default is /usr/local/easybuild/software/Python/3.9.5-GCCcore-10.3.0/bin/python3]: 


Found possible Python library paths:
  /usr/local/easybuild/software/Python/3.9.5-GCCcore-10.3.0/easybuild/python
  /usr/local/easybuild/software/Python/3.9.5-GCCcore-10.3.0/lib/python3.9/site-packages
Please input the desired Python library path to use.  Default is [/usr/local/easybuild/software/Python/3.9.5-GCCcore-10.3.0/easybuild/python]

Do you wish to build TensorFlow with ROCm support? [y/N]: N
No ROCm support will be enabled for TensorFlow.

Do you wish to build TensorFlow with CUDA support? [y/N]: y
CUDA support will be enabled for TensorFlow.

Do you wish to build TensorFlow with TensorRT support? [y/N]: N
No TensorRT support will be enabled for TensorFlow.

Could not find any cuda.h matching version '' in any subdirectory:
        ''
        'include'
        'include/cuda'
        'include/*-linux-gnu'
        'extras/CUPTI/include'
        'include/cuda/CUPTI'
        'local/cuda/extras/CUPTI/include'
of:
        '/lib'
        '/lib64'
        '/opt/dell/srvadmin/lib64'
        '/opt/dell/srvadmin/lib64/openmanage'
        '/opt/dell/srvadmin/lib64/openmanage/smpop'
        '/usr'
        '/usr/lib64//bind9-export'
        '/usr/lib64/dyninst'

Asking for detailed CUDA configuration...

Please specify the CUDA SDK version you want to use. [Leave empty to default to CUDA 10]: 11.2


Please specify the cuDNN version you want to use. [Leave empty to default to cuDNN 7]: 8.2.1


Please specify the locally installed NCCL version you want to use. [Leave empty to use http://github.com/nvidia/nccl]: 


Please specify the comma-separated list of base paths to look for CUDA libraries and headers. [Leave empty to use the default]: /usr/local/easybuild/software/CUDAcore/11.2.1/, /usr/local/easybuild/software/cuDNN/8.2.1.32-CUDA-11.3.1/


Could not find any cudnn.h, cudnn_version.h matching version '8.2.1' in any subdirectory:
        ''
        'include'
        'include/cuda'
        'include/*-linux-gnu'
        'extras/CUPTI/include'
        'include/cuda/CUPTI'
        'local/cuda/extras/CUPTI/include'
of:
        '/usr/local/easybuild/software/CUDAcore/11.2.1/'

Asking for detailed CUDA configuration...

Please specify the CUDA SDK version you want to use. [Leave empty to default to CUDA 10]: 
```
```


### Relevant log output

```shell
You have bazel 3.7.2 installed.
Please specify the location of python. [Default is /usr/local/easybuild/software/Python/3.9.5-GCCcore-10.3.0/bin/python3]: 


Found possible Python library paths:
  /usr/local/easybuild/software/Python/3.9.5-GCCcore-10.3.0/easybuild/python
  /usr/local/easybuild/software/Python/3.9.5-GCCcore-10.3.0/lib/python3.9/site-packages
Please input the desired Python library path to use.  Default is [/usr/local/easybuild/software/Python/3.9.5-GCCcore-10.3.0/easybuild/python]

Do you wish to build TensorFlow with ROCm support? [y/N]: N
No ROCm support will be enabled for TensorFlow.

Do you wish to build TensorFlow with CUDA support? [y/N]: y
CUDA support will be enabled for TensorFlow.

Do you wish to build TensorFlow with TensorRT support? [y/N]: N
No TensorRT support will be enabled for TensorFlow.

Could not find any cuda.h matching version '' in any subdirectory:
        ''
        'include'
        'include/cuda'
        'include/*-linux-gnu'
        'extras/CUPTI/include'
        'include/cuda/CUPTI'
        'local/cuda/extras/CUPTI/include'
of:
        '/lib'
        '/lib64'
        '/opt/dell/srvadmin/lib64'
        '/opt/dell/srvadmin/lib64/openmanage'
        '/opt/dell/srvadmin/lib64/openmanage/smpop'
        '/usr'
        '/usr/lib64//bind9-export'
        '/usr/lib64/dyninst'

Asking for detailed CUDA configuration...

Please specify the CUDA SDK version you want to use. [Leave empty to default to CUDA 10]: 11.2


Please specify the cuDNN version you want to use. [Leave empty to default to cuDNN 7]: 8.2.1


Please specify the locally installed NCCL version you want to use. [Leave empty to use http://github.com/nvidia/nccl]: 


Please specify the comma-separated list of base paths to look for CUDA libraries and headers. [Leave empty to use the default]: /usr/local/easybuild/software/CUDAcore/11.2.1/, /usr/local/easybuild/software/cuDNN/8.2.1.32-CUDA-11.3.1/


Could not find any cudnn.h, cudnn_version.h matching version '8.2.1' in any subdirectory:
        ''
        'include'
        'include/cuda'
        'include/*-linux-gnu'
        'extras/CUPTI/include'
        'include/cuda/CUPTI'
        'local/cuda/extras/CUPTI/include'
of:
        '/usr/local/easybuild/software/CUDAcore/11.2.1/'

Asking for detailed CUDA configuration...

Please specify the CUDA SDK version you want to use. [Leave empty to default to CUDA 10]: 
```
```
</details>"
56089,[Autograph] Inconsistent behaviour with lambda variable in loop,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

master

### Custom Code

No

### OS Platform and Distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
We have an inconsistent behavior with lambda variables in a loop in pure python and graph mode:
https://docs.python.org/3/faq/programming.html#why-do-lambdas-defined-in-a-loop-with-different-values-all-return-the-same-result
```


### Standalone code to reproduce the issue

```shell
import tensorflow as tf

def test_a():
  fns = []
  for i in range(3):
    fns.append(lambda: print(i))
  for f in fns:
    f()

@tf.function
def test_b():
  fns = []
  for i in range(3):
    fns.append(lambda: print(i))
  for f in fns:
    f()

def test_c():
  fns = []
  for i in range(3):
    fns.append(lambda i=i: print(i))
  for f in fns:
    f()

@tf.function 
def test_d():
  fns = []
  for i in range(3):
    fns.append(lambda i=i: print(i))
  for f in fns:
    f()

test_a() 
print(""==""*10)
tf.config.run_functions_eagerly(False)
test_b()
print(""==""*10)
tf.config.run_functions_eagerly(True)
test_b()
print(""==""*10)
test_c() 
print(""==""*10)
tf.config.run_functions_eagerly(False)
test_d()
print(""==""*10)
tf.config.run_functions_eagerly(True)
test_d() 
```

```python
2
2
2
====================
0
1
2
====================
2
2
2
====================
0
1
2
====================
0
1
2
====================
0
1
2
```
### Relevant log output

`test_b` is wrongly working ""as expected"" in graph mode:


```python
# coding=utf-8
def tf__test():
    with ag__.FunctionScope('test', 'fscope', ag__.ConversionOptions(recursive=True, user_requested=True, optional_features=(), internal_convert_user_code=True)) as fscope:
        fns = []

        def get_state():
            return ()

        def set_state(block_vars):
            pass

        def loop_body(itr):
            i = itr
            ag__.converted_call(ag__.ld(fns).append, (ag__.autograph_artifact((lambda : ag__.ld(print)(ag__.ld(i)))),), None, fscope)
        i = ag__.Undefined('i')
        ag__.for_stmt(ag__.converted_call(ag__.ld(range), (3,), None, fscope), None, loop_body, get_state, set_state, (), {'iterate_names': 'i'})

        def get_state_1():
            return ()

        def set_state_1(block_vars):
            pass

        def loop_body_1(itr_1):
            f = itr_1
            ag__.converted_call(ag__.ld(f), (), None, fscope)
        f = ag__.Undefined('f')
        ag__.for_stmt(ag__.ld(fns), None, loop_body_1, get_state_1, set_state_1, (), {'iterate_names': 'f'})
```
</details>"
56088,Tracker for TensorFlow pip package for Arm,"cc: @learning-to-play @penpornk @yarri-oss @rishikasinha-tf @mseth10 @nSircombe 

This issue tracks the discussion for installing third party TensorFlow packages for Arm/Graviton."
56085,Tensorflow docker image has outdated keys,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

tensorflow:latest

### Custom Code

No

### OS Platform and Distribution

Docker

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
When using a tensorflow docker image there seems to be an outdated apt repository key:
```


### Standalone code to reproduce the issue

```shell
docker run -it  tensorflow/tensorflow:latest-gpu bash

apt update
```


### Relevant log output

```shell
lukas@docker-client:~$ docker run -it  tensorflow/tensorflow:latest-gpu bash
Unable to find image 'tensorflow/tensorflow:latest-gpu' locally
latest-gpu: Pulling from tensorflow/tensorflow
7b1a6ab2e44d: Pull complete
28a427df77d0: Pull complete
7df9c933f388: Pull complete
5efcf2478dc2: Pull complete
3196a0117ed3: Pull complete
558a8016d36f: Pull complete
4187faa68339: Pull complete
5cb96aedb476: Pull complete
d827240235b3: Pull complete
75600f20c268: Pull complete
097a8b939f57: Pull complete
22ec0787b1d5: Pull complete
ad4c0760f8ac: Pull complete
f26dd99dc5e3: Pull complete
Digest: sha256:1e03623e335aac1610b1a3cfa6a96cf10156acb095287f9d6031df3980148663
Status: Downloaded newer image for tensorflow/tensorflow:latest-gpu

________                               _______________
___  __/__________________________________  ____/__  /________      __
__  /  _  _ \_  __ \_  ___/  __ \_  ___/_  /_   __  /_  __ \_ | /| / /
_  /   /  __/  / / /(__  )/ /_/ /  /   _  __/   _  / / /_/ /_ |/ |/ /
/_/    \___//_/ /_//____/ \____//_/    /_/      /_/  \____/____/|__/


WARNING: You are running this container as root, which can cause new files in
mounted volumes to be created as the root user on your host machine.

To avoid this, run the container by specifying your user's userid:

$ docker run -u $(id -u):$(id -g) args...

root@031b1960b4ea:/# apt update
Hit:1 http://archive.ubuntu.com/ubuntu focal InRelease
Get:2 http://archive.ubuntu.com/ubuntu focal-updates InRelease [114 kB]
Get:3 http://security.ubuntu.com/ubuntu focal-security InRelease [114 kB]
Get:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  InRelease [1581 B]
Get:5 http://archive.ubuntu.com/ubuntu focal-backports InRelease [108 kB]
Ign:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu2004/x86_64  InRelease
Err:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  InRelease
  The following signatures couldn't be verified because the public key is not available: NO_PUBKEY A4B469963BF863CC
Ign:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease
Hit:8 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu2004/x86_64  Release
Hit:9 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release
Get:10 http://security.ubuntu.com/ubuntu focal-security/restricted amd64 Packages [1170 kB]
Get:11 http://archive.ubuntu.com/ubuntu focal-updates/restricted amd64 Packages [1249 kB]
Get:12 http://security.ubuntu.com/ubuntu focal-security/multiverse amd64 Packages [25.8 kB]
Get:13 http://security.ubuntu.com/ubuntu focal-security/main amd64 Packages [1812 kB]
Get:15 http://security.ubuntu.com/ubuntu focal-security/universe amd64 Packages [873 kB]
Get:16 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 Packages [2239 kB]
Get:18 http://archive.ubuntu.com/ubuntu focal-updates/multiverse amd64 Packages [30.3 kB]
Get:19 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 Packages [1156 kB]
Get:20 http://archive.ubuntu.com/ubuntu focal-backports/universe amd64 Packages [26.0 kB]
Get:21 http://archive.ubuntu.com/ubuntu focal-backports/main amd64 Packages [51.2 kB]
Reading package lists... Done
W: GPG error: https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  InRelease: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY A4B469963BF863CC
E: The repository 'https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  InRelease' is no longer signed.
N: Updating from such a repository can't be done securely, and is therefore disabled by default.
N: See apt-secure(8) manpage for repository creation and user configuration details.
```
</details>"
56084,Reduce verbosity of certain log messages," ### Issue Type

Feature Request

### Source

source

### Tensorflow Version

TF 2.8.0

### Custom Code

No

### OS Platform and Distribution

Linux Ubuntu 20.04

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
When a user asks TF to place an op on a specified device, if the op is incompatible with the said device, TF emits a lengthy warning. The relevant information is buried under the verbose log. 

We expect the log to be more succinct, preferably with the ""Registered kernels"" section under either Debug or Info level verbosity (and not Warning level).

The issue is observed only with TF1 APIs, so not sure whether it will be fixed, but since the TFTRT converter uses TF1 APIs to make graph manipulations, it will be immensely useful to TFTRT users.
```


### Standalone code to reproduce the issue

```shell
import tensorflow as tf

with tf.Graph().as_default() as graph, tf.device('/job:localhost/replica:0/task:0/device:GPU:0'):
    a = tf.constant(value=""f1"", dtype=tf.string)
    print(""A device:"", a.device)
    b = a + a 
    print(""B device:"", b.device)

    sess = tf.compat.v1.Session()
    print(sess.run(b)) # --> leads to a long stack trace.
    sess.close()
```


### Relevant log output

```shell
Detected at node 'add' defined at (most recent call last):
    File ""m3.py"", line 7, in <module>
      b = a + a
Node: 'add'
Cannot assign a device for operation add: Could not satisfy explicit device specification '/job:localhost/replica:0/task:0/device:GPU:0' because no supported kernel for GPU devices is available.
Colocation Debug Info:
Colocation group had the following types and supported devices:
Root Member(assigned_device_name_index_=-1 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='' resource_device_name_='' supported_device_types_=[CPU] possible_devices_=[]
Add: CPU

Colocation members, user-requested devices, and framework assigned devices, if any:
  add (Add) /job:localhost/replica:0/task:0/device:GPU:0

Op: Add
Node attrs: T=DT_STRING
Registered kernels:
  device='DEFAULT'; T in [DT_INT32]
  device='GPU'; T in [DT_COMPLEX128]
  device='GPU'; T in [DT_COMPLEX64]
  device='GPU'; T in [DT_UINT8]
  device='GPU'; T in [DT_INT64]
  device='GPU'; T in [DT_INT16]
  device='GPU'; T in [DT_INT8]
  device='GPU'; T in [DT_DOUBLE]
  device='GPU'; T in [DT_FLOAT]
  device='GPU'; T in [DT_HALF]
  device='GPU'; T in [DT_INT32]
  device='CPU'; T in [DT_STRING]
  device='CPU'; T in [DT_COMPLEX128]
  device='CPU'; T in [DT_UINT8]
  device='CPU'; T in [DT_COMPLEX64]
  device='CPU'; T in [DT_INT16]
  device='CPU'; T in [DT_INT8]
  device='CPU'; T in [DT_BFLOAT16]
  device='CPU'; T in [DT_INT64]
  device='CPU'; T in [DT_INT32]
  device='CPU'; T in [DT_DOUBLE]
  device='CPU'; T in [DT_HALF]
  device='CPU'; T in [DT_FLOAT]

         [[{{node add}}]]
```
</details>"
56083,Not able to install Tensorflow Go in macOS arm64,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Build/Install

### Source

source

### Tensorflow Version

1.28

### Custom Code

No

### OS Platform and Distribution

macOS monterrey / arm64

### Mobile device

_No response_

### Python version

3.9.12

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
I'd expect tensorflow to be installed
```


### Standalone code to reproduce the issue

```shell
package main

import (
	tf ""github.com/tensorflow/tensorflow/tensorflow/go""
	""github.com/tensorflow/tensorflow/tensorflow/go/core/protobuf/for_core_protos_go_proto""
)

and go mod tidy
```


### Relevant log output

```shell
go mod tidy

go: finding module for package google.golang.org/protobuf/proto
go: finding module for package github.com/paulbellamy/ratecounter
go: finding module for package github.com/tensorflow/tensorflow/tensorflow/go/core/protobuf/for_core_protos_go_proto
go: finding module for package github.com/influxdata/tdigest
go: finding module for package go.uber.org/ratelimit
go: finding module for package github.com/tensorflow/tensorflow/tensorflow/go
go: found github.com/influxdata/tdigest in github.com/influxdata/tdigest v0.0.1
go: found github.com/paulbellamy/ratecounter in github.com/paulbellamy/ratecounter v0.2.0
go: found github.com/tensorflow/tensorflow/tensorflow/go in github.com/tensorflow/tensorflow v2.8.0+incompatible
go: found go.uber.org/ratelimit in go.uber.org/ratelimit v0.2.0
go: found google.golang.org/protobuf/proto in google.golang.org/protobuf v1.28.0
go: finding module for package github.com/tensorflow/tensorflow/tensorflow/go/core/framework/types_go_proto
go: finding module for package github.com/tensorflow/tensorflow/tensorflow/go/core/protobuf/for_core_protos_go_proto
go: finding module for package github.com/tensorflow/tensorflow/tensorflow/go/core/framework/tensor_shape_go_proto
tensorflow imports
	github.com/tensorflow/tensorflow/tensorflow/go/core/protobuf/for_core_protos_go_proto: module github.com/tensorflow/tensorflow@latest found (v2.8.0+incompatible), but does not contain package github.com/tensorflow/tensorflow/tensorflow/go/core/protobuf/for_core_protos_go_proto
tensorflow imports
	github.com/tensorflow/tensorflow/tensorflow/go tested by
	github.com/tensorflow/tensorflow/tensorflow/go.test imports
	github.com/tensorflow/tensorflow/tensorflow/go/core/framework/tensor_shape_go_proto: module github.com/tensorflow/tensorflow@latest found (v2.8.0+incompatible), but does not contain package github.com/tensorflow/tensorflow/tensorflow/go/core/framework/tensor_shape_go_proto
tensorflow imports
	github.com/tensorflow/tensorflow/tensorflow/go tested by
	github.com/tensorflow/tensorflow/tensorflow/go.test imports
	github.com/tensorflow/tensorflow/tensorflow/go/core/framework/types_go_proto: module github.com/tensorflow/tensorflow@latest found (v2.8.0+incompatible), but does not contain package github.com/tensorflow/tensorflow/tensorflow/go/core/framework/types_go_proto
```
</details>"
56082,Keras Sequential using RNN not working on M1 Max GPU,"<details><summary>Click to expand!</summary> 
 
### Issue Type

Bug

### Source

source

### Tensorflow Version

2.8.0

### Custom Code

No

### OS Platform and Distribution

MaxOS 12.3.1 

### Mobile device

_No response_

### Python version

3.9

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

M1 Max 26 cores GPU

### Current Behaviour?

If using a `Sequential` model, I use a `SimpleRNN` layer, there is no way to use the GPU as device (no problem with the same code on Colab, every runtime works).

The same code using:
```
with tf.device(""/device:CPU:0""):
  ...
```
works fine, but takes a while


### Standalone code to reproduce the issue

```shell
from tensorflow import keras
(X_train, y_train), (X_test, y_test) = keras.datasets.imdb.load_data(num_words=10000)
(X_valid, X_test) = X_test[:12500], X_test[12500:]
(y_valid, y_test) = y_test[:12500], y_test[12500:]
word_index = keras.datasets.imdb.get_word_index()
X_train_trim = keras.preprocessing.sequence.pad_sequences(X_train, maxlen=500)
X_test_trim = keras.preprocessing.sequence.pad_sequences(X_test, maxlen=500)
X_valid_trim = keras.preprocessing.sequence.pad_sequences(X_valid, maxlen=500)
model = keras.models.Sequential()
model.add(keras.layers.Embedding(input_dim=10000, output_dim=10))
model.add(keras.layers.SimpleRNN(32))
model.add(keras.layers.Dense(1, ""sigmoid""))

model.compile(loss='binary_crossentropy', optimizer=""adam"", metrics=[""accuracy""])

history = model.fit(X_train_trim, y_train,epochs=10, batch_size=128, validation_data=(X_valid_trim, y_valid))
```


### Relevant log output

```shell
Metal device set to: Apple M1 Max
systemMemory: 32.00 GB
maxCacheSize: 10.67 GB
2022-05-12 14:36:06.487099: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.
2022-05-12 14:36:06.487233: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)
2022-05-12 14:36:07.054786: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz
Epoch 1/10
2022-05-12 14:36:07.290001: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.
  1/196 [..............................] - ETA: 5:01:59 - loss: 0.6936 - accuracy: 0.5469
```
</details>"
56081,TFLite/GPU `tfl.strided_slice` not supported - docs claim it is.,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Documentation Bug

### Source

binary

### Tensorflow Version

v2.8.0-0-g3f878cff5b6 2.8.0

### Custom Code

Yes

### OS Platform and Distribution

Google Colab

### Mobile device

_No response_

### Python version

3.7.13 (Google Colab)

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
According to the [documentation](https://www.tensorflow.org/lite/performance/gpu_advanced#supported_ops), a `strided_slice` operation should be supported when running Tensorflow Lite with a GPU Delegate.

Running sanity check with the [Tensorflow Lite Authoring Tool](https://www.tensorflow.org/lite/guide/authoring#checking_gpu_compatibility) raises Exception. How should one use this op, to benefit from GPU acceleration on Android?
```


### Standalone code to reproduce the issue

```shell
# Colab: https://colab.research.google.com/drive/1ih1I3m1j4ZNnc7RKp7AzkLsM-1Cf9TUn?usp=sharing

import tensorflow as tf

# Declare dummy model with strided_slice op:
@tf.function(input_signature = [tf.TensorSpec(shape=(1, 2), dtype=tf.float32)])
def apply(x):
    return x[0, 0]

# Verify works 
apply(tf.constant([[1., 2.]]))

# Fails on the GPU with authoring tool check
target_spec = tf.lite.TargetSpec()
target_spec.experimental_supported_backends = [""GPU""]
func_to_test = tf.lite.experimental.authoring.compatible(
    apply, converter_target_spec=target_spec, raise_exception=True
)
func_to_test(tf.ones(shape=(1,2)))
```


### Relevant log output

```shell
'tfl.strided_slice' op is not GPU compatible: Slice does not support shrink_axis_mask parameter. 
  - /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082
  - /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py:150
  - <ipython-input-32-9f16c67cb20c>:6

COMPATIBILITY WARNING: op 'tfl.strided_slice' aren't compatible with TensorFlow Lite GPU delegate. https://www.tensorflow.org/lite/performance/gpu
```
</details>"
56080,loss does not decrease in Google Colab and local computer. (TF 1.13 vs  from TF 1.14 to TF 2.6),"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Performance

### Source

source

### Tensorflow Version

1.13 vs 2.6

### Custom Code

Yes

### OS Platform and Distribution

Windows 10

### Mobile device

_No response_

### Python version

3.7.4

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

11.2.0 / 8.1.0

### GPU model and memory

_No response_

### Current Behaviour?

```shell
I studied with my data and tf-gpu 1.6 and keras in 2019. 
At this time, training was done normally.

Although it is the same code as in the past, 
training loss and validation loss are decreased 
when training with TF 1.13  (working TF 1.6 ~ TF 1.13).

However, from TF 1.14 to TF 2.6, 
both train loss and validation loss have increased.

When the model weight made with TF 1.6 was called from TF 2.6 (tried to TF 1.14, TF 1.15, TF 2.0 and TF 2.6), 
it was called without any problems and the results were the same as those from the past.

So I can't understand why that happen.
I wonder what parts of TF 1.13 and TF 1.14 and above are different and affect training!!!!!!

Also, I tried updating the source code through tf_upgrade_v2, 
but it was not solved at all.
https://www.tensorflow.org/guide/upgrade?hl=en
tf_upgrade_v2 --infile my_code.py --outfile my_code_upgraded.py
```


### Standalone code to reproduce the issue

```shell
def define_model(time_steps, input_rows, input_dim, input_ch, output_dim, dropRate, learning_rate):   
    input_data = tf.keras.layers.Input(shape=(time_steps, input_rows, input_dim, input_ch), name='my_data')

    x = tf.keras.layers.TimeDistributed(tf.keras.layers.Conv2D(filters=16, kernel_size=(2, 2), strides=4, padding='same'))(input_data )
    x = tf.keras.layers.LeakyReLU()(x)   # default alpha = 0.3
    x = tf.keras.layers.TimeDistributed(tf.keras.layers.MaxPooling2D((2, 2), strides=2))(x)
    x = tf.keras.layers.Dropout(rate=dropRate)(x)

    x = tf.keras.layers.TimeDistributed(tf.keras.layers.Flatten())(x)
    x = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(128))(x)
    x = tf.keras.layers.LeakyReLU()(x)   # default alpha = 0.3

    ###============================== Model 2 (LSTM)
    x = tf.keras.layers.LSTM(128, dropout=0.2, recurrent_dropout=0.2, return_sequences=True)(x)
    x = tf.keras.layers.LSTM(10, dropout=0.2, recurrent_dropout=0.2, return_sequences=False)(x)

    x_out = tf.keras.layers.Dense(10, 'softmax')(x)

    model = Model(inputs=input_data, outputs=x_out)
    model.compile(optimizer=optimizers.Adam(learning_rate=0.001), loss=losses.categorical_crossentropy)

    return model
```


### Relevant log output

**decreased the loss when using TF 1.13**
![image](https://user-images.githubusercontent.com/39148033/168065098-12939b28-dbe7-4cef-9cb3-ecb0ea18843c.png)

**increased the loss when using TF 1.14 and TF 2.6**
![image](https://user-images.githubusercontent.com/39148033/168066373-cb5bb8b4-1f18-41ba-a412-446c5d0dd195.png)

_No response_</details>"
56079,Wrong prediction every time using the person detection model on ESP32-WROVER-IE board ,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

Microlite esp32 firmware 

### Custom Code

Yes

### OS Platform and Distribution

Linux Ubuntu 18.04

### Mobile device

_No response_

### Python version

Python 3.8

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
Hi guys,
I am using the ESP32-WROVER-IE board with the ov2640 camera connected to it. I am trying to run the person detection example and see if I can get some output results based on the captured image. Every time I get same result where the higher value is assigned to not_a_person prediction even if I am present on the picture. I also tried with the existing example but there as well the prediction is always negative (I mean it's always like there is nobody on the picture). Is there any possible solution for this issue? Any kind of help is welcome.

P.S. I am using MicroPython!
```


### Standalone code to reproduce the issue

```shell
https://github.com/mocleiri/tensorflow-micropython-examples/tree/main/examples/person_detection
```


### Relevant log output

_No response_</details>"
56078,Unit test //tensorflow/tools/docs:tf_doctest is broken by protobuf exception,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

git HEAD

### Custom Code

No

### OS Platform and Distribution

CentOS 7

### Mobile device

n/a

### Python version

3.8.13

### Bazel version

5.1.1

### GCC/Compiler version

10.2.1

### CUDA/cuDNN version

n/a

### GPU model and memory

n/a

### Current Behaviour?

```shell
//tensorflow/tools/docs:tf_doctest                                       FAILED in 12 out of 12 in 10.8s
```


### Standalone code to reproduce the issue

```shell
bazel test --test_timeout=300,500,-1,-1 --flaky_test_attempts=3 --test_output=all --cache_test_results=no --noremote_accept_cached --config=nonccl --copt=""-mtune=generic"" --copt=""-march=armv8-a"" --copt=""-O3"" --build_tag_filters=-no_oss,-oss_serial,-gpu,-tpu,-benchmark-test,-v1only,-no_aarch64,-requires-gpu --test_tag_filters=-no_oss,-oss_serial,-gpu,-tpu,-benchmark-test,-v1only,-no_aarch64,-requires-gpu --verbose_failures --build_tests_only --jobs=75 -- //tensorflow/tools/docs:tf_doctest
```


### Relevant log output

```shell
Introduced by https://github.com/tensorflow/tensorflow/commit/c777808941613acebc74dbcdd5e48c4e76ac5271

INFO: Options provided by the client:
  Inherited 'common' options: --isatty=1 --terminal_columns=132
INFO: Reading rc options for 'test' from /tmp/workspace/tensorflow-git/.bazelrc:
  Inherited 'common' options: --experimental_repo_remote_exec
INFO: Reading rc options for 'test' from /tmp/workspace/tensorflow-git/.bazelrc:
  Inherited 'build' options: --define framework_shared_object=true --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --enable_platform_specific_config --define=with_xla_support=true --config=short_logs --config=v2 --define=no_aws_support=true --define=no_hdfs_support=true --experimental_cc_shared_library --experimental_link_static_libraries_once=true
INFO: Reading rc options for 'test' from /tmp/workspace/tensorflow-git/.tf_configure.bazelrc:
  Inherited 'build' options: --action_env PYTHON_BIN_PATH=/tmp/workspace/venv-cp38-cp38/bin/python3 --action_env PYTHON_LIB_PATH=/tmp/workspace/venv-cp38-cp38/lib/python3.8/site-packages --python_path=/tmp/workspace/venv-cp38-cp38/bin/python3
INFO: Reading rc options for 'test' from /tmp/workspace/tensorflow-git/.bazelrc:
  Inherited 'build' options: --deleted_packages=tensorflow/compiler/mlir/tfrt,tensorflow/compiler/mlir/tfrt/benchmarks,tensorflow/compiler/mlir/tfrt/jit/python_binding,tensorflow/compiler/mlir/tfrt/jit/transforms,tensorflow/compiler/mlir/tfrt/python_tests,tensorflow/compiler/mlir/tfrt/tests,tensorflow/compiler/mlir/tfrt/tests/ir,tensorflow/compiler/mlir/tfrt/tests/analysis,tensorflow/compiler/mlir/tfrt/tests/jit,tensorflow/compiler/mlir/tfrt/tests/lhlo_to_tfrt,tensorflow/compiler/mlir/tfrt/tests/tf_to_corert,tensorflow/compiler/mlir/tfrt/tests/tf_to_tfrt_data,tensorflow/compiler/mlir/tfrt/tests/saved_model,tensorflow/compiler/mlir/tfrt/transforms/lhlo_gpu_to_tfrt_gpu,tensorflow/core/runtime_fallback,tensorflow/core/runtime_fallback/conversion,tensorflow/core/runtime_fallback/kernel,tensorflow/core/runtime_fallback/opdefs,tensorflow/core/runtime_fallback/runtime,tensorflow/core/runtime_fallback/util,tensorflow/core/tfrt/common,tensorflow/core/tfrt/eager,tensorflow/core/tfrt/eager/backends/cpu,tensorflow/core/tfrt/eager/backends/gpu,tensorflow/core/tfrt/eager/core_runtime,tensorflow/core/tfrt/eager/cpp_tests/core_runtime,tensorflow/core/tfrt/gpu,tensorflow/core/tfrt/run_handler_thread_pool,tensorflow/core/tfrt/runtime,tensorflow/core/tfrt/saved_model,tensorflow/core/tfrt/graph_executor,tensorflow/core/tfrt/saved_model/tests,tensorflow/core/tfrt/tpu,tensorflow/core/tfrt/utils
INFO: Reading rc options for 'test' from /tmp/workspace/tensorflow-git/.tf_configure.bazelrc:
  'test' options: --flaky_test_attempts=3 --test_size_filters=small,medium
INFO: Found applicable config definition build:short_logs in file /tmp/workspace/tensorflow-git/.bazelrc: --output_filter=DONT_MATCH_ANYTHING
INFO: Found applicable config definition build:v2 in file /tmp/workspace/tensorflow-git/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1
INFO: Found applicable config definition test:v2 in file /tmp/workspace/tensorflow-git/.tf_configure.bazelrc: --test_tag_filters=-benchmark-test,-no_oss,-gpu,-oss_serial,-v1only --build_tag_filters=-benchmark-test,-no_oss,-gpu,-v1only
INFO: Found applicable config definition build:nonccl in file /tmp/workspace/tensorflow-git/.bazelrc: --define=no_nccl_support=true
INFO: Found applicable config definition build:linux in file /tmp/workspace/tensorflow-git/.bazelrc: --copt=-w --host_copt=-w --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --define=PROTOBUF_INCLUDE_PATH=$(PREFIX)/include --cxxopt=-std=c++14 --host_cxxopt=-std=c++14 --config=dynamic_kernels --distinct_host_configuration=false --experimental_guard_against_concurrent_changes
INFO: Found applicable config definition build:dynamic_kernels in file /tmp/workspace/tensorflow-git/.bazelrc: --define=dynamic_loaded_kernels=true --copt=-DAUTOLOAD_DYNAMIC_KERNELS
INFO: Analyzed target //tensorflow/tools/docs:tf_doctest (279 packages loaded, 21308 targets configured).
INFO: Found 1 test target...
FAIL: //tensorflow/tools/docs:tf_doctest (shard 3 of 4) (see /root/.cache/bazel/_bazel_root/db210f68f81d95ddcca9ae96b16ed72c/execroot/org_tensorflow/bazel-out/aarch64-opt/testlogs/tensorflow/tools/docs/tf_doctest/shard_3_of_4/test_attempts/attempt_1.log)
FAIL: //tensorflow/tools/docs:tf_doctest (shard 1 of 4) (see /root/.cache/bazel/_bazel_root/db210f68f81d95ddcca9ae96b16ed72c/execroot/org_tensorflow/bazel-out/aarch64-opt/testlogs/tensorflow/tools/docs/tf_doctest/shard_1_of_4/test_attempts/attempt_1.log)
FAIL: //tensorflow/tools/docs:tf_doctest (shard 4 of 4) (see /root/.cache/bazel/_bazel_root/db210f68f81d95ddcca9ae96b16ed72c/execroot/org_tensorflow/bazel-out/aarch64-opt/testlogs/tensorflow/tools/docs/tf_doctest/shard_4_of_4/test_attempts/attempt_1.log)
FAIL: //tensorflow/tools/docs:tf_doctest (shard 2 of 4) (see /root/.cache/bazel/_bazel_root/db210f68f81d95ddcca9ae96b16ed72c/execroot/org_tensorflow/bazel-out/aarch64-opt/testlogs/tensorflow/tools/docs/tf_doctest/shard_2_of_4/test_attempts/attempt_1.log)
FAIL: //tensorflow/tools/docs:tf_doctest (shard 4 of 4) (see /root/.cache/bazel/_bazel_root/db210f68f81d95ddcca9ae96b16ed72c/execroot/org_tensorflow/bazel-out/aarch64-opt/testlogs/tensorflow/tools/docs/tf_doctest/shard_4_of_4/test_attempts/attempt_2.log)
FAIL: //tensorflow/tools/docs:tf_doctest (shard 1 of 4) (see /root/.cache/bazel/_bazel_root/db210f68f81d95ddcca9ae96b16ed72c/execroot/org_tensorflow/bazel-out/aarch64-opt/testlogs/tensorflow/tools/docs/tf_doctest/shard_1_of_4/test_attempts/attempt_2.log)
FAIL: //tensorflow/tools/docs:tf_doctest (shard 3 of 4) (see /root/.cache/bazel/_bazel_root/db210f68f81d95ddcca9ae96b16ed72c/execroot/org_tensorflow/bazel-out/aarch64-opt/testlogs/tensorflow/tools/docs/tf_doctest/shard_3_of_4/test_attempts/attempt_2.log)
FAIL: //tensorflow/tools/docs:tf_doctest (shard 2 of 4) (see /root/.cache/bazel/_bazel_root/db210f68f81d95ddcca9ae96b16ed72c/execroot/org_tensorflow/bazel-out/aarch64-opt/testlogs/tensorflow/tools/docs/tf_doctest/shard_2_of_4/test_attempts/attempt_2.log)
FAIL: //tensorflow/tools/docs:tf_doctest (shard 4 of 4) (see /root/.cache/bazel/_bazel_root/db210f68f81d95ddcca9ae96b16ed72c/execroot/org_tensorflow/bazel-out/aarch64-opt/testlogs/tensorflow/tools/docs/tf_doctest/shard_4_of_4/test.log)
INFO: From Testing //tensorflow/tools/docs:tf_doctest (shard 4 of 4):
==================== Test output for //tensorflow/tools/docs:tf_doctest (shard 4 of 4):
2022-05-12 10:42:30.717782: E tensorflow/core/common_runtime/session_factory.cc:48] Two session factories are being registered under GRPC_SESSION
[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/descriptor_database.cc:118] File already exists in database: tensorflow/python/framework/cpp_shape_inference.proto
[libprotobuf FATAL external/com_google_protobuf/src/google/protobuf/descriptor.cc:1379] CHECK failed: GeneratedDatabase()->Add(encoded_file_descriptor, size): 
terminate called after throwing an instance of 'google::protobuf::FatalException'
  what():  CHECK failed: GeneratedDatabase()->Add(encoded_file_descriptor, size): 
================================================================================
==================== Test output for //tensorflow/tools/docs:tf_doctest (shard 4 of 4):
2022-05-12 10:42:35.654227: E tensorflow/core/common_runtime/session_factory.cc:48] Two session factories are being registered under GRPC_SESSION
[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/descriptor_database.cc:118] File already exists in database: tensorflow/python/framework/cpp_shape_inference.proto
[libprotobuf FATAL external/com_google_protobuf/src/google/protobuf/descriptor.cc:1379] CHECK failed: GeneratedDatabase()->Add(encoded_file_descriptor, size): 
terminate called after throwing an instance of 'google::protobuf::FatalException'
  what():  CHECK failed: GeneratedDatabase()->Add(encoded_file_descriptor, size): 
================================================================================
==================== Test output for //tensorflow/tools/docs:tf_doctest (shard 4 of 4):
2022-05-12 10:42:40.591478: E tensorflow/core/common_runtime/session_factory.cc:48] Two session factories are being registered under GRPC_SESSION
[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/descriptor_database.cc:118] File already exists in database: tensorflow/python/framework/cpp_shape_inference.proto
[libprotobuf FATAL external/com_google_protobuf/src/google/protobuf/descriptor.cc:1379] CHECK failed: GeneratedDatabase()->Add(encoded_file_descriptor, size): 
terminate called after throwing an instance of 'google::protobuf::FatalException'
  what():  CHECK failed: GeneratedDatabase()->Add(encoded_file_descriptor, size): 
================================================================================
FAIL: //tensorflow/tools/docs:tf_doctest (shard 3 of 4) (see /root/.cache/bazel/_bazel_root/db210f68f81d95ddcca9ae96b16ed72c/execroot/org_tensorflow/bazel-out/aarch64-opt/testlogs/tensorflow/tools/docs/tf_doctest/shard_3_of_4/test.log)
INFO: From Testing //tensorflow/tools/docs:tf_doctest (shard 3 of 4):
==================== Test output for //tensorflow/tools/docs:tf_doctest (shard 3 of 4):
2022-05-12 10:42:30.717687: E tensorflow/core/common_runtime/session_factory.cc:48] Two session factories are being registered under GRPC_SESSION
[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/descriptor_database.cc:118] File already exists in database: tensorflow/python/framework/cpp_shape_inference.proto
[libprotobuf FATAL external/com_google_protobuf/src/google/protobuf/descriptor.cc:1379] CHECK failed: GeneratedDatabase()->Add(encoded_file_descriptor, size): 
terminate called after throwing an instance of 'google::protobuf::FatalException'
  what():  CHECK failed: GeneratedDatabase()->Add(encoded_file_descriptor, size): 
================================================================================
==================== Test output for //tensorflow/tools/docs:tf_doctest (shard 3 of 4):
2022-05-12 10:42:35.668010: E tensorflow/core/common_runtime/session_factory.cc:48] Two session factories are being registered under GRPC_SESSION
[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/descriptor_database.cc:118] File already exists in database: tensorflow/python/framework/cpp_shape_inference.proto
[libprotobuf FATAL external/com_google_protobuf/src/google/protobuf/descriptor.cc:1379] CHECK failed: GeneratedDatabase()->Add(encoded_file_descriptor, size): 
terminate called after throwing an instance of 'google::protobuf::FatalException'
  what():  CHECK failed: GeneratedDatabase()->Add(encoded_file_descriptor, size): 
================================================================================
==================== Test output for //tensorflow/tools/docs:tf_doctest (shard 3 of 4):
2022-05-12 10:42:40.629291: E tensorflow/core/common_runtime/session_factory.cc:48] Two session factories are being registered under GRPC_SESSION
[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/descriptor_database.cc:118] File already exists in database: tensorflow/python/framework/cpp_shape_inference.proto
[libprotobuf FATAL external/com_google_protobuf/src/google/protobuf/descriptor.cc:1379] CHECK failed: GeneratedDatabase()->Add(encoded_file_descriptor, size): 
terminate called after throwing an instance of 'google::protobuf::FatalException'
  what():  CHECK failed: GeneratedDatabase()->Add(encoded_file_descriptor, size): 
================================================================================
FAIL: //tensorflow/tools/docs:tf_doctest (shard 1 of 4) (see /root/.cache/bazel/_bazel_root/db210f68f81d95ddcca9ae96b16ed72c/execroot/org_tensorflow/bazel-out/aarch64-opt/testlogs/tensorflow/tools/docs/tf_doctest/shard_1_of_4/test.log)
INFO: From Testing //tensorflow/tools/docs:tf_doctest (shard 1 of 4):
==================== Test output for //tensorflow/tools/docs:tf_doctest (shard 1 of 4):
2022-05-12 10:42:30.717782: E tensorflow/core/common_runtime/session_factory.cc:48] Two session factories are being registered under GRPC_SESSION
[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/descriptor_database.cc:118] File already exists in database: tensorflow/python/framework/cpp_shape_inference.proto
[libprotobuf FATAL external/com_google_protobuf/src/google/protobuf/descriptor.cc:1379] CHECK failed: GeneratedDatabase()->Add(encoded_file_descriptor, size): 
terminate called after throwing an instance of 'google::protobuf::FatalException'
  what():  CHECK failed: GeneratedDatabase()->Add(encoded_file_descriptor, size): 
================================================================================
==================== Test output for //tensorflow/tools/docs:tf_doctest (shard 1 of 4):
2022-05-12 10:42:35.654227: E tensorflow/core/common_runtime/session_factory.cc:48] Two session factories are being registered under GRPC_SESSION
[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/descriptor_database.cc:118] File already exists in database: tensorflow/python/framework/cpp_shape_inference.proto
[libprotobuf FATAL external/com_google_protobuf/src/google/protobuf/descriptor.cc:1379] CHECK failed: GeneratedDatabase()->Add(encoded_file_descriptor, size): 
terminate called after throwing an instance of 'google::protobuf::FatalException'
  what():  CHECK failed: GeneratedDatabase()->Add(encoded_file_descriptor, size): 
================================================================================
==================== Test output for //tensorflow/tools/docs:tf_doctest (shard 1 of 4):
2022-05-12 10:42:40.629291: E tensorflow/core/common_runtime/session_factory.cc:48] Two session factories are being registered under GRPC_SESSION
[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/descriptor_database.cc:118] File already exists in database: tensorflow/python/framework/cpp_shape_inference.proto
[libprotobuf FATAL external/com_google_protobuf/src/google/protobuf/descriptor.cc:1379] CHECK failed: GeneratedDatabase()->Add(encoded_file_descriptor, size): 
terminate called after throwing an instance of 'google::protobuf::FatalException'
  what():  CHECK failed: GeneratedDatabase()->Add(encoded_file_descriptor, size): 
================================================================================
FAIL: //tensorflow/tools/docs:tf_doctest (shard 2 of 4) (see /root/.cache/bazel/_bazel_root/db210f68f81d95ddcca9ae96b16ed72c/execroot/org_tensorflow/bazel-out/aarch64-opt/testlogs/tensorflow/tools/docs/tf_doctest/shard_2_of_4/test.log)

FAILED: //tensorflow/tools/docs:tf_doctest (Summary)
      /root/.cache/bazel/_bazel_root/db210f68f81d95ddcca9ae96b16ed72c/execroot/org_tensorflow/bazel-out/aarch64-opt/testlogs/tensorflow/tools/docs/tf_doctest/shard_4_of_4/test.log
      /root/.cache/bazel/_bazel_root/db210f68f81d95ddcca9ae96b16ed72c/execroot/org_tensorflow/bazel-out/aarch64-opt/testlogs/tensorflow/tools/docs/tf_doctest/shard_4_of_4/test_attempts/attempt_1.log
      /root/.cache/bazel/_bazel_root/db210f68f81d95ddcca9ae96b16ed72c/execroot/org_tensorflow/bazel-out/aarch64-opt/testlogs/tensorflow/tools/docs/tf_doctest/shard_4_of_4/test_attempts/attempt_2.log
      /root/.cache/bazel/_bazel_root/db210f68f81d95ddcca9ae96b16ed72c/execroot/org_tensorflow/bazel-out/aarch64-opt/testlogs/tensorflow/tools/docs/tf_doctest/shard_3_of_4/test.log
      /root/.cache/bazel/_bazel_root/db210f68f81d95ddcca9ae96b16ed72c/execroot/org_tensorflow/bazel-out/aarch64-opt/testlogs/tensorflow/tools/docs/tf_doctest/shard_3_of_4/test_attempts/attempt_1.log
      /root/.cache/bazel/_bazel_root/db210f68f81d95ddcca9ae96b16ed72c/execroot/org_tensorflow/bazel-out/aarch64-opt/testlogs/tensorflow/tools/docs/tf_doctest/shard_3_of_4/test_attempts/attempt_2.log
      /root/.cache/bazel/_bazel_root/db210f68f81d95ddcca9ae96b16ed72c/execroot/org_tensorflow/bazel-out/aarch64-opt/testlogs/tensorflow/tools/docs/tf_doctest/shard_1_of_4/test.log
      /root/.cache/bazel/_bazel_root/db210f68f81d95ddcca9ae96b16ed72c/execroot/org_tensorflow/bazel-out/aarch64-opt/testlogs/tensorflow/tools/docs/tf_doctest/shard_1_of_4/test_attempts/attempt_1.log
      /root/.cache/bazel/_bazel_root/db210f68f81d95ddcca9ae96b16ed72c/execroot/org_tensorflow/bazel-out/aarch64-opt/testlogs/tensorflow/tools/docs/tf_doctest/shard_1_of_4/test_attempts/attempt_2.log
      /root/.cache/bazel/_bazel_root/db210f68f81d95ddcca9ae96b16ed72c/execroot/org_tensorflow/bazel-out/aarch64-opt/testlogs/tensorflow/tools/docs/tf_doctest/shard_2_of_4/test.log
      /root/.cache/bazel/_bazel_root/db210f68f81d95ddcca9ae96b16ed72c/execroot/org_tensorflow/bazel-out/aarch64-opt/testlogs/tensorflow/tools/docs/tf_doctest/shard_2_of_4/test_attempts/attempt_1.log
      /root/.cache/bazel/_bazel_root/db210f68f81d95ddcca9ae96b16ed72c/execroot/org_tensorflow/bazel-out/aarch64-opt/testlogs/tensorflow/tools/docs/tf_doctest/shard_2_of_4/test_attempts/attempt_2.log
INFO: From Testing //tensorflow/tools/docs:tf_doctest (shard 2 of 4):
==================== Test output for //tensorflow/tools/docs:tf_doctest (shard 2 of 4):
2022-05-12 10:42:30.717687: E tensorflow/core/common_runtime/session_factory.cc:48] Two session factories are being registered under GRPC_SESSION
[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/descriptor_database.cc:118] File already exists in database: tensorflow/python/framework/cpp_shape_inference.proto
[libprotobuf FATAL external/com_google_protobuf/src/google/protobuf/descriptor.cc:1379] CHECK failed: GeneratedDatabase()->Add(encoded_file_descriptor, size): 
terminate called after throwing an instance of 'google::protobuf::FatalException'
  what():  CHECK failed: GeneratedDatabase()->Add(encoded_file_descriptor, size): 
================================================================================
==================== Test output for //tensorflow/tools/docs:tf_doctest (shard 2 of 4):
2022-05-12 10:42:35.770968: E tensorflow/core/common_runtime/session_factory.cc:48] Two session factories are being registered under GRPC_SESSION
[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/descriptor_database.cc:118] File already exists in database: tensorflow/python/framework/cpp_shape_inference.proto
[libprotobuf FATAL external/com_google_protobuf/src/google/protobuf/descriptor.cc:1379] CHECK failed: GeneratedDatabase()->Add(encoded_file_descriptor, size): 
terminate called after throwing an instance of 'google::protobuf::FatalException'
  what():  CHECK failed: GeneratedDatabase()->Add(encoded_file_descriptor, size): 
================================================================================
==================== Test output for //tensorflow/tools/docs:tf_doctest (shard 2 of 4):
2022-05-12 10:42:40.991862: E tensorflow/core/common_runtime/session_factory.cc:48] Two session factories are being registered under GRPC_SESSION
[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/descriptor_database.cc:118] File already exists in database: tensorflow/python/framework/cpp_shape_inference.proto
[libprotobuf FATAL external/com_google_protobuf/src/google/protobuf/descriptor.cc:1379] CHECK failed: GeneratedDatabase()->Add(encoded_file_descriptor, size): 
terminate called after throwing an instance of 'google::protobuf::FatalException'
  what():  CHECK failed: GeneratedDatabase()->Add(encoded_file_descriptor, size): 
================================================================================
Target //tensorflow/tools/docs:tf_doctest up-to-date:
  bazel-bin/tensorflow/tools/docs/tf_doctest
INFO: Elapsed time: 681.341s, Critical Path: 425.75s
INFO: 3147 processes: 456 internal, 2691 local.
INFO: Build completed, 1 test FAILED, 3147 total actions
//tensorflow/tools/docs:tf_doctest                                       FAILED in 12 out of 12 in 10.8s
  Stats over 12 runs: max = 10.8s, min = 4.9s, avg = 6.9s, dev = 2.7s
  /root/.cache/bazel/_bazel_root/db210f68f81d95ddcca9ae96b16ed72c/execroot/org_tensorflow/bazel-out/aarch64-opt/testlogs/tensorflow/tools/docs/tf_doctest/shard_4_of_4/test.log
  /root/.cache/bazel/_bazel_root/db210f68f81d95ddcca9ae96b16ed72c/execroot/org_tensorflow/bazel-out/aarch64-opt/testlogs/tensorflow/tools/docs/tf_doctest/shard_4_of_4/test_attempts/attempt_1.log
  /root/.cache/bazel/_bazel_root/db210f68f81d95ddcca9ae96b16ed72c/execroot/org_tensorflow/bazel-out/aarch64-opt/testlogs/tensorflow/tools/docs/tf_doctest/shard_4_of_4/test_attempts/attempt_2.log
  /root/.cache/bazel/_bazel_root/db210f68f81d95ddcca9ae96b16ed72c/execroot/org_tensorflow/bazel-out/aarch64-opt/testlogs/tensorflow/tools/docs/tf_doctest/shard_3_of_4/test.log
  /root/.cache/bazel/_bazel_root/db210f68f81d95ddcca9ae96b16ed72c/execroot/org_tensorflow/bazel-out/aarch64-opt/testlogs/tensorflow/tools/docs/tf_doctest/shard_3_of_4/test_attempts/attempt_1.log
  /root/.cache/bazel/_bazel_root/db210f68f81d95ddcca9ae96b16ed72c/execroot/org_tensorflow/bazel-out/aarch64-opt/testlogs/tensorflow/tools/docs/tf_doctest/shard_3_of_4/test_attempts/attempt_2.log
  /root/.cache/bazel/_bazel_root/db210f68f81d95ddcca9ae96b16ed72c/execroot/org_tensorflow/bazel-out/aarch64-opt/testlogs/tensorflow/tools/docs/tf_doctest/shard_1_of_4/test.log
  /root/.cache/bazel/_bazel_root/db210f68f81d95ddcca9ae96b16ed72c/execroot/org_tensorflow/bazel-out/aarch64-opt/testlogs/tensorflow/tools/docs/tf_doctest/shard_1_of_4/test_attempts/attempt_1.log
  /root/.cache/bazel/_bazel_root/db210f68f81d95ddcca9ae96b16ed72c/execroot/org_tensorflow/bazel-out/aarch64-opt/testlogs/tensorflow/tools/docs/tf_doctest/shard_1_of_4/test_attempts/attempt_2.log
  /root/.cache/bazel/_bazel_root/db210f68f81d95ddcca9ae96b16ed72c/execroot/org_tensorflow/bazel-out/aarch64-opt/testlogs/tensorflow/tools/docs/tf_doctest/shard_2_of_4/test.log
  /root/.cache/bazel/_bazel_root/db210f68f81d95ddcca9ae96b16ed72c/execroot/org_tensorflow/bazel-out/aarch64-opt/testlogs/tensorflow/tools/docs/tf_doctest/shard_2_of_4/test_attempts/attempt_1.log
  /root/.cache/bazel/_bazel_root/db210f68f81d95ddcca9ae96b16ed72c/execroot/org_tensorflow/bazel-out/aarch64-opt/testlogs/tensorflow/tools/docs/tf_doctest/shard_2_of_4/test_attempts/attempt_2.log

INFO: Build completed, 1 test FAILED, 3147 total actions
```
</details>"
56077,Breaking change in protobuf v4.21.0-rc1 breaks `import tensorflow`,"### Issue Type

Bug

### Source

binary

### Tensorflow Version

tf 2.9.0-rc2

### Custom Code

No

### OS Platform and Distribution

Linux Ubuntu 20.04

### Mobile device

_No response_

### Python version

3.10

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

This issue is to give a warning (that might already be known in internal CI) that [`protobuf` `v4.21.0-rc1`](https://github.com/protocolbuffers/protobuf/releases/tag/v21.0-rc1) which was released today (2022-05-11) causes breaking changes in messages between Python and C++ that affect TensorFlow and will crash with

```pytb
AttributeError: module 'google._upb._message' has no attribute 'Message'. Did you mean: 'CMessage'?
```

on `import tensorflow`.

This is somewhat noted in the `protobuf` release notes for Python

> The C extension module for Python has been rewritten to use the upb library. This is expected to deliver significant performance benefits, especially when parsing large payloads. There are some minor breaking changes, but these should not impact most users. For more information see: https://developers.google.com/protocol-buffers/docs/news/2022-05-06#python-updates

where the [Python Updates notes](https://developers.google.com/protocol-buffers/docs/news/2022-05-06#python-updates) mentions

> Applications that rely on sharing messages between Python and C++ break in the new version. Most developers won't be affected by this, but users of `Nucleus{.external}` and possibly other libraries may be. As a workaround, you can [set an environment variable](https://developers.google.com/protocol-buffers/docs/reference/python-generated#sharing-messages) that forces the library to preserve compatibility.

which finally in [Sharing Messages Between Python and C++](https://developers.google.com/protocol-buffers/docs/reference/python-generated#sharing-messages) tells us that

> Prior to Python 4.21.0, Python apps could share messages with C++ using a native extension. Starting in Python 4.21.0, sharing messages between Python and C++ is not supported by the default install. To enable this capability when working with 4.x and later versions of the Python API, define the environment variable, `PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=cpp`, and ensure that the Python/C++ extension is installed.

However,

```console
$ export PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=cpp
```

just now leads to an

```pytb
ImportError: cannot import name '_message' from 'google.protobuf.pyext' (/venv/lib/python3.10/site-packages/google/protobuf/pyext/__init__.py)
```

Additionally tagging @deannagarcia who released [`protobuf` `v4.21.0-rc1`](https://github.com/protocolbuffers/protobuf/releases/tag/v21.0-rc1).

This was noticed in `pyhf`'s nightly [pre-release and HEAD of dependencies CI jobs](https://github.com/scikit-hep/pyhf/runs/6398925572?check_suite_focus=true).

### Standalone code to reproduce the issue

Here's a `python:3.10` Docker image example

<details>
<summary>Click to exapnd:</summary>

```console
$ docker run --rm -ti python:3.10 /bin/bash
root@a0c6928654f7:/# python -m venv venv && . venv/bin/activate
(venv) root@a0c6928654f7:/# python -m pip --quiet install --upgrade pip setuptools wheel
(venv) root@a0c6928654f7:/# python -m pip --quiet install 'tensorflow==2.8.0'  # First show this with stable release v2.8.0
(venv) root@a0c6928654f7:/# python -m pip list | grep 'tensorflow\|protobuf'
protobuf                     3.20.1
tensorflow                   2.8.0
tensorflow-io-gcs-filesystem 0.25.0
(venv) root@a0c6928654f7:/# python -c 'import tensorflow; print(tensorflow.__version__)'
2022-05-12 03:21:47.631420: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2022-05-12 03:21:47.631464: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2.8.0
(venv) root@a0c6928654f7:/# python -m pip --quiet install --pre --upgrade protobuf
(venv) root@a0c6928654f7:/# python -m pip show protobuf
Name: protobuf
Version: 4.21.0rc1
Summary: 
Home-page: 
Author: 
Author-email: 
License: 
Location: /venv/lib/python3.10/site-packages
Requires: 
Required-by: tensorboard, tensorflow
(venv) root@a0c6928654f7:/# python -c 'import tensorflow'
2022-05-12 03:23:19.770470: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2022-05-12 03:23:19.770491: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
Traceback (most recent call last):
  File ""<string>"", line 1, in <module>
  File ""/venv/lib/python3.10/site-packages/tensorflow/__init__.py"", line 37, in <module>
    from tensorflow.python.tools import module_util as _module_util
  File ""/venv/lib/python3.10/site-packages/tensorflow/python/__init__.py"", line 37, in <module>
    from tensorflow.python.eager import context
  File ""/venv/lib/python3.10/site-packages/tensorflow/python/eager/context.py"", line 29, in <module>
    from tensorflow.core.framework import function_pb2
  File ""/venv/lib/python3.10/site-packages/tensorflow/core/framework/function_pb2.py"", line 16, in <module>
    from tensorflow.core.framework import attr_value_pb2 as tensorflow_dot_core_dot_framework_dot_attr__value__pb2
  File ""/venv/lib/python3.10/site-packages/tensorflow/core/framework/attr_value_pb2.py"", line 16, in <module>
    from tensorflow.core.framework import tensor_pb2 as tensorflow_dot_core_dot_framework_dot_tensor__pb2
  File ""/venv/lib/python3.10/site-packages/tensorflow/core/framework/tensor_pb2.py"", line 16, in <module>
    from tensorflow.core.framework import resource_handle_pb2 as tensorflow_dot_core_dot_framework_dot_resource__handle__pb2
  File ""/venv/lib/python3.10/site-packages/tensorflow/core/framework/resource_handle_pb2.py"", line 16, in <module>
    from tensorflow.core.framework import tensor_shape_pb2 as tensorflow_dot_core_dot_framework_dot_tensor__shape__pb2
  File ""/venv/lib/python3.10/site-packages/tensorflow/core/framework/tensor_shape_pb2.py"", line 36, in <module>
    _descriptor.FieldDescriptor(
  File ""/venv/lib/python3.10/site-packages/google/protobuf/descriptor.py"", line 560, in __new__
    _message.Message._CheckCalledFromGeneratedFile()
AttributeError: module 'google._upb._message' has no attribute 'Message'. Did you mean: 'CMessage'?
(venv) root@a0c6928654f7:/# export PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=cpp  # try protobuf environment variable suggestion
(venv) root@a0c6928654f7:/# python -c 'import tensorflow'
2022-05-12 03:23:50.884921: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2022-05-12 03:23:50.884945: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
/venv/lib/python3.10/site-packages/google/protobuf/internal/api_implementation.py:109: UserWarning: Selected implementation cpp is not available.
  warnings.warn(
Traceback (most recent call last):
  File ""<string>"", line 1, in <module>
  File ""/venv/lib/python3.10/site-packages/tensorflow/__init__.py"", line 37, in <module>
    from tensorflow.python.tools import module_util as _module_util
  File ""/venv/lib/python3.10/site-packages/tensorflow/python/__init__.py"", line 37, in <module>
    from tensorflow.python.eager import context
  File ""/venv/lib/python3.10/site-packages/tensorflow/python/eager/context.py"", line 29, in <module>
    from tensorflow.core.framework import function_pb2
  File ""/venv/lib/python3.10/site-packages/tensorflow/core/framework/function_pb2.py"", line 7, in <module>
    from google.protobuf import descriptor as _descriptor
  File ""/venv/lib/python3.10/site-packages/google/protobuf/descriptor.py"", line 51, in <module>
    from google.protobuf.pyext import _message
ImportError: cannot import name '_message' from 'google.protobuf.pyext' (/venv/lib/python3.10/site-packages/google/protobuf/pyext/__init__.py)
(venv) root@a0c6928654f7:/# unset PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION
(venv) root@a0c6928654f7:/# python -m pip --quiet install --pre --upgrade tensorflow  # Try release candidate v2.9.0-rc2
(venv) root@a0c6928654f7:/# python -m pip show tensorflow
Name: tensorflow
Version: 2.9.0rc2
Summary: TensorFlow is an open source machine learning framework for everyone.
Home-page: https://www.tensorflow.org/
Author: Google Inc.
Author-email: packages@tensorflow.org
License: Apache 2.0
Location: /venv/lib/python3.10/site-packages
Requires: absl-py, astunparse, flatbuffers, gast, google-pasta, grpcio, h5py, keras, keras-preprocessing, libclang, numpy, opt-einsum, packaging, protobuf, setuptools, six, tensorboard, tensorflow-estimator, tensorflow-io-gcs-filesystem, termcolor, typing-extensions, wrapt
Required-by
(venv) root@a0c6928654f7:/# python -c 'import tensorflow'
2022-05-12 03:26:20.957106: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2022-05-12 03:26:20.957131: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
Traceback (most recent call last):
  File ""<string>"", line 1, in <module>
  File ""/venv/lib/python3.10/site-packages/tensorflow/__init__.py"", line 37, in <module>
    from tensorflow.python.tools import module_util as _module_util
  File ""/venv/lib/python3.10/site-packages/tensorflow/python/__init__.py"", line 37, in <module>
    from tensorflow.python.eager import context
  File ""/venv/lib/python3.10/site-packages/tensorflow/python/eager/context.py"", line 29, in <module>
    from tensorflow.core.framework import function_pb2
  File ""/venv/lib/python3.10/site-packages/tensorflow/core/framework/function_pb2.py"", line 16, in <module>
    from tensorflow.core.framework import attr_value_pb2 as tensorflow_dot_core_dot_framework_dot_attr__value__pb2
  File ""/venv/lib/python3.10/site-packages/tensorflow/core/framework/attr_value_pb2.py"", line 16, in <module>
    from tensorflow.core.framework import tensor_pb2 as tensorflow_dot_core_dot_framework_dot_tensor__pb2
  File ""/venv/lib/python3.10/site-packages/tensorflow/core/framework/tensor_pb2.py"", line 16, in <module>
    from tensorflow.core.framework import resource_handle_pb2 as tensorflow_dot_core_dot_framework_dot_resource__handle__pb2
  File ""/venv/lib/python3.10/site-packages/tensorflow/core/framework/resource_handle_pb2.py"", line 16, in <module>
    from tensorflow.core.framework import tensor_shape_pb2 as tensorflow_dot_core_dot_framework_dot_tensor__shape__pb2
  File ""/venv/lib/python3.10/site-packages/tensorflow/core/framework/tensor_shape_pb2.py"", line 36, in <module>
    _descriptor.FieldDescriptor(
  File ""/venv/lib/python3.10/site-packages/google/protobuf/descriptor.py"", line 560, in __new__
    _message.Message._CheckCalledFromGeneratedFile()
AttributeError: module 'google._upb._message' has no attribute 'Message'. Did you mean: 'CMessage'?
(venv) root@a0c6928654f7:/# export PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=cpp
(venv) root@a0c6928654f7:/# python -c 'import tensorflow'
2022-05-12 03:27:01.166115: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2022-05-12 03:27:01.166141: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
/venv/lib/python3.10/site-packages/google/protobuf/internal/api_implementation.py:109: UserWarning: Selected implementation cpp is not available.
  warnings.warn(
Traceback (most recent call last):
  File ""<string>"", line 1, in <module>
  File ""/venv/lib/python3.10/site-packages/tensorflow/__init__.py"", line 37, in <module>
    from tensorflow.python.tools import module_util as _module_util
  File ""/venv/lib/python3.10/site-packages/tensorflow/python/__init__.py"", line 37, in <module>
    from tensorflow.python.eager import context
  File ""/venv/lib/python3.10/site-packages/tensorflow/python/eager/context.py"", line 29, in <module>
    from tensorflow.core.framework import function_pb2
  File ""/venv/lib/python3.10/site-packages/tensorflow/core/framework/function_pb2.py"", line 7, in <module>
    from google.protobuf import descriptor as _descriptor
  File ""/venv/lib/python3.10/site-packages/google/protobuf/descriptor.py"", line 51, in <module>
    from google.protobuf.pyext import _message
ImportError: cannot import name '_message' from 'google.protobuf.pyext' (/venv/lib/python3.10/site-packages/google/protobuf/pyext/__init__.py)
```

</details>

### Relevant log output

```pytb
Traceback (most recent call last):
  File ""<string>"", line 1, in <module>
  File ""/venv/lib/python3.10/site-packages/tensorflow/__init__.py"", line 37, in <module>
    from tensorflow.python.tools import module_util as _module_util
  File ""/venv/lib/python3.10/site-packages/tensorflow/python/__init__.py"", line 37, in <module>
    from tensorflow.python.eager import context
  File ""/venv/lib/python3.10/site-packages/tensorflow/python/eager/context.py"", line 29, in <module>
    from tensorflow.core.framework import function_pb2
  File ""/venv/lib/python3.10/site-packages/tensorflow/core/framework/function_pb2.py"", line 16, in <module>
    from tensorflow.core.framework import attr_value_pb2 as tensorflow_dot_core_dot_framework_dot_attr__value__pb2
  File ""/venv/lib/python3.10/site-packages/tensorflow/core/framework/attr_value_pb2.py"", line 16, in <module>
    from tensorflow.core.framework import tensor_pb2 as tensorflow_dot_core_dot_framework_dot_tensor__pb2
  File ""/venv/lib/python3.10/site-packages/tensorflow/core/framework/tensor_pb2.py"", line 16, in <module>
    from tensorflow.core.framework import resource_handle_pb2 as tensorflow_dot_core_dot_framework_dot_resource__handle__pb2
  File ""/venv/lib/python3.10/site-packages/tensorflow/core/framework/resource_handle_pb2.py"", line 16, in <module>
    from tensorflow.core.framework import tensor_shape_pb2 as tensorflow_dot_core_dot_framework_dot_tensor__shape__pb2
  File ""/venv/lib/python3.10/site-packages/tensorflow/core/framework/tensor_shape_pb2.py"", line 36, in <module>
    _descriptor.FieldDescriptor(
  File ""/venv/lib/python3.10/site-packages/google/protobuf/descriptor.py"", line 560, in __new__
    _message.Message._CheckCalledFromGeneratedFile()
AttributeError: module 'google._upb._message' has no attribute 'Message'. Did you mean: 'CMessage'?
```

```pytb
/venv/lib/python3.10/site-packages/google/protobuf/internal/api_implementation.py:109: UserWarning: Selected implementation cpp is not available.
  warnings.warn(
Traceback (most recent call last):
  File ""<string>"", line 1, in <module>
  File ""/venv/lib/python3.10/site-packages/tensorflow/__init__.py"", line 37, in <module>
    from tensorflow.python.tools import module_util as _module_util
  File ""/venv/lib/python3.10/site-packages/tensorflow/python/__init__.py"", line 37, in <module>
    from tensorflow.python.eager import context
  File ""/venv/lib/python3.10/site-packages/tensorflow/python/eager/context.py"", line 29, in <module>
    from tensorflow.core.framework import function_pb2
  File ""/venv/lib/python3.10/site-packages/tensorflow/core/framework/function_pb2.py"", line 7, in <module>
    from google.protobuf import descriptor as _descriptor
  File ""/venv/lib/python3.10/site-packages/google/protobuf/descriptor.py"", line 51, in <module>
    from google.protobuf.pyext import _message
ImportError: cannot import name '_message' from 'google.protobuf.pyext' (/venv/lib/python3.10/site-packages/google/protobuf/pyext/__init__.py)
```"
56075,Converted tflite file is 30x the size of the original SavedModel,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

v2.8.0-0-g3f878cff5b6 2.8.0

### Custom Code

Yes

### OS Platform and Distribution

Linux Ubuntu 18.04.5

### Mobile device

Linux Ubuntu 18.04.5

### Python version

3.7.13

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

A SavedModel that is about 4mb turns into a 125mb model when converted into the tflite format.


### Standalone code to reproduce the issue

Minimal Google Colab replication: https://colab.research.google.com/drive/1D25Czt1yKmguObbVVp4eqkfdVKRTh9jA

```python
!wget https://huggingface.co/rocca/lit-web/resolve/main/debug/lit_savedmodel_no_params.zip
!unzip lit_savedmodel_no_params.zip

import tensorflow as tf

folder_name = ""lit_savedmodel""

converter = tf.lite.TFLiteConverter.from_saved_model(folder_name)
tflite_model = converter.convert()

with open(folder_name+'.tflite', 'wb') as f:
  f.write(tflite_model)
```

* Input SavedModel: https://huggingface.co/rocca/lit-web/resolve/main/debug/lit_savedmodel_no_params.zip
* Output TFLite file: https://huggingface.co/rocca/lit-web/resolve/main/debug/lit_savedmodel_no_params.tflite


### Relevant log output

_No response_</details>"
56065,Model fails to predict using float16,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Support

### Source

source

### Tensorflow Version

tf 2.8.0

### Custom Code

Yes

### OS Platform and Distribution

Linux Ubuntu 18.04

### Mobile device

_No response_

### Python version

3.9

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
I'm trying to build a model that uses `float16` in the inputs and outputs. However, I've noticed that none of the toy examples I've tried seems to work.
```


### Standalone code to reproduce the issue


For instance, the model below gives `NaN`:

```python
def total_variation(im1):
    score = tf.image.total_variation(im1)
    return tf.cast(score, tf.float16)

input1 = tf.keras.Input(shape=(512,512,3), batch_size=1, dtype=tf.float16)
output = total_variation(input1)
matrix1 = np.arange(512*512*3,dtype='float16').reshape(1,512,512,3)
model = tf.keras.Model(inputs=[input1], outputs=output, name='test')
x = model.predict([matrix1])
x # NaN
```

However, the following gives the correct result:

```python
def total_variation(im1):
    score = tf.image.total_variation(im1)
    return tf.cast(score, tf.float32)

input1 = tf.keras.Input(shape=(512,512,3), batch_size=1, dtype=tf.float32)
output = total_variation(input1)
matrix1 = np.arange(512*512*3,dtype='float32').reshape(1,512,512,3)
model = tf.keras.Model(inputs=[input1], outputs=output, name='test')
x = model.predict([matrix1])
x # array([1.207955e+09], dtype=float32)
```

Same result if `tf.keras.backend.set_floatx('float16')` was called instead. Does anyone know why this might be the case?
```


### Relevant log output

_No response_</details>"
56063,How to do partial checkpoint restore from different architectures in tensorflow 2,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Support

### Source

source

### Tensorflow Version

2.8

### Custom Code

No

### Python version

3.9

### Current Behaviour?

Hi, 

I trained a resnet model whose final layer has 3 outputs (multiclass classification). I want to use these model weights to pretrain a regression model which has the exact same architecture except the last layer, which has 1 output. 

This seems like a very basic use case, but I do not see how to do this. Restoring a checkpoint gives an error since the architectures are not the same (mismatched shape). All other solutions I have found are either for TF1 (eg https://innerpeace-wu.github.io/2017/12/13/Tensorflow-Restore-partial-weights/) or using Keras .h5 restore. 

How can I do this in TF2?

</details>"
56061,TFLite C API building in linux didnt create .a files,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Build/Install

### Source

source

### Tensorflow Version

2.8

### Custom Code

Yes

### OS Platform and Distribution

Ubuntu 20.04

### Mobile device

_No response_

### Python version

3.9

### Bazel version

5.0.0

### GCC/Compiler version

9.3

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
I've added a custom OP code from mediapipe to tensorflow code and when i build it using 

""bazel build --java_runtime_version=remotejdk_11 -c opt --define=no_tensorflow_py_deps=true --define tflite_with_xnnpack=true //tensorflow/lite/c:libtensorflowlite_c.so""

.so file is created and i can use it for general tflite code but no custom op, in mac/windows in addition to .dylib/.dll it'll also produce .a/.lib for the external libs (absl/flatbuffers etc..) and for mediapipe/delegates which i need for linking against my project.

so my question is, there is a way to produce those static libs in addition to the .so file?
```


### Standalone code to reproduce the issue

```shell
""bazel build --java_runtime_version=remotejdk_11 -c opt --define=no_tensorflow_py_deps=true --define tflite_with_xnnpack=true //tensorflow/lite/c:libtensorflowlite_c.so""

""bazel build --java_runtime_version=remotejdk_11 -c opt --define=no_tensorflow_py_deps=true --define tflite_with_xnnpack=true //tensorflow/lite/c:libtensorflowlite_c.dylib""

""bazel build --java_runtime_version=remotejdk_11 -c opt --define=no_tensorflow_py_deps=true --define tflite_with_xnnpack=true //tensorflow/lite/c:tensorflowlite_c.dll""
```


### Relevant log output

_No response_</details>"
56059,"Tensorflow 2.8.0 autograph transformation failure,  issues with : 'arguments' object has no attribute 'posonlyargs' and, decorate the function with @tf.autograph.experimental.do_not_convert","Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1.  It must be a bug, a feature request, or a significant problem with the
    documentation (for small docs fixes please send a PR instead).
2.  The form below must be filled out.
3.  It shouldn't be a TensorBoard issue. Those go
    [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information

-   **Have I written custom code (as opposed to using a stock example script
    provided in TensorFlow)**: yes, based on this tutorial : https://github.com/nmarincic/machineintelligence/blob/master/Exercise%2014%20-%20Classifying%20Hand-Written%20Digits.ipynb
-   **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10
-   **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue
    happens on a mobile device**:
-   **TensorFlow installed from (source or binary)**: source
-   **TensorFlow version (use command below)**: 2.8.0
-   **Python version**: 3.7.3
-   **Bazel version (if compiling from source)**:
-   **GCC/Compiler version (if compiling from source)**:
-   **CUDA/cuDNN version**:
-   **GPU model and memory**: Intel(R) HD Graphics , VRAM 64MB
-   **Exact command to reproduce**: Running code

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with:

```bash
python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""
```

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

tensorflow asked me to report a bug

Epoch 1/8
WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000243655EB048> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: 'arguments' object has no attribute 'posonlyargs'
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000243655EB048> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: 'arguments' object has no attribute 'posonlyargs'
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
~\AppData\Local\Temp\ipykernel_14688\4246955696.py in <module>
      7                 train_labels_new,
      8                 validation_data=(validation_data,validation_labels_new),
----> 9                 epochs=8
     10                 )
     11 

~\Anaconda3\lib\site-packages\keras\utils\traceback_utils.py in error_handler(*args, **kwargs)
     65     except Exception as e:  # pylint: disable=broad-except
     66       filtered_tb = _process_traceback_frames(e.__traceback__)
---> 67       raise e.with_traceback(filtered_tb) from None
     68     finally:
     69       del filtered_tb

~\Anaconda3\lib\site-packages\keras\metrics.py in sparse_categorical_accuracy(y_true, y_pred)
   4076   if (y_true_rank is not None) and (y_pred_rank is not None) and (len(
   4077       backend.int_shape(y_true)) == len(backend.int_shape(y_pred))):
-> 4078     y_true = tf.squeeze(y_true, [-1])
   4079   y_pred = tf.compat.v1.argmax(y_pred, axis=-1)
   4080 

ValueError: Can not squeeze dim[1], expected a dimension of 1, got 10 for '{{node Squeeze}} = Squeeze[T=DT_FLOAT, squeeze_dims=[-1]](remove_squeezable_dimensions/Squeeze)' with input shapes: [?,10].


### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.

%config InlineBackend.figure_format = 'retina'
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import numpy as np
np.set_printoptions(precision=3)
np.set_printoptions(suppress=True)

import tensorflow as tf

from tensorflow.keras.datasets import mnist

dataset=mnist.load_data()

(train_data, train_labels), (validation_data,validation_labels) = dataset

test_data  = train_data[-10000:]
test_labels = train_labels[-10000:]
train_data = train_data[:50000]
train_labels = train_labels[:50000]

train_data = train_data / 255.0
validation_data = validation_data / 255.0
test_data = test_data / 255.0

dp = train_data[0].reshape(28*28,1)

train_data = np.array([dp.reshape(784,1) for dp in train_data])
validation_data = np.array([dp.reshape(784,1) for dp in validation_data])
test_data = np.array([dp.reshape(784,1) for dp in test_data])

def convert_label(x):
    vec = np.zeros((10,1))
    vec[x]=1
    return vec
	
train_labels_new = np.array([convert_label(l) for l in train_labels])
validation_labels_new = np.array([convert_label(l) for l in validation_labels])
test_labels_new = np.array([convert_label(l) for l in test_labels])

train_set = np.array(list(zip(train_data, train_labels_new)), dtype=object)
validation_set = np.array(list(zip(validation_data, validation_labels_new)), dtype=object)
testing_set = np.array(list(zip(test_data, test_labels_new)), dtype=object)

model = tf.keras.models.Sequential([
  tf.keras.layers.Flatten(input_shape=(784,1)),
  tf.keras.layers.Dense(100, activation='sigmoid'),
  tf.keras.layers.Dense(10, activation='sigmoid')
])

model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate = 3.0),
              loss='mse',
              metrics=['accuracy'])

history = model.fit(train_data,
                train_labels_new, 
                validation_data=(validation_data,validation_labels_new),
                epochs=8
                )
    "
56058,TFLite object detection returns different output when set num_threads=2,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

tf 2.8

### Custom Code

Yes

### OS Platform and Distribution

Linux (google colab)

### Mobile device

_No response_

### Python version

Python 3.7.13

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
I used TFLite2.8 to infer an object detection model (the model's name is efficientdet-lite2 which is trained by TFLite Model Maker, the number of classes is 3).

In the experiments, I use an image as input, set the num_threads equals 1 and 2 and got two different outputs. 
Summary:
 - with num_threads=2, It seems the last classes (id=2) are not detected. 
 - Only num_threads=2 shows different results
 - I used regular NMS for post processing

Could you please look to this issue? Thanks.
```


### Standalone code to reproduce the issue

```shell
You can check the demo here:

https://github.com/Soba-Mask/TFLite-efficientdet/blob/main/TFLite_EfficientDet.ipynb
```


### Relevant log output

```shell
With num_threads=1

[{'bounding_box': array([-0.01516247,  0.22502708,  1.0412507 ,  0.54143524], dtype=float32), 'class_id': 2.0, 'score': 0.79296875}, {'bounding_box': array([0.03634   , 0.16444701, 0.99371195, 0.78906894], dtype=float32), 'class_id': 1.0, 'score': 0.703125}, {'bounding_box': array([0.00143668, 0.22852634, 0.8992057 , 0.47540623], dtype=float32), 'class_id': 1.0, 'score': 0.6875}, {'bounding_box': array([0.03634   , 0.16444701, 0.99371195, 0.78906894], dtype=float32), 'class_id': 2.0, 'score': 0.6328125}, {'bounding_box': array([0.46674758, 0.82076466, 1.042562  , 0.9846126 ], dtype=float32), 'class_id': 1.0, 'score': 0.6328125}, {'bounding_box': array([-0.01516247,  0.22502708,  1.0412507 ,  0.54143524], dtype=float32), 'class_id': 0.0, 'score': 0.59765625}, {'bounding_box': array([-0.05422914,  0.25673673,  1.0870984 ,  0.7988932 ], dtype=float32), 'class_id': 0.0, 'score': 0.59765625}, {'bounding_box': array([-0.09049654,  0.49012125,  1.0904965 ,  0.9169613 ], dtype=float32), 'class_id': 1.0, 'score': 0.421875}, {'bounding_box': array([0.54165643, 0.6360628 , 0.9419227 , 0.9792904 ], dtype=float32), 'class_id': 1.0, 'score': 0.421875}, {'bounding_box': array([0.46674758, 0.82076466, 1.042562  , 0.9846126 ], dtype=float32), 'class_id': 0.0, 'score': 0.40234375}, {'bounding_box': array([0.46674758, 0.82076466, 1.042562  , 0.9846126 ], dtype=float32), 'class_id': 2.0, 'score': 0.3671875}, {'bounding_box': array([0.18799314, 0.02530569, 0.8793888 , 1.0420763 ], dtype=float32), 'class_id': 1.0, 'score': 0.3671875}, {'bounding_box': array([-0.05960798,  0.6126696 ,  1.0335196 ,  0.94571483], dtype=float32), 'class_id': 0.0, 'score': 0.3671875}, {'bounding_box': array([-0.01747626,  0.11870687,  1.0944843 ,  0.4142177 ], dtype=float32), 'class_id': 2.0, 'score': 0.33203125}, {'bounding_box': array([0.06257483, 0.17665143, 0.5709784 , 0.5083512 ], dtype=float32), 'class_id': 1.0, 'score': 0.3125}, {'bounding_box': array([0.5273802, 0.4102384, 0.9415574, 0.8315512], dtype=float32), 'class_id': 1.0, 'score': 0.3125}, {'bounding_box': array([0.54165643, 0.6360628 , 0.9419227 , 0.9792904 ], dtype=float32), 'class_id': 0.0, 'score': 0.3125}]

INFO: Created TensorFlow Lite XNNPACK delegate for CPU.



With num_threads=2

[{'bounding_box': array([0.03634   , 0.16444701, 0.99371195, 0.78906894], dtype=float32), 'class_id': 1.0, 'score': 0.703125}, {'bounding_box': array([0.00143668, 0.22852634, 0.8992057 , 0.47540623], dtype=float32), 'class_id': 1.0, 'score': 0.6875}, {'bounding_box': array([0.46674758, 0.82076466, 1.042562  , 0.9846126 ], dtype=float32), 'class_id': 1.0, 'score': 0.6328125}, {'bounding_box': array([-0.01516247,  0.22502708,  1.0412507 ,  0.54143524], dtype=float32), 'class_id': 0.0, 'score': 0.59765625}, {'bounding_box': array([-0.05422914,  0.25673673,  1.0870984 ,  0.7988932 ], dtype=float32), 'class_id': 0.0, 'score': 0.59765625}, {'bounding_box': array([-0.09049654,  0.49012125,  1.0904965 ,  0.9169613 ], dtype=float32), 'class_id': 1.0, 'score': 0.421875}, {'bounding_box': array([0.54165643, 0.6360628 , 0.9419227 , 0.9792904 ], dtype=float32), 'class_id': 1.0, 'score': 0.421875}, {'bounding_box': array([0.46674758, 0.82076466, 1.042562  , 0.9846126 ], dtype=float32), 'class_id': 0.0, 'score': 0.40234375}, {'bounding_box': array([0.18799314, 0.02530569, 0.8793888 , 1.0420763 ], dtype=float32), 'class_id': 1.0, 'score': 0.3671875}, {'bounding_box': array([-0.05960798,  0.6126696 ,  1.0335196 ,  0.94571483], dtype=float32), 'class_id': 0.0, 'score': 0.3671875}, {'bounding_box': array([0.06257483, 0.17665143, 0.5709784 , 0.5083512 ], dtype=float32), 'class_id': 1.0, 'score': 0.3125}, {'bounding_box': array([0.5273802, 0.4102384, 0.9415574, 0.8315512], dtype=float32), 'class_id': 1.0, 'score': 0.3125}, {'bounding_box': array([0.54165643, 0.6360628 , 0.9419227 , 0.9792904 ], dtype=float32), 'class_id': 0.0, 'score': 0.3125}]

INFO: Created TensorFlow Lite XNNPACK delegate for CPU.
```
</details>"
56057,No matching distribution found for tensorflow==2.5.3,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Build/Install

### Source

binary

### Tensorflow Version

tensorflow 2.5.3

### Custom Code

Yes

### OS Platform and Distribution

Ubuntu 18.04 and Monterey 12.3.1

### Mobile device

_No response_

### Python version

3.7/3.8

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

I was trying to install tensorflow 2.5.3 by doing pip install as below, but it failed with no matching version 
```
$ pip install tensorflow==2.5.3
ERROR: Could not find a version that satisfies the requirement tensorflow==2.5.3
ERROR: No matching distribution found for tensorflow==2.5.3
```
However, I do see 2.5.3 is a Pypi public released version https://pypi.org/project/tensorflow/2.5.3/


### Standalone code to reproduce the issue

```
$ pip install tensorflow==2.5.3
ERROR: Could not find a version that satisfies the requirement tensorflow==2.5.3
ERROR: No matching distribution found for tensorflow==2.5.3
```


### Relevant log output

_No response_</details>"
56054,Cannot load_weights with keras StringLookup layer,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

tf 2.8

### Custom Code

No

### OS Platform and Distribution

macOS Monterey

### Mobile device

_No response_

### Python version

3.7.13

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
I am unable to reload the vocabulary of an adapted StringLookup layer by using the {save/load}_weights api of a subclassed keras Model.
```


### Standalone code to reproduce the issue

```shell
import tensorflow as tf
class TestModel(tf.keras.models.Model):
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.sl = tf.keras.layers.StringLookup()
        
    def adapt(self, df):
        self.sl.adapt(df)
    
        
    def call(self, x):
        return self.sl(x)

inp = tf.repeat(tf.constant(['A', 'B', 'C']), 10)
df_inp = tf.data.Dataset.from_tensor_slices(inp)

test_model  = TestModel()
test_model.adapt(df_inp)
print(test_model.get_weights())

'[array([b'C', b'B', b'A'], dtype=object)]'

test_model.save_weights('tmp/check_weights')

test_model_recon = TestModel()
test_model_recon.load_weights('tmp/check_weights')
print(test_model_recon.get_weights())

'[array([], dtype=object)]'
```


### Relevant log output

_No response_</details>"
56049,How to update .tflite ,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Support

### Source

source

### Tensorflow Version

Tflite

### Custom Code

No

### OS Platform and Distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
How to update tflite i.e after training and exporting , how to add more models in it. Instead of training whole model from first.
```


### Standalone code to reproduce the issue

```shell
Example : https://colab.research.google.com/github/khanhlvg/tflite_raspberry_pi/blob/main/object_detection/Train_custom_model_tutorial.ipynb#scrollTo=l4QQTXHHATDS
```


### Relevant log output

_No response_</details>"
56048,"The TensorFlow library was compiled to use SSE4.1 instructions, but these aren't available on your machine.","<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Build/Install

### Source

source

### Tensorflow Version

tf2.9

### Custom Code

No

### OS Platform and Distribution

ubuntu20

### Mobile device

ubuntu20

### Python version

3.7

### Bazel version

bazel-5.1.1

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
我的服务器执行shell命令：test@test-VirtualBox:~$ cat /proc/cpuinfo    显示如下指令信息：
flags  : fpu de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pse36 clflush mmx fxsr sse sse2 syscall nx lm rep_good nopl pni cx16 hypervisor lahf_lm abm
 如下该如何输入配置：
Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -Wno-sign-compare]:
 如下该如何输入配置：
./bazel-5.1.1-linux-x86_64 build --config=v1 --copt=-mavx --copt=-mavx2 --copt=-msse --copt=-msse2 --copt=-mssse3   -k //tensorflow/tools/pip_package:build_pip_package
```


### Standalone code to reproduce the issue

```shell
test@test-VirtualBox:/home/soft/tensorflow-master$  ./configure

Found possible Python library paths:
  /home/soft/anaconda3/envs/tf2/lib/python3.7/site-packages
Please input the desired Python library path to use.  Default is [/home/soft/anaconda3/envs/tf2/lib/python3.7/site-packages]

Do you wish to build TensorFlow with ROCm support? [y/N]: n
No ROCm support will be enabled for TensorFlow.

Do you wish to build TensorFlow with CUDA support? [y/N]: n
No CUDA support will be enabled for TensorFlow.

Do you wish to download a fresh release of clang? (Experimental) [y/N]: n
Clang will not be downloaded.

Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -Wno-sign-compare]:


Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: n


test@test-VirtualBox:/home/soft/tensorflow-master$ ./bazel-5.1.1-linux-x86_64 build --config=v1 --copt=-mavx --copt=-mavx2 --copt=-msse --copt=-msse2 --copt=-mssse3   -k //tensorflow/tools/pip_package:build_pip_package



=======================
我咨询的问题是：我应该如何选择配置才能支持我的服务器cpu（flags  : fpu de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pse36 clflush mmx fxsr sse sse2 syscall nx lm rep_good nopl pni cx16 hypervisor lahf_lm abm）
```


### Relevant log output

_No response_</details>"
56046,"Test for TStrings of type ""Offset"" returns incorrect size on s390x arch ","<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

2.8.0

### Custom Code

No

### OS Platform and Distribution

Linux Ubuntu 20.04

### Mobile device

NA

### Python version

Python 3.8.10

### Bazel version

4.2.2

### GCC/Compiler version

9.4.0

### CUDA/cuDNN version

NA

### GPU model and memory

NA

### Current Behaviour?

```shell
TF_CTStringTest OffsetType fails as size or TF_TSTR_OFFSET are 0 on big endian.
As per analysis done, TF_TString_ToInternalSizeT calls from TF_TString_ResizeUninitialized as well as in test file(https://github.com/tensorflow/tensorflow/blob/v2.8.0/tensorflow/core/platform/ctstring_test.cc#L397) returns a very high number but it is not decoded correctly.
Hence all calls such as TF_TString_GetSize, TF_TString_GetType return value of 0 on s390x.

Expected behaviour: This test should pass on BE systems as well.
```


### Standalone code to reproduce the issue

```shell
On s390x, run:
`bazel --host_jvm_args=""-Xms1024m"" --host_jvm_args=""-Xmx2048m"" test --strip never --jobs=10 --verbose_failures //tensorflow/core/platform:ctstring_test`
```


### Relevant log output

```shell
tensorflow/core/platform/ctstring_test.cc:401: Failure
Expected equality of these values:
  size
    Which is: 8
  TF_TString_GetSize(&s71)
    Which is: 0
tensorflow/core/platform/ctstring_test.cc:402: Failure
Expected equality of these values:
  TF_TSTR_OFFSET
    Which is: 2
  TF_TString_GetType(&s71)
    Which is: 0
[  FAILED  ] TF_CTStringTest.OffsetType (0 ms)
```
```
</details>"
56044,clang.exe: error: no such file or directory: '/d2ReducedOptimizeHugeFunctions',"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Build/Install

### Source

source

### Tensorflow Version

tf2.8

### Custom Code

No

### OS Platform and Distribution

window10 v1709

### Mobile device

android_arm64

### Python version

3.8

### Bazel version

4.2.2

### GCC/Compiler version

14.0.0

### CUDA/cuDNN version

no

### GPU model and memory

no

### Current Behaviour?

```shell
clang.exe: error: no such file or directory: '/d2ReducedOptimizeHugeFunctions'
Target //tensorflow/lite:libtensorflowlite.so failed to build
INFO: Elapsed time: 82.059s, Critical Path: 16.23s
INFO: 145 processes: 109 internal, 36 local.
FAILED: Build did NOT complete successfully
```


### Standalone code to reproduce the issue

```shell
clang version 14.0.0
Target: x86_64-w64-windows-gnu
Thread model: posix
InstalledDir: E:/Program Files/msys64/clang64/bin

(tf2.8) E:\Develop\tflite\tensorflow-2.8.0>bazel version
WARNING: Ignoring JAVA_HOME, because it must point to a JDK, not a JRE.
Build label: 4.2.1
Build target: bazel-out/x64_windows-opt/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar
Build time: Mon Aug 30 15:19:20 2021 (1630336760)
Build timestamp: 1630336760
Build timestamp as int: 1630336760

BAZEL_VC = C:\Program Files (x86)\Microsoft Visual Studio\2019\Enterprise\VC
BAZEL_WINSDK_FULL_VERSION = 10.0.19041.0
BAZEL_VC_FULL_VERSION = 14.29.30133
```


### Relevant log output

```shell
(tf2.8) E:\Develop\tflite\tensorflow-2.8.0>bazel build -c opt //tensorflow/lite:libtensorflowlite.so  --config=android_arm64 --cxxopt=""-std=c++11""  --verbose_failures
WARNING: Ignoring JAVA_HOME, because it must point to a JDK, not a JRE.
INFO: Options provided by the client:
  Inherited 'common' options: --isatty=1 --terminal_columns=120
INFO: Reading rc options for 'build' from e:\develop\tflite\tensorflow-2.8.0\.bazelrc:
  Inherited 'common' options: --experimental_repo_remote_exec
INFO: Options provided by the client:
  'build' options: --python_path=C:/Users/Administrator/Miniconda3/envs/tf2.8/python.exe
INFO: Reading rc options for 'build' from e:\develop\tflite\tensorflow-2.8.0\.bazelrc:
  'build' options: --define framework_shared_object=true --java_toolchain=@tf_toolchains//toolchains/java:tf_java_toolchain --host_java_toolchain=@tf_toolchains//toolchains/java:tf_java_toolchain --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --enable_platform_specific_config --define=with_xla_support=true --config=short_logs --config=v2 --define=no_aws_support=true --define=no_hdfs_support=true --experimental_cc_shared_library
INFO: Reading rc options for 'build' from e:\develop\tflite\tensorflow-2.8.0\.tf_configure.bazelrc:
  'build' options: --action_env PYTHON_BIN_PATH=C:/Users/Administrator/Miniconda3/envs/tf2.8/python.exe --action_env PYTHON_LIB_PATH=C:/Users/Administrator/Miniconda3/envs/tf2.8/lib/site-packages --python_path=C:/Users/Administrator/Miniconda3/envs/tf2.8/python.exe --copt=/d2ReducedOptimizeHugeFunctions --host_copt=/d2ReducedOptimizeHugeFunctions --define=override_eigen_strong_inline=true --action_env ANDROID_NDK_HOME=androidndk --action_env ANDROID_NDK_API_LEVEL=21 --action_env ANDROID_BUILD_TOOLS_VERSION=31.0.0 --action_env ANDROID_SDK_API_LEVEL=31 --action_env ANDROID_SDK_HOME=androidsdk
INFO: Reading rc options for 'build' from e:\develop\tflite\tensorflow-2.8.0\.bazelrc:
  'build' options: --deleted_packages=tensorflow/compiler/mlir/tfrt,tensorflow/compiler/mlir/tfrt/benchmarks,tensorflow/compiler/mlir/tfrt/jit/python_binding,tensorflow/compiler/mlir/tfrt/jit/transforms,tensorflow/compiler/mlir/tfrt/python_tests,tensorflow/compiler/mlir/tfrt/tests,tensorflow/compiler/mlir/tfrt/tests/analysis,tensorflow/compiler/mlir/tfrt/tests/jit,tensorflow/compiler/mlir/tfrt/tests/lhlo_to_tfrt,tensorflow/compiler/mlir/tfrt/tests/tf_to_corert,tensorflow/compiler/mlir/tfrt/tests/tf_to_tfrt_data,tensorflow/compiler/mlir/tfrt/tests/saved_model,tensorflow/compiler/mlir/tfrt/transforms/lhlo_gpu_to_tfrt_gpu,tensorflow/core/runtime_fallback,tensorflow/core/runtime_fallback/conversion,tensorflow/core/runtime_fallback/kernel,tensorflow/core/runtime_fallback/opdefs,tensorflow/core/runtime_fallback/runtime,tensorflow/core/runtime_fallback/util,tensorflow/core/tfrt/common,tensorflow/core/tfrt/eager,tensorflow/core/tfrt/eager/backends/cpu,tensorflow/core/tfrt/eager/backends/gpu,tensorflow/core/tfrt/eager/core_runtime,tensorflow/core/tfrt/eager/cpp_tests/core_runtime,tensorflow/core/tfrt/fallback,tensorflow/core/tfrt/gpu,tensorflow/core/tfrt/run_handler_thread_pool,tensorflow/core/tfrt/runtime,tensorflow/core/tfrt/saved_model,tensorflow/core/tfrt/saved_model/tests,tensorflow/core/tfrt/tpu,tensorflow/core/tfrt/utils
INFO: Found applicable config definition build:short_logs in file e:\develop\tflite\tensorflow-2.8.0\.bazelrc: --output_filter=DONT_MATCH_ANYTHING
INFO: Found applicable config definition build:v2 in file e:\develop\tflite\tensorflow-2.8.0\.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1
INFO: Found applicable config definition build:android_arm64 in file e:\develop\tflite\tensorflow-2.8.0\.bazelrc: --config=android --cpu=arm64-v8a --fat_apk_cpu=arm64-v8a
INFO: Found applicable config definition build:android in file e:\develop\tflite\tensorflow-2.8.0\.bazelrc: --crosstool_top=//external:android/crosstool --host_crosstool_top=@bazel_tools//tools/cpp:toolchain --noenable_platform_specific_config --copt=-w --cxxopt=-std=c++14 --host_cxxopt=-std=c++14 --define=with_xla_support=false
INFO: Analyzed target //tensorflow/lite:libtensorflowlite.so (79 packages loaded, 9053 targets configured).
INFO: Found 1 target...
ERROR: C:/users/administrator/_bazel_administrator/ndqjtql2/external/XNNPACK/BUILD.bazel:6644:19: Compiling src/x32-depthtospace2d-chw2hwc/scalar.c failed: (Exit 1): clang failed: error executing command
  cd C:/users/administrator/_bazel_administrator/ndqjtql2/execroot/org_tensorflow
  SET ANDROID_BUILD_TOOLS_VERSION=31.0.0
    SET ANDROID_NDK_API_LEVEL=21
    SET ANDROID_NDK_HOME=androidndk
    SET ANDROID_SDK_API_LEVEL=31
    SET ANDROID_SDK_HOME=androidsdk
    SET PATH=E:\Program Files\msys64\usr\bin;E:\Program Files\msys64\bin;C:\windows;C:\windows\System32;C:\windows\System32\WindowsPowerShell\v1.0;C:\Users\Administrator\Miniconda3\envs\tf2.8;C:\Users\Administrator\Miniconda3\envs\tf2.8\Library\mingw-w64\bin;C:\Users\Administrator\Miniconda3\envs\tf2.8\Library\usr\bin;C:\Users\Administrator\Miniconda3\envs\tf2.8\Library\bin;C:\Users\Administrator\Miniconda3\envs\tf2.8\Scripts;C:\Users\Administrator\Miniconda3\envs\tf2.8\bin;C:\Users\Administrator\Miniconda3\condabin;C:\windows;C:\windows\system32;C:\windows\System32\Wbem;C:\Program Files\Git\cmd;C:\windows\System32\WindowsPowerShell\v1.0;C:\Program Files (x86)\NVIDIA Corporation\PhysX\Common;C:\Program Files\NVIDIA Corporation\Nsight Compute 2020.2.0;C:\Program Files\NVIDIA Corporation\NVIDIA NvDLISR;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.1\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.1\libnvvp;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.1\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v10.1\libnvvp;C:\Program Files\MATLAB\R2018b\bin;C:\Users\Administrator\Miniconda3;C:\Users\Administrator\Miniconda3\Scripts;E:\Program Files\msys64;E:\Program Files\msys64\usr\bin;E:\Program Files\msys64\clang64\bin;C:\Users\Administrator\AppData\Local\Microsoft\WindowsApps;C:\Users\Administrator\Miniconda3;C:\Users\Administrator\Miniconda3\Scripts;C:\Program Files (x86)\mingw-w64\i686-8.1.0-posix-dwarf-rt_v6-rev0\mingw32\bin;C:\Windows\System32;C:\Users\Administrator\Miniconda3\Library\bin;C:\Program Files\NVIDIA Corporation\NVSMI;C:\Users\Administrator\AppData\Roaming\npm
    SET PWD=/proc/self/cwd
    SET PYTHON_BIN_PATH=C:/Users/Administrator/Miniconda3/envs/tf2.8/python.exe
    SET PYTHON_LIB_PATH=C:/Users/Administrator/Miniconda3/envs/tf2.8/lib/site-packages
    SET RUNFILES_MANIFEST_ONLY=1
    SET TF2_BEHAVIOR=1
  external/androidndk/ndk/toolchains/llvm/prebuilt/windows-x86_64/bin/clang -gcc-toolchain external/androidndk/ndk/toolchains/aarch64-linux-android-4.9/prebuilt/windows-x86_64 -target aarch64-none-linux-android -fpic -isystemexternal/androidndk/ndk/sysroot/usr/include/aarch64-linux-android -D__ANDROID_API__=21 -no-canonical-prefixes -Wno-invalid-command-line-argument -Wno-unused-command-line-argument -funwind-tables -fstack-protector-strong -fno-addrsig -Werror=return-type -Werror=int-to-pointer-cast -Werror=pointer-to-int-cast -Werror=implicit-function-declaration -O2 -g -DNDEBUG -MD -MF bazel-out/arm64-v8a-opt/bin/external/XNNPACK/_objs/scalar_prod_microkernels/3/scalar.pic.d -frandom-seed=bazel-out/arm64-v8a-opt/bin/external/XNNPACK/_objs/scalar_prod_microkernels/3/scalar.pic.o -fPIC -DPTHREADPOOL_NO_DEPRECATED_API -iquote external/XNNPACK -iquote bazel-out/arm64-v8a-opt/bin/external/XNNPACK -iquote external/FP16 -iquote bazel-out/arm64-v8a-opt/bin/external/FP16 -iquote external/FXdiv -iquote bazel-out/arm64-v8a-opt/bin/external/FXdiv -iquote external/pthreadpool -iquote bazel-out/arm64-v8a-opt/bin/external/pthreadpool -iquote external/cpuinfo -iquote bazel-out/arm64-v8a-opt/bin/external/cpuinfo -iquote external/clog -iquote bazel-out/arm64-v8a-opt/bin/external/clog -Ibazel-out/arm64-v8a-opt/bin/external/FP16/_virtual_includes/FP16 -Ibazel-out/arm64-v8a-opt/bin/external/FXdiv/_virtual_includes/FXdiv -Ibazel-out/arm64-v8a-opt/bin/external/pthreadpool/_virtual_includes/pthreadpool -Ibazel-out/arm64-v8a-opt/bin/external/cpuinfo/_virtual_includes/cpuinfo -Ibazel-out/arm64-v8a-opt/bin/external/clog/_virtual_includes/clog -isystem external/XNNPACK/include -isystem bazel-out/arm64-v8a-opt/bin/external/XNNPACK/include -isystem external/XNNPACK/src -isystem bazel-out/arm64-v8a-opt/bin/external/XNNPACK/src -isystem external/FP16/include -isystem bazel-out/arm64-v8a-opt/bin/external/FP16/include -isystem external/FXdiv/include -isystem bazel-out/arm64-v8a-opt/bin/external/FXdiv/include -isystem external/pthreadpool/include -isystem bazel-out/arm64-v8a-opt/bin/external/pthreadpool/include /d2ReducedOptimizeHugeFunctions -w -Iinclude -Isrc -std=c99 -O2 --sysroot=external/androidndk/ndk/platforms/android-21/arch-arm64 -isystem external/androidndk/ndk/sources/cxx-stl/llvm-libc++/include -isystem external/androidndk/ndk/sources/cxx-stl/llvm-libc++abi/include -isystem external/androidndk/ndk/sources/android/support/include -isystemexternal/androidndk/ndk/sysroot/usr/include -c external/XNNPACK/src/x32-depthtospace2d-chw2hwc/scalar.c -o bazel-out/arm64-v8a-opt/bin/external/XNNPACK/_objs/scalar_prod_microkernels/3/scalar.pic.o
Execution platform: @local_execution_config_platform//:platform
clang.exe: error: no such file or directory: '/d2ReducedOptimizeHugeFunctions'
Target //tensorflow/lite:libtensorflowlite.so failed to build
INFO: Elapsed time: 82.059s, Critical Path: 16.23s
INFO: 145 processes: 109 internal, 36 local.
FAILED: Build did NOT complete successfully
```
</details>"
56043,ERROR: Skipping '/tmp:tensorflow-lite': not a valid absolute pattern (absolute target patterns must start with exactly two slashes): '/tmp:tensorflow-lite',"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Build/Install

### Source

source

### Tensorflow Version

2.8

### Custom Code

No

### OS Platform and Distribution

windows10

### Mobile device

android

### Python version

3.8

### Bazel version

4.2.1

### GCC/Compiler version

MSVC 2019

### CUDA/cuDNN version

no

### GPU model and memory

no

### Current Behaviour?

```shell
ERROR: Skipping '/tmp:tensorflow-lite': not a valid absolute pattern (absolute target patterns must start with exactly two slashes): '/tmp:tensorflow-lite'
WARNING: Target pattern parsing failed.
ERROR: not a valid absolute pattern (absolute target patterns must start with exactly two slashes): '/tmp:tensorflow-lite'
INFO: Elapsed time: 0.912s
INFO: 0 processes.
FAILED: Build did NOT complete successfully (0 packages loaded)
```


### Standalone code to reproduce the issue

```shell
sh tensorflow/lite/tools/build_aar.sh --input_models=tflite_models/model.tflite --target_archs=arm64-v8a,armeabi-v7a
```


### Relevant log output

```shell
Full log:
D:\tensorflow\tensorflow-r2.8>sh tensorflow/lite/tools/build_aar.sh --input_models=tflite_models/model.tflite --target_archs=arm64-v8a,armeabi-v7a
INFO: Options provided by the client:
  Inherited 'common' options: --isatty=1 --terminal_columns=120
INFO: Reading rc options for 'build' from d:\tensorflow\tensorflow-r2.8\.bazelrc:
  Inherited 'common' options: --experimental_repo_remote_exec
INFO: Options provided by the client:
  'build' options: --python_path=C:/Users/11119519/Anaconda3/python.exe
INFO: Reading rc options for 'build' from d:\tensorflow\tensorflow-r2.8\.bazelrc:
  'build' options: --define framework_shared_object=true --java_toolchain=@tf_toolchains//toolchains/java:tf_java_toolchain --host_java_toolchain=@tf_toolchains//toolchains/java:tf_java_toolchain --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --enable_platform_specific_config --define=with_xla_support=true --config=short_logs --config=v2 --define=no_aws_support=true --define=no_hdfs_support=true --experimental_cc_shared_library
INFO: Reading rc options for 'build' from d:\tensorflow\tensorflow-r2.8\.tf_configure.bazelrc:
  'build' options: --action_env PYTHON_BIN_PATH=C:/Users/11119519/Anaconda3/python.exe --action_env PYTHON_LIB_PATH=C:/Users/11119519/Anaconda3/lib/site-packages --python_path=C:/Users/11119519/Anaconda3/python.exe --copt=/d2ReducedOptimizeHugeFunctions --host_copt=/d2ReducedOptimizeHugeFunctions --action_env ANDROID_NDK_HOME=C:/Users/11119519/AppData/Local/Android/Sdk/ndk/21.0.6113669 --action_env ANDROID_NDK_API_LEVEL=21 --action_env ANDROID_BUILD_TOOLS_VERSION=31.0.0 --action_env ANDROID_SDK_API_LEVEL=30 --action_env ANDROID_SDK_HOME=C:/Users/11119519/AppData/Local/Android/Sdk
INFO: Reading rc options for 'build' from d:\tensorflow\tensorflow-r2.8\.bazelrc:
  'build' options: --deleted_packages=tensorflow/compiler/mlir/tfrt,tensorflow/compiler/mlir/tfrt/benchmarks,tensorflow/compiler/mlir/tfrt/jit/python_binding,tensorflow/compiler/mlir/tfrt/jit/transforms,tensorflow/compiler/mlir/tfrt/python_tests,tensorflow/compiler/mlir/tfrt/tests,tensorflow/compiler/mlir/tfrt/tests/analysis,tensorflow/compiler/mlir/tfrt/tests/jit,tensorflow/compiler/mlir/tfrt/tests/lhlo_to_tfrt,tensorflow/compiler/mlir/tfrt/tests/tf_to_corert,tensorflow/compiler/mlir/tfrt/tests/tf_to_tfrt_data,tensorflow/compiler/mlir/tfrt/tests/saved_model,tensorflow/compiler/mlir/tfrt/transforms/lhlo_gpu_to_tfrt_gpu,tensorflow/core/runtime_fallback,tensorflow/core/runtime_fallback/conversion,tensorflow/core/runtime_fallback/kernel,tensorflow/core/runtime_fallback/opdefs,tensorflow/core/runtime_fallback/runtime,tensorflow/core/runtime_fallback/util,tensorflow/core/tfrt/common,tensorflow/core/tfrt/eager,tensorflow/core/tfrt/eager/backends/cpu,tensorflow/core/tfrt/eager/backends/gpu,tensorflow/core/tfrt/eager/core_runtime,tensorflow/core/tfrt/eager/cpp_tests/core_runtime,tensorflow/core/tfrt/fallback,tensorflow/core/tfrt/gpu,tensorflow/core/tfrt/run_handler_thread_pool,tensorflow/core/tfrt/runtime,tensorflow/core/tfrt/saved_model,tensorflow/core/tfrt/saved_model/tests,tensorflow/core/tfrt/tpu,tensorflow/core/tfrt/utils
INFO: Found applicable config definition build:short_logs in file d:\tensorflow\tensorflow-r2.8\.bazelrc: --output_filter=DONT_MATCH_ANYTHING
INFO: Found applicable config definition build:v2 in file d:\tensorflow\tensorflow-r2.8\.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1
INFO: Found applicable config definition build:windows in file d:\tensorflow\tensorflow-r2.8\.bazelrc: --copt=/W0 --copt=/D_USE_MATH_DEFINES --host_copt=/D_USE_MATH_DEFINES --cxxopt=/std:c++14 --host_cxxopt=/std:c++14 --config=monolithic --copt=-DWIN32_LEAN_AND_MEAN --host_copt=-DWIN32_LEAN_AND_MEAN --copt=-DNOGDI --host_copt=-DNOGDI --copt=/experimental:preprocessor --host_copt=/experimental:preprocessor --linkopt=/DEBUG --host_linkopt=/DEBUG --linkopt=/OPT:REF --host_linkopt=/OPT:REF --linkopt=/OPT:ICF --host_linkopt=/OPT:ICF --verbose_failures --features=compiler_param_file --distinct_host_configuration=false
INFO: Found applicable config definition build:monolithic in file d:\tensorflow\tensorflow-r2.8\.bazelrc: --define framework_shared_object=false
ERROR: Skipping '/tmp:tensorflow-lite': not a valid absolute pattern (absolute target patterns must start with exactly two slashes): '/tmp:tensorflow-lite'
WARNING: Target pattern parsing failed.
ERROR: not a valid absolute pattern (absolute target patterns must start with exactly two slashes): '/tmp:tensorflow-lite'
INFO: Elapsed time: 0.912s
INFO: 0 processes.
FAILED: Build did NOT complete successfully (0 packages loaded)
```
</details>"
56042,meta graph complaining *'_Resource' object has no attribute 'name'*,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

tf 2.6

### Custom Code

Yes

### OS Platform and Distribution

Linux

### Mobile device

_No response_

### Python version

3.6

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

I used `ops.resources.register_resource` to init my own resource type. But TF complains

WARNING:tensorflow:Issue encountered when serializing resources.
Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.
'_Resource' object has no attribute 'name'


But 'name' is not member of `_Resource`.
```python
# ops/resources.py
_Resource = collections.namedtuple(""_Resource"",
                                    [""handle"", ""create"", ""is_initialized""])
```


### Standalone code to reproduce the issue

I wrote a lot of custom code, so it's not easy to make standalone code to reproduce. That's how I register resource.

```python
resources.register_resource(
            x.resource_handle,
            x_init_op,
            x_is_initialized_op)
```


### Relevant log output

_No response_</details>"
56041,AssertionError: Bazel does not support execution of Python interpreters via labels yet,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Build/Install

### Source

source

### Tensorflow Version

tf1.5

### Custom Code

No

### OS Platform and Distribution

ubuntu20

### Mobile device

ubuntu20

### Python version

3.7

### Bazel version

bazel-0.26.1

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
./bazel-0.26.1-linux-x86_64 build --config=v1 --copt=-msse2  -k //tensorflow/tools/pip_package:build_pip_package
```


### Standalone code to reproduce the issue

```shell
.tf_configure.bazelrc
build --action_env PYTHON_BIN_PATH=""/home/soft/anaconda3/bin/python""
build --action_env PYTHON_LIB_PATH=""/home/soft/anaconda3/envs/tf/lib/python3.7/site-packages""
build --python_path=""//home/soft/anaconda3/bin/python""
build:xla --define with_xla_support=true
build:opt --copt=-msse2
build:opt --host_copt=-march=native
build:opt --define with_default_optimizations=true
build:v2 --define=tf_api_version=2
test --flaky_test_attempts=3
test --test_size_filters=small,medium
test --test_tag_filters=-benchmark-test,-no_oss,-oss_serial
test --build_tag_filters=-benchmark-test,-no_oss
test --test_tag_filters=-gpu
test --build_tag_filters=-gpu
build --action_env TF_CONFIGURE_IOS=""0""




ERROR: /home/soft/tensorflow-r1.15/tensorflow/core/BUILD:2760:1: Couldn't build file tensorflow/core/util/version_info.cc: Executing genrule //tensorflow/core:version_info_gen failed (Exit 1)
Traceback (most recent call last):
  File ""bazel-out/host/bin/tensorflow/tools/git/gen_git_source"", line 252, in <module>
    Main()
  File ""bazel-out/host/bin/tensorflow/tools/git/gen_git_source"", line 218, in Main
    program = python_program = FindPythonBinary(module_space)
  File ""bazel-out/host/bin/tensorflow/tools/git/gen_git_source"", line 60, in FindPythonBinary
    'Bazel does not support execution of Python interpreters via labels yet')
AssertionError: Bazel does not support execution of Python interpreters via labels yet
ERROR: /data/.cache/bazel/_bazel_test/9d8f535cf1766321e020e62e8d398482/external/llvm/BUILD.bazel:59:1: Couldn't build file external/llvm/include/llvm/Config/abi-breaking.h: Executing genrule @llvm//:abi_breaking_gen failed (Exit 1)
Traceback (most recent call last):
  File ""bazel-out/host/bin/external/org_tensorflow/third_party/llvm/expand_cmake_vars"", line 252, in <module>
    Main()
  File ""bazel-out/host/bin/external/org_tensorflow/third_party/llvm/expand_cmake_vars"", line 218, in Main
    program = python_program = FindPythonBinary(module_space)
  File ""bazel-out/host/bin/external/org_tensorflow/third_party/llvm/expand_cmake_vars"", line 60, in FindPythonBinary
    'Bazel does not support execution of Python interpreters via labels yet')
AssertionError: Bazel does not support execution of Python interpreters via labels yet
ERROR: /data/.cache/bazel/_bazel_test/9d8f535cf1766321e020e62e8d398482/external/llvm/BUILD.bazel:45:1: Couldn't build file external/llvm/include/llvm/Config/config.h: Executing genrule @llvm//:config_gen failed (Exit 1)
Traceback (most recent call last):
  File ""bazel-out/host/bin/external/org_tensorflow/third_party/llvm/expand_cmake_vars"", line 252, in <module>
    Main()
  File ""bazel-out/host/bin/external/org_tensorflow/third_party/llvm/expand_cmake_vars"", line 218, in Main
    program = python_program = FindPythonBinary(module_space)
  File ""bazel-out/host/bin/external/org_tensorflow/third_party/llvm/expand_cmake_vars"", line 60, in FindPythonBinary
    'Bazel does not support execution of Python interpreters via labels yet')
AssertionError: Bazel does not support execution of Python interpreters via labels yet
ERROR: /data/.cache/bazel/_bazel_test/9d8f535cf1766321e020e62e8d398482/external/llvm/BUILD.bazel:52:1: Couldn't build file external/llvm/include/llvm/Config/llvm-config.h: Executing genrule @llvm//:llvm_config_gen failed (Exit 1)
Traceback (most recent call last):
  File ""bazel-out/host/bin/external/org_tensorflow/third_party/llvm/expand_cmake_vars"", line 252, in <module>
    Main()
  File ""bazel-out/host/bin/external/org_tensorflow/third_party/llvm/expand_cmake_vars"", line 218, in Main
    program = python_program = FindPythonBinary(module_space)
  File ""bazel-out/host/bin/external/org_tensorflow/third_party/llvm/expand_cmake_vars"", line 60, in FindPythonBinary
    'Bazel does not support execution of Python interpreters via labels yet')
AssertionError: Bazel does not support execution of Python interpreters via labels yet
ERROR: /home/soft/tensorflow-r1.15/tensorflow/python/BUILD:6940:1: Couldn't build file tensorflow/python/framework/fast_tensor_util.cpp: Executing genrule //tensorflow/python:framework/fast_tensor_util.pyx_cython_translation failed (Exit 1)
Traceback (most recent call last):
  File ""bazel-out/host/bin/external/cython/cython_binary"", line 252, in <module>
    Main()
  File ""bazel-out/host/bin/external/cython/cython_binary"", line 218, in Main
    program = python_program = FindPythonBinary(module_space)
  File ""bazel-out/host/bin/external/cython/cython_binary"", line 60, in FindPythonBinary
    'Bazel does not support execution of Python interpreters via labels yet')
AssertionError: Bazel does not support execution of Python interpreters via labels yet
ERROR: /home/soft/tensorflow-r1.15/tensorflow/python/BUILD:198:1: Couldn't build file tensorflow/python/platform/build_info.py: Executing genrule //tensorflow/python:py_build_info_gen failed (Exit 1)
Traceback (most recent call last):
  File ""bazel-out/host/bin/tensorflow/tools/build_info/gen_build_info"", line 252, in <module>
    Main()
  File ""bazel-out/host/bin/tensorflow/tools/build_info/gen_build_info"", line 218, in Main
    program = python_program = FindPythonBinary(module_space)
  File ""bazel-out/host/bin/tensorflow/tools/build_info/gen_build_info"", line 60, in FindPythonBinary
    'Bazel does not support execution of Python interpreters via labels yet')
AssertionError: Bazel does not support execution of Python interpreters via labels yet
ERROR: /data/.cache/bazel/_bazel_test/9d8f535cf1766321e020e62e8d398482/external/grpc/BUILD:507:1: Couldn't build file external/grpc/_objs/gpr_base/log_linux.pic.o: C++ compilation of rule '@grpc//:gpr_base' failed (Exit 1)
external/grpc/src/core/lib/gpr/log_linux.cc:43:13: error: ambiguating new declaration of 'long int gettid()'
   43 | static long gettid(void) { return syscall(__NR_gettid); }
      |             ^~~~~~
In file included from /usr/include/unistd.h:1170,
                 from external/grpc/src/core/lib/gpr/log_linux.cc:41:
/usr/include/x86_64-linux-gnu/bits/unistd_ext.h:34:16: note: old declaration '__pid_t gettid()'
   34 | extern __pid_t gettid (void) __THROW;
      |                ^~~~~~
external/grpc/src/core/lib/gpr/log_linux.cc:43:13: warning: 'long int gettid()' defined but not used [-Wunused-function]
   43 | static long gettid(void) { return syscall(__NR_gettid); }
      |             ^~~~~~
ERROR: /data/.cache/bazel/_bazel_test/9d8f535cf1766321e020e62e8d398482/external/llvm/BUILD.bazel:45:1: Couldn't build file external/llvm/include/llvm/Config/config.h: Executing genrule @llvm//:config_gen failed (Exit 1)
Traceback (most recent call last):
  File ""bazel-out/host/bin/external/org_tensorflow/third_party/llvm/expand_cmake_vars"", line 252, in <module>
    Main()
  File ""bazel-out/host/bin/external/org_tensorflow/third_party/llvm/expand_cmake_vars"", line 218, in Main
    program = python_program = FindPythonBinary(module_space)
  File ""bazel-out/host/bin/external/org_tensorflow/third_party/llvm/expand_cmake_vars"", line 60, in FindPythonBinary
    'Bazel does not support execution of Python interpreters via labels yet')
AssertionError: Bazel does not support execution of Python interpreters via labels yet
ERROR: /data/.cache/bazel/_bazel_test/9d8f535cf1766321e020e62e8d398482/external/llvm/BUILD.bazel:59:1: Couldn't build file external/llvm/include/llvm/Config/abi-breaking.h: Executing genrule @llvm//:abi_breaking_gen failed (Exit 1)
Traceback (most recent call last):
  File ""bazel-out/host/bin/external/org_tensorflow/third_party/llvm/expand_cmake_vars"", line 252, in <module>
    Main()
  File ""bazel-out/host/bin/external/org_tensorflow/third_party/llvm/expand_cmake_vars"", line 218, in Main
    program = python_program = FindPythonBinary(module_space)
  File ""bazel-out/host/bin/external/org_tensorflow/third_party/llvm/expand_cmake_vars"", line 60, in FindPythonBinary
    'Bazel does not support execution of Python interpreters via labels yet')
AssertionError: Bazel does not support execution of Python interpreters via labels yet
ERROR: /data/.cache/bazel/_bazel_test/9d8f535cf1766321e020e62e8d398482/external/llvm/BUILD.bazel:52:1: Couldn't build file external/llvm/include/llvm/Config/llvm-config.h: Executing genrule @llvm//:llvm_config_gen failed (Exit 1)
Traceback (most recent call last):
  File ""bazel-out/host/bin/external/org_tensorflow/third_party/llvm/expand_cmake_vars"", line 252, in <module>
    Main()
  File ""bazel-out/host/bin/external/org_tensorflow/third_party/llvm/expand_cmake_vars"", line 218, in Main
    program = python_program = FindPythonBinary(module_space)
  File ""bazel-out/host/bin/external/org_tensorflow/third_party/llvm/expand_cmake_vars"", line 60, in FindPythonBinary
    'Bazel does not support execution of Python interpreters via labels yet')
AssertionError: Bazel does not support execution of Python interpreters via labels yet
ERROR: /home/soft/tensorflow-r1.15/tensorflow/core/BUILD:2760:1: Couldn't build file tensorflow/core/util/version_info.cc: Executing genrule //tensorflow/core:version_info_gen failed (Exit 1)
Traceback (most recent call last):
  File ""bazel-out/host/bin/tensorflow/tools/git/gen_git_source"", line 252, in <module>
    Main()
  File ""bazel-out/host/bin/tensorflow/tools/git/gen_git_source"", line 218, in Main
    program = python_program = FindPythonBinary(module_space)
  File ""bazel-out/host/bin/tensorflow/tools/git/gen_git_source"", line 60, in FindPythonBinary
    'Bazel does not support execution of Python interpreters via labels yet')
AssertionError: Bazel does not support execution of Python interpreters via labels yet
ERROR: /data/.cache/bazel/_bazel_test/9d8f535cf1766321e020e62e8d398482/external/grpc/BUILD:507:1: Couldn't build file external/grpc/_objs/gpr_base/log_linux.pic.o: C++ compilation of rule '@grpc//:gpr_base' failed (Exit 1)
external/grpc/src/core/lib/gpr/log_linux.cc:43:13: error: ambiguating new declaration of 'long int gettid()'
   43 | static long gettid(void) { return syscall(__NR_gettid); }
      |             ^~~~~~
In file included from /usr/include/unistd.h:1170,
                 from external/grpc/src/core/lib/gpr/log_linux.cc:41:
/usr/include/x86_64-linux-gnu/bits/unistd_ext.h:34:16: note: old declaration '__pid_t gettid()'
   34 | extern __pid_t gettid (void) __THROW;
      |                ^~~~~~
ERROR: /home/soft/tensorflow-r1.15/tensorflow/python/BUILD:198:1: Couldn't build file tensorflow/python/platform/build_info.py: Executing genrule //tensorflow/python:py_build_info_gen failed (Exit 1)
Traceback (most recent call last):
  File ""bazel-out/host/bin/tensorflow/tools/build_info/gen_build_info"", line 252, in <module>
    Main()
  File ""bazel-out/host/bin/tensorflow/tools/build_info/gen_build_info"", line 218, in Main
    program = python_program = FindPythonBinary(module_space)
  File ""bazel-out/host/bin/tensorflow/tools/build_info/gen_build_info"", line 60, in FindPythonBinary
    'Bazel does not support execution of Python interpreters via labels yet')
AssertionError: Bazel does not support execution of Python interpreters via labels yet
ERROR: /home/soft/tensorflow-r1.15/tensorflow/python/BUILD:6940:1: Couldn't build file tensorflow/python/framework/fast_tensor_util.cpp: Executing genrule //tensorflow/python:framework/fast_tensor_util.pyx_cython_translation failed (Exit 1)
Traceback (most recent call last):
  File ""bazel-out/host/bin/external/cython/cython_binary"", line 252, in <module>
    Main()
  File ""bazel-out/host/bin/external/cython/cython_binary"", line 218, in Main
    program = python_program = FindPythonBinary(module_space)
  File ""bazel-out/host/bin/external/cython/cython_binary"", line 60, in FindPythonBinary
    'Bazel does not support execution of Python interpreters via labels yet')
AssertionError: Bazel does not support execution of Python interpreters via labels yet
ERROR: /home/soft/tensorflow-r1.15/tensorflow/core/BUILD:2760:1: Couldn't build file tensorflow/core/util/version_info.cc: Executing genrule //tensorflow/core:version_info_gen failed (Exit 1)
Traceback (most recent call last):
  File ""bazel-out/host/bin/tensorflow/tools/git/gen_git_source"", line 252, in <module>
    Main()
  File ""bazel-out/host/bin/tensorflow/tools/git/gen_git_source"", line 218, in Main
    program = python_program = FindPythonBinary(module_space)
  File ""bazel-out/host/bin/tensorflow/tools/git/gen_git_source"", line 60, in FindPythonBinary
    'Bazel does not support execution of Python interpreters via labels yet')
AssertionError: Bazel does not support execution of Python interpreters via labels yet
ERROR: /data/.cache/bazel/_bazel_test/9d8f535cf1766321e020e62e8d398482/external/grpc/BUILD:507:1: Couldn't build file external/grpc/_objs/gpr_base/log_linux.pic.o: C++ compilation of rule '@grpc//:gpr_base' failed (Exit 1)
external/grpc/src/core/lib/gpr/log_linux.cc:43:13: error: ambiguating new declaration of 'long int gettid()'
   43 | static long gettid(void) { return syscall(__NR_gettid); }
      |             ^~~~~~
In file included from /usr/include/unistd.h:1170,
                 from external/grpc/src/core/lib/gpr/log_linux.cc:41:
/usr/include/x86_64-linux-gnu/bits/unistd_ext.h:34:16: note: old declaration '__pid_t gettid()'
   34 | extern __pid_t gettid (void) __THROW;
      |                ^~~~~~
ERROR: /home/soft/tensorflow-r1.15/tensorflow/python/BUILD:6940:1: Couldn't build file tensorflow/python/framework/fast_tensor_util.cpp: Executing genrule //tensorflow/python:framework/fast_tensor_util.pyx_cython_translation failed (Exit 1)
Traceback (most recent call last):
  File ""bazel-out/host/bin/external/cython/cython_binary"", line 252, in <module>
    Main()
  File ""bazel-out/host/bin/external/cython/cython_binary"", line 218, in Main
    program = python_program = FindPythonBinary(module_space)
  File ""bazel-out/host/bin/external/cython/cython_binary"", line 60, in FindPythonBinary
    'Bazel does not support execution of Python interpreters via labels yet')
AssertionError: Bazel does not support execution of Python interpreters via labels yet
ERROR: /data/.cache/bazel/_bazel_test/9d8f535cf1766321e020e62e8d398482/external/llvm/BUILD.bazel:45:1: Couldn't build file external/llvm/include/llvm/Config/config.h: Executing genrule @llvm//:config_gen failed (Exit 1)
Traceback (most recent call last):
  File ""bazel-out/host/bin/external/org_tensorflow/third_party/llvm/expand_cmake_vars"", line 252, in <module>
    Main()
  File ""bazel-out/host/bin/external/org_tensorflow/third_party/llvm/expand_cmake_vars"", line 218, in Main
    program = python_program = FindPythonBinary(module_space)
  File ""bazel-out/host/bin/external/org_tensorflow/third_party/llvm/expand_cmake_vars"", line 60, in FindPythonBinary
    'Bazel does not support execution of Python interpreters via labels yet')
AssertionError: Bazel does not support execution of Python interpreters via labels yet
ERROR: /data/.cache/bazel/_bazel_test/9d8f535cf1766321e020e62e8d398482/external/llvm/BUILD.bazel:59:1: Couldn't build file external/llvm/include/llvm/Config/abi-breaking.h: Executing genrule @llvm//:abi_breaking_gen failed (Exit 1)
Traceback (most recent call last):
  File ""bazel-out/host/bin/external/org_tensorflow/third_party/llvm/expand_cmake_vars"", line 252, in <module>
    Main()
  File ""bazel-out/host/bin/external/org_tensorflow/third_party/llvm/expand_cmake_vars"", line 218, in Main
    program = python_program = FindPythonBinary(module_space)
  File ""bazel-out/host/bin/external/org_tensorflow/third_party/llvm/expand_cmake_vars"", line 60, in FindPythonBinary
    'Bazel does not support execution of Python interpreters via labels yet')
AssertionError: Bazel does not support execution of Python interpreters via labels yet
ERROR: /data/.cache/bazel/_bazel_test/9d8f535cf1766321e020e62e8d398482/external/llvm/BUILD.bazel:52:1: Couldn't build file external/llvm/include/llvm/Config/llvm-config.h: Executing genrule @llvm//:llvm_config_gen failed (Exit 1)
Traceback (most recent call last):
  File ""bazel-out/host/bin/external/org_tensorflow/third_party/llvm/expand_cmake_vars"", line 252, in <module>
    Main()
  File ""bazel-out/host/bin/external/org_tensorflow/third_party/llvm/expand_cmake_vars"", line 218, in Main
    program = python_program = FindPythonBinary(module_space)
  File ""bazel-out/host/bin/external/org_tensorflow/third_party/llvm/expand_cmake_vars"", line 60, in FindPythonBinary
    'Bazel does not support execution of Python interpreters via labels yet')
AssertionError: Bazel does not support execution of Python interpreters via labels yet
ERROR: /home/soft/tensorflow-r1.15/tensorflow/python/BUILD:198:1: Couldn't build file tensorflow/python/platform/build_info.py: Executing genrule //tensorflow/python:py_build_info_gen failed (Exit 1)
Traceback (most recent call last):
  File ""bazel-out/host/bin/tensorflow/tools/build_info/gen_build_info"", line 252, in <module>
    Main()
  File ""bazel-out/host/bin/tensorflow/tools/build_info/gen_build_info"", line 218, in Main
    program = python_program = FindPythonBinary(module_space)
  File ""bazel-out/host/bin/tensorflow/tools/build_info/gen_build_info"", line 60, in FindPythonBinary
    'Bazel does not support execution of Python interpreters via labels yet')
AssertionError: Bazel does not support execution of Python interpreters via labels yet
Target //tensorflow/tools/pip_package:build_pip_package failed to build
Use --verbose_failures to see the command lines of failed build steps.
INFO: Elapsed time: 3.951s, Critical Path: 0.09s
INFO: 0 processes.
FAILED: Build did NOT complete successfully
```


### Relevant log output

_No response_</details>"
56030,TFLite ios podspecs are fixed to 2.7,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Others

### Source

source

### Tensorflow Version

2.8+

### Custom Code

No

### OS Platform and Distribution

iOS

### Mobile device

iOS

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

The podspecs for ios all seem to have TF version fixed to 2.7 even though 2.8 has been released and 2.9 is going to be released. I want to check if this is an oversight or if TFLite for iOS has a different versioning scheme.

For example [TensorFlowLiteC's](https://github.com/tensorflow/tensorflow/blob/v2.8.0/tensorflow/lite/ios/TensorFlowLiteC.podspec) podspec begins as 


```
Pod::Spec.new do |s|
  s.name             = 'TensorFlowLiteC'
  s.version          = '2.7.0'
  s.authors          = 'Google Inc.'
  s.license          = { :type => 'Apache' }
  s.homepage         = 'https://github.com/tensorflow/tensorflow'
  s.source           = { :http => ""https://dl.google.com/dl/cpdc/6ffa58c2d5bbf5ff/TensorFlowLiteC-#{s.version}.tar.gz"" }
  s.summary          = 'TensorFlow Lite'
  s.description      = <<-DESC
```



### Standalone code to reproduce the issue

```shell
See above.
```


### Relevant log output

_No response_</details>"
56029,//tensorflow/compiler/mlir/lite/tests:const-fold.mlir.test fails on manylinux2014-aarch64,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

git HEAD

### Custom Code

No

### OS Platform and Distribution

CentOS 7

### Mobile device

n/a

### Python version

3.8.13

### Bazel version

5.1.1

### GCC/Compiler version

10.2.1

### CUDA/cuDNN version

n/a

### GPU model and memory

n/a

### Current Behaviour?

```shell
MLIR test fails because value of std::sin(1.0) is slightly different due to version of libm in use in manylinux2014-aarch64 docker image.
```


### Standalone code to reproduce the issue

```shell
bazel test --test_timeout=300,500,-1,-1 --flaky_test_attempts=3 --test_output=all --cache_test_results=no --noremote_accept_cached --config=nonccl --copt=""-mtune=generic"" --copt=""-march=armv8-a"" --copt=""-O3"" --build_tag_filters=-no_oss,-oss_serial,-gpu,-tpu,-benchmark-test,-v1only,-no_aarch64,-requires-gpu --test_tag_filters=-no_oss,-oss_serial,-gpu,-tpu,-benchmark-test,-v1only,-no_aarch64,-requires-gpu --verbose_failures --build_tests_only --jobs=75 -- //tensorflow/compiler/mlir/lite/tests:const-fold.mlir.test
```


### Relevant log output

```shell
==================== Test output for //tensorflow/compiler/mlir/lite/tests:const-fold.mlir.test:
-- Testing: 1 tests, 1 workers --
FAIL: MLIR tests :: const-fold.mlir (1 of 1)
******************** TEST 'MLIR tests :: const-fold.mlir' FAILED ********************
Script:
--
: 'RUN: at line 1';   /root/.cache/bazel/_bazel_root/db210f68f81d95ddcca9ae96b16ed72c/execroot/org_tensorflow/bazel-out/aarch64-opt/bin/tensorflow/compiler/mlir/lite/tests/const-fold.mlir.test.runfiles/org_tensorflow/tensorflow/compiler/mlir/tf-opt /root/.cache/bazel/_bazel_root/db210f68f81d95ddcca9ae96b16ed72c/execroot/org_tensorflow/bazel-out/aarch64-opt/bin/tensorflow/compiler/mlir/lite/tests/const-fold.mlir.test.runfiles/org_tensorflow/tensorflow/compiler/mlir/lite/tests/const-fold.mlir -canonicalize | FILECHECK_OPTS="""" /root/.cache/bazel/_bazel_root/db210f68f81d95ddcca9ae96b16ed72c/execroot/org_tensorflow/bazel-out/aarch64-opt/bin/tensorflow/compiler/mlir/lite/tests/const-fold.mlir.test.runfiles/llvm-project/llvm/FileCheck /root/.cache/bazel/_bazel_root/db210f68f81d95ddcca9ae96b16ed72c/execroot/org_tensorflow/bazel-out/aarch64-opt/bin/tensorflow/compiler/mlir/lite/tests/const-fold.mlir.test.runfiles/org_tensorflow/tensorflow/compiler/mlir/lite/tests/const-fold.mlir
--
Exit Code: 1

Command Output (stderr):
--
/root/.cache/bazel/_bazel_root/db210f68f81d95ddcca9ae96b16ed72c/execroot/org_tensorflow/bazel-out/aarch64-opt/bin/tensorflow/compiler/mlir/lite/tests/const-fold.mlir.test.runfiles/org_tensorflow/tensorflow/compiler/mlir/lite/tests/const-fold.mlir:165:16: error: CHECK-DAG: expected string not found in input
 // CHECK-DAG: [[cst1:%.*]] = arith.constant dense<0.841470957> : tensor<f32>
               ^
<stdin>:54:29: note: scanning from here
 func @elementwise_unary_ops() -> (tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>) {
                            ^
<stdin>:59:3: note: possible intended match here
 %cst_3 = arith.constant dense<0.540302277> : tensor<f32>
  ^

Input file: <stdin>
Check file: /root/.cache/bazel/_bazel_root/db210f68f81d95ddcca9ae96b16ed72c/execroot/org_tensorflow/bazel-out/aarch64-opt/bin/tensorflow/compiler/mlir/lite/tests/const-fold.mlir.test.runfiles/org_tensorflow/tensorflow/compiler/mlir/lite/tests/const-fold.mlir

-dump-input=help explains the following input dump.

Input was:
<<<<<<
           .
           .
           .
          49:  %cst_0 = arith.constant dense<5.250000e+00> : tensor<4xf16> 
          50:  %cst_1 = arith.constant dense<-2.250000e+00> : tensor<4xf16> 
          51:  %cst_2 = arith.constant dense<6.750000e+00> : tensor<f16> 
          52:  return %cst_2, %cst_1, %cst_0, %cst : tensor<f16>, tensor<4xf16>, tensor<4xf16>, tensor<4xf16> 
          53:  } 
          54:  func @elementwise_unary_ops() -> (tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>) { 
dag:165'0                                 X~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ error: no match found
          55:  %cst = arith.constant dense<4.000000e+00> : tensor<f32> 
dag:165'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          56:  %cst_0 = arith.constant dense<5.000000e-01> : tensor<f32> 
dag:165'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          57:  %cst_1 = arith.constant dense<2.000000e+00> : tensor<f32> 
dag:165'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          58:  %cst_2 = arith.constant dense<0.000000e+00> : tensor<f32> 
dag:165'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          59:  %cst_3 = arith.constant dense<0.540302277> : tensor<f32> 
dag:165'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
dag:165'1       ?                                                        possible intended match
          60:  %cst_4 = arith.constant dense<8.414710e-01> : tensor<f32> 
dag:165'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          61:  %cst_5 = arith.constant dense<1.000000e+00> : tensor<f32> 
dag:165'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          62:  return %cst_5, %cst_4, %cst_3, %cst_2, %cst_1, %cst_0, %cst : tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32> 
dag:165'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          63:  } 
dag:165'0     ~~~
          64:  func @mul_int() -> (tensor<i32>, tensor<4xi32>, tensor<4xi32>, tensor<4xi32>) { 
dag:165'0     ~~~~~~~~~~~~~~
           .
           .
           .
>>>>>>

--

********************
********************
Failed Tests (1):
  MLIR tests :: const-fold.mlir


Testing Time: 0.23s
  Failed: 1
================================================================================
==================== Test output for //tensorflow/compiler/mlir/lite/tests:const-fold.mlir.test:
-- Testing: 1 tests, 1 workers --
FAIL: MLIR tests :: const-fold.mlir (1 of 1)
******************** TEST 'MLIR tests :: const-fold.mlir' FAILED ********************
Script:
--
: 'RUN: at line 1';   /root/.cache/bazel/_bazel_root/db210f68f81d95ddcca9ae96b16ed72c/execroot/org_tensorflow/bazel-out/aarch64-opt/bin/tensorflow/compiler/mlir/lite/tests/const-fold.mlir.test.runfiles/org_tensorflow/tensorflow/compiler/mlir/tf-opt /root/.cache/bazel/_bazel_root/db210f68f81d95ddcca9ae96b16ed72c/execroot/org_tensorflow/bazel-out/aarch64-opt/bin/tensorflow/compiler/mlir/lite/tests/const-fold.mlir.test.runfiles/org_tensorflow/tensorflow/compiler/mlir/lite/tests/const-fold.mlir -canonicalize | FILECHECK_OPTS="""" /root/.cache/bazel/_bazel_root/db210f68f81d95ddcca9ae96b16ed72c/execroot/org_tensorflow/bazel-out/aarch64-opt/bin/tensorflow/compiler/mlir/lite/tests/const-fold.mlir.test.runfiles/llvm-project/llvm/FileCheck /root/.cache/bazel/_bazel_root/db210f68f81d95ddcca9ae96b16ed72c/execroot/org_tensorflow/bazel-out/aarch64-opt/bin/tensorflow/compiler/mlir/lite/tests/const-fold.mlir.test.runfiles/org_tensorflow/tensorflow/compiler/mlir/lite/tests/const-fold.mlir
--
Exit Code: 1

Command Output (stderr):
--
/root/.cache/bazel/_bazel_root/db210f68f81d95ddcca9ae96b16ed72c/execroot/org_tensorflow/bazel-out/aarch64-opt/bin/tensorflow/compiler/mlir/lite/tests/const-fold.mlir.test.runfiles/org_tensorflow/tensorflow/compiler/mlir/lite/tests/const-fold.mlir:165:16: error: CHECK-DAG: expected string not found in input
 // CHECK-DAG: [[cst1:%.*]] = arith.constant dense<0.841470957> : tensor<f32>
               ^
<stdin>:54:29: note: scanning from here
 func @elementwise_unary_ops() -> (tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>) {
                            ^
<stdin>:59:3: note: possible intended match here
 %cst_3 = arith.constant dense<0.540302277> : tensor<f32>
  ^

Input file: <stdin>
Check file: /root/.cache/bazel/_bazel_root/db210f68f81d95ddcca9ae96b16ed72c/execroot/org_tensorflow/bazel-out/aarch64-opt/bin/tensorflow/compiler/mlir/lite/tests/const-fold.mlir.test.runfiles/org_tensorflow/tensorflow/compiler/mlir/lite/tests/const-fold.mlir

-dump-input=help explains the following input dump.

Input was:
<<<<<<
           .
           .
           .
          49:  %cst_0 = arith.constant dense<5.250000e+00> : tensor<4xf16> 
          50:  %cst_1 = arith.constant dense<-2.250000e+00> : tensor<4xf16> 
          51:  %cst_2 = arith.constant dense<6.750000e+00> : tensor<f16> 
          52:  return %cst_2, %cst_1, %cst_0, %cst : tensor<f16>, tensor<4xf16>, tensor<4xf16>, tensor<4xf16> 
          53:  } 
          54:  func @elementwise_unary_ops() -> (tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>) { 
dag:165'0                                 X~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ error: no match found
          55:  %cst = arith.constant dense<4.000000e+00> : tensor<f32> 
dag:165'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          56:  %cst_0 = arith.constant dense<5.000000e-01> : tensor<f32> 
dag:165'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          57:  %cst_1 = arith.constant dense<2.000000e+00> : tensor<f32> 
dag:165'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          58:  %cst_2 = arith.constant dense<0.000000e+00> : tensor<f32> 
dag:165'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          59:  %cst_3 = arith.constant dense<0.540302277> : tensor<f32> 
dag:165'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
dag:165'1       ?                                                        possible intended match
          60:  %cst_4 = arith.constant dense<8.414710e-01> : tensor<f32> 
dag:165'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          61:  %cst_5 = arith.constant dense<1.000000e+00> : tensor<f32> 
dag:165'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          62:  return %cst_5, %cst_4, %cst_3, %cst_2, %cst_1, %cst_0, %cst : tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32> 
dag:165'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          63:  } 
dag:165'0     ~~~
          64:  func @mul_int() -> (tensor<i32>, tensor<4xi32>, tensor<4xi32>, tensor<4xi32>) { 
dag:165'0     ~~~~~~~~~~~~~~
           .
           .
           .
>>>>>>

--

********************
********************
Failed Tests (1):
  MLIR tests :: const-fold.mlir


Testing Time: 0.19s
  Failed: 1
================================================================================
==================== Test output for //tensorflow/compiler/mlir/lite/tests:const-fold.mlir.test:
-- Testing: 1 tests, 1 workers --
FAIL: MLIR tests :: const-fold.mlir (1 of 1)
******************** TEST 'MLIR tests :: const-fold.mlir' FAILED ********************
Script:
--
: 'RUN: at line 1';   /root/.cache/bazel/_bazel_root/db210f68f81d95ddcca9ae96b16ed72c/execroot/org_tensorflow/bazel-out/aarch64-opt/bin/tensorflow/compiler/mlir/lite/tests/const-fold.mlir.test.runfiles/org_tensorflow/tensorflow/compiler/mlir/tf-opt /root/.cache/bazel/_bazel_root/db210f68f81d95ddcca9ae96b16ed72c/execroot/org_tensorflow/bazel-out/aarch64-opt/bin/tensorflow/compiler/mlir/lite/tests/const-fold.mlir.test.runfiles/org_tensorflow/tensorflow/compiler/mlir/lite/tests/const-fold.mlir -canonicalize | FILECHECK_OPTS="""" /root/.cache/bazel/_bazel_root/db210f68f81d95ddcca9ae96b16ed72c/execroot/org_tensorflow/bazel-out/aarch64-opt/bin/tensorflow/compiler/mlir/lite/tests/const-fold.mlir.test.runfiles/llvm-project/llvm/FileCheck /root/.cache/bazel/_bazel_root/db210f68f81d95ddcca9ae96b16ed72c/execroot/org_tensorflow/bazel-out/aarch64-opt/bin/tensorflow/compiler/mlir/lite/tests/const-fold.mlir.test.runfiles/org_tensorflow/tensorflow/compiler/mlir/lite/tests/const-fold.mlir
--
Exit Code: 1

Command Output (stderr):
--
/root/.cache/bazel/_bazel_root/db210f68f81d95ddcca9ae96b16ed72c/execroot/org_tensorflow/bazel-out/aarch64-opt/bin/tensorflow/compiler/mlir/lite/tests/const-fold.mlir.test.runfiles/org_tensorflow/tensorflow/compiler/mlir/lite/tests/const-fold.mlir:165:16: error: CHECK-DAG: expected string not found in input
 // CHECK-DAG: [[cst1:%.*]] = arith.constant dense<0.841470957> : tensor<f32>
               ^
<stdin>:54:29: note: scanning from here
 func @elementwise_unary_ops() -> (tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>) {
                            ^
<stdin>:59:3: note: possible intended match here
 %cst_3 = arith.constant dense<0.540302277> : tensor<f32>
  ^

Input file: <stdin>
Check file: /root/.cache/bazel/_bazel_root/db210f68f81d95ddcca9ae96b16ed72c/execroot/org_tensorflow/bazel-out/aarch64-opt/bin/tensorflow/compiler/mlir/lite/tests/const-fold.mlir.test.runfiles/org_tensorflow/tensorflow/compiler/mlir/lite/tests/const-fold.mlir

-dump-input=help explains the following input dump.

Input was:
<<<<<<
           .
           .
           .
          49:  %cst_0 = arith.constant dense<5.250000e+00> : tensor<4xf16> 
          50:  %cst_1 = arith.constant dense<-2.250000e+00> : tensor<4xf16> 
          51:  %cst_2 = arith.constant dense<6.750000e+00> : tensor<f16> 
          52:  return %cst_2, %cst_1, %cst_0, %cst : tensor<f16>, tensor<4xf16>, tensor<4xf16>, tensor<4xf16> 
          53:  } 
          54:  func @elementwise_unary_ops() -> (tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>) { 
dag:165'0                                 X~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ error: no match found
          55:  %cst = arith.constant dense<4.000000e+00> : tensor<f32> 
dag:165'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          56:  %cst_0 = arith.constant dense<5.000000e-01> : tensor<f32> 
dag:165'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          57:  %cst_1 = arith.constant dense<2.000000e+00> : tensor<f32> 
dag:165'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          58:  %cst_2 = arith.constant dense<0.000000e+00> : tensor<f32> 
dag:165'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          59:  %cst_3 = arith.constant dense<0.540302277> : tensor<f32> 
dag:165'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
dag:165'1       ?                                                        possible intended match
          60:  %cst_4 = arith.constant dense<8.414710e-01> : tensor<f32> 
dag:165'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          61:  %cst_5 = arith.constant dense<1.000000e+00> : tensor<f32> 
dag:165'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          62:  return %cst_5, %cst_4, %cst_3, %cst_2, %cst_1, %cst_0, %cst : tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32>, tensor<f32> 
dag:165'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          63:  } 
dag:165'0     ~~~
          64:  func @mul_int() -> (tensor<i32>, tensor<4xi32>, tensor<4xi32>, tensor<4xi32>) { 
dag:165'0     ~~~~~~~~~~~~~~
           .
           .
           .
>>>>>>

--

********************
********************
Failed Tests (1):
  MLIR tests :: const-fold.mlir


Testing Time: 0.19s
  Failed: 1
================================================================================
Target //tensorflow/compiler/mlir/lite/tests:const-fold.mlir.test up-to-date:
  bazel-bin/tensorflow/compiler/mlir/lite/tests/const-fold.mlir.test
INFO: Elapsed time: 120.692s, Critical Path: 108.40s
INFO: 45 processes: 1 internal, 44 local.
INFO: Build completed, 1 test FAILED, 45 total actions
//tensorflow/compiler/mlir/lite/tests:const-fold.mlir.test               FAILED in 3 out of 3 in 0.6s
```
</details>"
56026,NodeDefBuilder for custom OP  will report OpKernel for unknown op: UnwrapDatasetVariant,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Support

### Source

binary

### Tensorflow Version

tf 2.6.0

### Custom Code

Yes

### OS Platform and Distribution

macos 11.6

### Mobile device

_No response_

### Python version

python 3.7.6

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
when i test use gtest after developed custom op 'Factt' (just same as op 'Fact'),

using line: TF_EXPECT_OK(NodeDefBuilder(""fact_op"", ""Fact"").Finalize(node_def()));
will always report
E tensorflow/core/framework/op_kernel.cc:1623] opKernel ('op: ""WrapDatasetVariant"" device_type: ""CPU""') for unknown op: WrapDatasetVariant
```


### Standalone code to reproduce the issue

```shell
//============================src===========================
class FacttOp : public tensorflow::OpKernel {
 public:
  explicit FactOp(tensorflow::OpKernelConstruction *context) : OpKernel(context) {}

  void Compute(tensorflow::OpKernelContext *context) override {
    // Output a scalar string.
    tensorflow::Tensor *output_tensor = nullptr;
    OP_REQUIRES_OK(context, context->allocate_output(0, tensorflow::TensorShape(), &output_tensor));
    using tensorflow::string;
    auto output = output_tensor->template scalar<tensorflow::tstring>();

  }
};

REGISTER_KERNEL_BUILDER(Name(""Factt"").Device(tensorflow::DEVICE_CPU), FactOp);

//============================gtest===========================
TEST_F(ExampleFacttTest, Compute) {
TF_EXPECT_OK(
      NodeDefBuilder(""fact_op"", ""Factt"")
      .Finalize(node_def()));
  TF_EXPECT_OK(InitOpWithGraphVersion(8));
  TF_ASSERT_OK(RunOpKernel());
  Tensor* tensor_output = GetOutput(0);
  EXPECT_TRUE(tensor_output != nullptr);
  LOG(INFO) << ""Test ExampleMergeTest : compute SUCCESS"";
}
```


### Relevant log output

```shell
2022-05-09 20:22:57.092424: E tensorflow/core/framework/op_kernel.cc:1623] OpKernel ('op: ""UnwrapDatasetVariant"" device_type: ""GPU"" host_memory_arg: ""input_handle"" host_memory_arg: ""output_handle""') for unknown op: UnwrapDatasetVariant
2022-05-09 20:22:57.092471: E tensorflow/core/framework/op_kernel.cc:1623] OpKernel ('op: ""UnwrapDatasetVariant"" device_type: ""CPU""') for unknown op: UnwrapDatasetVariant
2022-05-09 20:22:57.092497: E tensorflow/core/framework/op_kernel.cc:1623] OpKernel ('op: ""WrapDatasetVariant"" device_type: ""GPU"" host_memory_arg: ""input_handle"" host_memory_arg: ""output_handle""') for unknown op: WrapDatasetVariant
2022-05-09 20:22:57.092518: E tensorflow/core/framework/op_kernel.cc:1623] OpKernel ('op: ""WrapDatasetVariant"" device_type: ""CPU""') for unknown op: WrapDatasetVariant
2022-05-09 20:26:11.601110: I /Users/yankai/Codelib/codes/CNBizAlgoOps/tests/cpp/test_example/test_example_fact.cc:30] Test ExampleMergeTest : compute SUCCESS
```
</details>"
56024,Autograph appears not to support Python variables without an initial value,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

2.8.0

### Custom Code

Yes

### OS Platform and Distribution

Ubuntu 18.04.6 LTS

### Mobile device

_No response_

### Python version

3.10.4

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
Autograph appears not to support Python variables without an initial value.
Although this is a rarely used feature of Python, I don't see why this should cause any problems. It literally has no control flow.

In my below example `foo` works, but `bar` does not, despite them essentially only having formatting differences.
```


### Standalone code to reproduce the issue

```shell
import tensorflow as tf


@tf.function
def foo(a: tf.Tensor, b: tf.Tensor) -> tf.Tensor:
    result: tf.Tensor = a + b
    return result


@tf.function
def bar(a: tf.Tensor, b: tf.Tensor) -> tf.Tensor:
    result: tf.Tensor
    result = a + b
    return result


foo(tf.constant(2), tf.constant(3))  # <-- Works.
bar(tf.constant(2), tf.constant(3))  # <-- WARNING:tensorflow:AutoGraph could not transform...
```


### Relevant log output

```shell
2022-05-09 10:25:03.704416: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-05-09 10:25:03.707662: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory
2022-05-09 10:25:03.708246: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
2022-05-09 10:25:03.708548: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
WARNING:tensorflow:AutoGraph could not transform <function bar at 0x7feba9ff7130> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: invalid value for ""node"": expected ""ast.AST"", got ""<class 'NoneType'>""; to visit lists of nodes, use ""visit_block"" instead
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
```
</details>"
56022,Crash when using TFLite on Window,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

tf 2.8.0

### Custom Code

Yes

### OS Platform and Distribution

Windows 10

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

4.2.1

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
When assign assign interpreter->outputs() to another variable, it crashed on Windows. Same code works fine on Linux.
```


### Standalone code to reproduce the issue

```c++
#include <tensorflow/lite/kernels/register.h>
using namespace tflite;

int main() {
	std::unique_ptr<tflite::Interpreter> interpreter;
	auto model = tflite::FlatBufferModel::BuildFromFile(""D:/test.tflite"");
	if (model == nullptr) {
		printf(""Error1\n"");
	}
	tflite::ops::builtin::BuiltinOpResolver resolver;
	if (InterpreterBuilder(*model, resolver)(&interpreter) != kTfLiteOk) {
		printf(""Error2\n"");
	}
	if (interpreter->AllocateTensors() != kTfLiteOk) {
		printf(""Error3\n"");
	}

	interpreter->outputs();   // This line will work
	 //auto outs = interpreter->outputs();  // This line will crash

	printf(""Done\n"");
	return 0;
}
```


### Relevant log output

_No response_</details>"
56021,failed to build //tensorflow/compiler/tf2tensorrt:segment_test on mac osx 12.3.1,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Build/Install

### Source

source

### Tensorflow Version

master commit id ab2a1290436c9b33ff4ddbc15b6d3dd2c159dd1f

### Custom Code

No

### OS Platform and Distribution

mac osx 12.3.1

### Mobile device

_No response_

### Python version

3.9

### Bazel version

5.1.1

### GCC/Compiler version

Apple clang version 13.1.6 (clang-1316.0.21.2.3)

### CUDA/cuDNN version

no

### GPU model and memory

no

### Current Behaviour?

```shell
./tensorflow/core/platform/default/logging.h:472:31: note: expanded from macro 'DCHECK_GE'
#define DCHECK_GE(val1, val2) CHECK_GE(val1, val2)
                              ^
./tensorflow/core/platform/default/logging.h:459:30: note: expanded from macro 'CHECK_GE'
#define CHECK_GE(val1, val2) CHECK_OP(Check_GE, >=, val1, val2)
                             ^
./tensorflow/core/platform/default/logging.h:452:40: note: expanded from macro 'CHECK_OP'
#define CHECK_OP(name, op, val1, val2) CHECK_OP_LOG(name, op, val1, val2)
                                       ^
./tensorflow/core/platform/default/logging.h:445:48: note: expanded from macro 'CHECK_OP_LOG'
  while (::tensorflow::internal::CheckOpString _result{        \
                                               ^
./tensorflow/core/platform/default/logging.h:306:8: note: 'CheckOpString' is not literal because it is not an aggregate and has no constexpr constructors other than copy or move constructors
struct CheckOpString {
       ^
In file included from tensorflow/compiler/xla/array.cc:16:
In file included from ./tensorflow/compiler/xla/array.h:35:
./tensorflow/compiler/xla/util.h:495:5: error: variable of non-literal type '::tensorflow::internal::CheckOpString' cannot be defined in a constexpr function
    DCHECK_GE(exponent, 0);
    ^
./tensorflow/core/platform/default/logging.h:472:31: note: expanded from macro 'DCHECK_GE'
#define DCHECK_GE(val1, val2) CHECK_GE(val1, val2)
                              ^
./tensorflow/core/platform/default/logging.h:459:30: note: expanded from macro 'CHECK_GE'
#define CHECK_GE(val1, val2) CHECK_OP(Check_GE, >=, val1, val2)
                             ^
./tensorflow/core/platform/default/logging.h:452:40: note: expanded from macro 'CHECK_OP'
#define CHECK_OP(name, op, val1, val2) CHECK_OP_LOG(name, op, val1, val2)
                                       ^
./tensorflow/core/platform/default/logging.h:445:48: note: expanded from macro 'CHECK_OP_LOG'
  while (::tensorflow::internal::CheckOpString _result{        \
                                               ^
./tensorflow/core/platform/default/logging.h:306:8: note: 'CheckOpString' is not literal because it is not an aggregate and has no constexpr constructors other than copy or move constructors
struct CheckOpString {
       ^
In file included from tensorflow/compiler/xla/array.cc:16:
In file included from ./tensorflow/compiler/xla/array.h:35:
./tensorflow/compiler/xla/util.h:568:12: error: no matching function for call to 'LsbMask'
    return LsbMask<uint64_t>(bits);
           ^~~~~~~~~~~~~~~~~
./tensorflow/compiler/xla/util.h:448:20: note: candidate template ignored: substitution failure [with T = unsigned long long]
constexpr inline T LsbMask(int width)
                   ^
3 errors generated.
Error in child process '/usr/bin/xcrun'. 1
INFO: Elapsed time: 2366.543s, Critical Path: 84.33s
INFO: 3324 processes: 1080 internal, 2244 local.
FAILED: Build did NOT complete successfully
```


### Standalone code to reproduce the issue

```shell
bazel build --config=v2 --config=dbg --config=noaws //tensorflow/compiler/tf2tensorrt:segment_test
```


### Relevant log output

_No response_</details>"
56019,Problem with gpu memory allocation,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Others

### Source

source

### Tensorflow Version

2.8.0

### Custom Code

Yes

### OS Platform and Distribution

Windows 10

### Mobile device

_No response_

### Python version

3.9.8

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

11.2

### GPU model and memory

notebook version of nvidia gtx 1060 (6GB)

### Current Behaviour?

```shell
I use tensorflow for image classification (20 classes) with convolutions. My dataset contains about 20000 train images and 5000 test images. Images (RGB) have 200x256 pixels. When I run script to train model using cpu everything seems fine. However when I try run script using gpu, after loading my training and test data I get error on model_fit function.

Num GPUs Available:  1
2022-05-04 17:58:58.482057: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-05-04 17:59:03.655618: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4634 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1060, pci bus id: xxxx:xx:xx.x, compute capability: 6.1
1 Physical GPUs, 1 Logical GPUs
Path: D:/Dataset/seg_train
Loading seg_train
Path: D:/Dataset/seg_test
Loading seg_test
2022-05-04 18:02:48.971100: W tensorflow/core/common_runtime/bfc_allocator.cc:462] Allocator (GPU_0_bfc) ran out of memory trying to allocate 10.44GiB (rounded to 11206656000)requested by op _EagerConst
If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation.
Current allocation summary follows.
Current allocation summary follows.
2022-05-04 18:02:48.996013: I tensorflow/core/common_runtime/bfc_allocator.cc:1010] BFCAllocator dump for GPU_0_bfc
2022-05-04 18:02:48.996173: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (256):  Total Chunks: 16, Chunks in use: 16. 4.0KiB allocated for chunks. 4.0KiB in use in bin. 392B client-requested in use in bin.
2022-05-04 18:02:48.996308: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (512):  Total Chunks: 1, Chunks in use: 1. 512B allocated for chunks. 512B in use in bin. 512B client-requested in use in bin.
2022-05-04 18:02:48.996473: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (1024):         Total Chunks: 1, Chunks in use: 1. 1.2KiB allocated for chunks. 1.2KiB in use in bin. 1.0KiB client-requested in use in bin.
2022-05-04 18:02:48.996629: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (2048):         Total Chunks: 2, Chunks in use: 1. 7.0KiB allocated for chunks. 3.5KiB in use in bin. 3.4KiB client-requested in use in bin.
2022-05-04 18:02:48.996889: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (4096):         Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2022-05-04 18:02:48.997493: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (8192):         Total Chunks: 1, Chunks in use: 1. 9.5KiB allocated for chunks. 9.5KiB in use in bin. 9.5KiB client-requested in use in bin.
2022-05-04 18:02:48.997960: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (16384):        Total Chunks: 1, Chunks in use: 0. 19.0KiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2022-05-04 18:02:48.998482: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (32768):        Total Chunks: 2, Chunks in use: 1. 79.5KiB allocated for chunks. 36.0KiB in use in bin. 36.0KiB client-requested in use in bin.
2022-05-04 18:02:48.999113: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (65536):        Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2022-05-04 18:02:48.999710: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (131072):       Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2022-05-04 18:02:49.000273: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (262144):       Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2022-05-04 18:02:49.000742: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (524288):       Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2022-05-04 18:02:49.001208: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (1048576):      Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2022-05-04 18:02:49.001671: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (2097152):      Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2022-05-04 18:02:49.002131: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (4194304):      Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2022-05-04 18:02:49.002700: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (8388608):      Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2022-05-04 18:02:49.004034: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (16777216):     Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2022-05-04 18:02:49.004682: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (33554432):     Total Chunks: 1, Chunks in use: 1. 44.56MiB allocated for chunks. 44.56MiB in use in bin. 44.56MiB client-requested in use in bin.
2022-05-04 18:02:49.005383: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (67108864):     Total Chunks: 1, Chunks in use: 0. 89.12MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2022-05-04 18:02:49.007520: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (134217728):    Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2022-05-04 18:02:49.008016: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (268435456):    Total Chunks: 1, Chunks in use: 0. 4.39GiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2022-05-04 18:02:49.008477: I tensorflow/core/common_runtime/bfc_allocator.cc:1033] Bin for 10.44GiB was 256.00MiB, Chunk State:
2022-05-04 18:02:49.008888: I tensorflow/core/common_runtime/bfc_allocator.cc:1039]   Size: 4.39GiB | Requested Size: 0B | in_use: 0 | bin_num: 20, prev:   Size: 44.56MiB | Requested Size: 44.56MiB | in_use: 1 | bin_num: -1
2022-05-04 18:02:49.009335: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] Next region of size 4859428864
2022-05-04 18:02:49.025604: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at b03a00000 of size 256 next 1
2022-05-04 18:02:49.025772: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at b03a00100 of size 1280 next 2
2022-05-04 18:02:49.026373: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at b03a00600 of size 256 next 3
2022-05-04 18:02:49.026991: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at b03a00700 of size 256 next 4
2022-05-04 18:02:49.028407: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at b03a00800 of size 256 next 5
2022-05-04 18:02:49.028560: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at b03a00900 of size 256 next 6
2022-05-04 18:02:49.029196: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at b03a00a00 of size 256 next 9
2022-05-04 18:02:49.029937: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at b03a00b00 of size 256 next 10
2022-05-04 18:02:49.030556: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at b03a00c00 of size 256 next 11
2022-05-04 18:02:49.031054: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at b03a00d00 of size 256 next 14
2022-05-04 18:02:49.031553: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at b03a00e00 of size 256 next 15
2022-05-04 18:02:49.031906: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at b03a00f00 of size 512 next 16
2022-05-04 18:02:49.032334: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at b03a01100 of size 256 next 19
2022-05-04 18:02:49.032719: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at b03a01200 of size 256 next 20
2022-05-04 18:02:49.033158: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at b03a01300 of size 256 next 21
2022-05-04 18:02:49.033523: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at b03a01400 of size 256 next 24
2022-05-04 18:02:49.033892: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at b03a01500 of size 256 next 25
2022-05-04 18:02:49.034323: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at b03a01600 of size 256 next 26
2022-05-04 18:02:49.034824: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] Free  at b03a01700 of size 3584 next 7
2022-05-04 18:02:49.035472: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at b03a02500 of size 3584 next 8
2022-05-04 18:02:49.035923: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] Free  at b03a03300 of size 19456 next 23
2022-05-04 18:02:49.036957: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at b03a07f00 of size 9728 next 22
2022-05-04 18:02:49.039251: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] Free  at b03a0a500 of size 44544 next 13
2022-05-04 18:02:49.039789: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at b03a15300 of size 36864 next 12
2022-05-04 18:02:49.040234: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] Free  at b03a1e300 of size 93454336 next 18
2022-05-04 18:02:49.040779: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at b0933e300 of size 46727168 next 17
2022-05-04 18:02:49.041233: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] Free  at b0bfce300 of size 4719123712 next 18446744073709551615
2022-05-04 18:02:49.041719: I tensorflow/core/common_runtime/bfc_allocator.cc:1071]      Summary of in-use Chunks by size:
2022-05-04 18:02:49.042440: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 16 Chunks of size 256 totalling 4.0KiB
2022-05-04 18:02:49.042831: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 512 totalling 512B
2022-05-04 18:02:49.043889: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 1280 totalling 1.2KiB
2022-05-04 18:02:49.044474: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 3584 totalling 3.5KiB
2022-05-04 18:02:49.044901: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 9728 totalling 9.5KiB
2022-05-04 18:02:49.045330: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 36864 totalling 36.0KiB
2022-05-04 18:02:49.045784: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 46727168 totalling 44.56MiB
2022-05-04 18:02:49.046196: I tensorflow/core/common_runtime/bfc_allocator.cc:1078] Sum Total of in-use chunks: 44.62MiB
2022-05-04 18:02:49.046552: I tensorflow/core/common_runtime/bfc_allocator.cc:1080] total_region_allocated_bytes_: 4859428864 memory_limit_: 4859428864 available bytes: 0 curr_region_allocation_bytes_: 9718857728
2022-05-04 18:02:49.046902: I tensorflow/core/common_runtime/bfc_allocator.cc:1086] Stats:
Limit:                      4859428864
InUse:                        46783232
MaxInUse:                    140225792
NumAllocs:                          34
MaxAllocSize:                 46727168
Reserved:                            0
PeakReserved:                        0
LargestFreeBlock:                    0

2022-05-04 18:02:49.047317: W tensorflow/core/common_runtime/bfc_allocator.cc:474] ***_________________________________________________________________________________________________
Traceback (most recent call last):
  File ""D:\DatasetProcessing\ImageClassification.py"", line 394, in <module>
    main()
  File ""D:\DatasetProcessing\ImageClassification.py"", line 387, in main
    first_model()
  File ""D:\DatasetProcessing\ImageClassification.py"", line 162, in first_model
    history = model.fit(train_images, train_labels, batch_size=2, epochs=4)
  File ""D:\WinPython\WPy64-3980\python-3.9.8.amd64\lib\site-packages\keras\utils\traceback_utils.py"", line 67, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File ""D:\WinPython\WPy64-3980\python-3.9.8.amd64\lib\site-packages\tensorflow\python\framework\constant_op.py"", line 102, in convert_to_eager_tensor
    return ops.EagerTensor(value, ctx.device_name, dtype)
tensorflow.python.framework.errors_impl.InternalError: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.

I have a notebook with nvidia gtx 1060 (6GB) gpu. I've installed the newest driver available for this gpu and cuda version 11.2. I checked gpu values in task manager when script was running but it was 1% up to 5%. It looks like tensorflow is not using gpu at all.

I tried to use:

TF_GPU_ALLOCATOR=cuda_malloc_async

and

memory_limit=4096

and

allow_growth=True

I've also decreased batch_size from 128 to 2. But neither of these options worked.
```


### Standalone code to reproduce the issue

```shell
model = tf.keras.Sequential([
            tf.keras.layers.Conv2D(32, (3,3), activation = 'relu', input_shape = (200, 256, 3)),
            tf.keras.layers.MaxPooling2D(2,2),
            tf.keras.layers.Conv2D(32, (3,3), activation = 'relu'),
            tf.keras.layers.MaxPooling2D(2,2),
            tf.keras.layers.Flatten(),
            tf.keras.layers.Dense(128, activation = tf.nn.relu),
            tf.keras.layers.Dense(20, activation = tf.nn.softmax)
        ])
model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics=['accuracy'])
history = model.fit(train_images, train_labels, batch_size=2, epochs=4)
```


### Relevant log output

_No response_</details>"
55973,[XLA]  Regression in NLP Models w/ error Tile Op must be a compile time constant,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

TF 2.8

### Custom Code

No

### OS Platform and Distribution

Linux Ubuntu 18.04

### Mobile device

_No response_

### Python version

3.9

### Bazel version

4.2.1

### GCC/Compiler version

9.4.0

### CUDA/cuDNN version

11.2

### GPU model and memory

Tesla V100 , 16384MiB

### Current Behaviour?

```shell
Currently it fails in masked_sparse_categorical_crossentropy loss function and complains about a Tile Op. However this op hasn't changed since TF2.7 XLA which means that the source of the error is probably somewhere since this error doesn't show up in TF2.7 XLA
```


### Standalone code to reproduce the issue

```shell
1. git clone https://github.com/huggingface/transformers.git 
2. pip3 install transformers==4.18.0, datasets==1.18.4, nltk, rouge_score, sacrebleu
3. cd transformers
4. python3 examples/tensorflow/summarization/run_summarization.py --model_name_or_path facebook/bart-base --dataset_name xsum --fp16 --do_train --output_dir ~/bart-test --per_device_train_batch_size 1 --overwrite_output_dir true --save_strategy no --num_train_epochs 1
```


### Relevant log output

```shell
2022-05-02 20:04:14.663607: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at tile_ops.cc:70 : INVALID_ARGUMENT: Input 1 to node `masked_sparse_categorical_crossentropy/RaggedReduceMean/RaggedReduceSum/RaggedSplitsToSegmentIds/Repeat/Tile` with op Tile must be a compile-time constant.

XLA compilation requires that operator arguments that represent shapes or dimensions be evaluated to concrete values at compile time. This error means that a shape or dimension argument could not be evaluated at compile time, usually because the value of the argument depends on a parameter to the computation, on a variable, or on a stateful operation such as a random number generator.

Traceback (most recent call last):
  File ""run_summarization.py"", line 674, in <module>
    main()
  File ""run_summarization.py"", line 632, in main
    steps_per_epoch=num_update_steps_per_epoch,
  File ""/home/ubuntu/anaconda3/lib/python3.7/site-packages/keras/utils/traceback_utils.py"", line 67, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File ""/home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/execute.py"", line 55, in quick_execute
    inputs, attrs, num_outputs)
tensorflow.python.framework.errors_impl.InvalidArgumentError: Graph execution error:

Detected at node 'masked_sparse_categorical_crossentropy/RaggedReduceMean/RaggedReduceSum/RaggedSplitsToSegmentIds/Repeat/Tile' defined at (most recent call last):
    File ""/home/ubuntu/anaconda3/lib/python3.7/threading.py"", line 890, in _bootstrap
      self._bootstrap_inner()
    File ""/home/ubuntu/anaconda3/lib/python3.7/threading.py"", line 926, in _bootstrap_inner
      self.run()
    File ""/home/ubuntu/anaconda3/lib/python3.7/site-packages/keras/engine/training.py"", line 1030, in run_step
      outputs = model.train_step(data)
    File ""/home/ubuntu/anaconda3/lib/python3.7/site-packages/transformers/modeling_tf_utils.py"", line 1000, in train_step
      loss = self.compiled_loss(y, y_pred, sample_weight, regularization_losses=self.losses)
    File ""/home/ubuntu/anaconda3/lib/python3.7/site-packages/keras/engine/compile_utils.py"", line 201, in __call__
      loss_value = loss_obj(y_t, y_p, sample_weight=sw)
    File ""/home/ubuntu/anaconda3/lib/python3.7/site-packages/keras/losses.py"", line 139, in __call__
      losses = call_fn(y_true, y_pred)
    File ""/home/ubuntu/anaconda3/lib/python3.7/site-packages/keras/losses.py"", line 243, in call
      return ag_fn(y_true, y_pred, **self._fn_kwargs)
    File ""run_summarization.py"", line 609, in masked_sparse_categorical_crossentropy
      losses = tf.reduce_mean(losses, axis=-1)
Node: 'masked_sparse_categorical_crossentropy/RaggedReduceMean/RaggedReduceSum/RaggedSplitsToSegmentIds/Repeat/Tile'
Detected at node 'masked_sparse_categorical_crossentropy/RaggedReduceMean/RaggedReduceSum/RaggedSplitsToSegmentIds/Repeat/Tile' defined at (most recent call last):
    File ""/home/ubuntu/anaconda3/lib/python3.7/threading.py"", line 890, in _bootstrap
      self._bootstrap_inner()
    File ""/home/ubuntu/anaconda3/lib/python3.7/threading.py"", line 926, in _bootstrap_inner
      self.run()
    File ""/home/ubuntu/anaconda3/lib/python3.7/site-packages/keras/engine/training.py"", line 1030, in run_step
      outputs = model.train_step(data)
    File ""/home/ubuntu/anaconda3/lib/python3.7/site-packages/transformers/modeling_tf_utils.py"", line 1000, in train_step
      loss = self.compiled_loss(y, y_pred, sample_weight, regularization_losses=self.losses)
    File ""/home/ubuntu/anaconda3/lib/python3.7/site-packages/keras/engine/compile_utils.py"", line 201, in __call__
      loss_value = loss_obj(y_t, y_p, sample_weight=sw)
    File ""/home/ubuntu/anaconda3/lib/python3.7/site-packages/keras/losses.py"", line 139, in __call__
      losses = call_fn(y_true, y_pred)
    File ""/home/ubuntu/anaconda3/lib/python3.7/site-packages/keras/losses.py"", line 243, in call
      return ag_fn(y_true, y_pred, **self._fn_kwargs)
    File ""run_summarization.py"", line 609, in masked_sparse_categorical_crossentropy
      losses = tf.reduce_mean(losses, axis=-1)
Node: 'masked_sparse_categorical_crossentropy/RaggedReduceMean/RaggedReduceSum/RaggedSplitsToSegmentIds/Repeat/Tile'
Detected at node 'masked_sparse_categorical_crossentropy/RaggedReduceMean/RaggedReduceSum/RaggedSplitsToSegmentIds/Repeat/Tile' defined at (most recent call last):
    File ""/home/ubuntu/anaconda3/lib/python3.7/threading.py"", line 890, in _bootstrap
      self._bootstrap_inner()
    File ""/home/ubuntu/anaconda3/lib/python3.7/threading.py"", line 926, in _bootstrap_inner
      self.run()
    File ""/home/ubuntu/anaconda3/lib/python3.7/site-packages/keras/engine/training.py"", line 1030, in run_step
      outputs = model.train_step(data)
    File ""/home/ubuntu/anaconda3/lib/python3.7/site-packages/transformers/modeling_tf_utils.py"", line 1000, in train_step
      loss = self.compiled_loss(y, y_pred, sample_weight, regularization_losses=self.losses)
    File ""/home/ubuntu/anaconda3/lib/python3.7/site-packages/keras/engine/compile_utils.py"", line 201, in __call__
      loss_value = loss_obj(y_t, y_p, sample_weight=sw)
    File ""/home/ubuntu/anaconda3/lib/python3.7/site-packages/keras/losses.py"", line 139, in __call__
      losses = call_fn(y_true, y_pred)
    File ""/home/ubuntu/anaconda3/lib/python3.7/site-packages/keras/losses.py"", line 243, in call
      return ag_fn(y_true, y_pred, **self._fn_kwargs)
    File ""run_summarization.py"", line 609, in masked_sparse_categorical_crossentropy
      losses = tf.reduce_mean(losses, axis=-1)
Node: 'masked_sparse_categorical_crossentropy/RaggedReduceMean/RaggedReduceSum/RaggedSplitsToSegmentIds/Repeat/Tile'
Detected at node 'masked_sparse_categorical_crossentropy/RaggedReduceMean/RaggedReduceSum/RaggedSplitsToSegmentIds/Repeat/Tile' defined at (most recent call last):
    File ""/home/ubuntu/anaconda3/lib/python3.7/threading.py"", line 890, in _bootstrap
      self._bootstrap_inner()
    File ""/home/ubuntu/anaconda3/lib/python3.7/threading.py"", line 926, in _bootstrap_inner
      self.run()
    File ""/home/ubuntu/anaconda3/lib/python3.7/site-packages/keras/engine/training.py"", line 1030, in run_step
      outputs = model.train_step(data)
    File ""/home/ubuntu/anaconda3/lib/python3.7/site-packages/transformers/modeling_tf_utils.py"", line 1000, in train_step
      loss = self.compiled_loss(y, y_pred, sample_weight, regularization_losses=self.losses)
    File ""/home/ubuntu/anaconda3/lib/python3.7/site-packages/keras/engine/compile_utils.py"", line 201, in __call__
      loss_value = loss_obj(y_t, y_p, sample_weight=sw)
    File ""/home/ubuntu/anaconda3/lib/python3.7/site-packages/keras/losses.py"", line 139, in __call__
      losses = call_fn(y_true, y_pred)
    File ""/home/ubuntu/anaconda3/lib/python3.7/site-packages/keras/losses.py"", line 243, in call
      return ag_fn(y_true, y_pred, **self._fn_kwargs)
    File ""run_summarization.py"", line 609, in masked_sparse_categorical_crossentropy
      losses = tf.reduce_mean(losses, axis=-1)
Node: 'masked_sparse_categorical_crossentropy/RaggedReduceMean/RaggedReduceSum/RaggedSplitsToSegmentIds/Repeat/Tile'
Detected at node 'masked_sparse_categorical_crossentropy/RaggedReduceMean/RaggedReduceSum/RaggedSplitsToSegmentIds/Repeat/Tile' defined at (most recent call last):
    File ""/home/ubuntu/anaconda3/lib/python3.7/threading.py"", line 890, in _bootstrap
      self._bootstrap_inner()
    File ""/home/ubuntu/anaconda3/lib/python3.7/threading.py"", line 926, in _bootstrap_inner
      self.run()
    File ""/home/ubuntu/anaconda3/lib/python3.7/site-packages/keras/engine/training.py"", line 1030, in run_step
      outputs = model.train_step(data)
    File ""/home/ubuntu/anaconda3/lib/python3.7/site-packages/transformers/modeling_tf_utils.py"", line 1000, in train_step
      loss = self.compiled_loss(y, y_pred, sample_weight, regularization_losses=self.losses)
    File ""/home/ubuntu/anaconda3/lib/python3.7/site-packages/keras/engine/compile_utils.py"", line 201, in __call__
      loss_value = loss_obj(y_t, y_p, sample_weight=sw)
    File ""/home/ubuntu/anaconda3/lib/python3.7/site-packages/keras/losses.py"", line 139, in __call__
      losses = call_fn(y_true, y_pred)
    File ""/home/ubuntu/anaconda3/lib/python3.7/site-packages/keras/losses.py"", line 243, in call
      return ag_fn(y_true, y_pred, **self._fn_kwargs)
    File ""run_summarization.py"", line 609, in masked_sparse_categorical_crossentropy
      losses = tf.reduce_mean(losses, axis=-1)
Node: 'masked_sparse_categorical_crossentropy/RaggedReduceMean/RaggedReduceSum/RaggedSplitsToSegmentIds/Repeat/Tile'
5 root error(s) found.
  (0) INVALID_ARGUMENT:  Input 1 to node `masked_sparse_categorical_crossentropy/RaggedReduceMean/RaggedReduceSum/RaggedSplitsToSegmentIds/Repeat/Tile` with op Tile must be a compile-time constant.

XLA compilation requires that operator arguments that represent shapes or dimensions be evaluated to concrete values at compile time. This error means that a shape or dimension argument could not be evaluated at compile time, usually because the value of the argument depends on a parameter to the computation, on a variable, or on a stateful operation such as a random number generator.

         [[{{node masked_sparse_categorical_crossentropy/RaggedReduceMean/RaggedReduceSum/RaggedSplitsToSegmentIds/Repeat/Tile}}]]
         [[cluster_14_1/xla_compile]]
         [[div_no_nan/ReadVariableOp_1/_1416]]
  (1) INVALID_ARGUMENT:  Input 1 to node `masked_sparse_categorical_crossentropy/RaggedReduceMean/RaggedReduceSum/RaggedSplitsToSegmentIds/Repeat/Tile` with op Tile must be a compile-time constant.

XLA compilation requires that operator arguments that represent shapes or dimensions be evaluated to concrete values at compile time. This error means that a shape or dimension argument could not be evaluated at compile time, usually because the value of the argument depends on a parameter to the computation, on a variable, or on a stateful operation such as a random number generator.

         [[{{node masked_sparse_categorical_crossentropy/RaggedReduceMean/RaggedReduceSum/RaggedSplitsToSegmentIds/Repeat/Tile}}]]
         [[cluster_14_1/xla_compile]]
         [[cond_2/Identity_3/_121/_3964]]
  (2) INVALID_ARGUMENT:  Input 1 to node `masked_sparse_categorical_crossentropy/RaggedReduceMean/RaggedReduceSum/RaggedSplitsToSegmentIds/Repeat/Tile` with op Tile must be a compile-time constant.

XLA compilation requires that operator arguments that represent shapes or dimensions be evaluated to concrete values at compile time. This error means that a shape or dimension argument could not be evaluated at compile time, usually because the value of the argument depends on a parameter to the computation, on a variable, or on a stateful operation such as a random number generator.

         [[{{node masked_sparse_categorical_crossentropy/RaggedReduceMean/RaggedReduceSum/RaggedSplitsToSegmentIds/Repeat/Tile}}]]
         [[cluster_14_1/xla_compile]]
         [[cluster_282_1/data_as_ctrl/_1595]]
  (3) INVALID_ARGUMENT:  Input 1 to node `masked_sparse_categorical_crossentropy/RaggedReduceMean/RaggedReduceSum/RaggedSplitsToSegmentIds/Repeat/Tile` with op Tile must be a compile-time constant.

XLA compilation requires that operator arguments that represent shapes or dimensions be evaluated to concrete values at compile time. This error means that a shape or dimension argument could not be evaluated at compile time, usually because the value of the argument depends on a parameter to the computation, on a variable, or on a stateful operation such as a random number generator.

         [[{{node masked_sparse_categorical_crossentropy/RaggedReduceMean/RaggedReduceSum/RaggedSplitsToSegmentIds/Repeat/Tile}}]]
         [[cluster_14_1/xla_compile]]
         [[cluster_264_1/merge_oidx_5/_9670]]
  (4) INVALID_ARGUMENT:  Input 1 to node `masked_sparse_categorical_crossentropy/RaggedReduceMean/RaggedReduceSum/RaggedSplitsToSegmentIds/Repeat/Tile` with op Tile must be a compile-time constant.

XLA compilation requires that operator arguments that represent shapes or dimensions be evaluated to concrete values at compile time. This error means that a shape or dimension argument could not be evaluated at compile time, usually because the value of the argument depends on a parameter to the computation, on a variable, or on a stateful operation such as a random number generator.

         [[{{node masked_sparse_categorical_crossentropy/RaggedReduceMean/RaggedReduceSum/RaggedSplitsToSegmentIds/Repeat/Tile}}]]
         [[cluster_14_1/xla_compile]]
0 successful operations.
0 derived errors ignored. [Op:__inference_train_function_161679]
2022-05-28 02:07:07.336896: W tensorflow/core/kernels/data/generator_dataset_op.cc:108] Error occurred when finalizing GeneratorDataset iterator: FAILED_PRECONDITION: Python interpreter state is not initialized. The process may be terminated.
         [[{{node PyFunc}}]]
```
</details>"
55972,how to save checkpoint in between each epochs and retain them after and continue ?,"how to save checkpoint in Google colab while training for tflite , save checkpoint after  each epochs and continue after..."
55971,Sparse_ops.sparse_tensor_dense_mat_mul breaks in tensorflow > 2.5: TypeError: You are passing KerasTensor... to a TF API that does not allow registering custom dispatchers.,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

tf 2.8

### Custom Code

No

### OS Platform and Distribution

Ubuntu, Google colabs

### Mobile device

-

### Python version

3.7.13

### Bazel version

-

### GCC/Compiler version

-

### CUDA/cuDNN version

-

### GPU model and memory

-

### Current Behaviour?

```shell
After updating Tensorflow 2.5 to 2.8 sparse_ops.sparse_tensor_dense_mat_mul raises a TypeError: You are passing KerasTensor... to a TF API that does not allow registering custom dispatchers. 

Code works for all versions of Tensorflow < 2.6. Changelogs do not indicate any changes related to this issue.
```


### Standalone code to reproduce the issue

```shell
Tensorflow 2.8 error example in google Colab:

https://colab.research.google.com/drive/1-VdUch8mJt5x1h3_tmJIR2Fcic_dBZLv?usp=sharing

Working example 2.5 and lower:
https://colab.research.google.com/drive/1zQ4GbBFVpuw2552Y0F827ddaXp8HwuyP?usp=sharing
```


### Relevant log output

```shell
TypeError                                 Traceback (most recent call last)
<ipython-input-9-473c8df7879f> in <module>()
      3 genemask, gene_end = make_mask_gene_layer(inputsize)  # get the mask to know which SNP connect to which gene
      4 
----> 5 model = GenNet_proof_of_concept_network(inputsize=int(inputsize), mask=genemask)  # create the neural network
      6 
      7 model.compile(loss=weighted_binary_crossentropy, optimizer=optimizer, metrics=[""accuracy"", sensitivity, specificity]) # compile the network

14 frames
<ipython-input-8-b62cfcdf7ff5> in GenNet_proof_of_concept_network(inputsize, mask)
     12 
     13     # next line we use the new Gennet layer (LocallyDirected1D) to define all the connections ourself
---> 14     Gene_layer = LocallyDirected1D(mask=mask, filters=1, input_shape=(inputsize, 1), name=""gene_layer"",)(Input_layer)
     15     Gene_layer = K.layers.Flatten()(Gene_layer)
     16     Gene_layer = K.layers.Activation(""tanh"")(Gene_layer) #gene layer

/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py in __call__(self, *args, **kwargs)
   1042         with autocast_variable.enable_auto_cast_variables(
   1043             self._compute_dtype_object):
-> 1044           outputs = call_fn(inputs, *args, **kwargs)
   1045 
   1046         if self._activity_regularizer:

<ipython-input-5-81f98e70498d> in call(self, inputs)
    149     def call(self, inputs):
    150 
--> 151         output = local_conv_matmul_sparse(inputs, self.mask, self.kernel, self.kernel_idx, self.output_length, self.filters)
    152 
    153         if self.use_bias:

<ipython-input-5-81f98e70498d> in local_conv_matmul_sparse(inputs, mask, kernel, kernel_idx, output_length, filters)
    188 
    189     output_flat = Kb.sparse_ops.sparse_tensor_dense_mat_mul(
--> 190         kernel_idx, kernel, (mask.shape[1], mask.shape[0]), inputs_flat, adjoint_b=True)
    191 
    192 

/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_sparse_ops.py in sparse_tensor_dense_mat_mul(a_indices, a_values, a_shape, b, adjoint_a, adjoint_b, name)
   3055       return sparse_tensor_dense_mat_mul_eager_fallback(
   3056           a_indices, a_values, a_shape, b, adjoint_a=adjoint_a,
-> 3057           adjoint_b=adjoint_b, name=name, ctx=_ctx)
   3058     except _core._SymbolicException:
   3059       pass  # Add nodes to the TensorFlow graph.

/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_sparse_ops.py in sparse_tensor_dense_mat_mul_eager_fallback(a_indices, a_values, a_shape, b, adjoint_a, adjoint_b, name, ctx)
   3091     adjoint_b = False
   3092   adjoint_b = _execute.make_bool(adjoint_b, ""adjoint_b"")
-> 3093   _attr_T, _inputs_T = _execute.args_to_matching_eager([a_values, b], ctx, [])
   3094   (a_values, b) = _inputs_T
   3095   _attr_Tindices, (a_indices,) = _execute.args_to_matching_eager([a_indices], ctx, [_dtypes.int32, _dtypes.int64, ], _dtypes.int64)

/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py in args_to_matching_eager(l, ctx, allowed_dtypes, default_dtype)
    263       if tensor is None:
    264         tensor = ops.convert_to_tensor(
--> 265             t, dtype, preferred_dtype=default_dtype, ctx=ctx)
    266 
    267       ret.append(tensor)

/usr/local/lib/python3.7/dist-packages/tensorflow/python/profiler/trace.py in wrapped(*args, **kwargs)
    181         with Trace(trace_name, **trace_kwargs):
    182           return func(*args, **kwargs)
--> 183       return func(*args, **kwargs)
    184 
    185     return wrapped

/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py in convert_to_tensor(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)
   1693 
   1694     if ret is None:
-> 1695       ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
   1696 
   1697     if ret is NotImplemented:

/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py in _constant_tensor_conversion_function(v, dtype, name, as_ref)
    341                                          as_ref=False):
    342   _ = as_ref
--> 343   return constant(v, dtype=dtype, name=name)
    344 
    345 

/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py in constant(value, dtype, shape, name)
    266   """"""
    267   return _constant_impl(value, dtype, shape, name, verify_shape=False,
--> 268                         allow_broadcast=True)
    269 
    270 

/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py in _constant_impl(value, dtype, shape, name, verify_shape, allow_broadcast)
    277       with trace.Trace(""tf.constant""):
    278         return _constant_eager_impl(ctx, value, dtype, shape, verify_shape)
--> 279     return _constant_eager_impl(ctx, value, dtype, shape, verify_shape)
    280 
    281   g = ops.get_default_graph()

/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py in _constant_eager_impl(ctx, value, dtype, shape, verify_shape)
    302 def _constant_eager_impl(ctx, value, dtype, shape, verify_shape):
    303   """"""Creates a constant on the current device.""""""
--> 304   t = convert_to_eager_tensor(value, ctx, dtype)
    305   if shape is None:
    306     return t

/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py in convert_to_eager_tensor(value, ctx, dtype)
    100       dtype = dtypes.as_dtype(dtype).as_datatype_enum
    101   ctx.ensure_initialized()
--> 102   return ops.EagerTensor(value, ctx.device_name, dtype)
    103 
    104 

/usr/local/lib/python3.7/dist-packages/keras/engine/keras_tensor.py in __array__(self, dtype)
    253   def __array__(self, dtype=None):
    254     raise TypeError(
--> 255         f'You are passing {self}, an intermediate Keras symbolic input/output, '
    256         'to a TF API that does not allow registering custom dispatchers, such '
    257         'as `tf.cond`, `tf.function`, gradient tapes, or `tf.map_fn`. '

TypeError: You are passing KerasTensor(type_spec=TensorSpec(shape=(None, None), dtype=tf.float32, name=None), name='tf.reshape/Reshape:0', description=""created by layer 'tf.reshape'""), an intermediate Keras symbolic input/output, to a TF API that does not allow registering custom dispatchers, such as `tf.cond`, `tf.function`, gradient tapes, or `tf.map_fn`. Keras Functional model construction only supports TF API calls that *do* support dispatching, such as `tf.math.add` or `tf.reshape`. Other APIs cannot be called directly on symbolic Kerasinputs/outputs. You can work around this limitation by putting the operation in a custom Keras layer `call` and calling that layer on this symbolic input/output.
```
</details>"
55970,TensorFlow Lite build with CMake does not produce a binary on Windows,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Build/Install

### Source

source

### Tensorflow Version

tf 2.8

### Custom Code

No

### OS Platform and Distribution

Windows 10

### Mobile device

-

### Python version

-

### Bazel version

-

### GCC/Compiler version

MSVC 19.31.31104.0

### CUDA/cuDNN version

-

### GPU model and memory

-

### Current Behaviour?

```shell
I am building TF Lite with CMake. On Ubuntu and MacOS there is no problem and it works just fine.
However, on Windows the build just stops at `generating code...`.

I am following [this guide](https://www.tensorflow.org/lite/guide/build_cmake)
```


### Standalone code to reproduce the issue

```shell
bash
git clone https://github.com/tensorflow/tensorflow tensorflow_src
cd tensorflow_src
git checkout r2.8
cd ..

mkdir tflite_build
cd tflite_build
cmake ../tensorflow_src/tensorflow/lite/c
cmake --build .
```

When now checking the build directory with `ls -a tflite_build/` there is no output file.
```


### Relevant log output

```shell
PS C:\Users\Dario\dev\tflite_build> cmake ../tensorflow_src/tensorflow/lite/c
-- Building for: Visual Studio 17 2022
-- Selecting Windows SDK version 10.0.19041.0 to target Windows 10.0.19044.
-- The C compiler identification is MSVC 19.31.31104.0
-- The CXX compiler identification is MSVC 19.31.31104.0
-- Detecting C compiler ABI info
-- Detecting C compiler ABI info - done
-- Check for working C compiler: C:/Program Files/Microsoft Visual Studio/2022/Community/VC/Tools/MSVC/14.31.31103/bin/Hostx64/x64/cl.exe - skipped
-- Detecting C compile features
-- Detecting C compile features - done
-- Detecting CXX compiler ABI info
-- Detecting CXX compiler ABI info - done
-- Check for working CXX compiler: C:/Program Files/Microsoft Visual Studio/2022/Community/VC/Tools/MSVC/14.31.31103/bin/Hostx64/x64/cl.exe - skipped
-- Detecting CXX compile features
-- Detecting CXX compile features - done
-- Setting build type to Release, for debug builds use'-DCMAKE_BUILD_TYPE=Debug'.
-- Looking for pthread.h
-- Looking for pthread.h - not found
-- Found Threads: TRUE
-- Performing Test standard_math_library_linked_to_automatically
-- Performing Test standard_math_library_linked_to_automatically - Success
-- Standard libraries to link to explicitly: none
-- Performing Test COMPILER_SUPPORT_OPENMP
-- Performing Test COMPILER_SUPPORT_OPENMP - Success
-- Looking for a Fortran compiler
-- Looking for a Fortran compiler - NOTFOUND
-- Could NOT find CLANG_FORMAT: Found unsuitable version ""0.0"", but required is exact version ""9"" (found CLANG_FORMAT_EXECUTABLE-NOTFOUND)
--
-- Configured Eigen 3.4.90
--
-- Performing Test FARMHASH_HAS_BUILTIN_EXPECT
-- Performing Test FARMHASH_HAS_BUILTIN_EXPECT - Failed
-- Looking for _strtof_l
-- Looking for _strtof_l - found
-- Looking for _strtoui64_l
-- Looking for _strtoui64_l - found
-- The ASM compiler identification is MSVC
-- Found assembler: C:/Program Files/Microsoft Visual Studio/2022/Community/VC/Tools/MSVC/14.31.31103/bin/Hostx64/x64/cl.exe
-- Downloading FP16 to C:/Users/Dario/dev/tflite_build/FP16-source (define FP16_SOURCE_DIR to avoid it)
-- Selecting Windows SDK version 10.0.19041.0 to target Windows 10.0.19044.
-- Configuring done
-- Generating done
-- Build files have been written to: C:/Users/Dario/dev/tflite_build/FP16-download
Microsoft (R) Build Engine version 17.1.0+ae57d105c for .NET Framework
Copyright (C) Microsoft Corporation. All rights reserved.

  Checking Build System
  Creating directories for 'fp16'
  Building Custom Rule C:/Users/Dario/dev/tflite_build/FP16-download/CMakeLists.txt
  Performing download step (download, verify and extract) for 'fp16'
  -- Downloading...
     dst='C:/Users/Dario/dev/tflite_build/FP16-download/fp16-prefix/src/0a92994d729ff76a58f692d3028ca1b64b145d91.zip'
     timeout='none'
     inactivity timeout='none'
  -- Using src='https://github.com/Maratyszcza/FP16/archive/0a92994d729ff76a58f692d3028ca1b64b145d91.zip'
  -- verifying file...
         file='C:/Users/Dario/dev/tflite_build/FP16-download/fp16-prefix/src/0a92994d729ff76a58f692d3028ca1b64b145d91.zip'
  -- Downloading... done
  -- extracting...
       src='C:/Users/Dario/dev/tflite_build/FP16-download/fp16-prefix/src/0a92994d729ff76a58f692d3028ca1b64b145d91.zip'
       dst='C:/Users/Dario/dev/tflite_build/FP16-source'
  -- extracting... [tar xfz]
  -- extracting... [analysis]
  -- extracting... [rename]
  -- extracting... [clean up]
  -- extracting... done
  No update step for 'fp16'
  No patch step for 'fp16'
  No configure step for 'fp16'
  No build step for 'fp16'
  No install step for 'fp16'
  No test step for 'fp16'
  Completed 'fp16'
  Building Custom Rule C:/Users/Dario/dev/tflite_build/FP16-download/CMakeLists.txt
-- Downloading FXdiv to C:/Users/Dario/dev/tflite_build/FXdiv-source (define FXDIV_SOURCE_DIR to avoid it)
-- Selecting Windows SDK version 10.0.19041.0 to target Windows 10.0.19044.
-- Configuring done
-- Generating done
-- Build files have been written to: C:/Users/Dario/dev/tflite_build/FXdiv-download
Microsoft (R) Build Engine version 17.1.0+ae57d105c for .NET Framework
Copyright (C) Microsoft Corporation. All rights reserved.

  Checking Build System
  Creating directories for 'fxdiv'
  Building Custom Rule C:/Users/Dario/dev/tflite_build/FXdiv-download/CMakeLists.txt
  Performing download step (download, verify and extract) for 'fxdiv'
  -- Downloading...
     dst='C:/Users/Dario/dev/tflite_build/FXdiv-download/fxdiv-prefix/src/b408327ac2a15ec3e43352421954f5b1967701d1.zip'
     timeout='none'
     inactivity timeout='none'
  -- Using src='https://github.com/Maratyszcza/FXdiv/archive/b408327ac2a15ec3e43352421954f5b1967701d1.zip'
  -- verifying file...
         file='C:/Users/Dario/dev/tflite_build/FXdiv-download/fxdiv-prefix/src/b408327ac2a15ec3e43352421954f5b1967701d1.zip'
  -- Downloading... done
  -- extracting...
       src='C:/Users/Dario/dev/tflite_build/FXdiv-download/fxdiv-prefix/src/b408327ac2a15ec3e43352421954f5b1967701d1.zip'
       dst='C:/Users/Dario/dev/tflite_build/FXdiv-source'
  -- extracting... [tar xfz]
  -- extracting... [analysis]
  -- extracting... [rename]
  -- extracting... [clean up]
  -- extracting... done
  No update step for 'fxdiv'
  No patch step for 'fxdiv'
  No configure step for 'fxdiv'
  No build step for 'fxdiv'
  No install step for 'fxdiv'
  No test step for 'fxdiv'
  Completed 'fxdiv'
  Building Custom Rule C:/Users/Dario/dev/tflite_build/FXdiv-download/CMakeLists.txt
-- Downloading pthreadpool to C:/Users/Dario/dev/tflite_build/pthreadpool-source (define PTHREADPOOL_SOURCE_DIR to avoid it)
-- Selecting Windows SDK version 10.0.19041.0 to target Windows 10.0.19044.
-- Configuring done
-- Generating done
-- Build files have been written to: C:/Users/Dario/dev/tflite_build/pthreadpool-download
Microsoft (R) Build Engine version 17.1.0+ae57d105c for .NET Framework
Copyright (C) Microsoft Corporation. All rights reserved.

  Checking Build System
  Creating directories for 'pthreadpool'
  Building Custom Rule C:/Users/Dario/dev/tflite_build/pthreadpool-download/CMakeLists.txt
  Performing download step (download, verify and extract) for 'pthreadpool'
  -- Downloading...
     dst='C:/Users/Dario/dev/tflite_build/pthreadpool-download/pthreadpool-prefix/src/545ebe9f225aec6dca49109516fac02e973a3de2.zip'
     timeout='none'
     inactivity timeout='none'
  -- Using src='https://github.com/Maratyszcza/pthreadpool/archive/545ebe9f225aec6dca49109516fac02e973a3de2.zip'
  -- verifying file...
         file='C:/Users/Dario/dev/tflite_build/pthreadpool-download/pthreadpool-prefix/src/545ebe9f225aec6dca49109516fac02e973a3de2.zip'
  -- Downloading... done
  -- extracting...
       src='C:/Users/Dario/dev/tflite_build/pthreadpool-download/pthreadpool-prefix/src/545ebe9f225aec6dca49109516fac02e973a3de2.zip'
       dst='C:/Users/Dario/dev/tflite_build/pthreadpool-source'
  -- extracting... [tar xfz]
  -- extracting... [analysis]
  -- extracting... [rename]
  -- extracting... [clean up]
  -- extracting... done
  No update step for 'pthreadpool'
  No patch step for 'pthreadpool'
  No configure step for 'pthreadpool'
  No build step for 'pthreadpool'
  No install step for 'pthreadpool'
  No test step for 'pthreadpool'
  Completed 'pthreadpool'
  Building Custom Rule C:/Users/Dario/dev/tflite_build/pthreadpool-download/CMakeLists.txt
-- Downloading PSimd to C:/Users/Dario/dev/tflite_build/psimd-source (define PSIMD_SOURCE_DIR to avoid it)
-- Selecting Windows SDK version 10.0.19041.0 to target Windows 10.0.19044.
-- Configuring done
-- Generating done
-- Build files have been written to: C:/Users/Dario/dev/tflite_build/psimd-download
Microsoft (R) Build Engine version 17.1.0+ae57d105c for .NET Framework
Copyright (C) Microsoft Corporation. All rights reserved.

  Checking Build System
  Creating directories for 'psimd'
  Building Custom Rule C:/Users/Dario/dev/tflite_build/psimd-download/CMakeLists.txt
  Performing download step (git clone) for 'psimd'
  Cloning into 'psimd-source'...
  Your branch is up to date with 'origin/master'.
  Already on 'master'
  Performing update step for 'psimd'
  HEAD is now at 072586a Fix psimd_qfma_f32 for FMA-enabled x86 processors
  No patch step for 'psimd'
  No configure step for 'psimd'
  No build step for 'psimd'
  No install step for 'psimd'
  No test step for 'psimd'
  Completed 'psimd'
  Building Custom Rule C:/Users/Dario/dev/tflite_build/psimd-download/CMakeLists.txt
-- Configuring done
-- Generating done
-- Build files have been written to: C:/Users/Dario/dev/tflite_build
PS C:\Users\Dario\dev\tflite_build> cmake --build . -j
Microsoft (R) Build Engine version 17.1.0+ae57d105c for .NET Framework
Copyright (C) Microsoft Corporation. All rights reserved.

  Checking Build System
  Building Custom Rule C:/Users/Dario/dev/tflite_build/clog/deps/clog/CMakeLists.txt
  clog.c
  Building Custom Rule C:/Users/Dario/dev/tflite_build/abseil-cpp/absl/base/CMakeLists.txt
  Building Custom Rule C:/Users/Dario/dev/tflite_build/abseil-cpp/absl/time/CMakeLists.txt
  Building Custom Rule C:/Users/Dario/dev/tflite_build/abseil-cpp/absl/base/CMakeLists.txt
  Building Custom Rule C:/Users/Dario/dev/tflite_build/abseil-cpp/absl/numeric/CMakeLists.txt
  Building Custom Rule C:/Users/Dario/dev/tflite_build/pthreadpool-source/CMakeLists.txt
  Building Custom Rule C:/Users/Dario/dev/tflite_build/abseil-cpp/absl/base/CMakeLists.txt
  portable-api.c
  Building Custom Rule C:/Users/Dario/dev/tflite_build/abseil-cpp/absl/flags/CMakeLists.txt
  log_severity.cc
  civil_time_detail.cc
  int128.cc
  spinlock_wait.cc
  Building Custom Rule C:/Users/Dario/dev/tflite_build/abseil-cpp/absl/time/CMakeLists.txt
C:\Program Files (x86)\Windows Kits\10\Include\10.0.19041.0\um\winbase.h(9531,5): warning C5105: macro expansion producing 'defined' has undefined behavior [C:\Users\Dario\dev\tflite_build\pthreadpool\pthreadpoo
l.vcxproj]
  commandlineflag.cc
  exponential_biased.cc
  time_zone_fixed.cc
  clog.vcxproj -> C:\Users\Dario\dev\tflite_build\_deps\clog-build\Debug\clog.lib
  absl_spinlock_wait.vcxproj -> C:\Users\Dario\dev\tflite_build\_deps\abseil-cpp-build\absl\base\Debug\absl_spinlock_wait.lib
  absl_flags_commandlineflag_internal.vcxproj -> C:\Users\Dario\dev\tflite_build\_deps\abseil-cpp-build\absl\flags\Debug\absl_flags_commandlineflag_internal.lib
  Building Custom Rule C:/Users/Dario/dev/tensorflow_src/tensorflow/lite/tools/cmake/modules/fft2d/CMakeLists.txt
  Building Custom Rule C:/Users/Dario/dev/tensorflow_src/tensorflow/lite/tools/cmake/modules/farmhash/CMakeLists.txt
  Building Custom Rule C:/Users/Dario/dev/tflite_build/flatbuffers/CMakeLists.txt
  memory.c
  Building Custom Rule C:/Users/Dario/dev/tflite_build/ruy/ruy/CMakeLists.txt
  absl_civil_time.vcxproj -> C:\Users\Dario\dev\tflite_build\_deps\abseil-cpp-build\absl\time\Debug\absl_civil_time.lib
  fftsg.c
  Building Custom Rule C:/Users/Dario/dev/tflite_build/ruy/ruy/profiler/CMakeLists.txt
  Building Custom Rule C:/Users/Dario/dev/tflite_build/ruy/ruy/CMakeLists.txt
  apply_multiplier.cc
  absl_exponential_biased.vcxproj -> C:\Users\Dario\dev\tflite_build\_deps\abseil-cpp-build\absl\base\Debug\absl_exponential_biased.lib
  farmhash.cc
  idl_parser.cpp
  absl_log_severity.vcxproj -> C:\Users\Dario\dev\tflite_build\_deps\abseil-cpp-build\absl\base\Debug\absl_log_severity.lib
  fft2d_fftsg.vcxproj -> C:\Users\Dario\dev\tflite_build\_deps\fft2d-build\Debug\fft2d_fftsg.lib
  instrumentation.cc
  time_zone_format.cc
  absl_int128.vcxproj -> C:\Users\Dario\dev\tflite_build\_deps\abseil-cpp-build\absl\numeric\Debug\absl_int128.lib
C:\Program Files (x86)\Windows Kits\10\Include\10.0.19041.0\um\winbase.h(9531,5): warning C5105: macro expansion producing 'defined' has undefined behavior [C:\Users\Dario\dev\tflite_build\pthreadpool\pthreadpoo
l.vcxproj]
  system_aligned_alloc.cc
C:\Users\Dario\dev\tflite_build\farmhash\src\farmhash.cc(394,1): warning C4319: '~': zero extending 'uint32_t' to 'T' of greater size [C:\Users\Dario\dev\tflite_build\_deps\farmhash-build\farmhash.vcxproj]
          with
          [
              T=uint64_t
          ]
C:\Users\Dario\dev\tflite_build\farmhash\src\farmhash.cc(404): message : see reference to function template instantiation 'T util::DebugTweak<uint64_t>(T)' being compiled [C:\Users\Dario\dev\tflite_build\_deps\f
armhash-build\farmhash.vcxproj]
          with
          [
              T=uint64_t
          ]
  Building Custom Rule C:/Users/Dario/dev/tflite_build/ruy/ruy/CMakeLists.txt
  Building Custom Rule C:/Users/Dario/dev/tflite_build/ruy/ruy/CMakeLists.txt
  ruy_profiler_instrumentation.vcxproj -> C:\Users\Dario\dev\tflite_build\_deps\ruy-build\ruy\profiler\Debug\ruy_profiler_instrumentation.lib
  Building Custom Rule C:/Users/Dario/dev/tflite_build/ruy/ruy/CMakeLists.txt
  Building Custom Rule C:/Users/Dario/dev/tflite_build/ruy/ruy/CMakeLists.txt
  Building Custom Rule C:/Users/Dario/dev/tflite_build/ruy/ruy/CMakeLists.txt
  have_built_path_for_avx.cc
  ruy_system_aligned_alloc.vcxproj -> C:\Users\Dario\dev\tflite_build\_deps\ruy-build\ruy\Debug\ruy_system_aligned_alloc.lib
  wait.cc
  farmhash.vcxproj -> C:\Users\Dario\dev\tflite_build\_deps\farmhash-build\Debug\farmhash.lib
  denormal.cc
  Building Custom Rule C:/Users/Dario/dev/tflite_build/ruy/ruy/CMakeLists.txt
  have_built_path_for_avx512.cc
  have_built_path_for_avx2_fma.cc
  ruy_have_built_path_for_avx.vcxproj -> C:\Users\Dario\dev\tflite_build\_deps\ruy-build\ruy\Debug\ruy_have_built_path_for_avx.lib
  ruy_apply_multiplier.vcxproj -> C:\Users\Dario\dev\tflite_build\_deps\ruy-build\ruy\Debug\ruy_apply_multiplier.lib
  allocator.cc
  windows.c
  time_zone_if.cc
  ruy_denormal.vcxproj -> C:\Users\Dario\dev\tflite_build\_deps\ruy-build\ruy\Debug\ruy_denormal.lib
  ruy_have_built_path_for_avx2_fma.vcxproj -> C:\Users\Dario\dev\tflite_build\_deps\ruy-build\ruy\Debug\ruy_have_built_path_for_avx2_fma.lib
  ruy_have_built_path_for_avx512.vcxproj -> C:\Users\Dario\dev\tflite_build\_deps\ruy-build\ruy\Debug\ruy_have_built_path_for_avx512.lib
  Building Custom Rule C:/Users/Dario/dev/tflite_build/abseil-cpp/absl/base/CMakeLists.txt
  Building Custom Rule C:/Users/Dario/dev/tensorflow_src/tensorflow/lite/tools/cmake/modules/fft2d/CMakeLists.txt
  Building Custom Rule C:/Users/Dario/dev/tflite_build/cpuinfo/CMakeLists.txt
  Building Custom Rule C:/Users/Dario/dev/tflite_build/ruy/ruy/CMakeLists.txt
C:\Program Files (x86)\Windows Kits\10\Include\10.0.19041.0\um\winbase.h(9531,5): warning C5105: macro expansion producing 'defined' has undefined behavior [C:\Users\Dario\dev\tflite_build\pthreadpool\pthreadpoo
l.vcxproj]
  raw_logging.cc
  Building Custom Rule C:/Users/Dario/dev/tflite_build/ruy/ruy/CMakeLists.txt
  init.c
  ruy_wait.vcxproj -> C:\Users\Dario\dev\tflite_build\_deps\ruy-build\ruy\Debug\ruy_wait.lib
  fftsg2d.c
  Building Custom Rule C:/Users/Dario/dev/tflite_build/ruy/ruy/CMakeLists.txt
  ruy_allocator.vcxproj -> C:\Users\Dario\dev\tflite_build\_deps\ruy-build\ruy\Debug\ruy_allocator.lib
  time_zone_impl.cc
  block_map.cc
  prepacked_cache.cc
  fft2d_fftsg2d.vcxproj -> C:\Users\Dario\dev\tflite_build\_deps\fft2d-build\Debug\fft2d_fftsg2d.lib
  blocking_counter.cc
  api.c
  fastpath.c
  absl_raw_logging_internal.vcxproj -> C:\Users\Dario\dev\tflite_build\_deps\abseil-cpp-build\absl\base\Debug\absl_raw_logging_internal.lib
  ruy_block_map.vcxproj -> C:\Users\Dario\dev\tflite_build\_deps\ruy-build\ruy\Debug\ruy_block_map.lib
  cache.c
  Building Custom Rule C:/Users/Dario/dev/tflite_build/abseil-cpp/absl/debugging/CMakeLists.txt
  Building Custom Rule C:/Users/Dario/dev/tflite_build/abseil-cpp/absl/types/CMakeLists.txt
  Building Custom Rule C:/Users/Dario/dev/tflite_build/abseil-cpp/absl/base/CMakeLists.txt
  ruy_prepacked_cache.vcxproj -> C:\Users\Dario\dev\tflite_build\_deps\ruy-build\ruy\Debug\ruy_prepacked_cache.lib
C:\Program Files (x86)\Windows Kits\10\Include\10.0.19041.0\um\winbase.h(9531,5): warning C5105: macro expansion producing 'defined' has undefined behavior [C:\Users\Dario\dev\tflite_build\pthreadpool\pthreadpoo
l.vcxproj]
  Building Custom Rule C:/Users/Dario/dev/tflite_build/abseil-cpp/absl/types/CMakeLists.txt
  address_is_readable.cc
  ruy_blocking_counter.vcxproj -> C:\Users\Dario\dev\tflite_build\_deps\ruy-build\ruy\Debug\ruy_blocking_counter.lib
  time_zone_info.cc
  bad_optional_access.cc
  throw_delegate.cc
  elf_mem_image.cc
  idl_gen_text.cpp
  vdso_support.cc
  Building Custom Rule C:/Users/Dario/dev/tflite_build/ruy/ruy/CMakeLists.txt
  info.c
  vendor.c
  Generating Code...
  uarch.c
  Building Custom Rule C:/Users/Dario/dev/tflite_build/abseil-cpp/absl/base/CMakeLists.txt
  bad_variant_access.cc
  name.c
  topology.c
  isa.c
  descriptor.c
  deterministic.c
  absl_debugging_internal.vcxproj -> C:\Users\Dario\dev\tflite_build\_deps\abseil-cpp-build\absl\debugging\Debug\absl_debugging_internal.lib
  Generating Code...
  cycleclock.cc
  Generating Code...
  thread_pool.cc
  Building Custom Rule C:/Users/Dario/dev/tflite_build/abseil-cpp/absl/debugging/CMakeLists.txt
  init.c
  time_zone_libc.cc
  spinlock.cc
  absl_throw_delegate.vcxproj -> C:\Users\Dario\dev\tflite_build\_deps\abseil-cpp-build\absl\base\Debug\absl_throw_delegate.lib
  absl_bad_optional_access.vcxproj -> C:\Users\Dario\dev\tflite_build\_deps\abseil-cpp-build\absl\types\Debug\absl_bad_optional_access.lib
  pthreadpool.vcxproj -> C:\Users\Dario\dev\tflite_build\pthreadpool\Debug\pthreadpool.lib
  stacktrace.cc
  absl_bad_variant_access.vcxproj -> C:\Users\Dario\dev\tflite_build\_deps\abseil-cpp-build\absl\types\Debug\absl_bad_variant_access.lib
  init.c
  init.c
  ruy_thread_pool.vcxproj -> C:\Users\Dario\dev\tflite_build\_deps\ruy-build\ruy\Debug\ruy_thread_pool.lib
  time_zone_lookup.cc
  sysinfo.cc
  absl_stacktrace.vcxproj -> C:\Users\Dario\dev\tflite_build\_deps\abseil-cpp-build\absl\debugging\Debug\absl_stacktrace.lib
  reflection.cpp
  cpuinfo.vcxproj -> C:\Users\Dario\dev\tflite_build\_deps\cpuinfo-build\Debug\cpuinfo.lib
  Building Custom Rule C:/Users/Dario/dev/tflite_build/ruy/ruy/CMakeLists.txt
  Building Custom Rule C:/Users/Dario/dev/tflite_build/xnnpack/CMakeLists.txt
  cpuinfo.cc
  time_zone_posix.cc
  ruy_cpuinfo.vcxproj -> C:\Users\Dario\dev\tflite_build\_deps\ruy-build\ruy\Debug\ruy_cpuinfo.lib
  Building Custom Rule C:/Users/Dario/dev/tflite_build/ruy/ruy/CMakeLists.txt
  zone_info_source.cc
  argmax-pooling-nhwc.c
  tune.cc
C:\Users\Dario\dev\tflite_build\xnnpack\src\operators\argmax-pooling-nhwc.c(234,81): warning C4090: 'function': different 'const' qualifiers [C:\Users\Dario\dev\tflite_build\_deps\xnnpack-build\XNNPACK.vcxproj]
  average-pooling-nhwc.c
  thread_identity.cc
C:\Users\Dario\dev\tflite_build\xnnpack\src\operators\average-pooling-nhwc.c(523,84): warning C4090: 'function': different 'const' qualifiers [C:\Users\Dario\dev\tflite_build\_deps\xnnpack-build\XNNPACK.vcxproj]
  binary-elementwise-nd.c
  channel-shuffle-nc.c
  Generating Code...
  constant-pad-nd.c
  convolution-nchw.c
  convolution-nhwc.c
  util.cpp
  ruy_tune.vcxproj -> C:\Users\Dario\dev\tflite_build\_deps\ruy-build\ruy\Debug\ruy_tune.lib
C:\Users\Dario\dev\tflite_build\xnnpack\src\operators\convolution-nhwc.c(1323,82): warning C4090: 'function': different 'const' qualifiers [C:\Users\Dario\dev\tflite_build\_deps\xnnpack-build\XNNPACK.vcxproj]
  deconvolution-nhwc.c
  Building Custom Rule C:/Users/Dario/dev/tflite_build/ruy/ruy/CMakeLists.txt
  Building Custom Rule C:/Users/Dario/dev/tflite_build/ruy/ruy/CMakeLists.txt
  Building Custom Rule C:/Users/Dario/dev/tflite_build/ruy/ruy/CMakeLists.txt
  Building Custom Rule C:/Users/Dario/dev/tflite_build/ruy/ruy/CMakeLists.txt
C:\Users\Dario\dev\tflite_build\xnnpack\src\operators\deconvolution-nhwc.c(576,112): warning C4090: 'function': different 'const' qualifiers [C:\Users\Dario\dev\tflite_build\_deps\xnnpack-build\XNNPACK.vcxproj]
  Building Custom Rule C:/Users/Dario/dev/tflite_build/ruy/ruy/CMakeLists.txt
C:\Users\Dario\dev\tflite_build\xnnpack\src\operators\deconvolution-nhwc.c(732,82): warning C4090: 'function': different 'const' qualifiers [C:\Users\Dario\dev\tflite_build\_deps\xnnpack-build\XNNPACK.vcxproj]
  depth-to-space-nchw2nhwc.c
  depth-to-space-nhwc.c
  Building Custom Rule C:/Users/Dario/dev/tflite_build/ruy/ruy/CMakeLists.txt
  fully-connected-nc.c
  Building Custom Rule C:/Users/Dario/dev/tflite_build/ruy/ruy/CMakeLists.txt
  Building Custom Rule C:/Users/Dario/dev/tflite_build/ruy/ruy/CMakeLists.txt
  absl_time_zone.vcxproj -> C:\Users\Dario\dev\tflite_build\_deps\abseil-cpp-build\absl\time\Debug\absl_time_zone.lib
  global-average-pooling-ncw.c
  unscaledcycleclock.cc
  kernel_avx512.cc
  kernel_arm32.cc
  pack_avx.cc
  kernel_avx.cc
  global-average-pooling-nwc.c
  pack_avx2_fma.cc
  pack_avx512.cc
  Generating Code...
  kernel_avx2_fma.cc
  lut-elementwise-nc.c
  max-pooling-nhwc.c
C:\Users\Dario\dev\tflite_build\xnnpack\src\operators\max-pooling-nhwc.c(276,78): warning C4090: 'function': different 'const' qualifiers [C:\Users\Dario\dev\tflite_build\_deps\xnnpack-build\XNNPACK.vcxproj]
  prelu-nc.c
C:\Users\Dario\dev\tflite_build\ruy\ruy\kernel_avx512.cc(890,9): warning C4068: unknown pragma 'unroll' [C:\Users\Dario\dev\tflite_build\_deps\ruy-build\ruy\ruy_kernel_avx512.vcxproj]
  kernel_arm64.cc
  resize-bilinear-nchw.c
C:\Users\Dario\dev\tflite_build\xnnpack\src\operators\resize-bilinear-nchw.c(154,105): warning C4090: 'function': different 'const' qualifiers [C:\Users\Dario\dev\tflite_build\_deps\xnnpack-build\XNNPACK.vcxproj
]
  resize-bilinear-nhwc.c
  pack_arm.cc
C:\Users\Dario\dev\tflite_build\xnnpack\src\operators\resize-bilinear-nhwc.c(208,105): warning C4090: 'function': different 'const' qualifiers [C:\Users\Dario\dev\tflite_build\_deps\xnnpack-build\XNNPACK.vcxproj
]
  Generating Code...
  softmax-nc.c
  absl_base.vcxproj -> C:\Users\Dario\dev\tflite_build\_deps\abseil-cpp-build\absl\base\Debug\absl_base.lib
  unary-elementwise-nc.c
  Building Custom Rule C:/Users/Dario/dev/tflite_build/ruy/ruy/CMakeLists.txt
  Generating Code...
  ruy_pack_avx.vcxproj -> C:\Users\Dario\dev\tflite_build\_deps\ruy-build\ruy\Debug\ruy_pack_avx.lib
  ruy_pack_avx2_fma.vcxproj -> C:\Users\Dario\dev\tflite_build\_deps\ruy-build\ruy\Debug\ruy_pack_avx2_fma.lib
  ruy_kernel_avx2_fma.vcxproj -> C:\Users\Dario\dev\tflite_build\_deps\ruy-build\ruy\Debug\ruy_kernel_avx2_fma.lib
  Generating Code...
  ruy_kernel_avx512.vcxproj -> C:\Users\Dario\dev\tflite_build\_deps\ruy-build\ruy\Debug\ruy_kernel_avx512.lib
  Compiling...
  unpooling-nhwc.c
  ruy_kernel_avx.vcxproj -> C:\Users\Dario\dev\tflite_build\_deps\ruy-build\ruy\Debug\ruy_kernel_avx.lib
C:\Users\Dario\dev\tflite_build\xnnpack\src\operators\unpooling-nhwc.c(196,94): warning C4090: 'function': different 'const' qualifiers [C:\Users\Dario\dev\tflite_build\_deps\xnnpack-build\XNNPACK.vcxproj]
  abs.c
  ruy_pack_avx512.vcxproj -> C:\Users\Dario\dev\tflite_build\_deps\ruy-build\ruy\Debug\ruy_pack_avx512.lib
  add2.c
  ruy_kernel_arm.vcxproj -> C:\Users\Dario\dev\tflite_build\_deps\ruy-build\ruy\Debug\ruy_kernel_arm.lib
  argmax-pooling-2d.c
  Building Custom Rule C:/Users/Dario/dev/tflite_build/abseil-cpp/absl/debugging/CMakeLists.txt
  Building Custom Rule C:/Users/Dario/dev/tflite_build/abseil-cpp/absl/strings/CMakeLists.txt
  Building Custom Rule C:/Users/Dario/dev/tflite_build/abseil-cpp/absl/base/CMakeLists.txt
  average-pooling-2d.c
  ctx.cc
  Building Custom Rule C:/Users/Dario/dev/tflite_build/abseil-cpp/absl/hash/CMakeLists.txt
  bankers-rounding.c
  ceiling.c
  clamp.c
  low_level_alloc.cc
  ruy_pack_arm.vcxproj -> C:\Users\Dario\dev\tflite_build\_deps\ruy-build\ruy\Debug\ruy_pack_arm.lib
  ostringstream.cc
  demangle.cc
  convert.c
  convolution-2d.c
  city.cc
  deconvolution-2d.c
  Building Custom Rule C:/Users/Dario/dev/tflite_build/abseil-cpp/absl/hash/CMakeLists.txt
  depth-to-space.c
  depthwise-convolution-2d.c
  divide.c
  elu.c
  absl_demangle_internal.vcxproj -> C:\Users\Dario\dev\tflite_build\_deps\abseil-cpp-build\absl\debugging\Debug\absl_demangle_internal.lib
  flatbuffers.vcxproj -> C:\Users\Dario\dev\tflite_build\_deps\flatbuffers-build\Debug\flatbuffers.lib
  floor.c
  fully-connected.c
  wyhash.cc
  global-average-pooling-2d.c
  hardswish.c
  leaky-relu.c
  Generating Code...
  absl_city.vcxproj -> C:\Users\Dario\dev\tflite_build\_deps\abseil-cpp-build\absl\hash\Debug\absl_city.lib
  utf8.cc
  escaping.cc
  Compiling...
  max-pooling-2d.c
  maximum2.c
  ruy_ctx.vcxproj -> C:\Users\Dario\dev\tflite_build\_deps\ruy-build\ruy\Debug\ruy_ctx.lib
  minimum2.c
  multiply2.c
  absl_wyhash.vcxproj -> C:\Users\Dario\dev\tflite_build\_deps\abseil-cpp-build\absl\hash\Debug\absl_wyhash.lib
  negate.c
  Building Custom Rule C:/Users/Dario/dev/tflite_build/ruy/ruy/CMakeLists.txt
  prelu.c
  Building Custom Rule C:/Users/Dario/dev/tflite_build/ruy/ruy/CMakeLists.txt
  Building Custom Rule C:/Users/Dario/dev/tflite_build/ruy/ruy/CMakeLists.txt
  sigmoid.c
  softmax.c
  trmul.cc
  square-root.c
  context.cc
  prepare_packed_matrices.cc
  square.c
  absl_malloc_internal.vcxproj -> C:\Users\Dario\dev\tflite_build\_deps\abseil-cpp-build\absl\base\Debug\absl_malloc_internal.lib
  squared-difference.c
  static-constant-pad.c
  Building Custom Rule C:/Users/Dario/dev/tflite_build/abseil-cpp/absl/synchronization/CMakeLists.txt
  static-reshape.c
  static-resize-bilinear-2d.c
  graphcycles.cc
  subtract.c
  Generating Code...
  unpooling-2d.c
  datatype-strings.c
  operator-strings.c
  subgraph-strings.c
  absl_strings_internal.vcxproj -> C:\Users\Dario\dev\tflite_build\_deps\abseil-cpp-build\absl\strings\Debug\absl_strings_internal.lib
  allocator.c
  Generating Code...
  Building Custom Rule C:/Users/Dario/dev/tflite_build/abseil-cpp/absl/strings/CMakeLists.txt
  Compiling...
  init.c
  ascii.cc
  ruy_prepare_packed_matrices.vcxproj -> C:\Users\Dario\dev\tflite_build\_deps\ruy-build\ruy\Debug\ruy_prepare_packed_matrices.lib
  ruy_trmul.vcxproj -> C:\Users\Dario\dev\tflite_build\_deps\ruy-build\ruy\Debug\ruy_trmul.lib
  ruy_context.vcxproj -> C:\Users\Dario\dev\tflite_build\_deps\ruy-build\ruy\Debug\ruy_context.lib
  Building Custom Rule C:/Users/Dario/dev/tflite_build/ruy/ruy/CMakeLists.txt
  Building Custom Rule C:/Users/Dario/dev/tflite_build/ruy/ruy/CMakeLists.txt
  context_get_ctx.cc
  frontend.cc
  charconv.cc
  absl_graphcycles_internal.vcxproj -> C:\Users\Dario\dev\tflite_build\_deps\abseil-cpp-build\absl\synchronization\Debug\absl_graphcycles_internal.lib
  memory-planner.c
  operator-delete.c
C:\Users\Dario\dev\tflite_build\xnnpack\src\operator-delete.c(29,44): warning C4090: 'function': different 'const' qualifiers [C:\Users\Dario\dev\tflite_build\_deps\xnnpack-build\XNNPACK.vcxproj]
  runtime.c
  subgraph.c
  tensor.c
  indirection.c
  operator-run.c
  ruy_frontend.vcxproj -> C:\Users\Dario\dev\tflite_build\_deps\ruy-build\ruy\Debug\ruy_frontend.lib
  packing.c
  exp2-k-over-64.c
  exp2-k-over-2048.c
  exp2minus-k-over-4.c
  exp2minus-k-over-8.c
  exp2minus-k-over-16.c
  exp2minus-k-over-64.c
  exp2minus-k-over-2048.c
  vcvt-scalar-float-x1.c
  ruy_context_get_ctx.vcxproj -> C:\Users\Dario\dev\tflite_build\_deps\ruy-build\ruy\Debug\ruy_context_get_ctx.lib
  vcvt-scalar-float-x4.c
  4x-scalar-c1.c
  escaping.cc
  9p8x-scalar-c1.c
  Generating Code...
  Compiling...
  9x-scalar-c1.c
  3x3s2p0p1c3x4-scalar-1x1.c
  up1x3-minmax-scalar-acc2.c
  up1x3-scalar-acc2.c
  up1x4-minmax-scalar-acc2.c
  up1x4-scalar-acc2.c
  up1x9-minmax-scalar-acc2.c
  up1x9-scalar-acc2.c
  up1x25-minmax-scalar-acc2.c
  up1x25-scalar-acc2.c
  3x3p1-minmax-scalar-2x1-acc2.c
  3x3p1-minmax-scalar-4x1.c
  3x3s2p1-minmax-scalar-1x1-acc2.c
  3x3s2p1-minmax-scalar-2x1-acc2.c
  5x5p2-minmax-scalar-1x1-acc5.c
  5x5p2-minmax-scalar-2x1-acc2.c
  5x5s2p2-minmax-scalar-1x1-acc5.c
  5x5s2p2-minmax-scalar-2x1-acc2.c
  vcvt-scalar-bitcast-x4.c
  charconv_bigint.cc
  vcvt-scalar-fabsf-x2.c
  Generating Code...
  Compiling...
  scalar-x1.c
  scalar-p4.c
  scalar-c2.c
  scalar-2x4.c
  scalar-p5-x4-acc2.c
  8x1-minmax-scalar.c
  8x2-minmax-scalar.c
  8x4-minmax-scalar.c
  vadd-minmax-scalar-x8.c
  vaddc-minmax-scalar-x8.c
  vdiv-minmax-scalar-x2.c
  vdiv-minmax-scalar-x8.c
  vdivc-minmax-scalar-x2.c
  vdivc-minmax-scalar-x8.c
  vmax-scalar-x8.c
  vmaxc-scalar-x8.c
  vmin-scalar-x8.c
  charconv_parse.cc
  vminc-scalar-x8.c
  vmul-minmax-scalar-x8.c
  vmulc-minmax-scalar-x8.c
  Generating Code...
  Compiling...
  vrdivc-minmax-scalar-x2.c
  vrdivc-minmax-scalar-x8.c
  vrsubc-minmax-scalar-x8.c
  vsqrdiff-scalar-x8.c
  vsqrdiffc-scalar-x8.c
  vsub-minmax-scalar-x8.c
  vsubc-minmax-scalar-x8.c
  memutil.cc
  vclamp-scalar-x4.c
  velu-scalar-rr2-lut16-p3-x2.c
  velu-scalar-rr2-lut16-p3-x4.c
  vhswish-scalar-x4.c
  vlrelu-scalar-x4.c
  c1-minmax-scalar-2x.c
  vrelu-scalar-x8.c
  vrndd-scalar-libm-x1.c
  vrndd-scalar-libm-x4.c
  vrndne-scalar-libm-x1.c
  vrndne-scalar-libm-x4.c
  vrndu-scalar-libm-x1.c
  vrndu-scalar-libm-x4.c
  match.cc
  Generating Code...
  Compiling...
  vrndz-scalar-libm-x1.c
  vrndz-scalar-libm-x4.c
  vsigmoid-scalar-lut64-p2-div-x2.c
  scalar-sqrt-x1.c
  vabs-scalar-x4.c
  vneg-scalar-x4.c
  vsqr-scalar-x4.c
  params-init.c
  numbers.cc
  7p7x-minmax-scalar-c4.c
  7x-minmax-scalar-c4.c
  lut-scalar-x4.c
  memcpy.c
  scalar-x16.c
  3x3s2p1c3x4-sse-2x2.c
  up8x3-minmax-sse.c
  up8x4-minmax-sse.c
  up8x9-minmax-sse.c
  up8x25-minmax-sse.c
  3x3p1-minmax-sse-2x4-acc2.c
  3x3s2p1-minmax-sse-1x4-acc3.c
  Generating Code...
  Compiling...
  5x5p2-minmax-sse-4x4.c
  5x5s2p2-minmax-sse-2x4.c
  sse-x4.c
  7p7x-minmax-sse-c4.c
  7x-minmax-sse-c4.c
  str_cat.cc
  sse-p8.c
  sse-c8.c
  sse.c
  32x1-minmax-sse.c
  vadd-minmax-sse-x8.c
  vaddc-minmax-sse-x8.c
  vdiv-minmax-sse-x8.c
  vdivc-minmax-sse-x8.c
  vmax-sse-x8.c
  vmaxc-sse-x8.c
  vmin-sse-x8.c
  vminc-sse-x8.c
  vmul-minmax-sse-x8.c
  vmulc-minmax-sse-x8.c
  vrdivc-minmax-sse-x8.c
  str_replace.cc
  Generating Code...
  Compiling...
  vrsubc-minmax-sse-x8.c
  vsqrdiff-sse-x8.c
  vsqrdiffc-sse-x8.c
  vsub-minmax-sse-x8.c
  vsubc-minmax-sse-x8.c
  vclamp-sse-x8.c
  vhswish-sse-x8.c
  vlrelu-sse-x8.c
  c4-minmax-sse-2x.c
  sse-sqrt-x4.c
  vabs-sse-x8.c
  str_split.cc
  vneg-sse-x8.c
  vsqr-sse-x8.c
  x4-sse.c
  vcvt-sse2-int16-x32.c
  4x-sse2-c4.c
  9p8x-sse2-c4.c
  9x-sse2-c4.c
  vcvt-sse2-x16.c
  sse2-2x8.c
  Generating Code...
  Compiling...
  sse2-p5-x20-acc2.c
  velu-sse2-rr2-lut16-p3-x12.c
  vlrelu-sse2-x8.c
  vrndd-sse2-x8.c
  vrndne-sse2-x8.c
  vrndu-sse2-x8.c
  vrndz-sse2-x8.c
  vsigmoid-sse2-lut64-p2-div-x8.c
  up8x9-minmax-fp32-sse2-mul16-add16.c
  string_view.cc
  up8x25-minmax-fp32-sse2-mul16-add16.c
  7p7x-minmax-sse2-c8-acc2.c
  7x-minmax-sse2-c8-acc2.c
  9p8x-minmax-sse2-c8.c
  9x-minmax-sse2-c8.c
  7p7x-minmax-sse2-c8.c
  7x-minmax-sse2-c8.c
  3x3p1-minmax-ssse3-2x4-acc2.c
  7p7x-minmax-ssse3-c8-acc2.c
  7x-minmax-ssse3-c8-acc2.c
  vcvt-sse41-int16-x16.c
  Generating Code...
  Compiling...
  vcvt-sse41-x8.c
  sse41-2x8.c
  vcvt-sse41-x32.c
  substitute.cc
  vlrelu-sse41-x8.c
  vrndd-sse41-x8.c
  vrndne-sse41-x8.c
  vrndu-sse41-x8.c
  vrndz-sse41-x8.c
  vsigmoid-sse41-lut64-p2-div-x8.c
  up8x9-minmax-fp32-sse41-mul16-add16.c
  up8x25-minmax-fp32-sse41-mul16-add16.c
  7p7x-minmax-sse41-c8-acc2.c
  7x-minmax-sse41-c8-acc2.c
  9p8x-minmax-sse41-c16.c
  sse41-x64.c
  Generating Code...
  Generating Code...
  9p8x-minmax-scalar-c1.c
  absl_strings.vcxproj -> C:\Users\Dario\dev\tflite_build\_deps\abseil-cpp-build\absl\strings\Debug\absl_strings.lib
  Building Custom Rule C:/Users/Dario/dev/tflite_build/abseil-cpp/absl/strings/CMakeLists.txt
  Building Custom Rule C:/Users/Dario/dev/tflite_build/abseil-cpp/absl/hash/CMakeLists.txt
  Building Custom Rule C:/Users/Dario/dev/tflite_build/abseil-cpp/absl/strings/CMakeLists.txt
  Building Custom Rule C:/Users/Dario/dev/tflite_build/abseil-cpp/absl/flags/CMakeLists.txt
  9x-minmax-scalar-c1.c
  Building Custom Rule C:/Users/Dario/dev/tflite_build/abseil-cpp/absl/time/CMakeLists.txt
  arg.cc
  commandlineflag.cc
  cord.cc
  Building Custom Rule C:/Users/Dario/dev/tflite_build/abseil-cpp/absl/debugging/CMakeLists.txt
  hash.cc
  civil_time.cc
  symbolize.cc
  3x3s2p1c3x4-scalar-1x1.c
  3x3s2p1c3x4-scalar-1x1.c
  absl_flags_commandlineflag.vcxproj -> C:\Users\Dario\dev\tflite_build\_deps\abseil-cpp-build\absl\flags\Debug\absl_flags_commandlineflag.lib
  7p7x-minmax-scalar-c1.c
  Building Custom Rule C:/Users/Dario/dev/tflite_build/abseil-cpp/absl/flags/CMakeLists.txt
  private_handle_accessor.cc
  absl_hash.vcxproj -> C:\Users\Dario\dev\tflite_build\_deps\abseil-cpp-build\absl\hash\Debug\absl_hash.lib
  bind.cc
  7x-minmax-scalar-c1.c
  clock.cc
  1x4-minmax-scalar.c
  absl_symbolize.vcxproj -> C:\Users\Dario\dev\tflite_build\_deps\abseil-cpp-build\absl\debugging\Debug\absl_symbolize.lib
  1x4-relu-scalar.c
  cord_internal.cc
  absl_flags_private_handle_accessor.vcxproj -> C:\Users\Dario\dev\tflite_build\_deps\abseil-cpp-build\absl\flags\Debug\absl_flags_private_handle_accessor.lib
  1x4-scalar.c
  extension.cc
  duration.cc
  2x4-minmax-scalar.c
  2x4-relu-scalar.c
  cord_rep_ring.cc
  float_conversion.cc
  2x4-scalar.c
  4x2-minmax-scalar.c
  4x2-relu-scalar.c
  format.cc
  Generating Code...
  4x2-scalar.c
  output.cc
  4x4-minmax-scalar.c
  absl_cord.vcxproj -> C:\Users\Dario\dev\tflite_build\_deps\abseil-cpp-build\absl\strings\Debug\absl_cord.lib
  4x4-relu-scalar.c
  time.cc
  parser.cc
  4x4-scalar.c
  1x4-minmax-scalar.c
  1x4-relu-scalar.c
  Generating Code...
  Generating Code...
  1x4-scalar.c
  absl_time.vcxproj -> C:\Users\Dario\dev\tflite_build\_deps\abseil-cpp-build\absl\time\Debug\absl_time.lib
  2x4-minmax-scalar.c
  absl_str_format_internal.vcxproj -> C:\Users\Dario\dev\tflite_build\_deps\abseil-cpp-build\absl\strings\Debug\absl_str_format_internal.lib
  Building Custom Rule C:/Users/Dario/dev/tflite_build/abseil-cpp/absl/flags/CMakeLists.txt
  Building Custom Rule C:/Users/Dario/dev/tflite_build/abseil-cpp/absl/status/CMakeLists.txt
  Building Custom Rule C:/Users/Dario/dev/tflite_build/abseil-cpp/absl/synchronization/CMakeLists.txt
  2x4-relu-scalar.c
  marshalling.cc
  status.cc
  barrier.cc
  2x4-scalar.c
  4x2-minmax-scalar.c
  4x2-relu-scalar.c
  blocking_counter.cc
  4x2-scalar.c
  absl_flags_marshalling.vcxproj -> C:\Users\Dario\dev\tflite_build\_deps\abseil-cpp-build\absl\flags\Debug\absl_flags_marshalling.lib
  status_payload_printer.cc
  4x4-minmax-scalar.c
  create_thread_identity.cc
  4x4-relu-scalar.c
  4x4-scalar.c
  Generating Code...
  9p8x-minmax-scalar-c1.c
  per_thread_sem.cc
  absl_status.vcxproj -> C:\Users\Dario\dev\tflite_build\_deps\abseil-cpp-build\absl\status\Debug\absl_status.lib
  9p8x-minmax-scalar-c1.c
  9x-minmax-scalar-c1.c
  vcvt-scalar-magic-iminmax-x1.c
  waiter.cc
  vcvt-scalar-magic-iminmax-x4.c
  vcvt-scalar-magic-iminmax-x1.c
  vcvt-scalar-magic-iminmax-x4.c
  notification.cc
  scalar.c
  up2x9-minmax-fp32-scalar-magic.c
  up2x25-minmax-fp32-scalar-magic.c
  mutex.cc
  1x2-minmax-fp32-scalar-magic.c
  1x4-minmax-fp32-scalar-magic.c
  2x2-minmax-fp32-scalar-magic.c
  Generating Code...
  4x4-minmax-fp32-scalar-magic.c
  absl_synchronization.vcxproj -> C:\Users\Dario\dev\tflite_build\_deps\abseil-cpp-build\absl\synchronization\Debug\absl_synchronization.lib
  Building Custom Rule C:/Users/Dario/dev/tflite_build/abseil-cpp/absl/flags/CMakeLists.txt
  Building Custom Rule C:/Users/Dario/dev/tflite_build/abseil-cpp/absl/container/CMakeLists.txt
  1x2-minmax-fp32-scalar-magic.c
  program_name.cc
  hashtablez_sampler.cc
  1x4-minmax-fp32-scalar-magic.c
  2x2-minmax-fp32-scalar-magic.c
  hashtablez_sampler_force_weak_definition.cc
  absl_flags_program_name.vcxproj -> C:\Users\Dario\dev\tflite_build\_deps\abseil-cpp-build\absl\flags\Debug\absl_flags_program_name.lib
  4x4-minmax-fp32-scalar-magic.c
  Building Custom Rule C:/Users/Dario/dev/tflite_build/abseil-cpp/absl/flags/CMakeLists.txt
  usage_config.cc
  up1x9-minmax-fp32-scalar-magic.c
  Generating Code...
  up1x25-minmax-fp32-scalar-magic.c
  absl_hashtablez_sampler.vcxproj -> C:\Users\Dario\dev\tflite_build\_deps\abseil-cpp-build\absl\container\Debug\absl_hashtablez_sampler.lib
  Building Custom Rule C:/Users/Dario/dev/tflite_build/abseil-cpp/absl/container/CMakeLists.txt
  raw_hash_set.cc
  up2x9-minmax-fp32-scalar-magic.c
  absl_flags_config.vcxproj -> C:\Users\Dario\dev\tflite_build\_deps\abseil-cpp-build\absl\flags\Debug\absl_flags_config.lib
  up2x25-minmax-fp32-scalar-magic.c
  Building Custom Rule C:/Users/Dario/dev/tflite_build/abseil-cpp/absl/flags/CMakeLists.txt
  flag.cc
  vcvt-scalar-x1.c
  vcvt-scalar-x4.c
  absl_raw_hash_set.vcxproj -> C:\Users\Dario\dev\tflite_build\_deps\abseil-cpp-build\absl\container\Debug\absl_raw_hash_set.lib
  Building Custom Rule C:/Users/Dario/dev/tflite_build/abseil-cpp/absl/flags/CMakeLists.txt
  7p7x-minmax-scalar-c1.c
  reflection.cc
  7x-minmax-scalar-c1.c
  absl_flags_internal.vcxproj -> C:\Users\Dario\dev\tflite_build\_deps\abseil-cpp-build\absl\flags\Debug\absl_flags_internal.lib
  1x2-minmax-fp32-scalar-magic.c
  1x4-minmax-fp32-scalar-magic.c
  1x4-minmax-rndnu-scalar.c
  2x2-minmax-fp32-scalar-magic.c
  absl_flags_reflection.vcxproj -> C:\Users\Dario\dev\tflite_build\_deps\abseil-cpp-build\absl\flags\Debug\absl_flags_reflection.lib
  3x4-minmax-rndnu-scalar.c
  Building Custom Rule C:/Users/Dario/dev/tflite_build/abseil-cpp/absl/flags/CMakeLists.txt
  flag.cc
  4x4-minmax-fp32-scalar-magic.c
  1x2-minmax-fp32-scalar-magic.c
  1x4-minmax-fp32-scalar-magic.c
  absl_flags.vcxproj -> C:\Users\Dario\dev\tflite_build\_deps\abseil-cpp-build\absl\flags\Debug\absl_flags.lib
  1x4-minmax-rndnu-scalar.c
  2x2-minmax-fp32-scalar-magic.c
  3x4-minmax-rndnu-scalar.c
  4x4-minmax-fp32-scalar-magic.c
  minmax-scalar-x1.c
  minmax-scalar-x4.c
  minmax-scalar-x1.c
  minmax-scalar-x4.c
  minmax-fp32-scalar-x4.c
  minmax-fp32-scalar-x4.c
  9p8x-minmax-scalar-c1.c
  9x-minmax-scalar-c1.c
  up1x9-minmax-fp32-scalar-magic.c
  up1x25-minmax-fp32-scalar-magic.c
  up2x9-minmax-fp32-scalar-magic.c
  up2x25-minmax-fp32-scalar-magic.c
  vcvt-scalar-x1.c
  vcvt-scalar-x4.c
  7p7x-minmax-scalar-c1.c
  7x-minmax-scalar-c1.c
  1x2-minmax-fp32-scalar-magic.c
  1x4-minmax-fp32-scalar-magic.c
  2x2-minmax-fp32-scalar-magic.c
  4x4-minmax-fp32-scalar-magic.c
  1x2-minmax-fp32-scalar-magic.c
  1x4-minmax-fp32-scalar-magic.c
  2x2-minmax-fp32-scalar-magic.c
  4x4-minmax-fp32-scalar-magic.c
  minmax-scalar-x1.c
  minmax-scalar-x4.c
  minmax-scalar-x1.c
  minmax-scalar-x4.c
  minmax-fp32-scalar-x4.c
  minmax-fp32-scalar-x4.c
  scalar-c1.c
  9p8x-minmax-scalar-c1.c
  scalar-x4.c
  scalar-c1.c
  scalar.c
  9p8x-minmax-scalar-c1.c
  scalar.c
  scalar-x4.c
  x2-scalar.c
  x3-scalar.c
  x4-scalar.c
  xm-scalar.c
  scalar.c
  x2-scalar.c
  x3-scalar.c
  x4-scalar.c
  scalar.c
  x2-scalar.c
  x3-scalar.c
  x4-scalar.c
  xm-scalar.c
  scalar.c
  9p8x-minmax-sse-c4.c
  9x-minmax-sse-c4.c
  1x8-minmax-sse-load1.c
  4x2c4-minmax-sse.c
  4x8-minmax-sse-load1.c
  1x8-minmax-sse-load1.c
  4x2c4-minmax-sse.c
  4x8-minmax-sse-load1.c
  9p8x-minmax-sse-c4.c
  9p8x-minmax-sse-c4.c
  9x-minmax-sse-c4.c
  vcvt-sse2-x32.c
  vcvt-sse2-x32.c
  up8x9-minmax-fp32-sse2-mul16.c
  up8x25-minmax-fp32-sse2-mul16.c
  1x4c8-minmax-fp32-sse2-ld64.c
  3x4c8-minmax-fp32-sse2-ld64.c
  1x4c8-minmax-fp32-sse2-ld64.c
  3x4c8-minmax-fp32-sse2-ld64.c
  vcvt-sse2-x32.c
  1x4c8-minmax-fp32-sse2-ld64.c
  3x4c8-minmax-fp32-sse2-ld64.c
  1x4c8-minmax-fp32-sse2-ld64.c
  3x4c8-minmax-fp32-sse2-ld64.c
  minmax-sse2-mul16-ld64-x8.c
  minmax-sse2-mul16-ld64-x8.c
  minmax-fp32-sse2-mul16-ld64-x8.c
  minmax-fp32-sse2-mul16-ld64-x8.c
  up8x9-minmax-fp32-sse2-mul16.c
  up8x25-minmax-fp32-sse2-mul16.c
  vcvt-sse2-x32.c
  1x4c8-minmax-fp32-sse2-ld64.c
  3x4c8-minmax-fp32-sse2-ld64.c
  1x4c8-minmax-fp32-sse2-ld64.c
  3x4c8-minmax-fp32-sse2-ld64.c
  minmax-sse2-mul16-ld64-x8.c
  minmax-sse2-mul16-ld64-x8.c
  minmax-fp32-sse2-mul16-ld64-x8.c
  minmax-fp32-sse2-mul16-ld64-x8.c
  sse2-c8.c
  9p8x-minmax-sse2-c16.c
  sse2-x64.c
  sse2-c8.c
  9p8x-minmax-sse2-c16.c
  sse2.c
  sse2-x64.c
  x2-sse2.c
  x3-sse2.c
  x4-sse2.c
  xm-sse2.c
  sse2.c
  x2-sse2.c
  x3-sse2.c
  x4-sse2.c
  xm-sse2.c
  sse2-x64.c
  sse2.c
  up8x9-minmax-fp32-sse41-mul16.c
  up8x25-minmax-fp32-sse41-mul16.c
  1x4c8-minmax-fp32-sse41-ld64.c
  3x4c8-minmax-fp32-sse41-ld64.c
  1x4c8-minmax-fp32-sse41-ld64.c
  3x4c8-minmax-fp32-sse41-ld64.c
  vcvt-sse41-x16.c
  1x4c8-minmax-fp32-sse41-ld64.c
  3x4c8-minmax-fp32-sse41-ld64.c
  1x4c8-minmax-fp32-sse41-ld64.c
  3x4c8-minmax-fp32-sse41-ld64.c
  minmax-sse41-mul16-ld64-x8.c
  minmax-sse41-mul16-ld64-x8.c
  minmax-fp32-sse41-mul16-ld64-x16.c
  minmax-fp32-sse41-mul16-ld64-x16.c
  up8x9-minmax-fp32-sse41-mul16.c
  up8x25-minmax-fp32-sse41-mul16.c
  vcvt-sse41-x16.c
  1x4c8-minmax-fp32-sse41-ld64.c
  3x4c8-minmax-fp32-sse41-ld64.c
  1x4c8-minmax-fp32-sse41-ld64.c
  3x4c8-minmax-fp32-sse41-ld64.c
  minmax-sse41-mul16-ld64-x8.c
  minmax-sse41-mul16-ld64-x8.c
  minmax-fp32-sse41-mul16-ld64-x16.c
  minmax-fp32-sse41-mul16-ld64-x16.c
  sse41-c16.c
  sse41-c16.c
  vcvt-avx-int16-x16.c
  up8x25-minmax-avx.c
  up16x3-minmax-avx.c
  up16x4-minmax-avx.c
  up16x9-minmax-avx.c
  vcvt-avx-x24.c
  avx-2x16.c
  vadd-minmax-avx-x16.c
  vaddc-minmax-avx-x16.c
  vdiv-minmax-avx-x16.c
  vdivc-minmax-avx-x16.c
  vmax-avx-x16.c
  vmaxc-avx-x16.c
  vmin-avx-x16.c
  vminc-avx-x16.c
  vmul-minmax-avx-x16.c
  vmulc-minmax-avx-x16.c
  vrdivc-minmax-avx-x16.c
  vrsubc-minmax-avx-x16.c
  vsqrdiff-avx-x16.c
  Generating Code...
  Compiling...
  vsqrdiffc-avx-x16.c
  vsub-minmax-avx-x16.c
  vsubc-minmax-avx-x16.c
  vclamp-avx-x16.c
  velu-avx-rr2-lut4-p4-perm-x32.c
  vhswish-avx-x16.c
  vlrelu-avx-x16.c
  vrndd-avx-x16.c
  vrndne-avx-x16.c
  vrndu-avx-x16.c
  vrndz-avx-x16.c
  vsigmoid-avx-rr2-p5-nr2-x40.c
  avx-sqrt-x8.c
  vabs-avx-x16.c
  vneg-avx-x16.c
  vsqr-avx-x16.c
  up16x9-minmax-fp32-avx-mul16.c
  up16x25-minmax-fp32-avx-mul16.c
  lut-avx-x64.c
  up16x9-minmax-fp32-xop-mul32.c
  Generating Code...
  Compiling...
  up16x25-minmax-fp32-xop-mul32.c
  up8x25-minmax-fma3.c
  up16x3-minmax-fma3.c
  up16x4-minmax-fma3.c
  up16x9-minmax-fma3.c
  vhswish-fma3-x16.c
  Generating Code...
  1x16-minmax-avx-broadcast.c
  5x16-minmax-avx-broadcast.c
  1x16-minmax-avx-broadcast.c
  5x16-minmax-avx-broadcast.c
  up16x9-minmax-fp32-avx-mul16-add16.c
  up16x25-minmax-fp32-avx-mul16-add16.c
  1x4c8-minmax-fp32-avx-ld128.c
  2x4c8-minmax-fp32-avx-ld128.c
  1x4c8-minmax-fp32-avx-ld128.c
  2x4c8-minmax-fp32-avx-ld128.c
  up16x9-minmax-fp32-avx-mul16-add16.c
  up16x25-minmax-fp32-avx-mul16-add16.c
  1x4c8-minmax-fp32-avx-ld128.c
  2x4c8-minmax-fp32-avx-ld128.c
  1x4c8-minmax-fp32-avx-ld128.c
  2x4c8-minmax-fp32-avx-ld128.c
  minmax-avx-mul32-ld32-x8.c
  minmax-avx-mul32-ld32-x8.c
  minmax-fp32-avx-mul16-ld64-x16.c
  minmax-fp32-avx-mul16-ld64-x16.c
  1x4c8-minmax-fp32-avx-ld128.c
  2x4c8-minmax-fp32-avx-ld128.c
  1x4c8-minmax-fp32-avx-ld128.c
  2x4c8-minmax-fp32-avx-ld128.c
  minmax-avx-mul32-ld32-x8.c
  minmax-avx-mul32-ld32-x8.c
  minmax-fp32-avx-mul16-ld64-x16.c
  minmax-fp32-avx-mul16-ld64-x16.c
  vcvt-f16c-x16.c
  vcvt-f16c-x16.c
C:\Users\Dario\dev\tflite_build\xnnpack\src\f32-f16-vcvt\gen\vcvt-f16c-x16.c(38,1): warning C4556: value of intrinsic immediate argument '8' is out of range '0 - 7' [C:\Users\Dario\dev\tflite_build\_deps\xnnpack
-build\XNNPACK.vcxproj]
C:\Users\Dario\dev\tflite_build\xnnpack\src\f32-f16-vcvt\gen\vcvt-f16c-x16.c(39,1): warning C4556: value of intrinsic immediate argument '8' is out of range '0 - 7' [C:\Users\Dario\dev\tflite_build\_deps\xnnpack
-build\XNNPACK.vcxproj]
C:\Users\Dario\dev\tflite_build\xnnpack\src\f32-f16-vcvt\gen\vcvt-f16c-x16.c(46,1): warning C4556: value of intrinsic immediate argument '8' is out of range '0 - 7' [C:\Users\Dario\dev\tflite_build\_deps\xnnpack
-build\XNNPACK.vcxproj]
C:\Users\Dario\dev\tflite_build\xnnpack\src\f32-f16-vcvt\gen\vcvt-f16c-x16.c(58,1): warning C4556: value of intrinsic immediate argument '8' is out of range '0 - 7' [C:\Users\Dario\dev\tflite_build\_deps\xnnpack
-build\XNNPACK.vcxproj]
C:\Users\Dario\dev\tflite_build\xnnpack\src\f32-f16-vcvt\gen\vcvt-f16c-x16.c(62,1): warning C4556: value of intrinsic immediate argument '8' is out of range '0 - 7' [C:\Users\Dario\dev\tflite_build\_deps\xnnpack
-build\XNNPACK.vcxproj]
  up16x9-minmax-fp32-xop-mul16-add16.c
  up16x25-minmax-fp32-xop-mul16-add16.c
  1x4c8-minmax-fp32-xop-ld64.c
  2x4c8-minmax-fp32-xop-ld64.c
  1x4c8-minmax-fp32-xop-ld64.c
  2x4c8-minmax-fp32-xop-ld64.c
  up16x9-minmax-fp32-xop-mul16-add16.c
  up16x25-minmax-fp32-xop-mul16-add16.c
  1x4c8-minmax-fp32-xop-ld64.c
  2x4c8-minmax-fp32-xop-ld64.c
  1x4c8-minmax-fp32-xop-ld64.c
  2x4c8-minmax-fp32-xop-ld64.c
  minmax-xop-mul32-ld32-x8.c
  minmax-xop-mul32-ld32-x8.c
  1x4c8-minmax-fp32-xop-ld64.c
  2x4c8-minmax-fp32-xop-ld64.c
  1x4c8-minmax-fp32-xop-ld64.c
  2x4c8-minmax-fp32-xop-ld64.c
  minmax-xop-mul32-ld32-x8.c
  minmax-xop-mul32-ld32-x8.c
  1x16-minmax-fma3-broadcast.c
  1x16s4-minmax-fma3-broadcast.c
  4x16s4-minmax-fma3-broadcast.c
  5x16-minmax-fma3-broadcast.c
  1x16-minmax-fma3-broadcast.c
  1x16s4-minmax-fma3-broadcast.c
  4x16s4-minmax-fma3-broadcast.c
  5x16-minmax-fma3-broadcast.c
  velu-avx2-rr1-lut4-p4-perm-x56.c
  vsigmoid-avx2-rr1-p5-div-x40.c
  lut-avx2-x128.c
  Generating Code...
  up16x9-minmax-fp32-avx2-mul32.c
  up16x25-minmax-fp32-avx2-mul32.c
  1x8c8-minmax-fp32-avx2.c
  3x8c8-minmax-fp32-avx2.c
  1x8c8-minmax-fp32-avx2.c
  3x8c8-minmax-fp32-avx2.c
  up16x9-minmax-fp32-avx2-mul32.c
  up16x25-minmax-fp32-avx2-mul32.c
  1x8c8-minmax-fp32-avx2.c
  3x8c8-minmax-fp32-avx2.c
  1x8c8-minmax-fp32-avx2.c
  3x8c8-minmax-fp32-avx2.c
  minmax-avx2-mul32-ld64-x16.c
  minmax-avx2-mul32-ld64-x16.c
  up16x9-minmax-fp32-avx2-mul32.c
  up16x25-minmax-fp32-avx2-mul32.c
  1x8c8-minmax-fp32-avx2.c
  3x8c8-minmax-fp32-avx2.c
  1x8c8-minmax-fp32-avx2.c
  3x8c8-minmax-fp32-avx2.c
  minmax-avx2-mul32-ld64-x16.c
  minmax-avx2-mul32-ld64-x16.c
  up16x3-minmax-avx512f.c
  up16x4-minmax-avx512f.c
  up16x9-minmax-avx512f.c
  up16x25-minmax-avx512f.c
  avx512f-2x16.c
  vadd-minmax-avx512f-x32.c
  vaddc-minmax-avx512f-x32.c
  vdiv-minmax-avx512f-x32.c
  vdivc-minmax-avx512f-x32.c
  vmax-avx512f-x32.c
  vmaxc-avx512f-x32.c
  vmin-avx512f-x32.c
  vminc-avx512f-x32.c
  vmul-minmax-avx512f-x32.c
  vmulc-minmax-avx512f-x32.c
  vrdivc-minmax-avx512f-x32.c
  vrsubc-minmax-avx512f-x32.c
  vsqrdiff-avx512f-x32.c
  vsqrdiffc-avx512f-x32.c
  vsub-minmax-avx512f-x32.c
  Generating Code...
  Compiling...
  vsubc-minmax-avx512f-x32.c
  vclamp-avx512f-x16.c
  velu-avx512f-rr1-lut16-p3-perm-x64.c
  vhswish-avx512f-x16.c
  vlrelu-avx512f-x16.c
  vrndd-avx512f-x16.c
  vrndne-avx512f-x16.c
  vrndu-avx512f-x16.c
  vrndz-avx512f-x16.c
  vsigmoid-avx512f-rr2-lut32-p2-perm2-scalef-div-x64.c
  vabs-avx512f-x16.c
  vneg-avx512f-x16.c
  vsqr-avx512f-x16.c
  lut-avx512skx-vpshufb-x64.c
  Generating Code...
  1x16-minmax-avx512f-broadcast.c
  7x16-minmax-avx512f-broadcast.c
  1x16-minmax-avx512f-broadcast.c
  7x16-minmax-avx512f-broadcast.c
  vcvt-avx512skx-x16.c
  vcvt-avx512skx-x16.c
  up32x9-minmax-fp32-avx512skx-mul32.c
  up32x25-minmax-fp32-avx512skx-mul32.c
  1x16c8-minmax-fp32-avx512skx.c
  4x16c8-minmax-fp32-avx512skx.c
  1x16c8-minmax-fp32-avx512skx.c
  4x16c8-minmax-fp32-avx512skx.c
  up32x9-minmax-fp32-avx512skx-mul32.c
  up32x25-minmax-fp32-avx512skx-mul32.c
  1x16c8-minmax-fp32-avx512skx.c
  4x16c8-minmax-fp32-avx512skx.c
  1x16c8-minmax-fp32-avx512skx.c
  4x16c8-minmax-fp32-avx512skx.c
  minmax-avx512skx-mul32-ld128-x16.c
  minmax-avx512skx-mul32-ld128-x16.c
  up32x9-minmax-fp32-avx512skx-mul32.c
  up32x25-minmax-fp32-avx512skx-mul32.c
  1x16c8-minmax-fp32-avx512skx.c
  4x16c8-minmax-fp32-avx512skx.c
  1x16c8-minmax-fp32-avx512skx.c
  4x16c8-minmax-fp32-avx512skx.c
  minmax-avx512skx-mul32-ld128-x16.c
  minmax-avx512skx-mul32-ld128-x16.c
  XNNPACK.vcxproj -> C:\Users\Dario\dev\tflite_build\_deps\xnnpack-build\Debug\XNNPACK.lib
  Building Custom Rule C:/Users/Dario/dev/tensorflow_src/tensorflow/lite/CMakeLists.txt
  error_reporter.cc
  flatbuffer_conversions.cc
  op_resolver.cc
  subgraph.cc
  c_api.cc
  c_api_experimental.cc
  c_api_for_testing.cc
  nnapi_delegate_disabled.cc
  interpreter_utils.cc
  serialization.cc
  telemetry.cc
  utils.cc
  xnnpack_delegate.cc
  initialization_status.cc
  resource_variable.cc
  static_hashtable.cc
  cpu_check.cc
  neon_tensor_utils.cc
  sse_tensor_utils.cc
  portable_tensor_utils.cc
  Generating Code...
  Compiling...
  kernel_utils.cc
  mfcc_dct.cc
  mfcc_mel_filterbank.cc
  spectrogram.cc
  transpose_utils.cc
  activations.cc
  add.cc
  add_n.cc
  arg_min_max.cc
  assign_variable.cc
  atan2.cc
  audio_spectrogram.cc
  basic_rnn.cc
  batch_matmul.cc
  batch_to_space_nd.cc
  bidirectional_sequence_lstm.cc
  bidirectional_sequence_rnn.cc
  broadcast_args.cc
  broadcast_to.cc
  bucketize.cc
  Generating Code...
  Compiling...
  call_once.cc
  cast.cc
  ceil.cc
  comparisons.cc
  complex_support.cc
  concatenation.cc
  conv.cc
  conv3d.cc
  conv3d_transpose.cc
  cpu_backend_context.cc
  cpu_backend_gemm_eigen.cc
  cumsum.cc
  densify.cc
  deprecated_backends.cc
  depth_to_space.cc
  depthwise_conv.cc
  dequantize.cc
  detection_postprocess.cc
  div.cc
  eigen_support.cc
  Generating Code...
  Compiling...
  elementwise.cc
  embedding_lookup.cc
  embedding_lookup_sparse.cc
  exp.cc
  expand_dims.cc
  fake_quant.cc
  fill.cc
  floor.cc
  floor_div.cc
  floor_mod.cc
  fully_connected.cc
  gather.cc
  gather_nd.cc
  gru_cell.cc
  hashtable.cc
  hashtable_find.cc
  hashtable_import.cc
  hashtable_lookup.cc
  hashtable_size.cc
  if.cc
  Generating Code...
  Compiling...
  irfft2d.cc
  kernel_util.cc
  l2norm.cc
  local_response_norm.cc
  logical.cc
  lsh_projection.cc
  lstm.cc
  lstm_eval.cc
  matrix_diag.cc
  matrix_set_diag.cc
  maximum_minimum.cc
  mirror_pad.cc
  mul.cc
  multinomial.cc
  neg.cc
  non_max_suppression.cc
  numeric_verify.cc
  one_hot.cc
  pack.cc
  pad.cc
  Generating Code...
  Compiling...
  pooling.cc
  pooling3d.cc
  pow.cc
  quantize.cc
  random_ops.cc
C:\Users\Dario\dev\tensorflow_src\tensorflow/core/lib/random/random_distributions_utils.h(78,27): error C2065: 'M_PI': undeclared identifier [C:\Users\Dario\dev\tflite_build\tensorflow-lite\tensorflow-lite.vcxpr
oj]
C:\Users\Dario\dev\tensorflow_src\tensorflow/core/lib/random/random_distributions_utils.h(78,15): error C2737: 'v1': const object must be initialized [C:\Users\Dario\dev\tflite_build\tensorflow-lite\tensorflow-l
ite.vcxproj]
  random_standard_normal_custom.cc
  random_uniform_custom.cc
  range.cc
  rank.cc
  read_variable.cc
  reduce.cc
  register.cc
  register_ref.cc
  reshape.cc
  resize_bilinear.cc
  resize_nearest_neighbor.cc
  reverse.cc
  reverse_sequence.cc
  rfft2d.cc
  roll.cc
  Generating Code...
  Compiling...
  round.cc
  scatter_nd.cc
  segment_sum.cc
  select.cc
  shape.cc
  sign.cc
  skip_gram.cc
  slice.cc
  space_to_batch_nd.cc
  space_to_depth.cc
  sparse_to_dense.cc
  split.cc
  split_v.cc
  squared_difference.cc
  squeeze.cc
  strided_slice.cc
  sub.cc
  svdf.cc
  table.cc
  tile.cc
  Generating Code...
  Compiling...
  topk_v2.cc
  transpose.cc
  transpose_conv.cc
  unidirectional_sequence_gru.cc
  unidirectional_sequence_lstm.cc
  unidirectional_sequence_rnn.cc
  unique.cc
  unpack.cc
  var_handle.cc
  where.cc
  while.cc
  zeros_like.cc
  nnapi_implementation_disabled.cc
  allocation.cc
  arena_planner.cc
  create_op_resolver_with_builtin_ops.cc
  external_cpu_backend_context.cc
  graph_info.cc
  interpreter.cc
  interpreter_builder.cc
  Generating Code...
  Compiling...
  interpreter_builder_experimental.cc
  interpreter_experimental.cc
  minimal_logging.cc
  minimal_logging_default.cc
C:\Users\Dario\dev\tensorflow_src\tensorflow\lite\minimal_logging_default.cc(28,9): warning C4068: unknown pragma 'clang' [C:\Users\Dario\dev\tflite_build\tensorflow-lite\tensorflow-lite.vcxproj]
C:\Users\Dario\dev\tensorflow_src\tensorflow\lite\minimal_logging_default.cc(29,9): warning C4068: unknown pragma 'clang' [C:\Users\Dario\dev\tflite_build\tensorflow-lite\tensorflow-lite.vcxproj]
C:\Users\Dario\dev\tensorflow_src\tensorflow\lite\minimal_logging_default.cc(31,9): warning C4068: unknown pragma 'clang' [C:\Users\Dario\dev\tflite_build\tensorflow-lite\tensorflow-lite.vcxproj]
  mmap_allocation_disabled.cc
  model_builder.cc
  mutable_op_resolver.cc
  optional_debug_tools.cc
  signature_runner.cc
  simple_memory_arena.cc
  simple_memory_arena_debug_dump.cc
  simple_planner.cc
  stderr_reporter.cc
  string_util.cc
  tflite_with_xnnpack_optional.cc
  util.cc
  platform_profiler.cc
  sparsity_format_converter.cc
  schema_utils.cc
  Generating Code...
```
</details>"
55965,Abort in tf.random.gamma and tf.random.poisson,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

tf2.1.0

### Custom Code

No

### OS Platform and Distribution

Linux Ubuntu 18.04

### Mobile device

_No response_

### Python version

3.6.9

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
`tf.random.gamma` and `tf.random.poisson` aborts with large `shape`.
```


### Standalone code to reproduce the issue

```shell
import numpy as np
import tensorflow as tf
tf.random.poisson(lam=np.ones((3,1,2,10)), shape = [104, 155, 187, 54, 64, 49, 176, 156, 84])
```

```
import numpy as np
import tensorflow as tf
tf.random.gamma(alpha=np.ones((3,1,2,10)), shape = [104, 155, 187, 54, 64, 49, 176, 156, 84])
```
```


### Relevant log output

```shell
2022-05-06 19:01:11.992136: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2022-05-06 19:01:11.992159: E tensorflow/stream_executor/cuda/cuda_driver.cc:351] failed call to cuInit: UNKNOWN ERROR (303)
2022-05-06 19:01:11.992201: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:163] no NVIDIA GPU device is present: /dev/nvidia0 does not exist
2022-05-06 19:01:11.992512: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2022-05-06 19:01:12.035310: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz
2022-05-06 19:01:12.042104: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x556a19dea300 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2022-05-06 19:01:12.042150: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2022-05-06 19:01:12.054334: F tensorflow/core/framework/tensor_shape.cc:353] Check failed: 0 <= new_num_elements (0 vs. -1)
Aborted (core dumped)

```
```
</details>"
55964,Segfualt in tf.ragged.segment_ids_to_row_splits,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

tf2.1.0

### Custom Code

No

### OS Platform and Distribution

Linux Ubuntu 18.04

### Mobile device

_No response_

### Python version

3.6.9

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
A segmentation fault occurred:
```


### Standalone code to reproduce the issue

```shell
import tensorflow as tf
tf.ragged.segment_ids_to_row_splits(segment_ids=[1,1], num_segments=1, out_type=20)
```
```


### Relevant log output

```shell
2022-05-06 18:49:54.747657: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2022-05-06 18:49:54.747681: E tensorflow/stream_executor/cuda/cuda_driver.cc:351] failed call to cuInit: UNKNOWN ERROR (303)
2022-05-06 18:49:54.747723: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:163] no NVIDIA GPU device is present: /dev/nvidia0 does not exist
2022-05-06 18:49:54.747996: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2022-05-06 18:49:54.779246: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz
2022-05-06 18:49:54.786014: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55ebcefb66d0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2022-05-06 18:49:54.786061: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
Segmentation fault (core dumped)
```
```
</details>"
55960,Unit test build failure on AARCH64,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Build/Install

### Source

source

### Tensorflow Version

git HEAD

### Custom Code

No

### OS Platform and Distribution

CentOS 7

### Mobile device

n/a

### Python version

3.8.13

### Bazel version

5.1.1

### GCC/Compiler version

10.2.1

### CUDA/cuDNN version

n/a

### GPU model and memory

n/a

### Current Behaviour?

```shell
//tensorflow/compiler/mlir/xla/tests/hlo_to_lhlo_with_xla:hlo_text_to_lhlo_no_opt.hlotxt.test FAILED TO BUILD
```


### Standalone code to reproduce the issue

```shell
bazel test --test_timeout=300,500,-1,-1 --flaky_test_attempts=3 --test_output=all --cache_test_results=no --noremote_accept_cached --config=nonccl --copt=""-mtune=generic"" --copt=""-march=armv8-a"" --copt=""-O3"" --build_tag_filters=-no_oss,-oss_serial,-gpu,-tpu,-benchmark-test,-v1only,-no_aarch64,-requires-gpu --test_tag_filters=-no_oss,-oss_serial,-gpu,-tpu,-benchmark-test,-v1only,-no_aarch64,-requires-gpu --verbose_failures --build_tests_only -- //tensorflow/compiler/mlir/xla/tests/...
```


### Relevant log output

```shell
ERROR: /tmp/workspace/tensorflow-git/tensorflow/compiler/mlir/xla/BUILD:725:13: Linking tensorflow/compiler/mlir/xla/xla-opt-gpu failed: (Exit 1): gcc failed: error executing command 
  (cd /root/.cache/bazel/_bazel_root/db210f68f81d95ddcca9ae96b16ed72c/execroot/org_tensorflow && \
  exec env - \
    LD_LIBRARY_PATH=/opt/rh/devtoolset-10/root/usr/lib64:/opt/rh/devtoolset-10/root/usr/lib:/opt/rh/devtoolset-10/root/usr/lib64/dyninst:/opt/rh/devtoolset-10/root/usr/lib/dyninst:/usr/local/lib64 \
    PATH=/root/.cache/bazelisk/downloads/bazelbuild/bazel-5.1.1-linux-arm64/bin:/tmp/workspace/venv-cp38-cp38/bin:/opt/rh/devtoolset-10/root/usr/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \
    PWD=/proc/self/cwd \
    PYTHON_BIN_PATH=/tmp/workspace/venv-cp38-cp38/bin/python3 \
    PYTHON_LIB_PATH=/tmp/workspace/venv-cp38-cp38/lib/python3.8/site-packages \
    TF2_BEHAVIOR=1 \
  /opt/rh/devtoolset-10/root/usr/bin/gcc @bazel-out/aarch64-opt/bin/tensorflow/compiler/mlir/xla/xla-opt-gpu-2.params)
# Configuration: 92dba1cfc4f3c6543dbe3e81a2d486f27b48fb279788144993db9493fddedf49
# Execution platform: @local_execution_config_platform//:platform
/opt/rh/devtoolset-10/root/usr/bin/ld.gold: error: Stub is too far away, try a smaller value for '--stub-group-size'. The current value is 0x7ffbffc.
collect2: error: ld returned 1 exit status
INFO: Elapsed time: 291.246s, Critical Path: 156.86s
INFO: 916 processes: 917 local.
FAILED: Build did NOT complete successfully
```
</details>"
55958,3D SSIM ,"Hi, is it possible to add 3D SSIM (batched) into TensorFlow? We need this feature for 3D inference. Currently `tf.image.ssim` only accepts batched 2D input. 

If not, is there any internal beta version of 3D SSIM for try-out? 

Thanks. 
"
55957,Reopened : Is tf2xla used even when jit_compile=False,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

tf 2.8

### Custom Code

No

### OS Platform and Distribution

linux 64 bit

### Mobile device

_No response_

### Python version

3.9

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
Reopening https://github.com/tensorflow/tensorflow/issues/55207
```


### Standalone code to reproduce the issue

```shell
See https://github.com/tensorflow/tensorflow/issues/55207
```


### Relevant log output

_No response_</details>"
55956,"When using Lambda, the output of the 1/x process is very likely to have nan/inf","<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

tf2.0

### Custom Code

Yes

### OS Platform and Distribution

Ubuntu 20.04.2 LTS (GNU/Linux 5.4.0-74-generic x86_64)

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

gcc (Ubuntu 9.3.0-17ubuntu1~20.04) 9.3.0

### CUDA/cuDNN version

CUDA Version: 11.2

### GPU model and memory

_No response_

### Current Behaviour?

```shell
When using Lambda, the output of the 1/x process is very likely to have nan/inf.  In some cases, the operator will not show output-nan/inf, but will show output-nan/inf. Scenarios, where this happens with lambda, are generally: when the lambda expression carried in the lambda operator has certain risks (the operator does not impose certain constraints on its expression).
```


### Standalone code to reproduce the issue

```shell
[{'name': 'ReduceMax', 'params': {'keep_dims': True, 'dim': 1, 'tensor_space': 4}}, {'name': 'Upsample2d', 'params': {'scale_factor': 2, 'mode': 'nearest'}}, {'name': 'Lambda', 'params': {'output_shape': [2, 32, 3], 'function': 'lambda x: 1 / x**0.5 + 1.0'}}, {'name': 'Flatten'}, {'name': 'Dense', 'params': {'in_features': 192, 'out_features': 200}}, {'name': 'Softmax'}]
```


### Relevant log output

_No response_</details>"
55955,"When using Rsqrt, the output of the 1/x process is very likely to have nan/inf","<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

tf2.0

### Custom Code

Yes

### OS Platform and Distribution

Ubuntu 20.04.2 LTS (GNU/Linux 5.4.0-74-generic x86_64)

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

gcc (Ubuntu 9.3.0-17ubuntu1~20.04) 9.3.0

### CUDA/cuDNN version

CUDA Version: 11.2

### GPU model and memory

_No response_

### Current Behaviour?

```shell
When using Rsqrt, the output of the 1/x process is very likely to have nan/inf. In some cases, the operator will not show output-nan/inf, but will show output-nan/inf
```


### Standalone code to reproduce the issue

```shell
[{'name': 'Slice', 'params': {'tensor_space': 4, 'begin': [0, 9, 1, 1], 'size': [50, 7, 15, 1]}}, {'name': 'ReduceMax', 'params': {'keep_dims': True, 'dim': 1, 'tensor_space': 4}}, {'name': 'Rsqrt', 'params': {}}, {'name': 'Flatten'}, {'name': 'Dense', 'params': {'in_features': 15, 'out_features': 200}}, {'name': 'Softmax'}]

[{'name': 'ReduceMean', 'params': {'keep_dims': True, 'dim': 3, 'tensor_space': 4}}, {'name': 'ReduceMean', 'params': {'keep_dims': False, 'dim': 1, 'tensor_space': 4}}, {'name': 'Flatten', 'params': {}}, {'name': 'Rsqrt', 'params': {}}, {'name': 'Dense', 'params': {'in_features': 16, 'out_features': 200}}, {'name': 'Softmax'}]

[{'name': 'ReduceSum', 'params': {'keep_dims': True, 'dim': 1, 'tensor_space': 4}}, {'name': 'Rsqrt', 'params': {}}, {'name': 'Flatten'}, {'name': 'Dense', 'params': {'in_features': 48, 'out_features': 200}}, {'name': 'Softmax'}]
```


### Relevant log output

_No response_</details>"
55954,Conv2dTranspose causes the inconsistency of output between frameworks,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

tf2.0

### Custom Code

Yes

### OS Platform and Distribution

Ubuntu 20.04.2 LTS (GNU/Linux 5.4.0-74-generic x86_64)

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

gcc (Ubuntu 9.3.0-17ubuntu1~20.04) 9.3.0

### CUDA/cuDNN version

CUDA Version: 11.2

### GPU model and memory

_No response_

### Current Behaviour?

```shell
Operators with Conv2dTranspose often cause inconsistency between frameworks. And for this inconsistency, only changing the input may cause its nature to change.
（Inconsistency: When testing the three frameworks, the inconsistency here refers to comparing the output of the Conv2dTranspose layer with the other two frameworks and computing their absolute values.）
```


### Standalone code to reproduce the issue

```shell
structure：
[{'name': 'Conv2dTranspose', 'params': {'in_channels': 1, 'out_channels': 96, 'kernel_size': [1, 1], 'stride': 1, 'dilation': 1, 'padding': 'same', 'bias': True, 'out_padding': 0}}, {'name': 'Flatten'}, {'name': 'Dense', 'params': {'in_features': 75264, 'out_features': 10}}, {'name': 'Softmax'}]
```


### Relevant log output

_No response_</details>"
55953,Conv2d causes the inconsistency of output between frameworks,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

tf2.0

### Custom Code

Yes

### OS Platform and Distribution

Ubuntu 20.04.2 LTS (GNU/Linux 5.4.0-74-generic x86_64)

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

gcc (Ubuntu 9.3.0-17ubuntu1~20.04) 9.3.0

### CUDA/cuDNN version

CUDA Version: 11.2

### GPU model and memory

_No response_

### Current Behaviour?

```shell
Operators with Conv2d often cause inconsistency between frameworks. And for this inconsistency, only changing the input may cause its nature to change.
（Inconsistency: When testing the three frameworks, the inconsistency here refers to comparing the output of the Conv2d layer with the other two frameworks and computing their absolute values.）
```


### Standalone code to reproduce the issue

```shell
structure：
[{'name': 'Conv2d', 'params': {'in_channels': 1, 'out_channels': 110, 'kernel_size': [6, 6], 'stride': 2, 'dilation': 1, 'padding': 'valid', 'bias': True}}, {'name': 'Flatten'}, {'name': 'Dense', 'params': {'in_features': 15840, 'out_features': 10}}, {'name': 'Softmax'}]

[{'name': 'Conv2d', 'params': {'in_channels': 1, 'out_channels': 52, 'kernel_size': [3, 3], 'stride': 1, 'dilation': 1, 'padding': 'same', 'bias': True}}, {'name': 'Flatten'}, {'name': 'Dense', 'params': {'in_features': 40768, 'out_features': 10}}, {'name': 'Softmax'}]
```


### Relevant log output

_No response_</details>"
55952,Resize causes the inconsistency of output between frameworks,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

tf2.0

### Custom Code

Yes

### OS Platform and Distribution

Ubuntu 20.04.2 LTS (GNU/Linux 5.4.0-74-generic x86_64)

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

gcc (Ubuntu 9.3.0-17ubuntu1~20.04) 9.3.0

### CUDA/cuDNN version

CUDA Version: 11.2

### GPU model and memory

_No response_

### Current Behaviour?

```shell
Operators with Resize often cause inconsistency between frameworks. And for this inconsistency, only changing the input may cause its nature to change.
（Inconsistency: When testing the three frameworks, the inconsistency here refers to comparing the output of the Resize layer with the other two frameworks and computing their absolute values.）
```


### Standalone code to reproduce the issue

```shell
structure：
[{'name': 'Resize', 'params': {'output_shape': [56, 15], 'mode': 'nearest'}}, {'name': 'Flatten'}, {'name': 'Dense', 'params': {'in_features': 840, 'out_features': 10}}, {'name': 'Softmax'}]

[{'name': 'Resize', 'params': {'output_shape': 19, 'mode': 'bicubic'}}, {'name': 'Flatten'}, {'name': 'Dense', 'params': {'in_features': 361, 'out_features': 10}}, {'name': 'Softmax'}]
```


### Relevant log output

_No response_</details>"
55951,AvgPool2d causes the inconsistency of output between frameworks,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

tf2.0

### Custom Code

Yes

### OS Platform and Distribution

Ubuntu 20.04.2 LTS (GNU/Linux 5.4.0-74-generic x86_64)

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

gcc (Ubuntu 9.3.0-17ubuntu1~20.04) 9.3.0

### CUDA/cuDNN version

CUDA Version: 11.2

### GPU model and memory

_No response_

### Current Behaviour?

```shell
Operators with AvgPool2d often cause inconsistency between frameworks. And for this inconsistency, only changing the input may cause its nature to change.
（Inconsistency: When testing the three frameworks, the inconsistency here refers to comparing the output of the AvgPool2d layer with the other two frameworks and computing their absolute values.）
```


### Standalone code to reproduce the issue

```shell
structure：
[{'name': 'AvgPool2d', 'params': {'pool_size': [7, 7], 'stride': [4, 1], 'padding': 'same'}}, {'name': 'Flatten'}, {'name': 'Dense', 'params': {'in_features': 196, 'out_features': 10}}, {'name': 'Softmax'}]
```


### Relevant log output

_No response_</details>"
55950,LayerNorm2d causes the inconsistency of output between frameworks,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

tf2.0

### Custom Code

Yes

### OS Platform and Distribution

Ubuntu 20.04.2 LTS (GNU/Linux 5.4.0-74-generic x86_64)

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

gcc (Ubuntu 9.3.0-17ubuntu1~20.04) 9.3.0

### CUDA/cuDNN version

CUDA Version: 11.2

### GPU model and memory

_No response_

### Current Behaviour?

```shell
Operators with LayerNorm2d often cause inconsistency between frameworks. And for this inconsistency, only changing the input may cause its nature to change.
（Inconsistency: When testing the three frameworks, the inconsistency here refers to comparing the output of the LayerNorm2d layer with the other two frameworks and computing their absolute values.）
```


### Standalone code to reproduce the issue

```shell
structure：
[{'name': 'Slice', 'params': {'tensor_space': 4, 'begin': [0, 10, 11, 0], 'size': [25, 13, 9, 1]}}, {'name': 'ReduceProd', 'params': {'keep_dims': True, 'dim': 3, 'tensor_space': 4}}, {'name': 'LayerNorm2d', 'params': {'eps': 6.995509286454143e-06, 'affine': True}}, {'name': 'Flatten'}, {'name': 'Dense', 'params': {'in_features': 117, 'out_features': 10}}, {'name': 'Softmax'}]
```


### Relevant log output

_No response_</details>"
55949,BatchNorm2d causes the inconsistency of output between frameworks,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

tf2.0

### Custom Code

Yes

### OS Platform and Distribution

Ubuntu 20.04.2 LTS (GNU/Linux 5.4.0-74-generic x86_64)

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

gcc (Ubuntu 9.3.0-17ubuntu1~20.04) 9.3.0

### CUDA/cuDNN version

CUDA Version: 11.2

### GPU model and memory

_No response_

### Current Behaviour?

```shell
Operators with BatchNorm2d often cause inconsistency between frameworks. And for this inconsistency, only changing the input may cause its nature to change.
（Inconsistency: When testing the three frameworks, the inconsistency here refers to comparing the output of the BatchNorm2d layer with the other two frameworks and computing their absolute values.）
```


### Standalone code to reproduce the issue

```shell
structure：
[{'name': 'ReLU6', 'params': {}}, {'name': 'BatchNorm2d', 'params': {'num_features': 1, 'eps': 2.5745934595451317e-06, 'momentum': 0.33708481957135894, 'affine': False, 'track_running_stats': True}}, {'name': 'Flatten'}, {'name': 'Dense', 'params': {'in_features': 784, 'out_features': 10}}, {'name': 'Softmax'}]
```


### Relevant log output

_No response_</details>"
55948,GlobalAvgPool2d causes the inconsistency of output between frameworks,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

tf2.0

### Custom Code

Yes

### OS Platform and Distribution

Ubuntu 20.04.2 LTS (GNU/Linux 5.4.0-74-generic x86_64)

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

gcc (Ubuntu 9.3.0-17ubuntu1~20.04) 9.3.0

### CUDA/cuDNN version

CUDA Version: 11.2

### GPU model and memory

_No response_

### Current Behaviour?

```shell
Operators with GlobalAvgPool2d often cause inconsistency between frameworks. And for this inconsistency, only changing the input may cause its nature to change.
（Inconsistency: When testing the three frameworks, the inconsistency here refers to comparing the output of the GlobalAvgPool2d layer with the other two frameworks and computing their absolute values.）
```


### Standalone code to reproduce the issue

```shell
structure：
[{'name': 'GlobalMaxPool2d', 'params': {}}, {'name': 'Dense', 'params': {'in_features': 1, 'out_features': 10}}, {'name': 'Softmax'}]
```


### Relevant log output

_No response_</details>"
55947,GlobalAveragePooling2D causes the inconsistency of output between frameworks,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

tf2.0

### Custom Code

Yes

### OS Platform and Distribution

Ubuntu 20.04.2 LTS (GNU/Linux 5.4.0-74-generic x86_64)

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

gcc (Ubuntu 9.3.0-17ubuntu1~20.04) 9.3.0

### CUDA/cuDNN version

CUDA Version: 11.2

### GPU model and memory

_No response_

### Current Behaviour?

```shell
Operators with Sum and Avg often cause inconsistency between frameworks. And for this inconsistency, only changing the input may cause its nature to change.

（Inconsistency: When testing the three frameworks, the inconsistency here refers to comparing the output of the GlobalAvgPool2d layer with the other two frameworks and computing their absolute values.）
```


### Standalone code to reproduce the issue

```shell
structure：GlobalAvgPool2d + Flatten + Dense + Softmax
dataset：mnist
batchsize：25
When batchsize is 25， it will appear as Tensorflow Inconsistency.
```


### Relevant log output

_No response_</details>"
55946,Build tensorflow failed using GCP RBE for python numpy_include module,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Build/Install

### Source

source

### Tensorflow Version

tf master, 2.8, 2,7.3

### Custom Code

No

### OS Platform and Distribution

Ubuntu 20.04.4 LTS

### Mobile device

_No response_

### Python version

3.8

### Bazel version

_No response_

### GCC/Compiler version

bazel 5.1.1

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
Build tensorflow failed using GCP RBE for

cp: cannot stat '/usr/local/lib/python3.8/dist-packages/numpy/core/include/numpy/.doxyfile': No such file or directory
```
but the file exist in local build machine
```
#  ls -al /usr/local/lib/python3.8/dist-packages/numpy/core/include/numpy/.doxyfile
-rw-r--r-- 1 root staff 58 May  6 12:25 /usr/local/lib/python3.8/dist-packages/numpy/core/include/numpy/.doxyfile
```
```


### Standalone code to reproduce the issue

```shell
# bazel build --config=rbe_cpu_linux //tensorflow/tools/pip_package:build_pip_package --config=tensorflow_testing_rbe_linux
```


### Relevant log output

```shell
# bazel build --config=rbe_cpu_linux //tensorflow/tools/pip_package:build_pip_package --config=tensorflow_testing_rbe_linux
WARNING: Option 'project_id' is deprecated: Use --bes_instance_name instead
INFO: Invocation ID: 6a945e3f-3528-413e-a110-58f8d1156089
INFO: Streaming build results to: https://source.cloud.google.com/results/invocations/6a945e3f-3528-413e-a110-58f8d1156089
INFO: Options provided by the client:
  Inherited 'common' options: --isatty=1 --terminal_columns=237
INFO: Reading rc options for 'build' from /data/tensorflow/.bazelrc:
  Inherited 'common' options: --experimental_repo_remote_exec
INFO: Reading rc options for 'build' from /data/tensorflow/.bazelrc:
  'build' options: --define framework_shared_object=true --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --enable_platform_specific_config --define=with_xla_support=true --config=short_logs --config=v2 --define=no_aws_support=true --define=no_hdfs_support=true --experimental_cc_shared_library --experimental_link_static_libraries_once=true
INFO: Reading rc options for 'build' from /data/tensorflow/.tf_configure.bazelrc:
  'build' options: --action_env PYTHON_BIN_PATH=/usr/bin/python3 --action_env PYTHON_LIB_PATH=/usr/lib/python3/dist-packages --python_path=/usr/bin/python3
INFO: Reading rc options for 'build' from /data/tensorflow/.bazelrc:
  'build' options: --deleted_packages=tensorflow/compiler/mlir/tfrt,tensorflow/compiler/mlir/tfrt/benchmarks,tensorflow/compiler/mlir/tfrt/jit/python_binding,tensorflow/compiler/mlir/tfrt/jit/transforms,tensorflow/compiler/mlir/tfrt/python_tests,tensorflow/compiler/mlir/tfrt/tests,tensorflow/compiler/mlir/tfrt/tests/ir,tensorflow/compiler/mlir/tfrt/tests/analysis,tensorflow/compiler/mlir/tfrt/tests/jit,tensorflow/compiler/mlir/tfrt/tests/lhlo_to_tfrt,tensorflow/compiler/mlir/tfrt/tests/tf_to_corert,tensorflow/compiler/mlir/tfrt/tests/tf_to_tfrt_data,tensorflow/compiler/mlir/tfrt/tests/saved_model,tensorflow/compiler/mlir/tfrt/transforms/lhlo_gpu_to_tfrt_gpu,tensorflow/core/runtime_fallback,tensorflow/core/runtime_fallback/conversion,tensorflow/core/runtime_fallback/kernel,tensorflow/core/runtime_fallback/opdefs,tensorflow/core/runtime_fallback/runtime,tensorflow/core/runtime_fallback/util,tensorflow/core/tfrt/common,tensorflow/core/tfrt/eager,tensorflow/core/tfrt/eager/backends/cpu,tensorflow/core/tfrt/eager/backends/gpu,tensorflow/core/tfrt/eager/core_runtime,tensorflow/core/tfrt/eager/cpp_tests/core_runtime,tensorflow/core/tfrt/gpu,tensorflow/core/tfrt/run_handler_thread_pool,tensorflow/core/tfrt/runtime,tensorflow/core/tfrt/saved_model,tensorflow/core/tfrt/graph_executor,tensorflow/core/tfrt/saved_model/tests,tensorflow/core/tfrt/tpu,tensorflow/core/tfrt/utils
INFO: Found applicable config definition build:short_logs in file /data/tensorflow/.bazelrc: --output_filter=DONT_MATCH_ANYTHING
INFO: Found applicable config definition build:v2 in file /data/tensorflow/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1
INFO: Found applicable config definition build:rbe_cpu_linux in file /data/tensorflow/.bazelrc: --config=rbe_linux --config=rbe_cpu_linux_base
INFO: Found applicable config definition build:rbe_linux in file /data/tensorflow/.bazelrc: --config=rbe_linux_base --config=avx_linux --linkopt=-lrt --host_linkopt=-lrt --linkopt=-lm --host_linkopt=-lm
INFO: Found applicable config definition build:rbe_linux_base in file /data/tensorflow/.bazelrc: --config=rbe --action_env=PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/go/bin
INFO: Found applicable config definition build:rbe in file /data/tensorflow/.bazelrc: --repo_env=BAZEL_DO_NOT_DETECT_CPP_TOOLCHAIN=1 --google_default_credentials --bes_backend=buildeventservice.googleapis.com --bes_results_url=https://source.cloud.google.com/results/invocations --bes_timeout=600s --define=EXECUTOR=remote --distinct_host_configuration=false --flaky_test_attempts=3 --jobs=200 --remote_executor=grpcs://remotebuildexecution.googleapis.com --remote_timeout=3600 --spawn_strategy=remote,worker,standalone,local --remote_download_toplevel
INFO: Found applicable config definition build:avx_linux in file /data/tensorflow/.bazelrc: --copt=-mavx --host_copt=-mavx
INFO: Found applicable config definition build:rbe_cpu_linux_base in file /data/tensorflow/.bazelrc: --host_crosstool_top=@ubuntu20.04-gcc9_manylinux2014-cuda11.2-cudnn8.1-tensorrt7.2_config_cuda//crosstool:toolchain --crosstool_top=@ubuntu20.04-gcc9_manylinux2014-cuda11.2-cudnn8.1-tensorrt7.2_config_cuda//crosstool:toolchain --extra_toolchains=@ubuntu20.04-gcc9_manylinux2014-cuda11.2-cudnn8.1-tensorrt7.2_config_cuda//crosstool:toolchain-linux-x86_64 --extra_execution_platforms=@ubuntu20.04-gcc9_manylinux2014-cuda11.2-cudnn8.1-tensorrt7.2_config_platform//:platform --host_platform=@ubuntu20.04-gcc9_manylinux2014-cuda11.2-cudnn8.1-tensorrt7.2_config_platform//:platform --platforms=@ubuntu20.04-gcc9_manylinux2014-cuda11.2-cudnn8.1-tensorrt7.2_config_platform//:platform
INFO: Found applicable config definition common:tensorflow_testing_rbe_linux in file /data/tensorflow/.bazelrc: --remote_instance_name=projects/xiaomi-rbe-poc/instances/xiaomi-cloud-rbe-us
INFO: Found applicable config definition build:tensorflow_testing_rbe_linux in file /data/tensorflow/.bazelrc: --config=tensorflow_testing_rbe --repo_env=TF_CUDA_COMPUTE_CAPABILITIES=sm_75
INFO: Found applicable config definition build:tensorflow_testing_rbe in file /data/tensorflow/.bazelrc: --project_id=xiaomi-rbe-poc
INFO: Found applicable config definition build:linux in file /data/tensorflow/.bazelrc: --copt=-w --host_copt=-w --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --define=PROTOBUF_INCLUDE_PATH=$(PREFIX)/include --cxxopt=-std=c++14 --host_cxxopt=-std=c++14 --config=dynamic_kernels --distinct_host_configuration=false --experimental_guard_against_concurrent_changes
INFO: Found applicable config definition build:dynamic_kernels in file /data/tensorflow/.bazelrc: --define=dynamic_loaded_kernels=true --copt=-DAUTOLOAD_DYNAMIC_KERNELS
DEBUG: /data/.cache/bazel/_bazel_root/48b0697df5815d95b49fd98c3083955b/external/bazel_tools/tools/cpp/lib_cc_configure.bzl:118:10: 
Auto-Configuration Warning: 'TMP' environment variable is not set, using 'C:\Windows\Temp' as default
INFO: Analyzed target //tensorflow/tools/pip_package:build_pip_package (0 packages loaded, 0 targets configured).
INFO: Found 1 target...
WARNING: Remote Cache: PERMISSION_DENIED: Permission ""remotebuildexecution.actions.set"" denied on resource ""projects/xiaomi-rbe-poc/instances/xiaomi-cloud-rbe-us"" (or it may not exist)
ERROR: /data/.cache/bazel/_bazel_root/48b0697df5815d95b49fd98c3083955b/external/local_config_python/BUILD:221:8: Executing genrule @local_config_python//:numpy_include failed: (Exit 1): bash failed: error executing command /bin/bash -c ... (remaining 1 argument skipped)
cp: cannot stat '/usr/local/lib/python3.8/dist-packages/numpy/core/include/numpy/.doxyfile': No such file or directory
Target //tensorflow/tools/pip_package:build_pip_package failed to build
Use --verbose_failures to see the command lines of failed build steps.
ERROR: /data/.cache/bazel/_bazel_root/48b0697df5815d95b49fd98c3083955b/external/local_config_python/BUILD:66:11 Middleman _middlemen/@local_Uconfig_Upython_S_S_Cnumpy_Uheaders-BazelCppSemantics_build_arch_k8-opt failed: (Exit 1): bash failed: error executing command /bin/bash -c ... (remaining 1 argument skipped)
INFO: Elapsed time: 3.029s, Critical Path: 2.44s
INFO: 439 processes: 176 remote cache hit, 260 internal, 1 local, 2 remote.
```
</details>"
55945,could not download Bazel: HTTP GET https://releases.bazel.build/5.1.1,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Build/Install

### Source

source

### Tensorflow Version

tensorflow from your tensorflow/tensorflow:devel

### Custom Code

No

### OS Platform and Distribution

Ubuntu 20.04.4 LTS

### Mobile device

android

### Python version

3.8

### Bazel version

no

### GCC/Compiler version

gcc version 9.4.0 (Ubuntu 9.4.0-1ubuntu1~20.04.1) 

### CUDA/cuDNN version

no

### GPU model and memory

no cuda

### Current Behaviour?

```shell
Hi, i followed your tutorial<https://www.tensorflow.org/lite/android/lite_build#set_up_build_environment_using_docker> to build tensorflow and tflite in a docker. I got a network error:
+ bazel build -c opt --cxxopt=--std=c++14 --fat_apk_cpu=arm64-v8a,armeabi-v7a --host_crosstool_top=@bazel_tools//tools/cpp:toolchain //tmp:tensorflow-lite
2022/05/06 09:48:55 Downloading https://releases.bazel.build/5.1.1/release/bazel-5.1.1-linux-x86_64...
2022/05/06 09:49:00 could not download Bazel: HTTP GET https://releases.bazel.build/5.1.1/release/bazel-5.1.1-linux-x86_64 failed: Get ""https://releases.bazel.build/5.1.1/release/bazel-5.1.1-linux-x86_64"": read tcp 172.17.0.14:54726->130.211.22.235:443: read: connection reset by peer

I tried to install bazel in advance, but the same problem still occurred. It seems that the bazel installed by myself did not take effect. When running the bazel command, I still tried to download bazel 5.1.1, and then failed due to network problems.
/tensorflow_src# bazel
2022/05/06 09:58:01 Downloading https://releases.bazel.build/5.1.1/release/bazel-5.1.1-linux-x86_64...
2022/05/06 09:58:02 could not download Bazel: HTTP GET https://releases.bazel.build/5.1.1/release/bazel-5.1.1-linux-x86_64 failed: Get ""https://releases.bazel.build/5.1.1/release/bazel-5.1.1-linux-x86_64"": read tcp 172.17.0.14:54934->130.211.22.235:443: read: connection reset by peer
```


### Standalone code to reproduce the issue

```shell
1.follow your tutorial:https://www.tensorflow.org/lite/android/lite_build#set_up_build_environment_using_docker
2.build:
bash tensorflow/lite/tools/build_aar.sh --input_models=model.tflite --target_archs=arm64-v8a,armeabi-v7a
```


### Relevant log output

_No response_</details>"
55942,libtensorflow_cc.so: Undefined references due to static dependencies with cc_shared_library and symbol hiding by linker scripts,"### Issue Type

Build/Install

### Source

source

### Tensorflow Version

617ca3da6c56ff668c202f853757d8df6ac779d7

### Custom Code

No

### OS Platform and Distribution

Linux Ubuntu 20.04

### Mobile device

_No response_

### Python version

3.8.10

### Bazel version

5.1.1 and 6.0.0-pre.20220421.3

### GCC/Compiler version

gcc (Ubuntu 9.4.0-1ubuntu1~20.04.1) 9.4.0

### CUDA/cuDNN version

11.7

### GPU model and memory

3080

### Current Behaviour?

Since the recent change to use `cc_shared_library`, I am seeing many undefined reference linker errors coming from LLVM/MLIR and libjpeg.

Both `libtensorflow_framework` and `libtensorflow_cc` have LLVM and libjpeb as static dependencies. Since `libtensorflow_cc` has a dynamic dependency on `libtensorflow_framework`, it appears that the behavior of `cc_shared_library` is to retrieve the static deps via `libtensorflow_framework` (previously, both libraries would duplicate them). The problem is that it cannot load the symbols because the [linker](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tf_private_symbols.lds) [scripts](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tf_framework_version_script.lds) are explicitly hiding those exact symbols.

### Standalone code to reproduce the issue

Simply build `libtensorflow_cc.so`.

```shell
docker pull tensorflow/tensorflow:devel
docker run -it -w /tensorflow_src -v $PWD:/mnt -e HOST_PERMS=""$(id -u):$(id -g)"" tensorflow/tensorflow:devel bash
git pull
echo """" | ./configure
bazel build --config=opt  --experimental_ui_max_stdouterr_bytes=-1 //tensorflow:libtensorflow_cc.so
```

` --experimental_ui_max_stdouterr_bytes=-1` is only needed to see the error message, otherwise it is hidden because it is too long due to all of the undefined references.

### Relevant log output


There are thousands of undefined references to LLVM,MLIR and libjpeg, here is a small snippet.

```shell
ERROR: /opt/tensorflow/tensorflow-source/tensorflow/BUILD:1135:20: Linking tensorflow/libtensorflow_cc.so.2.10.0 failed: (Exit 1): crosstool_wrapper_driver_is_not_gcc failed: error executing command (from target //tensorflow:libtensorflow_cc.so.2.10.0) external/local_co[294/1887]crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc @bazel-out/k8-opt/bin/tensorflow/libtensorflow_cc.so.2.10.0-2.params                                                                                                                                                            /usr/bin/ld: bazel-out/k8-opt/bin/tensorflow/core/lib/jpeg/libjpeg_internal.pic.a(jpeg_mem.pic.o): in function `tensorflow::jpeg::GetImageInfo(void const*, int, int*, int*, int*)':                                                                                                    jpeg_mem.cc:(.text._ZN10tensorflow4jpeg12GetImageInfoEPKviPiS3_S3_+0x95): undefined reference to `jpeg_std_error'                                                                                                                                                                       /usr/bin/ld: jpeg_mem.cc:(.text._ZN10tensorflow4jpeg12GetImageInfoEPKviPiS3_S3_+0xe2): undefined reference to `jpeg_CreateDecompress'                                                                                                                                                   /usr/bin/ld: jpeg_mem.cc:(.text._ZN10tensorflow4jpeg12GetImageInfoEPKviPiS3_S3_+0x107): undefined reference to `jpeg_read_header'                                                                                                                                                       /usr/bin/ld: jpeg_mem.cc:(.text._ZN10tensorflow4jpeg12GetImageInfoEPKviPiS3_S3_+0x10f): undefined reference to `jpeg_calc_output_dimensions'                                                                                                                                            /usr/bin/ld: jpeg_mem.cc:(.text._ZN10tensorflow4jpeg12GetImageInfoEPKviPiS3_S3_+0x157): undefined reference to `jpeg_destroy_decompress'                                                                                                                                                /usr/bin/ld: bazel-out/k8-opt/bin/tensorflow/core/lib/jpeg/libjpeg_internal.pic.a(jpeg_mem.pic.o): in function `tensorflow::jpeg::(anonymous namespace)::UncompressLow(void const*, tensorflow::jpeg::(anonymous namespace)::FewerArgsForCompiler*)':  
```"
55934,"hexagon delegate fails with -- dlopen failed: cannot locate symbol ""dlopen""","I'm trying to get hexagon (Qualcomm's NN accelerator DSP) working on Android, but following the [instructions](https://www.tensorflow.org/lite/android/delegates/hexagon) leads me here.

When I run my app, I get the following crash:

```
2022-05-05 11:22:07.315 20487-20487/org.tensorflow.lite.examples.detection E/AndroidRuntime: FATAL EXCEPTION: main
    Process: org.tensorflow.lite.examples.detection, PID: 20487
    java.lang.UnsatisfiedLinkError: dlopen failed: cannot locate symbol ""dlopen"" referenced by ""/data/app/~~oHfy74UV0cmPBaaworOtcA==/org.tensorflow.lite.examples.detection-KxIoTs7gEXEEvawBkjkh0A==/lib/arm64/libtensorflowlite_hexagon_jni.so""...
        at java.lang.Runtime.loadLibrary0(Runtime.java:1087)
        at java.lang.Runtime.loadLibrary0(Runtime.java:1008)
        at java.lang.System.loadLibrary(System.java:1664)
        at org.tensorflow.lite.examples.detection.tflite.TFLiteObjectDetectionAPIModel.create(TFLiteObjectDetectionAPIModel.java:145)
```

I'm trying to run this on the `tflite` `object_detection` example app from `github.com/tensorflow/examples`, on Android.

My Android device:
```
Device: Xiaomi Redmi Note 9 Pro

adb shell getprop ro.product.device
    joyeuse

adb shell getprop ro.board.platform
    atoll
```

If I `adb shell` into `/data/app/~~oHfy74UV0cmPBaaworOtcA==/org.tensorflow.lite.examples.detection-KxIoTs7gEXEEvawBkjkh0A==/lib/arm64`, and `ls`, then I see the following files:
```
libhexagon_interface.so                        
libhexagon_nn_skel.so                          
libhexagon_nn_skel_v65.so                      
libhexagon_nn_skel_v66.so                      
libtensorflowlite_hexagon_jni.so               
libtensorflowlite_jni.so                       
```

It seems very strange that `dlopen` itself is not found!"
55933,Segfault on tf.matmul and tf.einsum with batched input tensors using intel-tensorflow-avx512,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

tf 2.8

### Custom Code

Yes

### OS Platform and Distribution

SUSE Linux Enterprise Server 15 SP3, Kernel 5.3.18-59.19

### Mobile device

_No response_

### Python version

3.9.10

### Bazel version

5.1.1

### GCC/Compiler version

7.5.0

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?


Using `intel-tensorflow-avx512` either compiled manually or from the official pip package source, a segmentation fault is observed on the calls `tf.matmul` and `tf.einsum`. The log output is `Segmentation fault (core dumped)`.


After calling `tf.matmul` on tensors with at least one batching dimension, a consecutive call to `tf.einsum` causes a segfault. The same happens for `tf.einsum` followed by a `tf.matmul`. 
Calling just `tf.matmul` or just `tf.einsum` does not trigger a segfault.


This crash does not appear when using a shape such as [n,n], i.e. a shape without batching dimensions.
The non-Intel tensorflow version does not result in a segfault.


The section ""Standalone code to reproduce the issue"" gives a minimal example. The code within `# either #` and `# or #` refers to the two possible call orders.
The section ""Relevant log output"" lists a backtrace of the dumped core, shortened for brevity. The backtrace was obtained using gdb.

The self-compiled `intel-tensorflow-avx512` was compiled using ""Intel® Optimization for TensorFlow* Installation Guide"" [1].

This bug has been observed on two separate machine, running an Intel Xeon Platinum 8360Y and Intel Xeon W-2295 respectively. The second machine runs Linux Ubuntu Server 20.04.4 LTS.

[1] https://www.intel.com/content/www/us/en/developer/articles/guide/optimization-for-tensorflow-installation-guide.html



### Standalone code to reproduce the issue

```shell
import tensorflow as tf

b = 1
n = 4

shape = [b,n,n]

# either # 
print(f""Einsum A*B: {tf.einsum('...ij, ...jk -> ...ik', tf.random.normal(shape), tf.random.normal(shape)).shape}"")
print(f""Matmul A*B: {tf.matmul(tf.random.normal(shape), tf.random.normal(shape)).shape}"") # <-- crash

# or # 
print(f""Matmul A*B: {tf.matmul(tf.random.normal(shape), tf.random.normal(shape)).shape}"")
print(f""Einsum A*B: {tf.einsum('...ij, ...jk -> ...ik', tf.random.normal(shape), tf.random.normal(shape)).shape}"")  # <-- crash
```


### Relevant log output

```shell
(gdb) r </path/to/script.py>
Starting program: <path/to/python3> </path/to/script.py>
[...]

Einsum A*B: (1, 4, 4)

Thread 1 ""python3"" received signal SIGSEGV, Segmentation fault.
0x0000000002edf9c0 in ?? ()
(gdb) bt
#0  0x0000000002edf9c0 in ?? ()
#1  0x00007f2b36ffa0f1 in tensorflow::CreateStream(tensorflow::MklDnnThreadPool*, dnnl::engine const&) [clone .isra.370] ()
   from [...]/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#2  0x00007f2b37003010 in tensorflow::BatchMatMulMkl<Eigen::ThreadPoolDevice, float, float, float, true>::Compute(tensorflow::OpKernelContext*) ()
   from [...]/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#3  0x00007f2b2cff5644 in tensorflow::ThreadPoolDevice::Compute(tensorflow::OpKernel*, tensorflow::OpKernelContext*) ()
   from [...]/site-packages/tensorflow/python/../libtensorflow_framework.so.2
#4  0x00007f2b38da8dff in tensorflow::KernelAndDeviceOp::Run([...]) ()
   from [...]/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#5  0x00007f2b32c5c30c in tensorflow::EagerKernelExecute([...]) ()
   from [...]/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#6  0x00007f2b32c5d1a1 in tensorflow::ExecuteNode::Run() ()
   from [...]/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#7  0x00007f2b39232e8a in tensorflow::EagerExecutor::SyncExecute(tensorflow::EagerNode*) ()
   from [...]/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#8  0x00007f2b32c57e10 in tensorflow::(anonymous namespace)::EagerLocalExecute(tensorflow::EagerOperation*, tensorflow::TensorHandle**, int*) ()
   from [...]/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#9  0x00007f2b32c58439 in tensorflow::EagerExecute(tensorflow::EagerOperation*, tensorflow::TensorHandle**, int*) ()
   from [...]/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#10 0x00007f2b328d4319 in tensorflow::EagerOperation::Execute(absl::lts_20210324::Span<tensorflow::AbstractTensorHandle*>, int*) ()
   from [...]/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#11 0x00007f2b38db8a29 in tensorflow::CustomDeviceOpHandler::Execute([...]) () 
   from [...]/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#12 0x00007f2b325e783d in TFE_Execute ()
   from [...]/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#13 0x00007f2b32170bfb in TFE_Py_FastPathExecute_C(_object*) ()
   from [...]/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so
#14 0x00007f2b2829ba05 in pybind11::cpp_function::initialize<[...]>[...] () 
   from [...]/site-packages/tensorflow/python/_pywrap_tfe.so
#15 0x00007f2b282c0bb0 in pybind11::cpp_function::dispatcher(_object*, _object*, _object*) ()
   from [...]/site-packages/tensorflow/python/_pywrap_tfe.so
#16 0x00000000005f3989 in PyCFunction_Call ()

[...]

#62 Py_BytesMain (argc=<optimized out>, argv=<optimized out>)
    at [...]/main.c:731
#63 0x00007ffff66bd34d in __libc_start_main () from /lib64/libc.so.6
#64 0x000000000040106a in _start () at ../sysdeps/x86_64/start.S:120
```
</details>"
55932,tensorflow.python.framework.errors_impl.AlreadyExistsError: File system for s3 already registered error in load_library.py,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

'2.4.1'

### Custom Code

No

### OS Platform and Distribution

Linux Kubuntu 18.04

### Mobile device

_No response_

### Python version

Python 3.9.12

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

cudatoolkit: 10.1.243 ; cudnn:7.6.5

### GPU model and memory

_No response_

### Current Behaviour?

```shell
I am trying to locally train a model from tensorflow using the following command:


!python3 {ws_path}models/research/object_detection/model_main_tf2.py \
    --pipeline_config_path={pipeline_config_path} \
    --model_dir={model_dir} \
    --alsologtostderr \
    --num_train_steps={num_steps} \
    --sample_1_of_n_eval_examples=1 \
    --num_eval_steps={num_eval_steps}


But an error occurred and I tried really hard to search around but I can't find anything that could be a help. The error is as follow:

tensorflow.python.framework.errors_impl.AlreadyExistsError: File system for s3 already registered
```


### Standalone code to reproduce the issue

```shell
Maybe you can look at this recently posted question in stackoverflow:
https://stackoverflow.com/questions/72080563/alreadyexistserror-file-system-for-s3-already-registered

We got the same error on anaconda3\some-path\tensorflow\python\framework\load_library.py
```


### Relevant log output

```shell
2022-05-05 15:40:47.232501: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
Traceback (most recent call last):
  File ""/home/pinky/architectures/TRAINING/faster-rcnn-tf2/models/research/object_detection/model_main_tf2.py"", line 31, in <module>
    from object_detection import model_lib_v2
  File ""/home/pinky/anaconda3/envs/faster-rcnn-tf2/lib/python3.9/site-packages/object_detection/model_lib_v2.py"", line 30, in <module>
    from object_detection import inputs
  File ""/home/pinky/anaconda3/envs/faster-rcnn-tf2/lib/python3.9/site-packages/object_detection/inputs.py"", line 27, in <module>
    from object_detection.builders import model_builder
  File ""/home/pinky/anaconda3/envs/faster-rcnn-tf2/lib/python3.9/site-packages/object_detection/builders/model_builder.py"", line 37, in <module>
    from object_detection.meta_architectures import deepmac_meta_arch
  File ""/home/pinky/anaconda3/envs/faster-rcnn-tf2/lib/python3.9/site-packages/object_detection/meta_architectures/deepmac_meta_arch.py"", line 28, in <module>
    import tensorflow_io as tfio  # pylint:disable=g-import-not-at-top
  File ""/home/pinky/anaconda3/envs/faster-rcnn-tf2/lib/python3.9/site-packages/tensorflow_io-0.25.0-py3.9-linux-x86_64.egg/tensorflow_io/__init__.py"", line 17, in <module>
    from tensorflow_io.python.api import *  # pylint: disable=wildcard-import
  File ""/home/pinky/anaconda3/envs/faster-rcnn-tf2/lib/python3.9/site-packages/tensorflow_io-0.25.0-py3.9-linux-x86_64.egg/tensorflow_io/python/api/__init__.py"", line 19, in <module>
    from tensorflow_io.python.ops.io_dataset import IODataset
  File ""/home/pinky/anaconda3/envs/faster-rcnn-tf2/lib/python3.9/site-packages/tensorflow_io-0.25.0-py3.9-linux-x86_64.egg/tensorflow_io/python/ops/__init__.py"", line 96, in <module>
    plugin_ops = _load_library(""libtensorflow_io_plugins.so"", ""fs"")
  File ""/home/pinky/anaconda3/envs/faster-rcnn-tf2/lib/python3.9/site-packages/tensorflow_io-0.25.0-py3.9-linux-x86_64.egg/tensorflow_io/python/ops/__init__.py"", line 64, in _load_library
    l = load_fn(f)
  File ""/home/pinky/anaconda3/envs/faster-rcnn-tf2/lib/python3.9/site-packages/tensorflow_io-0.25.0-py3.9-linux-x86_64.egg/tensorflow_io/python/ops/__init__.py"", line 56, in <lambda>
    load_fn = lambda f: tf.experimental.register_filesystem_plugin(f) is None
  File ""/home/pinky/anaconda3/envs/faster-rcnn-tf2/lib/python3.9/site-packages/tensorflow/python/framework/load_library.py"", line 178, in register_filesystem_plugin
    py_tf.TF_RegisterFilesystemPlugin(plugin_location)
tensorflow.python.framework.errors_impl.AlreadyExistsError: File system for s3 already registered
```
</details>"
55931,Build error,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Build/Install

### Source

source

### Tensorflow Version

2.8

### Custom Code

No

### OS Platform and Distribution

GNU C17 (Gentoo x86_64-pc-linux-gnu)

### Mobile device

_No response_

### Python version

3.10

### Bazel version

4.2.2

### GCC/Compiler version

11.2.1_p20220115 p4

### CUDA/cuDNN version

no

### GPU model and memory

_No response_

### Current Behaviour?

```shell
Good day, I'm trying to build t11 from source, but with ""bazel build //tensorflow/tools/pip_package:build_pip_package"" I get the error ""Unrecognized option: --experimental_link_static_libraries_once=true""

openjdk version ""11.0.14"" 2022-01-18
OpenJDK Runtime Environment Temurin-11.0.14+9 (build 11.0.14+9)
OpenJDK 64-Bit Server VM Temurin-11.0.14+9 (build 11.0.14+9, mixed mode)
```


### Standalone code to reproduce the issue

```shell
https://prnt.sc/qoLWRYn1d5E8
```


### Relevant log output

```shell
bazel build //tensorflow/tools/pip_package:build_pip_package
INFO: Reading rc options for 'build' from /root/tensorflow/.bazelrc:
  'build' options: --define framework_shared_object=true --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --enable_platform_specific_config --define=with_xla_support=true --config=short_logs --config=v2 --define=no_aws_support=true --define=no_hdfs_support=true --experimental_cc_shared_library --experimental_link_static_libraries_once=true
ERROR: --experimental_link_static_libraries_once=true :: Unrecognized option: --experimental_link_static_libraries_once=true
```
</details>"
55930,Tensorflow GPU Cannot assign a device for operation MatMul,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Build/Install

### Source

source

### Tensorflow Version

1.15.0 gpu version

### Custom Code

No

### OS Platform and Distribution

RHEL 7.9

### Mobile device

_No response_

### Python version

3.7

### Bazel version

_No response_

### GCC/Compiler version

gcc (GCC) 4.8.5 20150623

### CUDA/cuDNN version

cuda 11.0 and driver version: 450.80.02

### GPU model and memory

_No response_

### Current Behaviour?

```shell
Tensor flow

tensorflow                         2.4.0
tensorflow-estimator               1.15.1
tensorflow-gpu                     1.15.0
tensorflow-io-gcs-filesystem       0.25.0

Below is the code from documentation
```


### Standalone code to reproduce the issue

```shell
Here is the code

import numpy as np
#import tensorflow as tf
import tensorflow.compat.v1 as tf
tf.disable_v2_behavior()
import datetime

# Processing Units logs
log_device_placement = True

# Num of multiplications to perform
n = 10

'''
Example: compute A^n + B^n on 2 GPUs
Results on 8 cores with 2 GTX-980:
 * Single GPU computation time: 0:00:11.277449
 * Multi GPU computation time: 0:00:07.131701
'''
# Create random large matrix
A = np.random.rand(2000, 2000).astype('float32')
B = np.random.rand(2000, 2000).astype('float32')

# Create a graph to store results
c1 = []
c2 = []

def matpow(M, n):
    if n < 1: #Abstract cases where n < 1
        return M
    else:
        return tf.matmul(M, matpow(M, n-1))

'''
Single GPU computing
'''
with tf.device('/gpu:0'):
    a = tf.placeholder(tf.float32, [2000, 2000])
    b = tf.placeholder(tf.float32, [2000, 2000])
    # Compute A^n and B^n and store results in c1
    c1.append(matpow(a, n))
    c1.append(matpow(b, n))

with tf.device('/cpu:0'):
    sum = tf.add_n(c1) #Addition of all elements in c1, i.e. A^n + B^n

t1_1 = datetime.datetime.now()
with tf.Session(config=tf.ConfigProto(log_device_placement=log_device_placement)) as sess:
    # Run the op.
    sess.run(sum, {a:A, b:B})
t2_1 = datetime.datetime.now()


'''
Multi GPU computing
'''
# GPU:0 computes A^n
with tf.device('/gpu:0'):
    # Compute A^n and store result in c2
    a = tf.placeholder(tf.float32, [2000, 2000])
    c2.append(matpow(a, n))

# GPU:1 computes B^n
with tf.device('/gpu:1'):
    # Compute B^n and store result in c2
    b = tf.placeholder(tf.float32, [2000, 2000])
    c2.append(matpow(b, n))

with tf.device('/cpu:0'):
    sum = tf.add_n(c2) #Addition of all elements in c2, i.e. A^n + B^n

t1_2 = datetime.datetime.now()
with tf.Session(config=tf.ConfigProto(log_device_placement=log_device_placement)) as sess:
    # Run the op.
    sess.run(sum, {a:A, b:B})
t2_2 = datetime.datetime.now()


print(""Single GPU computation time: "" + str(t2_1-t1_1))
print(""Multi GPU computation time: "" + str(t2_2-t1_2))
```


### Relevant log output

After executed the code got following warning message

WARNING:tensorflow:From /opt/miniconda3/envs/PY37/lib/python3.7/site-packages/tensorflow_core/python/compat/v2_compat.py:68: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.
Instructions for updating:
non-resource variables are not supported in the long term
Device mapping:
/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device
/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device
/job:localhost/replica:0/task:0/device:XLA_GPU:1 -> device: XLA_GPU device
/job:localhost/replica:0/task:0/device:XLA_GPU:2 -> device: XLA_GPU device
/job:localhost/replica:0/task:0/device:XLA_GPU:3 -> device: XLA_GPU device
/job:localhost/replica:0/task:0/device:XLA_GPU:4 -> device: XLA_GPU device
/job:localhost/replica:0/task:0/device:XLA_GPU:5 -> device: XLA_GPU device
/job:localhost/replica:0/task:0/device:XLA_GPU:6 -> device: XLA_GPU device
/job:localhost/replica:0/task:0/device:XLA_GPU:7 -> device: XLA_GPU device

then got below error

```shell
Error log:

InvalidArgumentError                      Traceback (most recent call last)
/opt/miniconda3/envs/PY37/lib/python3.7/site-packages/tensorflow_core/python/client/session.py in _do_call(self, fn, *args)
   1364     try:
-> 1365       return fn(*args)
   1366     except errors.OpError as e:

/opt/miniconda3/envs/PY37/lib/python3.7/site-packages/tensorflow_core/python/client/session.py in _run_fn(feed_dict, fetch_list, target_list, options, run_metadata)
   1347       # Ensure any changes to the graph are reflected in the runtime.
-> 1348       self._extend_graph()
   1349       return self._call_tf_sessionrun(options, feed_dict, fetch_list,

/opt/miniconda3/envs/PY37/lib/python3.7/site-packages/tensorflow_core/python/client/session.py in _extend_graph(self)
   1387     with self._graph._session_run_lock():  # pylint: disable=protected-access
-> 1388       tf_session.ExtendSession(self._session)
   1389 

InvalidArgumentError: Cannot assign a device for operation MatMul: {{node MatMul}} was explicitly assigned to /device:GPU:0 but available devices are [ /job:localhost/replica:0/task:0/device:CPU:0, /job:localhost/replica:0/task:0/device:XLA_CPU:0, /job:localhost/replica:0/task:0/device:XLA_GPU:0, /job:localhost/replica:0/task:0/device:XLA_GPU:1, /job:localhost/replica:0/task:0/device:XLA_GPU:2, /job:localhost/replica:0/task:0/device:XLA_GPU:3, /job:localhost/replica:0/task:0/device:XLA_GPU:4, /job:localhost/replica:0/task:0/device:XLA_GPU:5, /job:localhost/replica:0/task:0/device:XLA_GPU:6, /job:localhost/replica:0/task:0/device:XLA_GPU:7 ]. Make sure the device specification refers to a valid device.
	 [[MatMul]]

During handling of the above exception, another exception occurred:

InvalidArgumentError                      Traceback (most recent call last)
<ipython-input-1-f301b9bff9d4> in <module>
     47 with tf.Session(config=tf.ConfigProto(log_device_placement=log_device_placement)) as sess:
     48     # Run the op.
---> 49     sess.run(sum, {a:A, b:B})
     50 t2_1 = datetime.datetime.now()
     51 

/opt/miniconda3/envs/PY37/lib/python3.7/site-packages/tensorflow_core/python/client/session.py in run(self, fetches, feed_dict, options, run_metadata)
    954     try:
    955       result = self._run(None, fetches, feed_dict, options_ptr,
--> 956                          run_metadata_ptr)
    957       if run_metadata:
    958         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)

/opt/miniconda3/envs/PY37/lib/python3.7/site-packages/tensorflow_core/python/client/session.py in _run(self, handle, fetches, feed_dict, options, run_metadata)
   1178     if final_fetches or final_targets or (handle and feed_dict_tensor):
   1179       results = self._do_run(handle, final_targets, final_fetches,
-> 1180                              feed_dict_tensor, options, run_metadata)
   1181     else:
   1182       results = []

/opt/miniconda3/envs/PY37/lib/python3.7/site-packages/tensorflow_core/python/client/session.py in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)
   1357     if handle is None:
   1358       return self._do_call(_run_fn, feeds, fetches, targets, options,
-> 1359                            run_metadata)
   1360     else:
   1361       return self._do_call(_prun_fn, handle, feeds, fetches)

/opt/miniconda3/envs/PY37/lib/python3.7/site-packages/tensorflow_core/python/client/session.py in _do_call(self, fn, *args)
   1382                     '\nsession_config.graph_options.rewrite_options.'
   1383                     'disable_meta_optimizer = True')
-> 1384       raise type(e)(node_def, op, message)
   1385 
   1386   def _extend_graph(self):

InvalidArgumentError: Cannot assign a device for operation MatMul: node MatMul (defined at /opt/miniconda3/envs/PY37/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:1748)  was explicitly assigned to /device:GPU:0 but available devices are [ /job:localhost/replica:0/task:0/device:CPU:0, /job:localhost/replica:0/task:0/device:XLA_CPU:0, /job:localhost/replica:0/task:0/device:XLA_GPU:0, /job:localhost/replica:0/task:0/device:XLA_GPU:1, /job:localhost/replica:0/task:0/device:XLA_GPU:2, /job:localhost/replica:0/task:0/device:XLA_GPU:3, /job:localhost/replica:0/task:0/device:XLA_GPU:4, /job:localhost/replica:0/task:0/device:XLA_GPU:5, /job:localhost/replica:0/task:0/device:XLA_GPU:6, /job:localhost/replica:0/task:0/device:XLA_GPU:7 ]. Make sure the device specification refers to a valid device.
	 [[MatMul]]
```
</details>"
55929,No bounding box detection when using GPU,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

v2.8.0-rc1-32-g3f878cff5b6 2.8.0

### Custom Code

Yes

### OS Platform and Distribution

Linux Ubuntu 20.04

### Mobile device

_No response_

### Python version

3.9.7

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

CUDA V10.1.243  cuDNN 8400

### GPU model and memory

_No response_

### Current Behaviour?

```shell
I have a custom yolov4 .weights that is converted to .tf model. When run on GPU, the model only gives detection for first 2 frames. However, when the model is run on CPU, all detection are properly made.

I have tried out the same at my local machine, a workstation, and at Google Colab, all results the same.
```


### Standalone code to reproduce the issue

```shell
The code used was imported from https://github.com/theAIGuysCode/yolov4-deepsort.git 
We used a custom yolov4 model trained on darknet. To run our detection, we first compile .weights into .tf using *save_model.py* and then changed the path for *weights* to point to our model and updated the core/config.py *coco.names* to our custom *label.names*
```


### Relevant log output

```shell
Output when running on GPU

OpenCV: FFMPEG: tag 0x44495658/'XVID' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'
OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'
Frame #:  1
Objects being tracked: 3
FPS: 0.38
Frame #:  2
Objects being tracked: 0
FPS: 17.86
Frame #:  3
Objects being tracked: 0
FPS: 16.62
Frame #:  4
Objects being tracked: 0
FPS: 16.76
Frame #:  5
Objects being tracked: 0
FPS: 16.45
Frame #:  6
Objects being tracked: 0
FPS: 16.78
Frame #:  7
Objects being tracked: 0
FPS: 16.47
Frame #:  8
Objects being tracked: 0
FPS: 15.85
Frame #:  9
Objects being tracked: 0
.....................


Output when running on CPU

OpenCV: FFMPEG: tag 0x44495658/'XVID' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'
OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'
Frame #:  1
Objects being tracked: 3
FPS: 1.00
Frame #:  2
Objects being tracked: 3
FPS: 5.62
Frame #:  3
Objects being tracked: 3
Tracker ID: 1, Class: car,  BBox Coords (xmin, ymin, xmax, ymax): (67, 467, 146, 508)
Tracker ID: 2, Class: van,  BBox Coords (xmin, ymin, xmax, ymax): (235, 455, 522, 620)
Tracker ID: 3, Class: bus,  BBox Coords (xmin, ymin, xmax, ymax): (0, 435, 44, 482)
FPS: 5.97
Frame #:  4
Objects being tracked: 3
Tracker ID: 1, Class: car,  BBox Coords (xmin, ymin, xmax, ymax): (67, 467, 146, 508)
Tracker ID: 2, Class: van,  BBox Coords (xmin, ymin, xmax, ymax): (220, 441, 549, 631)
Tracker ID: 3, Class: bus,  BBox Coords (xmin, ymin, xmax, ymax): (0, 435, 44, 482)
FPS: 5.60
Frame #:  5
Objects being tracked: 3
Tracker ID: 1, Class: car,  BBox Coords (xmin, ymin, xmax, ymax): (68, 467, 146, 508)
Tracker ID: 2, Class: van,  BBox Coords (xmin, ymin, xmax, ymax): (253, 451, 545, 618)
Tracker ID: 3, Class: bus,  BBox Coords (xmin, ymin, xmax, ymax): (0, 435, 44, 482)
FPS: 5.82
Frame #:  6
Objects being tracked: 2
Tracker ID: 1, Class: car,  BBox Coords (xmin, ymin, xmax, ymax): (67, 467, 146, 508)
Tracker ID: 2, Class: van,  BBox Coords (xmin, ymin, xmax, ymax): (277, 453, 555, 610)
Tracker ID: 3, Class: bus,  BBox Coords (xmin, ymin, xmax, ymax): (0, 435, 44, 482)
FPS: 6.07
Frame #:  7
Objects being tracked: 2
Tracker ID: 1, Class: car,  BBox Coords (xmin, ymin, xmax, ymax): (67, 467, 146, 508)
Tracker ID: 2, Class: van,  BBox Coords (xmin, ymin, xmax, ymax): (277, 446, 578, 615)
FPS: 6.21
Frame #:  8
Objects being tracked: 2
Tracker ID: 1, Class: car,  BBox Coords (xmin, ymin, xmax, ymax): (67, 467, 146, 508)
Tracker ID: 2, Class: van,  BBox Coords (xmin, ymin, xmax, ymax): (297, 439, 588, 603)
FPS: 6.04
Frame #:  9
Objects being tracked: 2
Tracker ID: 1, Class: car,  BBox Coords (xmin, ymin, xmax, ymax): (67, 467, 146, 508)
Tracker ID: 2, Class: van,  BBox Coords (xmin, ymin, xmax, ymax): (315, 438, 593, 593)
FPS: 6.12
Frame #:  10
Objects being tracked: 2
Tracker ID: 1, Class: car,  BBox Coords (xmin, ymin, xmax, ymax): (67, 467, 146, 508)
Tracker ID: 2, Class: van,  BBox Coords (xmin, ymin, xmax, ymax): (332, 441, 596, 586)
FPS: 6.27
Frame #:  11
Objects being tracked: 2
Tracker ID: 1, Class: car,  BBox Coords (xmin, ymin, xmax, ymax): (67, 466, 147, 508)
Tracker ID: 2, Class: van,  BBox Coords (xmin, ymin, xmax, ymax): (317, 428, 627, 599)
.....................................
```
</details>"
55928,TfLite for Microcontrollers giving hybrid error,"I converted my keras .h5 file to a quantized tflite in order to run on the new stm32f746   but when I run it I get an error saying ""Hybrid Models are not supported on TFLite Micro.""

I'm not sure why my model is appearing as hybrid; the code I used to convert is below:

`      model = keras.models.load_model('2D_2CHAN_32_T1_model_2021-09-17_11-27-55.h5')
       converter = tf.lite.TFLiteConverter.from_keras_model(model)
       converter.optimizations = [tf.lite.Optimize.DEFAULT]
       converter.target_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]
       tflite_model = converter.convert()
       source_text, header_text = convert_bytes_to_c_source(tflite_model,""best_2Duint8"")
           with  open('best_2Duint8.h',  'w')  as  file:
                 file.write(header_text)
           with  open('best_2Duint8.cc',  'w')  as  file:
                 file.write(source_text)`

If I didn't do the quantization, I could have used the input of Float32 to get the right result, but the model was too big and too slow. If I quantify it, I get the same error whether I change the input to uint8_t or uint16_t.

Error message:../tensorflow/tensorflow/lite/micro/kernels/conv.cc Hybrid models are not supported on TFLite Micro. Node CONV_2D (number 4) failed to invoke with status 1

I'd appreciate if someone could guide me if I'm doing something wrong or if there is a better way to convert it."
55921,cannot import name '__version__' from 'keras',
55917,A problem in the example for pix2pix,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type
Others


### Current Behavior?

```shell
On this site:
https://github.com/tensorflow/docs/blob/master/site/en/tutorials/generative/pix2pix.ipynb

The output of the generator is tanh, but the image it is compared to is [0,...,1].  
This means half the dynamic range of the activation is wasted.  
This is going to slow down learning.

Where it says this:
last = tf.keras.layers.Conv2DTranspose(OUTPUT_CHANNELS, 4,
                                         strides=2,
                                         padding='same',
                                         kernel_initializer=initializer,
                                         activation='tanh') 

It might be better to say this:
last = tf.keras.layers.Conv2DTranspose(OUTPUT_CHANNELS, 4,
                                         strides=2,
                                         padding='same',
                                         kernel_initializer=initializer,
                                         activation='sigmoid')
```


### Standalone code to reproduce the issue

```shell
#test the discriminator

img_in = inp/255.
print(np.max(img_in))
print(np.min(img_in))

plt.imshow(img_in)
plt.colorbar()
plt.title(""Input image Left"")
plt.show()

gen_out = tf.keras.backend.squeeze(gen_output,0)
print(np.max(gen_out))
print(np.min(gen_out))
plt.imshow(gen_out)
plt.colorbar()
plt.title(""Input image Right"")
plt.show()

#put image pair through the discriminator
disc_out = discriminator([inp[tf.newaxis, ...], gen_output], training=False)

#show the discriminator output
# NOTE: the size is MUCH smaller than the input image.
plt.imshow(disc_out[0, ..., -1], vmin=-20, vmax=20, cmap='RdBu_r')
plt.title(""Discriminator Output (Note the axes scales)"")
plt.colorbar()
```


### Relevant log output

```shell
#this is the actual image range
1.0
0.0

#this is the warning it gives for the need to clip
Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).

#this is the actual range of the generator output
1.0
-1.0

<matplotlib.colorbar.Colorbar at 0x1c286147310>
```
</details>"
55916,tfd.Normal.prob outputs probabilities greater than 1,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

tf 2.8

### Custom Code

Yes

### OS Platform and Distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
A bug happened!
tfd.Normal.prob outputs probabilities greater than 1
```


### Standalone code to reproduce the issue

```shell
import tensorflow_probability as tfp
tfd = tfp.distributions

dist = tfd.Normal(loc=0.53605634, scale=0.3021255)
dist.prob(0.41487068)

output: <tf.Tensor: shape=(), dtype=float32, numpy=1.218389>
```


### Relevant log output

_No response_</details>"
55915,tf.train.Checkpoint does not support RMSprop weights for tensorflow-macos 2.8.8 ,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Feature Request

### Source

source

### Tensorflow Version

tensorflow-macos 2.8.0

### Custom Code

No

### OS Platform and Distribution

MacOS

### Mobile device

_No response_

### Python version

3.8.8

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
Optimizer is not supported

When I select 'RMSProp' in 
checkpoint = tf.train.Checkpoint(optimizer='RMSprop', model=model)
Then I get (1). The same when I don't use a string, but a full optimizer declaration in keras 

When I run it without setting an optimizer, then status.assert_consumed() starts complaining:
(2)
```


### Standalone code to reproduce the issue

```shell
keras.optimizer_v2.rmsprop.RMSprop 

tf.train.Checkpoint(optimizer='RMSprop', model=model)
```


### Relevant log output

```shell
(1)
Traceback (most recent call last):
  File ""main.py"", line 80, in <module>
    main(config_dot)
  File ""main.py"", line 47, in main
    model = load_model(config, training_data)
  File ""/Users/mark/Code/pythonProjects/music_RNN/train.py"", line 127, in load_model
    checkpoint = tf.train.Checkpoint(optimizer='RMSprop', model=model)
  File ""/Users/mark/opt/anaconda3/envs/tensorlfowGPU/lib/python3.8/site-packages/tensorflow/python/training/tracking/util.py"", line 2017, in __init__
    _assert_trackable(converted_v, k)
  File ""/Users/mark/opt/anaconda3/envs/tensorlfowGPU/lib/python3.8/site-packages/tensorflow/python/training/tracking/util.py"", line 1463, in _assert_trackable
    raise ValueError(
ValueError: `Checkpoint` was expecting optimizer to be a trackable object (an object derived from `Trackable`), got RMSprop. If you believe this object should be trackable (i.e. it is part of the TensorFlow Python API and manages state), please open an issue.



(2)
Traceback (most recent call last):
  File ""main.py"", line 80, in <module>
    main(config_dot)
  File ""main.py"", line 47, in main
    model = load_model(config, training_data)
  File ""/Users/mark/Code/pythonProjects/music_RNN/train.py"", line 131, in load_model
    status.assert_consumed()
  File ""/Users/mark/opt/anaconda3/envs/tensorlfowGPU/lib/python3.8/site-packages/tensorflow/python/training/tracking/util.py"", line 784, in assert_consumed
    raise AssertionError(
AssertionError: Unresolved object in checkpoint (root).model.optimizer.iter: attributes {
  name: ""VARIABLE_VALUE""
  full_name: ""RMSprop/iter""
  checkpoint_key: ""model/optimizer/iter/.ATTRIBUTES/VARIABLE_VALUE""
}
has_checkpoint_values {
  value: true
}

WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).model.optimizer.iter
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).model.optimizer.decay
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).model.optimizer.learning_rate
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).model.optimizer.momentum
WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).model.optimizer.rho
```
</details>"
55889,tf.data.Dataset.from_generator fails when Tensorflow is imported inside an Abseil app," ### Issue Type

Bug

### Source

binary

### Tensorflow Version

https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow_cpu-2.8.0-cp38-cp38-manylinux2010_x86_64.whl

### Custom Code

No

### Python version

3.8

### Current Behaviour?

`tf.data.Dataset.from_generator` fails with `Unable to find FunctionDef for __inference_Dataset_from_generator_generator_next_fn_24 in the registry. [Op:MakeIterator]` when tensorflow is imported within the body of a function when called from an Abseil app.

Works when tensorflow is imported the standard way in the script header then called from within the Abseil app.

Works when imported within a non-Abseil app function called from `__main__`.

Only seems to fail when the import occurs inside a function called within an Abseil app.

Only `tf.data.Dataset.from_generator` seems to be affected. Other pipelines can be used without issue and models can be trained on them.

Tested with CPU-only Tensorflow 2.8.0 (also tested with 2.7.0) installed from prebuilt wheel.
- `https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow_cpu-2.8.0-cp38-cp38-manylinux2010_x86_64.whl`
- `https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow_cpu-2.7.0-cp38-cp38-manylinux2010_x86_64.whl`

---

### Standalone code to reproduce the issue

#### Tensorflow deferred import in absl app function

```python
from absl import app

def main(argv):
    import tensorflow as tf

    print('tf.data.Dataset.range', list(iter(tf.data.Dataset.range(4))))

    def fn():
        yield from range(4)

    ds = tf.data.Dataset.from_generator(fn, output_types=tf.int32, output_shapes=())
    print('tf.data.Dataset.from_generator', list(iter(ds)))

if __name__ == ""__main__"":
    app.run(main)
```

```
tf.data.Dataset.range [<tf.Tensor: shape=(), dtype=int64, numpy=0>, <tf.Tensor: shape=(), dtype=int64, numpy=1>, <tf.Tensor: shape=(), dtype=int64, numpy=2>, <tf.Tensor: shape=(), dtype=int64, numpy=3>]
Traceback (most recent call last):
  File ""examples/test2.py"", line 19, in <module>
    app.run(main)
  File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run
    _run_main(main, args)
  File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main
    sys.exit(main(argv))
  File ""examples/test2.py"", line 16, in main
    print('tf.data.Dataset.from_generator', list(iter(ds)))
  File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/ops/dataset_ops.py"", line 486, in __iter__
    return iterator_ops.OwnedIterator(self)
  File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/ops/iterator_ops.py"", line 755, in __init__
    self._create_iterator(dataset)
  File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/data/ops/iterator_ops.py"", line 787, in _create_iterator
    gen_dataset_ops.make_iterator(ds_variant, self._iterator_resource)
  File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_dataset_ops.py"", line 3319, in make_iterator
    _ops.raise_from_not_ok_status(e, name)
  File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 7186, in raise_from_not_ok_status
    raise core._status_to_exception(e) from None  # pylint: disable=protected-access
tensorflow.python.framework.errors_impl.InvalidArgumentError: Unable to find FunctionDef for __inference_Dataset_from_generator_generator_next_fn_24 in the registry. [Op:MakeIterator]
```

---

#### Tensorflow deferred import in normal python function

```python
def main():
    import tensorflow as tf

    print('tf.data.Dataset.range', list(iter(tf.data.Dataset.range(4))))

    def fn():
        yield from range(4)

    ds = tf.data.Dataset.from_generator(fn, output_types=tf.int32, output_shapes=())
    print('tf.data.Dataset.from_generator', list(iter(ds)))

if __name__ == ""__main__"":
    main()
```

```
tf.data.Dataset.range [<tf.Tensor: shape=(), dtype=int64, numpy=0>, <tf.Tensor: shape=(), dtype=int64, numpy=1>, <tf.Tensor: shape=(), dtype=int64, numpy=2>, <tf.Tensor: shape=(), dtype=int64, numpy=3>]
tf.data.Dataset.from_generator [<tf.Tensor: shape=(), dtype=int32, numpy=0>, <tf.Tensor: shape=(), dtype=int32, numpy=1>, <tf.Tensor: shape=(), dtype=int32, numpy=2>, <tf.Tensor: shape=(), dtype=int32, numpy=3>]
```

---

#### Tensorflow standard import in header before absl app

```python
from absl import app

import tensorflow as tf

def main(argv):

    print('tf.data.Dataset.range', list(iter(tf.data.Dataset.range(4))))

    def fn():
        yield from range(4)

    ds = tf.data.Dataset.from_generator(fn, output_types=tf.int32, output_shapes=())
    print('tf.data.Dataset.from_generator', list(iter(ds)))


if __name__ == ""__main__"":
    app.run(main)
```

```
tf.data.Dataset.range [<tf.Tensor: shape=(), dtype=int64, numpy=0>, <tf.Tensor: shape=(), dtype=int64, numpy=1>, <tf.Tensor: shape=(), dtype=int64, numpy=2>, <tf.Tensor: shape=(), dtype=int64, numpy=3>]
tf.data.Dataset.from_generator [<tf.Tensor: shape=(), dtype=int32, numpy=0>, <tf.Tensor: shape=(), dtype=int32, numpy=1>, <tf.Tensor: shape=(), dtype=int32, numpy=2>, <tf.Tensor: shape=(), dtype=int32, numpy=3>]
```"
55845,//tensorflow/tools/docs:tf_doctest unit test broken,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

git HEAD

### Custom Code

No

### OS Platform and Distribution

Ubuntu 20.04

### Mobile device

n/a

### Python version

3.8.10

### Bazel version

5.1.1

### GCC/Compiler version

10.3.0

### CUDA/cuDNN version

n/a

### GPU model and memory

n/a

### Current Behaviour?

```shell
//tensorflow/tools/docs:tf_doctest fails
```


### Standalone code to reproduce the issue

```shell
bazel test --test_timeout=300,500,-1,-1 --flaky_test_attempts=3 --test_output=all --cache_test_results=no --config=nonccl --copt=""-mtune=generic"" --copt=""-march=armv8-a"" --copt=""-O3"" --verbose_failures --build_tag_filters=-no_oss,-oss_serial,-gpu,-tpu,-benchmark-test,-v1only,-no_aarch64,-requires-gpu --test_tag_filters=-no_oss,-oss_serial,-gpu,-tpu,-benchmark-test,-v1only,-no_aarch64,-requires-gpu --strip=never --build_tests_only -- //tensorflow/tools/docs:tf_doctest
```


### Relevant log output

```shell
$ bazel test --test_timeout=300,500,-1,-1 --flaky_test_attempts=3 --test_output=all --cache_test_results=no --config=nonccl --copt=""-mtune=generic"" --copt=""-march=armv8-a"" --copt=""-O3"" --verbose_failures --build_tag_filters=-no_oss,-oss_serial,-gpu,-tpu,-benchmark-test,-v1only,-no_aarch64,-requires-gpu --test_tag_filters=-no_oss,-oss_serial,-gpu,-tpu,-benchmark-test,-v1only,-no_aarch64,-requires-gpu --strip=never --build_tests_only -- //tensorflow/tools/docs:tf_doctest
INFO: Options provided by the client:
  Inherited 'common' options: --isatty=1 --terminal_columns=159
INFO: Reading rc options for 'test' from /home/builder/1/tensorflow_build/tensorflow-git/.bazelrc:
  Inherited 'common' options: --experimental_repo_remote_exec
INFO: Reading rc options for 'test' from /home/builder/1/tensorflow_build/tensorflow-git/.bazelrc:
  Inherited 'build' options: --define framework_shared_object=true --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --enable_platform_specific_config --define=with_xla_support=true --config=short_logs --config=v2 --define=no_aws_support=true --define=no_hdfs_support=true --experimental_cc_shared_library --experimental_link_static_libraries_once=true
INFO: Reading rc options for 'test' from /home/builder/1/tensorflow_build/tensorflow-git/.tf_configure.bazelrc:
  Inherited 'build' options: --action_env PYTHON_BIN_PATH=/home/builder/1/tensorflow_build/venv_py38/bin/python3 --action_env PYTHON_LIB_PATH=/home/builder/1/tensorflow_build/venv_py38/lib/python3.8/site-packages --python_path=/home/builder/1/tensorflow_build/venv_py38/bin/python3
INFO: Reading rc options for 'test' from /home/builder/1/tensorflow_build/tensorflow-git/.bazelrc:
  Inherited 'build' options: --deleted_packages=tensorflow/compiler/mlir/tfrt,tensorflow/compiler/mlir/tfrt/benchmarks,tensorflow/compiler/mlir/tfrt/jit/python_binding,tensorflow/compiler/mlir/tfrt/jit/transforms,tensorflow/compiler/mlir/tfrt/python_tests,tensorflow/compiler/mlir/tfrt/tests,tensorflow/compiler/mlir/tfrt/tests/ir,tensorflow/compiler/mlir/tfrt/tests/analysis,tensorflow/compiler/mlir/tfrt/tests/jit,tensorflow/compiler/mlir/tfrt/tests/lhlo_to_tfrt,tensorflow/compiler/mlir/tfrt/tests/tf_to_corert,tensorflow/compiler/mlir/tfrt/tests/tf_to_tfrt_data,tensorflow/compiler/mlir/tfrt/tests/saved_model,tensorflow/compiler/mlir/tfrt/transforms/lhlo_gpu_to_tfrt_gpu,tensorflow/core/runtime_fallback,tensorflow/core/runtime_fallback/conversion,tensorflow/core/runtime_fallback/kernel,tensorflow/core/runtime_fallback/opdefs,tensorflow/core/runtime_fallback/runtime,tensorflow/core/runtime_fallback/util,tensorflow/core/tfrt/common,tensorflow/core/tfrt/eager,tensorflow/core/tfrt/eager/backends/cpu,tensorflow/core/tfrt/eager/backends/gpu,tensorflow/core/tfrt/eager/core_runtime,tensorflow/core/tfrt/eager/cpp_tests/core_runtime,tensorflow/core/tfrt/gpu,tensorflow/core/tfrt/run_handler_thread_pool,tensorflow/core/tfrt/runtime,tensorflow/core/tfrt/saved_model,tensorflow/core/tfrt/graph_executor,tensorflow/core/tfrt/saved_model/tests,tensorflow/core/tfrt/tpu,tensorflow/core/tfrt/utils
INFO: Reading rc options for 'test' from /home/builder/1/tensorflow_build/tensorflow-git/.tf_configure.bazelrc:
  'test' options: --flaky_test_attempts=3 --test_size_filters=small,medium
INFO: Found applicable config definition build:short_logs in file /home/builder/1/tensorflow_build/tensorflow-git/.bazelrc: --output_filter=DONT_MATCH_ANYTHING
INFO: Found applicable config definition build:v2 in file /home/builder/1/tensorflow_build/tensorflow-git/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1
INFO: Found applicable config definition test:v2 in file /home/builder/1/tensorflow_build/tensorflow-git/.tf_configure.bazelrc: --test_tag_filters=-benchmark-test,-no_oss,-gpu,-oss_serial,-v1only --build_tag_filters=-benchmark-test,-no_oss,-gpu,-v1only
INFO: Found applicable config definition build:nonccl in file /home/builder/1/tensorflow_build/tensorflow-git/.bazelrc: --define=no_nccl_support=true
INFO: Found applicable config definition build:linux in file /home/builder/1/tensorflow_build/tensorflow-git/.bazelrc: --copt=-w --host_copt=-w --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --define=PROTOBUF_INCLUDE_PATH=$(PREFIX)/include --cxxopt=-std=c++14 --host_cxxopt=-std=c++14 --config=dynamic_kernels --distinct_host_configuration=false --experimental_guard_against_concurrent_changes
INFO: Found applicable config definition build:dynamic_kernels in file /home/builder/1/tensorflow_build/tensorflow-git/.bazelrc: --define=dynamic_loaded_kernels=true --copt=-DAUTOLOAD_DYNAMIC_KERNELS
INFO: Analyzed target //tensorflow/tools/docs:tf_doctest (283 packages loaded, 14898 targets configured).
INFO: Found 1 test target...
FAIL: //tensorflow/tools/docs:tf_doctest (shard 3 of 4) (see /home/builder/.cache/bazel/_bazel_builder/9dc2dbd69dc3512cedb530e1521082e7/execroot/org_tensorflow/bazel-out/aarch64-opt/testlogs/tensorflow/tools/docs/tf_doctest/shard_3_of_4/test_attempts/attempt_1.log)
FAIL: //tensorflow/tools/docs:tf_doctest (shard 1 of 4) (see /home/builder/.cache/bazel/_bazel_builder/9dc2dbd69dc3512cedb530e1521082e7/execroot/org_tensorflow/bazel-out/aarch64-opt/testlogs/tensorflow/tools/docs/tf_doctest/shard_1_of_4/test_attempts/attempt_1.log)
FAIL: //tensorflow/tools/docs:tf_doctest (shard 4 of 4) (see /home/builder/.cache/bazel/_bazel_builder/9dc2dbd69dc3512cedb530e1521082e7/execroot/org_tensorflow/bazel-out/aarch64-opt/testlogs/tensorflow/tools/docs/tf_doctest/shard_4_of_4/test_attempts/attempt_1.log)
FAIL: //tensorflow/tools/docs:tf_doctest (shard 2 of 4) (see /home/builder/.cache/bazel/_bazel_builder/9dc2dbd69dc3512cedb530e1521082e7/execroot/org_tensorflow/bazel-out/aarch64-opt/testlogs/tensorflow/tools/docs/tf_doctest/shard_2_of_4/test_attempts/attempt_1.log)
FAIL: //tensorflow/tools/docs:tf_doctest (shard 3 of 4) (see /home/builder/.cache/bazel/_bazel_builder/9dc2dbd69dc3512cedb530e1521082e7/execroot/org_tensorflow/bazel-out/aarch64-opt/testlogs/tensorflow/tools/docs/tf_doctest/shard_3_of_4/test_attempts/attempt_2.log)
FAIL: //tensorflow/tools/docs:tf_doctest (shard 1 of 4) (see /home/builder/.cache/bazel/_bazel_builder/9dc2dbd69dc3512cedb530e1521082e7/execroot/org_tensorflow/bazel-out/aarch64-opt/testlogs/tensorflow/tools/docs/tf_doctest/shard_1_of_4/test_attempts/attempt_2.log)
FAIL: //tensorflow/tools/docs:tf_doctest (shard 2 of 4) (see /home/builder/.cache/bazel/_bazel_builder/9dc2dbd69dc3512cedb530e1521082e7/execroot/org_tensorflow/bazel-out/aarch64-opt/testlogs/tensorflow/tools/docs/tf_doctest/shard_2_of_4/test_attempts/attempt_2.log)
FAIL: //tensorflow/tools/docs:tf_doctest (shard 4 of 4) (see /home/builder/.cache/bazel/_bazel_builder/9dc2dbd69dc3512cedb530e1521082e7/execroot/org_tensorflow/bazel-out/aarch64-opt/testlogs/tensorflow/tools/docs/tf_doctest/shard_4_of_4/test_attempts/attempt_2.log)
FAIL: //tensorflow/tools/docs:tf_doctest (shard 2 of 4) (see /home/builder/.cache/bazel/_bazel_builder/9dc2dbd69dc3512cedb530e1521082e7/execroot/org_tensorflow/bazel-out/aarch64-opt/testlogs/tensorflow/tools/docs/tf_doctest/shard_2_of_4/test.log)
INFO: From Testing //tensorflow/tools/docs:tf_doctest (shard 2 of 4):
==================== Test output for //tensorflow/tools/docs:tf_doctest (shard 2 of 4):
2022-05-03 14:24:00.201237: E tensorflow/core/common_runtime/session_factory.cc:48] Two session factories are being registered underGRPC_SESSION
[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/descriptor_database.cc:118] File already exists in database: tensorflow/python/framework/cpp_shape_inference.proto
[libprotobuf FATAL external/com_google_protobuf/src/google/protobuf/descriptor.cc:1379] CHECK failed: GeneratedDatabase()->Add(encoded_file_descriptor, size): 
terminate called after throwing an instance of 'google::protobuf::FatalException'
  what():  CHECK failed: GeneratedDatabase()->Add(encoded_file_descriptor, size): 
================================================================================
==================== Test output for //tensorflow/tools/docs:tf_doctest (shard 2 of 4):
2022-05-03 14:24:04.612762: E tensorflow/core/common_runtime/session_factory.cc:48] Two session factories are being registered underGRPC_SESSION
[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/descriptor_database.cc:118] File already exists in database: tensorflow/python/framework/cpp_shape_inference.proto
[libprotobuf FATAL external/com_google_protobuf/src/google/protobuf/descriptor.cc:1379] CHECK failed: GeneratedDatabase()->Add(encoded_file_descriptor, size): 
terminate called after throwing an instance of 'google::protobuf::FatalException'
  what():  CHECK failed: GeneratedDatabase()->Add(encoded_file_descriptor, size): 
================================================================================
==================== Test output for //tensorflow/tools/docs:tf_doctest (shard 2 of 4):
2022-05-03 14:24:08.768859: E tensorflow/core/common_runtime/session_factory.cc:48] Two session factories are being registered underGRPC_SESSION
[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/descriptor_database.cc:118] File already exists in database: tensorflow/python/framework/cpp_shape_inference.proto
[libprotobuf FATAL external/com_google_protobuf/src/google/protobuf/descriptor.cc:1379] CHECK failed: GeneratedDatabase()->Add(encoded_file_descriptor, size): 
terminate called after throwing an instance of 'google::protobuf::FatalException'
  what():  CHECK failed: GeneratedDatabase()->Add(encoded_file_descriptor, size): 
================================================================================
FAIL: //tensorflow/tools/docs:tf_doctest (shard 3 of 4) (see /home/builder/.cache/bazel/_bazel_builder/9dc2dbd69dc3512cedb530e1521082e7/execroot/org_tensorflow/bazel-out/aarch64-opt/testlogs/tensorflow/tools/docs/tf_doctest/shard_3_of_4/test.log)
INFO: From Testing //tensorflow/tools/docs:tf_doctest (shard 3 of 4):
==================== Test output for //tensorflow/tools/docs:tf_doctest (shard 3 of 4):
2022-05-03 14:24:00.195904: E tensorflow/core/common_runtime/session_factory.cc:48] Two session factories are being registered underGRPC_SESSION
[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/descriptor_database.cc:118] File already exists in database: tensorflow/python/framework/cpp_shape_inference.proto
[libprotobuf FATAL external/com_google_protobuf/src/google/protobuf/descriptor.cc:1379] CHECK failed: GeneratedDatabase()->Add(encoded_file_descriptor, size): 
terminate called after throwing an instance of 'google::protobuf::FatalException'
  what():  CHECK failed: GeneratedDatabase()->Add(encoded_file_descriptor, size): 
================================================================================
==================== Test output for //tensorflow/tools/docs:tf_doctest (shard 3 of 4):
2022-05-03 14:24:04.547096: E tensorflow/core/common_runtime/session_factory.cc:48] Two session factories are being registered underGRPC_SESSION
[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/descriptor_database.cc:118] File already exists in database: tensorflow/python/framework/cpp_shape_inference.proto
[libprotobuf FATAL external/com_google_protobuf/src/google/protobuf/descriptor.cc:1379] CHECK failed: GeneratedDatabase()->Add(encoded_file_descriptor, size): 
terminate called after throwing an instance of 'google::protobuf::FatalException'
  what():  CHECK failed: GeneratedDatabase()->Add(encoded_file_descriptor, size): 
================================================================================
==================== Test output for //tensorflow/tools/docs:tf_doctest (shard 3 of 4):
2022-05-03 14:24:08.838289: E tensorflow/core/common_runtime/session_factory.cc:48] Two session factories are being registered underGRPC_SESSION
[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/descriptor_database.cc:118] File already exists in database: tensorflow/python/framework/cpp_shape_inference.proto
[libprotobuf FATAL external/com_google_protobuf/src/google/protobuf/descriptor.cc:1379] CHECK failed: GeneratedDatabase()->Add(encoded_file_descriptor, size): 
terminate called after throwing an instance of 'google::protobuf::FatalException'
  what():  CHECK failed: GeneratedDatabase()->Add(encoded_file_descriptor, size): 
================================================================================
FAIL: //tensorflow/tools/docs:tf_doctest (shard 4 of 4) (see /home/builder/.cache/bazel/_bazel_builder/9dc2dbd69dc3512cedb530e1521082e7/execroot/org_tensorflow/bazel-out/aarch64-opt/testlogs/tensorflow/tools/docs/tf_doctest/shard_4_of_4/test.log)
INFO: From Testing //tensorflow/tools/docs:tf_doctest (shard 4 of 4):
==================== Test output for //tensorflow/tools/docs:tf_doctest (shard 4 of 4):
2022-05-03 14:24:00.201237: E tensorflow/core/common_runtime/session_factory.cc:48] Two session factories are being registered underGRPC_SESSION
[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/descriptor_database.cc:118] File already exists in database: tensorflow/python/framework/cpp_shape_inference.proto
[libprotobuf FATAL external/com_google_protobuf/src/google/protobuf/descriptor.cc:1379] CHECK failed: GeneratedDatabase()->Add(encoded_file_descriptor, size): 
terminate called after throwing an instance of 'google::protobuf::FatalException'
  what():  CHECK failed: GeneratedDatabase()->Add(encoded_file_descriptor, size): 
================================================================================
==================== Test output for //tensorflow/tools/docs:tf_doctest (shard 4 of 4):
2022-05-03 14:24:04.675745: E tensorflow/core/common_runtime/session_factory.cc:48] Two session factories are being registered underGRPC_SESSION
[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/descriptor_database.cc:118] File already exists in database: tensorflow/python/framework/cpp_shape_inference.proto
[libprotobuf FATAL external/com_google_protobuf/src/google/protobuf/descriptor.cc:1379] CHECK failed: GeneratedDatabase()->Add(encoded_file_descriptor, size): 
terminate called after throwing an instance of 'google::protobuf::FatalException'
  what():  CHECK failed: GeneratedDatabase()->Add(encoded_file_descriptor, size): 
================================================================================
==================== Test output for //tensorflow/tools/docs:tf_doctest (shard 4 of 4):
2022-05-03 14:24:08.891334: E tensorflow/core/common_runtime/session_factory.cc:48] Two session factories are being registered underGRPC_SESSION
[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/descriptor_database.cc:118] File already exists in database: tensorflow/python/framework/cpp_shape_inference.proto
[libprotobuf FATAL external/com_google_protobuf/src/google/protobuf/descriptor.cc:1379] CHECK failed: GeneratedDatabase()->Add(encoded_file_descriptor, size): 
terminate called after throwing an instance of 'google::protobuf::FatalException'
  what():  CHECK failed: GeneratedDatabase()->Add(encoded_file_descriptor, size): 
================================================================================
FAIL: //tensorflow/tools/docs:tf_doctest (shard 1 of 4) (see /home/builder/.cache/bazel/_bazel_builder/9dc2dbd69dc3512cedb530e1521082e7/execroot/org_tensorflow/bazel-out/aarch64-opt/testlogs/tensorflow/tools/docs/tf_doctest/shard_1_of_4/test.log)

FAILED: //tensorflow/tools/docs:tf_doctest (Summary)
      /home/builder/.cache/bazel/_bazel_builder/9dc2dbd69dc3512cedb530e1521082e7/execroot/org_tensorflow/bazel-out/aarch64-opt/testlogs/tensorflow/tools/docs/tf_doctest/shard_2_of_4/test.log
      /home/builder/.cache/bazel/_bazel_builder/9dc2dbd69dc3512cedb530e1521082e7/execroot/org_tensorflow/bazel-out/aarch64-opt/testlogs/tensorflow/tools/docs/tf_doctest/shard_2_of_4/test_attempts/attempt_1.log
      /home/builder/.cache/bazel/_bazel_builder/9dc2dbd69dc3512cedb530e1521082e7/execroot/org_tensorflow/bazel-out/aarch64-opt/testlogs/tensorflow/tools/docs/tf_doctest/shard_2_of_4/test_attempts/attempt_2.log
      /home/builder/.cache/bazel/_bazel_builder/9dc2dbd69dc3512cedb530e1521082e7/execroot/org_tensorflow/bazel-out/aarch64-opt/testlogs/tensorflow/tools/docs/tf_doctest/shard_3_of_4/test.log
      /home/builder/.cache/bazel/_bazel_builder/9dc2dbd69dc3512cedb530e1521082e7/execroot/org_tensorflow/bazel-out/aarch64-opt/testlogs/tensorflow/tools/docs/tf_doctest/shard_3_of_4/test_attempts/attempt_1.log
      /home/builder/.cache/bazel/_bazel_builder/9dc2dbd69dc3512cedb530e1521082e7/execroot/org_tensorflow/bazel-out/aarch64-opt/testlogs/tensorflow/tools/docs/tf_doctest/shard_3_of_4/test_attempts/attempt_2.log
      /home/builder/.cache/bazel/_bazel_builder/9dc2dbd69dc3512cedb530e1521082e7/execroot/org_tensorflow/bazel-out/aarch64-opt/testlogs/tensorflow/tools/docs/tf_doctest/shard_4_of_4/test.log
      /home/builder/.cache/bazel/_bazel_builder/9dc2dbd69dc3512cedb530e1521082e7/execroot/org_tensorflow/bazel-out/aarch64-opt/testlogs/tensorflow/tools/docs/tf_doctest/shard_4_of_4/test_attempts/attempt_1.log
      /home/builder/.cache/bazel/_bazel_builder/9dc2dbd69dc3512cedb530e1521082e7/execroot/org_tensorflow/bazel-out/aarch64-opt/testlogs/tensorflow/tools/docs/tf_doctest/shard_4_of_4/test_attempts/attempt_2.log
      /home/builder/.cache/bazel/_bazel_builder/9dc2dbd69dc3512cedb530e1521082e7/execroot/org_tensorflow/bazel-out/aarch64-opt/testlogs/tensorflow/tools/docs/tf_doctest/shard_1_of_4/test.log
      /home/builder/.cache/bazel/_bazel_builder/9dc2dbd69dc3512cedb530e1521082e7/execroot/org_tensorflow/bazel-out/aarch64-opt/testlogs/tensorflow/tools/docs/tf_doctest/shard_1_of_4/test_attempts/attempt_1.log
      /home/builder/.cache/bazel/_bazel_builder/9dc2dbd69dc3512cedb530e1521082e7/execroot/org_tensorflow/bazel-out/aarch64-opt/testlogs/tensorflow/tools/docs/tf_doctest/shard_1_of_4/test_attempts/attempt_2.log
INFO: From Testing //tensorflow/tools/docs:tf_doctest (shard 1 of 4):
==================== Test output for //tensorflow/tools/docs:tf_doctest (shard 1 of 4):
2022-05-03 14:24:00.195904: E tensorflow/core/common_runtime/session_factory.cc:48] Two session factories are being registered underGRPC_SESSION
[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/descriptor_database.cc:118] File already exists in database: tensorflow/python/framework/cpp_shape_inference.proto
[libprotobuf FATAL external/com_google_protobuf/src/google/protobuf/descriptor.cc:1379] CHECK failed: GeneratedDatabase()->Add(encoded_file_descriptor, size): 
terminate called after throwing an instance of 'google::protobuf::FatalException'
  what():  CHECK failed: GeneratedDatabase()->Add(encoded_file_descriptor, size): 
================================================================================
==================== Test output for //tensorflow/tools/docs:tf_doctest (shard 1 of 4):
2022-05-03 14:24:04.586980: E tensorflow/core/common_runtime/session_factory.cc:48] Two session factories are being registered underGRPC_SESSION
[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/descriptor_database.cc:118] File already exists in database: tensorflow/python/framework/cpp_shape_inference.proto
[libprotobuf FATAL external/com_google_protobuf/src/google/protobuf/descriptor.cc:1379] CHECK failed: GeneratedDatabase()->Add(encoded_file_descriptor, size): 
terminate called after throwing an instance of 'google::protobuf::FatalException'
  what():  CHECK failed: GeneratedDatabase()->Add(encoded_file_descriptor, size): 
================================================================================
==================== Test output for //tensorflow/tools/docs:tf_doctest (shard 1 of 4):
2022-05-03 14:24:08.950464: E tensorflow/core/common_runtime/session_factory.cc:48] Two session factories are being registered underGRPC_SESSION
[libprotobuf ERROR external/com_google_protobuf/src/google/protobuf/descriptor_database.cc:118] File already exists in database: tensorflow/python/framework/cpp_shape_inference.proto
[libprotobuf FATAL external/com_google_protobuf/src/google/protobuf/descriptor.cc:1379] CHECK failed: GeneratedDatabase()->Add(encoded_file_descriptor, size): 
terminate called after throwing an instance of 'google::protobuf::FatalException'
  what():  CHECK failed: GeneratedDatabase()->Add(encoded_file_descriptor, size): 
================================================================================
Target //tensorflow/tools/docs:tf_doctest up-to-date:
  bazel-bin/tensorflow/tools/docs/tf_doctest
INFO: Elapsed time: 469.600s, Critical Path: 344.39s
INFO: 968 processes: 141 internal, 827 local.
INFO: Build completed, 1 test FAILED, 968 total actions
//tensorflow/tools/docs:tf_doctest                                       FAILED in 12 out of 12 in 9.4s
  Stats over 12 runs: max = 9.4s, min = 4.1s, avg = 6.0s, dev = 2.4s
  /home/builder/.cache/bazel/_bazel_builder/9dc2dbd69dc3512cedb530e1521082e7/execroot/org_tensorflow/bazel-out/aarch64-opt/testlogs/tensorflow/tools/docs/tf_doctest/shard_2_of_4/test.log
  /home/builder/.cache/bazel/_bazel_builder/9dc2dbd69dc3512cedb530e1521082e7/execroot/org_tensorflow/bazel-out/aarch64-opt/testlogs/tensorflow/tools/docs/tf_doctest/shard_2_of_4/test_attempts/attempt_1.log
  /home/builder/.cache/bazel/_bazel_builder/9dc2dbd69dc3512cedb530e1521082e7/execroot/org_tensorflow/bazel-out/aarch64-opt/testlogs/tensorflow/tools/docs/tf_doctest/shard_2_of_4/test_attempts/attempt_2.log
  /home/builder/.cache/bazel/_bazel_builder/9dc2dbd69dc3512cedb530e1521082e7/execroot/org_tensorflow/bazel-out/aarch64-opt/testlogs/tensorflow/tools/docs/tf_doctest/shard_3_of_4/test.log
  /home/builder/.cache/bazel/_bazel_builder/9dc2dbd69dc3512cedb530e1521082e7/execroot/org_tensorflow/bazel-out/aarch64-opt/testlogs/tensorflow/tools/docs/tf_doctest/shard_3_of_4/test_attempts/attempt_1.log
  /home/builder/.cache/bazel/_bazel_builder/9dc2dbd69dc3512cedb530e1521082e7/execroot/org_tensorflow/bazel-out/aarch64-opt/testlogs/tensorflow/tools/docs/tf_doctest/shard_3_of_4/test_attempts/attempt_2.log
  /home/builder/.cache/bazel/_bazel_builder/9dc2dbd69dc3512cedb530e1521082e7/execroot/org_tensorflow/bazel-out/aarch64-opt/testlogs/tensorflow/tools/docs/tf_doctest/shard_4_of_4/test.log
  /home/builder/.cache/bazel/_bazel_builder/9dc2dbd69dc3512cedb530e1521082e7/execroot/org_tensorflow/bazel-out/aarch64-opt/testlogs/tensorflow/tools/docs/tf_doctest/shard_4_of_4/test_attempts/attempt_1.log
  /home/builder/.cache/bazel/_bazel_builder/9dc2dbd69dc3512cedb530e1521082e7/execroot/org_tensorflow/bazel-out/aarch64-opt/testlogs/tensorflow/tools/docs/tf_doctest/shard_4_of_4/test_attempts/attempt_2.log
  /home/builder/.cache/bazel/_bazel_builder/9dc2dbd69dc3512cedb530e1521082e7/execroot/org_tensorflow/bazel-out/aarch64-opt/testlogs/tensorflow/tools/docs/tf_doctest/shard_1_of_4/test.log
  /home/builder/.cache/bazel/_bazel_builder/9dc2dbd69dc3512cedb530e1521082e7/execroot/org_tensorflow/bazel-out/aarch64-opt/testlogs/tensorflow/tools/docs/tf_doctest/shard_1_of_4/test_attempts/attempt_1.log
  /home/builder/.cache/bazel/_bazel_builder/9dc2dbd69dc3512cedb530e1521082e7/execroot/org_tensorflow/bazel-out/aarch64-opt/testlogs/tensorflow/tools/docs/tf_doctest/shard_1_of_4/test_attempts/attempt_2.log

INFO: Build completed, 1 test FAILED, 968 total actions
```
</details>"
55840,The `tf.linalg.svd` bug report!  Serious!,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

tf 2.5 AND tf 2.8

### Custom Code

Yes

### OS Platform and Distribution

Linux Ubuntu 20.04 AND Windows 10

### Mobile device

_No response_

### Python version

3.9

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

A bug happened!
I make a example net that contains a simple `keras.Sequence` of a `Conv3D` keras layer, a `tf.linalg.svd` operation that consists of a trainable parameter `thres` and another `Conv3D` keras layer. 
When I calculate the gradients of the `Conv3D` layers, the `tf2.5` returns `nan` for the first `Conv3D` layer while the `tf2.8` seems to be normal but sometimes `tf2.8` reports error: `Segmentation Fault (core dumped)`, which I think may due to the `tf.linalg.svd`. please check it. 

run the Standalone code to reproduce the issue, and we choose a very simple input (tf.ones) and the bug can be reproduced too. 

We test it on Nvidia GV100 GPU and on `tf2.5` and `tf2.8`.



### Standalone code to reproduce the issue

```shell
import tensorflow as tf
import numpy as np

class CONV_OP(tf.keras.layers.Layer):
    def __init__(self, n_f=32, ifactivate=False):
        super(CONV_OP, self).__init__()
        self.mylayers = []
        self.mylayers.append(tf.keras.layers.Conv3D(n_f, 3, strides=1, padding='same', use_bias=False))
        if ifactivate == True:
            self.mylayers.append(tf.keras.layers.ReLU())
        self.seq = tf.keras.Sequential(self.mylayers)

    def call(self, input):
        res = self.seq(input)
        return res


class exam_net(tf.keras.Model):
    def __init__(self):
        super(exam_net, self).__init__(name='exam_net')
        self.conv = CONV_OP(n_f=2, ifactivate=False)
        self.conv_t = CONV_OP(n_f=2, ifactivate=False)
        self.thres_coef = tf.Variable(tf.constant(-2, dtype=tf.float32), trainable=True, name='thres_coef')

    def call(self, x_in):
        [batch, Nt, Nx, Ny] = x_in.get_shape()

        x_in = tf.stack([tf.math.real(x_in), tf.math.imag(x_in)], axis=-1)
        x = self.conv(x_in)

        x_c = tf.complex(x[:, :, :, :, 0], x[:, :, :, :, 1])

        St, Ut, Vt = tf.linalg.svd(x_c, compute_uv=True, full_matrices=True)
        thres = tf.sigmoid(self.thres_coef) * St[..., 0]
        thres = tf.expand_dims(thres, -1)
        St = tf.nn.relu(St - thres)
        St = tf.linalg.diag(St)

        St = tf.dtypes.cast(St, tf.complex64)
        Vt_conj = tf.transpose(Vt, perm=[0, 1, 3, 2])
        Vt_conj = tf.math.conj(Vt_conj)
        US = tf.linalg.matmul(Ut, St)
        x_soft = tf.linalg.matmul(US, Vt_conj)
        
        print(np.isnan(St.numpy()).any())
        print(np.isnan(Ut.numpy()).any())
        print(np.isnan(Vt.numpy()).any())

        x_soft = tf.stack([tf.math.real(x_soft), tf.math.imag(x_soft)], axis=-1)
        x_out = self.conv_t(x_soft)

        output = x_out + x_in
        output = tf.complex(output[:, :, :, :, 0], output[:, :, :, :, 1])

        return output

 

if __name__ == '__main__':
    with tf.GradientTape() as g:
        # x_in  = tf.constant(np.load('1.npy'))
        x_in  = tf.ones([1, 5, 5, 5], dtype=tf.complex64)
        g.watch(x_in)

        net = exam_net()
        x_out = net(x_in)

        grad = g.gradient(x_out, [x_in, net.trainable_variables])
        print(grad[1][0])
```
```


### Relevant log output

_No response_</details>"
55835,Exporting LSTM with TFlite Converter yields model which makes bad predictions in contrast to keras model,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

tf 2.8

### Custom Code

No

### OS Platform and Distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
I want to export the model presented in this (https://keras.io/examples/vision/captcha_ocr/) keras tutorial in the tflite format. I found two ways to export the model:

1. Setting the flag tf.lite.OpsSet.SELECT_TF_OPS
2. Using the function get_concrete_function

Option 1 works in terms of correct predictions, but I would like to refrain from using the flag. With option 2 the export works but the predictions of the exported model are bad.
```


### Standalone code to reproduce the issue

```shell
You can go through the keras notebook and add the following code for the two options.

Code for option 1:

model = prediction_model

converter = tf.lite.TFLiteConverter.from_keras_model(model)
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]
tflite_model = converter.convert()

with open('model.tflite', 'wb') as f:
    f.write(tflite_model)

----------------------------------------------------------------

Code for option 2:

model = prediction_model

run_model = tf.function(lambda x: model(x))
concrete_func = run_model.get_concrete_function(tf.TensorSpec([1] + model.inputs[0].shape[1:], model.inputs[0].dtype))

# model directory.
MODEL_DIR = ""keras_lstm""
model.save(MODEL_DIR, save_format=""tf"", signatures=concrete_func)

converter = tf.lite.TFLiteConverter.from_saved_model(MODEL_DIR)
tflite_model = converter.convert()

with open('flag_diopter_model.tflite', 'wb') as f:
    f.write(tflite_model)
```


### Relevant log output

_No response_</details>"
55829,AttributeError: module 'typing' has no attribute '_SpecialForm',"### System information

-   **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 18.04
-   **Python version**: 3.6
-   **Bazel version (if compiling from source)**: 5.1.1
-   **GCC/Compiler version (if compiling from source)**: 7.5.0

### Describe the problem
Observed an issue when building TensorFlow master from source. 
bazel --host_jvm_args=""-Xms1024m"" --host_jvm_args=""-Xmx2048m"" build  --define=tensorflow_mkldnn_contraction_kernel=0 --define tflite_with_xnnpack=false //tensorflow/tools/pip_package:build_pip_package

```
INFO: Analyzed target //tensorflow/tools/pip_package:build_pip_package (1 packages loaded, 3 targets configured).
INFO: Found 1 target...
ERROR: /root/tensorflow/tensorflow/BUILD:1352:19: Executing genrule //tensorflow:tf_python_api_gen_v2 failed: (Exit 1): bash failed: error executing command /bin/bash -c ... (remaining 1 argument skipped)
Traceback (most recent call last):
  File ""/root/.cache/bazel/_bazel_root/efb88f6336d9c4a18216fb94287b8d97/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/create_tensorflow.python_api_tf_python_api_gen_v2.runfiles/org_tensorflow/tensorflow/python/tools/api/generator/create_python_api.py"", line 22, in <module>
    from tensorflow.python.tools.api.generator import doc_srcs
  File ""/root/.cache/bazel/_bazel_root/efb88f6336d9c4a18216fb94287b8d97/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/create_tensorflow.python_api_tf_python_api_gen_v2.runfiles/org_tensorflow/tensorflow/python/__init__.py"", line 42, in <module>
    from tensorflow.python import data
  File ""/root/.cache/bazel/_bazel_root/efb88f6336d9c4a18216fb94287b8d97/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/create_tensorflow.python_api_tf_python_api_gen_v2.runfiles/org_tensorflow/tensorflow/python/data/__init__.py"", line 21, in <module>
    from tensorflow.python.data import experimental
  File ""/root/.cache/bazel/_bazel_root/efb88f6336d9c4a18216fb94287b8d97/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/create_tensorflow.python_api_tf_python_api_gen_v2.runfiles/org_tensorflow/tensorflow/python/data/experimental/__init__.py"", line 95, in <module>
    from tensorflow.python.data.experimental import service
  File ""/root/.cache/bazel/_bazel_root/efb88f6336d9c4a18216fb94287b8d97/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/create_tensorflow.python_api_tf_python_api_gen_v2.runfiles/org_tensorflow/tensorflow/python/data/experimental/service/__init__.py"", line 387, in <module>
    from tensorflow.python.data.experimental.ops.data_service_ops import distribute
  File ""/root/.cache/bazel/_bazel_root/efb88f6336d9c4a18216fb94287b8d97/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/create_tensorflow.python_api_tf_python_api_gen_v2.runfiles/org_tensorflow/tensorflow/python/data/experimental/ops/data_service_ops.py"", line 22, in <module>
    from tensorflow.python.data.experimental.ops import compression_ops
  File ""/root/.cache/bazel/_bazel_root/efb88f6336d9c4a18216fb94287b8d97/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/create_tensorflow.python_api_tf_python_api_gen_v2.runfiles/org_tensorflow/tensorflow/python/data/experimental/ops/compression_ops.py"", line 16, in <module>
    from tensorflow.python.data.util import structure
  File ""/root/.cache/bazel/_bazel_root/efb88f6336d9c4a18216fb94287b8d97/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/create_tensorflow.python_api_tf_python_api_gen_v2.runfiles/org_tensorflow/tensorflow/python/data/util/structure.py"", line 22, in <module>
    from tensorflow.python.data.util import nest
  File ""/root/.cache/bazel/_bazel_root/efb88f6336d9c4a18216fb94287b8d97/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/create_tensorflow.python_api_tf_python_api_gen_v2.runfiles/org_tensorflow/tensorflow/python/data/util/nest.py"", line 36, in <module>
    from tensorflow.python.framework import sparse_tensor as _sparse_tensor
  File ""/root/.cache/bazel/_bazel_root/efb88f6336d9c4a18216fb94287b8d97/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/create_tensorflow.python_api_tf_python_api_gen_v2.runfiles/org_tensorflow/tensorflow/python/framework/sparse_tensor.py"", line 24, in <module>
    from tensorflow.python.framework import constant_op
  File ""/root/.cache/bazel/_bazel_root/efb88f6336d9c4a18216fb94287b8d97/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/create_tensorflow.python_api_tf_python_api_gen_v2.runfiles/org_tensorflow/tensorflow/python/framework/constant_op.py"", line 25, in <module>
    from tensorflow.python.eager import execute
  File ""/root/.cache/bazel/_bazel_root/efb88f6336d9c4a18216fb94287b8d97/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/create_tensorflow.python_api_tf_python_api_gen_v2.runfiles/org_tensorflow/tensorflow/python/eager/execute.py"", line 24, in <module>
    from tensorflow.python.framework import ops
  File ""/root/.cache/bazel/_bazel_root/efb88f6336d9c4a18216fb94287b8d97/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/create_tensorflow.python_api_tf_python_api_gen_v2.runfiles/org_tensorflow/tensorflow/python/framework/ops.py"", line 55, in <module>
    from tensorflow.python.framework import indexed_slices
  File ""/root/.cache/bazel/_bazel_root/efb88f6336d9c4a18216fb94287b8d97/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/create_tensorflow.python_api_tf_python_api_gen_v2.runfiles/org_tensorflow/tensorflow/python/framework/indexed_slices.py"", line 28, in <module>
    from tensorflow.python.framework import tensor_shape
  File ""/root/.cache/bazel/_bazel_root/efb88f6336d9c4a18216fb94287b8d97/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/create_tensorflow.python_api_tf_python_api_gen_v2.runfiles/org_tensorflow/tensorflow/python/framework/tensor_shape.py"", line 26, in <module>
    from tensorflow.python.types import trace
  File ""/root/.cache/bazel/_bazel_root/efb88f6336d9c4a18216fb94287b8d97/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/create_tensorflow.python_api_tf_python_api_gen_v2.runfiles/org_tensorflow/tensorflow/python/types/trace.py"", line 30, in <module>
    from typing_extensions import Protocol
  File ""/root/.cache/bazel/_bazel_root/efb88f6336d9c4a18216fb94287b8d97/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/create_tensorflow.python_api_tf_python_api_gen_v2.runfiles/typing_extensions_archive/typing_extensions.py"", line 159, in <module>
    class _FinalForm(typing._SpecialForm, _root=True):
AttributeError: module 'typing' has no attribute '_SpecialForm'
Target //tensorflow/tools/pip_package:build_pip_package failed to build
Use --verbose_failures to see the command lines of failed build steps.
ERROR: /root/tensorflow/tensorflow/lite/python/BUILD:68:10 Middleman _middlemen/tensorflow_Slite_Spython_Stflite_Uconvert-runfiles failed: (Exit 1): bash failed: error executing command /bin/bash -c ... (remaining 1 argument skipped)

```"
55827,TF Windows CI test TIMEOUT error (intermittent) //py_test_dir/tensorflow/python/kernel_tests/nn_ops:xent_op_d9m_test_cpu TIMEOUT,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Build/Install

### Source

source

### Tensorflow Version

tf 2.9

### Custom Code

No

### OS Platform and Distribution

Windows Server 2019 32-core

### Mobile device

_No response_

### Python version

3.10

### Bazel version

5.2.0

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
Trying to build+unittest from TF master branch, and we see this TIMEOUT error occasionally during bazel test phase. In come runs it does pass. How can we handle this behavior?
The build was made within a clean Py-3.10 virtual-env, with ONLY these pip modules:
python -m pip install absl-py astunparse flatbuffers google_pasta h5py keras-nightly keras_preprocessing numpy opt_einsum protobuf scipy six termcolor typing_extensions wheel wrapt gast tensorboard tf-estimator-nightly packaging portpicker
```


### Standalone code to reproduce the issue

```shell
CI script is invoked in following dir C:/.../tensorflow/ using Windows command prompt:
bash C:/Jenkins/workspace/tf-test-win2/tensorflow/tensorflow/tools/ci_build/windows/cpu/pip/build_tf_windows.sh --extra_build_flags '--action_env=TEMP=C:/Jenkins/workspace/tf-test-win2/tmp --action_env=TMP=C:/Jenkins/workspace/tf-test-win2/tmp' --extra_test_flags '--action_env=TEMP=C:/Jenkins/workspace/tf-test-win2/tmp --action_env=TMP=C:/Jenkins/workspace/tf-test-win2/tmp'

This internally calls =>
bazel test --announce_rc --config=opt -k --test_output=errors --experimental_cc_shared_library --action_env=TEMP=C:/Jenkins/workspace/tf-test-win2/tmp --action_env=TMP=C:/Jenkins/workspace/tf-test-win2/tmp --define=no_tensorflow_py_deps=true --test_lang_filters=py --test_tag_filters=-no_pip,-no_windows,-no_oss,-gpu,-tpu,-v1only --build_tag_filters=-no_pip,-no_windows,-no_oss,-gpu,-tpu --build_tests_only --test_size_filters=small,medium --jobs=32 --test_timeout=300,450,1200,3600 --flaky_test_attempts=3 '--output_filter=^$' -- //py_test_dir/tensorflow/python/...
```


### Relevant log output

```shell
Error: //py_test_dir/tensorflow/python/kernel_tests/nn_ops:xent_op_d9m_test_cpu TIMEOUT
See:
Overall Build Status https://tensorflow-ci.intel.com/job/tf-test-win2/170/
Console Log https://tensorflow-ci.intel.com/job/tf-test-win2/170/console
Test Failure Summary https://tensorflow-ci.intel.com/job/tf-test-win2/170/artifact/test_failures.log
```
</details>"
55825,unable to pickle keras.layers.StringLookup,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

2.8

### Custom Code

No

### OS Platform and Distribution

colab

### Mobile device

_No response_

### Python version

3.7

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
trying to pickle a StringLookup layer causes an exception
tried in colab python 3.7 and local macos python 3.8
```


### Standalone code to reproduce the issue

```shell
import tensorflow
import pickle
print(tensorflow.__version__)
pickle.dumps(tensorflow.keras.layers.StringLookup())
```


### Relevant log output

```shell
---------------------------------------------------------------------------
InvalidArgumentError                      Traceback (most recent call last)
<ipython-input-2-caa8edb2bfc5> in <module>()
      2 import pickle
      3 print(tensorflow.__version__)
----> 4 pickle.dumps(tensorflow.keras.layers.StringLookup())

1 frames
/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py in _numpy(self)
   1189       return self._numpy_internal()
   1190     except core._NotOkStatusException as e:  # pylint: disable=protected-access
-> 1191       raise core._status_to_exception(e) from None  # pylint: disable=protected-access
   1192 
   1193   @property

InvalidArgumentError: Cannot convert a Tensor of dtype resource to a NumPy array.
```
</details>"
55824,tf.keras.optimizers.experimental.AdamW only support constant weight_decay,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Feature Request

### Source

source

### Tensorflow Version

2.8

### Custom Code

No

### OS Platform and Distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
tf.keras.optimizers.experimental.AdamW only supports constant weight decay. But usually we want the weight_decay value to decay with learning rate schedule.
```


### Standalone code to reproduce the issue

```shell
The legacy tfa.optimizers.AdamW supports callable weight_decay, which is much better.
```


### Relevant log output

_No response_</details>"
55823,`Square` and `Sqrt` ops do not support complex values on GPU,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Feature Request

### Source

binary

### Tensorflow Version

tf 2.8

### Custom Code

Yes

### OS Platform and Distribution

Colab

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

Attempting to train a complex64 variable using RMSprop throws a `Cannot assign a device for operation...` error (see full output below).

It seems the issue may be that the `Sqrt` and `Square` ops used during the variable update do not have GPU implementations for complex dtypes. Will these be supported?

Other optimizers (SGD, Adam) work fine as they do not require those ops. It's also possible to work around this by splitting the complex64 variable into two float32 variables representing real and imaginary parts, but this can get surprisingly messy in some circumstances.


### Standalone code to reproduce the issue

Colab: https://colab.research.google.com/drive/1wV3_UoLfGN6pTauD5ttoA5RHZUm9OCPe?usp=sharing

or see below:

```shell
import tensorflow as tf

class BasicLayer(tf.keras.layers.Layer):
  def build(self, input_shape):
    self.w = self.add_weight(name='w', shape=(3,),
                             initializer=tf.keras.initializers.Zeros())

  def call(self, inputs):
    return inputs * self.w

# Input/output data.
x = tf.constant([[1. + 2.j, 2. + 3.j, 3. + 4.j]])
y = x

# Create and compile model caling this layer.
input = tf.keras.Input(shape=(3,), dtype='complex64')
layer = BasicLayer(dtype='complex64')
model = tf.keras.Model(input, layer(input))
model.compile('rmsprop', 'mse')
model.train_on_batch(x, y)
```

### Relevant log output

```shell
InvalidArgumentError: Cannot assign a device for operation model_2/basic_layer_2/mul/ReadVariableOp: Could not satisfy explicit device specification '' because the node {{colocation_node model_2/basic_layer_2/mul/ReadVariableOp}} was colocated with a group of nodes that required incompatible device '/job:localhost/replica:0/task:0/device:GPU:0'. All available devices [/job:localhost/replica:0/task:0/device:CPU:0, /job:localhost/replica:0/task:0/device:GPU:0]. 
Colocation Debug Info:
Colocation group had the following types and supported devices: 
Root Member(assigned_device_name_index_=2 requested_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' resource_device_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported_device_types_=[CPU] possible_devices_=[]
RealDiv: GPU CPU 
AssignVariableOp: GPU CPU 
Sub: GPU CPU 
ReadVariableOp: GPU CPU 
_Arg: GPU CPU 
Sqrt: CPU 
Mul: GPU CPU 
Square: CPU 
AddV2: GPU CPU 

Colocation members, user-requested devices, and framework assigned devices, if any:
  model_2_basic_layer_2_mul_readvariableop_resource (_Arg)  framework assigned device=/job:localhost/replica:0/task:0/device:GPU:0
  rmsprop_rmsprop_update_mul_readvariableop_resource (_Arg)  framework assigned device=/job:localhost/replica:0/task:0/device:GPU:0
  model_2/basic_layer_2/mul/ReadVariableOp (ReadVariableOp) 
  RMSprop/RMSprop/update/mul/ReadVariableOp (ReadVariableOp) 
  RMSprop/RMSprop/update/mul (Mul) /job:localhost/replica:0/task:0/device:GPU:0
  RMSprop/RMSprop/update/Square (Square) /job:localhost/replica:0/task:0/device:GPU:0
  RMSprop/RMSprop/update/mul_1 (Mul) /job:localhost/replica:0/task:0/device:GPU:0
  RMSprop/RMSprop/update/add (AddV2) /job:localhost/replica:0/task:0/device:GPU:0
  RMSprop/RMSprop/update/AssignVariableOp (AssignVariableOp) /job:localhost/replica:0/task:0/device:GPU:0
  RMSprop/RMSprop/update/mul_2 (Mul) /job:localhost/replica:0/task:0/device:GPU:0
  RMSprop/RMSprop/update/Sqrt/ReadVariableOp (ReadVariableOp) /job:localhost/replica:0/task:0/device:GPU:0
  RMSprop/RMSprop/update/Sqrt (Sqrt) /job:localhost/replica:0/task:0/device:GPU:0
  RMSprop/RMSprop/update/add_1 (AddV2) /job:localhost/replica:0/task:0/device:GPU:0
  RMSprop/RMSprop/update/truediv (RealDiv) /job:localhost/replica:0/task:0/device:GPU:0
  RMSprop/RMSprop/update/ReadVariableOp (ReadVariableOp) 
  RMSprop/RMSprop/update/sub (Sub) /job:localhost/replica:0/task:0/device:GPU:0
  RMSprop/RMSprop/update/AssignVariableOp_1 (AssignVariableOp) /job:localhost/replica:0/task:0/device:GPU:0

	 [[{{node model_2/basic_layer_2/mul/ReadVariableOp}}]] [Op:__inference_train_function_1102]
```
</details>"
55821,"line 606, in compute_output_shape     raise NotImplementedError NotImplementedError","<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

1.15

### Custom Code

Yes

### OS Platform and Distribution

win11

### Mobile device

no

### Python version

3.6

### Bazel version

no

### GCC/Compiler version

no

### CUDA/cuDNN version

11.3-8.2.1

### GPU model and memory

8G

### Current Behaviour?

```shell
I use Keras to build the model, but there are always errors. How should I solve this problem？
Attach the code, you can directly execute, you can see the error.
```


### Standalone code to reproduce the issue

```shell
# from tensorflow import math
import tensorflow as tf
import keras
# from tensorflow.keras import Model
from keras import Model, Input
from keras.layers import (Concatenate, Lambda, UpSampling2D, MaxPool2D,
                          ZeroPadding2D, Conv2D, BatchNormalization)
from keras.activations import selu as SeLU
from keras.activations import sigmoid as Sigmoid


# from utils.utils import compose


# def gelu_(X):
#     return 0.5 * X * (1.0 + math.tanh(0.7978845608028654 * (X + 0.044715 * math.pow(X, 3))))
#
#
# def snake_(X, beta):
#     return X + (1 / beta) * math.square(math.sin(beta * X))
#
#
# class GELU(Model):
#     '''
#     Gaussian Error Linear Unit (GELU), an alternative of ReLU
#
#     Y = GELU()(X)
#
#     ----------
#     Hendrycks, D. and Gimpel, K., 2016. Gaussian error linear units (gelus). arXiv preprint arXiv:1606.08415.
#
#     Usage: use it as a tf.keras.Model
#
#
#     '''
#
#     def __init__(self, trainable=False, **kwargs):
#         super(GELU, self).__init__(**kwargs)
#         self.supports_masking = True
#         self.trainable = trainable
#
#     def build(self, input_shape):
#         super(GELU, self).build(input_shape)
#
#     def call(self, inputs, mask=None):
#         return gelu_(inputs)
#
#     def get_config(self):
#         config = {'trainable': self.trainable}
#         base_config = super(GELU, self).get_config()
#         return dict(list(base_config.items()) + list(config.items()))
#
#     def compute_output_shape(self, input_shape):
#         return input_shape


class up_conv(Model):
    """"""
    Up Convolution Block
    """"""

    def __init__(self, out_ch):
        super(up_conv, self).__init__()
        self.up = keras.Sequential()
        self.up.add(UpSampling2D(size=(2, 2)))
        self.up.add(Conv2D(out_ch, kernel_size=3, strides=1, padding='same', use_bias=True))
        self.up.add(BatchNormalization(momentum=0.97))

    def call(self, x, **kwargs):
        x = self.up(x)
        x = SeLU(x)
        return x


class Recurrent_block(Model):
    """"""
    Recurrent Block for R2Unet_CNN
    """"""

    def __init__(self, out_ch, t=2):
        super(Recurrent_block, self).__init__()

        self.t = t
        self.out_ch = out_ch
        self.conv = keras.Sequential()
        self.conv.add(Conv2D(out_ch, kernel_size=3, strides=1, padding='same', use_bias=True))
        self.conv.add(BatchNormalization(momentum=0.97))

    def call(self, x, **kwargs):
        for i in range(self.t):
            if i == 0:
                x = self.conv(x)
            out = self.conv(x + x)
            out = SeLU(out)
        return out


class Attention_block(Model):
    """"""
    Attention Block
    """"""

    def __init__(self, F_int):
        super(Attention_block, self).__init__()

        self.W_g = keras.Sequential()
        self.W_g.add(Conv2D(F_int, kernel_size=1, strides=1, padding=""same"", use_bias=True)),
        self.W_g.add(BatchNormalization(momentum=0.97))

        self.W_x = keras.Sequential()
        self.W_x.add(Conv2D(F_int, kernel_size=1, strides=1, padding=""same"", use_bias=True))
        self.W_x.add(BatchNormalization(momentum=0.97))

        self.psi = keras.Sequential()
        self.psi.add(Conv2D(1, kernel_size=1, strides=1, padding=""same"", use_bias=True)),
        self.psi.add(BatchNormalization(momentum=0.97))

    def call(self, inputs, **kwargs):
        g, x = inputs
        g1 = self.W_g(g)
        x1 = self.W_x(x)
        psi = SeLU(g1 + x1)
        psi = self.psi(psi)
        psi = Sigmoid(psi)
        out = x * psi
        return out


class RRCNN_block(Model):
    """"""
    Recurrent Residual Convolutional Neural Network Block
    """"""

    def __init__(self, out_ch, t=2):
        super(RRCNN_block, self).__init__()

        self.Conv = Conv2D(out_ch, kernel_size=1, strides=1, padding=""same"")
        # self.RCNN = compose(
        #     Recurrent_block(out_ch, t=t),
        #     Recurrent_block(out_ch, t=t)
        # )
        self.RCNN1 = Recurrent_block(out_ch, t=t)
        self.RCNN2 = Recurrent_block(out_ch, t=t)

    def call(self, x, **kwargs):
        x1 = self.Conv(x)
        # x2 = self.RCNN(x1)
        x2 = self.RCNN1(x1)
        x2 = self.RCNN2(x2)
        out = x1 + x2
        return out


class R2AttU_Net(Model):
    """"""
    Residual Recuurent Block with attention Unet
    Implementation : https://github.com/LeeJunHyun/Image_Segmentation
    """"""

    def __init__(self, out_ch=1, t=2):
        super(R2AttU_Net, self).__init__()

        n1 = 64
        filters = [n1, n1 * 2, n1 * 4, n1 * 8, n1 * 16]

        self.Maxpool1 = MaxPool2D(pool_size=(2, 2), strides=2)
        self.Maxpool2 = MaxPool2D(pool_size=(2, 2), strides=2)
        self.Maxpool3 = MaxPool2D(pool_size=(2, 2), strides=2)
        self.Maxpool4 = MaxPool2D(pool_size=(2, 2), strides=2)

        self.RRCNN1 = RRCNN_block(filters[0], t=t)
        self.RRCNN2 = RRCNN_block(filters[1], t=t)
        self.RRCNN3 = RRCNN_block(filters[2], t=t)
        self.RRCNN4 = RRCNN_block(filters[3], t=t)
        self.RRCNN5 = RRCNN_block(filters[4], t=t)

        self.Up5 = up_conv(filters[3])
        self.Att5 = Attention_block(F_int=filters[2])
        self.Up_RRCNN5 = RRCNN_block(filters[3], t=t)

        self.Up4 = up_conv(filters[2])
        self.Att4 = Attention_block(F_int=filters[1])
        self.Up_RRCNN4 = RRCNN_block(filters[2], t=t)

        self.Up3 = up_conv(filters[1])
        self.Att3 = Attention_block(F_int=filters[0])
        self.Up_RRCNN3 = RRCNN_block(filters[1], t=t)

        self.Up2 = up_conv(filters[0])
        self.Att2 = Attention_block(F_int=32)
        self.Up_RRCNN2 = RRCNN_block(filters[0], t=t)

        self.Conv = Conv2D(out_ch, kernel_size=1, strides=1, padding=""same"")

    def call(self, x, **kwargs):
        e1 = self.RRCNN1(x)

        e2 = self.Maxpool1(e1)
        e2 = self.RRCNN2(e2)

        e3 = self.Maxpool2(e2)
        e3 = self.RRCNN3(e3)

        e4 = self.Maxpool3(e3)
        e4 = self.RRCNN4(e4)

        e5 = self.Maxpool4(e4)
        e5 = self.RRCNN5(e5)

        d5 = self.Up5(e5)
        # print(""d5.shape:{}, e4.shape{}"".format(d5.shape, e4.shape))
        e4 = self.Att5([d5, e4])
        d5 = tf.concat((e4, d5), axis=-1)
        d5 = self.Up_RRCNN5(d5)

        d4 = self.Up4(d5)
        # print(""d4.shape:{}, e3.shape{}"".format(d4.shape, e3.shape))
        e3 = self.Att4([d4, e3])
        d4 = tf.concat((e3, d4), axis=-1)
        d4 = self.Up_RRCNN4(d4)

        d3 = self.Up3(d4)
        e2 = self.Att3([d3, e2])
        d3 = tf.concat((e2, d3), axis=-1)
        d3 = self.Up_RRCNN3(d3)

        d2 = self.Up2(d3)
        e1 = self.Att2([d2, e1])
        d2 = tf.concat((e1, d2), axis=-1)
        d2 = self.Up_RRCNN2(d2)

        out = self.Conv(d2)

        return out


if __name__ == '__main__':
    inputs1 = Input([512, 64, 7])
    inputs2 = Input([None, None, 1])
    # x1 = up_conv(1, 3)(inputs)
    # print(x1)
    # x2 = Attention_block(3, )(inputs1, inputs2)
    # print(x2)
    # x3 = RRCNN_block(3)(inputs1)
    # print(x3)
    deep_t = 2
    x3 = R2AttU_Net(1, deep_t)(inputs1)
    print(x3)
```


### Relevant log output

```shell
File ""D:/PyCharm/TF/CSPAttUNnetMusic_keras/nets/r2attu_net.py"", line 148, in call
    x2 = self.RCNN1(x1)
  File ""D:\Tool\Anaconda3\envs\TF\lib\site-packages\keras\engine\base_layer.py"", line 506, in __call__
    output_shape = self.compute_output_shape(input_shape)
  File ""D:\Tool\Anaconda3\envs\TF\lib\site-packages\keras\engine\network.py"", line 606, in compute_output_shape
    raise NotImplementedError
NotImplementedError

Process finished with exit code 1
```
</details>"
55819,"tflite model crashes before loading .tflite file in Google Colab, with no error or exception","I create a Visual Transformer (VIT) for image classification.

After that i create the model using Tensorflow, i obtain a .pb folder with these files inside: 
- 2 folders ""assets"" and ""variables""
- 2 files ""keras_metadata"" and ""saved_model""

I am now trying to convert this file into a "".tflite"" file but when i try to do the conversion and load the file .tfite, google colab crash and restart the run. 

I am using the version 2.6.0 of both Tensorflow and Keras.

This is my VIT:
```
# DATA
BUFFER_SIZE = 512 # Isn't taken into account
BATCH_SIZE = 256 # Number of training examples in 1 forward/backward pass. 
                 # Higher batch size, more memory space needed

# AUGMENTATION
IMAGE_SIZE = 256 
PATCH_SIZE = 32 # CHANGE HERE TO CHANGE THE NUMBER OF PATCHES 256/16=16
NUM_PATCHES = (IMAGE_SIZE // PATCH_SIZE) ** 2 # 64

# OPTIMIZER
LEARNING_RATE = 0.001
WEIGHT_DECAY = 0.0001

# TRAINING
EPOCHS = 50 # 1 epoch = 1 forward and 1 backward pass of all the training examples

# ARCHITECTURE
LAYER_NORM_EPS = 1e-6
TRANSFORMER_LAYERS = 8
PROJECTION_DIM = 32 # https://www.tensorflow.org/recommenders/examples/dcn , messo a 64 prima
NUM_HEADS = 4
TRANSFORMER_UNITS = [
    PROJECTION_DIM * 2,
    PROJECTION_DIM,
]
MLP_HEAD_UNITS = [2048, 1024]


data_augmentation = keras.Sequential(
    [
        layers.Normalization(), #if using a new version of tf
        #tf.keras.layers.experimental.preprocessing.Normalization, #if using an old version of tf
    ],
    name=""data_augmentation"",
)
# Compute the mean and the variance of the training data for normalization.
data_augmentation.layers[0].adapt(x_tr)

class ShiftedPatchTokenization(layers.Layer):
    def __init__(
      self,
      image_size=IMAGE_SIZE,
      patch_size=PATCH_SIZE,
      half_patch=PATCH_SIZE//2,
      num_patches=NUM_PATCHES,
      projection_dim=PROJECTION_DIM,
      flatten_patches=None,
      projection=None,
      layer_norm=None,
      vanilla=False,
      **kwargs,
    ):
      super(ShiftedPatchTokenization,self).__init__(**kwargs)
      self.vanilla = vanilla  # Flag to swtich to vanilla patch extractor
      self.image_size = image_size
      self.patch_size = patch_size
      self.half_patch = patch_size // 2 # la divisione con // dà il numero in int()
      self.flatten_patches = layers.Reshape((num_patches, -1))
      self.projection = layers.Dense(units=projection_dim)
      self.layer_norm = layers.LayerNormalization(epsilon=LAYER_NORM_EPS)

    # Override function to avoid error while saving model
    def get_config(self):
      config = super().get_config().copy()
      config.update(
          {
          ""image_size"": self.image_size,
          ""patch_size"": self.patch_size,
          ""half_patch"": self.half_patch,
          ""flatten_patches"": self.flatten_patches,
          ""vanilla"": self.vanilla,
          ""projection"": self.projection,
          ""layer_norm"": self.layer_norm,
          }
      )
      return config
     


    @classmethod
    def from_config(cls, config):
        return cls(**config)

    def crop_shift_pad(self, images, mode):
        # Build the diagonally shifted images
        if mode == ""left-up"":
            crop_height = self.half_patch
            crop_width = self.half_patch
            shift_height = 0
            shift_width = 0
        elif mode == ""left-down"":
            crop_height = 0
            crop_width = self.half_patch
            shift_height = self.half_patch
            shift_width = 0
        elif mode == ""right-up"":
            crop_height = self.half_patch
            crop_width = 0
            shift_height = 0
            shift_width = self.half_patch
        else:
            crop_height = 0
            crop_width = 0
            shift_height = self.half_patch
            shift_width = self.half_patch

        # Crop the shifted images and pad them
        crop = tf.image.crop_to_bounding_box(
            images,
            offset_height=crop_height,
            offset_width=crop_width,
            target_height=self.image_size - self.half_patch,
            target_width=self.image_size - self.half_patch,
        )
        shift_pad = tf.image.pad_to_bounding_box(
            crop,
            offset_height=shift_height,
            offset_width=shift_width,
            target_height=self.image_size,
            target_width=self.image_size,
        )
        return shift_pad

    def call(self, images):
        if not self.vanilla:
            # Concat the shifted images with the original image
            images = tf.concat(
                [
                    images,
                    self.crop_shift_pad(images, mode=""left-up""),
                    self.crop_shift_pad(images, mode=""left-down""),
                    self.crop_shift_pad(images, mode=""right-up""),
                    self.crop_shift_pad(images, mode=""right-down""),
                ],
                axis=-1,
            )
        # Patchify the images and flatten it
        patches = tf.image.extract_patches(
            images=images,
            sizes=[1, self.patch_size, self.patch_size, 1],
            strides=[1, self.patch_size, self.patch_size, 1],
            rates=[1, 1, 1, 1],
            padding=""VALID"",
        )
        flat_patches = self.flatten_patches(patches)
        if not self.vanilla:
            # Layer normalize the flat patches and linearly project it
            tokens = self.layer_norm(flat_patches)
            tokens = self.projection(tokens)
        else:
            # Linearly project the flat patches
            tokens = self.projection(flat_patches)
        return (tokens, patches)
```
-------------------------------------------------------------

```
# PATCH ENCODING LAYER, accepts projected patches and then adds positional information to them

class PatchEncoder(layers.Layer):
    def __init__(
        self,
        num_patches=NUM_PATCHES,
        projection_dim=PROJECTION_DIM,
        position_embedding=None,
        positions=None,
        **kwargs
    ):
        super(PatchEncoder,self).__init__(**kwargs)
        self.num_patches = num_patches
        self.position_embedding = layers.Embedding(
            input_dim=num_patches, output_dim=projection_dim
        )
        self.positions = tf.range(start=0, limit=self.num_patches, delta=1)

    def get_config(self):
      config = super().get_config().copy()
      config.update({
          ""num_patches"": self.num_patches,
          ""position_embedding"": self.position_embedding,
          ""positions"": self.positions.numpy(),
      })
      return config

    @classmethod
    def from_config(cls, config):
        return cls(**config)

    def call(self, encoded_patches):
        encoded_positions = self.position_embedding(self.positions)
        encoded_patches = encoded_patches + encoded_positions
        return encoded_patches
```
-------------------------------------------------------------

```
# LOCALITY SELF ATTENTION

# ho aggiunto elementi dove si trovano i commenti 'modificato'

class MultiHeadAttentionLSA(tf.keras.layers.MultiHeadAttention):
    def __init__(
        self,
        tau=None, #modificato, prima non c'era
        **kwargs
    ):
        super(MultiHeadAttentionLSA,self).__init__(**kwargs)
        self.tau = tf.Variable(math.sqrt(float(self._key_dim)), trainable=True) # The trainable temperature term. The initial value is the square root of the key dimension.

    def get_config(self):
      config = super().get_config().copy()
      config.update({
          ""tau"": self.tau.numpy(), #modificato, prima era solo self.tau
      })
      return config

    @classmethod
    def from_config(cls, config):
        return cls(**config)

    def _compute_attention(self, query, key, value, attention_mask=None, training=None):
        query = tf.multiply(query, 1.0 / self.tau)
        attention_scores = tf.einsum(self._dot_product_equation, key, query)
        attention_scores = self._masked_softmax(attention_scores, attention_mask) 
        attention_scores_dropout = self._dropout_layer(
            attention_scores, training=training
        )
        attention_output = tf.einsum(
            self._combine_equation, attention_scores_dropout, value
        )
        return attention_output, attention_scores
```
-------------------------------------------------------------

```

## PECRHè SI USA LA GELU piuttosto che altre?
# RISOLTO IN PARTE: si utilizza perche da risultati migliori in Computer Vision ed NLP

# Multi layer perceptron
def mlp(x, hidden_units, dropout_rate):
    for units in hidden_units:
        x = layers.Dense(units, activation=tf.nn.gelu)(x) # A Tensor with the same type as features where features are a Tensor representing preactivation values https://www.tensorflow.org/api_docs/python/tf/nn/gelu 
        # The GELU is the standard Gaussian cumulative distribution function
        x = layers.Dropout(dropout_rate)(x)
    return x


# Build the diagonal attention mask
diag_attn_mask = 1 - tf.eye(NUM_PATCHES)
diag_attn_mask = tf.cast([diag_attn_mask], dtype=tf.int8)

```
-------------------------------------------------------------

```

def create_vit_classifier(vanilla=False):
    inputs = layers.Input(shape=(256,256,3))
    # Augment data.
    augmented = data_augmentation(inputs)
    # Create patches.
    (tokens, _) = ShiftedPatchTokenization(vanilla=vanilla)(augmented)
    # Encode patches.
    encoded_patches = PatchEncoder()(tokens)

    # Create multiple layers of the Transformer block.
    for _ in range(TRANSFORMER_LAYERS):
        # Layer normalization 1.
        x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)
        # Create a multi-head attention layer.
        if not vanilla: # VANILLA TRUE
            attention_output = MultiHeadAttentionLSA(
                num_heads=NUM_HEADS, key_dim=PROJECTION_DIM, dropout=0.1
            )(x1, x1, attention_mask=diag_attn_mask)
        else: # VANILLA FALSE
            attention_output = layers.MultiHeadAttention(
                num_heads=NUM_HEADS, key_dim=PROJECTION_DIM, dropout=0.1
            )(x1, x1)

        # Skip connection 1.
        x2 = layers.Add()([attention_output, encoded_patches])
        # Layer normalization 2.
        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)
        # MLP.
        x3 = mlp(x3, hidden_units=TRANSFORMER_UNITS, dropout_rate=0.1)
        # Skip connection 2.
        encoded_patches = layers.Add()([x3, x2])

    # Create a [batch_size, projection_dim] tensor.
    representation = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)
    representation = layers.Flatten()(representation)
    representation = layers.Dropout(0.5)(representation)
    # Add MLP.
    features = mlp(representation, hidden_units=MLP_HEAD_UNITS, dropout_rate=0.5)
    # Classify outputs.
    logits = layers.Dense(len(classes))(features)
    # Create the Keras model.
    model = keras.Model(inputs=inputs, outputs=logits)
    return model
```
-------------------------------------------------------------

```

class WarmUpCosine(keras.optimizers.schedules.LearningRateSchedule):
  def __init__(
    self, learning_rate_base, total_steps, warmup_learning_rate, warmup_steps, pi=None
  ):
    super(WarmUpCosine, self).__init__()

    self.learning_rate_base = learning_rate_base
    self.total_steps = total_steps
    self.warmup_learning_rate = warmup_learning_rate
    self.warmup_steps = warmup_steps
    self.pi = tf.constant(np.pi)

  def get_config(self):
      config = super().get_config().copy()
      config.update({
          ""learning_rate_base"": self.learning_rate_base,
          ""total_steps"": self.total_steps,
          ""warmup_learning_rate"": self.warmup_learning_rate,
          ""warmup_steps"": self.warmup_steps,
          ""pi"": self.pi,
      })
      return config

  def __call__(self, step):
      if self.total_steps < self.warmup_steps:
          raise ValueError(""Total_steps must be larger or equal to warmup_steps."")

      cos_annealed_lr = tf.cos(
          self.pi
          * (tf.cast(step, tf.float32) - self.warmup_steps)
          / float(self.total_steps - self.warmup_steps)
      )
      learning_rate = 0.5 * self.learning_rate_base * (1 + cos_annealed_lr)

      if self.warmup_steps > 0:
          if self.learning_rate_base < self.warmup_learning_rate:
              raise ValueError(
                  ""Learning_rate_base must be larger or equal to ""
                  ""warmup_learning_rate.""
              )
          slope = (
              self.learning_rate_base - self.warmup_learning_rate
          ) / self.warmup_steps
          warmup_rate = slope * tf.cast(step, tf.float32) + self.warmup_learning_rate
          learning_rate = tf.where(
              step < self.warmup_steps, warmup_rate, learning_rate
          )
      return tf.where(
          step > self.total_steps, 0.0, learning_rate, name=""learning_rate""
      )


y_pred=[]
checkpoint_filepath_h5=""drive/MyDrive/Tirocinio/ViT/Model/vit_""+ num_dataset +"".h5""
checkpoint_filepath=""drive/MyDrive/Tirocinio/ViT/Model/vit_""+ num_dataset

# https://keras.io/api/models/model_training_apis/#evaluate-method
def run_experiment(model):
  total_steps = int((len(x_tr) / BATCH_SIZE) * EPOCHS)
  warmup_epoch_percentage = 0.10
  warmup_steps = int(total_steps * warmup_epoch_percentage)
  scheduled_lrs = WarmUpCosine(
      learning_rate_base=LEARNING_RATE,
      total_steps=total_steps,
      warmup_learning_rate=0.0,
      warmup_steps=warmup_steps,
  )

  optimizer = tfa.optimizers.AdamW(
      learning_rate=LEARNING_RATE, weight_decay=WEIGHT_DECAY
  )

  model.compile(
      optimizer=optimizer,
      loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),
      metrics=[
          keras.metrics.SparseCategoricalAccuracy(name=""accuracy""), # https://www.tensorflow.org/api_docs/python/tf/keras/metrics/SparseCategoricalAccuracy
          keras.metrics.SparseTopKCategoricalAccuracy(2, name=""top-2-accuracy""), #https://www.tensorflow.org/api_docs/python/tf/keras/metrics/SparseTopKCategoricalAccuracy
      ],
  )
  
  model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(
      filepath=checkpoint_filepath_h5,
      save_weights_only=False, # False=tutto il modello, True=solo i pesi
      mode='max',
      monitor='accuracy',
      verbose=0,
      save_best_only=True,
  )

  model.fit(
      x=x_tr,
      y=y_tr,
      batch_size=BATCH_SIZE,
      verbose=1,
      epochs=3,
      #callbacks = [model_checkpoint_callback],
      #save_freq=4,
      #validation_split=0.2,
  )

  # The model weights (that are considered the best) are loaded into the model.
  #model.load_weights(checkpoint_filepath_h5)
  
  y_pred_ = model.predict(x_te, batch_size=BATCH_SIZE)
  for i in range(len(y_pred_)):
    y_pred.append(y_pred_[i])
  loss_value, accuracy, top_k_accuracy = model.evaluate(x_te, y_te, batch_size=BATCH_SIZE)
  
  print(""\n\n\n"")
  print(""Y_pred is like: "" + str(y_pred[0]))
  print(""Len of Y_pred is: "" + str(len(y_pred)))
  print(f""Test accuracy --- : {round(accuracy * 100, 2)}%"") # projection_dim=64 --> acc=0.9412; projection_dim=32 --> acc=0.9533
  print(f""Test top 2 accuracy --- : {round(top_k_accuracy * 100, 2)}%"")

 
#  for i, w in enumerate(model.weights): 
#    print(i, w.name)
#    model.weights[i]._handle_name = model.weights[i].name + ""_"" + str(i)
#    print(i, w.name)
#    print()
  
#  for i in range(len(model.weights)):
#    model.weights[i]._handle_name = model.weights[i].name + ""_"" + str(i)


  # https://www.tensorflow.org/guide/keras/save_and_serialize
  #model.save(checkpoint_filepath+"".h5"", save_format=""h5"") # add .h5 or .hdf5, if not then will be PB -- ValueError: Unable to create dataset (name already exists)
  tf.keras.models.save_model(model,checkpoint_filepath) # (modello, filepath) --> Save in PB
  return model

# Run experiments with the vanilla ViT
#vit = create_vit_classifier(vanilla=True)
#history = run_experiment(vit)

# Run experiments with the Shifted Patch Tokenization and Locality Self Attention modified ViT
vit_net = create_vit_classifier(vanilla=False)
vit_model = run_experiment(vit_net)
```
-------------------------------------------------------------

Now this is ho i try to transform the model from PB to TFLITE
```
# From PB to TFLITE 

checkpoint_filepath=""drive/MyDrive/Tirocinio/ViT/Model/vit_""+ num_dataset

saved_model_dir = checkpoint_filepath
converter = tf.lite.TFLiteConverter.from_saved_model(
    saved_model_dir, signature_keys=['serving_default'])
converter.optimizations = [tf.lite.Optimize.DEFAULT]
converter.experimental_new_converter = True
converter.target_spec.supported_ops = [
    tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]
tflite_model = converter.convert()

fo = open(
    saved_model_dir +""/vit_1_model.tflite"", ""wb""
    )
fo.write(tflite_model)
fo.close
```"
55818,Tensorflow registering GPU with a lot less memory than available,"I recently installed a new GPU in my workstation - the EVGA Nvidia RTX 3080 with 12Gb. After successfully installing the corresponding drivers on my Ubuntu 18.04, as well as installing the latest CUDA and cuDNN, I opened Python in a terminal to test Tensorflow.

However, despite my GPU having exactly 12288MiB according to nvidia-smi (and only 435 Mb in usage by running processes Xorg and Gnome-Shell), tensorflow registered a device with only 9663 Mb. The exact message is:

2022-05-01 22:59:37.900290: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9663 MB 
memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:81:00.0, compute capability: 8.6

Note that while related to the closed issue **https://github.com/tensorflow/tensorflow/issues/22623**, mine cannot be explained in the same fashion because I am on Ubuntu (so the Windows issue described there does not apply) and also I do have nearly the entire 12Gb of GPU memory available per nvidia-smi - so no secondary processes are occupying the missing memory that Tensorflow is not allocating.

Details:

<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

2.8

### Custom Code

No

### OS Platform and Distribution

Linux Ubuntu 18.04

### Mobile device

_No response_

### Python version

3.8.8

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

11.6

### GPU model and memory

RTX 3080 12Gb

### Current Behaviour?

```shell
I recently installed a new GPU in my workstation - the EVGA Nvidia RTX 3080 with 12Gb. After successfully installing the corresponding drivers on my Ubuntu 18.04, as well as installing the latest CUDA and cuDNN, I opened Python in a terminal to test Tensorflow.

However, despite my GPU having exactly 12288MiB according to nvidia-smi (and only 435 Mb in usage by running processes Xorg and Gnome-Shell), tensorflow registered a device with only 9663 Mb. The exact message is:

2022-05-01 22:59:37.900290: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9663 MB 
memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:81:00.0, compute capability: 8.6

Note that while related to the closed issue **https://github.com/tensorflow/tensorflow/issues/22623**, mine cannot be explained in the same fashion because I am on Ubuntu (so the Windows issue described there does not apply) and also I do have nearly the entire 12Gb of GPU memory available per nvidia-smi - so no secondary processes are occupying the missing memory that Tensorflow is not allocating.
```


### Standalone code to reproduce the issue

```shell
Since the problem described is with the registration of GPU devices upon starting a Tensorflow code, the message appears with nearly any Tensorflow related command. For instance:

import tensorflow as tf
tf.test.gpu_device_name()
```


### Relevant log output

```shell
2022-05-01 22:59:37.900290: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9663 MB 
memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:81:00.0, compute capability: 8.6
```
</details>"
55817,Windows Build error with --cofig=mkl => ImportError: DLL load failed while importing _pywrap_tensorflow_internal,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Build/Install

### Source

source

### Tensorflow Version

tf2.9

### Custom Code

No

### OS Platform and Distribution

Windows Server 2019

### Mobile device

_No response_

### Python version

3.10

### Bazel version

5.2.0

### GCC/Compiler version

Windows VC++ 2019

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
Trying to build from TF master branch with --config=mkl flag, and we see this error.
The build was made within a clean Py-3.10 virtual-env, with ONLY these pip modules:
python -m pip install absl-py astunparse flatbuffers google_pasta h5py keras-nightly keras_preprocessing numpy opt_einsum protobuf scipy six termcolor typing_extensions wheel wrapt gast tensorboard tf-estimator-nightly packaging portpicker 

(tried with commit# 1cca89708c5b218e38cd68d341c98c2d06f3870b)

\C:\Users\mlp_admin\tmp\Bazel.runfiles_x184n_p0\runfiles\org_tensorflow\tensorflow\python\pywrap_tensorflow.py"", line 62, in <module>
    from tensorflow.python._pywrap_tensorflow_internal import *
ImportError: DLL load failed while importing _pywrap_tensorflow_internal: The specified module could not be found.
```


### Standalone code to reproduce the issue

```shell
CI script is invoked in following dir C:/.../tensorflow/ using Windows command prompt:
bash C:/Users/mlp_admin/tensorflow/tensorflow/tools/ci_build/windows/cpu/pip/build_tf_windows.sh --extra_build_flags '--action_env=TEMP=C:\Users\mlp_admin\tmp --action_env=TMP=C:\Users\mlp_admin\tmp --config=mkl' --extra_test_flags '--action_env=TEMP=C:\Users\mlp_admin\tmp --action_env=TMP=C:\Users\mlp_admin\tmp --config=mkl' --skip_test

This internally calls =>
bazel build --experimental_cc_shared_library --config=release_cpu_windows '--action_env=TEMP=C:\Users\mlp_admin\tmp' '--action_env=TMP=C:\Users\mlp_admin\tmp' --config=mkl '--output_filter=^$' tensorflow/tools/pip_package:build_pip_package
```


### Relevant log output

```shell
ERROR: C:/users/mlp_admin/tensorflow/tensorflow/BUILD:1352:19: Executing genrule //tensorflow:tf_python_api_gen_v2 failed: (Exit 1): bash.exe failed: error executing command 
  cd /d C:/users/mlp_admin/tensorflow-build/m2fy67yv/execroot/org_tensorflow
  SET PATH=C:\msys64\usr\bin;C:\msys64\bin;C:\Windows;C:\Windows\System32;C:\Windows\System32\WindowsPowerShell\v1.0;C:\Users\mlp_admin\AppData\Local\bazelisk\downloads\bazelbuild\bazel-4fd7983ca82fab536b8f9bb589610036b01d7490-windows-x86_64\bin;C:\tools\cuda\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.2\extras\CUPTI\libx64;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.2\bin;C:\C;C:\msys64\Users\mlp_admin\venv_py310\Scripts;C:\Program Files\Git\cmd;C:\C;C:\msys64\Users\mlp_admin\venv_py310;C:\tools\bazel\;C;C:\Users\mlp_admin\venv_py310\Scripts;C:\Tools\bazel;C:\Program Files\Git;C:\Program Files\Git\cmd;C:\msys64;C:\msys64\usr\bin;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem
    SET PYTHON_BIN_PATH=C:/Users/mlp_admin/venv_py310/Scripts/python.exe
    SET PYTHON_LIB_PATH=C:/Users/mlp_admin/venv_py310/Lib/site-packages
    SET RUNFILES_MANIFEST_ONLY=1
    SET TEMP=C:\Users\mlp_admin\tmp
    SET TF2_BEHAVIOR=1
    SET TMP=C:\Users\mlp_admin\tmp
  C:\msys64\usr\bin\bash.exe bazel-out/x64_windows-opt/bin/tensorflow/tf_python_api_gen_v2.genrule_script.sh
# Configuration: 92001cead5cfe54bd325acb14a4c0622c2eacc2d756dddb96cef1f45acd66008
# Execution platform: @local_execution_config_platform//:platform
Traceback (most recent call last):
  File ""\\?\C:\Users\mlp_admin\tmp\Bazel.runfiles_x184n_p0\runfiles\org_tensorflow\tensorflow\python\pywrap_tensorflow.py"", line 62, in <module>
    from tensorflow.python._pywrap_tensorflow_internal import *
ImportError: DLL load failed while importing _pywrap_tensorflow_internal: The specified module could not be found.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""\\?\C:\Users\mlp_admin\tmp\Bazel.runfiles_x184n_p0\runfiles\org_tensorflow\tensorflow\python\tools\api\generator\create_python_api.py"", line 22, in <module>
    from tensorflow.python.tools.api.generator import doc_srcs
  File ""\\?\C:\Users\mlp_admin\tmp\Bazel.runfiles_x184n_p0\runfiles\org_tensorflow\tensorflow\python\__init__.py"", line 36, in <module>
    from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow
  File ""\\?\C:\Users\mlp_admin\tmp\Bazel.runfiles_x184n_p0\runfiles\org_tensorflow\tensorflow\python\pywrap_tensorflow.py"", line 77, in <module>
    raise ImportError(
ImportError: Traceback (most recent call last):
  File ""\\?\C:\Users\mlp_admin\tmp\Bazel.runfiles_x184n_p0\runfiles\org_tensorflow\tensorflow\python\pywrap_tensorflow.py"", line 62, in <module>
    from tensorflow.python._pywrap_tensorflow_internal import *
ImportError: DLL load failed while importing _pywrap_tensorflow_internal: The specified module could not be found.


Failed to load the native TensorFlow runtime.
See https://www.tensorflow.org/install/errors for some common causes and solutions.
If you need help, create an issue at https://github.com/tensorflow/tensorflow/issues and include the entire stack trace above this error message.
Target //tensorflow/tools/pip_package:build_pip_package failed to build
ERROR: C:/users/mlp_admin/tensorflow/tensorflow/lite/python/BUILD:68:10 PythonZipper tensorflow/lite/python/tflite_convert.zip failed: (Exit 1): bash.exe failed: error executing command 
  cd /d C:/users/mlp_admin/tensorflow-build/m2fy67yv/execroot/org_tensorflow
  SET PATH=C:\msys64\usr\bin;C:\msys64\bin;C:\Windows;C:\Windows\System32;C:\Windows\System32\WindowsPowerShell\v1.0;C:\Users\mlp_admin\AppData\Local\bazelisk\downloads\bazelbuild\bazel-4fd7983ca82fab536b8f9bb589610036b01d7490-windows-x86_64\bin;C:\tools\cuda\bin;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.2\extras\CUPTI\libx64;C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.2\bin;C:\C;C:\msys64\Users\mlp_admin\venv_py310\Scripts;C:\Program Files\Git\cmd;C:\C;C:\msys64\Users\mlp_admin\venv_py310;C:\tools\bazel\;C;C:\Users\mlp_admin\venv_py310\Scripts;C:\Tools\bazel;C:\Program Files\Git;C:\Program Files\Git\cmd;C:\msys64;C:\msys64\usr\bin;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem
    SET PYTHON_BIN_PATH=C:/Users/mlp_admin/venv_py310/Scripts/python.exe
    SET PYTHON_LIB_PATH=C:/Users/mlp_admin/venv_py310/Lib/site-packages
    SET RUNFILES_MANIFEST_ONLY=1
    SET TEMP=C:\Users\mlp_admin\tmp
    SET TF2_BEHAVIOR=1
    SET TMP=C:\Users\mlp_admin\tmp
  C:\msys64\usr\bin\bash.exe bazel-out/x64_windows-opt/bin/tensorflow/tf_python_api_gen_v2.genrule_script.sh
# Configuration: 92001cead5cfe54bd325acb14a4c0622c2eacc2d756dddb96cef1f45acd66008
# Execution platform: @local_execution_config_platform//:platform
INFO: Elapsed time: 4138.656s, Critical Path: 866.88s
INFO: 11869 processes: 306 internal, 11563 local.
FAILED: Build did NOT complete successfully
FAILED: Build did NOT complete successfully
```
</details>"
55816,Error when making directory to a google cloud storage bucket path,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

2.8.0

### Custom Code

Yes

### OS Platform and Distribution

CentOS Linux release 7.4.1708

### Mobile device

_No response_

### Python version

3.7

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

cuda/11.2.2  cudnn/8.1a11

### GPU model and memory

_No response_

### Current Behaviour?

```shell
First I run `sbatch test_error.sh` on a NYU high-performance cluster. The following is the code of `test_error.sh`

And the error message in `myjob.e` is as follows...(I think the UserWarning about cloud_tpu_init has nothing to do with this issue so maybe we can ignore it here...)

A weird thing I discover is that if I don't submit `test_error.sh` to any host (such as aquila or gpu listed in `test_error.sh`) and just run 

`python -c ""import tensorflow as tf; tf.io.gfile.makedirs('gs://jukemir-t5/pretrain-model/pre/')""` 

in the default host (login2), this error disappears. (However, the login2 host doesn't have enough computing resource so I have to use other host such as aquila... )


As for the gcs bucket, I have already prove that it does exist. And I gave `allUsers` the following permission:

Storage Legacy Bucket Reader
Storage Legacy Bucket Writer
Storage Legacy Object Owner
Storage Object Viewer


I put the following environment variables in `~/.bashrc` file.

export GOOGLE_APPLICATION_CREDENTIALS='/gpfsnyu/scratch/kf2395/impressive-hull-347212-9ed6d5acf8ff.json'
export TENSORSTORE_CA_BUNDLE=""/etc/ssl/certs/ca-bundle.crt""
```


### Standalone code to reproduce the issue

```shell
#!/bin/bash

#SBATCH -p aquila,gpu # Partition to submit to

#SBATCH -n 1 # Number of cores

#SBATCH -N 1 # Number of nodes

#SBATCH --mem=100G # Memory pool for all cores, MB

#SBATCH -t 0-8:00

#SBATCH -o myjob.o # File to which STDOUT will be written

#SBATCH -e myjob.e # File to which STDERR will be written

#SBATCH --mail-type=ALL # Type of email notification- BEGIN,END,FAIL,ALL

#SBATCH --mail-user=kf2395@nyu.edu # Email which notifications will be sent  

#SBATCH --gres=gpu:4 # How much gpu need, n is the number

#SBATCH --export=ALL

module load cuda/11.2.2
python -c ""import tensorflow as tf; tf.io.gfile.makedirs('gs://jukemir-t5/pretrain-model/pre/')""
```


### Relevant log output

```shell
2022-04-29 17:33:22.818645: W tensorflow/core/platform/cloud/google_auth_provider.cc:184] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with ""FAILED_PRECONDITION: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Could not resolve host: www.googleapis.com"". Retrieving token from GCE failed with ""FAILED_PRECONDITION: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Could not resolve host: metadata"".
/gpfsnyu/scratch/kf2395/.cache/env/tf2-gpu-py3.7/lib/python3.7/site-packages/jax/__init__.py:27: UserWarning: cloud_tpu_init failed: ConnectionError(MaxRetryError(""HTTPConnectionPool(host='metadata.google.internal', port=80): Max retries exceeded with url: /computeMetadata/v1/instance/attributes/agent-worker-number (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f30dab30190>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution'))""))
 This a JAX bug; please report an issue at https://github.com/google/jax/issues
  _warn(f""cloud_tpu_init failed: {repr(exc)}\n This a JAX bug; please report ""
Traceback (most recent call last):
  File ""<string>"", line 1, in <module>
  File ""/gpfsnyu/scratch/kf2395/.cache/env/tf2-gpu-py3.7/lib/python3.7/site-packages/tensorflow/python/lib/io/file_io.py"", line 511, in recursive_create_dir_v2
    _pywrap_file_io.RecursivelyCreateDir(compat.path_to_bytes(path))
tensorflow.python.framework.errors_impl.FailedPreconditionError: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Could not resolve host: www.googleapis.com
	 when reading metadata of gs://jukemir-t5/pretrain-model/pre/
```
</details>"
55815,tf.data batching slows down on Windows,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

tf 2.8

### Custom Code

Yes

### OS Platform and Distribution

Windows 10

### Mobile device

_No response_

### Python version

3.8

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

CUDA 11.2 cuDNN 8.1.0

### GPU model and memory

Nvidia A40 48GB, 128GB System RAM

### Current Behaviour?


While training a keras model using a [custom tensorflow dataset](https://www.tensorflow.org/datasets/add_dataset), the training steps slow down once the remaining sample count in the first epoch is smaller than the shuffle buffer size. The slowdown carries over to the following epochs and takes longer and longer.

I would expect the opposite behavior since all remaining samples should already be in the buffer and do not need to be loaded anymore. I have tested it on multiple Windows systems and this slowdown occurred on all of them. However, it does not happen on Linux-based systems.

I then used the tensorboard profiling plugin to investigate what is causing the slowdown. As you can see here, it seems to be an input-related problem:
![profiler_1](https://user-images.githubusercontent.com/1509163/166112234-b795f11e-934f-4631-86b1-c8d79e1e1448.png)

From the input operations you can see that `Iterator::Root::Prefetch::BatchV2` takes the most time (this is also the case when removing the prefetching):
![profiler_2](https://user-images.githubusercontent.com/1509163/166112243-798a33a9-b329-4103-9d24-b0b70306411d.png)

The slowdown can also be seen in the trace viewer:
![profiler_3](https://user-images.githubusercontent.com/1509163/166112328-9e637031-1166-4ac6-afef-47a8a534bf9b.png)

Here is a more detailed comparison of `BatchV2` durations from different steps:
![profiler_4](https://user-images.githubusercontent.com/1509163/166112335-119bb08e-7cd2-4a4b-a149-0de1580332a4.png)
![profiler_5](https://user-images.githubusercontent.com/1509163/166112342-dd0ea8a4-9d79-4ec3-adc9-87ac133e118e.png)


Here is the [profiling_data.zip](https://github.com/tensorflow/tensorflow/files/8597248/profiling_data.zip).



### Standalone code to reproduce the issue

In order to reproduce and profile this issue the following code can be used. When running the `main.py` for the first time it will generate the dummy dataset which takes around 20 minutes to write 24GB of dummy data.

**dummy_dataset.py**
```python
import numpy as np
import tensorflow as tf
import tensorflow_datasets as tfds


class DummyDataset(tfds.core.GeneratorBasedBuilder):
    VERSION = tfds.core.Version('1.0.0')
    RELEASE_NOTES = {
        '1.0.0': 'Initial release.',
    }

    def _info(self) -> tfds.core.DatasetInfo:
        return tfds.core.DatasetInfo(
            builder=self,
            features=tfds.features.FeaturesDict({
                'audio': tfds.features.Audio(shape=(16000,), dtype=tf.float32),
                'label': tfds.features.Tensor(shape=(2,), dtype=tf.float32),
            }),
            supervised_keys=('audio', 'label')
        )

    def _split_generators(self, dl_manager: tfds.download.DownloadManager):
        return {
            'train': self._generate_examples(),
        }

    def _generate_examples(self):
        for i in range(400000): # If sample count is increased, issue starts later (tested with 1M+)
            yield i, {
                'audio': np.random.sample(16000).astype(dtype=np.float32),
                'label': tf.one_hot(np.random.choice(2), depth=2).numpy()
            }
```



**main.py**
```python
from dummy_dataset import DummyDataset
import tensorflow_datasets as tfds
import tensorflow as tf
import os
import datetime
from tensorflow import keras

# Configuration
shuffle_buffer = 300000 # Uses ~30GB RAM, can be lowered to 150000 if only 16GB RAM available
batch_size = 512
epochs = 3

optimizer = keras.optimizers.Adam(learning_rate=0.001)
losses = ['categorical_crossentropy']
metrics = [keras.metrics.CategoricalAccuracy()]

folder_name = datetime.datetime.now().strftime(""%Y-%m-%d_%H-%M-%S"")

# Prepare dataset (takes ~20min for the first time to generate ~24GB of dummy data)
ds_train, ds_info = tfds.load(
    name='DummyDataset',
    split='train',
    as_supervised=True,
    with_info=True,
    shuffle_files=True,
)
ds_train = ds_train.shuffle(shuffle_buffer)
ds_train = ds_train.batch(batch_size)
ds_train = ds_train.prefetch(tf.data.AUTOTUNE)

# Configure profiling
sample_count = ds_info.splits['train'].num_examples
slowdown_start = int((sample_count - shuffle_buffer) / batch_size)
profile_stop = slowdown_start + 150

callbacks = [keras.callbacks.TensorBoard(
    log_dir=os.path.join(os.getcwd(), 'tensorboard', folder_name),
    profile_batch=[slowdown_start, profile_stop]
)]

# Build and train model
input_layer = keras.layers.Input(shape=(16000,), dtype=tf.float32, name='audio_input')
output_layer = keras.layers.Dense(2, activation='softmax', name='prediction')(input_layer)
model = keras.Model(inputs=input_layer, outputs=output_layer, name='dummy_model')

model.compile(optimizer=optimizer, loss=losses, metrics=metrics)
model.summary()

print(f'Expected slowdown to start at batch {slowdown_start}, profiling batches {slowdown_start}-{profile_stop}')

model.fit(x=ds_train, epochs=epochs, verbose=1, callbacks=callbacks)
```

**requirements.txt**
```
tensorflow==2.8.0
tensorflow-datasets==4.5.2
tensorboard-plugin-profile
numpy
```


### Relevant log output

_No response_</details>"
55814,Inconsistent results with or without tf.function,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

tf 2.8.0

### Custom Code

No

### OS Platform and Distribution

Google Colab

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
The function with tf.function decorator should produce the same results the one without the decorator. In addition, adding one tf.print statement in the function with tf.function decorator will change the behavior.
```


### Standalone code to reproduce the issue

```shell
I created a google colab notebook. Please check this link.

https://colab.research.google.com/drive/1FOvjw0pPZHQw2bZtuFE8fnTAZk8_n0X8?usp=sharing
```


### Relevant log output

```shell
TensorFlow version: 2.8.0
loss_object tf.Tensor(26.064999, shape=(), dtype=float32)
loss_object_1 tf.Tensor(nan, shape=(), dtype=float32)
[[1.5240801e-14 4.78756791e-12 7.77465369e-15 ... 1 4.88135581e-29 0]]
loss_object_2 tf.Tensor(nan, shape=(), dtype=float32)
```
</details>"
55813,Voting issues for the output layer,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Support

### Source

source

### Tensorflow Version

tf2.1.1

### Custom Code

Yes

### OS Platform and Distribution

Windows

### Mobile device

_No response_

### Python version

3.7

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
When I want to vote with the output values of multiple neurons in the output layer and classify according to the voting results, there is an error in defining the loss function and the accuracy rate. I want to use the probability that the output value of the neuron is greater than a certain threshold as the classification Probability, what should I do
```


### Standalone code to reproduce the issue

```shell
@tf.function
def custom_accuracy(y_true, y_pred):
    y_true = tf.squeeze(y_true)

    y_pred1=tf.reshape(y_pred,[-1])

    y_pred2=tf.map_fn(lambda x: 1.0 if x >= 0 else 0.0, y_pred1)

    y_pred3=tf.reshape(y_pred2,[y_pred.shape[0],y_pred.shape[1]])
    y_pred4=tf.reduce_mean(y_pred3, axis=1, keepdims=False)
    y_pred5=tf.map_fn(lambda x: 1.0 if x >= 0.5 else 0.0, y_pred4)
    y_pred5=tf.cast(y_pred5,float64)

    return tf.keras.backend.mean(tf.keras.backend.equal(y_true, y_pred5))
```


### Relevant log output

_No response_</details>"
55812,Value Assignment by specific indices error in Tensorflow (Assign values using mask),"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Feature Request

### Source

source

### Tensorflow Version

tf 2.8

### Custom Code

Yes

### OS Platform and Distribution

Windows 10

### Mobile device

_No response_

### Python version

3.10.2

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
Hi! I'm trying to build a custom loss function for my model, but whenever I try to convert Tensors into .numpy() arrays with run_eagerly = True, it gives ""WARNING: Gradients do not exist for variables ..."". So I debugged other custom loss functions implemented using tensorflow. But in my case, I need to apply to mask and splitting index arrays and then use those arrays as indices to apply some sort of arithmetic functions using broadcasting. But I retrieved indices lists after masking, but I just have to access those indices and add specific functions. But I found no way in TensorFlow to implement that in a vectorized way.
```


### Standalone code to reproduce the issue

```shell
In NumPy, I can access it using:
error[i, j] = error[i, j] * 5
But TensorFlow does not provide any support related to this.
Also, I could not implement the custom_loss function by converting arrays to NumPy because it makes Gradient None. And it gives ""WARNING: Gradients do not exist for variables ..."".
```


### Relevant log output

```shell
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
Input In [193], in <cell line: 1>()
----> 1 error[i, j]

File ~\AppData\Local\Programs\Python\Python310\lib\site-packages\tensorflow\python\util\traceback_utils.py:153, in filter_traceback.<locals>.error_handler(*args, **kwargs)
    151 except Exception as e:
    152   filtered_tb = _process_traceback_frames(e.__traceback__)
--> 153   raise e.with_traceback(filtered_tb) from None
    154 finally:
    155   del filtered_tb

File ~\AppData\Local\Programs\Python\Python310\lib\site-packages\tensorflow\python\ops\array_ops.py:899, in _check_index(idx)
    894 dtype = getattr(idx, ""dtype"", None)
    895 if (dtype is None or dtypes.as_dtype(dtype) not in _SUPPORTED_SLICE_DTYPES or
    896     idx.shape and len(idx.shape) == 1):
    897   # TODO(slebedev): IndexError seems more appropriate here, but it
    898   # will break `_slice_helper` contract.
--> 899   raise TypeError(_SLICE_TYPE_ERROR + "", got {!r}"".format(idx))

TypeError: Only integers, slices (`:`), ellipsis (`...`), tf.newaxis (`None`) and scalar tf.int32/tf.int64 tensors are valid indices, got <tf.Tensor: shape=(4797,), dtype=int64, numpy=array([ 0,  0,  0, ..., 26, 26, 26], dtype=int64)>
I tried using other functions provided by TensorFlow too, but those did not work.
```
</details>"
55811,Unroll factor for keras.layers.RNN or performance fix for TensorArray / while_loop.,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Feature Request

### Tensorflow Version

2.7.0

### Custom Code

Yes

### OS Platform and Distribution

Ubuntu 20.04


### CUDA/cuDNN version

11.5

### GPU model and memory

RTX 2080Ti

</details>

### Feature description


`keras.layers.RNN` supports unrolling, which is great for performance, unless the unrolled time dimension is too long. The XLA compiler takes a ton of time processing a fully unrolled loop (e.g. 240 iterations). Every major compiler supports unrolling a loop for a given factor. The `unroll` argument from `keras.layers.RNN` could instead take an integer telling how many iterations it should unroll, and insert a while loop around the remaining factor. Using an unroll factor of 32 would do miracles for most long time-dimension datasets.

XLA speedups are huge for my custom RNN Cell, so I'd like to use it, but now I'm waiting 5 minutes for XLA/ptxas to finish processing the unrolled loop. On the other hand, if I don't unroll, the while_loop introduces a TensorArray struct takes a tremendous amount of time every time-iteration of the RNN as there is a cuMemcpyD2H of 4 bytes happening between GPU and CPU. The whole CUDA driver pipeline stalls for this 4-byte copy. Performance drops by a factor of 2 to 5 because of this. I don't know if the 4-byte copy is an unintentional performance bug in TensorArray/tf.while_loop or not. But if it's not, I think the unroll factor is a good compromise."
55810,Not able to install Tensorflow-gpu v2.8 in ubuntu 18.04,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Build/Install

### Source

binary

### Tensorflow Version

2.8

### Custom Code

No

### OS Platform and Distribution

Ubuntu 18.04

### Mobile device

_No response_

### Python version

3.7.6

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
Not able to install tensorflow-gpu in the environment. I have gpu in my PC.

nvidia-smi: 

Sat Apr 30 06:12:08 2022       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 450.119.03   Driver Version: 450.119.03   CUDA Version: 11.0     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  GeForce GTX 1070    Off  | 00000000:01:00.0  On |                  N/A |
| 27%   35C    P8     7W / 151W |    564MiB /  8116MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|    0   N/A  N/A      1453      G   /usr/lib/xorg/Xorg                 18MiB |
|    0   N/A  N/A      1786      G   /usr/bin/gnome-shell               50MiB |
|    0   N/A  N/A      2789      G   /usr/lib/xorg/Xorg                166MiB |
|    0   N/A  N/A      2920      G   /usr/bin/gnome-shell              106MiB |
|    0   N/A  N/A      2946      G   ...mviewer/tv_bin/TeamViewer        2MiB |
|    0   N/A  N/A      3732      G   ...AAAAAAAAA= --shared-files      214MiB |
+-----------------------------------------------------------------------------+



nvcc --version
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2020 NVIDIA Corporation
Built on Thu_Jun_11_22:26:38_PDT_2020
Cuda compilation tools, release 11.0, V11.0.194
Build cuda_11.0_bu.TC445_37.28540450_0
```


### Standalone code to reproduce the issue

```shell
python -m venv env
source env/bin/activate
pip install tensorflow

python
import tensorflow as tf
tf.config.list_physical_devices('GPU')
```


### Relevant log output

```shell
2022-04-30 06:07:54.975964: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-04-30 06:07:54.980421: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.0/lib64:/usr/local/cuda-11.0/lib64${LD_LIBRARY_PATH:+:}
2022-04-30 06:07:54.980435: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
[]
```
</details>"
55809,How to resize (downsample) 5D samples in tensorflow? ,"Issue Type: Feature Request
Source: binary
Tensorflow Version: tf 2.8
Custom Code: Yes
OS Platform and Distribution: Windows 10
Python version: 3.9

---

## Note.

Reposting from [here](https://github.com/keras-team/keras/issues/16260). It's closed in keras and recommended to post it on the tensorflow side because this functionality is not precisely available in tensorflow. It may need to write low-level ops in tf for best performance.


# Current Behaviour?

Currently, for **5D** data, `(batch_size, h, w, depth, channel)`, the [`tf.keras.backend.resize_volumes`](https://github.com/keras-team/keras/pull/3274) or `UpSampling3D` can be used to **upsampling purpose**. 

For example, I can do 

```python
a  = tf.ones(shape=(1, 100, 100, 64, 1))

tf.keras.backend.resize_volumes(
       a, depth_factor=2, 
       height_factor=2, 
       width_factor=2, 
       data_format=""channels_last""
).shape
TensorShape([1, 200, 200, 128, 1])
```

These `*_factor` values (above), should be an **integer**, and are coded here: https://github.com/keras-team/keras/blob/master/keras/backend.py#L3441-L3444. 

In that case, how can we **downsample** the input sample? For example:

```python
a  = tf.ones(shape=(1, 100, 100, 64, 1))

tf.keras.backend.resize_volumes(
       a, depth_factor=0.5, 
       height_factor=0.5, 
       width_factor=0.5 
       data_format=""channels_last""
).shape

TypeError: 'float' object cannot be interpreted as an integer

# EXPECTED
TensorShape([1, 50, 50, 32, 1])
```

[ HERE https://stackoverflow.com/q/57341504/9215780, another scenario where the factor needed to be fractional. ]

# Candidate Solutions

- [scipy.ndimage.zoom](https://docs.scipy.org/doc/scipy/reference/generated/scipy.ndimage.zoom.html)
- [in pytorch](https://discuss.pytorch.org/t/pytorch-resize-3d-numpy-array/70338/4) (didn't test)

## Others

- Such downsampling feature needs to be implemented in low-level. 
- In the `depth` part of volumetric data, it might be hard to decide the appropriate strategy to drop the slices depending on the domain. For example, in medical data, if we drop the slice blindly, we might lose information. FYI, in CT/MRI images, most of the information appears mainly in the **middle range**. 
- Currently a workaround for **medical data (CT/MRI)**, we're following:

```
# (input data: 1, 50, 50, 20, 4)
# (desired output: 1, 25, 25, 10, 4)
```
```python
a = tf.ones(shape=(1, 50, 50, 20, 4))
a.shape # TensorShape([1, 50, 50, 20, 4])

a2 = tf.reshape(a, [-1, 50, 50, 20*4])
a2.shape # TensorShape([1, 50, 50, 80])

a3 = tf.image.resize(a2, [25, 25])
a3.shape # TensorShape([1, 25, 25, 80])

a4 = tf.reshape(a3, [-1, 25, 25, 20, 4])
a4.shape # TensorShape([1, 25, 25, 20, 4])

# HERE, Picking some middle slices -
# - Assuming that by this we may get relevant slices. 
# How convenient is this? # May not general! 
a5 = a4[...,  5:15, :]
a5.shape
TensorShape([1, 25, 25, 10, 4])
```"
55803,Error building custom tensorflow op on Ubuntu and Windows,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

tf 2.8

### Custom Code

Yes

### OS Platform and Distribution

Ubuntu 20.04, Windows 10

### Mobile device

_No response_

### Python version

3.8, 3.9

### Bazel version

_No response_

### GCC/Compiler version

9.4.0

### CUDA/cuDNN version

11.2

### GPU model and memory

RTX 3080

### Current Behaviour?

I am trying to build a custom op following this https://www.tensorflow.org/guide/create_op. First, I compiled .cu file using nvcc into .cu.o successfully. Than I was trying to build a resulting .so file using g++, but I am constantly getting errors from compiler screaming on tensorflow internal src files. For example: 
```shell
/home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/framework/op.h:294:3: error: a storage class can only be specified for objects and functions
  294 |   static ::tensorflow::InitOnStartupMarker const register_op##ctr         \
      |   ^~~~~~
```
It seems like some versions or flags are messed up and compiler doesn't read tensorflow headers properly.

Output of `python -c 'import tensorflow as tf; print("" "".join(tf.sysconfig.get_compile_flags()))'`:
`-I/home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include -D_GLIBCXX_USE_CXX11_ABI=0 -DEIGEN_MAX_ALIGN_BYTES=64`

Output of `python -c 'import tensorflow as tf; print("" "".join(tf.sysconfig.get_link_flags()))'`:
`-L/home/dmitry/.local/lib/python3.8/site-packages/tensorflow -l:libtensorflow_framework.so.2`

### Standalone code to reproduce the issue

Here is my command for Ubuntu:
```shell
 g++ -std=c++14 -shared -o upfirdn2d.so upfirdn2d.cpp upfirdn2d.h upfirdn2d.cu.o \
  -I/home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include \
  -I/home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/external/protobuf_archive/src \
  -I/home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/external/com_google_absl \
  -I/home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/external/eigen_archive \
   -D_GLIBCXX_USE_CXX11_ABI=0 -DEIGEN_MAX_ALIGN_BYTES=64 \
  -fPIC -lcudart -L/home/dmitry/.local/lib/python3.8/site-packages/tensorflow -l:libtensorflow_framework.so.2 
```
I tried to play with different flags but no luck for now, exactly those erros (from log output) are present all the time both on Ubuntu and Windows. Files that I'm using to buld this op: [upfirdn2d.zip](https://github.com/tensorflow/tensorflow/files/8603489/upfirdn2d.zip)


### Relevant log output

```shell
In file included from /home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/framework/partial_tensor_shape.h:20,
                 from /home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/framework/attr_value_util.h:23,
                 from /home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/framework/node_def_util.h:23,
                 from /home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/framework/full_type_util.h:24,
                 from /home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/framework/op.h:24,
                 from upfirdn2d.h:12,
                 from upfirdn2d.cpp:9:
/home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/framework/tensor_shape.h:305:22: warning: ‘tensorflow::int64’ is deprecated: Use int64_t instead. [-Wdeprecated-declarations]
  305 |   gtl::InlinedVector<int64, 4> dim_sizes() const;
      |                      ^~~~~
In file included from /home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/platform/types.h:31,
                 from /home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/platform/logging.h:20,
                 from /home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/platform/errors.h:24,
                 from /home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/lib/core/errors.h:19,
                 from /home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/framework/tensor_shape.h:23,
                 from /home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/framework/partial_tensor_shape.h:20,
                 from /home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/framework/attr_value_util.h:23,
                 from /home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/framework/node_def_util.h:23,
                 from /home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/framework/full_type_util.h:24,
                 from /home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/framework/op.h:24,
                 from upfirdn2d.h:12,
                 from upfirdn2d.cpp:9:
/home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/platform/default/integral_types.h:29:63: note: declared here
   29 | [[deprecated(""Use int64_t instead."")]] typedef ::std::int64_t int64;
      |                                                               ^~~~~
In file included from /home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/platform/notification.h:27,
                 from /home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/lib/core/notification.h:21,
                 from /home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/framework/cancellation.h:22,
                 from /home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/framework/op_kernel.h:27,
                 from upfirdn2d.h:13,
                 from upfirdn2d.cpp:9:
/home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/platform/default/notification.h:61:65: warning: ‘tensorflow::int64’ is deprecated: Use int64_t instead. [-Wdeprecated-declarations]
   61 |                                              int64 timeout_in_us);
      |                                                                 ^
In file included from /home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/platform/types.h:31,
                 from /home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/platform/logging.h:20,
                 from /home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/platform/errors.h:24,
                 from /home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/lib/core/errors.h:19,
                 from /home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/framework/tensor_shape.h:23,
                 from /home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/framework/partial_tensor_shape.h:20,
                 from /home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/framework/attr_value_util.h:23,
                 from /home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/framework/node_def_util.h:23,
                 from /home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/framework/full_type_util.h:24,
                 from /home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/framework/op.h:24,
                 from upfirdn2d.h:12,
                 from upfirdn2d.cpp:9:
/home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/platform/default/integral_types.h:29:63: note: declared here
   29 | [[deprecated(""Use int64_t instead."")]] typedef ::std::int64_t int64;
      |                                                               ^~~~~
In file included from /home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/platform/notification.h:27,
                 from /home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/lib/core/notification.h:21,
                 from /home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/framework/cancellation.h:22,
                 from /home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/framework/op_kernel.h:27,
                 from upfirdn2d.h:13,
                 from upfirdn2d.cpp:9:
/home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/platform/default/notification.h:62:58: warning: ‘tensorflow::int64’ is deprecated: Use int64_t instead. [-Wdeprecated-declarations]
   62 |   bool WaitForNotificationWithTimeout(int64 timeout_in_us) {
      |                                                          ^
In file included from /home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/platform/types.h:31,
                 from /home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/platform/logging.h:20,
                 from /home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/platform/errors.h:24,
                 from /home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/lib/core/errors.h:19,
                 from /home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/framework/tensor_shape.h:23,
                 from /home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/framework/partial_tensor_shape.h:20,
                 from /home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/framework/attr_value_util.h:23,
                 from /home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/framework/node_def_util.h:23,
                 from /home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/framework/full_type_util.h:24,
                 from /home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/framework/op.h:24,
                 from upfirdn2d.h:12,
                 from upfirdn2d.cpp:9:
/home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/platform/default/integral_types.h:29:63: note: declared here
   29 | [[deprecated(""Use int64_t instead."")]] typedef ::std::int64_t int64;
      |                                                               ^~~~~
In file included from /home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/platform/notification.h:27,
                 from /home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/lib/core/notification.h:21,
                 from /home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/framework/cancellation.h:22,
                 from /home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/framework/op_kernel.h:27,
                 from upfirdn2d.h:13,
                 from upfirdn2d.cpp:9:
/home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/platform/default/notification.h:81:63: warning: ‘tensorflow::int64’ is deprecated: Use int64_t instead. [-Wdeprecated-declarations]
   81 |                                            int64 timeout_in_us) {
      |                                                               ^
In file included from /home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/platform/types.h:31,
                 from /home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/platform/logging.h:20,
                 from /home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/platform/errors.h:24,
                 from /home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/lib/core/errors.h:19,
                 from /home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/framework/tensor_shape.h:23,
                 from /home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/framework/partial_tensor_shape.h:20,
                 from /home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/framework/attr_value_util.h:23,
                 from /home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/framework/node_def_util.h:23,
                 from /home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/framework/full_type_util.h:24,
                 from /home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/framework/op.h:24,
                 from upfirdn2d.h:12,
                 from upfirdn2d.cpp:9:
/home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/platform/default/integral_types.h:29:63: note: declared here
   29 | [[deprecated(""Use int64_t instead."")]] typedef ::std::int64_t int64;
      |                                                               ^~~~~
In file included from upfirdn2d.h:12,
                 from upfirdn2d.cpp:9:
/home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/framework/op.h:294:3: error: a storage class can only be specified for objects and functions
  294 |   static ::tensorflow::InitOnStartupMarker const register_op##ctr         \
      |   ^~~~~~
/home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/framework/op.h:294:3: note: in definition of macro ‘REGISTER_OP_IMPL’
  294 |   static ::tensorflow::InitOnStartupMarker const register_op##ctr         \
      |   ^~~~~~
/home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/framework/registration/registration.h:146:41: note: in expansion of macro ‘TF_NEW_ID_FOR_INIT_2’
  146 | #define TF_NEW_ID_FOR_INIT_1(m, c, ...) TF_NEW_ID_FOR_INIT_2(m, c, __VA_ARGS__)
      |                                         ^~~~~~~~~~~~~~~~~~~~
/home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/framework/registration/registration.h:148:3: note: in expansion of macro ‘TF_NEW_ID_FOR_INIT_1’
  148 |   TF_NEW_ID_FOR_INIT_1(m, __COUNTER__, __VA_ARGS__)
      |   ^~~~~~~~~~~~~~~~~~~~
/home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/framework/op.h:301:3: note: in expansion of macro ‘TF_NEW_ID_FOR_INIT’
  301 |   TF_NEW_ID_FOR_INIT(REGISTER_OP_IMPL, name, false)
      |   ^~~~~~~~~~~~~~~~~~
upfirdn2d.cpp:266:1: note: in expansion of macro ‘REGISTER_OP’
  266 | REGISTER_OP(""UpFirDn2D"")
      | ^~~~~~~~~~~
/home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/framework/op.h:294:10: error: expected ‘;’ before ‘::’ token
  294 |   static ::tensorflow::InitOnStartupMarker const register_op##ctr         \
      |          ^~
/home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/framework/op.h:294:10: note: in definition of macro ‘REGISTER_OP_IMPL’
  294 |   static ::tensorflow::InitOnStartupMarker const register_op##ctr         \
      |          ^~
/home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/framework/registration/registration.h:146:41: note: in expansion of macro ‘TF_NEW_ID_FOR_INIT_2’
  146 | #define TF_NEW_ID_FOR_INIT_1(m, c, ...) TF_NEW_ID_FOR_INIT_2(m, c, __VA_ARGS__)
      |                                         ^~~~~~~~~~~~~~~~~~~~
/home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/framework/registration/registration.h:148:3: note: in expansion of macro ‘TF_NEW_ID_FOR_INIT_1’
  148 |   TF_NEW_ID_FOR_INIT_1(m, __COUNTER__, __VA_ARGS__)
      |   ^~~~~~~~~~~~~~~~~~~~
/home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/framework/op.h:301:3: note: in expansion of macro ‘TF_NEW_ID_FOR_INIT’
  301 |   TF_NEW_ID_FOR_INIT(REGISTER_OP_IMPL, name, false)
      |   ^~~~~~~~~~~~~~~~~~
upfirdn2d.cpp:266:1: note: in expansion of macro ‘REGISTER_OP’
  266 | REGISTER_OP(""UpFirDn2D"")
      | ^~~~~~~~~~~
In file included from /home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/framework/op.h:27,
                 from upfirdn2d.h:12,
                 from upfirdn2d.cpp:9:
/home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/framework/registration/registration.h:136:7: error: expected unqualified-id before ‘:’ token
  136 |       : ::tensorflow::InitOnStartupMarker {}
      |       ^
/home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/framework/op.h:296:11: note: in expansion of macro ‘TF_INIT_ON_STARTUP_IF’
  296 |           TF_INIT_ON_STARTUP_IF(is_system_op || SHOULD_REGISTER_OP(name)) \
      |           ^~~~~~~~~~~~~~~~~~~~~
/home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/framework/registration/registration.h:145:41: note: in expansion of macro ‘REGISTER_OP_IMPL’
  145 | #define TF_NEW_ID_FOR_INIT_2(m, c, ...) m(c, __VA_ARGS__)
      |                                         ^
/home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/framework/registration/registration.h:146:41: note: in expansion of macro ‘TF_NEW_ID_FOR_INIT_2’
  146 | #define TF_NEW_ID_FOR_INIT_1(m, c, ...) TF_NEW_ID_FOR_INIT_2(m, c, __VA_ARGS__)
      |                                         ^~~~~~~~~~~~~~~~~~~~
/home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/framework/registration/registration.h:148:3: note: in expansion of macro ‘TF_NEW_ID_FOR_INIT_1’
  148 |   TF_NEW_ID_FOR_INIT_1(m, __COUNTER__, __VA_ARGS__)
      |   ^~~~~~~~~~~~~~~~~~~~
/home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/framework/op.h:301:3: note: in expansion of macro ‘TF_NEW_ID_FOR_INIT’
  301 |   TF_NEW_ID_FOR_INIT(REGISTER_OP_IMPL, name, false)
      |   ^~~~~~~~~~~~~~~~~~
upfirdn2d.cpp:266:1: note: in expansion of macro ‘REGISTER_OP’
  266 | REGISTER_OP(""UpFirDn2D"")
      | ^~~~~~~~~~~
In file included from upfirdn2d.h:12,
                 from upfirdn2d.cpp:9:
/home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/framework/op.h:297:11: error: expected unqualified-id before ‘<<’ token
  297 |           << ::tensorflow::register_op::OpDefBuilderWrapper(name)
      |           ^~
/home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/framework/op.h:297:11: note: in definition of macro ‘REGISTER_OP_IMPL’
  297 |           << ::tensorflow::register_op::OpDefBuilderWrapper(name)
      |           ^~
/home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/framework/registration/registration.h:146:41: note: in expansion of macro ‘TF_NEW_ID_FOR_INIT_2’
  146 | #define TF_NEW_ID_FOR_INIT_1(m, c, ...) TF_NEW_ID_FOR_INIT_2(m, c, __VA_ARGS__)
      |                                         ^~~~~~~~~~~~~~~~~~~~
/home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/framework/registration/registration.h:148:3: note: in expansion of macro ‘TF_NEW_ID_FOR_INIT_1’
  148 |   TF_NEW_ID_FOR_INIT_1(m, __COUNTER__, __VA_ARGS__)
      |   ^~~~~~~~~~~~~~~~~~~~
/home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/framework/op.h:301:3: note: in expansion of macro ‘TF_NEW_ID_FOR_INIT’
  301 |   TF_NEW_ID_FOR_INIT(REGISTER_OP_IMPL, name, false)
      |   ^~~~~~~~~~~~~~~~~~
upfirdn2d.cpp:266:1: note: in expansion of macro ‘REGISTER_OP’
  266 | REGISTER_OP(""UpFirDn2D"")
      | ^~~~~~~~~~~
In file included from /home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/framework/partial_tensor_shape.h:20,
                 from /home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/framework/attr_value_util.h:23,
                 from /home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/framework/node_def_util.h:23,
                 from /home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/framework/full_type_util.h:24,
                 from /home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/framework/op.h:24,
                 from upfirdn2d.h:12:
/home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/framework/tensor_shape.h:305:22: warning: ‘tensorflow::int64’ is deprecated: Use int64_t instead. [-Wdeprecated-declarations]
  305 |   gtl::InlinedVector<int64, 4> dim_sizes() const;
      |                      ^~~~~
In file included from /home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/platform/types.h:31,
                 from /home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/platform/logging.h:20,
                 from /home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/platform/errors.h:24,
                 from /home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/lib/core/errors.h:19,
                 from /home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/framework/tensor_shape.h:23,
                 from /home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/framework/partial_tensor_shape.h:20,
                 from /home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/framework/attr_value_util.h:23,
                 from /home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/framework/node_def_util.h:23,
                 from /home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/framework/full_type_util.h:24,
                 from /home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/framework/op.h:24,
                 from upfirdn2d.h:12:
/home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/platform/default/integral_types.h:29:63: note: declared here
   29 | [[deprecated(""Use int64_t instead."")]] typedef ::std::int64_t int64;
      |                                                               ^~~~~
In file included from /home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/platform/notification.h:27,
                 from /home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/lib/core/notification.h:21,
                 from /home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/framework/cancellation.h:22,
                 from /home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/framework/op_kernel.h:27,
                 from upfirdn2d.h:13:
/home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/platform/default/notification.h:61:65: warning: ‘tensorflow::int64’ is deprecated: Use int64_t instead. [-Wdeprecated-declarations]
   61 |                                              int64 timeout_in_us);
      |                                                                 ^
In file included from /home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/platform/types.h:31,
                 from /home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/platform/logging.h:20,
                 from /home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/platform/errors.h:24,
                 from /home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/lib/core/errors.h:19,
                 from /home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/framework/tensor_shape.h:23,
                 from /home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/framework/partial_tensor_shape.h:20,
                 from /home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/framework/attr_value_util.h:23,
                 from /home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/framework/node_def_util.h:23,
                 from /home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/framework/full_type_util.h:24,
                 from /home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/framework/op.h:24,
                 from upfirdn2d.h:12:
/home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/platform/default/integral_types.h:29:63: note: declared here
   29 | [[deprecated(""Use int64_t instead."")]] typedef ::std::int64_t int64;
      |                                                               ^~~~~
In file included from /home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/platform/notification.h:27,
                 from /home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/lib/core/notification.h:21,
                 from /home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/framework/cancellation.h:22,
                 from /home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/framework/op_kernel.h:27,
                 from upfirdn2d.h:13:
/home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/platform/default/notification.h:62:58: warning: ‘tensorflow::int64’ is deprecated: Use int64_t instead. [-Wdeprecated-declarations]
   62 |   bool WaitForNotificationWithTimeout(int64 timeout_in_us) {
      |                                                          ^
In file included from /home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/platform/types.h:31,
                 from /home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/platform/logging.h:20,
                 from /home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/platform/errors.h:24,
                 from /home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/lib/core/errors.h:19,
                 from /home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/framework/tensor_shape.h:23,
                 from /home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/framework/partial_tensor_shape.h:20,
                 from /home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/framework/attr_value_util.h:23,
                 from /home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/framework/node_def_util.h:23,
                 from /home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/framework/full_type_util.h:24,
                 from /home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/framework/op.h:24,
                 from upfirdn2d.h:12:
/home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/platform/default/integral_types.h:29:63: note: declared here
   29 | [[deprecated(""Use int64_t instead."")]] typedef ::std::int64_t int64;
      |                                                               ^~~~~
In file included from /home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/platform/notification.h:27,
                 from /home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/lib/core/notification.h:21,
                 from /home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/framework/cancellation.h:22,
                 from /home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/framework/op_kernel.h:27,
                 from upfirdn2d.h:13:
/home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/platform/default/notification.h:81:63: warning: ‘tensorflow::int64’ is deprecated: Use int64_t instead. [-Wdeprecated-declarations]
   81 |                                            int64 timeout_in_us) {
      |                                                               ^
In file included from /home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/platform/types.h:31,
                 from /home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/platform/logging.h:20,
                 from /home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/platform/errors.h:24,
                 from /home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/lib/core/errors.h:19,
                 from /home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/framework/tensor_shape.h:23,
                 from /home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/framework/partial_tensor_shape.h:20,
                 from /home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/framework/attr_value_util.h:23,
                 from /home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/framework/node_def_util.h:23,
                 from /home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/framework/full_type_util.h:24,
                 from /home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/framework/op.h:24,
                 from upfirdn2d.h:12:
/home/dmitry/.local/lib/python3.8/site-packages/tensorflow/include/tensorflow/core/platform/default/integral_types.h:29:63: note: declared here
   29 | [[deprecated(""Use int64_t instead."")]] typedef ::std::int64_t int64;
      |                                                               ^~~~~
```

</details>"
55801,Kp,
55799,TFlite model with dilated convolution yields different results than TF model ,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

v2.4.0-49-g85c8b2a817f 2.4.1

### Custom Code

No

### OS Platform and Distribution

Windows 10

### Mobile device

_No response_

### Python version

3.8

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

CUDA 11.0, cuDNN 6.5.0

### GPU model and memory

NVIDIA GeForce RTX 3090

### Current Behaviour?

```shell
1. A model is created from a layer including 3 conv2d layers, randomly initialized weights.
2. The model ist stored on disk.
3. The model is called with random input data.
4. A TFlite model is created from the stored model.
5. The TFlite model is called with the same input data.
6. Output from TF model and TF lite model are compared.

=> Completely different results are obtained, if the 2nd conv2d-layer uses dilation (2, 1).
=> Almost equivalent results (with small numerical difference - 1e-3) are obtained with dilation (1, 1).
=> If filters is set to 16 (instead of 32), then also for dilation (2, 1) equivalent results (1e-7) are obtained.
```


### Standalone code to reproduce the issue

```shell
import tensorflow as tf
import matplotlib.pyplot as plt


class MyLayer(tf.keras.layers.Layer):
    def __init__(self, filters, dilation):
        super(MyLayer, self).__init__()

        self.c0 = tf.keras.layers.Conv2D(filters=filters,
                                         kernel_size=(3, 1),
                                         padding='same',
                                         activation=None)

        self.c1 = tf.keras.layers.Conv2D(filters=filters,
                                         kernel_size=(3, 1),
                                         dilation_rate=(dilation, 1),
                                         padding='same',
                                         activation=None)

        self.c2 = tf.keras.layers.Conv2D(filters=filters,
                                         kernel_size=(3, 1),
                                         padding='same',
                                         activation=None)

    def call(self, x):
        #  input: (B,  time, slices, channels)
        x = self.c0(x)
        x = self.c1(x)
        x = self.c2(x)
        return x


def main():
    dilation = 1    # yields almost equivalent results for filters == 32
    # dilation = 2  # yields different results between tflite and tensorflow for filters == 32
    # filters = 16  # with filters == 16, equivalent results are obtained, for both versions of dilation
    filters = 32  

    # Create a model with a Layer containing three Conv2D Layers
    input_shape = (128, 1, 1)
    x = tf.keras.Input(shape=input_shape, name='input', dtype=tf.float32)

    y = MyLayer(filters=filters, dilation=dilation)(x)

    model = tf.keras.Model(inputs=[x], outputs=[y])

    # Save tensorflow model
    test_tensorflow_model_path = 'test_tensorflow_model/'
    test_tflite_model_file = test_tensorflow_model_path + 'test_tflitemodel.tflite'
    model.save(test_tensorflow_model_path)

    # Load model from disk
    model = tf.keras.models.load_model(test_tensorflow_model_path)

    # create random test data and call model
    input_data = tf.random.normal((1, ) + input_shape, dtype=tf.float32)
    output_tf = model(input_data)

    # Create a TFlite model
    converter = tf.lite.TFLiteConverter.from_saved_model(test_tensorflow_model_path)

    converter.optimizations = [tf.lite.Optimize.DEFAULT]
    tflite_model = converter.convert()
    with open(test_tflite_model_file, 'wb') as f:
        f.write(tflite_model)
    print(""TF lite export done"")

    # Load the TFLite model in TFLite Interpreter
    interpreter = tf.lite.Interpreter(test_tflite_model_file)
    interpreter.allocate_tensors()

    # Call TFlite model with same input data as TF-model
    input_details = interpreter.get_input_details()[0]

    interpreter.set_tensor(input_details['index'], input_data)
    interpreter.invoke()
    out_tensor_index = interpreter.get_output_details()[0]['index']
    output_tflite = interpreter.get_tensor(out_tensor_index)

    # Compare results
    print('tflite_output: ', output_tflite[0, :, :, 0])
    print('tf_output: ', output_tf[0, :, :, 0])

    print('relative error: ', tf.math.sqrt(2*tf.math.reduce_variance(output_tf-output_tflite) / tf.math.reduce_variance(output_tf+output_tflite)), '%')

    plt.plot(output_tflite[0, :, :, 0])
    plt.plot(output_tf[0, :, :, 0])
    plt.show()


if __name__ == '__main__':
    main()
```


### Relevant log output

```shell
Different result with dilation == 2 (line 35):

relative error:  tf.Tensor(0.9494969, shape=(), dtype=float32) %

OK with dilation == 1 (changed in lines 34/35):

relative error:  tf.Tensor(0.010502108, shape=(), dtype=float32) %
```
</details>"
55798,gradient tape out of memory when repeatedly calling the same layer.,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Support

### Source

source

### Tensorflow Version

tf 2.8

### Custom Code

No

### OS Platform and Distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
Hi! 

So I have two models, A and B, that I wish to combine into a third model C. Both A and B are essentially CNNs but crucially A can only operate on patches of a full image, while B must operate on a full image. 

A has {input: 4, n/4, n/4, 1; output: 4, n/4,n/4,1}
B has {input: 1, n, n, 1; output: 1, 10}
C should be {input: 16, n/4, n/4, 1; output: 1, 10}

I set the model C up by repeatedly calling model A on 4 sets of 4 patches, then combining the patches to form a full size image, then feeding them into model B. I can call this model fine using C(data) and it gives the expected output. 

My problem is that when using gradient tape, I reach OOM. I believe this is because I am calling model A 16 times so its essentially saving gradients for 16 times. The models A and B are not that big (~10 million params), but calling it many times means its alot bigger.

Does anyone have an idea how to work around this? Perhaps by propagating the gradients through each call of model A seperately... how would I implement this?! 

Thanks very much in advance!!
```


### Standalone code to reproduce the issue

```shell
def mega(A, B, data, batch_size):

    inp = tf.keras.Input(shape = data.shape[1:],batch_size=batch_size)

    
    no_batches = int(inp.shape[0]/4) #model A can take 4 patches at once. 
    hyp_recon = []

    for i in range(no_batches):
        hyp_recon.append(A(inp[i*4:(i+1)*4])) #feed in 4 patches at once
    
    all_recon = tf.stack(hyp_recon) #stack the response

    full_images = batch_combine(all_recon) #this function combined the patches into full images
    
    final = B(full_images) #apply model B to full images

    model = tf.keras.Model(inp,final)
    model._name = 'mega'

    return model
```


### Relevant log output

```shell
OP_REQUIRES failed at matmul_op_impl.h:681 : RESOURCE_EXHAUSTED: OOM when allocating tensor with shape[4,17152,17152] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
```
</details>"
55797,Change to rolling bazel release is broken on AARCH64,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Build/Install

### Source

source

### Tensorflow Version

git HEAD

### Custom Code

No

### OS Platform and Distribution

CentOS 7

### Mobile device

n/a

### Python version

3.8.13

### Bazel version

last_downstream_green

### GCC/Compiler version

10.2.1

### CUDA/cuDNN version

n/a

### GPU model and memory

n/a

### Current Behaviour?

```shell
Build fails due to being unable to run bazel
```


### Standalone code to reproduce the issue

```shell
bazel clean --expunge
```


### Relevant log output

```shell
bazel clean --expunge
    2022/04/29 09:33:30 Using unreleased version at commit df96163124d220a04abde24f8302e77349ae5194
    2022/04/29 09:33:30 Downloading https://storage.googleapis.com/bazel-builds/artifacts/ubuntu1404/df96163124d220a04abde24f8302e77349ae5194/bazel...
    2022/04/29 09:33:34 could not run Bazel: could not start Bazel: fork/exec /root/.cache/bazelisk/downloads/bazelbuild/bazel-df96163124d220a04abde24f8302e77349ae5194-linux-arm64/bin/bazel: exec format error

Introduced by https://github.com/tensorflow/tensorflow/commit/c39f19c52ad5a0cc10cfdb4daefb12f8993bdf39
```
</details>"
55796,tf.range error with certain parameters,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

tf 2.8

### Custom Code

No

### OS Platform and Distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
tf.range reports errors with certain parameters when argument 'step' takes large numbers.

e.g.
tf.range(0, 137, 9223372036854775672, dtype=tf.int64)
tf.range(0, 1000, 9223372036854774809, dtype=tf.int64)

A closer examination finds that 9223372036854775672 + 137 - 2 = 9223372036854774809 + 1000 - 2 = 9223372036854775807, which is the largest number int64 can represent. And if argument 'stop' takes number larger than 137 and 1000 respectively for the two above examples, the same error occurs.
```


### Standalone code to reproduce the issue

```shell
tf.range(0, 136, 9223372036854775672, dtype=tf.int64)  # this works
tf.range(0, 137, 9223372036854775672, dtype=tf.int64)  # this doesn't
tf.range(0, 138, 9223372036854775672, dtype=tf.int64)  # doesn't either
```


### Relevant log output

_No response_</details>"
55795,Autograph crashes when using pythonw.exe on Windows,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

2.8.0

### Custom Code

No

### OS Platform and Distribution

Windows

### Mobile device

_No response_

### Python version

3.8

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

When using pythonw.exe, if local sources are not available, (e.g. only .pyc files are available), autograph causes a crash by trying to flush sys.stdout.

https://github.com/tensorflow/tensorflow/blob/f39905619ddf75b31e209264673f76ac2c72030e/tensorflow/python/autograph/core/ag_ctx.py#L100-L105
If the source code to Autograph itself isn't available, it emits this warning using ag_logging.warning:

https://github.com/tensorflow/tensorflow/blob/f39905619ddf75b31e209264673f76ac2c72030e/tensorflow/python/autograph/utils/ag_logging.py#L141-L145

For some reason, `warning()` is different than any of the other emitters and flushes the stream.  But when running in pythonw.exe, `sys.stdout` is `None`.  It checks for this using `echo_log_to_stdout` to ensure that it doesn't write to stdout, but then immediately tries to flush it.

This can be remediated to indenting the call to `sys.stdout.flush()` to inside the `if echo_log_to_stdout:` check.


### Standalone code to reproduce the issue

1. Create a virtual environment and install TensorFlow
2. Compile all of your py files in site-packages using the `compileall` module
3. Delete py files from your site-packages
4. Create an example tk-based script or something else that shows a GUI
5. Import tensorflow in your script and execute it using `pythonw.exe` and observe the error, which will not fail when running `python.exe`


### Relevant log output

_No response_</details>"
55794,Can't install tensorflow on macOs ,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Build/Install

### Source

binary

### Tensorflow Version

2.8

### Custom Code

No

### OS Platform and Distribution

MacOS Monterey

### Mobile device

_No response_

### Python version

3.10

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
I get this message when I try to install package:
""ERROR: Could not find a version that satisfies the requirement tensorflow (from versions: none)
ERROR: No matching distribution found for tensorflow""

I tried to build from source code, use conda, use python version < 3.10. But in all I get this message. I don't use venv. Please, help me!
```


### Standalone code to reproduce the issue

```shell
-
```


### Relevant log output

_No response_</details>"
55792,TF doesn't fuse Conv2D since v2.7,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

tf 2.8, tf 2.9, tf 2.10

### Custom Code

No

### OS Platform and Distribution

Ubuntu 20.04

### Mobile device

_No response_

### Python version

3.9

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

11.6/8.1

### GPU model and memory

_No response_

### Current Behaviour?

```shell
The TF no longer fuse the convolution+bias+activation patterns from 2.8 and later.
```


### Standalone code to reproduce the issue

```shell
import tensorflow as tf
import numpy as np

use_nhwc = True

N, H, W, C = 1, 2, 3, 3
k, r, s, c = 3, 2, 2, C

if use_nhwc:
  x_format = 'NHWC'
  x_format_keras = 'channels_last'
  bias_format = 'N...C'
  x_shape = (N, H, W, C)
  channel_axis = -1
else:
  x_format = 'NCHW'
  x_format_keras = 'channels_first'
  bias_format = 'NC...'
  x_shape = (N, C, H, W)
  channel_axis = 1
f_np = np.random.random([r, s, c, k]).astype(np.float32)
f = tf.Variable(f_np)
b_np = np.random.random([k]).astype(np.float32)
b = tf.Variable(b_np)


@tf.function
def fused_conv_bias_relu(x):
  y = tf.nn.conv2d(x, f, strides=(1,1), padding='SAME',
                   data_format=x_format, name='xxx_cno1')
  y = tf.nn.bias_add(y, b, data_format=bias_format)
  y = tf.nn.relu(y)
  return y

inputs = tf.random.normal(x_shape)
outputs = fused_conv_bias_relu(inputs)
print(outputs)
```


### Relevant log output

```shell
$ TF_CPP_VMODULE=remapper=2 python demo.py
In 2.7.1 container:
...
2022-04-28 20:35:13.516124: I tensorflow/core/grappler/optimizers/remapper.cc:1345] Fuse Conv2D with BiasAdd and Relu: activation=Relu bias_add=BiasAdd contraction=xxx_cno1

In nightly-gpu container:
...
<No fusion info>
```
</details>"
55789,tf.make_tensor_proto() does not respect byte order of numpy input array,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

tf 2.8

### Custom Code

No

### OS Platform and Distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
Byte order is not checked when creating a TensorProto with tf.make_tensor_proto() from a numpy.ndarray with non-native byte order. This leads to wrong tensor data.

I would expect that byte order is checked and swapped if necessary before assigning to tensor_proto.tensor_content in [python/framework/tensor_util.py](https://github.com/tensorflow/tensorflow/blob/v2.8.0/tensorflow/python/framework/tensor_util.py#L523)
```


### Standalone code to reproduce the issue

```shell
x = np.ones(shape=(1, 2), dtype=np.float32)
x_bswap = x.astype('>f4') # assuming native byte order is little endian

y = tf.make_ndarray(tf.make_tensor_proto(x))
y_bswap = tf.make_ndarray(tf.make_tensor_proto(x_bswap))

print(y)
print(y_bswap)

assert np.array_equal(x, y)
assert np.array_equal(x, y_bswap)
```


### Relevant log output

```shell
[[1. 1.]]
[[4.6006e-41 4.6006e-41]]
---------------------------------------------------------------------------
AssertionError                            Traceback (most recent call last)
in <cell line: 7>()
      5 print(y_bswap)
      6 assert np.array_equal(x, y)
----> 7 assert np.array_equal(x, y_bswap)

AssertionError:
```
</details>"
55787,Loss name not using names from the output dictionary,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Support

### Source

binary

### Tensorflow Version

v2.8.0-rc1-32-g3f878cff5b6 2.8.0

### Custom Code

No

### OS Platform and Distribution

Linux Arch 5.17.4-arch1-1

### Mobile device

_No response_

### Python version

3.9.12

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
I am not sure if this is expected behavior or not, but when I have custom layer that returns dict of tensors then I would like to loss use those names because order could change it I outputs change.

For example if I set `my_layer_1_mse` as a monitor variable in early stopping and change other outputs this will no longer work if `out2` changes from `my_layer_1_mse` to e.g. `my_layer_2_mse`

I would like to know if it is possible to have loss and metrics be named `out1_loss` and `out2_mse` in this specific case. Or at least `my_layer_out1_loss` and `my_layer_out2_loss`

Another problem is that I would like for model outputs to follow same naming convention if possible when exporting model to, for example, to tfjs. Currently outputs will be named `my_layer` and `my_layer_1` instead of `out1` and `out2` respectively. 

Thank you for your help.
```


### Standalone code to reproduce the issue

```shell
import tensorflow as tf


class Layer(tf.keras.layers.Layer):
    def __init__(self, **kwargs):
        super().__init__(**kwargs)

    def call(self, inputs):
        batch_size = tf.shape(inputs)[0]
        return {""out1"": tf.repeat(1, batch_size), ""out2"": tf.repeat(2, batch_size)}


def build_model():

    input = tf.keras.layers.Input(shape=(1,))
    out = Layer(name=""my_layer"")(input)

    return tf.keras.Model(
        inputs=input,
        outputs=out,
    )


model = build_model()

model.compile(
    optimizer=tf.keras.optimizers.Adam(),
    loss={""out1"": ""mse""},
    metrics={""out2"": ""mse""},
)

data = (
    # x
    [5, 5, 5, 5, 5, 5, 5, 5],
    # y
    {
        ""out1"": [5, 5, 5, 5, 5, 5, 5, 5],
        ""out2"": [5, 5, 5, 5, 5, 5, 5, 5],
    },
)


ds = tf.data.Dataset.from_tensor_slices(data)
ds = ds.batch(2)

model.fit(ds)
```


### Relevant log output

```shell
4/4 [==============================] - 0s 2ms/step - loss: 16.0000 - my_layer_loss: 16.0000 - my_layer_1_mse: 9.0000
```
</details>"
55786,Build C++ interface with CUDA on CentOS 8,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Build/Install

### Source

source

### Tensorflow Version

2.3.4, 2.4.4, 2.5.3, 2.6.3, 2.7.1, 2.8.0

### Custom Code

No

### OS Platform and Distribution

CentOS 8.5

### Mobile device

_No response_

### Python version

3.7.9

### Bazel version

3.1.0, 3.7.2, 4.2.1 depending on tf version

### GCC/Compiler version

gcc 8.5.0

### CUDA/cuDNN version

11.4 / 8

### GPU model and memory

A10

### Current Behaviour?

```shell
Compilation without CUDA works (at least for 2.3.4 and 2.8.0). But when trying to compile with CUDA, there are bazel dependency rule errors.
Trying to fix these errors by manipulating several BUILD.bazel files lead to a linker error.
```


### Standalone code to reproduce the issue

```shell
bazel --host_jvm_args=""-Djavax.net.ssl.trustStore=/usr/lib/jvm/jre-1.8.0/lib/security/cacerts"" build -c opt --verbose_failures --copt=-msse4.2 --copt=-mavx --copt=-mavx2 --copt=-mfma //tensorflow:libtensorflow_cc.so

bazel --host_jvm_args=""-Djavax.net.ssl.trustStore=/usr/lib/jvm/jre-1.8.0/lib/security/cacerts"" build -c opt --verbose_failures --copt=-msse4.2 --copt=-mavx --copt=-mavx2 --copt=-mfma --ignore_unsupported_sandboxing --genrule_strategy=standalone --spawn_strategy=standalone -s //tensorflow:libtensorflow_cc.so
```


### Relevant log output

```shell
# Dependency Error

SUBCOMMAND: # @local_config_cuda//cuda:cuda-include [action 'Executing genrule @local_config_cuda//cuda:cuda-include', configuration: 66f33c3c630191b83595d548feb993a615231a70b964ed630e032476da6f4e55, execution platform: @local_execution_config_platform//:platform]
(cd /root/.cache/bazel/_bazel_root/3d2810fb01b0f5b49453827b3eb9fb3e/execroot/org_tensorflow && \
  exec env - \
    CUDA_TOOLKIT_PATH=/opt/nvidia/cuda-11.4 \
    GCC_HOST_COMPILER_PATH=/bin/gcc \
    LD_LIBRARY_PATH=/opt/nvidia/cuda-11.4/lib64:/opt/nvidia/cuda-11.4/lib64/stubs:/opt/nvidia/cuda-11.4/lib/lib64:/opt/nvidia/cuda-11.4/targets/x86_64-linux/lib:/opt/nvidia/cuda-11.4/extras/CUPTI/lib64:/opt/openmpi/openmpi-4.0.5/lib:/opt/pmix/pmix-3.1.5/lib:/opt/python/python-3.7.9/lib:/usr/lib64:/opt/hdf5/hdf5-1.10.7/lib:/opt/libctl/libctl-4.5.0/lib:/opt/openblas/openblas-0.3.10/lib:/opt/fftw/fftw-3.3.8/lib:/opt/harminv/harminv-1.4.1/lib:/opt/nlopt/nlopt-2.6.2/lib64:/opt/gsl/gsl-2.6/lib:/opt/libgdsii/libgdsii-0.21/lib:/opt/mpb/mpb-1.10.0/lib:/opt/opencascade/opencascade-7.4.0/lib:/opt/ffmpeg/ffmpeg-4.3.1/lib:/opt/netcdf/netcdf-c-4.7.4-f-4.5.3/lib:/opt/scalapack/scalapack-2.1.0/lib:/opt/berkeleygw/berkeleygw-2.1/lib:/opt/pnfft/pnfft-1.0.7-alpha/lib:/opt/pfft/pfft-1.0.8-alpha/lib:/opt/libvdwxc/libvdwxc-0.4.0/lib:/opt/libxc/libxc-4.3.4/lib: \
    PATH=/opt/bazel/bazel-3.7.2/bin:/opt/bazel/bazel-4.2.1/bin:/opt/bazel/bazel-4.2.2/bin:/opt/nvidia/cuda-11.4/bin:/opt/openmpi/openmpi-4.0.5/bin:/opt/pmix/pmix-3.1.5/bin:/opt/python/python-3.7.9/bin:/opt/hdf5/hdf5-1.10.7/bin:/opt/libctl/libctl-4.5.0/bin:/opt/h5utils/h5utils-1.13.1/bin:/opt/ffmpeg/ffmpeg-4.3.1/bin:/opt/netcdf/netcdf-c-4.7.4-f-4.5.3/bin:/opt/berkeleygw/berkeleygw-2.1/bin:/opt/harminv/harminv-1.4.1/bin:/opt/mpb/mpb-1.10.0/bin:/opt/gmsh/gmsh-4.8.4/bin:/usr/share/Modules/bin:/sbin:/bin:/usr/sbin:/usr/bin:/opt/slurm/slurm-20.02.5/bin: \
    PYTHONPATH=/opt/python/python-3.7.9/lib: \
    PYTHON_BIN_PATH=/opt/python/python-3.7.9/bin/python3 \
    PYTHON_LIB_PATH=/opt/python/python-3.7.9/lib \
    TF2_BEHAVIOR=1 \
    TF_CUDA_COMPUTE_CAPABILITIES=7.0,7.5,8.6 \
    TF_CUDA_PATHS=/opt/nvidia/cuda-11.4 \
    TF_CUDA_VERSION=11 \
    TF_CUDNN_VERSION=8 \
    TF_NCCL_VERSION='' \
  /bin/bash -c 'source external/bazel_tools/tools/genrule/genrule-setup.sh; cp -rLf ""/opt/nvidia/cuda-11.4/targets/x86_64-linux/include/."" ""bazel-out/k8-opt/bin/external/local_config_cuda/cuda/cuda/include/"" ')
ERROR: /root/.cache/bazel/_bazel_root/3d2810fb01b0f5b49453827b3eb9fb3e/external/com_google_protobuf/BUILD:110:11: undeclared inclusion(s) in rule '@com_google_protobuf//:protobuf_lite':
this rule is missing dependency declarations for the following files included by 'com_google_protobuf/src/google/protobuf/io/zero_copy_stream.cc':
  '/include/c++/8/string'
  '/include/c++/8/x86_64-redhat-linux/bits/c++config.h'
  '/include/c++/8/x86_64-redhat-linux/bits/os_defines.h'
  '/include/c++/8/x86_64-redhat-linux/bits/cpu_defines.h'
  '/include/c++/8/bits/stringfwd.h'
  '/include/c++/8/bits/memoryfwd.h'
  '/include/c++/8/bits/char_traits.h'
  '/include/c++/8/bits/stl_algobase.h'
  '/include/c++/8/bits/functexcept.h'
  '/include/c++/8/bits/exception_defines.h'
  '/include/c++/8/bits/cpp_type_traits.h'
  '/include/c++/8/ext/type_traits.h'
  '/include/c++/8/ext/numeric_traits.h'
  '/include/c++/8/bits/stl_pair.h'
  '/include/c++/8/bits/move.h'
  '/include/c++/8/bits/concept_check.h'
  '/include/c++/8/type_traits'
  '/include/c++/8/bits/stl_iterator_base_types.h'
  '/include/c++/8/bits/stl_iterator_base_funcs.h'
  '/include/c++/8/debug/assertions.h'
  '/include/c++/8/bits/stl_iterator.h'
  '/include/c++/8/bits/ptr_traits.h'
  '/include/c++/8/debug/debug.h'
  '/include/c++/8/bits/predefined_ops.h'
  '/include/c++/8/bits/postypes.h'
  '/include/c++/8/cwchar'
  '/lib/gcc/x86_64-redhat-linux/8/include/stddef.h'
  '/lib/gcc/x86_64-redhat-linux/8/include/stdarg.h'
  '/include/c++/8/cstdint'
  '/lib/gcc/x86_64-redhat-linux/8/include/stdint.h'
  '/include/c++/8/bits/allocator.h'
  '/include/c++/8/x86_64-redhat-linux/bits/c++allocator.h'
  '/include/c++/8/ext/new_allocator.h'
  '/include/c++/8/new'
  '/include/c++/8/exception'
  '/include/c++/8/bits/exception.h'
  '/include/c++/8/bits/exception_ptr.h'
  '/include/c++/8/bits/cxxabi_init_exception.h'
  '/include/c++/8/typeinfo'
  '/include/c++/8/bits/hash_bytes.h'
  '/include/c++/8/bits/nested_exception.h'
  '/include/c++/8/bits/localefwd.h'
  '/include/c++/8/x86_64-redhat-linux/bits/c++locale.h'
  '/include/c++/8/clocale'
  '/include/c++/8/iosfwd'
  '/include/c++/8/cctype'
  '/include/c++/8/bits/ostream_insert.h'
  '/include/c++/8/bits/cxxabi_forced.h'
  '/include/c++/8/bits/stl_function.h'
  '/include/c++/8/backward/binders.h'
  '/include/c++/8/bits/range_access.h'
  '/include/c++/8/initializer_list'
  '/include/c++/8/bits/basic_string.h'
  '/include/c++/8/ext/atomicity.h'
  '/include/c++/8/x86_64-redhat-linux/bits/gthr.h'
  '/include/c++/8/x86_64-redhat-linux/bits/gthr-default.h'
  '/include/c++/8/x86_64-redhat-linux/bits/atomic_word.h'
  '/include/c++/8/ext/alloc_traits.h'
  '/include/c++/8/bits/alloc_traits.h'
  '/include/c++/8/ext/string_conversions.h'
  '/include/c++/8/cstdlib'
  '/include/c++/8/bits/std_abs.h'
  '/include/c++/8/cstdio'
  '/include/c++/8/cerrno'
  '/include/c++/8/bits/functional_hash.h'
  '/include/c++/8/bits/basic_string.tcc'
  '/include/c++/8/algorithm'
  '/include/c++/8/utility'
  '/include/c++/8/bits/stl_relops.h'
  '/include/c++/8/bits/stl_algo.h'
  '/include/c++/8/bits/algorithmfwd.h'
  '/include/c++/8/bits/stl_heap.h'
  '/include/c++/8/bits/stl_tempbuf.h'
  '/include/c++/8/bits/stl_construct.h'
  '/include/c++/8/bits/uniform_int_dist.h'
  '/include/c++/8/limits'
  '/include/c++/8/iostream'
  '/include/c++/8/ostream'
  '/include/c++/8/ios'
  '/include/c++/8/bits/ios_base.h'
  '/include/c++/8/bits/locale_classes.h'
  '/include/c++/8/bits/locale_classes.tcc'
  '/include/c++/8/system_error'
  '/include/c++/8/x86_64-redhat-linux/bits/error_constants.h'
  '/include/c++/8/stdexcept'
  '/include/c++/8/streambuf'
  '/include/c++/8/bits/streambuf.tcc'
  '/include/c++/8/bits/basic_ios.h'
  '/include/c++/8/bits/locale_facets.h'
  '/include/c++/8/cwctype'
  '/include/c++/8/x86_64-redhat-linux/bits/ctype_base.h'
  '/include/c++/8/bits/streambuf_iterator.h'
  '/include/c++/8/x86_64-redhat-linux/bits/ctype_inline.h'
  '/include/c++/8/bits/locale_facets.tcc'
  '/include/c++/8/bits/basic_ios.tcc'
  '/include/c++/8/bits/ostream.tcc'
  '/include/c++/8/istream'
  '/include/c++/8/bits/istream.tcc'
  '/include/c++/8/map'
  '/include/c++/8/bits/stl_tree.h'
  '/include/c++/8/ext/aligned_buffer.h'
  '/include/c++/8/bits/stl_map.h'
  '/include/c++/8/tuple'
  '/include/c++/8/array'
  '/include/c++/8/bits/uses_allocator.h'
  '/include/c++/8/bits/invoke.h'
  '/include/c++/8/bits/stl_multimap.h'
  '/include/c++/8/memory'
  '/include/c++/8/bits/stl_uninitialized.h'
  '/include/c++/8/bits/stl_raw_storage_iter.h'
  '/include/c++/8/ext/concurrence.h'
  '/include/c++/8/bits/unique_ptr.h'
  '/include/c++/8/bits/shared_ptr.h'
  '/include/c++/8/bits/shared_ptr_base.h'
  '/include/c++/8/bits/allocated_ptr.h'
  '/include/c++/8/bits/refwrap.h'
  '/include/c++/8/bits/shared_ptr_atomic.h'
  '/include/c++/8/bits/atomic_base.h'
  '/include/c++/8/bits/atomic_lockfree_defines.h'
  '/include/c++/8/backward/auto_ptr.h'
  '/include/c++/8/set'
  '/include/c++/8/bits/stl_set.h'
  '/include/c++/8/bits/stl_multiset.h'
  '/include/c++/8/vector'
  '/include/c++/8/bits/stl_vector.h'
  '/include/c++/8/bits/stl_bvector.h'
  '/include/c++/8/bits/vector.tcc'
  '/include/c++/8/stdlib.h'
  '/include/c++/8/cstddef'
  '/lib/gcc/x86_64-redhat-linux/8/include/limits.h'
  '/lib/gcc/x86_64-redhat-linux/8/include/syslimits.h'
Target //tensorflow:libtensorflow_cc.so failed to build
INFO: Elapsed time: 33.237s, Critical Path: 3.55s
INFO: 103 processes: 92 internal, 11 local.
FAILED: Build did NOT complete successfully


# Linker Error

ERROR: /root/.cache/bazel/_bazel_root/42e04b8ffa2c97bc3b6715d4727a1211/external/com_google_protobuf/BUILD:416:10: Linking external/com_google_protobuf/protoc failed: (Exit 1): crosstool_wrapper_driver_is_not_gcc failed: error executing command 
  (cd /root/.cache/bazel/_bazel_root/42e04b8ffa2c97bc3b6715d4727a1211/execroot/org_tensorflow && \
  exec env - \
    CUDA_TOOLKIT_PATH=/opt/nvidia/cuda-11.4 \
    GCC_HOST_COMPILER_PATH=/bin/gcc \
    LD_LIBRARY_PATH=/opt/nvidia/cuda-11.4/lib64:/opt/nvidia/cuda-11.4/lib64/stubs:/opt/nvidia/cuda-11.4/lib/lib64:/opt/nvidia/cuda-11.4/targets/x86_64-linux/lib:/opt/nvidia/cuda-11.4/extras/CUPTI/lib64:/opt/openmpi/openmpi-4.0.5/lib:/opt/pmix/pmix-3.1.5/lib:/opt/python/python-3.7.9/lib:/usr/lib64:/opt/hdf5/hdf5-1.10.7/lib:/opt/libctl/libctl-4.5.0/lib:/opt/openblas/openblas-0.3.10/lib:/opt/fftw/fftw-3.3.8/lib:/opt/harminv/harminv-1.4.1/lib:/opt/nlopt/nlopt-2.6.2/lib64:/opt/gsl/gsl-2.6/lib:/opt/libgdsii/libgdsii-0.21/lib:/opt/mpb/mpb-1.10.0/lib:/opt/opencascade/opencascade-7.4.0/lib:/opt/ffmpeg/ffmpeg-4.3.1/lib:/opt/netcdf/netcdf-c-4.7.4-f-4.5.3/lib:/opt/scalapack/scalapack-2.1.0/lib:/opt/berkeleygw/berkeleygw-2.1/lib:/opt/pnfft/pnfft-1.0.7-alpha/lib:/opt/pfft/pfft-1.0.8-alpha/lib:/opt/libvdwxc/libvdwxc-0.4.0/lib:/opt/libxc/libxc-4.3.4/lib: \
    PATH=/opt/bazel/bazel-4.2.1/bin:/opt/bazel/bazel-4.2.2/bin:/opt/nvidia/cuda-11.4/bin:/opt/openmpi/openmpi-4.0.5/bin:/opt/pmix/pmix-3.1.5/bin:/opt/python/python-3.7.9/bin:/opt/hdf5/hdf5-1.10.7/bin:/opt/libctl/libctl-4.5.0/bin:/opt/h5utils/h5utils-1.13.1/bin:/opt/ffmpeg/ffmpeg-4.3.1/bin:/opt/netcdf/netcdf-c-4.7.4-f-4.5.3/bin:/opt/berkeleygw/berkeleygw-2.1/bin:/opt/harminv/harminv-1.4.1/bin:/opt/mpb/mpb-1.10.0/bin:/opt/gmsh/gmsh-4.8.4/bin:/usr/share/Modules/bin:/sbin:/bin:/usr/sbin:/usr/bin:/opt/slurm/slurm-20.02.5/bin: \
    PWD=/proc/self/cwd \
    PYTHONPATH=/opt/python/python-3.7.9/lib: \
    PYTHON_BIN_PATH=/opt/python/python-3.7.9/bin/python3 \
    PYTHON_LIB_PATH=/opt/python/python-3.7.9/lib \
    TF2_BEHAVIOR=1 \
    TF_CUDA_COMPUTE_CAPABILITIES=7.0,7.5,8.6 \
    TF_CUDA_PATHS=/opt/nvidia/cuda-11.4 \
    TF_CUDA_VERSION=11 \
    TF_CUDNN_VERSION=8 \
    TF_NCCL_VERSION='' \
  external/local_config_cuda/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc @bazel-out/k8-opt/bin/external/com_google_protobuf/protoc-2.params)
Execution platform: @local_execution_config_platform//:platform
/bin/../lib/gcc/x86_64-redhat-linux/8/../../../../lib64/Scrt1.o: In function `_start':
(.text+0x24): undefined reference to `main'
collect2: error: ld returned 1 exit status
Target //tensorflow:libtensorflow_cc.so failed to build
INFO: Elapsed time: 4.644s, Critical Path: 0.55s
INFO: 5 processes: 5 internal.
FAILED: Build did NOT complete successfully
```
</details>"
55785,tflite quantization to fp16 only quantized input,"Hi, I have a model which is simply 3 layer fully connnected layers (the first layer will have resample on weights)

but I got a tflite graph that only quantized input:

![image](https://user-images.githubusercontent.com/21303438/165697855-63a99f9a-5de6-4446-a28a-b185bf3d29c7.png)

it only quantized the weights, but all other operations were dequantized and calculate in float32 way.

Why? I want the whole operations inference in fp16 since am runing on ARMv8.2 above CPU!"
55784,fp32 and mixed precision models,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Performance

### Source

source

### Tensorflow Version

tf 2.4

### Custom Code

No

### OS Platform and Distribution

_No response_

### Mobile device

_No response_

### Python version

3.6

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

cuda 11.2/cuDNN 8.0

### GPU model and memory

_No response_

### Current Behaviour?

```shell
training mixed-precision models and single precision models with the tf2.4, cudnn 8 and cuda11.2 versions in V100 and A100 GPUs. while training the mixed-precision model it is showing only 16% improvement compared to single precision models. while testing the mixed-precision model showing no improvement compared to single precision model. Mixed precision weights are saving in tf.Variable(dtype=float32) instead of tf.AutoCastVariable. Is this reason for no improvement in inference? do we have support for mixed-precision using tensorflow2.4? I saw many git issues regarding mixed-precision without any conclusions.
```


### Standalone code to reproduce the issue

```shell
-
```


### Relevant log output

```shell
-
```
</details>"
55782,Documentation unclear for parameter `central_fraction` in `tf.image.central_crop`,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Documentation Feature Request

### Source

binary

### Tensorflow Version

tf 2.8

### Custom Code

No

### OS Platform and Distribution

Linux Ubuntu 20.04

### Mobile device

_No response_

### Python version

3.9

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
The function `tf.image.central_crop` takes a parameter `central_fraction`. I would have expected that a larger `central_fraction` would mean that more of the image is kept. However, looking at [the code](https://github.com/tensorflow/tensorflow/blob/v2.8.0/tensorflow/python/ops/image_ops_impl.py#L844-L986=) my understanding is that a larger number means that more is cropped out. e.g.

bbox_h_start = int((img_hd - img_hd * central_fraction_static) / 2)
```

Changing the example from the current `central_fraction=0.5` to `central_fraction=0.25` would help clarify this point.
https://github.com/tensorflow/tensorflow/issues/29334
```


### Standalone code to reproduce the issue

```shell
https://www.tensorflow.org/api_docs/python/tf/image/central_crop
```


### Relevant log output

_No response_</details>"
55778,Quantization models ,"I get exactly the same timing for inference using fp16 and fp32 using GPU, shouldn't fp16 give faster computation? And why are the type of the weights in fp32 even if the file-size is different?

int8 does also take longer time to invoke than fp32, is it because of the dequantize quantize implementation for int8 written in the documentation?

(All inherit from the same trained model) "
55765,mixed precision support with tensorflow2.4,"Problem:  Unable to produce mixed-precision results with TensorFlow 2.4
1) Done mixed-precision set up with cudnn8, Cuda 11 and TensorFlow 2.4 version in A100 and V100 GPU.
    referred following sites for this (https://towardsdatascience.com/whats-new-in-tensorflow-2-4-fe7aee9ac977),(https://developer.nvidia.com/blog/cuda-11-features-revealed/) and many other sites.

2) Followed the following tutorial (https://www.tensorflow.org/guide/mixed_precision) for mixed-precision training.
mixed_precision.py code:
```
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras import mixed_precision

policy = mixed_precision.Policy('mixed_float16')
mixed_precision.set_global_policy(policy)

print('Compute dtype: %s' % policy.compute_dtype)
print('Variable dtype: %s' % policy.variable_dtype)
inputs = keras.Input(shape=(4096,), name='digits')
if tf.config.list_physical_devices('GPU'):
  print('The model will run with 4096 units on a GPU')
  num_units = 4096
else:
  # Use fewer units on CPUs so the model finishes in a reasonable amount of time
  print('The model will run with 64 units on a CPU')
  num_units = 64


dense1 = layers.Dense(num_units, activation='relu', name='dense_1')
x = dense1(inputs)
dense2 = layers.Dense(num_units, activation='relu', name='dense_2')
x = dense2(x)
dense3 = layers.Dense(num_units, activation='relu', name='dense_3')
x = dense3(x)
dense4 = layers.Dense(num_units, activation='relu', name='dense_4')
x = dense4(x)
dense5 = layers.Dense(num_units, activation='relu', name='dense_5')
x=dense5(x)
x = layers.Dense(16, name='dense_logits')(x)
outputs = layers.Activation('softmax', dtype='float32', name='predictions')(x)
print('Outputs dtype: %s' % outputs.dtype.name)
model = keras.Model(inputs=inputs, outputs=outputs)
print(model.summary())

optimizer=keras.optimizers.RMSprop()
optimizer=tf.keras.mixed_precision.LossScaleOptimizer(optimizer)
loss_object=tf.keras.losses.SparseCategoricalCrossentropy()
@tf.function
def train_step(x,y):
  with tf.GradientTape() as tape:
    predictions=model(x)
    loss=loss_object(y,predictions)
    scaled_loss=optimizer.get_scaled_loss(loss)
  scaled_gradients=tape.gradient(scaled_loss,model.trainable_variables)
  gradients=optimizer.get_unscaled_gradients(scaled_gradients)
  optimizer.apply_gradients(zip(gradients,model.trainable_variables))
  return loss
@tf.function
def test_step(x):
  return model(x,training=False)
x_train=tf.random.normal([1000000,num_units],dtype=tf.float32)
y_train=tf.random.uniform(shape=(1000000,),minval=0,maxval=15,dtype=tf.int64)
x_test=x_train
y_test=y_train
train_dataset=tf.data.Dataset.from_tensor_slices((x_train,y_train)).batch(512)
test_dataset = tf.data.Dataset.from_tensor_slices((x_test,y_test)).batch(512)
import time
start_time=time.perf_counter()
for epoch in range(10):
  epoch_loss_avg=tf.keras.metrics.Mean()
  test_accuracy=tf.keras.metrics.SparseCategoricalCrossentropy(name='test_accuracy')
  for x,y in train_dataset:
    loss=train_step(x,y)
    epoch_loss_avg(loss)
print(""---- Training time in seconds %s --""%(time.perf_counter()-start_time))
start_time=time.perf_counter()
for x,y in test_dataset:
  test_accuracy=tf.keras.metrics.SparseCategoricalCrossentropy(name='test_accuracy')
  predictions=test_step(x)
  test_accuracy.update_state(y,predictions)
print(""---- Testing time in seconds %s --""%(time.perf_counter()-start_time))
```



fp32.py code
```
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras import mixed_precision

inputs = keras.Input(shape=(4096,), name='digits')
if tf.config.list_physical_devices('GPU'):
  print('The model will run with 4096 units on a GPU')
  num_units = 4096
else:
  # Use fewer units on CPUs so the model finishes in a reasonable amount of time
  print('The model will run with 64 units on a CPU')
  num_units = 64


dense1 = layers.Dense(num_units, activation='relu', name='dense_1')
x = dense1(inputs)
dense2 = layers.Dense(num_units, activation='relu', name='dense_2')
x = dense2(x)
dense3 = layers.Dense(num_units, activation='relu', name='dense_3')
x = dense3(x)
dense4 = layers.Dense(num_units, activation='relu', name='dense_4')
x = dense4(x)
dense5 = layers.Dense(num_units, activation='relu', name='dense_5')
x=dense5(x)
x = layers.Dense(16, name='dense_logits')(x)
outputs = layers.Activation('softmax', dtype='float32', name='predictions')(x)
print('Outputs dtype: %s' % outputs.dtype.name)
model = keras.Model(inputs=inputs, outputs=outputs)
print(model.summary())

optimizer=keras.optimizers.RMSprop()

loss_object=tf.keras.losses.SparseCategoricalCrossentropy()
@tf.function
def train_step(x,y):
  with tf.GradientTape() as tape:
    predictions=model(x)
    loss=loss_object(y,predictions)
  gradients=tape.gradient(loss,model.trainable_variables)
  optimizer.apply_gradients(zip(gradients,model.trainable_variables))
  return loss
@tf.function
def test_step(x):
  return model(x,training=False)
x_train=tf.random.normal([1000000,num_units],dtype=tf.float32)
y_train=tf.random.uniform(shape=(1000000,),minval=0,maxval=15,dtype=tf.int64)
x_test=x_train
y_test=y_train
train_dataset=tf.data.Dataset.from_tensor_slices((x_train,y_train)).batch(512)
test_dataset = tf.data.Dataset.from_tensor_slices((x_test,y_test)).batch(512)
import time
start_time=time.perf_counter()
for epoch in range(10):
  epoch_loss_avg=tf.keras.metrics.Mean()
  test_accuracy=tf.keras.metrics.SparseCategoricalCrossentropy(name='test_accuracy')
  for x,y in train_dataset:
    loss=train_step(x,y)
    epoch_loss_avg(loss)
print(""---- Training time in seconds %s --""%(time.perf_counter()-start_time))
start_time=time.perf_counter()
for x,y in test_dataset:
  test_accuracy=tf.keras.metrics.SparseCategoricalCrossentropy(name='test_accuracy')
  predictions=test_step(x)
  test_accuracy.update_state(y,predictions)
print(""---- Testing time in seconds %s --""%(time.perf_counter()-start_time))
```

Questions:
(I)  do we have tensorflow2.4 support for mixed-precision? I saw many issues related to it. But not found the proper solution.
(ii) In above mixed_precision code and fp32 code both are running approximately the same time for training and inference in A100 and V100 GPU. Did I made any mistake?"
55764,Can tflite CoreML delegate add ELU activation support? (with fp16 as well)_,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Support

### Source

source

### Tensorflow Version

tf2.8

### Custom Code

No

### OS Platform and Distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
A bug happened!
Can tflite CoreML delegate add ELU activation support? (with fp16 as well)_
```


### Standalone code to reproduce the issue

```shell
Can tflite CoreML delegate add ELU activation support? (with fp16 as well)_
```


### Relevant log output

```shell
Can tflite CoreML delegate add ELU activation support? (with fp16 as well)_
```
</details>"
55763,How to load TF1 `.ckpt` weights into keras model?,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Others

### Source

binary

### Tensorflow Version

1.14

### Custom Code

Yes

### OS Platform and Distribution

macOS Monterey 12.3.1

### Mobile device

_No response_

### Python version

3.7

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
The code below creates a TF1 model, saves weights as `.ckpt`, creates an identical keras model. The objective is to load the saved weights from TF1 somehow using `tf.keras.Model.load_weights()` or whatever works.
```


### Standalone code to reproduce the issue

```python
  import os
  import tempfile
  import uuid
  from pathlib import Path
  
  import tensorflow as tf
  from tensorflow.keras import Input, Model
  from tensorflow.keras.layers import Conv2D, MaxPooling2D
  
  
  def create_tf1_model(saver=None, tf1_weights=None):
      x0 = tf.placeholder(tf.float32, shape=[None, None, None, 3])
      x = tf.contrib.slim.conv2d(
          x0,
          32,
          (7, 7),
          stride=(2, 2),
          padding='same',
      )
      x = tf.contrib.slim.conv2d(
          x,
          64,
          (3, 3),
          stride=(1, 1),
      )
      x = tf.contrib.slim.max_pool2d(x, [3, 3], stride=2)
      if saver and tf1_weights:
          ckpt_state = tf.train.get_checkpoint_state(tf1_weights)
          model_path = os.path.join(
              tf1_weights, os.path.basename(ckpt_state.model_checkpoint_path)
          )
          saver.restore(sess, model_path)
      return x
  
  
  def create_keras_model():
      x0 = Input((None, None, 3))
      x = Conv2D(32, (7, 7), (2, 2), 'same')(x0)
      x = Conv2D(64, (3, 3))(x)
      x = MaxPooling2D((3, 3), (2, 2))(x)
      return Model(x0, x)
  
  
  if __name__ == '__main__':
      global_step = tf.get_variable(
          'global_step', [], initializer=tf.constant_initializer(0), trainable=False
      )
      variable_averages = tf.train.ExponentialMovingAverage(0.997, global_step)
      _saver = tf.train.Saver(variable_averages.variables_to_restore())
      sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True))
      sess.run(tf.global_variables_initializer())
      tmpdir = tempfile.mkdtemp()
      create_tf1_model()
      weights_path = Path(tmpdir) / f'{uuid.uuid4()}.ckpt'
      _saver.save(sess, weights_path.as_posix())
      create_tf1_model(_saver, weights_path.parent.as_posix())
      keras_model = create_keras_model()
      keras_model.load_weights(weights_path.as_posix())  # code fails here
```


### Relevant log output

```shell
/Users/emadboctor/Desktop/ocr/eastenv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([(""qint8"", np.int8, 1)])
/Users/emadboctor/Desktop/ocr/eastenv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([(""quint8"", np.uint8, 1)])
/Users/emadboctor/Desktop/ocr/eastenv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([(""qint16"", np.int16, 1)])
/Users/emadboctor/Desktop/ocr/eastenv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([(""quint16"", np.uint16, 1)])
/Users/emadboctor/Desktop/ocr/eastenv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([(""qint32"", np.int32, 1)])
/Users/emadboctor/Desktop/ocr/eastenv/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([(""resource"", np.ubyte, 1)])
/Users/emadboctor/Desktop/ocr/eastenv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([(""qint8"", np.int8, 1)])
/Users/emadboctor/Desktop/ocr/eastenv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([(""quint8"", np.uint8, 1)])
/Users/emadboctor/Desktop/ocr/eastenv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([(""qint16"", np.int16, 1)])
/Users/emadboctor/Desktop/ocr/eastenv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([(""quint16"", np.uint16, 1)])
/Users/emadboctor/Desktop/ocr/eastenv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([(""qint32"", np.int32, 1)])
/Users/emadboctor/Desktop/ocr/eastenv/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([(""resource"", np.ubyte, 1)])
WARNING:tensorflow:From /Users/emadboctor/Library/Application Support/JetBrains/PyCharm2022.1/scratches/scratch_1.py:45: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.

WARNING:tensorflow:From /Users/emadboctor/Library/Application Support/JetBrains/PyCharm2022.1/scratches/scratch_1.py:49: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

WARNING:tensorflow:From /Users/emadboctor/Library/Application Support/JetBrains/PyCharm2022.1/scratches/scratch_1.py:50: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

WARNING:tensorflow:From /Users/emadboctor/Library/Application Support/JetBrains/PyCharm2022.1/scratches/scratch_1.py:50: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.

2022-04-27 08:21:58.963602: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
WARNING:tensorflow:From /Users/emadboctor/Library/Application Support/JetBrains/PyCharm2022.1/scratches/scratch_1.py:51: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.

WARNING:tensorflow:From /Users/emadboctor/Library/Application Support/JetBrains/PyCharm2022.1/scratches/scratch_1.py:12: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:From /Users/emadboctor/Desktop/ocr/eastenv/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to check for files with this prefix.
WARNING:tensorflow:From /Users/emadboctor/Desktop/ocr/eastenv/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Call initializer instance with the dtype argument instead of passing it to the constructor
WARNING:tensorflow:From /Users/emadboctor/Desktop/ocr/eastenv/lib/python3.7/site-packages/tensorflow/python/training/tracking/util.py:1200: NameBasedSaverStatus.__init__ (from tensorflow.python.training.tracking.util) is deprecated and will be removed in a future version.
Instructions for updating:
Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future.
Traceback (most recent call last):
  File ""/Users/emadboctor/Library/Application Support/JetBrains/PyCharm2022.1/scratches/scratch_1.py"", line 58, in <module>
    keras_model.load_weights(weights_path.as_posix())  # code fails here
  File ""/Users/emadboctor/Desktop/ocr/eastenv/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py"", line 162, in load_weights
    return super(Model, self).load_weights(filepath, by_name)
  File ""/Users/emadboctor/Desktop/ocr/eastenv/lib/python3.7/site-packages/tensorflow/python/keras/engine/network.py"", line 1400, in load_weights
    trackable_utils.streaming_restore(status=status, session=session)
  File ""/Users/emadboctor/Desktop/ocr/eastenv/lib/python3.7/site-packages/tensorflow/python/training/tracking/util.py"", line 619, in streaming_restore
    ""Streaming restore not supported from name-based checkpoints when ""
NotImplementedError: Streaming restore not supported from name-based checkpoints when graph building. File a feature request if this limitation bothers you. As a workaround, consider either using tf.train.Checkpoint to load name-based checkpoints or enabling eager execution.
```
</details>"
55757,TensorFlow does not use NVLink on Windows,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

tf 2.8

### Custom Code

No

### OS Platform and Distribution

Windows 10

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

470

### GPU model and memory

Titan RTX ×2 NVLink

### Current Behaviour?

```shell
TensorFlow does not use NVLink on Windows. Seems it is happens on all versions of TensorFlow 2.X
```


### Standalone code to reproduce the issue

It is not possible to provide a colab since it has to be tested on Windows.
However, by running the following simple code in TensorFlow 2.4 (Windows) on GPUs with NVLink, you can find there are no inter-connections between GPUs. (N instead of Y in matrix). 

I don't know how to see if the NVLink is enabled on TensorFlow 2.8, because the inter-connection matrix is removed.


```shell

import tensorflow as tf

tf.constant(1) + 1
```
"
55756,"when path contain '[' and ']'  character, tf.data.experimental.load return an empty dataset","<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

tf 2.8

### Custom Code

Yes

### OS Platform and Distribution

Linux Ubuntu 20.04

### Mobile device

_No response_

### Python version

3.9

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

11.6

### GPU model and memory

_No response_

### Current Behaviour?

```shell
when I load a dataset use tf.data.experimental.load , I get an empty dataset, but the dataset actually is not empty, the dataset was saved by tf.data.experimental.save correctly .The save path contains '[' and ']' character. If I remove '[' and ']' character , tf.data.experimental.load works fine.
```


### Standalone code to reproduce the issue

```shell
import tensorflow as tf

tf.data.experimental.load('datasets/build/train[m]_data')
```


### Relevant log output

_No response_</details>"
55755,Undefined reference to function FreezeSavedModel with C++ API,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Build/Install

### Source

source

### Tensorflow Version

tf 2.6

### Custom Code

Yes

### OS Platform and Distribution

Ubuntu 20.04

### Mobile device

_No response_

### Python version

3.8.10

### Bazel version

3.7.2

### GCC/Compiler version

9.4.0

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
Hi,

I have successfully build tf 2.6 with bazel on my ubuntu and I wanted to do a CNN using the C++ API. Without GPU for now.

I have found example on internet and used it to try it out.
I have tried basic stuff like ClientSession and they are all working fine. Now, I wanted to save a trained model. For this, I use FreezeSavedModel function. 
My problem is when I compile the code on CLion. I get an ""undefined reference"" error to FreezeSavedModel.

From my understanding, freeze the model and then use WriteBinaryProto is the way to save a model that has been train. Is it the only way ? If not, i would like suggestions to try it. If it is, then I really need this to work because otherwise it would be useless to have everything else.

I have the libtensorflow.so, libtensorflow_cc.so and libtensorflow_framework.so and all the headers include. 
I also have libprotobuf.so and libprotoc.so builded and included because I have read somewhere that it might be the issue but I see no difference with or without those libs. Seems it simply needs the headers... I don't know.

For the record, I have the same issue on Windows (I have read about 64k symbols in dll and stuff like that but if it also happends on ubuntu, then what ? haha)


Thanks for your help, it will be greatly appreciated.. I have search a lot but did not found much topic on this one.
```


### Standalone code to reproduce the issue

```shell
The header file :

#include <iostream>
#include <map>
#include <fstream>
#include ""tensorflow/cc/client/client_session.h""
#include ""tensorflow/cc/ops/standard_ops.h""
#include ""tensorflow/cc/framework/gradients.h""
#include ""tensorflow/core/framework/tensor.h""
#include ""tensorflow/core/public/session.h""
#include ""tensorflow/core/lib/io/path.h""
#include ""tensorflow/core/summary/summary_file_writer.h""
#include ""tensorflow/cc/tools/freeze_saved_model.h""
#include ""tensorflow/cc/ops/image_ops.h""

using namespace std;
using namespace tensorflow;
using namespace tensorflow::ops;

class CatDogCNN
{
private:
    Scope i_root; //graph for loading images into tensors
    const int image_side; //assuming quare picture
    const int image_channels; //RGB
    //load image vars
    Output file_name_var;
    Output image_tensor_var;
    //data augmentation
    Scope a_root;
    Output aug_tensor_input;
    Output aug_tensor_output;
    //training and validating the CNN
    Scope t_root; //graph
    unique_ptr<ClientSession> t_session;
    unique_ptr<Session> f_session;
    //CNN vars
    Output input_batch_var;
    string input_name = ""input"";
    Output input_labels_var;
    Output drop_rate_var; //use real drop rate in training and 1 in validating
    string drop_rate_name = ""drop_rate"";
    Output skip_drop_var; //use 0 in trainig and 1 in validating
    string skip_drop_name = ""skip_drop"";
    Output out_classification;
    string out_name = ""output_classes"";
    Output logits;
    //Network maps
    map<string, Output> m_vars;
    map<string, TensorShape> m_shapes;
    map<string, Output> m_assigns;
    //Loss variables
    vector<Output> v_weights_biases;
    vector<Operation> v_out_grads;
    Output out_loss_var;
    InputList MakeTransforms(int batch_size, Input a0, Input a1, Input a2, Input b0, Input b1, Input b2);
public:
    CatDogCNN(int side, int channels) :i_root(Scope::NewRootScope()), t_root(Scope::NewRootScope()), a_root(Scope::NewRootScope()), image_side(side), image_channels(channels) {}
    Status CreateGraphForImage(bool unstack);
    Status ReadTensorFromImageFile(string& file_name, Tensor& outTensor);
    Status ReadFileTensors(string& folder_name, vector<pair<string, float>> v_folder_label, vector<pair<Tensor, float>>& file_tensors);
    Status ReadBatches(string& folder_name, vector<pair<string, float>> v_folder_label, int batch_size, vector<Tensor>& image_batches, vector<Tensor>& label_batches);
    Input XavierInit(Scope scope, int in_chan, int out_chan, int filter_side = 0);
    Input AddConvLayer(string idx, Scope scope, int in_channels, int out_channels, int filter_side, Input input);
    Input AddDenseLayer(string idx, Scope scope, int in_units, int out_units, bool bActivation, Input input);
    Status CreateGraphForCNN(int filter_side);
    Status CreateOptimizationGraph(float learning_rate);
    Status Initialize();
    Status TrainCNN(Tensor& image_batch, Tensor& label_batch, vector<float>& results, float& loss);
    Status ValidateCNN(Tensor& image_batch, Tensor& label_batch, vector<float>& results);
    Status Predict(Tensor& image, int& result);
    Status FreezeSave(string& file_name);
    Status LoadSavedModel(string& file_name);
    Status PredictFromFrozen(Tensor& image, int& result);
    Status CreateAugmentGraph(int batch_size, int image_side, float flip_chances, float max_angles, float sscale_shift_factor);
    Status RandomAugmentBatch(Tensor& image_batch, Tensor& augmented_batch);
    Status WriteBatchToImageFiles(Tensor& image_batch, string folder_name, string image_name);
};


The cpp file :

#include ""CatDogCNN.h""
using namespace std;
using namespace tensorflow;
using namespace tensorflow::ops;

Status CatDogCNN::CreateGraphForImage(bool unstack)
{
    file_name_var = Placeholder(i_root.WithOpName(""input""), DT_STRING);
    auto file_reader = ReadFile(i_root.WithOpName(""file_readr""), file_name_var);

    auto image_reader = DecodeJpeg(i_root.WithOpName(""jpeg_reader""), file_reader, DecodeJpeg::Channels(image_channels));

    auto float_caster = Cast(i_root.WithOpName(""float_caster""), image_reader, DT_FLOAT);
    auto dims_expander = ExpandDims(i_root.WithOpName(""dim""), float_caster, 0);
    auto resized = ResizeBilinear(i_root.WithOpName(""size""), dims_expander, Const(i_root, { image_side, image_side }));
    auto div = Div(i_root.WithOpName(""normalized""), resized, { 255.f });
    if (unstack)
    {
        auto output_list = Unstack(i_root.WithOpName(""fold""), div, 1);
        image_tensor_var = output_list.output[0];
    }
    else
        image_tensor_var = div;
    return i_root.status();
}

Status CatDogCNN::ReadTensorFromImageFile(string& file_name, Tensor& outTensor)
{
    if (!i_root.ok())
        return i_root.status();
    if (!absl::EndsWith(file_name, "".jpg"") && !absl::EndsWith(file_name, "".jpeg""))
    {
        return errors::InvalidArgument(""Image must be jpeg encoded"");
    }
    vector<Tensor> out_tensors;
    ClientSession session(i_root);
    TF_CHECK_OK(session.Run({ {file_name_var, file_name} }, { image_tensor_var }, &out_tensors));
    outTensor = out_tensors[0]; // shallow copy
    return Status::OK();
}

Status CatDogCNN::ReadFileTensors(string& base_folder_name, vector<pair<string, float>> v_folder_label, vector<pair<Tensor, float>>& file_tensors)
{
    //validate the folder
    Env* penv = Env::Default();
    TF_RETURN_IF_ERROR(penv->IsDirectory(base_folder_name));
    //get the files
    bool b_shuffle = false;
    for (auto p : v_folder_label)
    {
        string folder_name = io::JoinPath(base_folder_name, p.first);
        TF_RETURN_IF_ERROR(penv->IsDirectory(folder_name));
        vector<string> file_names;
        TF_RETURN_IF_ERROR(penv->GetChildren(folder_name, &file_names));
        for (string file : file_names)
        {
            string full_path = io::JoinPath(folder_name, file);
            Tensor i_tensor;
            TF_RETURN_IF_ERROR(ReadTensorFromImageFile(full_path, i_tensor));
            size_t s = file_tensors.size();
            if (b_shuffle)
            {
                //suffle the images
                int i = rand() % s;
                file_tensors.emplace(file_tensors.begin() + i, make_pair(i_tensor, p.second));
            }
            else
                file_tensors.push_back(make_pair(i_tensor, p.second));
        }
        b_shuffle = true;
    }
    return Status::OK();
}

Status CatDogCNN::ReadBatches(string& base_folder_name, vector<pair<string, float>> v_folder_label, int batch_size, vector<Tensor>& image_batches, vector<Tensor>& label_batches)
{
    vector<pair<Tensor, float>> all_files_tensors;
    TF_RETURN_IF_ERROR(ReadFileTensors(base_folder_name, v_folder_label, all_files_tensors));
    auto start_i = all_files_tensors.begin();
    auto end_i = all_files_tensors.begin() + batch_size;
    size_t batches = all_files_tensors.size() / batch_size;
    if (batches * batch_size < all_files_tensors.size())
        batches++;
    for (int b = 0; b < batches; b++)
    {
        if (end_i > all_files_tensors.end())
            end_i = all_files_tensors.end();
        vector<pair<Tensor, float>> one_batch(start_i, end_i);
        //need to break the pairs
        vector<Input> one_batch_image, one_batch_lbl;
        for (auto p : one_batch)
        {
            one_batch_image.push_back(Input(p.first));
            Tensor t(DT_FLOAT, TensorShape({ 1 }));
            t.scalar<float>()(0) = p.second;
            one_batch_lbl.push_back(Input(t));
        }
        InputList one_batch_inputs(one_batch_image);
        InputList one_batch_labels(one_batch_lbl);
        Scope root = Scope::NewRootScope();
        auto stacked_images = Stack(root, one_batch_inputs);
        auto stacked_labels = Stack(root, one_batch_labels);
        TF_CHECK_OK(root.status());
        ClientSession session(root);
        vector<Tensor> out_tensors;
        TF_CHECK_OK(session.Run({}, { stacked_images, stacked_labels }, &out_tensors));
        image_batches.push_back(out_tensors[0]);
        label_batches.push_back(out_tensors[1]);
        start_i = end_i;
        if (start_i == all_files_tensors.end())
            break;
        end_i = start_i + batch_size;
    }
    return Status::OK();
}

Input CatDogCNN::XavierInit(Scope scope, int in_chan, int out_chan, int filter_side)
{
    float std;
    Tensor t;
    if (filter_side == 0)
    { //Dense
        std = sqrt(6.f / (in_chan + out_chan));
        Tensor ts(DT_INT64, { 2 });
        auto v = ts.vec<int64>();
        v(0) = in_chan;
        v(1) = out_chan;
        t = ts;
    }
    else
    { //Conv
        std = sqrt(6.f / (filter_side * filter_side * (in_chan + out_chan)));
        Tensor ts(DT_INT64, { 4 });
        auto v = ts.vec<int64>();
        v(0) = filter_side;
        v(1) = filter_side;
        v(2) = in_chan;
        v(3) = out_chan;
        t = ts;
    }
    auto rand = RandomUniform(scope, t, DT_FLOAT);
    return Multiply(scope, Sub(scope, rand, 0.5f), std * 2.f);
}

Input CatDogCNN::AddConvLayer(string idx, Scope scope, int in_channels, int out_channels, int filter_side, Input input)
{
    TensorShape sp({ filter_side, filter_side, in_channels, out_channels });
    m_vars[""W"" + idx] = Variable(scope.WithOpName(""W""), sp, DT_FLOAT);
    m_shapes[""W"" + idx] = sp;
    m_assigns[""W"" + idx + ""_assign""] = Assign(scope.WithOpName(""W_assign""), m_vars[""W"" + idx], XavierInit(scope, in_channels, out_channels, filter_side));
    sp = { out_channels };
    m_vars[""B"" + idx] = Variable(scope.WithOpName(""B""), sp, DT_FLOAT);
    m_shapes[""B"" + idx] = sp;
    m_assigns[""B"" + idx + ""_assign""] = Assign(scope.WithOpName(""B_assign""), m_vars[""B"" + idx], Input::Initializer(0.f, sp));
    auto conv = Conv2D(scope.WithOpName(""Conv""), input, m_vars[""W"" + idx], { 1, 1, 1, 1 }, ""SAME"");
    auto bias = BiasAdd(scope.WithOpName(""Bias""), conv, m_vars[""B"" + idx]);
    auto relu = Relu(scope.WithOpName(""Relu""), bias);
    return MaxPool(scope.WithOpName(""Pool""), relu, { 1, 2, 2, 1 }, { 1, 2, 2, 1 }, ""SAME"");
}

Input CatDogCNN::AddDenseLayer(string idx, Scope scope, int in_units, int out_units, bool bActivation, Input input)
{
    TensorShape sp = { in_units, out_units };
    m_vars[""W"" + idx] = Variable(scope.WithOpName(""W""), sp, DT_FLOAT);
    m_shapes[""W"" + idx] = sp;
    m_assigns[""W"" + idx + ""_assign""] = Assign(scope.WithOpName(""W_assign""), m_vars[""W"" + idx], XavierInit(scope, in_units, out_units));
    sp = { out_units };
    m_vars[""B"" + idx] = Variable(scope.WithOpName(""B""), sp, DT_FLOAT);
    m_shapes[""B"" + idx] = sp;
    m_assigns[""B"" + idx + ""_assign""] = Assign(scope.WithOpName(""B_assign""), m_vars[""B"" + idx], Input::Initializer(0.f, sp));
    auto dense = Add(scope.WithOpName(""Dense_b""), MatMul(scope.WithOpName(""Dense_w""), input, m_vars[""W"" + idx]), m_vars[""B"" + idx]);
    if (bActivation)
        return Relu(scope.WithOpName(""Relu""), dense);
    else
        return dense;
}

Status CatDogCNN::CreateGraphForCNN(int filter_side)
{
    //input image is batch_sizex150x150x3
    input_batch_var = Placeholder(t_root.WithOpName(input_name), DT_FLOAT);
    drop_rate_var = Placeholder(t_root.WithOpName(drop_rate_name), DT_FLOAT);//see class member for help
    skip_drop_var = Placeholder(t_root.WithOpName(skip_drop_name), DT_FLOAT);//see class member for help

    //Start Conv+Maxpool No 1. filter size 3x3x3 and we have 32 filters
    Scope scope_conv1 = t_root.NewSubScope(""Conv1_layer"");
    int in_channels = image_channels;
    int out_channels = 32;
    auto pool1 = AddConvLayer(""1"", scope_conv1, in_channels, out_channels, filter_side, input_batch_var);
    int new_side = ceil((float)image_side / 2); //max pool is reducing the size by factor of 2

    //Conv+Maxpool No 2
    Scope scope_conv2 = t_root.NewSubScope(""Conv2_layer"");
    in_channels = out_channels;
    out_channels = 64;
    auto pool2 = AddConvLayer(""2"", scope_conv2, in_channels, out_channels, filter_side, pool1);
    new_side = ceil((float)new_side / 2);

    //Conv+Maxpool No 3
    Scope scope_conv3 = t_root.NewSubScope(""Conv3_layer"");
    in_channels = out_channels;
    out_channels = 128;
    auto pool3 = AddConvLayer(""3"", scope_conv3, in_channels, out_channels, filter_side, pool2);
    new_side = ceil((float)new_side / 2);

    //Conv+Maxpool No 4
    Scope scope_conv4 = t_root.NewSubScope(""Conv4_layer"");
    in_channels = out_channels;
    out_channels = 128;
    auto pool4 = AddConvLayer(""4"", scope_conv4, in_channels, out_channels, filter_side, pool3);
    new_side = ceil((float)new_side / 2);

    //Flatten
    Scope flatten = t_root.NewSubScope(""flat_layer"");
    int flat_len = new_side * new_side * out_channels;
    auto flat = Reshape(flatten, pool4, { -1, flat_len });

    //Dropout
    Scope dropout = t_root.NewSubScope(""Dropout_layer"");
    auto rand = RandomUniform(dropout, Shape(dropout, flat), DT_FLOAT);
    //binary = floor(rand + (1 - drop_rate) + skip_drop)
    auto binary = Floor(dropout, Add(dropout, rand, Add(dropout, Sub(dropout, 1.f, drop_rate_var), skip_drop_var)));
    auto after_drop = Multiply(dropout.WithOpName(""dropout""), Div(dropout, flat, drop_rate_var), binary);

    //Dense No 1
    int in_units = flat_len;
    int out_units = 512;
    Scope scope_dense1 = t_root.NewSubScope(""Dense1_layer"");
    auto relu5 = AddDenseLayer(""5"", scope_dense1, in_units, out_units, true, after_drop);

    //Dense No 2
    in_units = out_units;
    out_units = 256;
    Scope scope_dense2 = t_root.NewSubScope(""Dense2_layer"");
    auto relu6 = AddDenseLayer(""6"", scope_dense2, in_units, out_units, true, relu5);

    //Dense No 3
    in_units = out_units;
    out_units = 1;
    Scope scope_dense3 = t_root.NewSubScope(""Dense3_layer"");
    auto logits = AddDenseLayer(""7"", scope_dense3, in_units, out_units, false, relu6);

    out_classification = Sigmoid(t_root.WithOpName(out_name), logits);
    return t_root.status();
}

Status CatDogCNN::CreateOptimizationGraph(float learning_rate)
{
    input_labels_var = Placeholder(t_root.WithOpName(""inputL""), DT_FLOAT);
    Scope scope_loss = t_root.NewSubScope(""Loss_scope"");
    out_loss_var = Mean(scope_loss.WithOpName(""Loss""), SquaredDifference(scope_loss, out_classification, input_labels_var), { 0 });
    TF_CHECK_OK(scope_loss.status());
    for (pair<string, Output> i : m_vars)
        v_weights_biases.push_back(i.second);
    vector<Output> grad_outputs;
    TF_CHECK_OK(AddSymbolicGradients(t_root, { out_loss_var }, v_weights_biases, &grad_outputs));
    int index = 0;
    for (pair<string, Output> i : m_vars)
    {
        //Applying Adam
        string s_index = to_string(index);
        auto m_var = Variable(t_root, m_shapes[i.first], DT_FLOAT);
        auto v_var = Variable(t_root, m_shapes[i.first], DT_FLOAT);
        m_assigns[""m_assign"" + s_index] = Assign(t_root, m_var, Input::Initializer(0.f, m_shapes[i.first]));
        m_assigns[""v_assign"" + s_index] = Assign(t_root, v_var, Input::Initializer(0.f, m_shapes[i.first]));

        auto adam = ApplyAdam(t_root, i.second, m_var, v_var, 0.f, 0.f, learning_rate, 0.9f, 0.999f, 0.00000001f, { grad_outputs[index] });
        v_out_grads.push_back(adam.operation);
        index++;
    }
    return t_root.status();
}

Status CatDogCNN::Initialize()
{
    if (!t_root.ok())
        return t_root.status();

    vector<Output> ops_to_run;
    for (pair<string, Output> i : m_assigns)
        ops_to_run.push_back(i.second);
    t_session = unique_ptr<ClientSession>(new ClientSession(t_root));
    TF_CHECK_OK(t_session->Run(ops_to_run, nullptr));
    /* uncomment if you want visualization of the model graph
    GraphDef graph;
    TF_RETURN_IF_ERROR(t_root.ToGraphDef(&graph));
    SummaryWriterInterface* w;
    TF_CHECK_OK(CreateSummaryFileWriter(1, 0, ""/Users/bennyfriedman/Code/TF2example/TF2example/graphs"", "".cnn-graph"", Env::Default(), &w));
    TF_CHECK_OK(w->WriteGraph(0, make_unique<GraphDef>(graph)));
    */
    return Status::OK();
}

Status CatDogCNN::TrainCNN(Tensor& image_batch, Tensor& label_batch, vector<float>& results, float& loss)
{
    if (!t_root.ok())
        return t_root.status();

    vector<Tensor> out_tensors;
    //Inputs: batch of images, labels, drop rate and do not skip drop.
    //Extract: Loss and result. Run also: Apply Adam commands
    TF_CHECK_OK(t_session->Run({ {input_batch_var, image_batch}, {input_labels_var, label_batch}, {drop_rate_var, 0.5f}, {skip_drop_var, 0.f} }, { out_loss_var, out_classification }, v_out_grads, &out_tensors));
    loss = out_tensors[0].scalar<float>()(0);
    //both labels and results are shaped [20, 1]
    auto mat1 = label_batch.matrix<float>();
    auto mat2 = out_tensors[1].matrix<float>();
    for (int i = 0; i < mat1.dimension(0); i++)
        results.push_back((fabs(mat2(i, 0) - mat1(i, 0)) > 0.5f) ? 0 : 1);
    return Status::OK();
}

Status CatDogCNN::ValidateCNN(Tensor& image_batch, Tensor& label_batch, vector<float>& results)
{
    if (!t_root.ok())
        return t_root.status();

    vector<Tensor> out_tensors;
    //Inputs: batch of images, drop rate 1 and skip drop.
    TF_CHECK_OK(t_session->Run({ {input_batch_var, image_batch}, {drop_rate_var, 1.f}, {skip_drop_var, 1.f} }, { out_classification }, &out_tensors));
    auto mat1 = label_batch.matrix<float>();
    auto mat2 = out_tensors[0].matrix<float>();
    for (int i = 0; i < mat1.dimension(0); i++)
        results.push_back((fabs(mat2(i, 0) - mat1(i, 0)) > 0.5f) ? 0 : 1);
    return Status::OK();
}

Status CatDogCNN::Predict(Tensor& image, int& result)
{
    if (!t_root.ok())
        return t_root.status();

    vector<Tensor> out_tensors;
    //Inputs: image, drop rate 1 and skip drop.
    TF_CHECK_OK(t_session->Run({ {input_batch_var, image}, {drop_rate_var, 1.f}, {skip_drop_var, 1.f} }, { out_classification }, &out_tensors));
    auto mat = out_tensors[0].matrix<float>();
    result = (mat(0, 0) > 0.5f) ? 1 : 0;
    return Status::OK();
}

Status CatDogCNN::FreezeSave(string& file_name)
{
    vector<Tensor> out_tensors;
    //Extract: current weights and biases current values
    TF_CHECK_OK(t_session->Run(v_weights_biases, &out_tensors));
    unordered_map<string, Tensor> variable_to_value_map;
    int idx = 0;
    for (Output o : v_weights_biases)
    {
        variable_to_value_map[o.node()->name()] = out_tensors[idx];
        idx++;
    }
    GraphDef graph_def;
    TF_CHECK_OK(t_root.ToGraphDef(&graph_def));
    //call the utility function (modified)
    SavedModelBundle saved_model_bundle;
    SignatureDef signature_def;
    (*signature_def.mutable_inputs())[input_batch_var.name()].set_name(input_batch_var.name());
    (*signature_def.mutable_outputs())[out_classification.name()].set_name(out_classification.name());
    MetaGraphDef* meta_graph_def = &saved_model_bundle.meta_graph_def;
    (*meta_graph_def->mutable_signature_def())[""signature_def""] = signature_def;
    *meta_graph_def->mutable_graph_def() = graph_def;
    SessionOptions session_options;
    saved_model_bundle.session.reset(NewSession(session_options));//even though we will not use it
    GraphDef frozen_graph_def;
    std::unordered_set<string> inputs;
    std::unordered_set<string> outputs;
    TF_CHECK_OK(FreezeSavedModel(saved_model_bundle, &frozen_graph_def, &inputs, &outputs));
    
    //write to file
    return WriteBinaryProto(Env::Default(), file_name, frozen_graph_def);
}

Status CatDogCNN::LoadSavedModel(string& file_name)
{
    std::unique_ptr<GraphDef> graph_def;
    SessionOptions options;
    f_session.reset(NewSession(options));
    graph_def.reset(new GraphDef());
    TF_CHECK_OK(ReadBinaryProto(Env::Default(), file_name, graph_def.get()));
    return f_session->Create(*graph_def.get());
}

Status CatDogCNN::PredictFromFrozen(Tensor& image, int& result)
{
    vector<Tensor> out_tensors;
    Tensor t(DT_FLOAT, TensorShape({ 1 }));
    t.scalar<float>()(0) = 1.f;
    //Inputs: image, drop rate 1 and skip drop.
    TF_CHECK_OK(f_session->Run({ {input_name, image}, {drop_rate_name, t}, {skip_drop_name, t} }, { out_name }, {}, &out_tensors));
    auto mat = out_tensors[0].matrix<float>();
    result = (mat(0, 0) > 0.5f) ? 1 : 0;
    return Status::OK();
}

InputList CatDogCNN::MakeTransforms(int batch_size, Input a0, Input a1, Input a2, Input b0, Input b1, Input b2)
{
    vector<Input> v_transforms;
    v_transforms.push_back(Reshape(a_root, a0, { batch_size, 1 }));
    v_transforms.push_back(Reshape(a_root, a1, { batch_size, 1 }));
    v_transforms.push_back(Reshape(a_root, a2, { batch_size, 1 }));
    v_transforms.push_back(Reshape(a_root, b0, { batch_size, 1 }));
    v_transforms.push_back(Reshape(a_root, b1, { batch_size, 1 }));
    v_transforms.push_back(Reshape(a_root, b2, { batch_size, 1 }));
    v_transforms.push_back(Input::Initializer(0.f, { batch_size, 2 }));
    InputList inp_transforms(v_transforms);
    return inp_transforms;
}

Status CatDogCNN::CreateAugmentGraph(int batch_size, int image_side, float flip_chances, float max_angles, float scale_shift_factor)
{
    aug_tensor_input = Placeholder(a_root.WithOpName(""input""), DT_FLOAT);
    //Do scale and shift
    Output shifted_images;
    /*if (scale_shift_factor)
    {
        auto rand1 = RandomUniform(a_root, { batch_size, 1 }, DT_FLOAT);
        auto rand2 = RandomUniform(a_root, { batch_size, 1 }, DT_FLOAT);
        auto rand3 = RandomUniform(a_root, { batch_size, 1 }, DT_FLOAT);
        auto rand4 = RandomUniform(a_root, { batch_size, 1 }, DT_FLOAT);
        auto rand_shift1 = Sub(a_root, Mul(a_root, rand1, scale_shift_factor * 2 * image_side), scale_shift_factor * image_side);
        auto rand_shift2 = Sub(a_root, Mul(a_root, rand2, scale_shift_factor * 2 * image_side), scale_shift_factor * image_side);
        auto rand_scale1 = Add(a_root, Mul(a_root, rand3, scale_shift_factor * 2), 1 - scale_shift_factor);
        auto rand_scale2 = Add(a_root, Mul(a_root, rand4, scale_shift_factor * 2), 1 - scale_shift_factor);
        Input::Initializer zeros(0.f, { batch_size, 1 });
        auto transforms = Concat(a_root, MakeTransforms(batch_size, rand_scale1, zeros, rand_shift1, zeros, rand_scale2, rand_shift2), Input::Initializer(1, {}));
        shifted_images = ImageProjectiveTransform(a_root, aug_tensor_input, transforms, ""BILINEAR"");
    }
    else*/
        shifted_images = Identity(a_root, aug_tensor_input);

    // do flips
    Output fliped_images;
    if (flip_chances)
    {
        auto rand5 = RandomUniform(a_root, { batch_size }, DT_FLOAT);
        auto flips_vector = Floor(a_root, Add(a_root, rand5, flip_chances));
        auto flips_tensor = Cast(a_root, Reshape(a_root, flips_vector, { batch_size, 1, 1, 1 }), DT_FLOAT);
        auto reverses = Reverse(a_root, shifted_images, { 2 }); // right to left
        auto tensors_reversed = Mul(a_root, reverses, flips_tensor);
        auto tensors_normal = Mul(a_root, shifted_images, Sub(a_root, 1.f, flips_tensor));
        fliped_images = Add(a_root, tensors_reversed, tensors_normal);
    }
    else
        fliped_images = Identity(a_root, aug_tensor_input);

    // do rotations
    //if (max_angles)
    //{
    //    
    //    auto rand6 = RandomUniform(a_root, { batch_size }, DT_FLOAT);
    //    auto angles = Mul(a_root, Sub(a_root, rand6, 0.5f), max_angles * 2);
    //    //TOVERIFY: auto rand_angles = Div(a_root, Mul(a_root, angles, (float)M_PI), 180.f);
    //    auto rand_angles = Div(a_root, Mul(a_root, angles, (float)3.14159265358979323846), 180.f);
    //    auto sins = Sin(a_root, rand_angles);
    //    auto m_sins = Mul(a_root, sins, -1.f);
    //    auto coss = Cos(a_root, rand_angles);
    //    float img_side_1 = image_side - 1;
    //    auto x_offset = Div(a_root, Sub(a_root, img_side_1, Sub(a_root, Mul(a_root, coss, img_side_1), Mul(a_root, sins, img_side_1))), 2.f);
    //    auto y_offset = Div(a_root, Sub(a_root, img_side_1, Add(a_root, Mul(a_root, sins, img_side_1), Mul(a_root, coss, img_side_1))), 2.f);
    //    auto transforms = Concat(a_root, MakeTransforms(batch_size, coss, m_sins, x_offset, sins, coss, y_offset), Input::Initializer(1, {}));
    //    aug_tensor_output = ImageProjectiveTransform(a_root, fliped_images, transforms, ""BILINEAR"");
    //}
    //else
        aug_tensor_output = Identity(a_root, fliped_images);
    return a_root.status();
}

Status CatDogCNN::RandomAugmentBatch(Tensor& image_batch, Tensor& augmented_batch)
{
    TF_CHECK_OK(a_root.status());
    ClientSession session(a_root);
    vector<Tensor> out_tensors;
    TF_CHECK_OK(session.Run({ {aug_tensor_input, image_batch} }, { aug_tensor_output }, &out_tensors));
    augmented_batch = out_tensors[0];
    return Status::OK();
}

Status CatDogCNN::WriteBatchToImageFiles(Tensor& image_batch, string folder_name, string image_name)
{
    Scope root = Scope::NewRootScope();
    auto unormalized = Multiply(root, image_batch, 255.f);
    auto cast = Cast(root, unormalized, DT_UINT8);
    auto image_list = Unstack(root, cast, image_batch.dim_size(0));
    size_t num = image_list.output.size();
    vector<Output> images;
    for (int i = 0; i < num; i++)
        images.push_back(EncodeJpeg(root, image_list.output[i]));

    TF_CHECK_OK(root.status());
    ClientSession session(root);
    vector<Tensor> out_tensors;
    TF_CHECK_OK(session.Run({}, { images }, &out_tensors));

    for (int i = 0; i < num; i++)
    {
        string i_name = image_name + to_string(i) + "".jpg"";
        string i_fullpath = io::JoinPath(folder_name, i_name);
        ofstream fs(i_fullpath, ios::binary);
        fs << out_tensors[i].scalar<string>()();
    }
    return Status::OK();
}

The make file :

cmake_minimum_required(VERSION 3.21)
project(TestIA)

set(CMAKE_CXX_STANDARD 14)

add_library(ts_base SHARED IMPORTED)
set_property(TARGET ts_base PROPERTY IMPORTED_LOCATION /home/gosu/Bureau/IA/tensorflow/bazel-bin/tensorflow/libtensorflow.so)
add_library(ts_cc SHARED IMPORTED)
set_property(TARGET ts_cc PROPERTY IMPORTED_LOCATION /home/gosu/Bureau/IA/tensorflow/bazel-bin/tensorflow/libtensorflow_cc.so)
add_library(ts_framework SHARED IMPORTED)
set_property(TARGET ts_framework PROPERTY IMPORTED_LOCATION /home/gosu/Bureau/IA/tensorflow/bazel-bin/tensorflow/libtensorflow_framework.so)
add_library(ts_protobuf SHARED IMPORTED)
set_property(TARGET ts_protobuf PROPERTY IMPORTED_LOCATION /usr/local/lib/libprotobuf.so)
add_library(ts_protoc SHARED IMPORTED)
set_property(TARGET ts_protoc PROPERTY IMPORTED_LOCATION /usr/local/lib/libprotoc.so)

add_executable(TestIA main.cpp cmake-build-debug/CatDogCNN.cpp cmake-build-debug/CatDogCNN.h)

target_link_libraries(TestIA ts_protobuf)
target_link_libraries(TestIA ts_protoc)
target_link_libraries(TestIA ts_base)
target_link_libraries(TestIA ts_cc)
target_link_libraries(TestIA ts_framework)
```


### Relevant log output

_No response_</details>"
55754,Huge Accuracy drop after re-training my model on device using tensorflow-lite 2.8,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Performance

### Source

source

### Tensorflow Version

tf 2.8

### Custom Code

Yes

### OS Platform and Distribution

_No response_

### Mobile device

Custom Linux Distribution on Raspberry Pi

### Python version

_No response_

### Bazel version

3.7.2

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?


* After converting my model to TensorFlow Lite and deploying it with your app, I am trying to retrain the model on a device using the fashion MNIST Test-set and the train signature method of my model. During the training on the device for 5 epochs, I can print the current Loss of each epoch. The https://www.tensorflow.org/lite/examples/on_device_training/overview#retrain_the_model_on_a_device article states that the training on target should start from the last loss value and the loss curve should be continuous as shown in the following figure: ![figure](https://www.tensorflow.org/lite/examples/on_device_training/overview#retrain_the_model_on_a_device). The weird behaviour I am noticing is mainly related to this, these are the loss values I get on my target after reproducing the same steps as the article.

```
[DEBUG][TRAINING] Current epoch: 0
[DEBUG][TRAINING] Current Loss: 0.000385568
[DEBUG][TRAINING] Current epoch: 1
[DEBUG][TRAINING] Current Loss: 0.000171647
[DEBUG][TRAINING] Current epoch: 2
[DEBUG][TRAINING] Current Loss: 0.000141491
[DEBUG][TRAINING] Current epoch: 3
[DEBUG][TRAINING] Current Loss: 0.000374128
[DEBUG][TRAINING] Current epoch: 4
[DEBUG][TRAINING] Current Loss: 4.76826e-05
```
The Loss value from the initial training on Google Colab seems to end at 0.241, but it starts at 0.0003855. 

* The second behavior is the accuracy drop in my model after retraining it on my device. The initial accuracy after training the model on Google Colab is around 92% after 100 epochs of training. But after retraining the model, saving the new weights and testing it, I notice a huge accuracy drop down to 83% after 5 epochs of training on device. That's a bit odd in my opinion. Any help to understand this behavior would be appreciated. 
Thanks you.

### Standalone code to reproduce the issue


I was trying to reproduce the on-device-training demo on a Linux Distribution (instead of an Android Target as detailed in the following article https://www.tensorflow.org/lite/examples/on_device_training/overview). I was able to build a libtensorflow-lite.so shared library with a Flex delegate and the necessary TF-Ops and kernels to make my model run and train smoothly on the target. The build has been done by using bazel's following command:
```
bazel build --config=monolithic --config=noaws --config=nogcp --config=nohdfs \
 --config=nonccl --config=elinux_aarch64 \
 --experimental_ui_max_stdouterr_bytes=1073741819 -c opt --cxxopt=--std=c++14 \
 //tensorflow/lite:libtensorflowlite.so
```
After modifying the BUILD to add Flex Delegate:
```
""//tensorflow/lite/delegates/flex:delegate"",
```
After building my shared library, I trained my model using the following Google Colab Gist https://colab.research.google.com/drive/1rryoMsfhf_nL3XRJoyXL8baTli9HEDz4?usp=sharing using Fashion MNIST dataset and extracted my **fashion_mnist_model.tflite**

On the target, I wrote a simple C++ application to retrain the model on device and it is running pretty well, I'm only questioning the huge Loss drop between. Here is the code sample used to retrain the model on target.
```
#include <cstdio>
#include <string>
#include <cstddef>
#include <cstdint>
#include <iostream>
#include <fstream>
#include <stdio.h>
#include <iomanip>
#include <getopt.h>
#include <ctime>

#include ""tensorflow/lite/interpreter.h""
#include ""tensorflow/lite/interpreter_builder.h""
#include ""tensorflow/lite/kernels/register.h""
#include ""tensorflow/lite/model.h""
#include ""tensorflow/lite/optional_debug_tools.h""
#include ""tensorflow/lite/signature_runner.h""


#define BATCH_SIZE 64

inline bool is_little_indian() {
	int val = 1;
	return *reinterpret_cast<char *>(&val) != 0;
}

uint32_t reverse_indian(uint32_t val) {
	val = ((val << 8) & 0xFF00FF00) | ((val >> 8) & 0xFF00FF);
	return (val << 16) | (val >> 16);
}

int main(int argc, char* argv[]) {

	std::string command = argv[1];
	const char* model_filename = argv[2];

	//Loading the tflite retrainable model
	std::unique_ptr<tflite::FlatBufferModel> model = tflite::FlatBufferModel::BuildFromFile(model_filename);
	if (model == nullptr) {
		fprintf(stderr, ""FlatBufferModel could not be created from given model argument."");
		return 1;
	}
	tflite::ops::builtin::BuiltinOpResolver resolver;
	tflite::InterpreterBuilder builder(*model, resolver);

	//Building the interpreter
	std::unique_ptr<tflite::Interpreter> interpreter;
	builder(&interpreter);

	//Getting the list of signatures
	auto signature_defs = interpreter->signature_keys();
		
    const std::string image_filename = argv[3];
    const std::string label_filename = argv[4];
    const int num_epochs = atoi(argv[5]);

    tflite::SignatureRunner* train_runner = interpreter->GetSignatureRunner(""train"");
    if (train_runner == nullptr) {
        fprintf(stderr, ""Couldn't create train runner from the signature of the interpreter."");
    return 1;
    }

    //Getting the input and output tensors names
    const std::vector<const char*>& input_names = train_runner->input_names();
    const std::vector<const char*>& output_names = train_runner->output_names();

    TfLiteTensor* train_input_x = train_runner->input_tensor((std::string(input_names[0])).c_str());
    TfLiteTensor* train_input_y = train_runner->input_tensor((std::string(input_names[1])).c_str());

    //Allocating tensors
    if (interpreter->AllocateTensors() != kTfLiteOk) {
        fprintf(stderr, ""Interpreter couldn't allocate tensors."");
        return 1;
    }

    if (train_runner->AllocateTensors() != kTfLiteOk) {
        fprintf(stderr, ""Training runner couldn't allocate tensors."");
        return 1;
    }

    // Parsing dataset
    std::ifstream imagefile(image_filename, std::ios::in | std::ios::binary);
    std::ifstream labelfile(label_filename, std::ios::in | std::ios::binary);

    uint32_t magic_number;
    uint32_t magic_number_label;
    uint32_t num_images;
    uint32_t num_labels;
    uint32_t num_rows;
    uint32_t num_cols;

    imagefile.read(reinterpret_cast<char *>(&magic_number), 4);
    imagefile.read(reinterpret_cast<char *>(&num_images), 4);
    imagefile.read(reinterpret_cast<char *>(&num_rows), 4);
    imagefile.read(reinterpret_cast<char *>(&num_cols), 4);
    labelfile.read(reinterpret_cast<char *>(&magic_number_label), 4);
    labelfile.read(reinterpret_cast<char *>(&num_labels), 4);

    //The first 4 bytes in dataset file are dedicated to the magic number
    // MNIST Dataset is in Big-Endian format
    if (is_little_indian()){
        magic_number = reverse_indian(magic_number);
        num_images = reverse_indian(num_images);
        num_labels = reverse_indian(num_labels);
        num_rows = reverse_indian(num_rows);
        num_cols = reverse_indian(num_cols);
    }

    char label;
    const uint32_t num_pixels = num_rows * num_cols;
    const uint32_t num_batches = num_images / BATCH_SIZE;
    std::cout << ""[DEBUG][METADATA] Number of batches: "" << num_batches << std::endl;
    std::cout << ""[DEBUG][TRAINING] Training launched ... "" << std::endl;
    for (int epoch = 0; epoch < num_epochs; ++epoch){
        float current_loss = 0;
        std::cout << ""[DEBUG][TRAINING] Current epoch: "" << epoch << std::endl;
        for (uint32_t batch_index = 0; batch_index < num_batches; ++batch_index){
            char *pixels{ new char[num_pixels * sizeof(float)]{}};
            float *fpixels{ new float[num_pixels]{}};
            for (int index = 0; index < BATCH_SIZE; ++index){
                float labels[10] = { 0.0 };
                imagefile.read(pixels, num_pixels);
                labelfile.read(&label, 1);
                labels[int(label)] = 1.0;
                for (uint32_t i=0; i<num_pixels; ++i){
                    fpixels[i] = float(float(*(pixels + i))/255);
                }
                train_input_y->data.f = labels;
                train_input_x->data.f = fpixels;
                if (train_runner->Invoke() != kTfLiteOk){
                    fprintf(stderr, ""ERROR: Training runner couldn't run Invoke of subgraph.\n"");
                    return 1;
                }
            }
            delete[] pixels;
            delete[] fpixels;
            const TfLiteTensor* output_tensor = train_runner->output_tensor((std::string(output_names[0])).c_str());
            float* output = output_tensor->data.f;
            current_loss = *(output);
        }
        std::cout << ""] - Current Loss: "" << current_loss << std::endl;
    }
    std::cout << ""[DEBUG][TRAINING] Training finished successfully."" << std::endl;
	
	return 0;
}



```
```


### Relevant log output

_No response_</details>"
55753,Different behavior between `tf.experimental.numpy.(v/h/d)split` and `np.(v/h/d)split`,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

tf 2.8

### Custom Code

Yes

### OS Platform and Distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?


I expected Tensorflow to throw a similar exception (`ValueError: array split does not result in an equal division`) as Numpy on invoking the experimental.numpy.*split functions (e.g. `tf.experimental.numpy.dsplit`, `tf.experimental.numpy.hsplit`, `tf.experimental.numpy.vsplit`),
but currently, Tensorflow consumes all RAM and crashes.

I wonder if Tensorflow should perform the validation checks in the same order as numpy (i.e., detect the invalid array split first)?


### Standalone code to reproduce the issue


Here's a colab notebook: https://colab.research.google.com/drive/1zyOtnyGi9KgZLskYc4SRCB74fV73rnyU?usp=sharing

```python
import tensorflow as tf
import numpy as np

x = np.arange(16.0)
tf.experimental.numpy.dsplit(ary=x,indices_or_sections=256000000)  # crashes
```

```python
# In contrast,
np.dsplit(ary=np.arange(16.0),indices_or_sections=128000000) # doesn't crash, but throws an exception instead. This is the expected behavior
```


### Relevant log output

_No response_</details>"
55750,Custom MLIR Tensorflow Pass,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Feature Request

### Source

source

### Tensorflow Version

2.8.0

### Custom Code

Yes

### OS Platform and Distribution

Linux Centos 7

### Mobile device

_No response_

### Python version

3.10.4

### Bazel version

4.2.1

### GCC/Compiler version

11.2.1

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

Hi, I am currently working a compiler project that identifies when complex arithmetic is being cast as real arithmetic. For example, say we want to compute 
```
C = tf.matmul(A, B)
```
where A, B, C are tf.complex64. But, due to whatever reason it is not allowed, or the person writing is a bad developer. Thus, instead we use real arithmetic to compute 
```
Cr = tf.matmul(Ar, Br) - tf.matmul(Ai, Bi)
Ci = tf.matmul(Ar, Bi) + tf.matmul(Ai, Br)
```
where Ar, Ai, Br, Bi, Cr, Ci are tf.float32. I would like to catch this in a compiler pass and modify the program to use a high performance complex matmul kernel instead. As well as convert the data format into the one expected by the kernel.

I was looking into the [Tensorflow MLIR passes](https://www.tensorflow.org/mlir/tf_passes) and was wondering how could I go about writing my own pass to implement this. So far I have been trying to convert `tf` MLIR to `linalg` MLIR and then writing an `OperationPass` for this. It would be a lot easier if I could just add a custom pass such that I can use it within `tf-opt`

TLDR: Are there any docs on writing custom [tensorflow passes](https://www.tensorflow.org/mlir/tf_passes)? If not, can these be added?

### Standalone code to reproduce the issue

```
# Assumes tf 2.8
import tensorflow as tf

@tf.function
def cgemm_explict(A_r, A_i, B_r, B_i, C_r, C_i):
    return tf.complex(A_r @ B_r - A_i @ B_i + C_r, A_r @ B_i + A_i @ B_r + C_i)

m, n, k = 3, 3, 3
func_obj = cgemm_explict.get_concrete_function(
    tf.TensorSpec(shape=[m, k], dtype=tf.dtypes.float32, name=""Ar""),
    tf.TensorSpec(shape=[m, k], dtype=tf.dtypes.float32, name=""Ai""),
    tf.TensorSpec(shape=[k, n], dtype=tf.dtypes.float32, name=""Br""),
    tf.TensorSpec(shape=[k, n], dtype=tf.dtypes.float32, name=""Bi""),
    tf.TensorSpec(shape=[m, n], dtype=tf.dtypes.float32, name=""Cr""),
    tf.TensorSpec(shape=[m, n], dtype=tf.dtypes.float32, name=""Ci"")
)
# replace 'tf-standard-pipeline' with custom pass
mlir_obj = tf.mlir.experimental.convert_function(func_obj, pass_pipeline='tf-standard-pipeline')

print(mlir_obj) # print tf MLIR for the given tf.function
```


### Relevant log output

```shell
module attributes {tf.versions = {bad_consumers = [], min_consumer = 0 : i32, producer = 987 : i32}}  {
  func @__inference_cgemm_explict_19(%arg0: tensor<3x3xf32> {tf._user_specified_name = ""Ar""}, %arg1: tensor<3x3xf32> {tf._user_specified_name = ""Ai""}, %arg2: tensor<3x3xf32> {tf._user_specified_name = ""Br""}, %arg3: tensor<3x3xf32> {tf._user_specified_name = ""Bi""}, %arg4: tensor<3x3xf32> {tf._user_specified_name = ""Cr""}, %arg5: tensor<3x3xf32> {tf._user_specified_name = ""Ci""}) -> tensor<3x3xcomplex<f32>> attributes {tf.entry_function = {control_outputs = """", inputs = ""ar,ai,br,bi,cr,ci"", outputs = ""identity_RetVal""}} {
    %0 = ""tf.MatMul""(%arg1, %arg3) {device = """", transpose_a = false, transpose_b = false} : (tensor<3x3xf32>, tensor<3x3xf32>) -> tensor<3x3xf32>
    %1 = ""tf.MatMul""(%arg0, %arg3) {device = """", transpose_a = false, transpose_b = false} : (tensor<3x3xf32>, tensor<3x3xf32>) -> tensor<3x3xf32>
    %2 = ""tf.MatMul""(%arg0, %arg2) {device = """", transpose_a = false, transpose_b = false} : (tensor<3x3xf32>, tensor<3x3xf32>) -> tensor<3x3xf32>
    %3 = ""tf.Sub""(%2, %0) {device = """"} : (tensor<3x3xf32>, tensor<3x3xf32>) -> tensor<3x3xf32>
    %4 = ""tf.MatMul""(%arg1, %arg2) {device = """", transpose_a = false, transpose_b = false} : (tensor<3x3xf32>, tensor<3x3xf32>) -> tensor<3x3xf32>
    %5 = ""tf.AddV2""(%1, %4) {device = """"} : (tensor<3x3xf32>, tensor<3x3xf32>) -> tensor<3x3xf32>
    %6 = ""tf.AddV2""(%5, %arg5) {device = """"} : (tensor<3x3xf32>, tensor<3x3xf32>) -> tensor<3x3xf32>
    %7 = ""tf.AddV2""(%3, %arg4) {device = """"} : (tensor<3x3xf32>, tensor<3x3xf32>) -> tensor<3x3xf32>
    %8 = ""tf.Complex""(%7, %6) {device = """"} : (tensor<3x3xf32>, tensor<3x3xf32>) -> tensor<3x3xcomplex<f32>>
    %9 = ""tf.Identity""(%8) {device = """"} : (tensor<3x3xcomplex<f32>>) -> tensor<3x3xcomplex<f32>>
    return %9 : tensor<3x3xcomplex<f32>>
  }
}
```
</details>"
55749,Why does tflite using CoreML delegate not accelerate on small models?,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Performance

### Source

source

### Tensorflow Version

tf2.8

### Custom Code

No

### OS Platform and Distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
mobilnetv2, tflite with CoreML slower than on GPU
```


### Standalone code to reproduce the issue

```shell
n ocode
```


### Relevant log output

_No response_</details>"
55748,About On Device Training case cannot support correlation ops," Hello, I would like to ask a question aboout On Device Training case. When I perform migration learning, I get the following error, which seems to be that these operators are not supported. That is, does the On Device Training case currently not support the use of convolution? How should I go about solving this problem? Looking forward to your reply！

""TFLite interpreter needs to link Flex delegate in order to run the model since it contains the following Select TFop(s): Flex ops: FlexBroadcastGradientArgs, FlexConv2DBackpropFilter, FlexFusedBatchNormGradV3, FlexFusedBatchNormV3, FlexReluGrad"""
55747,"Kernel names as ""a_unnamed"" in TF2.8 if XLA debug option ""--xla_dump_to"" is on","<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

TF2.8

### Custom Code

Yes

### OS Platform and Distribution

Ubuntu 20.04.4 LTS

### Mobile device

_No response_

### Python version

3.8

### Bazel version

5.0.0

### GCC/Compiler version

No

### CUDA/cuDNN version

_No response_

### GPU model and memory

V100

### Current Behaviour?


In TF2.8 with XLA turned on, as long as XLA Debug Option contains '--xla_dump_to', the fused kernels will have a name "" a_unnamed "" instead of ""fusion_xx"". This can be observed with `nsys profile --stats=true` or directly seen in the dumped HLO graph. It seems that MLIR module doesn't record the name of XLA fusion kernels and thus dump its default `unnamed`. It is related to [this](https://github.com/tensorflow/tensorflow/commit/a7b03c184e2371a77186ccb3497f4bdbc0cc6585#diff-54d8af79ae786071a2d4aba7751a7d431da73570bdb8f0fc815c638dd9abc56dR858) commit.



### Standalone code to reproduce the issue

```shell
import tensorflow as tf
import tensorflow.python as tf_python
import os
from datetime import datetime
from absl import app, flags
import math
import time
import sys

batch_size = 32


policy = tf.keras.mixed_precision.experimental.Policy(""mixed_float16"")
tf.keras.mixed_precision.experimental.set_policy(policy)

tf.config.optimizer.set_jit(True)
os.environ['XLA_FLAGS'] = ""--xla_dump_to='./xla_logs'""

H = 32
W = 32
C = 64
input_shape = (batch_size, H, W, C)

class EinSumLayer(tf.keras.layers.Layer):
    def __init__(self, name='', **kwargs):
        super(EinSumLayer, self).__init__(**kwargs)
        self._name = name

    def call(self, inputs):
        return tf.einsum('ij, jk->ik', inputs[0], inputs[1])


class TrainingModel(tf.keras.Model):
    def __init__(self):
        super(TrainingModel, self).__init__()

        # x
        # 1x1 conv 64, BN 64, Relu
        # 3x3 conv 64, BN 64, Relu
        # 1x1 conv 256, BN 256
        # Residual add : output + x
        #
        self.conv1 = tf.keras.layers.Conv2D(filters=16, input_shape=input_shape[1:],
                                            kernel_size=(1, 1), strides=(1, 1),
                                            padding='same', data_format='channels_last',
                                            activation=None, use_bias=True)
        self.bn1 = tf.keras.layers.BatchNormalization()
        self.relu1 = tf.keras.layers.ReLU()

        self.conv2 = tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), strides=(1, 1),
                                            padding='same', data_format='channels_last',
                                            activation=None, use_bias=True)
        self.bn2 = tf.keras.layers.BatchNormalization()
        self.relu2 = tf.keras.layers.ReLU()

        self.conv3 = tf.keras.layers.Conv2D(filters=64, kernel_size=(1, 1), strides=(1, 1),
                                            padding='same', data_format='channels_last',
                                            activation=None, use_bias=True)
        self.bn3 = tf.keras.layers.BatchNormalization()
        self.relu3 = tf.keras.layers.ReLU()

        self.add = tf.keras.layers.Add()

        # Pooling
        self.pool1 = tf.keras.layers.MaxPool2D(pool_size=(2, 2), padding='same',
                                               data_format='channels_last')
        self.relu4 = tf.keras.layers.ReLU()

        # Dense layer pattern
        self.flatten = tf.keras.layers.Flatten(data_format='channels_last')

        # Activation none is supposed to check for MatMul + BiasAdd fusion
        # With activation BiasAdd gets fused with Relu
        # It is weird that smaller Dense layer sizes do not result in XLA fusion
        self.dense1 = tf.keras.layers.Dense(64, activation=None, use_bias=True)
        self.dense3 = tf.keras.layers.Dense(32, activation=None, use_bias=True)
        self.dense_out = tf.keras.layers.Dense(1, activation='relu', use_bias=True)

        self.ein_sum = EinSumLayer('ein_sum')
        self.relu5 = tf.keras.layers.ReLU()

        self.optimizer = tf.keras.optimizers.Adam()

    @tf.function
    def call(self, x):
        y = x
        x = self.conv1(x)
        x = self.bn1(x)
        x = self.relu1(x)

        x = self.conv2(x)
        x = self.bn2(x)
        x = self.relu2(x)

        x = self.conv3(x)
        x = self.bn3(x)
        x = self.relu3(x)

        x = self.add([x, y])

        x = self.pool1(x)
        x = self.relu4(x)

        x = self.flatten(x)

        x = self.dense1(x)
        x = self.dense3(x)
        x = self.ein_sum((x, x))
        x = self.relu5(x)
        x = self.dense_out(x)

        return x


model = TrainingModel()
steps = 20
input = tf.random.uniform(shape=[batch_size * steps, H, W, C], dtype=tf.float32)
target = tf.random.uniform(shape=[batch_size * steps, 1], dtype=tf.float32)
train_dataset = tf.data.Dataset.from_tensor_slices((input, target))
train_dataset = train_dataset.batch(batch_size)

# model(input)

def train_step(model_xy, x, y):
    with tf.GradientTape() as tape:
        pred = model_xy(x, training=True)
        y = tf.cast(y, dtype=tf.float16)
        loss = tf.math.reduce_mean(pred - y)

    grads = tape.gradient(loss, model_xy.trainable_weights)
    model_xy.optimizer.apply_gradients(zip(grads, model_xy.trainable_weights))

for epochs in range(1):
    for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):
        loss_value = train_step(model, x_batch_train, y_batch_train)

model.compile(optimizer='adam', loss='mse')
model.fit(train_dataset)
```


### Relevant log output

```shell
nsys profile --trace cuda  --stats=true  --sample cpu -o keras_toy python tf_keras.py --amp --xla

      0.0            66720         20    3336.0    3328.5      3137      3488         76.1  Neg_GPU_DT_HALF_DT_HALF_kernel                                     
      0.0            66560         20    3328.0    3264.0      3200      3840        148.0  a_unnamed__47                                                      
      0.0            66526         20    3326.3    3296.0      3263      3424         51.6  a_unnamed__49                                                      
      0.0            65919         20    3296.0    3295.5      3263      3392         41.6  a_unnamed__53                                                      
      0.0            65181         20    3259.1    3232.0      3200      3392         46.8  Div_GPU_DT_HALF_DT_HALF_kernel
```
</details>"
55745,TF Lite (CMake): Does not compile on Windows,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

2.9.0

### Custom Code

No

### OS Platform and Distribution

Windows (MSVC 2019)

### Mobile device

N/A

### Python version

N/A

### Bazel version

N/A

### GCC/Compiler version

N/A

### CUDA/cuDNN version

N/A

### GPU model and memory

N/A

### Current Behaviour?

```shell
TF Lite fails to compile on Windows with MSVC 2019 due to `M_PI` being used by `tensorflow/core/lib/random/random_distributions_utils.h` without defining `_USE_MATH_DEFINES` (see https://docs.microsoft.com/en-us/cpp/c-runtime-library/math-constants?view=msvc-160).
```


### Standalone code to reproduce the issue

```shell
Attempt to compile TF Lite on Windows with CMake and it will fail to build with the following error:

random_ops.cc
build\tensorflow\tensorflow/core/lib/random/random_distributions_utils.h(78,27): error C2065: 'M_PI': undeclared identifier
 [build\_deps\tensorflow-build\tensorflow-lite.vcxproj]
\build\tensorflow\tensorflow/core/lib/random
/random_distributions_utils.h(78,15): error C2737: 'v1': const object must be initialized [build\_deps\tensorflow-build\tensorflow-lite.vcxproj]
```
```


### Relevant log output

_No response_</details>"
55744,tensorflow_datasets AttributeError: module 'distutils' has no attribute 'version' ,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Build/Install

### Source

binary

### Tensorflow Version

tf 2.6

### Custom Code

No

### OS Platform and Distribution

Linux

### Mobile device

_No response_

### Python version

3.7

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

11.2/8.1

### GPU model and memory

_No response_

### Current Behaviour?

```shell
Previous tensorflow_datasets pip install worked fine: 
pip install tensorflow==2.6
pip install keras==2.6.0 
pip install --upgrade tensorflow-hub
pip install tensorflow_datasets

Just found that same pip install tensorflow_datasets broke last night:
Requirement already satisfied: six in ./anaconda3/envs/py37/lib/python3.7/site-packages (from tensorflow_datasets) (1.15.0)
Requirement already satisfied: typing-extensions; python_version < ""3.8"" in ./anaconda3/envs/py37/lib/python3.7/site-packages (from tensorflow_datasets) (3.7.4.3)
Collecting importlib-resources; python_version < ""3.9""
Downloading https://pypi.apple.com/packages/packages/bd/4d/19cb95029e824d878d5d13b62825839b5b024a62706ea308781a9e2cf534/importlib_resources-5.7.1-py3-none-any.whl (28 kB)
Requirement already satisfied: requests>=2.19.0 in ./anaconda3/lib/python3.7/site-packages (from tensorflow_datasets) (2.22.0)
Collecting promise
Downloading https://pypi.apple.com/packages/packages/cf/9c/fb5d48abfe5d791cd496e4242ebcf87a4bb2e0c3dcd6e0ae68c11426a528/promise-2.3.tar.gz (19 kB)
Collecting googleapis-common-protos<2,>=1.52.0
Downloading https://pypi.apple.com/packages/packages/bd/f7/3b5b207a008cf5a15d623c96c59c8bc3663d4ac2618e23602a0dc2b99808/googleapis_common_protos-1.56.0-py2.py3-none-any.whl (241 kB)
Collecting zipp>=3.1.0; python_version < ""3.10""
Downloading https://pypi.apple.com/packages/packages/80/0e/16a7ee38617aab6a624e95948d314097cc2669edae9b02ded53309941cfc/zipp-3.8.0-py3-none-any.whl (5.4 kB)
Requirement already satisfied: certifi>=2017.4.17 in ./anaconda3/lib/python3.7/site-packages (from requests>=2.19.0->tensorflow_datasets) (2019.11.28)
Requirement already satisfied: chardet<3.1.0,>=3.0.2 in ./anaconda3/lib/python3.7/site-packages (from requests>=2.19.0->tensorflow_datasets) (3.0.4)
Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in ./anaconda3/lib/python3.7/site-packages (from requests>=2.19.0->tensorflow_datasets) (1.25.8)
Requirement already satisfied: idna<2.9,>=2.5 in ./anaconda3/lib/python3.7/site-packages (from requests>=2.19.0->tensorflow_datasets) (2.8)
Building wheels for collected packages: promise
  Building wheel for promise (setup.py): started
  Building wheel for promise (setup.py): finished with status 'done'
  Created wheel for promise: filename=promise-2.3-py3-none-any.whl size=21494 sha256=763fed2298136d167ce5bfb16930dbf4349c9f263a73bb8ac00027cb43de1d48
  Stored in directory: /root/.cache/pip/wheels/0b/1b/71/56b96659fcf28d2983ad511ceadabf12ca962ee5face504f40
Successfully built promise
Installing collected packages: dill, googleapis-common-protos, tensorflow-metadata, zipp, importlib-resources, promise, tensorflow-datasets
  Attempting uninstall: zipp
    Found existing installation: zipp 2.2.0
    Uninstalling zipp-2.2.0:
      Successfully uninstalled zipp-2.2.0
Successfully installed dill-0.3.4 googleapis-common-protos-1.56.0 importlib-resources-5.7.1 promise-2.3 tensorflow-datasets-4.5.2 tensorflow-metadata-1.7.0 zipp-3.8.0

Although pip install was successful but looks like there's a version conflict issue, it throws AttributeError from tensorflow_datasets.core import tf_compat:

Traceback (most recent call last):
  File ""nt_qrewrite/data_pipeline.py"", line 42, in <module>
    import tensorflow_datasets as tfds
  File ""/mnt/task_runtime/anaconda3/envs/py37/lib/python3.7/site-packages/tensorflow_datasets/__init__.py"", line 43, in <module>
    from tensorflow_datasets.core import tf_compat
  File ""/mnt/task_runtime/anaconda3/envs/py37/lib/python3.7/site-packages/tensorflow_datasets/core/__init__.py"", line 22, in <module>
    tf_compat.ensure_tf_install()
  File ""/mnt/task_runtime/anaconda3/envs/py37/lib/python3.7/site-packages/tensorflow_datasets/core/tf_compat.py"", line 60, in ensure_tf_install
    tf_version = distutils.version.LooseVersion(tf.__version__)
AttributeError: module 'distutils' has no attribute 'version'

Please advise how to fix this. Thanks!
```


### Standalone code to reproduce the issue

```shell
pip install tensorflow==2.6
pip install keras==2.6.0 
pip install --upgrade tensorflow-hub
pip install tensorflow_datasets
python -c ""import tensorflow_datasets as tfds; print('tfds.__version__:' + tfds.__version__)""
```


### Relevant log output

```shell
Collecting dill
Downloading https://pypi.apple.com/packages/packages/b6/c3/973676ceb86b60835bb3978c6db67a5dc06be6cfdbd14ef0f5a13e3fc9fd/dill-0.3.4-py2.py3-none-any.whl (86 kB)
Collecting tensorflow-metadata
Downloading https://pypi.apple.com/packages/packages/ed/c4/e4fa9d2725eff8eeed00f2c959d1cbb0a7f027f46ea36b9987b99d4e0d8c/tensorflow_metadata-1.7.0-py3-none-any.whl (48 kB)
Requirement already satisfied: six in ./anaconda3/envs/py37/lib/python3.7/site-packages (from tensorflow_datasets) (1.15.0)
Requirement already satisfied: typing-extensions; python_version < ""3.8"" in ./anaconda3/envs/py37/lib/python3.7/site-packages (from tensorflow_datasets) (3.7.4.3)
Collecting importlib-resources; python_version < ""3.9""
Downloading https://pypi.apple.com/packages/packages/bd/4d/19cb95029e824d878d5d13b62825839b5b024a62706ea308781a9e2cf534/importlib_resources-5.7.1-py3-none-any.whl (28 kB)
Requirement already satisfied: requests>=2.19.0 in ./anaconda3/lib/python3.7/site-packages (from tensorflow_datasets) (2.22.0)
Collecting promise
Downloading https://pypi.apple.com/packages/packages/cf/9c/fb5d48abfe5d791cd496e4242ebcf87a4bb2e0c3dcd6e0ae68c11426a528/promise-2.3.tar.gz (19 kB)
Collecting googleapis-common-protos<2,>=1.52.0
Downloading https://pypi.apple.com/packages/packages/bd/f7/3b5b207a008cf5a15d623c96c59c8bc3663d4ac2618e23602a0dc2b99808/googleapis_common_protos-1.56.0-py2.py3-none-any.whl (241 kB)
Collecting zipp>=3.1.0; python_version < ""3.10""
Downloading https://pypi.apple.com/packages/packages/80/0e/16a7ee38617aab6a624e95948d314097cc2669edae9b02ded53309941cfc/zipp-3.8.0-py3-none-any.whl (5.4 kB)
Requirement already satisfied: certifi>=2017.4.17 in ./anaconda3/lib/python3.7/site-packages (from requests>=2.19.0->tensorflow_datasets) (2019.11.28)
Requirement already satisfied: chardet<3.1.0,>=3.0.2 in ./anaconda3/lib/python3.7/site-packages (from requests>=2.19.0->tensorflow_datasets) (3.0.4)
Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in ./anaconda3/lib/python3.7/site-packages (from requests>=2.19.0->tensorflow_datasets) (1.25.8)
Requirement already satisfied: idna<2.9,>=2.5 in ./anaconda3/lib/python3.7/site-packages (from requests>=2.19.0->tensorflow_datasets) (2.8)
Building wheels for collected packages: promise
  Building wheel for promise (setup.py): started
  Building wheel for promise (setup.py): finished with status 'done'
  Created wheel for promise: filename=promise-2.3-py3-none-any.whl size=21494 sha256=763fed2298136d167ce5bfb16930dbf4349c9f263a73bb8ac00027cb43de1d48
  Stored in directory: /root/.cache/pip/wheels/0b/1b/71/56b96659fcf28d2983ad511ceadabf12ca962ee5face504f40
Successfully built promise
Installing collected packages: dill, googleapis-common-protos, tensorflow-metadata, zipp, importlib-resources, promise, tensorflow-datasets
  Attempting uninstall: zipp
    Found existing installation: zipp 2.2.0
    Uninstalling zipp-2.2.0:
      Successfully uninstalled zipp-2.2.0
Successfully installed dill-0.3.4 googleapis-common-protos-1.56.0 importlib-resources-5.7.1 promise-2.3 tensorflow-datasets-4.5.2 tensorflow-metadata-1.7.0 zipp-3.8.0

Traceback (most recent call last):
  File ""nt_qrewrite/data_pipeline.py"", line 42, in <module>
    import tensorflow_datasets as tfds
  File ""/mnt/task_runtime/anaconda3/envs/py37/lib/python3.7/site-packages/tensorflow_datasets/__init__.py"", line 43, in <module>
    from tensorflow_datasets.core import tf_compat
  File ""/mnt/task_runtime/anaconda3/envs/py37/lib/python3.7/site-packages/tensorflow_datasets/core/__init__.py"", line 22, in <module>
    tf_compat.ensure_tf_install()
  File ""/mnt/task_runtime/anaconda3/envs/py37/lib/python3.7/site-packages/tensorflow_datasets/core/tf_compat.py"", line 60, in ensure_tf_install
    tf_version = distutils.version.LooseVersion(tf.__version__)
AttributeError: module 'distutils' has no attribute 'version'
```
</details>"
55741,TF Lite (CMake): neon2sse missing license file location,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

2.9.0

### Custom Code

No

### OS Platform and Distribution

Linux

### Mobile device

_No response_

### Python version

3.8

### Bazel version

N/A

### GCC/Compiler version

N/A

### CUDA/cuDNN version

N/A

### GPU model and memory

N/A

### Current Behaviour?

```shell
https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/tools/cmake/modules/OverridableFetchContent.cmake tracks licenses for each dependency of an imported module of TensorFlow Lite. This allows projects using TF Lite to build an aggregate license file for redistribution (e.g https://github.com/google-research/falken/blob/e15aea40aec08e1e5858905e7dd6de7da2e4a1ec/sdk/cpp/CMakeLists.txt#L196 )

https://github.com/tensorflow/tensorflow/commit/1485091a6a64989a01cd2db76d53fe71653ae666 caused a regression in TF Lite's CMake dependencies by manually specifying a download URL where the license URL can no longer be inferred by `OverridableFetchContent.cmake`.

I'm happy to provide a fix that:
* Specifies the license URL and downloaded location.
* Enables license file checking in the TF Lite CMake project.
```


### Standalone code to reproduce the issue

```shell
Add `set(OVERRIDABLE_FETCH_CONTENT_LICENSE_CHECK ON)` near the top of `tensorflow/lite/CMakeLists.txt`, configure the project and wait for configuration to fail due to neon2sse missing a license.
```


### Relevant log output

```shell
$ cd tensorflow/lite
$ mkdir build
$ cd build
$ cmake ..
# lots of output
- Could NOT find CLANG_FORMAT: Found unsuitable version ""0.0"", but required is exact version ""9"" (found CLANG_FORMAT_EXECUTABLE-NOTFOUND)
--
-- Configured Eigen 3.4.90
--
-- Performing Test FARMHASH_HAS_BUILTIN_EXPECT
-- Performing Test FARMHASH_HAS_BUILTIN_EXPECT - Success
-- Looking for strtof_l
-- Looking for strtof_l - found
-- Looking for strtoull_l
-- Looking for strtoull_l - found
CMake Error at tools/cmake/modules/OverridableFetchContent.cmake:571 (message):
  Required license URL not found for neon2sse
Call Stack (most recent call first):
  tools/cmake/modules/neon2sse.cmake:37 (OverridableFetchContent_Populate)
  tools/cmake/modules/Findneon2sse.cmake:18 (include)
  CMakeLists.txt:148 (find_package)


-- Configuring incomplete, errors occurred!
See also ""/home/stewart/src/tensorflow/tensorflow/lite/build/CMakeFiles/CMakeOutput.log"".
See also ""/home/stewart/src/tensorflow/tensorflow/lite/build/CMakeFiles/CMakeError.log"".
```
</details>"
55740,Flatbuffer 2.0.X support,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Build/Install

### Source

source

### Tensorflow Version

2.7 but i think 2.8 as well

### Custom Code

Yes

### OS Platform and Distribution

Conda-forge Liux

### Mobile device

_No response_

### Python version

Any

### Bazel version

4

### GCC/Compiler version

10

### CUDA/cuDNN version

N/A

### GPU model and memory

N/A

### Current Behaviour?

```shell
It seems that some permutations of VerifyField have been removed from flatbuffers 2.0.X.

We were able to build conda-forge tensorflow with flatbuffers 2.0.0 but in some update we hit the bug. I'm attempting to build with 2.0.0 while the issue is resolved.

 https://github.com/Qengineering/TensorFlow_Lite_Pose_RPi_64-bits/issues/3
```


### Standalone code to reproduce the issue

```shell
https://github.com/conda-forge/tensorflow-feedstock/pull/218
```


### Relevant log output
[79-broken_flatbuffers.txt](https://github.com/tensorflow/tensorflow/files/8557928/79-broken_flatbuffers.txt)

</details>"
55738,BatchNorm with mixed_bfloat16 returns empty output,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

tf 2.7.0

### Custom Code

No

### OS Platform and Distribution

Linx Ubuntu 18.04

### Mobile device

_No response_

### Python version

3.8.10

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

11.2/8.1

### GPU model and memory

NVIDIA A100

### Current Behaviour?

```shell
BatchNorm layer using `dtype=""mixed_bfloat16""` or ""bfloat16"" on an NVIDIA A100 returns an empty output with TF 2.7.0. However, when using `dtype=""float32""`, ""float16"", or ""mixed_float16"", an actual input is returned.

As a side note, it is also only with `float32` that I get the message `tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8100`. `mixed_float16` gives the message `Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: A100-PCIE-40GB, compute capability 8.0`. `float16` does not have a message of its own, it seems.

To minimize environmental problems, I used the `tensorflow/tensorflow:2.7.0-gpu` Docker image and ran `docker run -it --gpus all tensorflow/tensorflow:2.7.0-gpu bash`

Thank you in advance for helping solve this issue!
```


### Standalone code to reproduce the issue

```shell
import tensorflow as tf
import numpy as np

test_bn = tf.keras.layers.BatchNormalization(dtype=""mixed_bfloat16"")
test_bn(np.random.randn(16, 24, 24, 32))
```


### Relevant log output

```shell
When using mixed_bfloat16 or bfloat16:

2022-04-25 18:55:54.298268: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-04-25 18:55:54.845911: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38403 MB memory:  -> device: 0, name: A100-PCIE-40GB, pci bus id: 0000:01:00.0, compute capability: 8.0
<tf.Tensor: shape=(0,), dtype=float32, numpy=array([], dtype=float32)>


When using float32:

2022-04-25 18:58:51.935409: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-04-25 18:58:53.684462: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38403 MB memory:  -> device: 0, name: A100-PCIE-40GB, pci bus id: 0000:01:00.0, compute capability: 8.0
2022-04-25 18:58:54.296455: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8100
<tf.Tensor: shape=(16, 24, 24, 32), dtype=float32, numpy=
array([[[[-1.78168976e+00,  8.01364720e-01,  3.17569762e-01, ...,
          -1.08890069e+00, -4.05266196e-01,  9.75035071e-01],
         [-9.24855590e-01,  5.21459460e-01,  1.35295260e+00, ...,
          -1.89387918e+00,  8.45147550e-01, -7.09079564e-01],
         [ 1.49759853e+00,  3.18406433e-01,  2.32584342e-01, ...,
           2.76129186e-01, -2.41327822e-01, -4.68785256e-01],
         ...,

...
```
</details>"
55736,`function_from_graph_def` failure on a model with a loop after Grappler optimization,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

2.9

### Current Behaviour?

On a model with a loop (see simple reproducer below), `wrap_function.function_from_graph_def` fails with a `ValueError` (see log output below). This happens when the model has been frozen and optimized with Grappler. In particular, this seems to happen only if the `""common_subgraph_elimination""` optimizer is run.

I have some understanding of what is happening:
- `lift_to_graph` tries to do a topological sort of the graph. However, because of the loop, it is undefined, so some nodes are not in topological order.
- In `_copy_non_source`, when a node is processed and its inputs haven't been added to the `op_map` yet, a placeholder of the right shape and type is created.
- When the node needs to read its input int32 tensor to get a shape, if the input is a placeholder it results in the exception below.
- The bug is non-deterministic, which might be due to getting the next element in a Python set? So the failure is intermittent, with the pseudo-topological order sometimes being accidentally correct enough.

I'm not sure if the common subgraph elimination is necessary for this bug to happen, but so far I haven't reproduced it without it.


### Standalone code to reproduce the issue

```python
import tensorflow as tf
from tensorflow.python.grappler import tf_optimizer
from tensorflow.core.protobuf import meta_graph_pb2
from tensorflow.python.training.saver import export_meta_graph
from tensorflow.core.protobuf import config_pb2
from tensorflow.python.eager import wrap_function
from tensorflow.python.eager import context
from tensorflow.python.framework import convert_to_constants


class MyModel(tf.Module):
  """"""Simple Fibonacci model.
  To get this bug, I need a loop and two tensor arrays of the same dimensions,
  using a different dtype so the TensorListReserve nodes don't get merged.
  """"""
  @tf.function
  def __call__(self, n):
    ta = tf.TensorArray(tf.float32, size=n)
    tb = tf.TensorArray(tf.int32, size=n)
    ta = ta.write(0, 0.)
    ta = ta.write(1, 1.)
    tb = tb.write(0, 0)
    tb = tb.write(1, 1)

    for i in range(2, n):
      ta = ta.write(i, ta.read(i - 1) + ta.read(i - 2))
      tb = tb.write(i, tb.read(i - 1) + tb.read(i - 2))

    return ta.stack() + tf.cast(tb.stack(), dtype=tf.float32)


def run_grappler(func, graph_def):
  meta_graph = export_meta_graph(graph_def=graph_def, graph=func.graph)

  # Add a collection 'train_op' so that Grappler knows the outputs.
  fetch_collection = meta_graph_pb2.CollectionDef()
  for array in func.inputs + func.outputs:
    fetch_collection.node_list.value.append(array.name)
  meta_graph.collection_def[""train_op""].CopyFrom(fetch_collection)

  # Configure Grappler to execute one pass of common subgraph elimination.
  config = config_pb2.ConfigProto()
  rewrite_options = config.graph_options.rewrite_options
  rewrite_options.optimizers.extend([
    ""common_subgraph_elimination""
  ])
  rewrite_options.meta_optimizer_iterations = 1
  return tf_optimizer.OptimizeGraph(config, meta_graph)

my_model = MyModel()
func = my_model.__call__.get_concrete_function(
    tf.TensorSpec([], tf.int32))

# Freeze the function
frozen_func = convert_to_constants.convert_variables_to_constants_v2(func)

# Run common subgraph elimination
graph_def = frozen_func.graph.as_graph_def()
new_graph_def = run_grappler(func, graph_def)

# Remove the old functions from the context
for f in new_graph_def.library.function:
  while context.context().has_function(f.signature.name):
    context.context().remove_function(f.signature.name)

# Reconstruct a function from the graph definition
new_func = wrap_function.function_from_graph_def(
    new_graph_def,
    [tensor.name for tensor in frozen_func.inputs],
    [tensor.name for tensor in frozen_func.outputs])
```


### Relevant log output

```
Traceback (most recent call last):
  File ""reproducer.py"", line 67, in <module>
    new_func = wrap_function.function_from_graph_def(
  File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/wrap_function.py"", line 657, in function_from_graph_def
    return wrapped_import.prune(
  File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/wrap_function.py"", line 332, in prune
    lift_map = lift_to_graph.lift_to_graph(
  File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/lift_to_graph.py"", line 336, in lift_to_graph
    new_input_mutations, new_control_mutations = _copy_non_source(
  File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/lift_to_graph.py"", line 122, in _copy_non_source
    copied_op = graph.create_op(
  File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/deprecation.py"", line 561, in new_func
    return func(*args, **kwargs)
  File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py"", line 153, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py"", line 1970, in _create_c_op
    raise ValueError(e.message)
ValueError: Received a shape scalar with unknown static value.  A static value of '-1' is required to represent an unknown shape.
```
</details>"
55733,Can not build from source,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Build/Install

### Source

source

### Tensorflow Version

2.9

### Custom Code

No

### OS Platform and Distribution

windows 10

### Mobile device

_No response_

### Python version

3.7

### Bazel version

5.0.0

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
I am tring to build tensorflow with avx2 support. When using bazel getting errors.
bazel version 5.0.0 as mentioned tensorflow-2.9.0-rc1
```


### Standalone code to reproduce the issue

```shell
bazel build //tensorflow/tools/pip_package:build_pip_package
```


### Relevant log output

```shell
PS C:\Users\onurb\Downloads\tensorflow-2.9.0-rc1\tensorflow-2.9.0-rc1> bazel build //tensorflow/tools/pip_package:build_pip_package
Starting local Bazel server and connecting to it...
INFO: Options provided by the client:
  Inherited 'common' options: --isatty=1 --terminal_columns=120
INFO: Reading rc options for 'build' from c:\users\onurb\downloads\tensorflow-2.9.0-rc1\tensorflow-2.9.0-rc1\.bazelrc:
  Inherited 'common' options: --experimental_repo_remote_exec
INFO: Options provided by the client:
  'build' options: --python_path=C:/Users/onurb/AppData/Local/Microsoft/WindowsApps/python.exe
INFO: Reading rc options for 'build' from c:\users\onurb\downloads\tensorflow-2.9.0-rc1\tensorflow-2.9.0-rc1\.bazelrc:
  'build' options: --define framework_shared_object=true --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --enable_platform_specific_config --define=with_xla_support=true --config=short_logs --config=v2 --define=no_aws_support=true --define=no_hdfs_support=true --experimental_cc_shared_library
INFO: Reading rc options for 'build' from c:\users\onurb\downloads\tensorflow-2.9.0-rc1\tensorflow-2.9.0-rc1\.tf_configure.bazelrc:
  'build' options: --action_env PYTHON_BIN_PATH=C:/Users/onurb/AppData/Local/Programs/Python/Python37/python.exe --action_env PYTHON_LIB_PATH=C:/Users/onurb/AppData/Local/Programs/Python/Python37/lib/site-packages --python_path=C:/Users/onurb/AppData/Local/Programs/Python/Python37/python.exe --copt=/d2ReducedOptimizeHugeFunctions --host_copt=/d2ReducedOptimizeHugeFunctions
INFO: Reading rc options for 'build' from c:\users\onurb\downloads\tensorflow-2.9.0-rc1\tensorflow-2.9.0-rc1\.bazelrc:
  'build' options: --deleted_packages=tensorflow/compiler/mlir/tfrt,tensorflow/compiler/mlir/tfrt/benchmarks,tensorflow/compiler/mlir/tfrt/jit/python_binding,tensorflow/compiler/mlir/tfrt/jit/transforms,tensorflow/compiler/mlir/tfrt/python_tests,tensorflow/compiler/mlir/tfrt/tests,tensorflow/compiler/mlir/tfrt/tests/ir,tensorflow/compiler/mlir/tfrt/tests/analysis,tensorflow/compiler/mlir/tfrt/tests/jit,tensorflow/compiler/mlir/tfrt/tests/lhlo_to_tfrt,tensorflow/compiler/mlir/tfrt/tests/tf_to_corert,tensorflow/compiler/mlir/tfrt/tests/tf_to_tfrt_data,tensorflow/compiler/mlir/tfrt/tests/saved_model,tensorflow/compiler/mlir/tfrt/transforms/lhlo_gpu_to_tfrt_gpu,tensorflow/core/runtime_fallback,tensorflow/core/runtime_fallback/conversion,tensorflow/core/runtime_fallback/kernel,tensorflow/core/runtime_fallback/opdefs,tensorflow/core/runtime_fallback/runtime,tensorflow/core/runtime_fallback/util,tensorflow/core/tfrt/common,tensorflow/core/tfrt/eager,tensorflow/core/tfrt/eager/backends/cpu,tensorflow/core/tfrt/eager/backends/gpu,tensorflow/core/tfrt/eager/core_runtime,tensorflow/core/tfrt/eager/cpp_tests/core_runtime,tensorflow/core/tfrt/gpu,tensorflow/core/tfrt/run_handler_thread_pool,tensorflow/core/tfrt/runtime,tensorflow/core/tfrt/saved_model,tensorflow/core/tfrt/graph_executor,tensorflow/core/tfrt/saved_model/tests,tensorflow/core/tfrt/tpu,tensorflow/core/tfrt/utils
INFO: Found applicable config definition build:short_logs in file c:\users\onurb\downloads\tensorflow-2.9.0-rc1\tensorflow-2.9.0-rc1\.bazelrc: --output_filter=DONT_MATCH_ANYTHING
INFO: Found applicable config definition build:v2 in file c:\users\onurb\downloads\tensorflow-2.9.0-rc1\tensorflow-2.9.0-rc1\.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1
INFO: Found applicable config definition build:windows in file c:\users\onurb\downloads\tensorflow-2.9.0-rc1\tensorflow-2.9.0-rc1\.bazelrc: --copt=/W0 --copt=/D_USE_MATH_DEFINES --host_copt=/D_USE_MATH_DEFINES --cxxopt=/std:c++14 --host_cxxopt=/std:c++14 --config=monolithic --copt=-DWIN32_LEAN_AND_MEAN --host_copt=-DWIN32_LEAN_AND_MEAN --copt=-DNOGDI --host_copt=-DNOGDI --copt=/experimental:preprocessor --host_copt=/experimental:preprocessor --linkopt=/DEBUG --host_linkopt=/DEBUG --linkopt=/OPT:REF --host_linkopt=/OPT:REF --linkopt=/OPT:ICF --host_linkopt=/OPT:ICF --verbose_failures --features=compiler_param_file --distinct_host_configuration=false
INFO: Found applicable config definition build:monolithic in file c:\users\onurb\downloads\tensorflow-2.9.0-rc1\tensorflow-2.9.0-rc1\.bazelrc: --define framework_shared_object=false
WARNING: Download from https://storage.googleapis.com/mirror.tensorflow.org/github.com/tensorflow/runtime/archive/093ed77f7d50f75b376f40a71ea86e08cedb8b80.tar.gz failed: class java.io.FileNotFoundException GET returned 404 Not Found
WARNING: Download from https://mirror.bazel.build/github.com/bazelbuild/rules_cc/archive/081771d4a0e9d7d3aa0eed2ef389fa4700dfb23e.tar.gz failed: class java.io.FileNotFoundException GET returned 404 Not Found
ERROR: C:/users/onurb/downloads/tensorflow-2.9.0-rc1/tensorflow-2.9.0-rc1/tensorflow/python/tools/api/generator/BUILD:40:8: In rule 'create_python_api_test', size 'medium' is not a valid size.
ERROR: C:/users/onurb/downloads/tensorflow-2.9.0-rc1/tensorflow-2.9.0-rc1/tensorflow/python/tools/api/generator/BUILD:40:8: In rule 'create_python_api_test', timeout 'illegal' is not a valid timeout.
rc1/tensorflow/tools/pip_package/BUILD:277:10: Target '//tensorflow/python/distribute/experimental/rpc:rpc_ops' contains an error and its package is in error and referenced by '//tensorflow/tools/pip_package:build_pip_package'
ERROR: C:/users/onurb/downloads/tensorflow-2.9.0-rc1/tensorflow-2.9.0-rc1/tensorflow/tools/pip_package/BUILD:277:10: Target '//tensorflow/tools/docs:tf_doctest_lib' contains an error and its package is in error and referenced by '//tensorflow/tools/pip_package:build_pip_package'
ERROR: Analysis of target '//tensorflow/tools/pip_package:build_pip_package' failed; build aborted: Analysis failed
INFO: Elapsed time: 375.138s
INFO: 0 processes.
FAILED: Build did NOT complete successfully (50 packages loaded, 14 targets configured)
    currently loading: tensorflow/lite/python ... (3 packages)
    Fetching https://storage.googleapis.com/.../github.com/bazelbuild/rules_android/archive/v0.1.1.zip
    Fetching https://storage.googleapis.com/.../github.com/google/flatbuffers/archive/v1.12.0.tar.gz
```
</details>"
55728,@local_config_cc//:toolchain' does not contain a toolchain for cpu 'arm64-v8a,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Build/Install

### Source

source

### Tensorflow Version

v2.9.0-rc1

### Custom Code

No

### OS Platform and Distribution

Linux Ubuntu 20.04

### Mobile device

_No response_

### Python version

3.8.10

### Bazel version

5.0.0

### GCC/Compiler version

9.4.0

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
I want to build a benchmark_model binary for Android platform, so I run the following command as the readme.md suggests:
`bazel build -c opt --config=android_arm64 tensorflow/lite/tools/benchmark:benchmark_model`
but got the error:
@local_config_cc//:toolchain' does not contain a toolchain for cpu 'arm64-v8a'
and I found where this error take place:
cc_toolchain_suite(
     name = ""toolchain"",
     toolchains = {
         ""k8|compiler"": "":cc-compiler-k8"",
         ""k8"": "":cc-compiler-k8"",
         ""armeabi-v7a|compiler"": "":cc-compiler-armeabi-v7a"",
         ""armeabi-v7a"": "":cc-compiler-armeabi-v7a"",
     },
)
So I wonder that why do you take ""arm64-v8a"" for an example while it's not supported, and how could I build a benchmark_model for android arm64?
```


### Standalone code to reproduce the issue

```shell
`bazel build -c opt --config=android_arm64 tensorflow/lite/tools/benchmark:benchmark_model`
```


### Relevant log output

_No response_</details>"
55727,Inconsistent keras model saving and loading,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

tf 2.5

### Custom Code

Yes

### OS Platform and Distribution

ubuntu 20.04

### Mobile device

_No response_

### Python version

3.7

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
A bug happened!
I can load and save model parameters through save_weight, but after saving the model with save, load the model and inference, the following error is reported.
ValueError: Dimension 1 in both shapes must be equal, but are 127 and 45. Shapes are [1,127] and [1,45]. for '{{node concat}} = ConcatV2[N=2, T=DT_FLOAT, Tidx=DT_INT32](inputs, inputs_1, concat/axis)' with input shapes: [1,127,128], [1,45,128], [] and with computed input tensors: input[2] = <2>.
```


### Standalone code to reproduce the issue

```shell
https://colab.research.google.com/drive/1AdwLdKwxIBJI_qqAGJOGhHU4WDyjilyT#scrollTo=0DU8b93Twd7i&uniqifier=1
```


### Relevant log output

```shell
InvalidArgumentError: Exception encountered when calling layer ""concatenate"" (type Concatenate).

ConcatOp : Dimension 1 in both shapes must be equal: shape[0] = [1,127,128] vs. shape[1] = [1,45,128] [Op:ConcatV2] name: concat

Call arguments received:
  • inputs=['tf.Tensor(shape=(1, 127, 128), dtype=float32)', 'tf.Tensor(shape=(1, 45, 128), dtype=float32)']
```
</details>"
55725,"Cannot install 2.9.0rc1, only available for few OS and Python versions","<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Build/Install

### Source

binary

### Tensorflow Version

2.9.0rc1

### Custom Code

No

### OS Platform and Distribution

Linux Ubuntu

### Mobile device

_No response_

### Python version

3.8

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

I cannot install latest 2.9.0rc1 package via pip:

```shell
$ pip install --pre tensorflow-cpu==2.9.0rc1
ERROR: Could not find a version that satisfies the requirement tensorflow-cpu==2.9.0rc1 (from versions: 2.2.0, 2.2.1, 2.2.2, 2.2.3, 2.3.0, 2.3.1, 2.3.2, 2.3.3, 2.3.4, 2.4.0, 2.4.1, 2.4.2, 2.4.3, 2.4.4, 2.5.0, 2.5.1, 2.5.2, 2.5.3, 2.6.0, 2.6.1, 2.6.2, 2.6.3, 2.7.0, 2.7.1, 2.8.0, 2.9.0rc0)
ERROR: No matching distribution found for tensorflow-cpu==2.9.0rc1
```

Installing version rc0 works perfectly fine:
```
$ pip install --pre tensorflow-cpu==2.9.0rc0
Collecting tensorflow-cpu==2.9.0rc0
  Downloading tensorflow_cpu-2.9.0rc0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (207.4 MB)
...
```

Reason is, rc1 is available only for a few OS and Python versions, and `manylinux` and `py38` is not among them: https://pypi.org/project/tensorflow-cpu/2.9.0rc1/#files

Has the release been incomplete?

### Standalone code to reproduce the issue
Run with Linux and Python != 3.7:

```shell
pip install --pre tensorflow-cpu==2.9.0rc1
```


### Relevant log output
See above.
</details>"
55724,AttributeError: module 'tensorflow.compat.v2.__internal__.distribute' has no attribute 'strategy_supports_no_merge_call',"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

v2.7.0-rc1-69-gc256c071bb2 2.7.0

### Custom Code

Yes

### OS Platform and Distribution

NAME=""CentOS Linux"" VERSION=""7 (Core)""

### Mobile device

_No response_

### Python version

Python 3.7.13

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

Cuda 8.x and Cuda 11.x

### GPU model and memory

NVIDIA GeForce GTX 1080 Ti  11178MiB

### Current Behaviour?

```shell
When I want to train my model I get the error shown below. I couldn't find any solution our hint. 
Can you explain why this error occurs and how to solve it?

Many thanks in advance!
```


### Standalone code to reproduce the issue

```shell
This error arises in my own code, which is a simple U-net taking in 3D numpy arrays
```


### Relevant log output

```shell
Traceback (most recent call last):
  File ""./training.py"", line 299, in launch
    sample_weight=sample_weight,
  File ""./python3.7/site-packages/keras/engine/training.py"", line 2093, in train_on_batch
    logs = self.train_function(iterator)
  File ""./python3.7/site-packages/tensorflow/python/util/traceback_utils.py"", line 153, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File ""./.local/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py"", line 1129, in autograph_handler
    raise e.ag_error_metadata.to_exception(e)
AttributeError: in user code:

    File ""./lib/python3.7/site-packages/keras/engine/training.py"", line 1021, in train_function  *
        return step_function(self, iterator)
    File ""./lib/python3.7/site-packages/keras/engine/training.py"", line 1010, in step_function  **
        outputs = model.distribute_strategy.run(run_step, args=(data,))
    File ""./lib/python3.7/site-packages/keras/engine/training.py"", line 1000, in run_step  **
        outputs = model.train_step(data)
    File ""./lib/python3.7/site-packages/keras/engine/training.py"", line 863, in train_step
        self.optimizer.minimize(loss, self.trainable_variables, tape=tape)
    File ""./lib/python3.7/site-packages/keras/optimizer_v2/optimizer_v2.py"", line 532, in minimize
        return self.apply_gradients(grads_and_vars, name=name)
    File ""./lib/python3.7/site-packages/keras/optimizer_v2/optimizer_v2.py"", line 668, in apply_gradients
        grads_and_vars = self._aggregate_gradients(grads_and_vars)
    File ""./lib/python3.7/site-packages/keras/optimizer_v2/optimizer_v2.py"", line 484, in _aggregate_gradients
        return self.gradient_aggregator(grads_and_vars)
    File ""./lib/python3.7/site-packages/keras/optimizer_v2/utils.py"", line 33, in all_reduce_sum_gradients
        if tf.__internal__.distribute.strategy_supports_no_merge_call():

    AttributeError: module 'tensorflow.compat.v2.__internal__.distribute' has no attribute 'strategy_supports_no_merge_call'
```
</details>"
55723,Missing `f` prefix on f-strings,"Some strings looks like they're meant to be f-strings but are missing the `f` prefix meaning variable interpolation won't happen.

https://github.com/tensorflow/tensorflow/blob/dfe3b83eeb47752bf26a6523ab7f42c1caa58d4a/tensorflow/python/data/experimental/ops/lookup_ops.py#L168
https://github.com/tensorflow/tensorflow/blob/dfe3b83eeb47752bf26a6523ab7f42c1caa58d4a/tensorflow/python/tpu/tpu_sharding.py#L86
https://github.com/tensorflow/tensorflow/blob/dfe3b83eeb47752bf26a6523ab7f42c1caa58d4a/tensorflow/python/ops/resource_variable_ops.py#L1762
https://github.com/tensorflow/tensorflow/blob/dfe3b83eeb47752bf26a6523ab7f42c1caa58d4a/tensorflow/python/ops/critical_section_ops.py#L197
https://github.com/tensorflow/tensorflow/blob/dfe3b83eeb47752bf26a6523ab7f42c1caa58d4a/tensorflow/python/ops/lookup_ops.py#L716
https://github.com/tensorflow/tensorflow/blob/dfe3b83eeb47752bf26a6523ab7f42c1caa58d4a/tensorflow/python/distribute/tpu_strategy.py#L1345

I found this issue automatically. I'm a bot. Beep Boop 🦊. See other issues I found in your repo [here](https://codereview.doctor/tensorflow/tensorflow)"
55721,How to import Keras BatchNormalization to use with Cuda,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Support

### Source

binary

### Tensorflow Version

2.8.0

### Custom Code

No

### OS Platform and Distribution

Pop OS 21.10 Linux 5.15.34

### Mobile device

_No response_

### Python version

3.9.7

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

Driver Version: 510.54 | CUDA Version: 11.6 | cuDNN version: 8400

### GPU model and memory

NVIDIA GeForce GTX 1050 Ti 4096MiB

### Current Behaviour?

I cannot import BatchNormalization from Keras. It seems that tensorflow.python.keras has no normalization tools at all, but in standalone Keras BatchNormalization is available. 
I have to use Keras from Tensorflow to run it on GPU properly (?)

So how can I use Normalization in my project?
I've tried to use BatchNormalization from standalone Keras but it crashes:

```shell
'2022-04-23 20:07:46.070877: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at fused_batch_norm_op.cc:1380 : RESOURCE_EXHAUSTED: OOM when allocating tensor with shape[256,64,48,48] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator gpu_async_0
Traceback (most recent call last):
  File ""/home/oleksii/PycharmProjects/ai_lab1/main.py"", line 110, in <module>
    model.fit(XTrain, YTrain, batch_size=256, epochs=50, validation_split=0.1, verbose=1)
  File ""/home/oleksii/PycharmProjects/venv/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py"", line 1189, in fit
    tmp_logs = self.train_function(iterator)
  File ""/home/oleksii/PycharmProjects/venv/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py"", line 153, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File ""/home/oleksii/PycharmProjects/venv/lib/python3.9/site-packages/tensorflow/python/eager/execute.py"", line 54, in quick_execute
    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
tensorflow.python.framework.errors_impl.ResourceExhaustedError: Graph execution error:

Detected at node 'sequential/module_wrapper_3/batch_normalization_3/FusedBatchNormV3' defined at (most recent call last):
    File ""/home/oleksii/PycharmProjects/ai_lab1/main.py"", line 110, in <module>
      model.fit(XTrain, YTrain, batch_size=256, epochs=50, validation_split=0.1, verbose=1)
    File ""/home/oleksii/PycharmProjects/venv/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py"", line 1189, in fit
      tmp_logs = self.train_function(iterator)
    File ""/home/oleksii/PycharmProjects/venv/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py"", line 859, in train_function
      return step_function(self, iterator)
    File ""/home/oleksii/PycharmProjects/venv/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py"", line 849, in step_function
      outputs = model.distribute_strategy.run(run_step, args=(data,))
    File ""/home/oleksii/PycharmProjects/venv/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py"", line 842, in run_step
      outputs = model.train_step(data)
    File ""/home/oleksii/PycharmProjects/venv/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py"", line 799, in train_step
      y_pred = self(x, training=True)
    File ""/home/oleksii/PycharmProjects/venv/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py"", line 1044, in __call__
      outputs = call_fn(inputs, *args, **kwargs)
    File ""/home/oleksii/PycharmProjects/venv/lib/python3.9/site-packages/tensorflow/python/keras/engine/sequential.py"", line 379, in call
      return super(Sequential, self).call(inputs, training=training, mask=mask)
    File ""/home/oleksii/PycharmProjects/venv/lib/python3.9/site-packages/tensorflow/python/keras/engine/functional.py"", line 419, in call
      return self._run_internal_graph(
    File ""/home/oleksii/PycharmProjects/venv/lib/python3.9/site-packages/tensorflow/python/keras/engine/functional.py"", line 555, in _run_internal_graph
      outputs = node.layer(*args, **kwargs)
    File ""/home/oleksii/PycharmProjects/venv/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py"", line 1044, in __call__
      outputs = call_fn(inputs, *args, **kwargs)
    File ""/home/oleksii/PycharmProjects/venv/lib/python3.9/site-packages/tensorflow/python/keras/engine/functional.py"", line 1446, in call
      return getattr(self._module, self._method_name)(*args, **kwargs)
    File ""/home/oleksii/PycharmProjects/venv/lib/python3.9/site-packages/keras/utils/traceback_utils.py"", line 64, in error_handler
      return fn(*args, **kwargs)
    File ""/home/oleksii/PycharmProjects/venv/lib/python3.9/site-packages/keras/engine/base_layer.py"", line 1096, in __call__
      outputs = call_fn(inputs, *args, **kwargs)
    File ""/home/oleksii/PycharmProjects/venv/lib/python3.9/site-packages/keras/utils/traceback_utils.py"", line 92, in error_handler
      return fn(*args, **kwargs)
    File ""/home/oleksii/PycharmProjects/venv/lib/python3.9/site-packages/keras/layers/normalization/batch_normalization.py"", line 767, in call
      outputs = self._fused_batch_norm(inputs, training=training)
    File ""/home/oleksii/PycharmProjects/venv/lib/python3.9/site-packages/keras/layers/normalization/batch_normalization.py"", line 623, in _fused_batch_norm
      output, mean, variance = control_flow_util.smart_cond(
    File ""/home/oleksii/PycharmProjects/venv/lib/python3.9/site-packages/keras/utils/control_flow_util.py"", line 105, in smart_cond
      return tf.__internal__.smart_cond.smart_cond(
    File ""/home/oleksii/PycharmProjects/venv/lib/python3.9/site-packages/keras/layers/normalization/batch_normalization.py"", line 589, in _fused_batch_norm_training
      return tf.compat.v1.nn.fused_batch_norm(
Node: 'sequential/module_wrapper_3/batch_normalization_3/FusedBatchNormV3'
OOM when allocating tensor with shape[256,64,48,48] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator gpu_async_0
	 [[{{node sequential/module_wrapper_3/batch_normalization_3/FusedBatchNormV3}}]]
Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.
 [Op:__inference_train_function_2649]'
```



If I'm not using normalization (which is of course wrong), there are a lot of errors like this:
```shell
gpu_async_0 cuMemAllocAsync failed to allocate 1375879168 bytes: CUDA error: out of memory (CUDA_ERROR_OUT_OF_MEMORY)
```
which is also bothering me. (however, it works even with these errors) I've tried to google it but I had found nothing that has worked for me.

I have used pip 22.0.4 to install Tensorflow.
My rep with this code https://github.com/lesha198a/ai_lab1

Any help will be appreciated.


### Standalone code to reproduce the issue

```shell
from tensorflow.python.keras.layers import BatchNormalization
```


### Relevant log output

```shell
Traceback (most recent call last):
  File ""/home/oleksii/PycharmProjects/ai_lab1/main.py"", line 5, in <module>
    from tensorflow.python.keras.layers import BatchNormalization
ImportError: cannot import name 'BatchNormalization' from 'tensorflow.python.keras.layers' (/home/oleksii/PycharmProjects/venv/lib/python3.9/site-packages/tensorflow/python/keras/layers/__init__.py)
```
</details>"
55720,pip install tensorflow pip install tf-nightly-gpu,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Documentation Feature Request

### Source

source

### Tensorflow Version

tf 2.8

### Custom Code

Yes

### OS Platform and Distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
A bug happened!
```


### Standalone code to reproduce the issue

```shell
Notes/any notes
```


### Relevant log output

```shell
pip install tensorflow
pip install tf-nightly-gpu
```
</details>"
55719,Error cascade on model.save() version 2.9.0-rc0,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

2.9.0-rc0

### Custom Code

No

### OS Platform and Distribution

Linux Ubuntu 21.09

### Mobile device

_No response_

### Python version

3.9.7

### Bazel version

5.1.1

### GCC/Compiler version

11.2.0

### CUDA/cuDNN version

_No response_

### GPU model and memory

Intel Core i7 980

### Current Behaviour?

```shell
Error cascade on saving model after training.

Saves fine before training. 

Many thanks
Brendan
```


### Standalone code to reproduce the issue

```shell
import tensorflow as tf
from tensorflow import keras
import pandas as pd

print(tf.version.GIT_VERSION, tf.version.VERSION)

def baseline_model():
    b_model = keras.Sequential()
    b_model.add(keras.layers.Flatten(input_shape=[5]))
    
    b_model.add(keras.layers.Dense(units=512, activation='relu', name='dense_1'))
    b_model.add(keras.layers.Dropout(0.2))
    b_model.add(keras.layers.Dense(units=32, activation='relu', name='dense_2'))
    b_model.add(keras.layers.Dense(3, activation='softmax'))
    
    b_model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001),
                  loss=keras.losses.CategoricalCrossentropy(),
                  metrics=[""accuracy""])
    return b_model


f = {'feature1': [1, 1], 'feature2': [2, 2], 'feature3': [3, 3], 'feature4': [4, 4], 'feature5': [5, 5] }
c = {'cat1': [0, 1 ], 'cat2': [1, 0], 'cat3': [0, 0] }
x_train = pd.DataFrame(f)
y_train = pd.DataFrame(c)
                                 
model = baseline_model()
model.save('grrrrr_untrained')
model.fit(x_train, y_train, epochs=2, verbose=1)
model.save('grrrrr_trained')
```


### Relevant log output

```shell
v1.12.1-73396-g3903c35b3bf 2.9.0-rc0
2022-04-23 10:22:59.360155: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
Epoch 1/2

1/1 [==============================] - ETA: 0s - loss: 0.9775 - accuracy: 0.5000
1/1 [==============================] - 1s 612ms/step - loss: 0.9775 - accuracy: 0.5000
Epoch 2/2

1/1 [==============================] - ETA: 0s - loss: 0.8341 - accuracy: 0.5000
1/1 [==============================] - 0s 3ms/step - loss: 0.8341 - accuracy: 0.5000
Traceback (most recent call last):
...
RuntimeError: in user code:
    RuntimeError: Mismatching ReplicaContext.
...
ValueError: Error when tracing gradients for SavedModel.
...
Check the error log to see the error that was raised when converting a gradient function to a concrete function. You may need to update the custom gradient, or disable saving gradients with the option tf.saved_model.SaveOptions(custom_gradients=False).
	Problematic op name: Adam/IdentityN
	Gradient inputs: (<tf.Tensor 'gradient_tape/sequential/dense_1/MatMul/MatMul:0' shape=(5, 512) dtype=float32>, <tf.Tensor 'gradient_tape/sequential/dense_1/BiasAdd/BiasAddGrad:0' shape=(512,) dtype=float32>, <tf.Tensor 'gradient_tape/sequential/dense_2/MatMul/MatMul_1:0' shape=(512, 32) dtype=float32>, <tf.Tensor 'gradient_tape/sequential/dense_2/BiasAdd/BiasAddGrad:0' shape=(32,) dtype=float32>, <tf.Tensor 'gradient_tape/sequential/dense/MatMul/MatMul_1:0' shape=(32, 3) dtype=float32>, <tf.Tensor 'gradient_tape/sequential/dense/BiasAdd/BiasAddGrad:0' shape=(3,) dtype=float32>, <tf.Tensor 'gradient_tape/sequential/dense_1/MatMul/MatMul:0' shape=(5, 512) dtype=float32>, <tf.Tensor 'gradient_tape/sequential/dense_1/BiasAdd/BiasAddGrad:0' shape=(512,) dtype=float32>, <tf.Tensor 'gradient_tape/sequential/dense_2/MatMul/MatMul_1:0' shape=(512, 32) dtype=float32>, <tf.Tensor 'gradient_tape/sequential/dense_2/BiasAdd/BiasAddGrad:0' shape=(32,) dtype=float32>, <tf.Tensor 'gradient_tape/sequential/dense/MatMul/MatMul_1:0' shape=(32, 3) dtype=float32>, <tf.Tensor 'gradient_tape/sequential/dense/BiasAdd/BiasAddGrad:0' shape=(3,) dtype=float32>)
```
</details>"
55717,Non-OK-status: tensorflow::Env::Default()->DeleteFile(ptx_path) status: Permission denied,"### System information
Ubuntu 20.04.2 LTS (GNU/Linux 5.4.0-74-generic x86_64)
TensorFlow 2.0.0 installed by anaconda
gcc (Ubuntu 8.4.0-3ubuntu2) 8.4.0
NVIDIA-SMI 460.80 Driver Version: 460.80 CUDA Version: 11.2 (10.1 installed in fact)

### Describe the problem
When I am running with my tensorflow program, it seems that when it meets some conditions, my program turns out to crash like below, and then I found my root directory has become read-only. But it doesn't happen by accident, for I have repaired my disk with e2fsck for times, but when the same things happened, everything repeated.
Every time the same things happened, new files would appear in the working directory, more details are presented as below:
![1](https://user-images.githubusercontent.com/94270103/164766755-974a2e93-d4a9-4d40-a9f6-9965c1600e83.png)
![2](https://user-images.githubusercontent.com/94270103/164766731-d8cc25d5-2e43-4f9c-b816-f6a9670c0331.png)
I am not sure whether my disk caused the error of my program or the program just caused the disk error.
Logs and part of my code are presented below, thanks for your support!
### Source code / logs
![3](https://user-images.githubusercontent.com/94270103/164767903-10f30ba7-d436-44ac-b186-ce8f89ed1edc.png)
![image](https://user-images.githubusercontent.com/94270103/164768296-173dd2d0-cedc-4510-a8b1-9ae29289c3d6.png)
I use more than one DL framework in my program, and other frameworks seem still work.

"
55715,./build_all_linux.sh ,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

tf1.15

### Custom Code

No

### OS Platform and Distribution

ubuntu18.04

### Mobile device

ubuntu18.04

### Python version

python==3.6.13

### Bazel version

0.26.1

### GCC/Compiler version

7.5

### CUDA/cuDNN version

CPU

### GPU model and memory

CPU

### Current Behaviour?

```shell
A bug happened!

tensorflow/contrib/makefile# ./build_all_linux.sh


  inflating: /tmp/tmp.8jIp3DIvsk/gemmlowp-12fed0cd7cfcd9e169bf1925bc3a7a58725fdcc3/test/ios/gemmlowp_test/AppDelegate.h  
  inflating: /tmp/tmp.8jIp3DIvsk/gemmlowp-12fed0cd7cfcd9e169bf1925bc3a7a58725fdcc3/test/ios/gemmlowp_test/AppDelegate.mm  
   creating: /tmp/tmp.8jIp3DIvsk/gemmlowp-12fed0cd7cfcd9e169bf1925bc3a7a58725fdcc3/test/ios/gemmlowp_test/Base.lproj/
  inflating: /tmp/tmp.8jIp3DIvsk/gemmlowp-12fed0cd7cfcd9e169bf1925bc3a7a58725fdcc3/test/ios/gemmlowp_test/Base.lproj/LaunchScreen.xib  
  inflating: /tmp/tmp.8jIp3DIvsk/gemmlowp-12fed0cd7cfcd9e169bf1925bc3a7a58725fdcc3/test/ios/gemmlowp_test/Base.lproj/Main.storyboard  
   creating: /tmp/tmp.8jIp3DIvsk/gemmlowp-12fed0cd7cfcd9e169bf1925bc3a7a58725fdcc3/test/ios/gemmlowp_test/Images.xcassets/
   creating: /tmp/tmp.8jIp3DIvsk/gemmlowp-12fed0cd7cfcd9e169bf1925bc3a7a58725fdcc3/test/ios/gemmlowp_test/Images.xcassets/AppIcon.appiconset/
  inflating: /tmp/tmp.8jIp3DIvsk/gemmlowp-12fed0cd7cfcd9e169bf1925bc3a7a58725fdcc3/test/ios/gemmlowp_test/Images.xcassets/AppIcon.appiconset/Contents.json  
  inflating: /tmp/tmp.8jIp3DIvsk/gemmlowp-12fed0cd7cfcd9e169bf1925bc3a7a58725fdcc3/test/ios/gemmlowp_test/Info.plist  
  inflating: /tmp/tmp.8jIp3DIvsk/gemmlowp-12fed0cd7cfcd9e169bf1925bc3a7a58725fdcc3/test/ios/gemmlowp_test/ViewController.h  
  inflating: /tmp/tmp.8jIp3DIvsk/gemmlowp-12fed0cd7cfcd9e169bf1925bc3a7a58725fdcc3/test/ios/gemmlowp_test/ViewController.m  
  inflating: /tmp/tmp.8jIp3DIvsk/gemmlowp-12fed0cd7cfcd9e169bf1925bc3a7a58725fdcc3/test/ios/gemmlowp_test/main.m  
  inflating: /tmp/tmp.8jIp3DIvsk/gemmlowp-12fed0cd7cfcd9e169bf1925bc3a7a58725fdcc3/test/test.cc  
  inflating: /tmp/tmp.8jIp3DIvsk/gemmlowp-12fed0cd7cfcd9e169bf1925bc3a7a58725fdcc3/test/test.h  
  inflating: /tmp/tmp.8jIp3DIvsk/gemmlowp-12fed0cd7cfcd9e169bf1925bc3a7a58725fdcc3/test/test_allocator.cc  
  inflating: /tmp/tmp.8jIp3DIvsk/gemmlowp-12fed0cd7cfcd9e169bf1925bc3a7a58725fdcc3/test/test_blocking_counter.cc  
  inflating: /tmp/tmp.8jIp3DIvsk/gemmlowp-12fed0cd7cfcd9e169bf1925bc3a7a58725fdcc3/test/test_data.cc  
  inflating: /tmp/tmp.8jIp3DIvsk/gemmlowp-12fed0cd7cfcd9e169bf1925bc3a7a58725fdcc3/test/test_data.h  
  inflating: /tmp/tmp.8jIp3DIvsk/gemmlowp-12fed0cd7cfcd9e169bf1925bc3a7a58725fdcc3/test/test_fixedpoint.cc  
  inflating: /tmp/tmp.8jIp3DIvsk/gemmlowp-12fed0cd7cfcd9e169bf1925bc3a7a58725fdcc3/test/test_math_helpers.cc  
   creating: /tmp/tmp.8jIp3DIvsk/gemmlowp-12fed0cd7cfcd9e169bf1925bc3a7a58725fdcc3/todo/
  inflating: /tmp/tmp.8jIp3DIvsk/gemmlowp-12fed0cd7cfcd9e169bf1925bc3a7a58725fdcc3/todo/armv8-64bit-kernel-for-less-than-8-bit.txt  
  inflating: /tmp/tmp.8jIp3DIvsk/gemmlowp-12fed0cd7cfcd9e169bf1925bc3a7a58725fdcc3/todo/error-diffusion-experiments.txt  
  inflating: /tmp/tmp.8jIp3DIvsk/gemmlowp-12fed0cd7cfcd9e169bf1925bc3a7a58725fdcc3/todo/fast-gemv.txt  
  inflating: /tmp/tmp.8jIp3DIvsk/gemmlowp-12fed0cd7cfcd9e169bf1925bc3a7a58725fdcc3/todo/less-than-8-bit-without-requantization.txt  
  inflating: /tmp/tmp.8jIp3DIvsk/gemmlowp-12fed0cd7cfcd9e169bf1925bc3a7a58725fdcc3/todo/multi-threading-experiments.txt  
  inflating: /tmp/tmp.8jIp3DIvsk/gemmlowp-12fed0cd7cfcd9e169bf1925bc3a7a58725fdcc3/todo/neon-depth-major-sources-packing.txt  
  inflating: /tmp/tmp.8jIp3DIvsk/gemmlowp-12fed0cd7cfcd9e169bf1925bc3a7a58725fdcc3/todo/remove-default-template-param-values.txt  
  inflating: /tmp/tmp.8jIp3DIvsk/gemmlowp-12fed0cd7cfcd9e169bf1925bc3a7a58725fdcc3/todo/x86-kernels.txt  
downloading https://github.com/google/googletest/archive/refs/tags/release-1.8.0.tar.gz

gzip: stdin: unexpected end of file
tar: Child returned status 1
tar: Error is not recoverable: exiting now
```


### Standalone code to reproduce the issue

```shell
tensorflow/contrib/makefile# ./build_all_linux.sh

gzip: stdin: unexpected end of file
tar: Child returned status 1
tar: Error is not recoverable: exiting now
```


### Relevant log output

```shell
tensorflow/contrib/makefile# ./build_all_linux.sh

gzip: stdin: unexpected end of file
tar: Child returned status 1
tar: Error is not recoverable: exiting now
```
</details>"
55713,TPU Execution Failure,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Support

### Source

binary

### Tensorflow Version

tf 2.6

### Custom Code

Yes

### OS Platform and Distribution

_No response_

### Mobile device

20.04.1 Ubuntu SMP

### Python version

Python 3.8.10

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
Trying to get Waymo Occupancy Flow Tutorial https://github.com/waymo-research/waymo-open-dataset/blob/master/tutorial/tutorial_occupancy_flow.ipynb
 to run on TPU. It works on CPU, but when I modify code for TPU execution it fails.
```


### Standalone code to reproduce the issue

```shell
162 with strategy.scope():
163     model_inputs = _make_model_inputs(timestep_grids, vis_grids)
164     model = _make_model(model_inputs=model_inputs, config=config)
```


### Relevant log output

```shell
58562022-04-22 10:58:53.161278: I tensorflow/core/tpu/graph_rewrite/encapsulate_tpu_computation\
    s_pass.cc:263] Subgraph fingerprint:7296879430535566001
58572022-04-22 10:58:54.520719: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:801] mo\
    del_pruner failed: Invalid argument: Graph does not contain terminal node Adam/Adam/AssignA\
    ddVariableOp.
```
</details>"
55711,"can't use keras function, 'CategoryCrossing' in tensorflow version 2.8","<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Build/Install

### Source

source

### Tensorflow Version

tf 2.8

### Custom Code

Yes

### OS Platform and Distribution

Google Cloud Vertex AI TensorFlow:2.6 notebook

### Mobile device

_No response_

### Python version

3.7.12

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

4 vCPUs, 15 GB RAM & NVIDIA Tesla T4 x 1 	

### Current Behaviour?

```shell
The keras function 'CategoryCrossing()' was working fine in tf version 2.6.2 but throws AttributeError when used in tf version 2.8.

Is this a version issue ? or was the 'Cross Category' function branched under a different library in the 2.8 version?
```


### Standalone code to reproduce the issue

```shell
day_hour_cross = tf.keras.layers.experimental.preprocessing.CategoryCrossing()([day_category, hour_category])
```


### Relevant log output

```shell
AttributeError: module 'keras.api._v2.keras.layers.experimental.preprocessing' has no attribute 'CategoryCrossing'
```
</details>"
55710,Tensorflow 2.8.0 Limiting GPU memory growth fails.,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

tf 2.8

### Custom Code

Yes

### OS Platform and Distribution

Ubuntu 16.04

### Mobile device

_No response_

### Python version

3.7.6

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

CUDA 11.3.1 cuDNN 8.2.1

### GPU model and memory

_No response_

### Current Behaviour?

```shell
My GPU card is Nivida RTX 2080Ti. Follow the GPU usage instruction on the website, I want to limit my gpu memory growth during a HMC test and use the code as follows:
'''
import tensorflow as tf
gpus = tf.config.experimental.list_physical_devices('GPU')
if gpus:
  # Restrict TensorFlow to only allocate 1GB of memory on the first GPU
  try:
    tf.config.experimental.set_virtual_device_configuration(
        gpus[0],
        [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=1024)])
    logical_gpus = tf.config.experimental.list_logical_devices('GPU')
    print(len(gpus), ""Physical GPUs,"", len(logical_gpus), ""Logical GPUs"")
  except RuntimeError as e:
import jax
import jax.numpy as jnp
import matplotlib.pyplot as plt

# from colabtools import adhoc_import
from contextlib import ExitStack

ADHOC = True
CLIENT = 'fig-export-fig_tree-change-451-3e0a679e9746'

import tensorflow_probability.substrates.jax as tfp
from fun_mc import using_jax as fun_mc
tfd = tfp.distributions



dist = tfd.Normal(0., 1.)
n_chains = 1024
n_super_chains = 4
n_steps = 100
n_sub_chains = n_chains // n_super_chains

def target_log_prob_fn(x):
  return dist.log_prob(x), ()


def kernel(hmc_state, seed):
  hmc_seed, seed = jax.random.split(seed)
  hmc_state, hmc_extra = fun_mc.hamiltonian_monte_carlo_step(
      hmc_state,
      target_log_prob_fn=target_log_prob_fn,
      step_size=0.5,
      num_integrator_steps=1,
      seed=hmc_seed)
  return (hmc_state, seed), (hmc_state.state, hmc_extra.is_accepted)



init_x=dist.sample([n_chains], seed=jax.random.PRNGKey(1))

_, (chain, is_accepted) = fun_mc.trace((fun_mc.hamiltonian_monte_carlo_init(init_x,
    target_log_prob_fn), jax.random.PRNGKey(1)), kernel, 1000)

init_x2 = dist.sample([n_super_chains], seed=jax.random.PRNGKey(3))
init_x2 = jnp.repeat(init_x2, n_sub_chains)
#init_x2 = dist.sample([num_chains], seed=jax.random.PRNGKey(3))
init_x2 = init_x2.reshape([n_super_chains, n_sub_chains])

_, (chain2, is_accepted2) = fun_mc.trace((fun_mc.hamiltonian_monte_carlo_init(init_x2,
    target_log_prob_fn), jax.random.PRNGKey(3)), kernel, 1000)

chain = jnp.concatenate([init_x[jnp.newaxis], chain], 0)
chain2 = jnp.concatenate([init_x2[jnp.newaxis], chain2], 0)
'''
```


### Standalone code to reproduce the issue

```shell
However, I find it failed to control my gpu usage and the code use all the memory in GPU 0. I want to know how to make the limitation works. Thank you !
```


### Relevant log output

_No response_</details>"
55709,The tflite model has a custom layer and cannot achieve variable-length input,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Feature Request

### Source

source

### Tensorflow Version

tf 2.5

### Custom Code

Yes

### OS Platform and Distribution

ubuntu 20.04

### Mobile device

_No response_

### Python version

3.7

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
A bug happened!I tried the steps as https://github.com/tensorflow/tensorflow/issues/24607, but the input shape of the interpreter is still fixed. The model has two custom layers.
```


### Standalone code to reproduce the issue

```shell
with tf.io.gfile.GFile('model.tflite', 'wb') as f:
    f.write(tflite_model)
    
interpreter = tf.lite.Interpreter(model_path='model.tflite')
```


### Relevant log output

_No response_</details>"
55708,Submit and test model is not working while I'm taking the TensorFlow exam,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

2.X

### Custom Code

No

### OS Platform and Distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
It keeps uploading whene I try to submit and test a model
```


### Standalone code to reproduce the issue

```shell
I could not test and submit my models while I am taking the exam there is somthing wrong with the plugin please I need your help !
```


### Relevant log output

```shell
java.net.SocketTimeoutException: Read timed out
	at java.base/java.net.SocketInputStream.socketRead0(Native Method)
	at java.base/java.net.SocketInputStream.socketRead(SocketInputStream.java:115)
	at java.base/java.net.SocketInputStream.read(SocketInputStream.java:168)
	at java.base/java.net.SocketInputStream.read(SocketInputStream.java:140)
	at java.base/sun.security.ssl.SSLSocketInputRecord.read(SSLSocketInputRecord.java:478)
	at java.base/sun.security.ssl.SSLSocketInputRecord.readHeader(SSLSocketInputRecord.java:472)
	at java.base/sun.security.ssl.SSLSocketInputRecord.bytesInCompletePacket(SSLSocketInputRecord.java:70)
	at java.base/sun.security.ssl.SSLSocketImpl.readApplicationRecord(SSLSocketImpl.java:1374)
	at java.base/sun.security.ssl.SSLSocketImpl$AppInputStream.read(SSLSocketImpl.java:985)
	at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:252)
	at java.base/java.io.BufferedInputStream.read1(BufferedInputStream.java:292)
	at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:351)
	at java.base/sun.net.www.http.HttpClient.parseHTTPHeader(HttpClient.java:754)
	at java.base/sun.net.www.http.HttpClient.parseHTTP(HttpClient.java:689)
	at java.base/sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1615)
	at java.base/sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1520)
	at java.base/java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:527)
	at java.base/sun.net.www.protocol.https.HttpsURLConnectionImpl.getResponseCode(HttpsURLConnectionImpl.java:334)
	at com.google.api.client.http.javanet.NetHttpResponse.<init>(NetHttpResponse.java:36)
	at com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:152)
	at com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:84)
	at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1012)
	at com.google.developers.certification.tensorflow.TestModel.executeCurrentRequest(TestModel.kt:203)
	at com.google.developers.certification.tensorflow.TestModel.upload(TestModel.kt:101)
	at com.google.developers.certification.tensorflow.TestModel.run(TestModel.kt:75)
	at com.google.developers.certification.assistant.AssistantActionViewImpl$newUpload$1.run(AssistantActionViewImpl.kt:184)
	at com.intellij.openapi.progress.impl.CoreProgressManager.startTask(CoreProgressManager.java:436)
	at com.intellij.openapi.progress.impl.ProgressManagerImpl.startTask(ProgressManagerImpl.java:120)
	at com.intellij.openapi.progress.impl.CoreProgressManager.lambda$runProcessWithProgressAsync$5(CoreProgressManager.java:496)
	at com.intellij.openapi.progress.impl.ProgressRunner.lambda$submit$3(ProgressRunner.java:244)
	at com.intellij.openapi.progress.impl.CoreProgressManager.lambda$runProcess$2(CoreProgressManager.java:188)
	at com.intellij.openapi.progress.impl.CoreProgressManager.lambda$executeProcessUnderProgress$12(CoreProgressManager.java:624)
	at com.intellij.openapi.progress.impl.CoreProgressManager.registerIndicatorAndRun(CoreProgressManager.java:698)
	at com.intellij.openapi.progress.impl.CoreProgressManager.computeUnderProgress(CoreProgressManager.java:646)
	at com.intellij.openapi.progress.impl.CoreProgressManager.executeProcessUnderProgress(CoreProgressManager.java:623)
	at com.intellij.openapi.progress.impl.ProgressManagerImpl.executeProcessUnderProgress(ProgressManagerImpl.java:66)
	at com.intellij.openapi.progress.impl.CoreProgressManager.runProcess(CoreProgressManager.java:175)
	at com.intellij.openapi.progress.impl.ProgressRunner.lambda$submit$4(ProgressRunner.java:244)
	at java.base/java.util.concurrent.CompletableFuture$AsyncSupply.run(CompletableFuture.java:1700)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.util.concurrent.Executors$PrivilegedThreadFactory$1$1.run(Executors.java:668)
	at java.base/java.util.concurrent.Executors$PrivilegedThreadFactory$1$1.run(Executors.java:665)
	at java.base/java.security.AccessController.doPrivileged(Native Method)
	at java.base/java.util.concurrent.Executors$PrivilegedThreadFactory$1.run(Executors.java:665)
	at java.base/java.lang.Thread.run(Thread.java:829)
```
</details>"
55707,adam optimizer does not work in tensorflow-macos,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

tensorflow-macos-2.8

### Custom Code

Yes

### OS Platform and Distribution

macos 12.3.1

### Mobile device

_No response_

### Python version

3.8

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
adam optimizer does not work
```


### Standalone code to reproduce the issue

```shell
#!/usr/bin/env python
# coding: utf-8

# ##### Copyright 2018 The TensorFlow Authors.

# In[1]:


#@title Licensed under the Apache License, Version 2.0 (the ""License"");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an ""AS IS"" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.


# In[2]:


#@title MIT License
#
# Copyright (c) 2017 François Chollet
#
# Permission is hereby granted, free of charge, to any person obtaining a
# copy of this software and associated documentation files (the ""Software""),
# to deal in the Software without restriction, including without limitation
# the rights to use, copy, modify, merge, publish, distribute, sublicense,
# and/or sell copies of the Software, and to permit persons to whom the
# Software is furnished to do so, subject to the following conditions:
#
# The above copyright notice and this permission notice shall be included in
# all copies or substantial portions of the Software.
#
# THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL
# THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
# FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
# DEALINGS IN THE SOFTWARE.


# # Basic classification: Classify images of clothing

# <table class=""tfo-notebook-buttons"" align=""left"">
#   <td>
#     <a target=""_blank"" href=""https://www.tensorflow.org/tutorials/keras/classification""><img src=""https://www.tensorflow.org/images/tf_logo_32px.png"" />View on TensorFlow.org</a>
#   </td>
#   <td>
#     <a target=""_blank"" href=""https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/keras/classification.ipynb""><img src=""https://www.tensorflow.org/images/colab_logo_32px.png"" />Run in Google Colab</a>
#   </td>
#   <td>
#     <a target=""_blank"" href=""https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/classification.ipynb""><img src=""https://www.tensorflow.org/images/GitHub-Mark-32px.png"" />View source on GitHub</a>
#   </td>
#   <td>
#     <a href=""https://storage.googleapis.com/tensorflow_docs/docs/site/en/tutorials/keras/classification.ipynb""><img src=""https://www.tensorflow.org/images/download_logo_32px.png"" />Download notebook</a>
#   </td>
# </table>

# This guide trains a neural network model to classify images of clothing, like sneakers and shirts. It's okay if you don't understand all the details; this is a fast-paced overview of a complete TensorFlow program with the details explained as you go.
# 
# This guide uses [tf.keras](https://www.tensorflow.org/guide/keras), a high-level API to build and train models in TensorFlow.

# In[3]:


# TensorFlow and tf.keras
import tensorflow as tf

# Helper libraries
import numpy as np
import matplotlib.pyplot as plt

print(tf.__version__)


# ## Import the Fashion MNIST dataset

# This guide uses the [Fashion MNIST](https://github.com/zalandoresearch/fashion-mnist) dataset which contains 70,000 grayscale images in 10 categories. The images show individual articles of clothing at low resolution (28 by 28 pixels), as seen here:
# 
# <table>
#   <tr><td>
#     <img src=""https://tensorflow.org/images/fashion-mnist-sprite.png""
#          alt=""Fashion MNIST sprite""  width=""600"">
#   </td></tr>
#   <tr><td align=""center"">
#     <b>Figure 1.</b> <a href=""https://github.com/zalandoresearch/fashion-mnist"">Fashion-MNIST samples</a> (by Zalando, MIT License).<br/>&nbsp;
#   </td></tr>
# </table>
# 
# Fashion MNIST is intended as a drop-in replacement for the classic [MNIST](http://yann.lecun.com/exdb/mnist/) dataset—often used as the ""Hello, World"" of machine learning programs for computer vision. The MNIST dataset contains images of handwritten digits (0, 1, 2, etc.) in a format identical to that of the articles of clothing you'll use here.
# 
# This guide uses Fashion MNIST for variety, and because it's a slightly more challenging problem than regular MNIST. Both datasets are relatively small and are used to verify that an algorithm works as expected. They're good starting points to test and debug code.
# 
# Here, 60,000 images are used to train the network and 10,000 images to evaluate how accurately the network learned to classify images. You can access the Fashion MNIST directly from TensorFlow. Import and [load the Fashion MNIST data](https://www.tensorflow.org/api_docs/python/tf/keras/datasets/fashion_mnist/load_data) directly from TensorFlow:

# In[4]:


fashion_mnist = tf.keras.datasets.fashion_mnist

(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()


# Loading the dataset returns four NumPy arrays:
# 
# * The `train_images` and `train_labels` arrays are the *training set*—the data the model uses to learn.
# * The model is tested against the *test set*, the `test_images`, and `test_labels` arrays.
# 
# The images are 28x28 NumPy arrays, with pixel values ranging from 0 to 255. The *labels* are an array of integers, ranging from 0 to 9. These correspond to the *class* of clothing the image represents:
# 
# <table>
#   <tr>
#     <th>Label</th>
#     <th>Class</th>
#   </tr>
#   <tr>
#     <td>0</td>
#     <td>T-shirt/top</td>
#   </tr>
#   <tr>
#     <td>1</td>
#     <td>Trouser</td>
#   </tr>
#     <tr>
#     <td>2</td>
#     <td>Pullover</td>
#   </tr>
#     <tr>
#     <td>3</td>
#     <td>Dress</td>
#   </tr>
#     <tr>
#     <td>4</td>
#     <td>Coat</td>
#   </tr>
#     <tr>
#     <td>5</td>
#     <td>Sandal</td>
#   </tr>
#     <tr>
#     <td>6</td>
#     <td>Shirt</td>
#   </tr>
#     <tr>
#     <td>7</td>
#     <td>Sneaker</td>
#   </tr>
#     <tr>
#     <td>8</td>
#     <td>Bag</td>
#   </tr>
#     <tr>
#     <td>9</td>
#     <td>Ankle boot</td>
#   </tr>
# </table>
# 
# Each image is mapped to a single label. Since the *class names* are not included with the dataset, store them here to use later when plotting the images:

# In[5]:


class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',
               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']


# ## Explore the data
# 
# Let's explore the format of the dataset before training the model. The following shows there are 60,000 images in the training set, with each image represented as 28 x 28 pixels:

# In[6]:


train_images.shape


# Likewise, there are 60,000 labels in the training set:

# In[7]:


len(train_labels)


# Each label is an integer between 0 and 9:

# In[8]:


train_labels


# There are 10,000 images in the test set. Again, each image is represented as 28 x 28 pixels:

# In[9]:


test_images.shape


# And the test set contains 10,000 images labels:

# In[10]:


len(test_labels)


# ## Preprocess the data
# 
# The data must be preprocessed before training the network. If you inspect the first image in the training set, you will see that the pixel values fall in the range of 0 to 255:

# In[11]:


plt.figure()
plt.imshow(train_images[0])
plt.colorbar()
plt.grid(False)
plt.show()


# Scale these values to a range of 0 to 1 before feeding them to the neural network model. To do so, divide the values by 255. It's important that the *training set* and the *testing set* be preprocessed in the same way:

# In[12]:


train_images = train_images / 255.0

test_images = test_images / 255.0


# To verify that the data is in the correct format and that you're ready to build and train the network, let's display the first 25 images from the *training set* and display the class name below each image.

# In[13]:


plt.figure(figsize=(10,10))
for i in range(25):
    plt.subplot(5,5,i+1)
    plt.xticks([])
    plt.yticks([])
    plt.grid(False)
    plt.imshow(train_images[i], cmap=plt.cm.binary)
    plt.xlabel(class_names[train_labels[i]])
plt.show()


# ## Build the model
# 
# Building the neural network requires configuring the layers of the model, then compiling the model.

# ### Set up the layers
# 
# The basic building block of a neural network is the [*layer*](https://www.tensorflow.org/api_docs/python/tf/keras/layers). Layers extract representations from the data fed into them. Hopefully, these representations are meaningful for the problem at hand.
# 
# Most of deep learning consists of chaining together simple layers. Most layers, such as `tf.keras.layers.Dense`, have parameters that are learned during training.

# In[14]:


model = tf.keras.Sequential([
    tf.keras.layers.Flatten(input_shape=(28, 28)),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dense(10)
])


# The first layer in this network, `tf.keras.layers.Flatten`, transforms the format of the images from a two-dimensional array (of 28 by 28 pixels) to a one-dimensional array (of 28 * 28 = 784 pixels). Think of this layer as unstacking rows of pixels in the image and lining them up. This layer has no parameters to learn; it only reformats the data.
# 
# After the pixels are flattened, the network consists of a sequence of two `tf.keras.layers.Dense` layers. These are densely connected, or fully connected, neural layers. The first `Dense` layer has 128 nodes (or neurons). The second (and last) layer returns a logits array with length of 10. Each node contains a score that indicates the current image belongs to one of the 10 classes.
# 
# ### Compile the model
# 
# Before the model is ready for training, it needs a few more settings. These are added during the model's [*compile*](https://www.tensorflow.org/api_docs/python/tf/keras/Model#compile) step:
# 
# * [*Loss function*](https://www.tensorflow.org/api_docs/python/tf/keras/losses) —This measures how accurate the model is during training. You want to minimize this function to ""steer"" the model in the right direction.
# * [*Optimizer*](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers) —This is how the model is updated based on the data it sees and its loss function.
# * [*Metrics*](https://www.tensorflow.org/api_docs/python/tf/keras/metrics) —Used to monitor the training and testing steps. The following example uses *accuracy*, the fraction of the images that are correctly classified.

# In[15]:


model.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])


# ## Train the model
# 
# Training the neural network model requires the following steps:
# 
# 1. Feed the training data to the model. In this example, the training data is in the `train_images` and `train_labels` arrays.
# 2. The model learns to associate images and labels.
# 3. You ask the model to make predictions about a test set—in this example, the `test_images` array.
# 4. Verify that the predictions match the labels from the `test_labels` array.
# 

# ### Feed the model
# 
# To start training,  call the [`model.fit`](https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit) method—so called because it ""fits"" the model to the training data:

# In[16]:


model.fit(train_images, train_labels, epochs=10)


# As the model trains, the loss and accuracy metrics are displayed. This model reaches an accuracy of about 0.91 (or 91%) on the training data.

# ### Evaluate accuracy
# 
# Next, compare how the model performs on the test dataset:

# In[17]:


test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)

print('\nTest accuracy:', test_acc)


# It turns out that the accuracy on the test dataset is a little less than the accuracy on the training dataset. This gap between training accuracy and test accuracy represents *overfitting*. Overfitting happens when a machine learning model performs worse on new, previously unseen inputs than it does on the training data. An overfitted model ""memorizes"" the noise and details in the training dataset to a point where it negatively impacts the performance of the model on the new data. For more information, see the following:
# *   [Demonstrate overfitting](https://www.tensorflow.org/tutorials/keras/overfit_and_underfit#demonstrate_overfitting)
# *   [Strategies to prevent overfitting](https://www.tensorflow.org/tutorials/keras/overfit_and_underfit#strategies_to_prevent_overfitting)

# ### Make predictions
# 
# With the model trained, you can use it to make predictions about some images.
# Attach a softmax layer to convert the model's linear outputs—[logits](https://developers.google.com/machine-learning/glossary#logits)—to probabilities, which should be easier to interpret.

# In[18]:


probability_model = tf.keras.Sequential([model, 
                                         tf.keras.layers.Softmax()])


# In[19]:


predictions = probability_model.predict(test_images)


# Here, the model has predicted the label for each image in the testing set. Let's take a look at the first prediction:

# In[20]:


predictions[0]


# A prediction is an array of 10 numbers. They represent the model's ""confidence"" that the image corresponds to each of the 10 different articles of clothing. You can see which label has the highest confidence value:

# In[21]:


np.argmax(predictions[0])


# So, the model is most confident that this image is an ankle boot, or `class_names[9]`. Examining the test label shows that this classification is correct:

# In[22]:


test_labels[0]


# Graph this to look at the full set of 10 class predictions.

# In[23]:


def plot_image(i, predictions_array, true_label, img):
  true_label, img = true_label[i], img[i]
  plt.grid(False)
  plt.xticks([])
  plt.yticks([])

  plt.imshow(img, cmap=plt.cm.binary)

  predicted_label = np.argmax(predictions_array)
  if predicted_label == true_label:
    color = 'blue'
  else:
    color = 'red'

  plt.xlabel(""{} {:2.0f}% ({})"".format(class_names[predicted_label],
                                100*np.max(predictions_array),
                                class_names[true_label]),
                                color=color)

def plot_value_array(i, predictions_array, true_label):
  true_label = true_label[i]
  plt.grid(False)
  plt.xticks(range(10))
  plt.yticks([])
  thisplot = plt.bar(range(10), predictions_array, color=""#777777"")
  plt.ylim([0, 1])
  predicted_label = np.argmax(predictions_array)

  thisplot[predicted_label].set_color('red')
  thisplot[true_label].set_color('blue')


# ### Verify predictions
# 
# With the model trained, you can use it to make predictions about some images.

# Let's look at the 0th image, predictions, and prediction array. Correct prediction labels are blue and incorrect prediction labels are red. The number gives the percentage (out of 100) for the predicted label.

# In[24]:


i = 0
plt.figure(figsize=(6,3))
plt.subplot(1,2,1)
plot_image(i, predictions[i], test_labels, test_images)
plt.subplot(1,2,2)
plot_value_array(i, predictions[i],  test_labels)
plt.show()


# In[25]:


i = 12
plt.figure(figsize=(6,3))
plt.subplot(1,2,1)
plot_image(i, predictions[i], test_labels, test_images)
plt.subplot(1,2,2)
plot_value_array(i, predictions[i],  test_labels)
plt.show()


# Let's plot several images with their predictions. Note that the model can be wrong even when very confident.

# In[26]:


# Plot the first X test images, their predicted labels, and the true labels.
# Color correct predictions in blue and incorrect predictions in red.
num_rows = 5
num_cols = 3
num_images = num_rows*num_cols
plt.figure(figsize=(2*2*num_cols, 2*num_rows))
for i in range(num_images):
  plt.subplot(num_rows, 2*num_cols, 2*i+1)
  plot_image(i, predictions[i], test_labels, test_images)
  plt.subplot(num_rows, 2*num_cols, 2*i+2)
  plot_value_array(i, predictions[i], test_labels)
plt.tight_layout()
plt.show()


# ## Use the trained model
# 
# Finally, use the trained model to make a prediction about a single image.

# In[27]:


# Grab an image from the test dataset.
img = test_images[1]

print(img.shape)


# `tf.keras` models are optimized to make predictions on a *batch*, or collection, of examples at once. Accordingly, even though you're using a single image, you need to add it to a list:

# In[28]:


# Add the image to a batch where it's the only member.
img = (np.expand_dims(img,0))

print(img.shape)


# Now predict the correct label for this image:

# In[29]:


predictions_single = probability_model.predict(img)

print(predictions_single)


# In[30]:


plot_value_array(1, predictions_single[0], test_labels)
_ = plt.xticks(range(10), class_names, rotation=45)
plt.show()


# `tf.keras.Model.predict` returns a list of lists—one list for each image in the batch of data. Grab the predictions for our (only) image in the batch:

# In[31]:


np.argmax(predictions_single[0])


# And the model predicts a label as expected.
```


### Relevant log output

```shell
2022-04-22 11:20:54.940284: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
Metal device set to: AMD Radeon Pro 5300M

systemMemory: 16.00 GB
maxCacheSize: 1.99 GB

2022-04-22 11:20:54.944819: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.
2022-04-22 11:20:54.946411: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)
Epoch 1/10
2022-04-22 11:20:56.708315: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.
2022-04-22 11:20:56.767 python[93125:17723871] -[MPSGraph adamUpdateWithLearningRateTensor:beta1Tensor:beta2Tensor:epsilonTensor:beta1PowerTensor:beta2PowerTensor:valuesTensor:momentumTensor:velocityTensor:gradientTensor:name:]: unrecognized selector sent to instance 0x6000042b2680
[1]    93125 segmentation fault  python classification.py
```
</details>"
55703,"TypeError: expected str, bytes or os.PathLike object, not GFile","<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

tf 2.8

### Custom Code

Yes

### OS Platform and Distribution

MacOS 10.15.7

### Mobile device

_No response_

### Python version

3.7

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
Whenever I try to load any TensorFlow model, I get this error TypeError: expected str, bytes or os.PathLike object, not GFile

Loading the model on google collab works without any error. I don't know if it is an OS-specific issue.
I have searched online and I have not seen a case like mine. Please can you help me?
```


### Standalone code to reproduce the issue

```shell
1. Open this google colab https://colab.research.google.com/drive/1gGEk8s2c4H_dHUn5GBPrit1mtTsS4bor?usp=sharing
2. Download the model test.h5
3. Import the model in your code 
  
import tensorflow as tf

model = tf.keras.models.load_model('test.h5')
```


### Relevant log output
```shell
(tf) kofi@Kofis-MacBook-Pro Masters Research % python main.py dataset/mypaperdataset.mp4 -d
Traceback (most recent call last):
  File ""main.py"", line 26, in <module>
    eyes_model = tf.keras.models.load_model('test.h5')
  File ""/Users/kofi/opt/anaconda3/envs/tf/lib/python3.7/site-packages/keras/utils/traceback_utils.py"", line 67, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File ""/Users/kofi/opt/anaconda3/envs/tf/lib/python3.7/site-packages/h5py/_hl/files.py"", line 309, in __init__
    name = filename_encode(name)
  File ""/Users/kofi/opt/anaconda3/envs/tf/lib/python3.7/site-packages/h5py/_hl/compat.py"", line 111, in filename_encode
    filename = fspath(filename)
TypeError: expected str, bytes or os.PathLike object, not GFile

```
_No response_</details>"
55702,"TFLite doesn't build OOB on VS2019, requires /std:c++20","<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Build/Install

### Source

source

### Tensorflow Version

github master 185c176

### Custom Code

No

### OS Platform and Distribution

Windows 10 x64

### Mobile device

N/A

### Python version

N/A

### Bazel version

N/A

### GCC/Compiler version

VS2019 16.11.12

### CUDA/cuDNN version

N/A

### GPU model and memory

N/A (Intel UHD)

### Current Behaviour?

I followed the instructions here: https://www.tensorflow.org/lite/guide/build_cmake, making allowances for windows:
1) CMake 3.23.0-rc2, using cmake-gui
2) Chose tensorflow_src/tensorflow/lite as ""where is the source code""
3) Chose new folder, tensorflow_src/tflite_build as ""where to build the binaries""
4) Clicked ""Configure"", chose VS 2019 version in dropdown and left it with other options default.
5) Clicked ""Generate"", then ""Open Project"", which correctly opened in VS

In CMake's output, the only warning was in abseil-cpp/CMakeLists.txt:74, ""A future Abseil release will default ABSL_PROPAGATE_CXX_STD to ON for CMake 3.8 and up. We recommend enabling this option to ensure your project still builds correctly""

Once the project opened in VS, I chose ""Release"" build type, and left everything else default, then clicked ""Build Project""

The build failed. Code C7555, ""use of designated initializers requires /srd:c++20"", in project tensorflow-lite, in external_delegate.cc:158.

I'm unsure whether this is supposed to be a supported build configuration. If not, please close the issue.


### Standalone code to reproduce the issue

```shell
No code necessary; instructions above.
```


### Relevant log output

```shell
Severity   Code    Description    Project File    Line    Suppression State
Error    C7555    use of designated initializers requires at least '/std:c++20'    tensorflow-lite    C:\Users\gbriggs\src\tensorflow_src\tensorflow\lite\delegates\external\external_delegate.cc    158
```
</details>"
55701,Python Linux 3.10 CPU-only wheel not found,"### Describe the problem
[Link](https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow_cpu-2.8.0-cp310-cp310-manylinux2010_x86_64.whl) to **Python Linux 3.10 CPU-only** is not found. 

"
55699,//tensorflow/tools/docs:tf_doctest fails on machines without GPU,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

git HEAD

### Custom Code

No

### OS Platform and Distribution

CentOS 7

### Mobile device

n/a

### Python version

3.7.13

### Bazel version

5.1.1

### GCC/Compiler version

10.2.1

### CUDA/cuDNN version

n/a

### GPU model and memory

n/a

### Current Behaviour?

```shell
Unit test //tensorflow/tools/docs:tf_doctest fails when run on machine without GPU installed.
```


### Standalone code to reproduce the issue

```shell
bazel test --test_timeout=300,500,-1,-1 --flaky_test_attempts=3 --test_output=all --cache_test_results=no --noremote_accept_cached --config=nonccl --build_tag_filters=-no_oss,-oss_serial,-gpu,-tpu,-benchmark-test,-v1only,-no_aarch64,-requires-gpu --test_tag_filters=-no_oss,-oss_serial,-gpu,-tpu,-benchmark-test,-v1only,-no_aarch64,-requires-gpu --verbose_failures --build_tests_only -- //tensorflow/tools/docs:tf_doctest
```


### Relevant log output

```shell
Multiple instances similar to

----------------------------------------------------------------------
File ""/root/.cache/bazel/_bazel_root/db210f68f81d95ddcca9ae96b16ed72c/execroot/org_tensorflow/bazel-out/aarch64-opt/bin/tensorflow/tools/docs/tf_doctest.runfiles/org_tensorflow/tensorflow/python/types/distribute.py"", line 156, in tensorflow.python.types.distribute.DistributedValues
Failed example:
    strategy = tf.distribute.MirroredStrategy([""GPU:0"", ""GPU:1""])
Exception raised:
    Traceback (most recent call last):
      File ""/opt/python/cp37-cp37m/lib/python3.7/doctest.py"", line 1337, in __run
        compileflags, 1), test.globs)
      File ""<doctest tensorflow.python.types.distribute.DistributedValues[22]>"", line 1, in <module>
        strategy = tf.distribute.MirroredStrategy([""GPU:0"", ""GPU:1""])
      File ""/root/.cache/bazel/_bazel_root/db210f68f81d95ddcca9ae96b16ed72c/execroot/org_tensorflow/bazel-out/aarch64-opt/bin/tensorflow/tools/docs/tf_doctest.runfiles/org_tensorflow/tensorflow/python/distribute/mirrored_strategy.py"", line 287, in __init__
        self, devices=devices, cross_device_ops=cross_device_ops)
      File ""/root/.cache/bazel/_bazel_root/db210f68f81d95ddcca9ae96b16ed72c/execroot/org_tensorflow/bazel-out/aarch64-opt/bin/tensorflow/tools/docs/tf_doctest.runfiles/org_tensorflow/tensorflow/python/distribute/mirrored_strategy.py"", line 342, in __init__
        self._initialize_strategy(devices)
      File ""/root/.cache/bazel/_bazel_root/db210f68f81d95ddcca9ae96b16ed72c/execroot/org_tensorflow/bazel-out/aarch64-opt/bin/tensorflow/tools/docs/tf_doctest.runfiles/org_tensorflow/tensorflow/python/distribute/mirrored_strategy.py"", line 367, in _initialize_strategy
        self._collective_ops = self._make_collective_ops(devices)
      File ""/root/.cache/bazel/_bazel_root/db210f68f81d95ddcca9ae96b16ed72c/execroot/org_tensorflow/bazel-out/aarch64-opt/bin/tensorflow/tools/docs/tf_doctest.runfiles/org_tensorflow/tensorflow/python/distribute/mirrored_strategy.py"", line 385, in _make_collective_ops
        collective_keys=self._collective_keys)
      File ""/root/.cache/bazel/_bazel_root/db210f68f81d95ddcca9ae96b16ed72c/execroot/org_tensorflow/bazel-out/aarch64-opt/bin/tensorflow/tools/docs/tf_doctest.runfiles/org_tensorflow/tensorflow/python/distribute/cross_device_ops.py"", line 1104, in __init__
        group_key, group_size, self._collective_keys, device, options)
      File ""/root/.cache/bazel/_bazel_root/db210f68f81d95ddcca9ae96b16ed72c/execroot/org_tensorflow/bazel-out/aarch64-opt/bin/tensorflow/tools/docs/tf_doctest.runfiles/org_tensorflow/tensorflow/python/distribute/cross_device_utils.py"", line 271, in __init__
        self._ordering_token = resource_variable_ops.ResourceVariable(0.)
      File ""/root/.cache/bazel/_bazel_root/db210f68f81d95ddcca9ae96b16ed72c/execroot/org_tensorflow/bazel-out/aarch64-opt/bin/tensorflow/tools/docs/tf_doctest.runfiles/org_tensorflow/tensorflow/python/util/traceback_utils.py"", line 141, in error_handler
        return fn(*args, **kwargs)
      File ""/root/.cache/bazel/_bazel_root/db210f68f81d95ddcca9ae96b16ed72c/execroot/org_tensorflow/bazel-out/aarch64-opt/bin/tensorflow/tools/docs/tf_doctest.runfiles/org_tensorflow/tensorflow/python/ops/variables.py"", line 268, in __call__
        return super(VariableMetaclass, cls).__call__(*args, **kwargs)
      File ""/root/.cache/bazel/_bazel_root/db210f68f81d95ddcca9ae96b16ed72c/execroot/org_tensorflow/bazel-out/aarch64-opt/bin/tensorflow/tools/docs/tf_doctest.runfiles/org_tensorflow/tensorflow/python/ops/resource_variable_ops.py"", line 1670, in __init__
        validate_shape=validate_shape,
      File ""/root/.cache/bazel/_bazel_root/db210f68f81d95ddcca9ae96b16ed72c/execroot/org_tensorflow/bazel-out/aarch64-opt/bin/tensorflow/tools/docs/tf_doctest.runfiles/org_tensorflow/tensorflow/python/ops/resource_variable_ops.py"", line 1817, in _init_from_args
        initial_value, name=""initial_value"", dtype=dtype)
      File ""/root/.cache/bazel/_bazel_root/db210f68f81d95ddcca9ae96b16ed72c/execroot/org_tensorflow/bazel-out/aarch64-opt/bin/tensorflow/tools/docs/tf_doctest.runfiles/org_tensorflow/tensorflow/python/profiler/trace.py"", line 183, in wrapped
        return func(*args, **kwargs)
      File ""/root/.cache/bazel/_bazel_root/db210f68f81d95ddcca9ae96b16ed72c/execroot/org_tensorflow/bazel-out/aarch64-opt/bin/tensorflow/tools/docs/tf_doctest.runfiles/org_tensorflow/tensorflow/python/framework/ops.py"", line 1640, in convert_to_tensor
        ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
      File ""/root/.cache/bazel/_bazel_root/db210f68f81d95ddcca9ae96b16ed72c/execroot/org_tensorflow/bazel-out/aarch64-opt/bin/tensorflow/tools/docs/tf_doctest.runfiles/org_tensorflow/tensorflow/python/framework/tensor_conversion_registry.py"", line 48, in _default_conversion_function
        return constant_op.constant(value, dtype, name=name)
      File ""/root/.cache/bazel/_bazel_root/db210f68f81d95ddcca9ae96b16ed72c/execroot/org_tensorflow/bazel-out/aarch64-opt/bin/tensorflow/tools/docs/tf_doctest.runfiles/org_tensorflow/tensorflow/python/framework/constant_op.py"", line 268, in constant
        allow_broadcast=True)
      File ""/root/.cache/bazel/_bazel_root/db210f68f81d95ddcca9ae96b16ed72c/execroot/org_tensorflow/bazel-out/aarch64-opt/bin/tensorflow/tools/docs/tf_doctest.runfiles/org_tensorflow/tensorflow/python/framework/constant_op.py"", line 279, in _constant_impl
        return _constant_eager_impl(ctx, value, dtype, shape, verify_shape)
      File ""/root/.cache/bazel/_bazel_root/db210f68f81d95ddcca9ae96b16ed72c/execroot/org_tensorflow/bazel-out/aarch64-opt/bin/tensorflow/tools/docs/tf_doctest.runfiles/org_tensorflow/tensorflow/python/framework/constant_op.py"", line 304, in _constant_eager_impl
        t = convert_to_eager_tensor(value, ctx, dtype)
      File ""/root/.cache/bazel/_bazel_root/db210f68f81d95ddcca9ae96b16ed72c/execroot/org_tensorflow/bazel-out/aarch64-opt/bin/tensorflow/tools/docs/tf_doctest.runfiles/org_tensorflow/tensorflow/python/framework/constant_op.py"", line 102, in convert_to_eager_tensor
        return ops.EagerTensor(value, ctx.device_name, dtype)
    tensorflow.python.framework.errors_impl.InvalidArgumentError: Could not satisfy device specification '/job:localhost/replica:0/task:0/device:GPU:0'. enable_soft_placement=0. Supported device types [CPU]. All available devices [/job:localhost/replica:0/task:0/device:CPU:0].
----------------------------------------------------------------------
File ""/root/.cache/bazel/_bazel_root/db210f68f81d95ddcca9ae96b16ed72c/execroot/org_tensorflow/bazel-out/aarch64-opt/bin/tensorflow/tools/docs/tf_doctest.runfiles/org_tensorflow/tensorflow/python/types/distribute.py"", line 158, in tensorflow.python.types.distribute.DistributedValues
Failed example:
    dataset_iterator = iter(strategy.experimental_distribute_dataset(dataset))
Exception raised:
    Traceback (most recent call last):
      File ""/opt/python/cp37-cp37m/lib/python3.7/doctest.py"", line 1337, in __run
        compileflags, 1), test.globs)
      File ""<doctest tensorflow.python.types.distribute.DistributedValues[24]>"", line 1, in <module>
        dataset_iterator = iter(strategy.experimental_distribute_dataset(dataset))
    NameError: name 'strategy' is not defined
----------------------------------------------------------------------
File ""/root/.cache/bazel/_bazel_root/db210f68f81d95ddcca9ae96b16ed72c/execroot/org_tensorflow/bazel-out/aarch64-opt/bin/tensorflow/tools/docs/tf_doctest.runfiles/org_tensorflow/tensorflow/python/types/distribute.py"", line 159, in tensorflow.python.types.distribute.DistributedValues
Failed example:
    per_replica_values = strategy.experimental_local_results(
       distributed_values)
Exception raised:
    Traceback (most recent call last):
      File ""/opt/python/cp37-cp37m/lib/python3.7/doctest.py"", line 1337, in __run
        compileflags, 1), test.globs)
      File ""<doctest tensorflow.python.types.distribute.DistributedValues[25]>"", line 1, in <module>
        per_replica_values = strategy.experimental_local_results(
    NameError: name 'strategy' is not defined
----------------------------------------------------------------------
File ""/root/.cache/bazel/_bazel_root/db210f68f81d95ddcca9ae96b16ed72c/execroot/org_tensorflow/bazel-out/aarch64-opt/bin/tensorflow/tools/docs/tf_doctest.runfiles/org_tensorflow/tensorflow/python/types/distribute.py"", line 161, in tensorflow.python.types.distribute.DistributedValues
Failed example:
    per_replica_values
Exception raised:
    Traceback (most recent call last):
      File ""/opt/python/cp37-cp37m/lib/python3.7/doctest.py"", line 1337, in __run
        compileflags, 1), test.globs)
      File ""<doctest tensorflow.python.types.distribute.DistributedValues[26]>"", line 1, in <module>
        per_replica_values
    NameError: name 'per_replica_values' is not defined


----------------------------------------------------------------------
```
</details>"
55698,TFLite Tensor name converted by 2.7.0 is much longer than 1.14.0,"### System information

-   **OS Platform and Distribution**: Linux Ubuntu 18.04
-   **Mobile device**: No
-   **TensorFlow installed from (source or binary)**: binary, pip install tensorflow==2.7.0
-   **TensorFlow version**: 2.7.0
-   **Python version**: 3.8.13
-   **Bazel version (if compiling from source)**: None
-   **GCC/Compiler version (if compiling from source)**: None
-   **CUDA/cuDNN version**: None
-   **GPU model and memory**: None
-   **Exact command to reproduce**: None

### Describe the problem
Using tensorflow 1.14.0 convert .pb model to tflite as follows:
```python
import tensorflow as tf

graph_def_file = '/path/to/mobilenet_v1.pb'
input_arrays = ['input']
output_arrays = ['MobilenetV1/Predictions/Reshape_1']
input_shapes = {'input': [1, 224, 224, 3]}

convert = tf.lite.TFLiteConverter.from_frozen_graph(graph_def_file, input_arrays, output_arrays, input_shapes)
tflite_model = convert.convert()
with open('mobilenet_v1_tf1.14.tflite', 'wb') as f:
    f.write(tflite_model)
```

After update tensorflow to 2.7.0 and modify scripts as follows:
```python
import tensorflow as tf

graph_def_file = '/path/to/mobilenet_v1.pb'
input_arrays = ['input']
output_arrays = ['MobilenetV1/Predictions/Reshape_1']
input_shapes = {'input': [1, 224, 224, 3]}

convert = tf.compat.v1.lite.TFLiteConverter.from_frozen_graph(graph_def_file, input_arrays, output_arrays, input_shapes)
tflite_model = convert.convert()
with open('mobilenet_v1_tf2.7.tflite', 'wb') as f:
    f.write(tflite_model)
```
I found tensor name in `mobilenet_v1_tf2.7.tflite` is much longer than `mobilenet_v1_tf1.14.tflite`. Such a long name caused a lot of trouble when comparing the tflite model with the original model.

However, I also noticed that there will be a new `Attributes` in TFLiteConverter.
```python
convert = tf.compat.v1.lite.TFLiteConverter.from_frozen_graph(graph_def_file, input_arrays, output_arrays, input_shapes)
convert.experimental_new_convert = False
tflite_model = convert.convert()
```
But the log as follows warning me that old converter is deprecated:
```shell
WARNING:absl:Please consider switching to the new converter by setting experimental_new_converter=True. The old converter (TOCO) is deprecated.
```
Is is possible to add an attribute in the new version, so that the model conversion name can remain unchanged, and the tensor of folder const can be removed.

"
55696,tf.nn.embedding_lookup_sparse doesn't work with @tf.function(jit_compile=True),"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

2.8.0

### Custom Code

No

### OS Platform and Distribution

Colab Notebook

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
Tried to use `tf.nn.embedding_lookup_sparse` within a function decorated with `@tf.function(jit_compile=True)` and it failed.
```


### Standalone code to reproduce the issue

```shell
import tensorflow as tf
print(tf.__version__)

try:
  tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection
  print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])
except ValueError:
  raise BaseException('ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')

tf.config.experimental_connect_to_cluster(tpu)
tf.tpu.experimental.initialize_tpu_system(tpu)
tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)


@tf.function(jit_compile=True)
def run_embedding_bag(params, sp_ids):
  return tf.nn.embedding_lookup_sparse(
    params, sp_ids, None, combiner='sum', max_norm=None, name=None
  )


with tf.device('/TPU:0'):
  params = tf.random.uniform([1000, 64])
  sp_ids = tf.sparse.SparseTensor([[0, 0], [0, 2]], values=[1, 2], dense_shape=[3, 4])
  res = run_embedding_bag(params, sp_ids)

print(res.shape)
print(run_embedding_bag.experimental_get_compiler_ir(params, sp_ids)(stage='hlo'))
```


### Relevant log output

```shell
InvalidArgumentError: Detected unsupported operations when trying to compile graph __inference_run_embedding_bag_978[_XlaMustCompile=true,config_proto=3175580994766145631,executor_type=11160318154034397263] on XLA_TPU_JIT: SparseSegmentSum (No registered 'SparseSegmentSum' OpKernel for XLA_TPU_JIT devices compatible with node {{node embedding_lookup_sparse}}){{node embedding_lookup_sparse}}
One approach is to outside compile the unsupported ops to run on CPUs by enabling soft placement `tf.config.set_soft_device_placement(True)`. This has a potential performance penalty.
```
</details>"
55695,Non-deterministic behavior when Run on Different GPU in different Machines,"Hello everyone, I would like to ask a determinism Issue with **Tensorflow version 1.15**

I tried to run some ML-model without tf.data.Dataset. (As i know there is some random in tf.data.Dataset) I also tried to add:
os.environ['TF_CUDNN_DETERMINISTIC'] = '1'
random.seed(1)
np.random.seed(1)
tf.set_random_seed(1)

The results is that I can reproduce the results with 100% similarity in the **SAME** machine. However, I cannot reproduce the results with 100% similarity in other machine.
Due to some issue in my old GPU, I cannot upgrade the **tensorflow** version, so we keep the version of 1.15
In our case, we try to run ML-model (Machine Learning - with Convolutional Neural Networks model) in two different Machines, one with the **GPU**:
**GeForce RTX 2070
NVIDIA-SMI 440.33.01    
Driver Version: 440.33.01    
CUDA Version: 10.2**

Another machine with the **GPU**:
**GeForce RTX 2080
NVIDIA-SMI 460.91.03    
Driver Version: 460.91.03    
CUDA Version: 11.2**  

The ML-results shows differently with these two machine. I hear about the difference of hard-ware version/**CUDA** version might cause the random results. May I ask that can anyone fix these issue? OR if the issue really cannot fix, which one has a bigger impact, difference of **GPU** hardware or **CUDA** version?

In other words, if the **GPUs** are the same, but **CUDAs** version are not the same, is it better than same **CUDA** with different **GPU**?

Thank you very much.
"
55693,Replacing Add Layer with Linear Combination of Learnable Weights,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Feature Request

The Add() Layer can be expressed as a linear combination of inputs where each coefficient value is 1. 

I was trying to make a custom layer that performs the same as Add, except uses trainable coefficients as we assume a coefficient of 1 is optimal. Unfortunately, I was unable to do so on my own, specifically the gradients. 

I do not think this would be too hard to implement as all the code is kind of already there, just need to calculate gradients and then update.

### Source

source

### Tensorflow Version

2.7

### Custom Code

Yes

### OS Platform and Distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
The Add() Layer can be expressed as a linear combination of inputs where each coefficient value is 1. 

I was trying to make a custom layer that performs the same as Add, except uses trainable coefficients as we assume a coefficient of 1 is optimal. Unfortunately, I was unable to do so on my own, specifically the gradients. 

I do not think this would be too hard to implement as all the code is kind of already there, just need to calculate gradients and then update.
```


### Standlone code to reproduce the issue

```shell
x
```


### Relevant log output

_No response_</details>"
55692,"GPT-J saved_model conversion to fp16 TF-TRT errors with ``Message tensorflow.GraphDef exceeds maximum protobuf size of 2GB: 23499914257""","<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

2.8

### Custom Code

No

### OS Platform and Distribution

Ubuntu 20.04.3 LTS

### Mobile device

_No response_

### Python version

3.9

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

11.4/8.1.0

### GPU model and memory

A100 40GB

### Current Behaviour?

I tried converting a saved_model of GPT-J using TF-TRT to an FP16 version. I ran into a problem with the protobuf size limit (log below), it seems the model is too large even though saving works correctly. The standalone code was executed using the tensorflow:latest-gpu image. The saved_model can be produced with the following snippet
```shell
from transformers import TFGPTJForSequenceClassification

model = TFGPTJForSequenceClassification.from_pretrained(""EleutherAI/gpt-j-6B"", revision=""float16"", from_pt=True)
# the saved_model parameter is a flag to create a SavedModel version of the model in same time than the h5 weights
model.save_pretrained(""sequence_fp16_model"", saved_model=True)
```
Expected Behaviour:
The saved_model should be converted into a TF-TRT version.


### Standlone code to reproduce the issue

```shell
from tensorflow.python.compiler.tensorrt import trt_convert as trt
converter = trt.TrtGraphConverterV2(input_saved_model_dir='<home_dir>/sequence_model/saved_model/1', precision_mode='FP16', use_dynamic_shape=True)
converter.convert()
converter.save('<home_dir>/seqfp16_model/saved_model/1')
```


### Relevant log output

```shell
2022-04-20 21:10:56.139648: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-04-20 21:10:56.733368: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38420 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:00:04.0, compute capability: 8.0
2022-04-20 21:11:38.182109: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1
2022-04-20 21:11:38.182325: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session
2022-04-20 21:11:38.184816: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38420 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:00:04.0, compute capability: 8.0
2022-04-20 21:11:39.502737: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1164] Optimization results for grappler item: graph_to_optimize
  function_optimizer: Graph size after: 18132 nodes (17815), 21036 edges (20719), time = 829.118ms.
  function_optimizer: function_optimizer did nothing. time = 0.075ms.

Traceback (most recent call last):
  File ""convert_to_fp16.py"", line 3, in <module>
    converter.convert()
  File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/compiler/tensorrt/trt_convert.py"", line 1201, in convert
    frozen_func = convert_to_constants.convert_variables_to_constants_v2(func)
  File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/convert_to_constants.py"", line 1151, in convert_variables_to_constants_v2
    return _construct_concrete_function(func, output_graph_def,
  File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/convert_to_constants.py"", line 1076, in _construct_concrete_function
    new_func = wrap_function.function_from_graph_def(output_graph_def,
  File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/wrap_function.py"", line 655, in function_from_graph_def
    wrapped_import = wrap_function(_imports_graph_def, [])
  File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/wrap_function.py"", line 619, in wrap_function
    func_graph.func_graph_from_py_func(
  File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/func_graph.py"", line 1161, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/wrap_function.py"", line 83, in __call__
    return self.call_with_variable_creator_scope(self._fn)(*args, **kwargs)
  File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/wrap_function.py"", line 89, in wrapped
    return fn(*args, **kwargs)
  File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/wrap_function.py"", line 649, in _imports_graph_def
    importer.import_graph_def(graph_def, name="""")
  File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/deprecation.py"", line 548, in new_func
    return func(*args, **kwargs)
  File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/importer.py"", line 403, in import_graph_def
    return _import_graph_def_internal(
  File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/importer.py"", line 497, in _import_graph_def_internal
    with c_api_util.tf_buffer(graph_def.SerializeToString()) as serialized:
ValueError: Message tensorflow.GraphDef exceeds maximum protobuf size of 2GB: 23499914257
```
</details>"
55688,tf.quantization.fake_quant_with_min_max_vars crashes,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

tf 2.8

### Custom Code

Yes

### OS Platform and Distribution

Linux Ubuntu 20.04

### Mobile device

n/a

### Python version

3.9

### Bazel version

n/a

### GCC/Compiler version

n/a

### CUDA/cuDNN version

n/a

### GPU model and memory

n/a

### Current Behaviour?

```shell
Session crashes when run the code below.
The code is buggy in that the argument `min_value` and `max_value` of `tf.quantization.fake_quant_with_min_max_vars` should be scalars instead of tensors of shape `(2,)`.
However, we expect the buggy code to be handled with `Exception` instead of just crashes.
```


### Standlone code to reproduce the issue

```shell
import tensorflow as tf
import numpy as np
input_data = np.random.rand(1,3,3,2).astype(np.float32)
min_value = tf.constant([0.0, -1.0], dtype=tf.float32)
max_value = tf.constant([1.0, 0.0], dtype=tf.float32)
input_tensor = tf.constant(input_data)
output = tf.quantization.fake_quant_with_min_max_vars(input_tensor, min_value, max_value)
```


### Relevant log output

```shell
abort (core dumped)
```
</details>"
55682,XLA: softmax with numerically masked inputs does not match its non-XLA counterpart on CPU,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

2.8

### Custom Code

No

### OS Platform and Distribution

Linux Ubuntu 20.04.3 LTS

### Mobile device

_No response_

### Python version

3.8.10

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

11.4

### GPU model and memory

T4 (16 GB)

### Current Behaviour?

```shell
TL;DR if a function contains a softmax after a numerically masked input (i.e. after adding a very large negative penalty), and that function is compiled with `tf.function(jit_compile=True)`, its CPU output is very different from its non compiled counterpart. On GPU, the two outputs are very close.

Long description:
On NLP models, like `T5`, it is common to have multiple inputs in the same batch with different lengths. To handle them without `RaggedTensors`, we pad the shortest entries in the batch to the longest length, and send the padded tokens along an attention mask (containing 0s where padding happened, 1s otherwise). Internally, in the model, we convert this binary attention mask to a numerical one, containing a large penalty (e.g. `-1e9` in Hugging Face's `T5`) that will be added to the input of the attention layers' softmax, such that no attention is given to padding. As such, this numerically masked softmax is a common operation in large language models.

As part of our efforts to speed up text generation at Hugging Face, we struggled to reproduce forward passes of some models when they were compiled with `tf.function(jit_compile=True)` (https://github.com/huggingface/transformers/issues/16838). Upon further inspection, we noticed that:
- The problematic behavior was CPU-only;
- The issue came from the softmax operation, but only when masking was present;
- It is present even when the attention mask contains all 1s, meaning that the large negative penalty doesn't get applied at all to the inputs;
- Reducing the large penalty to a not so large penalty, like `-100`, still results in noticable mismatches.

The snippet below gives a simple example where the problem described above can be seen -- it passes on GPU but fails on CPU. Because it is easily reproducible, I'm not including the XLA compilation files (as suggested [here](https://www.tensorflow.org/xla#reproducible_bug_reports)), but feel free to request them :)
```


### Standlone code to reproduce the issue

```shell
import tensorflow as tf


# same outcome for values <= -1e3
LARGE_PENALTY = -1e9


def simple_softmax(x):
    return tf.nn.softmax(x)


def masked_softmax(x, boolean_mask):
    numerical_mask = (1. - tf.cast(boolean_mask, dtype=tf.float32)) * LARGE_PENALTY
    masked_x = x + numerical_mask
    return tf.nn.softmax(masked_x)


xla_masked_softmax = tf.function(masked_softmax, jit_compile=True)
xla_simple_softmax = tf.function(simple_softmax, jit_compile=True)
x = tf.random.normal((1, 10))

# same outcome regardless of the boolean mask here
boolean_mask = tf.convert_to_tensor([[1] * 9 + [0] * 1], dtype=tf.int32)

# masks input outside of the compiled softmax -> works correctly on CPU and GPU
numerical_mask = (1. - tf.cast(boolean_mask, dtype=tf.float32)) * LARGE_PENALTY
masked_x = x + numerical_mask
xla_out = xla_simple_softmax(masked_x)
out = simple_softmax(masked_x)
print(tf.math.reduce_max(tf.math.abs(xla_out - out)).numpy())
assert tf.experimental.numpy.allclose(xla_out, out)

# masked_softmax -> fails regardless of the mask on CPU, works correctly on GPU
xla_out = xla_masked_softmax(x, boolean_mask)
out = masked_softmax(x, boolean_mask)
print(tf.math.reduce_max(tf.math.abs(xla_out - out)).numpy())
assert tf.experimental.numpy.allclose(xla_out, out)
```


### Relevant log output

_No response_</details>"
55681,Improper expression in “tf.keras.layers.Embedding” ‘s function introduction,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Others

### Source

binary

### Tensorflow Version

tf 2.8

### Custom Code

No

### OS Platform and Distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
tf.keras.layers.Embedding Turns positive integers (indexes) into dense vectors of fixed size.I think ""positive integers"" should be revised to ""non-negative integers"",because index ""0"" is not a positive integer. ""positive integers"" is a little improper from this perspective.
```


### Standlone code to reproduce the issue

```shell
inputs for tf.keras.layers.Embedding could have ""0"",but it's not a positive integer.
```


### Relevant log output

_No response_</details>"
55680,build tflite-2.7.1 android_arm64 shared library failed,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

tf 2.7

### Custom Code

No

### OS Platform and Distribution

Linux Ubuntu 20.04

### Mobile device

Android

### Python version

 3.8.10

### Bazel version

5.1.0

### GCC/Compiler version

clang version 9.0.9

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
./build_tflite-2.7.1_android_arm64_so.sh 
Target //tensorflow/lite:libtensorflowlite.so failed to build
INFO: Elapsed time: 1727.329s, Critical Path: 629.53s
INFO: 1906 processes: 108 internal, 1798 local.
FAILED: Build did NOT complete successfully
```


### Standlone code to reproduce the issue

```shell
Modifying tensorflow/lite/BUILD as follows:
tflite_cc_shared_object(
    name = ""libtensorflowlite.so"",
    linkopts = select({
        ""//tensorflow:macos"": [
            ""-Wl,-exported_symbols_list,$(location //tensorflow/lite:tflite_exported_symbols.lds)"",
            ""-Wl,-install_name,@rpath/libtensorflowlite.so"",
        ],
        ""//tensorflow:windows"": [],
        ""//conditions:default"": [
            ""-z defs"",
            ""-Wl,--version-script,$(location //tensorflow/lite:tflite_version_script.lds)"",
        ],
    }),
    deps = [
        "":framework"",
        "":tflite_exported_symbols.lds"",
        "":tflite_version_script.lds"",
        ""//tensorflow/lite/kernels:builtin_ops"",
        ""//tensorflow/lite/delegates/flex:delegate"",
    ],
)

Running the following command in Ubuntu 20.04 shell.
bazel build --jobs 6 --verbose_failures -c opt --config=monolithic --config=android_arm64 --cpu=arm64-v8a --define=tflite_convert_with_select_tf_ops=true --define=with_select_tf_ops=true //tensorflow/lite:libtensorflowlite.so
```


### Relevant log output

```shell
./build_tflite-2.7.1_android_arm64_so.sh 
INFO: Options provided by the client:
  Inherited 'common' options: --isatty=1 --terminal_columns=101
INFO: Reading rc options for 'build' from /home/andyueng/samba/workspece_TensorFlow2/tensorflow-2.7.0_android_arm64/.bazelrc:
  Inherited 'common' options: --experimental_repo_remote_exec
INFO: Reading rc options for 'build' from /home/andyueng/samba/workspece_TensorFlow2/tensorflow-2.7.0_android_arm64/.bazelrc:
  'build' options: --define framework_shared_object=true --java_toolchain=@tf_toolchains//toolchains/java:tf_java_toolchain --host_java_toolchain=@tf_toolchains//toolchains/java:tf_java_toolchain --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --enable_platform_specific_config --define=with_xla_support=true --config=short_logs --config=v2 --define=no_aws_support=true --define=no_hdfs_support=true
INFO: Reading rc options for 'build' from /home/andyueng/samba/workspece_TensorFlow2/tensorflow-2.7.0_android_arm64/.tf_configure.bazelrc:
  'build' options: --action_env PYTHON_BIN_PATH=/usr/bin/python3 --action_env PYTHON_LIB_PATH=/usr/lib/python3/dist-packages --python_path=/usr/bin/python3 --action_env ANDROID_NDK_HOME=/home/andyueng/Android/Sdk/ndk/21.4.7075529 --action_env ANDROID_NDK_API_LEVEL=21 --action_env ANDROID_BUILD_TOOLS_VERSION=30.0.3 --action_env ANDROID_SDK_API_LEVEL=30 --action_env ANDROID_SDK_HOME=/home/andyueng/Android/Sdk
INFO: Reading rc options for 'build' from /home/andyueng/samba/workspece_TensorFlow2/tensorflow-2.7.0_android_arm64/.bazelrc:
  'build' options: --deleted_packages=tensorflow/compiler/mlir/tfrt,tensorflow/compiler/mlir/tfrt/benchmarks,tensorflow/compiler/mlir/tfrt/jit/python_binding,tensorflow/compiler/mlir/tfrt/jit/transforms,tensorflow/compiler/mlir/tfrt/python_tests,tensorflow/compiler/mlir/tfrt/tests,tensorflow/compiler/mlir/tfrt/tests/saved_model,tensorflow/compiler/mlir/tfrt/transforms/lhlo_gpu_to_tfrt_gpu,tensorflow/core/runtime_fallback,tensorflow/core/runtime_fallback/conversion,tensorflow/core/runtime_fallback/kernel,tensorflow/core/runtime_fallback/opdefs,tensorflow/core/runtime_fallback/runtime,tensorflow/core/runtime_fallback/util,tensorflow/core/tfrt/common,tensorflow/core/tfrt/eager,tensorflow/core/tfrt/eager/backends/cpu,tensorflow/core/tfrt/eager/backends/gpu,tensorflow/core/tfrt/eager/core_runtime,tensorflow/core/tfrt/eager/cpp_tests/core_runtime,tensorflow/core/tfrt/fallback,tensorflow/core/tfrt/gpu,tensorflow/core/tfrt/run_handler_thread_pool,tensorflow/core/tfrt/runtime,tensorflow/core/tfrt/saved_model,tensorflow/core/tfrt/saved_model/tests,tensorflow/core/tfrt/tpu,tensorflow/core/tfrt/utils
INFO: Found applicable config definition build:short_logs in file /home/andyueng/samba/workspece_TensorFlow2/tensorflow-2.7.0_android_arm64/.bazelrc: --output_filter=DONT_MATCH_ANYTHING
INFO: Found applicable config definition build:v2 in file /home/andyueng/samba/workspece_TensorFlow2/tensorflow-2.7.0_android_arm64/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1
INFO: Found applicable config definition build:monolithic in file /home/andyueng/samba/workspece_TensorFlow2/tensorflow-2.7.0_android_arm64/.bazelrc: --define framework_shared_object=false
INFO: Found applicable config definition build:android_arm64 in file /home/andyueng/samba/workspece_TensorFlow2/tensorflow-2.7.0_android_arm64/.bazelrc: --config=android --cpu=arm64-v8a --fat_apk_cpu=arm64-v8a
INFO: Found applicable config definition build:android in file /home/andyueng/samba/workspece_TensorFlow2/tensorflow-2.7.0_android_arm64/.bazelrc: --crosstool_top=//external:android/crosstool --host_crosstool_top=@bazel_tools//tools/cpp:toolchain --noenable_platform_specific_config --copt=-w --cxxopt=-std=c++14 --host_cxxopt=-std=c++14 --define=with_xla_support=false
INFO: Analyzed target //tensorflow/lite:libtensorflowlite.so (156 packages loaded, 13239 targets configured).
INFO: Found 1 target...
[1,739 / 3,099] 6 actions, 2 running
    Compiling tensorflow/core/common_runtime/process_function_library_runtime.cc; 7s local
    Compiling tensorflow/core/platform/scanner.cc; 0s local
    [Sched] Compiling tensorflow/core/c[1,739 / 3,099] 6 actions, 2 running
    Compiling tensorflow/core/common_runtime/process_function_library_runtime.cc; 8s local
    Compiling tensorflow/core/platform/scanner.cc; 1s local
    [Sched] Compiling tensorflow/core/c[1,740 / 3,099] 6 actions, 2 running
    Compiling tensorflow/core/common_runtime/process_function_library_runtime.cc; 8s local
    Compiling tensorflow/core/common_runtime/process_state.cc; 0s local
    [Sched] Compiling tensorflow/core/p[1,740 / 3,099] 6 actions, 2 running
    Compiling tensorflow/core/common_runtime/process_function_library_runtime.cc; 9s local
    Compiling tensorflow/core/common_runtime/process_state.cc; 0s local
ERROR: /home/andyueng/samba/workspece_TensorFlow2/tensorflow-2.7.0_android_arm64/tensorflow/core/kernels/BUILD:6804:11: C++ compilation of rule '//tensorflow/core/kernels:portable_tensorflow_kernels' failed (Exit 254): clang failed: error executing command 
  (cd /home/andyueng/.cache/bazel/_bazel_andyueng/927465b164a8f43413ec0d8510052d3f/execroot/org_tensorflow && \
  exec env - \
    ANDROID_BUILD_TOOLS_VERSION=30.0.3 \
    ANDROID_NDK_API_LEVEL=21 \
    ANDROID_NDK_HOME=/home/andyueng/Android/Sdk/ndk/21.4.7075529 \
    ANDROID_SDK_API_LEVEL=30 \
    ANDROID_SDK_HOME=/home/andyueng/Android/Sdk \
    PATH=/home/andyueng/.local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin \
    PWD=/proc/self/cwd \
    PYTHON_BIN_PATH=/usr/bin/python3 \
    PYTHON_LIB_PATH=/usr/lib/python3/dist-packages \
    TF2_BEHAVIOR=1 \
  external/androidndk/ndk/toolchains/llvm/prebuilt/linux-x86_64/bin/clang -gcc-toolchain external/androidndk/ndk/toolchains/aarch64-linux-android-4.9/prebuilt/linux-x86_64 -target aarch64-none-linux-android -fpic -isystemexternal/androidndk/ndk/sysroot/usr/include/aarch64-linux-android '-D__ANDROID_API__=21' -no-canonical-prefixes -Wno-invalid-command-line-argument -Wno-unused-command-line-argument -funwind-tables -fstack-protector-strong -fno-addrsig '-Werror=return-type' '-Werror=int-to-pointer-cast' '-Werror=pointer-to-int-cast' '-Werror=implicit-function-declaration' -O2 -g -DNDEBUG -MD -MF bazel-out/arm64-v8a-opt/bin/tensorflow/core/kernels/_objs/portable_tensorflow_kernels/gather_op.pic.d '-frandom-seed=bazel-out/arm64-v8a-opt/bin/tensorflow/core/kernels/_objs/portable_tensorflow_kernels/gather_op.pic.o' -fPIC '-DS_IREAD=S_IRUSR' '-DS_IWRITE=S_IWUSR' '-DS_IEXEC=S_IXUSR' -DEIGEN_MPL2_ONLY '-DEIGEN_MAX_ALIGN_BYTES=64' -DSUPPORT_SELECTIVE_REGISTRATION -iquote . -iquote bazel-out/arm64-v8a-opt/bin -iquote external/gif -iquote bazel-out/arm64-v8a-opt/bin/external/gif -iquote external/eigen_archive -iquote bazel-out/arm64-v8a-opt/bin/external/eigen_archive -iquote external/com_google_absl -iquote bazel-out/arm64-v8a-opt/bin/external/com_google_absl -iquote external/nsync -iquote bazel-out/arm64-v8a-opt/bin/external/nsync -iquote external/libjpeg_turbo -iquote bazel-out/arm64-v8a-opt/bin/external/libjpeg_turbo -iquote external/com_google_protobuf -iquote bazel-out/arm64-v8a-opt/bin/external/com_google_protobuf -iquote external/zlib -iquote bazel-out/arm64-v8a-opt/bin/external/zlib -iquote external/double_conversion -iquote bazel-out/arm64-v8a-opt/bin/external/double_conversion -iquote external/com_googlesource_code_re2 -iquote bazel-out/arm64-v8a-opt/bin/external/com_googlesource_code_re2 -iquote external/farmhash_archive -iquote bazel-out/arm64-v8a-opt/bin/external/farmhash_archive -iquote external/png -iquote bazel-out/arm64-v8a-opt/bin/external/png -iquote external/highwayhash -iquote bazel-out/arm64-v8a-opt/bin/external/highwayhash -iquote external/icu -iquote bazel-out/arm64-v8a-opt/bin/external/icu -iquote external/fft2d -iquote bazel-out/arm64-v8a-opt/bin/external/fft2d -iquote external/gemmlowp -iquote bazel-out/arm64-v8a-opt/bin/external/gemmlowp -isystem external/gif -isystem bazel-out/arm64-v8a-opt/bin/external/gif -isystem external/eigen_archive -isystem bazel-out/arm64-v8a-opt/bin/external/eigen_archive -isystem external/nsync/public -isystem bazel-out/arm64-v8a-opt/bin/external/nsync/public -isystem external/com_google_protobuf/src -isystem bazel-out/arm64-v8a-opt/bin/external/com_google_protobuf/src -isystem external/zlib -isystem bazel-out/arm64-v8a-opt/bin/external/zlib -isystem external/double_conversion -isystem bazel-out/arm64-v8a-opt/bin/external/double_conversion -isystem external/farmhash_archive/src -isystem bazel-out/arm64-v8a-opt/bin/external/farmhash_archive/src -isystem external/png -isystem bazel-out/arm64-v8a-opt/bin/external/png -isystem external/icu/icu4c/source/common -isystem bazel-out/arm64-v8a-opt/bin/external/icu/icu4c/source/common -w '-std=c++14' -DEIGEN_AVOID_STL_ARRAY -Iexternal/gemmlowp -Wno-sign-compare '-ftemplate-depth=900' -fno-exceptions -DTENSORFLOW_MONOLITHIC_BUILD -DTF_LEAN_BINARY -Wno-narrowing -fomit-frame-pointer -O2 '--sysroot=external/androidndk/ndk/platforms/android-21/arch-arm64' -isystem external/androidndk/ndk/sources/cxx-stl/llvm-libc++/include -isystem external/androidndk/ndk/sources/cxx-stl/llvm-libc++abi/include -isystem external/androidndk/ndk/sources/android/support/include -isystemexternal/androidndk/ndk/sysroot/usr/include -c tensorflow/core/kernels/gather_op.cc -o bazel-out/arm64-v8a-opt/bin/tensorflow/core/kernels/_objs/portable_tensorflow_kernels/gather_op.pic.o)
Execution platform: @local_execution_config_platform//:platform
clang: error: unable to execute command: Killed
clang: error: clang frontend command failed due to signal (use -v to see invocation)
Android (7019983 based on r365631c3) clang version 9.0.9 (https://android.googlesource.com/toolchain/llvm-project a2a1e703c0edb03ba29944e529ccbf457742737b) (based on LLVM 9.0.9svn)
Target: aarch64-none-linux-android
Thread model: posix
InstalledDir: external/androidndk/ndk/toolchains/llvm/prebuilt/linux-x86_64/bin
clang: note: diagnostic msg: PLEASE submit a bug report to https://github.com/android-ndk/ndk/issues and include the crash backtrace, preprocessed source, and associated run script.
clang: note: diagnostic msg: 
********************

PLEASE ATTACH THE FOLLOWING FILES TO THE BUG REPORT:
Preprocessed source(s) and associated run script(s) are located at:
clang: note: diagnostic msg: /tmp/gather_op-af1fc4.cpp
clang: note: diagnostic msg: /tmp/gather_op-af1fc4.sh
clang: note: diagnostic msg: 

********************
Target //tensorflow/lite:libtensorflowlite.so failed to build
INFO: Elapsed time: 1727.329s, Critical Path: 629.53s
INFO: 1906 processes: 108 internal, 1798 local.
FAILED: Build did NOT complete successfully
```
</details>"
55679,Android - Does not encode a valid TensorFlow Lite model.,"Previously I was using TensorFlowInferenceInterface to read the model. but I was facing a lot of crashes. As per one of the moderator's recommendation, i replaced the method with the following:

**Code:**
```
 private var sTFInterface: Interpreter? = null
 private const val MODEL_FILE = ""file:///android_asset/auto.pb""

sTFInterface = Interpreter(File(MODEL_FILE))
```
But now i see a very strange error and it is unable to read tensorflowlite model. Still ""abort"" crashes are on spike.

**Error:**
> java.lang.IllegalArgumentException: Contents of /file:/android_asset/auto.pb does not encode a valid TensorFlow Lite model: Could not open '/file:/android_asset/auto.pb'.
> The model allocation is null/empty

Please help

Attached model:
[auto.pb.zip](https://github.com/tensorflow/tensorflow/files/8520578/auto.pb.zip)

"
55676,"Would like to build for ppc64el, is this possible?","<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Build/Install

### Source

source

### Tensorflow Version

2.8

### Custom Code

No

### OS Platform and Distribution

Redhat Enterprise Linux 8

### Mobile device

_No response_

### Python version

3.9

### Bazel version

bazel4.2.1

### GCC/Compiler version

8.5

### CUDA/cuDNN version

11.2/8.4

### GPU model and memory

Nvidia P100 x4 16GB

### Current Behaviour?

```shell
Trying to build on IBM Power8 Server (8335-GTB) using ppc64el arch.
```


### Standlone code to reproduce the issue

```shell
bazel build --config=cuda //tensorflow/tools/pip_package:build_pip_package
```


### Relevant log output

```shell
ERROR: Analysis of target '//tensorflow/tools/pip_package:build_pip_package' failed; build aborted: /home/theskaz/.cache/bazel/_bazel_theskaz/70be98ca39496e399681fb572266510d/external/cpuinfo/BUILD.bazel:100:11: Configurable attribute ""srcs"" doesn't match this configuration (would a default condition help?).
Conditions checked:
 @cpuinfo//:linux_x86_64
 @cpuinfo//:linux_arm
 @cpuinfo//:linux_armhf
 @cpuinfo//:linux_armv7a
 @cpuinfo//:linux_armeabi
 @cpuinfo//:linux_aarch64
 @cpuinfo//:linux_mips64
 @cpuinfo//:linux_riscv64
 @cpuinfo//:linux_s390x
 @cpuinfo//:macos_x86_64
 @cpuinfo//:macos_arm64
 @cpuinfo//:windows_x86_64
 @cpuinfo//:android_armv7
 @cpuinfo//:android_arm64
 @cpuinfo//:android_x86
 @cpuinfo//:android_x86_64
 @cpuinfo//:ios_x86_64
 @cpuinfo//:ios_x86
 @cpuinfo//:ios_armv7
 @cpuinfo//:ios_arm64
 @cpuinfo//:ios_arm64e
 @cpuinfo//:watchos_x86_64
 @cpuinfo//:watchos_x86
 @cpuinfo//:watchos_armv7k
 @cpuinfo//:watchos_arm64_32
 @cpuinfo//:tvos_x86_64
 @cpuinfo//:tvos_arm64
 @cpuinfo//:emscripten_wasm
```
</details>"
55675,[TRT] TF 2.8.0 EfficientDet D0 TRT conversion failed - Unable to save gradient functions,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

2.8.0

### Custom Code

No

### OS Platform and Distribution

Linux Ubuntu 18.04

### Mobile device

_No response_

### Python version

3.7

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN/TensorRT version

11.2 / 8.1.1.33 / 7.2.3-1

### GPU model and memory

Nvidia Tesla T4 16GB (aws g4dn.2xlarge)

### Current Behaviour?

```shell
TF 2.8.0
TRT converter can convert EfficientDet D0 model BUT failed to save it.

# Error
ValueError: Unable to save gradient functions when exporting a _DefinedFunction (generally created through graph freezing utils or through V1 graph importers). Please save with `options=tf.SaveOptions(experimental_custom_gradients=False)`

TRT conversion and saving work fine in TF 2.4.4, 2.7.1 and 2.9.0-rc0
```


### Standlone code to reproduce the issue

Download EfficientDet D0 model from [TensorFlow Hub](https://tfhub.dev/tensorflow/efficientdet/d0/1)
Extract model tar.gz to efficientdet_d0 folder
```python
# Convert the model
import tensorflow as tf
from tensorflow.python.compiler.tensorrt import trt_convert as trt
mmm=""efficientdet_d0""
conversion_params = trt.TrtConversionParams()
converter = trt.TrtGraphConverterV2(
    input_saved_model_dir=mmm,
    conversion_params=conversion_params)
converter.convert()
converter.save(mmm + ""_trt_fp32"")
```
```shell
# Error
ValueError: Unable to save gradient functions when exporting a _DefinedFunction (generally created through graph freezing utils or through V1 graph importers). Please save with `options=tf.SaveOptions(experimental_custom_gradients=False)`
```


### Relevant log output

```shell
2022-04-20 04:39:57.385230: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-04-20 04:39:57.391168: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-04-20 04:39:57.393240: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-04-20 04:39:57.395527: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-04-20 04:39:57.396021: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-04-20 04:39:57.398117: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-04-20 04:39:57.400194: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-04-20 04:39:58.084849: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-04-20 04:39:58.086283: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-04-20 04:39:58.087478: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-04-20 04:39:58.088632: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13598 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5
2022-04-20 04:40:19.154659: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-04-20 04:40:19.156146: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1
2022-04-20 04:40:19.156320: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session
2022-04-20 04:40:19.156736: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-04-20 04:40:19.158083: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-04-20 04:40:19.159358: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-04-20 04:40:19.160688: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-04-20 04:40:19.161965: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-04-20 04:40:19.163204: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13598 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5
2022-04-20 04:40:19.873601: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1164] Optimization results for grappler item: graph_to_optimize
  function_optimizer: Graph size after: 11949 nodes (11247), 19488 edges (18779), time = 418.884ms.
  function_optimizer: function_optimizer did nothing. time = 0.03ms.

2022-04-20 04:40:29.021558: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-04-20 04:40:29.023022: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1
2022-04-20 04:40:29.023118: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session
2022-04-20 04:40:29.023521: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-04-20 04:40:29.024914: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-04-20 04:40:29.026207: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-04-20 04:40:29.027569: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-04-20 04:40:29.028843: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-04-20 04:40:29.030082: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13598 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5
2022-04-20 04:40:30.639612: W tensorflow/compiler/tf2tensorrt/convert/trt_optimization_pass.cc:385] Calibration with FP32 or FP16 is not implemented. Falling back to use_calibration = False.Note that the default value of use_calibration is True.
2022-04-20 04:40:30.639665: I tensorflow/compiler/tf2tensorrt/convert/trt_optimization_pass.cc:403] [TF-TRT] not using explicit QDQ mode
2022-04-20 04:40:30.950302: W tensorflow/compiler/tf2tensorrt/segment/segment.cc:884]

################################################################################
TensorRT unsupported/non-converted OP Report:
	- Placeholder -> 513x
	- GatherV2 -> 390x
	- Reshape -> 325x
	- StridedSlice -> 273x
	- Fill -> 273x
	- Shape -> 246x
	- Sub -> 213x
	- ConcatV2 -> 187x
	- Pack -> 167x
	- Mul -> 112x
	- Select -> 102x
	- Slice -> 101x
	- AddV2 -> 100x
	- Minimum -> 97x
	- Identity -> 95x
	- Less -> 95x
	- Range -> 93x
	- ZerosLike -> 92x
	- NonMaxSuppressionV5 -> 90x
	- Switch -> 27x
	- Merge -> 26x
	- Enter -> 25x
	- NextIteration -> 25x
	- DataFormatVecPermute -> 22x
	- Exit -> 20x
	- Cast -> 20x
	- NoOp -> 15x
	- ExpandDims -> 14x
	- Greater -> 12x
	- Unpack -> 9x
	- Pad -> 9x
	- TensorListReserve -> 9x
	- TensorListSetItem -> 9x
	- TensorListFromTensor -> 8x
	- TensorListGetItem -> 8x
	- TensorListStack -> 8x
	- Tile -> 6x
	- Split -> 5x
	- Maximum -> 4x
	- Round -> 4x
	- RealDiv -> 4x
	- Transpose -> 3x
	- TopKV2 -> 2x
	- LoopCond -> 2x
	- Assert -> 2x
	- Const -> 2x
	- StopGradient -> 2x
	- Squeeze -> 2x
	- Size -> 2x
	- Equal -> 2x
	- ResizeBilinear -> 2x
	- Reciprocal -> 2x
	- Exp -> 2x
	- LogicalAnd -> 2x
	- Sum -> 1x
	- GreaterEqual -> 1x
	- Where -> 1x
--------------------------------------------------------------------------------
	- Total nonconverted OPs: 3883
	- Total nonconverted OP Types: 57
For more information see https://docs.nvidia.com/deeplearning/frameworks/tf-trt-user-guide/index.html#supported-ops.
################################################################################

2022-04-20 04:40:31.806241: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:799] Number of TensorRT candidate segments: 33
2022-04-20 04:40:31.918157: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:910] Replaced segment 0 consisting of 6 nodes by TRTEngineOp_0_0.
2022-04-20 04:40:31.918285: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:910] Replaced segment 1 consisting of 38 nodes by TRTEngineOp_0_1.
2022-04-20 04:40:31.918497: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:910] Replaced segment 2 consisting of 29 nodes by TRTEngineOp_0_2.
2022-04-20 04:40:31.918707: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:910] Replaced segment 3 consisting of 166 nodes by TRTEngineOp_0_3.
2022-04-20 04:40:31.919229: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:910] Replaced segment 4 consisting of 38 nodes by TRTEngineOp_0_4.
2022-04-20 04:40:31.919419: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:910] Replaced segment 5 consisting of 38 nodes by TRTEngineOp_0_5.
2022-04-20 04:40:31.919642: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:910] Replaced segment 6 consisting of 139 nodes by TRTEngineOp_0_6.
2022-04-20 04:40:31.920011: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:910] Replaced segment 7 consisting of 29 nodes by TRTEngineOp_0_7.
2022-04-20 04:40:31.920264: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:910] Replaced segment 8 consisting of 29 nodes by TRTEngineOp_0_8.
2022-04-20 04:40:31.920410: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:910] Replaced segment 9 consisting of 29 nodes by TRTEngineOp_0_9.
2022-04-20 04:40:31.920691: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:910] Replaced segment 10 consisting of 663 nodes by TRTEngineOp_0_10.
2022-04-20 04:40:31.922440: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:910] Replaced segment 11 consisting of 29 nodes by TRTEngineOp_0_11.
2022-04-20 04:40:31.922600: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:910] Replaced segment 12 consisting of 29 nodes by TRTEngineOp_0_12.
2022-04-20 04:40:31.922745: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:910] Replaced segment 13 consisting of 29 nodes by TRTEngineOp_0_13.
2022-04-20 04:40:31.922881: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:910] Replaced segment 14 consisting of 22 nodes by TRTEngineOp_0_14.
2022-04-20 04:40:31.923039: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:910] Replaced segment 15 consisting of 42 nodes by TRTEngineOp_0_15.
2022-04-20 04:40:31.923218: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:910] Replaced segment 16 consisting of 42 nodes by TRTEngineOp_0_16.
2022-04-20 04:40:31.923401: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:910] Replaced segment 17 consisting of 44 nodes by TRTEngineOp_0_17.
2022-04-20 04:40:31.923585: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:910] Replaced segment 18 consisting of 42 nodes by TRTEngineOp_0_18.
2022-04-20 04:40:31.923770: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:910] Replaced segment 19 consisting of 44 nodes by TRTEngineOp_0_19.
2022-04-20 04:40:31.923947: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:910] Replaced segment 20 consisting of 42 nodes by TRTEngineOp_0_20.
2022-04-20 04:40:31.924331: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:910] Replaced segment 21 consisting of 44 nodes by TRTEngineOp_0_21.
2022-04-20 04:40:31.924552: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:910] Replaced segment 22 consisting of 44 nodes by TRTEngineOp_0_22.
2022-04-20 04:40:31.924764: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:910] Replaced segment 23 consisting of 42 nodes by TRTEngineOp_0_23.
2022-04-20 04:40:31.924981: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:910] Replaced segment 24 consisting of 44 nodes by TRTEngineOp_0_24.
2022-04-20 04:40:31.925201: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:910] Replaced segment 25 consisting of 44 nodes by TRTEngineOp_0_25.
2022-04-20 04:40:31.925432: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:910] Replaced segment 26 consisting of 42 nodes by TRTEngineOp_0_26.
2022-04-20 04:40:31.925639: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:910] Replaced segment 27 consisting of 44 nodes by TRTEngineOp_0_27.
2022-04-20 04:40:31.925847: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:910] Replaced segment 28 consisting of 44 nodes by TRTEngineOp_0_28.
2022-04-20 04:40:31.926047: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:910] Replaced segment 29 consisting of 44 nodes by TRTEngineOp_0_29.
2022-04-20 04:40:31.926231: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:910] Replaced segment 30 consisting of 9 nodes by TRTEngineOp_0_30.
2022-04-20 04:40:31.926323: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:910] Replaced segment 31 consisting of 9 nodes by TRTEngineOp_0_31.
2022-04-20 04:40:31.926450: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:910] Replaced segment 32 consisting of 5 nodes by TRTEngineOp_0_32.
2022-04-20 04:40:32.725324: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1164] Optimization results for grappler item: tf_graph
  constant_folding: Graph size after: 9106 nodes (-2558), 15479 edges (-2877), time = 532.691ms.
  layout: Graph size after: 9384 nodes (278), 15757 edges (278), time = 442.72ms.
  constant_folding: Graph size after: 9368 nodes (-16), 15741 edges (-16), time = 380.424ms.
  TensorRTOptimizer: Graph size after: 7417 nodes (-1951), 12053 edges (-3688), time = 1359.01294ms.
  constant_folding: Graph size after: 7362 nodes (-55), 12053 edges (0), time = 249.141ms.
Optimization results for grappler item: TRTEngineOp_0_27_native_segment
  constant_folding: Graph size after: 50 nodes (0), 52 edges (0), time = 2.382ms.
  layout: Graph size after: 50 nodes (0), 52 edges (0), time = 3.47ms.
  constant_folding: Graph size after: 50 nodes (0), 52 edges (0), time = 2.043ms.
  TensorRTOptimizer: Graph size after: 50 nodes (0), 52 edges (0), time = 0.291ms.
  constant_folding: Graph size after: 50 nodes (0), 52 edges (0), time = 2.02ms.
Optimization results for grappler item: TRTEngineOp_0_13_native_segment
  constant_folding: Graph size after: 33 nodes (0), 36 edges (0), time = 0.788ms.
  layout: Graph size after: 33 nodes (0), 36 edges (0), time = 0.828ms.
  constant_folding: Graph size after: 33 nodes (0), 36 edges (0), time = 0.787ms.
  TensorRTOptimizer: Graph size after: 33 nodes (0), 36 edges (0), time = 0.062ms.
  constant_folding: Graph size after: 33 nodes (0), 36 edges (0), time = 0.799ms.
Optimization results for grappler item: TRTEngineOp_0_17_native_segment
  constant_folding: Graph size after: 49 nodes (0), 51 edges (0), time = 1.077ms.
  layout: Graph size after: 49 nodes (0), 51 edges (0), time = 1.207ms.
  constant_folding: Graph size after: 49 nodes (0), 51 edges (0), time = 1.083ms.
  TensorRTOptimizer: Graph size after: 49 nodes (0), 51 edges (0), time = 0.098ms.
  constant_folding: Graph size after: 49 nodes (0), 51 edges (0), time = 1.06ms.
Optimization results for grappler item: TRTEngineOp_0_22_native_segment
  constant_folding: Graph size after: 49 nodes (0), 51 edges (0), time = 1.313ms.
  layout: Graph size after: 49 nodes (0), 51 edges (0), time = 1.614ms.
  constant_folding: Graph size after: 49 nodes (0), 51 edges (0), time = 1.269ms.
  TensorRTOptimizer: Graph size after: 49 nodes (0), 51 edges (0), time = 0.131ms.
  constant_folding: Graph size after: 49 nodes (0), 51 edges (0), time = 1.286ms.
Optimization results for grappler item: TRTEngineOp_0_14_native_segment
  constant_folding: Graph size after: 25 nodes (0), 26 edges (0), time = 0.593ms.
  layout: Graph size after: 25 nodes (0), 26 edges (0), time = 0.635ms.
  constant_folding: Graph size after: 25 nodes (0), 26 edges (0), time = 0.595ms.
  TensorRTOptimizer: Graph size after: 25 nodes (0), 26 edges (0), time = 0.048ms.
  constant_folding: Graph size after: 25 nodes (0), 26 edges (0), time = 0.582ms.
Optimization results for grappler item: TRTEngineOp_0_31_native_segment
  constant_folding: Graph size after: 14 nodes (0), 15 edges (0), time = 0.362ms.
  layout: Graph size after: 14 nodes (0), 15 edges (0), time = 0.252ms.
  constant_folding: Graph size after: 14 nodes (0), 15 edges (0), time = 0.347ms.
  TensorRTOptimizer: Graph size after: 14 nodes (0), 15 edges (0), time = 0.012ms.
  constant_folding: Graph size after: 14 nodes (0), 15 edges (0), time = 0.341ms.
Optimization results for grappler item: TRTEngineOp_0_18_native_segment
  constant_folding: Graph size after: 47 nodes (0), 49 edges (0), time = 1.056ms.
  layout: Graph size after: 47 nodes (0), 49 edges (0), time = 1.178ms.
  constant_folding: Graph size after: 47 nodes (0), 49 edges (0), time = 1.052ms.
  TensorRTOptimizer: Graph size after: 47 nodes (0), 49 edges (0), time = 0.092ms.
  constant_folding: Graph size after: 47 nodes (0), 49 edges (0), time = 1.063ms.
Optimization results for grappler item: TRTEngineOp_0_3_native_segment
  constant_folding: Graph size after: 181 nodes (0), 192 edges (0), time = 3.86ms.
  layout: Graph size after: 181 nodes (0), 192 edges (0), time = 4.5ms.
  constant_folding: Graph size after: 181 nodes (0), 192 edges (0), time = 3.769ms.
  TensorRTOptimizer: Graph size after: 181 nodes (0), 192 edges (0), time = 0.32ms.
  constant_folding: Graph size after: 181 nodes (0), 192 edges (0), time = 3.804ms.
Optimization results for grappler item: TRTEngineOp_0_28_native_segment
  constant_folding: Graph size after: 50 nodes (0), 52 edges (0), time = 2.284ms.
  layout: Graph size after: 50 nodes (0), 52 edges (0), time = 3.438ms.
  constant_folding: Graph size after: 50 nodes (0), 52 edges (0), time = 2.111ms.
  TensorRTOptimizer: Graph size after: 50 nodes (0), 52 edges (0), time = 0.29ms.
  constant_folding: Graph size after: 50 nodes (0), 52 edges (0), time = 2.09ms.
Optimization results for grappler item: TRTEngineOp_0_8_native_segment
  constant_folding: Graph size after: 33 nodes (0), 36 edges (0), time = 0.826ms.
  layout: Graph size after: 33 nodes (0), 36 edges (0), time = 0.843ms.
  constant_folding: Graph size after: 33 nodes (0), 36 edges (0), time = 0.827ms.
  TensorRTOptimizer: Graph size after: 33 nodes (0), 36 edges (0), time = 0.061ms.
  constant_folding: Graph size after: 33 nodes (0), 36 edges (0), time = 0.802ms.
Optimization results for grappler item: TRTEngineOp_0_32_native_segment
  constant_folding: Graph size after: 12 nodes (0), 11 edges (0), time = 0.338ms.
  layout: Graph size after: 12 nodes (0), 11 edges (0), time = 0.227ms.
  constant_folding: Graph size after: 12 nodes (0), 11 edges (0), time = 0.299ms.
  TensorRTOptimizer: Graph size after: 12 nodes (0), 11 edges (0), time = 0.01ms.
  constant_folding: Graph size after: 12 nodes (0), 11 edges (0), time = 0.313ms.
Optimization results for grappler item: TRTEngineOp_0_6_native_segment
  constant_folding: Graph size after: 154 nodes (0), 165 edges (0), time = 3.207ms.
  layout: Graph size after: 154 nodes (0), 165 edges (0), time = 3.662ms.
  constant_folding: Graph size after: 154 nodes (0), 165 edges (0), time = 3.273ms.
  TensorRTOptimizer: Graph size after: 154 nodes (0), 165 edges (0), time = 0.331ms.
  constant_folding: Graph size after: 154 nodes (0), 165 edges (0), time = 3.227ms.
Optimization results for grappler item: TRTEngineOp_0_29_native_segment
  constant_folding: Graph size after: 49 nodes (0), 51 edges (0), time = 2.206ms.
  layout: Graph size after: 49 nodes (0), 51 edges (0), time = 3.379ms.
  constant_folding: Graph size after: 49 nodes (0), 51 edges (0), time = 2.069ms.
  TensorRTOptimizer: Graph size after: 49 nodes (0), 51 edges (0), time = 0.295ms.
  constant_folding: Graph size after: 49 nodes (0), 51 edges (0), time = 2.029ms.
Optimization results for grappler item: TRTEngineOp_0_2_native_segment
  constant_folding: Graph size after: 33 nodes (0), 36 edges (0), time = 0.862ms.
  layout: Graph size after: 33 nodes (0), 36 edges (0), time = 0.852ms.
  constant_folding: Graph size after: 33 nodes (0), 36 edges (0), time = 0.812ms.
  TensorRTOptimizer: Graph size after: 33 nodes (0), 36 edges (0), time = 0.061ms.
  constant_folding: Graph size after: 33 nodes (0), 36 edges (0), time = 0.816ms.
Optimization results for grappler item: TRTEngineOp_0_4_native_segment
  constant_folding: Graph size after: 42 nodes (0), 45 edges (0), time = 1.028ms.
  layout: Graph size after: 42 nodes (0), 45 edges (0), time = 1.183ms.
  constant_folding: Graph size after: 42 nodes (0), 45 edges (0), time = 1.018ms.
  TensorRTOptimizer: Graph size after: 42 nodes (0), 45 edges (0), time = 0.079ms.
  constant_folding: Graph size after: 42 nodes (0), 45 edges (0), time = 1.072ms.
Optimization results for grappler item: TRTEngineOp_0_30_native_segment
  constant_folding: Graph size after: 12 nodes (0), 13 edges (0), time = 0.335ms.
  layout: Graph size after: 12 nodes (0), 13 edges (0), time = 0.23ms.
  constant_folding: Graph size after: 12 nodes (0), 13 edges (0), time = 0.295ms.
  TensorRTOptimizer: Graph size after: 12 nodes (0), 13 edges (0), time = 0.01ms.
  constant_folding: Graph size after: 12 nodes (0), 13 edges (0), time = 0.305ms.
Optimization results for grappler item: TRTEngineOp_0_11_native_segment
  constant_folding: Graph size after: 33 nodes (0), 36 edges (0), time = 0.806ms.
  layout: Graph size after: 33 nodes (0), 36 edges (0), time = 0.82ms.
  constant_folding: Graph size after: 33 nodes (0), 36 edges (0), time = 0.807ms.
  TensorRTOptimizer: Graph size after: 33 nodes (0), 36 edges (0), time = 0.062ms.
  constant_folding: Graph size after: 33 nodes (0), 36 edges (0), time = 0.806ms.
Optimization results for grappler item: TRTEngineOp_0_15_native_segment
  constant_folding: Graph size after: 46 nodes (0), 48 edges (0), time = 1.016ms.
  layout: Graph size after: 46 nodes (0), 48 edges (0), time = 1.088ms.
  constant_folding: Graph size after: 46 nodes (0), 48 edges (0), time = 1.025ms.
  TensorRTOptimizer: Graph size after: 46 nodes (0), 48 edges (0), time = 0.083ms.
  constant_folding: Graph size after: 46 nodes (0), 48 edges (0), time = 1.05ms.
Optimization results for grappler item: TRTEngineOp_0_20_native_segment
  constant_folding: Graph size after: 47 nodes (0), 49 edges (0), time = 1.245ms.
  layout: Graph size after: 47 nodes (0), 49 edges (0), time = 1.482ms.
  constant_folding: Graph size after: 47 nodes (0), 49 edges (0), time = 1.256ms.
  TensorRTOptimizer: Graph size after: 47 nodes (0), 49 edges (0), time = 0.118ms.
  constant_folding: Graph size after: 47 nodes (0), 49 edges (0), time = 1.24ms.
Optimization results for grappler item: TRTEngineOp_0_12_native_segment
  constant_folding: Graph size after: 33 nodes (0), 36 edges (0), time = 0.788ms.
  layout: Graph size after: 33 nodes (0), 36 edges (0), time = 0.822ms.
  constant_folding: Graph size after: 33 nodes (0), 36 edges (0), time = 0.811ms.
  TensorRTOptimizer: Graph size after: 33 nodes (0), 36 edges (0), time = 0.062ms.
  constant_folding: Graph size after: 33 nodes (0), 36 edges (0), time = 0.814ms.
Optimization results for grappler item: TRTEngineOp_0_19_native_segment
  constant_folding: Graph size after: 50 nodes (0), 52 edges (0), time = 1.126ms.
  layout: Graph size after: 50 nodes (0), 52 edges (0), time = 1.256ms.
  constant_folding: Graph size after: 50 nodes (0), 52 edges (0), time = 1.133ms.
  TensorRTOptimizer: Graph size after: 50 nodes (0), 52 edges (0), time = 0.094ms.
  constant_folding: Graph size after: 50 nodes (0), 52 edges (0), time = 1.121ms.
Optimization results for grappler item: TRTEngineOp_0_9_native_segment
  constant_folding: Graph size after: 33 nodes (0), 36 edges (0), time = 0.802ms.
  layout: Graph size after: 33 nodes (0), 36 edges (0), time = 0.823ms.
  constant_folding: Graph size after: 33 nodes (0), 36 edges (0), time = 0.859ms.
  TensorRTOptimizer: Graph size after: 33 nodes (0), 36 edges (0), time = 0.064ms.
  constant_folding: Graph size after: 33 nodes (0), 36 edges (0), time = 0.799ms.
Optimization results for grappler item: TRTEngineOp_0_10_native_segment
  constant_folding: Graph size after: 692 nodes (0), 761 edges (0), time = 15.29ms.
  layout: Graph size after: 692 nodes (0), 761 edges (0), time = 18.143ms.
  constant_folding: Graph size after: 692 nodes (0), 761 edges (0), time = 15.126ms.
  TensorRTOptimizer: Graph size after: 692 nodes (0), 761 edges (0), time = 1.447ms.
  constant_folding: Graph size after: 692 nodes (0), 761 edges (0), time = 15.151ms.
Optimization results for grappler item: TRTEngineOp_0_1_native_segment
  constant_folding: Graph size after: 44 nodes (0), 46 edges (0), time = 2.195ms.
  layout: Graph size after: 44 nodes (0), 46 edges (0), time = 3.041ms.
  constant_folding: Graph size after: 44 nodes (0), 46 edges (0), time = 1.848ms.
  TensorRTOptimizer: Graph size after: 44 nodes (0), 46 edges (0), time = 0.264ms.
  constant_folding: Graph size after: 44 nodes (0), 46 edges (0), time = 1.887ms.
Optimization results for grappler item: TRTEngineOp_0_21_native_segment
  constant_folding: Graph size after: 50 nodes (0), 52 edges (0), time = 1.372ms.
  layout: Graph size after: 50 nodes (0), 52 edges (0), time = 1.707ms.
  constant_folding: Graph size after: 50 nodes (0), 52 edges (0), time = 1.368ms.
  TensorRTOptimizer: Graph size after: 50 nodes (0), 52 edges (0), time = 0.133ms.
  constant_folding: Graph size after: 50 nodes (0), 52 edges (0), time = 1.348ms.
Optimization results for grappler item: TRTEngineOp_0_16_native_segment
  constant_folding: Graph size after: 47 nodes (0), 49 edges (0), time = 1.066ms.
  layout: Graph size after: 47 nodes (0), 49 edges (0), time = 1.159ms.
  constant_folding: Graph size after: 47 nodes (0), 49 edges (0), time = 1.096ms.
  TensorRTOptimizer: Graph size after: 47 nodes (0), 49 edges (0), time = 0.095ms.
  constant_folding: Graph size after: 47 nodes (0), 49 edges (0), time = 1.097ms.
Optimization results for grappler item: TRTEngineOp_0_23_native_segment
  constant_folding: Graph size after: 47 nodes (0), 49 edges (0), time = 1.465ms.
  layout: Graph size after: 47 nodes (0), 49 edges (0), time = 1.878ms.
  constant_folding: Graph size after: 47 nodes (0), 49 edges (0), time = 1.417ms.
  TensorRTOptimizer: Graph size after: 47 nodes (0), 49 edges (0), time = 0.15ms.
  constant_folding: Graph size after: 47 nodes (0), 49 edges (0), time = 1.446ms.
Optimization results for grappler item: TRTEngineOp_0_24_native_segment
  constant_folding: Graph size after: 50 nodes (0), 52 edges (0), time = 1.551ms.
  layout: Graph size after: 50 nodes (0), 52 edges (0), time = 2.083ms.
  constant_folding: Graph size after: 50 nodes (0), 52 edges (0), time = 1.488ms.
  TensorRTOptimizer: Graph size after: 50 nodes (0), 52 edges (0), time = 0.169ms.
  constant_folding: Graph size after: 50 nodes (0), 52 edges (0), time = 1.547ms.
Optimization results for grappler item: TRTEngineOp_0_7_native_segment
  constant_folding: Graph size after: 33 nodes (0), 36 edges (0), time = 0.826ms.
  layout: Graph size after: 33 nodes (0), 36 edges (0), time = 0.835ms.
  constant_folding: Graph size after: 33 nodes (0), 36 edges (0), time = 0.823ms.
  TensorRTOptimizer: Graph size after: 33 nodes (0), 36 edges (0), time = 0.061ms.
  constant_folding: Graph size after: 33 nodes (0), 36 edges (0), time = 0.808ms.
Optimization results for grappler item: TRTEngineOp_0_5_native_segment
  constant_folding: Graph size after: 42 nodes (0), 45 edges (0), time = 1.003ms.
  layout: Graph size after: 42 nodes (0), 45 edges (0), time = 1.102ms.
  constant_folding: Graph size after: 42 nodes (0), 45 edges (0), time = 1.03ms.
  TensorRTOptimizer: Graph size after: 42 nodes (0), 45 edges (0), time = 0.086ms.
  constant_folding: Graph size after: 42 nodes (0), 45 edges (0), time = 1.002ms.
Optimization results for grappler item: TRTEngineOp_0_0_native_segment
  constant_folding: Graph size after: 8 nodes (0), 7 edges (0), time = 0.265ms.
  layout: Graph size after: 8 nodes (0), 7 edges (0), time = 0.186ms.
  constant_folding: Graph size after: 8 nodes (0), 7 edges (0), time = 0.234ms.
  TensorRTOptimizer: Graph size after: 8 nodes (0), 7 edges (0), time = 0.008ms.
  constant_folding: Graph size after: 8 nodes (0), 7 edges (0), time = 0.243ms.
Optimization results for grappler item: TRTEngineOp_0_25_native_segment
  constant_folding: Graph size after: 50 nodes (0), 52 edges (0), time = 1.566ms.
  layout: Graph size after: 50 nodes (0), 52 edges (0), time = 2ms.
  constant_folding: Graph size after: 50 nodes (0), 52 edges (0), time = 1.503ms.
  TensorRTOptimizer: Graph size after: 50 nodes (0), 52 edges (0), time = 0.164ms.
  constant_folding: Graph size after: 50 nodes (0), 52 edges (0), time = 1.532ms.
Optimization results for grappler item: TRTEngineOp_0_26_native_segment
  constant_folding: Graph size after: 47 nodes (0), 49 edges (0), time = 1.988ms.
  layout: Graph size after: 47 nodes (0), 49 edges (0), time = 2.847ms.
  constant_folding: Graph size after: 47 nodes (0), 49 edges (0), time = 1.775ms.
  TensorRTOptimizer: Graph size after: 47 nodes (0), 49 edges (0), time = 0.245ms.
  constant_folding: Graph size after: 47 nodes (0), 49 edges (0), time = 1.851ms.

2022-04-20 04:40:38.881680: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at trt_engine_resource_ops.cc:198 : NOT_FOUND: Container TF-TRT does not exist. (Could not find resource: TF-TRT/TRTEngineOp_0_30)
2022-04-20 04:40:38.882029: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at trt_engine_resource_ops.cc:198 : NOT_FOUND: Container TF-TRT does not exist. (Could not find resource: TF-TRT/TRTEngineOp_0_31)
2022-04-20 04:40:38.882302: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at trt_engine_resource_ops.cc:198 : NOT_FOUND: Container TF-TRT does not exist. (Could not find resource: TF-TRT/TRTEngineOp_0_14)
2022-04-20 04:40:38.882531: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at trt_engine_resource_ops.cc:198 : NOT_FOUND: Container TF-TRT does not exist. (Could not find resource: TF-TRT/TRTEngineOp_0_0)
2022-04-20 04:40:38.882749: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at trt_engine_resource_ops.cc:198 : NOT_FOUND: Container TF-TRT does not exist. (Could not find resource: TF-TRT/TRTEngineOp_0_15)
2022-04-20 04:40:38.882961: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at trt_engine_resource_ops.cc:198 : NOT_FOUND: Container TF-TRT does not exist. (Could not find resource: TF-TRT/TRTEngineOp_0_16)
2022-04-20 04:40:38.883192: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at trt_engine_resource_ops.cc:198 : NOT_FOUND: Container TF-TRT does not exist. (Could not find resource: TF-TRT/TRTEngineOp_0_17)
2022-04-20 04:40:38.883404: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at trt_engine_resource_ops.cc:198 : NOT_FOUND: Container TF-TRT does not exist. (Could not find resource: TF-TRT/TRTEngineOp_0_18)
2022-04-20 04:40:38.883624: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at trt_engine_resource_ops.cc:198 : NOT_FOUND: Container TF-TRT does not exist. (Could not find resource: TF-TRT/TRTEngineOp_0_19)
2022-04-20 04:40:38.883835: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at trt_engine_resource_ops.cc:198 : NOT_FOUND: Container TF-TRT does not exist. (Could not find resource: TF-TRT/TRTEngineOp_0_20)
2022-04-20 04:40:38.884032: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at trt_engine_resource_ops.cc:198 : NOT_FOUND: Container TF-TRT does not exist. (Could not find resource: TF-TRT/TRTEngineOp_0_21)
2022-04-20 04:40:38.884223: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at trt_engine_resource_ops.cc:198 : NOT_FOUND: Container TF-TRT does not exist. (Could not find resource: TF-TRT/TRTEngineOp_0_22)
2022-04-20 04:40:38.884408: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at trt_engine_resource_ops.cc:198 : NOT_FOUND: Container TF-TRT does not exist. (Could not find resource: TF-TRT/TRTEngineOp_0_23)
2022-04-20 04:40:38.884594: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at trt_engine_resource_ops.cc:198 : NOT_FOUND: Container TF-TRT does not exist. (Could not find resource: TF-TRT/TRTEngineOp_0_24)
2022-04-20 04:40:38.884777: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at trt_engine_resource_ops.cc:198 : NOT_FOUND: Container TF-TRT does not exist. (Could not find resource: TF-TRT/TRTEngineOp_0_25)
2022-04-20 04:40:38.884962: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at trt_engine_resource_ops.cc:198 : NOT_FOUND: Container TF-TRT does not exist. (Could not find resource: TF-TRT/TRTEngineOp_0_26)
2022-04-20 04:40:38.885146: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at trt_engine_resource_ops.cc:198 : NOT_FOUND: Container TF-TRT does not exist. (Could not find resource: TF-TRT/TRTEngineOp_0_27)
2022-04-20 04:40:38.885331: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at trt_engine_resource_ops.cc:198 : NOT_FOUND: Container TF-TRT does not exist. (Could not find resource: TF-TRT/TRTEngineOp_0_28)
2022-04-20 04:40:38.885530: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at trt_engine_resource_ops.cc:198 : NOT_FOUND: Container TF-TRT does not exist. (Could not find resource: TF-TRT/TRTEngineOp_0_29)
2022-04-20 04:40:38.885716: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at trt_engine_resource_ops.cc:198 : NOT_FOUND: Container TF-TRT does not exist. (Could not find resource: TF-TRT/TRTEngineOp_0_1)
2022-04-20 04:40:38.885902: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at trt_engine_resource_ops.cc:198 : NOT_FOUND: Container TF-TRT does not exist. (Could not find resource: TF-TRT/TRTEngineOp_0_2)
2022-04-20 04:40:38.886088: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at trt_engine_resource_ops.cc:198 : NOT_FOUND: Container TF-TRT does not exist. (Could not find resource: TF-TRT/TRTEngineOp_0_4)
2022-04-20 04:40:38.886271: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at trt_engine_resource_ops.cc:198 : NOT_FOUND: Container TF-TRT does not exist. (Could not find resource: TF-TRT/TRTEngineOp_0_5)
2022-04-20 04:40:38.886455: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at trt_engine_resource_ops.cc:198 : NOT_FOUND: Container TF-TRT does not exist. (Could not find resource: TF-TRT/TRTEngineOp_0_3)
2022-04-20 04:40:38.886639: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at trt_engine_resource_ops.cc:198 : NOT_FOUND: Container TF-TRT does not exist. (Could not find resource: TF-TRT/TRTEngineOp_0_9)
2022-04-20 04:40:38.886819: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at trt_engine_resource_ops.cc:198 : NOT_FOUND: Container TF-TRT does not exist. (Could not find resource: TF-TRT/TRTEngineOp_0_8)
2022-04-20 04:40:38.887015: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at trt_engine_resource_ops.cc:198 : NOT_FOUND: Container TF-TRT does not exist. (Could not find resource: TF-TRT/TRTEngineOp_0_7)
2022-04-20 04:40:38.887202: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at trt_engine_resource_ops.cc:198 : NOT_FOUND: Container TF-TRT does not exist. (Could not find resource: TF-TRT/TRTEngineOp_0_6)
2022-04-20 04:40:38.887387: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at trt_engine_resource_ops.cc:198 : NOT_FOUND: Container TF-TRT does not exist. (Could not find resource: TF-TRT/TRTEngineOp_0_13)
2022-04-20 04:40:38.887571: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at trt_engine_resource_ops.cc:198 : NOT_FOUND: Container TF-TRT does not exist. (Could not find resource: TF-TRT/TRTEngineOp_0_12)
2022-04-20 04:40:38.887755: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at trt_engine_resource_ops.cc:198 : NOT_FOUND: Container TF-TRT does not exist. (Could not find resource: TF-TRT/TRTEngineOp_0_11)
2022-04-20 04:40:38.887937: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at trt_engine_resource_ops.cc:198 : NOT_FOUND: Container TF-TRT does not exist. (Could not find resource: TF-TRT/TRTEngineOp_0_10)
2022-04-20 04:40:38.888158: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at trt_engine_resource_ops.cc:198 : NOT_FOUND: Container TF-TRT does not exist. (Could not find resource: TF-TRT/TRTEngineOp_0_32)
WARNING:absl:Found untraced functions such as restored_function_body, restored_function_body, restored_function_body, restored_function_body, restored_function_body while saving (showing 5 of 318). These functions will not be directly callable after loading.
Traceback (most recent call last):
  File ""./convert.py"", line 14, in <module>
    converter.save(mmm + ""_trt_fp32"")
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/compiler/tensorrt/trt_convert.py"", line 1408, in save
    save.save(self._saved_model, output_saved_model_dir, signatures)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/saved_model/save.py"", line 1334, in save
    save_and_return_nodes(obj, export_dir, signatures, options)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/saved_model/save.py"", line 1369, in save_and_return_nodes
    _build_meta_graph(obj, signatures, options, meta_graph_def))
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/saved_model/save.py"", line 1536, in _build_meta_graph
    return _build_meta_graph_impl(obj, signatures, options, meta_graph_def)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/saved_model/save.py"", line 1492, in _build_meta_graph_impl
    options.namespace_whitelist, options.experimental_custom_gradients)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/saved_model/save.py"", line 944, in _fill_meta_graph_def
    _trace_gradient_functions(exported_graph, saveable_view)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/saved_model/save.py"", line 799, in _trace_gradient_functions
    for op_type, op in _iterate_op_types(fn):
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/saved_model/save.py"", line 762, in _iterate_op_types
    ""Unable to save gradient functions when exporting a ""
ValueError: Unable to save gradient functions when exporting a _DefinedFunction (generally created through graph freezing utils or through V1 graph importers). Please save with `options=tf.SaveOptions(experimental_custom_gradients=False)`
```
</details>"
55669,"[TRT] TF 2.9.0-rc0 ssd_mobilenet_v2 TRT FP16 conversion failed. (-1,-1,-1,3), float32","<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

2.9.0-rc0

### Custom Code

No

### OS Platform and Distribution

Linux Ubuntu 18.04

### Mobile device

_No response_

### Python version

3.7

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN/TensorRT version

11.2 / 8.1.1.33 / 7.2.3-1

### GPU model and memory

Nvidia Tesla T4 16GB (aws g4dn.2xlarge)

### Current Behaviour?

```shell
ssd_mobilenet_v2 model is from TF2 model Zoo.
It was exported with `--input_type=float_image_tensor` parameter.
Exported model input is `<tf.Tensor 'input_tensor:0' shape=(None, None, None, 3) dtype=float32>`.

Converting the model to TRT with FP16 PrecisionMode fails.
Error: `ValueError: Received a shape scalar with unknown static value.  A static value of '-1' is required to represent an unknown shape.`

The conversion worked fine in TF 2.4, 2.6, 2.7, 2.8.
The issue started to happen in TF 2.9.0-rc0
```

### Standlone code to reproduce the issue
Download [SSD MobileNet v2 320x320](http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_320x320_coco17_tpu-8.tar.gz) from [TensorFlow 2 Detection Model Zoo](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md)

Export the model using `--input_type=float_image_tensor` parameter. 
It will create a model with input `<tf.Tensor 'input_tensor:0' shape=(None, None, None, 3) dtype=float32>`:
```shell
# Export the Model
MODEL=ssd_mobilenet_v2_320x320_coco17_tpu-8
python3 object_detection/exporter_main_v2.py \
    --input_type=float_image_tensor \
    --pipeline_config_path=$MODEL/pipeline.config \
    --trained_checkpoint_dir=$MODEL/checkpoint \
    --output_directory=output/${MODEL}_float32_batchN
```
Exported model can be downloaded from [here](https://www.dropbox.com/s/1uznvtf6u4czgot/ssd_mobilenet_v2_320x320_coco17_tpu-8_float32_batchN.tar.gz?dl=0)
```
# Convert the model to TRT FP16

cd output/ssd_mobilenet_v2_320x320_coco17_tpu-8_float32_batchN

import tensorflow as tf
from tensorflow.python.compiler.tensorrt import trt_convert as trt
conversion_params = trt.TrtConversionParams(precision_mode=trt.TrtPrecisionMode.FP16)
converter = trt.TrtGraphConverterV2(
    input_saved_model_dir=""saved_model"",
    conversion_params=conversion_params)
converter.convert()
```


### Relevant log output

```shell
>>> converter = trt.TrtGraphConverterV2(
...     input_saved_model_dir=""saved_model"",
...     conversion_params=conversion_params)
INFO:tensorflow:Linked TensorRT version: (7, 2, 2)
INFO:tensorflow:Loaded TensorRT version: (7, 2, 3)
INFO:tensorflow:Loaded TensorRT 7.2.3 and linked TensorFlow against TensorRT 7.2.2. This is supported because TensorRT minor/patch upgrades are backward compatible.
>>> converter.convert()
2022-04-19 18:59:33.559459: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-04-19 18:59:33.566342: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-04-19 18:59:33.568044: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-04-19 18:59:33.569815: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-04-19 18:59:33.570320: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-04-19 18:59:33.571871: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-04-19 18:59:33.573363: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-04-19 18:59:34.263138: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-04-19 18:59:34.264552: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-04-19 18:59:34.265704: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-04-19 18:59:34.266826: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13596 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5
2022-04-19 18:59:45.455700: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-04-19 18:59:45.457173: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1
2022-04-19 18:59:45.457334: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session
2022-04-19 18:59:45.457786: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-04-19 18:59:45.459086: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-04-19 18:59:45.460342: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-04-19 18:59:45.461644: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-04-19 18:59:45.462905: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-04-19 18:59:45.464134: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13596 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5
2022-04-19 18:59:53.296013: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-04-19 18:59:53.297496: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1
2022-04-19 18:59:53.297612: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session
2022-04-19 18:59:53.297949: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-04-19 18:59:53.299278: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-04-19 18:59:53.300541: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-04-19 18:59:53.301857: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-04-19 18:59:53.303121: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-04-19 18:59:53.304366: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13596 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5
2022-04-19 18:59:54.739820: W tensorflow/compiler/tf2tensorrt/convert/trt_optimization_pass.cc:186] Calibration with FP32 or FP16 is not implemented. Falling back to use_calibration = False.Note that the default value of use_calibration is True.
2022-04-19 18:59:54.922287: W tensorflow/compiler/tf2tensorrt/segment/segment.cc:952]

################################################################################
TensorRT unsupported/non-converted OP Report:
	- Placeholder -> 1267x
	- GatherV2 -> 390x
	- ConcatV2 -> 186x
	- Fill -> 184x
	- StridedSlice -> 133x
	- Sub -> 117x
	- Shape -> 117x
	- Reshape -> 113x
	- Slice -> 102x
	- Select -> 102x
	- AddV2 -> 100x
	- Less -> 94x
	- ZerosLike -> 92x
	- NonMaxSuppressionV5 -> 90x
	- Pack -> 35x
	- Merge -> 25x
	- Enter -> 25x
	- NextIteration -> 25x
	- Switch -> 25x
	- Mul -> 21x
	- Exit -> 20x
	- Identity -> 12x
	- Greater -> 12x
	- ExpandDims -> 10x
	- Cast -> 9x
	- TensorListSetItem -> 9x
	- TensorListFromTensor -> 8x
	- TensorListGetItem -> 8x
	- TensorListStack -> 8x
	- Pad -> 6x
	- DataFormatVecPermute -> 6x
	- Minimum -> 6x
	- Unpack -> 6x
	- TensorListReserve -> 4x
	- Split -> 4x
	- NoOp -> 4x
	- Maximum -> 4x
	- Range -> 3x
	- Transpose -> 3x
	- Tile -> 2x
	- TopKV2 -> 2x
	- Exp -> 2x
	- Reciprocal -> 2x
	- LoopCond -> 2x
	- LogicalAnd -> 2x
	- Sum -> 1x
	- Squeeze -> 1x
	- ResizeBilinear -> 1x
	- GreaterEqual -> 1x
	- Where -> 1x
--------------------------------------------------------------------------------
	- Total nonconverted OPs: 3402
	- Total nonconverted OP Types: 50
For more information see https://docs.nvidia.com/deeplearning/frameworks/tf-trt-user-guide/index.html#supported-ops.
################################################################################

2022-04-19 18:59:54.996948: W tensorflow/compiler/tf2tensorrt/segment/segment.cc:1280] The environment variable TF_TRT_MAX_ALLOWED_ENGINES=20 has no effect since there are only 3 TRT Engines with  at least minimum_segment_size=3 nodes.
2022-04-19 18:59:55.004054: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:795] Number of TensorRT candidate segments: 3
2022-04-19 18:59:55.057662: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:909] Replaced segment 0 consisting of 536 nodes by TRTEngineOp_000_000.
2022-04-19 18:59:55.058968: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:909] Replaced segment 1 consisting of 3 nodes by TRTEngineOp_000_001.
2022-04-19 18:59:55.059085: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:909] Replaced segment 2 consisting of 4 nodes by TRTEngineOp_000_002.
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/compiler/tensorrt/trt_convert.py"", line 1234, in convert
    [tensor.name for tensor in frozen_func.outputs])
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/wrap_function.py"", line 659, in function_from_graph_def
    nest.map_structure(import_graph.as_graph_element, outputs))
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/wrap_function.py"", line 336, in prune
    base_graph=self._func_graph)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/lift_to_graph.py"", line 337, in lift_to_graph
    op=op, graph=graph, op_map=op_map, base_graph=base_graph)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/lift_to_graph.py"", line 131, in _copy_non_source
    name=op.name)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py"", line 561, in new_func
    return func(*args, **kwargs)
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py"", line 153, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File ""/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py"", line 1963, in _create_c_op
    raise ValueError(e.message)
ValueError: Received a shape scalar with unknown static value.  A static value of '-1' is required to represent an unknown shape.
```
</details>"
55668,Inconsistent documentation regarding supported input data type and ParameterServerStrategy,"### Issue Type

Documentation Bug

### Current Behaviour?

There is a direct conflict between the `ParameterServerStrategy` [tutorial doc][1], which states:

```
Keras Model.fit with tf.distribute.ParameterServerStrategy can take input data in the form of a tf.data.Dataset, tf.distribute.DistributedDataset, or a tf.keras.utils.experimental.DatasetCreator, with Dataset being the recommended option for ease of use.
```

And these pages:

* [ParameterServerStrategy][2]:

```
When using Model.fit, tf.distribute.experimental.ParameterServerStrategy must be used with a tf.keras.utils.experimental.DatasetCreator, and steps_per_epoch must be specified.
```

* [Distributed Input][3]:

```
Users of tf.distribute.experimental.ParameterServerStrategy with the Model.fit API need to use a tf.keras.utils.experimental.DatasetCreator as the input
```

* [Model.fit][4]:

```
If using tf.distribute.experimental.ParameterServerStrategy, only DatasetCreator type is supported for X
```

**The former recommends using `Dataset` while the latter explicitly states only `DatasetCreator` is supported.**

[1]: https://www.tensorflow.org/tutorials/distribute/parameter_server_training#input_data
[2]: https://www.tensorflow.org/api_docs/python/tf/distribute/experimental/ParameterServerStrategy
[3]: https://www.tensorflow.org/tutorials/distribute/input
[4]: https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit
"
55664,"java.lang.IllegalArgumentException: Error occurred when initializing ObjectDetector: Mobile SSD models are expected to have exactly 4 outputs, found 8","I have quantized my custom trained TensorFlow model into tflite model using the following code but when I put my quantized tflite model into Tensorflow's Object detection android app with a label file, above mentioned error occurred in android studio. Please guide me to solve this problem. Thanks a Lot.

Custom Code used for quantization of TensorFlow model:

```shell
import tensorflow as tf

converter = tf.lite.TFLiteConverter.from_saved_model(""/saved_model"")
converter.optimizations = [tf.lite.Optimize.DEFAULT]
converter.target_spec.supported_types = [tf.float16]
converter.target_spec.supported_ops = [
  tf.lite.OpsSet.TFLITE_BUILTINS, # enable TensorFlow Lite ops.
  tf.lite.OpsSet.SELECT_TF_OPS # enable TensorFlow ops.
]
tflite_quant_model = converter.convert()

print(len(tflite_quant_model))
with open(""tflite_quant_model.tflite"", ""wb"") as f:
    f.write(tflite_quant_model)
```


The Output which I got after adding the quantized model into Tensorflow's Android application:

```shell
E/TaskJniUtils: Error getting native address of native library: task_vision_jni
    java.lang.IllegalArgumentException: Error occurred when initializing ObjectDetector: Mobile SSD models are expected to have exactly 4 outputs, found 8
        at org.tensorflow.lite.task.vision.detector.ObjectDetector.initJniWithByteBuffer(Native Method)
        at org.tensorflow.lite.task.vision.detector.ObjectDetector.access$100(ObjectDetector.java:88)
        at org.tensorflow.lite.task.vision.detector.ObjectDetector$3.createHandle(ObjectDetector.java:223)
        at org.tensorflow.lite.task.core.TaskJniUtils.createHandleFromLibrary(TaskJniUtils.java:91)
        at org.tensorflow.lite.task.vision.detector.ObjectDetector.createFromBufferAndOptions(ObjectDetector.java:219)
        at org.tensorflow.lite.examples.detection.tflite.TFLiteObjectDetectionAPIModel.<init>(TFLiteObjectDetectionAPIModel.java:88)
        at org.tensorflow.lite.examples.detection.tflite.TFLiteObjectDetectionAPIModel.create(TFLiteObjectDetectionAPIModel.java:82)
        at org.tensorflow.lite.examples.detection.DetectorActivity.onPreviewSizeChosen(DetectorActivity.java:105)
        at org.tensorflow.lite.examples.detection.CameraActivity.onPreviewFrame(CameraActivity.java:200)
        at android.hardware.Camera$EventHandler.handleMessage(Camera.java:1221)
        at android.os.Handler.dispatchMessage(Handler.java:107)
        at android.os.Looper.loop(Looper.java:214)
        at android.app.ActivityThread.main(ActivityThread.java:7356)
        at java.lang.reflect.Method.invoke(Native Method)
        at com.android.internal.os.RuntimeInit$MethodAndArgsCaller.run(RuntimeInit.java:492)
        at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:930)
E/tensorflow: CameraActivity: Exception!
    java.lang.IllegalStateException: Error getting native address of native library: task_vision_jni
        at org.tensorflow.lite.task.core.TaskJniUtils.createHandleFromLibrary(TaskJniUtils.java:95)
        at org.tensorflow.lite.task.vision.detector.ObjectDetector.createFromBufferAndOptions(ObjectDetector.java:219)
        at org.tensorflow.lite.examples.detection.tflite.TFLiteObjectDetectionAPIModel.<init>(TFLiteObjectDetectionAPIModel.java:88)
        at org.tensorflow.lite.examples.detection.tflite.TFLiteObjectDetectionAPIModel.create(TFLiteObjectDetectionAPIModel.java:82)
        at org.tensorflow.lite.examples.detection.DetectorActivity.onPreviewSizeChosen(DetectorActivity.java:105)
        at org.tensorflow.lite.examples.detection.CameraActivity.onPreviewFrame(CameraActivity.java:200)
        at android.hardware.Camera$EventHandler.handleMessage(Camera.java:1221)
        at android.os.Handler.dispatchMessage(Handler.java:107)
        at android.os.Looper.loop(Looper.java:214)
        at android.app.ActivityThread.main(ActivityThread.java:7356)
        at java.lang.reflect.Method.invoke(Native Method)
        at com.android.internal.os.RuntimeInit$MethodAndArgsCaller.run(RuntimeInit.java:492)
        at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:930)
     Caused by: java.lang.IllegalArgumentException: Error occurred when initializing ObjectDetector: Mobile SSD models are expected to have exactly 4 outputs, found 8
        at org.tensorflow.lite.task.vision.detector.ObjectDetector.initJniWithByteBuffer(Native Method)
        at org.tensorflow.lite.task.vision.detector.ObjectDetector.access$100(ObjectDetector.java:88)
        at org.tensorflow.lite.task.vision.detector.ObjectDetector$3.createHandle(ObjectDetector.java:223)
        at org.tensorflow.lite.task.core.TaskJniUtils.createHandleFromLibrary(TaskJniUtils.java:91)
        at org.tensorflow.lite.task.vision.detector.ObjectDetector.createFromBufferAndOptions(ObjectDetector.java:219) 
        at org.tensorflow.lite.examples.detection.tflite.TFLiteObjectDetectionAPIModel.<init>(TFLiteObjectDetectionAPIModel.java:88) 
        at org.tensorflow.lite.examples.detection.tflite.TFLiteObjectDetectionAPIModel.create(TFLiteObjectDetectionAPIModel.java:82) 
        at org.tensorflow.lite.examples.detection.DetectorActivity.onPreviewSizeChosen(DetectorActivity.java:105) 
        at org.tensorflow.lite.examples.detection.CameraActivity.onPreviewFrame(CameraActivity.java:200) 
        at android.hardware.Camera$EventHandler.handleMessage(Camera.java:1221) 
        at android.os.Handler.dispatchMessage(Handler.java:107) 
        at android.os.Looper.loop(Looper.java:214) 
        at android.app.ActivityThread.main(ActivityThread.java:7356) 
        at java.lang.reflect.Method.invoke(Native Method) 
        at com.android.internal.os.RuntimeInit$MethodAndArgsCaller.run(RuntimeInit.java:492) 
        at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:930) 
```
</details>"
55663,tf.GradientTape.gradients(),
55662,build tensorflow2.8 failed ,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Build/Install

### Source

source

### Tensorflow Version

tf2.8

### Custom Code

Yes

### OS Platform and Distribution

centos7.6

### Mobile device

_No response_

### Python version

3.7.12

### Bazel version

4.2.2

### GCC/Compiler version

7.3.1

### CUDA/cuDNN version

rocm5.0.2

### GPU model and memory

_No response_

### Current Behaviour?

```shell
build failed
ERROR: /root/.cache/bazel/_bazel_root/7e60a61be90f35a88e89e062446eed75/external/llvm-project/mlir/BUILD.bazel:5763:10: Linking external/llvm-project/mlir/mlir-tblgen failed: (Exit 1): crosstool_wrapper_driver_is_not_gcc failed: error executing command
  (cd /root/.cache/bazel/_bazel_root/7e60a61be90f35a88e89e062446eed75/execroot/org_tensorflow && \
  exec env - \
    LD_LIBRARY_PATH=/opt/dtk-22.04/hip/lib:/opt/dtk-22.04/llvm/lib:/opt/dtk-22.04/lib:/opt/dtk-22.04/lib64:/opt/dtk-22.04/hip/lib:/opt/dtk-22.04/llvm/lib:/opt/dtk-22.04/lib:/opt/dtk-22.04/lib64:/opt/rh/devtoolset-7/root/usr/lib64:/opt/rh/devtoolset-7/root/usr/lib:/opt/rh/devtoolset-7/root/usr/lib64/dyninst:/opt/rh/devtoolset-7/root/usr/lib/dyninst:/opt/rh/devtoolset-7/root/usr/lib64:/opt/rh/devtoolset-7/root/usr/lib \
    PATH=/opt/dtk-22.04/bin:/opt/dtk-22.04/llvm/bin:/opt/dtk-22.04/hip/bin:/opt/dtk-22.04/bin:/opt/dtk-22.04/llvm/bin:/opt/dtk-22.04/hip/bin:/home/tensorflow-2.8.0/Depend/bin:/home/tensorflow/Depend/bin:/opt/git-2.30.0/bin:/opt/cmake-3.19.3-Linux-x86_64/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \
    PWD=/proc/self/cwd \
  external/local_config_rocm/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc @bazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/mlir/mlir-tblgen-2.params)
Execution platform: @local_execution_config_platform//:platform
bazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/mlir/_objs/mlir-tblgen/AttrOrTypeDefGen.o:AttrOrTypeDefGen.cpp:function llvm::detail::provider_format_adapter<llvm::StringRef&>::~provider_format_adapter(): error: undefined reference to 'operator delete(void*, unsigned long)'
bazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/mlir/_objs/mlir-tblgen/AttrOrTypeDefGen.o:AttrOrTypeDefGen.cpp:function llvm::detail::provider_format_adapter<llvm::StringRef>::~provider_format_adapter(): error: undefined reference to 'operator delete(void*, unsigned long)'
bazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/mlir/_objs/mlir-tblgen/AttrOrTypeDefGen.o:AttrOrTypeDefGen.cpp:function llvm::detail::provider_format_adapter<char const*>::~provider_format_adapter(): error: undefined reference to 'operator delete(void*, unsigned long)'
bazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/mlir/_objs/mlir-tblgen/AttrOrTypeDefGen.o:AttrOrTypeDefGen.cpp:function llvm::detail::provider_format_adapter<std::string&>::~provider_format_adapter(): error: undefined reference to 'operator delete(void*, unsigned long)'
bazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/llvm/_objs/TableGen/Main.o:Main.cpp:function llvm::TableGenMain(char const*, bool (*)(llvm::raw_ostream&, llvm::RecordKeeper&)): error: undefined reference to 'std::_V2::system_category()'
bazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/llvm/_objs/TableGen/Main.o:Main.cpp:function llvm::TableGenMain(char const*, bool (*)(llvm::raw_ostream&, llvm::RecordKeeper&)): error: undefined reference to 'std::_V2::system_category()'
bazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/llvm/_objs/Support/CommandLine.o:CommandLine.cpp:function ExpandResponseFile(llvm::StringRef, llvm::StringSaver&, void (*)(llvm::StringRef, llvm::StringSaver&, llvm::SmallVectorImpl<char const*>&, bool), llvm::SmallVectorImpl<char const*>&, bool, bool, llvm::vfs::FileSystem&): error: undefined reference to 'std::_V2::generic_category()'
bazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/llvm/_objs/Support/ConvertUTFWrapper.o:ConvertUTFWrapper.cpp:function llvm::convertUTF16ToUTF8String(llvm::ArrayRef<char>, std::string&): error: undefined reference to 'std::__throw_out_of_range_fmt(char const*, ...)'
bazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/llvm/_objs/Support/Error.o:Error.cpp:function (anonymous namespace)::ErrorErrorCategory::~ErrorErrorCategory(): error: undefined reference to 'std::_V2::error_category::~error_category()'
bazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/llvm/_objs/Support/Error.o:Error.cpp:function (anonymous namespace)::ErrorErrorCategory::~ErrorErrorCategory(): error: undefined reference to 'std::_V2::error_category::~error_category()'
bazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/llvm/_objs/Support/Error.o:Error.cpp:function llvm::object_deleter<(anonymous namespace)::ErrorErrorCategory>::call(void*): error: undefined reference to 'std::_V2::error_category::~error_category()'
bazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/llvm/_objs/Support/Error.o:Error.cpp:function llvm::errorToErrorCode(llvm::Error): error: undefined reference to 'std::_V2::system_category()'
bazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/llvm/_objs/Support/Error.o:Error.cpp:typeinfo for (anonymous namespace)::ErrorErrorCategory: error: undefined reference to 'typeinfo for std::_V2::error_category'
bazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/llvm/_objs/Support/Error.o:Error.cpp:vtable for (anonymous namespace)::ErrorErrorCategory: error: undefined reference to 'std::_V2::error_category::_M_message(int) const'
bazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/llvm/_objs/Support/Error.o:Error.cpp:vtable for (anonymous namespace)::ErrorErrorCategory: error: undefined reference to 'std::_V2::error_category::default_error_condition(int) const'
bazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/llvm/_objs/Support/Error.o:Error.cpp:vtable for (anonymous namespace)::ErrorErrorCategory: error: undefined reference to 'std::_V2::error_category::equivalent(int, std::error_condition const&) const'
bazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/llvm/_objs/Support/Error.o:Error.cpp:vtable for (anonymous namespace)::ErrorErrorCategory: error: undefined reference to 'std::_V2::error_category::equivalent(std::error_code const&, int) const'
bazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/llvm/_objs/Support/raw_ostream.o:raw_ostream.cpp:function llvm::raw_fd_ostream::write_impl(char const*, unsigned long): error: undefined reference to 'std::_V2::generic_category()'
bazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/llvm/_objs/Support/raw_ostream.o:raw_ostream.cpp:function getFD(llvm::StringRef, std::error_code&, llvm::sys::fs::CreationDisposition, llvm::sys::fs::FileAccess, llvm::sys::fs::OpenFlags): error: undefined reference to 'std::_V2::system_category()'
bazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/llvm/_objs/Support/raw_ostream.o:raw_ostream.cpp:function llvm::raw_fd_ostream::seek(unsigned long): error: undefined reference to 'std::_V2::generic_category()'
bazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/llvm/_objs/Support/raw_ostream.o:raw_ostream.cpp:function llvm::raw_fd_stream::raw_fd_stream(llvm::StringRef, std::error_code&): error: undefined reference to 'std::_V2::generic_category()'
bazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/llvm/_objs/Support/StringRef.o:StringRef.cpp:function llvm::APFloat::Storage::~Storage(): error: undefined reference to 'operator delete[](void*, unsigned long)'
bazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/llvm/_objs/Support/StringRef.o:StringRef.cpp:function llvm::APFloat::Storage::~Storage(): error: undefined reference to 'operator delete[](void*, unsigned long)'
bazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/llvm/_objs/Support/StringRef.o:StringRef.cpp:function llvm::APFloat::Storage::~Storage(): error: undefined reference to 'operator delete[](void*, unsigned long)'
bazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/llvm/_objs/Support/StringRef.o:StringRef.cpp:function llvm::APFloat::Storage::~Storage(): error: undefined reference to 'operator delete[](void*, unsigned long)'
bazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/llvm/_objs/Support/StringRef.o:StringRef.cpp:function unsigned int llvm::ComputeEditDistance<char>(llvm::ArrayRef<char>, llvm::ArrayRef<char>, bool, unsigned int): error: undefined reference to '__cxa_throw_bad_array_new_length'
bazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/llvm/_objs/Support/SourceMgr.o:SourceMgr.cpp:function llvm::SMDiagnostic::print(char const*, llvm::raw_ostream&, bool, bool) const: error: undefined reference to 'std::__throw_out_of_range_fmt(char const*, ...)'
collect2: error: ld returned 1 exit status
Target //tensorflow/tools/pip_package:build_pip_package failed to build
INFO: Elapsed time: 24.185s, Critical Path: 15.00s
INFO: 1352 processes: 67 internal, 1285 local.
FAILED: Build did NOT complete successfully
```


### Standlone code to reproduce the issue

```shell
bazel build -c opt  --config=rocm //tensorflow/tools/pip_package:build_pip_package --verbose_failures
```


### Relevant log output

```shell
INFO: Options provided by the client:
  Inherited 'common' options: --isatty=1 --terminal_columns=229
INFO: Reading rc options for 'build' from /home/tensorflow-2.8.0/.bazelrc:
  Inherited 'common' options: --experimental_repo_remote_exec
INFO: Reading rc options for 'build' from /home/tensorflow-2.8.0/.bazelrc:
  'build' options: --define framework_shared_object=true --java_toolchain=@tf_toolchains//toolchains/java:tf_java_toolchain --host_java_toolchain=@tf_toolchains//toolchains/java:tf_java_toolchain --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --enable_platform_specific_config --define=with_xla_support=true --config=short_logs --config=v2 --define=no_aws_support=true --define=no_hdfs_support=true --experimental_cc_shared_library
INFO: Reading rc options for 'build' from /home/tensorflow-2.8.0/.tf_configure.bazelrc:
  'build' options: --action_env PYTHON_BIN_PATH=/usr/bin/python3 --action_env PYTHON_LIB_PATH=/usr/local/python3.7.12/lib/python3.7/site-packages --python_path=/usr/bin/python3 --config=rocm --action_env LD_LIBRARY_PATH=/opt/dtk-22.04/hip/lib:/opt/dtk-22.04/llvm/lib:/opt/dtk-22.04/lib:/opt/dtk-22.04/lib64:/opt/dtk-22.04/hip/lib:/opt/dtk-22.04/llvm/lib:/opt/dtk-22.04/lib:/opt/dtk-22.04/lib64:/opt/rh/devtoolset-7/root/usr/lib64:/opt/rh/devtoolset-7/root/usr/lib:/opt/rh/devtoolset-7/root/usr/lib64/dyninst:/opt/rh/devtoolset-7/root/usr/lib/dyninst:/opt/rh/devtoolset-7/root/usr/lib64:/opt/rh/devtoolset-7/root/usr/lib --action_env ROCM_PATH=/opt/dtk-22.04 --action_env ROCBLAS_TENSILE_LIBPATH=/opt/dtk-22.04/lib/library
INFO: Reading rc options for 'build' from /home/tensorflow-2.8.0/.bazelrc:
  'build' options: --deleted_packages=tensorflow/compiler/mlir/tfrt,tensorflow/compiler/mlir/tfrt/benchmarks,tensorflow/compiler/mlir/tfrt/jit/python_binding,tensorflow/compiler/mlir/tfrt/jit/transforms,tensorflow/compiler/mlir/tfrt/python_tests,tensorflow/compiler/mlir/tfrt/tests,tensorflow/compiler/mlir/tfrt/tests/analysis,tensorflow/compiler/mlir/tfrt/tests/jit,tensorflow/compiler/mlir/tfrt/tests/lhlo_to_tfrt,tensorflow/compiler/mlir/tfrt/tests/tf_to_corert,tensorflow/compiler/mlir/tfrt/tests/tf_to_tfrt_data,tensorflow/compiler/mlir/tfrt/tests/saved_model,tensorflow/compiler/mlir/tfrt/transforms/lhlo_gpu_to_tfrt_gpu,tensorflow/core/runtime_fallback,tensorflow/core/runtime_fallback/conversion,tensorflow/core/runtime_fallback/kernel,tensorflow/core/runtime_fallback/opdefs,tensorflow/core/runtime_fallback/runtime,tensorflow/core/runtime_fallback/util,tensorflow/core/tfrt/common,tensorflow/core/tfrt/eager,tensorflow/core/tfrt/eager/backends/cpu,tensorflow/core/tfrt/eager/backends/gpu,tensorflow/core/tfrt/eager/core_runtime,tensorflow/core/tfrt/eager/cpp_tests/core_runtime,tensorflow/core/tfrt/fallback,tensorflow/core/tfrt/gpu,tensorflow/core/tfrt/run_handler_thread_pool,tensorflow/core/tfrt/runtime,tensorflow/core/tfrt/saved_model,tensorflow/core/tfrt/saved_model/tests,tensorflow/core/tfrt/tpu,tensorflow/core/tfrt/utils
INFO: Found applicable config definition build:short_logs in file /home/tensorflow-2.8.0/.bazelrc: --output_filter=DONT_MATCH_ANYTHING
INFO: Found applicable config definition build:v2 in file /home/tensorflow-2.8.0/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1
INFO: Found applicable config definition build:rocm in file /home/tensorflow-2.8.0/.bazelrc: --crosstool_top=@local_config_rocm//crosstool:toolchain --define=using_rocm_hipcc=true --repo_env TF_NEED_ROCM=1
INFO: Found applicable config definition build:rocm in file /home/tensorflow-2.8.0/.bazelrc: --crosstool_top=@local_config_rocm//crosstool:toolchain --define=using_rocm_hipcc=true --repo_env TF_NEED_ROCM=1
INFO: Found applicable config definition build:linux in file /home/tensorflow-2.8.0/.bazelrc: --copt=-w --host_copt=-w --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --define=PROTOBUF_INCLUDE_PATH=$(PREFIX)/include --cxxopt=-std=c++14 --host_cxxopt=-std=c++14 --config=dynamic_kernels --distinct_host_configuration=false --experimental_guard_against_concurrent_changes
INFO: Found applicable config definition build:dynamic_kernels in file /home/tensorflow-2.8.0/.bazelrc: --define=dynamic_loaded_kernels=true --copt=-DAUTOLOAD_DYNAMIC_KERNELS
INFO: Analyzed target //tensorflow/tools/pip_package:build_pip_package (0 packages loaded, 0 targets configured).
INFO: Found 1 target...
ERROR: /root/.cache/bazel/_bazel_root/7e60a61be90f35a88e89e062446eed75/external/llvm-project/mlir/BUILD.bazel:5763:10: Linking external/llvm-project/mlir/mlir-tblgen failed: (Exit 1): crosstool_wrapper_driver_is_not_gcc failed: error executing command
  (cd /root/.cache/bazel/_bazel_root/7e60a61be90f35a88e89e062446eed75/execroot/org_tensorflow && \
  exec env - \
    LD_LIBRARY_PATH=/opt/dtk-22.04/hip/lib:/opt/dtk-22.04/llvm/lib:/opt/dtk-22.04/lib:/opt/dtk-22.04/lib64:/opt/dtk-22.04/hip/lib:/opt/dtk-22.04/llvm/lib:/opt/dtk-22.04/lib:/opt/dtk-22.04/lib64:/opt/rh/devtoolset-7/root/usr/lib64:/opt/rh/devtoolset-7/root/usr/lib:/opt/rh/devtoolset-7/root/usr/lib64/dyninst:/opt/rh/devtoolset-7/root/usr/lib/dyninst:/opt/rh/devtoolset-7/root/usr/lib64:/opt/rh/devtoolset-7/root/usr/lib \
    PATH=/opt/dtk-22.04/bin:/opt/dtk-22.04/llvm/bin:/opt/dtk-22.04/hip/bin:/opt/dtk-22.04/bin:/opt/dtk-22.04/llvm/bin:/opt/dtk-22.04/hip/bin:/home/tensorflow-2.8.0/Depend/bin:/home/tensorflow/Depend/bin:/opt/git-2.30.0/bin:/opt/cmake-3.19.3-Linux-x86_64/bin:/opt/rh/devtoolset-7/root/usr/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \
    PWD=/proc/self/cwd \
  external/local_config_rocm/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc @bazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/mlir/mlir-tblgen-2.params)
Execution platform: @local_execution_config_platform//:platform
bazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/mlir/_objs/mlir-tblgen/AttrOrTypeDefGen.o:AttrOrTypeDefGen.cpp:function llvm::detail::provider_format_adapter<llvm::StringRef&>::~provider_format_adapter(): error: undefined reference to 'operator delete(void*, unsigned long)'
bazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/mlir/_objs/mlir-tblgen/AttrOrTypeDefGen.o:AttrOrTypeDefGen.cpp:function llvm::detail::provider_format_adapter<llvm::StringRef>::~provider_format_adapter(): error: undefined reference to 'operator delete(void*, unsigned long)'
bazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/mlir/_objs/mlir-tblgen/AttrOrTypeDefGen.o:AttrOrTypeDefGen.cpp:function llvm::detail::provider_format_adapter<char const*>::~provider_format_adapter(): error: undefined reference to 'operator delete(void*, unsigned long)'
bazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/mlir/_objs/mlir-tblgen/AttrOrTypeDefGen.o:AttrOrTypeDefGen.cpp:function llvm::detail::provider_format_adapter<std::string&>::~provider_format_adapter(): error: undefined reference to 'operator delete(void*, unsigned long)'
bazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/llvm/_objs/TableGen/Main.o:Main.cpp:function llvm::TableGenMain(char const*, bool (*)(llvm::raw_ostream&, llvm::RecordKeeper&)): error: undefined reference to 'std::_V2::system_category()'
bazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/llvm/_objs/TableGen/Main.o:Main.cpp:function llvm::TableGenMain(char const*, bool (*)(llvm::raw_ostream&, llvm::RecordKeeper&)): error: undefined reference to 'std::_V2::system_category()'
bazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/llvm/_objs/Support/CommandLine.o:CommandLine.cpp:function ExpandResponseFile(llvm::StringRef, llvm::StringSaver&, void (*)(llvm::StringRef, llvm::StringSaver&, llvm::SmallVectorImpl<char const*>&, bool), llvm::SmallVectorImpl<char const*>&, bool, bool, llvm::vfs::FileSystem&): error: undefined reference to 'std::_V2::generic_category()'
bazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/llvm/_objs/Support/ConvertUTFWrapper.o:ConvertUTFWrapper.cpp:function llvm::convertUTF16ToUTF8String(llvm::ArrayRef<char>, std::string&): error: undefined reference to 'std::__throw_out_of_range_fmt(char const*, ...)'
bazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/llvm/_objs/Support/Error.o:Error.cpp:function (anonymous namespace)::ErrorErrorCategory::~ErrorErrorCategory(): error: undefined reference to 'std::_V2::error_category::~error_category()'
bazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/llvm/_objs/Support/Error.o:Error.cpp:function (anonymous namespace)::ErrorErrorCategory::~ErrorErrorCategory(): error: undefined reference to 'std::_V2::error_category::~error_category()'
bazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/llvm/_objs/Support/Error.o:Error.cpp:function llvm::object_deleter<(anonymous namespace)::ErrorErrorCategory>::call(void*): error: undefined reference to 'std::_V2::error_category::~error_category()'
bazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/llvm/_objs/Support/Error.o:Error.cpp:function llvm::errorToErrorCode(llvm::Error): error: undefined reference to 'std::_V2::system_category()'
bazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/llvm/_objs/Support/Error.o:Error.cpp:typeinfo for (anonymous namespace)::ErrorErrorCategory: error: undefined reference to 'typeinfo for std::_V2::error_category'
bazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/llvm/_objs/Support/Error.o:Error.cpp:vtable for (anonymous namespace)::ErrorErrorCategory: error: undefined reference to 'std::_V2::error_category::_M_message(int) const'
bazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/llvm/_objs/Support/Error.o:Error.cpp:vtable for (anonymous namespace)::ErrorErrorCategory: error: undefined reference to 'std::_V2::error_category::default_error_condition(int) const'
bazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/llvm/_objs/Support/Error.o:Error.cpp:vtable for (anonymous namespace)::ErrorErrorCategory: error: undefined reference to 'std::_V2::error_category::equivalent(int, std::error_condition const&) const'
bazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/llvm/_objs/Support/Error.o:Error.cpp:vtable for (anonymous namespace)::ErrorErrorCategory: error: undefined reference to 'std::_V2::error_category::equivalent(std::error_code const&, int) const'
bazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/llvm/_objs/Support/raw_ostream.o:raw_ostream.cpp:function llvm::raw_fd_ostream::write_impl(char const*, unsigned long): error: undefined reference to 'std::_V2::generic_category()'
bazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/llvm/_objs/Support/raw_ostream.o:raw_ostream.cpp:function getFD(llvm::StringRef, std::error_code&, llvm::sys::fs::CreationDisposition, llvm::sys::fs::FileAccess, llvm::sys::fs::OpenFlags): error: undefined reference to 'std::_V2::system_category()'
bazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/llvm/_objs/Support/raw_ostream.o:raw_ostream.cpp:function llvm::raw_fd_ostream::seek(unsigned long): error: undefined reference to 'std::_V2::generic_category()'
bazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/llvm/_objs/Support/raw_ostream.o:raw_ostream.cpp:function llvm::raw_fd_stream::raw_fd_stream(llvm::StringRef, std::error_code&): error: undefined reference to 'std::_V2::generic_category()'
bazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/llvm/_objs/Support/StringRef.o:StringRef.cpp:function llvm::APFloat::Storage::~Storage(): error: undefined reference to 'operator delete[](void*, unsigned long)'
bazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/llvm/_objs/Support/StringRef.o:StringRef.cpp:function llvm::APFloat::Storage::~Storage(): error: undefined reference to 'operator delete[](void*, unsigned long)'
bazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/llvm/_objs/Support/StringRef.o:StringRef.cpp:function llvm::APFloat::Storage::~Storage(): error: undefined reference to 'operator delete[](void*, unsigned long)'
bazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/llvm/_objs/Support/StringRef.o:StringRef.cpp:function llvm::APFloat::Storage::~Storage(): error: undefined reference to 'operator delete[](void*, unsigned long)'
bazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/llvm/_objs/Support/StringRef.o:StringRef.cpp:function unsigned int llvm::ComputeEditDistance<char>(llvm::ArrayRef<char>, llvm::ArrayRef<char>, bool, unsigned int): error: undefined reference to '__cxa_throw_bad_array_new_length'
bazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/llvm/_objs/Support/SourceMgr.o:SourceMgr.cpp:function llvm::SMDiagnostic::print(char const*, llvm::raw_ostream&, bool, bool) const: error: undefined reference to 'std::__throw_out_of_range_fmt(char const*, ...)'
collect2: error: ld returned 1 exit status
Target //tensorflow/tools/pip_package:build_pip_package failed to build
INFO: Elapsed time: 24.185s, Critical Path: 15.00s
INFO: 1352 processes: 67 internal, 1285 local.
FAILED: Build did NOT complete successfully
```
</details>"
55660,Post-training quantization for efficientnet_lite give bad accuracy ,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Performance

### Source

source

### Tensorflow Version

tf 2.8

### Custom Code

No

### OS Platform and Distribution

ubntu 18.04

### Mobile device

None

### Python version

3.8.10

### Bazel version

None

### GCC/Compiler version

None

### CUDA/cuDNN version

None

### GPU model and memory

None

### Current Behaviour?

```shell
Thank for your image classification model [maker](https://www.tensorflow.org/lite/tutorials/model_maker_image_classification). By follow your tutorial, i create a training script with a purpose to use efficientnet-lite as our classifier.

However, after export tflite model (efficientnet_lite2). Without quantization, out model get high accuracy (99.4% on my test dataset), very low speed (1.3748071193695068/image).
So i decide to use quantization to get better speed. 
But the accuray is really bad. 



### Relevant log output

```shell
Model: ""sequential""
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
hub_keras_layer_v1v2 (HubKer (None, 1280)              4869168   
_________________________________________________________________
dropout (Dropout)            (None, 1280)              0         
_________________________________________________________________
dense (Dense)                (None, 2)                 2562      
=================================================================
Total params: 4,871,730
Trainable params: 2,562
Non-trainable params: 4,869,168
_________________________________________________________________
None
/usr/local/lib/python3.8/dist-packages/keras/optimizer_v2/optimizer_v2.py:355: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.
  warnings.warn(
Epoch 1/5
2022-04-19 03:05:06.677678: I tensorflow/stream_executor/cuda/cuda_dnn.cc:381] Loaded cuDNN version 8204
455/455 [==============================] - 204s 442ms/step - loss: 0.2681 - accuracy: 0.9708 - val_loss: 0.2391 - val_accuracy: 0.9897
Epoch 2/5
455/455 [==============================] - 202s 441ms/step - loss: 0.2428 - accuracy: 0.9881 - val_loss: 0.2343 - val_accuracy: 0.9930
Epoch 3/5
455/455 [==============================] - 203s 443ms/step - loss: 0.2396 - accuracy: 0.9901 - val_loss: 0.2320 - val_accuracy: 0.9933
Epoch 4/5
455/455 [==============================] - 203s 445ms/step - loss: 0.2373 - accuracy: 0.9909 - val_loss: 0.2308 - val_accuracy: 0.9941
Epoch 5/5
455/455 [==============================] - 202s 442ms/step - loss: 0.2365 - accuracy: 0.9913 - val_loss: 0.2301 - val_accuracy: 0.9940
Model: ""sequential""
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
hub_keras_layer_v1v2 (HubKer (None, 1280)              4869168   
_________________________________________________________________
dropout (Dropout)            (None, 1280)              0         
_________________________________________________________________
dense (Dense)                (None, 2)                 2562      
=================================================================
Total params: 4,871,730
Trainable params: 2,562
Non-trainable params: 4,869,168
_________________________________________________________________
228/228 [==============================] - 33s 54ms/step - loss: 0.2290 - accuracy: 0.9951
############### FOR FP32 MODEL
2022-04-19 03:22:31.386912: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
2022-04-19 03:22:33.971451: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-04-19 03:22:33.972101: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1
2022-04-19 03:22:33.972400: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session
2022-04-19 03:22:33.973941: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-04-19 03:22:33.974352: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-04-19 03:22:33.974627: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-04-19 03:22:33.976490: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-04-19 03:22:33.976763: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-04-19 03:22:33.977095: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 8938 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:2d:00.0, compute capability: 7.5
2022-04-19 03:22:34.005010: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1164] Optimization results for grappler item: graph_to_optimize
  function_optimizer: Graph size after: 1188 nodes (856), 1203 edges (869), time = 13.073ms.
  function_optimizer: function_optimizer did nothing. time = 0.225ms.

2022-04-19 03:22:34.653218: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:351] Ignored output_format.
2022-04-19 03:22:34.653265: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:354] Ignored drop_control_dependency.
2022-04-19 03:22:34.711780: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:210] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
fully_quantize: 0, inference_type: 6, input_inference_type: 3, output_inference_type: 3
WARNING:absl:For model inputs containing unsupported operations which cannot be quantized, the `inference_input_type` attribute will default to the original type.
############### FOR FP16 MODEL
2022-04-19 03:32:07.372624: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-04-19 03:32:07.372880: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1
2022-04-19 03:32:07.372951: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session
2022-04-19 03:32:07.373226: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-04-19 03:32:07.373494: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-04-19 03:32:07.373724: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-04-19 03:32:07.373987: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-04-19 03:32:07.374212: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1050] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-04-19 03:32:07.374402: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 8938 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 Ti, pci bus id: 0000:2d:00.0, compute capability: 7.5
2022-04-19 03:32:07.397998: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1164] Optimization results for grappler item: graph_to_optimize
  function_optimizer: Graph size after: 1188 nodes (856), 1203 edges (869), time = 12.634ms.
  function_optimizer: function_optimizer did nothing. time = 0.21ms.

2022-04-19 03:32:08.278801: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:351] Ignored output_format.
2022-04-19 03:32:08.278847: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:354] Ignored drop_control_dependency.
```
</details>"
55659,The callbacks in the training functions in kernels_experimental.cc unnecessarily transfer ownership of the tensors to the caller,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

binary

### Tensorflow Version

tf 2.9

### Custom Code

No

### OS Platform and Distribution

Linux Ubuntu 16.04

### Mobile device

_No response_

### Python version

3.9

### Bazel version

5.1.0

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

Currently, the callbacks in the `kernels_experimental.cc` file transfer ownership of the tensors to the caller. Although we explain this behavior in the header, this is not intuitive because the tensors don't need to outlive the callback. A better solution would be to automatically free the tensors as soon as the callback returns, thus avoiding instances where callers could mistakenly omit to free the memory themselves.


### Standlone code to reproduce the issue

```c++
void callback(TF_OpKernelContext* ctx, TF_Tensor* source, TF_Tensor* dest) {
  // We are not releasing the memory for `source` and `dest, so memory leak occurs
}

TF_AssignVariable(ctx, 0, 1, callback, status);
```


### Relevant log output

_No response_</details>"
55658,Got this BUG while attempting to save the model,"

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04.5 LTS
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: 
- TensorFlow installed from (source or binary): I don't know, I ran on a cloud server that I rent
- TensorFlow version (use command below): 2.4.1
- Python version: 3.8
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source): 
- CUDA/cuDNN version: 11.1.1
- GPU model and memory: GeForce RTX 3090, 23G

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

> root@625d1712cc5660deb2f669c7:~# python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""
> 2022-04-18 21:15:44.795209: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
> v2.4.0-49-g85c8b2a817f 2.4.1


**Describe the current behavior**
A checkpoint model is supposed to be saved at the 100st iteration, while attempting to save it, this BUG occurred and is shown under **Other info / logs**, and then the process stopped.

**Describe the expected behavior**
After successfully saving the checkpoint model at the 100st iteration, the process should go on training normaly.

**[Contributing](https://www.tensorflow.org/community/contribute)**

- Do you want to contribute a PR? (yes/no): not sure what a PR is
- Briefly describe your candidate solution(if contributing):

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.
https://drive.google.com/drive/folders/1fKO0aQmXu1KSNBeny_HWt8SiAtvZ4D_b?usp=sharing

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

> [libprotobuf ERROR google/protobuf/wire_format_lite.cc:577] String field 'tensorflow.TensorShapeProto.Dim.name' contains invalid UTF-8 data when parsing a protocol buffer. Use the 'bytes' type if you intend to send raw bytes. 
> Traceback (most recent call last):
>   File ""train.py"", line 77, in <module>
>     train(model)
>   File ""train.py"", line 24, in train
>     model.optimize()
>   File ""/user-data/HyperBox-main/script/model/box_model.py"", line 329, in optimize
>     self.save_model(itr)
>   File ""/user-data/HyperBox-main/script/model/box_model.py"", line 140, in save_model
>     self.saver.save(self.sess, filename)
>   File ""/opt/conda/lib/python3.8/site-packages/tensorflow/python/training/saver.py"", line 1208, in save
>     self.export_meta_graph(
>   File ""/opt/conda/lib/python3.8/site-packages/tensorflow/python/training/saver.py"", line 1254, in export_meta_graph
>     graph_def=ops.get_default_graph().as_graph_def(add_shapes=True),
>   File ""/opt/conda/lib/python3.8/site-packages/tensorflow/python/framework/ops.py"", line 3345, in as_graph_def
>     result, _ = self._as_graph_def(from_version, add_shapes)
>   File ""/opt/conda/lib/python3.8/site-packages/tensorflow/python/framework/ops.py"", line 3262, in _as_graph_def
>     graph.ParseFromString(compat.as_bytes(data))
> google.protobuf.message.DecodeError: Error parsing message
> "
55656,test,"<details><summary>Click to expand!</summary> 
 
 ### Issue Type

Bug

### Source

source

### Tensorflow Version

2.6

### Custom Code

Yes

### OS Platform and Distribution

_No response_

### Mobile device

_No response_

### Python version

_No response_

### Bazel version

_No response_

### GCC/Compiler version

_No response_

### CUDA/cuDNN version

_No response_

### GPU model and memory

_No response_

### Current Behaviour?

```shell
A bug happened!
```


### Standlone code to reproduce the issue

```shell
test
```


### Relevant log output

_No response_</details>"
55654,Google Colab ValueError: faster_rcnn_inception_v2 is not supported for tf version 2. See `model_builder.py` for features extractors compatible with different versions of Tensorflow,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Google Colab (Default)
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): Google Colab (Default)
- TensorFlow version: 2.8.0
- Python version: 3.7.13
- Installed using virtualenv? pip? conda?: Google Colab (so pip)
- Bazel version (if compiling from source):  Google Colab (Default)
- GCC/Compiler version (if compiling from source):  (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
- CUDA/cuDNN version:  V11.1.105
- GPU model and memory:  Google Colab (Default)

**Describe the problem**
Don't know why faster_rcnn_inception_v2 is not supported checked the `model_builder_tf2_test.py` inside builder, can't seem to figure out what is wronf

Ran the blocks one after other

```
from google.colab import drive
drive.mount('/content/drive/')
```

```
import os 
os.chdir(""/content/drive/MyDrive/Tensorflow/models/research"")
```

```
!protoc object_detection/protos/*.proto --python_out=.
```

```
import pycocotools
```

```
!cp /content/drive/MyDrive/Tensorflow/models/research/object_detection/packages/tf2/setup.py .
!python -m pip install .
```
> Output
```
Processing /content/drive/MyDrive/Tensorflow/models/research
  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.
   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.
...
Successfully built object-detection
Installing collected packages: requests, cloudpickle, object-detection
  Attempting uninstall: requests
    Found existing installation: requests 2.23.0
    Uninstalling requests-2.23.0:
      Successfully uninstalled requests-2.23.0
  Attempting uninstall: cloudpickle
    Found existing installation: cloudpickle 1.6.0
    Uninstalling cloudpickle-1.6.0:
      Successfully uninstalled cloudpickle-1.6.0
  Attempting uninstall: object-detection
    Found existing installation: object-detection 0.1
    Uninstalling object-detection-0.1:
      Successfully uninstalled object-detection-0.1
ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.
gym 0.17.3 requires cloudpickle<1.7.0,>=1.2.0, but you have cloudpickle 2.0.0 which is incompatible.
google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.27.1 which is incompatible.
Successfully installed cloudpickle-2.0.0 object-detection-0.1 requests-2.27.1
```


```
!python /content/drive/MyDrive/Tensorflow/models/research/object_detection/builders/model_builder_tf2_test.py
```
> Ouput
```
Running tests under Python 3.7.13: /usr/bin/python3
[ RUN      ] ModelBuilderTF2Test.test_create_center_net_deepmac
2022-04-18 17:22:34.522498: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
W0418 17:22:34.835057 140651717425024 model_builder.py:1102] Building experimental DeepMAC meta-arch. Some features may be omitted.
INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 1.37s
I0418 17:22:35.309757 140651717425024 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 1.37s
[       OK ] ModelBuilderTF2Test.test_create_center_net_deepmac
[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)
INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.7s
I0418 17:22:36.007474 140651717425024 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.7s
[       OK ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)
[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)
INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.35s
I0418 17:22:36.355132 140651717425024 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.35s
[       OK ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)
[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints
INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.32s
I0418 17:22:36.673634 140651717425024 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.32s
[       OK ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints
[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet
INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 2.25s
I0418 17:22:38.921587 140651717425024 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 2.25s
[       OK ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet
[ RUN      ] ModelBuilderTF2Test.test_create_experimental_model
INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s
I0418 17:22:38.922625 140651717425024 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s
[       OK ] ModelBuilderTF2Test.test_create_experimental_model
[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)
INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.03s
I0418 17:22:38.949134 140651717425024 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.03s
[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)
[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)
INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.02s
I0418 17:22:38.972606 140651717425024 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.02s
[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)
[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner
INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.02s
I0418 17:22:38.995841 140651717425024 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.02s
[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner
[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul
INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.12s
I0418 17:22:39.120243 140651717425024 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.12s
[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul
[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul
INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.12s
I0418 17:22:39.241493 140651717425024 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.12s
[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul
[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul
INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.13s
I0418 17:22:39.367335 140651717425024 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.13s
[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul
[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul
INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.13s
I0418 17:22:39.499283 140651717425024 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.13s
[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul
[ RUN      ] ModelBuilderTF2Test.test_create_rfcn_model_from_config
INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.12s
I0418 17:22:39.622432 140651717425024 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.12s
[       OK ] ModelBuilderTF2Test.test_create_rfcn_model_from_config
[ RUN      ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config
INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.03s
I0418 17:22:39.655929 140651717425024 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.03s
[       OK ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config
[ RUN      ] ModelBuilderTF2Test.test_create_ssd_models_from_config
I0418 17:22:39.881075 140651717425024 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b0
I0418 17:22:39.881299 140651717425024 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 64
I0418 17:22:39.881403 140651717425024 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 3
I0418 17:22:39.884063 140651717425024 efficientnet_model.py:144] round_filter input=32 output=32
I0418 17:22:39.909026 140651717425024 efficientnet_model.py:144] round_filter input=32 output=32
I0418 17:22:39.909201 140651717425024 efficientnet_model.py:144] round_filter input=16 output=16
I0418 17:22:39.982957 140651717425024 efficientnet_model.py:144] round_filter input=16 output=16
I0418 17:22:39.983191 140651717425024 efficientnet_model.py:144] round_filter input=24 output=24
I0418 17:22:40.185760 140651717425024 efficientnet_model.py:144] round_filter input=24 output=24
I0418 17:22:40.185985 140651717425024 efficientnet_model.py:144] round_filter input=40 output=40
I0418 17:22:40.383517 140651717425024 efficientnet_model.py:144] round_filter input=40 output=40
I0418 17:22:40.383721 140651717425024 efficientnet_model.py:144] round_filter input=80 output=80
I0418 17:22:40.676204 140651717425024 efficientnet_model.py:144] round_filter input=80 output=80
I0418 17:22:40.676435 140651717425024 efficientnet_model.py:144] round_filter input=112 output=112
I0418 17:22:40.967956 140651717425024 efficientnet_model.py:144] round_filter input=112 output=112
I0418 17:22:40.968163 140651717425024 efficientnet_model.py:144] round_filter input=192 output=192
I0418 17:22:41.539747 140651717425024 efficientnet_model.py:144] round_filter input=192 output=192
I0418 17:22:41.539965 140651717425024 efficientnet_model.py:144] round_filter input=320 output=320
I0418 17:22:41.629632 140651717425024 efficientnet_model.py:144] round_filter input=1280 output=1280
I0418 17:22:41.666049 140651717425024 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')
I0418 17:22:41.727125 140651717425024 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b1
I0418 17:22:41.727278 140651717425024 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 88
I0418 17:22:41.727388 140651717425024 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 4
I0418 17:22:41.729334 140651717425024 efficientnet_model.py:144] round_filter input=32 output=32
I0418 17:22:41.748022 140651717425024 efficientnet_model.py:144] round_filter input=32 output=32
I0418 17:22:41.748164 140651717425024 efficientnet_model.py:144] round_filter input=16 output=16
I0418 17:22:41.909050 140651717425024 efficientnet_model.py:144] round_filter input=16 output=16
I0418 17:22:41.909280 140651717425024 efficientnet_model.py:144] round_filter input=24 output=24
I0418 17:22:42.199975 140651717425024 efficientnet_model.py:144] round_filter input=24 output=24
I0418 17:22:42.200182 140651717425024 efficientnet_model.py:144] round_filter input=40 output=40
I0418 17:22:42.490325 140651717425024 efficientnet_model.py:144] round_filter input=40 output=40
I0418 17:22:42.490564 140651717425024 efficientnet_model.py:144] round_filter input=80 output=80
I0418 17:22:42.882098 140651717425024 efficientnet_model.py:144] round_filter input=80 output=80
I0418 17:22:42.882309 140651717425024 efficientnet_model.py:144] round_filter input=112 output=112
I0418 17:22:43.272372 140651717425024 efficientnet_model.py:144] round_filter input=112 output=112
I0418 17:22:43.272558 140651717425024 efficientnet_model.py:144] round_filter input=192 output=192
I0418 17:22:43.749095 140651717425024 efficientnet_model.py:144] round_filter input=192 output=192
I0418 17:22:43.749329 140651717425024 efficientnet_model.py:144] round_filter input=320 output=320
I0418 17:22:43.950352 140651717425024 efficientnet_model.py:144] round_filter input=1280 output=1280
I0418 17:22:43.988394 140651717425024 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')
I0418 17:22:44.066077 140651717425024 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b2
I0418 17:22:44.066259 140651717425024 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 112
I0418 17:22:44.066420 140651717425024 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 5
I0418 17:22:44.068452 140651717425024 efficientnet_model.py:144] round_filter input=32 output=32
I0418 17:22:44.097079 140651717425024 efficientnet_model.py:144] round_filter input=32 output=32
I0418 17:22:44.097218 140651717425024 efficientnet_model.py:144] round_filter input=16 output=16
I0418 17:22:44.254661 140651717425024 efficientnet_model.py:144] round_filter input=16 output=16
I0418 17:22:44.254885 140651717425024 efficientnet_model.py:144] round_filter input=24 output=24
I0418 17:22:44.559297 140651717425024 efficientnet_model.py:144] round_filter input=24 output=24
I0418 17:22:44.559684 140651717425024 efficientnet_model.py:144] round_filter input=40 output=48
I0418 17:22:44.873531 140651717425024 efficientnet_model.py:144] round_filter input=40 output=48
I0418 17:22:44.873750 140651717425024 efficientnet_model.py:144] round_filter input=80 output=88
I0418 17:22:45.300951 140651717425024 efficientnet_model.py:144] round_filter input=80 output=88
I0418 17:22:45.301170 140651717425024 efficientnet_model.py:144] round_filter input=112 output=120
I0418 17:22:45.704520 140651717425024 efficientnet_model.py:144] round_filter input=112 output=120
I0418 17:22:45.704799 140651717425024 efficientnet_model.py:144] round_filter input=192 output=208
I0418 17:22:46.203318 140651717425024 efficientnet_model.py:144] round_filter input=192 output=208
I0418 17:22:46.203543 140651717425024 efficientnet_model.py:144] round_filter input=320 output=352
I0418 17:22:46.401460 140651717425024 efficientnet_model.py:144] round_filter input=1280 output=1408
I0418 17:22:46.447006 140651717425024 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.1, depth_coefficient=1.2, resolution=260, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')
I0418 17:22:46.522991 140651717425024 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b3
I0418 17:22:46.523183 140651717425024 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 160
I0418 17:22:46.523305 140651717425024 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 6
I0418 17:22:46.525346 140651717425024 efficientnet_model.py:144] round_filter input=32 output=40
I0418 17:22:46.545359 140651717425024 efficientnet_model.py:144] round_filter input=32 output=40
I0418 17:22:46.545502 140651717425024 efficientnet_model.py:144] round_filter input=16 output=24
I0418 17:22:46.945021 140651717425024 efficientnet_model.py:144] round_filter input=16 output=24
I0418 17:22:46.945224 140651717425024 efficientnet_model.py:144] round_filter input=24 output=32
I0418 17:22:47.246878 140651717425024 efficientnet_model.py:144] round_filter input=24 output=32
I0418 17:22:47.247097 140651717425024 efficientnet_model.py:144] round_filter input=40 output=48
I0418 17:22:47.545889 140651717425024 efficientnet_model.py:144] round_filter input=40 output=48
I0418 17:22:47.546088 140651717425024 efficientnet_model.py:144] round_filter input=80 output=96
I0418 17:22:48.029253 140651717425024 efficientnet_model.py:144] round_filter input=80 output=96
I0418 17:22:48.029495 140651717425024 efficientnet_model.py:144] round_filter input=112 output=136
I0418 17:22:48.550718 140651717425024 efficientnet_model.py:144] round_filter input=112 output=136
I0418 17:22:48.550914 140651717425024 efficientnet_model.py:144] round_filter input=192 output=232
I0418 17:22:49.137728 140651717425024 efficientnet_model.py:144] round_filter input=192 output=232
I0418 17:22:49.137917 140651717425024 efficientnet_model.py:144] round_filter input=320 output=384
I0418 17:22:49.339728 140651717425024 efficientnet_model.py:144] round_filter input=1280 output=1536
I0418 17:22:49.376200 140651717425024 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.2, depth_coefficient=1.4, resolution=300, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')
I0418 17:22:49.457432 140651717425024 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b4
I0418 17:22:49.457614 140651717425024 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 224
I0418 17:22:49.457733 140651717425024 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 7
I0418 17:22:49.459825 140651717425024 efficientnet_model.py:144] round_filter input=32 output=48
I0418 17:22:49.480137 140651717425024 efficientnet_model.py:144] round_filter input=32 output=48
I0418 17:22:49.480267 140651717425024 efficientnet_model.py:144] round_filter input=16 output=24
I0418 17:22:49.626461 140651717425024 efficientnet_model.py:144] round_filter input=16 output=24
I0418 17:22:49.626665 140651717425024 efficientnet_model.py:144] round_filter input=24 output=32
I0418 17:22:50.004109 140651717425024 efficientnet_model.py:144] round_filter input=24 output=32
I0418 17:22:50.004311 140651717425024 efficientnet_model.py:144] round_filter input=40 output=56
I0418 17:22:50.396405 140651717425024 efficientnet_model.py:144] round_filter input=40 output=56
I0418 17:22:50.396666 140651717425024 efficientnet_model.py:144] round_filter input=80 output=112
I0418 17:22:51.007864 140651717425024 efficientnet_model.py:144] round_filter input=80 output=112
I0418 17:22:51.008074 140651717425024 efficientnet_model.py:144] round_filter input=112 output=160
I0418 17:22:51.602847 140651717425024 efficientnet_model.py:144] round_filter input=112 output=160
I0418 17:22:51.603067 140651717425024 efficientnet_model.py:144] round_filter input=192 output=272
I0418 17:22:52.382356 140651717425024 efficientnet_model.py:144] round_filter input=192 output=272
I0418 17:22:52.382547 140651717425024 efficientnet_model.py:144] round_filter input=320 output=448
I0418 17:22:52.584087 140651717425024 efficientnet_model.py:144] round_filter input=1280 output=1792
I0418 17:22:52.621994 140651717425024 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.4, depth_coefficient=1.8, resolution=380, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')
I0418 17:22:52.946643 140651717425024 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b5
I0418 17:22:52.946854 140651717425024 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 288
I0418 17:22:52.946960 140651717425024 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 7
I0418 17:22:52.949278 140651717425024 efficientnet_model.py:144] round_filter input=32 output=48
I0418 17:22:52.968531 140651717425024 efficientnet_model.py:144] round_filter input=32 output=48
I0418 17:22:52.968678 140651717425024 efficientnet_model.py:144] round_filter input=16 output=24
I0418 17:22:53.208381 140651717425024 efficientnet_model.py:144] round_filter input=16 output=24
I0418 17:22:53.208580 140651717425024 efficientnet_model.py:144] round_filter input=24 output=40
I0418 17:22:53.705475 140651717425024 efficientnet_model.py:144] round_filter input=24 output=40
I0418 17:22:53.705704 140651717425024 efficientnet_model.py:144] round_filter input=40 output=64
I0418 17:22:54.200186 140651717425024 efficientnet_model.py:144] round_filter input=40 output=64
I0418 17:22:54.200397 140651717425024 efficientnet_model.py:144] round_filter input=80 output=128
I0418 17:22:54.891355 140651717425024 efficientnet_model.py:144] round_filter input=80 output=128
I0418 17:22:54.891623 140651717425024 efficientnet_model.py:144] round_filter input=112 output=176
I0418 17:22:55.574701 140651717425024 efficientnet_model.py:144] round_filter input=112 output=176
I0418 17:22:55.574891 140651717425024 efficientnet_model.py:144] round_filter input=192 output=304
I0418 17:22:56.476717 140651717425024 efficientnet_model.py:144] round_filter input=192 output=304
I0418 17:22:56.476914 140651717425024 efficientnet_model.py:144] round_filter input=320 output=512
I0418 17:22:56.763684 140651717425024 efficientnet_model.py:144] round_filter input=1280 output=2048
I0418 17:22:56.816832 140651717425024 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.6, depth_coefficient=2.2, resolution=456, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')
I0418 17:22:56.921765 140651717425024 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b6
I0418 17:22:56.921953 140651717425024 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 384
I0418 17:22:56.922078 140651717425024 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 8
I0418 17:22:56.924120 140651717425024 efficientnet_model.py:144] round_filter input=32 output=56
I0418 17:22:56.943723 140651717425024 efficientnet_model.py:144] round_filter input=32 output=56
I0418 17:22:56.943849 140651717425024 efficientnet_model.py:144] round_filter input=16 output=32
I0418 17:22:57.174894 140651717425024 efficientnet_model.py:144] round_filter input=16 output=32
I0418 17:22:57.175107 140651717425024 efficientnet_model.py:144] round_filter input=24 output=40
I0418 17:22:57.765460 140651717425024 efficientnet_model.py:144] round_filter input=24 output=40
I0418 17:22:57.765691 140651717425024 efficientnet_model.py:144] round_filter input=40 output=72
I0418 17:22:58.367207 140651717425024 efficientnet_model.py:144] round_filter input=40 output=72
I0418 17:22:58.367408 140651717425024 efficientnet_model.py:144] round_filter input=80 output=144
I0418 17:22:59.146869 140651717425024 efficientnet_model.py:144] round_filter input=80 output=144
I0418 17:22:59.147065 140651717425024 efficientnet_model.py:144] round_filter input=112 output=200
I0418 17:23:00.243004 140651717425024 efficientnet_model.py:144] round_filter input=112 output=200
I0418 17:23:00.243216 140651717425024 efficientnet_model.py:144] round_filter input=192 output=344
I0418 17:23:01.329543 140651717425024 efficientnet_model.py:144] round_filter input=192 output=344
I0418 17:23:01.329753 140651717425024 efficientnet_model.py:144] round_filter input=320 output=576
I0418 17:23:01.632538 140651717425024 efficientnet_model.py:144] round_filter input=1280 output=2304
I0418 17:23:01.667076 140651717425024 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=1.8, depth_coefficient=2.6, resolution=528, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')
I0418 17:23:01.783803 140651717425024 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet EfficientNet backbone version: efficientnet-b7
I0418 17:23:01.783980 140651717425024 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 384
I0418 17:23:01.784088 140651717425024 ssd_efficientnet_bifpn_feature_extractor.py:149] EfficientDet BiFPN num iterations: 8
I0418 17:23:01.786011 140651717425024 efficientnet_model.py:144] round_filter input=32 output=64
I0418 17:23:01.804804 140651717425024 efficientnet_model.py:144] round_filter input=32 output=64
I0418 17:23:01.804945 140651717425024 efficientnet_model.py:144] round_filter input=16 output=32
I0418 17:23:02.119777 140651717425024 efficientnet_model.py:144] round_filter input=16 output=32
I0418 17:23:02.120019 140651717425024 efficientnet_model.py:144] round_filter input=24 output=48
I0418 17:23:02.801890 140651717425024 efficientnet_model.py:144] round_filter input=24 output=48
I0418 17:23:02.802091 140651717425024 efficientnet_model.py:144] round_filter input=40 output=80
I0418 17:23:03.464561 140651717425024 efficientnet_model.py:144] round_filter input=40 output=80
I0418 17:23:03.464781 140651717425024 efficientnet_model.py:144] round_filter input=80 output=160
I0418 17:23:04.441631 140651717425024 efficientnet_model.py:144] round_filter input=80 output=160
I0418 17:23:04.441842 140651717425024 efficientnet_model.py:144] round_filter input=112 output=224
I0418 17:23:05.429579 140651717425024 efficientnet_model.py:144] round_filter input=112 output=224
I0418 17:23:05.429809 140651717425024 efficientnet_model.py:144] round_filter input=192 output=384
I0418 17:23:06.740693 140651717425024 efficientnet_model.py:144] round_filter input=192 output=384
I0418 17:23:06.740902 140651717425024 efficientnet_model.py:144] round_filter input=320 output=640
I0418 17:23:07.480772 140651717425024 efficientnet_model.py:144] round_filter input=1280 output=2560
I0418 17:23:07.517922 140651717425024 efficientnet_model.py:454] Building model efficientnet with params ModelConfig(width_coefficient=2.0, depth_coefficient=3.1, resolution=600, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')
INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 28.01s
I0418 17:23:07.669898 140651717425024 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 28.01s
[       OK ] ModelBuilderTF2Test.test_create_ssd_models_from_config
[ RUN      ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update
INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s
I0418 17:23:07.677198 140651717425024 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s
[       OK ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update
[ RUN      ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold
INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s
I0418 17:23:07.679375 140651717425024 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s
[       OK ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold
[ RUN      ] ModelBuilderTF2Test.test_invalid_model_config_proto
INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s
I0418 17:23:07.680015 140651717425024 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s
[       OK ] ModelBuilderTF2Test.test_invalid_model_config_proto
[ RUN      ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size
INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s
I0418 17:23:07.681699 140651717425024 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s
[       OK ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size
[ RUN      ] ModelBuilderTF2Test.test_session
[  SKIPPED ] ModelBuilderTF2Test.test_session
[ RUN      ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor
INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s
I0418 17:23:07.683473 140651717425024 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s
[       OK ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor
[ RUN      ] ModelBuilderTF2Test.test_unknown_meta_architecture
INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s
I0418 17:23:07.684104 140651717425024 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s
[       OK ] ModelBuilderTF2Test.test_unknown_meta_architecture
[ RUN      ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor
INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s
I0418 17:23:07.685307 140651717425024 test_util.py:2374] time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s
[       OK ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor
----------------------------------------------------------------------
Ran 24 tests in 33.750s

OK (skipped=1)
```

```
!pip install opencv-python-headless==4.1.2.30
```

```
import tensorflow.compat.v2 as tf
from object_detection import model_lib_v2

tf.config.set_soft_device_placement(True)

model_dir = ""/content/drive/MyDrive/Tensorflow/models/research/faster_rcnn_inception_v2_coco_2018_01_28/model_dir""

config = tf_estimator.RunConfig(model_dir=model_dir)

pipeline_config_path= ""/content/drive/MyDrive/Tensorflow/models/research/faster_rcnn_inception_v2_coco_2018_01_28/pipeline.config""

num_train_steps=100
sample_1_of_n_eval_examples=1
sample_1_of_n_eval_on_train_examples=5
model_lib_v2.eval_continuously(
    pipeline_config_path=pipeline_config_path,
    model_dir=model_dir,
    train_steps=num_train_steps,
    sample_1_of_n_eval_examples=sample_1_of_n_eval_examples,
    sample_1_of_n_eval_on_train_examples=(sample_1_of_n_eval_on_train_examples),
    wait_interval=300, timeout=3600)
```
> Output
```
WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.
[04/18 17:33:47] tensorflow WARNING: Forced number of epochs for all eval validations to be 1.
INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: 1
[04/18 17:33:47] tensorflow INFO: Maybe overwriting sample_1_of_n_eval_examples: 1
INFO:tensorflow:Maybe overwriting use_bfloat16: False
[04/18 17:33:47] tensorflow INFO: Maybe overwriting use_bfloat16: False
INFO:tensorflow:Maybe overwriting train_steps: 100
[04/18 17:33:47] tensorflow INFO: Maybe overwriting train_steps: 100
INFO:tensorflow:Maybe overwriting eval_num_epochs: 1
[04/18 17:33:47] tensorflow INFO: Maybe overwriting eval_num_epochs: 1
WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.
[04/18 17:33:47] tensorflow WARNING: Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
[<ipython-input-24-432f892b36ea>](https://localhost:8080/#) in <module>()
     19     sample_1_of_n_eval_examples=sample_1_of_n_eval_examples,
     20     sample_1_of_n_eval_on_train_examples=(sample_1_of_n_eval_on_train_examples),
---> 21     wait_interval=300, timeout=3600)
     22 

3 frames
[/content/drive/MyDrive/Tensorflow/models/research/object_detection/builders/model_builder.py](https://localhost:8080/#) in _check_feature_extractor_exists(feature_extractor_type)
    268         '{} is not supported for tf version {}. See `model_builder.py` for '
    269         'features extractors compatible with different versions of '
--> 270         'Tensorflow'.format(feature_extractor_type, tf_version_str))
    271 
    272 

ValueError: faster_rcnn_inception_v2 is not supported for tf version 2. See `model_builder.py` for features extractors compatible with different versions of Tensorflow
```"
55652,hlo-legalize-to-linalg is incorrect for mhlo::DotGeneralOp,"The usage of `i` in https://github.com/tensorflow/tensorflow/blob/master/tensorflow/compiler/mlir/hlo/lib/Dialect/mhlo/transforms/legalize_to_linalg.cc#L2945 and https://github.com/tensorflow/tensorflow/blob/master/tensorflow/compiler/mlir/hlo/lib/Dialect/mhlo/transforms/legalize_to_linalg.cc#L2970 is incorrect.  You need another index, say `j` that only increments when `assigned_dims[i]` is false.

Suggested fix
```
      for (int i = 0, j = 0; i < lhs_rank; ++i) {
        if (!assigned_dims[i]) {
          lhs_indices[i] =
              rewriter.getAffineDimExpr(j + lhs_batching_dims.size());
              j++;
        }
      }
```

and similarly for the corresponding loop for RHS map.  Here's a test case

```
func.func @dot_general_2(%arg0: tensor<64x16x128x32xf32>,
                  %arg1: tensor<16x256x32x128xf32>) -> tensor<16x32x64x256xf32> {
  %0 = ""mhlo.dot_general""(%arg0, %arg1) {
    dot_dimension_numbers = #mhlo.dot<
      lhs_batching_dimensions = [1, 3],
      lhs_contracting_dimensions = [2],
      rhs_batching_dimensions = [0, 2],
      rhs_contracting_dimensions = [3]
    >,
    precision_config = [#mhlo<""precision DEFAULT"">, #mhlo<""precision DEFAULT"">],
    someattr
  } : (tensor<64x16x128x32xf32>, tensor<16x256x32x128xf32>) -> tensor<16x32x64x256xf32>
  func.return %0 : tensor<16x32x64x256xf32>
}
// The iterations are (Batch Dim, Batch Dim, LHS Other Dim, RHS Other dim, Contracting Dim)
// CHECK: #[[MAP0:.*]] = affine_map<(d0, d1, d2, d3, d4) -> (d2, d0, d4, d1)>
// CHECK: #[[MAP1:.*]] = affine_map<(d0, d1, d2, d3, d4) -> (d0, d3, d1, d4)>
// Output is the iterators excluding contracting
// CHECK: #[[MAP2:.*]] = affine_map<(d0, d1, d2, d3, d4) -> (d0, d1, d2, d3)>
// CHECK: func @dot_general_2(
// CHECK-SAME: %[[ARG0:.*]]: tensor<64x16x128x32xf32>, %[[ARG1:.*]]: tensor<16x256x32x128xf32>)
// CHECK: %[[INIT:.*]] = linalg.init_tensor [16, 32, 64, 256]
// CHECK: %[[FILL:.*]] = linalg.fill ins(%{{.*}}{{.*}}outs(%[[INIT]]
// CHECK: linalg.generic
// CHECK-SAME: indexing_maps = [#[[MAP0]], #[[MAP1]], #[[MAP2]]]
// Only contracting dims are reductions
// CHECK-SAME: iterator_types = [""parallel"", ""parallel"", ""parallel"", ""parallel"", ""reduction""]
// CHECK-SAME: ins(%[[ARG0]], %[[ARG1]] : tensor<64x16x128x32xf32>, tensor<16x256x32x128xf32>)
// CHECK-SAME: outs(%[[FILL]] : tensor<16x32x64x256xf32>)
// CHECK-SAME: {someattr}
// CHECK:   ^bb0(%[[ARG2:.*]]: f32, %[[ARG3:.*]]: f32, %[[ARG4:.*]]: f32):
// CHECK:     %[[MUL:.*]] = arith.mulf %[[ARG2]], %[[ARG3]] : f32
// CHECK:     %[[SUM:.*]] = arith.addf %[[MUL]], %[[ARG4]] : f32
// CHECK:     linalg.yield %[[SUM]] : f32
// CHECK: } -> tensor<16x32x64x256xf32>
```

It might be worth considering adding even more test cases, as obviously the current coverage isn't enough."
55651,Not able to encode tensor in any type of image format that other libraries can understand,"I am trying to write a tensor to an image format As seen in colab in bottom, when I take the encoded bytes and write it a file using python, it doesn't work. Trying opening the image it gets corrupted. I have used gif, png, jpeg
When I use tf.io.write_file it works. I also tried taking a png and using tf.io_decode_png and than tf.io.encoding_png and the image string bytes differ from the original png. I am using tensorflow serving and using this png result through the rest api, where I don't have access to tf.io.write_file so I was wondering what encode  does differently, than traditional encodings.

https://www.loom.com/share/4b32b330a0e742cab2ea3a1a9af11b22
https://colab.research.google.com/drive/13Y4ET8jAHZDq7qwUYgg8nuBkxqniUqGu#scrollTo=IcXVZepnhkW4
"
55650,FusedBatchNormV3 split/fuse to/from Cheaper primitive ops with TF-1.15/TF-2.8,"Hi, 

I am doing Inference with Bert Large & Bert Base models with TF-1.15 and TF-2.8. 

**Inference with Checkpoints:**
For TF-2.8, I observed set of primitive ops are Fused to single node FusedBatchNormV3 whereas in TF-1.15 fusion of primitive ops is not happening(The graph consists of Primitive ops).

**Inference with Frozen Graph:**
With frozen graph(.pb) the graph itself has FusedBatchNormV3 node. For TF-1.15 the FusedBatchNormV3 is split into set of primitive ops. whereas in TF-2.8 split of ops is not happening (The graph consists of Fused op).

I am trying to find where this fusion/split is happening when it differs TF versions. After going through fusions that happens at grappler phase(remapper.cc) I found the fusion is happening before it reaches grappler phase. 

Can someone help me to point out where the fusion/split of FusedBatchNormV3 is being taken place?

Thanks!!"
55649,"Invalid number of inputs provided for running a SignatureDef, expected 4 vs provided 1","### 1. System information

OS: Windows 10:
TensorFlow: 2.7:

### 2. Code

python version : 3.7.13  / 64 bit

#### Code used to create and convert transfer learning tflite model 

```
    # * TESTED
    @tf.function(input_signature=[tf.TensorSpec(shape=[], dtype=tf.string)])
    def extract_weights(self,checkpoint_path):
        """"""
        Extracts the traininable weights of the head model as a list of tensors.

        Paramaters:

        Returns:
            Map of extracted weights and biases.
        """"""
        tmp_dict = {}
        tensor_names = [weight.name for weight in self.head_model.weights]
        tensors_to_save = [weight.read_value() for weight in self.head_model.weights]
        for index, layer in enumerate(tensors_to_save):
            tmp_dict[tensor_names[index]] = layer

        return tmp_dict


    @tf.function(input_signature=[SIGNATURE_DICT])
    def initialize_weights(self, weights):
        """"""
        Initializes weights of the head model.

        Paramaters:
            weights : dict of tensors used for initialization.
        Returns:
            NONE
        """"""

        restored_tensors={}
        tensor_names = [weight.name for weight in self.head_model.weights]
        for i, tensor in enumerate(self.head_model.weights):
            tensor.assign(weights[tensor_names[i]])
            restored_tensors[tensor.name] = tensor
        
        return restored_tensors
```
Android Dependency:

implementation 'org.tensorflow:tensorflow-lite:2.7.0'

This is the android method that uses the extract signature.
```
  float[][] extractWeights(){
    //ce ar trebui sa pun pe input ?
    //da eroare daca e null
    Map<String, Object> inputs = new HashMap<>();
    File outputFile=new File(""workaround"");
    inputs.put(""checkpoint_path"",outputFile.getAbsolutePath());

    Map<String,Object> outputs=new HashMap<>();
      // cred ca pe outputs trebuie sa imi fac legit 4
      // inserari ptr fiecare layer de weightsuri de dims ( [1280,128],[128,],[128,11],[11,]
    float[][] layer1_kernel=new float[BOTTLENECK_SIZE][128];
    float[][] layer1_bias  =new float[128][]; //sau ar trebui sa aibe doar o dimensiune ?
    float[][] layer2_kernel=new float[128][numClasses];
    float[][] layer2_bias  =new float[numClasses][];

    outputs.put(""dense_1/kernel:0"", layer1_kernel);
    outputs.put(""dense_1/bias:0"", layer1_bias);
    outputs.put(""dense_2/kernel:0"", layer2_kernel);
    outputs.put(""dense_2/bias:0"", layer2_bias);

    this.interpreter.runSignature(inputs,outputs,""extract"");

    return outputs;
  }
```


Error got :

Invalid number of inputs provided for running a SignatureDef, expected 4 vs provided 1

From my point of view the output of extract should be passable as input parameter to initialize giving that the output and the input sgnature are exactly the same as data types and structure.

You can find a colab with the implementation problems here [colab](https://colab.research.google.com/drive/1XC8vgEWm32TS9w0rszlGEnn8G6BOYlcM?usp=sharing) . "
55648,Gradients not computed upon `tf.concat()`,"Hi!

I am trying to re-write MAVNet (https://github.com/sudakshin/imitation_learning/blob/master/2.train_model/MavNet.py) into genuine Tensorflow (instead of TFLearn) and train it. Note that MAVNet consists of numerous `tf.keras.layers.Concatenate()`, which involves `tf.concat()`.
For some reason, gradient flow seems to break... and I just found out that the flow breaks whenever it passes `tf.concat()`.

Please pardon if this issue is a duplicate of #37726 , but I feel that the previous issue has been closed too early without being thoroughly investigated and resolved.

The details of this issue is as follows:

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.3.0-2.8.0 (issue reproduced from all versions included in this range)
- Python version: 3.8.3
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: CUDA 11.4 + cuDNN 8.1.1
- GPU model and memory: NVIDIA GeForce GTX Titan X

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
Tensorflow is not able to compute gradients after concatenating multiple feature maps with `tf.concat()`.

**Describe the expected behavior**
Tensorflow should be able to compute gradients after concatenating multiple feature maps with `tf.concat()`.

**Standalone code to reproduce the issue**

(Here, we assume all necessary libraries (including Tensorflow) are imported)

    class LocalResponseNormalization(tf.keras.layers.Layer):
        def __init__(self, depth_radius=5, bias=1, alpha=1, beta=0.5):
            super(LocalResponseNormalization, self).__init__()
            self.depth_radius = depth_radius
            self.bias = bias
            self.alpha = alpha
            self.beta = beta

        def build(self,input):
            pass

        def call(self, input):
            return tf.nn.local_response_normalization(input, alpha=self.alpha, beta=self.beta)

        def get_config(self):
            config = super().get_config().copy()
            return config

    def MavNet(input_shape, num_classes=2):
        img_input = tf.keras.layers.Input(shape=input_shape)

        conv1_7_7 = tf.keras.layers.Conv2D(64, 7, strides=2, activation='relu', padding='same', name = 'conv1_7_7_s2')(img_input)
        pool1_3_3 = tf.keras.layers.MaxPooling2D(pool_size=3, strides=2)(conv1_7_7)
        pool1_3_3 = LocalResponseNormalization(alpha=0.0001, beta=0.75)(pool1_3_3)
        conv2_3_3_reduce = tf.keras.layers.Conv2D(64,1, activation='relu', padding='same', name = 'conv2_3_3_reduce')(pool1_3_3)
        conv2_3_3 = tf.keras.layers.Conv2D(192,3, activation='relu', padding='same', name='conv2_3_3')(conv2_3_3_reduce)
        conv2_3_3 = LocalResponseNormalization(alpha=0.0001, beta=0.75)(conv2_3_3)
        pool2_3_3 = tf.keras.layers.MaxPooling2D(pool_size=3, strides=2, name='pool2_3_3_s2')(conv2_3_3)

        mavnet_3a_1_1 = tf.keras.layers.Conv2D(64, 1, activation='relu', padding='same', name='mavnet_3a_1_1')(pool2_3_3)
        mavnet_3a_3_3_reduce = tf.keras.layers.Conv2D(96,1, activation='relu', padding='same',  name='mavnet_3a_3_3_reduce')(pool2_3_3)
        mavnet_3a_3_3 = tf.keras.layers.Conv2D(128,kernel_size=3,  activation='relu', padding='same',  name = 'mavnet_3a_3_3')(mavnet_3a_3_3_reduce)
        mavnet_3a_pool = tf.keras.layers.MaxPooling2D(pool_size=3, strides=1, padding='same')(pool2_3_3)
        mavnet_3a_pool_1_1 = tf.keras.layers.Conv2D(32, kernel_size=1, activation='relu', padding='same', name='mavnet_3a_pool_1_1')(mavnet_3a_pool)
        mavnet_3a_output = tf.keras.layers.Concatenate(axis=3)([mavnet_3a_1_1, mavnet_3a_3_3, mavnet_3a_pool_1_1])

        mavnet_3b_1_1 = tf.keras.layers.Conv2D(128,kernel_size=1,activation='relu', padding='same', name= 'mavnet_3b_1_1' )(mavnet_3a_output)
        mavnet_3b_3_3_reduce = tf.keras.layers.Conv2D( 128, kernel_size=1, activation='relu', padding='same', name='mavnet_3b_3_3_reduce')(mavnet_3a_output)
        mavnet_3b_3_3 = tf.keras.layers.Conv2D( 192, kernel_size=3,  activation='relu', padding='same', name='mavnet_3b_3_3')(mavnet_3b_3_3_reduce)
        mavnet_3b_pool = tf.keras.layers.MaxPooling2D( pool_size=3, strides=1, padding='same', name='mavnet_3b_pool')(mavnet_3a_output)
        mavnet_3b_pool_1_1 = tf.keras.layers.Conv2D( 64, kernel_size=1,activation='relu', padding='same', name='mavnet_3b_pool_1_1')(mavnet_3b_pool)
        mavnet_3b_output = tf.keras.layers.Concatenate(axis=3,name='mavnet_3b_output')([mavnet_3b_1_1, mavnet_3b_3_3, mavnet_3b_pool_1_1])

        pool3_3_3 = tf.keras.layers.MaxPooling2D( pool_size=3, strides=2, padding='same', name='pool3_3_3')(mavnet_3b_output)

        mavnet_4a_1_1 = tf.keras.layers.Conv2D( 192, kernel_size=1, activation='relu', padding='same', name='mavnet_4a_1_1')(pool3_3_3)
        mavnet_4a_3_3_reduce = tf.keras.layers.Conv2D( 96, kernel_size=1, activation='relu', padding='same', name='mavnet_4a_3_3_reduce')(pool3_3_3)
        mavnet_4a_3_3 = tf.keras.layers.Conv2D( 208, kernel_size=3,  activation='relu', padding='same', name='mavnet_4a_3_3')(mavnet_4a_3_3_reduce)
        mavnet_4a_pool = tf.keras.layers.MaxPooling2D( pool_size=3, strides=1, padding='same', name='mavnet_4a_pool')(pool3_3_3)
        mavnet_4a_pool_1_1 = tf.keras.layers.Conv2D( 64, kernel_size=1, activation='relu', padding='same', name='mavnet_4a_pool_1_1')(mavnet_4a_pool)
        mavnet_4a_output = tf.keras.layers.Concatenate(axis=3, name='mavnet_4a_output')([mavnet_4a_1_1, mavnet_4a_3_3, mavnet_4a_pool_1_1])

        mavnet_4b_1_1 = tf.keras.layers.Conv2D( 160, kernel_size=1, activation='relu', padding='same', name='mavnet_4b_1_1')(mavnet_4a_output)
        mavnet_4b_3_3_reduce = tf.keras.layers.Conv2D( 112, kernel_size=1, activation='relu', padding='same', name='mavnet_4b_3_3_reduce')(mavnet_4a_output)
        mavnet_4b_3_3 = tf.keras.layers.Conv2D( 224, kernel_size=3, activation='relu', padding='same', name='mavnet_4b_3_3')(mavnet_4b_3_3_reduce)
        mavnet_4b_pool = tf.keras.layers.MaxPooling2D( pool_size=3, strides=1, padding='same', name='mavnet_4b_pool')(mavnet_4a_output)
        mavnet_4b_pool_1_1 = tf.keras.layers.Conv2D( 64, kernel_size=1, activation='relu', padding='same', name='mavnet_4b_pool_1_1')(mavnet_4b_pool)
        mavnet_4b_output = tf.keras.layers.Concatenate(axis=3, name='mavnet_4b_output')([mavnet_4b_1_1, mavnet_4b_3_3, mavnet_4b_pool_1_1])

        mavnet_4c_1_1 = tf.keras.layers.Conv2D( 128, kernel_size=1, activation='relu', padding='same', name='mavnet_4c_1_1')(mavnet_4b_output)
        mavnet_4c_3_3_reduce = tf.keras.layers.Conv2D( 128, kernel_size=1, activation='relu', padding='same', name='mavnet_4c_3_3_reduce')(mavnet_4b_output)
        mavnet_4c_3_3 = tf.keras.layers.Conv2D( 256,  kernel_size=3, activation='relu', padding='same', name='mavnet_4c_3_3')(mavnet_4c_3_3_reduce)
        mavnet_4c_pool = tf.keras.layers.MaxPooling2D( pool_size=3, strides=1, padding='same')(mavnet_4b_output)
        mavnet_4c_pool_1_1 = tf.keras.layers.Conv2D( 64, kernel_size=1, activation='relu', padding='same', name='mavnet_4c_pool_1_1')(mavnet_4c_pool)
        mavnet_4c_output = tf.keras.layers.Concatenate(axis=3,name='mavnet_4c_output')([mavnet_4c_1_1, mavnet_4c_3_3, mavnet_4c_pool_1_1])

        mavnet_4d_1_1 = tf.keras.layers.Conv2D( 112, kernel_size=1, activation='relu', padding='same', name='mavnet_4d_1_1')(mavnet_4c_output)
        mavnet_4d_3_3_reduce = tf.keras.layers.Conv2D( 144, kernel_size=1, activation='relu', padding='same', name='mavnet_4d_3_3_reduce')(mavnet_4c_output)
        mavnet_4d_3_3 = tf.keras.layers.Conv2D( 288, kernel_size=3, activation='relu', padding='same', name='mavnet_4d_3_3')(mavnet_4d_3_3_reduce)
        mavnet_4d_pool = tf.keras.layers.MaxPooling2D( pool_size=3, strides=1, padding='same', name='mavnet_4d_pool')(mavnet_4c_output)
        mavnet_4d_pool_1_1 = tf.keras.layers.Conv2D( 64, kernel_size=1, activation='relu', padding='same', name='mavnet_4d_pool_1_1')(mavnet_4d_pool)
        mavnet_4d_output = tf.keras.layers.Concatenate(axis=3, name='mavnet_4d_output')([mavnet_4d_1_1, mavnet_4d_3_3, mavnet_4d_pool_1_1])

        mavnet_4e_1_1 = tf.keras.layers.Conv2D( 256, kernel_size=1, activation='relu', padding='same', name='mavnet_4e_1_1')(mavnet_4d_output)
        mavnet_4e_3_3_reduce = tf.keras.layers.Conv2D( 160, kernel_size=1, activation='relu', padding='same', name='mavnet_4e_3_3_reduce')(mavnet_4d_output)
        mavnet_4e_3_3 = tf.keras.layers.Conv2D( 320, kernel_size=3, activation='relu', padding='same', name='mavnet_4e_3_3')(mavnet_4e_3_3_reduce)
        mavnet_4e_pool = tf.keras.layers.MaxPooling2D( pool_size=3, strides=1, padding='same', name='mavnet_4e_pool')(mavnet_4d_output)
        mavnet_4e_pool_1_1 = tf.keras.layers.Conv2D( 128, kernel_size=1, activation='relu', padding='same', name='mavnet_4e_pool_1_1')(mavnet_4e_pool)
        mavnet_4e_output = tf.keras.layers.Concatenate(axis=3)([mavnet_4e_1_1, mavnet_4e_3_3,mavnet_4e_pool_1_1])

        pool4_3_3 = tf.keras.layers.MaxPooling2D(pool_size=3, strides=2, padding='same', name='pool_3_3')(mavnet_4e_output)

        mavnet_5a_1_1 = tf.keras.layers.Conv2D( 256, kernel_size=1, activation='relu', padding='same', name='mavnet_5a_1_1')(pool4_3_3)
        mavnet_5a_3_3_reduce = tf.keras.layers.Conv2D( 160, kernel_size=1, activation='relu', padding='same', name='mavnet_5a_3_3_reduce')(pool4_3_3)
        mavnet_5a_3_3 = tf.keras.layers.Conv2D( 320, kernel_size=3, activation='relu', padding='same', name='mavnet_5a_3_3')(mavnet_5a_3_3_reduce)
        mavnet_5a_pool = tf.keras.layers.MaxPooling2D( pool_size=3, strides=1, padding='same', name='mavnet_5a_pool')(pool4_3_3)
        mavnet_5a_pool_1_1 = tf.keras.layers.Conv2D( 128, kernel_size=1,activation='relu', padding='same', name='mavnet_5a_pool_1_1')(mavnet_5a_pool)
        mavnet_5a_output = tf.keras.layers.Concatenate(axis=3)([mavnet_5a_1_1, mavnet_5a_3_3, mavnet_5a_pool_1_1])

        mavnet_5b_1_1 = tf.keras.layers.Conv2D( 384, kernel_size=1,activation='relu', padding='same', name='mavnet_5b_1_1')(mavnet_5a_output)
        mavnet_5b_3_3_reduce = tf.keras.layers.Conv2D( 192, kernel_size=1, activation='relu', padding='same', name='mavnet_5b_3_3_reduce')(mavnet_5a_output)
        mavnet_5b_3_3 = tf.keras.layers.Conv2D( 384,  kernel_size=3,activation='relu', padding='same', name='mavnet_5b_3_3')(mavnet_5b_3_3_reduce)
        mavnet_5b_pool = tf.keras.layers.MaxPooling2D( pool_size=3, strides=1, padding='same', name='mavnet_5b_pool')(mavnet_5a_output)
        mavnet_5b_pool_1_1 = tf.keras.layers.Conv2D( 128, kernel_size=1, activation='relu', padding='same', name='mavnet_5b_pool_1_1')(mavnet_5b_pool)
        mavnet_5b_output = tf.keras.layers.Concatenate(axis=3)([mavnet_5b_1_1, mavnet_5b_3_3, mavnet_5b_pool_1_1])

        pool5_7_7 = tf.keras.layers.AveragePooling2D(pool_size=7, strides=1, padding='same')(mavnet_5b_output)
        pool5_7_7 = tf.keras.layers.Dropout(0.4)(pool5_7_7)
        pool5_7_7_flatten = tf.keras.layers.Flatten()(pool5_7_7)
        output = tf.keras.layers.Dense(num_classes, activation='softmax')(pool5_7_7_flatten)

        model = tf.keras.Model(img_input, output)
        model.compile(optimizer=tf.keras.optimizers.SGD(0.0001), loss='categorical_crossentropy', metrics=['accuracy'])

        return model

    model = MavNet((100, 100, 1), num_classes)

    # Here, you can put input data of your own
    model.fit(data)



In addition, according to #37726, you can refer to a simple example in which gradient computation after `tf.concat` does not work : https://colab.research.google.com/drive/1dkCcL5jfBmo47EsvmhNumjIkCGIdeFd5
"
55647,ValueError: Input 0 of node model/prune_low_magnitude_conv2d/AssignVariableOp was passed float from model/prune_low_magnitude_conv2d/Mul/ReadVariableOp/resource:0 incompatible with expected resource.,"### 1. System information

- OS Platform and Distribution:
centos 7
- TensorFlow installation (pip package or built from source):
pip package
- TensorFlow library (version, if pip package or github SHA, if built from source):
pip package， tensorflow2.6,  tensorflow-model-optimization==0.7.2

### 2. Code

Provide code to help us reproduce your issues using one of the following options:

`
            self.model = create_model(args['networks'])

            pruning_params = {
                'pruning_schedule':
                    PolynomialDecay(
                        initial_sparsity=0.0,
                        final_sparsity=0.50,
                        begin_step=0,
                        end_step=500000000,
                        frequency=100),
            }

            self.model = prune.prune_low_magnitude(
                self.model, **pruning_params)

        self.lg.info('Create model successfully! Params: [{:.2f}]K'.format(self.model.count_params()/1e3))
        self.lg.info('Create model successfully! Params: [{:.2f}]'.format(self.model.count_params()))

        self.train_data = train_data
        self.val_data = val_data
        self.writer = writer

        self.optimizer = tf.keras.optimizers.Adam(lr=self.opt['lr'])
        lr_scheduler = LearningRateScheduler(self.scheduler)
        epoch_end_call = Epoch_End_Callback(self.val_data, self.train_data, self.lg, self.writer, args['paths'], self.opt['val_step'], state=self.state)
        self.callback = [lr_scheduler, epoch_end_call]

        self.prune_callbacks = [
            lr_scheduler,
            epoch_end_call,
            pruning_callbacks.UpdatePruningStep(),
            pruning_callbacks.PruningSummaries(log_dir=""./logs""),
        ]

    def train(self):
        if self.resume == False:
            self.model.compile(optimizer=self.optimizer, loss=self.opt['loss'])
        # history = self.model.fit(self.train_data, epochs=self.opt['epochs'], workers=self.opt['workers'], callbacks=self.callback, initial_epoch=self.state['current_epoch']+1)
        history = self.model.fit(self.train_data, epochs=self.opt['epochs'], workers=self.opt['workers'], callbacks=self.prune_callbacks, initial_epoch=self.state['current_epoch']+1)

        converter = tf.lite.TFLiteConverter.from_keras_model(self.model)
        converter._enable_tflite_resource_variables = True
        converter.optimizations = {tf.lite.Optimize.EXPERIMENTAL_SPARSITY, tf.lite.Optimize.DEFAULT}
        tflite_model = converter.convert()

        tflite_model_path = './logs/model.tflite'
        print('model is saved to {}'.format(tflite_model_path))
        with open(tflite_model_path, 'wb') as f:
            f.write(tflite_model)


`



### 3. Failure after conversion
If the conversion is successful, but the generated model is wrong, then state what is wrong:

- Model produces wrong results and/or has lesser accuracy.
- Model produces correct results, but it is slower than expected.

`
/home/usrname/anaconda3/envs/tf2.6_cudnn8.1/lib/python3.7/site-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.
  category=CustomMaskWarning)
Traceback (most recent call last):
  File ""train.py"", line 68, in <module>
    solver.train()
  File ""/home/usrname/SR/TF/mymodel_03/solvers/solver.py"", line 122, in train
    tflite_model = converter.convert()
  File ""/home/usrname/anaconda3/envs/tf2.6_cudnn8.1/lib/python3.7/site-packages/tensorflow/lite/python/lite.py"", line 729, in wrapper
    return self._convert_and_export_metrics(convert_func, *args, **kwargs)
  File ""/home/usrname/anaconda3/envs/tf2.6_cudnn8.1/lib/python3.7/site-packages/tensorflow/lite/python/lite.py"", line 715, in _convert_and_export_metrics
    result = convert_func(self, *args, **kwargs)
  File ""/home/usrname/anaconda3/envs/tf2.6_cudnn8.1/lib/python3.7/site-packages/tensorflow/lite/python/lite.py"", line 1123, in convert
    self._freeze_keras_model())
  File ""/home/usrname/anaconda3/envs/tf2.6_cudnn8.1/lib/python3.7/site-packages/tensorflow/lite/python/convert_phase.py"", line 218, in wrapper
    raise error from None  # Re-throws the exception.
  File ""/home/usrname/anaconda3/envs/tf2.6_cudnn8.1/lib/python3.7/site-packages/tensorflow/lite/python/convert_phase.py"", line 208, in wrapper
    return func(*args, **kwargs)
  File ""/home/usrname/anaconda3/envs/tf2.6_cudnn8.1/lib/python3.7/site-packages/tensorflow/lite/python/lite.py"", line 1080, in _freeze_keras_model
    self._funcs[0], lower_control_flow=False))
  File ""/home/usrname/anaconda3/envs/tf2.6_cudnn8.1/lib/python3.7/site-packages/tensorflow/python/framework/convert_to_constants.py"", line 1235, in convert_variables_to_constants_v2_as_graph
    converted_input_indices)
  File ""/home/usrname/anaconda3/envs/tf2.6_cudnn8.1/lib/python3.7/site-packages/tensorflow/python/framework/convert_to_constants.py"", line 1080, in _construct_concrete_function
    new_output_names)
  File ""/home/usrname/anaconda3/envs/tf2.6_cudnn8.1/lib/python3.7/site-packages/tensorflow/python/eager/wrap_function.py"", line 650, in function_from_graph_def
    wrapped_import = wrap_function(_imports_graph_def, [])
  File ""/home/usrname/anaconda3/envs/tf2.6_cudnn8.1/lib/python3.7/site-packages/tensorflow/python/eager/wrap_function.py"", line 628, in wrap_function
    collections={}),
  File ""/home/usrname/anaconda3/envs/tf2.6_cudnn8.1/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py"", line 1007, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File ""/home/usrname/anaconda3/envs/tf2.6_cudnn8.1/lib/python3.7/site-packages/tensorflow/python/eager/wrap_function.py"", line 87, in __call__
    return self.call_with_variable_creator_scope(self._fn)(*args, **kwargs)
  File ""/home/usrname/anaconda3/envs/tf2.6_cudnn8.1/lib/python3.7/site-packages/tensorflow/python/eager/wrap_function.py"", line 93, in wrapped
    return fn(*args, **kwargs)
  File ""/home/usrname/anaconda3/envs/tf2.6_cudnn8.1/lib/python3.7/site-packages/tensorflow/python/eager/wrap_function.py"", line 648, in _imports_graph_def
    importer.import_graph_def(graph_def, name="""")
  File ""/home/usrname/anaconda3/envs/tf2.6_cudnn8.1/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py"", line 549, in new_func
    return func(*args, **kwargs)
  File ""/home/usrname/anaconda3/envs/tf2.6_cudnn8.1/lib/python3.7/site-packages/tensorflow/python/framework/importer.py"", line 405, in import_graph_def
    producer_op_list=producer_op_list)
  File ""/home/usrname/anaconda3/envs/tf2.6_cudnn8.1/lib/python3.7/site-packages/tensorflow/python/framework/importer.py"", line 501, in _import_graph_def_internal
    raise ValueError(str(e))
ValueError: Input 0 of node model/prune_low_magnitude_conv2d/AssignVariableOp was passed float from model/prune_low_magnitude_conv2d/Mul/ReadVariableOp/resource:0 incompatible with expected resource.
`

### 4. bug
When I use tfmot to try to sparse a model and convert the model to tflite format, it reports an error：
`
ValueError: Input 0 of node model/prune_low_magnitude_conv2d/AssignVariableOp was passed float from model/prune_low_magnitude_conv2d/Mul/ReadVariableOp/resource:0 incompatible with expected resource.
`

"
55646,Enable `unique` bool for `tf.random.uniform`! ,"**System information**
- TensorFlow version (you are using): 2.8
- Are you willing to contribute it (Yes/No): No


**Describe the feature and the current behavior/state.**

Currently, the `tf.random.uniform`, randomly sample values form given min and max range **without considering the repeating same value**. For example, currently:

```python
tf.random.uniform(shape=[5], maxval=5, dtype=tf.int32, seed=10)
<tf.Tensor: shape=(5,), dtype=int32, numpy=array([0, 0, 3, 3, 1], dtype=int32)>
````

but if it has a `unique` bool parameter, it would be possible to generate a unique random value. For example:

```python
tf.random.uniform(shape=[5], maxval=5, dtype=tf.int32, seed=10, unique=True)
<tf.Tensor: shape=(5,), dtype=int32, numpy=array([0, 2, 4, 3, 1], dtype=int32)>
````

**Will this change the current API? How?**

From 

```python
tf.random.uniform(
    shape,
    minval=0,
    maxval=None,
    dtype=tf.dtypes.int32,
    seed=None,
    name=None
)
```

To 

```python
tf.random.uniform(
    shape,
    minval=0,
    maxval=None,
    dtype=tf.dtypes.int32,
    seed=None,
    name=None,
    unique=False
)
```


**Who will benefit from this feature?**

A similar thing is possible with `import random; random.sample`. So, having `unique` bool in `tf.ranom.uniform` might be useful in some special cases. Similar param in [tf.random.uniform_candidate_sampler](https://www.tensorflow.org/api_docs/python/tf/random/uniform_candidate_sampler).



**Any Other info.**

I am not sure if there is any other convenient TensorFlow function that can be used to generate unique random values. I know we can do 

```python
tf.random.shuffle(tf.range(5))
```

But `tf.random.shuffle` has certain limitations to fall back to `while_loop`. That's why we can't use it here. Let me know if I've missed something. "
55644,"TFLite: Cannot run model inference converted with SELECT_TF_OPS: ERROR: Select TensorFlow op(s), included in the given model, is(are) not supported by this interpreter. Make sure you apply/link the Flex delegate before inference.","### 1. System information

- OS Platform and Distribution: Ubuntu 20.04.3 LTS
- TensorFlow installation: from source
- TensorFlow library: 2.9

### 2. Code

Provide code to help us reproduce your issues using one of the following options:

**Code:** https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/examples/minimal
**Model:** https://tfhub.dev/google/boundless/quarter/1 (basically any model which must be converted with `tf.lite.OpsSet.SELECT_TF_OPS`)

Model conversion code (with SELECT_TF_OPS):
```
# Load the original model
model = hub.load(model_handle)
concrete_function = model.signatures['default']

# Convert the model to TensorFlow Lite
converter = tf.lite.TFLiteConverter.from_concrete_functions([concrete_function])
converter.optimizations = [tf.lite.Optimize.DEFAULT]
converter.target_spec.supported_ops = [tf.lite.OpsSet.SELECT_TF_OPS]

tflite_model = converter.convert()

# Serialize the model
filename = f'boundless_quarter_{quantization}.tflite' 
open(filename, 'wb').write(tflite_model)

```
### 3. Any other info / logs
**Error message when minimal.exe gets model.tflite saved with SELECT_TF_OPS:**
```
user1@ubuntu:~/minimal$ ./minimal ../boundless_quarter_integer.tflite 
INFO: Created TensorFlow Lite XNNPACK delegate for CPU.
ERROR: Select TensorFlow op(s), included in the given model, is(are) not supported by this interpreter. Make sure you apply/link the Flex delegate before inference. For the Android, it can be resolved by adding ""org.tensorflow:tensorflow-lite-select-tf-ops"" dependency. See instructions: https://www.tensorflow.org/lite/guide/ops_select
ERROR: Node number 0 (FlexIdentity) failed to prepare.
ERROR: Select TensorFlow op(s), included in the given model, is(are) not supported by this interpreter. Make sure you apply/link the Flex delegate before inference. For the Android, it can be resolved by adding ""org.tensorflow:tensorflow-lite-select-tf-ops"" dependency. See instructions: https://www.tensorflow.org/lite/guide/ops_select
ERROR: Node number 0 (FlexIdentity) failed to prepare.
Error at /home/user1/tensorflow_src/tensorflow/lite/examples/minimal/minimal.cc:60
```

**Correct output, using any model saved without SELECT_TF_OPS (Expected behaviour):**
```
user1@ubuntu:~/minimal$ ./minimal ../model.tflite 
INFO: Created TensorFlow Lite XNNPACK delegate for CPU.
=== Pre-invoke Interpreter State ===
Interpreter has 1 subgraphs.

-----------Subgraph-0 has 27 tensors and 4 nodes------------
1 Inputs: [0] -> 4B (0.00MB)
1 Outputs: [8] -> 4B (0.00MB)

Tensor  ID Name                      Type            AllocType          Size (Bytes/MB)    Shape      MemAddr-Offset  
Tensor   0 serving_default_dense_... kTfLiteFloat32  kTfLiteArenaRw     4        / 0.00 [1,1] [0, 4)
Tensor   1 dense_2/bias              kTfLiteFloat32  kTfLiteMmapRo      4        / 0.00 [1] [572, 576)
Tensor   2 sequential/dense/MatMul   kTfLiteFloat32  kTfLiteMmapRo      4        / 0.00 [1,1] [480, 484)
Tensor   3 sequential/dense_1/MatMul kTfLiteFloat32  kTfLiteMmapRo      64       / 0.00 [16,1] [336, 400)
Tensor   4 sequential/dense_2/MatMul kTfLiteFloat32  kTfLiteMmapRo      64       / 0.00 [1,16] [192, 256)
Tensor   5 sequential/dense_1/Mat... kTfLiteFloat32  kTfLiteMmapRo      64       / 0.00 [16] [0, 64)
Tensor   6 sequential/dense/MatMul1  kTfLiteFloat32  kTfLiteArenaRw     4        / 0.00 [1,1] [-1, -1)
Tensor   7 sequential/dense/BiasA... kTfLiteFloat32  kTfLiteArenaRw     64       / 0.00 [1,16] [-1, -1)
Tensor   8 StatefulPartitionedCall:0 kTfLiteFloat32  kTfLiteArenaRw     4        / 0.00 [1,1] [64, 68)
Tensor   9 (nil)                     kTfLiteNoType   kTfLiteMemNone     0        / 0.00 (null) [-1, -1)
Tensor  10 (nil)                     kTfLiteNoType   kTfLiteMemNone     0        / 0.00 (null) [-1, -1)
Tensor  11 (nil)                     kTfLiteNoType   kTfLiteMemNone     0        / 0.00 (null) [-1, -1)
Tensor  12 (nil)                     kTfLiteNoType   kTfLiteMemNone     0        / 0.00 (null) [-1, -1)
Tensor  13 (nil)                     kTfLiteNoType   kTfLiteMemNone     0        / 0.00 (null) [-1, -1)
Tensor  14 (nil)                     kTfLiteNoType   kTfLiteMemNone     0        / 0.00 (null) [-1, -1)
Tensor  15 (nil)                     kTfLiteNoType   kTfLiteMemNone     0        / 0.00 (null) [-1, -1)
Tensor  16 (nil)                     kTfLiteNoType   kTfLiteMemNone     0        / 0.00 (null) [-1, -1)
Tensor  17 (nil)                     kTfLiteNoType   kTfLiteMemNone     0        / 0.00 (null) [-1, -1)
Tensor  18 (nil)                     kTfLiteNoType   kTfLiteMemNone     0        / 0.00 (null) [-1, -1)
Tensor  19 (nil)                     kTfLiteNoType   kTfLiteMemNone     0        / 0.00 (null) [-1, -1)
Tensor  20 (nil)                     kTfLiteNoType   kTfLiteMemNone     0        / 0.00 (null) [-1, -1)
Tensor  21 (nil)                     kTfLiteNoType   kTfLiteMemNone     0        / 0.00 (null) [-1, -1)
Tensor  22 (nil)                     kTfLiteNoType   kTfLiteMemNone     0        / 0.00 (null) [-1, -1)
Tensor  23 (nil)                     kTfLiteNoType   kTfLiteMemNone     0        / 0.00 (null) [-1, -1)
Tensor  24 (nil)                     kTfLiteNoType   kTfLiteMemNone     0        / 0.00 (null) [-1, -1)
Tensor  25 (nil)                     kTfLiteNoType   kTfLiteMemNone     0        / 0.00 (null) [-1, -1)
Tensor  26 (nil)                     kTfLiteNoType   kTfLiteMemNone     0        / 0.00 (null) [-1, -1)

kTfLiteArenaRw Info: 
Tensor 0 has the max size 4 bytes (0.000 MB).
This memory arena is estimated as[0x55e3cc5bb104, 0x55e3cc5bb0c0), taking 68 bytes (0.000 MB).
One possible set of tensors that have non-overlapping memory spaces with each other, and they take up the whole arena:
Tensor 0 -> 8.

kTfLiteArenaRwPersistent Info: not holding any allocation.

kTfLiteMmapRo Info: 
Tensor 3 has the max size 64 bytes (0.000 MB).
This memory arena is estimated as[0x7fb2de3f4648, 0x7fb2de3f4408), taking 576 bytes (0.001 MB).
One possible set of tensors that have non-overlapping memory spaces with each other, and they take up the whole arena:
Tensor 5 -> 4 -> 3 -> 2 -> 1.

kTfLiteDynamic Info: not holding any allocation.

Node   0 Operator Builtin Code   9 FULLY_CONNECTED (delegated by node 3)
  3 Input Tensors:[0,2,-1] -> 0B (0.00MB)
  1 Output Tensors:[6] -> 0B (0.00MB)
Node   1 Operator Builtin Code   9 FULLY_CONNECTED (delegated by node 3)
  3 Input Tensors:[6,3,5] -> 0B (0.00MB)
  1 Output Tensors:[7] -> 0B (0.00MB)
Node   2 Operator Builtin Code   9 FULLY_CONNECTED (delegated by node 3)
  3 Input Tensors:[7,4,1] -> 0B (0.00MB)
  1 Output Tensors:[8] -> 0B (0.00MB)
Node   3 Operator Custom Name TfLiteXNNPackDelegate 
  6 Input Tensors:[0-5] -> 204B (0.00MB)
  1 Output Tensors:[8] -> 4B (0.00MB)

Execution plan as the list of 1 nodes invoked in-order: [3]
Among these nodes in the execution plan:
  Node 3 is a TfLiteXNNPackDelegate node (0x55e3cc5ba4f0), which has delegated 3 nodes: [0-2]
--------------Subgraph-0 dump has completed--------------



=== Post-invoke Interpreter State ===
Interpreter has 1 subgraphs.

-----------Subgraph-0 has 27 tensors and 4 nodes------------
1 Inputs: [0] -> 4B (0.00MB)
1 Outputs: [8] -> 4B (0.00MB)

Tensor  ID Name                      Type            AllocType          Size (Bytes/MB)    Shape      MemAddr-Offset  
Tensor   0 serving_default_dense_... kTfLiteFloat32  kTfLiteArenaRw     4        / 0.00 [1,1] [0, 4)
Tensor   1 dense_2/bias              kTfLiteFloat32  kTfLiteMmapRo      4        / 0.00 [1] [572, 576)
Tensor   2 sequential/dense/MatMul   kTfLiteFloat32  kTfLiteMmapRo      4        / 0.00 [1,1] [480, 484)
Tensor   3 sequential/dense_1/MatMul kTfLiteFloat32  kTfLiteMmapRo      64       / 0.00 [16,1] [336, 400)
Tensor   4 sequential/dense_2/MatMul kTfLiteFloat32  kTfLiteMmapRo      64       / 0.00 [1,16] [192, 256)
Tensor   5 sequential/dense_1/Mat... kTfLiteFloat32  kTfLiteMmapRo      64       / 0.00 [16] [0, 64)
Tensor   6 sequential/dense/MatMul1  kTfLiteFloat32  kTfLiteArenaRw     4        / 0.00 [1,1] [-1, -1)
Tensor   7 sequential/dense/BiasA... kTfLiteFloat32  kTfLiteArenaRw     64       / 0.00 [1,16] [-1, -1)
Tensor   8 StatefulPartitionedCall:0 kTfLiteFloat32  kTfLiteArenaRw     4        / 0.00 [1,1] [64, 68)
Tensor   9 (nil)                     kTfLiteNoType   kTfLiteMemNone     0        / 0.00 (null) [-1, -1)
Tensor  10 (nil)                     kTfLiteNoType   kTfLiteMemNone     0        / 0.00 (null) [-1, -1)
Tensor  11 (nil)                     kTfLiteNoType   kTfLiteMemNone     0        / 0.00 (null) [-1, -1)
Tensor  12 (nil)                     kTfLiteNoType   kTfLiteMemNone     0        / 0.00 (null) [-1, -1)
Tensor  13 (nil)                     kTfLiteNoType   kTfLiteMemNone     0        / 0.00 (null) [-1, -1)
Tensor  14 (nil)                     kTfLiteNoType   kTfLiteMemNone     0        / 0.00 (null) [-1, -1)
Tensor  15 (nil)                     kTfLiteNoType   kTfLiteMemNone     0        / 0.00 (null) [-1, -1)
Tensor  16 (nil)                     kTfLiteNoType   kTfLiteMemNone     0        / 0.00 (null) [-1, -1)
Tensor  17 (nil)                     kTfLiteNoType   kTfLiteMemNone     0        / 0.00 (null) [-1, -1)
Tensor  18 (nil)                     kTfLiteNoType   kTfLiteMemNone     0        / 0.00 (null) [-1, -1)
Tensor  19 (nil)                     kTfLiteNoType   kTfLiteMemNone     0        / 0.00 (null) [-1, -1)
Tensor  20 (nil)                     kTfLiteNoType   kTfLiteMemNone     0        / 0.00 (null) [-1, -1)
Tensor  21 (nil)                     kTfLiteNoType   kTfLiteMemNone     0        / 0.00 (null) [-1, -1)
Tensor  22 (nil)                     kTfLiteNoType   kTfLiteMemNone     0        / 0.00 (null) [-1, -1)
Tensor  23 (nil)                     kTfLiteNoType   kTfLiteMemNone     0        / 0.00 (null) [-1, -1)
Tensor  24 (nil)                     kTfLiteNoType   kTfLiteMemNone     0        / 0.00 (null) [-1, -1)
Tensor  25 (nil)                     kTfLiteNoType   kTfLiteMemNone     0        / 0.00 (null) [-1, -1)
Tensor  26 (nil)                     kTfLiteNoType   kTfLiteMemNone     0        / 0.00 (null) [-1, -1)

kTfLiteArenaRw Info: 
Tensor 0 has the max size 4 bytes (0.000 MB).
This memory arena is estimated as[0x55e3cc5bb104, 0x55e3cc5bb0c0), taking 68 bytes (0.000 MB).
One possible set of tensors that have non-overlapping memory spaces with each other, and they take up the whole arena:
Tensor 0 -> 8.

kTfLiteArenaRwPersistent Info: not holding any allocation.

kTfLiteMmapRo Info: 
Tensor 3 has the max size 64 bytes (0.000 MB).
This memory arena is estimated as[0x7fb2de3f4648, 0x7fb2de3f4408), taking 576 bytes (0.001 MB).
One possible set of tensors that have non-overlapping memory spaces with each other, and they take up the whole arena:
Tensor 5 -> 4 -> 3 -> 2 -> 1.

kTfLiteDynamic Info: not holding any allocation.

Node   0 Operator Builtin Code   9 FULLY_CONNECTED (delegated by node 3)
  3 Input Tensors:[0,2,-1] -> 0B (0.00MB)
  1 Output Tensors:[6] -> 0B (0.00MB)
Node   1 Operator Builtin Code   9 FULLY_CONNECTED (delegated by node 3)
  3 Input Tensors:[6,3,5] -> 0B (0.00MB)
  1 Output Tensors:[7] -> 0B (0.00MB)
Node   2 Operator Builtin Code   9 FULLY_CONNECTED (delegated by node 3)
  3 Input Tensors:[7,4,1] -> 0B (0.00MB)
  1 Output Tensors:[8] -> 0B (0.00MB)
Node   3 Operator Custom Name TfLiteXNNPackDelegate 
  6 Input Tensors:[0-5] -> 204B (0.00MB)
  1 Output Tensors:[8] -> 4B (0.00MB)

Execution plan as the list of 1 nodes invoked in-order: [3]
Among these nodes in the execution plan:
  Node 3 is a TfLiteXNNPackDelegate node (0x55e3cc5ba4f0), which has delegated 3 nodes: [0-2]
--------------Subgraph-0 dump has completed--------------

```
### 4. Question
How should I build the minimal.cc to use tflite models saved with SELECT_TF_OPS. The platform where I'll use my code is Linux. I created libtensorflow_flex.so using this [tutorial ](https://www.tensorflow.org/lite/guide/ops_select#cc), but now I don't know what should I do with created shared library. I am a complete newbie in the usage of tflite models with C++, so you have to assume that I don't know most of the well-known things :)

What steps should I do to get minimal.exe which runs smoothly with the aforementioned models? "
55643,StatelessRandomBinomial op's  first input (shape) does not support int64,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
```
import tensorflow as tf
shape = tf.constant([1, 1, 1], dtype=tf.int64)
seed = [52, 35]
counts = [10.1]
probs = [0.1]

data = tf.raw_ops.StatelessRandomBinomial(
    shape = shape, seed=seed, counts = counts, probs=probs, dtype=tf.float32
)
print(data)
```
- TensorFlow version (use command below):
 2.6.3


**Describe the current behavior**
```
tensorflow/core/framework/tensor.cc:708] Check failed: dtype() == expected_dtype (9 vs. 3) int32 expected, got int64
Aborted

I think this bug caused by the following code which are only work for int32

for (int64 i = 0; i < num_sample_dims; ++i) {
      samples_per_batch *= shape_tensor.flat<**int32**>()(i);
    }
```

"
55642,tensorflow installed but cannot be imported ,"**System information**
- windows 11
- TensorFlow installed from (source or binary):
- TensorFlow version:2.8.0
- Python version:3.10
- Installed using: pip
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:



**Describe the problem**
The installation of tensorflow using the pip3 install --upgrade  tensorflow command was successful but when I test the command import tensorflow as tf in jupyter notebook , I get the following result:

---------------------------------------------------------------------------
ModuleNotFoundError                       Traceback (most recent call last)
C:\Users\VIDYAS~1\AppData\Local\Temp/ipykernel_8636/4294963926.py in <module>
----> 1 import tensorflow

ModuleNotFoundError: No module named 'tensorflow'

Steps :
pip install --user virtualenv
pip install --upgrade  tensorflow


"
55639,`tf.vectorized_maps` resolve fallbacks,"Mirroring https://github.com/keras-team/keras-cv/issues/291 for the TF core component.

**System information**
- TensorFlow version (you are using):
master
- Are you willing to contribute it (Yes/No):
I don't know. If I have a clear contribution path/pin-pointer probably.

**Describe the feature and the current behavior/state.**
Missing converters PFOR and eventually mitigate other fallbacks

**Will this change the current api? How?**
No

**Who will benefit with this feature?**
Performance on fallback

**Any Other info.**

/cc @wangpengmit 
"
55635,使用cmake 变异tensorflow c  库     失败  cmake版本为2.23.1    tensorflow 为 2.4.0,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version:
- Python version:
- Installed using virtualenv? pip? conda?:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:



**Describe the problem**

**Provide the exact sequence of commands / steps that you executed before running into the problem**


**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
55633,[XLA:GPU] Failed to determine best cudnn convolution algorithm,"I got `Failed to determine best cudnn convolution algorithm`  error when running `facebook/wav2vec2-base-960h` model using torch_xla on GPU in fp16 mode. This error only occurs when using fp16 and fp32 works fine.

Minimal HLO to reproduce:
```llvm
HloModule Test

ENTRY main {
  x = f16[44,768,1,49]{3,2,1,0} parameter(0)
  y = f16[44,768,1,50]{3,2,1,0} parameter(1)
  ROOT %convolution.10022 = f16[1,128,48,768]{3,2,1,0} convolution(f16[44,768,1,49]{3,2,1,0} %x, f16[44,768,1,50]{3,2,1,0} %y), window={size=1x50 pad=0_0x64_64}, dim_labels=fb01_io01->01bf, batch_group_count=16
}
```

The following is the full log file.
```
(base) ubuntu@xla-p3-8x:~/src/tensorflow/xla_benchmark$ ../bazel-bin/tensorflow/compiler/xla/tools/replay_computation_gpu --use_fake_data=true --num_runs=1 --print_result=false conv.hlo 
2022-04-15 00:10:23.507808: I tensorflow/compiler/xla/service/platform_util.cc:69] platform Host present but no XLA compiler available: could not find registered compiler for platform Host -- check target linkage (hint: try adding tensorflow/compiler/jit:xla_cpu_jit as a dependency)
2022-04-15 00:10:24.852458: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-04-15 00:10:24.935392: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-04-15 00:10:24.944338: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-04-15 00:10:24.967499: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-04-15 00:10:24.983119: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-04-15 00:10:25.002219: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-04-15 00:10:25.025011: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-04-15 00:10:25.050733: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-04-15 00:10:25.052806: I tensorflow/compiler/xla/service/service.cc:174] XLA service 0x562e5c814b50 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2022-04-15 00:10:25.052832: I tensorflow/compiler/xla/service/service.cc:182]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-04-15 00:10:25.052839: I tensorflow/compiler/xla/service/service.cc:182]   StreamExecutor device (1): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-04-15 00:10:25.052844: I tensorflow/compiler/xla/service/service.cc:182]   StreamExecutor device (2): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-04-15 00:10:25.052849: I tensorflow/compiler/xla/service/service.cc:182]   StreamExecutor device (3): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-04-15 00:10:25.052854: I tensorflow/compiler/xla/service/service.cc:182]   StreamExecutor device (4): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-04-15 00:10:25.052859: I tensorflow/compiler/xla/service/service.cc:182]   StreamExecutor device (5): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-04-15 00:10:25.052863: I tensorflow/compiler/xla/service/service.cc:182]   StreamExecutor device (6): Tesla V100-SXM2-32GB, Compute Capability 7.0
2022-04-15 00:10:25.052868: I tensorflow/compiler/xla/service/service.cc:182]   StreamExecutor device (7): Tesla V100-SXM2-32GB, Compute Capability 7.0
conv.hlo: is not HloSnapshot. Trying HloProto.
conv.hlo: is not HloProto. Trying HLO text.
2022-04-15 00:10:25.053972: I tensorflow/compiler/xla/tools/replay_computation.cc:470] Compiling 1 modules in parallel.
2022-04-15 00:10:25.622602: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8204
2022-04-15 00:10:26.108045: I tensorflow/compiler/xla/tools/replay_computation.cc:487] Done compiling; now running the modules.
2022-04-15 00:10:26.108867: E tensorflow/compiler/xla/tools/replay_computation.cc:491] Compilation failed: UNKNOWN: Failed to determine best cudnn convolution algorithm for:
%cudnn-conv = (f16[1,128,48,768]{3,1,0,2}, u8[0]{0}) custom-call(f16[704,48,1,49]{0,3,2,1} %bitcast.2, f16[48,768,1,50]{0,3,2,1} %pad), window={size=1x50 pad=0_0x64_64}, dim_labels=fb01_io01->01bf, feature_group_count=16, custom_call_target=""__cudnn$convForward"", backend_config=""{\""conv_result_scale\"":1,\""activation_mode\"":\""0\"",\""side_input_scale\"":0}""

Original error: UNKNOWN: CUDNN_STATUS_BAD_PARAM
in tensorflow/stream_executor/cuda/cuda_dnn.cc(3520): 'op' CUDNN_BACKEND_OPERATION: cudnnFinalize Failed

To ignore this failure and try to use a fallback algorithm (which may have suboptimal performance), use XLA_FLAGS=--xla_gpu_strict_conv_algorithm_picker=false.  Please also file a bug for the root cause of failing autotuning.: hlo { hlo_module { name: ""Test"" entry_computation_name: ""main"" computations { name: ""main"" instructions { name: ""x"" opcode: ""parameter"" shape { element_type: F16 dimensions: 44 dimensions: 768 dimensions: 1 dimensions: 49 layout { minor_to_major: 3 minor_to_major: 2 minor_to_major: 1 minor_to_major: 0 format: DENSE } is_dynamic_dimension: false is_dynamic_dimension: false is_dynamic_dimension: false is_dynamic_dimension: false } metadata { } frontend_attributes { } } instructions { name: ""y"" opcode: ""parameter"" shape { element_type: F16 dimensions: 44 dimensions: 768 dimensions: 1 dimensions: 50 layout { minor_to_major: 3 minor_to_major: 2 minor_to_major: 1 minor_to_major: 0 format: DENSE } is_dynamic_dimension: false is_dynamic_dimension: false is_dynamic_dimension: false is_dynamic_dimension: false } metadata { } parameter_number: 1 id: 1 frontend_attributes { } } instructions { name: ""convolution.10022"" opcode: ""convolution"" shape { element_type: F16 dimensions: 1 dimensions: 128 dimensions: 48 dimensions: 768 layout { minor_to_major: 3 minor_to_major: 2 minor_to_major: 1 minor_to_major: 0 format: DENSE } is_dynamic_dimension: false is_dynamic_dimension: false is_dynamic_dimension: false is_dynamic_dimension: false } metadata { } window { dimensions { size: 1 stride: 1 window_dilation: 1 base_dilation: 1 } dimensions { size: 50 stride: 1 padding_low: 64 padding_high: 64 window_dilation: 1 base_dilation: 1 } } convolution_dimension_numbers { kernel_output_feature_dimension: 1 kernel_spatial_dimensions: 2 kernel_spatial_dimensions: 3 input_batch_dimension: 1 output_batch_dimension: 2 output_feature_dimension: 3 input_spatial_dimensions: 2 input_spatial_dimensions: 3 output_spatial_dimensions: 0 output_spatial_dimensions: 1 } id: 2 operand_ids: 0 operand_ids: 1 feature_group_count: 1 precision_config { operand_precision: DEFAULT operand_precision: DEFAULT } batch_group_count: 16 frontend_attributes { } } program_shape { parameters { element_type: F16 dimensions: 44 dimensions: 768 dimensions: 1 dimensions: 49 layout { minor_to_major: 3 minor_to_major: 2 minor_to_major: 1 minor_to_major: 0 format: DENSE } is_dynamic_dimension: false is_dynamic_dimension: false is_dynamic_dimension: false is_dynamic_dimension: false } parameters { element_type: F16 dimensions: 44 dimensions: 768 dimensions: 1 dimensions: 50 layout { minor_to_major: 3 minor_to_major: 2 minor_to_major: 1 minor_to_major: 0 format: DENSE } is_dynamic_dimension: false is_dynamic_dimension: false is_dynamic_dimension: false is_dynamic_dimension: false } result { element_type: F16 dimensions: 1 dimensions: 128 dimensions: 48 dimensions: 768 layout { minor_to_major: 3 minor_to_major: 2 minor_to_major: 1 minor_to_major: 0 format: DENSE } is_dynamic_dimension: false is_dynamic_dimension: false is_dynamic_dimension: false is_dynamic_dimension: false } parameter_names: ""x"" parameter_names: ""y"" } id: 2 root_id: 2 } host_program_shape { parameters { element_type: F16 dimensions: 44 dimensions: 768 dimensions: 1 dimensions: 49 layout { minor_to_major: 3 minor_to_major: 2 minor_to_major: 1 minor_to_major: 0 format: DENSE } is_dynamic_dimension: false is_dynamic_dimension: false is_dynamic_dimension: false is_dynamic_dimension: false } parameters { element_type: F16 dimensions: 44 dimensions: 768 dimensions: 1 dimensions: 50 layout { minor_to_major: 3 minor_to_major: 2 minor_to_major: 1 minor_to_major: 0 format: DENSE } is_dynamic_dimension: false is_dynamic_dimension: false is_dynamic_dimension: false is_dynamic_dimension: false } result { element_type: F16 dimensions: 1 dimensions: 128 dimensions: 48 dimensions: 768 layout { minor_to_major: 3 minor_to_major: 2 minor_to_major: 1 minor_to_major: 0 format: DENSE } is_dynamic_dimension: false is_dynamic_dimension: false is_dynamic_dimension: false is_dynamic_dimension: false } parameter_names: ""p0"" parameter_names: ""p1"" } entry_computation_id: 2 input_output_alias { } dynamic_parameter_binding { } } }
```

Tested with tensorflow commit 75861c43005523e2552bb3f85b2f0defc16ea9cf, CUDA 11.4, CUDNN 8.2."
55627,`tf.io.write_graph` fails to stip debug nodes,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): `macOS Monterey 12.2.1 (m1)`
- TensorFlow installed from (source or binary):  source, following https://developer.apple.com/metal/tensorflow-plugin/
- TensorFlow version (use command below): 
```
tensorflow-deps==2.8.0
tensorflow-macos==2.8.0
tensorflow-metal==0.4.0  
```
(the provided command returns `unknown 2.8.0`)
- Python version: `3.9`

**Describe the current behavior**
Despite having set:`tf.config.optimizer.set_experimental_options({'debug_stripper': True})`, the `.pbtxt` record of a simple `tf.function` graph, generated by `tf.io.write_graph` still contains `assert_shape` nodes.

***Minimal example***:
```python
import tensorflow as tf
tf.config.optimizer.set_experimental_options({'debug_stripper': True})

@tf.function(
    input_signature=[
        tf.TensorSpec(
            shape=(2, 2),
            dtype=tf.int32,
            name=""Input"",
        ),
    ]
)
def fn(x):
    tf.debugging.assert_shapes(
        [
            (x, (2, 2))
        ]
    )
    return x

tf.io.write_graph(
    fn.get_concrete_function().graph,
    logdir=""."",
    name=""example.pbtxt"",
    as_text=True,
)
```

**Describe the expected behavior**
`assert_shape` nodes should not be present in the final graph.

**Standalone code to reproduce the issue**
Colab notebook: https://colab.research.google.com/drive/1l_P345AjMiHsLUTqG5io2Fjyag-1qIAM?usp=sharing

**Other info / logs**
Resulting `.pbtxt` file: 
```pbtxt
node {
  name: ""Input""
  op: ""Placeholder""
  attr {
    key: ""_user_specified_name""
    value {
      s: ""Input""
    }
  }
  attr {
    key: ""dtype""
    value {
      type: DT_INT32
    }
  }
  attr {
    key: ""shape""
    value {
      shape {
        dim {
          size: 2
        }
        dim {
          size: 2
        }
      }
    }
  }
}
node {
  name: ""assert_shapes/Shape""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_INT32
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: ""\002\000\000\000\002\000\000\000""
      }
    }
  }
}
node {
  name: ""assert_shapes/assert_rank/rank""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_INT32
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
        }
        int_val: 2
      }
    }
  }
}
node {
  name: ""assert_shapes/assert_rank/Shape""
  op: ""Const""
  attr {
    key: ""dtype""
    value {
      type: DT_INT32
    }
  }
  attr {
    key: ""value""
    value {
      tensor {
        dtype: DT_INT32
        tensor_shape {
          dim {
            size: 2
          }
        }
        tensor_content: ""\002\000\000\000\002\000\000\000""
      }
    }
  }
}
node {
  name: ""assert_shapes/assert_rank/assert_type/statically_determined_correct_type""
  op: ""NoOp""
}
node {
  name: ""assert_shapes/assert_rank/static_checks_determined_all_ok""
  op: ""NoOp""
}
node {
  name: ""group_deps""
  op: ""NoOp""
  input: ""^assert_shapes/assert_rank/static_checks_determined_all_ok""
}
node {
  name: ""Identity""
  op: ""Identity""
  input: ""Input""
  attr {
    key: ""T""
    value {
      type: DT_INT32
    }
  }
}
versions {
  producer: 987
}
```
"
55626,NotImplementedError: Cannot convert a symbolic Tensor (cond_2/strided_slice:0) to a numpy array.,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Google Colab
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Google Colab
- TensorFlow installed from (source or binary): Google Colab (default)
- TensorFlow version: 1.15.2
- Python version: 3.7.13
- Installed using virtualenv? pip? conda?: Google Colab (no env)
- Bazel version (if compiling from source): Google Colab (default)
- GCC/Compiler version (if compiling from source): Google Colab (default)
- CUDA/cuDNN version: Google Colab (default)
- GPU model and memory: Google Colab (default)



**Describe the problem**
Trying to train custom object detector referring blog [Custom object detection in the browser using TensorFlow.js](https://blog.tensorflow.org/2021/01/custom-object-detection-in-browser.html)

**Provide the exact sequence of commands / steps that you executed before running into the problem**
Ran these blocks one after other inside Google colab

```
from google.colab import drive
drive.mount('/content/drive/')
```

```
%cd /content/drive/MyDrive/Tensorflow/models/research/
```

```
!git clone https://github.com/tensorflow/models.git
```

```
%tensorflow_version 1.x
```

```
!protoc object_detection/protos/*.proto --python_out=.
# Install TensorFlow Object Detection API.
!cp object_detection/packages/tf1/setup.py .
!python -m pip install .
```

```
!python /content/drive/MyDrive/Tensorflow/models/research/object_detection/builders/model_builder_tf1_test.py
```

```
num_classes = 1
batch_size = 96
num_steps = 7500
num_eval_steps = 1000

train_record_path = '/content/drive/MyDrive/Tensorflow/dataset/train.record'
test_record_path = '/content/drive/MyDrive/Tensorflow/dataset/test.record'
model_dir = '/content/training/'
labelmap_path = '/content/drive/MyDrive/Tensorflow/dataset/labelmap.pbtxt'

pipeline_config_path = '/content/drive/MyDrive/Tensorflow/models/research/faster_rcnn_inception_v2_coco_2018_01_28/pipeline.config'
fine_tune_checkpoint = '/content/drive/MyDrive/Tensorflow/models/research/faster_rcnn_inception_v2_coco_2018_01_28_training/faster_rcnn_inception_training.ckpt-1'
```

```
!python /content/drive/MyDrive/Tensorflow/models/research/object_detection/model_main.py \
    --pipeline_config_path={pipeline_config_path} \
    --model_dir={model_dir} \
    --alsologtostderr \
    --num_train_steps={num_steps} \
    --sample_1_of_n_eval_examples=1 \
    --num_eval_steps={num_eval_steps}
```

Error I get
```
return input_fn(**kwargs)
  File ""/usr/local/lib/python3.7/dist-packages/object_detection/inputs.py"", line 770, in _train_input_fn
    params=params)
  File ""/usr/local/lib/python3.7/dist-packages/object_detection/inputs.py"", line 913, in train_input
    reduce_to_frame_fn=reduce_to_frame_fn)
  File ""/usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py"", line 251, in build
    input_reader_config)
  File ""/usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py"", line 236, in dataset_map_fn
    fn_to_map, num_parallel_calls=num_parallel_calls)
  File ""/tensorflow-1.15.2/python3.7/tensorflow_core/python/util/deprecation.py"", line 324, in new_func
    return func(*args, **kwargs)
  File ""/tensorflow-1.15.2/python3.7/tensorflow_core/python/data/ops/dataset_ops.py"", line 1950, in map_with_legacy_function
    use_legacy_function=True))
  File ""/tensorflow-1.15.2/python3.7/tensorflow_core/python/data/ops/dataset_ops.py"", line 3472, in __init__
    use_legacy_function=use_legacy_function)
  File ""/tensorflow-1.15.2/python3.7/tensorflow_core/python/data/ops/dataset_ops.py"", line 2689, in __init__
    self._function.add_to_graph(ops.get_default_graph())
  File ""/tensorflow-1.15.2/python3.7/tensorflow_core/python/framework/function.py"", line 545, in add_to_graph
    self._create_definition_if_needed()
  File ""/tensorflow-1.15.2/python3.7/tensorflow_core/python/framework/function.py"", line 377, in _create_definition_if_needed
    self._create_definition_if_needed_impl()
  File ""/tensorflow-1.15.2/python3.7/tensorflow_core/python/framework/function.py"", line 408, in _create_definition_if_needed_impl
    capture_resource_var_by_value=self._capture_resource_var_by_value)
  File ""/tensorflow-1.15.2/python3.7/tensorflow_core/python/framework/function.py"", line 944, in func_graph_from_py_func
    outputs = func(*func_graph.inputs)
  File ""/tensorflow-1.15.2/python3.7/tensorflow_core/python/data/ops/dataset_ops.py"", line 2681, in wrapper_fn
    ret = _wrapper_helper(*args)
  File ""/tensorflow-1.15.2/python3.7/tensorflow_core/python/data/ops/dataset_ops.py"", line 2652, in _wrapper_helper
    ret = autograph.tf_convert(func, ag_ctx)(*nested_args)
  File ""/tensorflow-1.15.2/python3.7/tensorflow_core/python/autograph/impl/api.py"", line 237, in wrapper
    raise e.ag_error_metadata.to_exception(e)
NotImplementedError: in converted code:

    /usr/local/lib/python3.7/dist-packages/object_detection/data_decoders/tf_example_decoder.py:580 decode
        default_groundtruth_weights)
    /tensorflow-1.15.2/python3.7/tensorflow_core/python/util/deprecation.py:507 new_func
        return func(*args, **kwargs)
    /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/control_flow_ops.py:1235 cond
        orig_res_f, res_f = context_f.BuildCondBranch(false_fn)
    /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/control_flow_ops.py:1061 BuildCondBranch
        original_result = fn()
    /usr/local/lib/python3.7/dist-packages/object_detection/data_decoders/tf_example_decoder.py:573 default_groundtruth_weights
        dtype=tf.float32)
    /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/array_ops.py:2560 ones
        output = _constant_if_small(one, shape, dtype, name)
    /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/array_ops.py:2295 _constant_if_small
        if np.prod(shape) < 1000:
    <__array_function__ internals>:6 prod
        
    /usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:3052 prod
        keepdims=keepdims, initial=initial, where=where)
    /usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:86 _wrapreduction
        return ufunc.reduce(obj, axis, dtype, out, **passkwargs)
    /tensorflow-1.15.2/python3.7/tensorflow_core/python/framework/ops.py:736 __array__
        "" array."".format(self.name))

    NotImplementedError: Cannot convert a symbolic Tensor (cond_2/strided_slice:0) to a numpy array.
```

If I run this
```
import tensorflow as tf
print(tf.__version__)
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function
from absl import flags
import tensorflow as tf
from object_detection import model_hparams
from object_detection import model_lib

model_dir = ""/content/drive/MyDrive/Tensorflow/models/research/faster_rcnn_inception_v2_coco_2018_01_28_training/""



config = tf.estimator.RunConfig(model_dir=model_dir)
pipeline_config_path= ""/content/drive/MyDrive/Tensorflow/models/research/faster_rcnn_inception_v2_coco_2018_01_28/pipeline.config""
num_train_steps=100


train_and_eval_dict = model_lib.create_estimator_and_inputs(
                        run_config=config,
                        hparams=model_hparams.create_hparams(None),
                        pipeline_config_path = pipeline_config_path,
                        train_steps =num_train_steps,
                        sample_1_of_n_eval_examples = 1)

estimator = train_and_eval_dict['estimator']
train_input_fn = train_and_eval_dict['train_input_fn']
eval_input_fns = train_and_eval_dict['eval_input_fns']
eval_on_train_input_fn = train_and_eval_dict['eval_on_train_input_fn']
predict_input_fn = train_and_eval_dict['predict_input_fn']
train_steps = train_and_eval_dict['train_steps']

train_spec, eval_specs = model_lib.create_train_and_eval_specs(
        train_input_fn,
        eval_input_fns,
        eval_on_train_input_fn,
        predict_input_fn,
        train_steps,
        eval_on_train_data=False)
tf.estimator.train_and_evaluate(estimator,train_spec,eval_specs[0])
```

Error I get
```
Using TensorFlow backend.
WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.
[04/14 16:53:43] tensorflow WARNING: Forced number of epochs for all eval validations to be 1.
INFO:tensorflow:Maybe overwriting train_steps: 100
[04/14 16:53:43] tensorflow INFO: Maybe overwriting train_steps: 100
INFO:tensorflow:Maybe overwriting use_bfloat16: False
[04/14 16:53:43] tensorflow INFO: Maybe overwriting use_bfloat16: False
INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: 1
[04/14 16:53:43] tensorflow INFO: Maybe overwriting sample_1_of_n_eval_examples: 1
INFO:tensorflow:Maybe overwriting eval_num_epochs: 1
[04/14 16:53:43] tensorflow INFO: Maybe overwriting eval_num_epochs: 1
INFO:tensorflow:Maybe overwriting load_pretrained: True
[04/14 16:53:43] tensorflow INFO: Maybe overwriting load_pretrained: True
INFO:tensorflow:Ignoring config override key: load_pretrained
[04/14 16:53:43] tensorflow INFO: Ignoring config override key: load_pretrained
WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.
[04/14 16:53:43] tensorflow WARNING: Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.
INFO:tensorflow:create_estimator_and_inputs: use_tpu False, export_to_tpu False
[04/14 16:53:43] tensorflow INFO: create_estimator_and_inputs: use_tpu False, export_to_tpu False
INFO:tensorflow:Using config: {'_model_dir': '/content/drive/MyDrive/Tensorflow/models/research/faster_rcnn_inception_v2_coco_2018_01_28_training/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true
graph_options {
  rewrite_options {
    meta_optimizer_iterations: ONE
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f6e89f30590>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
[04/14 16:53:43] tensorflow INFO: Using config: {'_model_dir': '/content/drive/MyDrive/Tensorflow/models/research/faster_rcnn_inception_v2_coco_2018_01_28_training/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true
graph_options {
  rewrite_options {
    meta_optimizer_iterations: ONE
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f6e89f30590>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}
WARNING:tensorflow:Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7f6e89f2f050>) includes params argument, but params are not passed to Estimator.
[04/14 16:53:43] tensorflow WARNING: Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7f6e89f2f050>) includes params argument, but params are not passed to Estimator.
INFO:tensorflow:Not using Distribute Coordinator.
[04/14 16:53:43] tensorflow INFO: Not using Distribute Coordinator.
INFO:tensorflow:Running training and evaluation locally (non-distributed).
[04/14 16:53:43] tensorflow INFO: Running training and evaluation locally (non-distributed).
INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.
[04/14 16:53:43] tensorflow INFO: Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.
WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
[04/14 16:53:43] tensorflow WARNING: From /tensorflow-1.15.2/python3.7/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.
Instructions for updating:
Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.
INFO:tensorflow:Reading unweighted datasets: ['/content/drive/MyDrive/Tensorflow/dataset/train.record']
[04/14 16:53:43] tensorflow INFO: Reading unweighted datasets: ['/content/drive/MyDrive/Tensorflow/dataset/train.record']
INFO:tensorflow:Reading record datasets for input file: ['/content/drive/MyDrive/Tensorflow/dataset/train.record']
[04/14 16:53:43] tensorflow INFO: Reading record datasets for input file: ['/content/drive/MyDrive/Tensorflow/dataset/train.record']
INFO:tensorflow:Number of filenames to read: 1
[04/14 16:53:43] tensorflow INFO: Number of filenames to read: 1
WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.
[04/14 16:53:43] tensorflow WARNING: num_readers has been reduced to 1 to match input file shards.
WARNING:tensorflow:From /content/drive/MyDrive/Tensorflow/models/research/object_detection/builders/dataset_builder.py:104: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
[04/14 16:53:43] tensorflow WARNING: From /content/drive/MyDrive/Tensorflow/models/research/object_detection/builders/dataset_builder.py:104: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.
WARNING:tensorflow:From /content/drive/MyDrive/Tensorflow/models/research/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.map()
[04/14 16:53:43] tensorflow WARNING: From /content/drive/MyDrive/Tensorflow/models/research/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.map()
WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f6e89f3fc10>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'
[04/14 16:53:43] tensorflow WARNING: Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f6e89f3fc10>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'
WARNING: Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7f6e89f3fc10>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Index'
---------------------------------------------------------------------------
NotImplementedError                       Traceback (most recent call last)
[<ipython-input-11-ab0734737a9e>](https://localhost:8080/#) in <module>()
     39         train_steps,
     40         eval_on_train_data=False)
---> 41 tf.estimator.train_and_evaluate(estimator,train_spec,eval_specs[0])

22 frames
[/tensorflow-1.15.2/python3.7/tensorflow_core/python/autograph/impl/api.py](https://localhost:8080/#) in wrapper(*args, **kwargs)
    235       except Exception as e:  # pylint:disable=broad-except
    236         if hasattr(e, 'ag_error_metadata'):
--> 237           raise e.ag_error_metadata.to_exception(e)
    238         else:
    239           raise

NotImplementedError: in converted code:

    /content/drive/MyDrive/Tensorflow/models/research/object_detection/data_decoders/tf_example_decoder.py:580 decode
        default_groundtruth_weights)
    /tensorflow-1.15.2/python3.7/tensorflow_core/python/util/deprecation.py:507 new_func
        return func(*args, **kwargs)
    /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/control_flow_ops.py:1235 cond
        orig_res_f, res_f = context_f.BuildCondBranch(false_fn)
    /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/control_flow_ops.py:1061 BuildCondBranch
        original_result = fn()
    /content/drive/MyDrive/Tensorflow/models/research/object_detection/data_decoders/tf_example_decoder.py:573 default_groundtruth_weights
        dtype=tf.float32)
    /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/array_ops.py:2560 ones
        output = _constant_if_small(one, shape, dtype, name)
    /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/array_ops.py:2295 _constant_if_small
        if np.prod(shape) < 1000:
    <__array_function__ internals>:6 prod
        
    /usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:3052 prod
        keepdims=keepdims, initial=initial, where=where)
    /usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:86 _wrapreduction
        return ufunc.reduce(obj, axis, dtype, out, **passkwargs)
    /tensorflow-1.15.2/python3.7/tensorflow_core/python/framework/ops.py:736 __array__
        "" array."".format(self.name))

    NotImplementedError: Cannot convert a symbolic Tensor (cond_2/strided_slice:0) to a numpy array.
```
 What is wrong here?
"
55624,Build TFLite in c++ using cmake for GPU,"Hello! 
I am struggling with building my project files in c++ using cmake. My setup is folloging:

- tensorflow lite installed using bazel (created a .so file)
- CMakeLists as below
- building using ""make""-commad in a build folder

````
cmake_minimum_required(VERSION 3.17)

project(TFLite)

set(CMAKE_CXX_STANDARD 14)

find_package(OpenCV REQUIRED)
include_directories(${OpenCV_INCLUDE_DIRS})

include_directories(${CMAKE_CURRENT_SOURCE_DIR}/../tflite-dist/include/)

set(TIME TFLiteTimeit)
set(TIMEGPU TFLiteTimeitGPU)

add_executable(${TIME} tflite_timeit.cpp)
add_executable(${TIMEGPU} tflite_timeit_gpu.cpp)

add_library(tensorflowlite SHARED IMPORTED)
set_property(TARGET tensorflowlite PROPERTY IMPORTED_LOCATION ${CMAKE_CURRENT_SOURCE_DIR}/../tflite-dist/libs/linux_x64/libtensorflowlite.so)

target_link_libraries(${TIME} tensorflowlite ${OpenCV_LIBS})
target_link_libraries(${TIMEGPU} tensorflowlite ${OpenCV_LIBS})
````

TFLiteTimeit works but not TFLiteTimeitGPU since it also includes following in the c++ code:
````
TfLiteGpuDelegateOptionsV2 gpu_options = TfLiteGpuDelegateOptionsV2Default();

  auto* delegate = TfLiteGpuDelegateV2Create(&gpu_options);
  if (interpreter->ModifyGraphWithDelegate(delegate) != kTfLiteOk) {
    std::cout << ""Fail"" << std::endl;
    return -1;
  }
````
Error i get when i try to build the file:
````
/usr/bin/ld: CMakeFiles/TFLiteMemoryGPY.dir/tflite_mem_gpu.cpp.o: in function `main':
tflite_mem_gpu.cpp:(.text+0x31a): undefined reference to `TfLiteGpuDelegateOptionsV2Default'
/usr/bin/ld: tflite_mem_gpu.cpp:(.text+0x329): undefined reference to `TfLiteGpuDelegateV2Create'
collect2: error: ld returned 1 exit status
make[2]: *** [CMakeFiles/TFLiteMemoryGPY.dir/build.make:146: TFLiteMemoryGPY] Error 1
make[1]: *** [CMakeFiles/Makefile2:93: CMakeFiles/TFLiteMemoryGPY.dir/all] Error 2
make: *** [Makefile:91: all] Error 2
````

My question is: what do I need to add to be able to run the code with GPU-delegates? (if I want to have the same setup)"
55623,fit() with generator and multiprocessing leaks sockets/files,"**System information**
- Have I written custom code - yes
- OS Platform and Distribution - Linux CentOS7
- TensorFlow installed from binary
- TensorFlow version 2.5.0
- Python version: 3.8
- 
**Describe the current behavior**

If I run model.fit() with a generator in a loop, for a long time, I eventually get `OSError: [Errno 24] Too many open files`.

**Describe the expected behavior**

Run stably forever.

The actual code is on an offline machine, but this is the basic idea:

```
while True:
   model.fit(mySeqGen(xx), ..., use_multiprocessing=True, workers=8)
   <stuff>
   model.save_weights(fname)
   gc.collect()
```
This will run for a long time, but eventually it will generate the error every iteration.  The stack trace is all about ""python3.8/multiprocessing/..."" so I'm sure it's not related to actual files, but rather sockets or whatever the multiprocessor generates.  I thought the `gc.collect()` would solve the problem but does not appear to do so, or it can't keep up.  Each loop iteration takes about a minute as I have it configured now.  Note also that the seqGen is a wrapper around a simulator and does not go to the file system."
55622,tensorflow 2.8 distributed training for neural network model (designed by subclass) cannot improve the training runtime on multicore CPUs,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no (the code is too long)
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu (18.04.6)
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: no
- TensorFlow installed from (source or binary): pip install tensorflow==2.8.0
- TensorFlow version (use command below): 2.8.0
- Python version: 3.7.6
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source): 
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A

**Describe the current behavior**

I am trying to train a neural network model built by tf2.8 and keras 2.8.
I would like to train the model with distributed training on multiple CPUs (e.g. EC2 m4.4 with 16 cpu cores) to improve the training performance.
I am using [MirroredStrategy](https://www.tensorflow.org/api_docs/python/tf/distribute/MirroredStrategy).
I am following the example at https://www.tensorflow.org/tutorials/distribute/keras
and https://www.tensorflow.org/tutorials/distribute/custom_training
My neural network model is built by subclass (not functional API) of TF2.8 and keras.

But, the training run time  (50 mins per epoch) is not improved significantly compared with non-distributed training (65 mins per epoch) on EC2 m4.4 (16 cpu cores). During the training process, most cores are idle or have very low utilizations (< 5%).
I also got a warning at the end of each epoch:     

**WARNING:tensorflow:Using MirroredStrategy eagerly has significant overhead currently. We will be working on improving this in the future, but for now please wrap `call_for_each_replica` or `experimental_run` or `run` inside a tf.function to get the best performance.**

 But, in my model, there are no ""call_for_each_replica"", ""experimental_run"" and ""run"". 
There are only 

     with mirroredStrategy.scope():
         class model(keras.model):
                 def __init__(self):
                      self.subclass_model1 = model1()
                      self.subclass_model2 = model2() 

                 def  call(self, input, training=True):
                      # call self.subclass_model1  and self.subclass_model2 to run the whole model
      with mirroredStrategy.scope():
          model.compile()
          model.fit()

Please let me know how to improve the training runtime ? 

**Describe the expected behavior**
 The distributed training runtime should be improved greatly compared with non-distributed training. 

"
55621,Build issue r2.6 with Cuda Compatibility 3.0,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): source
- TensorFlow version: 2.6.3
- Python version: 3.7
- Installed using virtualenv? pip? conda?: No
- Bazel version (if compiling from source): 3.7.2
- GCC/Compiler version (if compiling from source): MSVC2019
- CUDA/cuDNN version: 10.1/7.6
- GPU model and memory: Nvidia Quadro K1100M 2GB

**Describe the problem**

Hi,
I'm trying to build Tensorflow 2.6.3 from source on Windows, to support Cuda Compatibility 3.0.`
I follow this procedure [53062](https://github.com/tensorflow/tensorflow/issues/53062), but after few tries i continue to get this error during the compiling:

> Starting local Bazel server and connecting to it...
INFO: Options provided by the client:
  Inherited 'common' options: --isatty=1 --terminal_columns=146
INFO: Reading rc options for 'build' from c:\users\priva\tensorflow\.bazelrc:
  Inherited 'common' options: --experimental_repo_remote_exec
INFO: Options provided by the client:
  'build' options: --python_path=C:/Users/priva/AppData/Local/Programs/Python/Python37/python.exe
INFO: Reading rc options for 'build' from c:\users\priva\tensorflow\.bazelrc:
  'build' options: --define framework_shared_object=true --java_toolchain=@tf_toolchains//toolchains/java:tf_java_toolchain --host_java_toolchain=@tf_toolchains//toolchains/java:tf_java_toolchain --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --enable_platform_specific_config --define=with_xla_support=true --config=short_logs --config=v2 --define=no_aws_support=true --define=no_hdfs_support=true
INFO: Reading rc options for 'build' from c:\users\priva\tensorflow\.tf_configure.bazelrc:
  'build' options: --action_env PYTHON_BIN_PATH=C:/Users/priva/AppData/Local/Programs/Python/Python37/python.exe --action_env PYTHON_LIB_PATH=C:/Users/priva/AppData/Local/Programs/Python/Python37/lib/site-packages --python_path=C:/Users/priva/AppData/Local/Programs/Python/Python37/python.exe --action_env CUDA_TOOLKIT_PATH=C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v10.1 --action_env TF_CUDA_COMPUTE_CAPABILITIES=3.0 --config=cuda --define=with_xla_support=false --action_env TF_ENABLE_XLA=0 --copt=/d2ReducedOptimizeHugeFunctions --host_copt=/d2ReducedOptimizeHugeFunctionsINFO: Found applicable config definition build:short_logs in file c:\users\priva\tensorflow\.bazelrc: --output_filter=DONT_MATCH_ANYTHING
INFO: Found applicable config definition build:v2 in file c:\users\priva\tensorflow\.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1
INFO: Found applicable config definition build:cuda in file c:\users\priva\tensorflow\.bazelrc: --repo_env TF_NEED_CUDA=1 --crosstool_top=@local_config_cuda//crosstool:toolchain --@local_config_cuda//:enable_cuda
INFO: Found applicable config definition build:windows in file c:\users\priva\tensorflow\.bazelrc: --copt=/W0 --copt=/D_USE_MATH_DEFINES --host_copt=/D_USE_MATH_DEFINES --cxxopt=/std:c++14 --host_cxxopt=/std:c++14 --config=monolithic --copt=-DWIN32_LEAN_AND_MEAN --host_copt=-DWIN32_LEAN_AND_MEAN --copt=-DNOGDI --host_copt=-DNOGDI --copt=/experimental:preprocessor --host_copt=/experimental:preprocessor --linkopt=/DEBUG --host_linkopt=/DEBUG --linkopt=/OPT:REF --host_linkopt=/OPT:REF --linkopt=/OPT:ICF --host_linkopt=/OPT:ICF --verbose_failures --distinct_host_configuration=falseINFO: Found applicable config definition build:monolithic in file c:\users\priva\tensorflow\.bazelrc: --define framework_shared_object=false
DEBUG: C:/users/priva/_bazel_priva/5lyc5377/external/tf_runtime/third_party/cuda/dependencies.bzl:51:10: The following command will download NVIDIA proprietary software. By using the software you agree to comply with the terms of the license agreement that accompanies the software. If you do not agree to the terms of the license agreement, do not use the software.
DEBUG: Rule 'io_bazel_rules_docker' indicated that a canonical reproducible form can be obtained by modifying arguments shallow_since = ""1556410077 -0400""
DEBUG: Repository io_bazel_rules_docker instantiated at:
  C:/users/priva/tensorflow/WORKSPACE:23:14: in <toplevel>
  C:/users/priva/tensorflow/tensorflow/workspace0.bzl:108:34: in workspace
  C:/users/priva/_bazel_priva/5lyc5377/external/bazel_toolchains/repositories/repositories.bzl:37:23: in repositories
Repository rule git_repository defined at:
  C:/users/priva/_bazel_priva/5lyc5377/external/bazel_tools/tools/build_defs/repo/git.bzl:199:33: in <toplevel>
INFO: Analyzed target //tensorflow/tools/pip_package:build_pip_package (441 packages loaded, 32225 targets configured).
INFO: Found 1 target...
ERROR: C:/users/priva/tensorflow/tensorflow/core/kernels/BUILD:1222:18: C++ compilation of rule '//tensorflow/core/kernels:inplace_ops_gpu' failed (Exit 1): python.exe failed: error executing command
  cd C:/users/priva/_bazel_priva/5lyc5377/execroot/org_tensorflow
  SET CUDA_TOOLKIT_PATH=C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v10.1
    SET INCLUDE=C:\Program Files (x86)\Microsoft Visual Studio\2019\BuildTools\VC\Tools\MSVC\14.29.30133\include;C:\Program Files (x86)\Windows Kits\NETFXSDK\4.8\include\um;C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\ucrt;C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\shared;C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\um;C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\winrt;C:\Program Files (x86)\Windows Kits\10\include\10.0.19041.0\cppwinrt
    SET LIB=C:\Program Files (x86)\Microsoft Visual Studio\2019\BuildTools\VC\Tools\MSVC\14.29.30133\lib\x64;C:\Program Files (x86)\Windows Kits\NETFXSDK\4.8\lib\um\x64;C:\Program Files (x86)\Windows Kits\10\lib\10.0.19041.0\ucrt\x64;C:\Program Files (x86)\Windows Kits\10\lib\10.0.19041.0\um\x64
    SET PATH=C:\Program Files (x86)\Microsoft Visual Studio\2019\BuildTools\VC\Tools\MSVC\14.29.30133\bin\HostX64\x64;C:\Program Files (x86)\Microsoft Visual Studio\2019\BuildTools\Common7\IDE\VC\VCPackages;C:\Program Files (x86)\Microsoft Visual Studio\2019\BuildTools\Common7\IDE\CommonExtensions\Microsoft\TestWindow;C:\Program Files (x86)\Microsoft Visual Studio\2019\BuildTools\Common7\IDE\CommonExtensions\Microsoft\TeamFoundation\Team Explorer;C:\Program Files (x86)\Microsoft Visual Studio\2019\BuildTools\MSBuild\Current\bin\Roslyn;C:\Program Files (x86)\Microsoft SDKs\Windows\v10.0A\bin\NETFX 4.8 Tools\x64\;C:\Program Files (x86)\Microsoft Visual Studio\2019\BuildTools\Common7\Tools\devinit;C:\Program Files (x86)\Windows Kits\10\bin\10.0.19041.0\x64;C:\Program Files (x86)\Windows Kits\10\bin\x64;C:\Program Files (x86)\Microsoft Visual Studio\2019\BuildTools\\MSBuild\Current\Bin;C:\WINDOWS\Microsoft.NET\Framework64\v4.0.30319;C:\Program Files (x86)\Microsoft Visual Studio\2019\BuildTools\Common7\IDE\;C:\Program Files (x86)\Microsoft Visual Studio\2019\BuildTools\Common7\Tools\;;C:\WINDOWS\system32;C:\Program Files (x86)\Microsoft Visual Studio\2019\BuildTools\Common7\IDE\CommonExtensions\Microsoft\CMake\CMake\bin;C:\Program Files (x86)\Microsoft Visual Studio\2019\BuildTools\Common7\IDE\CommonExtensions\Microsoft\CMake\Ninja
    SET PWD=/proc/self/cwd
    SET PYTHON_BIN_PATH=C:/Users/priva/AppData/Local/Programs/Python/Python37/python.exe
    SET PYTHON_LIB_PATH=C:/Users/priva/AppData/Local/Programs/Python/Python37/lib/site-packages
    SET RUNFILES_MANIFEST_ONLY=1
    SET TEMP=C:\Users\priva\AppData\Local\Temp
    SET TF2_BEHAVIOR=1
    SET TF_CUDA_COMPUTE_CAPABILITIES=3.0
    SET TF_ENABLE_XLA=0
    SET TMP=C:\Users\priva\AppData\Local\Temp
  C:/Users/priva/AppData/Local/Programs/Python/Python37/python.exe -B external/local_config_cuda/crosstool/windows/msvc_wrapper_for_nvcc.py /nologo /DCOMPILER_MSVC /DNOMINMAX /D_WIN32_WINNT=0x0600 /D_CRT_SECURE_NO_DEPRECATE /D_CRT_SECURE_NO_WARNINGS /D_SILENCE_STDEXT_HASH_DEPRECATION_WARNINGS /bigobj /Zm500 /J /Gy /GF /EHsc /wd4351 /wd4291 /wd4250 /wd4996 /I. /Ibazel-out/x64_windows-opt/bin /Iexternal/com_google_absl /Ibazel-out/x64_windows-opt/bin/external/com_google_absl /Iexternal/nsync /Ibazel-out/x64_windows-opt/bin/external/nsync /Iexternal/eigen_archive /Ibazel-out/x64_windows-opt/bin/external/eigen_archive /Iexternal/gif /Ibazel-out/x64_windows-opt/bin/external/gif /Iexternal/libjpeg_turbo /Ibazel-out/x64_windows-opt/bin/external/libjpeg_turbo /Iexternal/com_google_protobuf /Ibazel-out/x64_windows-opt/bin/external/com_google_protobuf /Iexternal/com_googlesource_code_re2 /Ibazel-out/x64_windows-opt/bin/external/com_googlesource_code_re2 /Iexternal/farmhash_archive /Ibazel-out/x64_windows-opt/bin/external/farmhash_archive /Iexternal/fft2d /Ibazel-out/x64_windows-opt/bin/external/fft2d /Iexternal/highwayhash /Ibazel-out/x64_windows-opt/bin/external/highwayhash /Iexternal/zlib /Ibazel-out/x64_windows-opt/bin/external/zlib /Iexternal/double_conversion /Ibazel-out/x64_windows-opt/bin/external/double_conversion /Iexternal/snappy /Ibazel-out/x64_windows-opt/bin/external/snappy /Iexternal/local_config_cuda /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda /Iexternal/local_config_rocm /Ibazel-out/x64_windows-opt/bin/external/local_config_rocm /Iexternal/local_config_tensorrt /Ibazel-out/x64_windows-opt/bin/external/local_config_tensorrt /Iexternal/cudnn_frontend_archive /Ibazel-out/x64_windows-opt/bin/external/cudnn_frontend_archive /Iexternal/mkl_dnn_v1 /Ibazel-out/x64_windows-opt/bin/external/mkl_dnn_v1 /Iexternal/curl /Ibazel-out/x64_windows-opt/bin/external/curl /Iexternal/boringssl /Ibazel-out/x64_windows-opt/bin/external/boringssl /Iexternal/jsoncpp_git /Ibazel-out/x64_windows-opt/bin/external/jsoncpp_git /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda/_virtual_includes/cuda_headers_virtual /Ibazel-out/x64_windows-opt/bin/external/local_config_tensorrt/_virtual_includes/tensorrt_headers /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda/_virtual_includes/cudnn_header /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda/_virtual_includes/cublas_headers_virtual /Ibazel-out/x64_windows-opt/bin/external/cudnn_frontend_archive/_virtual_includes/cudnn_frontend /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda/_virtual_includes/cufft_headers_virtual /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda/_virtual_includes/curand_headers_virtual /Iexternal/nsync/public /Ibazel-out/x64_windows-opt/bin/external/nsync/public /Ithird_party/eigen3/mkl_include /Ibazel-out/x64_windows-opt/bin/third_party/eigen3/mkl_include /Iexternal/eigen_archive /Ibazel-out/x64_windows-opt/bin/external/eigen_archive /Iexternal/gif /Ibazel-out/x64_windows-opt/bin/external/gif /Iexternal/gif/windows /Ibazel-out/x64_windows-opt/bin/external/gif/windows /Iexternal/com_google_protobuf/src /Ibazel-out/x64_windows-opt/bin/external/com_google_protobuf/src /Iexternal/farmhash_archive/src /Ibazel-out/x64_windows-opt/bin/external/farmhash_archive/src /Iexternal/zlib /Ibazel-out/x64_windows-opt/bin/external/zlib /Iexternal/double_conversion /Ibazel-out/x64_windows-opt/bin/external/double_conversion /Iexternal/local_config_cuda/cuda /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda /Iexternal/local_config_cuda/cuda/cuda/include /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda/cuda/include /Iexternal/local_config_rocm/rocm /Ibazel-out/x64_windows-opt/bin/external/local_config_rocm/rocm /Iexternal/local_config_rocm/rocm/rocm/include /Ibazel-out/x64_windows-opt/bin/external/local_config_rocm/rocm/rocm/include /Iexternal/local_config_rocm/rocm/rocm/include/rocrand /Ibazel-out/x64_windows-opt/bin/external/local_config_rocm/rocm/rocm/include/rocrand /Iexternal/local_config_rocm/rocm/rocm/include/roctracer /Ibazel-out/x64_windows-opt/bin/external/local_config_rocm/rocm/rocm/include/roctracer /Iexternal/local_config_cuda/cuda/cublas/include /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda/cublas/include /Iexternal/local_config_cuda/cuda/cufft/include /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda/cufft/include /Iexternal/local_config_cuda/cuda/curand/include /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda/curand/include /Iexternal/mkl_dnn_v1/include /Ibazel-out/x64_windows-opt/bin/external/mkl_dnn_v1/include /Iexternal/mkl_dnn_v1/src /Ibazel-out/x64_windows-opt/bin/external/mkl_dnn_v1/src /Iexternal/mkl_dnn_v1/src/common /Ibazel-out/x64_windows-opt/bin/external/mkl_dnn_v1/src/common /Iexternal/mkl_dnn_v1/src/common/ittnotify /Ibazel-out/x64_windows-opt/bin/external/mkl_dnn_v1/src/common/ittnotify /Iexternal/mkl_dnn_v1/src/cpu /Ibazel-out/x64_windows-opt/bin/external/mkl_dnn_v1/src/cpu /Iexternal/mkl_dnn_v1/src/cpu/gemm /Ibazel-out/x64_windows-opt/bin/external/mkl_dnn_v1/src/cpu/gemm /Iexternal/mkl_dnn_v1/src/cpu/x64/xbyak /Ibazel-out/x64_windows-opt/bin/external/mkl_dnn_v1/src/cpu/x64/xbyak /Iexternal/curl/include /Ibazel-out/x64_windows-opt/bin/external/curl/include /Iexternal/boringssl/src/include /Ibazel-out/x64_windows-opt/bin/external/boringssl/src/include /Iexternal/jsoncpp_git/include /Ibazel-out/x64_windows-opt/bin/external/jsoncpp_git/include /DTENSORFLOW_USE_CUSTOM_CONTRACTION_KERNEL /DTENSORFLOW_USE_MKLDNN_CONTRACTION_KERNEL /DCURL_STATICLIB /DTF_USE_SNAPPY /DEIGEN_MPL2_ONLY /DEIGEN_MAX_ALIGN_BYTES=64 /showIncludes /MD /O2 /DNDEBUG /W0 /D_USE_MATH_DEFINES -DWIN32_LEAN_AND_MEAN -DNOGDI /experimental:preprocessor /d2ReducedOptimizeHugeFunctions /std:c++14 -x cuda -DGOOGLE_CUDA=1 -Xcuda-fatbinary=--compress-all --no-cuda-include-ptx=all --cuda-include-ptx=sm_30 --cuda-gpu-arch=sm_30 -DGOOGLE_CUDA=1 -DTENSORFLOW_USE_NVCC=1 -DINTEL_MKL -DTENSORFLOW_MONOLITHIC_BUILD /DPLATFORM_WINDOWS /DEIGEN_HAS_C99_MATH /DTENSORFLOW_USE_EIGEN_THREADPOOL /DEIGEN_AVOID_STL_ARRAY /Iexternal/gemmlowp /wd4018 /wd4577 /DNOGDI /DTF_COMPILE_LIBRARY -nvcc_options=relaxed-constexpr -nvcc_options=ftz=true /Fobazel-out/x64_windows-opt/bin/tensorflow/core/kernels/_objs/inplace_ops_gpu/inplace_ops_functor_gpu.cu.obj /c tensorflow/core/kernels/inplace_ops_functor_gpu.cu.cc
Execution platform: @local_execution_config_platform//:platform
cl : warning della riga di comando D9035 : l'opzione 'experimental:preprocessor' è deprecata e verrà rimossa in una futura versione
cl : warning della riga di comando D9036 : utilizzare 'Zc:preprocessor' invece di 'experimental:preprocessor'
cl : warning della riga di comando D9002 : l'opzione sconosciuta '--no-cuda-include-ptx=all' verrà ignorata
cl : warning della riga di comando D9002 : l'opzione sconosciuta '--cuda-include-ptx=sm_30' verrà ignorata
cl : warning della riga di comando D9002 : l'opzione sconosciuta '--cuda-gpu-arch=sm_30' verrà ignorata
C:\users\priva\_bazel_priva\5lyc5377\execroot\org_tensorflow\external\eigen_archive\unsupported\Eigen\CXX11\src/Tensor/TensorBlock.h(245): warning: invalid friend declaration
C:\users\priva\_bazel_priva\5lyc5377\execroot\org_tensorflow\external\eigen_archive\unsupported\Eigen\CXX11\src/Tensor/TensorBlock.h(709): warning: invalid friend declaration
external/com_google_absl\absl/strings/string_view.h(337): warning: expression has no effect
external/com_google_absl\absl/strings/string_view.h(347): warning: expression has no effect
external/com_google_absl\absl/strings/string_view.h(529): warning: expression has no effect
external/com_google_protobuf/src\google/protobuf/map.h(1028): warning: invalid friend declaration
external/com_google_absl\absl/types/internal/span.h(38): error: incomplete type is not allowed
          detected during instantiation of ""absl::lts_20210324::span_internal::GetDataImpl"" based on template argument <tensorflow::TensorShapeProto>
.\tensorflow/core/framework/tensor_shape.h(376): here
.\tensorflow/core/lib/gtl/flatmap.h(157): warning: invalid friend declaration
.\tensorflow/core/platform/file_system.h(574): warning: overloaded virtual function ""tensorflow::FileSystem::FilesExist"" is only partially overridden in class ""tensorflow::WrappedFileSystem""
.\tensorflow/core/platform/file_system.h(574): warning: overloaded virtual function ""tensorflow::FileSystem::CreateDir"" is only partially overridden in class ""tensorflow::WrappedFileSystem""
.\tensorflow/core/platform/env.h(495): warning: overloaded virtual function ""tensorflow::Env::RegisterFileSystem"" is only partially overridden in class ""tensorflow::EnvWrapper""
external/com_google_absl\absl/types/optional.h(428): warning: expression has no effect
          detected during instantiation of ""const T &absl::lts_20210324::optional<T>::operator*() const & [with T=stream_executor::dnn::AlgorithmDesc]""
.\tensorflow/stream_executor/dnn.h(817): here
external/com_google_absl\absl/types/optional.h(428): warning: expression has no effect
          detected during instantiation of ""const T &absl::lts_20210324::optional<T>::operator*() const & [with T=size_t]""
.\tensorflow/stream_executor/dnn.h(876): here
1 error detected in the compilation of ""C:/Users/priva/AppData/Local/Temp/nvcc_inter_files_tmp_dir/tmpcg3nm8rj/inplace_ops_functor_gpu.cu.cpp1.ii"".
Target //tensorflow/tools/pip_package:build_pip_package failed to build
INFO: Elapsed time: 1302.308s, Critical Path: 224.15s
INFO: 4180 processes: 2005 internal, 2175 local.
FAILED: Build did NOT complete successfully

Is this a problem related with the MSVC compiler or something else?
Thanks for the support."
55620,No module named 'tensorflow.contrib.framework.ops',"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution: win 10 
- TensorFlow installed from (source or binary): I don't remember....
- TensorFlow version: 1.15.0
- Python version: 3.6
- Installed using virtualenv? pip? conda?: pip
- Bazel version (if compiling from source): 0.26.1
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:10.0/7.4
- GPU model and memory: MX330



**Describe the problem**
When i run the train_ssd_network.py in ssd training program there was an error:
=======================================================

 from tensorflow.contrib.framework.ops import variables as contrib_variables

ModuleNotFoundError: No module named 'tensorflow.contrib.framework.ops'

=====================================================


The codes which caused problem are in metrics.py and these are part of the codes:
-----------------------------------------------------------------------------------------
import tensorflow as tf
import numpy as np

_**from tensorflow.contrib.framework.ops import variables as contrib_variables**_
from tensorflow.python.framework import dtypes
from tensorflow.python.framework import ops
from tensorflow.python.ops import array_ops
from tensorflow.python.ops import math_ops
from tensorflow.python.ops import nn
from tensorflow.python.ops import state_ops
from tensorflow.python.ops import variable_scope
from tensorflow.python.ops import variables

from tf_extended import math as tfe_math
----------------------------------------------------------------------------------------------
**Provide the exact sequence of commands / steps that you executed before running into the problem**


**Any other info / logs**

"
55618,Android - abort crash.,"I'm having this crash on android 10.

**Dependencies**

implementation 'org.tensorflow:tensorflow-lite:2.8.0'
implementation 'org.tensorflow:tensorflow-lite-gpu:2.8.0'

Stack Trace:

abort

pid: 0, tid: 0 >>> com.humbbles.imagenes <<<

backtrace:
  #00  pc 000000000005ec46  /apex/com.android.runtime/lib/bionic/libc.so (abort+166)
  #00  pc 000000000003606d  /system/lib/libc++.so (abort_message+88)
  #00  pc 00000000000361e9  /system/lib/libc++.so (demangling_terminate_handler()+160)
  #00  pc 0000000000044ecb  /system/lib/libc++.so (std::__terminate(void (*)())+2)
  #00  pc 00000000000446cf  /system/lib/libc++.so (__cxxabiv1::failed_throw(__cxxabiv1::__cxa_exception*)+12)
  #00  pc 0000000000044631  /system/lib/libc++.so (__cxa_throw+72)
  #00  pc 000000000007fe5f  /system/lib/libc++.so (std::__1::__throw_system_error(int, char const*)+86)
  #00  pc 000000000000e645  /system/lib/libEGL.so (android::egl_cache_t::setBlob(void const*, long, void const*, long)+228)
  #00  pc 000000000000e4fd  /system/lib/libEGL.so (android::setBlob(void const*, long, void const*, long)+20)
  #00  pc 0000000000141aa8  /vendor/lib/egl/libGLES_mali.so
  #00  pc 0000000000141ddc  /vendor/lib/egl/libGLES_mali.so
  #00  pc 00000000003cabe8  /vendor/lib/egl/libGLES_mali.so
  #00  pc 0000000002bfc13b  /data/app/com.google.android.trichromelibrary_469209830-OMAU-ijYS8rmP_RtBvJXIg==/base.apk!libmonochrome.so (offset 0x664000)
  #00  pc 0000000002bfbe99  /data/app/com.google.android.trichromelibrary_469209830-OMAU-ijYS8rmP_RtBvJXIg==/base.apk!libmonochrome.so (offset 0x664000)
  #00  pc 0000000002bfbd59  /data/app/com.google.android.trichromelibrary_469209830-OMAU-ijYS8rmP_RtBvJXIg==/base.apk!libmonochrome.so (offset 0x664000)
  #00  pc 0000000002bfc91d  /data/app/com.google.android.trichromelibrary_469209830-OMAU-ijYS8rmP_RtBvJXIg==/base.apk!libmonochrome.so (offset 0x664000)
  #00  pc 0000000002bfc511  /data/app/com.google.android.trichromelibrary_469209830-OMAU-ijYS8rmP_RtBvJXIg==/base.apk!libmonochrome.so (offset 0x664000)
  #00  pc 0000000002bfc1e1  /data/app/com.google.android.trichromelibrary_469209830-OMAU-ijYS8rmP_RtBvJXIg==/base.apk!libmonochrome.so (offset 0x664000)
  #00  pc 0000000002bfb1a1  /data/app/com.google.android.trichromelibrary_469209830-OMAU-ijYS8rmP_RtBvJXIg==/base.apk!libmonochrome.so (offset 0x664000)
  #00  pc 0000000002b50861  /data/app/com.google.android.trichromelibrary_469209830-OMAU-ijYS8rmP_RtBvJXIg==/base.apk!libmonochrome.so (offset 0x664000)
  #00  pc 0000000002b51477  /data/app/com.google.android.trichromelibrary_469209830-OMAU-ijYS8rmP_RtBvJXIg==/base.apk!libmonochrome.so (offset 0x664000)
  #00  pc 0000000002b51203  /data/app/com.google.android.trichromelibrary_469209830-OMAU-ijYS8rmP_RtBvJXIg==/base.apk!libmonochrome.so (offset 0x664000)
  #00  pc 0000000002b51095  /data/app/com.google.android.trichromelibrary_469209830-OMAU-ijYS8rmP_RtBvJXIg==/base.apk!libmonochrome.so (offset 0x664000)
  #00  pc 0000000002b5100d  /data/app/com.google.android.trichromelibrary_469209830-OMAU-ijYS8rmP_RtBvJXIg==/base.apk!libmonochrome.so (offset 0x664000)
  #00  pc 0000000002b606c1  /data/app/com.google.android.trichromelibrary_469209830-OMAU-ijYS8rmP_RtBvJXIg==/base.apk!libmonochrome.so (offset 0x664000)
  #00  pc 00000000020ca769  /data/app/com.google.android.trichromelibrary_469209830-OMAU-ijYS8rmP_RtBvJXIg==/base.apk!libmonochrome.so (offset 0x664000)
  #00  pc 00000000020c88c7  /data/app/com.google.android.trichromelibrary_469209830-OMAU-ijYS8rmP_RtBvJXIg==/base.apk!libmonochrome.so (offset 0x664000)
  #00  pc 0000000001796063  /data/app/com.google.android.trichromelibrary_469209830-OMAU-ijYS8rmP_RtBvJXIg==/base.apk!libmonochrome.so (offset 0x664000)
  #00  pc 0000000002061309  /data/app/com.google.android.trichromelibrary_469209830-OMAU-ijYS8rmP_RtBvJXIg==/base.apk!libmonochrome.so (offset 0x664000)
  #00  pc 000000000206109d  /data/app/com.google.android.trichromelibrary_469209830-OMAU-ijYS8rmP_RtBvJXIg==/base.apk!libmonochrome.so (offset 0x664000)
  #00  pc 0000000002060e01  /data/app/com.google.android.trichromelibrary_469209830-OMAU-ijYS8rmP_RtBvJXIg==/base.apk!libmonochrome.so (offset 0x664000)
  #00  pc 0000000002060d1f  /data/app/com.google.android.trichromelibrary_469209830-OMAU-ijYS8rmP_RtBvJXIg==/base.apk!libmonochrome.so (offset 0x664000)
  #00  pc 00000000020df89d  /data/app/com.google.android.trichromelibrary_469209830-OMAU-ijYS8rmP_RtBvJXIg==/base.apk!libmonochrome.so (offset 0x664000)
  #00  pc 00000000020df0b7  /data/app/com.google.android.trichromelibrary_469209830-OMAU-ijYS8rmP_RtBvJXIg==/base.apk!libmonochrome.so (offset 0x664000)
  #00  pc 00000000000a6077  /apex/com.android.runtime/lib/bionic/libc.so (__pthread_start(void*)+20)
  #00  pc 0000000000060131  /apex/com.android.runtime/lib/bionic/libc.so (__start_thread+30)"
55616,How does MultiWorkerMirroredStrategy works?,"We are training to run a distributed training on cluster with just CPUs. After reading the tutorials we choose to use tf.distribute.MultiWorkerMirroredStrategy. But there are something confusing us. It said that I need to prepare the same code on every work and this strategy will send all the model, checkpoint and dataset to every worker. **But dose It sent the data of the sample or just the index of every sample?** Do I need to prepare model, checkpoint and whole dataset on every worker? I hope that the chef worker can load all data from itself and sent what others need to every worker so that other workers don't have to prepare training data. It's not easy for us to put all data on every worker limit to  cluster using rules of our business.
We try to only load checkpoint on chef worker and the program doesn't work. We also try to load the whole dataset on chef worker and load just a part of dataset on other workers and it doesn't work."
55615,tf.io.encode png doesn't work when trying to write array to png,"Please see here.  https://colab.research.google.com/drive/1ayBIErWSDAZGJ6B_CjeqraJyMAzEWSyv?usp=sharing

I am trying to write a tensor to a png. As seen here, when I take the encoded bytes and write it a file using python, it doesn't work. Trying opening the image it gets corrupted 
When I use tf.io.write_file it works. I also tried taking a png and using tf.io_decode_png and than tf.io.encoding_png and the image string bytes differ from the original png. I am using tensorflow serving and using this png result through the rest api, where I don't have access to tf.io.wrte_file so I was wondering what encode_png does differently, than traditional png encodings.  
"
55614,[Memory Issue]: Dst tensor is not initialized,"Summary: I believe this issue is fired by Memory Issue with GPU on Tensorflow 2.8 and Tensorflow-GPU 2.8.

Configuration:
- Python 3.8.12
- GPU: NVIDIA Quadro P1000 Notebook 4Gb (InUse: ~ 3Gb)
- RAM: 16 Gb
- OS: Windows 10 Pro
Config 1: Tensorflow: 2.8 - Tensorflow-GPU: 2.8 - TF-Addons: 0.16.1 - Keras: 2.8
Config 2: Tensorflow: 2.5.x - Tensorflow-GPU: 2.5.x - TF-Addons: 0.15

Description: The following model was just a super-cheap model using only Dense, Add, and Concatenation with only 8M+ parameters, but the warning warns me about memory overflow and stop my training on PyCharm

Total behaviour: 
(Batch Size: 256)
- I have been training this model (8M+) and two heavier versions (48M+, and 55M+) on Tensorflow 2.3.x and 2.5.x but Tensorflow did not raise to me either warning and error and the model still worked fine. The model received four input with `dtype='uint8'`, totally 14930 features per vector using 256 batch size with Adam optimizer.
- But since I upgraded my Tensorflow to 2.8, this issue arised on both models, even I have pruned my model to 8M+ parameters with 13674 features per vector only (same dtype=uint8). 
- In the same code, I always used `from tensorflow.keras import ...` for both versions: 2.5- and 2.8

The memory log is displayed in PyCharm 2021.3.3
[memory_p07-15.pdf](https://github.com/tensorflow/tensorflow/files/8485684/memory_p07-15.pdf)

Behaviour Prediction: I believed this is raised in version 2.6 due to the introduction of API shifting. Please check on that. Also, the PyCharm could not track the code + autocompletion when Tensorflow >= 2.6 (It worked only with Tensorflow 2.3 - 2.5*).
* I did not try installing previous version of Tensorflow "
55610,[XLA] Different JIT compile behavior from TF2.7,"For the customized code below, I have seen such a error at runtime when xla is turned on. This does NOT appear in TF2.7.
`2022-04-13 19:49:36.873241: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at xla_ops.cc:436 : INVALID_ARGUMENT: Fail to proof the equality of two dimensions at compile time: %multiply.144 = s32[] multiply(s32[] %constant.142, s32[] %add.1), metadata={op_type=""Reshape"" op_name=""Reshape_3""} vs %add = s32[] add(s32[] %reduce.109, s32[] %constant.17)`


**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution: Ubuntu 20.04.4 LTS
- TensorFlow installed from (source or binary): binary
- TensorFlow version:2.8.0
- Python version: 3.8
- GCC/Compiler version (if compiling from source): gcc 10
- CUDA/cuDNN version: 11.6
- GPU model and memory: V100, 32G

**Standalone code to reproduce the issue**
```
import tensorflow as tf
import numpy as np
display_id_counter = tf.Variable(0, trainable=False, dtype=tf.float64)

@tf.function
def evaluation_step(x, y, predictions):
    dummy_loss = 0.9
    predictions = tf.reshape(predictions, [-1])
    predictions = tf.cast(predictions, tf.float64)
    display_ids = x
    display_ids = tf.reshape(display_ids, [-1])
    labels = tf.reshape(y, [-1])
    sorted_ids = tf.argsort(display_ids)
    display_ids = tf.gather(display_ids, indices=sorted_ids)
    predictions = tf.gather(predictions, indices=sorted_ids)
    labels = tf.gather(labels, indices=sorted_ids)
    _, display_ids_idx, display_ids_ads_count = tf.unique_with_counts(
        display_ids, out_idx=tf.int64)
    pad_length = 30 - tf.reduce_max(display_ids_ads_count)
    preds = tf.RaggedTensor.from_value_rowids(
        predictions, display_ids_idx).to_tensor()
    labels = tf.RaggedTensor.from_value_rowids(
        labels, display_ids_idx).to_tensor()
    labels_mask = tf.math.reduce_max(labels, 1)
    preds_masked = tf.boolean_mask(preds, labels_mask)
    labels_masked = tf.boolean_mask(labels, labels_mask)
    labels_masked = tf.argmax(labels_masked, axis=1, output_type=tf.int32)
    labels_masked = tf.reshape(labels_masked, [-1, 1])

    preds_masked = tf.pad(preds_masked, [(0, 0), (0, pad_length)])
    _, predictions_idx = tf.math.top_k(preds_masked, 12)
    indices = tf.math.equal(predictions_idx, labels_masked)

    shape = tf.cast(tf.shape(indices)[0], tf.float64)
    display_id_counter.assign_add(shape)

DIM = 102400
tf.config.optimizer.set_jit(True)
for step in range(200):
    pre = np.random.random((DIM, 1))
    y_tmp = np.zeros((DIM, 1), dtype=float)

    num_ones = np.random.randint(1, DIM+1, 1)
    id_one = np.random.randint(0, DIM, num_ones)
    for i in id_one:
        y_tmp[i][0] = 1.
    x_tmp = np.random.randint(0, DIM, (DIM, 1), dtype=np.int64)
    evaluation_step(x_tmp, y_tmp, pre)
```

Tracked down to commit [ac4575](https://github.com/tensorflow/tensorflow/commit/ac457560364f18f24ae506d978f2ab5f04aa501b)."
55609,tensorflow 2.8 neural network model training cannot be run as multiprocess even though the training data is created by keras.utils.Sequence ,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu (18.04.6)
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: no
- TensorFlow installed from (source or binary): pip install tensorflow==2.8.0
- TensorFlow version (use command below): 2.8.0
- Python version: 3.7.6
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source): 
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A

**Describe the current behavior**

I am trying to train a neural network model built by tf2.8 ans keras 2.8.
I would like to train the model with **""multiprocess"".** to improve the training performance.
The following url shows that only keras.utils.Sequence is supported for multiprocess.
https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit

"" ""use_multiprocessing""  Boolean. **Used for generator or [keras.utils.Sequence](https://www.tensorflow.org/api_docs/python/tf/keras/utils/Sequence) input only**. If True, use process-based threading. If unspecified, use_multiprocessing will default to False. Note that because this implementation relies on multiprocessing, you should not pass non-picklable arguments to the generator as they can't be passed easily to children processes.""

**My code (tf2.8):** 

------------------------------
```
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.utils import Sequence

class MyDataGenerator(Sequence):
    def __init__(self, train_file_paths, batch_size, train_data_size, epoch ):

        self.file_paths = train_file_paths
        self.batch_size = batch_size
        self.index_and_filename = defaultdict(str)
        self.cur_file_index = 0
        self.total_file_nums = 0
        self.num_parallel_calls = -1
        self.set_files_indices()
        self.on_epoch_end()
       
    def __len__(self):
        return 100
   
    def __getitem__(self, index):
        cur_train_file_path = self.index_and_filename[self.cur_file_index]
        features_and_labels = self.__data_create(cur_train_file_path)
        self.cur_file_index += 1
        features, labels = next(iter(features_and_labels))
        return features, labels
   
    def  on_epoch_end(self):
        self.cur_file_index = 0
        self.total_file_nums = 0
        
    def  set_files_indices(self):
        for a_file in self.file_paths:
            self.index_and_filename[self.total_file_nums] = a_file
            self.total_file_nums += 1
        
    def data_generation(self, file_path):
       
        def process_sample(input_dataset):
            features = tf.io.parse_single_example(input_dataset, [some feature names])
            labels = tf.io.parse_single_example(input_dataset, LABEL_NAME)[LABEL_NAME]
            return (features, labels)
       
        file_paths_ds = tf.data.Dataset.from_tensors(file_path)
       
        all_features_dataset = file_paths_ds.interleave(lambda x: tf.data.TFRecordDataset(x,  compression_type='GZIP'),
                                        cycle_length=10, num_parallel_calls=-1, deterministic=False)
        
        all_features_dataset = all_features_dataset.map(lambda x: process_sample(x),
                                                num_parallel_calls=-1,
                                                deterministic=False)
       
        all_features_dataset = all_features_dataset.shuffle(100)
        all_features_dataset = all_features_dataset.batch(self.batch_size, drop_remainder=True)
        all_features_dataset = all_features_dataset.cache()
        return all_features_dataset

train_data_generator = MyDataGenerator(train_data_path, 2, 10000, 2)
test_data_generator = MyDataGenerator(train_data_path, 2, 1000, 2)

model.fit(train_data_generator,
          epochs=2
          steps_per_epoch = 100,
          validation_data=test_data_generator,
          validation_steps=10,
          **workers=1,
          use_multiprocessing=False**)

```


If I run model.fit as:

```
model.fit(train_data_generator,
          epochs=2,
          steps_per_epoch = 100 ,
          validation_data=test_data_generator,
          validation_steps=10),
          workers=1,
          use_multiprocessing=False)
```

I got error: 

```
InvalidArgumentError: ValueError: Could not find callback with key=pyfunc_44 in the registry.
    Traceback (most recent call last):

   File ""lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py"", line 259, in __call__
    raise ValueError(f""Could not find callback with key={token} in the ""

    ValueError: Could not find callback with key=pyfunc_44 in the registry.

	 [[{{node EagerPyFunc}}]] [Op:IteratorGetNext]
```

------------------
If I run model.fit as:

 ```
model.fit(train_data_generator,
          epochs=2,
          steps_per_epoch = 100 ,
          validation_data=test_data_generator,
          validation_steps=10),
          workers=2,
          use_multiprocessing=True)
```

The whole training process is frozen and made no progress and no errors popped.
It seems that there is a deadlock ? 
I have also tried tf2.9, got the same error. 
Could anybody let me know what I did wrong ? 
I missed something ? 

thanks


**Describe the expected behavior**

The 

    model.fit(train_data_generator,
          epochs=2,
          steps_per_epoch = 100 ,
          validation_data=test_data_generator,
          validation_steps=10),
          workers=2,
          use_multiprocessing=True)

should not be frozen and all CPU cores should be busy in working on data loading and model training. 

And, if run it by single-process, 

```
model.fit(train_data_generator,
          epochs=2,
          steps_per_epoch = 100 ,
          validation_data=test_data_generator,
          validation_steps=10),
          workers=1,
          use_multiprocessing=False)
```
it should also works well. No errors.

"
55607,k,
55606,Some modification for tflite GPU delegate,"I find some bug during programming. But I am not sure if these are right way to fix them, so I list them here first.

**System information**
- Mobile device  MTK mobile device.

**Details**
1. When a model has the structure that a Div followed by a Conv2D, and feature map has 3 channels. In this situation, I would get a all-nan output.
file [tensorflow/lite/delegates/gpu/common/tasks/conv_powervr.cc:](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/delegates/gpu/common/tasks/conv_powervr.cc)
in line 857, 
```
-        for (int ch = 0; ch < 4; ++ch){
+        for (int ch = 0; ch < (input_ch < 4 ? input_ch : 4); ++ch) {
```
in line 1043:
```
-        conv_core(0);
+        conv_core(0, input_ch);
```
in line 1046:
```
-         conv_core(i * block_size.w * 4);
+         input_ch -= 4;
+         conv_core(i * block_size.w * 4, input_ch);
```
Where input_ch represents the input channel number, which is 3 in this situation.
This modification will prevent zeros in channel 4, which is padded by GPU device for alignment, getting into calculation process.

2. When a conv2D op receive a dynamic weight as its second input, it will resullt in wrong padding.
file [tensorflow/lite/delegates/gpu/common/model_builder.cc](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/delegates/gpu/common/model_builder.cc)
line 531, add this two lines after RETURN_IF_ERROR(reader->AddInput(node, 1)):
```
+          attr.weights.shape.h = graph->FindInputs(node->id)[1]->tensor.shape.h;
+          attr.weights.shape.w = graph->FindInputs(node->id)[1]->tensor.shape.w;
```
This modification will provide shape information for padding, which is in line 542:
UpdatePadding(tf_options->padding, graph->FindInputs(node->id)[0]->tensor.shape, &attr);

3. When a model has the structure that a Div followed by a Sub, and feature map has batch greater than 1, for example, feature map is in shape 64x1. This will cause a calculation error.
file [tensorflow/lite/delegates/gpu/common/tasks/elementwise.cc,](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/delegates/gpu/common/tasks/elementwise.cc) function CreateElementwiseTwoInput:
```
-        const std::string x_coord = shape.w == 1 ? ""0"" : ""X_COORD"";
+        const std::string x_coord = (definition.IsBatchSupported() ? shape.w * shape.b : shape.w) == 1 ? ""0"" : ""X_COORD"";
```

"
55607,k,
55606,Some modification for tflite GPU delegate,"I find some bug during programming. But I am not sure if these are right way to fix them, so I list them here first.

**System information**
- Mobile device  MTK mobile device.

**Details**
1. When a model has the structure that a Div followed by a Conv2D, and feature map has 3 channels. In this situation, I would get a all-nan output.
file [tensorflow/lite/delegates/gpu/common/tasks/conv_powervr.cc:](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/delegates/gpu/common/tasks/conv_powervr.cc)
in line 857, 
```
-        for (int ch = 0; ch < 4; ++ch){
+        for (int ch = 0; ch < (input_ch < 4 ? input_ch : 4); ++ch) {
```
in line 1043:
```
-        conv_core(0);
+        conv_core(0, input_ch);
```
in line 1046:
```
-         conv_core(i * block_size.w * 4);
+         input_ch -= 4;
+         conv_core(i * block_size.w * 4, input_ch);
```
Where input_ch represents the input channel number, which is 3 in this situation.
This modification will prevent zeros in channel 4, which is padded by GPU device for alignment, getting into calculation process.

2. When a conv2D op receive a dynamic weight as its second input, it will resullt in wrong padding.
file [tensorflow/lite/delegates/gpu/common/model_builder.cc](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/delegates/gpu/common/model_builder.cc)
line 531, add this two lines after RETURN_IF_ERROR(reader->AddInput(node, 1)):
```
+          attr.weights.shape.h = graph->FindInputs(node->id)[1]->tensor.shape.h;
+          attr.weights.shape.w = graph->FindInputs(node->id)[1]->tensor.shape.w;
```
This modification will provide shape information for padding, which is in line 542:
UpdatePadding(tf_options->padding, graph->FindInputs(node->id)[0]->tensor.shape, &attr);

3. When a model has the structure that a Div followed by a Sub, and feature map has batch greater than 1, for example, feature map is in shape 64x1. This will cause a calculation error.
file [tensorflow/lite/delegates/gpu/common/tasks/elementwise.cc,](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/delegates/gpu/common/tasks/elementwise.cc) function CreateElementwiseTwoInput:
```
-        const std::string x_coord = shape.w == 1 ? ""0"" : ""X_COORD"";
+        const std::string x_coord = (definition.IsBatchSupported() ? shape.w * shape.b : shape.w) == 1 ? ""0"" : ""X_COORD"";
```

"
55605,Cant't make quantization for op that tflite doesn't support,"I will use tf.raw_ops.CropAndResize as an example.

This is how I define the op:
with tf.compat.v1.Session() as sess:
    inputs  = tf.raw_ops.Placeholder(dtype = tf.float32, shape = [1,18,18,8], name = ""input"")
    boxes = tf.raw_ops.Placeholder(dtype = tf.float32, shape = [1,64,4], name = ""boxes"")
    zeros = [0,0,0,0]
    zeros = zeros + zeros + zeros + zeros
    zeros = zeros + zeros + zeros + zeros
    crop_size = [18, 18]
    out = tf.raw_ops.CropAndResize(image=inputs, boxes= boxes, box_ind=zeros, crop_size=crop_size)
graph = tf.compat.v1.get_default_graph()
graph_def = graph.as_graph_def()
output_graph_def = tf.graph_util.convert_variables_to_constants(sess, sess.graph_def, ['output'])
with tf.io.gfile.GFile(save_name, 'wb') as f:
    f.write(graph_def.SerializeToString())

This is part of code I convert the .pb to .tflite and make quantization:
model = tf.compat.v1.lite.TFLiteConverter.from_frozen_graph(graph_def_file = pb_name, input_arrays=[""input"",""boxes""],output_arrays=[""CropAndResize""])
model.optimizations = [tf.lite.Optimize.DEFAULT]
model.representative_dataset = representative_dataset
model.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]
model.inference_input_type = tf.uint8  # or tf.uint8
model.inference_output_type = tf.uint8  # or tf.uint8
model.target_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]
model.allow_custom_ops = True
tflite_model = model.convert()
with open(tflite_name, 'wb') as f:
    f.write(tflite_model)

I have some questions during this process:
1. Can I use SaveModel to save this single layer model?
2. I don't know why I failed to quantize this model. But I could convert it from .pb to .tflite without quantization successfully. What's more, I can quantize a similar single conv layer model successfully, with similar way above.


"
55604,Handle called_computation in AbslHashValue,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): master
- Are you willing to contribute it (Yes/No): yes


**Describe the feature and the current behavior/state.**

https://github.com/tensorflow/tensorflow/blob/master/tensorflow/compiler/xla/service/hlo_instruction.h#L1315
Only `kFusion` is considered in this code, modify to the following code to consider other instructions that has a called_computation.

```python
if (!hlo.called_computations().empty()) {
  for (auto* comp : hlo.called_computations()) {
    h = H::combine(std::move(h), *comp);
  }
}

if (hlo.opcode() == HloOpcode::kFusion) {
  h = H::combine(std::move(h), hlo.fusion_kind(), 
                 hlo.fused_instruction_count(),
                 hlo.fused_parameters().size());
}
```


**Will this change the current api? How?**
No

**Who will benefit with this feature?**
Everyone who is using the hash value to distinguish different computations.

**Any Other info.**
"
55602,C++ Using TensorflowLiteC in iOS with Flex delegate TensorflowLiteCSelectTfOps,"I try to make inference with flex delegate supported tflite model in iOS using C++ language.

following the instructions in:
https://www.tensorflow.org/lite/guide/ops_select

I have installed the following pods:

   pod 'TensorFlowLiteC', '~> 2.5.0'

   pod 'TensorFlowLiteSelectTfOps', '~> 2.5.0'

and I have also added linker flag:

-force_load $(SRCROOT)/Pods/TensorFlowLiteSelectTfOps/Frameworks/TensorFlowLiteSelectTfOps.framework/TensorFlowLiteSelectTfOps

But during inference I observe:

 **Regular TensorFlow ops are not supported by this interpreter. Make sure you apply/link the Flex delegate before inference.**

is TensorFlowLiteSelectTfOps  not suitable for C++? or what am I doing wrong here?

Thanks"
55601,Allow different inputs choice to pad to bucket boundary in tf.data.Dataset.bucket_by_sequence_length,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): 2.8.0
- Are you willing to contribute it (Yes/No): No

**Describe the feature and the current behavior/state.**
tf.data.Dataset().bucket_by_sequence_length() has boolean input variable `pad_to_bucket_boundary`. However, if one wants to pad multiple sequences (e.g. audio, length=1000) and labels (e.g. 10 categories) then there is no capability to pad one by bucket_boundary and the other by maximum length in batch.

In my instance, I'd like to pad the audio to the maximum length in the batch, but the label by buckets.

**Will this change the current api? How?**
Boolean pad_to_bucket_boundary can also receive a dictionary with string key and boolean value.

**Who will benefit with this feature?**
Users who want to avoid unnecessary sparsity conversions/padding

**Any Other info.**
"
55600,request for feature gather and matmul,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): 2.7.1
- Are you willing to contribute it (Yes/No):
Yes


**Describe the feature and the current behavior/state.**
This function can realize that the corresponding weight is taken from the matrix B according to the index given by the matrix C and then multiplied by the matrix A.
A: [batch, h]
B: [num, h, d]
C: [batch, ]
out: [batch, d]
batch >> num
```python
for i, j in enumerate(C):
   out[i] = matmul(A[i], B[j])
```
Currently this function can be implemented by tf.gather then tf.matmul. However, it will waste a lot of gpu memory due to the need to define an intermediate variable W.
```python
W = tf.gather(B, C)
out = tf.matmul(A, W)
```
It can also be implemented by one hot matmul. However the time complexity of the calculation will be very high.
```python
tmp = tf.one_hot(C, depth=num)
out = tf.enisum('bh,bn,nhd->bd', A, tmp, B)
```
**Will this change the current api? How?**
No
**Who will benefit with this feature?**
This function can be applied to the moe model to achieve the assignment of experts strictly according to the probability of the router. Avoids the limitations of the expert capacity currently required. 
**Any Other info.**
No"
55599,"right after install TensorFlowLiteObjC , by pod install, cause error in Xcode","my Podfile is 

```
# Uncomment the next line to define a global platform for your project
# platform :ios, '9.0'

target 'MyApp' do
  # Comment the next line if you don't want to use dynamic frameworks
  # use_frameworks!

  # Pods for MyApp
  pod 'TensorFlowLiteObjC'

end
```


right after install pod file by commanding 
arch -x86_64 pod install


then build keep failed saying 

diff: /Podfile.lock: No such file or directory
diff: /Manifest.lock: No such file or directory
error: The sandbox is not in sync with the Podfile.lock. Run 'pod install' or update your CocoaPods installation.

I did many things that on web says...delete pods file...clean .... I did almost everything but no worth it. 
it just happened when install pod. 

m1 Mac 

"
55598,In tensorflow 2.8.0 multi input / multi output keras model not working,"**System information**
- tensorflow 2.8.0
- python 3.8.12
- Windows 10 Home 21H2 (19044.1586)
- CPU : AMD Ryzen 9 3900XT 12-Core Processor 3.80 GHz
- RAM : 64.0GB
- GPU : NVIDIA GeForce GRX 1660 SUPER
- NVIDIA-SMI 496.13 / Driver Version: 496.13 / CUDA Version: 11.5 / cuDNN version 8302
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
```import numpy as np
import tensorflow as tf
i1 = tf.keras.layers.Input(shape=(10, 1))
i2 = tf.keras.layers.Input(shape=(20, 1))
i3 = tf.keras.layers.Input(shape=(40, 10))
h1 = tf.keras.layers.Conv1D(32, 10, name='o1')(i1)
h2 = tf.keras.layers.Conv1D(32, 20, name='o2')(i2)
h3 = tf.keras.layers.Conv1D(32, 40, name='o3')(i3)
m = tf.keras.Model(inputs=[i1,i2,i3], outputs=[h1,h2,h3])
def loss(y_true,y_pred):
    return tf.losses.mean_absolute_error(y_true, y_pred) + tf.losses.mean_squared_error(y_true, y_pred)
m.compile(optimizer='adam', loss={'o1': 'mse', 'o2':""mae"", 'o3': loss})
m.fit([np.random.normal(size=(10,10,1)), np.random.normal(size=(10,20,1)), np.random.normal(size=(10,40,10))], [np.random.normal(size=(10,1,32)),np.random.normal(size=(10,1,32)),np.random.normal(size=(10,1,32))])
m.predict([np.random.normal(size=(10,10,1)), np.random.normal(size=(10,20,1)), np.random.normal(size=(10,40,10))])
```
- OUTPUT : 
```2022-04-13 09:27:20.307913: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-04-13 09:27:20.725606: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3995 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 SUPER, pci bus id: 0000:26:00.0, compute capability: 7.5
2022-04-13 09:27:22.135084: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8302

Process finished with exit code -1073740791 (0xC0000409)
```

**Describe the expected behavior**
In Previous version tensorflow, work done same code, but in later 2.7.1 occur, error and can't running same code


- Do you want to contribute a PR? (yes/no): may be can't
- Briefly describe your candidate solution(if contributing):
"
55595,Possible shuffling issue with using `tf.data.Dataset.list_files`?,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): 22.04 (Tried colab as well)
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): pip wheel
- TensorFlow version (use command below): 2.8.0 `v2.8.0-rc1-32-g3f878cff5b6 2.8.0`
- Python version: 3.8.6
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: 11.2
- GPU model and memory: RTX 3090 (24GB)

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

I'm having some weird behavior where I'm enumerating files in a directory, then generating the corresponding labels by using the map of the first dataset. However the order isn't being preserved when I zip them together. I've tried zipping a dataset generated from tensor slices and that seems to work. I've also tested this on Colab and get the same issue.

EDIT: I checked the documentation and understand there's a shuffle parameter in list files which defaults to True, but I was expecting that if I'm zipping the same object with itself I should get matching pairs. Let me know if this is the intended behavior

**Describe the expected behavior**

I expect that if I zip a dataset with itself I should get pairs of matching items when I iterate over it.

**[Contributing](https://www.tensorflow.org/community/contribute)**

- Do you want to contribute a PR? (yes/no): no
- Briefly describe your candidate solution(if contributing):

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

```
import os
import tensorflow as tf

tf.random.set_seed(42)

from tempfile import TemporaryDirectory

with TemporaryDirectory() as temp_dir:
    for i in range(10):
        os.mknod(os.path.join(temp_dir, f""{i}.txt""))

    inputs = tf.data.Dataset.list_files(f""{temp_dir}/*"")
    ds = tf.data.Dataset.zip((inputs, inputs))

    for x, y in ds:
        print(f""Input: {str(x)}, Output: {str(y)}"")
```

Gives me:
```
Input: tf.Tensor(b'/tmp/tmpxcqf5sg_/5.txt', shape=(), dtype=string), Output: tf.Tensor(b'/tmp/tmpxcqf5sg_/8.txt', shape=(), dtype=string)
Input: tf.Tensor(b'/tmp/tmpxcqf5sg_/8.txt', shape=(), dtype=string), Output: tf.Tensor(b'/tmp/tmpxcqf5sg_/0.txt', shape=(), dtype=string)
Input: tf.Tensor(b'/tmp/tmpxcqf5sg_/2.txt', shape=(), dtype=string), Output: tf.Tensor(b'/tmp/tmpxcqf5sg_/4.txt', shape=(), dtype=string)
Input: tf.Tensor(b'/tmp/tmpxcqf5sg_/0.txt', shape=(), dtype=string), Output: tf.Tensor(b'/tmp/tmpxcqf5sg_/1.txt', shape=(), dtype=string)
Input: tf.Tensor(b'/tmp/tmpxcqf5sg_/4.txt', shape=(), dtype=string), Output: tf.Tensor(b'/tmp/tmpxcqf5sg_/2.txt', shape=(), dtype=string)
Input: tf.Tensor(b'/tmp/tmpxcqf5sg_/7.txt', shape=(), dtype=string), Output: tf.Tensor(b'/tmp/tmpxcqf5sg_/7.txt', shape=(), dtype=string)
Input: tf.Tensor(b'/tmp/tmpxcqf5sg_/1.txt', shape=(), dtype=string), Output: tf.Tensor(b'/tmp/tmpxcqf5sg_/3.txt', shape=(), dtype=string)
Input: tf.Tensor(b'/tmp/tmpxcqf5sg_/3.txt', shape=(), dtype=string), Output: tf.Tensor(b'/tmp/tmpxcqf5sg_/9.txt', shape=(), dtype=string)
Input: tf.Tensor(b'/tmp/tmpxcqf5sg_/9.txt', shape=(), dtype=string), Output: tf.Tensor(b'/tmp/tmpxcqf5sg_/6.txt', shape=(), dtype=string)
Input: tf.Tensor(b'/tmp/tmpxcqf5sg_/6.txt', shape=(), dtype=string), Output: tf.Tensor(b'/tmp/tmpxcqf5sg_/5.txt', shape=(), dtype=string)
```

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
55592,Unable to Get Metric Result Using Mixed Precision and Mirrored Strategy,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): Binary
- TensorFlow version (use command below): 2.6.2
- Python version: 3.7.12
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: cuda_11.1.TC455_06.29190527_0
- GPU model and memory:  NVIDIA RTX A6000 48GB

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
Unable to call `tf.keras.Metric.result()` when using MixedPrecision.

We get the following error 

```
NotImplementedError: in user code:                                                                                                                           
                                                                                                                                                             
    /home/zach/package/package_name/metrics.py:113 result  *                                                                                             
        true_mean = self._true_sum / self._count                                                                                                             
    /home/zach/conda/envs/gent/lib/python3.7/site-packages/keras/mixed_precision/autocast_variable.py:412 __truediv__                                        
        return self.read_value() / o                                                                                                                         
    /home/zach/conda/envs/gent/lib/python3.7/site-packages/keras/mixed_precision/autocast_variable.py:113 read_value                                         
        val = self._variable.read_value()                                                                                                                    
    /home/zach/conda/envs/gent/lib/python3.7/site-packages/tensorflow/python/distribute/values.py:1303 read_value                                            
        ""call `variable.read_value()` inside variable_sync_on_read_context is""                                                                               
                                                                                                                                                             
    NotImplementedError: call `variable.read_value()` inside variable_sync_on_read_context is not supported **Describe the
``` 
**Expected behavior**
Should be able to get metric when using `MirroredStrategy` and `MixedPrecision`

**[Contributing](https://www.tensorflow.org/community/contribute)**

- Do you want to contribute a PR? (yes/no):
- Briefly describe your candidate solution(if contributing):

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
55591,ImportError: cannot import name 'deepmac_meta_arch' from 'object_detection.meta_architectures',"
**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Google Colab
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Google colab
- TensorFlow installed from (source or binary): Google colab (default)
- TensorFlow version: 1.15.2
- Python version: 3.7.13
- Installed using virtualenv? pip? conda?: Google Colab (no env)
- Bazel version (if compiling from source): Google colab (default)
- GCC/Compiler version (if compiling from source): Google colab (default)
- CUDA/cuDNN version: Google colab (default)
- GPU model and memory: Google colab (default)



**Describe the problem**
Trying to train custom object detector referring blog [Custom object detection in the browser using TensorFlow.js](https://blog.tensorflow.org/2021/01/custom-object-detection-in-browser.html)


**Provide the exact sequence of commands / steps that you executed before running into the problem**
Ran these blocks one after other inside Google colab
```
from google.colab import drive
drive.mount('/content/drive/')
```

```
%cd /content/drive/MyDrive/Tensorflow/models/research/
!protoc object_detection/protos/*.proto --python_out=.
# Install TensorFlow Object Detection API.
!cp object_detection/packages/tf2/setup.py .
```

```
!pip install tensorflow-object-detection-api
```

```
%tensorflow_version 1.x
```

```
%cd /content/drive/MyDrive/Tensorflow/models/research/slim/
```

```
%%bash
export PYTHONPATH=$PYTHONPATH:`pwd`:`pwd`/slim

python setup.py build
python setup.py install
```

```
!python /content/drive/MyDrive/Tensorflow/models/research/object_detection/builders/model_builder_tf2_test.py
```

Error in this block
```
WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

Traceback (most recent call last):
  File ""/content/drive/MyDrive/Tensorflow/models/research/object_detection/builders/model_builder_tf2_test.py"", line 27, in <module>
    from object_detection.meta_architectures import deepmac_meta_arch
ImportError: cannot import name 'deepmac_meta_arch' from 'object_detection.meta_architectures' (/usr/local/lib/python3.7/dist-packages/object_detection/meta_architectures/__init__.py)
```

"
55588,"ValueError: Input 0 of layer ""sequential"" is incompatible with the layer: expected shape=(None, 219566, 6), found shape=(None, 6)","Guys, do you have any idea how to solve this problem (LSTM, Keras, Tensorflow)? 
---------------------------------------------------------------------------
I looked through the similar topics but suggested solutions do not work for me. The code is pretty simple:


import pandas as pd
import numpy as np
import tensorflow as tf
import sklearn
import keras_tuner as kt

from tensorflow import keras
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
from tensorflow.keras import layers

df_training_data = pd.read_csv (r'G:\Research\Oils\REQUESTS\US_data\ProdAbo_AllHeaders_csv.csv')

x_total = df_training_data.loc[:,['Lat_X1','Lon_X2','Month_X3',
                                  'Well_length_X5','Density_X7','Month_from_start_X8']]

y_total = df_training_data.loc[:,'Liquids_Y1']

scaler = MinMaxScaler()
x_total = scaler.fit_transform(x_total)

x_total = np.array(x_total).astype(np.float32)
y_total = np.array(y_total).astype(np.float32)

x_train, x_test, y_train, y_test = train_test_split(x_total, y_total, test_size = 0.3, random_state = 0)

num_rows, num_cols = x_train.shape

x_train = tf.reshape(x_train, [num_rows, num_cols])
y_train = tf.reshape(y_train, [num_rows, 1])

batch_size = 100
num_epochs = 5

model = tf.keras.models.Sequential([tf.keras.layers.LSTM(num_cols, 
                                                         input_shape=(num_rows,num_cols), 
                                                         activation = tf.nn.tanh,
                                                         return_sequences=True),        
                                    tf.keras.layers.LSTM(10, activation = tf.nn.tanh),
                                    tf.keras.layers.Dense(1, activation = tf.nn.relu)]) 

model.compile(optimizer='adam', loss='mse', metrics=[tf.keras.metrics.RootMeanSquaredError()])

model.fit(x_train, y_train, epochs=num_epochs, batch_size=batch_size, validation_data=(x_test, y_test))


And here we are:
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
<ipython-input-18-37ddda0f53d6> in <module>
      3 num_epochs = 5
      4 
----> 5 model.fit(x_train, y_train, epochs=num_epochs, batch_size=batch_size, validation_data=(x_test, y_test))
      6 
      7 #model.fit(train_data, epochs=num_epochs, batch_size=batch_size, validation_data=test_data)

C:\ProgramData\Anaconda3\lib\site-packages\keras\utils\traceback_utils.py in error_handler(*args, **kwargs)
     65     except Exception as e:  # pylint: disable=broad-except
     66       filtered_tb = _process_traceback_frames(e.__traceback__)
---> 67       raise e.with_traceback(filtered_tb) from None
     68     finally:
     69       del filtered_tb

C:\ProgramData\Anaconda3\lib\site-packages\tensorflow\python\framework\func_graph.py in autograph_handler(*args, **kwargs)
   1145           except Exception as e:  # pylint:disable=broad-except
   1146             if hasattr(e, ""ag_error_metadata""):
-> 1147               raise e.ag_error_metadata.to_exception(e)
   1148             else:
   1149               raise

ValueError: in user code:

    File ""C:\ProgramData\Anaconda3\lib\site-packages\keras\engine\training.py"", line 1021, in train_function  *
        return step_function(self, iterator)
    File ""C:\ProgramData\Anaconda3\lib\site-packages\keras\engine\training.py"", line 1010, in step_function  **
        outputs = model.distribute_strategy.run(run_step, args=(data,))
    File ""C:\ProgramData\Anaconda3\lib\site-packages\keras\engine\training.py"", line 1000, in run_step  **
        outputs = model.train_step(data)
    File ""C:\ProgramData\Anaconda3\lib\site-packages\keras\engine\training.py"", line 859, in train_step
        y_pred = self(x, training=True)
    File ""C:\ProgramData\Anaconda3\lib\site-packages\keras\utils\traceback_utils.py"", line 67, in error_handler
        raise e.with_traceback(filtered_tb) from None
    File ""C:\ProgramData\Anaconda3\lib\site-packages\keras\engine\input_spec.py"", line 264, in assert_input_compatibility
        raise ValueError(f'Input {input_index} of layer ""{layer_name}"" is '

    ValueError: Input 0 of layer ""sequential"" is incompatible with the layer: expected shape=(None, 219566, 6), found shape=(None, 6)"
55586,how to define representative_data_gen function when model has two inputs?,"https://www.tensorflow.org/lite/performance/post_training_integer_quant:

def representative_data_gen():
  for input_value in tf.data.Dataset.from_tensor_slices(train_images).batch(1).take(100):
    # Model has only one input so each data point has one element.
    yield [input_value]
converter = tf.lite.TFLiteConverter.from_keras_model(model)
converter.optimizations = [tf.lite.Optimize.DEFAULT]
converter.representative_dataset = representative_data_gen
tflite_model_quant = converter.convert()

My question is, how to modify the code listed above, when model has two or more inputs?"
55585,"on xcode,  not found for architecture arm64 caused","
I added on my podfile 
pod 'TensorFlowLiteObjc' 

then install, 
build then cause error on xcode. 

what may be the problem? 
I'm using m1 mac 

```
ld: warning: Could not find or use auto-linked framework 'TFLTensorFlowLite'
Undefined symbols for architecture arm64:
  ""_OBJC_CLASS_$_TFLInterpreter"", referenced from:
      objc-class-ref in SmartVisionVehicle.o
ld: symbol(s) not found for architecture arm64
```

"
55584,Android- No implementation found.,"Hello everyone. I'm using tensorflow for background removal of an object. Every thing is working great but I'm keep getting this exception on the first time of model load. once the model is loaded it did not occurred.

**Stack Trace:**
No implementation found for long org.tensorflow.contrib.android.RunStats.allocate() (tried Java_org_tensorflow_contrib_android_RunStats_allocate and Java_org_tensorflow_contrib_android_RunStats_allocate__)
I/TensorFlowInferenceInterface: TensorFlow native methods not found, attempting to load via tensorflow_inference
I/TensorFlowInferenceInterface: Successfully loaded TensorFlow native methods (RunStats error may be ignored)

**Code:**

   private var sTFInterface: TensorFlowInferenceInterface? = null
   sTFInterface = TensorFlowInferenceInterface(context.assets, MODEL_FILE)

**Dependencies:**
    implementation 'org.tensorflow:tensorflow-lite:2.8.0'
    implementation 'org.tensorflow:tensorflow-lite-gpu:2.8.0'"
55583,how reduce  tensorflow-lite-select-tf-ops.aar size ？,"

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Ubuntu 20.04.4 LTS 
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): source 
- TensorFlow version: 2.7.0
- Python version:3.8.10 
- Installed using virtualenv? pip? conda?: 
- Bazel version (if compiling from source):3.7.2
- GCC/Compiler version (if compiling from source):  9.4.0
- CUDA/cuDNN version:N
- GPU model and memory:



**Describe the problem**

I follow the guide [reduce_binary_size](https://www.tensorflow.org/lite/guide/reduce_binary_size#selectively_build_tensorflow_lite_with_docker)  and execute this commands: [model.tflite](https://drive.google.com/file/d/1f-BDEojrEgx0lPmaI8_x44sKOJl-1mOv/view?usp=sharing)

```
bash tensorflow/lite/tools/build_aar.sh  --input_models=/host_dir/model.tflite --target_archs=arm64-v8a,armeabi-v7a
```

and get the tensorflow-lite-select-tf-ops.aar 6.5M

```
6507898 Apr 12 03:31 tensorflow-lite-select-tf-ops.aar*
```

but its size is still too big，can i further reduce it size ? only build cpu or build without Delegate?



**Any other info / logs**


Intermediate file in tmp :`ops_list.txt`

```
[""AddN"",""BiasAddGrad"",""BroadcastGradientArgs"",""Cast"",""ConcatOffset"",""EmptyTensorList"",""ReluGrad"",""Restore"",""Save"",""ShapeN"",""SigmoidGrad"",""StridedSliceGrad"",""TensorListElementShape"",""TensorListFromTensor"",""TensorListGetItem"",""TensorListLength"",""TensorListPopBack"",""TensorListPushBack"",""TensorListReserve"",""TensorListSetItem"",""TensorListStack"",""UnsortedSegmentSum"",""ZerosLike""]
```
"
55582,Cannot install tensorflow-gpu==1.15.0,"**System information**
- OS Platform and Distribution: Linux Ubuntu 20.04
- TensorFlow version: tensorflow-gpu==1.15.0
- Python version: 3.17.13
- Installed using virtualenv? pip? conda?: pip
- CUDA/cuDNN version: 
- GPU model and memory: 

Describe the problem
I get the following error when trying to install tensorflow-gpu in version  1.15.0:
```
Using pip 22.0.4 from /home/dmitriy/.local/lib/python3.8/site-packages/pip (python 3.8)
ERROR: Could not find a version that satisfies the requirement tensorflow-gpu==1.15.0 (from versions: 2.2.0, 2.2.1, 2.2.2, 2.2.3, 2.3.0, 2.3.1, 2.3.2, 2.3.3, 2.3.4, 2.4.0, 2.4.1, 2.4.2, 2.4.3, 2.4.4, 2.5.0, 2.5.1, 2.5.2, 2.5.3, 2.6.0, 2.6.1, 2.6.2, 2.6.3, 2.7.0rc0, 2.7.0rc1, 2.7.0, 2.7.1, 2.8.0rc0, 2.8.0rc1, 2.8.0)
ERROR: No matching distribution found for tensorflow-gpu==1.15.0
```
After I try change this line in file `requirements.txt`.
```
tensorflow-gpu==1.15.0
```
to 
```
tensorflow==2.8.0
```
And I've got this error:
```
Running command python setup.py egg_info
  fatal: not a git repository (or any of the parent directories): .git
  Traceback (most recent call last):
    File ""<string>"", line 2, in <module>
    File ""<pip-setuptools-caller>"", line 34, in <module>
    File ""/tmp/pip-install-4b7bdwir/onnx_617da0f137a840d89f00ab87f0ff4f40/setup.py"", line 72, in <module>
      assert CMAKE, 'Could not find ""cmake"" executable!'
  AssertionError: Could not find ""cmake"" executable!
  error: subprocess-exited-with-error
  
  × python setup.py egg_info did not run successfully.
  │ exit code: 1
  ╰─> See above for output.
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
  full command: /usr/bin/python3 -c '
  exec(compile('""'""''""'""''""'""'
  # This is <pip-setuptools-caller> -- a caller that pip uses to run setup.py
  #
  # - It imports setuptools before invoking setup.py, to enable projects that directly
  #   import from `distutils.core` to work with newer packaging standards.
  # - It provides a clear error message when setuptools is not installed.
  # - It sets `sys.argv[0]` to the underlying `setup.py`, when invoking `setup.py` so
  #   setuptools doesn'""'""'t think the script is `-c`. This avoids the following warning:
  #     manifest_maker: standard file '""'""'-c'""'""' not found"".
  # - It generates a shim setup.py, for handling setup.cfg-only projects.
  import os, sys, tokenize
  
  try:
      import setuptools
  except ImportError as error:
      print(
          ""ERROR: Can not execute `setup.py` since setuptools is not available in ""
          ""the build environment."",
          file=sys.stderr,
      )
      sys.exit(1)
  
  __file__ = %r
  sys.argv[0] = __file__
  
  if os.path.exists(__file__):
      filename = __file__
      with tokenize.open(__file__) as f:
          setup_py_code = f.read()
  else:
      filename = ""<auto-generated setuptools caller>""
      setup_py_code = ""from setuptools import setup; setup()""
  
  exec(compile(setup_py_code, filename, ""exec""))
  '""'""''""'""''""'""' % ('""'""'/tmp/pip-install-4b7bdwir/onnx_617da0f137a840d89f00ab87f0ff4f40/setup.py'""'""',), ""<pip-setuptools-caller>"", ""exec""))' egg_info --egg-base /tmp/pip-pip-egg-info-zivjykrk
  cwd: /tmp/pip-install-4b7bdwir/onnx_617da0f137a840d89f00ab87f0ff4f40/
  Preparing metadata (setup.py) ... error
error: metadata-generation-failed

× Encountered error while generating package metadata.
╰─> See above for output.

note: This is an issue with the package mentioned above, not pip.
hint: See above for details.

```


After that I install `cmake` by `sudo apt install cmake`. And I've got this error:
```
The conflict is caused by:
    The user requested keras==2.3.1
    tensorflow 2.8.0 depends on keras<2.9 and >=2.8.0rc0

To fix this you could try to:
1. loosen the range of package versions you've specified
2. remove package versions to allow pip attempt to solve the dependency conflict
```
I changed keras version in file `requirements.txt`.
```
keras==2.3.1
```
to
```
keras==2.8.0
```
And then I 've got error: 
```
The conflict is caused by:
    The user requested numpy==1.19.1
    tensorflow 2.8.0 depends on numpy>=1.20

To fix this you could try to:
1. loosen the range of package versions you've specified
2. remove package versions to allow pip attempt to solve the dependency conflict
```  
I changed numpy version in file `requirements.txt`.
```
numpy==1.19.1
```
to
```
numpy==1.22.0
```
then i have got error:
```
 -- Configuring incomplete, errors occurred!
  See also ""/tmp/pip-install-cxnneqyj/onnx_1ec1fa5d6a8d47ca9cbff428da18c916/.setuptools-cmake-build/CMakeFiles/CMakeOutput.log"".
  See also ""/tmp/pip-install-cxnneqyj/onnx_1ec1fa5d6a8d47ca9cbff428da18c916/.setuptools-cmake-build/CMakeFiles/CMakeError.log"".
  Traceback (most recent call last):
    File ""<string>"", line 2, in <module>
    File ""<pip-setuptools-caller>"", line 34, in <module>
    File ""/tmp/pip-install-cxnneqyj/onnx_1ec1fa5d6a8d47ca9cbff428da18c916/setup.py"", line 315, in <module>
      setuptools.setup(
    File ""/home/dmitriy/.local/lib/python3.8/site-packages/setuptools/__init__.py"", line 87, in setup
      return distutils.core.setup(**attrs)
    File ""/home/dmitriy/.local/lib/python3.8/site-packages/setuptools/_distutils/core.py"", line 148, in setup
      return run_commands(dist)
    File ""/home/dmitriy/.local/lib/python3.8/site-packages/setuptools/_distutils/core.py"", line 163, in run_commands
      dist.run_commands()
    File ""/home/dmitriy/.local/lib/python3.8/site-packages/setuptools/_distutils/dist.py"", line 967, in run_commands
      self.run_command(cmd)
    File ""/home/dmitriy/.local/lib/python3.8/site-packages/setuptools/dist.py"", line 1214, in run_command
      super().run_command(command)
    File ""/home/dmitriy/.local/lib/python3.8/site-packages/setuptools/_distutils/dist.py"", line 986, in run_command
      cmd_obj.run()
    File ""/usr/lib/python3/dist-packages/wheel/bdist_wheel.py"", line 223, in run
      self.run_command('build')
    File ""/home/dmitriy/.local/lib/python3.8/site-packages/setuptools/_distutils/cmd.py"", line 313, in run_command
      self.distribution.run_command(command)
    File ""/home/dmitriy/.local/lib/python3.8/site-packages/setuptools/dist.py"", line 1214, in run_command
      super().run_command(command)
    File ""/home/dmitriy/.local/lib/python3.8/site-packages/setuptools/_distutils/dist.py"", line 986, in run_command
      cmd_obj.run()
    File ""/home/dmitriy/.local/lib/python3.8/site-packages/setuptools/_distutils/command/build.py"", line 136, in run
      self.run_command(cmd_name)
    File ""/home/dmitriy/.local/lib/python3.8/site-packages/setuptools/_distutils/cmd.py"", line 313, in run_command
      self.distribution.run_command(command)
    File ""/home/dmitriy/.local/lib/python3.8/site-packages/setuptools/dist.py"", line 1214, in run_command
      super().run_command(command)
    File ""/home/dmitriy/.local/lib/python3.8/site-packages/setuptools/_distutils/dist.py"", line 986, in run_command
      cmd_obj.run()
    File ""/tmp/pip-install-cxnneqyj/onnx_1ec1fa5d6a8d47ca9cbff428da18c916/setup.py"", line 209, in run
      self.run_command('cmake_build')
    File ""/home/dmitriy/.local/lib/python3.8/site-packages/setuptools/_distutils/cmd.py"", line 313, in run_command
      self.distribution.run_command(command)
    File ""/home/dmitriy/.local/lib/python3.8/site-packages/setuptools/dist.py"", line 1214, in run_command
      super().run_command(command)
    File ""/home/dmitriy/.local/lib/python3.8/site-packages/setuptools/_distutils/dist.py"", line 986, in run_command
      cmd_obj.run()
    File ""/tmp/pip-install-cxnneqyj/onnx_1ec1fa5d6a8d47ca9cbff428da18c916/setup.py"", line 195, in run
      subprocess.check_call(cmake_args)
    File ""/usr/lib/python3.8/subprocess.py"", line 364, in check_call
      raise CalledProcessError(retcode, cmd)
  subprocess.CalledProcessError: Command '['/usr/bin/cmake', '-DPYTHON_INCLUDE_DIR=/usr/include/python3.8', '-DPYTHON_EXECUTABLE=/usr/bin/python3', '-DBUILD_ONNX_PYTHON=ON', '-DCMAKE_EXPORT_COMPILE_COMMANDS=ON', '-DONNX_NAMESPACE=onnx', '-DPY_EXT_SUFFIX=.cpython-38-x86_64-linux-gnu.so', '-DCMAKE_BUILD_TYPE=Release', '-DONNX_ML=1', '/tmp/pip-install-cxnneqyj/onnx_1ec1fa5d6a8d47ca9cbff428da18c916']' returned non-zero exit status 1.
  error: subprocess-exited-with-error
  
  × python setup.py bdist_wheel did not run successfully.
  │ exit code: 1
  ╰─> See above for output.
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
  full command: /usr/bin/python3 -u -c '
  exec(compile('""'""''""'""''""'""'
  # This is <pip-setuptools-caller> -- a caller that pip uses to run setup.py
  #
  # - It imports setuptools before invoking setup.py, to enable projects that directly
  #   import from `distutils.core` to work with newer packaging standards.
  # - It provides a clear error message when setuptools is not installed.
  # - It sets `sys.argv[0]` to the underlying `setup.py`, when invoking `setup.py` so
  #   setuptools doesn'""'""'t think the script is `-c`. This avoids the following warning:
  #     manifest_maker: standard file '""'""'-c'""'""' not found"".
  # - It generates a shim setup.py, for handling setup.cfg-only projects.
  import os, sys, tokenize
  
  try:
      import setuptools
  except ImportError as error:
      print(
          ""ERROR: Can not execute `setup.py` since setuptools is not available in ""
          ""the build environment."",
          file=sys.stderr,
      )
      sys.exit(1)
  
  __file__ = %r
  sys.argv[0] = __file__
  
  if os.path.exists(__file__):
      filename = __file__
      with tokenize.open(__file__) as f:
          setup_py_code = f.read()
  else:
      filename = ""<auto-generated setuptools caller>""
      setup_py_code = ""from setuptools import setup; setup()""
  
  exec(compile(setup_py_code, filename, ""exec""))
  '""'""''""'""''""'""' % ('""'""'/tmp/pip-install-cxnneqyj/onnx_1ec1fa5d6a8d47ca9cbff428da18c916/setup.py'""'""',), ""<pip-setuptools-caller>"", ""exec""))' bdist_wheel -d /tmp/pip-wheel-i5wyi68e
  cwd: /tmp/pip-install-cxnneqyj/onnx_1ec1fa5d6a8d47ca9cbff428da18c916/
  Building wheel for onnx (setup.py) ... error
  ERROR: Failed building wheel for onnx
  Running setup.py clean for onnx
  Running command python setup.py clean
```
and second error
```
-- Configuring incomplete, errors occurred!
  See also ""/tmp/pip-install-uou042w3/onnx_f2684108a6604e46b4d58ca7bca088b7/.setuptools-cmake-build/CMakeFiles/CMakeOutput.log"".
  See also ""/tmp/pip-install-uou042w3/onnx_f2684108a6604e46b4d58ca7bca088b7/.setuptools-cmake-build/CMakeFiles/CMakeError.log"".
  Traceback (most recent call last):
    File ""<string>"", line 2, in <module>
    File ""<pip-setuptools-caller>"", line 34, in <module>
    File ""/tmp/pip-install-uou042w3/onnx_f2684108a6604e46b4d58ca7bca088b7/setup.py"", line 315, in <module>
      setuptools.setup(
    File ""/home/dmitriy/.local/lib/python3.8/site-packages/setuptools/__init__.py"", line 87, in setup
      return distutils.core.setup(**attrs)
    File ""/home/dmitriy/.local/lib/python3.8/site-packages/setuptools/_distutils/core.py"", line 148, in setup
      return run_commands(dist)
    File ""/home/dmitriy/.local/lib/python3.8/site-packages/setuptools/_distutils/core.py"", line 163, in run_commands
      dist.run_commands()
    File ""/home/dmitriy/.local/lib/python3.8/site-packages/setuptools/_distutils/dist.py"", line 967, in run_commands
      self.run_command(cmd)
    File ""/home/dmitriy/.local/lib/python3.8/site-packages/setuptools/dist.py"", line 1214, in run_command
      super().run_command(command)
    File ""/home/dmitriy/.local/lib/python3.8/site-packages/setuptools/_distutils/dist.py"", line 986, in run_command
      cmd_obj.run()
    File ""/home/dmitriy/.local/lib/python3.8/site-packages/setuptools/command/install.py"", line 68, in run
      return orig.install.run(self)
    File ""/home/dmitriy/.local/lib/python3.8/site-packages/setuptools/_distutils/command/install.py"", line 670, in run
      self.run_command('build')
    File ""/home/dmitriy/.local/lib/python3.8/site-packages/setuptools/_distutils/cmd.py"", line 313, in run_command
      self.distribution.run_command(command)
    File ""/home/dmitriy/.local/lib/python3.8/site-packages/setuptools/dist.py"", line 1214, in run_command
      super().run_command(command)
    File ""/home/dmitriy/.local/lib/python3.8/site-packages/setuptools/_distutils/dist.py"", line 986, in run_command
      cmd_obj.run()
    File ""/home/dmitriy/.local/lib/python3.8/site-packages/setuptools/_distutils/command/build.py"", line 136, in run
      self.run_command(cmd_name)
    File ""/home/dmitriy/.local/lib/python3.8/site-packages/setuptools/_distutils/cmd.py"", line 313, in run_command
      self.distribution.run_command(command)
    File ""/home/dmitriy/.local/lib/python3.8/site-packages/setuptools/dist.py"", line 1214, in run_command
      super().run_command(command)
    File ""/home/dmitriy/.local/lib/python3.8/site-packages/setuptools/_distutils/dist.py"", line 986, in run_command
      cmd_obj.run()
    File ""/tmp/pip-install-uou042w3/onnx_f2684108a6604e46b4d58ca7bca088b7/setup.py"", line 209, in run
      self.run_command('cmake_build')
    File ""/home/dmitriy/.local/lib/python3.8/site-packages/setuptools/_distutils/cmd.py"", line 313, in run_command
      self.distribution.run_command(command)
    File ""/home/dmitriy/.local/lib/python3.8/site-packages/setuptools/dist.py"", line 1214, in run_command
      super().run_command(command)
    File ""/home/dmitriy/.local/lib/python3.8/site-packages/setuptools/_distutils/dist.py"", line 986, in run_command
      cmd_obj.run()
    File ""/tmp/pip-install-uou042w3/onnx_f2684108a6604e46b4d58ca7bca088b7/setup.py"", line 195, in run
      subprocess.check_call(cmake_args)
    File ""/usr/lib/python3.8/subprocess.py"", line 364, in check_call
      raise CalledProcessError(retcode, cmd)
  subprocess.CalledProcessError: Command '['/usr/bin/cmake', '-DPYTHON_INCLUDE_DIR=/usr/include/python3.8', '-DPYTHON_EXECUTABLE=/usr/bin/python3', '-DBUILD_ONNX_PYTHON=ON', '-DCMAKE_EXPORT_COMPILE_COMMANDS=ON', '-DONNX_NAMESPACE=onnx', '-DPY_EXT_SUFFIX=.cpython-38-x86_64-linux-gnu.so', '-DCMAKE_BUILD_TYPE=Release', '-DONNX_ML=1', '/tmp/pip-install-uou042w3/onnx_f2684108a6604e46b4d58ca7bca088b7']' returned non-zero exit status 1.
  error: subprocess-exited-with-error
  
  × Running setup.py install for onnx did not run successfully.
  │ exit code: 1
  ╰─> See above for output.
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
  full command: /usr/bin/python3 -u -c '
  exec(compile('""'""''""'""''""'""'
  # This is <pip-setuptools-caller> -- a caller that pip uses to run setup.py
  #
  # - It imports setuptools before invoking setup.py, to enable projects that directly
  #   import from `distutils.core` to work with newer packaging standards.
  # - It provides a clear error message when setuptools is not installed.
  # - It sets `sys.argv[0]` to the underlying `setup.py`, when invoking `setup.py` so
  #   setuptools doesn'""'""'t think the script is `-c`. This avoids the following warning:
  #     manifest_maker: standard file '""'""'-c'""'""' not found"".
  # - It generates a shim setup.py, for handling setup.cfg-only projects.
  import os, sys, tokenize
  
  try:
      import setuptools
  except ImportError as error:
      print(
          ""ERROR: Can not execute `setup.py` since setuptools is not available in ""
          ""the build environment."",
          file=sys.stderr,
      )
      sys.exit(1)
  
  __file__ = %r
  sys.argv[0] = __file__
  
  if os.path.exists(__file__):
      filename = __file__
      with tokenize.open(__file__) as f:
          setup_py_code = f.read()
  else:
      filename = ""<auto-generated setuptools caller>""
      setup_py_code = ""from setuptools import setup; setup()""
  
  exec(compile(setup_py_code, filename, ""exec""))
  '""'""''""'""''""'""' % ('""'""'/tmp/pip-install-446qbri3/onnx_5a2c95655ead4090aa493849a53eb885/setup.py'""'""',), ""<pip-setuptools-caller>"", ""exec""))' install --record /tmp/pip-record-6gso7uyj/install-record.txt --single-version-externally-managed --user --prefix= --compile --install-headers /home/dmitriy/.local/include/python3.8/onnx
  cwd: /tmp/pip-install-446qbri3/onnx_5a2c95655ead4090aa493849a53eb885/
  Running setup.py install for onnx ... error
error: legacy-install-failure

× Encountered error while trying to install package.
╰─> onnx

note: This is an issue with the package mentioned above, not pip.
hint: See above for output from the failure.
```
For improve fail I run this command:  `sudo apt-get install protobuf-compiler libprotoc-dev` and eventually 
`Installation Succeeded`"
55581,macOS wheel URLs are incorrect,"## URL(s) with the issue:

https://www.tensorflow.org/install/pip

## Description of issue (what needs changing):

The Mac wheels that the docs page purport to exist do not, in fact, exist:
```
NoSuchKeyThe specified key does not exist.No such object: tensorflow/mac/cpu/tensorflow-2.8.0-cp39-cp39-macosx_10_11_x86_64.whl
```

Where are these wheels actually located?

### Submit a pull request?

I would submit a PR, but I am not aware of what the correct URLs are. The storage bucket does not have any index as far as I could tell."
55580,tf.keras.callbacks.ModelCheckpoint ignores the montior parameter and always use loss,"I am running tf.keras.callbacks.ModelCheckpoint with the accuracy metric but loss is used to save the best checkpoints. I have tested this in different places (my computer and collab) and two different code and faced the same issue. Here is an example code and the results:

```
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import os
import shutil

def get_uncompiled_model():
    inputs = keras.Input(shape=(784,), name=""digits"")
    x = layers.Dense(64, activation=""relu"", name=""dense_1"")(inputs)
    x = layers.Dense(64, activation=""relu"", name=""dense_2"")(x)
    outputs = layers.Dense(10, activation=""softmax"", name=""predictions"")(x)
    model = keras.Model(inputs=inputs, outputs=outputs)
    return model

def get_compiled_model():
    model = get_uncompiled_model()
    model.compile(
        optimizer=""rmsprop"",
        loss=""sparse_categorical_crossentropy"",
        metrics=[""accuracy""],
    )
    return model

(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()

# Preprocess the data (these are NumPy arrays)
x_train = x_train.reshape(60000, 784).astype(""float32"") / 255
x_test = x_test.reshape(10000, 784).astype(""float32"") / 255

y_train = y_train.astype(""float32"")
y_test = y_test.astype(""float32"")

# Reserve 10,000 samples for validation
x_val = x_train[-10000:]
y_val = y_train[-10000:]
x_train = x_train[:-10000]
y_train = y_train[:-10000]


ckpt_folder = os.path.join(os.getcwd(), 'ckpt')
if os.path.exists(ckpt_folder):
    shutil.rmtree(ckpt_folder)

ckpt_path = os.path.join(r'D:\deep_learning\tf_keras\semantic_segmentation\logs', 'mymodel_{epoch}')


callbacks = [
    tf.keras.callbacks.ModelCheckpoint(
        # Path where to save the model
        # The two parameters below mean that we will overwrite
        # the current checkpoint if and only if
        # the `val_loss` score has improved.
        # The saved model name will include the current epoch.
        filepath=ckpt_path,
        montior=""val_accuracy"",
        # save the model weights with best validation accuracy
        mode='max',
        save_best_only=True,  # only save the best weights
        save_weights_only=False,
        # only save model weights (not whole model)
        verbose=1
    )
]

model = get_compiled_model()


model.fit(
    x_train, y_train, epochs=3, batch_size=1, callbacks=callbacks, validation_split=0.2, steps_per_epoch=1
)
```


1/1 [==============================] - ETA: 0s - loss: 2.6475 - accuracy: 0.0000e+00
Epoch 1: val_loss improved from -inf to 2.32311, saving model to D:\deep_learning\tf_keras\semantic_segmentation\logs\mymodel_1
1/1 [==============================] - 6s 6s/step - loss: 2.6475 - accuracy: 0.0000e+00 - val_loss: 2.3231 - val_accuracy: 0.1142
Epoch 2/3
1/1 [==============================] - ETA: 0s - loss: 1.9612 - accuracy: 1.0000
Epoch 2: val_loss improved from 2.32311 to 2.34286, saving model to D:\deep_learning\tf_keras\semantic_segmentation\logs\mymodel_2
1/1 [==============================] - 5s 5s/step - loss: 1.9612 - accuracy: 1.0000 - val_loss: 2.3429 - val_accuracy: 0.1187
Epoch 3/3
1/1 [==============================] - ETA: 0s - loss: 2.8378 - accuracy: 0.0000e+00
Epoch 3: val_loss did not improve from 2.34286
1/1 [==============================] - 5s 5s/step - loss: 2.8378 - accuracy: 0.0000e+00 - val_loss: 2.2943 - val_accuracy: 0.1346"
55576,TFLite InterpreterBuilder Segmentation fault 11 on MacOS 11.6,"I use C++ to load tflite model. Same code works fine on Linux & Android. But when running on MacOS it gives Segmentation fault 11  error.

I am using tensorflow 2.8.0. 

```C++
#include <tensorflow/lite/kernels/register.h>

std::unique_ptr<tflite::FlatBufferModel> model;
std::unique_ptr<tflite::Interpreter> interpreter;

int main() {
  model = tflite::FlatBufferModel::BuildFromFile""model.tflite"");
  tflite::ops::builtin::BuiltinOpResolver resolver;
  tflite::InterpreterBuilder(*model, resolver)(&interpreter); // -> Segmentation fault 11 here
  return 0;
}
```"
55575,Unwanted log messages and crash/force termination,"### System information

-   **Have I written custom code (as opposed to using a stock example script
    provided in TensorFlow)**: Yes
-   **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: RHEL 8.5
-   **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue
    happens on a mobile device**: No
-   **TensorFlow installed from (source or binary)**: Binary
-   **TensorFlow version (use command below)**: 2.5.3
-   **Python version**: 3.8.8
-   **Bazel version (if compiling from source)**:
-   **GCC/Compiler version (if compiling from source)**:
-   **CUDA/cuDNN version**: CUDA 11.2.2
-   **GPU model and memory**:  P100

### Describe the problem
While running a model training using `.fit` function using a tf.data.Dataset we observe a lot of prints of the statement `Cleanup called...`. Example:
```
Cleanup called...
Cleanup called...
Cleanup called...
Cleanup called...
Cleanup called...
Cleanup called...
Cleanup called...
```
Followed by Python code termination with an error code:
`Aborted (core dumped) python run.py`

This problem occurs with TF 2.5.3. The same code runs perfectly with TF 2.5.2.
Even though the Python interpreter errors out with the core dumped message, actual model training works fine and the model also gets saved.

We use the function `tf.io.decode_image` in the tf.data pipeline which seems to be causing these prints."
55574,Difference in Inference result in JAVA and Swift using same TFLite Model,"I have trained a Mobile Bert Custom TFLite model for Text Classification and the model works as expected in Android. The output values match the expected values from running the TFLite model in Python. However, while running the same model in iOS with same input, I am getting different results. 

I am new to iOS, this is the first time I'm working on iOS so my gut feeling is that I'm doing something wrong. The only clue I currently have is the slight difference in my Java Code and Swift Code to extract the result from Model Output.

Java

`float[][][] bert_output = new float[1][MAX_SEQ_LEN][BERT_HIDDEN_LAYERS];` 
`bert_model.run(inputIds, bert_output); `
inputIds here is an Int Array
In Java I directly call **run** in the interpreter and pass the Input in inputIds as well as the output array object and at the end of it I get a populated Output array in bert_output.

Swift

In Swift the inference seems to work a little different. You have to convert Your input(Int Array) to Tensor format and also fetch the output in Tensor format and convert it back to Float array. I feel this is the part where things are going wrong but no way to confirm.

Convert Input into Tensor
`let input_tensor = inputIds.withUnsafeBufferPointer(Data.init)`
Copy Input to Model Input Layer 0
`try interpreter_bert?.copy(input, toInputAt: 0)`
Inference
`try interpreter_bert?.invoke()`
Copy Output Tensor from Output Layer 0
`let temp_res = try interpreter_bert?.output(at: 0)`
Convert Output Tensor Data to Float Array
`let mResult = BertHelper.TensorToArray<Float32>(tensor: temp_res!)`
You can find the Conversion code [here](https://pastebin.com/nThQw730)

After the Conversion, the Result Shape matches the Java result and Expected result but the probability values don't match up. 

It would be a big help if someone here could help me. Tensorflow documentation and examples where Model Interpreter is directly called, only showcase Models which work on images and the NLP examples use TensorflowTaskLibrary, hence putting my issue up here."
55573,training input shape changed after v2.7.0,"https://github.com/tensorflow/tensorflow/blob/92a6bb06549e74a8bd8cdb8e28552496e5520007/tensorflow/python/keras/engine/training.py#L798

There is a expand operation for 1d input data, but this op is missed in v2.7.0. I'd like to know why and how can i keep compatibility"
55572,Tensorflow Lite build for Android results in issue - class file not found,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): source
- TensorFlow version: master repo / nightly repo
- Python version: 3.7.3
- Installed using virtualenv? pip? conda?:
- Bazel version (if compiling from source): 5.1.1
- GCC/Compiler version (if compiling from source): 7.5.0
- CUDA/cuDNN version: not using cuda
- GPU model and memory: not using GPU



**Describe the problem**

I am trying to use custom-built tensorflow lite AAR on model personalization example of official tensorflow repo from the [link](https://github.com/tensorflow/examples/tree/master/lite/examples/model_personalization)

Before I change anything from the master repository, I followed the steps in this [link](https://www.tensorflow.org/lite/guide/build_android) to build Tensorflow Lite AAR with bazel.

Actually the bazel build did not flawlessly work at once; I had to change the visibility option of 'op_resolver_internal' to public in tensorflow/lite/core/api/BUILD to successfully build the AAR.

Anyways, when I substituted the tensorflow-lite api with my built AARs, I get the following error:

Error 1:
android\transfer_api\src\main\java\org\tensorflow\lite\examples\transfer\api\LiteMultipleSignatureModel.java:57: error: cannot access InterpreterApi
    this.interpreter.runSignature(inputs, outputs, ""load"");
                    ^
  class file for org.tensorflow.lite.InterpreterApi not found

Error 2:
android\transfer_api\src\main\java\org\tensorflow\lite\examples\transfer\api\LiteMultipleSignatureModel.java:105: error: cannot access Tensor
    return this.interpreter.getInputTensorFromSignature(""bottleneck"", ""train"").shape()[1];
                                                       ^
  class file for org.tensorflow.lite.Tensor not found

Why does this happen?? Is there anything wrong with the current bazel build?

I also built the tensorflow-lite-select-tf-ops.aar and included that in build.gradle.

**Provide the exact sequence of commands / steps that you executed before running into the problem**

Described above

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
55571,building tensorflow with docker image fails,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Ubuntu 20.04(in docker)
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):source
- TensorFlow version: master branch
- Python version:3.8
- Installed using virtualenv? pip? conda?:
- Bazel version (if compiling from source):5.1.0
- GCC/Compiler version (if compiling from source):gcc9.4.0
- CUDA/cuDNN version:cuda11.2 cudnn8
- GPU model and memory:RTX3090



**Describe the problem**
i follow the instruction in the tensorflow document to build the source with docker.I pulled the devel-gpu image and and try to build source in the container. i found using the command in the document i went to the directory  ""tensorflow"",but it cant pull as it is not a git repo, go to the directory “tensorflow_src"" it can work but i can not checkout branch like r2.7,so i build the master branch with default configuration and i got the error.Really confused me. 
**Provide the exact sequence of commands / steps that you executed before running into the problem**
bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
/root/.cache/bazel/_bazel_root/43801f1e35f242fb634ebbc6079cf6c5/external/nsync/BUILD:467:11: Compiling platform/c++11/src/nsync_panic.cc failed: (Exit 1): crosstool_wrapper_driver_is_not_gcc failed: error executing command 
  (cd /root/.cache/bazel/_bazel_root/43801f1e35f242fb634ebbc6079cf6c5/execroot/org_tensorflow && \
  exec env - \
    CUDA_TOOLKIT_PATH=/usr/local/cuda-11.2 \
    GCC_HOST_COMPILER_PATH=/usr/bin/x86_64-linux-gnu-gcc-9 \
    LD_LIBRARY_PATH=/usr/local/cuda-11.0/targets/x86_64-linux/lib:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64:/usr/include/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/lib64/stubs:/usr/local/cuda-11.0/lib64:/usr/local/cuda-11.2/lib64 \
    PATH=/root/.cache/bazelisk/downloads/bazelbuild/bazel-5.1.0-linux-x86_64/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \
    PWD=/proc/self/cwd \
    PYTHON_BIN_PATH=/usr/bin/python3 \
    PYTHON_LIB_PATH=/usr/lib/python3/dist-packages \
    TF2_BEHAVIOR=1 \
    TF_CUDA_COMPUTE_CAPABILITIES=8.6 \
    TF_CUDA_VERSION=11.2 \
    TF_CUDNN_VERSION=8 \
  external/local_config_cuda/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -MD -MF bazel-out/k8-opt/bin/external/nsync/_objs/nsync_cpp/nsync_panic.d '-frandom-seed=bazel-out/k8-opt/bin/external/nsync/_objs/nsync_cpp/nsync_panic.o' -iquote external/nsync -iquote bazel-out/k8-opt/bin/external/nsync -isystem external/nsync/public -isystem bazel-out/k8-opt/bin/external/nsync/public -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' -fPIE -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -Wall -fno-omit-frame-pointer -no-canonical-prefixes -fno-canonical-system-headers -DNDEBUG -g0 -O2 -ffunction-sections -fdata-sections -w -DAUTOLOAD_DYNAMIC_KERNELS -Wno-sign-compare '-std=c++14' -x c++ '-std=c++11' -I./external/nsync//platform/c++11.futex -DNSYNC_ATOMIC_CPP11 -DNSYNC_USE_CPP11_TIMEPOINT -I./external/nsync//platform/c++11 -I./external/nsync//platform/gcc -I./external/nsync//platform/x86_64 -I./external/nsync//public -I./external/nsync//internal -I./external/nsync//platform/posix '-D_POSIX_C_SOURCE=200809L' -pthread -c external/nsync/platform/c++11/src/nsync_panic.cc -o bazel-out/k8-opt/bin/external/nsync/_objs/nsync_cpp/nsync_panic.o)
# Configuration: c750dc19fc82070b294558f14293082aaaae479c4ce153dc94857ec7a3f60c5d
# Execution platform: @local_execution_config_platform//:platform
In file included from /usr/include/c++/9/mutex:44,
                 from ./external/nsync//platform/c++11.futex/../c++11/platform.h:29,
                 from ./external/nsync//platform/c++11.futex/platform.h:22,
                 from ./external/nsync//internal/headers.h:19,
                 from external/nsync/platform/c++11/src/nsync_panic.cc:15:
/usr/include/c++/9/bits/unique_lock.h: In instantiation of ‘void std::unique_lock<_Mutex>::lock() [with _Mutex = std::mutex]’:
./external/nsync//platform/c++11.futex/../c++11/platform.h:99:14:   required from here
/usr/include/c++/9/bits/unique_lock.h:136:35: internal compiler error: Segmentation fault
  136 |    __throw_system_error(int(errc::operation_not_permitted));
"
55569,Illegal Instruction,"I literally just imported the library........
that's it, I import it and it errors. A brutal re-welcoming and a goodbye to this library.

Ubuntu
I was using Python.
I'm on an Intel laptop. "
55568,Bug in tf.saved_model.load(): 'NormalizeUTF8' not in self._op_def_cache,"I load my model with just these two lines of code:
```
import tensorflow as tf
reloaded = tf.saved_model.load('my_model')
```

But I get the error below. HOWEVER! When I also import tensorflow_text, everything works:
```
import tensorflow as tf
import tensorflow_text
reloaded = tf.saved_model.load('my_model')
```

I don't actually call anything from tensorflow_text. I believe when tensorflow_text is imported, it updates self._op_def_cache in the Graph class in `tensorflow/python/framework/ops.py`.

I tested this on both Mac and Windows, in jupyter notebook and an IDE. Behavior is the same.


The error:
```
--------------------------------------------------------------------------
KeyError                                  Traceback (most recent call last)
~\anaconda3\lib\site-packages\tensorflow\python\framework\ops.py in _get_op_def(self, type)
   4176     try:
-> 4177       return self._op_def_cache[type]
   4178     except KeyError:

KeyError: 'NormalizeUTF8'

During handling of the above exception, another exception occurred:

NotFoundError                             Traceback (most recent call last)
~\anaconda3\lib\site-packages\tensorflow\python\saved_model\load.py in load_internal(export_dir, tags, options, loader_cls, filters)
    974         loader = loader_cls(object_graph_proto, saved_model_proto, export_dir,
--> 975                             ckpt_options, options, filters)
    976       except errors.NotFoundError as err:

~\anaconda3\lib\site-packages\tensorflow\python\saved_model\load.py in __init__(self, object_graph_proto, saved_model_proto, export_dir, ckpt_options, save_options, filters)
    151             saved_object_graph=self._proto,
--> 152             wrapper_function=_WrapperFunction))
    153     # Store a set of all concrete functions that have been set up with

~\anaconda3\lib\site-packages\tensorflow\python\saved_model\function_deserialization.py in load_function_def_library(library, saved_object_graph, load_shared_name_suffix, wrapper_function)
    408           structured_input_signature=structured_input_signature,
--> 409           structured_outputs=structured_outputs)
    410     # Restores gradients for function-call ops (not the same as ops that use

~\anaconda3\lib\site-packages\tensorflow\python\framework\function_def_to_graph.py in function_def_to_graph(fdef, structured_input_signature, structured_outputs, input_shapes)
     70   graph_def, nested_to_flat_tensor_name = function_def_to_graph_def(
---> 71       fdef, input_shapes)
     72 

~\anaconda3\lib\site-packages\tensorflow\python\framework\function_def_to_graph.py in function_def_to_graph_def(fdef, input_shapes)
    238     else:
--> 239       op_def = default_graph._get_op_def(node_def.op)  # pylint: disable=protected-access
    240 

~\anaconda3\lib\site-packages\tensorflow\python\framework\ops.py in _get_op_def(self, type)
   4181         pywrap_tf_session.TF_GraphGetOpDef(self._c_graph, compat.as_bytes(type),
-> 4182                                            buf)
   4183         # pylint: enable=protected-access

NotFoundError: Op type not registered 'NormalizeUTF8' in binary running on DESKTOP-CTLPA1S. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.

During handling of the above exception, another exception occurred:

FileNotFoundError                         Traceback (most recent call last)
<ipython-input-2-20584f519f7a> in <module>
----> 1 reloaded = tf.saved_model.load('translator')

~\anaconda3\lib\site-packages\tensorflow\python\saved_model\load.py in load(export_dir, tags, options)
    934     ValueError: If `tags` don't match a MetaGraph in the SavedModel.
    935   """"""
--> 936   result = load_internal(export_dir, tags, options)[""root""]
    937   return result
    938 

~\anaconda3\lib\site-packages\tensorflow\python\saved_model\load.py in load_internal(export_dir, tags, options, loader_cls, filters)
    976       except errors.NotFoundError as err:
    977         raise FileNotFoundError(
--> 978             str(err) + ""\n You may be trying to load on a different device ""
    979             ""from the computational device. Consider setting the ""
    980             ""`experimental_io_device` option in `tf.saved_model.LoadOptions` ""

FileNotFoundError: Op type not registered 'NormalizeUTF8' in binary running on DESKTOP-#####. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed.
 You may be trying to load on a different device from the computational device. Consider setting the `experimental_io_device` option in `tf.saved_model.LoadOptions` to the io_device such as '/job:localhost'.
```"
55565,tf.keras.metrics.MeanIoU outcome is not improving,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): 2.8.0
- Python version: 3.95

**Describe the current behavior**
I am using tf.keras.metrics.MeanIoU as a metric in a semantic segmentation problem. All of the other metrics (accuracy, precision, recall) are changing during training but MeanIoU does not change. I am using tf.keras.losses.CategoricalCrossentropy(from_logits=False) for my loss function.

This issue has been reported in the following two StackOverFlow but no solution provided yet.

https://stackoverflow.com/questions/71729853/tf-keras-metrics-meaniou-outcome-is-not-improving/71813168#71813168

https://stackoverflow.com/questions/70848143/mean-iou-in-tensorflow-not-updating-resulting-in-correct-value/71813135#71813135

Here is an example of metrics during training:

Epoch 1/30

Epoch 1: val_loss improved from inf to 2.39962, saving model to /content/drive/MyDrive/Colab/test/semantic_segmentation/models_trained/training-min-val_loss.hdf5
269/269 - 899s - loss: 0.2277 - accuracy: 0.9108 - IoU: 0.2500 - val_loss: 2.3996 - val_accuracy: 0.9286 - val_IoU: 0.8372 - lr: 0.0010 - 899s/epoch - 3s/step
Epoch 2/30

Epoch 2: val_loss did not improve from 2.39962
269/269 - 853s - loss: 0.1805 - accuracy: 0.9320 - IoU: 0.2500 -  val_loss: 4.5132 - val_accuracy: 0.9244 - val_IoU: 0.8303 -  lr: 0.0010 - 853s/epoch - 3s/step
Epoch 3/30

Epoch 3: val_loss did not improve from 2.39962
269/269 - 817s - loss: 0.1672 - accuracy: 0.9380 - IoU: 0.2500 -  val_loss: 3.2384 - val_accuracy: 0.9198 - val_IoU: 0.8092 - lr: 0.0010 - 817s/epoch - 3s/step
Epoch 4/30

Epoch 4: val_loss improved from 2.39962 to 0.36882, saving model to /content/drive/MyDrive/Colab/test/semantic_segmentation/models_trained/training-min-val_loss.hdf5
269/269 - 855s - loss: 0.1643 - accuracy: 0.9390 - IoU: 0.2500 - val_loss: 0.3688 - val_accuracy: 0.9337 - val_IoU: 0.2600 -  lr: 0.0010 - 855s/epoch - 3s/step

If I change my one hot encoded labels to a one band maks, use SparseCategoricalAccuracy and the following modified MeanIoU....it works all fine.

class SparseMeanIoU(tf.keras.metrics.MeanIoU):
  def __init__(self,
               y_true=None,
               y_pred=None,
               num_classes=None,
               name=None,
               dtype=None):
    super(SparseMeanIoU, self).__init__(num_classes = num_classes,name=name, dtype=dtype)

  def update_state(self, y_true, y_pred, sample_weight=None):
    y_pred = tf.math.argmax(y_pred, axis=-1)
    return super().update_state(y_true, y_pred, sample_weight)

**Describe the expected behavior**
MeanIoU should change during training.

- Do you want to contribute a PR? (yes/no): no
"
55564,Tensorflow ERROR - Testing a linear regression model using TensorFlow,"I'm trying to resolve an error in tensoflow but I can't understand what the error is. I can't understand what the type [('resource', 'u1')] is and what that means.
I am studying the book Mastering OpenCV 4 with Python by the author Alberto Fernandez Villan, but the code is outdated, I have already updated everything according to version 2.8 of tensorflow, but now this error appears. can you help me? Here is the complete code and the error.

numpy version: 1.22.3
tensorflow version: 2.8.0

-------------------------------------------------------------------------------------

import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt
tf.compat.v1.disable_eager_execution()

# Number of points:
N = 50

# Make random numbers predictable:
np.random.seed(101)
tf.compat.v1.set_random_seed(101)

# Generate random data composed by 50 (N = 50) points:
x = np.linspace(0, N, N) #float64
y = 3 * np.linspace(0, N, N) + np.random.uniform(-10, 10, N) #float64

# Number of points to predict:
M = 3

# Define 'M' more points to get the predictions using the trained model:
new_x = np.linspace(N + 1, N + 10, M) #float64


# Restore the model.
# First step when loading a model is to load the graph from '.meta':
tf.compat.v1.reset_default_graph()
imported_meta = tf.compat.v1.train.import_meta_graph(""linear_regression.meta"")

# The second step when loading a model is to load the values of the variables:
# Note that values only exist within a session
with tf.compat.v1.Session() as sess:
    imported_meta.restore(sess, './linear_regression')
    # Run the model to get the values of the variables W, b and new prediction values:
    W_estimated = sess.run('W:0')
    b_estimated = sess.run('b:0')
    new_predictions = sess.run(['y_model:0'], {'X:0': new_x}) #[array([153.04472, 166.54755, 180.05037], dtype=float32)]
    print(W_estimated.dtype)
    print(b_estimated.dtype)

# Reshape for proper visualization:
new_predictions = np.reshape(new_predictions, (M, -1)) #float32

# Calculate the predictions:
predictions = W_estimated * x + b_estimated

# Create the dimensions of the figure and set title:
fig = plt.figure(figsize=(12, 5))
plt.suptitle(""Linear regression using TensorFlow"", fontsize=14, fontweight='bold')
fig.patch.set_facecolor('silver')

# Plot training data:
plt.subplot(1, 3, 1)
plt.plot(x, y, 'ro', label='Original data')
plt.xlabel('x')
plt.ylabel('y')
plt.title(""Training Data"")
plt.legend()

# Plot results:
plt.subplot(1, 3, 2)
plt.plot(x, y, 'ro', label='Original data')
plt.plot(x, predictions, label='Fitted line')
plt.xlabel('x')
plt.ylabel('y')
plt.title('Linear Regression Result')
plt.legend()

# Plot new predicted data:
plt.subplot(1, 3, 3)
plt.plot(x, y, 'ro', label='Original data')
plt.plot(x, predictions, label='Fitted line')
plt.plot(new_x, new_predictions, 'bo', label='New predicted data')
plt.xlabel('x')
plt.ylabel('y')
plt.title('Predicting new points')
plt.legend()

# Show the Figure:
plt.show()


---------------------------------------------------------------------------------
ERROR: line 51, in <module>predictions = W_estimated * x + b_estimated
numpy.core._exceptions.UFuncTypeError: ufunc 'multiply' did not contain a loop with signature matching types (dtype([('resource', 'u1')]), dtype('float64')) -> None"
55563,Build failed: undeclared inclusion(s) in rule '@llvm-project//mlir:GPUTransforms',"**System information**

- Have I written custom code: No
- OS Platform and Distribution: Ubuntu 20.04.4 LTS x86_64
- TensorFlow version: Latest commit [`55645ca`](https://github.com/tensorflow/tensorflow/commit/55645ca964508507890529a71591f51a344a6356)
- Python version: 3.10.4
- Bazel version (if compiling from source): 5.1.1
- GCC/Compiler version (if compiling from source): 9.4.0
- CUDA/cuDNN version: No CUDA
- GPU model and memory: No GPU

I am trying to build Tensorflow with TPU support on a Cloud TPU VM.

I have successfully built [v2.8.0](https://github.com/tensorflow/tensorflow/tree/v2.8.0) before, but now it shows an error:

```
$ bazel build --config=tpu //tensorflow/tools/pip_package:build_pip_package
...
ERROR: /home/ayaka/.cache/bazel/_bazel_ayaka/daa247f909e330d435159750c8dca57c/external/llvm-project/mlir/BUILD.bazel:3385:11: Compiling mlir/lib/Dialect/GPU/Transforms/SerializeToCubin.cpp failed: undeclared inclusion(s) in rule '@llvm-project//mlir:GPUTransforms':
this rule is missing dependency declarations for the following files included by 'mlir/lib/Dialect/GPU/Transforms/SerializeToCubin.cpp':
  'bazel-out/k8-opt/bin/external/llvm-project/mlir/_virtual_includes/GPUBaseIncGen/mlir/Dialect/GPU/GPUOpsDialect.h.inc'
Target //tensorflow/tools/pip_package:build_pip_package failed to build
Use --verbose_failures to see the command lines of failed build steps.
INFO: Elapsed time: 269.070s, Critical Path: 131.50s
INFO: 3174 processes: 247 internal, 2927 local.
FAILED: Build did NOT complete successfully
```

I am willing to provide more information on this issue."
55560,Question: how to implement tf.gather with some other tf ops ?,"I am trying to implement tf.gather with some simple and common tf ops, because tf.gather is not supported in the ncnn deployment framework currently, for now I can only think of implementing it with numpy:
```
import tensorflow as tf 

indices = [3, 5, 2]

params = tf.constant([[[11, 12, 13], 
                    [14, 15, 16], 
                    [17, 18, 19],
                    [21, 22, 23],
                    [24, 25, 26], 
                    [27, 28, 29]],
                    [[31, 32, 33],
                    [34, 35, 36],
                    [37, 38, 39],
                    [41, 42, 43],
                    [44, 45, 46],
                    [47, 48, 49]]])
print(""==>> params.shape: "", params.shape)
res = tf.gather(indices = indices, params = params, axis=1)
print(""==>> res: "", res)
print(""==>> res.shape: "", res.shape)

def gather(params, indices):
    """""" equivalent to tf.gather(axis=1)""""""
    output_shape = [params.shape[0], len(indices), params.shape[2]]
    params = params.numpy()
    output_tensor = params[:,indices,:]
    return tf.constant(output_tensor,dtype=tf.float32)

res2 = gather(params,indices)
print(""==>> res2: "", res2)
print(""==>> res2.shape: "", res2.shape)
``` 
If I don't convert the type of tensor to numpy by `params = params.numpy()`, it will reports error:
```
TypeError: Only integers, slices (`:`), ellipsis (`...`), tf.newaxis (`None`) and scalar tf.int32/tf.int64 tensors are valid indices, got [3, 5, 2]
```
So how to implement tf.gather with some other tf ops and  without numpy, thanks in advance !"
55551,Unexpected failure when preparing tensor allocations: tensorflow/lite/kernels/reshape.cc:85 num_input_elements != num_output_elements (1280 != 0),"### 1. System information

OS: Windows 10:
TensorFlow: 2.7.1:

### 2. Code

python version : 3.7.13  / 64 bit

#### Code used to create and convert transfer learning tflite model 

```
import tensorflow as tf
import numpy as np
import os

IMG_SIZE = 32
NUM_CLASSES = 10
NUM_FEATURES = 1 * 1 * 1280
BATCH_SIZE = 32


class TransferLearningModel(tf.Module):

    def __init__(self, learning_rate=0.01):
        """"""
        Initializes a transfer learning model instance.

        Parameters:
            learning_rate (float) : A learning rate for the optimzer.
        """"""

        # - head model
        # ? DEBATABLE IF THE INPUT SHAPE SHOULD BE DECLARED ON THE FIRST LAYER
        self.head_model = tf.keras.Sequential([
            tf.keras.layers.Dense(128, activation='relu', name='dense_1', input_shape=([NUM_FEATURES])),
            tf.keras.layers.Dense(NUM_CLASSES, name='dense_2')])

        # - base model
        self.base_model = tf.keras.applications.MobileNetV2(
            input_shape=(IMG_SIZE, IMG_SIZE, 3),
            alpha=1.0,
            include_top=False,
            weights='imagenet')

        # ? from_logits = True or False
        # - loss function
        self.loss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=True)

        # - optimizer
        self.optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate)

        self.head_model.compile(optimizer=self.optimizer,
                                loss=self.loss_fn)

    @tf.function(input_signature=[tf.TensorSpec([None, IMG_SIZE, IMG_SIZE, 3], tf.float32), ])
    # * TESTED
    def load(self, feature):
        """"""
        Generates and loads bottleneck features from the given image batch.

        Parameters:
            feature: A tensor of image feature batch to generate the bottleneck from.
        Returns:
            Map of the bottleneck.
        """"""

        # - Preprocesses a tensor or Numpy array encoding a batch of images.
        x = tf.keras.applications.mobilenet_v2.preprocess_input(
            tf.multiply(feature, 255))

        # - reshapes the base_model output to 1,1*1*1280(1 is image size downsampled five times
        # - and 1280 is the number of features extracted)
        base_model_output = self.base_model(x, training=False)
        bottleneck = tf.reshape(
            base_model_output, (-1, NUM_FEATURES))

        return {'bottleneck': bottleneck}

    # - passes the bottleneck features trought the head model
    # * TESTED
    @tf.function(input_signature=[
        tf.TensorSpec([None, NUM_FEATURES], tf.float32),
        tf.TensorSpec([None, NUM_CLASSES], tf.float32), ])
    def train(self, bottleneck, label):
        """"""
        Runs one training step with the given bottleneck features and labels.

        Parameters:
            bottleneck: A tensor of bottleneck features generated from the base model.
            label: A tensor of class labels for the given batch.
        Returns:
            Map of the training loss.
        """"""

        with tf.GradientTape() as tape:
            logits = self.head_model(bottleneck)
            prediction = tf.nn.softmax(logits)

            loss = self.head_model.loss(prediction, label)
            # ? loss=self.loss_fn(prediction,label)

        gradients = tape.gradient(loss, self.head_model.trainable_variables)

        self.head_model.optimizer.apply_gradients(
            zip(gradients, self.head_model.trainable_variables))
        # ? self.optimizer.apply_gradients(zip(gradients, self.model.trainable_variables))

        result = {""loss"": loss}
        for grad in gradients:
            result[grad.name] = grad
        return result

    # * TESTED
    @tf.function(input_signature=[tf.TensorSpec([None, IMG_SIZE, IMG_SIZE, 3], tf.float32)])
    def infer(self, image):
        """"""
        Invokes an inference on the given image.

        Parameters:
                feature: A tensor of image feature batch to invoke an inference on.
        Returns:
                Map of the softmax output.
        """"""
        x = tf.keras.applications.mobilenet_v2.preprocess_input(
            tf.multiply(image, 255))
        bottleneck = tf.reshape(
            self.base_model(x, training=False), (-1, NUM_FEATURES))
        logits = self.head_model(bottleneck)
        return {'output': tf.nn.softmax(logits)}

    # * TESTED
    @tf.function(input_signature=[tf.TensorSpec(shape=[], dtype=tf.string)])
    def save(self, checkpoint_path: str):
        """"""
        Saves the trainable weights to the given checkpoint file.

        Parameters:
                checkpoint_path (String) : A file path to save the model.
        Returns:
                Map of the checkpoint file path.
        """"""

        tensor_names = [weight.name for weight in self.head_model.weights]
        tensors_to_save = [weight.read_value() for weight in self.head_model.weights]
        tf.raw_ops.Save(
            filename=checkpoint_path,
            tensor_names=tensor_names,
            data=tensors_to_save,
            name='save')

        return {'checkpoint_path': checkpoint_path}

    # * TESTED
    @tf.function(input_signature=[tf.TensorSpec(shape=[], dtype=tf.string)])
    def restore(self, checkpoint_path):
        """"""
        Restores the serialized trainable weights from the given checkpoint file.

        Paramaters:
            checkpoint_path (String) : A path to a saved checkpoint file.
        Returns:
            Map of restored weights and biases.
        """"""
        restored_tensors = {}
        for tensor in self.head_model.weights:
            restored = tf.raw_ops.Restore(file_pattern=checkpoint_path,
                                          tensor_name=tensor.name,
                                          dt=tensor.dtype,
                                          name='restore')
            tensor.assign(restored)
            restored_tensors[tensor.name] = restored

        return restored_tensors

    # * TESTED
    @tf.function
    def extract_weights(self):
        """"""
        Extracts the traininable weights of the head model as a list of numpy arrays.

        Paramaters:

        Returns:
            Map of extracted weights and biases.
        """"""
        tmp_dict = {}
        tensor_names = [weight.name for weight in self.head_model.weights]
        tensors_to_save = [weight.read_value() for weight in self.head_model.weights]
        for index, layer in enumerate(tensors_to_save):
            tmp_dict[tensor_names[index]] = layer

        return tmp_dict


def convert_and_save(saved_model_dir='saved_model_new'):
    """"""
    Converts and saves the TFLite Transfer Learning model.

    Parameters:
        saved_model_dir: A directory path to save a converted model.
    Returns:
        NONE
    """"""
    transfer_learning_model = TransferLearningModel()

    tf.saved_model.save(
        transfer_learning_model,
        saved_model_dir,
        signatures={
            'load': transfer_learning_model.load.get_concrete_function(),
            'train': transfer_learning_model.train.get_concrete_function(),
            'infer': transfer_learning_model.infer.get_concrete_function(),
            'save': transfer_learning_model.save.get_concrete_function(),
            'restore': transfer_learning_model.restore.get_concrete_function(),
            'extract': transfer_learning_model.extract_weights.get_concrete_function()
        })

    # Convert the model
    converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)
    converter.target_spec.supported_ops = [
        tf.lite.OpsSet.TFLITE_BUILTINS,  # enable TensorFlow Lite ops.
        tf.lite.OpsSet.SELECT_TF_OPS  # enable TensorFlow ops.
    ]

    converter.experimental_enable_resource_variables = True
    tflite_model = converter.convert()

    model_file_path = os.path.join('model.tflite')
    with open(model_file_path, 'wb') as model_file:
        model_file.write(tflite_model)

if __name__ == '__main__':
    model = TransferLearningModel()
    convert_and_save()
```
Android Dependency:

implementation 'org.tensorflow:tensorflow-lite:2.7.0'

I have to specify that the inputs map will load an object of size [1][32][32][3]
and outputs of [1][1280] as i've seen while debugging.

Android method called:
```

  float[] loadBottleneck(float[][][] image) {

    Map<String, Object> inputs = new HashMap<>();
    inputs.put(""feature"", new float[][][][]{image});
    Map<String, Object> outputs = new HashMap<>();
    float[][] bottleneck = new float[1][BOTTLENECK_SIZE];
    outputs.put(""bottleneck"", bottleneck);
    this.interpreter.runSignature(inputs, outputs, ""load"");
    return bottleneck[0];
  }
```

Error got :

 Internal error: Unexpected failure when preparing tensor allocations: tensorflow/lite/kernels/reshape.cc:85 num_input_elements != num_output_elements (1280 != 0)
    Node number 70 (RESHAPE) failed to prepare.


Node 70 (the reshape one) from netron visualization:
![image](https://user-images.githubusercontent.com/62502494/162421884-07b510eb-fdd5-4c24-98de-ff2b43578c1f.png)
![image](https://user-images.githubusercontent.com/62502494/162422010-7d168c59-ee6e-427d-8afc-2fb210bebf2c.png)


"
55550,"tf.io.decode_image(img, channels=1) has different results for a RGB image and a RGBA image where A is set to 255. ","**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 Build 19044
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:  /
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.3.0
- Python version: 3.8.8
- Bazel version (if compiling from source): /
- GCC/Compiler version (if compiling from source): /
- CUDA/cuDNN version: /
- GPU model and memory: /

**Describe the current behavior**
`tf.io.decode_image(img, channels=1)` should convert the input image to grayscale ([see link](https://www.tensorflow.org/api_docs/python/tf/io/decode_png#accepted_values_are)), the results for an RGB image and a RGBA image where the A dimensions is just 255 should be the same but they are not.

`tf.image.rgb_to_grayscale(img)` also does not yield the same result as the `decode_image` version. 

**Describe the expected behavior**
It seems to me that both the RGB and the RGBA image (with A=255) should yield the same result when using `decode_image `with channels=1?  The output from `rgb_to_grayscale`  is also different which is odd, shouldn't the implementation be very similar?

**Standalone code to reproduce the issue**
Example image and notebook in attachment:
[decode_image_bug.zip](https://github.com/tensorflow/tensorflow/files/8449964/decode_image_bug.zip)

**Other info / logs** 
/


"
55549,GPU has no significant performance benefit over CPU.,"<em>Please make sure that this is an issue related to performance of TensorFlow.
As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:performance_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 11 [21H2 - 22000.556]
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): Binary
- TensorFlow version (use command below): v2.8.0-rc1-32-g3f878cff5b6 2.8.0
- Python version: Python 3.10
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 
```
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2022 NVIDIA Corporation
Built on Tue_Mar__8_18:36:24_Pacific_Standard_Time_2022
Cuda compilation tools, release 11.6, V11.6.124
Build cuda_11.6.r11.6/compiler.31057947_0
```
- GPU model and memory:
```
name: NVIDIA GeForce RTX 3080 Laptop GPU
memory: 13626 MB
compute capability: 8.6
```

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
Training a 3-layer neural network on CPU on the MNIST fashion dataset:
Epoch 1:
```
CPU: 72s 1ms/step
GPU: 60s 977us/step
```
Epoch 2:
```
CPU: 73s 1ms/step
GPU: 58s 974us/step
```
Epoch 3:
```
CPU: 73s 1ms/step
GPU: 59s 976us/step
```

For reference, my CPU and System Memory are: 
```
11th Gen Intel(R) Core(TM) i9-11900H @ 2.50GHz (Max Turbo: 4.90 GHz)
L1 cache: 640KB
L2 cache: 10.0MB
L3 cache: 24.0MB

32GB DDR4 (Hardware Reserved: 323 MB)
```

**Describe the expected behavior**
While I'm fairly new to working with Tensorflow in the grand scheme of things, I've worked with Tensorflows using GPUs in the past. 

As one can note from the current behavior, the performance benefits for training over a GPU vs a CPU are minimal at best (max 15s time reduction per epoch). I may be incorrect, but shouldn't the performance benefits be far more substantial? Considering GPUs can parallelize a large chunk of this. 

**Standalone code to reproduce the issue**
```py
import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt

tf.get_logger().setLevel(""INFO"")
# tf.debugging.set_log_device_placement(True)
tf.config.experimental.set_memory_growth(
    device=tf.config.list_physical_devices(""GPU"")[0],
    enable=True
)

def test_gpu():
    print(""Num GPUs Available: "", len(tf.config.list_physical_devices('GPU')))


# Image Classes (Input Image)
# Input Image = 28x28
# Input Layer: (28 * 28) = 784 Neurons
# Hidden Layer [1]
# Output Classes: 5
# Output Layer: 5 Neurons (Val: [0, 1]), simga(output_layer) = 1
# Activation FX: f(sigma(layer) + b)
# Cost/Loss FX: distance(expected, current) [MSE, MAE, HL]
# Gradient Descent: Function to tell us how to make cost/loss
# as minimum as possible. (Optimizing cost/loss fx)
# Optimizers just implement the above functions in different ways.
def nn_task():
    mnist = keras.datasets.fashion_mnist
    # (60K, 28, 28), [0, 0, 0] = 0  ---- 0: Black, 255: White
    (train_features, train_labels), (test_features, test_labels) = mnist.load_data()
    print(train_features.shape)
    label_names = [
        ""Top"", ""Bottom"", ""Pullover"",
        ""Dress"", ""Coat"", ""Sandal"",
        ""Dress Shirt"", ""Sneaker"",
        ""Bag"", ""Ankle Boot""
    ]

    # plt.figure()
    # plt.imshow(train_features[0])
    # plt.colorbar()
    # plt.gray()
    # plt.plot()
    # plt.pause(5)

    # Normalize to scale of [0, 1]
    # Ensures that values only range from 0 to 1.
    train_features = train_features / 255
    test_features = test_features / 255

    model = keras.Sequential([
        # Flattens the input to 784 neurons.
        keras.layers.Flatten(input_shape=(28, 28), name=""Input""),

        # Dense just means all neurons from previous
        # layer are connected to this layer too.
        # The number 128 is arbitrary - usually, you'd
        # want this number to be less than input neurons
        # but more than output neurons.
        # ReLU: x < 0 => y = 0 || x >= 0 => y = x
        keras.layers.Dense(128, activation=""relu"", name=""DataParser""),

        # Dense just means all neurons from previous
        # layer are connected to this layer too.
        # Layer size is based on how many classes we have.
        # Softmax: sigma(layer) = 1
        keras.layers.Dense(len(label_names), activation=""softmax"", name=""Output"")
    ], ""Fashion-Cloth-Classifier"")

    model.compile(
        optimizer=""adam"", 
        loss=""sparse_categorical_crossentropy"",  # We use SCCE for loss.
        metrics=[""accuracy""]  # Check only the accuracy metric.
    )
    model.summary()

    with tf.device(""/GPU:0""):  # Change this line to train on CPU or GPU
        model.fit(train_features, train_labels, epochs=10, batch_size=1)

    t_loss, t_acc = model.evaluate(test_features, test_labels, verbose=1)

    print(""Test Loss: "", t_loss)
    print(""Test Accuracy: "", t_acc)


def work():
    nn_task()


if __name__ == '__main__':
    test_gpu()
    work()

```
"
55546,TensorFlow Dataset has not correct shape,"Hi,
   I think the issue here is from the dataset, which doesn't populate the shape info for the sequence dim.

  It is becouse print(dataset) gives me:
`<ZipDataset element_spec=(TensorSpec(shape=(None, None, 25, 81), dtype=tf.float64, name=None), TensorSpec(shape=(None, None, 25, 1), dtype=tf.float64, name=None))> `.

The model knows from the dataset object only the last two axis, but I need to it knows the last 3 axis. 
The shape must be defined for example: `shape=(None, 7, 25, 81)` or `shape=(None, 7, 25, 1)`.

Thanks. 

## System information
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS 12.3 / Debian 5.10.70-1 (2021-09-30)
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.8.0 / 2.9.0-dev20220329
- Python version: Python 3.9.7 / Python 3.9.2
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source): Clang 11.1.0 / GCC 10.2.1
- CUDA/cuDNN version: No
- GPU model and memory: Apple M1, 16GB / No

## Code
```python
from tensorflow.keras.layers import Dense, Dropout, Layer, Input
from tensorflow.keras.initializers import TruncatedNormal
from tensorflow.keras.models import Model

import tensorflow as tf
import numpy as np

class PositionalEmbedding(Layer):
    def __init__(self, units, dropout_rate, **kwargs):
        super(PositionalEmbedding, self).__init__(**kwargs)

        self.units = units

        self.projection = Dense(units, kernel_initializer=TruncatedNormal(stddev=0.02))
        self.dropout = Dropout(rate=dropout_rate)

    def build(self, input_shape):
        super(PositionalEmbedding, self).build(input_shape)

        print(input_shape, '\n')
        self.position = self.add_weight(
            name=""position"",
            shape=(1, input_shape[1], input_shape[2], self.units),
            initializer=TruncatedNormal(stddev=0.02),
            trainable=True,
        )

    def call(self, inputs, training):
        x = self.projection(inputs)
        x += self.position

        return self.dropout(x, training=training)

class Transformer(Model):
    def __init__(
        self,
        embed_dim,
        dropout_rate,
        **kwargs
    ):
        super(Transformer, self).__init__(**kwargs)

        # Input
        self.pos_embs = PositionalEmbedding(embed_dim, dropout_rate)

    def compile(self, optimizer, loss):
        super(Transformer, self).compile()
        self.optimizer = optimizer
        self.loss = loss

    def call(self, inputs, training):
        inputs, targets = inputs
        
        return self.pos_embs(inputs, training=training)

    def train_step(self, inputs):
        inputs, targets = inputs

        print(inputs.shape)
        print(targets.shape, '\n')

        targets_inputs = targets[:, :-1]
        targets_real = targets[:, 1:]

        with tf.GradientTape() as tape:
            y_pred = self([inputs, targets_inputs], training=True)
            loss = self.loss(targets_real, y_pred)

        trainable_vars = self.trainable_variables
        gradients = tape.gradient(loss, trainable_vars)
        self.optimizer.apply_gradients(zip(gradients, trainable_vars))

        return {
            ""loss"": loss,
        }

def load_dataset(batch_size, window_size):
  x_all = np.ones((1000, 25, 81)) #np.load('./dataset/X_all.npy')
  y_all = np.ones((1000, 25, 1)) #np.load('./dataset/y_all.npy')

  inputs_dataset = tf.keras.preprocessing.timeseries_dataset_from_array(
      x_all, None, sequence_length=window_size, sequence_stride=(window_size // 2), batch_size=batch_size)
  targets_dataset = tf.keras.preprocessing.timeseries_dataset_from_array(
      y_all, None, sequence_length=window_size, sequence_stride=(window_size // 2), batch_size=batch_size)

  return inputs_dataset, targets_dataset



# load dataset
inputs_dataset, targets_dataset = load_dataset(
      batch_size=64,
      window_size=7,
)
dataset = tf.data.Dataset.zip((inputs_dataset, targets_dataset))

for batch in dataset:
    inputs, targets = batch
    print(inputs.shape)
    print(targets.shape, '\n')
    break

sample_transformer = Transformer(
    embed_dim=256, dropout_rate=0.1,
)

sample_transformer.compile(
      loss=tf.keras.losses.mean_squared_error,
      optimizer=tf.keras.optimizers.Adam(),
)

# Train model
sample_transformer.fit(
      dataset,
      epochs=10
)
```"
55545,tf.keras.layers.BatchNormalization computes moving variances inconsistently when `fused=True` vs. when `fused=False` ,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 20.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.8.0 (gpu)
- Python version: 3.10.2
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: 11.5/8.3.1
- GPU model and memory: 1080 Ti 12GB

**Describe the current behavior**

`tf.keras.layers.BatchNormalization` computes moving variances inconsistently when `fused=True` vs when `fused=False`. When `fused=False` it computes it with 

             next_variance=old_variance*momentum+batch_variance*(1-momentum)

whereas when `fused=True` it computes it with: 

             next_variance=old_variance*momentum+batch_variance*(1-momentum)*bessel_coefficient_correction

**This is a very minor bug when n is large** as bessel_coefficient_correction tends to 1. But when number of elements per channel is small it becomes noticeable. Below I gave an example code for when elements per channel is 2.

**Describe the expected behavior**

I would expect `fused=True` and `fused=False` to be consistent.

- Do you want to contribute a PR? (yes/no): no

**Solution**

I think the issue lies [here](https://github.com/tensorflow/tensorflow/blob/b89a2f2a1b761ac68aa808f2bcd847314b15c6c1/tensorflow/core/kernels/fused_batch_norm_op.cc#L213). In which you can see the bessel_coefficient_correction as `rest_size_adjust`. Either that should be removed in fused batch norm or it should be added for non-fused batch norm.

**Standalone code to reproduce the issue**

```
import tensorflow as tf
from math import sqrt


with tf.device(""/cpu:0""):
# with tf.device(""/gpu:0""):
    var = 5.0
    std = sqrt(var)
    n=2
    inp = tf.random.normal((1,n,1,1))
    true_mean = tf.reduce_mean(inp, axis=(0, 1, 2)).numpy()
    print(""True mean: "" + str(true_mean))
    true_var = tf.math.reduce_variance(inp, axis=(0, 1, 2)).numpy()
    print(""True variance: "" + str(true_var))

    for momentum in [0.0, 0.25, 0.75, 0.9]:
        for fused in [True, False]:
            layer = tf.keras.layers.BatchNormalization(
                scale=True, center=True, trainable=True, momentum=momentum, fused=fused
            )
            initial_mean = 0.0
            initial_var = 1.0
            out = layer(inp, training=True)
            print(""\n==========================="")
            print(""Momentum: "" + str(momentum) + "" Fused: "" + str(fused))
            print(""Moving mean: "" + str(layer.moving_mean.numpy()))
            print(
                ""Moving mean always correctly computed: ""
                + str(initial_mean * momentum + true_mean * (1 - momentum))
            )
            print(f""Moving var computed with fused={fused}: "" + str(layer.moving_variance.numpy()))
            print(
                ""Moving var with Bessel correction: ""
                + str(initial_var * momentum + n/(n-1) * true_var * (1 - momentum))
            )
            print(
                ""Moving var without Bessel correction: ""
                + str(initial_var * momentum + true_var * (1 - momentum))
            )
            print(""===========================\n"")

```

See this gist: https://gist.github.com/canbakiskan/9a1fe01a218277539f9602081719a1c3"
55538,imdeu.htmi,"### 1. System information

git adt- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- TensorFlow installation (pip package or built from source):
- TensorFlow library (version, if pip package or github gtr SHA, if built comdlim t):

### 2. Code

Provide code to help us reproduce your issues using one of the following options:

#### Option A: Reference colab notebooks

1)  Reference [TensorFlow Model Colab](https://colab.research.google.com/gist/ymodak/e96a4270b953201d5362c61c1e8b78aa/tensorflow-datasets.ipynb?authuser=1): Demonstrate how to build your TF model.
2)  Reference [TensorFlow Lite Model Colab](https://colab.research.google.com/gist/ymodak/0dfeb28255e189c5c48d9093f296e9a8/tensorflow-lite-debugger-colab.ipynb): Demonstrate how to convert your TF model to a TF Lite model (with quantization, if used) and run TFLite Inference (if possible).

```
(You can paste links or attach files by dragging & dropping them below)
- Provide links to your updated versions of the above two colab notebooks.
- Provide links to your TensorFlow model and (optionally) TensorFlow Lite Model.
```

#### Option B: Paste your code here or provide a link to a custom end-to-end colab

```
(You can paste links or attach files by dragging & dropping them below)
- Include code to invoke the TFLite Converter Python API and the errors.
- Provide links to your TensorFlow model and (optionally) TensorFlow Lite Model.
```

### 3. Failure after conversion
If the conversion is successful, but the generated model is wrong, then state what is wrong:

- Model produces wrong results and/or has lesser accuracy.
- Model produces correct results, but it is slower than expected.

### 4. (optional) RNN conversion support
If converting TF RNN to TFLite fused RNN ops, please prefix [RNN] in the title.

### 5. (optional) Any other info / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
55537,Alom,"### 1. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- TensorFlow installation (pip package or built from source):
- TensorFlow library (version, if pip package or github SHA, if built from source):

### 2. Code

Provide code to help us reproduce your issues using one of the following options:

#### Option A: Reference colab notebooks

1)  Reference [TensorFlow Model Colab](https://colab.research.google.com/gist/ymodak/e96a4270b953201d5362c61c1e8b78aa/tensorflow-datasets.ipynb?authuser=1): Demonstrate how to build your TF model.
2)  Reference [TensorFlow Lite Model Colab](https://colab.research.google.com/gist/ymodak/0dfeb28255e189c5c48d9093f296e9a8/tensorflow-lite-debugger-colab.ipynb): Demonstrate how to convert your TF model to a TF Lite model (with quantization, if used) and run TFLite Inference (if possible).

```
(You can paste links or attach files by dragging & dropping them below)
- Provide links to your updated versions of the above two colab notebooks.
- Provide links to your TensorFlow model and (optionally) TensorFlow Lite Model.
```

#### Option B: Paste your code here or provide a link to a custom end-to-end colab

```
(You can paste links or attach files by dragging & dropping them below)
- Include code to invoke the TFLite Converter Python API and the errors.
- Provide links to your TensorFlow model and (optionally) TensorFlow Lite Model.
```

### 3. Failure after conversion
If the conversion is successful, but the generated model is wrong, then state what is wrong:

- Model produces wrong results and/or has lesser accuracy.
- Model produces correct results, but it is slower than expected.

### 4. (optional) RNN conversion support
If converting TF RNN to TFLite fused RNN ops, please prefix [RNN] in the title.

### 5. (optional) Any other info / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
55536,Adding Select Tf Ops to Cmake,"**System information**
- TensorFlow version (you are using): any
- Are you willing to contribute it (Yes/No): no



**Describe the feature and the current behavior/state.** 
Currently one has to decide between using Select TF ops with bazel or GPU support with CMake.
It would be nice if either bazel has an option to support GPU on any OpenCL system or CMake can build with TF Ops.

**Will this change the current api? How?**
No

**Who will benefit with this feature?**
Everybody who wants to use GPU acceleration and TF Ops.

"
55532,Bullet Points missing,"![image](https://user-images.githubusercontent.com/63838746/162250635-d3786b74-37f7-417d-855b-7c5647b7f4f1.png)
"
55531,buil,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version:
- Python version:
- Installed using virtualenv? pip? conda?:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:



**Describe the problem**

**Provide the exact sequence of commands / steps that you executed before running into the problem**


**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
55530,Test fail on r2.8: core:__tensorflow_core_lib_math_math_util_test   ,"EDIT: PR fixing this issue is https://github.com/tensorflow/tensorflow/pull/55730

<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): v2.8.0-2-ge994fb9c3ad 2.8.0
- Python version: 3.8.3
- Bazel version (if compiling from source): 0.25.2
- GCC/Compiler version (if compiling from source): gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A

**Describe the current behavior**

test fails

**Describe the expected behavior**

test passes

**[Contributing](https://www.tensorflow.org/community/contribute)**

- Do you want to contribute a PR? (yes/no): yes
- Briefly describe your candidate solution(if contributing):

[EDIT: Removed incorrect hypothesis]

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

```
$ git checkout r2.8
$ bazel  --host_jvm_args=-Xmx32g test --jobs=12  --config=dbg --verbose_failures -k //tensorflow/core:__tensorflow_core_lib_math_math_util_test   
```

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

[test.log](https://github.com/tensorflow/tensorflow/files/8443281/t.log)

"
55528,how to build v2.8.0 with verbs under centos7.8?,
55527,I would like to ask how to save the personalization model during training on device,"I would like to ask how to save the personalization model during training on device. If this personalization model can be used for transmission, it may be possible to implement federated learning for user privacy and security, and I would like to ask if this feature is supported or will be supported soon."
55526,Unable to load packages inside docker. All mirrors are down,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): source
- TensorFlow version:
- Python version: 3
- Installed using virtualenv? pip? conda?:
- Bazel version (if compiling from source): 0.16.1
- GCC/Compiler version (if compiling from source): 7.5.0
- CUDA/cuDNN version:
- GPU model and memory:



**Describe the problem**
I am testing tensorflow-lite example with my project. I am able to run tensorflow-lite along with my project on baremetal and it works fine. But when i run the same steps inside docker container, it throws the error 0 Package Loaded and all mirrors are down.

Please tell me what settings should be enabled in my docker environment to run this example

**Provide the exact sequence of commands / steps that you executed before running into the problem**
cd tensorflow && /root/bin/bazel build tensorflow/contrib/lite/examples/label_image

**Any other info / logs**
Starting local Bazel server and connecting to it...
ERROR: error loading package '': Encountered error while reading extension file 'closure/defs.bzl': no such package '@io_bazel_rules_closure//closure': Error downloading [https://mirror.bazel.build/github.com/bazelbuild/rules_closure/archive/dbb96841cc0a5fb2664c37822803b06dab20c7d1.tar.gz, https://github.com/bazelbuild/rules_closure/archive/dbb96841cc0a5fb2664c37822803b06dab20c7d1.tar.gz] to /intel/.cache/bazel/_bazel_root/98545780cf4453991b5570835db641da/external/io_bazel_rules_closure/dbb96841cc0a5fb2664c37822803b06dab20c7d1.tar.gz: All mirrors are down: []
ERROR: error loading package '': Encountered error while reading extension file 'closure/defs.bzl': no such package '@io_bazel_rules_closure//closure': Error downloading [https://mirror.bazel.build/github.com/bazelbuild/rules_closure/archive/dbb96841cc0a5fb2664c37822803b06dab20c7d1.tar.gz, https://github.com/bazelbuild/rules_closure/archive/dbb96841cc0a5fb2664c37822803b06dab20c7d1.tar.gz] to /intel/.cache/bazel/_bazel_root/98545780cf4453991b5570835db641da/external/io_bazel_rules_closure/dbb96841cc0a5fb2664c37822803b06dab20c7d1.tar.gz: All mirrors are down: []
INFO: Elapsed time: 57.362s
INFO: 0 processes.
FAILED: Build did NOT complete successfully (0 packages loaded)
"
55525,"XNNPack delegate support for quantized models, no latency improvement","

I built tensorflow with  --define tflite_with_xnnpack=true --define xnn_enable_qs8=true to have acceleration for quantized models. But I don't gain any improvement in the latency of the quantized models compared to when I build tensorflow with --define tflite_with_xnnpack=true alone. I tested both in windows and linux. I am testing on desktop with intel CPU.  Is there anything I am doing wrong? I tested with trained models too. I used the following code to quantize the model.:

```
import tensorflow as tf
import numpy as np
from tensorflow.keras.layers import *

from os import listdir
from os.path import isfile, join

def representative_dataset():
    folder = '.\\test'
    onlyfiles = [f for f in listdir(folder) if isfile(join(folder, f))]  #you can use random arrays I guess
    for file in onlyfiles:
        data = np.load(join(folder, file))
        data = np.expand_dims(data, axis=0)
        yield [tf.dtypes.cast(data, tf.float32)]

def SOC(input_tensor, classNumer=1, epsilonBN=1e-3):
    a = Input(shape=input_tensor)
    x = Conv2D(16, (3, 3), padding='same', use_bias=False, name=""Conv_1"")(a)
    x = BatchNormalization(epsilon=epsilonBN, name=""BN_1"")(x)
    x=Activation('relu')(x)
    x = MaxPooling2D(pool_size=(2, 2), name=""MaxPool_1"")(x)

    x = Conv2D(32, (3, 3), padding='same', use_bias=False, name=""Conv_2"")(x)
    x = BatchNormalization(epsilon=epsilonBN, name=""BN_2"")(x)
    x=Activation('relu')(x)
    x = MaxPooling2D(pool_size=(2, 2), name=""MaxPool_2"")(x)

    x = Conv2D(64, (3, 3), padding='same', use_bias=False, name=""Conv_3"")(x)
    x = BatchNormalization(epsilon=epsilonBN, name=""BN_3"")(x)
    x=Activation('relu')(x) 
    x = MaxPooling2D(pool_size=(2, 2), name=""MaxPool_3"")(x)

    x = Conv2D(128, (3, 3), padding='same', use_bias=False, name=""Conv_4"")(x)
    x = BatchNormalization(epsilon=epsilonBN, name=""BN_4"")(x)
    x = Activation('relu')(x)
    x = MaxPooling2D(pool_size=(2, 2), name=""MaxPool_4"")(x)

    x = Flatten()(x)
    x = Dense(classNumer, kernel_initializer='uniform', name=""Dense"")(x)
    model = tf.keras.Model(inputs=a, outputs=x)
    return model

new_model = SOC((32,32,5))
converter = tf.lite.TFLiteConverter.from_keras_model(new_model)
converter.optimizations = [tf.lite.Optimize.DEFAULT]
converter.representative_dataset = representative_dataset
tflite_quant_model = converter.convert()

with open('qmodel.tflite', 'wb') as f:
    f.write(tflite_quant_model)
````

**System information**
- OS: Windows 10 Pro
- Desktop, Intel(R) Core(TM) i7-9700K CPU 
- Tensorflow 2.9 built from source (tested with tensoflow 2.8 built from source on linux too)
- python 3.10
- Bazel 5.1.0
- Did not include gpu support on the tensorflow build in windows

"
55524,"Run ""bazel build --config=mkl --config=opt //tensorflow/tools/pip_package:build_pip_package --verbose_failures"" failed","**System information**
- CentOS Linux release 7.8.2003 (Core)


**Describe the current behavior**
bazel build --config=mkl --config=opt //tensorflow/tools/pip_package:build_pip_package --verbose_failures


logs:
![image](https://user-images.githubusercontent.com/13997135/162117884-3aa73da3-d0bc-4a37-b991-c7d49f91697e.png)
"
55522,"tflite gpu_delegate ""undefined symbol: glFenceSync""","**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 22.04 arm64
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): 2.8.0
- Python version: 3.10
- Bazel version (if compiling from source): 
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory: Mali G72

**Describe the current behavior**
i compiled tflite from source to test the gpu / gl delegate in python with
`bazel build -s -c opt --copt ""-DEGL_NO_X11"" --copt=""-DMESA_EGL_NO_X11_HEADERS"" tensorflow/lite/delegates/gpu:libtensorflowlite_gpu_delegate.so`

tflite inference and training works without loading the delegate, uses xnnpack delegate for cpu

if loading the gpu delegate, i get following error:
OSError: /home/linux/Documents/libtensorflowlite_gpu_delegate.so: undefined symbol: glFenceSync
**UPDATE: the loading takes places via following code:
`delegate = tf.lite.experimental.load_delegate('./libtensorflowlite_gpu_delegate.so')`
the error is exactly following:
OSError                                   Traceback (most recent call last)
/tmp/ipykernel_24874/1769046455.py in <module>
----> 1 delegate = tf.lite.experimental.load_delegate('./libtensorflowlite_gpu_delegate.so')
      2 model = tf.lite.Interpreter(model_content=tflite_model, experimental_delegates=[delegate])
      3 
      4 model.allocate_tensors()
      5 infer = generator_lite.get_signature_runner(""infer"")

~/.local/lib/python3.10/site-packages/tensorflow/lite/python/interpreter.py in load_delegate(library, options)
    173   """"""
    174   try:
--> 175     delegate = Delegate(library, options)
    176   except ValueError as e:
    177     raise ValueError('Failed to load delegate from {}\n{}'.format(

~/.local/lib/python3.10/site-packages/tensorflow/lite/python/interpreter.py in __init__(self, library, options)
     81                          'due to missing immediate reference counting.')
     82 
---> 83     self._library = ctypes.pydll.LoadLibrary(library)
     84     self._library.tflite_plugin_create_delegate.argtypes = [
     85         ctypes.POINTER(ctypes.c_char_p),

/usr/lib/python3.10/ctypes/__init__.py in LoadLibrary(self, name)
    450 
    451     def LoadLibrary(self, name):
--> 452         return self._dlltype(name)
    453 
    454     __class_getitem__ = classmethod(_types.GenericAlias)

/usr/lib/python3.10/ctypes/__init__.py in __init__(self, name, mode, handle, use_errno, use_last_error, winmode)
    372 
    373         if handle is None:
--> 374             self._handle = _dlopen(self._name, mode)
    375         else:
    376             self._handle = handle

`OSError: ./libtensorflowlite_gpu_delegate.so: undefined symbol: glFenceSync`
--> This is on Ubuntu 22.04 arm64
--> on Ubuntu 22.04 x64 the Error is:
`OSError: ./libtensorflowlite_gpu_delegate.so: undefined symbol: glDeleteBuffers` 
**

**Describe the expected behavior**
should work with gpu delegate?


**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
55521,Hi,"Hi I've been trying to train tflite pose classifiers to work with your movenet pi example
https://github.com/tensorflow/examples/tree/master/lite/examples/pose_estimation/raspberry_pi

I've used the suggested tutorial and colab 
https://www.tensorflow.org/lite/tutorials/pose_classification
and carefully followed the example yoga pose dataset (with train and test examples) but the classification results seem almost random (2 classifiers out 4 successfully classify a pose about 50% of the time).

My dataset is here
https://github.com/roddicki/movenet-pi-dataset

The training in the colab works well with a confusion matrix with no errors. The model accuracy is also high (0.9977) and the increasing accuracy through the training epochs looks as expected. I wondered if anyone has used this colab with success?

Thanks!

"
55520,Serialize TF graph after XLA compilation ,"
**System information**
- TensorFlow version (you are using): 2.8.0

**Describe the feature and the current behavior/state.**
Not available
**Will this change the current api? How?**
Potentially

Hi, I was wondering if there is a way to serialize a TF graph after compiling with XLA. Typically we can serialize a graph as a proto file and load it afterwards. However, the graph execution is slow the first time we run it after loading presumably due to JIT compilation. Is there a way to store the graph so that there is no performance overhead during the first run after loading it? 

Consider the following example: 
[https://gist.github.com/pemoi1982jpm/bf3e6afe90551a824d0f9e9baa42d041](https://gist.github.com/pemoi1982jpm/bf3e6afe90551a824d0f9e9baa42d041)

So the question:  Is there a way to serialize the TF graph in a way that the first run is also fast after restoring it?  

In principle the graph was already compiled using XLA, Can we store it in some format so that XLA doesn’t have to compile it again? 

Any help or guidance would be really helpful. 
"
55519,Tensorflow for M1 mac,"I have a macbook air m1. I am trying to use tensorflow (for darkflow) in my mac. I need to get tensorflow 1.13.2 but brew and conda always installs the latest version. Now it gives me error ' tensorflow.contrib' not found as it was removed in 1.14. 

I am importing this: 'from darkflow.net.build import TFNet'

Could someone please explain what commands to replace for the new version."
55515,Custom Gradient for Sparse Weight Tensors,"I am trying to create a custom layer which computes W\*x + b where W is a sparse tensor. It is important that I don't ever form the dense version of W because it would be too large to store in memory. It is my understanding that the computation of W\*x, using `tf.sparse.sparse_dense_matmul(W, x),` does not have a supported gradient. Is such a gradient expected to be supported anytime soon? It seems that many others would want this functionality as well.

To make this work, I am trying to implement a custom gradient using the following code:

    @tf.custom_gradient
          def sparse_weight_multiply(self, w):
    	     # compute the product sparse_W * inputs, where sparse_W is a sparse tensor formed from the entries in w
  
              self.sparse_W = tf.sparse.SparseTensor(self.indices, w, self.shape)
              w_inputs = tf.sparse.sparse_dense_matmul(self.sparse_W, self.inputs)
  
              # define gradient for this function
              def sparse_weight_grad(upstream_grad):
                  '''
                  upstream_grad is the gradient computed thus far in the computational graph. 
                  The output of this function will be the gradient of the function sparse_weight_multiply 
                  times upstream_grad, due to the product rule in differentiation. 
  
                  '''
                  # check the shape of upstream_grad
                  print(""Shape of upstream grad: {}"".format(upstream_grad.shape))
                  print(""Shape of inputs: {}"".format(inputs.shape))
                  print(""Shape of weight: {}"".format(self.shape))
  
                  # map entries of input to corresponding locations in the gradient of weights*inputs
                  n_out   = upstream_grad.shape[0]
                  num_RHS = upstream_grad.shape[1]
  
                  indices_i = range(0,self.num_connections)
                  indices_j = self.indices[:, 0]
                  indices_k = self.indices[:, 1]
                  J_indices = tf.cast(tf.transpose(tf.concat([[indices_i],[indices_j]], 0)), tf.int64)
  
                  grad_weights = []
  
                  for l in range(num_RHS):
                      input_permuted = np.array(self.inputs)[:,l][indices_k]
                      sparse_J = tf.sparse.SparseTensor(J_indices, input_permuted, (self.num_connections, n_out))
                      grad_weights.append(tf.sparse.sparse_dense_matmul(sparse_J, tf.reshape(upstream_grad[:,l], (n_out, 1)) ))
  
                  grad_weights = tf.transpose(tf.squeeze(tf.convert_to_tensor(grad_weights)))
                  return grad_weights
  
              return w_inputs, sparse_weight_grad

However, I get the error:
`tensorflow.python.framework.errors_impl.InvalidArgumentError: var and grad do not have the same shape[9632] [9632,638] [Op:ResourceApplyAdam]`
I believe this is because my input, `w`, is a tensor of shape [9632]. However, I want to compute the gradient of `W*x` for each input `x` to the layer, of which I have 638 in my training set. Thus, the gradient I return has shape [9632,638], corresponding to a gradient with shape [9632] for each input. This matches the shape of the upstream gradient I am given, which has shape (3836, 638). I definitely want to pass a gradient for each input, but how do I tell tensorflow that that is what I am doing?"
55513,RFE tensorflow-aarch64==2.6.0 build ?,"**System information**
 TensorFlow version (you are using):  2.6.0
- Are you willing to contribute it (Yes/No): Yes

**Describe the feature and the current behavior/state.**

Brainchip Akida AKD1000 SNN neuromorphic MetaTF SDK support 2.6.0 on x86_64. They claim support for aarch64, but when creating a virtualenv it fails on aarch64 due to lacking tensorflow-aarc64==2.6.0 build.

**Will this change the current api? How?**

NA

**Who will benefit with this feature?**

Customer of Brainchip Akida who run on Arm64 platforms.

**Any Other info.**

https://doc.brainchipinc.com/installation.html


"
55512,Converting models to TFLite is not deterministic,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Mac 11.5.2
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.7.1
- Python version: 3.8.8
- GPU model and memory: AMD Radeon Pro 5300M 4 GB, Intel UHD Graphics 630 1536 M

**Describe the current behavior**
I have a keras model that I convert into a tflite model using `tf.lite.TFLiteConverter.from_keras_model`.
I then save the converted tflite model. I noticed that the output of the conversion is not bit-exact. That means if I save the same converted tflite model twice, the two files may have different hashes.

**Describe the expected behavior**
I would expect the output tflite model file to always have the same hash. I need this so I will be able to know if the model changed.

**Standalone code to reproduce the issue**
This behavior doesn't reproduce every time, but it happens pretty often

```
import os
import tensorflow as tf

def create_model():
    inputs = tf.keras.Input(shape=[5, 5, 3])
    x = tf.keras.layers.Conv2D(32, 3, strides=2, padding=""same"")(inputs)
    x = tf.keras.layers.BatchNormalization()(x)
    model = tf.keras.Model(inputs, x)
    return model


model = create_model()

converter = tf.lite.TFLiteConverter.from_keras_model(model)
converter.experimental_new_converter = True
converter.optimizations = [tf.lite.Optimize.DEFAULT]
converter.target_spec.supported_types = [tf.float16]

tflite_model1 = converter.convert()

tflite_model2 = converter.convert()

with open(""model1.tflite"", ""wb"") as f:
    f.write(tflite_model1)

with open(""model2.tflite"", ""wb"") as f:
    f.write(tflite_model2)

print(os.system(""diff model1.tflite model2.tflite""))


converter = tf.lite.TFLiteConverter.from_keras_model(model)
converter.experimental_new_converter = True
converter.optimizations = [tf.lite.Optimize.DEFAULT]
converter.target_spec.supported_types = [tf.float16]

tflite_model3 = converter.convert()

with open(""model3.tflite"", ""wb"") as f:
    f.write(tflite_model3)

print(os.system(""diff model1.tflite model3.tflite""))
```
"
55510,TypeError: __call__() missing 1 required positional argument: 'step',"there is bug in tensorflow 2.6,
LearningRateSchedule is not correctly recognize by isinstance
tensorflow/python/keras/optimizer_v2/optimizer_v2.py line 1014 and 807,
```
    # value is tf.keras.optimizers.schedules.PiecewiseConstantDecay
    print(isinstance(value, learning_rate_schedule.LearningRateSchedule))  # return false , not desired
    import tensorflow
    print(isinstance(value, tensorflow.keras.optimizers.schedules.LearningRateSchedule)) # return true ,can slove the bug below
```
Can any one create a pull request?
```
ne/training_generator_v1.py"", line 574, in fit
    return fit_generator(
  File ""/home/fujiaqing/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training_generator_v1.py"", line 256, in model_iteration
    batch_outs = batch_function(*batch_data)
  File ""/home/fujiaqing/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training_v1.py"", line 1093, in train_on_batch
    self._make_train_function()
  File ""/home/fujiaqing/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training_v1.py"", line 2028, in _make_train_function
    updates = self.optimizer.get_updates(
  File ""/home/fujiaqing/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py"", line 784, in get_updates
    return [self.apply_gradients(grads_and_vars)]
  File ""/home/fujiaqing/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py"", line 671, in apply_gradients
    apply_state = self._prepare(var_list)
  File ""/home/fujiaqing/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py"", line 957, in _prepare
    self._prepare_local(var_device, var_dtype, apply_state)
  File ""/home/fujiaqing/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/gradient_descent.py"", line 125, in _prepare_local
    super(SGD, self)._prepare_local(var_device, var_dtype, apply_state)
  File ""/home/fujiaqing/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py"", line 963, in _prepare_local
    lr_t = array_ops.identity(self._decayed_lr(var_dtype))
  File ""/home/fujiaqing/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py"", line 1017, in _decayed_lr
    lr_t = self._get_hyper(""learning_rate"", var_dtype)
  File ""/home/fujiaqing/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py"", line 814, in _get_hyper
    value = value()
TypeError: __call__() missing 1 required positional argument: 'step'

```
test code
```
  boundaries = [len(x_train)/batch_size*70, len(x_train)/batch_size*150]
  values = [0.1, 0.01, 0.001]
  learning_rate_fn = tf.keras.optimizers.schedules.PiecewiseConstantDecay(boundaries, values)
      
  optimizer1 = gradient_descent_v2.SGD(learning_rate=learning_rate_fn,momentum=0.9)
  model.compile(loss=""categorical_crossentropy"", optimizer=optimizer1, metrics=[""accuracy""])
  model.fit()
```"
55505,Build TF wheel in another project which depends on TF,"**System information**
- OS Platform and Distribution: (Linux Ubuntu 20.04)
- TensorFlow installed from (source or binary): source
- TensorFlow version: 2.8.0
- Python version: 3.8.0
- Installed using virtualenv? pip? conda?:
- Bazel version (if compiling from source): 4.2.1
- GCC/Compiler version (if compiling from source): gcc version 9.4.0
- CUDA/cuDNN version: CUDA 11.2/ cuDNN 8
- GPU model and memory: V100



**Describe the problem**
I have a bazel project which depends on `org_tensorflow`.  My project's `.bazelrc` is copied from TF project
In my project, I can successfully build TF `build_pip_package` target by:
```bash
bazel build --config=native_arch_linux --config=cuda @org_tensorflow//tensorflow/tools/pip_package:build_pip_package
```
However, the following error occurs when generating the wheel
```
./bazel-bin/external/org_tensorflow/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg

Wed Apr 6 10:41:47 CST 2022 : === Preparing sources in dir: /tmp/tmp.C0MooMsKIF
Could not find bazel-bin.  Did you run from the root of the build tree?
```
The prompt is very intuitive. I also checked `./bazel-bin/external/org_tensorflow/tensorflow/tools/pip_package/build_pip_package`
The script assumes that TF is not an external dependency.
 In this situation. How can I generate the TF wheel?

**Provide the exact sequence of commands / steps that you executed before running into the problem**
```bash
bazel build --config=native_arch_linux --config=cuda @org_tensorflow//tensorflow/tools/pip_package:build_pip_package
```
```bash
./bazel-bin/external/org_tensorflow/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg
```"
55503,2.7.0: memory leak in TFLite's tflite::Interpreter::Invoke(),"Seeing a memory leak in tflite::Interpreter::Invoke().
The leak is observed while running our software, wrapping TFLite 2.7.0 (built from source at that tag), on iOS 15.4 (EDIT: confirmed still leaking with 2.7.1 and 15.4.1), and using CoreML delegate.

The following leaks seem to occur roughly with every call to Invoke:

80 bytes chunk with the following stack:
```
class_createInstance		
__CFAllocateObject		
__NSSetI_new		
-[NSSet initWithArray:range:copyItems:]		
+[NSSet setWithArray:]		
-[MLDictionaryFeatureProvider featureNames]		
0x11e19b664		
0x11e14b44c		
tflite::Subgraph::Invoke()		
tflite::Interpreter::Invoke()	
```

48 bytes chunk with the following stack:
```
class_createInstance		
__CFAllocateObject		
__NSSetI_new		
-[NSSet initWithArray:range:copyItems:]		
+[NSSet setWithArray:]		
-[MLDictionaryFeatureProvider featureNames]		
0x11e19b664		
0x11e14b44c		
tflite::Subgraph::Invoke()		
tflite::Interpreter::Invoke()
```

16 bytes chunk with the following stack:
```
_CFCreateArrayStorage		
-[NSDictionary allKeys]		
-[MLDictionaryFeatureProvider featureNames]		
0x11e19b664		
0x11e14b44c		
tflite::Subgraph::Invoke()		
tflite::Interpreter::Invoke()	
```

32 bytes chunk with the following stack 
```
_objc_rootAllocWithZone		
objc_alloc_init		
-[NSTaggedPointerString UTF8String]		
0x11e19afd0		
-[MLNeuralNetworkEngine verifyInputs:error:]		
-[MLNeuralNetworkEngine evaluateInputs:options:error:]		
__62-[MLNeuralNetworkEngine predictionFromFeatures:options:error:]_block_invoke		
0x10342e7bc		
_dispatch_lane_barrier_sync_invoke_and_complete		
-[MLNeuralNetworkEngine predictionFromFeatures:options:error:]		
0x11e19b714		
0x11e14b44c		
tflite::Subgraph::Invoke()		
tflite::Interpreter::Invoke()	
```

Last time I went hunting for memory leaks, we were using 2.5.0, and there had been no leak there."
55502,"Using model.predict(X) gives me ""InternalError: Failed copying input tensor from CPU to GPU in order to run _EagerConst: Dst tensor is not initialized.""","**System information**
- OS Platform and Distribution (Linux Ubuntu 20.04):
- TensorFlow installed from Docker (tensorflow/tensorflow):
- TensorFlow version: 2.8.0
- Python version: Python 3.8.10
- GPU model and memory: NVIDIA GeForce MX110 2048 MB

I have built a neural network model with TensorFlow Probability and when trying to predict values as in 
`pred_train = model.predict(X_train)`
 it gives me this error, most of the times 
`InternalError: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.`
and sometimes it runs ok without errors.

The same data/code was used with different models and works just fine. The problem seems to appear only with models built with TensorFlow Probability "
55500,High memory usage while training with tflite_model_maker,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): True
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 / Ubuntu 18.04
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.8.0
- Python version: 3.7.13
- CUDA/cuDNN version: CUDA 11.1
- GPU model and memory: Tesla K80 (Colab GPU) 24 GB GDDR5

**Describe the current behavior**

No errors, however upon increasing `batch_size` past 1 or 2 an OOM error is incurred. Even when keeping `batch_size` to 1, OOM occurs when using more than 1 epoch. When using 1 `batch_size` and 1 `epoch`, after execution of epochs, the memory usage grows until eventually crashing. 

**Describe the expected behavior**

No errors, the training ends without crashing.

**Standalone code to reproduce the issue**
[colab](https://colab.research.google.com/drive/1bMpah_j9tyyK_cg3uL0KuFv8BBO3k4Iu?usp=sharing)"
55499,"TFlite conversion from concrete function returns ""ValueError: This converter can only convert a single ConcreteFunction. Converting multiple functions is under development.""","### 1. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- TensorFlow installation (pip package or built from source): Pip
- TensorFlow library (version, if pip package or github SHA, if built from source): tensorflow==2.8.0

### 2. Code

Provide code to help us reproduce your issues using one of the following options:

#### Option A: Reference colab notebooks

1)  Reference [TensorFlow Model Colab]

https://colab.research.google.com/drive/1n3xeAtFU0xRxtMDEdw3k_xsyHHnsVnP7#scrollTo=Nbvrn_9uaCSY

### 3. Failure after conversion
Conversion fails with "" ValueError: This converter can only convert a single ConcreteFunction. Converting multiple functions is under development.""

"
55497,TF loads/initializes DevicePlugins multiple times if there are symlinked paths in sys.path.,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux CentOS but others also are affected
- TensorFlow installed from (source or binary): all >= 2.6
- TensorFlow version (use command below): v2.6.1-9-gc2363d6d025 2.6.2
- Python version: >= 3.7

**Describe the current behavior**
When TF starts up, the ```__init__.py``` checks ```sys.path``` for paths to site-packages, that will then be used for loading PluggableDevices. If the identical file is accessible through a symlink from a different path, i.e.:

- ```.../lib/python3.8/site-packages/tensorflow-plugins/libmydevice.so```
- ```.../lib64/python3.8/site-packages/tensorflow-plugins/libmydevice.so```

with ```lib64``` being a symlink to ```lib``` (as it is the case for VENVs) then TensorFlow loads the library twice and dies with
```
stream_executor::MultiPlatformManager::RegisterPlatform( std::move(cplatform)) status: Internal: platform is already registered with name: ""NAME""
```

In https://github.com/tensorflow/tensorflow/blob/master/tensorflow/c/c_api_experimental.cc#L724 a map with std::string is used, which cannot distinguish the symlink and therefore will call the initialization methods within the PluggableDevice library a second time.

**Describe the expected behavior**
The library does not get initialized twice.

**[Contributing](https://www.tensorflow.org/community/contribute)**

- Do you want to contribute a PR? (yes/no): no
- Briefly describe your candidate solution(if contributing):

I think the easiest solution would be to change ```TF_LoadPluggableDeviceLibrary``` to use a set on the library handle instead of map, i.e.:

```cpp
TF_Library* TF_LoadPluggableDeviceLibrary(const char* library_filename,
                                          TF_Status* status) {
#if defined(IS_MOBILE_PLATFORM) || defined(IS_SLIM_BUILD)
  status->status = tensorflow::errors::Unimplemented(
      ""PluggableDevice plugin functionality is not supported on mobile"");
  return nullptr;
#else
  TF_Library* lib_handle = new TF_Library;
  static tensorflow::mutex mu(tensorflow::LINKER_INITIALIZED);
  static std::unordered_set<void*>* loaded_libs =
      new std::unordered_set<void*>();
  tensorflow::Env* env = tensorflow::Env::Default();
  {
    tensorflow::mutex_lock lock(mu);
    status->status =
      env->LoadDynamicLibrary(library_filename, &lib_handle->lib_handle);
    if (status->status.ok()) {
      if (loaded_libs.emplace(lib_handle->lib_handle).second) {
        TF_CHECK_OK(tensorflow::RegisterPluggableDevicePlugin(lib_handle->lib_handle));
      } else {
        dlclose(lib_handle->lib_handle);
      }
    } else {
      delete lib_handle;
      return nullptr;
    }
    return lib_handle;
  }
#endif
}
```

```LoadDynamicLibrary``` uses ```dlopen``` and will return ALWAYS the same handle independent of symlinks, see: https://man7.org/linux/man-pages/man3/dlopen.3.html. The call to ```dlclose``` is to decrease the reference count in case the lib got opened multiple times.

**Standalone code to reproduce the issue**
We encountered this error when using a VENV with rh-python38 package, because it puts ```lib``` and ```lib64``` into ```sys.path```. But can also be triggered by forging the PYTHONPATH env var:

```bash
pip3 install tensorflow
# install any PluggableDevice library you like
ln -s ~/.local/lib ~/.local/lib64
PYTHONPATH=~/.local/lib/python3.8/site-packages:~/.local/lib64/python3.8/site-packages python3 -c ""import tensorflow""
```
"
55496,Unit test //tensorflow/core/kernels:conv_ops_benchmark_test_cpu fails to build on non-mkl build,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): CentOS 7
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: n/a
- TensorFlow installed from (source or binary): source
- TensorFlow version: git HEAD
- Python version: 3.8.12
- Installed using virtualenv? pip? conda?: no
- Bazel version (if compiling from source): 5.1.0
- GCC/Compiler version (if compiling from source): 10.2.1
- CUDA/cuDNN version: n/a
- GPU model and memory: n/a



**Describe the problem**

Build of unit test //tensorflow/core/kernels:conv_ops_benchmark_test_cpu fails with 

ERROR: /tmp/workspace/tensorflow-git/tensorflow/core/kernels/BUILD:1836:16: Compiling tensorflow/core/kernels/conv_ops_benchmark_test.cc failed: undeclared inclusion(s) in rule '//tensorflow/core/kernels:conv_ops_benchmark_test_cpu':
this rule is missing dependency declarations for the following files included by 'tensorflow/core/kernels/conv_ops_benchmark_test.cc':
  'tensorflow/core/graph/mkl_graph_util.h'
Target //tensorflow/core/kernels:conv_ops_benchmark_test_cpu failed to build
INFO: Elapsed time: 50.018s, Critical Path: 46.01s
INFO: 314 processes: 74 internal, 240 local.
FAILED: Build did NOT complete successfully
//tensorflow/core/kernels:conv_ops_benchmark_test_cpu           FAILED TO BUILD

FAILED: Build did NOT complete successfully

**Provide the exact sequence of commands / steps that you executed before running into the problem**

bazel test --test_timeout=300,500,-1,-1 --flaky_test_attempts=3 --test_output=all --cache_test_results=no --config=nonccl --verbose_failures --build_tag_filters=-no_oss,-oss_serial,-gpu,-tpu,-benchmark-test,-v1only,-no_aarch64,-requires-gpu --test_tag_filters=-no_oss,-oss_serial,-gpu,-tpu,-benchmark-test,-v1only,-no_aarch64,-requires-gpu --jobs=75 --build_tests_only -- //tensorflow/core/kernels:conv_ops_benchmark_test_cpu

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

Introduced by https://github.com/tensorflow/tensorflow/commit/3a0c3b215c969ea5f1a9d59f11b4c628b8c4b22f"
55495,TfLiteGpuDelegateV2Create() causes segmentation fault with tflite-gpu2.8 on native side in Android,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Android 10, API 29
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Galaxy S9
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.8
- Python version: N/A
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: N/A
- GPU model and memory: Qualcomm Adreno 630

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
1. On Native side.
`auto* delegate = TfLiteGpuDelegateV2Create(/*default options=*/nullptr);`
results in following error with tensorflow-lite 2.8
`A/libc: Fatal signal 11 (SIGSEGV), code 1 (SEGV_MAPERR), fault addr 0x18 in tid 23129 (com.example.gpu), pid 23129 (com.example.gpu)`

2. In Java.
GPU delegation works fine with tensorflow-lite 2.8, following code works well.
`GpuDelegate.Options delegateOptions = compatList.getBestOptionsForThisDevice();
delegate = new GpuDelegate(delegateOptions);
options.addDelegate(delegate);`

**Describe the expected behavior**
No segmentation fault in 1.

**[Contributing](https://www.tensorflow.org/community/contribute)**

- Do you want to contribute a PR? (yes/no): Not at the moment
- Briefly describe your candidate solution(if contributing):

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.
I downloaded the tflite-2.8 and tflite-gpu-2.8 from the maven repository(https://search.maven.org/) and added them to a new C++ Android project.
And in the default native-lib.cpp added the above code, which throws the error.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

"
55494,Pip package build broken by removal of declare of RUY LICENSE,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Debian 11
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: n/a
- TensorFlow installed from (source or binary): source
- TensorFlow version: git HEAD
- Python version: 3.9.2
- Installed using virtualenv? pip? conda?: no
- Bazel version (if compiling from source): 5.1.0
- GCC/Compiler version (if compiling from source): 10.3.0
- CUDA/cuDNN version: n/a
- GPU model and memory: n/a



**Describe the problem**

Build fails with error

**Provide the exact sequence of commands / steps that you executed before running into the problem**

bazel build --config=nonccl --verbose_failures -- //tensorflow/tools/pip_package:build_pip_package

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

$ bazel build --config=nonccl --verbose_failures -- //tensorflow/tools/pip_package:build_pip_package
Starting local Bazel server and connecting to it...
INFO: Options provided by the client:
  Inherited 'common' options: --isatty=1 --terminal_columns=131
INFO: Reading rc options for 'build' from /home/debian-j13-x86-05/src/tensorflow/.bazelrc:
  Inherited 'common' options: --experimental_repo_remote_exec
INFO: Reading rc options for 'build' from /home/debian-j13-x86-05/src/tensorflow/.bazelrc:
  'build' options: --define framework_shared_object=true --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --enable_platform_specific_config --define=with_xla_support=true --config=short_logs --config=v2 --define=no_aws_support=true --define=no_hdfs_support=true --experimental_cc_shared_library
INFO: Reading rc options for 'build' from /home/debian-j13-x86-05/src/tensorflow/.tf_configure.bazelrc:
  'build' options: --action_env PYTHON_BIN_PATH=/home/debian-j13-x86-05/venv_py39/bin/python3 --action_env PYTHON_LIB_PATH=/home/debian-j13-x86-05/venv_py39/lib/python3.9/site-packages --python_path=/home/debian-j13-x86-05/venv_py39/bin/python3
INFO: Reading rc options for 'build' from /home/debian-j13-x86-05/src/tensorflow/.bazelrc:
  'build' options: --deleted_packages=tensorflow/compiler/mlir/tfrt,tensorflow/compiler/mlir/tfrt/benchmarks,tensorflow/compiler/mlir/tfrt/jit/python_binding,tensorflow/compiler/mlir/tfrt/jit/transforms,tensorflow/compiler/mlir/tfrt/python_tests,tensorflow/compiler/mlir/tfrt/tests,tensorflow/compiler/mlir/tfrt/tests/ir,tensorflow/compiler/mlir/tfrt/tests/analysis,tensorflow/compiler/mlir/tfrt/tests/jit,tensorflow/compiler/mlir/tfrt/tests/lhlo_to_tfrt,tensorflow/compiler/mlir/tfrt/tests/tf_to_corert,tensorflow/compiler/mlir/tfrt/tests/tf_to_tfrt_data,tensorflow/compiler/mlir/tfrt/tests/saved_model,tensorflow/compiler/mlir/tfrt/transforms/lhlo_gpu_to_tfrt_gpu,tensorflow/core/runtime_fallback,tensorflow/core/runtime_fallback/conversion,tensorflow/core/runtime_fallback/kernel,tensorflow/core/runtime_fallback/opdefs,tensorflow/core/runtime_fallback/runtime,tensorflow/core/runtime_fallback/util,tensorflow/core/tfrt/common,tensorflow/core/tfrt/eager,tensorflow/core/tfrt/eager/backends/cpu,tensorflow/core/tfrt/eager/backends/gpu,tensorflow/core/tfrt/eager/core_runtime,tensorflow/core/tfrt/eager/cpp_tests/core_runtime,tensorflow/core/tfrt/gpu,tensorflow/core/tfrt/run_handler_thread_pool,tensorflow/core/tfrt/runtime,tensorflow/core/tfrt/saved_model,tensorflow/core/tfrt/graph_executor,tensorflow/core/tfrt/saved_model/tests,tensorflow/core/tfrt/tpu,tensorflow/core/tfrt/utils
INFO: Found applicable config definition build:short_logs in file /home/debian-j13-x86-05/src/tensorflow/.bazelrc: --output_filter=DONT_MATCH_ANYTHING
INFO: Found applicable config definition build:v2 in file /home/debian-j13-x86-05/src/tensorflow/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1
INFO: Found applicable config definition build:nonccl in file /home/debian-j13-x86-05/src/tensorflow/.bazelrc: --define=no_nccl_support=true
INFO: Found applicable config definition build:linux in file /home/debian-j13-x86-05/src/tensorflow/.bazelrc: --copt=-w --host_copt=-w --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --define=PROTOBUF_INCLUDE_PATH=$(PREFIX)/include --cxxopt=-std=c++14 --host_cxxopt=-std=c++14 --config=dynamic_kernels --distinct_host_configuration=false --experimental_guard_against_concurrent_changes
INFO: Found applicable config definition build:dynamic_kernels in file /home/debian-j13-x86-05/src/tensorflow/.bazelrc: --define=dynamic_loaded_kernels=true --copt=-DAUTOLOAD_DYNAMIC_KERNELS
WARNING: Download from https://storage.googleapis.com/mirror.tensorflow.org/github.com/tensorflow/runtime/archive/73ef596c0dba3638242bcb57e895d4163e31da64.tar.gz failed: class java.io.FileNotFoundException GET returned 404 Not Found
ERROR: /home/debian-j13-x86-05/src/tensorflow/tensorflow/tools/pip_package/BUILD:182:10: no such target '@ruy//:LICENSE': target 'LICENSE' not declared in package ''; however, a source file of this name exists.  (Perhaps add 'exports_files([""LICENSE""])' to /BUILD?) defined by /home/debian-j13-x86-05/.cache/bazel/_bazel_debian-j13-x86-05/6dfc29351d9ac80b1cbc1c3ca56d5b08/external/ruy/BUILD.bazel and referenced by '//tensorflow/tools/pip_package:licenses'
ERROR: Analysis of target '//tensorflow/tools/pip_package:build_pip_package' failed; build aborted: 
INFO: Elapsed time: 130.450s
INFO: 0 processes.
FAILED: Build did NOT complete successfully (272 packages loaded, 3958 targets configured)
    Fetching @local_jdk; fetching

Introduced by https://github.com/tensorflow/tensorflow/commit/57226b829ef6f3fddb3579ce6cf2fb7af0ca90ba
"
55492,is there tensorflow-gpu available for cuda 11.4？,"<em>I was wandering whether there is a available tensorflow-gpu version for cuda 11.4， when i install the latest version 2.8.0，when i import the tensorflow，i got this

：""W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib:/usr/local/cuda/lib:
2022-04-05 11:20:15.733394: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine."",  

i see the version attached to cuda latest is 11.2，but i have no authority to downgrad the cuda version, thanks for your attention!</em>

**System information**
- TensorFlow installed from (source or binary):source
- TensorFlow version:2.8.0
- Python version:3.8.0
- Installed using virtualenv? pip? conda?:conda
- CUDA/cuDNN version:11.4

"
55487,https://www.tensorflow.org/tutorials/generative/autoencoder,"On define convolution encoder: encoded_imgs = autoencoder.encoder(x_test).numpy()

Here the input data is supposed to be "" x_test_noisy"""
55486,Memory Leak in Example/Tutorial Documentation,"## URL(s) with the issue:
https://www.tensorflow.org/tensorboard/image_summaries#logging_arbitrary_image_data

## Description of issue (what needs changing):
Listed example needs to be corrected as to avoid memory leaks.

### Clear description
It appears that the example is creating `tf.image.decode_png`  and `tf.expand_dims` layers within `plot_to_image` which is being repeatedly called by a `tf.keras.callbacks.LambdaCallback`.  These layers are filling VRAM or system RAM, depending on whether or not the example is running on GPU or not.  "
55485,Are the instructions for building TFLite examples outdated?,"I am trying to build an image classifier for android, and I am following the instructions provided [here](https://github.com/tensorflow/examples/tree/master/lite/examples/image_classification/android). Following the instructions to run the given example, I am getting this error:

```
Querying the mapped value of map(java.io.File property(org.gradle.api.file.Directory, fixed(class org.gradle.api.internal.file.DefaultFilePropertyFactory$FixedDirectory, /Users/user1/samples/android_example/models/build/generated/ap_generated_sources/debug/out)) org.gradle.api.internal.file.DefaultFilePropertyFactory$ToFileTransformer@2325887e) before task ':models:compileDebugJavaWithJavac' has completed is not supported

```

**System Info**

* System: mac
* Android Studio version: 3.2
* Android SDK version: 23
"
55484,Adding a parameter to teh tf.image.extract_patches function to change the value of added border pixels due to the padding,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): 2.8
- Are you willing to contribute it (Yes/No): Yes


**Describe the feature and the current behavior/state.**
Using tf.image.extract_patches with ""same"" padding leads to zeros on the image border. Zero is a default value and cannot be changed by the user. This means that the mask data for image segmentation should always have zero as the background class, otherwise it does mess up after patching. It is best to add this default value as a parameter so the user can change it if needed.

**Will this change the current api? How?**
Adding a parameter to teh tf.image.extract_patches function to change the value of added border pixels due to the padding

**Who will benefit with this feature?**
Anyone using this function for patching data for image segmentation

**Any Other info.**
"
55483,How to convert XLA HLO debug code to executable ?,"Background : We use TF1.15 to training model, and I'm so sorry we can not upgrade TF to 2.8, because we add some new function for custom tensorflow.
Question: I have a big model, and I want to increase training speed by using xla, but I meet a CUDA_ERROR_ILLEGAL_ADDRESS when I use xla, so I want to know how to solve this question. 
now I have some infomations:
1. I got error xla_cluster name.
2. I got all inputs of error xla_cluster.
3. I got all XLA HLO codes by ```export XLA_FLAGS=""--xla_dump_to=./xla""```
For eaier debug, For easier debugging, I want a method that converts the IR code into an executable.
Debugging xla is very, very difficult, please help.

other infos:
cluster_728 have 30 ops. 
The problem will not be repeated when I narrow down the cluster.
The problem will not recur when I shrink the batch_size again.
debug-file about cluster_728: [module_0023.tar.gz](https://github.com/tensorflow/tensorflow/files/8410698/module_0023.tar.gz)

![image](https://user-images.githubusercontent.com/33950866/161570318-b613eca7-6a1e-49da-b223-3b744258f5e6.png)"
55482,Which version of CUDA does tensorflow2.8.0 correspond to? I can't find it on the website.,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version:
- Python version:
- Installed using virtualenv? pip? conda?:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:



**Describe the problem**

**Provide the exact sequence of commands / steps that you executed before running into the problem**


**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
55479,Build TF 2.3 with GPU minus AVX,How to custom build TF 2.3 in centos 8 with GPU and without avx as my hardware not support AVX.
55478,How can we use gradients accumulation in tf.keras by defining the custom training step?,"I found that when I used a very large model like robert-large,the implementation of gradients accumulation like this
https://gist.github.com/innat/ba6740293e7b7b227829790686f2119c
may be very expensive for the gpu memory because  I need to store an additional copy of the parameters of the entire roberta model 
in here
""        self.gradient_accumulation = [tf.Variable(tf.zeros_like(v, dtype=tf.float32), 
                                                  trainable=False) for v in self.trainable_variables] ""

The below is my implementation , just  an imitation of the gradient accumulation of pytorch，but this implementation is not valid because I found that the loss just did not decrese . I think it is a problem of the design of tf.gradienttape,when one batch size is over ,the tape did not record the gradients in last batch size . How can I resolve this problem?


 
```
class Model2(tf.keras.Model): #cumsum the loss not the gradients
    def __init__(self, n_gradients, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.n_gradients = float(n_gradients)
        self.n_acum_step = 0
        #self.gradient_accumulation = [tf.Variable(tf.zeros_like(v, dtype=tf.float32), trainable=False) for v in self.trainable_variables]
        self.total_loss= 0.00
        #self.g=[]

    def train_step(self, data):
        self.n_acum_step+=1

        x, y = data
        # Gradient Tape
        with tf.GradientTape() as tape:
            y_pred = self(x, training=True)
            loss = self.compiled_loss(y, y_pred, regularization_losses=self.losses)
            self.total_loss += loss ##just cumsum the loss here
        if self.n_acum_step >= self.n_gradients:
          gradients = tape.gradient(self.total_loss/self.n_gradients, self.trainable_variables) # remember to average the loss
          self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))
          self.total_loss=0.00 # reset the total loss
          self.n_acum_step=0 ##reset the accumulation step

          # update metrics
        self.compiled_metrics.update_state(y, y_pred)
        return {m.name: m.result() for m in self.metrics}

model = Model2(n_gradients=16,inputs...,outputs...)
model.fit....
```
"
55477,error: no matching function for call to 'partition_block_load_flags',"- OS Platform and Distribution: Gentoo
- TensorFlow installed from source
- TensorFlow version: 2.10.0
- Python version: 3.10.4
- Installed using: emerge
- Bazel version: 5.1.1
- GCC/Compiler version: 10.2.0
- LLVM/Clang version: 14.0.1
- CUDA/cuDNN version: 11.6.2
- GPU model and memory: AMD Vega Frontier 16Gb
- ROCM version: 5.1.1

Does not build from sources with errors:
`bazel-out/k8-opt/bin/external/local_config_rocm/rocm/rocm/include/rocprim/device/detail/device_partition.hpp:760:5: error: no matching function for call to 'partition_block_load_flags'
`

`IUSE=""rocm -cuda"" emerge sci-libs/tensorflow`

[build.log](https://gist.github.com/raw/65bfdca10a815078fffe5e2aa00bc657)
"
55476,TFLite performance difference between python and c++,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Debian 10 Linux buster
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): 2.8.0
- TensorFlow version (use command below): 2.8.0
- Python version: 3.7.3
- Bazel version (if compiling from source): 4.2.1
- GCC/Compiler version (if compiling from source): 8.3.0
- CUDA/cuDNN version: NA
- GPU model and memory: NA

 TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
v2.8.0-rc1-32-g3f878cff5b6 2.8.0

**Describe the current behavior**

Python performance of tflite is much better than C++.
When number of threads is set to -1, Not getting best performance in C++.
Manual setting the number of threads to max is giving improvement in C++ API performance and still its less than python.
As per this issue(https://github.com/tensorflow/tensorflow/issues/46272) It is mentioned, number of threads in c++ are automatically set to -1 and all threads will be used, But its not happening and there is performance difference.
Performance is not modified proportionately based on the threads. Suppose when threads are set to 2, we are not getting 2x performance than threads as 1

**Describe the expected behavior**
Match the performance of python with C++.
Give an API or directly automate the setting the threads without manual change.
What is the backend used for python and C++ ? Are they same ?
Can we expect the performance proportionately based on the threads. Suppose when threads are set to 2, can we expect 2x performance than 1 thread ?


**Standalone code to reproduce the issue**
Python TFlite--

`` python3 tfliteversionprofile_latest_singleiteration.py ``

2.8.0
Time elapsed during the process:%d ms 99.971158

`` python3 tfliteversionprofile_latest_singleiteration_multicores.py ``

.2.8.0
Time elapsed during the process:%d ms 85.076159
There is clear change in performance when number of threads are set to max. 
My cpu has 6 cores and 2 threads per core, so set to 12.

C++ TFlite-- 

But when c++ API is used there is huge impact in performance , Using example label image.

when -1 is set as number of threads.
`` bazel-4.2.1 build -c opt //tensorflow/lite/examples/label_image:label_image ``

when -1 (number of threads) is set in label_image.h present in tensorflow/lite/examples/label_image, 

`` bazel-bin/tensorflow/lite/examples/label_image/label_image --tflite_model detect.tflite --labels labelmap.txt --image tensorflow/lite/examples/label_image/testdata/grace_hopper.bmp `` 

INFO: Loaded model detect.tflite
INFO: resolved reporter
INFO: Created TensorFlow Lite XNNPACK delegate for CPU.
INFO: invoked
INFO: average time: 323.143 ms
INFO: 0.00389769: 3 car
INFO: 0.0038741: 2 bicycle


 
when 12 is set as number of threads.
`` bazel-4.2.1 build -c opt //tensorflow/lite/examples/label_image:label_image ``

when 12 (number of threads) is set in label_image.h present in tensorflow/lite/examples/label_image, 

`` bazel-bin/tensorflow/lite/examples/label_image/label_image --tflite_model detect.tflite --labels labelmap.txt --image tensorflow/lite/examples/label_image/testdata/grace_hopper.bmp ``

INFO: Loaded model detect.tflite
INFO: resolved reporter
INFO: Created TensorFlow Lite XNNPACK delegate for CPU.
INFO: invoked
INFO: average time: 141.746 ms
INFO: 0.00389769: 3 car
INFO: 0.0038741: 2 bicycle


Attached the model, scripts and labels file.,
[labelmap.txt](
[New folder.zip](https://github.com/tensorflow/tensorflow/files/8405110/New.folder.zip)
https://github.com/tensorflow/tensorflow/files/8405102/labelmap.txt)
[labelmap.txt](https://github.com/tensorflow/tensorflow/files/8405103/labelmap.txt)

"
55475,tf.map_fn on RaggedTensors crash during gradient computation on a GPU,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): **yes**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **Colab**
- TensorFlow installed from (source or binary): **binary**
- TensorFlow version (use command below): **2.8**
- Python version: **3.7**

**Describe the current behavior**

When some loss (`tf.losses.SparseCategoricalCrossentropy`, `tf.losses.CategoricalCrossentropy`, `tf.losses.BinaryCrossentropy`, or `tf.losses.MeanSquaredError`) is used on Ragged tensors, which is computed via a `tf.map_fn` on a `RaggedTensor`, that the gradient computation on a GPU crashes with
```
Node: 'Adam/gradients/zeros_like_2'
2 root error(s) found.
  (0) INTERNAL:  No unary variant unary_op function found for op ZEROS_LIKE Variant type_name: RaggedTensorVariant for device type: GPU
	 [[{{node Adam/gradients/zeros_like_2}}]]
	 [[binary_crossentropy/map/while/loop_body_control/_124/_67]]
  (1) INTERNAL:  No unary variant unary_op function found for op ZEROS_LIKE Variant type_name: RaggedTensorVariant for device type: GPU
	 [[{{node Adam/gradients/zeros_like_2}}]]
0 successful operations.
0 derived errors ignored. [Op:__inference_train_function_16690]
```

The computation does not crash on a CPU and it does not crash when `tf.function`s are executed eagerly.

Also, if the `tf.map_fn` is circumvented by using the following argument to compile
```python
  loss=lambda yt, yp: tf.losses.BinaryCrossentropy()(yt. values, yp.values)
```
it works on GPU without a crash.


**Describe the expected behavior**

The code does not crash on a GPU.

- Do you want to contribute a PR? (yes/no): **no**

**Standalone code to reproduce the issue**

A simple Colab reproducing the error is here: https://colab.research.google.com/drive/1OELAhvpQHhaz3sOYabf4SdBqKlQCjNjs?usp=sharing

**Other info / logs**

The `map_fn` used is here: https://github.com/keras-team/keras/blob/2db5acf3e3c5904b014cb409d3c514bef44f9640/keras/losses.py#L1408 "
55474,"Using tf.data.Dataset.list_files prints ""unshardable source dataset"" warning","**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04 LTS
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): v2.8.0-rc1-32-g3f878cff5b6 2.8.0
- Python version: 3.8.10

**Describe the current behavior**

Using distributed strategy and `tf.data.Dataset.list_files` prints a `unshardable source dataset` warning.

**Describe the expected behavior**
API should detect that the source dataset is files and can be sharded. 

Reference: https://www.tensorflow.org/tutorials/distribute/input

**Standalone code to reproduce the issue**
```python
strategy = tf.distribute.MirroredStrategy()
ds = tf.data.Dataset.list_files("".*"", shuffle=False).map(lambda x: (tf.strings.length(x), tf.strings.length(x)))
with strategy.scope():
  dummy_model = tf.keras.Sequential()
  dummy_model.add(tf.keras.layers.Dense(1, input_shape=(1,)))
  dummy_model.compile(loss=""mse"")
dummy_model.fit(ds.batch(4))
```
```
2022-04-03 16:22:04.058728: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: ""TensorSliceDataset/_1""
op: ""TensorSliceDataset""
input: ""Placeholder/_0""
attr {
  key: ""Toutput_types""
  value {
    list {
      type: DT_STRING
    }
  }
}
attr {
  key: ""_cardinality""
  value {
    i: 1
  }
}
attr {
  key: ""is_files""
  value {
    b: false
  }
}
attr {
  key: ""metadata""
  value {
    s: ""\n\026TensorSliceDataset:350""
  }
}
attr {
  key: ""output_shapes""
  value {
    list {
      shape {
      }
    }
  }
}
experimental_type {
  type_id: TFT_PRODUCT
  args {
    type_id: TFT_DATASET
    args {
      type_id: TFT_PRODUCT
      args {
        type_id: TFT_TENSOR
        args {
          type_id: TFT_STRING
        }
      }
    }
  }
  args {
    type_id: TFT_DATASET
    args {
      type_id: TFT_PRODUCT
      args {
        type_id: TFT_TENSOR
        args {
          type_id: TFT_STRING
        }
      }
    }
  }
}
```"
55473,"when installing tf-nightly, pip's dependency resolver, tensorflow 2.8.0 requires tf-estimator-nightly==2.8.0, but you have 2.10.0","<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04.4
- pip version: 22.0.4
- TensorFlow installed from (source or binary): pip install tensorflow
- TensorFlow version: 2.8.0
- Python version: 3.9.11
- Installed using virtualenv? pip? conda?: pip

**Describe the problem**
I follow the [tensorflow installation instruction](https://www.tensorflow.org/install),.
When I process this: `pip install tf-nightly`, it says:
""
ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.
tensorflow 2.8.0 requires tf-estimator-nightly==2.8.0.dev2021122109, but you have tf-estimator-nightly 2.10.0.dev2022040208 which is incompatible.
""

Do I need to solve this and how to solve this?"
55472,tf.image.extract_patches default value for areas outside the input ,"Running tf.image.extract_patches by the ""Same"" padding leads to zeros for areas outside the input. There is no way to change the default value and it is best to have this as another parameter for this function. This background label should be always zero; otherwise, this function mess up the labels."
55471,difference Between the output of conv1d with same input and weights for tf2.3 and tf2.6,"Hello, I had met a problem just like the title. The inputs and weights  are same, use difference tf's version 2.3 and 2.6, I got difference outputs. Is this caused by precision
![clipboard_image_1648902447965](https://user-images.githubusercontent.com/20295041/161383301-524ba7bc-e9ef-4ac3-a5aa-a69566420557.png)
![clipboard_image_1648902397799](https://user-images.githubusercontent.com/20295041/161383307-36ef8a79-fd5a-446f-bf6c-874107116a7a.png)
?"
55468,UnimplementedError  DNN library is not found when running a Conv1D layer,"Windows 10
cudnn 8.1.1.33, CUDA 11.2.2_461.33
Nvidia driver 11.2.109
tensorflow 2.8.0
Python 3.9.12
Anaconda environment
Nvidia GeForece GPU RTX 3060,  16GB RAM, 512GB SSD

**UnimplementedError  Node: 'sequential/conv1d/Conv1D'
DNN library is not found.**

```
# Parameters
embedding_dim = 16
filters = 128
kernel_size = 5
dense_dim = 6

# Model Definition with Conv1D
model_conv = tf.keras.Sequential([
    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),
    tf.keras.layers.Conv1D(filters, kernel_size, activation='relu'),
    tf.keras.layers.GlobalMaxPooling1D(),
    tf.keras.layers.Dense(dense_dim, activation='relu'),
    tf.keras.layers.Dense(1, activation='sigmoid')
])

# Set the training parameters
model_conv.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])

# Print the model summary
model_conv.summary()
```

Model: ""sequential""
```
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 embedding (Embedding)       (None, 120, 16)           160000    
                                                                 
 conv1d (Conv1D)             (None, 116, 128)          10368     
                                                                 
 global_max_pooling1d (Globa  (None, 128)              0         
 lMaxPooling1D)                                                  
                                                                 
 dense (Dense)               (None, 6)                 774       
                                                                 
 dense_1 (Dense)             (None, 1)                 7         
                                                                 
=================================================================
```
```
Total params: 171,149
Trainable params: 171,149
Non-trainable params: 0

NUM_EPOCHS = 10

# Train the model
history_conv = model_conv.fit(training_padded, training_labels, epochs=NUM_EPOCHS, validation_data=(testing_padded, testing_labels))

```


Epoch 1/10
---------------------------------------------------------------------------
UnimplementedError                        Traceback (most recent call last)
Input In [6], in <cell line: 4>()
      1 NUM_EPOCHS = 10
      3 # Train the model
----> 4 history_conv = model_conv.fit(training_padded, training_labels, epochs=NUM_EPOCHS, validation_data=(testing_padded, testing_labels))

File ~\.conda\envs\tf-gpu\lib\site-packages\keras\utils\traceback_utils.py:67, in filter_traceback.<locals>.error_handler(*args, **kwargs)
     65 except Exception as e:  # pylint: disable=broad-except
     66   filtered_tb = _process_traceback_frames(e.__traceback__)
---> 67   raise e.with_traceback(filtered_tb) from None
     68 finally:
     69   del filtered_tb

File ~\.conda\envs\tf-gpu\lib\site-packages\tensorflow\python\eager\execute.py:54, in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)
     52 try:
     53   ctx.ensure_initialized()
---> 54   tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
     55                                       inputs, attrs, num_outputs)
     56 except core._NotOkStatusException as e:
     57   if name is not None:

UnimplementedError: Graph execution error:

Detected at node 'sequential/conv1d/Conv1D' defined at (most recent call last):
    File ""C:\Users\me\.conda\envs\tf-gpu\lib\runpy.py"", line 197, in _run_module_as_main
      return _run_code(code, main_globals, None,
    File ""C:\Users\me\.conda\envs\tf-gpu\lib\runpy.py"", line 87, in _run_code
      exec(code, run_globals)
    File ""C:\Users\me\.conda\envs\tf-gpu\lib\site-packages\ipykernel_launcher.py"", line 16, in <module>
      app.launch_new_instance()
    File ""C:\Users\me\.conda\envs\tf-gpu\lib\site-packages\traitlets\config\application.py"", line 846, in launch_instance
      app.start()
    File ""C:\Users\me\.conda\envs\tf-gpu\lib\site-packages\ipykernel\kernelapp.py"", line 677, in start
      self.io_loop.start()
    File ""C:\Users\me\.conda\envs\tf-gpu\lib\site-packages\tornado\platform\asyncio.py"", line 199, in start
      self.asyncio_loop.run_forever()
    File ""C:\Users\me\.conda\envs\tf-gpu\lib\asyncio\base_events.py"", line 601, in run_forever
      self._run_once()
    File ""C:\Users\me\.conda\envs\tf-gpu\lib\asyncio\base_events.py"", line 1905, in _run_once
      handle._run()
    File ""C:\Users\me\.conda\envs\tf-gpu\lib\asyncio\events.py"", line 80, in _run
      self._context.run(self._callback, *self._args)
    File ""C:\Users\me\.conda\envs\tf-gpu\lib\site-packages\ipykernel\kernelbase.py"", line 473, in dispatch_queue
      await self.process_one()
    File ""C:\Users\me\.conda\envs\tf-gpu\lib\site-packages\ipykernel\kernelbase.py"", line 462, in process_one
      await dispatch(*args)
    File ""C:\Users\me\.conda\envs\tf-gpu\lib\site-packages\ipykernel\kernelbase.py"", line 369, in dispatch_shell
      await result
    File ""C:\Users\me\.conda\envs\tf-gpu\lib\site-packages\ipykernel\kernelbase.py"", line 664, in execute_request
      reply_content = await reply_content
    File ""C:\Users\me\.conda\envs\tf-gpu\lib\site-packages\ipykernel\ipkernel.py"", line 355, in do_execute
      res = shell.run_cell(code, store_history=store_history, silent=silent)
    File ""C:\Users\me\.conda\envs\tf-gpu\lib\site-packages\ipykernel\zmqshell.py"", line 532, in run_cell
      return super().run_cell(*args, **kwargs)
    File ""C:\Users\me\.conda\envs\tf-gpu\lib\site-packages\IPython\core\interactiveshell.py"", line 2863, in run_cell
      result = self._run_cell(
    File ""C:\Users\me\.conda\envs\tf-gpu\lib\site-packages\IPython\core\interactiveshell.py"", line 2909, in _run_cell
      return runner(coro)
    File ""C:\Users\me\.conda\envs\tf-gpu\lib\site-packages\IPython\core\async_helpers.py"", line 129, in _pseudo_sync_runner
      coro.send(None)
    File ""C:\Users\me\.conda\envs\tf-gpu\lib\site-packages\IPython\core\interactiveshell.py"", line 3106, in run_cell_async
      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,
    File ""C:\Users\me\.conda\envs\tf-gpu\lib\site-packages\IPython\core\interactiveshell.py"", line 3309, in run_ast_nodes
      if await self.run_code(code, result, async_=asy):
    File ""C:\Users\me\.conda\envs\tf-gpu\lib\site-packages\IPython\core\interactiveshell.py"", line 3369, in run_code
      exec(code_obj, self.user_global_ns, self.user_ns)
    File ""C:\Users\me\AppData\Local\Temp\ipykernel_9748\331718196.py"", line 4, in <cell line: 4>
      history_conv = model_conv.fit(training_padded, training_labels, epochs=NUM_EPOCHS, validation_data=(testing_padded, testing_labels))
    File ""C:\Users\me\.conda\envs\tf-gpu\lib\site-packages\keras\utils\traceback_utils.py"", line 64, in error_handler
      return fn(*args, **kwargs)
    File ""C:\Users\me\.conda\envs\tf-gpu\lib\site-packages\keras\engine\training.py"", line 1384, in fit
      tmp_logs = self.train_function(iterator)
    File ""C:\Users\me\.conda\envs\tf-gpu\lib\site-packages\keras\engine\training.py"", line 1021, in train_function
      return step_function(self, iterator)
    File ""C:\Users\me\.conda\envs\tf-gpu\lib\site-packages\keras\engine\training.py"", line 1010, in step_function
      outputs = model.distribute_strategy.run(run_step, args=(data,))
    File ""C:\Users\me\.conda\envs\tf-gpu\lib\site-packages\keras\engine\training.py"", line 1000, in run_step
      outputs = model.train_step(data)
    File ""C:\Users\me\.conda\envs\tf-gpu\lib\site-packages\keras\engine\training.py"", line 859, in train_step
      y_pred = self(x, training=True)
    File ""C:\Users\me\.conda\envs\tf-gpu\lib\site-packages\keras\utils\traceback_utils.py"", line 64, in error_handler
      return fn(*args, **kwargs)
    File ""C:\Users\me\.conda\envs\tf-gpu\lib\site-packages\keras\engine\base_layer.py"", line 1096, in __call__
      outputs = call_fn(inputs, *args, **kwargs)
    File ""C:\Users\me\.conda\envs\tf-gpu\lib\site-packages\keras\utils\traceback_utils.py"", line 92, in error_handler
      return fn(*args, **kwargs)
    File ""C:\Users\me\.conda\envs\tf-gpu\lib\site-packages\keras\engine\sequential.py"", line 374, in call
      return super(Sequential, self).call(inputs, training=training, mask=mask)
    File ""C:\Users\me\.conda\envs\tf-gpu\lib\site-packages\keras\engine\functional.py"", line 451, in call
      return self._run_internal_graph(
    File ""C:\Users\me\.conda\envs\tf-gpu\lib\site-packages\keras\engine\functional.py"", line 589, in _run_internal_graph
      outputs = node.layer(*args, **kwargs)
    File ""C:\Users\me\.conda\envs\tf-gpu\lib\site-packages\keras\utils\traceback_utils.py"", line 64, in error_handler
      return fn(*args, **kwargs)
    File ""C:\Users\me\.conda\envs\tf-gpu\lib\site-packages\keras\engine\base_layer.py"", line 1096, in __call__
      outputs = call_fn(inputs, *args, **kwargs)
    File ""C:\Users\me\.conda\envs\tf-gpu\lib\site-packages\keras\utils\traceback_utils.py"", line 92, in error_handler
      return fn(*args, **kwargs)
    File ""C:\Users\me\.conda\envs\tf-gpu\lib\site-packages\keras\layers\convolutional.py"", line 248, in call
      outputs = self.convolution_op(inputs, self.kernel)
    File ""C:\Users\me\.conda\envs\tf-gpu\lib\site-packages\keras\layers\convolutional.py"", line 233, in convolution_op
      return tf.nn.convolution(
Node: 'sequential/conv1d/Conv1D'
DNN library is not found.
	 [[{{node sequential/conv1d/Conv1D}}]] [Op:__inference_train_function_842]
"
55466,undefined symbol when linking tf code with custom op,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): AmazonLinux2
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): installed through pip
- TensorFlow version: 2.8
- Python version: 3.8
- Installed using virtualenv? pip? conda?: pip
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 11.2
- GPU model and memory: Nvidia V100



**Describe the problem**

Hi,

I'm writing a custom op and I'd like to reuse an existing tf function `tensorflow::functor::DenseUpdate<>` for updating `tf.Variable`. I am able to compile my custom op successfully but I get the following error at runtime when I try to load my op in python:

```
undefined symbol: _ZN10tensorflow7functor11DenseUpdateIN5Eigen9GpuDeviceEdLNS_15DenseUpdateTypeE2EEclERKS3_NS2_9TensorMapINS2_6TensorIdLi1ELi1ElEELi16ENS2_11MakePointerEEENS8_INS9_IKdLi1ELi1ElEELi16ESB_EE
```

I am able to find this symbol in `_pywrap_tensorflow_internal.so` library which gets loaded when I import tensorflow.
```
$ nm -gD /home/ec2-user/anaconda3/envs/tf2/lib/python3.8/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so | grep _ZN10tensorflow7functor11DenseUpdateIN5Eigen9GpuDevice
_ZN10tensorflow7functor11DenseUpdateIN5Eigen9GpuDeviceEdLNS_15DenseUpdateTypeE2EEclERKS3_NS2_9TensorMapINS2_6TensorIdLi1ELi1ElEELi16ENS2_11MakePointerEEENS8_INS9_IKdLi1ELi1ElEELi16ESB_EE
```

Can someone help point out what could be an issue here?

Thanks

"
55463,I am using AD9361z7035 breakout board. using ubuntu version linaro 12.06 I want to install tensorflow lite on it. ,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1.  It must be a bug, a feature request, or a significant problem with the
    documentation (for small docs fixes please send a PR instead).
2.  The form below must be filled out.
3.  It shouldn't be a TensorBoard issue. Those go
    [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information

-   **Have I written custom code (as opposed to using a stock example script
    provided in TensorFlow)**:
-   **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
-   **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue
    happens on a mobile device**:
-   **TensorFlow installed from (source or binary)**:
-   **TensorFlow version (use command below)**:
-   **Python version**:
-   **Bazel version (if compiling from source)**:
-   **GCC/Compiler version (if compiling from source)**:
-   **CUDA/cuDNN version**:
-   **GPU model and memory**:
-   **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with:

```bash
python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""
```

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
55461,Possibly platform related tflite conversion issue,"### 1. System information

#### (1) With issues in:
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): `macOS Monterey 12.2.1 (m1)`
- TensorFlow installation (pip package or built from source):  following https://developer.apple.com/metal/tensorflow-plugin/
- TensorFlow library (version, if pip package or github SHA, if built from source): 
```
tensorflow-deps==2.8.0
tensorflow-graphics==2021.12.3
tensorflow-macos==2.8.0
tensorflow-metal==0.4.0  
```

#### (2) Without issues in:
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): `Arch Linux x86_64 (5.16.16-arch1-1)`
- TensorFlow installation (pip package or built from source):  `pip`
- TensorFlow library (version, if pip package or github SHA, if built from source): `2.8.0`

### 2. Code
Written to match [this example](https://www.tensorflow.org/graphics/api_docs/python/tfg/math/optimizer/levenberg_marquardt/minimize#examplesl) as much as possible.

```python
import os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'

import tensorflow as tf
from tensorflow_graphics.math.optimizer import levenberg_marquardt


def convert_to_tflite(
    model_path: str,
) -> bytes:
    converter = tf.lite.TFLiteConverter.from_saved_model(model_path)
    converter.optimizations = [tf.lite.Optimize.DEFAULT]
    converter.target_spec.supported_ops = [
        tf.lite.OpsSet.TFLITE_BUILTINS,  # enable TensorFlow Lite ops.
        tf.lite.OpsSet.SELECT_TF_OPS,  # enable TensorFlow ops.
    ]

    tflite_model = converter.convert()
    assert isinstance(tflite_model, bytes)

    return tflite_model


def tflite_inference(
    inputs: list[tf.Tensor],
    tflite_model: bytes,
) -> list:
    # create interpreter
    interpreter = tf.lite.Interpreter(model_content=tflite_model)
    interpreter.allocate_tensors()

    # set inputs
    input_details = interpreter.get_input_details()
    for input_tensor, input_placeholder in zip(inputs, input_details):
        interpreter.set_tensor(input_placeholder[""index""], input_tensor)

    # invoke interpreter
    interpreter.invoke()

    # return outputs
    output_details = interpreter.get_output_details()
    return [interpreter.get_tensor(output[""index""]) for output in output_details]


def create_lmo_model():
    def f1(x, y):
        return x + y

    def f2(x, y):
        return x * y

    class LMO(tf.keras.layers.Layer):
        def call(self, inputs):
            _, (r1, r2) = levenberg_marquardt.minimize(
                residuals=(f1, f2),
                variables=inputs,
                max_iterations=10,
            )
            return [r1, r2]

    input_x = tf.keras.Input(
        shape=(1, 2),
    )
    input_y = tf.keras.Input(
        shape=(3, 1),
    )
    output = LMO()([input_x, input_y])

    return tf.keras.Model(
        inputs=[input_x, input_y],
        outputs=output,
    )


def main():
    tf.random.set_seed(5)
    x = tf.random.uniform((1, 1, 2))
    y = tf.random.uniform((1, 3, 1))
    inputs = [x, y]

    model = create_lmo_model()
    print(model(inputs))

    tf.saved_model.save(
        model,
        ""lmo_model"",
    )

    tflite_model = convert_to_tflite(""lmo_model"")
    print(
        tflite_inference(
            tflite_model=tflite_model,
            inputs=inputs,
        )
    )


if __name__ == ""__main__"":
    main()
```

### 3. Failure after conversion
On platform 1 tflite interpreter fails to invoke with error:
```bash
RuntimeError: Input matrix is not invertible.
	 (while executing 'MatrixTriangularSolve' via Eager)Node number 15 (TfLiteFlexDelegate) failed to invoke.Node number 104 (IF) failed to invoke.Node number 10 (WHILE) failed to invoke.
```
On platform 2 everything works as expected."
55455,GRU performance severely degraded inside tf.function with Apple m1 chip,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Mac OS Monterey 12.3, Metal device set to: Apple M1 Pro
- TensorFlow installed from (source or binary):
binary
- TensorFlow version:
tensorflow-deps           2.7.0                
tensorflow-macos          2.8.0              
tensorflow-metal          0.4.0 
- Python version:
3.9.12
- GPU model and memory:
 Apple M1 Pro

**Describe the current behavior**

I run this simple code with a GRU layer with a `tf.function` decorator:

```
import tensorflow as tf
from time import time

a = tf.random.truncated_normal([4, 4, 4])
layer = tf.keras.layers.GRU(4) 

@tf.function
def f(a):
    return layer(a)

start = time()
for _ in range(1000):
    with tf.GradientTape() as tape:
        b = f(a)
print(str(time() - start), ""seconds"")
```
its much slower (~5-10x times) than running in the eager mode. However, this bug only shows up for recurrent layers. When using Dense, the `tf.function` mode is faster than the eager mode as expected. The issue also disappeared outside `tf.GradientTape()`.
I only encountered this problem in my Apple Macbook Pro with M1 chip. I tried it on a linux machine and it's ok.

**Describe the expected behavior**
`tf.function` should be faster (at least not several times slower) than the eager mode.

**Standalone code to reproduce the issue**
It cannot be reproduced on a linux machine, so no Colab notebook is available.

**Other info / logs** 

FYI the code above runs with the warning message as follows:

> 2022-03-31 14:40:34.462151: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz
2022-03-31 14:40:34.463604: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.
2022-03-31 14:40:34.480917: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:828] function_optimizer failed: INVALID_ARGUMENT: Input 0 of node gru_partitionedcall_10_RetVal was passed float from gru/PartitionedCall:12 incompatible with expected variant.
2022-03-31 14:40:34.487243: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:828] tfg_optimizer{} failed: INVALID_ARGUMENT: Input 0 of node gru_partitionedcall_10_RetVal was passed float from gru/PartitionedCall:12 incompatible with expected variant.
	when importing GraphDef to MLIR module in GrapplerHook
2022-03-31 14:40:34.488903: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:828] function_optimizer failed: INVALID_ARGUMENT: Input 0 of node gru_partitionedcall_10_RetVal was passed float from gru/PartitionedCall:12 incompatible with expected variant.
2022-03-31 14:40:34.494395: W tensorflow/core/common_runtime/process_function_library_runtime.cc:932] Ignoring multi-device function optimization failure: INVALID_ARGUMENT: Input 0 of node gru_partitionedcall_10_RetVal was passed float from gru/PartitionedCall:12 incompatible with expected variant.
2022-03-31 14:40:34.508855: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled."
55454,Keras cant load model with tf.where when dtype is float64,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: -
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.8 (also encountered on 2.4)
- Python version: 3.7.5
- Bazel version (if compiling from source): -
- GCC/Compiler version (if compiling from source): -
- CUDA/cuDNN version: -
- GPU model and memory: -

**Describe the current behavior**
Loading a model that utilizes `tf.where` to replace a variable with some constant fails when all involved tensors are `float64` tensors.

Possibly connected to [this issue](https://github.com/tensorflow/tensorflow/issues/47161).

**Describe the expected behavior**
The model loads successfuly.

**Standalone code to reproduce the issue**
```
import tensorflow as tf
from tensorflow import keras

dtype = 'float64'

some_input = keras.Input(shape=(1), dtype=dtype)
some_value = keras.layers.Dense(4, activation=""relu"", dtype=dtype)(some_input)
some_value = keras.layers.Dense(2, dtype=dtype)(some_value)

other_value = tf.constant([0.1], dtype=dtype)

mask = tf.equal([0, 1], 1)
replaced_value = tf.where(mask, x=other_value, y=some_value)

model = tf.keras.Model(inputs=[some_input], outputs=[replaced_value])
model.save('my_test_model')

loaded_model = tf.keras.models.load_model('my_test_model')
```

However, the model can be loaded properly when the arguments in the call to `tf.where` are switched, like this `tf.where(mask, x=some_value, y=other_value)`

Setting `tf.keras.backend.set_floatx('float64')` does not prevent the error from occuring.

See this [Colab notebook](https://colab.research.google.com/drive/1mii4nbvHUJHaqbG60bEm88-ttdB7AltJ).

**Other info / logs**
```
---------------------------------------------------------------------------

TypeError                                 Traceback (most recent call last)

[<ipython-input-11-a4651214ca80>](https://localhost:8080/#) in <module>()
----> 1 loaded_model = tf.keras.models.load_model('my_test_model')

[/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py](https://localhost:8080/#) in error_handler(*args, **kwargs)
     65     except Exception as e:  # pylint: disable=broad-except
     66       filtered_tb = _process_traceback_frames(e.__traceback__)
---> 67       raise e.with_traceback(filtered_tb) from None
     68     finally:
     69       del filtered_tb

[/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py](https://localhost:8080/#) in _apply_op_helper(op_type_name, name, **keywords)
    545 
    546             raise TypeError(
--> 547                 f""{prefix} type ""
    548                 f""{dtypes.as_dtype(attrs[input_arg.type_attr]).name} of ""
    549                 f""argument '{inferred_from[input_arg.type_attr]}'."")

TypeError: Exception encountered when calling layer ""tf.where_3"" (type TFOpLambda).

Input 'e' of 'SelectV2' Op has type float64 that does not match type float32 of argument 't'.

Call arguments received:
  • condition=['tf.Tensor(shape=(), dtype=bool)', 'tf.Tensor(shape=(), dtype=bool)']
  • x=['0.1']
  • y=tf.Tensor(shape=(None, 2), dtype=float64)
  • name=None
```
"
55452,TensorRT conversion fails with 5D input data,"Hi, I'm having an issue with tensorrt conversion of model which uses 3D convolutions and processes 5D input.

Code to reproduce error (I cut the model to minimal example):
```
import tensorflow as tf
import numpy as np
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Input,Conv3D,BatchNormalization,Activation

print(""TensorFlow version: "",tf.version.VERSION)

src_dir='model_bn'
dst_dir='model_bn_conv'
batch=4
input_shape=(24,160,160,3)

def input_fn():
    yield [np.zeros(((batch,)+input_shape),dtype='float32')]

model=Sequential()
model.add(Input(shape=input_shape))
model.add(Conv3D(24,3))
model.add(BatchNormalization())
model.add(Activation('relu'))

model.save(src_dir)

params=tf.experimental.tensorrt.ConversionParams(precision_mode='FP32')
converter=tf.experimental.tensorrt.Converter(input_saved_model_dir=src_dir,conversion_params=params)

converter.convert()
print('Converted successfully!')

print('Running build()...')
converter.build(input_fn=input_fn)
print('Build completed')
converter.save(dst_dir)
```

The output:
```
TensorFlow version:  2.8.0
2022-03-31 11:44:04.711186: I tensorflow/core/platform/cpu_feature_guard.cc:152] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-03-31 11:44:05.311164: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13608 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:3b:00.0, compute capability: 7.5
WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
2022-03-31 11:44:05.990618: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
2022-03-31 11:44:06.422604: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1
2022-03-31 11:44:06.422784: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session
2022-03-31 11:44:06.458670: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13608 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:3b:00.0, compute capability: 7.5
2022-03-31 11:44:06.485282: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1191] Optimization results for grappler item: graph_to_optimize
  function_optimizer: Graph size after: 30 nodes (20), 41 edges (31), time = 1.05ms.
  function_optimizer: function_optimizer did nothing. time = 0.01ms.

2022-03-31 11:44:06.529996: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1
2022-03-31 11:44:06.530104: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session
2022-03-31 11:44:06.539721: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13608 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:3b:00.0, compute capability: 7.5
2022-03-31 11:44:06.551640: W tensorflow/compiler/tf2tensorrt/convert/trt_optimization_pass.cc:192] Calibration with FP32 or FP16 is not implemented. Falling back to use_calibration = False.Note that the default value of use_calibration is True.
2022-03-31 11:44:06.551665: I tensorflow/compiler/tf2tensorrt/convert/trt_optimization_pass.cc:211] [TF-TRT] not using explicit QDQ mode
2022-03-31 11:44:06.552184: W tensorflow/compiler/tf2tensorrt/segment/segment.cc:954]

################################################################################
TensorRT unsupported/non-converted OP Report:
        - NoOp -> 2x
        - Identity -> 1x
        - Placeholder -> 1x
--------------------------------------------------------------------------------
        - Total nonconverted OPs: 4
        - Total nonconverted OP Types: 3
For more information see https://docs.nvidia.com/deeplearning/frameworks/tf-trt-user-guide/index.html#supported-ops.
################################################################################

2022-03-31 11:44:06.552276: W tensorflow/compiler/tf2tensorrt/segment/segment.cc:1281] The environment variable TF_TRT_MAX_ALLOWED_ENGINES=20 has no effect since there are only 1 TRT Engines with  at least minimum_segment_size=3 nodes.
2022-03-31 11:44:06.552292: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:795] Number of TensorRT candidate segments: 1
2022-03-31 11:44:06.552678: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:909] Replaced segment 0 consisting of 11 nodes by TRTEngineOp_0_0.
2022-03-31 11:44:06.556775: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1191] Optimization results for grappler item: tf_graph
  model_pruner: Graph size after: 22 nodes (-8), 33 edges (-8), time = 0.273ms.
  debug_stripper: debug_stripper did nothing. time = 0.008ms.
  layout: Graph size after: 26 nodes (4), 37 edges (4), time = 1.157ms.
  dependency_optimizer: Graph size after: 16 nodes (-10), 15 edges (-22), time = 0.228ms.
  constant_folding: Graph size after: 16 nodes (0), 15 edges (0), time = 0.564ms.
  common_subgraph_elimination: Graph size after: 13 nodes (-3), 15 edges (0), time = 0.124ms.
  TensorRTOptimizer: Graph size after: 3 nodes (-10), 2 edges (-13), time = 1.148ms.
  constant_folding: Graph size after: 3 nodes (0), 2 edges (0), time = 0.294ms.
Optimization results for grappler item: TRTEngineOp_0_0_native_segment
  model_pruner: Graph size after: 13 nodes (0), 15 edges (0), time = 0.083ms.
  debug_stripper: debug_stripper did nothing. time = 0.006ms.
  layout: Graph size after: 13 nodes (0), 15 edges (0), time = 0.4ms.
  dependency_optimizer: Graph size after: 12 nodes (-1), 13 edges (-2), time = 0.116ms.
  constant_folding: Graph size after: 12 nodes (0), 13 edges (0), time = 0.366ms.
  common_subgraph_elimination: Graph size after: 12 nodes (0), 13 edges (0), time = 0.093ms.
  TensorRTOptimizer: Graph size after: 12 nodes (0), 13 edges (0), time = 0.013ms.
  constant_folding: Graph size after: 12 nodes (0), 13 edges (0), time = 0.346ms.

Converted successfully!
Running build()...
2022-03-31 11:44:06.640977: I tensorflow/compiler/tf2tensorrt/kernels/trt_engine_op.cc:446] TRTEngineOp not using explicit QDQ
2022-03-31 11:44:06.643431: I tensorflow/compiler/tf2tensorrt/common/utils.cc:100] Linked TensorRT version: 8.2.3
2022-03-31 11:44:06.643602: I tensorflow/compiler/tf2tensorrt/common/utils.cc:102] Loaded TensorRT version: 8.2.3
2022-03-31 11:44:07.618558: F ./tensorflow/compiler/tf2tensorrt/utils/trt_tensor_proxy.h:158] 'trt_tensor_' Must be non NULL
Aborted
```

Other observations:
- Removing activation layer or swapping it with BatchNorm makes script to execute without errors, but doesn't produce valid trt engine. It writes the following warning: ""TF-TRT Warning: Engine creation for TRTEngineOp_0_0 failed. The native segment will be used instead. Reason: INVALID_ARGUMENT: Rank of perm for transpose does not match with that of the input.""
- Removing Conv3D layer does not change the result.
- Trying to tweak conversion parameters did not help.
- Using 4D input data and 2D convolutions seem to work fine.

**System information**
(Using NVidia NGC container for Tensorflow, version 22.03)
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): **Yes**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **Linux Ubuntu 20.04**
- TensorFlow installed from (source or binary): **binary**
- TensorFlow version (use command below): **2.8.0**
- Python version: **3.8.10**
- CUDA/cuDNN version: **11.6/8.3.3**
- GPU model and memory: **NVidia Tesla T4 16Gb**
"
55451,CustomGraphOptimizer doesn't work,"I implemented a `CustomGraphOptimizer`, and registered it through `CustomGraphOptimizerRegistrar`, but that optimizer seems not to work? Am I doing anything wrong?

Here is my cc codes about `CustomGraphOptimizer`:
```c++
#include ""tensorflow/core/grappler/clusters/cluster.h""
#include ""tensorflow/core/grappler/grappler_item.h""
#include ""tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.h""
#include ""tensorflow/core/grappler/utils/functions.h""

namespace tensorflow {
namespace grappler {

#define DebugINFO(msg)                           \
    do {                                         \
        std::cout << ""[CUSTOM_OPTIMIZER]"" << "":"" \
                  << __FILE__ << "":"" << __LINE__ \
                  << "": "" << #msg << std::endl;  \
    } while (0)

class MyCustomGraphOptimizer : public CustomGraphOptimizer {
public:
    MyCustomGraphOptimizer(const string& name) 
    : name_(name) {
        DebugINFO(MyCustomGraphOptimizer_Ctor);
    }

    Status Init(const tensorflow::RewriterConfig_CustomGraphOptimizer* config) override {
        DebugINFO(Init);
        return Status::OK();
    } 

    string name() const override { 
        DebugINFO(name); 
        return name_; 
    }

    bool UsesFunctionLibrary() const override { 
        DebugINFO(UsesFunctionLibrary);
        return false; 
    }

    Status Optimize(Cluster* cluster, const GrapplerItem& item, GraphDef* optimized_graph) override {
        DebugINFO(Optimize);
        return Status::OK();
    }
private:
    const string name_;
};

class MyCustomGraphOptimizerRegistrar : public CustomGraphOptimizerRegistrar {
public:
    MyCustomGraphOptimizerRegistrar(
        const CustomGraphOptimizerRegistry::Creator& creator,
        const string& name) 
    : CustomGraphOptimizerRegistrar(creator, name) {
        DebugINFO(CustomGraphOptimizerRegistrar_Ctor); 

        std::vector<string> optimizers = CustomGraphOptimizerRegistry::GetRegisteredOptimizers();
        for (auto const& opt : optimizers) {
            std::cout << ""RegisteredOptimizer: "" << opt << std::endl;
        }
    }
};

static MyCustomGraphOptimizerRegistrar MyCustomGraphOptimizer_Registrar(
    /*creator=*/
    [](){
        DebugINFO(MyCustomGraphOptimizer_Registrar);
        return new MyCustomGraphOptimizer(""MyCustomGraphOptimizer"");
    }, /*name=*/""CustomGraphOptimizer"");

} // namespace grappler
} // namespace tensorflow
```

And here is my python testing codes:
```python
from tensorflow.core.protobuf import config_pb2
from tensorflow.python.framework import ops
from tensorflow.python.grappler import tf_optimizer
from tensorflow.python.framework import meta_graph
from tensorflow.core.protobuf import rewriter_config_pb2
from tensorflow.core.framework import graph_pb2
from build import TFCustomGraphOptimizer as custom_graph_op

def _get_custom_rewriter_config():
    rewriter_config = rewriter_config_pb2.RewriterConfig()
    
    rewriter_config.meta_optimizer_iterations = (
      rewriter_config_pb2.RewriterConfig.ONE)
    rewriter_config.min_graph_nodes = -1 # do not skip optimization

    rewriter_config.optimizers.extend([""constfold"", ""CustomGraphOptimizer""])
    rewriter_config.custom_optimizers.add().name = ""layout""

    opt = rewriter_config.custom_optimizers.add()
    opt.name = ""MyCustomGraphOptimizer""

    return rewriter_config

def OptimizeGraph(graph, verbose=False):
    # convert to metaGraph
    meta_graph_def = meta_graph.create_meta_graph_def(graph=graph)

    # create custom ConfigProto for Grappler
    grappler_session_config = config_pb2.ConfigProto()
    custom_rewriter_config = _get_custom_rewriter_config()
    grappler_session_config.graph_options.rewrite_options.CopyFrom(custom_rewriter_config)

    # Run Grappler
    grappler = tf_optimizer.OptimizeGraph
    converted_graph_def = grappler(config_proto=grappler_session_config,
                                   metagraph=meta_graph_def,
                                   verbose=verbose,
                                   cluster=None,
                                   strip_default_attributes=False)

    return converted_graph_def

if __name__ == ""__main__"":
    import tensorflow as tf
    from tensorflow.python.ops import random_ops

    with ops.Graph().as_default() as g:
        a = random_ops.random_uniform(shape=())
        b = random_ops.random_uniform(shape=())

        c = a + b

        train_op = ops.get_collection_ref(ops.GraphKeys.TRAIN_OP)
        train_op.append(c)

        optimized_graph = OptimizeGraph(graph=g, verbose=True)
        # print(optimized_graph)
```"
55450,"Python Import error for tensorflow, tflearn and nltk libraries!","```
Traceback (most recent call last):
  File ""/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/__init__.py"", line 61, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 28, in <module>
    _pywrap_tensorflow = swig_import_helper()
  File ""/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow', fp, pathname, description)
  File ""/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/imp.py"", line 243, in load_module
    return load_dynamic(name, filename, file)
  File ""/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/imp.py"", line 343, in load_dynamic
    return _load(spec)
ImportError: dlopen(/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/_pywrap_tensorflow.so, 0x000A): tried: '/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/_pywrap_tensorflow.so' (mach-o file, but is an incompatible architecture (have 'x86_64', need 'arm64e'))

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/Users/virajsabhaya/Library/CloudStorage/OneDrive-UniversityofTexasatArlington/Documents/MyPersonalProject/Interview_Chat_Bot/main.py"", line 2, in <module>
    import tensorflow as tf
  File ""/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/__init__.py"", line 24, in <module>
    from tensorflow.python import *
  File ""/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/__init__.py"", line 72, in <module>
    raise ImportError(msg)
ImportError: Traceback (most recent call last):
  File ""/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/__init__.py"", line 61, in <module>
    from tensorflow.python import pywrap_tensorflow
  File ""/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 28, in <module>
    _pywrap_tensorflow = swig_import_helper()
  File ""/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 24, in swig_import_helper
    _mod = imp.load_module('_pywrap_tensorflow', fp, pathname, description)
  File ""/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/imp.py"", line 243, in load_module
    return load_dynamic(name, filename, file)
  File ""/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/imp.py"", line 343, in load_dynamic
    return _load(spec)
ImportError: dlopen(/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/_pywrap_tensorflow.so, 0x000A): tried: '/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/_pywrap_tensorflow.so' (mach-o file, but is an incompatible architecture (have 'x86_64', need 'arm64e'))


Failed to load the native TensorFlow runtime.

See https://github.com/tensorflow/tensorflow/blob/master/tensorflow/g3doc/get_started/os_setup.md#import_error

for some common reasons and solutions.  Include the entire stack trace
above this error message when asking for help.
```
---

- I have even changed the path and tried setting up the envn paths to anaconda and python3 but it still shows this error. 
- If I comment the imports of the libraries mentioned I don't get any errors."
55449,Notebooks deleted when following beginner tutorial,"Hi!

This issue is related to a notebook which is a part of the beginner tutorial focusing on text classification. 

Links:
https://www.tensorflow.org/tutorials/keras/text_classification
https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/text_classification.ipynb

I'm a beginner so I might be doing something wrong or something that is discouraged, but I figured that a warning may be appropriate if this is the case since this notebook is part of the beginner learning material.

## Description of issue (reproduction steps):
In short, the issue is that when executing a few steps in a specific order, .ipynb files with a specific prefix in the working directory are deleted.

Repro steps:
1. Run cell 1 (imports)
1. Run cell 2 (check version)
1. Run cell 3 (get IMDB dataset)
1. Restart kernel **before cell 3 is done**
1. Run cell 1 again

Now all .ipynb files in the working directory with a prefix of ""x_"" where x is a digit are deleted.

## Environment
I'm running the notebook in a local jupyter-lab (version 3.3.2) on a windows 10 (version 19042.1586) machine. 

If there is anything else anyone would like to know I'm happy to answer!

Thanks!"
55448,X86_64 - TFLite different inference results depending on whether it was compiled with XNNpack delegate or not,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): **_Yes_**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **_4.19.0-18-amd64 1 SMP Debian 4.19.208-1 (2021-09-29) x86_64 GNU/Linux_**
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: **No**
- TensorFlow installed from (source or binary): **_source_**
- TensorFlow version (use command below): **_r2.5, r2.8_**
- Python version: **_3.7.3_**
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source): **gcc 8.3.0**
- CUDA/cuDNN version: **N/A**
- GPU model and memory: **N/A**

**Describe the current behavior**
Running inference in CPP using tensorflow lite library compiled from source using CMake with default settings with XNNPACK support produce wrong results:
```[0, 0, 1, 0, ]```
 If tflite is sompiled with disabled XNNPACK support (`cmake -D TFLITE_ENABLE_XNNPACK=OFF ..`) - model works as expected.
If inference is running from python with XNNPACK support (based on console output - it prints `INFO: Created TensorFlow Lite XNNPACK delegate for CPU.`) - it is provide expected results.
```[1, 0, 0, 0, ]```
+ if we run inference from python with tensorflow==2.5.0 it doesn't show string above in regards of XNNPACK but produce valid results as well.

**Describe the expected behavior**
TFlite compiled with XNNPACK in cpp produce the same result as library without XNNPACK

**[Contributing](https://www.tensorflow.org/community/contribute)**

- Do you want to contribute a PR? (yes/no): no

**Standalone code to reproduce the issue**
https://github.com/kruglov-dmitry/tensorflow_lite_from_cpp_python

Repository contains:
- tflite model and test image to run inference
- cpp source, makefile and build instructions
- python source"
55447,How about exporting `Tensor::FromProto` to Python API?,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): 2.8
- Are you willing to contribute it (Yes/No):

**Describe the feature and the current behavior/state.**

If we have to convert TensorProto message in Python env, we can't directly convert it.
We have to 

1. construct a new tensor with protobuf message field
2. serialize message to string and parse it using `tf.io.parse_tensor`
3. or some other way

**Will this change the current api? How?**

Yes. Maybe we can add the `tf.from_tensor_proto` like `tf.make_tensor_proto`.

**Who will benefit with this feature?**

The people who frequently handle protobuf messages.
For example, I handle TensorProto messages directly when I predict some examples with TensorFlow Serving using gRPC.

**Any Other info.**

[`Tensor::FromProto` docs link](https://www.tensorflow.org/api_docs/cc/class/tensorflow/tensor#fromproto)"
55446,"Checkpoint variable names are assigned ""variables/0/..."" etc if keras model has more than two nested layers/models","**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 20.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.8.0 (gpu)
- Python version: 3.10.2
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: 11.5/8.3.1
- GPU model and memory: 1080 Ti 12GB

**Describe the current behavior**

When a keras model has more than two nested layers/models the names of saved variables of inner layers get assigned incremental values like `variables/{0,1,2...}/.ATTRIBUTES/VARIABLE_VALUE` instead of `inner/layer/kernel/.ATTRIBUTES/VARIABLE_VALUE` for example. This does not happen in nested `tf.Module`s.

**Describe the expected behavior**

To be honest I would expect both tensorflow and keras to respect the actual names of variables in `.name` attribute when saving to a checkpoint, like with TF1.x scopes; rather than this mess of `module_name/module_name/kernel/.ATTRIBUTES/VARIABLE_VALUE`. But if we have to accept the `.ATTRIBUTES/VARIABLE_VALUE` business, the variable names should still follow the nested module names rather than `variables/0/` etc.

- Do you want to contribute a PR? (yes/no): yes
- Briefly describe your candidate solution(if contributing):

The issue is caused when the `TrackableReference` chain to a variable is shorter through `variables/{index}` (2 jumps) than it is with `inner/layer/kernel` (3 jumps or more) during the breadth first traversal implemented here: https://github.com/tensorflow/tensorflow/blob/38976aedc4e9d9149bfe75f485be0dd833e9eec7/tensorflow/python/training/tracking/graph_view.py#L246

**Solution**

Add
```
elif any([path_element.name in [""variables"", ""trainable_variables"", ""non_trainable_variables""] for path_element in node_paths[dependency]]):
    node_paths[dependency] = node_paths[current_trackable] + (base.TrackableReference(name, dependency),)
```
after https://github.com/tensorflow/tensorflow/blob/38976aedc4e9d9149bfe75f485be0dd833e9eec7/tensorflow/python/training/tracking/graph_view.py#L260

**Standalone code to reproduce the issue**

```
import tensorflow as tf

class inner_block(tf.keras.layers.Layer):
    def __init__(self):
        super().__init__(name=""inner"")
        self.layer = tf.keras.layers.Dense(2, name=""inner_dense"") # kernel of this will save as ""variables/0/.ATTRIBUTES/VARIABLE_VALUE""
        self.var = tf.Variable([1.0, 2.0], name=""inner_var"") # this will save as expected ""inner_m/var/.ATTRIBUTES/VARIABLE_VALUE""

    def call(self, x):
        return self.layer(x) + self.var

class model(tf.keras.Model):
    def __init__(self):
        super().__init__(name=""outer"")
        self.inner_m = inner_block()
        self.dense = tf.keras.layers.Dense(2, name=""outer_dense"") # kernel of this will save as expected ""dense/kernel/.ATTRIBUTES/VARIABLE_VALUE""

    def call(self, x):
        x = self.inner_m(x)
        x = self.dense(x)
        return x

m = model()
m.build((None, 3))
m(tf.random.normal((1, 3)))

m.save(""model"")  # or tf.saved_model.save(m, ""model"")
tf.train.list_variables(
    ""model/variables/variables""
)  # this lists 'variables/0/...' 'variables/1/...' along with the expected names
```"
55445,RuntimeError: Encountered unresolved custom op: PyFunc.Node number 559 (PyFunc) failed to prepare.,"System information

Windows
TF 2.5.0

Command used to run the converter or code if you’re using the Python API
Converter:

**keras_model = model.keras_model
converter = tf.lite.TFLiteConverter.from_keras_model(keras_model)
converter.allow_custom_ops = True
converter.experimental_new_converter = True
converter.target_spec.supported_ops = [
    tf.lite.OpsSet.TFLITE_BUILTINS, # enable TensorFlow Lite ops.
    tf.lite.OpsSet.SELECT_TF_OPS # enable TensorFlow ops.
]
tflite_model = converter.convert()**

Inference:

 **# Load the TFLite model and allocate tensors.
interpreter = tf.lite.Interpreter(model_path=tflite_model_path)

input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()

interpreter.resize_tensor_input(input_details[0]['index'], layer_image.shape)
interpreter.allocate_tensors()

input_data_1 = np.array(layer_image, dtype=np.float32)
interpreter.set_tensor(input_details[0]['index'], input_data_1)

interpreter.invoke()**

The output from the Inference:
**RuntimeError: Encountered unresolved custom op: PyFunc.Node number 559 (PyFunc) failed to prepare.**

Im pretty new to tensorflow. Im facing an issue in tflite model inference.I have used a **tf.numpy_function** in my keras layer for inference part, the inference is perfectly working in keras. But when converted to tflite, the pinvoke is giving me the above error




"
55444,what is the order when I call tf.keras.Layers.BatchNormation.get_weights() ? my tensorflow version is 2.2.0?,"<em>Please make sure that this is an issue related to keras.
tag:keras_template</em>

**Important Notice**

Please note that `tf.keras` code was moved entirely to
[keras-team/keras](https://github.com/keras-team/keras) repository

You can open any code/doc bugs, performance issues, and feature requests
 in [keras-team/keras](https://github.com/keras-team/keras/issues) repository

`tf.keras` related issues opened in
[tensorflow/tensorflow](https://github.com/tensorflow/tensorflow) repository may
not get attention as [keras-team/keras](https://github.com/keras-team/keras)
repository is dedicated for the development of `keras` code
"
55442,Pylint phantom checks,"Some check that we have enabled in `.pylintrc` are silently not executed anymore.

https://github.com/tensorflow/tensorflow/blob/fa6895a1564f14f488c5019039e3f0addef49f32/tensorflow/tools/ci_build/pylintrc#L48
`python -m pylint --list-msgs | egrep ""indexing-exception|old-raise-syntax|W0311|W0312|C0330|C0301|C0326|W0611|W0622""`

We have only 4/9 explicitly enabled checks that are still valid: 
```
:line-too-long (C0301): *Line too long (%s/%s)*
:bad-indentation (W0311): *Bad indentation. Found %s %s, expected %s*
:unused-import (W0611): *Unused %s*
:redefined-builtin (W0622): *Redefining built-in %r*
```
It could require `black` to support some of these check again. 
Please check https://github.com/tensorflow/tensorflow/pull/55396#issuecomment-1083685885

/cc @mihaimaruseac @angerson @mdanatg"
55441,[Saved Model] Loading Saved Model & GraphDef mostly doesn't respect device placement,"In the context of TF-TRT, we need to be able to load and assign SavedModel and GraphDef to a specific `tf.device`. And as shown in this reproducer, virtually all calls lead to a loss/disrespect of the device information, and defaults back on `GPU:0` when actually executed.

Problem: TF-TRT needs internally to access graphdef, and manipulate it. Unfortunately for now, we can't find a way to assign any graphdef to a GPU != 0.

Please see the following reproducer case:

```python
import os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'

import tensorflow as tf
from tensorflow import keras
from keras import backend as K
from tensorflow.python.framework import ops

tf.get_logger().setLevel('WARNING')


def extract_devices_from_graphdef(graphdef):
    all_nodes = [n for n in graphdef.node]
    all_devices = list(set([n.device for n in all_nodes]))
    return all_devices


def create_model():
  """"""Define a simple sequential model""""""
  model = tf.keras.models.Sequential([
    keras.layers.Dense(512, activation='relu', input_shape=(784,)),
    keras.layers.Dropout(0.2),
    keras.layers.Dense(10)
  ])
  model.compile(optimizer='adam',
                loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),
                metrics=[tf.metrics.SparseCategoricalAccuracy()])
  return model


if __name__ == ""__main__"":

    try:
        gpus = tf.config.list_physical_devices('GPU')
    except AttributeError:
        gpus = tf.config.experimental.list_physical_devices('GPU')

    if not gpus:
        raise RuntimeError(""No GPUs has been found."")

    print('Found the following GPUs:')
    for gpu in gpus:
        print(f""\t- {gpu}"")


    # Create a basic model instance
    model = create_model()
    model.save('./saved_model/my_model')

    # Case 1 - Working
    with tf.device(""gpu:1""):
        print(""\n=================== CASE 1: `tf.saved_model.load` ==================="")
        from tensorflow.python.saved_model import load as load_module
        from tensorflow.python.saved_model.load import load as load_fn
        print(""TF2 API:      "", id(tf.saved_model.load))
        # >>> TF2 API:       139634355265248
        print(""Direct Access:"", id(load_fn))
        # >>> Direct Access: 139634355265248
        print(""Module Access:"", id(load_module.load))
        # >>> Module Access: 139634355265248

        model_loaded = tf.saved_model.load(export_dir='./saved_model/my_model')
        print(""Loaded Model:"", model_loaded.variables[0].device)
        # >>> '/job:localhost/replica:0/task:0/device:GPU:1'

        from tensorflow.python.saved_model import signature_constants
        func = model_loaded.signatures[
            signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY
        ]

        print(""Loaded Func Found Devices:"", extract_devices_from_graphdef(func.graph.as_graph_def()))
        # >>> Loaded Func Found Devices: {''}

        from tensorflow.python.framework import convert_to_constants
        frozen_func = convert_to_constants.convert_variables_to_constants_v2(func)
        print(""Frozen Func Found Devices:"", extract_devices_from_graphdef(frozen_func.graph.as_graph_def()))

        print(""\n=================== CASE 2: `loader.load` ==================="")
        from tensorflow.python.saved_model import loader
        from tensorflow.python.saved_model import tag_constants
        from tensorflow.python.client import session
        from tensorflow.python.saved_model import signature_constants

        with session.Session() as sess:
            input_meta_graph_def = loader.load(
                sess, [tag_constants.SERVING], './saved_model/my_model'
            )
            # input_signature_def = input_meta_graph_def.signature_def[
            #     signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY
            # ]

            print(""Found Devices:"", extract_devices_from_graphdef(sess.graph.as_graph_def()))
            # >>> Found Devices: ['', '/device:CPU:0']

        print(""\n=================== CASE 3: `importer.import_graph_def` ==================="")
        from tensorflow.python.framework import importer

        print(""Direct Access:"", id(tf.graph_util.import_graph_def))
        # >>> Direct Access: 139634355265248
        print(""Module Access:"", id(importer.import_graph_def))
        # >>> Module Access: 139634355265248
        
        with ops.Graph().as_default() as graph:
            importer.import_graph_def(input_meta_graph_def.graph_def, name="""")
            print(""Found Devices:"", extract_devices_from_graphdef(graph.as_graph_def()))
            # >>> Found Devices: ['', '/device:CPU:0']
```


Output:

```bash
Found the following GPUs:
	- PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')
	- PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')
	- 
=================== CASE 1: `tf.saved_model.load` ===================
TF2 API:       140219455831776
Direct Access: 140219455831776
Module Access: 140219455831776
Loaded Model: /job:localhost/replica:0/task:0/device:GPU:1
Loaded Func Found Devices: ['']
Frozen Func Found Devices: ['']

=================== CASE 2: `loader.load` ===================
WARNING:tensorflow:From whatever.py:85: load (from tensorflow.python.saved_model.loader_impl) is deprecated and will be removed in a future version.
Instructions for updating:
This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.loader.load or tf.compat.v1.saved_model.load. There will be a new function for importing SavedModels in Tensorflow 2.0.
Found Devices: ['', '/device:CPU:0']

=================== CASE 3: `importer.import_graph_def` ===================
Direct Access: 140219510558784
Module Access: 140219510558784
Found Devices: ['', '/device:CPU:0']
```

**Question: How can we load and manipulate a graphdef on a specific GPU ?**"
55440,Tensorflow 2.8.0 | Error Message: ImportError: SystemError. | Tensorflow package error?,"Greetings Tensorflow Support Team.
Hi, I got this error recently on my anaconda environment on my Windows 10 Machine.
### Error Message:

> ImportError: SystemError: <built-in method __contains__ of dict object at 0x000001E3DD963A48> returned a result with an error set

### System Information

> Windows 10
> Anaconda Navigator 2.1.2
> Python: 3.7.11
> Numpy: 1.21.5
> Nvidia RTX 3060 Laptop GPU
> Nvidia CUDA: 11.2
> cuDNN Version: 8.1

### I got this error when upgrade it to Tensorflow 2.8.0 (Installed using pip)
`pip install tensorflow`

Error Log:
```
(shapes_tf2) C:\Users\User>python -c ""import tensorflow as tf;print(tf.__version__)""
RuntimeError: module compiled against API version 0xe but this version of numpy is 0xd
Traceback (most recent call last):
  File ""<string>"", line 1, in <module>
  File ""D:\VirtualEnvironment\anaconda3\envs\shapes_tf2\lib\site-packages\tensorflow\__init__.py"", line 37, in <module>
    from tensorflow.python.tools import module_util as _module_util
  File ""D:\VirtualEnvironment\anaconda3\envs\shapes_tf2\lib\site-packages\tensorflow\python\__init__.py"", line 37, in <module>
    from tensorflow.python.eager import context
  File ""D:\VirtualEnvironment\anaconda3\envs\shapes_tf2\lib\site-packages\tensorflow\python\eager\context.py"", line 35, in <module>
    from tensorflow.python.client import pywrap_tf_session
  File ""D:\VirtualEnvironment\anaconda3\envs\shapes_tf2\lib\site-packages\tensorflow\python\client\pywrap_tf_session.py"", line 19, in <module>
    from tensorflow.python.client._pywrap_tf_session import *
ImportError: SystemError: <built-in method __contains__ of dict object at 0x000001E3DD963A48> returned a result with an error set

(shapes_tf2) C:\Users\User>python -c ""import tensorflow as tf;print(tf.reduce_sum(tf.random.normal([1000, 1000])))""
RuntimeError: module compiled against API version 0xe but this version of numpy is 0xd
Traceback (most recent call last):
  File ""<string>"", line 1, in <module>
  File ""D:\VirtualEnvironment\anaconda3\envs\shapes_tf2\lib\site-packages\tensorflow\__init__.py"", line 37, in <module>
    from tensorflow.python.tools import module_util as _module_util
  File ""D:\VirtualEnvironment\anaconda3\envs\shapes_tf2\lib\site-packages\tensorflow\python\__init__.py"", line 37, in <module>
    from tensorflow.python.eager import context
  File ""D:\VirtualEnvironment\anaconda3\envs\shapes_tf2\lib\site-packages\tensorflow\python\eager\context.py"", line 35, in <module>
    from tensorflow.python.client import pywrap_tf_session
  File ""D:\VirtualEnvironment\anaconda3\envs\shapes_tf2\lib\site-packages\tensorflow\python\client\pywrap_tf_session.py"", line 19, in <module>
    from tensorflow.python.client._pywrap_tf_session import *
ImportError: SystemError: <built-in method __contains__ of dict object at 0x000001D6FFDF3A48> returned a result with an error set
```
### But when I'm downgrade it to 2.7.0, it runs normal. (Installed using pip)
`pip install tensorflow==2.7.0`
```
(shapes_tf2) C:\Users\User>python -c ""import tensorflow as tf;print(tf.__version__)""
2.7.0

(shapes_tf2) C:\Users\User>python -c ""import tensorflow as tf;print(tf.reduce_sum(tf.random.normal([1000, 1000])))""
2022-03-31 02:42:33.973041: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-03-31 02:42:34.357936: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3493 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6
tf.Tensor(95.8436, shape=(), dtype=float32)
```

Any solutions for this (other than downgrade it?).
I'm not having any problem for downgrade it. I'm here to report the error I got.
Thank you in advance.

March, 31st 2022

Aldy"
55438,model is loaded as Loader._recreate_base_user_object.<locals>._UserObject,"
python == 3.8
tensorflow (gpu) == 'v2.8.0-rc1-32-g3f878cff5b6'
keras == 2.8
windows 10

I am saving the model as both an h5 and keras format with

```
model.save('model.h5')
model.save(model_location)
type(model)   
```
```
keras.engine.functional.Functional
```

Then, I am loading the model with 

```
model = keras.models.load_model(model_location)
# or 
model = tf.saved_model.load(model_location) # results in the same
type(model)
```

```<class 'tensorflow.python.saved_model.load.Loader._recreate_base_user_object.<locals>._UserObject'>```

There is something up with the loading process that results in the following error when calling `model.predict(X)` 

```AttributeError: '_UserObject' object has no attribute 'predict'```

```
tf.saved_model.contains_saved_model(model_location)

true
```
However, loading the same model saved as an h5 file 
```
model = keras.models.load_model('model.h5')
type(model)
```
```
keras.engine.functional.Functional
```
works. 


Thanks in advance!

"
55437,runpath not including //tensorflow/python for _dtensor_device.so,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): manylinux2014
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: n/a
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): git HEAD
- Python version: 3.7.x
- Bazel version (if compiling from source): 5.0.0
- GCC/Compiler version (if compiling from source): 10.2.1
- CUDA/cuDNN version: n/a
- GPU model and memory: n/a

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

auditwheel fails with message about cannot find _pywrap_tensorflow_internal.so

**Describe the expected behavior**

auditwheel passes

**[Contributing](https://www.tensorflow.org/community/contribute)**

- Do you want to contribute a PR? (yes/no):
- Briefly describe your candidate solution(if contributing):

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

auditwheel repair -w ../wheels/ tensorflow-pkg/tensorflow_aarch64-2.9.0-cp38-cp38-linux_aarch64.wh

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

Issue introduced with https://github.com/tensorflow/tensorflow/commit/fd94c2628c344a288ee194bcdbfe36239f5d4cdd
"
55436,TF 2.8.0 NNApi createInterpreter fails on Android API 32 devices,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
Yes (sample project linked below)

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Android API 32 - Pixel 6

- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
Any device running Android API 32 (such as Pixel 6)

- TensorFlow installed from (source or binary):
Binary

- TensorFlow version (use command below):
2.8.0

- GPU model and memory:
Mali-G78 MP20, N/A (Shared memory)

**Describe the current behavior**

Instrumented test in sample project succeeds on API <= 31, fails on API == 32

**Describe the expected behavior**

Instrumented test in sample project succeeds on all Android API levels

- Do you want to contribute a PR? (yes/no): No, I don't know the fix.

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

`./gradlew connectedAndroidTest`

https://github.com/elevenfive/TensorFlowApplication

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

```
NNApi test threw exception
    java.lang.IllegalArgumentException: Internal error: Failed to apply delegate: NN API returned error ANEURALNETWORKS_OP_FAILED at line 4483 while completing NNAPI compilation.
    
    Node number 7 (TfLiteNnapiDelegate) failed to prepare.
    Restored original execution plan after delegate application failure.
        at org.tensorflow.lite.NativeInterpreterWrapper.createInterpreter(Native Method)
        at org.tensorflow.lite.NativeInterpreterWrapper.init(NativeInterpreterWrapper.java:93)
        at org.tensorflow.lite.NativeInterpreterWrapper.<init>(NativeInterpreterWrapper.java:66)
        at org.tensorflow.lite.NativeInterpreterWrapperExperimental.<init>(NativeInterpreterWrapperExperimental.java:44)
        at org.tensorflow.lite.Interpreter.<init>(Interpreter.java:226)
```"
55435,Loss names are not equal to the outputs dictionary keys of a model,"**System information**
- Have I written custom code: yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10.0.18363
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.8.0
- Python version: 3.8.10
- CUDA/cuDNN version: none
- GPU model and memory: none

**Current behavior**

The names for the single losses of a multi output model correspond to the output 
layer names instead to the output names provided by the keys in the outputs dictionary.
I am not sure if this is the desired behavior.

**Expected behavior**

I would expect that the names of the losses are the same as the keys in the dictionary 
passed to the outputs argument when creating the model.

**Standalone code to reproduce the issue**

    import numpy as np
    from tensorflow.keras.layers import Dense, Input
    from tensorflow.keras.models import Model
    
    first_input = Input(1)
    x = Dense(100)(first_input)
    x = Dense(1)(x)
    
    second_input = Input(1)
    x2 = Dense(100)(second_input)
    x2 = Dense(1)(x2)
    
    model = Model(
        inputs={""first_input"": first_input, ""second_input"": second_input},
        outputs={""first_output"": x, ""second_output"": x2},
    )
    
    first_input_data = np.random.random(100)
    second_input_data = np.random.random(100)
    first_output_data = np.random.random(100)
    second_output_data = np.random.random(100)
    
    model.compile(loss=""mse"")
    
    model.fit(
        x={""first_input"": first_input_data, ""second_input"": second_input_data},
        y={""first_output"": first_output_data, ""second_output"": second_output_data},
        batch_size=2,
        epochs=2,
    )



**Other info / logs**

The loss names are visible in the following logging, when running the code example:


    Epoch 1/2
    50/50 [==============================] - 0s 673us/step - loss: 0.2440 - dense_1_loss: 0.1308 - dense_3_loss: 0.1131
    Epoch 2/2
    50/50 [==============================] - 0s 592us/step - loss: 0.1934 - dense_1_loss: 0.0973 - dense_3_loss: 0.0961


The problem is that I cannot see which loss belongs to which single output. 

Of course, my real use case is much more complicated, so that I cannot just name the output layers correctly."
55433,tensorflow-macos version 2.8.0 cannot import keras,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
macOS 12.3
`x86_64` and `arm64` versions
tensorflow-macos 2.8.0 installed via pypi
* https://pypi.org/project/tensorflow-macos/#files
* https://files.pythonhosted.org/packages/e5/6c/05e158fd3a729c3d11720468b170bfa18db140e0091452e5bec2976e0f3d/tensorflow_macos-2.8.0-cp38-cp38-macosx_11_0_x86_64.whl

**Describe the current behavior**
These `keras` imports don't work:
```bash
python3.8 -c 'import tensorflow.keras'
Traceback (most recent call last):
  File ""<string>"", line 1, in <module>
ModuleNotFoundError: No module named 'tensorflow.keras'
```

```bash
python3.8 -c 'import tensorflow.keras.datasets.mnist'
Traceback (most recent call last):
  File ""<string>"", line 1, in <module>
ModuleNotFoundError: No module named 'tensorflow.keras'
```

```bash
python3.8 -c 'from tensorflow import keras as keras ; keras.datasets.mnist.load_data'
Traceback (most recent call last):
  File ""<string>"", line 1, in <module>
  File ""/opt/local/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/util/lazy_loader.py"", line 58, in __getattr__
    module = self._load()
  File ""/opt/local/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/util/lazy_loader.py"", line 41, in _load
    module = importlib.import_module(self.__name__)
  File ""/opt/local/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/importlib/__init__.py"", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File ""<frozen importlib._bootstrap>"", line 1014, in _gcd_import
  File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load
  File ""<frozen importlib._bootstrap>"", line 961, in _find_and_load_unlocked
  File ""<frozen importlib._bootstrap>"", line 219, in _call_with_frames_removed
  File ""<frozen importlib._bootstrap>"", line 1014, in _gcd_import
  File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load
  File ""<frozen importlib._bootstrap>"", line 961, in _find_and_load_unlocked
  File ""<frozen importlib._bootstrap>"", line 219, in _call_with_frames_removed
  File ""<frozen importlib._bootstrap>"", line 1014, in _gcd_import
  File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load
  File ""<frozen importlib._bootstrap>"", line 961, in _find_and_load_unlocked
  File ""<frozen importlib._bootstrap>"", line 219, in _call_with_frames_removed
  File ""<frozen importlib._bootstrap>"", line 1014, in _gcd_import
  File ""<frozen importlib._bootstrap>"", line 991, in _find_and_load
  File ""<frozen importlib._bootstrap>"", line 973, in _find_and_load_unlocked
```

```bash
python3.8 -c 'from tensorflow.python import keras as keras ; keras.datasets.mnist.load_data'
Traceback (most recent call last):
  File ""<string>"", line 1, in <module>
AttributeError: module 'tensorflow.python.keras' has no attribute 'datasets'
```

**Describe the expected behavior**

All `keras` imports above should work.
"
55432,MobileNetV3 reloading weights from version 2.8 gives error but not 2.7,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes 
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: no 
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): 2.7 and 2.8
- Python version: 3

**current behavior** is it give an error when loading weights in V2.8 but not in 2.7. tested models include 
ResNetV2 = works!
MobileNetV3Large = ERROR
MobileNetV3Small = ERROR
inceptionnetV3 = works!

it give the following error for MobileNetV3Large 
`ValueError: Layer count mismatch when loading weights from file. Model expected 110 layers, found 111 saved layers.`

**expected behavior** is to load the weights 

- Do you want to contribute a PR? (yes/no): no, 

**Standalone code to reproduce the issue**
here is a [Colab notebook](https://colab.research.google.com/drive/1RdRdW2GtLl_XrRkRgA78R170r9hZh-of?usp=sharing) that shows the issue, it downloads my weight file and everything but just in case [here is a link](https://www.dropbox.com/s/9pkhkvij53paz5m/0022_cp.hdf5?dl=0) to my weights.

**Other info / logs** 
when I originally created and trained my model and when rebuilding my model I get the following warning
`WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not 224. Weights for input shape (224, 224) will be loaded as the default.`

because I use image size of [96, 96, 3] and not [224, 224] as the warning mentioned above. the model worked great so I didn't worry about it, maybe this is related to the issue? 


Thanks for your hard work and I hope this helps other community members! "
55426,Bazel build error. Warning on retrieving an archive which is not found and then fails.,"Hi fellow developers,

I am trying to build Tensorflow from source on Windows using the tutorial on the website (https://www.tensorflow.org/install/source_windows) but I have an issue when i get to the bazel build of tensorflow
I am using this command to build since I have cuda and cudnn installed on my computer. (When i did the ./configure it found them and I could specify the compute capability for example) :
`bazel build --config=opt --config=cuda --define=no_tensorflow_py_deps=true --copt=-nvcc_options=disable-warnings //tensorflow/tools/pip_package:build_pip_package`

Here is the trace starting a little before it could not found an archive and then fails.
```
INFO: Repository local_config_cuda instantiated at:
  C:/users/me/desktop/ia/tensorflow-master/WORKSPACE:15:14: in <toplevel>
  C:/users/me/desktop/ia/tensorflow-master/tensorflow/workspace2.bzl:870:19: in workspace
  C:/users/me/desktop/ia/tensorflow-master/tensorflow/workspace2.bzl:96:19: in _tf_toolchains
Repository rule cuda_configure defined at:
  C:/users/me/desktop/ia/tensorflow-master/third_party/gpus/cuda_configure.bzl:1448:33: in <toplevel>
WARNING: Download from https://storage.googleapis.com/mirror.tensorflow.org/github.com/tensorflow/runtime/archive/8b8793a6d3d528e9b190ab7f9b85fea2f1aadc2c.tar.gz failed: class java.io.FileNotFoundException GET returned 404 Not Found
ERROR: An error occurred during the fetch of repository 'local_config_cuda':
   Traceback (most recent call last):
        File ""C:/users/me/desktop/ia/tensorflow-master/third_party/gpus/cuda_configure.bzl"", line 1401, column 38, in _cuda_autoconf_impl
                _create_local_cuda_repository(repository_ctx)
        File ""C:/users/me/desktop/ia/tensorflow-master/third_party/gpus/cuda_configure.bzl"", line 1239, column 56, in _create_local_cuda_repository
                host_compiler_includes + _cuda_include_path(
        File ""C:/users/me/desktop/ia/tensorflow-master/third_party/gpus/cuda_configure.bzl"", line 364, column 32, in _cuda_include_path
                inc_entries.append(realpath(repository_ctx, cuda_config.cuda_toolkit_path + ""/include""))
        File ""C:/users/me/desktop/ia/tensorflow-master/third_party/remote_config/common.bzl"", line 290, column 19, in realpath
                return execute(repository_ctx, [bash_bin, ""-c"", ""realpath \""%s\"""" % path]).stdout.strip()
        File ""C:/users/me/desktop/ia/tensorflow-master/third_party/remote_config/common.bzl"", line 230, column 13, in execute
                fail(
Error in fail: Repository command failed
/usr/bin/bash: line 1: realpath: command not found
ERROR: C:/users/me/desktop/ia/tensorflow-master/WORKSPACE:15:14: fetching cuda_configure rule //external:local_config_cuda: Traceback (most recent call last):
        File ""C:/users/me/desktop/ia/tensorflow-master/third_party/gpus/cuda_configure.bzl"", line 1401, column 38, in _cuda_autoconf_impl
                _create_local_cuda_repository(repository_ctx)
        File ""C:/users/me/desktop/ia/tensorflow-master/third_party/gpus/cuda_configure.bzl"", line 1239, column 56, in _create_local_cuda_repository
                host_compiler_includes + _cuda_include_path(
        File ""C:/users/me/desktop/ia/tensorflow-master/third_party/gpus/cuda_configure.bzl"", line 364, column 32, in _cuda_include_path
                inc_entries.append(realpath(repository_ctx, cuda_config.cuda_toolkit_path + ""/include""))
        File ""C:/users/me/desktop/ia/tensorflow-master/third_party/remote_config/common.bzl"", line 290, column 19, in realpath
                return execute(repository_ctx, [bash_bin, ""-c"", ""realpath \""%s\"""" % path]).stdout.strip()
        File ""C:/users/me/desktop/ia/tensorflow-master/third_party/remote_config/common.bzl"", line 230, column 13, in execute
                fail(
Error in fail: Repository command failed
/usr/bin/bash: line 1: realpath: command not found
INFO: Found applicable config definition build:cuda in file c:\users\me\desktop\ia\tensorflow-master\.bazelrc: --repo_env TF_NEED_CUDA=1 --crosstool_top=@local_config_cuda//crosstool:toolchain --@local_config_cuda//:enable_cuda
INFO: Found applicable config definition build:cuda in file c:\users\me\desktop\ia\tensorflow-master\.bazelrc: --repo_env TF_NEED_CUDA=1 --crosstool_top=@local_config_cuda//crosstool:toolchain --@local_config_cuda//:enable_cuda
WARNING: The following configs were expanded more than once: [cuda]. For repeatable flags, repeats are counted twice and may lead to unexpected behavior.
ERROR: @local_config_cuda//:enable_cuda :: Error loading option @local_config_cuda//:enable_cuda: Repository command failed
/usr/bin/bash: line 1: realpath: command not found
```

I am really sorry if it appears to be a problem on my side but since I can't retrieve the archive I think it is best to start here first.
Thank you for your help and your job.

"
55425,`pfor`/`tf.vectorize_map`: Improve feedback/hints messages when it `fallback_to_while_loop`,"**System information**
- TensorFlow version (you are using):
- Are you willing to contribute it (Yes/No):
Probably if I can talk with a codeowner of this namepace

**Describe the feature and the current behavior/state.**
As we are adding [a root cause message](https://github.com/tensorflow/tensorflow/pull/55192) on the cause we are going internally to rely on `fallback_to_while_loop`  it would be nice to have a more clear feedback  string to the user on what kind of action is required (e.g. refactoring his function, open a new ticket with a code gist on TF github, etc..).

See more at https://github.com/tensorflow/tensorflow/pull/55192#issuecomment-1081306349 /cc @wangpengmit 

**Will this change the current api? How?**
No
**Who will benefit with this feature?**
Developers that partially fail to fully `tf.vectorize_map` their functions
**Any Other info.**
"
55424,TFLite allocate tensors fails: (CONCATENATION) failed to prepare ,"### 1. System information

There is a problem in the pytorch model -> tflite quantization process, the model is a multi-input multi-output structure

The model inference process is shown in the code

`    def forward(self, input_x: torch.Tensor, tdnn_s0, tdnn_s1, tdnn_s1_2):
         model_in = input_x

        conv1_inputs = torch.cat([tdnn_s0, model_in], 2) 

        conv1 = self.norm[0](self.relu(self.convs[0](conv1_inputs)).permute(0, 2, 1)).permute(0, 2, 1)

        output_conv1 = conv1

        conv2_inputs = torch.cat([tdnn_s1, conv1], 2) 
        conv2 = self.convs[1](conv2_inputs) 
        output_conv2 = conv2

        conv2_2_inputs = torch.cat([tdnn_s1_2, conv2], 2) 
        conv2_2 = self.norm[1](self.relu(self.convs[2](conv2_2_inputs)).permute(0, 2, 1)).permute(0, 2, 1)

        conv2_2 = torch.add(conv2_inputs[:,:,:-1], conv2_2)

        dense_input = conv2_2.permute(0, 2, 1)

        output = self.dense(dense_input)

        return  output, output_conv1, output_conv2`

When I quantize the model I get an error like the following, but when I comment out the quantization in the code, it works; I don't yet know where the problem is

2022-03-29 20:37:26.144668: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:345] Ignored output_format.
2022-03-29 20:37:26.144820: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:348] Ignored drop_control_dependency.
2022-03-29 20:37:26.144875: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:354] Ignored change_concat_input_ranges.
2022-03-29 20:37:26.146905: I tensorflow/cc/saved_model/reader.cc:38] Reading SavedModel from: tmp
2022-03-29 20:37:26.149434: I tensorflow/cc/saved_model/reader.cc:90] Reading meta graph with tags { serve }
2022-03-29 20:37:26.149493: I tensorflow/cc/saved_model/reader.cc:132] Reading SavedModel debug info (if present) from: tmp
2022-03-29 20:37:26.158658: I tensorflow/cc/saved_model/loader.cc:206] Restoring SavedModel bundle.
2022-03-29 20:37:26.159847: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2200000000 Hz
2022-03-29 20:37:26.178324: I tensorflow/cc/saved_model/loader.cc:190] Running initialization op on SavedModel bundle at path: tmp
2022-03-29 20:37:26.187430: I tensorflow/cc/saved_model/loader.cc:277] SavedModel load for tags { serve }; Status: success: OK. Took 40531 microseconds.
2022-03-29 20:37:26.210737: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:210] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
calib [[1, 40, 4], [1, 40, 2], [1, 160, 1], [1, 20, 1]]
Traceback (most recent call last):
  File ""export_flow_layer2.py"", line 207, in <module>
    main()
  File ""export_flow_layer2.py"", line 180, in main
    tflite_model_quant = converter.convert()
  File ""/home/storage06/lidongbo/tools/anaconda3/lib/python3.8/site-packages/tensorflow/lite/python/lite.py"", line 921, in convert
    result = self._calibrate_quantize_model(result, **flags)
  File ""/home/storage06/lidongbo/tools/anaconda3/lib/python3.8/site-packages/tensorflow/lite/python/lite.py"", line 521, in _calibrate_quantize_model
    calibrated = calibrate_quantize.calibrate(
  File ""/home/storage06/lidongbo/tools/anaconda3/lib/python3.8/site-packages/tensorflow/lite/python/optimize/calibrator.py"", line 173, in calibrate
    self._calibrator.Prepare([list(s.shape) for s in sample])
RuntimeError: tensorflow/lite/kernels/concatenation.cc:80 t->dims->data[d] != t0->dims->data[d] (160 != 40)Node number 0 (CONCATENATION) failed to prepare .

### 2. Code
``` 
      def representative_data_gen():
            for item in range(2):
                feat = torch.zeros(1, 40, 4, dtype=torch.float)
                tdnn_s0 = torch.zeros(1, 40, 2, dtype=torch.float)
                tdnn_s1 = torch.zeros(1, 160, 1, dtype=torch.float)
                tdnn_s1_2 = torch.zeros(1, 20, 1, dtype=torch.float)
                yield [feat.numpy(), tdnn_s0.numpy(), tdnn_s1.numpy(), tdnn_s1_2.numpy()]

        converter = tf.lite.TFLiteConverter.from_saved_model(args.pb_model)
        converter.optimizations = [tf.lite.Optimize.DEFAULT]
        converter.representative_dataset = representative_data_gen
        converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]
        converter.inference_input_type = tf.int8
        converter.inference_output_type = tf.int8
        tflite_model_quant = converter.convert()

        with open(args.tflite, 'wb') as f:
            f.write(tflite_model_quant)
```"
55423,Customize TF tensor multiplication,"**System information**
- TensorFlow version (you are using): 2.5.0
- Are you willing to contribute it (Yes/No): Yes



**Describe the feature and the current behavior/state.**
Is there a way o customize/modify the tensor/matrix multiplication operation used through out tensorflow? Let's say whenever I am executing a forward pass on a given input, involving a sequence of tensor multiplications defined by the architecture of the neural net, how would I proceed to change the very definition of how the multiplication is carried out? 
Which source file do I have to edit to achieve this? Maybe smewhere in `tensorflow/python/ops`  ?

Thank you for your help.
"
55422,Parameter init_epoch can not be identified when calling model.train(),"Hi,
    I am trying to implement incremental training (when the model trained is stopped due to other reasons, I can retrain the model from the latest checkpoint). There, I used the parameter 'init_epoch' when calling model.train(). However, parameter 'init_epoch' can not be identified in Tensorflow2.4.0.
   I want to know which version of Tensorflow support parameter 'init_epoch'?

![scr](https://user-images.githubusercontent.com/12910533/160596038-09c582fa-334f-4426-bb5a-8d014398e617.png)

"
55421,How can I take CPU variable as input of a custom GPU operation?,"I want to hold embedding in DRAM and make a HBM cache for it.
So I registered a GPU only operation, and I want to it take a CPU resource variable as input.

```c++
REGISTER_KERNEL_BUILDER(Name(""MyLookup"")
                            .Device(DEVICE_GPU)
                            .HostMemory(""embeddings""),
                        MyLookupOp);

REGISTER_OP(""MyLookup"")
    .Attr(""E: {float16, float32, float64}"")
    .Attr(""K: {int32, int64}"")
    .Input(""embeddings: resource"")
    .Input(""keys: K"")
    .Output(""vecs: E"")
    .SetShapeFn(LookupShapeInfer);
```

```python
  with tf.device('/device:CPU:0'):
    var = tf.get_variable(shape=[VOC, EMB_SIZE],
                           dtype=np.float32,
                           initializer=tf.ones_initializer(),
                           name='EMB')
  keys = tf.random.uniform(shape=[BATCH_SIZE, KEY_NUM],
                           minval=0,
                           maxval=VOC,
                           dtype=tf.int64)
  ret = lib.my_lookup(var, keys)
  print(ret)
```

But I got exception complaining no CPU OpKernel available.

```
  File ""/usr/local/lib64/python3.6/site-packages/tensorflow/python/framework/ops.py"", line 6862, in raise_from_not_ok_status
    six.raise_from(core._status_to_exception(e.code, message), None)
  File ""<string>"", line 3, in raise_from
tensorflow.python.framework.errors_impl.NotFoundError: No registered 'MyLookup' OpKernel for 'CPU' devices compatible with node {{node HorovodEmbeddingLookupCss}}
        .  Registered:  device='GPU'
 [Op:HorovodEmbeddingLookupCss]
```

How can I take CPU variable as input of a custom GPU operation?"
55419,RuntimeError: Encountered unresolved custom op: StridedSlice.,"### 1. System information

- OS Platform and Distribution: Linux Ubuntu 21.10
- TensorFlow installation: pip
- TensorFlow library: 2.8.0

### 2. Code
        original = img
        height = self.input_details[0]['shape'][1]
        width = self.input_details[0]['shape'][2]
        img = cv2.resize(img, (width, height), interpolation=cv2.INTER_AREA)
        img = np.expand_dims(img, axis=0)

        # Normalize input data
        input_mean = 127.5
        input_std = 127.5
        input_data = np.uint8((np.float32(img) - input_mean) / input_std)
        self.interpreter.set_tensor(self.input_details[0]['index'], input_data)

        self.interpreter.invoke()

Code Im using to convert model:

          converter = tf.lite.TFLiteConverter.from_saved_model('./saved_model')
          converter.target_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]
          converter.allow_custom_ops=True
          converter.experimental_new_converter =True
          tflite_model = converter.convert()

### 3. Failure after conversion
Model converting finished with no error, but the converted model couldn't run through the interpreter.

### 4. Error traceback
       Traceback (most recent call last):
        File ""/home/whoisltd/detect/serve_model.py"", line 32, in <module>
          print(predict(image))
        File ""/home/whoisltd/detect/serve_model.py"", line 21, in predict
          result = model.predict(img)
        File ""/home/whoisltd/detect/src/merged_model.py"", line 88, in predict
          self.detect_text(cropped_image)
        File ""/home/whoisltd/detect/src/merged_model.py"", line 49, in detect_text
          detection_boxes, detection_classes, _ = self.text_detection_model.predict(image)
        File ""/home/whoisltd/detect/src/detector/detector.py"", line 46, in predict
          self.interpreter.invoke()
        File ""/home/whoisltd/detect/det/lib/python3.9/site-packages/tensorflow/lite/python/interpreter.py"", line 916, in invoke
          self._interpreter.Invoke()
      RuntimeError: Encountered unresolved custom op: StridedSlice.
      See instructions: https://www.tensorflow.org/lite/guide/ops_customNode number 11 (StridedSlice) failed to prepare.Node number 0 (WHILE) failed to invoke.
      double free or corruption (!prev)
      Aborted (core dumped)
"
55417,How to update tf.Variable inplace using custom op?,"Hi,

I want to write a custom op which updates the contents of `tf.Variable` inplace on a GPU (cuda) device. I haven't found any relevant documentation to achieve this, hence creating this issue. It'll be great if you can point me out to any relevant doc/code implementation for this.  I can do the same with assign op, but that requires creation of extra tensor and will prefer to update it inplace.

I looked at the implementation of Adam op registration from [here](https://github.com/tensorflow/tensorflow/blob/94964d0a95ff50a2fc6d1b9856c85e9ce40b2682/tensorflow/core/kernels/training_ops.cc#L3613-L3615) and noticed that the variables to be updated are copied to host memory. Also, it appears the same approach is followed [here](https://github.com/tensorflow/tensorflow/blob/94964d0a95ff50a2fc6d1b9856c85e9ce40b2682/tensorflow/core/kernels/resource_variable_ops.cc#L538) in assign op implementation. 

Is this really needed to update variables and can this be avoided? I suspect this might have some performance implications of copying data to CPU every time it needs to be updated. 

Thanks
"
55414,Known issues with new RUN_EAGER_OP_AS_FUNCTION feature,"This refers to the unified eager op/tf.function execution mode available for optional use in 2.9.

Tracking known issues here:

1. With CUDA enabled, unnecessary data transfers to/from the GPU causing additional slowdowns. (already under investigation)
"
55407,TensorBoard Dev doesn't update upon delete operation,"Hi,

I'm using TensorBoard dev to log my training metrics. My TensorBoard version is `2.8.0`.

I log my data using the command
```
tensorboard dev upload --logdir=my/dir/of/logs
```

However, I noticed that once a version is created, and is apparent on TensorBoard dev, even if I delete it locally, it still exist on the online version. This behavior doesn't happen with local TensorBoard.

Is this behavior expected? is there a way to correct this?

Thank you in advance."
55405,tf.nn.ctc_loss is more numerically unstable when providing sparse instead of dense labels,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS BigSur
- TensorFlow installed from (source or binary): Binary
- TensorFlow version (use command below): 2.8
- Python version: 3.7

**Describe the current behavior**

`tf.nn.ctc_loss` can return `Inf` value for an input example if the labels are given as sparse tensor, while it computes the value correctly for the same inputs when the labels are given as dense tensor. So it appears that the implementation used when providing dense labels is more numerically stable - this occurs only once the logits coming from the model are more ""extreme"", as in, very large or very small. However, this issue can and was encountered by me during training an actual model, which broke training.

See example below.

**Describe the expected behavior**

The loss when providing sparse labels is not `Inf` but rather the same value that you get when providing dense labels.

If that cannot be achieved, we should offer a fallback mechanism as shown in my example code, where the dense codepath is used whenever an Inf is encountered.

At the bare minimum, the docs for `tf.nn.ctc_loss` should warn about the numerical instability of the sparse version.

**Standalone code to reproduce the issue**

```
import tensorflow as tf

labels = tf.ones((1, 50), dtype=tf.int64)
logits = tf.concat([tf.ones((1, 1000, 1)), -100 * tf.ones((1, 1000, 1))], axis=2)
label_length = tf.constant([50])
logit_length = tf.constant([1000])

dense_ctc_losses = tf.nn.ctc_loss(
    labels=labels,
    logits=logits,
    label_length=label_length,
    logit_length=logit_length,
    logits_time_major=False,
    blank_index=0,
)

sparse_ctc_losses = tf.nn.ctc_loss(
    labels=tf.sparse.from_dense(tf.cast(tf.convert_to_tensor(labels), dtype=tf.int32)),
    logits=logits,
    label_length=label_length,
    logit_length=tf.cast(logit_length, tf.int32),
    logits_time_major=False,
    blank_index=0,
)

ctc_losses = tf.cond(
    tf.math.reduce_all(tf.math.is_finite(sparse_ctc_losses)),
    lambda: sparse_ctc_losses,
    lambda: tf.nn.ctc_loss(
        labels=labels,
        logits=logits,
        label_length=label_length,
        logit_length=logit_length,
        logits_time_major=False,
        blank_index=0,
    ),
)

# This works fine and produces a proper value
print(f""Dense labels: {dense_ctc_losses}"")
# Sparse version gives us an inf value
print(f""Sparse labels: {sparse_ctc_losses}"")
# Uses sparse, falls back to dense if sparse gives Inf
print(f""Fallback CTC: {ctc_losses}"")
```

Output:
```
2022-03-28 14:35:13.481252: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
WARNING:tensorflow:From /Users/dstoller/.pyenv/versions/lyric-align-baseline/lib/python3.7/site-packages/tensorflow/python/ops/ctc_ops.py:1443: alias_inplace_add (from tensorflow.python.ops.inplace_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Prefer tf.tensor_scatter_nd_add, which offers the same functionality with well-defined read-write semantics.
WARNING:tensorflow:From /Users/dstoller/.pyenv/versions/lyric-align-baseline/lib/python3.7/site-packages/tensorflow/python/ops/ctc_ops.py:1426: alias_inplace_update (from tensorflow.python.ops.inplace_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Prefer tf.tensor_scatter_nd_update, which offers the same functionality with well-defined read-write semantics.
2022-03-28 14:35:15.541318: W ./tensorflow/core/util/ctc/ctc_loss_calculator.h:499] No valid path found.
Dense labels: [706.8936]
Sparse labels: [inf]
Combined CTC: [706.8936]
```
"
55403,ValueError: Python inputs incompatible with input_signature,"I'm working with this On-Device Training with TensorFlow Lite
https://www.tensorflow.org/lite/examples/on_device_training/overview#setup

However, I customized the model. But, after customization, the following error is coming
ValueError: Python inputs incompatible with input_signature:
  inputs: (
    tf.Tensor(
[[ 9.       17.229916]
 [15.       10.601508]
 [15.       10.517618]
 [ 7.       26.893026]
 [15.       10.572687]
 [ 7.       27.393883]
 [15.        9.859101]
 [14.       11.724992]
 [12.       13.421819]
 [ 7.       28.229916]], shape=(10, 2), dtype=float32),
    tf.Tensor([1. 1. 1. 0. 1. 0. 1. 1. 1. 0.], shape=(10,), dtype=float32))
  input_signature: (
    TensorSpec(shape=(10, 2), dtype=tf.float32, name=None),
    TensorSpec(shape=(10, 1), dtype=tf.float32, name=None)).

Please find the code here
https://colab.research.google.com/drive/1jLM8BWuB7VRDMJHxKUDAIBR17MHqYSKk?usp=sharing


"
55399,TFLite Failed to Allocate Tensor,"### 2. Code
I have an exported Frozen Graph .pb file, and converted it to tflite using
```
graph_def_file = ""model.pb""
input_arrays = [""Placeholder""]
input_shape = {""Placeholder"": [1024, 2048, 3]}
output_arrays = [""final_output""]
converter = tf.compat.v1.lite.TFLiteConverter.from_frozen_graph(
    graph_def_file, input_arrays, output_arrays, input_shape)

tflite_model = converter.convert()
with open(""my_model.tflite"", ""wb"") as f:
        f.write(tflite_model)
```
And I could not restore my model with
```
interpreter = tf.lite.Interpreter(model_path=""my_model.tflite"")
interpreter.resize_tensor_input(0, [1024, 2048, 3], strict=True)
interpreter.allocate_tensors()
---------------------------------------------------------------------------
RuntimeError                              Traceback (most recent call last)
<ipython-input-28-3cfaee7dc51c> in <module>
      1 interpreter = tf.lite.Interpreter(model_path=model_path)
      2 interpreter.resize_tensor_input(0, [1024, 2048, 3], strict=True)
----> 3 interpreter.allocate_tensors()

~/.local/lib/python3.9/site-packages/tensorflow/lite/python/interpreter.py in allocate_tensors(self)
    512   def allocate_tensors(self):
    513     self._ensure_safe()
--> 514     return self._interpreter.AllocateTensors()
    515 
    516   def _safe_to_run(self):

RuntimeError: tensorflow/lite/kernels/conv.cc:349 input->dims->data[3] != filter->dims->data[3] (65 != 64)Node number 11 (CONV_2D) failed to prepare.Failed to apply the default TensorFlow Lite delegate indexed at 0.
```

However, I can successfully reload my .pb file frozen graph by using
```
with tf.gfile.GFile('my_model.pb', ""rb"") as pb:
    graph_def = tf.GraphDef()
    graph_def.ParseFromString(pb.read())
with tf.Graph().as_default() as graph:
    tf.import_graph_def(
            graph_def,
            name="""", 
            )
```
and also successfully generated result by

```
node_in = graph.get_tensor_by_name('Placeholder:0') 
node_out = graph.get_tensor_by_name('final_output:0') 

with tf.Session(graph=graph) as sess:  # Session()
    # sess.run(tf.global_variables_initializer()) 
    feed_dict = {node_in: input_img}  
    pred = sess.run(node_out, feed_dict) 
    print(pred)
    sess.close()
```

I've checked the node 11 of the .tflite file in Netron, but everything seemed fine.
![node 11](https://user-images.githubusercontent.com/42362331/160350576-92c32abb-2ccc-4ee5-9003-a6ec3538dd78.png)
What could be the problem? 

The file attached is my .pb frozen graph
 [model.zip](https://github.com/tensorflow/tensorflow/files/8359810/model.zip)"
55398,Calling `model.compile()` multiple times leads to memory leak,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04, macOS 12.3
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: -
- TensorFlow installed from (source or binary): `pip install tensorflow==2.8.0`
- TensorFlow version (use command below): 2.8.0
- Python version: 3.9.7
- Bazel version (if compiling from source): -
- GCC/Compiler version (if compiling from source): -
- CUDA/cuDNN version: - 
- GPU model and memory:- 

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

[Stackoverflow](https://stackoverflow.com/posts/71633201/timeline)

I have tried resetting the state of the optimizer by re-compiling the model. Then I found that it could lead to a memory leak.

reproducible code attached.

**Describe the expected behavior**

Since there are no active variables that could reach the old generated model graph. The old graph in RAM should be freed.

**[Contributing](https://www.tensorflow.org/community/contribute)**

- Do you want to contribute a PR? (yes/no): no
- Briefly describe your candidate solution(if contributing): -

**Standalone code to reproduce the issue**


```python
import tensorflow as tf
import numpy as np
import objgraph

m = tf.keras.models.Sequential([tf.keras.layers.InputLayer(input_shape=(20,)), tf.keras.layers.Dense(10),tf.keras.layers.Dense(10),tf.keras.layers.Dense(10),tf.keras.layers.Dense(10)])
objgraph.show_growth()

for i in range(100):
    tf.keras.backend.clear_session()
    m.compile('adam', loss='mse')
    data = np.arange(32*20).reshape(32, 20)
    labels = np.zeros(32)
    results = m.fit(data, labels, epochs=10)
    objgraph.show_growth()
```

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
55390,tanh(float(7~8)) = 1.0000001 in XLA,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): linux or mac 
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: no
- TensorFlow installed from (source or binary): source 
- TensorFlow version (use command below): 2.8 or 1.15
- Python version: 3.9 or 2.7
- Bazel version (if compiling from source): bazel release 5.0.0-pre.20211011.2
- GCC/Compiler version (if compiling from source): Apple clang version 13.0.0 (clang-1300.0.29.3) 
- CUDA/cuDNN version: no
- GPU model and memory: no 

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""` 
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`
    zsh: command not found: v1.12.1-68911-gea661077441

**Describe the current behavior**
The return value of tanh function is  1.0000001, but tanh can not return more than 1.

**Describe the expected behavior**
The return value of tanh function is 1 or less than 1.

**[Contributing](https://www.tensorflow.org/community/contribute)**

- Do you want to contribute a PR? (yes/no): yes
- Briefly describe your candidate solution(if contributing):
There is a description in the xla comment that the xla implementation of the tanh function is copied from eigen3.(tensorflow/compiler/xla/service/llvm_ir/math_ops.h:25), but I compare the implementation of the tanh function within xla and eigen3, they not have same implementation .so I copy the implementation of tanh function from eigen3 to tensorflow ....

**Standalone code to reproduce the issue**
```
import os
os.environ['TF_XLA_FLAGS'] = '--tf_xla_auto_jit=2 --tf_xla_cpu_global_jit --tf_xla_min_cluster_size=0'

import tensorflow as tf

tf.compat.v1.disable_eager_execution()

#with tf.compat.v1.device('gpu'):
ctr_y = tf.compat.v1.random.uniform([1], minval=8, maxval=9, dtype=tf.compat.v1.float32)
ctr_pred_ori = tf.compat.v1.tanh(ctr_y)


session_config = tf.compat.v1.ConfigProto(allow_soft_placement=True, log_device_placement=True)
session_config.graph_options.rewrite_options.disable_meta_optimizer=True
with tf.compat.v1.Session(config=session_config) as sess:
  while  True:
    ret = sess.run([ctr_pred_ori])[0]
    if ret > 1.0:
      print(ret);
```


**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
```
 212 [array([0.99999964], dtype=float32)]
13702 [array([0.99999976], dtype=float32)]
 621 [array([0.9999997], dtype=float32)]
17916 [array([0.9999998], dtype=float32)]
21312 [array([0.99999994], dtype=float32)]
48624 [array([0.9999999], dtype=float32)]
8097 [array([1.0000001], dtype=float32)]
   5 [array([1.0000002], dtype=float32)]
42322 [array([1.], dtype=float32)]
```
tanh return 1.0000001 8097 times"
55389,TensorflowLite Undefined symbol: _TfLiteTensorCopy,"**System information**
Xcode13.3, complie app for arm64 iPhone

The step I following is here:
https://www.tensorflow.org/lite/guide/ops_select#ios

Demo code is here:
[iOSDemo 2.zip](https://github.com/tensorflow/tensorflow/files/8356734/iOSDemo.2.zip)

**Step to reproduce issue**
1. Download the zip,and `cd` to the project root folder
2. Run `pod update` 
3. Compile project.
4. Get the error and compile failed.

<img width=""352"" alt=""QQ20220327-110056@2x"" src=""https://user-images.githubusercontent.com/49340347/160264810-524cfabc-5cfd-48bd-a93c-9ff9966374a6.png"">

"
55388,module 'tensorflow_federated.python.learning' has no attribute 'reconstruction',"Hello, I tried running this piece of code from the tutorial ""Federated Reconstruction with Matrix Factorization"" and an error arises. 

---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
<ipython-input-18-c29214822d98> in <module>
     23 def get_matrix_factorization_model(
     24     num_items: int,
---> 25     num_latent_factors: int) -> tff.learning.reconstruction.Model:
     26   """"""Defines a Keras matrix factorization model.""""""
     27   # Layers with variables will be partitioned into global and local layers.

AttributeError: module 'tensorflow_federated.python.learning' has no attribute 'reconstruction'

Why does this happen? And how to solve this? 
Thank you "
55377,RuntimeError: module compiled against API version 0xe but this version of numpy is 0xd,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Debian 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: -
- TensorFlow installed from (source or binary): source 
- TensorFlow version: v2.4.4
- Python version: 3.7.3
- Installed using virtualenv? pip? conda?: pip3
- Bazel version (if compiling from source): 3.1.0 (bazel-3.1.0-linux-x86_64)
- GCC/Compiler version (if compiling from source): 8.3.0
- CUDA/cuDNN version: -
- GPU model and memory: -

**Describe the problem**

I installed moodlemlbackend v3.0.2 (I use Moodle v3.9).
`pip3 install moodlemlbackend==3.0.2`

Now I try to meet the requirements:
https://github.com/moodlehq/moodle-mlbackend-python/blob/3.0.2/requirements.txt
Requires:
tensorflow>=2.4.2,<2.5
numpy>=1.19.2,<1.20

I had to recompile tensorflow v2.4.4 with noavx option.
Used options: -march=nehalem -msse4.1 -msse4.2 -mpclmul -mpopcnt -maes -mno-avx -mno-avx2

`pip3 install /git/tensorflow/tensorflow_output/tensorflow-2.4.4-cp37-cp37m-linux_x86_64.whl`

Also installed the required numpy v1.19.5:
`pip3 install numpy==1.19.5`

Now I get the following error:

```
python3 -c 'import tensorflow'
# RuntimeError: module compiled against API version 0xe but this version of numpy is 0xd
# RuntimeError: module compiled against API version 0xe but this version of numpy is 0xd
# ImportError: numpy.core._multiarray_umath failed to import
# ImportError: numpy.core.umath failed to import
# 2022-03-25 17:43:52.642579: F tensorflow/python/lib/core/bfloat16.cc:714] Check failed: PyBfloat16_Type.tp_base != nullptr
# Aborted
```


**Provide the exact sequence of commands / steps that you executed before running into the problem**


**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
55376,'Activation' object has no attribute 'kernel' applying regularization to MobileNetV3,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): v2.7.0-rc1-69-gc256c071bb2, tf-nightly-2.9.0.dev20220325
- Python version: 3.9.7
- CUDA/cuDNN version: N/A 
- GPU model and memory: N/A

**Describe the current behavior**

Attempting to add regularization to MobileNetV3. The regularization appears to be applied correctly (applied to 43 Conv2D and Dense layers), but calling `model.fit` fails with the error `AttributeError: 'Activation' object has no attribute 'kernel'`.

It appears that calling `model.fit` is reapplying the regularization, but on the last `layer`, which is the output Activation. Adding regularization this way works on MobileNetV2 and custom models I've built, but only fails on MobileNetV3 (small or large).

If a default argument is used in the lambda (`layer.add_loss(lambda l=layer: regularizer(l.kernel))`), I can build and train the model, but saving the model with the Saved Model API fails with `tensorflow.python.saved_model.nested_structure_coder.NotEncodableError: No encoder for object <keras.layers.convolutional.Conv2D object at 0x7f0c4083be80> of type <class 'keras.layers.convolutional.Conv2D'>.`

**Describe the expected behavior**

The sample script should run without fail, or at least fail similarly between MobieNetV2 and MobileNetV3.

**Standalone code to reproduce the issue**

Colab notebook (2.9.0 nightly) https://colab.research.google.com/drive/1JQxl6KyCf5vWUnFjo0qB7v_I5maMMspb#scrollTo=HAlKVbk08W3X

Standalone code:

```python
import numpy as np
import tensorflow as tf


model = tf.keras.applications.MobileNetV3Small(input_shape=(96, 96, 3))
# model = tf.keras.applications.MobileNetV2(input_shape=(96, 96, 3))
regularizer = tf.keras.regularizers.L1(1e-3)

for layer in model.layers:
    if hasattr(layer, ""kernel""):
        layer.add_loss(lambda: regularizer(layer.kernel))  # Fails building V3
        # layer.add_loss(lambda l=layer: regularizer(l.kernel))  # Fails saving SavedModel all versions

# Ensure regularization only applied to Conv2D or Dense layers
regularization_count = 0
for layer in model.layers:
    if layer.losses:
        regularization_count += 1
        assert isinstance(layer, tf.keras.layers.Conv2D) or isinstance(layer, tf.keras.layers.Dense)
        assert not isinstance(layer, tf.keras.layers.Activation)

print(f""Regularization added to {regularization_count} layers"")

model.compile(loss=""mse"")
model.fit(
    np.random.randn(10, 96, 96, 3),
    np.random.randn(10, 1000),
)
model.save(""test"")
```

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

Traceback from Colab notebook:

```
WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not 224. Weights for input shape (224, 224) will be loaded as the default.
Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v3/weights_mobilenet_v3_small_224_1.0_float.h5
10734624/10734624 [==============================] - 0s 0us/step
Regularization added to 43 layers

---------------------------------------------------------------------------

AttributeError                            Traceback (most recent call last)

[<ipython-input-3-0ea365886076>](https://localhost:8080/#) in <module>()
     23 model.fit(
     24     np.random.randn(10, 96, 96, 3),
---> 25     np.random.randn(10, 1000),
     26 )

2 frames

[<ipython-input-3-0ea365886076>](https://localhost:8080/#) in <lambda>()
      8 for layer in model.layers:
      9     if hasattr(layer, ""kernel""):
---> 10         layer.add_loss(lambda: regularizer(layer.kernel))
     11 
     12 # Ensure regularization only applied to Conv2D or Dense layers

AttributeError: in user code:

    File ""/usr/local/lib/python3.7/dist-packages/keras/engine/training.py"", line 1051, in train_function  *
        return step_function(self, iterator)
    File ""/usr/local/lib/python3.7/dist-packages/keras/engine/training.py"", line 1040, in step_function  **
        outputs = model.distribute_strategy.run(run_step, args=(data,))
    File ""/usr/local/lib/python3.7/dist-packages/keras/engine/training.py"", line 1030, in run_step  **
        outputs = model.train_step(data)
    File ""/usr/local/lib/python3.7/dist-packages/keras/engine/training.py"", line 890, in train_step
        loss = self.compute_loss(x, y, y_pred, sample_weight)
    File ""/usr/local/lib/python3.7/dist-packages/keras/engine/training.py"", line 949, in compute_loss
        y, y_pred, sample_weight, regularization_losses=self.losses)
    File ""/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py"", line 1268, in losses
        loss_tensor = regularizer()
    File ""/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py"", line 1342, in _tag_callable
        loss = loss()
    File ""<ipython-input-3-0ea365886076>"", line 10, in <lambda>
        layer.add_loss(lambda: regularizer(layer.kernel))

    AttributeError: 'Activation' object has no attribute 'kernel'
```
"
55375,tf.load_op_library doesn't load .so file and throws file not found error although the file exists,"```
**System information**
== check python ===================================================
python version: 3.7.7
python branch: 
python build version: ('default', 'Jan 13 2021 07:47:31')
python compiler version: GCC 7.5.0
python implementation: CPython


== check os platform ===============================================
os: Linux
os kernel version: 69-18.04.1-Ubuntu SMP Wed Feb 9 15:36:54 UTC 2022
os release version: 5.4.0-1066-aws
os platform: Linux-5.4.0-1066-aws-x86_64-with-debian-buster-sid
linux distribution: ('debian', 'buster/sid', '')
linux os distribution: ('debian', 'buster/sid', '')
architecture: ('64bit', '')
machine: x86_64


== are we in docker =============================================
No

== compiler =====================================================
c++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0
Copyright (C) 2017 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.

== check pips ===================================================
numpy                            1.21.5
protobuf                         3.14.0
tensorflow                       2.8.0
tensorflow-estimator             1.14.0
tensorflow-hub                   0.11.0
tensorflow-io-gcs-filesystem     0.24.0
wsproto                          1.0.0

== check for virtualenv =========================================
False

== tensorflow import ============================================
tf.version.VERSION = 2.8.0
tf.version.GIT_VERSION = v2.8.0-rc1-32-g3f878cff5b6
tf.version.COMPILER_VERSION = 7.3.1 20180303
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- TensorFlow installed from (source or binary):binary

== env ==========================================================
LD_LIBRARY_PATH /usr/lib64/openmpi/lib/:/usr/local/cuda/lib64:/usr/local/lib:/usr/lib:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/mpi/lib:/lib/:/usr/local/cuda/lib64:/usr/local/lib:/usr/lib:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib:/opt/amazon/efa/lib:/usr/local/mpi/lib:/opt/amazon/openmpi/lib:/usr/lib64/openmpi/lib/:/usr/local/cuda/lib64:/usr/local/lib:/usr/lib:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/mpi/lib:/lib/:/usr/local/cuda/lib64:/usr/local/lib:/usr/lib:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib:/opt/amazon/efa/lib:/usr/local/mpi/lib:/opt/amazon/openmpi/lib:/usr/lib64/openmpi/lib/:/usr/local/cuda/lib64:/usr/local/lib:/usr/lib:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/mpi/lib:/lib/:
DYLD_LIBRARY_PATH is unset

== nvidia-smi ===================================================
NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.


== cuda libs  ===================================================
/usr/local/cuda-9.0/lib64/libcudart_static.a
/usr/local/cuda-9.0/lib64/libcudart.so.9.0.176
/usr/local/cuda-9.0/doc/man/man7/libcudart.7
/usr/local/cuda-9.0/doc/man/man7/libcudart.so.7
/usr/local/cuda-10.2/targets/x86_64-linux/lib/libcudart_static.a
/usr/local/cuda-10.2/targets/x86_64-linux/lib/libcudart.so.10.2.89
/usr/local/cuda-10.2/doc/man/man7/libcudart.7
/usr/local/cuda-10.2/doc/man/man7/libcudart.so.7
/usr/local/cuda-10.1/targets/x86_64-linux/lib/libcudart.so.10.1.243
/usr/local/cuda-10.1/targets/x86_64-linux/lib/libcudart_static.a
/usr/local/cuda-10.1/doc/man/man7/libcudart.7
/usr/local/cuda-10.1/doc/man/man7/libcudart.so.7
/usr/local/cuda-9.2/lib64/libcudart_static.a
/usr/local/cuda-9.2/lib64/libcudart.so.9.2.148
/usr/local/cuda-9.2/doc/man/man7/libcudart.7
/usr/local/cuda-9.2/doc/man/man7/libcudart.so.7
/usr/local/cuda-10.0/lib64/libcudart.so.10.0.130
/usr/local/cuda-10.0/lib64/libcudart_static.a
/usr/local/cuda-10.0/doc/man/man7/libcudart.7
/usr/local/cuda-10.0/doc/man/man7/libcudart.so.7

== tensorflow installed from info ==================
Name: tensorflow
Version: 2.8.0
Summary: TensorFlow is an open source machine learning framework for everyone.
Home-page: https://www.tensorflow.org/
Author-email: packages@tensorflow.org
License: Apache 2.0
Location: /home/ubuntu/venvpipe1v1/lib/python3.7/site-packages
Required-by: spacy-universal-sentence-encoder

== python version  ==============================================
(major, minor, micro, releaselevel, serial)
(3, 7, 7, 'final', 0)

== bazel version  ===============================================
```
**Describe the current behavior**

When the code below is executed
```
print(config.COREF_KERNELS_SO_FILE_PATH.is_file())
coref_op_library = tf.load_op_library(str(config.COREF_KERNELS_SO_FILE_PATH))
```
The first line prints `True` which means that the file exists. But the second line throws the following error.

`
 File ""/home/ubuntu/venvpipe1v1/lib/python3.7/site-packages/tensorflow/python/framework/load_library.py"", line 54, in load_op_library
    lib_handle = py_tf.TF_LoadLibrary(library_filename)
tensorflow.python.framework.errors_impl.NotFoundError: libtensorflow_framework.so.1: cannot open shared object file: No such file or directory
`

**Describe the expected behavior**

The .so file should load

- Do you want to contribute a PR? (yes/no): no

**Standalone code to reproduce the issue**

```
import tensorflow as tf
coref_op_library = tf.load_op_librarypath to .so file')

```
**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

```
2022-03-24 17:39:30.761737: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory
2022-03-24 17:39:30.761779: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
```"
55374,Factor limit of `tf.image.adjust_contrast` and `tf.image.adjust_saturation`? ,"- [tf.image.adjust_saturation(image, saturation_factor, name=None)](https://www.tensorflow.org/api_docs/python/tf/image/adjust_saturation)
- [tf.image.adjust_contrast(images, contrast_factor)](https://www.tensorflow.org/api_docs/python/tf/image/adjust_contrast)

Could you please help understand what is the **expected range** or **limit** of the `saturation_factor` and `contrast_factor` in the above two functions? In the documentation, it's not stated clearly. "
55373,Failed to call tf.convert_to_tensor for a tf.RaggedTensor with a PlaceHolder value,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS 12.3
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): https://developer.apple.com/metal/tensorflow-plugin/
- TensorFlow version (use command below): unknown 2.8.0
- Python version: 3.8.12
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: N/A
- GPU model and memory: Apple M1 16.00 GB
 
**Describe the current behavior**
related issue in tensorflow-text github : https://github.com/tensorflow/text/issues/867

```
Metal device set to: Apple M1

systemMemory: 16.00 GB
maxCacheSize: 5.33 GB

2022-03-23 16:43:41.295408: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.
2022-03-23 16:43:41.295626: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)
2022-03-23 16:43:44.494936: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz
2022-03-23 16:43:44.530574: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.
2022-03-23 16:43:44.554177: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.
Traceback (most recent call last):
  File ""_text.py"", line 31, in <module>
    y_txt = trimmer.trim([y_txt])[0]
  File ""/Users/user/miniforge3/envs/tf/lib/python3.8/site-packages/tensorflow_text/python/ops/trimmer_ops.py"", line 49, in trim
    segments = [
  File ""/Users/user/miniforge3/envs/tf/lib/python3.8/site-packages/tensorflow_text/python/ops/trimmer_ops.py"", line 50, in <listcomp>
    ragged_tensor.convert_to_tensor_or_ragged_tensor(s) for s in segments
  File ""/Users/user/miniforge3/envs/tf/lib/python3.8/site-packages/tensorflow/python/ops/ragged/ragged_tensor.py"", line 2658, in convert_to_tensor_or_ragged_tensor
    return ops.convert_to_tensor_v2_with_dispatch(
  File ""/Users/user/miniforge3/envs/tf/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py"", line 153, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File ""/Users/user/miniforge3/envs/tf/lib/python3.8/site-packages/keras/layers/core/tf_op_layer.py"", line 107, in handle
    return TFOpLambda(op)(*args, **kwargs)
  File ""/Users/user/miniforge3/envs/tf/lib/python3.8/site-packages/keras/utils/traceback_utils.py"", line 67, in error_handler
    raise e.with_traceback(filtered_tb) from None
TypeError: Exception encountered when calling layer ""tf.convert_to_tensor"" (type TFOpLambda).

Failed to convert elements of tf.RaggedTensor(values=tf.RaggedTensor(values=Tensor(""Placeholder:0"", shape=(None,), dtype=int32), row_splits=Tensor(""Placeholder_1:0"", shape=(None,), dtype=int64)), row_splits=Tensor(""Placeholder_2:0"", shape=(None,), dtype=int64)) to Tensor. Consider casting elements to a supported type. See https://www.tensorflow.org/api_docs/python/tf/dtypes for supported TF dtypes.

Call arguments received:
  • value=tf.RaggedTensor(values=tf.RaggedTensor(values=Tensor(""Placeholder:0"", shape=(None,), dtype=int32), row_splits=Tensor(""Placeholder_1:0"", shape=(None,), dtype=int64)), row_splits=Tensor(""Placeholder_2:0"", shape=(None,), dtype=int64))
  • dtype=None
  • dtype_hint=None
  • name=None
```

**Describe the expected behavior**

```
Metal device set to: Apple M1

systemMemory: 16.00 GB
maxCacheSize: 5.33 GB

2022-03-23 16:42:31.925269: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.
2022-03-23 16:42:31.925539: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)
2022-03-23 16:42:36.016294: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz
2022-03-23 16:42:36.057489: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.
2022-03-23 16:42:36.081872: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.
2022-03-23 16:42:36.096263: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.
<tf.RaggedTensor [[[101],
  [7592],
  [2088],
  [999],
  [102]]]>
```

**[Contributing](https://www.tensorflow.org/community/contribute)**

- Do you want to contribute a PR? (yes/no): no
- Briefly describe your candidate solution(if contributing):

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

```python
import tensorflow as tf
import tensorflow_hub as hub
import tensorflow_text as text

x_txt = tf.keras.layers.Input(shape=(), dtype=tf.string)
bert_pre = hub.load(""https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3"")
tokenize = hub.KerasLayer(bert_pre.tokenize)
bert_info = bert_pre.tokenize.get_special_tokens_dict()

trimmer = text.RoundRobinTrimmer(max_seq_length=40)
mlm_selector = text.RandomItemSelector(
    max_selections_per_batch=1000,
    selection_rate=0.15,
    unselectable_ids=[
        bert_info[""end_of_segment_id""],
        bert_info[""mask_id""],
        bert_info[""padding_id""],
        bert_info[""start_of_sequence_id""],
    ],
)
mask_values_chooser = text.MaskValuesChooser(
    bert_info[""vocab_size""], bert_info[""mask_id""], mask_token_rate=0.8
)

y_txt = tokenize(x_txt)
y_txt, _segment_id = text.combine_segments(
    [y_txt],
    bert_info[""start_of_sequence_id""],
    bert_info[""end_of_segment_id""],
)
y_txt = trimmer.trim([y_txt])[0]

model = tf.keras.models.Model(inputs=[x_txt], outputs=[y_txt])
print(model.predict(tf.constant([""hello world!""])))
```

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

This eager execution equivalent returns expected output.

```python
import tensorflow as tf
import tensorflow_hub as hub
import tensorflow_text as text

x_txt = tf.constant([""hello world!""])
bert_pre = hub.load(""https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3"")
tokenize = hub.KerasLayer(bert_pre.tokenize)
bert_info = bert_pre.tokenize.get_special_tokens_dict()

trimmer = text.RoundRobinTrimmer(max_seq_length=40)
mlm_selector = text.RandomItemSelector(
    max_selections_per_batch=1000,
    selection_rate=0.15,
    unselectable_ids=[
        bert_info[""end_of_segment_id""],
        bert_info[""mask_id""],
        bert_info[""padding_id""],
        bert_info[""start_of_sequence_id""],
    ],
)
mask_values_chooser = text.MaskValuesChooser(
    bert_info[""vocab_size""], bert_info[""mask_id""], mask_token_rate=0.8
)

y_txt = tokenize(x_txt)
y_txt, _segment_id = text.combine_segments(
    [y_txt],
    bert_info[""start_of_sequence_id""],
    bert_info[""end_of_segment_id""],
)
y_txt = trimmer.trim([y_txt])[0]
print(y_txt)
```"
55372,Wrong definition of arg fixed_length in api_docs/python/tf/raw_ops/DecodePaddedRaw,"Thank you for submitting a TensorFlow documentation issue. Per our GitHub
policy, we only address code/doc bugs, performance issues, feature requests, and
build/installation issues on GitHub.

The TensorFlow docs are open source! To get involved, read the documentation
contributor guide: https://www.tensorflow.org/community/contribute/docs

## URL(s) with the issue:

https://www.tensorflow.org/api_docs/python/tf/raw_ops/DecodePaddedRaw

## Description of issue (what needs changing):

Wrong type decription of `fixed_length` .

### Clear description

`fixed_length` should be a positive int, but the doc has following description:
````
A Tensor of type int32. Length in bytes for each element of the decoded output. Must be a multiple of the size of the output type.
````


### Parameters defined

`fixed_length` should be a positive int.


### Submit a pull request?

no
"
55371,Feature request: Add left_side flag and functionality to tf.linalg.triangular_solve,"**System information**
- TensorFlow version (you are using): 2.8.0
- Are you willing to contribute it (Yes/No): No



**Describe the feature and the current behavior/state.**
Add `left_side` flag and functionality to `tf.linalg.triangular_solve` as described in documentation for XLA TriangularSolve:
https://www.tensorflow.org/xla/operation_semantics?hl=sl&skip_cache=true#triangularsolve

**Will this change the current api? How?**
It will add an additional flag, which can be defaulted to maintain current behavior.

**Who will benefit with this feature?**
Those who want to solve triangular systems without a bulk of unnecessary transpose operations.
"
55370,mlflow.start_run() cases internal XLA error on TPU v2-8 with TF 2.8.0,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): pre-installed on GCP TPU instance
- TensorFlow version (use command below): tpu-vm-tf-2.8.0
- Python version: 3.8.10
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: N/A
- GPU model and memory: tpu v2-8, tpu-vm-tf-2.8.0

**Describe the current behavior**
```
2022-03-25 03:01:14.053145: I tensorflow/core/tpu/tpu_api_dlsym_initializer.cc:116] Libtpu path is: libtpu.so
2022-03-25 03:01:15.555809: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-03-25 03:01:29.331594: I tensorflow/compiler/xla/service/service.cc:171] XLA service 0x429e9c0 initialized for platform TPU (this does not guarantee that XLA will be used). Devices:
2022-03-25 03:01:29.331633: I tensorflow/compiler/xla/service/service.cc:179]   StreamExecutor device (0): TPU, 2a886c8
2022-03-25 03:01:29.331640: I tensorflow/compiler/xla/service/service.cc:179]   StreamExecutor device (1): TPU, 2a886c8
2022-03-25 03:01:29.331646: I tensorflow/compiler/xla/service/service.cc:179]   StreamExecutor device (2): TPU, 2a886c8
2022-03-25 03:01:29.331656: I tensorflow/compiler/xla/service/service.cc:179]   StreamExecutor device (3): TPU, 2a886c8
2022-03-25 03:01:29.331664: I tensorflow/compiler/xla/service/service.cc:179]   StreamExecutor device (4): TPU, 2a886c8
2022-03-25 03:01:29.331671: I tensorflow/compiler/xla/service/service.cc:179]   StreamExecutor device (5): TPU, 2a886c8
2022-03-25 03:01:29.331681: I tensorflow/compiler/xla/service/service.cc:179]   StreamExecutor device (6): TPU, 2a886c8
2022-03-25 03:01:29.331694: I tensorflow/compiler/xla/service/service.cc:179]   StreamExecutor device (7): TPU, 2a886c8
All devices:  [LogicalDevice(name='/device:TPU:0', device_type='TPU'), LogicalDevice(name='/device:TPU:1', device_type='TPU'), LogicalDevice(name='/device:TPU:2', device_type='TPU'), LogicalDevice(name='/device:TPU:3', device_type='TPU'), LogicalDevice(name='/device:TPU:4', device_type='TPU'), LogicalDevice(name='/device:TPU:5', device_type='TPU'), LogicalDevice(name='/device:TPU:6', device_type='TPU'), LogicalDevice(name='/device:TPU:7', device_type='TPU')]
2022-03-25 03:01:56.679371: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:237] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2022-03-25 03:01:56.701447: I tensorflow/compiler/jit/xla_compilation_cache.cc:399] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2022-03-25 03:01:56.703897: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at xla_compile_on_demand_op.cc:183 : INTERNAL: Core halted unexpectedly: No error message available as no compiler metadata was provided.
Traceback (most recent call last):
  File ""testcase.py"", line 23, in <module>
    main()
  File ""testcase.py"", line 19, in main
    seq = tf.keras.Sequential([tf.keras.layers.Dense(512)])
  File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/tracking/base.py"", line 629, in _method_wrapper
    result = method(self, *args, **kwargs)
  File ""/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py"", line 67, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/constant_op.py"", line 102, in convert_to_eager_tensor
    return ops.EagerTensor(value, ctx.device_name, dtype)
tensorflow.python.framework.errors_impl.InternalError: Core halted unexpectedly: No error message available as no compiler metadata was provided.
```

**Describe the expected behavior**

`tf.keras.Sequential([tf.keras.layers.Dense(512)])` returns successfully

**[Contributing](https://www.tensorflow.org/community/contribute)**

 - I doubt I can fix this myself

**Standalone code to reproduce the issue**
```
# testcase.py
import mlflow
import tensorflow as tf

def init_tf_gpus():
    resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='local')
    tf.config.experimental_connect_to_cluster(resolver)
    # This is the TPU initialization code that has to be at the beginning.
    tf.tpu.experimental.initialize_tpu_system(resolver)
    print(""All devices: "", tf.config.list_logical_devices('TPU'))

    tf.config.optimizer.set_jit(True)

    return tf.distribute.TPUStrategy(resolver)

def main():
    strategy = init_tf_gpus()
    with mlflow.start_run(run_name=""test""): # disable this line to make it work
        with strategy.scope():
            seq = tf.keras.Sequential([tf.keras.layers.Dense(512)])


if __name__ == ""__main__"":
    main()
```
**Other info / logs** Include any logs or source code that would be helpful to

Install mlflow via `pip install mlflow`, I am using 1.24.0"
55369,Failed to build libtensorflow (v2.8.0 + bazel 4.2.1) from source on Apple M1 ,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
`Apple M1`

- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
`Source: v2.8.0 branch`

- TensorFlow version:
- Python version:
`3.9.9`

- Installed using virtualenv? pip? conda?
- Bazel version (if compiling from source):
`4.2.1`

- GCC/Compiler version (if compiling from source):
```
Apple clang version 13.1.6 (clang-1316.0.21.2)
Target: arm64-apple-darwin21.4.0
Thread model: posix
InstalledDir: /Library/Developer/CommandLineTools/usr/bin
```

- CUDA/cuDNN version:
- GPU model and memory:



**Describe the problem**
```
bazel build --jobs 10 --config opt --cpu=darwin_arm64 --host_cpu=darwin_arm64 //tensorflow/tools/lib_package:libtensorflow

ERROR: /private/var/tmp/_bazel_leonard/dbb496db86443ebdf640b47e39125a9a/external/local_config_cc/BUILD:48:19: in cc_toolchain_suite rule @local_config_cc//:toolchain: cc_toolchain_suite '@local_config_cc//:toolchain' does not contain a toolchain for cpu 'darwin_arm64'
ERROR: Analysis of target '//tensorflow/tools/lib_package:libtensorflow' failed; build aborted: Analysis of target '@local_config_cc//:toolchain' failed
INFO: Elapsed time: 131.509s
INFO: 0 processes.
FAILED: Build did NOT complete successfully (126 packages loaded, 2996 targets configured)
    Fetching @icu; fetching 6s
    Fetching ...6db86443ebdf640b47e39125a9a/external/icu; Extracting /private/var/tmp/_bazel_leonard/dbb496db86443ebdf640b47e39125a9a/external/icu/temp15584703296969244655/release-69-1.zip
    Fetching @com_google_absl; Restarting.
```

**Provide the exact sequence of commands / steps that you executed before running into the problem**
```
./configure

bazel build --jobs 10 --config opt --cpu=darwin_arm64 --host_cpu=darwin_arm64 //tensorflow/tools/lib_package:libtensorflow
```

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
55368,"TensorFlow android throw java.lang.OutOfMemoryError when building project, but there's free 20GB memory.","![image](https://user-images.githubusercontent.com/12729184/160032113-66a91d3c-81cf-4ac0-a5e7-f4046f5da39c.png)

My process:
- Clone project from https://github.com/tensorflow/tensorflow/tree/master/tensorflow/tools/android/test
- Click build button (My PC memory : 11.7/31.9 GB (37%))
- When building the memory only use 2GB, then it throwed error : 
```
:packageDebug' `
> A failure occurred while executing com.android.build.gradle.internal.tasks.Workers$ActionFacade
> java.lang.OutOfMemoryError (no error message)
```
- My PC has hyper-v

Did I miss some key steps?  Really appreciate Tensorflow team's efforts."
55366,DOC: explain the meaning of model.fit() history tracking in a distributed scenario,"## URL(s) with the issue:

Perhaps most closely related to some of these docs pages:
  - https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit
  - https://www.tensorflow.org/tutorials/distribute/multi_worker_with_keras#overview

## Description of issue (what needs changing):

There are fairly substantial docs about distributed training with tensorflow, including docs related to the `MultiWorkerMirroredStrategy`. But, as far as I can tell, reading those docs still doesn't prepare the end user for some of the perils of distributed training. One thing I'd like to see described/explained by an expert, is what it means to track the `history` result of `model.fit()` from many different distributed workers.

For example, what does it mean that the learning curves are different between different workers? Should they be? What about accuracy results exceeding 100 % like in the two-worker example results below? Should we even be looking at these individually?

Node 0 `model.fit()` results:

![bench_epoch_rank_0_hostname_cn662](https://user-images.githubusercontent.com/7903078/160017020-721ca1a4-a28c-48d2-bf43-9dadcc14c6f7.png)

Node 1 `model.fit()` results:

![bench_epoch_rank_1_hostname_cn663](https://user-images.githubusercontent.com/7903078/160017031-3300d4b9-de47-4180-a4ac-a02c18aeb298.png)

Should the results be condensed/reduced somehow? For that matter, is there any troubleshooting documentation on what an accuracy greater than 100 % means?

### Correct links

Not related to links.

### Parameters defined

Not related to parameters.

### Returns defined

Perhaps for `model.fit()` there could be a side-note of some sort on how to interpret `history.history` in distributed scenarios, and what kinds of fluctuations between workers are normal vs. suspicious?

### Raises listed and defined

No exception handling issues reported here.

### Usage example

I don't think I've actually seen a good usage example that shows the distributed `history.history` tracking plots differ between workers?

### Request visuals, if applicable

I could probably provide some sample loss/accuracy plots for distributed cases if that would help.

### Submit a pull request?

Are you planning to also submit a pull request to fix the issue? 

If you can offer some guidance on how this is supposed to work, I think that would be useful enough for me to justify helping improve the docs as well.
"
55364,benchmark_model: Could not create Hexagon delegate: platform may not support delegate or required libraries are missing,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Android 11
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Samsung S21
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): nightly

**Describe the current behavior**
* Follow instructions in https://www.tensorflow.org/lite/performance/measurement#native_benchmark_binary and https://www.tensorflow.org/lite/performance/hexagon_delegate to run TFLite `benchmark_model` with `use_hexagon=true`.
* `adb push` contents of these to `/data/local/tmp`:
  * [android_aarch64_benchmark_model](https://storage.googleapis.com/tensorflow-nightly-public/prod/tensorflow/release/lite/tools/nightly/latest/android_aarch64_benchmark_model)
  * [libhexagon_interface.so ](https://storage.googleapis.com/tensorflow-nightly-public/prod/tensorflow/release/lite/tools/nightly/latest/android_aarch64_libhexagon_interface.so)
  * [hexagon_nn_skel v1.20.0.1](https://storage.cloud.google.com/download.tensorflow.org/tflite/hexagon_nn_skel_v1.20.0.1.run)
  * [mobilenet_v2_1.0_224_quant](https://storage.googleapis.com/download.tensorflow.org/models/tflite_11_05_08/mobilenet_v2_1.0_224_quant.tgz)
* Verify with `adb shell ls /data/local/tmp`: 
  ```
  android_aarch64_benchmark_model
  libhexagon_interface.so
  libhexagon_nn_skel.so
  libhexagon_nn_skel_v65.so
  libhexagon_nn_skel_v66.so
  mobilenet_v2_1.0_224.tflite
  mobilenet_v2_1.0_224_quant.tflite
  ```
* Run `adb shell /data/local/tmp/android_aarch64_benchmark_model --graph=/data/local/tmp/mobilenet_v2_1.0_224_quant.tflite --use_hexagon=true --hexagon_lib_path=/data/local/tmp`
* Hexagon delegate fail to create:
  ```
  STARTING!
  Log parameter values verbosely: [0]
  Graph: [/data/local/tmp/mobilenet_v2_1.0_224_quant.tflite]
  Use Hexagon: [1]
  Hexagon lib path: [/data/local/tmp]
  Loaded model /data/local/tmp/mobilenet_v2_1.0_224_quant.tflite
  INFO: Initialized TensorFlow Lite runtime.
  WARNING: Failed to fetch Hexagon NN version. This might be because you're using incompatible versions of libhexagon_interface and libhexagon_nn_skel. You must use compatible versions. Refer to Tensorflow Lite Hexagon Delegate Guide.
  INFO: Hexagon Delegate is not supported.
  
  loaded libcdsprpc.so
  Could not create Hexagon delegate: platform may not support delegate or required libraries are missing
  The input model file size (MB): 3.57776
  Initialized session in 51.739ms.
  Running benchmark for at least 1 iterations and at least 0.5 seconds but terminate if exceeding 150 seconds.
  count=66 first=23605 curr=6778 min=6765 max=23605 avg=7583.89 std=2197
  
  Running benchmark for at least 50 iterations and at least 1 seconds but terminate if exceeding 150 seconds.
  count=82 first=6870 curr=850063 min=6765 max=850063 avg=17097.5 std=92551
  
  Inference timings in us: Init: 51739, First inference: 23605, Warmup (avg): 7583.89, Inference (avg): 17097.5
  Note: as the benchmark tool itself affects memory footprint, the following is only APPROXIMATE to the actual memory footprint of the model at runtime. Take the information at your discretion.
  Memory footprint delta from the start of the tool (MB): init=4.73828 overall=8.75
  ``` 

**Describe the expected behavior**

`benchmark_model` runs with hexagon delegate enabled."
55361,About how does buffer size from Dataset.shuffle() influence Dataset.cache(),"Hi,
I find when I set `train_ds = train_ds.cache(filename='...')`
`train_ds = train_ds.shuffle(buffer_size=int(training_size/10)).batch(batch_size).prefetch(buffer_size=AUTOTUNE)`
During the first epoch of model fitting, what happened looks strange.

`Epoch 1/10
2022-03-24 16:54:22.982546: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8101
245/274 [=========================>....] - ETA: 8s - loss: 1.5153 - accuracy: 0.5639`

`2022-03-24 16:55:42.858875: W tensorflow/core/kernels/data/cache_dataset_ops.cc:233] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.`

`274/274 [==============================] - 109s 352ms/step - loss: 1.4703 - accuracy: 0.5753 - val_loss: 2.4110 - val_accuracy: 0.3950`

`Epoch 2/10
274/274 [==============================] - 93s 336ms/step - loss: 0.9126 - accuracy: 0.7168 - val_loss: 0.7763 - val_accuracy: 0.7676`

`Epoch 3/10
274/274 [==============================] - 92s 334ms/step - loss: 0.7067 - accuracy: 0.7886 - val_loss: 0.6996 - val_accuracy: 0.7922`
`

It seems that the model fitting ends before the feeding of the last 1/10 batches (this proportion is same as the proportion used in buffer size, I set this number in buffer size to save memory). Then the model fitting is restarted and the first epoch model fitting is finish.

I would like to ask 1) why this happens? 2) Is all my dataset successfully been cached rather than only the dataset for the first 90% batches is cached?










"
55360,"DeeplabV3 custom dataset, inference problem black images","Good morning,

I want to train a custom dataset using deeplabV3.

I'm following this tutorial (https://sanjayparajuli27.medium.com/how-to-train-deeplab-on-custom-dataset-a40c41c4c6a3) for this dataset (https://www.kaggle.com/datasets/dansbecker/cityscapes-image-pairs) that I found on Kaggle, based on cityscapes.

There are images of 256x256 pixel in RGB colors, divided in 2975 imgs for training and 500 for validation, and I created the respective mask using this script

```
import tensorflow as tf
from PIL import Image
from tqdm import tqdm
import numpy as np

import os, shutil

# palette (color map) describes the (R, G, B): Label pair
palette = {(0,   0,   0) : 0 ,
           (128,  0, 0) : 1,
           (0, 128, 0): 2,
           (128, 128, 0): 3,
           (0, 0, 128): 4,
           (0, 128, 128): 5,
           (128, 128, 128): 6,
           (64, 0, 0): 7,
           (192, 0, 0): 8,
           (64, 128, 0): 9,
           (192, 128, 0): 10,
           (64, 0, 128): 11,
           (192, 0, 128): 12,
           (64, 128, 128): 13,
           (0, 64, 0): 14,
           (128, 64, 0): 15,
           (0, 192, 0): 16,
           (128, 192, 0): 17,
           (0, 64, 128): 18,
           (128, 0, 128): 19
         }

def convert_from_color_segmentation(arr_3d):
    arr_2d = np.zeros((arr_3d.shape[0], arr_3d.shape[1]), dtype=np.uint8)

    for c, i in palette.items():
        m = np.all(arr_3d == np.array(c).reshape(1, 1, 3), axis=2)
        arr_2d[m] = i
    return arr_2d


label_dir = ""C:/Users/paolo.david/Desktop/Datasets/final/Validation/Mask_real/"" #don't forget the '/' at the end
new_label_dir = ""C:/Users/paolo.david/Desktop/Datasets/final/Validation/Mask_RAW2/""

if not os.path.isdir(new_label_dir):
    print(""creating folder: "",new_label_dir)
    os.mkdir(new_label_dir)
else:
    print(""Folder alread exists. Delete the folder and re-run the code!!!"")


label_files = os.listdir(label_dir)

for l_f in tqdm(label_files):
    #arr = np.array(Image.open(l_f))
    arr = np.array(Image.open(label_dir + l_f))
    arr = arr[:,:,0:3]
    arr_2d = convert_from_color_segmentation(arr)
    #Image.fromarray(arr_2d).save(label_dir)
    Image.fromarray(arr_2d).save(new_label_dir + l_f)
```

Each image in the dataset contain its same mask, so before to launch the new notebook I divided the image and the mask to have a situation like in the tutorial.

You can find my code here: https://drive.google.com/drive/folders/105JMDmujY6lknH3D74WM8R8S7jTb51qX?usp=sharing and this is the notebook https://drive.google.com/file/d/1xmUtLB-XPj4mZdqbx9SAQOXKSwxtxCLX/view?usp=sharing

I have a problem with the inference. Every time I launch the notebook with few epochs (less then 10) I receive good results, but trying to increase the number of epoch I have all black images.

These are the parameters that I used for the train:

```
--model_variant=""xception_65"" \
--atrous_rates=6 \
--atrous_rates=12 \
--atrous_rates=18 \
--output_stride=16 \
--decoder_output_stride=4 \
--train_crop_size=""256,256"" \
--train_batch_size=4 \
--training_number_of_steps=30 \
--initialize_last_layer=False \
--last_layers_contain_logits_only=True \
--fine_tune_batch_norm=False \
```

I edited the data_generator.py file putting

```
_CUSTOM_INFORMATION = DatasetDescriptor(
    splits_to_sizes={
        'train': 270,  # num of samples in train.txt
        'val': 30,  # num of samples in val.txt
    },
    num_classes=21, # classes+bg+ignore_label
    ignore_label=255,
)

_DATASETS_INFORMATION = {
    'cityscapes': _CITYSCAPES_INFORMATION,
    'pascal_voc_seg': _PASCAL_VOC_SEG_INFORMATION,
    'ade20k': _ADE20K_INFORMATION,
    'custom': _CUSTOM_INFORMATION  # custom dataset
}
```

I'm using a pretrained model downloaded from here: http://download.tensorflow.org/models/deeplabv3_cityscapes_train_2018_02_06.tar.gz

I keep the batch size at 4, and I don't know if it is correct or not. Can you tell me where could be the possible error?"
55359,tf2.0  dataset disable_eager_execution,"tf is 2.4.0
import tensorflow as tf
tf.compat.v1.disable_eager_execution()
with tf.device('/cpu'):
    dataset = tf.data.Dataset.from_tensor_slices([1,3,4,5,6,7,8])

@tf.function(autograph=False)
def iter_funs(ds):
    iterator = iter(dataset)
    return iterator.get_next()

with tf.compat.v1.InteractiveSession().as_default():
    with tf.device('/cpu'):
        xx = iter_funs(dataset)
        print(xx.eval())
        print(xx.eval())

the output is always 1 ,xx not iterator.
so how can i do to iterator the data"
55358,MirroredStrategy was not working.,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): `Yes`
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): `Ubuntu 20.04`
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: `No mobile device.`
- TensorFlow installed from (source or binary): `Installed tensorflow from pip.`
- TensorFlow version (use command below): tf.version.GIT_VERSION = v2.8.0-rc1-32-g3f878cff5b6; `tensorflow-gpu=2.8.0.`
- Python version: `python=3.10`
- Bazel version (if compiling from source): `Not compiled from source code.`
- GCC/Compiler version (if compiling from source): `No.`
- CUDA/cuDNN version: `cuda-11.5 ; cudnn-8.3.2.44.`
- GPU model and memory: `RTX3090 * 2.`

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
My neural network callback code was illustrated as follows:

````
class ResnetBuilder(object):
    @staticmethod
    @tf.function
    def build(block, blocks_num, im_width=224, im_height=224, num_classes=1000):
        input_image = layers.Input(shape=(im_height, im_width, 3), dtype=""float32"", name=""layers_inputs"")
        x = layers.Conv2D(filters=64, kernel_size=7, strides=2, padding=""SAME"",
                          use_bias=False, name=""layers_conv1"")(input_image)  
        x = layers.BatchNormalization(momentum=0.9, epsilon=1e-5)(x)
        x = layers.ReLU()(x)
        x = layers.MaxPool2D(pool_size=3, strides=2, padding=""SAME"")(x)

        x = _make_layer(block, 64, blocks_num[0], layer_name=""ml1"", strides=1)(x)
        x = _make_layer(block, 128, blocks_num[1], layer_name=""ml2"", strides=2)(x)
        x = _make_layer(block, 256, blocks_num[2], layer_name=""ml3"", strides=2)(x)
        x = _make_layer(block, 512, blocks_num[3], layer_name=""ml4"", strides=2)(x)

        x = layers.GlobalAvgPool2D()(x)  # pool + flatten
        x = layers.Dense(num_classes, name=""logits"")(x)

        predict = layers.Softmax()(x)
        # predict = layers.Activation('softmax', dtype='float32', name='predictions')(x)

        model = Model(inputs=input_image, outputs=predict)
        return model

    @staticmethod
    @tf.function
    def resnet101(im_width=224, im_height=224, num_classes=1000):
        # tf.keras.backend.clear_session()
        return ResnetBuilder.build(Bottleneck, [3, 4, 23, 3], im_width, im_height, num_classes)

    @staticmethod
    @tf.function
    def resnet50(im_width=224, im_height=224, num_classes=1000):
        # tf.keras.backend.clear_session()
        return ResnetBuilder.build(Bottleneck, [3, 4, 6, 3], im_width, im_height, num_classes)
````

You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

` tf.version.GIT_VERSION = v2.8.0-rc1-32-g3f878cff5b6; tensorflow-gpu=2.8.0.`

**Describe the current behavior**
The tf.distribute.MirroredStrategy was not working, I have checked cuda, cudnn, driver and nccl, all is well, however, distribution train has frozen, only one GPU worked in this distribution training scene.
**Describe the expected behavior**
I do not know which problem was caused this status.
**[Contributing](https://www.tensorflow.org/community/contribute)**

- Do you want to contribute a PR? (yes/no): No, thanks very much.
- Briefly describe your candidate solution(if contributing):

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook

```
import gc
import os

import numpy as np
import pandas as pd
import tensorflow as tf
import tensorflow_addons as tfa

from utils import save_appoint_csv, FGVCSave
from BaseConstruct.ResnetFunctionDepthWise import ResnetBuilder

print(tf.compat.v1.executing_eagerly_outside_functions())
np.random.seed(0)
tf.config.run_functions_eagerly(True) 
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'


def scheduler(epoch):
    if epoch < 40:
        return 0.1
    if epoch < 100:
        return 0.06
    if epoch < 150:
        return 0.01
    if epoch < 200:
        return 0.006
    return 0.0001


def trainFGVC():
    BATCH_SIZE = 10
    num_classes = 30
    all_labels = []
    epochs = 250
    save_path = r""*********""
    save_train_data = r""*********""
    train_img_path = r""*********""
    test_img_path = r""*********""
    train_data = pd.read_csv(r'*********, delimiter="","")

    train_data['label'] = train_data['label'].astype('str')
    Y = train_data[['label']]
    test_data = pd.read_csv(r'*********, delimiter="","")
    test_data['label'] = test_data['label'].astype('str')

    generator = tf.keras.preprocessing.image.ImageDataGenerator(
        rescale=1.0 / 255)  

    for i in range(num_classes):
        all_labels.append(str(i))
    train_data_generator = generator.flow_from_dataframe(train_data, directory=train_img_path,
                                                         x_col=""filename"",
                                                         batch_size=BATCH_SIZE, y_col=""label"",
                                                         class_mode='categorical',
                                                         target_size=(448, 448), shuffle=True,
                                                         classes=all_labels)

    val_data_generator = generator.flow_from_dataframe(test_data, directory=test_img_path,
                                                       x_col=""filename"",
                                                       batch_size=BATCH_SIZE, y_col=""label"",
                                                       class_mode='categorical',
                                                       target_size=(448, 448), shuffle=False,
                                                       classes=all_labels)
    kept = tf.keras.callbacks.ModelCheckpoint(save_train_data + ""\\"" + ""model.{epoch:02d}-{val_loss:.4f}-"" +
                                              str(0) + "".h5"", monitor='val_accuracy', verbose=1,
                                              save_best_only=True, mode='max')

    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=save_train_data + ""\\"" + r""TensorBoard"",
                                                          write_graph=True,
                                                          histogram_freq=5)
    lr_reducer = tf.keras.callbacks.LearningRateScheduler(scheduler)
    loss = tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.1)

    strategy = tf.distribute.MirroredStrategy()
    with strategy.scope():
        model = ResnetBuilder.resnet101(im_width=448, im_height=448, num_classes=num_classes)
        optimizer = tfa.optimizers.SGDW(weight_decay=1e-5, learning_rate=0.02, momentum=0.9)

    model.compile(loss=loss, optimizer=optimizer, metrics=['accuracy'], run_eagerly=True)

    history = model.fit(x=train_data_generator, validation_data=val_data_generator, epochs=epochs,
                        callbacks=[kept, tensorboard_callback, lr_reducer])

    print(history.history[""val_recall""])
    data_dic = {""val_accuracy"": history.history['val_accuracy'],
                ""val_loss"": history.history['val_loss'],
                ""val_recall"": history.history[""val_recall""],
                ""val_precision"": history.history[""val_precision""]
                }

    flag, path = save_appoint_csv(data_dic, 0, save_path)

    if flag == -1:
        print(""save training data false! Please check function code!"")
    elif flag == 1:
        print(""save training data successful! Save path is "", path)

    del history
    del model
    for i in range(999):
        gc.collect()


if __name__ == '__main__':
    trainFGVC()
```


**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
`I am sorry, there was no log or information has collected from logging.`"
55357,@tensorflow/tfjs: Unable to load model,"Using Webpack to build a node app with @tensorflow/tfjs included, when using tf.loadLayersModel() the following error is received:

```
webpack:///./node_modules/@tensorflow/tfjs-core/dist/platforms/platform_node.js?:59
        return systemFetch(path, requestInits);
               ^

TypeError: systemFetch is not a function
```

When looking into the node_module, it does appear that this is a bug in the tensorflowjs core code. This happens when trying to load a model via an http request or a direct file (since this is a node application)"
55355,TF.data.dataset.cache(path) still uses memory despite the cache file path is given in tf2.8,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Linux Ubuntu 16.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
binary
- TensorFlow version (use command below):
tf2.8.0
- Python version:
python 3.8
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
CUDA v11.2. cuDNN v8.1
- GPU model and memory:
K80, gMem=16GB

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
I came across a weird problem when I read TFrecords files from S3 through tf.dataset and cached them to my local path. Here is my reading code

    filenames=['s3s:path1', ''s3s:path2']
    dataset = tf.data.TFRecordDataset(filenames, compression_type=""GZIP"")
    parsed_dataset = (
        dataset.batch(batch_size, num_parallel_calls=tf.data.AUTOTUNE)
        .map(decode, num_parallel_calls=tf.data.AUTOTUNE)
        .cache(cache_file_path)
        .prefetch(tf.data.AUTOTUNE)
    )
It’s very strange that cache() still uses the internal memory which results in OOM. Here is the memory usage I printed via callback during training.

2022-03-08T22:19:40.154191003Z ...Training: end of batch 15700; got log keys: ['loss', 'copc', 'auc']
2022-03-08T22:19:40.159188560Z totalmemor: 59.958843GB
2022-03-08T22:19:40.159223737Z availablememory: 8.418320GB
2022-03-08T22:19:40.159250296Z usedmemory: 50.959393GB
2022-03-08T22:19:40.159257814Z percentof used memory: 86.000000
2022-03-08T22:19:40.159263710Z freememory:1.072124GB
2022-03-08T22:19:47.752077011Z Tue Mar  8 22:19:47 UTC 2022	job-submitter:	job run error: signal: killed

**Describe the expected behavior**
I have tested the code on TF2.3 which has no such an issue, but TF2.8 have such an OOM issue. It's supposed that when the path is given, cache(path) should use files to cache instead of memory.


**[Contributing](https://www.tensorflow.org/community/contribute)**

- Do you want to contribute a PR? (yes/no):
- Briefly describe your candidate solution(if contributing):

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
55349,TF-lite conversion of complex abs layer not working with integer quantization with fallbacks,"I'm trying to optimize a speech-to-text Conformer model for tflite usage. Quantization of the model is working for _default_ optimization mode, but not when a _representative dataset_ is used. In this case it fails in inference with: `type != kTfLiteFloat32 (INT8 != FLOAT32) Node number 46 (COMPLEX_ABS) failed to prepare`

Shouldn't the model use the _float32_ fallback in this case, since I'm not enforcing _int8_ operators?

### 1. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20:04
- TensorFlow installation (pip package or built from source): Nvidia-Docker
- TensorFlow library (version, if pip package or github SHA, if built from source): 2.7


### 2. Failure after conversion

```
Transcribing the audio ...
Label:             they were subjected to constant surveillance and periodic searches
Traceback (most recent call last):
  File ""/Scribosermo/exporting/testing_file.py"", line 161, in <module>
    main()
  File ""/Scribosermo/exporting/testing_file.py"", line 155, in main
    test_tflite(checkpoint_tflite_quant)
  File ""/Scribosermo/exporting/testing_file.py"", line 118, in test_tflite
    prediction = predict(interpreter, audio)
  File ""/Scribosermo/exporting/testing_file.py"", line 92, in predict
    interpreter.invoke()
  File ""/usr/local/lib/python3.8/dist-packages/tflite_runtime/interpreter.py"", line 923, in invoke
    self._interpreter.Invoke()
RuntimeError: /workspace/tensorflow/lite/kernels/complex_support.cc:43 output-> \
  type != kTfLiteFloat32 (INT8 != FLOAT32)Node number 46 (COMPLEX_ABS) failed to prepare.
```

### 3. Code snippets

```python3
# Conversion settings
def export_tflite(model, save_path, optimize):

    converter = tf.lite.TFLiteConverter.from_keras_model(model)

    if optimize:
        converter.optimizations = [tf.lite.Optimize.DEFAULT]
        converter.representative_dataset = representative_dataset

    tflite_model = converter.convert()

    with open(save_path, ""wb+"") as file:
        file.write(tflite_model)

# Spectrogram definition
def audio_to_spect(self, audio):
        """"""Calculate the spectrogram""""""

        # Pytorch uses a slightly different spectrogram calculation which is matched to librosa
        # unlike the default tensorflow implementation
        n_fft = 512
        nbatch = tf.shape(audio)[0]

        # Add center padding
        signal = tf.reshape(audio, [nbatch, -1])
        pad_amount = int(self.audio_window_samples // 2)
        signal = tf.pad(signal, [[0, 0], [pad_amount, pad_amount]], ""REFLECT"")
        signal = tf.reshape(signal, [nbatch, 1, -1])

        # Calculate short-time Fourier transforms with a differnt windowing approach
        f = tf.signal.frame(
            signal, self.audio_window_samples, self.audio_step_samples, pad_end=False
        )
        w = tf.signal.hann_window(self.audio_window_samples, periodic=False)
        stfts = tf.signal.rfft(f * w, fft_length=[n_fft])

        # Obtain the magnitude of the STFT.
        spectrogram = tf.abs(stfts) ** 2
        spectrogram = tf.squeeze(spectrogram, axis=1)

        return spectrogram
```

<br>

Related issue: https://github.com/tensorflow/tensorflow/issues/53393#issuecomment-1009703703 (was closed without solution)"
55348,summarization  ,"<em>Please make sure that this is an issue related to performance of TensorFlow.
As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:performance_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below):
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

**Describe the expected behavior**

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached."
55347,MirroredStrategy,"Please go to Stack Overflow for help and support:

https://stackoverflow.com/questions/tagged/tensorflow

If you open a GitHub issue, here is our policy:

1.  It must be a bug, a feature request, or a significant problem with the
    documentation (for small docs fixes please send a PR instead).
2.  The form below must be filled out.
3.  It shouldn't be a TensorBoard issue. Those go
    [here](https://github.com/tensorflow/tensorboard/issues).

**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.

------------------------

### System information

-   **Have I written custom code (as opposed to using a stock example script
    provided in TensorFlow)**:
-   **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:
-   **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue
    happens on a mobile device**:
-   **TensorFlow installed from (source or binary)**:
-   **TensorFlow version (use command below)**:
-   **Python version**:
-   **Bazel version (if compiling from source)**:
-   **GCC/Compiler version (if compiling from source)**:
-   **CUDA/cuDNN version**:
-   **GPU model and memory**:
-   **Exact command to reproduce**:

You can collect some of this information using our environment capture script:

https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh

You can obtain the TensorFlow version with:

```bash
python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""
```

### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.
"
55346,Opening GUIs on host machine using the TensorFlow docker image,"Hello everyone 

I'm using TensorFlow gpu docker image and it is working just fine on my python scripts. 
My issue is trying to open some GUI applications like spyder-ide.

The _Dockerfile_ used to build the image is:
```
FROM tensorflow/tensorflow:latest-gpu
RUN apt-get update
RUN apt-get install python3-opencv libasound2 -y
RUN pip install --upgrade pip
RUN pip install spyder
RUN pip install numpy
RUN pip install pandas
RUN pip install sklearn
RUN pip install matplotlib
WORKDIR /home
```

and the docker arguments used to start the image are
```
sudo docker run -it \
    --gpus all \
    --env=""DISPLAY"" \
    --net=host \
    -v /tmp/.X11-unix:/tmp/.X11-unix \
    -v $PWD:/home imagename/imagename \
    spyder
```

But I'm getting the following error...

```
root@350X:/home# spyder
Could not load the Qt platform plugin ""xcb"" in """" even though it was found.
This application failed to start because no Qt platform plugin could be initialized. Reinstalling the application may fix this problem.

Available platform plugins are: eglfs, linuxfb, minimal, minimalegl, offscreen, vnc, wayland-egl, wayland, wayland-xcomposite-egl, wayland-xcomposite-glx, webgl, xcb.

Aborted (core dumped)
```

Any ideas how could I open GUIs on the host machine using the TensorFlow docker image ?
I tried reinstalling the application and getting these plugins but had no success in opening GUIs.
"
55345,How to convert Keras LSTM model into tf.nn.rnn_cell.LSTMCell model,"I have trained a LSTM model on pytorch, and converted it into Keras lstm model with `set_weights` method. The performance looks almost the same. However, I need to convert the model into lstm model with older tensorflow version (V1.xx), by using `tf.nn.rnn_cell.LSTMCell` method. What confused me was that I did not find any method that can load lstm weights from numpy like arrays. The only method I find is loading saved checkpoints, but not suitable for me.
Any suggestion for me? Thanks."
55344,Can't link with TF Lite C API static lib - undefined reference to `tflite::DefaultErrorReporter()',"I've built the TensorFlow Lite **static** library, the **C API** version. Cloned [the sources][1] and called CMake while turning OFF the shared build flag (`DTFLITE_C_BUILD_SHARED_LIBS:BOOL=OFF`):  
```
cmake -S ../tensorflow_src/tensorflow/lite/c -DTFLITE_C_BUILD_SHARED_LIBS:BOOL=OFF
cmake --build . -j
```
This built the `libtensorflowlite_c.a`. 

I also linked all other `.a` sub-dependencies from the `_dep` directory into a single `libtensorflowdep.a` library (this includes `absl`, `clog` and all other transient dependencies listed here in the [TensorFlow CMake file][2]).

I tried to test the lib using a minimal example: 
```C
#include <stdio.h>
#include ""tensorflow/lite/c/c_api.h""

int main(void) {
	printf(""Hello!"");

	const char *version = TfLiteVersion();
	printf(""Hello from TensorFlow Lite C API library version = %s\n"", version);

	return 0;
}
```

`gcc -L""/home/joedoe/out/subprojects/tensorflow"" -o ""MAIN""  ./src/MAIN.o   -ltensorflowlite_c -ltensorflowdep`

But linking fails:

```
/usr/bin/ld: /home/joedoe/out/subprojects/tensorflow/libtensorflowlite_c.a(c_api.cc.o): in function `TfLiteModelCreate':
c_api.cc:(.text+0x210): undefined reference to `tflite::DefaultErrorReporter()'
/usr/bin/ld: c_api.cc:(.text+0x22f): undefined reference to `tflite::FlatBufferModel::VerifyAndBuildFromBuffer(char const*, unsigned long, tflite::TfLiteVerifier*, tflite::ErrorReporter*)'
/usr/bin/ld: c_api.cc:(.text+0x276): undefined reference to `operator new(unsigned long)'
/usr/bin/ld: /home/joedoe/out/subprojects/tensorflow/libtensorflowlite_c.a(c_api.cc.o): in function `TfLiteModelCreateFromFile':
c_api.cc:(.text+0x322): undefined reference to `tflite::DefaultErrorReporter()'
/usr/bin/ld: c_api.cc:(.text+0x33d): undefined reference to `tflite::FlatBufferModel::VerifyAndBuildFromFile(char const*, tflite::TfLiteVerifier*, tflite::ErrorReporter*)'
/usr/bin/ld: c_api.cc:(.text+0x384): undefined reference to `operator new(unsigned long)'
/usr/bin/ld: /home/joedoe/out/subprojects/tensorflow/libtensorflowlite_c.a(c_api.cc.o): in function `TfLiteModelDelete':
c_api.cc:(.text+0x433): undefined reference to `operator delete(void*)'
/usr/bin/ld: /home/joedoe/out/subprojects/tensorflow/libtensorflowlite_c.a(c_api.cc.o): in function `TfLiteInterpreterOptionsCreate':
c_api.cc:(.text+0x452): undefined reference to `operator new(unsigned long)'
/usr/bin/ld: /home/joedoe/out/subprojects/tensorflow/libtensorflowlite_c.a(c_api.cc.o): in function `TfLiteInterpreterOptionsDelete':
c_api.cc:(.text+0x4a7): undefined reference to `operator delete(void*)'
/usr/bin/ld: /home/joedoe/out/subprojects/tensorflow/libtensorflowlite_c.a(c_api.cc.o): in function `TfLiteInterpreterCreate':
c_api.cc:(.text+0x560): undefined reference to `tflite::CreateOpResolver()'
/usr/bin/ld: /home/joedoe/out/subprojects/tensorflow/libtensorflowlite_c.a(c_api.cc.o): in function `TfLiteInterpreterDelete':
c_api.cc:(.text+0x5fa): undefined reference to `operator delete(void*)'
/usr/bin/ld: /home/joedoe/out/subprojects/tensorflow/libtensorflowlite_c.a(c_api.cc.o): in function `TfLiteInterpreterResizeInputTensor':
c_api.cc:(.text+0x75a): undefined reference to `tflite::Interpreter::ResizeInputTensor(int, std::vector<int, std::allocator<int> > const&)'
/usr/bin/ld: /home/joedoe/out/subprojects/tensorflow/libtensorflowlite_c.a(c_api.cc.o): in function `TfLiteInterpreterAllocateTensors':
c_api.cc:(.text+0x7ee): undefined reference to `tflite::Interpreter::AllocateTensors()'
/usr/bin/ld: /home/joedoe/out/subprojects/tensorflow/libtensorflowlite_c.a(c_api.cc.o): in function `TfLiteInterpreterInvoke':
c_api.cc:(.text+0x824): undefined reference to `tflite::delegates::InterpreterUtils::InvokeWithCPUFallback(tflite::Interpreter*)'
/usr/bin/ld: c_api.cc:(.text+0x83e): undefined reference to `tflite::Interpreter::Invoke()'
/usr/bin/ld: /home/joedoe/out/subprojects/tensorflow/libtensorflowlite_c.a(c_api.cc.o): in function `tflite::internal::InterpreterCreateWithOpResolver(TfLiteModel const*, TfLiteInterpreterOptions const*, tflite::MutableOpResolver*)':
c_api.cc:(.text+0xaf5): undefined reference to `operator new(unsigned long)'
/usr/bin/ld: c_api.cc:(.text+0xb5b): undefined reference to `tflite::MutableOpResolver::AddAll(tflite::MutableOpResolver const&)'
/usr/bin/ld: c_api.cc:(.text+0xbf1): undefined reference to `tflite::DefaultErrorReporter()'
/usr/bin/ld: c_api.cc:(.text+0xc2f): undefined reference to `tflite::InterpreterBuilder::InterpreterBuilder(tflite::Model const*, tflite::OpResolver const&, tflite::ErrorReporter*)'
/usr/bin/ld: c_api.cc:(.text+0xc53): undefined reference to `tflite::InterpreterBuilder::operator()(std::unique_ptr<tflite::Interpreter, std::default_delete<tflite::Interpreter> >*)'
/usr/bin/ld: c_api.cc:(.text+0xca7): undefined reference to `tflite::Interpreter::SetNumThreads(int)'
/usr/bin/ld: c_api.cc:(.text+0xcd0): undefined reference to `tflite::NnApiDelegate()'
/usr/bin/ld: c_api.cc:(.text+0xcdb): undefined reference to `tflite::Interpreter::ModifyGraphWithDelegate(TfLiteDelegate*)'
/usr/bin/ld: c_api.cc:(.text+0xd88): undefined reference to `tflite::Interpreter::ModifyGraphWithDelegate(TfLiteDelegate*)'
/usr/bin/ld: c_api.cc:(.text+0xe08): undefined reference to `operator new(unsigned long)'
/usr/bin/ld: c_api.cc:(.text+0xe67): undefined reference to `tflite::InterpreterBuilder::~InterpreterBuilder()'
/usr/bin/ld: c_api.cc:(.text+0xebe): undefined reference to `tflite::InterpreterBuilder::~InterpreterBuilder()'
/usr/bin/ld: /home/joedoe/out/subprojects/tensorflow/libtensorflowlite_c.a(c_api.cc.o): in function `(anonymous namespace)::CallbackOpResolver::~CallbackOpResolver()':
c_api.cc:(.text+0xf62): undefined reference to `operator delete(void*)'
/usr/bin/ld: /home/joedoe/out/subprojects/tensorflow/libtensorflowlite_c.a(c_api.cc.o): in function `(anonymous namespace)::CallbackErrorReporter::~CallbackErrorReporter()':
c_api.cc:(.text+0xfba): undefined reference to `operator delete(void*)'
/usr/bin/ld: /home/joedoe/out/subprojects/tensorflow/libtensorflowlite_c.a(c_api.cc.o):(.data.rel.ro+0x8): undefined reference to `vtable for __cxxabiv1::__si_class_type_info'
/usr/bin/ld: /home/joedoe/out/subprojects/tensorflow/libtensorflowlite_c.a(c_api.cc.o):(.data.rel.ro+0x20): undefined reference to `vtable for __cxxabiv1::__si_class_type_info'
/usr/bin/ld: /home/joedoe/out/subprojects/tensorflow/libtensorflowlite_c.a(c_api.cc.o): in function `tflite::ErrorReporter::~ErrorReporter()':
c_api.cc:(.text._ZN6tflite13ErrorReporterD0Ev[_ZN6tflite13ErrorReporterD5Ev]+0x24): undefined reference to `operator delete(void*)'
/usr/bin/ld: /home/joedoe/out/subprojects/tensorflow/libtensorflowlite_c.a(c_api.cc.o): in function `tflite::OpResolver::~OpResolver()':
c_api.cc:(.text._ZN6tflite10OpResolverD0Ev[_ZN6tflite10OpResolverD5Ev]+0x24): undefined reference to `operator delete(void*)'
/usr/bin/ld: /home/joedoe/out/subprojects/tensorflow/libtensorflowlite_c.a(c_api.cc.o): in function `tflite::MutableOpResolver::MutableOpResolver()':
c_api.cc:(.text._ZN6tflite17MutableOpResolverC2Ev[_ZN6tflite17MutableOpResolverC5Ev]+0x1f): undefined reference to `vtable for tflite::MutableOpResolver'
/usr/bin/ld: /home/joedoe/out/subprojects/tensorflow/libtensorflowlite_c.a(c_api.cc.o): in function `std::default_delete<tflite::FlatBufferModel>::operator()(tflite::FlatBufferModel*) const':
c_api.cc:(.text._ZNKSt14default_deleteIN6tflite15FlatBufferModelEEclEPS1_[_ZNKSt14default_deleteIN6tflite15FlatBufferModelEEclEPS1_]+0x22): undefined reference to `tflite::FlatBufferModel::~FlatBufferModel()'
/usr/bin/ld: c_api.cc:(.text._ZNKSt14default_deleteIN6tflite15FlatBufferModelEEclEPS1_[_ZNKSt14default_deleteIN6tflite15FlatBufferModelEEclEPS1_]+0x2a): undefined reference to `operator delete(void*)'
/usr/bin/ld: /home/joedoe/out/subprojects/tensorflow/libtensorflowlite_c.a(c_api.cc.o): in function `void std::vector<TfLiteDelegate*, std::allocator<TfLiteDelegate*> >::_M_realloc_insert<TfLiteDelegate* const&>(__gnu_cxx::__normal_iterator<TfLiteDelegate**, std::vector<TfLiteDelegate*, std::allocator<TfLiteDelegate*> > >, TfLiteDelegate* const&)':
c_api.cc:(.text._ZNSt6vectorIP14TfLiteDelegateSaIS1_EE17_M_realloc_insertIJRKS1_EEEvN9__gnu_cxx17__normal_iteratorIPS1_S3_EEDpOT_[_ZNSt6vectorIP14TfLiteDelegateSaIS1_EE17_M_realloc_insertIJRKS1_EEEvN9__gnu_cxx17__normal_iteratorIPS1_S3_EEDpOT_]+0x267): undefined reference to `__cxa_begin_catch'
/usr/bin/ld: c_api.cc:(.text._ZNSt6vectorIP14TfLiteDelegateSaIS1_EE17_M_realloc_insertIJRKS1_EEEvN9__gnu_cxx17__normal_iteratorIPS1_S3_EEDpOT_[_ZNSt6vectorIP14TfLiteDelegateSaIS1_EE17_M_realloc_insertIJRKS1_EEEvN9__gnu_cxx17__normal_iteratorIPS1_S3_EEDpOT_]+0x2d0): undefined reference to `__cxa_rethrow'
/usr/bin/ld: c_api.cc:(.text._ZNSt6vectorIP14TfLiteDelegateSaIS1_EE17_M_realloc_insertIJRKS1_EEEvN9__gnu_cxx17__normal_iteratorIPS1_S3_EEDpOT_[_ZNSt6vectorIP14TfLiteDelegateSaIS1_EE17_M_realloc_insertIJRKS1_EEEvN9__gnu_cxx17__normal_iteratorIPS1_S3_EEDpOT_]+0x2dc): undefined reference to `__cxa_end_catch'
/usr/bin/ld: /home/joedoe/out/subprojects/tensorflow/libtensorflowlite_c.a(c_api.cc.o): in function `tflite::MutableOpResolver::~MutableOpResolver()':
c_api.cc:(.text._ZN6tflite17MutableOpResolverD2Ev[_ZN6tflite17MutableOpResolverD5Ev]+0x13): undefined reference to `vtable for tflite::MutableOpResolver'
/usr/bin/ld: /home/joedoe/out/subprojects/tensorflow/libtensorflowlite_c.a(c_api.cc.o): in function `tflite::MutableOpResolver::~MutableOpResolver()':
c_api.cc:(.text._ZN6tflite17MutableOpResolverD0Ev[_ZN6tflite17MutableOpResolverD5Ev]+0x24): undefined reference to `operator delete(void*)'
/usr/bin/ld: /home/joedoe/out/subprojects/tensorflow/libtensorflowlite_c.a(c_api.cc.o): in function `std::default_delete<tflite::Interpreter>::operator()(tflite::Interpreter*) const':
c_api.cc:(.text._ZNKSt14default_deleteIN6tflite11InterpreterEEclEPS1_[_ZNKSt14default_deleteIN6tflite11InterpreterEEclEPS1_]+0x22): undefined reference to `tflite::Interpreter::~Interpreter()'
/usr/bin/ld: c_api.cc:(.text._ZNKSt14default_deleteIN6tflite11InterpreterEEclEPS1_[_ZNKSt14default_deleteIN6tflite11InterpreterEEclEPS1_]+0x2a): undefined reference to `operator delete(void*)'
/usr/bin/ld: /home/joedoe/out/subprojects/tensorflow/libtensorflowlite_c.a(c_api.cc.o): in function `std::vector<TfLiteDelegate*, std::allocator<TfLiteDelegate*> >::_M_check_len(unsigned long, char const*) const':
c_api.cc:(.text._ZNKSt6vectorIP14TfLiteDelegateSaIS1_EE12_M_check_lenEmPKc[_ZNKSt6vectorIP14TfLiteDelegateSaIS1_EE12_M_check_lenEmPKc]+0x5f): undefined reference to `std::__throw_length_error(char const*)'
/usr/bin/ld: /home/joedoe/out/subprojects/tensorflow/libtensorflowlite_c.a(c_api.cc.o): in function `std::vector<int, std::allocator<int> >::_S_check_init_len(unsigned long, std::allocator<int> const&)':
c_api.cc:(.text._ZNSt6vectorIiSaIiEE17_S_check_init_lenEmRKS0_[_ZNSt6vectorIiSaIiEE17_S_check_init_lenEmRKS0_]+0x62): undefined reference to `std::__throw_length_error(char const*)'
/usr/bin/ld: /home/joedoe/out/subprojects/tensorflow/libtensorflowlite_c.a(c_api.cc.o): in function `__gnu_cxx::new_allocator<int>::deallocate(int*, unsigned long)':
c_api.cc:(.text._ZN9__gnu_cxx13new_allocatorIiE10deallocateEPim[_ZN9__gnu_cxx13new_allocatorIiE10deallocateEPim]+0x20): undefined reference to `operator delete(void*)'
/usr/bin/ld: /home/joedoe/out/subprojects/tensorflow/libtensorflowlite_c.a(c_api.cc.o): in function `__gnu_cxx::new_allocator<std::function<std::unique_ptr<TfLiteDelegate, void (*)(TfLiteDelegate*)> (int)> >::deallocate(std::function<std::unique_ptr<TfLiteDelegate, void (*)(TfLiteDelegate*)> (int)>*, unsigned long)':
c_api.cc:(.text._ZN9__gnu_cxx13new_allocatorISt8functionIFSt10unique_ptrI14TfLiteDelegatePFvPS3_EEiEEE10deallocateEPS9_m[_ZN9__gnu_cxx13new_allocatorISt8functionIFSt10unique_ptrI14TfLiteDelegatePFvPS3_EEiEEE10deallocateEPS9_m]+0x20): undefined reference to `operator delete(void*)'
/usr/bin/ld: /home/joedoe/out/subprojects/tensorflow/libtensorflowlite_c.a(c_api.cc.o): in function `std::__shared_count<(__gnu_cxx::_Lock_policy)2>::__shared_count<tflite::FlatBufferModel*>(tflite::FlatBufferModel*)':
c_api.cc:(.text._ZNSt14__shared_countILN9__gnu_cxx12_Lock_policyE2EEC2IPN6tflite15FlatBufferModelEEET_[_ZNSt14__shared_countILN9__gnu_cxx12_Lock_policyE2EEC5IPN6tflite15FlatBufferModelEEET_]+0x26): undefined reference to `operator new(unsigned long)'
/usr/bin/ld: c_api.cc:(.text._ZNSt14__shared_countILN9__gnu_cxx12_Lock_policyE2EEC2IPN6tflite15FlatBufferModelEEET_[_ZNSt14__shared_countILN9__gnu_cxx12_Lock_policyE2EEC5IPN6tflite15FlatBufferModelEEET_]+0x4d): undefined reference to `__cxa_begin_catch'
/usr/bin/ld: c_api.cc:(.text._ZNSt14__shared_countILN9__gnu_cxx12_Lock_policyE2EEC2IPN6tflite15FlatBufferModelEEET_[_ZNSt14__shared_countILN9__gnu_cxx12_Lock_policyE2EEC5IPN6tflite15FlatBufferModelEEET_]+0x5e): undefined reference to `tflite::FlatBufferModel::~FlatBufferModel()'
/usr/bin/ld: c_api.cc:(.text._ZNSt14__shared_countILN9__gnu_cxx12_Lock_policyE2EEC2IPN6tflite15FlatBufferModelEEET_[_ZNSt14__shared_countILN9__gnu_cxx12_Lock_policyE2EEC5IPN6tflite15FlatBufferModelEEET_]+0x66): undefined reference to `operator delete(void*)'
/usr/bin/ld: c_api.cc:(.text._ZNSt14__shared_countILN9__gnu_cxx12_Lock_policyE2EEC2IPN6tflite15FlatBufferModelEEET_[_ZNSt14__shared_countILN9__gnu_cxx12_Lock_policyE2EEC5IPN6tflite15FlatBufferModelEEET_]+0x6b): undefined reference to `__cxa_rethrow'
/usr/bin/ld: c_api.cc:(.text._ZNSt14__shared_countILN9__gnu_cxx12_Lock_policyE2EEC2IPN6tflite15FlatBufferModelEEET_[_ZNSt14__shared_countILN9__gnu_cxx12_Lock_policyE2EEC5IPN6tflite15FlatBufferModelEEET_]+0x77): undefined reference to `__cxa_end_catch'
/usr/bin/ld: /home/joedoe/out/subprojects/tensorflow/libtensorflowlite_c.a(c_api.cc.o): in function `std::_Sp_counted_base<(__gnu_cxx::_Lock_policy)2>::~_Sp_counted_base()':
c_api.cc:(.text._ZNSt16_Sp_counted_baseILN9__gnu_cxx12_Lock_policyE2EED0Ev[_ZNSt16_Sp_counted_baseILN9__gnu_cxx12_Lock_policyE2EED5Ev]+0x24): undefined reference to `operator delete(void*)'
/usr/bin/ld: /home/joedoe/out/subprojects/tensorflow/libtensorflowlite_c.a(c_api.cc.o): in function `__gnu_cxx::new_allocator<tflite::OpResolver const*>::deallocate(tflite::OpResolver const**, unsigned long)':
c_api.cc:(.text._ZN9__gnu_cxx13new_allocatorIPKN6tflite10OpResolverEE10deallocateEPS4_m[_ZN9__gnu_cxx13new_allocatorIPKN6tflite10OpResolverEE10deallocateEPS4_m]+0x20): undefined reference to `operator delete(void*)'
/usr/bin/ld: /home/joedoe/out/subprojects/tensorflow/libtensorflowlite_c.a(c_api.cc.o): in function `__gnu_cxx::new_allocator<TfLiteDelegate*>::deallocate(TfLiteDelegate**, unsigned long)':
c_api.cc:(.text._ZN9__gnu_cxx13new_allocatorIP14TfLiteDelegateE10deallocateEPS2_m[_ZN9__gnu_cxx13new_allocatorIP14TfLiteDelegateE10deallocateEPS2_m]+0x20): undefined reference to `operator delete(void*)'
/usr/bin/ld: /home/joedoe/out/subprojects/tensorflow/libtensorflowlite_c.a(c_api.cc.o): in function `__gnu_cxx::new_allocator<int>::allocate(unsigned long, void const*)':
c_api.cc:(.text._ZN9__gnu_cxx13new_allocatorIiE8allocateEmPKv[_ZN9__gnu_cxx13new_allocatorIiE8allocateEmPKv]+0x30): undefined reference to `std::__throw_bad_alloc()'
/usr/bin/ld: c_api.cc:(.text._ZN9__gnu_cxx13new_allocatorIiE8allocateEmPKv[_ZN9__gnu_cxx13new_allocatorIiE8allocateEmPKv]+0x40): undefined reference to `operator new(unsigned long)'
/usr/bin/ld: /home/joedoe/out/subprojects/tensorflow/libtensorflowlite_c.a(c_api.cc.o): in function `__gnu_cxx::new_allocator<TfLiteDelegate*>::allocate(unsigned long, void const*)':
c_api.cc:(.text._ZN9__gnu_cxx13new_allocatorIP14TfLiteDelegateE8allocateEmPKv[_ZN9__gnu_cxx13new_allocatorIP14TfLiteDelegateE8allocateEmPKv]+0x30): undefined reference to `std::__throw_bad_alloc()'
/usr/bin/ld: c_api.cc:(.text._ZN9__gnu_cxx13new_allocatorIP14TfLiteDelegateE8allocateEmPKv[_ZN9__gnu_cxx13new_allocatorIP14TfLiteDelegateE8allocateEmPKv]+0x40): undefined reference to `operator new(unsigned long)'
/usr/bin/ld: /home/joedoe/out/subprojects/tensorflow/libtensorflowlite_c.a(c_api.cc.o): in function `__gnu_cxx::new_allocator<std::__detail::_Hash_node_base*>::deallocate(std::__detail::_Hash_node_base**, unsigned long)':
c_api.cc:(.text._ZN9__gnu_cxx13new_allocatorIPNSt8__detail15_Hash_node_baseEE10deallocateEPS3_m[_ZN9__gnu_cxx13new_allocatorIPNSt8__detail15_Hash_node_baseEE10deallocateEPS3_m]+0x20): undefined reference to `operator delete(void*)'
/usr/bin/ld: /home/joedoe/out/subprojects/tensorflow/libtensorflowlite_c.a(c_api.cc.o): in function `std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, int>::~pair()':
c_api.cc:(.text._ZNSt4pairINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEiED2Ev[_ZNSt4pairINSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEiED5Ev]+0x18): undefined reference to `std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >::~basic_string()'
/usr/bin/ld: /home/joedoe/out/subprojects/tensorflow/libtensorflowlite_c.a(c_api.cc.o): in function `__gnu_cxx::new_allocator<std::__detail::_Hash_node<std::pair<std::pair<tflite::BuiltinOperator, int> const, TfLiteRegistration>, true> >::deallocate(std::__detail::_Hash_node<std::pair<std::pair<tflite::BuiltinOperator, int> const, TfLiteRegistration>, true>*, unsigned long)':
c_api.cc:(.text._ZN9__gnu_cxx13new_allocatorINSt8__detail10_Hash_nodeISt4pairIKS3_IN6tflite15BuiltinOperatorEiE18TfLiteRegistrationELb1EEEE10deallocateEPSA_m[_ZN9__gnu_cxx13new_allocatorINSt8__detail10_Hash_nodeISt4pairIKS3_IN6tflite15BuiltinOperatorEiE18TfLiteRegistrationELb1EEEE10deallocateEPSA_m]+0x20): undefined reference to `operator delete(void*)'
/usr/bin/ld: /home/joedoe/out/subprojects/tensorflow/libtensorflowlite_c.a(c_api.cc.o): in function `__gnu_cxx::new_allocator<std::__detail::_Hash_node<std::pair<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, int> const, TfLiteRegistration>, true> >::deallocate(std::__detail::_Hash_node<std::pair<std::pair<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, int> const, TfLiteRegistration>, true>*, unsigned long)':
c_api.cc:(.text._ZN9__gnu_cxx13new_allocatorINSt8__detail10_Hash_nodeISt4pairIKS3_INSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEiE18TfLiteRegistrationELb1EEEE10deallocateEPSE_m[_ZN9__gnu_cxx13new_allocatorINSt8__detail10_Hash_nodeISt4pairIKS3_INSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEEiE18TfLiteRegistrationELb1EEEE10deallocateEPSE_m]+0x20): undefined reference to `operator delete(void*)'
/usr/bin/ld: /home/joedoe/out/subprojects/tensorflow/libtensorflowlite_c.a(c_api.cc.o): in function `std::_Sp_counted_ptr<tflite::FlatBufferModel*, (__gnu_cxx::_Lock_policy)2>::~_Sp_counted_ptr()':
c_api.cc:(.text._ZNSt15_Sp_counted_ptrIPN6tflite15FlatBufferModelELN9__gnu_cxx12_Lock_policyE2EED0Ev[_ZNSt15_Sp_counted_ptrIPN6tflite15FlatBufferModelELN9__gnu_cxx12_Lock_policyE2EED5Ev]+0x24): undefined reference to `operator delete(void*)'
/usr/bin/ld: /home/joedoe/out/subprojects/tensorflow/libtensorflowlite_c.a(c_api.cc.o):(.data.rel.ro._ZTVN6tflite10OpResolverE[_ZTVN6tflite10OpResolverE]+0x10): undefined reference to `__cxa_pure_virtual'
/usr/bin/ld: /home/joedoe/out/subprojects/tensorflow/libtensorflowlite_c.a(c_api.cc.o):(.data.rel.ro._ZTVN6tflite10OpResolverE[_ZTVN6tflite10OpResolverE]+0x18): undefined reference to `__cxa_pure_virtual'
/usr/bin/ld: /home/joedoe/out/subprojects/tensorflow/libtensorflowlite_c.a(c_api.cc.o):(.data.rel.ro._ZTVN6tflite13ErrorReporterE[_ZTVN6tflite13ErrorReporterE]+0x20): undefined reference to `__cxa_pure_virtual'
/usr/bin/ld: /home/joedoe/out/subprojects/tensorflow/libtensorflowlite_c.a(c_api.cc.o):(.data.rel.ro._ZTVSt16_Sp_counted_baseILN9__gnu_cxx12_Lock_policyE2EE[_ZTVSt16_Sp_counted_baseILN9__gnu_cxx12_Lock_policyE2EE]+0x20): undefined reference to `__cxa_pure_virtual'
/usr/bin/ld: /home/joedoe/out/subprojects/tensorflow/libtensorflowlite_c.a(c_api.cc.o):(.data.rel.ro._ZTVSt16_Sp_counted_baseILN9__gnu_cxx12_Lock_policyE2EE[_ZTVSt16_Sp_counted_baseILN9__gnu_cxx12_Lock_policyE2EE]+0x30): undefined reference to `__cxa_pure_virtual'
/usr/bin/ld: /home/joedoe/out/subprojects/tensorflow/libtensorflowlite_c.a(c_api.cc.o):(.data.rel.ro._ZTISt15_Sp_counted_ptrIPN6tflite15FlatBufferModelELN9__gnu_cxx12_Lock_policyE2EE[_ZTISt15_Sp_counted_ptrIPN6tflite15FlatBufferModelELN9__gnu_cxx12_Lock_policyE2EE]+0x0): undefined reference to `vtable for __cxxabiv1::__si_class_type_info'
/usr/bin/ld: /home/joedoe/out/subprojects/tensorflow/libtensorflowlite_c.a(c_api.cc.o):(.data.rel.ro._ZTIN6tflite10OpResolverE[_ZTIN6tflite10OpResolverE]+0x0): undefined reference to `vtable for __cxxabiv1::__class_type_info'
/usr/bin/ld: /home/joedoe/out/subprojects/tensorflow/libtensorflowlite_c.a(c_api.cc.o):(.data.rel.ro._ZTIN6tflite13ErrorReporterE[_ZTIN6tflite13ErrorReporterE]+0x0): undefined reference to `vtable for __cxxabiv1::__class_type_info'
/usr/bin/ld: /home/joedoe/out/subprojects/tensorflow/libtensorflowlite_c.a(c_api.cc.o):(.data.rel.ro._ZTISt16_Sp_counted_baseILN9__gnu_cxx12_Lock_policyE2EE[_ZTISt16_Sp_counted_baseILN9__gnu_cxx12_Lock_policyE2EE]+0x0): undefined reference to `vtable for __cxxabiv1::__si_class_type_info'
/usr/bin/ld: /home/joedoe/out/subprojects/tensorflow/libtensorflowlite_c.a(c_api.cc.o): in function `std::_Sp_counted_ptr<tflite::FlatBufferModel*, (__gnu_cxx::_Lock_policy)2>::_M_dispose()':
c_api.cc:(.text._ZNSt15_Sp_counted_ptrIPN6tflite15FlatBufferModelELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv[_ZNSt15_Sp_counted_ptrIPN6tflite15FlatBufferModelELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv]+0x22): undefined reference to `tflite::FlatBufferModel::~FlatBufferModel()'
/usr/bin/ld: c_api.cc:(.text._ZNSt15_Sp_counted_ptrIPN6tflite15FlatBufferModelELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv[_ZNSt15_Sp_counted_ptrIPN6tflite15FlatBufferModelELN9__gnu_cxx12_Lock_policyE2EE10_M_disposeEv]+0x2a): undefined reference to `operator delete(void*)'
/usr/bin/ld: /home/joedoe/out/subprojects/tensorflow/libtensorflowlite_c.a(c_api.cc.o):(.data.rel.ro._ZTISt11_Mutex_baseILN9__gnu_cxx12_Lock_policyE2EE[_ZTISt11_Mutex_baseILN9__gnu_cxx12_Lock_policyE2EE]+0x0): undefined reference to `vtable for __cxxabiv1::__class_type_info'
/usr/bin/ld: /home/joedoe/out/subprojects/tensorflow/libtensorflowlite_c.a(c_api.cc.o):(.data.rel.local.DW.ref.__gxx_personality_v0[DW.ref.__gxx_personality_v0]+0x0): undefined reference to `__gxx_personality_v0'
collect2: error: ld returned 1 exit status
make: *** [makefile:45: TF] Error 1
```

  [1]: https://github.com/tensorflow/tensorflow
  [2]: https://github.com/tensorflow/tensorflow/blob/e41d9eb9edcc1ff2cf52736edde76e6f5d62f6ed/tensorflow/lite/CMakeLists.txt#L139"
55343,"Normalization and BatchNormalization layer does not rescale or normalize inputs, am I missing anything?","**System information**

colab with tf-2.8
[old-tf_env.txt](https://github.com/tensorflow/tensorflow/files/8330439/old-tf_env.txt)

---

**Describe the current behavior**

Normalization and Batch Normalization layer does not rescale or normalize inputs as excepted, the inputs barely not changing.

---


**Standalone code to reproduce the issue**


## Tensorflow:

###  Normalization layer
```python
tfdata = np.array([[1,2,3,4,5]],dtype=float)
print(""tfdata:"" ,tfdata)
print(""avg: "", np.average(tfdata))
print(""var: "", np.var(tfdata))
```
>tfdata: [[1. 2. 3. 4. 5.]]
avg:  3.0
var:  2.0



```python
normalization_layer = tf.keras.layers.Normalization(axis=-1)
normalized_data = normalization_layer(tfdata)
print(normalized_data.numpy())
print(""normalized avg: "", np.average(normalized_data.numpy()))
print(""normalized var: "", np.var(normalized_data.numpy()))
```
**output:** 

>[[1. 2. 3. 4. 5.]]
normalized avg:  3.0
normalized var:  2.0

**This output is unchanged**


### BatchNormalization layer

```python

batch_normalization_layer = tf.keras.layers.BatchNormalization(axis=-1,scale=True,center=True)
batch_normalized_data = batch_normalization_layer(tfdata)
print(batch_normalized_data.numpy())
print(""batch normalized avg: "", np.average(batch_normalized_data.numpy()))
print(""batch normalized var: "", np.var(batch_normalized_data.numpy()))
```
**output:**
>[[0.9995004 1.9990008 2.9985013 3.9980016 4.997502 ]]
batch normalized avg:  2.9985013
batch normalized var:  1.9980018

---

**This output still unchanged!**

## Torch:

### LayerNorm

```python
tdata = torch.tensor([1,2,3,4,5],dtype=torch.float32)
normalization_layer=torch.nn.LayerNorm(normalized_shape=[5])
normalized_data = normalization_layer(tdata).detach().numpy()
print(normalized_data)
print(""normalized avg: "", np.average(normalized_data))
print(""normalized var: "", np.var(normalized_data))
```

**output**

>[-1.4142101  -0.70710504 -0.00000006  0.7071049   1.4142098 ]
normalized avg:  -4.7683717e-08
normalized var:  0.9999949

normalized av closed to 0, and normalized var close to 1, correct answer.

and BatchNormalization ... all the same
"
55341,Error Cannot copy to a TensorFlowLite tensor,"When i traid to process my model  got this error:
`java.lang.IllegalArgumentException: Cannot copy to a TensorFlowLite tensor (serving_default_conv2d_input:0) with 90000 bytes from a Java Buffer with 22500 bytes.`

Here are the libraries i'm using:
`implementation 'org.tensorflow:tensorflow-lite:2.8.0'`
   ` implementation 'org.tensorflow:tensorflow-lite-support:0.3.1'`
    `implementation 'org.tensorflow:tensorflow-lite-metadata:0.3.1'`

[Here ](https://i.stack.imgur.com/1njLj.png)you can see my model properties:

I'm traing to config the output of this way, i'm not sure if is of this way..
`val p = photoFile.data!!.extras!!.get(""data"") as Bitmap`
            `val tensorImage = TensorImage.fromBitmap(p)`
            `val model = Modelo.newInstance(applicationContext)1`
            `val imageProcessor: ImageProcessor = ImageProcessor.Builder()`
                `.add(ResizeOp(150, 150, ResizeOp.ResizeMethod.NEAREST_NEIGHBOR))`
                `.add(TransformToGrayscaleOp())`
                `.add(NormalizeOp(0f,255f))`
                `.build()`
            `imageProcessor.process(tensorImage)`
"
55340,Autovectorization fail with tf.vectorized_map and range,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Colab
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: 
- TensorFlow installed from (source or binary):
Binary
- TensorFlow version (use command below):
Nightly
- Python version:
Colab
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
```python
import tensorflow as tf
tf.autograph.set_verbosity(10)
def outer_product(a):
  for i in tf.range(10):
    pass
  return tf.tensordot(a, a, 0)

@tf.function
def vectorized(a):
  return tf.vectorized_map(outer_product, a)  

batch_size = 100
a = tf.ones((batch_size, 32, 32))
c = vectorized(a)
assert c.shape == (batch_size, 32, 32, 32, 32)
```

```
OperatorNotAllowedInGraphError: iterating over `tf.Tensor` is not allowed: AutoGraph did convert this function. This might indicate you are trying to use an unsupported feature.
```
**Describe the expected behavior**

**[Contributing](https://www.tensorflow.org/community/contribute)**

- Do you want to contribute a PR? (yes/no):
- Briefly describe your candidate solution(if contributing):

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
55338,Tensorflow installation in venv results in RuntimeError when importing the library,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 20.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): Using pip
- TensorFlow version: Latest (cannot determine version after installation)
- Python version: 3.8.10
- Installed using virtualenv? pip? conda?: Using pip, inside venv
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:



**Describe the problem**
When trying to install Tensorflow using pip inside a virtual environment, installation completes, but importing the library results in a RuntimeError.

**Provide the exact sequence of commands / steps that you executed before running into the problem**
1. `python3 -m venv venv`
2. `. venv/bin/activate`
3. `python3 -m pip install tensorflow`
4. `python3 -c ""import tensorflow as tf; print(tf.__version__)""`

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

First 3 steps work as expected, 4th step results in the following errors:
```
RuntimeError: module compiled against API version 0xe but this version of numpy is 0xd.
...
ImportError: SystemError: <built-in method __contains__ of dict object at 0x7f47294d6b80> returned a result with an error set
```
I have tried manually upgrading numpy, but that didn't resolve my issue.
"
55336,undefined references on tflite x86_64 cross compiled with NDK Android toolchain,"
**System information**
- OS Platform and Distribution: Linux Ubuntu 21.04
- TensorFlow version: 2.8.0
- GCC/Compiler version: Clang 9.0.8, from Android NDK 21.3.6528147


**Describe the problem**

I'm able to build `libtensorflow-lite.a` for Android x86_64, but when I try to link the library I get
```
error: undefined reference to 'xnn_setup_runtime'
```
If I build the lib without XNN delegate support, I got an error on NNAPI. If also disable NNAPI, I got undefined reference errors for ryu related functions. It seems like that all the delegate symbols in the built static library are undefined.


**Provide the exact sequence of commands / steps that you executed before running into the problem**

to build  `libtensorflow-lite.a`:
```
mkdir build
cd build
cmake -DCMAKE_TOOLCHAIN_FILE=~/Android/Sdk/ndk/21.3.6528147/build/cmake/android.toolchain.cmake -DANDROID_ABI=x86_64  ../tensorflow/lite
make -j12
```
later linked using CMake on an Android project with `target_link_libraries(...)`.



**Any other info / logs**

output of `nm -C libtensorflow-lite.a | grep xnn`:
```
0000000000000000 T tflite::xnnpack::DequantizeInt8(signed char const*, float*, tflite::RuntimeShape const&, int, double)
0000000000000000 T tflite::xnnpack::DequantizeFloat16(unsigned short const*, float*, unsigned long)
0000000000000000 T tflite::xnnpack::PerChannelDequantizeInt8(signed char const*, float*, tflite::RuntimeShape const&, int const*, float const*, int)
xnnpack_delegate.cc.o:
                 U xnn_create_runtime_v2
                 U xnn_create_subgraph
                 U xnn_define_abs
                 U xnn_define_add2
                 U xnn_define_argmax_pooling_2d
                 U xnn_define_average_pooling_2d
                 U xnn_define_bankers_rounding
                 U xnn_define_ceiling
                 U xnn_define_channelwise_quantized_tensor_value
                 U xnn_define_clamp
                 U xnn_define_convert
                 U xnn_define_convolution_2d
                 U xnn_define_deconvolution_2d
                 U xnn_define_depth_to_space
                 U xnn_define_depthwise_convolution_2d
                 U xnn_define_divide
                 U xnn_define_elu
                 U xnn_define_floor
                 U xnn_define_fully_connected
                 U xnn_define_global_average_pooling_2d
                 U xnn_define_hardswish
                 U xnn_define_leaky_relu
                 U xnn_define_maximum2
                 U xnn_define_max_pooling_2d
                 U xnn_define_minimum2
                 U xnn_define_multiply2
                 U xnn_define_negate
                 U xnn_define_prelu
                 U xnn_define_quantized_tensor_value
                 U xnn_define_sigmoid
                 U xnn_define_softmax
                 U xnn_define_square
                 U xnn_define_squared_difference
                 U xnn_define_square_root
                 U xnn_define_static_constant_pad
                 U xnn_define_static_reshape
                 U xnn_define_static_resize_bilinear_2d
                 U xnn_define_subtract
                 U xnn_define_tensor_value
                 U xnn_define_unpooling_2d
                 U xnn_delete_runtime
                 U xnn_delete_subgraph
                 U xnn_initialize
                 U xnn_invoke_runtime
                 U xnn_setup_runtime
0000000000000000 b guard variable for tflite::xnnpack::(anonymous namespace)::Delegate::Delegate(TfLiteXNNPackDelegateOptions const*)::s_logged
0000000000000000 t tflite::xnnpack::(anonymous namespace)::SubgraphFree(TfLiteContext*, void*)
0000000000000000 t tflite::xnnpack::(anonymous namespace)::SubgraphInit(TfLiteContext*, char const*, unsigned long)
0000000000000000 t tflite::xnnpack::(anonymous namespace)::SubgraphInvoke(TfLiteContext*, TfLiteNode*)
0000000000000000 t tflite::xnnpack::(anonymous namespace)::DelegatePrepare(TfLiteContext*, TfLiteDelegate*)
0000000000000000 t tflite::xnnpack::(anonymous namespace)::SubgraphPrepare(TfLiteContext*, TfLiteNode*)
0000000000000000 d tflite::xnnpack::(anonymous namespace)::kSubgraphRegistration
0000000000000000 t tflite::xnnpack::(anonymous namespace)::Subgraph::VisitReluNode(xnn_subgraph*, tflite::xnnpack::(anonymous namespace)::Delegate const&, TfLiteContext*, int, TfLiteNode*, TfLiteTensor const*, float, float, std::__ndk1::vector<unsigned int, std::__ndk1::allocator<unsigned int> > const&)
0000000000000000 t tflite::xnnpack::(anonymous namespace)::Subgraph::CheckPoolingParams(TfLiteContext*, TfLitePoolParams const*, int)
0000000000000000 t tflite::xnnpack::(anonymous namespace)::Subgraph::CheckMediaPipePoolParams(TfLiteContext*, TfLitePoolParams const*, int)
0000000000000000 t tflite::xnnpack::(anonymous namespace)::Subgraph::CheckTensorQInt8OrQUInt8Type(tflite::xnnpack::(anonymous namespace)::Delegate const&, TfLiteContext*, TfLiteTensor const&, int, int)
0000000000000000 t tflite::xnnpack::(anonymous namespace)::Subgraph::CalculateTransposeConvPaddings(TfLiteContext*, TfLitePadding, int, int, int, int, int, int, int, int, int, int, int, int*, int*, int*, int*, int*, int*)
0000000000000000 t tflite::xnnpack::(anonymous namespace)::Subgraph::CheckTensorFloat32OrQCInt8Type(tflite::xnnpack::(anonymous namespace)::Delegate const&, TfLiteContext*, TfLiteTensor const&, int, int, int)
0000000000000000 t tflite::xnnpack::(anonymous namespace)::Subgraph::CheckTensorFloat32OrQUInt8Type(tflite::xnnpack::(anonymous namespace)::Delegate const&, TfLiteContext*, TfLiteTensor const&, int, int)
0000000000000000 t tflite::xnnpack::(anonymous namespace)::Subgraph::VisitNode(xnn_subgraph*, tflite::xnnpack::(anonymous namespace)::Delegate const&, TfLiteContext*, TfLiteRegistration*, TfLiteNode*, int, std::__ndk1::unordered_set<int, std::__ndk1::hash<int>, std::__ndk1::equal_to<int>, std::__ndk1::allocator<int> > const&, std::__ndk1::vector<unsigned int, std::__ndk1::allocator<unsigned int> > const&)
                 U tflite::xnnpack::DequantizeInt8(signed char const*, float*, tflite::RuntimeShape const&, int, double)
                 U tflite::xnnpack::DequantizeFloat16(unsigned short const*, float*, unsigned long)
                 U tflite::xnnpack::PerChannelDequantizeInt8(signed char const*, float*, tflite::RuntimeShape const&, int const*, float const*, int)
0000000000000000 t bool std::__ndk1::__insertion_sort_incomplete<tflite::xnnpack::(anonymous namespace)::Delegate::PrepareOpsToDelegate(TfLiteContext*)::$_0&, int*>(int*, int*, tflite::xnnpack::(anonymous namespace)::Delegate::PrepareOpsToDelegate(TfLiteContext*)::$_0&)
0000000000000000 t void std::__ndk1::__sort<tflite::xnnpack::(anonymous namespace)::Delegate::PrepareOpsToDelegate(TfLiteContext*)::$_0&, int*>(int*, int*, tflite::xnnpack::(anonymous namespace)::Delegate::PrepareOpsToDelegate(TfLiteContext*)::$_0&)
0000000000000000 W void std::__ndk1::vector<xnn_external_value, std::__ndk1::allocator<xnn_external_value> >::__push_back_slow_path<xnn_external_value const&>(xnn_external_value const&)
0000000000000000 t unsigned int std::__ndk1::__sort3<tflite::xnnpack::(anonymous namespace)::Delegate::PrepareOpsToDelegate(TfLiteContext*)::$_0&, int*>(int*, int*, int*, tflite::xnnpack::(anonymous namespace)::Delegate::PrepareOpsToDelegate(TfLiteContext*)::$_0&)
0000000000000000 t unsigned int std::__ndk1::__sort4<tflite::xnnpack::(anonymous namespace)::Delegate::PrepareOpsToDelegate(TfLiteContext*)::$_0&, int*>(int*, int*, int*, int*, tflite::xnnpack::(anonymous namespace)::Delegate::PrepareOpsToDelegate(TfLiteContext*)::$_0&)
0000000000000000 t unsigned int std::__ndk1::__sort5<tflite::xnnpack::(anonymous namespace)::Delegate::PrepareOpsToDelegate(TfLiteContext*)::$_0&, int*>(int*, int*, int*, int*, int*, tflite::xnnpack::(anonymous namespace)::Delegate::PrepareOpsToDelegate(TfLiteContext*)::$_0&)
0000000000000000 b tflite::xnnpack::(anonymous namespace)::Delegate::Delegate(TfLiteXNNPackDelegateOptions const*)::s_logged
tflite_with_xnnpack_optional.cc.o:
```

"
55334,Cannot predict or serialize model that performs tf.image.resize after decoding image bytearray.,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04 (Google Colab)
- TensorFlow installed from (source or binary): Binary
- TensorFlow version (use command below): 2.8.0
- Python version: 3.7.12

**Describe the current behavior**
When creating a model that receives a bytearray of an image, decodes it, resizes it and feeds it to the model, it won't serialize nor work with the `predict` method, we can only use `__call__`. 

**Describe the expected behavior**
The model would interpolate the tensor for the size inputed, serialize and save it.

**[Contributing](https://www.tensorflow.org/community/contribute)**

- Do you want to contribute a PR? (yes/no): no

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

Colab link: https://colab.research.google.com/drive/11VDEMesHjflnG7YytMI-KC9CgbA7hRYa

```python
from PIL import Image

import tensorflow as tf
import numpy as np


class MyModel(tf.keras.models.Model):
    def __init__(self):
        super().__init__()
        self.model = tf.keras.applications.ResNet101(
          include_top=True,
          weights=""imagenet"",
          input_tensor=None,
          input_shape=None,
          pooling=None,
          classes=1000,
      )

    def call(self, x):
        x = self.preprocess(x)
        return self.model(x)

    def preprocess(self, x):
        x = tf.map_fn(
            self.decode_bytes,
            x,
            dtype=tf.float32
        )
        x = tf.image.resize(x, (224, 224))

        return x

    def decode_bytes(self, x):
        return tf.io.decode_image(x, channels=3, dtype=tf.float32)


def create_input_tensor():
    fname = ""/tmp/image.png""

    mock_input = np.random.random((330, 330, 3)).astype(np.float32)
    mock_image = Image.fromarray(mock_input, ""RGB"")
    mock_image.save(fname)
    b = tf.io.read_file(fname)
    return tf.expand_dims(b, axis=0)


model = MyModel()
in_tensor = create_input_tensor()

model.predict(in_tensor)
```

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

```
WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:616: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Use fn_output_signature instead
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
[<ipython-input-7-efcc1d4139ed>](https://localhost:8080/#) in <module>()
----> 1 model.predict(in_tensor)

1 frames
[/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py](https://localhost:8080/#) in autograph_handler(*args, **kwargs)
   1145           except Exception as e:  # pylint:disable=broad-except
   1146             if hasattr(e, ""ag_error_metadata""):
-> 1147               raise e.ag_error_metadata.to_exception(e)
   1148             else:
   1149               raise

ValueError: in user code:

    File ""/usr/local/lib/python3.7/dist-packages/keras/engine/training.py"", line 1801, in predict_function  *
        return step_function(self, iterator)
    File ""/usr/local/lib/python3.7/dist-packages/keras/engine/training.py"", line 1790, in step_function  **
        outputs = model.distribute_strategy.run(run_step, args=(data,))
    File ""/usr/local/lib/python3.7/dist-packages/keras/engine/training.py"", line 1783, in run_step  **
        outputs = model.predict_step(data)
    File ""/usr/local/lib/python3.7/dist-packages/keras/engine/training.py"", line 1751, in predict_step
        return self(x, training=False)
    File ""/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py"", line 67, in error_handler
        raise e.with_traceback(filtered_tb) from None

    ValueError: Exception encountered when calling layer ""my_model"" (type MyModel).
    
    in user code:
    
        File ""<ipython-input-4-f4258c3336bd>"", line 17, in call  *
            x = self.preprocess(x)
        File ""<ipython-input-4-f4258c3336bd>"", line 26, in preprocess  *
            x = tf.image.resize(x, (224, 224))
    
        ValueError: 'images' contains no shape.
    
    
    Call arguments received:
      • x=tf.Tensor(shape=(None,), dtype=string)
```

**EDIT 1: workaround**

Colab link: https://colab.research.google.com/drive/1_VF5TWbehTECy-33TjdzqQyoOvSOF0bZ?usp=sharing

It seems that a workaround is to save the model with the resize operation but receiving the tensor (not a tf.string tensor with the bytearray), then load it, wrap it into a model that receives the bytearray then save it again. 

When the operation is already serialized and loaded into a model it seems to do no harm. 

Anyway, this is hacky and despite we can make it work like that it is not ideal. "
55331,XNNPack delegate subgraph creation in TensorFlow Lite non-deterministically crashes when initializing tensors,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS Big Sur 11.6.4
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: iPhone 13
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): 2.8.0
- Python version: 3.8
- Bazel version (if compiling from source): 4.2.1
- GCC/Compiler version (if compiling from source): Apple clang version 12.0.0
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A

**Describe the current behavior**
I have a custom model that has its graph modified by the XNNPack delegate using the C API. When the XNNPack delegate modifies the interpreter graph, it works maybe 80% of the time and crashes another 20% of the time due to an error such as seen below.
```
libc++abi: terminating with uncaught exception of type std::length_error: vector
  dyld4 config: DYLD_LIBRARY_PATH=/usr/lib/system/introspection DYLD_INSERT_LIBRARIES=/Developer/usr/lib/libBacktraceRecording.dylib:/Developer/usr/lib/libMainThreadChecker.dylib:/Developer/Library/PrivateFrameworks/DTDDISupport.framework/libViewDebuggerSupport.dylib:/usr/lib/libMTLCapture.dylib
  terminating with uncaught exception of type std::length_error: vector
```

I'm using the C API so I can use the TensorFlow Lite library across native applications (e.g. iOS, Android, Desktop, etc). 

**Describe the expected behavior**
I would not expect it to crash and to always succeed.

**[Contributing](https://www.tensorflow.org/community/contribute)**

- Do you want to contribute a PR? (yes/no): Yes
- Briefly describe your candidate solution(if contributing):

   See https://github.com/tensorflow/tensorflow/pull/55330. Basically, when debugging, I found that the graph sometimes ended up with all unused tensors (-1 in the vector). As a result, the `tensors` end up having a size of 0 and calling `back()` on an empty vector leads to undefined behavior according to C++ spec: https://www.cplusplus.com/reference/vector/vector/back/
   ```
   Calling this function on an [empty](https://www.cplusplus.com/vector::empty) container causes undefined behavior.
   ```

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.
I'm unfortunately not able to share my model or code, but I'm happy to adjust any unit tests or look more into coming up with a smaller reproducible use case if needed. I think the change is relatively clear though, so I haven't done anything else yet.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
N/A. "
55328,tf.nn.ctc_loss behaviour changes depending on whether dense or sparse labels are provided,"The [tf.nn.ctc_loss](https://www.tensorflow.org/api_docs/python/tf/nn/ctc_loss) changes its behaviour unexpectedly based on whether the labels provided are sparse or dense.

In particular, it accepts empty target label sequences in the dense version, and maximises (as one would expect) the log probability of the blank token at each time frame in the `logits` prediction matrix. It does not output any warning or error.

However, if you convert the label to be sparse by using `tf.sparse_from_dense`, given the same inputs (with empty target label sequence), it errors out with

```
tensorflow.python.framework.errors_impl.InvalidArgumentError: Labels length is zero in batch 0 [Op:CTCLoss]
```

This inconsistency in behaviour should be fixed.

Option 1: Ideally, we would implement support for empty labels in the case of sparse tensors.

Option 2: Add a warning to the CTC loss doc that empty labels are not supported in the case of sparse tensors.

Another inconsistency is that the dtype for `logit_length` can be int64 for the dense version, but needs to be int32 for the sparse version, and errors out if int64 is provided. Again, ideally this should be converted internally, but if it really cannot be fixed, the docs should reflect this, which they do not at the moment.

## Function affected:

https://www.tensorflow.org/api_docs/python/tf/nn/ctc_loss

### Usage example

This runs fine:
```
tf.nn.ctc_loss(
    labels=tf.ones((4, 50), dtype=tf.int32),
    logits=tf.zeros((4, 200, 10), dtype=tf.float32),
    label_length=tf.constant(50, dtype=tf.int64, shape=4),
    logit_length=tf.constant(200, dtype=tf.int64, shape=4),
    logits_time_major=False,
    blank_index=0,
)
```

Converting to sparse labels:
```
tf.nn.ctc_loss(
    labels=tf.sparse.from_dense(tf.ones((4, 50), dtype=tf.int32)),
    logits=tf.zeros((4, 200, 10), dtype=tf.float32),
    label_length=tf.constant(50, dtype=tf.int64, shape=4),
    logit_length=tf.constant(200, dtype=tf.int64, shape=4),
    logits_time_major=False,
    blank_index=0,
)
```
suddenly raises 
```
tensorflow.python.framework.errors_impl.InvalidArgumentError: cannot compute CTCLoss as input #3(zero-based) was expected to be a int32 tensor but is a int64 tensor [Op:CTCLoss]
```
which is fixed by running

```
tf.nn.ctc_loss(
    labels=tf.sparse.from_dense(tf.ones((4, 50), dtype=tf.int32)),
    logits=tf.zeros((4, 200, 10), dtype=tf.float32),
    label_length=tf.constant(50, dtype=tf.int64, shape=4),
    logit_length=tf.cast(tf.constant(200, dtype=tf.int64, shape=4), tf.int32),
    logits_time_major=False,
    blank_index=0,
)
```

Now introducing empty label sequences:
```
tf.nn.ctc_loss(
    labels=tf.sparse.from_dense(tf.ones((4, 0), dtype=tf.int32)),
    logits=tf.zeros((4, 200, 10), dtype=tf.float32),
    label_length=tf.constant(0, dtype=tf.int64, shape=4),
    logit_length=tf.cast(tf.constant(200, dtype=tf.int64, shape=4), tf.int32),
    logits_time_major=False,
    blank_index=0,
)
```
raises
```
tensorflow.python.framework.errors_impl.InvalidArgumentError: Labels length is zero in batch 0 [Op:CTCLoss]
```
wheras the dense version is fine:
```
tf.nn.ctc_loss(
    labels=tf.ones((4, 0), dtype=tf.int32),
    logits=tf.zeros((4, 200, 10), dtype=tf.float32),
    label_length=tf.constant(0, dtype=tf.int64, shape=4),
    logit_length=tf.cast(tf.constant(200, dtype=tf.int64, shape=4), tf.int32),
    logits_time_major=False,
    blank_index=0,
)
```"
55327,I dont have TransformToGrayscaleOp class in android using tensorflowlite,"I want to transform my image to grayscale in android but when i traid to use [TransformToGrayscaleOp](https://www.tensorflow.org/lite/api_docs/java/org/tensorflow/lite/support/image/ops/TransformToGrayscaleOp?hl=en) class i got this error in the ide: _**Unresolved reference: TransformToGrayscaleOp**_

Here's my code until now:

        val imageProcessor: ImageProcessor = ImageProcessor.Builder()
            .add(ResizeOp(150, 150, ResizeOp.ResizeMethod.NEAREST_NEIGHBOR))
            .add( TransformToGrayscaleOp()) //<----- dont find this class
            .build()
        imageProcessor.process(tensorImage)`

**build.gradle**

`implementation 'org.tensorflow:tensorflow-lite:2.8.0'
implementation 'org.tensorflow:tensorflow-lite-support:0.1.0'
implementation 'org.tensorflow:tensorflow-lite-metadata:0.1.0'`

Why i dont have that class?"
55326,"[Accuracy] round issue on tf.nn.conv2d, it does not return the same results for a kernel depth size < 8 vs kernel depth size > 16","**System information**
- OS Platform and Distribution: Ubuntu 18.04 ($uname -a)
`Linux *** 5.0.0-37-generic #40~18.04.1-Ubuntu SMP Thu Nov 14 12:06:39 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux`

- TensorFlow installed from : pypi.org
- TensorFlow version: tested on 2.4.1, 2.6.0, 2.6.2, 2.8.0
  - tf.version.VERSION: ""2.6.2""
  - tf.version.GIT_VERSION: 'v2.6.1-9-gc2363d6d025'
  - tf.version.COMPILER_VERSION: '7.3.1 20180303'
- Python version: 3.6.9, 3.8.0, 3.9.11

- CUDA/cuDNN version: no CUDA
- GPU model and memory: no GPU

**Describe the current behavior**
Comparing a 2d-convolution with kernel depth =16 with two 2d-convolution with kernel depth = 8 then concatenated would provide strictly the same results. However, it is not the case. Trace is:
```
>> test with kernel depth = 32 pass
>> test with kernel depth =  8 pass
Traceback (most recent call last):
  File ""/***/test_conv2d/tf_conv2d_d8d8_vs_d16.py"", line 76, in <module>
    _test(d)
  File ""/***/test_conv2d/tf_conv2d_d8d8_vs_d16.py"", line 71, in _test
    numpy.testing.assert_allclose(out_1, out_2)
  File ""/***/.local/share/virtualenvs/python-3.9-venv/lib/python3.9/site-packages/numpy/testing/_private/utils.py"", line 1527, in assert_allclose
    assert_array_compare(compare, actual, desired, err_msg=str(err_msg),
  File ""/***/.local/share/virtualenvs/python-3.9-venv/lib/python3.9/site-packages/numpy/testing/_private/utils.py"", line 840, in assert_array_compare
    raise AssertionError(msg)
AssertionError: 
Not equal to tolerance rtol=1e-07, atol=0

Mismatched elements: 2044522 / 4194304 (48.7%)
Max absolute difference: 1.7881393e-07
Max relative difference: 0.10666173
 x: array([[[[ 0.283143,  0.117474,  0.101533, ...,  0.302509, -0.060525,
          -0.123441],
         [ 0.044446, -0.08746 ,  0.078083, ...,  0.173368,  0.143438,...
 y: array([[[[ 0.283143,  0.117474,  0.101533, ...,  0.302509, -0.060525,
          -0.123441],
         [ 0.044446, -0.08746 ,  0.078083, ...,  0.173368,  0.143438,...

Process finished with exit code 1
```

**Describe the expected behavior**
It appears that:
- for a depth size of 8 vs 4-4, results are strictly the same
- for a depth size of 16 vs 8-8, results are not strictly the same (round issue?)
- for a depth size of 32 vs 16-16, results are strictly the same

**[Contributing](https://www.tensorflow.org/community/contribute)**

- Do you want to contribute a PR? (yes/no): ...
- Briefly describe your candidate solution(if contributing):

**Standalone code to reproduce the issue**
tf_conv2d_d8d8_vs_d16.py
```python
import numpy
import tensorflow as tf


class Model_1conv2d(tf.Module):
    def __init__(self, kernel):
        super().__init__()
        self.conv2d_weigths = tf.constant(kernel)

    @tf.function(input_signature=[
        tf.TensorSpec(shape=(1, 512, 512, 3), dtype=tf.float32, name='input')])
    def f(self, input_1):
        conv2d = tf.nn.conv2d(
            input_1,
            self.conv2d_weigths,
            data_format=""NHWC"",
            padding=""SAME"",
            dilations=[1, 1],
            strides=[1, 1, 1, 1],
            name=""conv2d"")
        return conv2d

class Model_2conv2d(tf.Module):
    def __init__(self, k1, k2):
        super().__init__()
        self.conv2d_weigths_1 = tf.constant(k1)
        self.conv2d_weigths_2 = tf.constant(k2)

    @tf.function(input_signature=[
        tf.TensorSpec(shape=(1, 512, 512, 3), dtype=tf.float32, name='input_1_input')
    ])
    def f(self, input_1):
        conv2d_1 = tf.nn.conv2d(
            input_1,
            self.conv2d_weigths_1,
            data_format=""NHWC"",
            padding=""SAME"",
            dilations=[1, 1],
            strides=[1, 1, 1, 1],
            name=""conv2d1"")
        conv2d_2 = tf.nn.conv2d(
            input_1,
            self.conv2d_weigths_2,
            data_format=""NHWC"",
            padding=""SAME"",
            dilations=[1, 1],
            strides=[1, 1, 1, 1],
            name=""conv2d2"")
        concat = tf.concat([
            conv2d_1,
            conv2d_2,],
            axis=3,
            name=""output"")
        return concat


def _test(depth):

    kernel = (numpy.random.uniform(
        low=-0.05,
        high=0.05,
        size=[3, 3, 3, depth])).astype(dtype=numpy.float16).astype(dtype=numpy.float32)

    x = 2 * numpy.random.rand(1, 512, 512, 3).astype(dtype=numpy.float32)
    input_1_feed = numpy.where(x > 1, x - 0.5, x - 1.5).astype(dtype=numpy.float32)

    model_1 = Model_1conv2d(kernel)
    model_2 = Model_2conv2d(kernel[:, :, :, :(depth // 2)], kernel[:, :, :, (depth // 2):])

    out_1 = model_1.f(input_1_feed,).numpy()
    out_2 = model_2.f(input_1_feed,).numpy()

    numpy.testing.assert_allclose(out_1, out_2)


if __name__ == '__main__':
    for d in [32, 8, 16]:
        _test(d)
        print('>> test with kernel depth = %2s pass' % d)
```

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
55325,AttributeError: 'arguments' object has no attribute 'posonlyargs',"summary: while running locally the efficient net tutorial, the logs showed and error and asked to report to the tf team.
""AttributeError: 'arguments' object has no attribute 'posonlyargs'
WARNING:tensorflow:AutoGraph could not transform <function _create_pre_batch_dataset_fn.<locals>.get_dataset.<locals>.<lambda> at 0x7ff6443d2e60> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: 'arguments' object has no attribute 'posonlyargs'""

**System information**
- Code is an official example of how to run efficientnet:(https://github.com/tensorflow/tpu/blob/master/models/official/detection/GETTING_STARTED.md) 
- OS Platform Linux Ubuntu 20.04, Lenovo T14, no gpu.
- TensorFlow installed from binary.
- TensorFlow version v2.5.0-rc3-213-ga4dfb8d1a71 2.5.0.
- Python version 3.8

log:


`tpu/models/official/detection/main.py -model=retinanet --model_dir=/home/dannyb/Documents/Research/copy_paste/model_output --mode=train --eval_after_training=True --use_tpu=False ""--params_override={ train: { checkpoint: { path: gs://cloud-tpu-checkpoints/retinanet/resnet50-checkpoint-2018-02-07/model.ckpt-112603, prefix: resnet50/ }, train_file_pattern: /home/dannyb/Documents/Research/copy_paste/cocoapi/PythonAPI/data/coco }, eval: { val_json_file: /home/dannyb/Documents/Research/copy_paste/cocoapi/PythonAPI/data/coco/raw-data/annotations/image_info_test-dev2017.json, eval_file_pattern: /home/dannyb/Documents/Research/copy_paste/cocoapi/PythonAPI/data/coco } }""
Connected to pydev debugger (build 213.7172.26)
2022-03-22 13:26:39.711187: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2022-03-22 13:26:39.711228: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (dannybarash-t14-gen-1): /proc/driver/nvidia/version does not exist
I0322 13:26:39.726564 140697653870976 main.py:114] Model Parameters: {'anchor': {'anchor_size': 4.0,
            'aspect_ratios': [1.0, 2.0, 0.5],
            'num_scales': 3},
 'architecture': {'backbone': 'resnet',
                  'max_level': 7,
                  'min_level': 3,
                  'multilevel_features': 'fpn',
                  'num_classes': 91,
                  'output_flat_fpn_features': False,
                  'parser': 'retinanet_parser',
                  'pre_parser': None,
                  'space_to_depth_block_size': 1,
                  'use_bfloat16': False},
 'batch_norm_activation': {'activation': 'relu',
                           'batch_norm_epsilon': 0.0001,
                           'batch_norm_momentum': 0.997,
                           'batch_norm_trainable': True,
                           'use_sync_bn': False},
 'dropblock': {'dropblock_keep_prob': None, 'dropblock_size': None},
 'enable_summary': False,
 'eval': {'eval_batch_size': 8,
          'eval_dataset_type': 'tfrecord',
          'eval_file_pattern': '/home/dannyb/Documents/Research/copy_paste/cocoapi/PythonAPI/data/coco',
          'eval_samples': None,
          'eval_timeout': None,
          'min_eval_interval': 180,
          'num_steps_per_eval': 1000,
          'per_category_metrics': False,
          'skip_eval_loss': False,
          'suffix': '',
          'type': 'box',
          'use_json_file': True,
          'val_json_file': '/home/dannyb/Documents/Research/copy_paste/cocoapi/PythonAPI/data/coco/raw-data/annotations/image_info_test-dev2017.json'},
 'fpn': {'fpn_feat_dims': 256,
         'use_batch_norm': True,
         'use_separable_conv': False},
 'isolate_session_state': False,
 'model_dir': '/home/dannyb/Documents/Research/copy_paste/model_output',
 'nasfpn': {'activation': None,
            'block_fn': 'conv',
            'fpn_feat_dims': 256,
            'init_drop_connect_rate': None,
            'num_repeats': 5,
            'use_separable_conv': False,
            'use_sum_for_combination': False},
 'platform': {'eval_master': None,
              'gcp_project': None,
              'tpu': None,
              'tpu_zone': None},
 'postprocess': {'apply_nms': True,
                 'apply_sigmoid': True,
                 'max_total_size': 100,
                 'nms_iou_threshold': 0.5,
                 'nms_version': 'v1',
                 'pre_nms_num_boxes': 5000,
                 'score_threshold': 0.05,
                 'use_batched_nms': False},
 'predict': {'predict_batch_size': 8},
 'resnet': {'init_drop_connect_rate': None, 'resnet_depth': 50},
 'retinanet_head': {'anchors_per_location': None,
                    'num_convs': 4,
                    'num_filters': 256,
                    'use_batch_norm': True,
                    'use_separable_conv': False},
 'retinanet_loss': {'box_loss_weight': 50,
                    'focal_loss_alpha': 0.25,
                    'focal_loss_gamma': 1.5,
                    'huber_loss_delta': 0.1,
                    'normalizer_momentum': 0.0},
 'retinanet_parser': {'aug_policy': '',
                      'aug_rand_hflip': True,
                      'aug_scale_max': 1.0,
                      'aug_scale_min': 1.0,
                      'match_threshold': 0.5,
                      'max_num_instances': 100,
                      'output_size': [640, 640],
                      'regenerate_source_id': False,
                      'skip_crowd_during_training': True,
                      'unmatched_threshold': 0.5},
 'spinenet': {'init_drop_connect_rate': None,
              'model_id': '49',
              'use_native_resize_op': False},
 'spinenet_mbconv': {'init_drop_connect_rate': None,
                     'model_id': '49',
                     'se_ratio': 0.2,
                     'use_native_resize_op': False},
 'tpu_job_name': None,
 'train': {'checkpoint': {'path': 'gs://cloud-tpu-checkpoints/retinanet/resnet50-checkpoint-2018-02-07/model.ckpt-112603',
                          'prefix': 'resnet50/',
                          'skip_variables_regex': ''},
           'frozen_variable_prefix': None,
           'gradient_clip_norm': 0.0,
           'input_partition_dims': None,
           'iterations_per_loop': 100,
           'l2_weight_decay': 0.0001,
           'learning_rate': {'init_learning_rate': 0.08,
                             'learning_rate_levels': [0.008, 0.0008],
                             'learning_rate_steps': [15000, 20000],
                             'type': 'step',
                             'warmup_learning_rate': 0.0067,
                             'warmup_steps': 500},
           'num_cores_per_replica': None,
           'num_shards': 8,
           'optimizer': {'momentum': 0.9, 'type': 'momentum'},
           'pre_parser_dataset': {'dataset_type': 'tfrecord',
                                  'file_pattern': ''},
           'regularization_variable_regex': '.*(kernel|weight):0$',
           'space_to_depth_block_size': 1,
           'total_steps': 22500,
           'train_batch_size': 64,
           'train_dataset_type': 'tfrecord',
           'train_file_pattern': '/home/dannyb/Documents/Research/copy_paste/cocoapi/PythonAPI/data/coco',
           'transpose_input': True},
 'type': 'retinanet',
 'use_tpu': False}
INFO:tensorflow:gpu devices: []
I0322 13:26:39.727839 140697653870976 tpu_executor.py:134] gpu devices: []
2022-03-22 13:26:39.728716: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.
W0322 13:26:39.730379 140697653870976 cross_device_ops.py:1386] There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.
INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)
I0322 13:26:39.737167 140697653870976 mirrored_strategy.py:374] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)
INFO:tensorflow:Number of devices: 1
I0322 13:26:39.737861 140697653870976 tpu_executor.py:137] Number of devices: 1
INFO:tensorflow:Initializing RunConfig with distribution strategies.
I0322 13:26:39.827292 140697653870976 run_config.py:582] Initializing RunConfig with distribution strategies.
INFO:tensorflow:Not using Distribute Coordinator.
I0322 13:26:39.827548 140697653870976 estimator_training.py:163] Not using Distribute Coordinator.
INFO:tensorflow:Using config: {'_model_dir': '/home/dannyb/Documents/Research/copy_paste/model_output', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true
graph_options {
  rewrite_options {
    meta_optimizer_iterations: ONE
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': <tensorflow.python.distribute.mirrored_strategy.MirroredStrategyV1 object at 0x7ff6509af290>, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_distribute_coordinator_mode': None}
I0322 13:26:39.831076 140697653870976 estimator.py:202] Using config: {'_model_dir': '/home/dannyb/Documents/Research/copy_paste/model_output', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true
graph_options {
  rewrite_options {
    meta_optimizer_iterations: ONE
  }
}
, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': <tensorflow.python.distribute.mirrored_strategy.MirroredStrategyV1 object at 0x7ff6509af290>, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_distribute_coordinator_mode': None}
WARNING:tensorflow:From /home/dannyb/miniconda/envs/copypaste/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py:1244: StrategyBase.configure (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.
Instructions for updating:
use `update_config_proto` instead.
W0322 13:26:39.871531 140697653870976 deprecation.py:343] From /home/dannyb/miniconda/envs/copypaste/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/estimator.py:1244: StrategyBase.configure (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.
Instructions for updating:
use `update_config_proto` instead.
WARNING:tensorflow:From /home/dannyb/Documents/Research/copy_paste/tpu/models/official/detection/dataloader/input_reader.py:48: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.
W0322 13:26:39.898388 140697653870976 deprecation.py:343] From /home/dannyb/Documents/Research/copy_paste/tpu/models/official/detection/dataloader/input_reader.py:48: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.
INFO:tensorflow:Converted call: <function _create_pre_batch_dataset_fn.<locals>.get_dataset.<locals>.<lambda> at 0x7ff6443d2e60>
    args: (<tf.Tensor 'args_0:0' shape=() dtype=string>,)
    kwargs: {}
I0322 13:26:39.902364 140697653870976 ag_logging.py:136] Converted call: <function _create_pre_batch_dataset_fn.<locals>.get_dataset.<locals>.<lambda> at 0x7ff6443d2e60>
    args: (<tf.Tensor 'args_0:0' shape=() dtype=string>,)
    kwargs: {}
INFO:tensorflow:Not allowed: <method-wrapper '__call__' of function object at 0x7ff6443d2e60>: default rule
I0322 13:26:39.903000 140697653870976 ag_logging.py:136] Not allowed: <method-wrapper '__call__' of function object at 0x7ff6443d2e60>: default rule
INFO:tensorflow:Not allowed: <function _create_pre_batch_dataset_fn.<locals>.get_dataset.<locals>.<lambda> at 0x7ff6443d2e60>: default rule
I0322 13:26:39.903301 140697653870976 ag_logging.py:136] Not allowed: <function _create_pre_batch_dataset_fn.<locals>.get_dataset.<locals>.<lambda> at 0x7ff6443d2e60>: default rule
INFO:tensorflow:<function _create_pre_batch_dataset_fn.<locals>.get_dataset.<locals>.<lambda> at 0x7ff6443d2e60> is not cached for subkey ConversionOptions[{}]
I0322 13:26:39.903635 140697653870976 ag_logging.py:136] <function _create_pre_batch_dataset_fn.<locals>.get_dataset.<locals>.<lambda> at 0x7ff6443d2e60> is not cached for subkey ConversionOptions[{}]
INFO:tensorflow:Source code of <function _create_pre_batch_dataset_fn.<locals>.get_dataset.<locals>.<lambda> at 0x7ff6443d2e60>:
lambda file_name: dataset_cls(file_name).prefetch(1),
I0322 13:26:39.912487 140697653870976 ag_logging.py:136] Source code of <function _create_pre_batch_dataset_fn.<locals>.get_dataset.<locals>.<lambda> at 0x7ff6443d2e60>:
lambda file_name: dataset_cls(file_name).prefetch(1),
INFO:tensorflow:Error transforming entity <function _create_pre_batch_dataset_fn.<locals>.get_dataset.<locals>.<lambda> at 0x7ff6443d2e60>
Traceback (most recent call last):
  File ""/home/dannyb/miniconda/envs/copypaste/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py"", line 427, in converted_call
    converted_f = _convert_actual(target_entity, program_ctx)
  File ""/home/dannyb/miniconda/envs/copypaste/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py"", line 269, in _convert_actual
    transformed, module, source_map = _TRANSPILER.transform(entity, program_ctx)
  File ""/home/dannyb/miniconda/envs/copypaste/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/transpiler.py"", line 282, in transform
    return self.transform_function(obj, user_context)
  File ""/home/dannyb/miniconda/envs/copypaste/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/transpiler.py"", line 466, in transform_function
    nodes, ctx = super(PyToPy, self).transform_function(fn, user_context)
  File ""/home/dannyb/miniconda/envs/copypaste/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/transpiler.py"", line 359, in transform_function
    result = self.transform_ast(node, context)
  File ""/home/dannyb/miniconda/envs/copypaste/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py"", line 237, in transform_ast
    node = self.initial_analysis(node, ctx)
  File ""/home/dannyb/miniconda/envs/copypaste/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py"", line 225, in initial_analysis
    node = activity.resolve(node, ctx, None)
  File ""/home/dannyb/miniconda/envs/copypaste/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/static_analysis/activity.py"", line 700, in resolve
    return ActivityAnalyzer(context, parent_scope).visit(node)
  File ""/home/dannyb/miniconda/envs/copypaste/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/transformer.py"", line 441, in visit
    result = super(Base, self).visit(node)
  File ""/home/dannyb/miniconda/envs/copypaste/lib/python3.7/ast.py"", line 271, in visit
    return visitor(node)
  File ""/home/dannyb/miniconda/envs/copypaste/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/static_analysis/activity.py"", line 605, in visit_Lambda
    node = self._visit_arg_annotations(node)
  File ""/home/dannyb/miniconda/envs/copypaste/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/static_analysis/activity.py"", line 546, in _visit_arg_annotations
    node = self._visit_arg_declarations(node)
  File ""/home/dannyb/miniconda/envs/copypaste/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/static_analysis/activity.py"", line 551, in _visit_arg_declarations
    node.args.posonlyargs = self._visit_node_list(node.args.posonlyargs)
AttributeError: 'arguments' object has no attribute 'posonlyargs'
I0322 13:26:39.914238 140697653870976 ag_logging.py:136] Error transforming entity <function _create_pre_batch_dataset_fn.<locals>.get_dataset.<locals>.<lambda> at 0x7ff6443d2e60>
Traceback (most recent call last):
  File ""/home/dannyb/miniconda/envs/copypaste/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py"", line 427, in converted_call
    converted_f = _convert_actual(target_entity, program_ctx)
  File ""/home/dannyb/miniconda/envs/copypaste/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py"", line 269, in _convert_actual
    transformed, module, source_map = _TRANSPILER.transform(entity, program_ctx)
  File ""/home/dannyb/miniconda/envs/copypaste/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/transpiler.py"", line 282, in transform
    return self.transform_function(obj, user_context)
  File ""/home/dannyb/miniconda/envs/copypaste/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/transpiler.py"", line 466, in transform_function
    nodes, ctx = super(PyToPy, self).transform_function(fn, user_context)
  File ""/home/dannyb/miniconda/envs/copypaste/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/transpiler.py"", line 359, in transform_function
    result = self.transform_ast(node, context)
  File ""/home/dannyb/miniconda/envs/copypaste/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py"", line 237, in transform_ast
    node = self.initial_analysis(node, ctx)
  File ""/home/dannyb/miniconda/envs/copypaste/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py"", line 225, in initial_analysis
    node = activity.resolve(node, ctx, None)
  File ""/home/dannyb/miniconda/envs/copypaste/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/static_analysis/activity.py"", line 700, in resolve
    return ActivityAnalyzer(context, parent_scope).visit(node)
  File ""/home/dannyb/miniconda/envs/copypaste/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/transformer.py"", line 441, in visit
    result = super(Base, self).visit(node)
  File ""/home/dannyb/miniconda/envs/copypaste/lib/python3.7/ast.py"", line 271, in visit
    return visitor(node)
  File ""/home/dannyb/miniconda/envs/copypaste/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/static_analysis/activity.py"", line 605, in visit_Lambda
    node = self._visit_arg_annotations(node)
  File ""/home/dannyb/miniconda/envs/copypaste/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/static_analysis/activity.py"", line 546, in _visit_arg_annotations
    node = self._visit_arg_declarations(node)
  File ""/home/dannyb/miniconda/envs/copypaste/lib/python3.7/site-packages/tensorflow/python/autograph/pyct/static_analysis/activity.py"", line 551, in _visit_arg_declarations
    node.args.posonlyargs = self._visit_node_list(node.args.posonlyargs)
AttributeError: 'arguments' object has no attribute 'posonlyargs'
WARNING:tensorflow:AutoGraph could not transform <function _create_pre_batch_dataset_fn.<locals>.get_dataset.<locals>.<lambda> at 0x7ff6443d2e60> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: 'arguments' object has no attribute 'posonlyargs'
`"
55324,Auto comment generation project - model training loop crash,"Trying to train a model in an automatic comment generation project, the training loop throws an exception.
This error has occured with 3 combinations of python/tensorflow versions, which I note below as (1), (2) and (3), as well as on both a conda env in Powershell and in the WSL Ubuntu command line.
It also happens on 2 different machines, both with the official (https://github.com/tech-srl/code2seq) and unofficial (https://github.com/Kolkir/code2seq) versions of the project. 

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Not sure if the project devs did, I assume not.
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 x64, Ubuntu 20.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 1.12 (1), 2.8.0 (2), 2.8.0 (3)
- Python version: 3.6.5 (1), 3.9.7 (2), 3.8.10 (3)
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: N/A
- GPU model and memory: RTX 2080 SUPER 8GB, but N/A

**Describe the current behavior**

Running the training loop with `bash train.sh` both in Powershell (conda) and Ubuntu WSL command line :

```
Traceback (most recent call last):
  File ""C:\Users\gbaulard\Anaconda3\lib\site-packages\tensorflow\python\module\module.py"", line 407, in _flatten_module
    leaves = nest.flatten_with_tuple_paths(
  File ""C:\Users\gbaulard\Anaconda3\lib\site-packages\tensorflow\python\util\nest.py"", line 1698, in flatten_with_tuple_paths
    flatten(structure, expand_composites=expand_composites)))
  File ""C:\Users\gbaulard\Anaconda3\lib\site-packages\tensorflow\python\util\nest.py"", line 451, in flatten
    return _pywrap_utils.Flatten(structure, expand_composites)
TypeError: '<' not supported between instances of 'WhileBodyFuncGraph' and 'FuncGraph'

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File ""C:\Users\gbaulard\Documents\GitHub\code2seq\code2seq.py"", line 29, in <module>
    model.train()
  File ""C:\Users\gbaulard\Documents\GitHub\code2seq\modelrunner.py"", line 129, in train
    gradients = tape.gradient(loss, self.model.trainable_variables)
  File ""C:\Users\gbaulard\Anaconda3\lib\site-packages\tensorflow\python\module\module.py"", line 171, in trainable_variables
    return tuple(
  File ""C:\Users\gbaulard\Anaconda3\lib\site-packages\tensorflow\python\module\module.py"", line 449, in _flatten_module
    for subvalue in subvalues:
  File ""C:\Users\gbaulard\Anaconda3\lib\site-packages\tensorflow\python\module\module.py"", line 449, in _flatten_module
    for subvalue in subvalues:
  File ""C:\Users\gbaulard\Anaconda3\lib\site-packages\tensorflow\python\module\module.py"", line 449, in _flatten_module
    for subvalue in subvalues:
  File ""C:\Users\gbaulard\Anaconda3\lib\site-packages\tensorflow\python\module\module.py"", line 410, in _flatten_module
    six.raise_from(
  File ""<string>"", line 3, in raise_from
ValueError: Error processing property '_dropout_mask_cache' of <ContextValueCache at 0x17309fd0df0>
```

Code snippet being triggered in module.py of tensorflow :

```
try:
      leaves = nest.flatten_with_tuple_paths(
          prop, expand_composites=expand_composites)
    except Exception as cause:  # pylint: disable=broad-except
      six.raise_from(
          ValueError(
              ""Error processing property {!r} of {!r}"".format(key, prop)),
          cause)
```
**Describe the expected behavior**

The traning loop should terminate without errors.

**Standalone code to reproduce the issue**

Best I can do is give the project git:
- https://github.com/tech-srl/code2seq (official version, tensorflow 1.12)
- https://github.com/Kolkir/code2seq (unofficial version, tensorflow 2.8.0)"
55323,`tf.image.non_max_suppression_padded` pads indices with a valid index value (0),"`tf.image.non_max_suppression` returns a vector of surviving indices of dynamic shape.
To hold static shapes, you use `tf.image.non_max_suppression_padded` which returns a vector of surviving indices (and a scalar indicates the amount).

This vector however, is padded with zeros, to match the input shape (dimension 0).
Since [0] is a valid index in the input, I find it weird and confusing -- does the first zero encountered in the surviving indices is a survivor or just a padding?
For instance, I cannot use `>=0` since that will take all indices, and I cannot use `>0` since it will skip index 0 in case it does survive
```python
return tf.where(tf.expand_dims(indices, axis=1) >= 0, x, tf.zeros_like(x))
```

I understand that this is solvable using the second returned value which indicates the amount of survivors, but I wish the vector itself would be sufficient.

A current workaround is prepending a dummy box with confidence=0 just to make sure that valid indices start from [1].

CoreML handles this issue by padding -1s -- which makes more sense, I guess that might be helpful here as well.


TF 2.8.0"
55322,[TFLite] Failed to build iOS framework: thread-local storage is not supported for the current target,"Hi I use the [official guide](https://tensorflow.google.cn/lite/guide/build_ios) to build a framework for iOS, however, when I run this command:
```
bazel build --config=ios_fat -c opt \
  //tensorflow/lite/ios:TensorFlowLiteC_framework
```
I'm getting this error:

```
ERROR: tensorflow-master/tensorflow/lite/kernels/BUILD:256:11: Compiling tensorflow/lite/kernels/eigen_support.cc failed: (Aborted): wrapped_clang_pp failed: error executing command external/local_config_cc/wrapped_clang_pp '-D_FORTIFY_SOURCE=1' -fstack-protector -fcolor-diagnostics -Wall -Wthread-safety -Wself-assign -fno-omit-frame-pointer -g0 -O2 -DNDEBUG ... (remaining 77 arguments skipped)
In file included from tensorflow/lite/kernels/eigen_support.cc:23:
In file included from ./tensorflow/lite/kernels/internal/optimized/eigen_spatial_convolutions.h:42:
In file included from ./third_party/eigen3/unsupported/Eigen/CXX11/Tensor:1:
In file included from external/eigen_archive/unsupported/Eigen/CXX11/Tensor:45:
In file included from external/eigen_archive/unsupported/Eigen/CXX11/ThreadPool:67:
external/eigen_archive/unsupported/Eigen/CXX11/src/ThreadPool/NonBlockingThreadPool.h:468:5: error: thread-local storage is not supported for the current target
    EIGEN_THREAD_LOCAL PerThread per_thread_;
    ^
external/eigen_archive/unsupported/Eigen/CXX11/src/ThreadPool/ThreadLocal.h:22:35: note: expanded from macro 'EIGEN_THREAD_LOCAL'
#define EIGEN_THREAD_LOCAL static thread_local
                                  ^
1 error generated.
Error in child process '/usr/bin/xcrun'. 1
Target //tensorflow/lite/ios:TensorFlowLiteC_framework failed to build
Use --verbose_failures to see the command lines of failed build steps.
INFO: Elapsed time: 4.019s, Critical Path: 2.75s
INFO: 17 processes: 17 internal.
FAILED: Build did NOT complete successfully
```

My System Info:

+ tensorflow: from master branch, the latest code
+ bazel: 5.0.0

I think a similar issue is #18356, however the solution didn't work for me, perhaps it works for tensorflow version below 2.0.
"
55321,distributed training with tensorflow on 'x' gpu makes loss 1/x,"I was trying to run a model on multiple gpu with `mirror strategy` of tensorflow.

I used a custom loss function like this:
```python3
def mae(y_true, y_pred):
	# y_true, y_pred shape  = (B, L)
	loss = tf.keras.metrics.mean_absolute_error(y_true, y_pred) 
	# loss shape = (B,)
	return loss
class custom_loss(tf.keras.losses.Loss):
	def __init__(self, BATCH_SIZE = 1, **kwargs):
		super(custom_loss, self).__init__(**kwargs)
		self.BATCH_SIZE = BATCH_SIZE

	def call(self, y_true, y_pred):
		# y_true, y_pred shape = (B, L, 1)
		loss = mae(tf.squeeze(y_true, [-1]), tf.squeeze(y_pred, [-1]))
		loss = tf.reduce_sum(loss) * (1. / self.BATCH_SIZE)
		return loss

	def get_config(self):
		config = super().get_config().copy()
		config.update({'BATCH_SIZE': self.BATCH_SIZE})
		return config
```

with mirror strategy I train the model like this:
```python3
def get_compiled_model(args, BATCH_SIZE):
	# Make a simple 2-layer densely-connected neural network.
	model = MyCustomModel(input_shape=(args.L, 1))
	model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=args.learning_rate, beta_1=args.beta_1, beta_2=args.beta_2, epsilon=args.epsilon), loss = custom_loss(BATCH_SIZE))
	return model

def run_training(args, steps, model = None):
	# Create a MirroredStrategy.
	strategy = tf.distribute.MirroredStrategy()
	BATCH_SIZE_PER_REPLICA = args.batch_size
	BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync

	# Open a strategy scope and create/restore the model
	with strategy.scope():
		if isinstance(model, type(None)):
			model = get_compiled_model(args, BATCH_SIZE)
		train_dataset, test_dataset, valid_dataset = get_dataset(args, BATCH_SIZE)
		callbacks = [
			tf.keras.callbacks.ModelCheckpoint(
				filepath=os.path.join(args.checkpoints_dir , steps + ""_epoch-{epoch:03d}_loss-{loss:.4f}""), save_best_only = True
			)
		]
		model.fit(train_dataset, epochs=args.epochs, callbacks=callbacks, validation_data = valid_dataset, steps_per_epoch = (None if args.steps_per_epoch == -1 else args.steps_per_epoch), validation_steps = (None if args.steps_per_epoch == -1 else args.steps_per_epoch), verbose = 1)
```

But if I run this on 4 GPU, my loss value becomes 1/4 times than the loss I get when run on single GPU. Does it fail to sum up the different losses from the different GPUs?"
55315,tfds.load Movie Lens  Failed to establish a new connection,"I am executing the code on colab using the CPU configuration. Then, I execute this sequence of `pip install`:

```
!pip install tfds-nightly
!pip install -q tensorflow-recommenders
!pip install -q --upgrade tensorflow-datasets==4.3
!pip install -q scann
```

**The Code That Caused the error:**

```Python
tfds.load(""movielens/100k-ratings"", split=""train"", shuffle_files = False)
```

This is the error message:

```Python
OSError                                   Traceback (most recent call last)
/usr/local/lib/python3.7/dist-packages/urllib3/connection.py in _new_conn(self)
    158             conn = connection.create_connection(
--> 159                 (self._dns_host, self.port), self.timeout, **extra_kw)
    160 

38 frames
OSError: [Errno 113] No route to host

During handling of the above exception, another exception occurred:

NewConnectionError                        Traceback (most recent call last)
NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7f834bc01790>: Failed to establish a new connection: [Errno 113] No route to host

During handling of the above exception, another exception occurred:

MaxRetryError                             Traceback (most recent call last)
MaxRetryError: HTTPConnectionPool(host='files.grouplens.org', port=80): Max retries exceeded with url: /datasets/movielens/ml-100k.zip (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f834bc01790>: Failed to establish a new connection: [Errno 113] No route to host'))

During handling of the above exception, another exception occurred:

ConnectionError                           Traceback (most recent call last)
/usr/local/lib/python3.7/dist-packages/requests/adapters.py in send(self, request, stream, timeout, verify, cert, proxies)
    514                 raise SSLError(e, request=request)
    515 
--> 516             raise ConnectionError(e, request=request)
    517 
    518         except ClosedPoolError as e:

ConnectionError: HTTPConnectionPool(host='files.grouplens.org', port=80): Max retries exceeded with url: /datasets/movielens/ml-100k.zip (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f834bc01790>: Failed to establish a new connection: [Errno 113] No route to host'))
```"
55313,Redundant `create_padding_mask(inp)` masks,"Hello,

  in your tutorial about Transormer I think there are redundant `create_padding_mask(inp)` masks. The same mask is created for Encoder and Decoder too. Please look here:

```python
    # Encoder padding mask
    enc_padding_mask = create_padding_mask(inp)

    # Used in the 2nd attention block in the decoder.
    # This padding mask is used to mask the encoder outputs.
    dec_padding_mask = create_padding_mask(inp)
```

It's the same padding mask created from `inp`. It's memory inefficient.
 
Link: https://www.tensorflow.org/text/tutorials/transformer#create_the_transformer

Thanks.
Have a nice day.

"
55312,"DeeplabV3 custom dataset, inference problem black images","Good morning,

I want to train a custom dataset using deeplabV3.

I'm following this tutorial (https://sanjayparajuli27.medium.com/how-to-train-deeplab-on-custom-dataset-a40c41c4c6a3) for this dataset (https://www.kaggle.com/datasets/dansbecker/cityscapes-image-pairs) that I found on Kaggle, based on cityscapes.

There are images of 256x256 pixel in RGB colors, divided in 2975 imgs for training and 500 for validation, and I created the respective mask using this script

```
import tensorflow as tf
from PIL import Image
from tqdm import tqdm
import numpy as np

import os, shutil

# palette (color map) describes the (R, G, B): Label pair
palette = {(0,   0,   0) : 0 ,
           (128,  0, 0) : 1,
           (0, 128, 0): 2,
           (128, 128, 0): 3,
           (0, 0, 128): 4,
           (0, 128, 128): 5,
           (128, 128, 128): 6,
           (64, 0, 0): 7,
           (192, 0, 0): 8,
           (64, 128, 0): 9,
           (192, 128, 0): 10,
           (64, 0, 128): 11,
           (192, 0, 128): 12,
           (64, 128, 128): 13,
           (0, 64, 0): 14,
           (128, 64, 0): 15,
           (0, 192, 0): 16,
           (128, 192, 0): 17,
           (0, 64, 128): 18,
           (128, 0, 128): 19
         }

def convert_from_color_segmentation(arr_3d):
    arr_2d = np.zeros((arr_3d.shape[0], arr_3d.shape[1]), dtype=np.uint8)

    for c, i in palette.items():
        m = np.all(arr_3d == np.array(c).reshape(1, 1, 3), axis=2)
        arr_2d[m] = i
    return arr_2d


label_dir = ""C:/Users/paolo.david/Desktop/Datasets/final/Validation/Mask_real/"" #don't forget the '/' at the end
new_label_dir = ""C:/Users/paolo.david/Desktop/Datasets/final/Validation/Mask_RAW2/""

if not os.path.isdir(new_label_dir):
    print(""creating folder: "",new_label_dir)
    os.mkdir(new_label_dir)
else:
    print(""Folder alread exists. Delete the folder and re-run the code!!!"")


label_files = os.listdir(label_dir)

for l_f in tqdm(label_files):
    #arr = np.array(Image.open(l_f))
    arr = np.array(Image.open(label_dir + l_f))
    arr = arr[:,:,0:3]
    arr_2d = convert_from_color_segmentation(arr)
    #Image.fromarray(arr_2d).save(label_dir)
    Image.fromarray(arr_2d).save(new_label_dir + l_f)
```

Each image in the dataset contain its same mask, so before to launch the new notebook I divided the image and the mask to have a situation like in the tutorial.

You can find my code here: https://drive.google.com/drive/folders/105JMDmujY6lknH3D74WM8R8S7jTb51qX?usp=sharing and this is the notebook https://drive.google.com/file/d/1xmUtLB-XPj4mZdqbx9SAQOXKSwxtxCLX/view?usp=sharing

I have a problem with the inference. Every time I launch the notebook with few epochs (less then 10) I receive good results, but trying to increase the number of epoch I have all black images.

These are the parameters that I used for the train:

```
--model_variant=""xception_65"" \
--atrous_rates=6 \
--atrous_rates=12 \
--atrous_rates=18 \
--output_stride=16 \
--decoder_output_stride=4 \
--train_crop_size=""256,256"" \
--train_batch_size=4 \
--training_number_of_steps=30 \
--initialize_last_layer=False \
--last_layers_contain_logits_only=True \
--fine_tune_batch_norm=False \
```

I edited the data_generator.py file putting

```
_CUSTOM_INFORMATION = DatasetDescriptor(
    splits_to_sizes={
        'train': 270,  # num of samples in train.txt
        'val': 30,  # num of samples in val.txt
    },
    num_classes=21, # classes+bg+ignore_label
    ignore_label=255,
)

_DATASETS_INFORMATION = {
    'cityscapes': _CITYSCAPES_INFORMATION,
    'pascal_voc_seg': _PASCAL_VOC_SEG_INFORMATION,
    'ade20k': _ADE20K_INFORMATION,
    'custom': _CUSTOM_INFORMATION  # custom dataset
}
```

I'm using a pretrained model downloaded from here: http://download.tensorflow.org/models/deeplabv3_cityscapes_train_2018_02_06.tar.gz

I keep the batch size at 4, and I don't know if it is correct or not. Can you tell me where could be the possible error?"
55311,can it possible improve the tf serving performance,"Now I train a recommend nn model offline ,and then predict it by tf serving on cpu online machine. There are 8 cores i just applied, and found it cost slow when predict it. More than 0.4% it costs 100ms when predict. The batch size request is 50. There are 167 one hot features and 3 full-connected layers.And the usage of cpu is also slow, it is only 20% usage.
How can i analyze the bottleneck of serving ,and can it possible to reduce the time cost ratio by adjust some parameters?

i have tried many ways followed this links https://www.tensorflow.org/tfx/serving/performance ,but it hardly worked.
Tf serving can't support many sparse features so well?"
55309,Node: 'model/conv1d/Conv1D' DNN library is not found.,"**System information**
- OS: Linux Ubuntu 20.04:
- TensorFlow installed from pip
- TensorFlow version: v2.8.0-rc1-32-g3f878cff5b6 2.8.0
- Python version: Python 3.8.10
- CUDA/cuDNN version: NVIDIA-SMI 510.47.03    Driver Version: 510.47.03    CUDA Version: 11.6   
- GPU model : [GeForce GTX 1650] 

Hello, everyone.
I'm trying to run a  convolutional neural network on tensorflow but I'm receiving the current error:

> 2022-03-21 10:40:20.665473: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
> 2022-03-21 10:40:20.687599: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
> 2022-03-21 10:40:20.687804: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
> 2022-03-21 10:40:22.544819: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
> To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
> 2022-03-21 10:40:22.545204: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
> 2022-03-21 10:40:22.545428: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
> 2022-03-21 10:40:22.545579: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
> 2022-03-21 10:40:22.815601: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
> 2022-03-21 10:40:22.815824: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
> 2022-03-21 10:40:22.815975: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
> 2022-03-21 10:40:22.816100: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2607 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1650, pci bus id: 0000:01:00.0, compute capability: 7.5
> Epoch 1/999999
> 2022-03-21 10:40:23.481069: E tensorflow/stream_executor/cuda/cuda_dnn.cc:361] Loaded runtime CuDNN library: 8.0.4 but source was compiled with: 8.1.0.  CuDNN library needs to have matching major version and equal or higher minor version. If using a binary install, upgrade your CuDNN library.  If building from sources, make sure the library loaded at runtime is compatible with the version specified during compile configuration.
> 2022-03-21 10:40:23.481615: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at conv_ops.cc:1120 : UNIMPLEMENTED: DNN library is not found.
> Traceback (most recent call last):
>   File ""CNN_regression.py"", line 367, in <module>
>     results = pd.concat([results,main(mode)], ignore_index=True)
>   File ""CNN_regression.py"", line 124, in main
>     history = model.fit(X_train, Y_train,
>   File ""/home/italocaliari/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py"", line 67, in error_handler
>     raise e.with_traceback(filtered_tb) from None
>   File ""/home/italocaliari/.local/lib/python3.8/site-packages/tensorflow/python/eager/execute.py"", line 54, in quick_execute
>     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
> tensorflow.python.framework.errors_impl.UnimplementedError: Graph execution error:
> 
> Detected at node 'model/conv1d/Conv1D' defined at (most recent call last):
>     File ""CNN_regression.py"", line 367, in <module>
>       results = pd.concat([results,main(mode)], ignore_index=True)
>     File ""CNN_regression.py"", line 124, in main
>       history = model.fit(X_train, Y_train,
>     File ""/home/italocaliari/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py"", line 64, in error_handler
>       return fn(*args, **kwargs)
>     File ""/home/italocaliari/.local/lib/python3.8/site-packages/keras/engine/training.py"", line 1384, in fit
>       tmp_logs = self.train_function(iterator)
>     File ""/home/italocaliari/.local/lib/python3.8/site-packages/keras/engine/training.py"", line 1021, in train_function
>       return step_function(self, iterator)
>     File ""/home/italocaliari/.local/lib/python3.8/site-packages/keras/engine/training.py"", line 1010, in step_function
>       outputs = model.distribute_strategy.run(run_step, args=(data,))
>     File ""/home/italocaliari/.local/lib/python3.8/site-packages/keras/engine/training.py"", line 1000, in run_step
>       outputs = model.train_step(data)
>     File ""/home/italocaliari/.local/lib/python3.8/site-packages/keras/engine/training.py"", line 859, in train_step
>       y_pred = self(x, training=True)
>     File ""/home/italocaliari/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py"", line 64, in error_handler
>       return fn(*args, **kwargs)
>     File ""/home/italocaliari/.local/lib/python3.8/site-packages/keras/engine/base_layer.py"", line 1096, in __call__
>       outputs = call_fn(inputs, *args, **kwargs)
>     File ""/home/italocaliari/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py"", line 92, in error_handler
>       return fn(*args, **kwargs)
>     File ""/home/italocaliari/.local/lib/python3.8/site-packages/keras/engine/functional.py"", line 451, in call
>       return self._run_internal_graph(
>     File ""/home/italocaliari/.local/lib/python3.8/site-packages/keras/engine/functional.py"", line 589, in _run_internal_graph
>       outputs = node.layer(*args, **kwargs)
>     File ""/home/italocaliari/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py"", line 64, in error_handler
>       return fn(*args, **kwargs)
>     File ""/home/italocaliari/.local/lib/python3.8/site-packages/keras/engine/base_layer.py"", line 1096, in __call__
>       outputs = call_fn(inputs, *args, **kwargs)
>     File ""/home/italocaliari/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py"", line 92, in error_handler
>       return fn(*args, **kwargs)
>     File ""/home/italocaliari/.local/lib/python3.8/site-packages/keras/layers/convolutional.py"", line 248, in call
>       outputs = self.convolution_op(inputs, self.kernel)
>     File ""/home/italocaliari/.local/lib/python3.8/site-packages/keras/layers/convolutional.py"", line 233, in convolution_op
>       return tf.nn.convolution(
> Node: 'model/conv1d/Conv1D'
> DNN library is not found.
> 	 [[{{node model/conv1d/Conv1D}}]] [Op:__inference_train_function_660]



I'm running the exact same code with another computer with a Nvidia MX110 and is working just fine. I think this might be a configuration/installation issue related to:

>  ""Loaded runtime CuDNN library: 8.0.4 but source was compiled with: 8.1.0.  CuDNN library needs to have matching major version and equal or higher minor version. If using a binary install, upgrade your CuDNN library.  If building from sources, make sure the library loaded at runtime is compatible with the version specified during compile configuration."" 

I could not find any solution to this problem.

Thank you all in advance.

"
55308,I am getting the same errors with version 2.8.0 and python 3.9.,"I am getting the same errors with version 2.8.0 and python 3.9.
I need to use class_weight cause of my data is heavily imbalanced. 
If I run without the class_weight, no errors.
Is there solutions or workarounds for this issue?
Thanks


When using a list for class_weight, I got:
```
  File ""/opt/local/stow/Python-3.7.1/lib/python3.7/site-packages/keras/engine/data_adapter.py"", line 1416, in _make_class_weight_map_fn
    class_ids = list(sorted(class_weight.keys()))
AttributeError: 'list' object has no attribute 'keys'
```
When using a dictionary for class_weight, I got:
```
  File ""/opt/local/lib/python3.7/site-packages/tensorflow/python/eager/execute.py"", line 55, in quick_execute
    inputs, attrs, num_outputs)
tensorflow.python.framework.errors_impl.InvalidArgumentError: Graph execution error:

indices[24] = 18 is not in [0, 10)
         [[{{node GatherV2}}]]
         [[IteratorGetNext]] [Op:__inference_train_function_43205]
```
These errors occur even when I give all classes a weight 1.

However, when I do not use class_weight in model.fit(), the training for my model just works fine.

So it looks like I just cannot use class_weight in training. But my classes are highly imbalanced; not using class weights would train a useless model.

I would really appreciate any solution or workaround for this issue.

Thank you very much!

_Originally posted by @lauraht in https://github.com/tensorflow/tensorflow/issues/40070#issuecomment-1066037695_"
55307,[TPU] TPUClusterResolver Can't Resolve TPU Metadata When Using Regional GKE Cluster,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): tensorflow/tensorflow:2.7.1, tensorflow/tensorflow:2.8.0
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.7.1, 2.8.0
- Python version: 3.8
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory: cloud-tpus.google.com/preemptible-v2: ""8""

**Describe the current behavior**
We have a GKE regional cluster with TPU support. When I tried to create a ResNet-RS using the official TPU guide, I encountered the issue with TPUClusterResolver.
```
Traceback (most recent call last):
  File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/tpu/client/client.py"", line 259, in _fetch_cloud_tpu_metadata
    r = service.projects().locations().nodes().get(name=self._full_name())
  File ""/usr/local/lib/python3.8/dist-packages/googleapiclient/discovery.py"", line 1044, in method
    raise TypeError(
TypeError: Parameter ""name"" value ""projects/[PROJECT-CODE]/locations/us-central1-b/nodes/us-central1-b/[TPU-RESOURCE]"" does not match the pattern ""^projects/[^/]+/locations/[^/]+/nodes/[^/]+$""

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/root/models/official/vision/beta/train.py"", line 70, in <module>
    app.run(main)
  File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 312, in run
    _run_main(main, args)
  File ""/usr/local/lib/python3.8/dist-packages/absl/app.py"", line 258, in _run_main
    sys.exit(main(argv))
  File ""/root/models/official/vision/beta/train.py"", line 50, in main
    distribution_strategy = distribute_utils.get_distribution_strategy(
  File ""/root/models/official/common/distribute_utils.py"", line 151, in get_distribution_strategy
    cluster_resolver = tpu_initialize(tpu_address)
  File ""/root/models/official/common/distribute_utils.py"", line 88, in tpu_initialize
    tf.config.experimental_connect_to_cluster(cluster_resolver)
  File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/remote.py"", line 141, in connect_to_cluster
    if cluster_spec_or_resolver.master() in _LOCAL_MASTERS:
  File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/cluster_resolver/tpu/tpu_cluster_resolver.py"", line 256, in master
    cluster_spec = self.cluster_spec()
  File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/cluster_resolver/tpu/tpu_cluster_resolver.py"", line 330, in cluster_spec
    network_endpoints = self._cloud_tpu_client.network_endpoints()
  File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/tpu/client/client.py"", line 346, in network_endpoints
    response = self._fetch_cloud_tpu_metadata()
  File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/tpu/client/client.py"", line 262, in _fetch_cloud_tpu_metadata
    raise ValueError(""Could not lookup TPU metadata from name '%s'. Please ""
ValueError: Could not lookup TPU metadata from name 'us-central1-b/[TPU-RESOURCE]'. Please doublecheck the tpu argument in the TPUClusterResolver constructor. Exception: Parameter ""name"" value ""projects/[PROJECT-CODE]/locations/us-central1-b/nodes/us-central1-b/[TPU-RESOURCE]"" does not match the pattern ""^projects/[^/]+/locations/[^/]+/nodes/[^/]+$""
```

**Describe the expected behavior**
The ResNet-RS job should run in TPU core without any issues.

**[Contributing](https://www.tensorflow.org/community/contribute)**

- Do you want to contribute a PR? (yes/no): No
- Briefly describe your candidate solution(if contributing): N/A

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.
https://cloud.google.com/tpu/docs/tutorials/resnet-rs-2.x
Run this guide in a regional GKE cluster with TPU support.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
```
apiVersion: v1
kind: Pod
metadata:
    endpoints.cloud-tpus.google.com/gke: grpc://10.0.0.106:8470
    name.cloud-tpus.google.com/gke: us-central1-b/[TPU-RESOURCE]
  name: gke
spec:
  containers:
  - command:
    - bash
    - -c
    - export PYTHONPATH=$PYTHONPATH:/root/models && cd /root && apt-get update &&
      apt-get install -y git && git clone https://github.com/tensorflow/models.git
      && pip3 install tf-models-nightly tensorflow-text-nightly && pip3 install -r
      models/official/requirements.txt && python3 /root/models/official/vision/beta/train.py
      --experiment=resnet_rs_imagenet --mode=train_and_eval --model_dir=$MODEL_DIR
      --tpu=$TPU_NAME --config_file=/root/models/official/vision/beta/configs/experiments/image_classification/imagenet_resnetrs50_i160.yaml
      --params_override=""task.train_data.input_path=$IMAGENET_DIR/train*, task.validation_data.input_path=$IMAGENET_DIR/valid*,
      trainer.train_steps=100"" && sleep 900
    env:
    - name: IMAGENET_DIR
      value: gs://cloud-tpu-test-datasets/fake_imagenet
    - name: STORAGE_BUCKET
      value: gs://xxxxx
    - name: MODEL_DIR
      value: gs://xxxxx/resnet-rs-2x_v6
    - name: GOOGLE_APPLICATION_CREDENTIALS
      value: /var/secrets/google/key.json
    - name: KUBE_GOOGLE_CLOUD_TPU_ENDPOINTS
      valueFrom:
        fieldRef:
          apiVersion: v1
          fieldPath: metadata.annotations['endpoints.cloud-tpus.google.com/gke-dgtest-tpu-resnetrs6']
    - name: TPU_NAME
      valueFrom:
        fieldRef:
          apiVersion: v1
          fieldPath: metadata.annotations['name.cloud-tpus.google.com/gke-dgtest-tpu-resnetrs6']
    image: tensorflow/tensorflow:2.8.0
```
"
55305,`tf.strings.unsorted_segment_join` crashes unexpectedly when `num_segments` is negative,"
**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below):2.8.0
- Python version: 3.7.12
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A

**Describe the current behavior**
Given the following code snippet:
```
import tensorflow as tf

try:
  tf.strings.unsorted_segment_join(inputs=['123'],segment_ids=[0],num_segments=-1)
except Exception:
  print('an exception should be thrown, but unsorted_segment_join crashes')

print('Not reached')
```
the call to `tf.strings.unsorted_segment_join`  causes a crash.

**Describe the expected behavior**

Since `num_segments` is negative, an exception should be thrown (perhaps an `InvalidArgumentError` or `ValueError`. The code should not crash.


**Standalone code to reproduce the issue**

The code snippet above should reproduce the issue. 

The following colab notebook (running the notebook should crash the session) demonstrates the issue: https://colab.research.google.com/drive/1zoYVGQXY9MlYgbtW4N3lC51yC8wQh5J2?usp=sharing

"
55304,`tf.recompute_grad` completely broken inside graph loop with big tensors,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes, provided.
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 Pro 21H1
- TensorFlow installed from: `pip`
- TensorFlow version (use command below): `v2.8.0-rc1-32-g3f878cff5b6 2.8.0`
- Python version: 3.7.8

**Describe the current behavior**
Use of the `tf.recompute_grad` decorator inside a graph-based loop (versus Python-based with Eager) results in invalid-argument `TypeError`s. Editing the TensorFlow source to realign the arguments then results in other errors (e.g. invoking graph-mode attributes on tensors in Eager mode).

**Describe the expected behavior**
No differences (beyond what `tf.recompute_grad` is advertised to do) from when `tf.recompute_grad` is removed.

**Standalone code to reproduce the issue**
```py
import tensorflow as tf
import tensorflow.keras.layers as layers

model = tf.keras.Sequential([
    layers.Conv2D(8, kernel_size=(5, 5), padding='same', input_shape=(24, 24, 3)),
    layers.MaxPooling2D(pool_size=(24, 24), padding='valid'),
    layers.Flatten(),
    layers.Dense(3),
])

@tf.function
def run_episode(
        model: tf.keras.Model,
        max_steps: int):
    
    outs = tf.TensorArray(tf.float32, size=0, dynamic_size=True)
    for t in tf.range(max_steps):
        ins = tf.random.uniform((16, 24, 24, 3))
        out = tf.recompute_grad(model)(ins)
        outs = outs.write(t, out)
            
    return outs.stack()

with tf.GradientTape() as tape:
    lp = run_episode(model, max_steps=500)
    sigma = tf.reduce_sum(lp)
g = tape.gradient(sigma, model.trainable_variables)
```

```
[...]
TypeError: Exception encountered when calling layer ""conv2d_2"" (type Conv2D).

Expected float32 passed to parameter 'filter' of op 'Conv2D', got <tf.Variable 'conv2d_2/kernel:0' shape=(5, 5, 3, 8) dtype=float32> of type 'ResourceVariable' instead. Error: Expected resource passed to parameter 'resource' of op 'ReadVariableOp', got <tf.Tensor: shape=(), dtype=resource, value=<Resource Tensor>> of type 'EagerTensor' instead. Error: _capture_helper() takes 3 positional arguments but 4 were given

Call arguments received:
  • inputs=tf.Tensor(shape=(16, 24, 24, 3), dtype=float32)
```"
55303,Code under tf.init_scope behaves differently than code manually lifted from graph.,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Colab with TPU
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.8.0
- Python version: 3.7.12
- CUDA/cuDNN version: -
- GPU model and memory: TPUv2

**Describe the current behavior**
I'm trying to implement sharding algorithm from paper https://arxiv.org/pdf/2010.05222.pdf. To emulate sharded variable I wrote wrappers for SaveableObject and tf.Variable with tf.VariableSynchronization.ON_READ and tf.VariableAggregation.NONE. At the restore from checkpoint moment I need to run Variable.assign in replica context to assign different values to shards on different TPU replicas.
SaveableObject.restore called under tf.init_scope: train_function -> step_function -> train_step -> optimizer.minimize -> apply_gradients -> tf.init_scope -> optimizer._create_all_weights -> _create_slots -> add_slot -> _restore_slot_variable -> restore.
There are two problems with tf.init_scope:
1) ReplicaContext.replica_id_in_sync_group is unusable. Attempt to use it leads to an error ""TypeError: <tf.Tensor 'replicated_input_0:0' shape=() dtype=int32> is out of scope and cannot be used here. Use return values, explicit Python locals or TensorFlow collections to access it."".
This colab demonstrates the issue https://colab.research.google.com/drive/1BjRHdrWG9mM75zHe43rpOlp-pfjE0kta?usp=sharing
2) Strategy.run (after merge_call) leads to an error ""NotImplementedError: tpu_shard_context cannot be nested.If you're using TPUEstimator with inference_on_tpu, make sure you have set export_saved_model_api_version=ExportSavedModelApiVersion.V2 in the creation of TPUEstimator.""
This colab demonstrates the issue https://colab.research.google.com/drive/1MVAWCQO5F6Pf0f2R0NZJd_djC1FTzrHU?usp=sharing

**Describe the expected behavior**
1) tf.distribute.ReplicaContext.replica_id_in_sync_group should be usable under tf.init_scope. It should be from current graph.
2) tf.distribute.Strategy.run should restart nesting counter under tf.init_scope and should be usable from tf.init_scope.

**[Contributing](https://www.tensorflow.org/community/contribute)**

- Do you want to contribute a PR? (yes/no): no
- Briefly describe your candidate solution(if contributing):

**Standalone code to reproduce the issue**
1) https://colab.research.google.com/drive/1BjRHdrWG9mM75zHe43rpOlp-pfjE0kta?usp=sharing
2) https://colab.research.google.com/drive/1MVAWCQO5F6Pf0f2R0NZJd_djC1FTzrHU?usp=sharing
"
55300,Installation Issue - OSError: [Errno 2] No such file or directory: ...\\BufferizableOpInterface.cpp.inc,"**System information**
- OS Platform and Distribution: Windows 11 Professional 
- TensorFlow installed from: binary (`pip install tensorflow`)
- TensorFlow version: 2.8.0
- Python version: 3.10.3
- Installed using virtualenv: `pip`
- CUDA/cuDNN version: 11.6
- GPU model and memory: NVIDIA RTX A2000 / RAM 32 GB

Trying to install tensorflow on my PC (system described above) and found an issue as follows at the end of `pip install tensorflow`:

```
Installing collected packages: tensorflow
ERROR: Could not install packages due to an OSError: [Errno 2] No such file or directory: 'C:\\Users\\%PathToRepo%\\tfenv\\Lib\\site-packages\\tensorflow\\include\\external\\llvm-project\\mlir\\_virtual_includes\\BufferizableOpInterfaceIncGen\\mlir\\Dialect\\Linalg\\ComprehensiveBufferize\\BufferizableOpInterface.cpp.inc'
```

`tfenv` is the name of the virtual environment I've created using the command `python -m venv --system-site-packages tfenv`.
I've installed the pre-requisite (Microsoft Visual C++ Redistributable for Visual Studio 2015, 2017 and 2019) from this [link](https://support.microsoft.com/help/2977003/the-latest-supported-visual-c-downloads). I'm guessing the error is somehow related to the MS Visual C++ or the virtual environment, but I'm not sure how.

Could you help me please? Thank you in advance."
55299,Using Numpy BitGenerator with TF-1.15 (?),"Hi
I am running minigo code from [here](https://github.com/mlcommons/training_results_v1.1/tree/main/NVIDIA/benchmarks/minigo/implementations/tensorflow/minigo). Although TF-1.15 and Numpy 1.17.3 are installed, I get the following error

```
  File ""freeze_graph.py"", line 19, in <module>
    import dual_net
  File ""/opt/reinforcement/minigo/dual_net.py"", line 32, in <module>
    import tensorflow as tf
  File ""/usr/local/lib/python3.8/dist-packages/tensorflow/__init__.py"", line 101, in <module>
    from tensorflow_core import *
  File ""/usr/local/lib/python3.8/dist-packages/tensorflow_core/__init__.py"", line 36, in <module>
    from tensorflow._api.v1 import compat
  File ""/usr/local/lib/python3.8/dist-packages/tensorflow_core/_api/v1/compat/__init__.py"", line 23, in <module>
    from tensorflow._api.v1.compat import v1
  File ""/usr/local/lib/python3.8/dist-packages/tensorflow_core/_api/v1/compat/v1/__init__.py"", line 673, in <module>
    from tensorflow_estimator.python.estimator.api._v1 import estimator
  File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/__init__.py"", line 10, in <module>
    from tensorflow_estimator._api.v1 import estimator
  File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/_api/v1/estimator/__init__.py"", line 12, in <module>
    from tensorflow_estimator._api.v1.estimator import inputs
  File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/_api/v1/estimator/inputs/__init__.py"", line 10, in <module>
    from tensorflow_estimator.python.estimator.inputs.numpy_io import numpy_input_fn
  File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/inputs/numpy_io.py"", line 26, in <module>
    from tensorflow_estimator.python.estimator.inputs.queues import feeding_functions
  File ""/usr/local/lib/python3.8/dist-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_functions.py"", line 40, in <module>
    import pandas as pd
  File ""/usr/local/lib/python3.8/dist-packages/pandas/__init__.py"", line 22, in <module>
    from pandas.compat import is_numpy_dev as _is_numpy_dev
  File ""/usr/local/lib/python3.8/dist-packages/pandas/compat/__init__.py"", line 14, in <module>
    from pandas._typing import F
  File ""/usr/local/lib/python3.8/dist-packages/pandas/_typing.py"", line 120, in <module>
    np.random.BitGenerator,
AttributeError: module 'numpy.random' has no attribute 'BitGenerator'
```
Any idea about that? Am I missing something?"
55298,org.tensorflow:tensorflow-lite-support:0.3.1 has missing files,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below):
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
When trying to deploy a TFLite model in Android Studio, I received the error ClassNotFound: about org.tensorflow.lite.support.common.SupportPreconditions.
**Describe the expected behavior**
No error.
**[Contributing](https://www.tensorflow.org/community/contribute)**

- Do you want to contribute a PR? (yes/no):
- Briefly describe your candidate solution(if contributing):

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.
modelPath = ""local_path_of_model""
AudioClassifier model = AudioClassifier.createFromFile(requireContext(), modelPath);
TensorAudio tensor = model.createInputTensorAudio();
AudioRecord record = model.createAudioRecord();

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
When I downgraded to org.tensorflow:tensorflow-lite-support:0.3.0, I didn't receive the error anymore.
"
55297,how to change tensorflow version if build from source?,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04 lts
- TensorFlow installed from (source or binary): source
- TensorFlow version: master
- Python version: 3.10.2
- Bazel version (if compiling from source): 5.0.0
- GCC/Compiler version (if compiling from source): 9.3.0
- CUDA/cuDNN version: 11.2/8.1
- GPU model and memory: RTX 3090



**Describe the problem**

I am trying to build tensorflow from source. Everything works good and I successfully build it based on master branch. 

After I get the `.whl` package, I installed it and checked the version number. I get the following output:

```
Python 3.9.5 (default, Jun 18 2021, 13:37:06)
[GCC 9.3.0] on linux
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import tensorflow as tf
>>> tf.__version__
'2.9.0'
>>>
```

I get the version number as `'2.9.0'`. it makes sense as I build based on master branch and the current release is `2.8.0`. However, I wish to customize the version number, for example, as `2.9.0--xxx` so that I know what features I added into this build. I thought there should be a setup file or something I can change but I cannot find it. Any ideas? Thx!

"
55296,Upstream Gradient of variables in tf.custom_gradient is (unexpectedly and seemingly generally) zero,"**System information**
TF 2.8, via Google Colab (so none of the other information should be relevant here?)

**Describe the current behavior**
Using tf.custom_gradient the upstream of a variable currently seems to be zero generally. Exemplary code:

```
def call_model_with_weights(model, x, weights):
  vars = [var.assign(val) for var, val in zip(model.trainable_weights, weights)]
  y = model(x)
  len_vars = len(weights)
  len_y = len(y)

  #stitching together the gradient
  @tf.custom_gradient
  def copy_gradient(var, val, y):
    def grad(*upstream):
      var_up = upstream[:len_vars]
      y_up = upstream[len_vars:]
      return var_up, var_up, y_up

    return (var, y), grad

  _, _y = copy_gradient(model.trainable_weights, weights, y) #this does not change when changing 'model.trainable_weights' to 'vars'
  return _y

model=some_model
x=some_input
weights = some_list_of_model_weights_with_appropriate_shapes #in the simplest case just model.trainable_weights
with tf.GradientTape() as tape:
  tape.watch(weights)
  y = call_model_with_weights(model, x, weights)
gradient=tape.gradient(y, weights) #this gradient is zero (not even NaN as in not connected, but just appropriate shapes of zeros)
```

(background: Trying to implement an equivalent to PyTorch [higher](https://github.com/facebookresearch/higher) library, to enable meta-learning research also on TF, where it currently strongly lacks behind)

I have come upon this while trying to implement a wrapper that calls a function as a function of weights. I observe that generally, the upstream gradient of any variable seems to be zero.

I'm reporting this as a bug, because the behavior is (1) unexpected, (2) undocumented (from what I could find at least), and (3) the expected behavior would generally be more useful from what I understand. 

A full colab notebook reproducing the problem can be found here: https://colab.research.google.com/drive/1kSQhgtxaIhwwpzp0VObZQbqGC0dmxeNc?usp=sharing

I hope this is not just some other stupid coding mistake I made somewhere, but I've been trying to eliminate any other possible reasons for this behavior I could come up with.


**Describe the expected behavior**
The upstream gradient of a variable in tf.custom_gradient should be the actual upstream gradient, not a vector of zeros of the same shape

- Do you want to contribute a PR? (yes/no): Since I'm not sure how thiis could be fixed, no; If I get pointed in the correct direction I will happily do that! 
- Briefly describe your candidate solution(if contributing): See above

**Standalone code to reproduce the issue**
Link again: https://colab.research.google.com/drive/1kSQhgtxaIhwwpzp0VObZQbqGC0dmxeNc?usp=sharing

**Other info / logs** 
None"
55295,Plugin implementation of AssignVarOp,"I am struggling a lot to understand how plugins (pluggable device) should implement `AssignVarOp`.

I created a [post](https://discuss.tensorflow.org/t/how-does-assignvarop-work/8335/3) on the discussion forum but it seems like no one is able to answer pluggable device questions.

I am trying to run a `Conv2D` on a separate device (only dummy for now) using the pluggable device interface.
I implemented the `Conv2D` kernel, and when running tensorflow asked for an implementation of `AssignVarOp`.
So I started implementing `AssignVarOp`, it has two input tensors (variable and value), variable is a tensor of type `TF_RESOURCE`.
I imagine I should modify the data of the resource tensor, but what does it contain?
After further research, it looks like `VarHandleOp` is the kernel responsible for the creation of the variable (and it's resource). 
So I wrote a kernel for `VarHandleOp`. Checking the parameters at runtime, they are all uninitialized at the first call (`shared_name` is a default value, `shape` unitialized, etc).
So I am left with two choices:
- Either I would update the variable attributes later (doesn't seem possible as the C api doesn't provide any function for modifying an input tensor dimensions)
- Either I should store all dimensions, etc in the resource tensor data in the form of a `ResourceHandle`. Is this `Resourcehandle` type arbitrarily defined by the user?

I have been following this basic [tutorial](https://github.com/jzhoulon/community/blob/plugin_tutorial/rfcs/20200624-pluggable-device-for-tensorflow/tutorial.md) for writing tensorflow plugins, but the logic for variable handling is missing and it seems like a necessary step for plugins.

**I will be really thankful if the tensorflow team (or anyone) could help me understand the mechanism of variable handling for plugins.**

**Thank you.**"
55294,Updates ,"This template is for miscellaneous issues not covered by the other issue categories.

For questions on how to work with TensorFlow, or support for problems that are
not verified bugs in TensorFlow, please go to
[Discourse](https://discuss.tensorflow.org/).

If you are reporting a vulnerability, please use the [dedicated reporting process](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md).

For high-level discussions about TensorFlow, please post to discuss@tensorflow.org, for questions about the development or internal workings of TensorFlow, or if you would like to know how to contribute to TensorFlow, please post to developers@tensorflow.org.
"
55293,Update ,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below):
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

**Describe the expected behavior**

**[Contributing](https://www.tensorflow.org/community/contribute)**

- Do you want to contribute a PR? (yes/no):
- Briefly describe your candidate solution(if contributing):

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

"
55292,"`tf.experimental.numpy.array` should have the same behavior as `numpy.array`, but currently crashes","
**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): N/A
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.8.0
- Python version: 3.7.12
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A


**Describe the current behavior**

Currently, the following code snippet below leads to a crash due to the incorrect value of `ndmin`.
```
a = tf.constant(value=1)
b = tf.constant(value=1000)
tf.experimental.numpy.array(val=a,ndmin=b)
```

**Describe the expected behavior**

It should not crash.
It should have the  same behavior as numpy.array given the same inputs (in which ndmin is validated):
`ValueError: ndmin bigger than allowable number of dimensions NPY_MAXDIMS (=32)`

**[Contributing](https://www.tensorflow.org/community/contribute)**

- Do you want to contribute a PR? (yes/no):
- Briefly describe your candidate solution(if contributing):

**Standalone code to reproduce the issue**
The following colab demonstrates the issue:
https://colab.research.google.com/drive/1Voz0WB5TCt3s5pQ2etIU3HFBZqN-YVFc?usp=sharing

"
55291,Missing information on headers providing symbols,"While scrolling through the API documentation I was missing the information on which headers (for C/C++) the TF (and TFLite) APIs want me to include. As I'm using [IWYU](https://github.com/include-what-you-use/include-what-you-use) it would be nice if the documentation could provide clear guidance on which headers of the API are regarded as internal implementation details and which headers are meant for use by foreign code.

Questions that should be answered by the documentation are (e.g.):
* Is there a central (set of) header(s) to include? If so which?
* Are there certain headers meant for inclusion to group several related includes?
* What headers are not typically meant for use by foreign code?"
55290,"tf.nn.ctc_loss documentation misleads about GPU support, leading to 50x performance difference","## URL(s) with the issue:

https://www.tensorflow.org/api_docs/python/tf/nn/ctc_loss

## Description of issue (what needs changing):

[The documentation for `tf.nn.ctc_loss`](https://github.com/tensorflow/tensorflow/blob/v2.8.0/tensorflow/python/ops/ctc_ops.py#L790) states:
> On TPU and GPU: Only dense padded labels are supported.
> On CPU: Caller may use SparseTensor or dense padded labels but calling with a SparseTensor will be significantly faster.

However, reading through [the code for the CTC loss implementation](https://github.com/tensorflow/tensorflow/blob/v2.8.0/tensorflow/python/ops/ctc_ops.py#L921-L957) shows that SparseTensors _are_ supported on GPU, and in practice, the SparseTensor code path uses CUDNN and is about 50x faster than the non-sparse code path.

I have tested this on GPU, but not on TPU, where I expect the documentation may be accurate (as the CUDNN code path doesn't apply to TPU). 

### Submit a pull request?

Would be happy to, after confirmation that this is indeed an issue.

cc @kaixih, @f90"
55289,The code says that it failed to save and then never ran properly again. basically i upload a picture and then it shows the right prediction but the second picture it run into error but if i start with second photo as my first inout then it show the correct prediction ,"from google.colab import files
uploaded = files.upload()

new_image = plt.imread('20220316_134951.jpg')
img = plt.imshow(new_image)

from skimage.transform import resize
resized_image = resize(new_image, (IMG_SIZE,IMG_SIZE,3))
img = plt.imshow(resized_image)



predictions = model.predict(np.array([resized_image]))

predictions

list_index = [0,1,2,3,4]
x = predictions

for i in range(5):
  for j in range(5):
    if x[0][list_index[i]] > x[0][list_index[j]]:
      temp = list_index[i]
      list_index[i] = list_index[j]
      list_index[j] = temp

for i in range(3):
  print(CATEGORIES[list_index[i]], ':', predictions[0][list_index[i]] *100, '%')

print(CATEGORIES[list_index[0]])
"
55285,Crashed if using different types of grad in adadelta optimizer,"


I'm trying to use adadelta optimizer in my training process but it crashed. It came to that I used different types of value in grad parameters.

**System information**

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.8.0
- Python version: 3.7.11

**Describe the current behavior**

Crashed with error info.

**Describe the expected behavior**

Error info could show the wrong type and would not crash.


**Standalone code to reproduce the issue**
```
from tensorflow.python.eager import context
from tensorflow.python.framework import constant_op
from tensorflow.python.framework import dtypes
from tensorflow.python.ops import variables
from tensorflow.python.training import adadelta


if __name__ == ""__main__"":
    num_updates = 4
    for grad in [0.2, 0.1, 0.01]:
      for lr in [1.0, 0.5, 0.1]:
          var0_init = [1.0, 2.0]
          var1_init = [3.0, 4.0]
          var0 = variables.Variable(var0_init, dtype=dtypes.float32)
          var1 = variables.Variable(var1_init, dtype=dtypes.float32)
          grads = constant_op.constant([grad, grad], dtype=dtypes.float16) # will pass if use dtypes.float32
          accum = 0.0
          accum_update = 0.0
          rho = 0.95
          epsilon = 1e-08

          adadelta_opt = adadelta.AdadeltaOptimizer(learning_rate=lr, rho=rho, epsilon=epsilon)
          if (not context.executing_eagerly()):
              adadelta_update = adadelta_opt.apply_gradients(zip([grads, grads], [var0, var1]))

              slot = ([None] * 2)
              slot_update = ([None] * 2)

          for step in range(num_updates):
              adadelta_opt.apply_gradients(zip([grads, grads], [var0, var1]))
```

**Other info / logs** Include any logs or source code that would be helpful to

```
2022-03-19 05:46:32.562381: F tensorflow/core/framework/tensor.cc:718] Check failed: dtype() == expected_dtype (1 vs. 19) half expected, got float

Aborted (core dumped)
```
"
55284,self._interpreter.AllocateTensors() returns with error : +1: Node number 189 (ADD) failed to prepare.,"After converting model to tflite successfully getting error at interpreter.AllocateTensors() 
### 1. System information
tensorflow 2.6
onnx 1.9
python 3.6

#### code to invoke the TFLite Converter Python API and the errors.
converter = tf.lite.TFLiteConverter.from_saved_model('/model.pb')
 converter.target_spec.supported_ops = [
        tf.lite.OpsSet.TFLITE_BUILTINS,  # enable TensorFlow Lite ops.
        tf.lite.OpsSet.SELECT_TF_OPS  # enable TensorFlow ops.
    ]
    
  tflite_model = converter.convert()
  tflite_model_path = 'test_net_.tflite'
    # Save the model
  with open(tflite_model_path, 'wb') as f:
        f.write(tflite_model)
interpreter = tf.lite.Interpreter(model_path=""test_net_.tflite"")
interpreter.allocate_tensors()

error logs:
INFO: Created TensorFlow Lite delegate for select TF ops.
2022-03-18 12:56:44.148260: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-03-18 12:56:44.149833: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1835] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.
Skipping registering GPU devices...
INFO: TfLiteFlexDelegate delegate: 11 nodes delegated out of 1402 nodes with 3 partitions.

INFO: TfLiteFlexDelegate delegate: 0 nodes delegated out of 1 nodes with 0 partitions.

INFO: TfLiteFlexDelegate delegate: 0 nodes delegated out of 0 nodes with 0 partitions.

INFO: TfLiteFlexDelegate delegate: 0 nodes delegated out of 0 nodes with 0 partitions.

INFO: TfLiteFlexDelegate delegate: 0 nodes delegated out of 1 nodes with 0 partitions.

INFO: TfLiteFlexDelegate delegate: 0 nodes delegated out of 1 nodes with 0 partitions.

INFO: TfLiteFlexDelegate delegate: 0 nodes delegated out of 0 nodes with 0 partitions.

INFO: TfLiteFlexDelegate delegate: 0 nodes delegated out of 0 nodes with 0 partitions.

INFO: TfLiteFlexDelegate delegate: 0 nodes delegated out of 1 nodes with 0 partitions.

INFO: TfLiteFlexDelegate delegate: 0 nodes delegated out of 2 nodes with 0 partitions.

INFO: TfLiteFlexDelegate delegate: 0 nodes delegated out of 14 nodes with 0 partitions.

INFO: TfLiteFlexDelegate delegate: 0 nodes delegated out of 2 nodes with 0 partitions.

INFO: TfLiteFlexDelegate delegate: 0 nodes delegated out of 14 nodes with 0 partitions.

INFO: TfLiteFlexDelegate delegate: 0 nodes delegated out of 2 nodes with 0 partitions.

INFO: TfLiteFlexDelegate delegate: 0 nodes delegated out of 14 nodes with 0 partitions.

INFO: TfLiteFlexDelegate delegate: 0 nodes delegated out of 1 nodes with 0 partitions.

INFO: TfLiteFlexDelegate delegate: 0 nodes delegated out of 14 nodes with 0 partitions.

INFO: TfLiteFlexDelegate delegate: 0 nodes delegated out of 1 nodes with 0 partitions.

INFO: TfLiteFlexDelegate delegate: 0 nodes delegated out of 8 nodes with 0 partitions.

INFO: TfLiteFlexDelegate delegate: 0 nodes delegated out of 2 nodes with 0 partitions.

INFO: TfLiteFlexDelegate delegate: 0 nodes delegated out of 14 nodes with 0 partitions.

INFO: TfLiteFlexDelegate delegate: 0 nodes delegated out of 2 nodes with 0 partitions.

INFO: TfLiteFlexDelegate delegate: 0 nodes delegated out of 14 nodes with 0 partitions.

INFO: TfLiteFlexDelegate delegate: 0 nodes delegated out of 2 nodes with 0 partitions.

INFO: TfLiteFlexDelegate delegate: 0 nodes delegated out of 14 nodes with 0 partitions.

INFO: TfLiteFlexDelegate delegate: 0 nodes delegated out of 2 nodes with 0 partitions.

INFO: TfLiteFlexDelegate delegate: 0 nodes delegated out of 14 nodes with 0 partitions.

INFO: TfLiteFlexDelegate delegate: 0 nodes delegated out of 2 nodes with 0 partitions.

INFO: TfLiteFlexDelegate delegate: 0 nodes delegated out of 14 nodes with 0 partitions.

INFO: TfLiteFlexDelegate delegate: 0 nodes delegated out of 2 nodes with 0 partitions.

INFO: TfLiteFlexDelegate delegate: 0 nodes delegated out of 14 nodes with 0 partitions.

INFO: TfLiteFlexDelegate delegate: 0 nodes delegated out of 1 nodes with 0 partitions.

INFO: TfLiteFlexDelegate delegate: 1 nodes delegated out of 14 nodes with 1 partitions.

INFO: TfLiteFlexDelegate delegate: 0 nodes delegated out of 1 nodes with 0 partitions.

INFO: TfLiteFlexDelegate delegate: 0 nodes delegated out of 8 nodes with 0 partitions.

INFO: TfLiteFlexDelegate delegate: 0 nodes delegated out of 2 nodes with 0 partitions.

INFO: TfLiteFlexDelegate delegate: 0 nodes delegated out of 14 nodes with 0 partitions.

INFO: TfLiteFlexDelegate delegate: 0 nodes delegated out of 2 nodes with 0 partitions.

INFO: TfLiteFlexDelegate delegate: 0 nodes delegated out of 14 nodes with 0 partitions.

INFO: TfLiteFlexDelegate delegate: 0 nodes delegated out of 2 nodes with 0 partitions.

INFO: TfLiteFlexDelegate delegate: 0 nodes delegated out of 14 nodes with 0 partitions.

INFO: TfLiteFlexDelegate delegate: 0 nodes delegated out of 2 nodes with 0 partitions.

INFO: TfLiteFlexDelegate delegate: 0 nodes delegated out of 14 nodes with 0 partitions.

Traceback (most recent call last):
  
  File ""/home/usr/.local/lib/python3.6/site-packages/tensorflow/lite/python/interpreter.py"", line 423, in allocate_tensors
    return self._interpreter.AllocateTensors()
RuntimeError: Given shapes, [1, 63, 95, 256] and [1, 64, 96, 256], are not broadcastable.Node number 189 (ADD) failed to prepare.

"
55283,The tensorflow training freezes for no reason,"I run a deep learning training code written in tensorflow and it seems stuck at the following code:
```python
history = model.fit(X_train_all, Y_train_all,
                        epochs=nb_epoch,
                        batch_size=batch_size,
                        validation_data=(X_test, Y_test),
                        # callbacks=[early_stopping, model_checkpoint],
                        # callbacks=[model_checkpoint, lr_callback],
                        callbacks=[model_checkpoint],
                        verbose=0)
```
I tried to look closely and found it actually stuck at 
```python
# coding=utf-8
def outer_factory():

    def inner_factory(ag__):

        def tf__rmse(y_true, y_pred):
            with ag__.FunctionScope('rmse', 'fscope', ag__.STD) as fscope:
                do_return = False
                retval_ = ag__.UndefinedReturnValue()
                try:
                    do_return = True
                    retval_ = (ag__.converted_call(ag__.ld(mean_squared_error), (ag__.ld(y_true), ag__.ld(y_pred)), None, fscope) ** 0.5)
                except:
                    do_return = False
                    raise
                return fscope.ret(retval_, do_return)
        return tf__rmse
    return inner_factory
```
The outputs:
```bash
training model...
/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py:3504: UserWarning: Even though the tf.config.experimental_run_functions_eagerly option is set, this option does not apply to tf.data functions. tf.data functions are still traced and executed as graphs.
  ""Even though the tf.config.experimental_run_functions_eagerly ""
2022-03-18 07:54:21.572669: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2022-03-18 07:54:21.589590: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2300020000 Hz
2022-03-18 07:54:21.624242: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8
2022-03-18 07:54:23.469658: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11
2022-03-18 07:54:23.863409: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.11
/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py:3504: UserWarning: Even though the tf.config.experimental_run_functions_eagerly option is set, this option does not apply to tf.data functions. tf.data functions are still traced and executed as graphs.
  ""Even though the tf.config.experimental_run_functions_eagerly ""
```
<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): `pip3 install tensorflow ==2.4.1`
- TensorFlow version (use command below): tensorflow                    2.4.1
- Python version: Python 3.6.9
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: CUDA Version: 11.6 
- GPU model and memory: Tesla V100-SXM2...

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

**Describe the expected behavior**

**[Contributing](https://www.tensorflow.org/community/contribute)**

- Do you want to contribute a PR? (yes/no):
- Briefly describe your candidate solution(if contributing):

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
55282,TFX Starter Tutorial Typo,"Hello,

there is a typo in the TFX [starter tutorial](https://www.tensorflow.org/tfx/tutorials/tfx/penguin_simple#run_the_pipeline).

LocalDagRunner provides fast iterations for **developemnt** and debugging. TFX also supports other orchestrators including Kubeflow Pipelines and Apache Airflow which are suitable for production use cases."
55279,Build from Source Instructions for Tensorflow C++ on Linux,"Thank you for submitting a TensorFlow documentation issue. Per our GitHub
policy, we only address code/doc bugs, performance issues, feature requests, and
build/installation issues on GitHub.

The TensorFlow docs are open source! To get involved, read the documentation
contributor guide: https://www.tensorflow.org/community/contribute/docs

## URL(s) with the issue:

https://www.tensorflow.org/api_docs/cc
https://blog.devgenius.io/standalone-c-build-tensorflow-opencv-6dc9d8a1412d

## Description of issue (what needs changing):
Please could you provide clear instructions for building Tensorflow C++ 2.x (2.4 and above) on Linux and potentially how to use the built library in a project with all its dependencies such as Eigen, protobuf and abseil? 

### Clear description
The documentation says that Tensorflow provides a stable C++ API but no build and usage (compiling and linking with CMake) appear to exist in documentation. I have spent a lot of time  dredging  for relevant information in articles and stackoverflow and realised that most of it is outdated becasue bazel-genfiles  folder doesnt exist and has been replaced quite possibly with bin folder, and there is no contrib file as well anymore which allowed easy building of dependencies. 

It would be of great help if the Tensorflow Developers could demonstrate through a simple example for VS Code (it has become a standard) in Ubuntu, how to compile and link the library using CMake and ideally a descriptive example where a developer gets the idea of the capability of C++ API? It would be very useful if you could please make it clear what is possible with C++ API and what is not. For instance if C++ API also allows building the graph or just accepts the .pb file or how much of this example can be done in C++ API for instance as a cross reference: https://www.tensorflow.org/tensorboard/tensorboard_profiling_keras ? 

Is it possible to do everything in C++ and not use Python at all ? 

Why should someone use this method? How is it useful?
Tensorflow documentation should be the one stop shop for all official information about tensorflow especially associated with building, compiling and linking the library where the API is available, There is information on C API but not C++. Tensorflow is written in C++ (I believe) so it is not unfair to request the developers to help guide the users, how to use the C++ API well. Not sure why this hasn't already been done. If this information exists somewhere, I would very much appreciate if you could please make it more obvious. Python is popular but C++ is also useful in production performant environments. You all are doing a great job developing and building this library and I can only be grateful for that. I am very much hoping that you would help me and many other developers. Thanks very much. 


"
55278,tf.function condition with tensor,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Colab
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
colab
- TensorFlow version (use command below):
default colab
- Python version:
default colab
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
```python 
@tf.function
def test():
  b = tf.math.maximum(0,1)
  if 0 < b <= 2:
   b = b+1
  return b
test().numpy()
```
```python
OperatorNotAllowedInGraphError: in user code:

    File ""<ipython-input-80-cfa5312e70c9>"", line 4, in test  *
        if 0 < b <= 2:

    OperatorNotAllowedInGraphError: using a `tf.Tensor` as a Python `bool` is not allowed: AutoGraph did convert this function. This might indicate you are trying to use an unsupported feature.
```


**Describe the expected behavior**
I suppose that it will give `2` as with this little modified version:

```python
@tf.function
def test():
  b = tf.math.maximum(0,1)
  if 0 < b and b <= 2:
   b = b+1
  return b
test().numpy()
```
```python
2
```
**[Contributing](https://www.tensorflow.org/community/contribute)**

- Do you want to contribute a PR? (yes/no):
With some hints
- Briefly describe your candidate solution(if contributing):
I need some pointer

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
55277,Tensorflow Model Compiler Metrics Error: NaN Outputs,"I am having a problem using Tensorflow when trying to use two custom metric functions which calculate the mean and maximum fractional errors. My code for these functions are the following:

```
meanFE = np.sum(np.abs(f_emulator - f_test))
maxFE = np.max(np.abs(f_emulator - f_test))
```

When I try to use these metrics, all of the loss outputs go to NaN. If I use my meanFE and maxFE outside of Tensorflow, I don't encounter this issue. The only way I have been able to use these functions in Tensorflow is to remove the denominator term in the fractional errors, but this defeats the purpose of using a fractional error in the first place. I suspect this has something to do with the fact that my arrays get turned into Tensor objects by default when the system trains. My inputs are astronomical spectra (i.e., each spectrum is an array of shape (500 x 100), or there are 500 spectral arrays with 100 wavelength bins per array.

I have tried using other built in functions for my metrics, namely the MAPE function (mean absolute percentage error), but this generates bad spectra (output spectra do not look like input spectra), so I am trying to implement my own shown above. Has anyone encountered NaN outputs as your loss and metric output when using functions such as these? I am using Tensorflow 1.14.0 on macOS."
55276,"Event file summary metric type changed, breaking the example in summary_iterator.py","Thank you for submitting a TensorFlow documentation issue. Per our GitHub
policy, we only address code/doc bugs, performance issues, feature requests, and
build/installation issues on GitHub.

The TensorFlow docs are open source! To get involved, read the documentation
contributor guide: https://www.tensorflow.org/community/contribute/docs

## URL(s) with the issue:

[Please provide a link to the documentation entry, for example:
https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/](https://github.com/tensorflow/tensorflow/blob/r2.0/tensorflow/python/summary/summary_iterator.py#L45)

## Description of issue (what needs changing):

### Clear description
```
  for e in tf.compat.v1.train.summary_iterator(path to events file):
      for v in e.summary.value:
          if v.tag == 'loss':
              print(v.simple_value)
```
Some version between TF 2.3 and TF 2.8, it seems the behavior of logging metrics in TB event files changed. Before, values were logged as `simple_value` in the proto. Now, it is logged as a tensor that requires additional parsing with `tf.make_ndarray()` for example. As a result, this example in the documentation here no longer works. I'm not sure if the change to metrics writing was intentional (wasn't able to find release notes on that) but we should update the documentation here to a working one.

TF 2.3 gist: https://colab.research.google.com/gist/timatim/067edda865dc9c0899bda0befd97930c/beginner.ipynb
```
v.simple_value
```
TF 2.8 gist: https://colab.research.google.com/gist/timatim/2828cf9aa67e77d20baa22fc9935a684/beginner.ipynb
```
tf.make_ndarray(v.tensor)
```"
55270,"model.fit error, I need to adjust my code for a 5 categories instead of two.","
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D



X = pickle.load(open(""X.pickle"",""rb""))
y = pickle.load(open(""y.pickle"",""rb""))

X = X/255.0


model = Sequential()

model.add(  Conv2D(64,  (3,3), input_shape = X.shape[1:]  ))
model.add(Activation(""relu""))
model.add(MaxPooling2D(pool_size=(2,2)))

model.add(Conv2D(64,  (3,3)))
model.add(Activation(""relu""))
model.add(MaxPooling2D(pool_size=(2,2)))

model.add(Flatten())
model.add(Dense(64))
model.add(Activation(""relu""))

model.add(Dense(1))
model.add(Activation('sigmoid'))

model.compile(loss=""categorical_crossentropy"",
              optimizer=""adam"",
              metrics=['accuracy'])

model.fit(X, [y], batch_size=32, epochs=30, validation_split=0.1)"
55269,"Hexagon delegate doesn`t work on Android devices, cannot be loaded library UnsatisfiedLinkError (CMake)","**System information**
- OS Platform and Distribution: build with ubuntu:18.04(docker image)
-  Samsung S7 tab (SM-T875, Android12, Snapdragon 865), Samsung S21 (SM-G9910, Snapdragon 888, Android 12), Vivotek FT9392-EHTV-0 (Smart Camera, Qualcomm SOC, Custom Android OS API 27 - Azena OS)
- TensorFlow version: 2.5.0
- Python version: 3.6
- Installed using bazel build
- Bazel version: bazel-3.7.2
- Compiler version: clang(ndk;18.1.5063045)
- CUDA/cuDNN version: not used
- GPU model and memory:  not used



**Describe the problem**

**Provide the exact sequence of commands / steps that you executed before running into the problem**
TF build with this command:
```
    bazel --output_base=. build -c opt --config=android_arm64 //tensorflow/lite:libtensorflowlite.so && \
    bazel --output_base=. build -c opt --config=android_arm64 tensorflow/lite/delegates/hexagon:hexagon_delegate && \
    bazel --output_base=. build -c opt --config=android_arm64  tensorflow/lite/delegates/hexagon/hexagon_nn:libhexagon_interface.so
```
Linkage: 
CMake:
```
target_link_libraries(TFLite INTERFACE ""/opt/tflite/lib/libtensorflowlite.so"" ""/opt/tflite/lib/libhexagon_delegate.so"" ""/opt/tflite/lib/libhexagon_interface.so"" log)
```
CppCode (based on https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/tools/evaluation/utils.cc#L132):
```
tflite::Interpreter::TfLiteDelegatePtr CreateHexagonDelegate(
 const TfLiteHexagonDelegateOptions* options,
 const std::string& library_directory_path) {
	if (library_directory_path.empty()) {
		TfLiteHexagonInit();
	} else {
		TfLiteHexagonInitWithPath(library_directory_path.c_str());
	}

	TfLiteDelegate* delegate = TfLiteHexagonDelegateCreate(options);
	if (!delegate) {
		TfLiteHexagonTearDown();
		return CreateNullDelegate();
	}
	return tflite::Interpreter::TfLiteDelegatePtr(delegate, [](TfLiteDelegate* delegate) {
		TfLiteHexagonDelegateDelete(delegate);
		TfLiteHexagonTearDown();
	});
}

tflite::Interpreter::TfLiteDelegatePtr CreateDelegate() {
        // path from tablet
	std::string library_directory_path = ""/system/vendor/lib/rfsa/adsp"";
	TfLiteHexagonDelegateOptions options = {0};
	bool profiling = true;
	options.print_graph_profile = profiling;
	return CreateHexagonDelegate(&options, library_directory_path);
}
```

Aar contains: libhexagon_interface.so; libhexagon_delegate.so; libtensorflowlite.so; libhexagon_nn_skel(_v66/_v65/).so

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
```
Failed to load library
    java.lang.UnsatisfiedLinkError: dlopen failed: library ""libadsprpc.so"" not found: needed by /data/app/~~61iiTanIn8XaBlzk1Msb3g==/com.brainbuilder-fKAm_DWPORj_MBhTzkwZqQ==/base.apk!/lib/arm64-v8a/libhexagon_interface.so in namespace classloader-namespace
```"
55268,Build TensorFlow Lite for iOS on macOS Mojave,"Hello,
I'm trying to build TensorFlow Lite 2.8.0 for iOS on an Intel MacBook Pro with macOS Monterey. 

I'm following [this link](https://www.tensorflow.org/lite/guide/build_ios?hl=en)

but whan I execute the command:

`bazel build --config=ios_fat -c opt //tensorflow/lite/ios:TensorFlowLiteC_framework`

I get this error:

```
ERROR: .../tensorflow/tensorflow/lite/ios/BUILD:104:21: Bundling Preprocessed_TensorFlowLiteC_framework failed: (Exit 127): bundletool failed: error executing command 
  (cd /private/var/tmp/_bazel_gcutri/7cb05f4ce32b1b08677be1af22c0dd6b/execroot/org_tensorflow && \
  exec env - \
  bazel-out/host/bin/external/build_bazel_rules_apple/tools/bundletool/bundletool bazel-out/applebin_ios-ios_armv7-opt-ST-36ad1e8d6baf/bin/tensorflow/lite/ios/Preprocessed_TensorFlowLiteC_framework-intermediates/bundletool_control.json)
Execution platform: @local_execution_config_platform//:platform
env: python: No such file or directory
```

It seems that python is not found when executing the script bundletool. I installed both python 3.9 and 2.7.

Please help"
55267,[RNN] Max and min for dynamic tensors should be recorded during calibration: Failed for tensor arg1 Empty min/max for tensor arg1,"### 1. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Colab
- TensorFlow installation (pip package or built from source): pip
- TensorFlow library (version, if pip package or github SHA, if built from source): 2.8.0

### 2. Code

Provide code to help us reproduce your issues using one of the following options:

[Colab Link
](https://colab.research.google.com/drive/1FMUCqyB48x88mEwhIJA1KM1SKA1SDWwb?usp=sharing
)

```
import tensorflow as tf

# Load MNIST dataset
mnist = tf.keras.datasets.mnist
(train_images, train_labels), (test_images, test_labels) = mnist.load_data()

# Normalize the input image so that each pixel value is between 0 to 1.
train_images = train_images / 255.0
test_images = test_images / 255.0

# Define the model architecture
model = tf.keras.Sequential([
  tf.keras.layers.InputLayer(input_shape=(28, 28)),
  tf.keras.layers.GRU(5,return_sequences=True),
  tf.keras.layers.Flatten(),
  tf.keras.layers.Dense(10)
])

# Train the digit classification model
model.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])
model.fit(
  train_images,
  train_labels,
  epochs=1,
  validation_data=(test_images, test_labels)
)

# Wrap it into function (like in https://colab.research.google.com/github/tensorflow/tensorflow/blob/master/tensorflow/lite/examples/experimental_new_converter/Keras_LSTM_fusion_Codelab.ipynb )
run_model = tf.function(lambda x: model(x))
BATCH_SIZE = 1
concrete_func = run_model.get_concrete_function(
    tf.TensorSpec([BATCH_SIZE, model.input.shape[1], model.input.shape[2]], model.inputs[0].dtype))

MODEL_DIR = ""keras_model""
model.save(MODEL_DIR, save_format=""tf"", signatures=concrete_func)

# Convert it using integer quantization with int16 activations
converter = tf.lite.TFLiteConverter.from_saved_model(MODEL_DIR)
converter.optimizations = [tf.lite.Optimize.DEFAULT]
converter.target_spec.supported_ops = [tf.lite.OpsSet.EXPERIMENTAL_TFLITE_BUILTINS_ACTIVATIONS_INT16_WEIGHTS_INT8]
converter.inference_input_type = tf.int16
converter.inference_output_type = tf.int16

mnist_train, _ = tf.keras.datasets.mnist.load_data()
images = tf.cast(mnist_train[0], tf.float32) / 255.0
mnist_ds = tf.data.Dataset.from_tensor_slices((images)).batch(1)
def representative_data_gen():
  for input_value in mnist_ds.take(10):
    # Model has only one input so each data point has one element.
    yield [input_value]
converter.representative_dataset = representative_data_gen

tflite_16x8_model = converter.convert()
```
Output:
`RuntimeError: Max and min for dynamic tensors should be recorded during calibration: Failed for tensor arg1
Empty min/max for tensor arg1`

I'm trying to quantize this model using 8 bit for weights and 16 bit for activations. Code works perfectly if full 8 bit quantization (including activations) is used or if the GRU layer is removed. So the experimental 8x16 bit quantization seems to fail for GRUs.

### 4. (optional) RNN conversion support
If converting TF RNN to TFLite fused RNN ops, please prefix [RNN] in the title.

### 5. (optional) Any other info / logs
flatbuffers downgraded to version 1.12, got error otherwise (same as in https://github.com/tensorflow/tensorflow/issues/51590#issuecomment-912614740 ). "
55266,Exact Same outputs with 2 different datasets,"I was trying to reimplement the paper https://arxiv.org/pdf/1901.11196.pdf and created 2 models which have same structure one takes in the augmented data and one doesn't to see which one performs better but for some weird reason both of them have exact same loss and other metrics and it doesn't even change after every epoch
This is the link for my implementation - https://colab.research.google.com/drive/192mGhABi1n51cg8SFLvuUCwvsYIMNvx1?usp=sharing
The model training is at the very end
I tried to check and the inputs, encoders etc. are all different to both models but still this issue persists. Any ideas what could be going wrong?"
55263,`tf.compat.v1.signal.rfft2d` and `rfft3d` lacks input validation leading to crashes,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): N/A
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.8.0
- Python version:3.7.12
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 11.2 (based on a colab notebook)
- GPU model and memory: Tesla T4, 15109MiB (based on a colab notebook)

**Describe the current behavior**

The following code snippets lead to crashes when executed:

```
import numpy as np
import tensorflow as tf

a = np.empty([6, 0])
b = np.array([1, -1])
try:
  tf.compat.v1.signal.rfft2d(input_tensor=a,fft_length=b)
  # on a different machine: Check failed: size >= 0 (-9223372036854775808 vs. 0)
  # Aborted (core dumped)
except:
  pass

print('execution does not reach this line')
```

and

```
import numpy as np
import tensorflow as tf

a = np.empty([6, 1, 1])
b = np.array([1, 2, 0])

try:
  tf.compat.v1.signal.irfft3d(input_tensor=a,fft_length=b)
  # on a different machine: failed to initialize batched cufft plan with customized allocator: Failed to make cuFFT batched plan.
  # Aborted (core dumped)
except:
  pass
print('execution does not reach this line')
```

In either case, the inputs do not quite make sense, and tensorflow should throw.

**Describe the expected behavior**

Tensorflow should throw exceptions instead of crashing.

**[Contributing](https://www.tensorflow.org/community/contribute)**

- Do you want to contribute a PR? (yes/no):
- Briefly describe your candidate solution(if contributing):

**Standalone code to reproduce the issue**

Here is a colab notebook:
https://colab.research.google.com/drive/168jYG6MqnW4jpJdIXFMUBkyiaweA43aP?usp=sharing
Edit: the notebook has to be run with GPU 

The code snippets above should also reproduce the issue.

"
55262,tf.gradient returns None ,"<em>Please make sure that this is an issue related to performance of TensorFlow.
As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:performance_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS Big Sur 11.3.1
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): v2.6.1-9-gc2363d6d025 2.6.2
- Python version: Python 3.6.8
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
In training an LSTM model I would like to compute the gradients of the cell state at step t on the initial cell state: dc_t/dc_0. However calling ```tf.gradients(ct, c0)``` returns None type output.

**Describe the expected behavior**
My c_t c_0 are both of shape (100, 200). I am expecting the gradient to be a real-valued Tensor of the same shape. 

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

```
### 1. Define model
batch_size = 100
input_length_m= 1403
output_dim= 100

xtr_pad = tf.random.uniform((batch_size, input_length_m), maxval = 500, dtype=tf.int32)
ytr = tf.random.normal((batch_size, input_length_m, 200))
inp= Input(batch_shape= (batch_size, input_length_m), name= 'input') 
emb_out= Embedding(500, output_dim, input_length= input_length_m, trainable= False, name= 'embedding')(inp)

class LSTMCellwithStates(LSTMCell):
    def call(self, inputs, states, training=None):
        real_inputs = inputs[:,:self.units] # decouple [h, c]
        outputs, [h,c] = super().call(real_inputs, states, training=training)
        return tf.concat([h, c], axis=1), [h,c]
    
rnn = RNN(LSTMCellwithStates(200), return_sequences= True, return_state= False, name= 'LSTM') 
h0 = tf.Variable(tf.random.uniform((batch_size, 200)))
c0 = tf.Variable(tf.random.uniform((batch_size, 200)))
rnn_allstates= rnn(emb_out, initial_state=[h0, c0])  
model_lstm_mod = Model(inputs=inp, outputs= rnn_allstates, name= 'model_LSTMCell')
model_lstm_mod.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])

### 2. Compute gradients:
ds = tf.data.Dataset.from_tensor_slices((xtr_pad, ytr)).batch(100)

@tf.function
def compute_dct_dc0(ct, c0):
    return tf.gradients(ct, c0)

n_b = int(xtr_pad.shape[0]/ 100)
n_steps = 20   # look up only the first and last 20 steps

dctdc0_all= tf.zeros([n_b, n_steps])
for b, (x_batch_train, y_batch_train) in enumerate(ds):  
    grad_batch= []   
    cell_states= model_lstm_mod(x_batch_train)[:, :, 200:]
    for t in range(n_steps):  
        ct= cell_states[:, t, :]
        print(ct)
        # steps 0,...,19
        dctdc0_b_t = compute_dct_dc0(ct, c0)  # (batch_size, n_units)
        print(dctdc0_b_t)
        grad_t = tf.reduce_mean(abs(dctdc0_b_t[0]), [0,1]) # Scalar dctdc0 at the current batch and step
        print('step', t+1, 'of batch' ,b+1, 'done')
        grad_batch.append(grad_t)
    
    dctdc0_all= tf.concat([dctdc0_all, [grad_batch]], axis = 0)   
```
The error occurs specifically here:
```
### 3. 
@tf.function
def compute_dct_dc0(ct, c0):
    print(ct)
    print(c0)
    return tf.gradients(ct, c0)
compute_dct_dc0(ct, c0)

>> Tensor(""ct:0"", shape=(100, 200), dtype=float32)
<tf.Variable 'Variable:0' shape=(100, 200) dtype=float32>
[None]
```

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

Surprisingly when the function is defined in a slightly different manner the gradients are computed without issue:
```
@tf.function
# Compute gradients
def compute_dct_dc0(t, x, c0):
    return tf.gradients(model_lstm_mod(x)[:,t,:], c0)

n_b = int(xtr_pad.shape[0]/ 100) 
n_steps = 20   # look up only the first and last 20 steps

dctdc0_all= tf.zeros([n_b, n_steps])
for b, (x_batch_train, y_batch_train) in enumerate(ds):  # batches 0,1
    grad_batch= []   # a list of 1403 scalar gradients on the current batch
    for t in range(n_steps):  
        # steps 0,...,19
        dctdc0_b_t = compute_dct_dc0(t, x_batch_train, c0)  # (batch_size, n_units)
        grad_t = tf.reduce_mean(abs(dctdc0_b_t[0]), [0,1]) # Scalar dctdc0 at the current batch and step
        print('step', t+1, 'of batch' ,b+1, 'done')
        grad_batch.append(grad_t)
    
    dctdc0_all= tf.concat([dctdc0_all, [grad_batch]], axis = 0)   

## Outputs:
>> step 1 of batch 1 done
step 2 of batch 1 done
step 3 of batch 1 done
```
However this way is a lot more expensive because it will be fitted the entire batch for each step t. 
```cell_states= model_lstm_mod(x_batch_train)[:, :, 200:]``` fits the batch only once and extracts c_t for each t to compute gradients. 
"
55261,How can I use tf.data.experimental.make_csv_dataset to make a dataset with no batches,"Currently I'm doing this - 

```
column_names = ['Label','Sentence']
batchsize = 32
label = column_names[0]
train_dataset = tf.data.experimental.make_csv_dataset(
    'datasettrain.csv',
    batchsize,
    column_names = column_names,
    label_name = label,
    num_epochs=1
)
```

Due to this the batches being ordered dicts don't allow me to do certain things which a dataset directly loaded from tfds.load would allow. For instance in this tutorial - https://www.tensorflow.org/text/tutorials/text_classification_rnn

The author is able to run - 

```
for example, label in train_dataset.take(1):
  print('text: ', example.numpy())
  print('label: ', label.numpy())
```

and I wish to do the same however in my case the type for example comes out to be `<class 'collections.OrderedDict'>` while in the tutorials it is `<class 'tensorflow.python.framework.ops.EagerTensor'>`.

Is there some way I can do the same with `tf.data.experimental.make_csv_dataset`?

Using -

```
ls = []
for example, label in train_dataset:
  ls.append([example['Sentence'][0],label[0]])
```

I was able to get the required form internally however the entire array is no longer a `<class 'tensorflow.python.data.ops.dataset_ops.PrefetchDataset'>` is there any way to do that from this `ls`?"
55260,List of TF ops that tf.vectorized_map supports,"Where can I get this information? 

Which tf operation is a vectorized operation? and which one is not?

"
55259,Facing Issues with tf.io.TFRecordWriter while trying to write string,"I'm trying to write a dataset to a tfrecords file however the string portion keeps raising an error
```
infile='dataset.csv'
outfile='data.tfrecords'

csv = pd.read_csv(infile, header=None).values

itr = 1
with tf.io.TFRecordWriter(outfile) as file_writer:
    for row in csv:
        if (itr==1):
          itr+=1
          continue
        record_bytes = tf.train.Example(features=tf.train.Features(feature={
          ""sentence"": tf.train.Feature(bytes_list=tf.train.BytesList(value=[row[3]])),
          ""split"": tf.train.Feature(float_list=tf.train.FloatList(value=[row[2]])),
          ""Label"": tf.train.Feature(float_list=tf.train.FloatList(value=[row[1]])),
        })).SerializeToString()
        file_writer.write(record_bytes)
```

Error - 

```
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
[<ipython-input-91-a13b07fac787>](https://localhost:8080/#) in <module>()
     11           continue
     12         record_bytes = tf.train.Example(features=tf.train.Features(feature={
---> 13           ""sentence"": tf.train.Feature(bytes_list=tf.train.BytesList(value=[row[3]])),
     14           ""split"": tf.train.Feature(float_list=tf.train.FloatList(value=[row[2]])),
     15           ""Label"": tf.train.Feature(float_list=tf.train.FloatList(value=[row[1]])),

TypeError: 'a stirring , funny and finally transporting re imagining of beauty and the beast and 1930s horror f has type str, but expected one of: bytes
```

I looked at several doc pages but it seems BytesList is the wat to go with string but for some reason it isn't working here.
Am I missing something?"
55257,C-API Binaries for 32-bit for x86 instruction set,"**System information**
- TensorFlow version (you are using): 2.7.0
- Are you willing to contribute it (Yes/No): No


**Describe the feature and the current behavior/state.**

Tensorflow provides Windows binaries for the C-API for 64-bit processprs for instruction set x86 (= x64), see:
https://www.tensorflow.org/install/lang_c#supported_platforms

It would be great to support this for 32-bit also.

**Who will benefit with this feature?**
Projects requiring to build in 32-bit and 64-bit OS.
"
55251,Test //tensorflow/core/framework:model_test fails on AARCH64,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): CentOS 7
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: n/a
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): git HEAD
- Python version: 3.8.12
- Bazel version (if compiling from source): 5.0.0
- GCC/Compiler version (if compiling from source): 10.2.1
- CUDA/cuDNN version: n/a
- GPU model and memory: n/a

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

Test fails with

[ RUN      ] Test/AsyncUnknownRatioTest.Model/0
tensorflow/core/framework/model_test.cc:462: Failure
Expected equality of these values:
  async_unknown_many->TotalProcessingTime( nullptr)
    Which is: 109.333
  ratio * (50 + 50) + 128 / 3.0
    Which is: 109.333
[  FAILED  ] Test/AsyncUnknownRatioTest.Model/0, where GetParam() = (1, 0) (1 ms)

**Describe the expected behavior**

Test passes

**[Contributing](https://www.tensorflow.org/community/contribute)**

- Do you want to contribute a PR? (yes/no): yes
- Briefly describe your candidate solution(if contributing):

Add some tolerance to test for equality. Debugging the test shows that there is a difference of 1.42109e-14 in the two values on AARCH64.

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

bazel test --test_timeout=300,500,-1,-1 --flaky_test_attempts=3 --test_output=all --cache_test_results=no --config=nonccl --verbose_failures --build_tag_filters=-no_oss,-oss_serial,-gpu,-tpu,-benchmark-test,-v1only,-no_aarch64,-requires-gpu --test_tag_filters=-no_oss,-oss_serial,-gpu,-tpu,-benchmark-test,-v1only,-no_aarch64,-requires-gpu --jobs=75 --build_tests_only -- //tensorflow/core/framework:model_test

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

Introduced with https://github.com/tensorflow/tensorflow/commit/8d46773e6aa6b2eb44b62e422b3c7ccc4adb79b6
"
55250,"multi worker training in tensorflow gives error - ""terminate called without an active exception aborted""","I am running a tensorflow distributed training model on multiple workers using vertex AI/local and multiworkermirroredstrategy

After completion of all epochs it gives the error of ""terminate called without an active exception aborted""

python=3.8
tensorflow=2.7

Can anyone explain why is this happening."
55246,Generalise `xla::Map` to functions over arbitrary shapes,"**System information**
- TensorFlow version (you are using): 2.8
- Are you willing to contribute it (Yes/No): No

**Describe the feature and the current behavior/state.**

Currently `xla::Map` only allow functions from shape [] to []. I'd like to use functions with arbitrary shapes. For example, apply a function with shapes [2, 3] -> [5] to a tensor [100, 4, 2, 3] to get a [100, 4, 5].

I've not yet thought about how it would work when mapping multiple input tensors at once.

**Will this change the current api? How?**

It would extend `xla::Map`, either internally, or as an overload. It's possible additional information would need to be passed to a more general implementation of map, in which an overload may be preferable to maintain backwards compatibility.

**Who will benefit with this feature?**

Anyone using XLA who'd like to apply a function over sections of a tensor. It would effectively be an alternative to (some portion of) broadcasting, allowing people to use functions that don't allow leading dimensions to tensors with leading dimensions.

It is particularly useful for me as I'm working with dependent types and adding leading dimensions is non-trivial (and verbose) in type signatures.

**Any Other info.**

It is already possible to do this by indexing into the tensor and iteratively applying the function to the contents, then concatenating the results, but I expect this is significantly slower than could be achieved within XLA. I have considered using `xla::While` for this but I still expect the slicing and concatenation would still come with a significant performance cost."
55243,tf.random.poisson hangs on nan input,"Running on colab.research.google.com (`v2.8.0-0-g3f878cff5b6` at time of writing).

Looking at this code.

```
import tensorflow as tf
import math

print(tf.version.GIT_VERSION, tf.version.VERSION)

for lam in [3.2,-3.2,math.inf,-math.inf,math.nan]:
  print(lam,tf.random.poisson((1,),tf.convert_to_tensor(lam).numpy()))

```

**Describe the current behavior**

`tf.random.poisson` currently seems to handle nonsensical input as follows
- Negative values --> return 0
- +infinite values --> return infinity
- -infinite values --> return 0
- nan values --> freeze program completely (presumably running some rejection sampling algorithm forever??)

All of these seem okay except the last one.  

**Describe the expected behavior**

I have no strong opinions here.  I suppose my intuition would be 
- Negative values --> return nan
- +infinite values --> return infinity
- -infinite values --> return nan
- nan values --> return nan

But there may be good reasons for other behavior.  

At minimum, I suppose something should be added to the documentation indicating what expected behavior is (or that behavior is undefined in some cases).  
"
55242,Regression: TFLiteConverter changes output order again since 2.7,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
  No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
   Ubuntu 20.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
   N/A
- TensorFlow installed from (source or binary):
   Binary
- TensorFlow version (use command below):
   2.7.1
- Python version:
   3.8.10
- Bazel version (if compiling from source):
   N/A
- GCC/Compiler version (if compiling from source):
   N/A
- CUDA/cuDNN version:
   11.2
- GPU model and memory:
   1080TI, 11G

**Describe the current behavior**
   tf.lite.TFLiteConverter.from_keras_model changes output order.

**Describe the expected behavior**
   Should keep the same order as the keras model.

- Do you want to contribute a PR? (yes/no):
  No

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

This is a regression bug. Please find an example here: https://github.com/tensorflow/tensorflow/issues/33303
"
55241,`tf.keras.callbacks.BackupAndRestore` showing wrong number of steps after restoring the model!,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): colab
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): colab
- TensorFlow version (use command below): v2.8.0-0-g3f878cff5b6 2.8.0
- Python version: 3.7.12
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 11.2 
- GPU model and memory: Tesla V100-SXM2-16GB

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
By using the BackupAndRestore, I can save and reload the model from the last saved checkpoint and the training will continue from the last epoch before the interruption. The problem I'm facing is that after the training of the epoch is complete, the number of steps for that epoch is wrong (it takes the number of steps of the epoch and multiplies it with the number of epochs completed). The time of the epoch is correct but because the number of steps is wrong, the time per step is also wrong (as It divides the time taken for this epoch and divides it with the wrong number of steps). This issue causes the next epochs to show wrong progress bar and wrong number of steps as well.

You can see an example here:
My model trains for 1481 steps per epoch and it usually takes 7 to 8 seconds per step therefore I expect the total time of the epoch to be around 1481 * 8 = 10000 to 12000 seconds. I get the following log for training the model after restoring the 16th epoch by using the last saved checkpoint.

Epoch 16/40
23696/23696 [==============================] - 11513s 484ms/step - loss: 32.1565 - lr: 0.0010
Epoch 17/40
   74/23696 [..............................] - ETA: 40:37:26 - loss: 31.8166


As you can see, the number of steps should be 1481 but it's instead 16*1481=23696 for 16th epoch. The time per step should be 11513 / 1481 which is around 7s but what it shows is 11513 / 23696 = 484ms.

Also, the next epoch has a wrong total number of steps and ETA as well because of the wrong number of steps of the previous epoch. it stays like this until I restore from another epoch which produces the same issue


**Describe the expected behavior**
The expected behavior is to see the total time of the epoch (and not all the trained epochs) and to see the correct time per step

For example, I expect to see this in my case:
Epoch 16/40
1481/1481 [==============================] - 11513s 7s/step - loss: 32.1565 - lr: 0.0010
Epoch 17/40
   74/1481 [..............................] - ETA: 3:19:00 - loss: 31.8166

**[Contributing](https://www.tensorflow.org/community/contribute)**

- Do you want to contribute a PR? (yes/no): No
- Briefly describe your candidate solution(if contributing):

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

This is the training method of my model.
```
def train(self, loss_function:Callable, data_generator:Callable=None, learning_rate_scheduler:tf.keras.callbacks=None, learning_rate:float = 1e-3, epochs:int=40, batch_size:int=8, shuffle_data:bool=True, seed:int=0)->History:
    '''This method will generate the train_dataset and trains and backup the model after each epoch.
       it finally saves the model and removes the checkpoints
    '''
    def store_spectrograms():
        music_names = os.listdir(self._train_dir_path)
        music_names.remove(""spectrograms"")
        train_spectrograms_temp_dir_path = os.path.join(self._train_dir_path, ""spectrograms"")
        for music_name in music_names:
            #print(f""storing spectrograms for {music_name}"")
            music_dir_path = os.path.join(train_spectrograms_temp_dir_path, music_name)
            
            for file_name in [""mixture.wav"", ""vocals.wav"", ""accompaniment.wav""]:
                destination_dir = os.path.join(music_dir_path, file_name[:-4])
                if os.path.exists(destination_dir):
                    # print(f""{destination_dir} already exists"")
                    continue
                Config_Handler.make_dir(destination_dir)
                wav_file_handler = Wav_File_Handler(wav_file_path = os.path.join(music_dir_path, file_name))
                _, spectrograms = wav_file_handler.generate_segments_and_spectrograms(segment_length_in_seconds=self._segment_length_in_seconds, clip_stft_to_even_frequency_bins=self._clip_stft_to_even_frequency_bins)
                for i, spectrogram in enumerate(spectrograms):
                    spectrogram_id = f""id_{i}""
                    destination_path = os.path.join(destination_dir, f""{spectrogram_id}-spectrogram.npy"")
                    np.save(destination_path, spectrogram)
            #print(f""storing spectrograms for {music_name} completed!\n"")

    store_spectrograms()

    if os.path.exists(self._model_path):
      train_more = str.lower(input(f""Model is already trained, are you sure you want to train it for {epochs} more epochs? \n (y for yes and n for no:)""))
      while train_more not in [""y"", ""n""]:
        print(""invalid answer!"")
        train_more = input(f""Model is already trained, are you sure you want to train it for {epochs} more epochs? \n (y for yes and n for no:)"")
      if train_more == ""n"":
        print(""cancelling training!"")
        return
      else:
        print(f""model will be trained for {epochs} more epochs"")

    input_file_name = ""mixture.wav""
    output_vocal_file_name = ""vocals.wav""
    output_ac_file_name = ""accompaniment.wav""
    music_dict = dict()
    
    train_dataset = tf.data.Dataset.from_generator(lambda: self.generate_data(self._train_dir_path),
                                             output_signature=(tf.TensorSpec(shape=(None, self._input_shape[0], self._input_shape[1], self._input_shape[2]), dtype=tf.float32),
                                                               tf.TensorSpec(shape=(None, self._input_shape[0], self._input_shape[1], 2, self._input_shape[2]), dtype=tf.float32)))
    # test_dataset = tf.data.Dataset.from_generator(lambda: self.generate_data(self._test_dir_path, shuffle_data=shuffle_data, seed=seed),
    #                                          output_signature=(tf.TensorSpec(shape=(None, 1024, 256, 1), dtype=tf.float32),
    #                                                            tf.TensorSpec(shape=(None, 1024, 256, 2, 1), dtype=tf.float32)))
    optimizer = AdamW(weight_decay=1e-6, learning_rate=1e-3)

    tensorboard_callback = tf.keras.callbacks.TensorBoard(
    log_dir=self._tensorboard_logs_dir, histogram_freq=0, write_graph=True,
    write_images=False, write_steps_per_second=False, update_freq='epoch',
    profile_batch=0, embeddings_freq=0, embeddings_metadata=None,)
    #tf.debugging.experimental.enable_dump_debug_info(self._tensorboard_logs_dir, tensor_debug_mode=""FULL_HEALTH"", circular_buffer_size=-1)
    #tf.debugging.experimental.disable_dump_debug_info()

    backup_and_restore_callback = tf.keras.callbacks.BackupAndRestore( 
    backup_dir=self._checkpoint_path)
    callbacks = [tensorboard_callback, backup_and_restore_callback] + [tf.keras.callbacks.LearningRateScheduler(learning_rate_scheduler)] if learning_rate_scheduler != None else []
    self._model.compile(loss=loss_function, optimizer=optimizer)
    print(""starting training!"")
    history = self._model.fit(train_dataset, epochs=epochs, batch_size=batch_size, callbacks=callbacks, verbose=1)

    self.save_model()
    self._finalise_training()

    return history
```

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
55240,"Windows Build From Source, executing ./config responded 404 is a different issue.","Had applied a potential fix for #55218, however, I think this 404 is a different issue.
_Originally posted by @Gelesh in https://github.com/tensorflow/tensorflow/issues/55218#issuecomment-1066932121_

below is the console message, I think this 404 is a different issue.

INFO: Found applicable config definition build:monolithic in file c:\users\gomath776\christwork\tensorflow_renamed\.bazelrc: --define framework_shared_object=false
Loading:
Loading: 0 packages loaded
Loading: 0 packages loaded
Loading: 0 packages loaded
Loading: 0 packages loaded
Loading: 0 packages loaded
Loading: 0 packages loaded
Loading: 0 packages loaded
Loading: 0 packages loaded
Loading: 0 packages loaded
Loading: 0 packages loaded
WARNING: Download from https://storage.googleapis.com/mirror.tensorflow.org/github.com/tensorflow/runtime/archive/e83168170a0d0bdf856a109187936bc44853c1b8.tar.gz failed: class java.io.FileNotFoundException GET returned 404 Not Found

_Originally posted by @Gelesh in https://github.com/tensorflow/tensorflow/issues/55218#issuecomment-1066932121_"
55237,`tf.strided_slice()` option for `inclusive_end`,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): Latest (2.8)
- Are you willing to contribute it (Yes/No): Yes



**Describe the feature and the current behavior/state.**

I am maintainer of the [R interface to tensorflow](https://github.com/rstudio/tensorflow). The convention in R is for subsetting with `[` to be 1-based, and inclusive of the slice end. In most situations it is trivial to adapt the `[` tensor method in R to Python convention of 0-based indices and a half-open interval. Except for one case: when the slice end is also the first element of the container.

For example,
```
x = [1, 2, 3, 4, 5, 6]
```
An R call like `x[3:1]` would return `[3, 2, 1]`. To translate this to Python, the call would be `x[2::-1]`. This translation is easy enough to do in eager mode, but it's difficult in graph mode if the user supplied the slice end as a tensor, because that would make the dtype of `end` a varient (An integer or `None`, depending on the tensor value at run time).

Wrapping the `end` in a `tf.experimental.Optional()` doesn't work, nor does `tf.strided_slice()` accept a tensor value for `end_mask`. This means that there is no way to faithfully translate an R call like `x[start:end]` if `end` is a tensor and `end` could potentially resolve to the first element of the tensor.


**Will this change the current api? How?**

There are a couple of ways to resolve this, but the simplest I believe is to add an argument with default to `tf.strided_slice(..., inclusive_end=False)`. This would be no breaking change to existing code. From the R interface, we can then call `tf.strided_slice(..., inclusive_end = True)`.

**Who will benefit with this feature?**

All Tensorflow users from R, as well as interfaces to Tensorflow from other languages with 1-based and closed interval slice semantics (e.g., Julia).

**Any Other info.**

Having an additional arg `tf.strided_slice(..., one_based = False)` would be icing on the cake :). Having `tf.strided_slice()` automatically infer when `stride` should be negative would be the cherries on top :)"
55234,MutexLock should not segfault given a non-mutex,"
**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): N/A
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below):2.8.0
- Python version:3.7.12
- Bazel version (if compiling from source):N/A
- GCC/Compiler version (if compiling from source):N/A
- CUDA/cuDNN version:N/A
- GPU model and memory:N/A

**Describe the current behavior**
Given the following code:
```
import numpy as np
import tensorflow as tf

tf.raw_ops.MutexLock(mutex=np.shape(a=4))
```
This currently crashes the colab notebook. On a different machine, it leads to a segfault.

**Describe the expected behavior**

Tensorflow should throw an exception rejecting the invalid argument.  Tensorflow should reject the `mutex` argument since it's not a mutex resource (`A Tensor of type resource`, based on https://www.tensorflow.org/api_docs/python/tf/raw_ops/MutexLock)


**[Contributing](https://www.tensorflow.org/community/contribute)**

- Do you want to contribute a PR? (yes/no):
- Briefly describe your candidate solution(if contributing):

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

https://colab.research.google.com/drive/1cwMDIYX9pruA1eG22eYykAxlbhDayjT8?usp=sharing

```
import numpy as np
import tensorflow as tf

tf.raw_ops.MutexLock(mutex=np.shape(a=4))
```

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
55230,Incorrect calculation of 2nd derivative of a determinant of a matrix,"

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Mac OS Monterey.  Also seen on Linux.
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): v2.8.0-rc1-32-g3f878cff5b6 2.8.0 (also seen in 2.6.X)
- Python version: 3.8.6
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: N/A, but also seen in cuda11.4
- GPU model and memory: CPU, but also seen in A100 40GB/80GB

**Describe the current behavior**

The calculation of the second derivative of a determinant is incorrect. 

It is a little challenging to describe the full issue in markdown.  I've created a standalone notebook to reproduce the issue.  I compare the TF gradients through a determinant against both finite differences and a custom (albeit slow) determinant implementation.  The TF gradients for the determinant of a matrix, let's call them G, agree with both finite differences and the custom op.  The second derivative, dG/dx, aka the Hessian of the determinant of a matrix, is badly incorrect.  Using autodifferentiation on the custom determinant operation twice, however, agrees well with finite differences methods.

Full reproducer available in this notebook (standalone) here: https://github.com/Nuclear-Physics-with-Machine-Learning/MLQM/blob/spin/examples/2nd%20Derivative%20of%20Determinant%20of%20a%20matrix.ipynb

**Describe the expected behavior**

The calculation of the second derivative of a determinant should be correct.

**[Contributing](https://www.tensorflow.org/community/contribute)**

- Do you want to contribute a PR? (yes/no):  If we can track down the bug, and it's something i can fix, I could.  I haven't modified yet.
- Briefly describe your candidate solution(if contributing):  I believe the operations registered for the backprop through a determinant of a matrix must be missing something, and this could be fixed.

**Standalone code to reproduce the issue**

https://github.com/Nuclear-Physics-with-Machine-Learning/MLQM/blob/spin/examples/2nd%20Derivative%20of%20Determinant%20of%20a%20matrix.ipynb

"
55228,Cannot load optimizer state on TPUs,"**System information**
- Have I written custom code: Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): GCP
- TensorFlow installed from (source or binary):Binary
- TensorFlow version (use command below):2.5
- Python version:3.7
- CUDA/cuDNN version:
- GPU model and memory: TPU

**Describe the current behavior**
With TPUs, it is not possible to load the optimizer state. This is pretty important when running tuning runs, or when continuing a train job. Any sort of work around for saving the model with the optimizer or another way to load the optimizer would be greatly appreciated. 

**[Contributing](https://www.tensorflow.org/community/contribute)**

- Do you want to contribute a PR? (yes/no): No
- Briefly describe your candidate solution(if contributing):

**Standalone code to reproduce the issue**
```
import os
import tensorflow as tf
import numpy as np
import os.path as osp
import pickle
from tensorflow.keras.layers import Input
from tensorflow.keras.layers import Dense
from tensorflow.keras import Model

#build model
X, y = np.random.rand(100, 50), np.random.randint(2, size=100)
x = Input((50,))
out = Dense(1, activation='sigmoid')(x)
model = Model(x, out)

#build setup an optimizer and save the state
optimizer = tf.keras.optimizers.Adam(learning_rate=0.0005)
opt_path = 'opt_wights.npy'
grad_vars = model.trainable_weights
zero_grads = [tf.zeros_like(w) for w in grad_vars]
optimizer.apply_gradients(zip(zero_grads, grad_vars))
np.save(opt_path, optimizer.get_weights())

#do the same thing with a load, but in strategy scope
#get the strategy
bTPU = True
if bTPU:
    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection
    tf.config.experimental_connect_to_cluster(tpu)
    tf.tpu.experimental.initialize_tpu_system(tpu)
    strategy = tf.distribute.TPUStrategy(tpu)
else:    
    gpus = tf.config.experimental.list_logical_devices(""GPU"")
    if len(gpus) > 1:
        strategy = tf.distribute.MirroredStrategy(cross_device_ops=tf.distribute.HierarchicalCopyAllReduce())
    elif len(gpus) == 1:
        strategy = tf.distribute.get_strategy()
    else:
        strategy = tf.distribute.get_strategy()

with strategy.scope():
    #build the model and optimizer again
    optimizer = tf.keras.optimizers.Adam(learning_rate=0.0005)
    X, y = np.random.rand(100, 50), np.random.randint(2, size=100)
    x = tf.keras.layers.Input((50,))
    out = tf.keras.layers.Dense(1, activation='sigmoid')(x)
    model = tf.keras.Model(x, out)
    @tf.function	
    def _model_weight_setting():
        opt_weights = np.load(opt_path, allow_pickle=True)
        grad_vars = model.trainable_weights
        zero_grads = [tf.zeros_like(w) for w in grad_vars]
        optimizer.apply_gradients(zip(zero_grads, grad_vars))
        optimizer.set_weights(opt_weights)
    strategy.run(_model_weight_setting)
```
"
55226,Tracker for TensorFlow-DirectML,"cc: @PatriceVignola @wchao1115

This issue tracks pending PRs, issues, and possible cherry-picks necessary for TensorFlow-DirectML for each TF release. Please post a comment with new things to track and I will update this post to reflect the changes.

New PRs:
* https://github.com/tensorflow/tensorflow/pull/56707
    * Awaiting internal discussion in the TensorFlow team.
* https://github.com/tensorflow/tensorflow/pull/55677

PRs that need more investigation.
* #55382 [A similar PR broke tests before so this can't go in until the issue is resolved.]
* https://github.com/tensorflow/tensorflow/pull/55381 
    * Reverted because it broke internal tests. 

PRs that made it into TF nightly (post r2.10 branch cut):
* #51759 
* https://github.com/tensorflow/tensorflow/pull/55544 
* https://github.com/tensorflow/tensorflow/pull/55557
* https://github.com/tensorflow/tensorflow/pull/55579
* https://github.com/tensorflow/tensorflow/pull/52157

PRs that made it into TF 2.10:
* https://github.com/tensorflow/tensorflow/pull/55379
    * Resubmitted in https://github.com/tensorflow/tensorflow/pull/55640
* https://github.com/tensorflow/tensorflow/pull/55678
* https://github.com/tensorflow/tensorflow/pull/55645
* https://github.com/tensorflow/tensorflow/pull/55558

PRs that made it into TF 2.9:
* #55173 
* #54468 
* #54139
* #51758
* https://github.com/tensorflow/tensorflow/pull/55384 
* https://github.com/tensorflow/tensorflow/pull/55385 
* https://github.com/tensorflow/tensorflow/pull/55386 
* https://github.com/tensorflow/tensorflow/pull/55387 
* https://github.com/tensorflow/tensorflow/pull/55392
* https://github.com/tensorflow/tensorflow/pull/55393
* https://github.com/tensorflow/tensorflow/pull/54746
* https://github.com/tensorflow/tensorflow/pull/55395

Closed PR:
* #55362"
55224, Can't use multiple tensorboard callbacks in TF2.8,"**System information**.
- Have I written custom code (as opposed to using a stock example script provided in Keras): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): v2.8.0-rc1-32-g3f878cff5b6 2.8.0
- Python version: 3.8.12
- Bazel version (if compiling from source):
- GPU model and memory: None
- Exact command to reproduce:

**Describe the problem.**

I am using multiple tensoboard callbacks with the same Model. Since I upgraded Tensorflow from 2.5 to 2.8, I have an error at the end of the training when closing the Tensorboard writers.  
I opened an issue on the Keras repo https://github.com/keras-team/keras/issues/16235, but after diving a little bit more into the source code, I think the issue directly comes from Tensorflow and not from keras. This [commit](https://github.com/tensorflow/tensorflow/commit/6edaa9105a2cd91369ae69da0dd10993f77557b3) might have introduced the bug.

**Describe the current behavior.**

The training doesn't end correctly because of a Tensrboard callback error.

**Describe the expected behavior.**

It used to work in TF2.5 and it should still do.


**Standalone code to reproduce the issue**.

```python
import tensorflow as tf
import tempfile

with tempfile.TemporaryDirectory() as tmpdir:
    batch_size = 3
    nb_samples = 10
    update_freq = 2
    inputs = tf.random.normal((nb_samples, 2))
    outputs = tf.random.normal((nb_samples, 10))
    dataset = tf.data.Dataset.from_tensor_slices((inputs, outputs)).batch(batch_size)
    dataset_val = tf.data.Dataset.from_tensor_slices((inputs, outputs)).batch(batch_size)
    nb_epochs = 5

    model = tf.keras.Sequential([tf.keras.layers.Dense(10)])
    optimizer = tf.keras.optimizers.SGD()

    tensorboard_kwargs = dict(profile_batch=0, update_freq=update_freq, write_graph=False)

    tensorboard_callbacks = [
        tf.keras.callbacks.TensorBoard(tmpdir.join(""tensorboard_1""), **tensorboard_kwargs),
        tf.keras.callbacks.TensorBoard(tmpdir.join(""tensorboard_2""), **tensorboard_kwargs)
    ]
    model.compile(optimizer, ""mse"")
    model.fit(
        dataset,
        batch_size=batch_size,
        callbacks=tensorboard_callbacks,
        epochs=nb_epochs,
        validation_data=dataset_val
    )
```

**Stacktrace**

```bash
2022-03-14 13:24:44.758272: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
Epoch 1/5
4/4 [==============================] - 1s 43ms/step - loss: 1.3517 - val_loss: 1.3417
Epoch 2/5
4/4 [==============================] - 0s 5ms/step - loss: 1.3396 - val_loss: 1.3297
Epoch 3/5
4/4 [==============================] - 0s 8ms/step - loss: 1.3276 - val_loss: 1.3178
Epoch 4/5
4/4 [==============================] - 0s 5ms/step - loss: 1.3158 - val_loss: 1.3062
Epoch 5/5
4/4 [==============================] - 0s 10ms/step - loss: 1.3042 - val_loss: 1.2947
Traceback (most recent call last):
  File ""poulet.py"", line 26, in <module>
    model.fit(
  File ""/Users/antoinehoorelbeke/vision/venv/lib/python3.8/site-packages/keras/utils/traceback_utils.py"", line 67, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File ""/Users/antoinehoorelbeke/vision/venv/lib/python3.8/site-packages/tensorflow/python/ops/summary_ops_v2.py"", line 93, in __exit__
    _summary_state.writer.flush()
AttributeError: 'NoneType' object has no attribute 'flush'
```
"
55223,seq2seq.BasicDecoder not working with seq2seq.SampleEmbeddingSampler ,"Tensorflow 2, my code

```
def beam_evaluate_sentence(text, beam_width=3):
    
  # work on preprocessed text (lower, space before punctuation)
  text = dataset_creator.preprocess_text(text)

  text = '<start> ' + text + ' <end>'

  inputs = [tokenizer.word_index[i] for i in text.split(' ')]

  maxlen=len(inputs)

  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],
                                                          maxlen=maxlen,
                                                          padding='post')

  inputs = tf.convert_to_tensor(inputs)
  inference_batch_size = inputs.shape[0]
  result = ''

  enc_start_state = [tf.zeros((inference_batch_size, units)), tf.zeros((inference_batch_size,units))]
  enc_out, enc_h, enc_c = encoder(inputs, enc_start_state)

  dec_h = enc_h
  dec_c = enc_c

  start_tokens = tf.fill([inference_batch_size], tokenizer.word_index['<start>'])
  end_token = tokenizer.word_index['<end>']
  
  # From official documentation
  # NOTE If you are using the BeamSearchDecoder with a cell wrapped in AttentionWrapper, then you must ensure that:
  # The encoder output has been tiled to beam_width via tfa.seq2seq.tile_batch (NOT tf.tile).
  # The batch_size argument passed to the get_initial_state method of this wrapper is equal to true_batch_size * beam_width.
  # The initial state created with get_initial_state above contains a cell_state value containing properly tiled final state from the encoder.

  enc_out = tfa.seq2seq.tile_batch(enc_out, multiplier=beam_width)
  decoder.attention_mechanism.setup_memory(enc_out)
  print(""beam_with * [batch_size, max_length_input, rnn_units] :  3 * [1, 16, 1024]] :"", enc_out.shape)

  # set decoder_inital_state which is an AttentionWrapperState considering beam_width
  hidden_state = tfa.seq2seq.tile_batch([enc_h, enc_c], multiplier=beam_width)
  decoder_initial_state = decoder.rnn_cell.get_initial_state(batch_size=beam_width*inference_batch_size, dtype=tf.float32)
  decoder_initial_state = decoder_initial_state.clone(cell_state=hidden_state)

  temperature_sampler = tfa.seq2seq.sampler.SampleEmbeddingSampler(softmax_temperature=TEMPERATURE)

  # Instantiate BasicDecoder object
  decoder_instance = tfa.seq2seq.BasicDecoder(cell=decoder.rnn_cell, sampler=temperature_sampler, output_layer=decoder.fc)
  # Setup Memory in decoder stack
  decoder.attention_mechanism.setup_memory(enc_out)

  decoder_initial_state = decoder.build_initial_state(inference_batch_size, [enc_h, enc_c], tf.float32)

  decoder_embedding_matrix = decoder.embedding.variables[0]

  outputs, _, _ = decoder_instance(decoder_embedding_matrix, start_tokens = start_tokens, end_token= end_token, initial_state=decoder_initial_state)
  return outputs.sample_id.numpy()
```

The problem is appearing when I switch from a greedy sampler to 

`  temperature_sampler = tfa.seq2seq.sampler.SampleEmbeddingSampler(softmax_temperature=TEMPERATURE)
`

and the issue is 

```
Traceback (most recent call last):
  File ""/root/gen.py"", line 268, in <module>
    sample_decoder_outputs = decoder(sample_x, initial_state)
  File ""/root/.local/lib/python3.9/site-packages/keras/utils/traceback_utils.py"",or_handler
    raise e.with_traceback(filtered_tb) from None
  File ""/root/gen.py"", line 258, in call
    outputs, _, _ = self.decoder(x, initial_state=initial_state, sequence_length=ax_length_output-1])
  File ""/usr/local/lib/python3.9/dist-packages/tensorflow_addons/seq2seq/decoder.n call
    return dynamic_decode(
  File ""/usr/local/lib/python3.9/dist-packages/typeguard/__init__.py"", line 1033,
    retval = func(*args, **kwargs)
  File ""/usr/local/lib/python3.9/dist-packages/tensorflow_addons/seq2seq/decoder.n dynamic_decode
    initial_finished, initial_inputs, initial_state = decoder.initialize(
  File ""/usr/local/lib/python3.9/dist-packages/tensorflow_addons/seq2seq/basic_de128, in initialize
    return self.sampler.initialize(inputs, **kwargs) + (initial_state,)
TypeError: Exception encountered when calling layer ""basic_decoder"" (type BasicDe

initialize() got an unexpected keyword argument 'sequence_length'

Call arguments received:
  • inputs=tf.Tensor(shape=(32, 17, 256), dtype=float32)
  • initial_state=AttentionWrapperState(cell_state=['tf.Tensor(shape=(32, 1024),  'tf.Tensor(shape=(32, 1024), dtype=float32)'], attention='tf.Tensor(shape=(32, 1t32)', alignments='tf.Tensor(shape=(32, 17), dtype=float32)', alignment_history=(te='tf.Tensor(shape=(32, 17), dtype=float32)')
  • training=None
  • kwargs={'sequence_length': ['16', '16', '16', '16', '16', '16', '16', '16', ' '16', '16', '16', '16', '16', '16', '16', '16', '16', '16', '16', '16', '16', '1'16', '16', '16', '16', '16']}

```"
55220,"Failed to use evaluation function from TF, TypeError: tf__loss() after loading a saved model","<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): 
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **Ubuntu 18.04**
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): **from pip**
- TensorFlow version (use command below): 2.8
- Python version: 3.10.2
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 11.2
- GPU model and memory:   A100-PCI 40GB *4

**Describe the current behavior**
```
# Save and load using High-level API
siamese.save('test_model')
a = tf.keras.models.load_model(""test_model"", custom_objects={'contrastive_loss': loss})

## Evaluate the model
results = a.evaluate([x_test_1, x_test_2], labels_test)
print(""test loss, test acc:"", results)
```
After saving my trained model (assigned as `siamese`), I loaded the saved model that I just had saved (assigned as `a`) . When I perform evaluate on the loaded model (load `a`). I face this error:

`TypeError: tf__loss() takes from 0 to 1 positional arguments but 2 were given
`
**Describe the expected behavior**
When I tried evaluating with `siamese` model, it worked fine. But if I saved it, loaded it I got the above error, 

Here is my loss function:
```

def loss(margin=1):
    def contrastive_loss(y_true, y_pred):
        square_pred = tf.math.square(y_pred)
        margin_square = tf.math.square(tf.math.maximum(margin - (y_pred), 0))
        return tf.math.reduce_mean(
            (1 - y_true) * square_pred + (y_true) * margin_square
        )
    return contrastive_loss
```"
55218,"Build fails to make use of bazelisk, if available.","<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): WINDOWS
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):  https://github.com/tensorflow/tensorflow.git
- TensorFlow version: r2.
- Python version: 3.10
- Installed using virtualenv? pip? conda?: GIT
- Bazel version (if compiling from source): 5.0
- GCC/Compiler version (if compiling from source): 11.2
- CUDA/cuDNN version: NA
- GPU model and memory: NA



**Describe the problem**

When using the [build from source](https://www.tensorflow.org/install/source_windows) https://www.tensorflow.org/install/source_windows , Even when 'bazelisk' is installed, the install run fails from config.py stating 
'Cannot find bazel. Please install bazel.',

This could easly be fixed, like

```
  if bazel_executable is None:
    bazel_executable = which('bazelisk')
    print('bazel_executable not found, instead using bazelisk @ ',bazel_executable)
    if bazel_executable is None:
        print('Cannot find bazel. Please install bazel.')
        sys.exit(1)
```

**Provide the exact sequence of commands / steps that you executed before running into the problem**
Remove from path variable /Un Install bazel.
Install bazelisk.

execute ./config  or python config.py

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
**Error**: 'Cannot find bazel. Please install bazel.'
"
55217,`tf.experimental.numpy.stack` should check out-of-bound `axis` ,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Y
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.7.0
- Python version: 3.8
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source):N/A
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A


**Standalone code to reproduce the issue**
```
import tensorflow as tf
x = tf.random.uniform([5])
print(tf.experimental.numpy.stack(x, axis=-2)) # Outputs a shape [5] tensor
```

**Describe the current behavior**
In the above example, the input is a rank-1 tensor, so `axis` cannot be -2. `tf.experimental.numpy.stack` did not check the argument `axis`.

Expect it to throw an error like `tf.stack`:
```

import tensorflow as tf
x = tf.random.uniform([5])
tf.stack(x, axis=-1) # Pass
tf.stack(x, axis=-2) # ValueError: Argument `axis` = -2 not in range [-1, 1)
```

"
55216,Model.compute_loss documentation section is not correct. compute_loss function is not called,"Hello,

[Model.compute_loss documentation section is not correct]( https://www.tensorflow.org/api_docs/python/tf/keras/Model)

compute_loss function is not called for some reason.

```
import tensorflow as tf


class MyModel(tf.keras.Model):

  def __init__(self, *args, **kwargs):
    super(MyModel, self).__init__(*args, **kwargs)
    self.loss_tracker = tf.keras.metrics.Mean(name='loss')

  def compute_loss(self, x, y, y_pred, sample_weight):
    tf.print(""compute_loss is called:"")
    loss = tf.reduce_mean(tf.math.squared_difference(y_pred, y))
    loss += tf.add_n(self.losses)
    self.loss_tracker.update_state(loss)
    return loss

  def reset_metrics(self):
    self.loss_tracker.reset_states()

  @property
  def metrics(self):
    return [self.loss_tracker]

tensors = tf.random.uniform((10, 10)), tf.random.uniform((10,))
dataset = tf.data.Dataset.from_tensor_slices(tensors).repeat().batch(1)

inputs = tf.keras.layers.Input(shape=(10,), name='my_input')
outputs = tf.keras.layers.Dense(10)(inputs)
model = MyModel(inputs, outputs)
model.add_loss(tf.reduce_sum(outputs))

optimizer = tf.keras.optimizers.SGD()
model.compile(optimizer, loss='mse', steps_per_execution=10)
model.fit(dataset, epochs=2, steps_per_epoch=10)
print('My custom loss: ', model.loss_tracker.result().numpy())
```

'compute_loss is called:' is not printed.  Checked on tensorflow 2.6.2"
55215,Crashed if using negative num_streams in QuantileOpsTest,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.5.0
- Python version: 3.7.11
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: None
- GPU model and memory:

**Describe the current behavior**
QuantileOpsTest got crashed if using negative parameters in _create_quantile_stream_resource_() in tf 2.5.0. When running the same test case in tf 2.6.0, it would not crash and printed error info.

**Describe the expected behavior**
The test case sould fail and give relative error information.

**[Contributing](https://www.tensorflow.org/community/contribute)**

- Do you want to contribute a PR? (yes/no):
- Briefly describe your candidate solution(if contributing):

**Standalone code to reproduce the issue**
I ran the following code named bug3.py:
```
from tensorflow.python.framework import test_util
from tensorflow.python.ops import boosted_trees_ops
from tensorflow.python.ops import resources
from tensorflow.python.ops.gen_boosted_trees_ops import boosted_trees_quantile_stream_resource_handle_op as resource_handle_op
from tensorflow.python.ops.gen_boosted_trees_ops import is_boosted_trees_quantile_stream_resource_initialized as resource_initialized
from tensorflow.python.platform import googletest

@test_util.run_deprecated_v1
class QuantileOpsTest(test_util.TensorFlowTestCase):

    def setUp(self):
        self.eps = 0.01
        self.max_elements = (1 << 16)

    def testBasicQuantileBucketsSingleResourcesAddFlushed(self):
        with self.cached_session():
            quantile_accumulator_handle = resource_handle_op(container='', shared_name='floats_0', name='floats_0')
            create_op = boosted_trees_ops.create_quantile_stream_resource(quantile_accumulator_handle, epsilon=self.eps,
                                                                              max_elements=self.max_elements,
                                                                              num_streams= -2 )
            
            is_initialized_op = resource_initialized(quantile_accumulator_handle)
            resources.register_resource(quantile_accumulator_handle, create_op, is_initialized_op)
            resources.initialize_resources(resources.shared_resources()).run()

if (__name__ == '__main__'):
    googletest.main()
```

**Other info / logs** Include any logs or source code that would be helpful to
Here is the log in tf 2.5.0:
```
[ RUN      ] QuantileOpsTest.testBasicQuantileBucketsSingleResourcesAddFlushed
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-03-14 05:21:01.193346: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2097635000 Hz
terminate called after throwing an instance of 'std::length_error'
  what():  vector::reserve
Fatal Python error: Aborted

Thread 0x00007efcd9c1b180 (most recent call first):
  File ""/root/anaconda3/envs/tf2.5.0/lib/python3.7/site-packages/tensorflow/python/client/session.py"", line 1453 in _call_tf_sessionrun
  File ""/root/anaconda3/envs/tf2.5.0/lib/python3.7/site-packages/tensorflow/python/client/session.py"", line 1360 in _run_fn
  File ""/root/anaconda3/envs/tf2.5.0/lib/python3.7/site-packages/tensorflow/python/client/session.py"", line 1375 in _do_call
  File ""/root/anaconda3/envs/tf2.5.0/lib/python3.7/site-packages/tensorflow/python/client/session.py"", line 1369 in _do_run
  File ""/root/anaconda3/envs/tf2.5.0/lib/python3.7/site-packages/tensorflow/python/client/session.py"", line 1191 in _run
  File ""/root/anaconda3/envs/tf2.5.0/lib/python3.7/site-packages/tensorflow/python/client/session.py"", line 968 in run
  File ""/root/anaconda3/envs/tf2.5.0/lib/python3.7/site-packages/tensorflow/python/framework/test_util.py"", line 1729 in run
  File ""/root/anaconda3/envs/tf2.5.0/lib/python3.7/site-packages/tensorflow/python/framework/ops.py"", line 5578 in _run_using_default_session
  File ""/root/anaconda3/envs/tf2.5.0/lib/python3.7/site-packages/tensorflow/python/framework/ops.py"", line 2625 in run
  File ""test_bug/bug3.py"", line 24 in testBasicQuantileBucketsSingleResourcesAddFlushed
  File ""/root/anaconda3/envs/tf2.5.0/lib/python3.7/site-packages/tensorflow/python/framework/test_util.py"", line 1345 in decorated
  File ""/root/anaconda3/envs/tf2.5.0/lib/python3.7/unittest/case.py"", line 628 in run
  File ""/root/anaconda3/envs/tf2.5.0/lib/python3.7/unittest/case.py"", line 676 in __call__
  File ""/root/anaconda3/envs/tf2.5.0/lib/python3.7/unittest/suite.py"", line 122 in run
  File ""/root/anaconda3/envs/tf2.5.0/lib/python3.7/unittest/suite.py"", line 84 in __call__
  File ""/root/anaconda3/envs/tf2.5.0/lib/python3.7/unittest/suite.py"", line 122 in run
  File ""/root/anaconda3/envs/tf2.5.0/lib/python3.7/unittest/suite.py"", line 84 in __call__
  File ""/root/anaconda3/envs/tf2.5.0/lib/python3.7/unittest/runner.py"", line 176 in run
  File ""/root/anaconda3/envs/tf2.5.0/lib/python3.7/site-packages/absl/testing/_pretty_print_reporter.py"", line 87 in run
  File ""/root/anaconda3/envs/tf2.5.0/lib/python3.7/unittest/main.py"", line 271 in runTests
  File ""/root/anaconda3/envs/tf2.5.0/lib/python3.7/unittest/main.py"", line 101 in __init__
  File ""/root/anaconda3/envs/tf2.5.0/lib/python3.7/site-packages/absl/testing/absltest.py"", line 2553 in _run_and_get_tests_result
  File ""/root/anaconda3/envs/tf2.5.0/lib/python3.7/site-packages/absl/testing/absltest.py"", line 2585 in run_tests
  File ""/root/anaconda3/envs/tf2.5.0/lib/python3.7/site-packages/absl/testing/absltest.py"", line 2172 in _run_in_app
  File ""/root/anaconda3/envs/tf2.5.0/lib/python3.7/site-packages/absl/testing/absltest.py"", line 2065 in main
  File ""/root/anaconda3/envs/tf2.5.0/lib/python3.7/site-packages/tensorflow/python/platform/googletest.py"", line 55 in g_main
  File ""/root/anaconda3/envs/tf2.5.0/lib/python3.7/site-packages/absl/app.py"", line 258 in _run_main
  File ""/root/anaconda3/envs/tf2.5.0/lib/python3.7/site-packages/absl/app.py"", line 312 in run
  File ""/root/anaconda3/envs/tf2.5.0/lib/python3.7/site-packages/tensorflow/python/platform/googletest.py"", line 64 in main_wrapper
  File ""/root/anaconda3/envs/tf2.5.0/lib/python3.7/site-packages/tensorflow/python/platform/benchmark.py"", line 518 in benchmarks_main
  File ""/root/anaconda3/envs/tf2.5.0/lib/python3.7/site-packages/tensorflow/python/platform/googletest.py"", line 66 in main
  File ""test_bug/bug3.py"", line 28 in <module>
Aborted (core dumped)
```
"
55214,list_ops.empty_tensor_list() crashed when element_shape is a two dimensional tensor,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): 2.6.0, 2.7.0
- Python version: 3.7.11
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: None
- GPU model and memory:

**Describe the current behavior**
When running test cases for list_ops.empty_tensor_list(), the program crashed for core dump if I used 2-d tensor in the attribute of element_shape. The normal case is using 1-d tensor like [1], but getting crashed when using [[1]].

**Describe the expected behavior**
Since users might misuse some parameters, the program would show ValueError related to incorrect shape information.

**[Contributing](https://www.tensorflow.org/community/contribute)**

- Do you want to contribute a PR? (yes/no):
- Briefly describe your candidate solution(if contributing):

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.
```
from tensorflow.python.framework import constant_op
from tensorflow.python.framework import dtypes
from tensorflow.python.ops import list_ops
from tensorflow.python.platform import test

class TensorsTest(test.TestCase):

    def test_is_tensor_array(self):
        # this case will pass if using [1] in element_shape
        return list_ops.empty_tensor_list(element_shape=constant_op.constant([[1]], dtype=dtypes.int32),
                                          element_dtype=dtypes.int32) 

if (__name__ == '__main__'):
    test.main()
```

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
Here is a snapshot of the error log.
```
[ RUN      ] TensorsTest.test_is_tensor_array
2022-03-14 04:44:22.682042: F tensorflow/core/framework/tensor_shape.cc:46] Check failed: NDIMS == dims() (1 vs. 2)Asking for tensor of 1 dimensions from a tensor of 2 dimensions
Fatal Python error: Aborted

Current thread 0x00007ff0c7b02180 (most recent call first):
  File ""/root/anaconda3/envs/tf2.5.0/lib/python3.7/site-packages/tensorflow/python/ops/gen_list_ops.py"", line 49 in empty_tensor_list
  File ""/root/anaconda3/envs/tf2.5.0/lib/python3.7/site-packages/tensorflow/python/ops/list_ops.py"", line 62 in empty_tensor_list
  File ""test_bug/bug2.py"", line 11 in test_is_tensor_array
  File ""/root/anaconda3/envs/tf2.5.0/lib/python3.7/unittest/case.py"", line 628 in run
  File ""/root/anaconda3/envs/tf2.5.0/lib/python3.7/unittest/case.py"", line 676 in __call__
  File ""/root/anaconda3/envs/tf2.5.0/lib/python3.7/unittest/suite.py"", line 122 in run
......

*** End stack trace ***
Aborted (core dumped)
```
"
55213,support vscode devcontiners for development,"**System information**
- TensorFlow version (you are using): latest
- Are you willing to contribute it (Yes/No): Yes

**Describe the feature and the current behavior/state.**
support for vscode devcontainers is required for good dependency management and overall good support for modern development
"
55212,Example code of tfd.Independent seems to be incorrect.,"## URL(s) with the issue:
https://www.tensorflow.org/probability/api_docs/python/tfp/distributions/Independent

## Description of issue (what needs changing):
The example code provided seems to be incorrect.
In my understanding ind.batch_shape should be [2] and even_shape should be [3].

```
# Make independent distribution from a 2-batch bivariate Normal.
  ind = tfd.Independent(
      distribution=tfd.MultivariateNormalDiag(
          loc=[[-1., 1], [1, -1]],
          scale_identity_multiplier=[1., 0.5]),
      reinterpreted_batch_ndims=1)

# All batch dims have been 'absorbed' into event dims.
ind.batch_shape  # ==> []
ind.event_shape  # ==> [2, 2]
```
"
55211,"Early Stopping time - after 100,000 iterations ","**System information**
- I have used multiple custom classes to optimize the training time
- OS Linux Ubuntu 18.04):
- TensorFlow installed from binary
- TensorFlow 2.5
- Python 3.6:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN 11.2 / 8.5
- GPU Test T4 

****

please see below 100k iterations, what is the time Early stopping is required to prevent overfitting. 

![image](https://user-images.githubusercontent.com/47017344/158029847-344d56f9-ad75-4d89-8deb-7708f6923f0f.png)

"
55209,"tf.matmul() fails with ragged inputs of shape [batch_size, None, dims] and transpose_b=True","**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Debian 11.2 ""bullseye"" (keras-dev docker image)
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): v1.12.1-72504-gfeb9095a53f 2.9.0-dev20220311
- Python version: 3.9.10
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A

**Describe the current behavior**

When A and B are two ragged tensors, both of shape [batch_size, None, dims], then `tf.matmul(A, B, transpose_b=True)` fails. However, when A and B are ragged tensors of shape [batch_size, None, None], with the exact same values, then it works fine.

**Describe the expected behavior**

I expect the first scenario to work, and it should return the same result as the second scenario.

**[Contributing](https://www.tensorflow.org/community/contribute)**

- Do you want to contribute a PR? (yes/no): not sure I'll have time, but if it's not too long ok
- Briefly describe your candidate solution(if contributing): I'm guessing there's a bug in the shape checks in `tf.matmul()` since I see no reason why [batch_size, None, dims] would fail while [batch_size, None, None] would succeed. If anything, I would have expected the opposite.

**Standalone code to reproduce the issue**

See this [gist](https://colab.research.google.com/gist/ageron/1226921dbd2be65dc69f12847f2c229b/tensorflow-issue-matmul-ragged.ipynb).

This code fails:

```python
import tensorflow as tf

A_ids = tf.ragged.constant([[1, 2], [1, 0, 5]])
B_ids = tf.ragged.constant([[2, 4, 6, 9], [3]])
embedding_layer = tf.keras.layers.Embedding(10, 3)
A = embedding_layer(A_ids)  # A has shape [2, None, 3]
B = embedding_layer(B_ids)  # B has shape [2, None, 3]
C = tf.matmul(A, B, transpose_b=True)  # RAISES AN InvalidArgumentError!!!
```

But this one succeeds:

```python
import tensorflow as tf

A = tf.ragged.constant([  # A has shape [2, None, None]
    [[1., 2., 3.], [3., 4., 5.]],
    [[1., 3., 5.], [5., 7., 9.], [9., 11., 13.]]
])
B = tf.ragged.constant([  # B has shape [2, None, None]
    [[10., 20., 30.], [30., 40., 50.], [50., 60., 70.], [70., 80., 90.]],
    [[11., 21., 31.]]
])

C = tf.matmul(A, B, transpose_b=True)  # WORKS FINE NOW!
```

The only difference I can see is that the shape of `A` and `B` is `[2, None, 3]` in the first case, but it's `[2, None, None]` in the second case. It doesn't make sense.

**Other info / logs**

Below is the full stacktrace:

<details>

```stacktrace
---------------------------------------------------------------------------
InvalidArgumentError                      Traceback (most recent call last)
[<ipython-input-8-3e4e536edcee>](https://localhost:8080/#) in <module>()
      6 A = embedding_layer(A_ids)  # A has shape [2, None, 3]
      7 B = embedding_layer(B_ids)  # B has shape [2, None, 3]
----> 8 C = tf.matmul(A, B, transpose_b=True)  # ERROR!

1 frames
[/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py](https://localhost:8080/#) in error_handler(*args, **kwargs)
    151     except Exception as e:
    152       filtered_tb = _process_traceback_frames(e.__traceback__)
--> 153       raise e.with_traceback(filtered_tb) from None
    154     finally:
    155       del filtered_tb

[/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py](https://localhost:8080/#) in raise_from_not_ok_status(e, name)
   7184 def raise_from_not_ok_status(e, name):
   7185   e.message += ("" name: "" + name if name is not None else """")
-> 7186   raise core._status_to_exception(e) from None  # pylint: disable=protected-access
   7187 
   7188 

InvalidArgumentError: All flat_values must have compatible shapes.  Shape at index 0: [4].  Shape at index 1: [1].  If you are using tf.map_fn, then you may need to specify an explicit fn_output_signature with appropriate ragged_rank, and/or convert output tensors to RaggedTensors. [Op:RaggedTensorFromVariant]
```

</details>

**Related issues**

* This TF issue is probably the cause of this Keras issue: https://github.com/keras-team/keras/issues/16226
* There's a closed issue about TF matmul + ragged tensors, but I think it's different: https://github.com/tensorflow/tensorflow/issues/28109
"
55208,Comment,<spam>
55207,Is tf2xla  used even when jit_compile=False,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Ubuntu
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.8
- Python version: 3.9.10
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A


**Describe the current behavior**
With TF_CPP_MAX_VLOG_LEVEL=3 ,  still see lines like the following  in the log.


> 10048:2022-03-11 09:50:05.273639: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: XlaWhile
10049:2022-03-11 09:50:05.273651: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: XlaWhile
10050:2022-03-11 09:50:05.273660: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: XlaIf
10051:2022-03-11 09:50:05.273670: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: XlaIf
10052:2022-03-11 09:50:05.273680: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: StatelessIf
10053:2022-03-11 09:50:05.273689: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: StatelessIf
10054:2022-03-11 09:50:05.273698: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: If
10055:2022-03-11 09:50:05.273707: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: If
10056:2022-03-11 09:50:05.273718: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_GPU_JIT op: StatelessCase
10057:2022-03-11 09:50:05.273727: I tensorflow/compiler/tf2xla/xla_op_registry.cc:328] XLA op registration: device: XLA_CPU_JIT op: StatelessCase
.
.
.
10973:2022-03-11 09:50:05.281066: I tensorflow/compiler/tf2xla/xla_op_registry.cc:414] For operation Reshape required constants are: shape
10974:2022-03-11 09:50:05.281070: I tensorflow/compiler/tf2xla/const_analysis.cc:261] marking consts for must-be-const inputs of model/flatten/Reshape
10975:2022-03-11 09:50:05.281074: I tensorflow/compiler/tf2xla/const_analysis.cc:222] marking consts for must-be-const node model/flatten/Const
10978:2022-03-11 09:50:05.281228: I tensorflow/compiler/tf2xla/xla_op_registry.cc:153] tf_xla_cpu_global_jit = 0
10979:2022-03-11 09:50:05.281237: I tensorflow/compiler/tf2xla/xla_op_registry.cc:51] LaunchOpHasKernelForDevice kernel_class_name: XlaLocalLaunchOp
10980:2022-03-11 09:50:05.281247: I tensorflow/compiler/tf2xla/xla_op_registry.cc:51] LaunchOpHasKernelForDevice kernel_class_name: XlaLocalLaunchOp
11170:2022-03-11 09:50:05.282582: I tensorflow/compiler/tf2xla/xla_op_registry.cc:414] For operation Sum required constants are: reduction_indices
11171:2022-03-11 09:50:05.282588: I tensorflow/compiler/tf2xla/const_analysis.cc:261] marking consts for must-be-const inputs of sparse_categorical_crossentropy/weighted_loss/Sum
11172:2022-03-11 09:50:05.282605: I tensorflow/compiler/tf2xla/xla_op_registry.cc:414] For operation Reshape required constants are: shape
11173:2022-03-11 09:50:05.282611: I tensorflow/compiler/tf2xla/const_analysis.cc:261] marking consts for must-be-const inputs of model/flatten/Reshape


**Describe the expected behavior**

tf2xla should not show up in the log. 

"
55203,`tf.gather_nd` and `tf.gather` have inconsistent type check for `batch_dims`,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Y
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.8.0
- Python version: 3.8
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source):N/A
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A

**Standalone code to reproduce the issue**
```
import tensorflow as tf
params = tf.random.uniform([3, 1, 12, 64], dtype=tf.float32)
indices = tf.random.uniform([35, 2], minval=0, maxval=1, dtype=tf.int64)
batch_dims = False
tf.gather_nd(params, indices, batch_dims=batch_dims) # Pass
tf.gather(params, indices, batch_dims=batch_dims) # InvalidArgumentError
```
Detailed error message:
```
InvalidArgumentError: Value for attr 'Taxis' of bool is not in the list of allowed values: int32, int64
	; NodeDef: {{node GatherV2}}; Op<name=GatherV2; signature=params:Tparams, indices:Tindices, axis:Taxis -> output:Tparams; attr=batch_dims:int,default=0; attr=Tparams:type; attr=Tindices:type,allowed=[DT_INT32, DT_INT64]; attr=Taxis:type,allowed=[DT_INT32, DT_INT64]> [Op:GatherV2]
```

**Describe the current behavior**
In the above code, `batch_dims` is a `bool`, not a `int`. `tf.gather` complains about this type mismatch and throws `InvalidArgumentError`. However, `tf.gather_nd` would do implicit conversion and convert `False` to `0`. There is an inconsistency in the type checking.

**Describe the expected behavior**
Either allow implicit `bool`-`int` conversion in all cases, or throw an Error in all cases."
55202,google.protobuf.message.DecodeError: Error parsing message with type 'tensorflow.GraphDef',"I trained the model and saved it, now I am trying to load but unable to do. I have seen in previous post as well, but reference links are not working.

**Code**

```
`#load model

with tf.io.gfile.GFile(args.model, ""rb"") as f:
    graph_def = tf.compat.v1.GraphDef()
    graph_def.ParseFromString(f.read())

# with tf.Graph().as_default() as graph:
generated_image_1, generated_image_2, generated_image_3, = tf.graph_util.import_graph_def(
        graph_def, 
        input_map={'input_image' : input_tensor, 'short_edge_1' : short_edge_1, 'short_edge_2' : short_edge_2, 'short_edge_3' : short_edge_3}, 
        return_elements=['style_subnet/conv-block/resize_conv_1/output:0', 'enhance_subnet/resize_conv_1/output:0', 'refine_subnet/resize_conv_1/output:0'],  
        producer_op_list=None
    )`
```

**Error:**

```
`Traceback (most recent call last):
  File ""stylize.py"", line 97, in <module>
    main()
  File ""stylize.py"", line 57, in main
    graph_def.ParseFromString(f.read())
google.protobuf.message.DecodeError: Error parsing message with type 'tensorflow.GraphDef'`
```

Note: I am using,
python = 3.7.6
Tensorflow-gpu=1.15
tensorboard=1.15.0
protobuf =3.19.4"
55201,Encounter Abort(core dump) in ClipOpsTest when changing shapes,"**System information**
- Ubuntu 20.04
- python 3.7.11
- In TF 2.5.0, 2.6.0, 2.7.0, 2.8.0

When I run test cases in TensorFlow, it occurred to me that ClipOpsTest would crash when I use a huge attribute in shape.


**Describe the current behavior**
The code crashed and provided 'Abort (core dump)' message.

**Describe the expected behavior**
The program found shape-related problems and returned ValueError or MemoryError.

**[Contributing](https://www.tensorflow.org/community/contribute)**

- Do you want to contribute a PR? (yes/no): no
- Briefly describe your candidate solution(if contributing): 

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

```
from tensorflow.python.framework import ops
from tensorflow.python.ops import clip_ops
from tensorflow.python.platform import test
from tensorflow.python.framework import constant_op

class ClipOpsTest(test.TestCase):

    def _testClipIndexedSlicesByNorm(self, values, indices, shape, max_norm, axes):
        values = constant_op.constant(values)
        indices = constant_op.constant(indices)
        shape = constant_op.constant(shape)
        indexed_slices = ops.IndexedSlices(values, indices, shape)
        clipped = clip_ops.clip_by_norm(indexed_slices, max_norm, axes)
        clipped = ops.convert_to_tensor(clipped)
        
    def testClipIndexedSlicesByNorm_Failed(self):
        values = [[[(- 3.0), 0.0, 0.0], [4.0, 0.0, 0.0]], [[0.0, 2.0, 0.0], [0.0, 0.0, (- 1.0)]]]
        indices = [2, 6]
        # shape = [9223372036854775807, 1, 9223372036854775807]
     
        shape = [9223372036854775807, 2, 3] 
        self._testClipIndexedSlicesByNorm(values, indices, shape, 4.0, None) # crashed


    def testClipIndexedSlicesByNorm_Pass(self):
        values = [[[(- 3.0), 0.0, 0.0], [4.0, 0.0, 0.0]], [[0.0, 2.0, 0.0], [0.0, 0.0, (- 1.0)]]]
        indices = [2, 6]

        shape = [10, 2, 3] 
        self._testClipIndexedSlicesByNorm(values, indices, shape, 4.0, None) # passed

if (__name__ == '__main__'):
    test.main()
```


**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.



[ RUN      ] ClipOpsTest.testClipIndexedSlicesByNorm
**2022-03-12 05:39:14.085939: F tensorflow/core/framework/tensor_shape.cc:404] Check failed: 0 <= new_num_elements (0 vs. -2)
Fatal Python error: Aborted**
Current thread 0x00007fb591724180 (most recent call first):
  File ""/root/anaconda3/envs/tf2.8.0/lib/python3.7/site-packages/tensorflow/python/ops/gen_math_ops.py"", line 12118 in unsorted_segment_sum
  File ""/root/anaconda3/envs/tf2.8.0/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py"", line 448 in _indexed_slices_to_tensor
  File ""/root/anaconda3/envs/tf2.8.0/lib/python3.7/site-packages/tensorflow/python/framework/ops.py"", line 1695 in convert_to_tensor
  File ""/root/anaconda3/envs/tf2.8.0/lib/python3.7/site-packages/tensorflow/python/profiler/trace.py"", line 183 in wrapped
  File ""test_bug.py"", line 16 in _testClipIndexedSlicesByNorm
  File ""test_bug.py"", line 29 in testClipIndexedSlicesByNorm
  File ""/root/anaconda3/envs/tf2.8.0/lib/python3.7/unittest/case.py"", line 628 in run
  File ""/root/anaconda3/envs/tf2.8.0/lib/python3.7/unittest/case.py"", line 676 in __call__
  File ""/root/anaconda3/envs/tf2.8.0/lib/python3.7/unittest/suite.py"", line 122 in run
  File ""/root/anaconda3/envs/tf2.8.0/lib/python3.7/unittest/suite.py"", line 84 in __call__
  File ""/root/anaconda3/envs/tf2.8.0/lib/python3.7/unittest/suite.py"", line 122 in run
  File ""/root/anaconda3/envs/tf2.8.0/lib/python3.7/unittest/suite.py"", line 84 in __call__
  File ""/root/anaconda3/envs/tf2.8.0/lib/python3.7/unittest/runner.py"", line 176 in run
  File ""/root/anaconda3/envs/tf2.8.0/lib/python3.7/site-packages/absl/testing/_pretty_print_reporter.py"", line 86 in run
  File ""/root/anaconda3/envs/tf2.8.0/lib/python3.7/unittest/main.py"", line 271 in runTests
  File ""/root/anaconda3/envs/tf2.8.0/lib/python3.7/unittest/main.py"", line 101 in __init__
  File ""/root/anaconda3/envs/tf2.8.0/lib/python3.7/site-packages/absl/testing/absltest.py"", line 2537 in _run_and_get_tests_result
  File ""/root/anaconda3/envs/tf2.8.0/lib/python3.7/site-packages/absl/testing/absltest.py"", line 2569 in run_tests
  File ""/root/anaconda3/envs/tf2.8.0/lib/python3.7/site-packages/absl/testing/absltest.py"", line 2156 in _run_in_app
  File ""/root/anaconda3/envs/tf2.8.0/lib/python3.7/site-packages/absl/testing/absltest.py"", line 2049 in main
  File ""/root/anaconda3/envs/tf2.8.0/lib/python3.7/site-packages/tensorflow/python/platform/googletest.py"", line 51 in g_main
  File ""/root/anaconda3/envs/tf2.8.0/lib/python3.7/site-packages/absl/app.py"", line 258 in _run_main
  File ""/root/anaconda3/envs/tf2.8.0/lib/python3.7/site-packages/absl/app.py"", line 312 in run
  File ""/root/anaconda3/envs/tf2.8.0/lib/python3.7/site-packages/tensorflow/python/platform/googletest.py"", line 60 in main_wrapper
  File ""/root/anaconda3/envs/tf2.8.0/lib/python3.7/site-packages/tensorflow/python/platform/benchmark.py"", line 503 in benchmarks_main
  File ""/root/anaconda3/envs/tf2.8.0/lib/python3.7/site-packages/tensorflow/python/platform/googletest.py"", line 62 in main
  File ""/root/anaconda3/envs/tf2.8.0/lib/python3.7/site-packages/tensorflow/python/platform/test.py"", line 56 in main
  File ""test_bug.py"", line 32 in <module>


"
55199,Missing input validation on `tf.ragged.constant`,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): 
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): 
- TensorFlow version (use command below):2.8.0
- Python version: 3.7.12
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: using a colab notebook
- GPU model and memory: using a colab notebook

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

If I pass an empty list with a large ragged_rank to `tf.ragged.constant`,
all RAM is consumed, causing the notebook to crash.
The docs indicate that ragged_rank should be between 0 and the rank of pylist, so the large value of ragged_rank should be rejected

**Describe the expected behavior**

Some input validation should be done and an exception thrown.

**[Contributing](https://www.tensorflow.org/community/contribute)**

- Do you want to contribute a PR? (yes/no):
- Briefly describe your candidate solution(if contributing):

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.
The colab notebook:
https://colab.research.google.com/drive/1OyQNTCiqHKjmHKfYbSOmVt4EfkLEgsNA?usp=sharing

```
import tensorflow as tf
tf.ragged.constant(pylist=[],ragged_rank=8968073515812833920)
```

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
55198,Fail to convert trained model to TensorFlow Lite (integer only and unsigned integer),"

### 1. System information
- OS Platform and Distribution: Linux Ubuntu 16.04
- TensorFlow installation: pip package
- TensorFlow library: 2.4.0
- tensorflow-model-optimization: 0.7.1.

### 2. Code
(int8 conversion)
```
converter = tf.lite.TFLiteConverter.from_keras_model(model)
converter.allow_custom_ops = True
converter.optimizations = [tf.lite.Optimize.DEFAULT] # require representative dataset
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]
converter.inference_input_type = tf.int8 
converter.inference_output_type = tf.int8 

converter.representative_dataset = representative_data_gen
tflite_int8_model = converter.convert()
```

(uint8 conversion)
```
converter = tf.lite.TFLiteConverter.from_keras_model(model)
converter.optimizations = [tf.lite.Optimize.DEFAULT]
converter.target_spec.supported_ops = [tf.uint8]
converter.inference_input_type = tf.uint8
converter.inference_output_type = tf.uint8

tflite_uint8_model = converter.convert()
```

I'm trying to apply post-training quantization to the trained model, the model is built and trained through TensorFlow2 functional API. However, for conversion of integer only, the converter generates the error message: `Model output is not dquntized.` when executing converter.convert(); for conversion of unsigned integer, the converter generates the error message: `the inference_input_type and inference_output_type must be tf.float32.` if I assigned `converter.target_spec.supported_ops = [tf.uint8]`, `converter.inference_input_type = tf.uint8`, and `converter.inference_output_type = tf.uint8`.
![keras_to_int8_error](https://user-images.githubusercontent.com/8951991/157827139-3259fa6a-8a63-4b89-acb6-55efa0b98e92.png)

![keras_to_uint8_error](https://user-images.githubusercontent.com/8951991/157827152-aa8e4b0c-7425-455d-96af-dbdc9f3d378e.png)


Are there settings required to convert the trained model to int8 and uint8 precision?

Best Regards,
Rahn"
55197,supported Image formats (.PNG) for custom object detection training,"Hey guys,

After reading through the topics a bit, it was mentioned that certain image formats are not supported, but that wrappers have been written by individual users.

These were then added to the code in the tensorflow/core/..... etc. folder structure.

How does TensorFlow behave with an individual training with .PNG images? Would I also have to use one of these wrappers and if so, it is not exactly clear to me where this has to be inserted.

Thank you very much, I am grateful for any tips.
"
55195,TensorFlowLiteSwift ld: 4 duplicate symbols for architecture arm64,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
BIG SUR 11.4
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
ALL
- TensorFlow installed from (source or binary):
from cocoapods pod install 
- TensorFlow version:
  pod 'TensorFlowLiteSwift', '~> 2.7.0'
  pod 'TensorFlowLiteSelectTfOps', '~> 2.7.0'
- Python version:
N/A
- Installed using virtualenv? pip? conda?:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:



**Describe the problem**
Build error for TensorFlowLiteSwift', '~> 2.7.0' and TensorFlowLiteSelectTfOps', '~> 2.7.0'... 
error:
ld: 4 duplicate symbols for architecture arm64

**Provide the exact sequence of commands / steps that you executed before running into the problem**
Steps to reproduce: 
download sample project https://github.com/tensorflow/examples
change tensorflow versions in podfile to 2.7.0
pod install 
run the project from the xcworkspace file 

**Any other info / logs**
duplicate symbol '_TfLiteXNNPackDelegateCreate' in:
    /Users/brett/Desktop/examples/lite/examples/sound_classification/ios/Pods/TensorFlowLiteSelectTfOps/Frameworks/TensorFlowLiteSelectTfOps.framework/TensorFlowLiteSelectTfOps(xnnpack_delegate.o)
    /Users/brett/Desktop/examples/lite/examples/sound_classification/ios/Pods/TensorFlowLiteC/Frameworks/TensorFlowLiteC.framework/TensorFlowLiteC
duplicate symbol '_TfLiteXNNPackDelegateDelete' in:
    /Users/brett/Desktop/examples/lite/examples/sound_classification/ios/Pods/TensorFlowLiteSelectTfOps/Frameworks/TensorFlowLiteSelectTfOps.framework/TensorFlowLiteSelectTfOps(xnnpack_delegate.o)
    /Users/brett/Desktop/examples/lite/examples/sound_classification/ios/Pods/TensorFlowLiteC/Frameworks/TensorFlowLiteC.framework/TensorFlowLiteC
duplicate symbol '_TfLiteXNNPackDelegateGetThreadPool' in:
    /Users/brett/Desktop/examples/lite/examples/sound_classification/ios/Pods/TensorFlowLiteSelectTfOps/Frameworks/TensorFlowLiteSelectTfOps.framework/TensorFlowLiteSelectTfOps(xnnpack_delegate.o)
    /Users/brett/Desktop/examples/lite/examples/sound_classification/ios/Pods/TensorFlowLiteC/Frameworks/TensorFlowLiteC.framework/TensorFlowLiteC
duplicate symbol '_TfLiteXNNPackDelegateOptionsDefault' in:
    /Users/brett/Desktop/examples/lite/examples/sound_classification/ios/Pods/TensorFlowLiteSelectTfOps/Frameworks/TensorFlowLiteSelectTfOps.framework/TensorFlowLiteSelectTfOps(xnnpack_delegate.o)
    /Users/brett/Desktop/examples/lite/examples/sound_classification/ios/Pods/TensorFlowLiteC/Frameworks/TensorFlowLiteC.framework/TensorFlowLiteC
ld: 4 duplicate symbols for architecture arm64
clang: error: linker command failed with exit code 1 (use -v to see invocation)
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
55194,XLA support for ImageProjectiveTransformV3,"**System information**
- TensorFlow version (you are using):
master
- Are you willing to contribute it (Yes/No):
I don't know, only if I have a clear contribution path

**Describe the feature and the current behavior/state.**
XLA support for `ImageProjectiveTransformV3` 
**Will this change the current api? How?**
No
**Who will benefit with this feature?**
Performance on image preprocessing
**Any Other info.**

```python
import tensorflow as tf
import numpy as np
@tf.function(jit_compile=True)
def transform():
    inp = np.arange(15).reshape((1, 5, 3, 1)).astype(np.float32)
    transform_matrix = np.asarray([[1., 0., 0., 0., 1., -1., 0., 0.]])
    output_shape = tf.shape(inp)[1:3]
    tf.raw_ops.ImageProjectiveTransformV3(
        images=inp,
        output_shape=output_shape,
        fill_value=0.0,
        transforms=transform_matrix,
        fill_mode=""constant"",
        interpolation=""bilinear"")

transform()
```

```
 on XLA_CPU_JIT: ImageProjectiveTransformV3 (No registered 'ImageProjectiveTransformV3' OpKernel for XLA_CPU_JIT devices compatible with node {{node ImageProjectiveTransformV3}}){{node ImageProjectiveTransformV3}}
```

Extra:
Please also note that the CPU/GPU TF2XLA supported ops tables are probably outdated (2018):
https://github.com/tensorflow/tensorflow/issues/14798#issuecomment-1047796247"
55190,Got this warning while using @tf.function on tensorflow_probability.,"I am trying to train a reinforcment learning agent on BipedalWalker. To Speed things up I used @tf.function wrapper on my gradient calculations and then I got this warning.

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes.
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 20.04LTS
- Device: Lenovo Legion Y540
- TensorFlow installed from (source or binary): conda
- TensorFlow version (use command below): v2.4
- TensorFlow-Probability: v0.12.2
- Python version: v3.9
- Bazel version (if compiling from source): 
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 10.1/7.6.5
- GPU model and memory: Nvidia Geforce Gtx 1650 4GB


**Describe the current behavior**

```
WARNING:tensorflow:AutoGraph could not transform <bound method A3CAgent.act of <tensorflow.python.eager.function.TfMethodTarget object at 0x7f20540f1940>> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: module 'gast' has no attribute 'Index'
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
WARNING: AutoGraph could not transform <bound method A3CAgent.act of <tensorflow.python.eager.function.TfMethodTarget object at 0x7f20540f1940>> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: module 'gast' has no attribute 'Index'
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
WARNING:tensorflow:From /home/himanshu/anaconda3/envs/myenv/lib/python3.9/site-packages/tensorflow_probability/python/distributions/distribution.py:298: calling MultivariateNormalDiag.__init__ (from tensorflow_probability.python.distributions.mvn_diag) with scale_identity_multiplier is deprecated and will be removed after 2020-01-01.
Instructions for updating:
`scale_identity_multiplier` is deprecated; please combine it with `scale_diag` directly instead.
WARNING:tensorflow:From /home/himanshu/anaconda3/envs/myenv/lib/python3.9/site-packages/tensorflow/python/ops/linalg/linear_operator_diag.py:167: calling LinearOperator.__init__ (from tensorflow.python.ops.linalg.linear_operator) with graph_parents is deprecated and will be removed in a future version.
Instructions for updating:
Do not pass `graph_parents`.  They will  no longer be used.
```

**Describe the expected behavior**
   Tensorflow should not give these warnings.



- Do you want to contribute a PR? (yes/no): no
- Briefly describe your candidate solution(if contributing): None

**Standalone code to reproduce the issue**
  Link to the jupyter notebook can be found [here](https://drive.google.com/file/d/1OzDI00TQ1U1g63UR7HxuKhEzAQ3nMwug/view?usp=sharing).


"
55189,tensorflow training: result is different if model passed as argument to training loop,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes and no. the training loops are stock but the rest of code is not
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): microsoft windows 10 pro
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): 2.1
- Python version: 3.7.9
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: none
- GPU model and memory: NVIDIA QUATRO RTX 4000 with max-q design

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

I have experimented with training a simple tensorflow model using two scenarios: passing my model to my training loop (and to the subfunctions which are called from training loop), versus not passing my model to the training loop. The two cases result in different results. When passing my model to the training functions, the model is trained properly. But in the second scenario, something is wrong because the model is apparently not trained. I am baffled, and I wonder if it's a scope thing.

To be more specific, my setup involves dynamically creating a new model of larger size (adding some layers at each iteration of a for loop), and then training the resulting model. As stated before, I train the model in two scenarios: passing the model to training subfunctions and not doing so, and I obtain different results depending on which one I do. I verify this by giving the model a test sample (class 0 MNIST images) and checking if the correct classification is output. The models trained by passing the model as an argument is trained correctly, but, if I do not do this, then only the first model created by the for loop is correctly trained, as verified by incorrect class predictions. Can this be explained?

**Describe the expected behavior**
Training a model should not be different whether or not I pass the model as an argument to the custom training function.

**[Contributing](https://www.tensorflow.org/community/contribute)**

- Do you want to contribute a PR? (yes/no):
no

- Briefly describe your candidate solution(if contributing):

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

`
import tensorflow as tf
physical_devices = tf.config.experimental.list_physical_devices('GPU')
tf.config.experimental.set_memory_growth(physical_devices[0], True)
from tensorflow.keras.optimizers import Adam
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np
import time

epochs = 200
input_shape = (28,28,1)
num_classes=10
batch_size = 64
(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()

x_val = x_train[-10000:]
y_val = y_train[-10000:]
x_train = x_train[:-10000]
y_train = y_train[:-10000]

x_train = np.expand_dims(x_train, -1)
x_val = np.expand_dims(x_val, -1)
x_test = np.expand_dims(x_test, -1)
x_train = x_train.astype(""float32"") 
x_test = x_test.astype(""float32"") 
x_val = x_val.astype(""float32"") 

y_test_sorted_args_0=np.where(y_test == 0)
x_test_0=x_test[y_test_sorted_args_0]
y_test_0=np.full( (x_test_0.shape)[0],0)

train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))
train_dataset = train_dataset.shuffle(buffer_size=1024).batch(batch_size)

val_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val))
val_dataset = val_dataset.batch(batch_size)

acc_metric = keras.metrics.SparseCategoricalAccuracy()
val_acc_metric = keras.metrics.SparseCategoricalAccuracy()
optimizer = keras.optimizers.SGD(learning_rate=1e-3)
loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=False)
    
@tf.function
def train_step(x, y):
    with tf.GradientTape() as tape:
        mod_output = model(x, training=True)
        loss_value = loss_fn(y, mod_output)
    grads = tape.gradient(loss_value, model.trainable_weights)
    optimizer.apply_gradients(zip(grads, model.trainable_weights))
    acc_metric.update_state(y, mod_output)
    return loss_value

@tf.function
def test_step(x, y):
    val = model(x, training=False)
    acc_metric.update_state(y, val)

def train( epochs):
    for epoch in range(epochs):
        print(""\nStart of epoch %d"" % (epoch,))
        start_time = time.time()
        
        # Iterate over the batches of the dataset.
        for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):
            loss_value = train_step( x_batch_train, y_batch_train)
    
            # Log every 200 batches.
            if step % 200 == 0:
                print(
                    ""Training loss (for one batch) at step %d: %.4f""
                    % (step, float(loss_value))
                )
                print(""Seen so far: %d samples"" % ((step + 1) * batch_size))
    
        # Display metrics at the end of each epoch.
        train_acc = acc_metric.result()
        print(""Training acc over epoch: %.4f"" % (float(train_acc),))
    
        # Reset training metrics at the end of each epoch
        acc_metric.reset_states()
    
        # Run a validation loop at the end of each epoch.
        for x_batch_val, y_batch_val in val_dataset:
            test_step(x_batch_val, y_batch_val)
    
        val_acc = acc_metric.result()
        val_acc_metric.reset_states()
        print(""Validation acc: %.4f"" % (float(val_acc),))
        print(""Time taken: %.2fs"" % (time.time() - start_time))

max_hidden=7
for num_hidden_layers in range(1,max_hidden,3):    
    model1 = keras.Sequential(
        [
            keras.Input(shape=input_shape),
            layers.Flatten(),
        ]
    )
    
    for i in range(1, num_hidden_layers+1):
        model1.add(layers.Dense(150, activation=""relu""))
    model1.add(layers.Dense(num_classes, activation=""softmax""))
    
    model=model1
    
    train(epochs)
    
    #verify that the model is properly trained by checking that the model correclty predicts images from class 0.  
    #The more class 0 predictions we have, the better.
    for sample_index in range(0,10): 
        x_sample=x_test_0[sample_index,:,:,:]
        x_sample=np.expand_dims(x_sample, 0)
        print(tf.math.argmax(model(x_sample),axis=1))
    time.sleep(1)
        
`


**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
55188,Inconsistent behavior betweek tf.nn.leaky_relu and keras.layers.LeakyReLU,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): 
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.8.0
- Python version: 3.7.12
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A

**Describe the current behavior**
When giving `tf.nn.leaky_relu()` a `-np.Inf` array and set the `alpha=0.0`. `tf.nn.leaky_relu` will output `nan`. However, since `-np.Inf` is still a valid array, would it be more reasonable that leaky_relu output 0? For comparison, I also check the result of `keras.layers.LeakyReLU` and set `alpha=0.0`, `keras.layers.LeakyReLU` will output 0 instead of `nan`.

**Standalone code to reproduce the issue**
Please run below code or directly access this colab link: https://colab.research.google.com/drive/1ILYlPKkKlbLcPNq9VTEBJTlHURGBbMG2?usp=sharing
```
import keras
import tensorflow as tf
input_shape = (1, 3, 3, 3)
x = keras.layers.Input(input_shape[1:])
y = keras.layers.LeakyReLU(alpha=0.0)(x)
model = keras.Model(x,y)
model.summary()
import numpy as np
x = np.random.rand(*input_shape)
x *= -np.Inf
keras_output = model.predict(x)
print(""Keras's result"", keras_output)

tf_output = tf.nn.leaky_relu(x, alpha=0.0).numpy()
print(""TensorFlow's result"", tf_output)
```
Program output:
```
Keras's result [[[[0. 0. 0.]
   [0. 0. 0.]
   [0. 0. 0.]]

  [[0. 0. 0.]
   [0. 0. 0.]
   [0. 0. 0.]]

  [[0. 0. 0.]
   [0. 0. 0.]
   [0. 0. 0.]]]]
TensorFlow's result [[[[nan nan nan]
   [nan nan nan]
   [nan nan nan]]

  [[nan nan nan]
   [nan nan nan]
   [nan nan nan]]

  [[nan nan nan]
   [nan nan nan]
   [nan nan nan]]]]
```
"
55187,Will 64-bit support ever be added to the TPU driver API?,"Hi, this is my first GitHub issue so please let me know if this is an innapropriate place to ask this question.

When I try to create an array of type `float64` in JAX I get the following message:

`RuntimeError: INVALID_ARGUMENT: 64-bit data types are not yet supported on the TPU driver API. Convert inputs to float32/int32_t before using.`

which from what I can tell is from the file `tensorflow/compiler/xla/python/tpu_driver/client/tpu_client.cc` in the Tensorflow repo, which I assume is part of the TPU driver API code. The verbiage here suggests this support may one day be added to the TPU driver API, so I'd like to know if this is something that's planned to be added in the future. If it is planned, is there an ETA on when this feature may be available?

For a university project I'm trying to implement a Mersenne prime number search program which runs on the TPU. These calculations are very sensitive to precision errors, and we've found that although we may be able to use the TPU to improve performance over existing GPU-based programs, the precision of `bfloat16` or even `float32` are too low for the calculations we're trying to run."
55186,tensorflow core while do stdthread create,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (yes):
- OS Platform and Distribution (e.g., Linux Red Hat 4.8.5-16) (GCC) ):
- Mobile device (no) if the issue happens on mobile device:
- TensorFlow installed from (source):
- TensorFlow version (use command below):1.15.0
- Python version:no
- Bazel version (3.1.0):
- GCC/Compiler version (5.4.0):
- CUDA/cuDNN version:no
- GPU model and memory:no

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
while I load savedmodel,tensorflow core dump,the detail gdb info at below.

**Describe the expected behavior**
load saved model success
**[Contributing](https://www.tensorflow.org/community/contribute)**

- Do you want to contribute a PR? (no):
- Briefly describe your candidate solution(if contributing):

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs**
core dump stack info:
#0  0x0000000000000000 in ?? ()
#1  0x00007f201fbfbaf3 in __gthread_create (__args=<optimized out>, __func=0x7f201fbfb990 <std::execute_native_thread_routine(void*)>, __threadid=0x2ab77d8)
    at /usr/gcc-5.4.0/gcc-build/x86_64-unknown-linux-gnu/libstdc++-v3/include/x86_64-unknown-linux-gnu/bits/gthr-default.h:662
#2  std::thread::_M_start_thread (this=0x2ab77d8, __b=...) at ../../../../../libstdc++-v3/src/c++11/thread.cc:149
#3  0x00007f2016dc92c1 in std::thread::thread<std::function<void ()>&>(std::function<void ()>&) ()
   from /.../bazel-bin/src/lib/lib_common/xxx.so
#4  0x00007f2016dc8027 in tensorflow::(anonymous namespace)::StdThread::StdThread(tensorflow::ThreadOptions const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::function<void ()>) ()
   from /.../bazel-bin/src/lib/lib_common/xxx.so
#5  0x00007f2016dc83d6 in tensorflow::(anonymous namespace)::PosixEnv::StartThread(tensorflow::ThreadOptions const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::function<void ()>) ()
   from /.../bazel-bin/src/lib/lib_common/xxx.so
#6  0x00007f2016db46b5 in tensorflow::thread::EigenEnvironment::CreateThread(std::function<void ()>) ()
   from /.../bazel-bin/src/lib/lib_common/xxx.so
#7  0x00007f2016db517b in Eigen::ThreadPoolTempl<tensorflow::thread::EigenEnvironment>::ThreadPoolTempl(int, bool, tensorflow::thread::EigenEnvironment) ()
   from /.../bazel-bin/src/lib/lib_common/xxx.so
#8  0x00007f2016db1c9c in tensorflow::thread::ThreadPool::ThreadPool(tensorflow::Env*, tensorflow::ThreadOptions const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, int, bool, Eigen::Allocator*) ()
   from /.../bazel-bin/src/lib/lib_common/xxx.so
#9  0x00007f2016850084 in tensorflow::LocalDevice::EigenThreadPoolInfo::EigenThreadPoolInfo(tensorflow::SessionOptions const&, int, tensorflow::Allocator*)
    () from /.../bazel-bin/src/lib/lib_common/xxx.so
#10 0x00007f201684f9f9 in tensorflow::LocalDevice::LocalDevice(tensorflow::SessionOptions const&, tensorflow::DeviceAttributes const&) ()
   from /.../bazel-bin/src/lib/lib_common/xxx.so
#11 0x00007f20168ca7d1 in tensorflow::ThreadPoolDevice::ThreadPoolDevice(tensorflow::SessionOptions const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, tensorflow::gtl::IntType<tensorflow::Bytes_tag_, long long>, tensorflow::DeviceLocality const&, tensorflow::Allocator*)
    () from /.../bazel-bin/src/lib/lib_common/xxx.so
#12 0x00007f20168cbcb6 in absl::memory_internal::MakeUniqueResult<tensorflow::ThreadPoolDevice>::scalar absl::make_unique<tensorflow::ThreadPoolDevice, tensorflow::SessionOptions const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&, tensorflow::gtl::IntType<tensorflow::Bytes_tag_---Type <return> to continue, or q <return> to quit---
, long long>, tensorflow::DeviceLocality, tensorflow::Allocator*>(tensorflow::SessionOptions const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >&, tensorflow::gtl::IntType<tensorflow::Bytes_tag_, long long>&&, tensorflow::DeviceLocality&&, tensorflow::Allocator*&&) ()
   from /.../bazel-bin/src/lib/lib_common/xxx.so
#13 0x00007f20168cb92a in tensorflow::ThreadPoolDeviceFactory::CreateDevices(tensorflow::SessionOptions const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::vector<std::unique_ptr<tensorflow::Device, std::default_delete<tensorflow::Device> >, std::allocator<std::unique_ptr<tensorflow::Device, std::default_delete<tensorflow::Device> > > >*) ()
   from /.../bazel-bin/src/lib/lib_common/xxx.so
#14 0x00007f20167f3272 in tensorflow::DeviceFactory::AddDevices(tensorflow::SessionOptions const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::vector<std::unique_ptr<tensorflow::Device, std::default_delete<tensorflow::Device> >, std::allocator<std::unique_ptr<tensorflow::Device, std::default_delete<tensorflow::Device> > > >*) () from /.../bazel-bin/src/lib/lib_common/xxx.so
#15 0x00007f2015eb4a5d in tensorflow::DirectSessionFactory::NewSession(tensorflow::SessionOptions const&, tensorflow::Session**) ()
   from /.../bazel-bin/src/lib/lib_common/xxx.so
#16 0x00007f20168aa054 in tensorflow::NewSession(tensorflow::SessionOptions const&, tensorflow::Session**) ()
   from /.../bazel-bin/src/lib/lib_common/xxx.so
#17 0x00007f200f324559 in tensorflow::(anonymous namespace)::LoadMetaGraphIntoSession(tensorflow::MetaGraphDef const&, tensorflow::SessionOptions const&, std::unique_ptr<tensorflow::Session, std::default_delete<tensorflow::Session> >*) ()
   from /.../bazel-bin/src/lib/lib_common/xxx.so
#18 0x00007f200f32617a in tensorflow::(anonymous namespace)::LoadSavedModelInternal(tensorflow::SessionOptions const&, tensorflow::RunOptions const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::unordered_set<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&, tensorflow::SavedModelBundle*) () from /.../bazel-bin/src/lib/lib_common/xxx.so
#19 0x00007f200f3268e1 in tensorflow::LoadSavedModel(tensorflow::SessionOptions const&, tensorflow::RunOptions const&, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, std::unordered_set<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::hash<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::equal_to<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&, tensorflow::SavedModelBundle*) () from /.../bazel-bin/src/lib/lib_common/xxx.so
#20 0x00007f200f10a683 in fg_framework::TFGraphModel::LoadFromSavedModelBundle(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >---Type <return> to continue, or q <return> to quit---
 const&, fg_framework::LocalModelBundle*) () from /.../bazel-bin/src/lib/lib_common/xxx.so
#21 0x00007f200f10ac77 in fg_framework::TFGraphModel::Load(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) ()
   from /.../bazel-bin/src/lib/lib_common/xxx.so
#22 0x00007f200f1077ad in fg_framework::FeatureGenerator::InitFgConfig(std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) () from /.../bazel-bin/src/lib/lib_common/xxx.so
"
55185,`tf.random.set_seed` lack input validation,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Y
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.7.0
- Python version: 3.8
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source):N/A
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A

**Standalone code to reproduce the issue**
```
import tensorflow as tf
seed = None
tf.random.set_seed(seed, )
a = tf.random.uniform([1, 2])
tf.random.set_seed(seed, )
b = tf.random.uniform([1, 2])
tf.debugging.assert_near(a, b) # InvalidArgumentError
```

**Describe the current behavior**
[`tf.random.set_seed`](https://www.tensorflow.org/api_docs/python/tf/random/set_seed) should be called with an integer, however, calling `tf.random.set_seed(None)` will not result in error, and it cannot guarantee reproducibility : `a` is not equal to `b`.


**Describe the expected behavior**
`tf.random.set_seed` should check properly that `seed` is an integer, and raise an error if `seed` is `None`.
"
55184,Tensor evaluating to None,"**System information**
- TensorFlow version (you are using): TF1 and TF2
- Are you willing to contribute it (Yes/No): Depends on the extent of the change necessary.

**Describe the feature and the current behavior/state.** 
I have TF datasets (both TF1 and TF2) that I would like to transform (dataset.map). Transforms package the datasets into a new structure and this structure might contain some None elements. If I try to make elements None, I get some ""fetches errors"" saying None is not supported. I'm wondering if there is a value that would evaluate to None? If not, could we add support for one?

Alternative would be to create an iterator and manually doing the map on fetched items, but that messes up external API (as we no longer work on tf.Datasets but Iterators instead).

**Will this change the current api? How?**
Not sure.

**Who will benefit with this feature?**
DeepMind internal.

**Any Other info.**
"
55183,Targets in `tensorflow/core/kernels/fuzzing` directory.,"Hello. I'm trying to build fuzzing targets from `tensorflow/core/kernels/fuzzing` directory, and by default all targets from there are built as libraries. Was there some idea in this way of building, and is there any way to build them not like a library?
"
55182,"You have two different versions of our example for tf.transpose(x) , only one of your tutorial examples  of the exact same thing is correct!","Thank you for submitting a TensorFlow documentation issue. Per our GitHub
policy, we only address code/doc bugs, performance issues, feature requests, and
build/installation issues on GitHub.

The TensorFlow docs are open source! To get involved, read the documentation
contributor guide: https://www.tensorflow.org/community/contribute/docs

## URL(s) with the issue:
Tutorial Links:
Correct example of x @ tf.transpose(x)
https://www.tensorflow.org/api_docs/python/tf/compat/v1/transpose?authuser=2

Incorrect example of x @ tf.transpose(x)
https://www.tensorflow.org/guide/basics?authuser=2

## Description of issue (what needs changing):
Need to decide which result it correct when performing the x @ tf.transpose(x)

### Clear description
You have two different outcomes for the same x @ tf.transpose(x) [command]
You can't have it both ways.
"
55181,Make computation of higher order gradients through apply_gradients possible,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): 2.7 / 2.8
- Are you willing to contribute it (Yes/No): No



**Describe the feature and the current behavior/state.**
Currently, TF can not compute gradients through optimizer.apply_gradients calls - I suspect this would be caused by the underlying assign operation not being differentiable. However, this operation is in itself definitely differentiable and computing a gradient over this operation is a staple in multiple important works, especially in Meta-Learning and other fields actually making use of higher order gradients. 
Current behavior: While higher-order gradients can easily be implemented using e.g. nested gradient tapes (https://www.tensorflow.org/guide/advanced_autodiff#higher-order_gradients), they can not be achieved through applying gradient updates - generally done via optimizer.apply_gradients(). 

While in theory one can create work-arounds by stitching together gradients by hand ( let 'theta' be parameters before update, theta_dash parameters after update, phi some term dependent on the updated parameters one wants the gradient for: [d_L/d_theta_dash] x [d_theta_dash/d_theta] x [d_theta/d_phi] can be computed because TF can compute [d_L/d_theta_dash] and [d_theta/d_phi] naturally, for SGD [d_theta_dash/d_theta] is just vec(-1) really. However this workaround really only works for SGD without Momentum, for anything used in practice (let's say Adam as a default) this workaround does not work anymore because [d_theta_dash/d_theta] is dependent on specific parameter update from the optimizer rather than the gradient itself, which is not naturally exposed. )
In summary: De facto TF currently makes it extremely difficult and messy to implement hypergradients through gradient updates. This could partially be tackled by exposing differentiable computed parameter updates from optimizers.

Generally what should be possible can lazily be summarized like this: 
```

model = some_model()
inner_optimizer=optimizers.Adam()
with tf.GradientTape() as outer_tape:
    with tf.GradientTape() as inner_tape:
        y = model(x)
        inner_loss = loss(y)
    inner_gradients = inner_tape.gradient(inner_loss, model.trainable_weights)
    inner_optimizer.apply_gradients(zip(inner_gradients, model.trainable_weights))
    
    outer_loss = model(x')
outer_gradients = outer_tape.gradient(outer_loss, model.trainable_weights) #!notworking

        
```


**Will this change the current api? How?**
This should not change the API at all, in my opinion gradient computation through gradient updates in apply_gradient seems natural given the Graph nature of TF. Worst case this would create a boolean flag argument in apply_gradient to enable/disable gradients through the computation. 


**Who will benefit with this feature?**
Primarily the Meta-Learning Community and Researchers and Users relying from advances in this field. Two very impactful papers that showcase why this would be important: 
 - Model-Agnostic Meta Learning for Fast Adaption of Deep Networks : https://arxiv.org/pdf/1703.03400.pdf (>5500 citations)
 - Teaching with commentaries : https://arxiv.org/pdf/2011.03037.pdf (still novel, but seems to be impactful)
 
 Also: Google as Developer of TF, as even research at Google has to default to PyTorch for research on topics like the above, see e.g. here: (https://github.com/googleinterns/commentaries)


**Any Other info.**
Nothing technical, just love for TF as an awesome library that I wish stays ahead!"
55179,[TfLite] C++ tflite::InterpreterBuilder is missing in version r1.12,"Hi, I'm using the tflite library from version [r1.12](https://github.com/tensorflow/tensorflow/tree/r1.12/tensorflow/contrib/lite). However, I followed the guide in [official doc](https://www.tensorflow.org/lite/api_docs/cc/class/tflite/interpreter):

```
// Create model from file. Note that the model instance must outlive the
// interpreter instance.
auto model = [tflite::FlatBufferModel::BuildFromFile](https://tensorflow.google.cn/lite/api_docs/cc/class/tflite/flat-buffer-model#classtflite_1_1_flat_buffer_model_1aa38cad2bc62ae19a647c64f10226862b)(...);
if (model == nullptr) {
  // Return error.
}
// Create an [Interpreter](https://tensorflow.google.cn/lite/api_docs/cc/class/tflite/interpreter#classtflite_1_1_interpreter) with an [InterpreterBuilder](https://tensorflow.google.cn/lite/api_docs/cc/class/tflite/interpreter-builder#classtflite_1_1_interpreter_builder).
std::unique_ptr interpreter;
tflite::ops::builtin::BuiltinOpResolver resolver;
if (InterpreterBuilder(*model, resolver)(&interpreter) != kTfLiteOk) {
  // Return failure.
}
if (interpreter->AllocateTensors() != kTfLiteOk) {
  // Return failure.
}
```

It seems that the `interpreterBuilder.h` file is missing in the r1.12 version. In this case, what should I do to create an interpreter with a specified model in r1.12? Thanks.
"
55178,tf.distribute.MultiWorkerMirroredStrategy() not getting initialized(RuntimeError: Collective ops must be configured at program startup),"I am running a training job on vertex AI. 
Versions:
TF = 2.7
python = 3.8

The model runs fine for mirrored strategy where we have only one node with multiple gpu attached to it.

For MultiWorkerMirroredStrategy I am using
chief - n1 32 with 4V100 gpu - count 1(default)
worker n1 32 with 4V100 gpu - count 1

When I am trying to run the code using multiple nodes using MultiWorkerMirroredStrategy, It is giving following error

RuntimeError: Collective ops must be configured at program startup

I found some suggestions to put the strategy at the program beginning  but that also didn't help.
Vertex AI is setting the TF_CONFIG correctly.
But it is not able to instantiate the MultiWorkerMirroredStrategy

The stack trace

 mirrored_strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()""
"" File ""/opt/conda/envs/py38/lib/python3.8/site-packages/tensorflow/python/util/deprecation.py"", line 348, in new_func""

workerpool0-0
"" File ""/opt/conda/envs/py38/lib/python3.8/site-packages/tensorflow/python/distribute/collective_all_reduce_strategy.py"", line 253, in __init__""
"" super(_CollectiveAllReduceStrategyExperimental,""
workerpool0-0
"" File ""/opt/conda/envs/py38/lib/python3.8/site-packages/tensorflow/python/distribute/collective_all_reduce_strategy.py"", line 186, in __init__""
workerpool0-0
"" CollectiveAllReduceExtended(""
workerpool0-0
"" File ""/opt/conda/envs/py38/lib/python3.8/site-packages/tensorflow/python/distribute/collective_all_reduce_strategy.py"", line 330, in __init__""
workerpool0-0
"" self._initialize_strategy(self._cluster_resolver)""
Error
2022-03-09 09:57:09.622 IST
workerpool0-0
"" File ""/opt/conda/envs/py38/lib/python3.8/site-packages/tensorflow/python/distribute/collective_all_reduce_strategy.py"", line 342, in _initialize_strategy""
Error
2022-03-09 09:57:09.622 IST
workerpool0-0
"" self._initialize_multi_worker(cluster_resolver)""
Error
2022-03-09 09:57:09.622 IST
workerpool0-0
"" File ""/opt/conda/envs/py38/lib/python3.8/site-packages/tensorflow/python/distribute/collective_all_reduce_strategy.py"", line 463, in _initialize_multi_worker""
Error
2022-03-09 09:57:09.622 IST
workerpool0-0
"" context.context().configure_collective_ops(""
Error
2022-03-09 09:57:09.622 IST
workerpool0-0
"" File ""/opt/conda/envs/py38/lib/python3.8/site-packages/tensorflow/python/eager/context.py"", line 817, in configure_collective_ops""
Error
2022-03-09 09:57:09.622 IST
workerpool0-0
"" raise RuntimeError(""Collective ops must be configured at program startup"")""
Error
2022-03-09 09:57:09.622 IST
workerpool0-0
""RuntimeError: Collective ops must be configured at program startup"""
55174,Silent reset_states() error in custom model,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Custom code
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS Monterey 12.1
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): 2.8
- Python version: 3.9

**Describe the current behavior**
I am developing a custom model by inheriting from the `tf.keras.Model` class, in particular I am developing a custom LSTM residual network. Following the documentation and code, if calling `model.reset_states()` on a stateless layer should trigger an exception present in the layer class (in my case LSTM). 

However, such call is obscured by a conditional statement that prevents the raising of such exception in any case (at least the one I was trying). So basically model.reset_states() runs silently without errors and without resetting the states. 

This is the function present inside tf.keras.Model class. The conditional statement prevents the condition from layer.reset_states() to be raised. By manually forcing the evaluation  of `layer.reset_states()` inside a debugger, the exception is correctly raised.

```
  def reset_states(self):
    for layer in self.layers:
      if hasattr(layer, 'reset_states') and getattr(layer, 'stateful', False):
        layer.reset_states()

```

**Describe the expected behavior**
Raise the exception and make explicit whether reset_states() is called on layers that are not stateful

- Do you want to contribute a PR? (yes/no): no

**Standalone code to reproduce the issue**


```
class ResNetModel(Model):
    def __init__(self, num_inputs, **kwargs):
        """"""
        The class initialiser should call the base class initialiser, passing any keyword
        arguments along. It should also create the layers of the network according to the
        above specification.
        """"""
        super(ResNetModel, self).__init__(**kwargs)
        self.lstm_1 = tf.keras.layers.LSTM(units=32, input_shape=(None, num_inputs), return_sequences=True, stateful = False)
        self.dense = tf.keras.layers.Dense(units=1, activation=None)

    def call(self, inputs, training=False):
        """"""
        This method should contain the code for calling the layer according to the above
        specification, using the layer objects set up in the initialiser.
        """"""
        x = self.lstm_1(inputs)
        y = self.dense(x)
        return y + inputs

model = ResNetModel(1)
model.reset_states() # does not raise any errors
```
"
55148,Build of tests //tensorflow/core/transforms/... fails,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: n/a
- TensorFlow installed from (source or binary): source
- TensorFlow version: git HEAD
- Python version: 3.8.12
- Installed using virtualenv? pip? conda?: no
- Bazel version (if compiling from source): 5.0.0
- GCC/Compiler version (if compiling from source): 10.3.0
- CUDA/cuDNN version: n/a
- GPU model and memory: n/a



**Describe the problem**

Attempting to build //tensorflow/core/transforms/... fails with many undefined references

**Provide the exact sequence of commands / steps that you executed before running into the problem**

bazel test --test_timeout=300,500,-1,-1 --flaky_test_attempts=3 --test_output=all --cache_test_results=no --config=nonccl --verbose_failures --build_tag_filters=-no_oss,-oss_serial,-gpu,-tpu,-benchmark-test,-v1only,-no_aarch64,-requires-gpu --test_tag_filters=-no_oss,-oss_serial,-gpu,-tpu,-benchmark-test,-v1only,-no_aarch64,-requires-gpu --jobs=75 -- //tensorflow/core/transforms/...

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.


ERROR: /tmp/workspace/tensorflow-git/tensorflow/core/transforms/BUILD:92:20: Linking tensorflow/core/transforms/tfg-transforms-opt failed: (Exit 1): gcc failed: error executing command 
  (cd /root/.cache/bazel/_bazel_root/db210f68f81d95ddcca9ae96b16ed72c/execroot/org_tensorflow && \
  exec env - \
    LD_LIBRARY_PATH=/opt/rh/devtoolset-10/root/usr/lib64:/opt/rh/devtoolset-10/root/usr/lib:/opt/rh/devtoolset-10/root/usr/lib64/dyninst:/opt/rh/devtoolset-10/root/usr/lib/dyninst:/usr/local/lib64 \
    PATH=/tmp/workspace/venv-cp38-cp38/bin:/opt/rh/devtoolset-10/root/usr/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \
    PWD=/proc/self/cwd \
    PYTHON_BIN_PATH=/tmp/workspace/venv-cp38-cp38/bin/python3 \
    PYTHON_LIB_PATH=/tmp/workspace/venv-cp38-cp38/lib/python3.8/site-packages \
    TF2_BEHAVIOR=1 \
  /opt/rh/devtoolset-10/root/usr/bin/gcc @bazel-out/aarch64-opt/bin/tensorflow/core/transforms/tfg-transforms-opt-2.params)
# Configuration: adf76bbb856b8d7e1075d9fa81311a63f070542e9be48c5b759e905be0f8e507
# Execution platform: @local_execution_config_platform//:platform
bazel-out/aarch64-opt/bin/tensorflow/core/user_ops/_objs/user_ops_op_lib/fact.o:fact.cc:function FactOp::~FactOp(): error: undefined reference to 'tensorflow::OpKernel::~OpKernel()'
bazel-out/aarch64-opt/bin/tensorflow/core/user_ops/_objs/user_ops_op_lib/fact.o:fact.cc:function FactOp::~FactOp(): error: undefined reference to 'tensorflow::OpKernel::~OpKernel()'
bazel-out/aarch64-opt/bin/tensorflow/core/user_ops/_objs/user_ops_op_lib/fact.o:fact.cc:function register_kernel_1::{lambda(tensorflow::KernelDef const*)#1}::operator()(tensorflow::KernelDef const) const::{lambda(register_kernel_1::OpKernelConstruction*)#1}::_FUN(register_kernel_1::{lambda(tensorflow::KernelDef const*)#1}): error: undefined reference to 'tensorflow::OpKernel::OpKernel(tensorflow::OpKernelConstruction*)'
bazel-out/aarch64-opt/bin/tensorflow/core/user_ops/_objs/user_ops_op_lib/fact.o:fact.cc:function FactOp::Compute(tensorflow::OpKernelContext*): error: undefined reference to 'tensorflow::TensorShapeBase<tensorflow::TensorShape>::TensorShapeBase()'
bazel-out/aarch64-opt/bin/tensorflow/core/user_ops/_objs/user_ops_op_lib/fact.o:fact.cc:function FactOp::Compute(tensorflow::OpKernelContext*): error: undefined reference to 'tensorflow::OpKernelContext::allocate_output(int, tensorflow::TensorShape const&, tensorflow::Tensor**)'
bazel-out/aarch64-opt/bin/tensorflow/core/user_ops/_objs/user_ops_op_lib/fact.o:fact.cc:function FactOp::Compute(tensorflow::OpKernelContext*): error: undefined reference to 'tensorflow::Tensor::CheckIsAlignedAndSingleElement() const'
bazel-out/aarch64-opt/bin/tensorflow/core/user_ops/_objs/user_ops_op_lib/fact.o:fact.cc:function FactOp::Compute(tensorflow::OpKernelContext*): error: undefined reference to 'tensorflow::TensorShapeRep::DestructorOutOfLine()'
bazel-out/aarch64-opt/bin/tensorflow/core/user_ops/_objs/user_ops_op_lib/fact.o:fact.cc:function FactOp::Compute(tensorflow::OpKernelContext*): error: undefined reference to 'tensorflow::CheckNotInComputeAsync(tensorflow::OpKernelContext*, char const*)'
bazel-out/aarch64-opt/bin/tensorflow/core/user_ops/_objs/user_ops_op_lib/fact.o:fact.cc:function FactOp::Compute(tensorflow::OpKernelContext*): error: undefined reference to 'tensorflow::OpKernelContext::CtxFailureWithWarning(char const*, int, tensorflow::Status const&)'
bazel-out/aarch64-opt/bin/tensorflow/core/user_ops/_objs/user_ops_op_lib/fact.o:fact.cc:function __static_initialization_and_destruction_0(int, int) [clone .constprop.0]: error: undefined reference to 'tensorflow::OpDefBuilder::OpDefBuilder(std::string)'
bazel-out/aarch64-opt/bin/tensorflow/core/user_ops/_objs/user_ops_op_lib/fact.o:fact.cc:function __static_initialization_and_destruction_0(int, int) [clone .constprop.0]: error: undefined reference to 'tensorflow::OpDefBuilder::Output(std::string)'
bazel-out/aarch64-opt/bin/tensorflow/core/user_ops/_objs/user_ops_op_lib/fact.o:fact.cc:function __static_initialization_and_destruction_0(int, int) [clone .constprop.0]: error: undefined reference to 'tensorflow::shape_inference::UnknownShape(tensorflow::shape_inference::InferenceContext*)'
bazel-out/aarch64-opt/bin/tensorflow/core/user_ops/_objs/user_ops_op_lib/fact.o:fact.cc:function __static_initialization_and_destruction_0(int, int) [clone .constprop.0]: error: undefined reference to 'tensorflow::shape_inference::UnknownShape(tensorflow::shape_inference::InferenceContext*)'
bazel-out/aarch64-opt/bin/tensorflow/core/user_ops/_objs/user_ops_op_lib/fact.o:fact.cc:function __static_initialization_and_destruction_0(int, int) [clone .constprop.0]: error: undefined reference to 'tensorflow::OpDefBuilder::SetShapeFn(std::function<tensorflow::Status (tensorflow::shape_inference::InferenceContext*)>)'
bazel-out/aarch64-opt/bin/tensorflow/core/user_ops/_objs/user_ops_op_lib/fact.o:fact.cc:function __static_initialization_and_destruction_0(int, int) [clone .constprop.0]: error: undefined reference to 'tensorflow::register_op::OpDefBuilderWrapper::operator()()'
bazel-out/aarch64-opt/bin/tensorflow/core/user_ops/_objs/user_ops_op_lib/fact.o:fact.cc:function __static_initialization_and_destruction_0(int, int) [clone .constprop.0]: error: undefined reference to 'tensorflow::OpDef::~OpDef()'
bazel-out/aarch64-opt/bin/tensorflow/core/user_ops/_objs/user_ops_op_lib/fact.o:fact.cc:function __static_initialization_and_destruction_0(int, int) [clone .constprop.0]: error: undefined reference to 'tensorflow::KernelDefBuilder::KernelDefBuilder(char const*)'
bazel-out/aarch64-opt/bin/tensorflow/core/user_ops/_objs/user_ops_op_lib/fact.o:fact.cc:function __static_initialization_and_destruction_0(int, int) [clone .constprop.0]: error: undefined reference to 'tensorflow::DEVICE_CPU'
bazel-out/aarch64-opt/bin/tensorflow/core/user_ops/_objs/user_ops_op_lib/fact.o:fact.cc:function __static_initialization_and_destruction_0(int, int) [clone .constprop.0]: error: undefined reference to 'tensorflow::DEVICE_CPU'
bazel-out/aarch64-opt/bin/tensorflow/core/user_ops/_objs/user_ops_op_lib/fact.o:fact.cc:function __static_initialization_and_destruction_0(int, int) [clone .constprop.0]: error: undefined reference to 'tensorflow::KernelDefBuilder::Device(char const*)'
bazel-out/aarch64-opt/bin/tensorflow/core/user_ops/_objs/user_ops_op_lib/fact.o:fact.cc:function __static_initialization_and_destruction_0(int, int) [clone .constprop.0]: error: undefined reference to 'tensorflow::KernelDefBuilder::Build()'
bazel-out/aarch64-opt/bin/tensorflow/core/user_ops/_objs/user_ops_op_lib/fact.o:fact.cc:function __static_initialization_and_destruction_0(int, int) [clone .constprop.0]: error: undefined reference to 'vtable for tensorflow::kernel_factory::OpKernelRegistrar::PtrOpKernelFactory'
/opt/rh/devtoolset-10/root/usr/bin/ld.gold: the vtable symbol may be undefined because the class is missing its key function
bazel-out/aarch64-opt/bin/tensorflow/core/user_ops/_objs/user_ops_op_lib/fact.o:fact.cc:function __static_initialization_and_destruction_0(int, int) [clone .constprop.0]: error: undefined reference to 'vtable for tensorflow::kernel_factory::OpKernelRegistrar::PtrOpKernelFactory'
/opt/rh/devtoolset-10/root/usr/bin/ld.gold: the vtable symbol may be undefined because the class is missing its key function
bazel-out/aarch64-opt/bin/tensorflow/core/user_ops/_objs/user_ops_op_lib/fact.o:fact.cc:function __static_initialization_and_destruction_0(int, int) [clone .constprop.0]: error: undefined reference to 'tensorflow::kernel_factory::OpKernelRegistrar::InitInternal(tensorflow::KernelDef const*, absl::lts_20211102::string_view, std::unique_ptr<tensorflow::kernel_factory::OpKernelFactory, std::default_delete<tensorflow::kernel_factory::OpKernelFactory> >)'
bazel-out/aarch64-opt/bin/tensorflow/core/user_ops/_objs/user_ops_op_lib/fact.o:fact.cc:function __static_initialization_and_destruction_0(int, int) [clone .constprop.0]: error: undefined reference to 'tensorflow::KernelDefBuilder::~KernelDefBuilder()'
bazel-out/aarch64-opt/bin/tensorflow/core/user_ops/_objs/user_ops_op_lib/fact.o:fact.cc:typeinfo for FactOp: error: undefined reference to 'typeinfo for tensorflow::OpKernel'
bazel-out/aarch64-opt/bin/tensorflow/core/user_ops/_objs/user_ops_op_lib/fact.o:fact.cc:vtable for FactOp: error: undefined reference to 'tensorflow::OpKernel::TraceString(tensorflow::OpKernelContext const&, bool) const'
bazel-out/aarch64-opt/bin/tensorflow/core/ops/_objs/array_ops_op_lib/array_ops.o:array_ops.cc:function std::_Function_handler<tensorflow::Status (tensorflow::shape_inference::InferenceContext*), tensorflow::register_op19::{lambda(tensorflow::shape_inference::InferenceContext*)#1}>::_M_invoke(std::_Any_data const&, tensorflow::shape_inference::InferenceContext*&&): error: undefined reference to 'tensorflow::shape_inference::UnchangedShape(tensorflow::shape_inference::InferenceContext*)'
bazel-out/aarch64-opt/bin/tensorflow/core/ops/_objs/array_ops_op_lib/array_ops.o:array_ops.cc:function std::_Function_handler<tensorflow::Status (tensorflow::shape_inference::InferenceContext*), tensorflow::register_op10::{lambda(tensorflow::shape_inference::InferenceContext*)#1}>::_M_invoke(std::_Any_data const&, tensorflow::shape_inference::InferenceContext*&&): error: undefined reference to 'tensorflow::shape_inference::ConcatShape(tensorflow::shape_inference::InferenceContext*, int)'
bazel-out/aarch64-opt/bin/tensorflow/core/ops/_objs/array_ops_op_lib/array_ops.o:array_ops.cc:function tensorflow::shape_inference::ScalarShape(tensorflow::shape_inference::InferenceContext*): error: undefined reference to 'tensorflow::shape_inference::InferenceContext::Scalar()'
bazel-out/aarch64-opt/bin/tensorflow/core/ops/_objs/array_ops_op_lib/array_ops.o:array_ops.cc:function std::_Function_handler<tensorflow::Status (tensorflow::shape_inference::InferenceContext*), tensorflow::register_op57::{lambda(tensorflow::shape_inference::InferenceContext*)#1}>::_M_invoke(std::_Any_data const&, tensorflow::shape_inference::InferenceContext*&&): error: undefined reference to 'tensorflow::shape_inference::InferenceContext::Vector(tensorflow::shape_inference::DimensionOrConstant)'
bazel-out/aarch64-opt/bin/tensorflow/core/ops/_objs/array_ops_op_lib/array_ops.o:array_ops.cc:function std::_Function_handler<tensorflow::Status (tensorflow::shape_inference::InferenceContext*), tensorflow::register_op57::{lambda(tensorflow::shape_inference::InferenceContext*)#1}>::_M_invoke(std::_Any_data const&, tensorflow::shape_inference::InferenceContext*&&): error: undefined reference to 'tensorflow::shape_inference::InferenceContext::WithRank(tensorflow::shape_inference::ShapeHandle, long, tensorflow::shape_inference::ShapeHandle*)'
bazel-out/aarch64-opt/bin/tensorflow/core/ops/_objs/array_ops_op_lib/array_ops.o:array_ops.cc:function std::_Function_handler<tensorflow::Status (tensorflow::shape_inference::InferenceContext*), tensorflow::register_op59::{lambda(tensorflow::shape_inference::InferenceContext*)#1}>::_M_invoke(std::_Any_data const&, tensorflow::shape_inference::InferenceContext*&&): error: undefined reference to 'tensorflow::shape_inference::InferenceContext::Vector(tensorflow::shape_inference::DimensionOrConstant)'
bazel-out/aarch64-opt/bin/tensorflow/core/ops/_objs/array_ops_op_lib/array_ops.o:array_ops.cc:function tensorflow::(anonymous namespace)::ScatterNdTensorShape(tensorflow::shape_inference::InferenceContext*): error: undefined reference to 'tensorflow::shape_inference::InferenceContext::WithRankAtLeast(tensorflow::shape_inference::ShapeHandle, long, tensorflow::shape_inference::ShapeHandle*)'
bazel-out/aarch64-opt/bin/tensorflow/core/ops/_objs/array_ops_op_lib/array_ops.o:array_ops.cc:function tensorflow::(anonymous namespace)::ScatterNdTensorShape(tensorflow::shape_inference::InferenceContext*): error: undefined reference to 'tensorflow::shape_inference::InferenceContext::WithRankAtLeast(tensorflow::shape_inference::ShapeHandle, long, tensorflow::shape_inference::ShapeHandle*)'
bazel-out/aarch64-opt/bin/tensorflow/core/ops/_objs/array_ops_op_lib/array_ops.o:array_ops.cc:function tensorflow::(anonymous namespace)::ScatterNdTensorShape(tensorflow::shape_inference::InferenceContext*): error: undefined reference to 'tensorflow::shape_inference::InferenceContext::WithRankAtLeast(tensorflow::shape_inference::ShapeHandle, long, tensorflow::shape_inference::ShapeHandle*)'
bazel-out/aarch64-opt/bin/tensorflow/core/ops/_objs/array_ops_op_lib/array_ops.o:array_ops.cc:function tensorflow::(anonymous namespace)::ScatterNdTensorShape(tensorflow::shape_inference::InferenceContext*): error: undefined reference to 'tensorflow::shape_inference::ScatterNdShapeHelper(tensorflow::shape_inference::InferenceContext*, tensorflow::shape_inference::ShapeHandle, tensorflow::shape_inference::ShapeHandle, tensorflow::shape_inference::ShapeHandle)'
bazel-out/aarch64-opt/bin/tensorflow/core/ops/_objs/array_ops_op_lib/array_ops.o:array_ops.cc:function std::_Function_handler<tensorflow::Status (tensorflow::shape_inference::InferenceContext*), tensorflow::register_op118::{lambda(tensorflow::shape_inference::InferenceContext*)#1}>::_M_invoke(std::_Any_data const&, tensorflow::shape_inference::InferenceContext*&&): error: undefined reference to 'tensorflow::shape_inference::UnchangedShape(tensorflow::shape_inference::InferenceContext*)'
bazel-out/aarch64-opt/bin/tensorflow/core/ops/_objs/array_ops_op_lib/array_ops.o:array_ops.cc:function std::_Function_handler<tensorflow::Status (tensorflow::shape_inference::InferenceContext*), tensorflow::register_op118::{lambda(tensorflow::shape_inference::InferenceContext*)#1}>::_M_invoke(std::_Any_data const&, tensorflow::shape_inference::InferenceContext*&&): error: undefined reference to 'tensorflow::shape_inference::InferenceContext::WithRank(tensorflow::shape_inference::ShapeHandle, long, tensorflow::shape_inference::ShapeHandle*)'

and much more...."
55147,MultiWorkerMirroredStrategy reinitializes reduce operations multiple times at start and also from time to time.,"<em>Please make sure that this is an issue related to performance of TensorFlow.
As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:performance_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: -
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): v2.7.0-rc1-69-gc256c071bb2 2.7.0
- Python version: 3.8
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 11.4 
- GPU model and memory: V100 16GB

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
Fyi: I use a custom training loop. 
On a multi worker setup with `MultiWorkerMirroredStrategy` I get this output for the first 3 train steps and they are also super slow:
```
[08/03/22 16:50:11] [tensorflow] INFO : Collective all_reduce tensors: 236 all_reduces, num_devices = 8, group_size = 48, implementation = NCCL, num_packs = 1
[08/03/22 16:50:20] [tensorflow] INFO : Collective all_reduce tensors: 1 all_reduces, num_devices = 8, group_size = 48, implementation = NCCL, num_packs = 1
[08/03/22 16:50:20] [tensorflow] INFO : Collective all_reduce tensors: 1 all_reduces, num_devices = 1, group_size = 6, implementation = NCCL, num_packs = 1
[08/03/22 16:50:20] [tensorflow] INFO : Collective all_reduce tensors: 1 all_reduces, num_devices = 1, group_size = 6, implementation = NCCL, num_packs = 1
[08/03/22 16:50:20] [tensorflow] INFO : Collective all_reduce tensors: 1 all_reduces, num_devices = 1, group_size = 6, implementation = NCCL, num_packs = 1
[08/03/22 16:50:20] [tensorflow] INFO : Collective all_reduce tensors: 1 all_reduces, num_devices = 1, group_size = 6, implementation = NCCL, num_packs = 1
[08/03/22 16:50:20] [tensorflow] INFO : Collective all_reduce tensors: 1 all_reduces, num_devices = 1, group_size = 6, implementation = NCCL, num_packs = 1
[08/03/22 16:50:20] [tensorflow] INFO : Collective all_reduce tensors: 1 all_reduces, num_devices = 1, group_size = 6, implementation = NCCL, num_packs = 1
[08/03/22 16:50:20] [tensorflow] INFO : Collective all_reduce tensors: 1 all_reduces, num_devices = 1, group_size = 6, implementation = NCCL, num_packs = 1
[08/03/22 16:50:20] [tensorflow] INFO : Collective all_reduce tensors: 1 all_reduces, num_devices = 1, group_size = 6, implementation = NCCL, num_packs = 1
[08/03/22 16:50:20] [tensorflow] INFO : Collective all_reduce tensors: 1 all_reduces, num_devices = 1, group_size = 6, implementation = NCCL, num_packs = 1
[08/03/22 16:50:20] [tensorflow] INFO : Collective all_reduce tensors: 1 all_reduces, num_devices = 1, group_size = 6, implementation = NCCL, num_packs = 1
[08/03/22 16:50:20] [tensorflow] INFO : Collective all_reduce tensors: 1 all_reduces, num_devices = 1, group_size = 6, implementation = NCCL, num_packs = 1
[08/03/22 16:50:20] [tensorflow] INFO : Collective all_reduce tensors: 1 all_reduces, num_devices = 1, group_size = 6, implementation = NCCL, num_packs = 1
[08/03/22 16:50:20] [tensorflow] INFO : Collective all_reduce tensors: 1 all_reduces, num_devices = 1, group_size = 6, implementation = NCCL, num_packs = 1
[08/03/22 16:50:20] [tensorflow] INFO : Collective all_reduce tensors: 1 all_reduces, num_devices = 1, group_size = 6, implementation = NCCL, num_packs = 1
``` 

Then the training runs as expected but it seems that the above init/retracing can happen randomly in the middle of the training again with the same logs. So an intermediate step after 1000 iterations can again take minutes (the more workers/devices the longer)
The step at which this happens is not the same for multiple runs, that being the reason why I say randomly.

Could this be related to non-constant input sizes (number of points in a pointcloud? They are of course padded within a batch) Do I need to globally pad here?

**Describe the expected behavior**
Only initialize the Collective all_reduce tensors once and especially not in the middle of training.

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
55143,How to retrain a model with changed shape of intermediate layer,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below):2.3
- Python version:3.8
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
I have a custom layer in my model that has a switch behavior for its output, For the first behavior say it gives an output shape of tensor shape(100,24,24,6) and for the second shape it gives the output shape of (100,24,24,1). My model is already trained for first behavior how can I retrain it for second behavior with the same model architecture and the weights but with a different output shape for a intermediate layer?
 Is it possible in TensorFlow to change the output shape of a intermediate layer? Any suggestions are appreciated. Thank you in advance.

**Describe the expected behavior**
Successful retraining of the model with changed shape of intermediate layer
**[Contributing](https://www.tensorflow.org/community/contribute)**

- Do you want to contribute a PR? (yes/no):
- Briefly describe your candidate solution(if contributing):

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
55139,Bug in feature_column.embedding_column based on vocabulary size,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux  AL2
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): v2.3.3-137-gea90cf44f73 2.3.4
- Python version: 3.6

- CUDA/cuDNN version: replicable on CPU
- GPU model and memory: replicable on CPU 

**Describe the current behavior**
While trying to use `tf.feature_column.embedding_column` API. While I don't think is relevant I'm generating the input data via `tf.data.Dataset.from_generator`.

Code   
```python
 for colmn_name in indicator_colms:
        feature_col = feature_column.categorical_column_with_vocabulary_list(
            colmn_name, unique_values(colmn_name))
        indicator_column = feature_column.indicator_column(feature_col)
        feature_columns.append(indicator_column)
```

**Describe the expected behavior**
For small vocabulary sizes everything works fine but the moment I try to add more elements to my vocabulary I weirdly get the following exception:
```
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
~/anaconda3/envs/amazonei_tensorflow2_p36/lib/python3.6/site-packages/keras/feature_column/dense_features.py in call(self, features, cols_to_output_tensors, training)
    165           tensor = column.get_dense_tensor(
--> 166               transformation_cache, self._state_manager, training=training)
    167         except TypeError:

TypeError: get_dense_tensor() got an unexpected keyword argument 'training'

During handling of the above exception, another exception occurred:

TypeError                                 Traceback (most recent call last)
~/anaconda3/envs/amazonei_tensorflow2_p36/lib/python3.6/site-packages/tensorflow/python/feature_column/feature_column_v2.py in get(self, key, state_manager, training)
   2457       transformed = column.transform_feature(
-> 2458           self, state_manager, training=training)
   2459     except TypeError:

TypeError: transform_feature() got an unexpected keyword argument 'training'

During handling of the above exception, another exception occurred:

TypeError                                 Traceback (most recent call last)
~/anaconda3/envs/amazonei_tensorflow2_p36/lib/python3.6/site-packages/tensorflow/python/feature_column/feature_column_v2.py in get(self, key, state_manager, training)
   2457       transformed = column.transform_feature(
-> 2458           self, state_manager, training=training)
   2459     except TypeError:

TypeError: transform_feature() got an unexpected keyword argument 'training'

During handling of the above exception, another exception occurred:

ValueError                                Traceback (most recent call last)
<ipython-input-69-8136fbe34af6> in <module>
      2     feature_columns = _create_feature_columns()
      3     feature_layer = tf.keras.layers.DenseFeatures(feature_columns)
----> 4     demo(feature_columns)

<ipython-input-10-65d9d3c8db7a> in demo(feature_column)
      1 def demo(feature_column):
      2     demo_feature_layer = layers.DenseFeatures(feature_column)
----> 3     print(demo_feature_layer(example_batch).numpy())

~/anaconda3/envs/amazonei_tensorflow2_p36/lib/python3.6/site-packages/keras/engine/base_layer.py in __call__(self, *args, **kwargs)
   1035         with autocast_variable.enable_auto_cast_variables(
   1036             self._compute_dtype_object):
-> 1037           outputs = call_fn(inputs, *args, **kwargs)
   1038 
   1039         if self._activity_regularizer:

~/anaconda3/envs/amazonei_tensorflow2_p36/lib/python3.6/site-packages/keras/feature_column/dense_features.py in call(self, features, cols_to_output_tensors, training)
    167         except TypeError:
    168           tensor = column.get_dense_tensor(transformation_cache,
--> 169                                            self._state_manager)
    170         processed_tensors = self._process_dense_tensor(column, tensor)
    171         if cols_to_output_tensors is not None:

~/anaconda3/envs/amazonei_tensorflow2_p36/lib/python3.6/site-packages/tensorflow/python/feature_column/feature_column_v2.py in get_dense_tensor(self, transformation_cache, state_manager)
   4301     # Feature has been already transformed. Return the intermediate
   4302     # representation created by transform_feature.
-> 4303     return transformation_cache.get(self, state_manager)
   4304 
   4305   @deprecation.deprecated(_FEATURE_COLUMN_DEPRECATION_DATE,

~/anaconda3/envs/amazonei_tensorflow2_p36/lib/python3.6/site-packages/tensorflow/python/feature_column/feature_column_v2.py in get(self, key, state_manager, training)
   2458           self, state_manager, training=training)
   2459     except TypeError:
-> 2460       transformed = column.transform_feature(self, state_manager)
   2461     if transformed is None:
   2462       raise ValueError('Column {} is not supported.'.format(column.name))

~/anaconda3/envs/amazonei_tensorflow2_p36/lib/python3.6/site-packages/tensorflow/python/feature_column/feature_column_v2.py in transform_feature(self, transformation_cache, state_manager)
   4238     """"""
   4239     id_weight_pair = self.categorical_column.get_sparse_tensors(
-> 4240         transformation_cache, state_manager)
   4241     return self._transform_id_weight_pair(id_weight_pair,
   4242                                           self.variable_shape[-1])

~/anaconda3/envs/amazonei_tensorflow2_p36/lib/python3.6/site-packages/tensorflow/python/feature_column/feature_column_v2.py in get_sparse_tensors(self, transformation_cache, state_manager)
   3725     """"""See `CategoricalColumn` base class.""""""
   3726     return CategoricalColumn.IdWeightPair(
-> 3727         transformation_cache.get(self, state_manager), None)
   3728 
   3729   @deprecation.deprecated(_FEATURE_COLUMN_DEPRECATION_DATE,

~/anaconda3/envs/amazonei_tensorflow2_p36/lib/python3.6/site-packages/tensorflow/python/feature_column/feature_column_v2.py in get(self, key, state_manager, training)
   2458           self, state_manager, training=training)
   2459     except TypeError:
-> 2460       transformed = column.transform_feature(self, state_manager)
   2461     if transformed is None:
   2462       raise ValueError('Column {} is not supported.'.format(column.name))

~/anaconda3/envs/amazonei_tensorflow2_p36/lib/python3.6/site-packages/tensorflow/python/feature_column/feature_column_v2.py in transform_feature(self, transformation_cache, state_manager)
   3703     input_tensor = _to_sparse_input_and_drop_ignore_values(
   3704         transformation_cache.get(self.key, state_manager))
-> 3705     return self._transform_input_tensor(input_tensor, state_manager)
   3706 
   3707   @deprecation.deprecated(_FEATURE_COLUMN_DEPRECATION_DATE,

~/anaconda3/envs/amazonei_tensorflow2_p36/lib/python3.6/site-packages/tensorflow/python/feature_column/feature_column_v2.py in _transform_input_tensor(self, input_tensor, state_manager)
   3691             num_oov_buckets=self.num_oov_buckets,
   3692             dtype=key_dtype,
-> 3693             name=name)
   3694       if state_manager is not None:
   3695         state_manager.add_resource(self, name, table)

~/anaconda3/envs/amazonei_tensorflow2_p36/lib/python3.6/site-packages/tensorflow/python/ops/lookup_ops.py in index_table_from_tensor(vocabulary_list, num_oov_buckets, default_value, hasher_spec, dtype, name)
   1507 
   1508   with ops.name_scope(name, ""string_to_index""):
-> 1509     keys = ops.convert_to_tensor(vocabulary_list)
   1510     if keys.dtype.is_integer != dtype.is_integer:
   1511       raise ValueError(

~/anaconda3/envs/amazonei_tensorflow2_p36/lib/python3.6/site-packages/tensorflow/python/profiler/trace.py in wrapped(*args, **kwargs)
    161         with Trace(trace_name, **trace_kwargs):
    162           return func(*args, **kwargs)
--> 163       return func(*args, **kwargs)
    164 
    165     return wrapped

~/anaconda3/envs/amazonei_tensorflow2_p36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py in convert_to_tensor(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)
   1564 
   1565     if ret is None:
-> 1566       ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)
   1567 
   1568     if ret is NotImplemented:

~/anaconda3/envs/amazonei_tensorflow2_p36/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py in _constant_tensor_conversion_function(v, dtype, name, as_ref)
    344                                          as_ref=False):
    345   _ = as_ref
--> 346   return constant(v, dtype=dtype, name=name)
    347 
    348 

~/anaconda3/envs/amazonei_tensorflow2_p36/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py in constant(value, dtype, shape, name)
    270   """"""
    271   return _constant_impl(value, dtype, shape, name, verify_shape=False,
--> 272                         allow_broadcast=True)
    273 
    274 

~/anaconda3/envs/amazonei_tensorflow2_p36/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py in _constant_impl(value, dtype, shape, name, verify_shape, allow_broadcast)
    281       with trace.Trace(""tf.constant""):
    282         return _constant_eager_impl(ctx, value, dtype, shape, verify_shape)
--> 283     return _constant_eager_impl(ctx, value, dtype, shape, verify_shape)
    284 
    285   g = ops.get_default_graph()

~/anaconda3/envs/amazonei_tensorflow2_p36/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py in _constant_eager_impl(ctx, value, dtype, shape, verify_shape)
    306 def _constant_eager_impl(ctx, value, dtype, shape, verify_shape):
    307   """"""Creates a constant on the current device.""""""
--> 308   t = convert_to_eager_tensor(value, ctx, dtype)
    309   if shape is None:
    310     return t

~/anaconda3/envs/amazonei_tensorflow2_p36/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py in convert_to_eager_tensor(value, ctx, dtype)
    104       dtype = dtypes.as_dtype(dtype).as_datatype_enum
    105   ctx.ensure_initialized()
--> 106   return ops.EagerTensor(value, ctx.device_name, dtype)
    107 
    108 

ValueError: Can't convert Python sequence with mixed types to Tensor.
```

**[Contributing](https://www.tensorflow.org/community/contribute)**

- Do you want to contribute a PR? (yes/no): no
- Briefly describe your candidate solution(if contributing):

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.
```python

def _create_feature_columns(): 
    indicator_columns = [...] # list of columns
    for colmn_name in indicator_colms:
        feature_col = feature_column.categorical_column_with_vocabulary_list(
            colmn_name, unique_values(colmn_name))
        indicator_column = feature_column.indicator_column(feature_col)
        feature_columns.append(indicator_column)

def demo(feature_column):
    demo_feature_layer = layers.DenseFeatures(feature_column)
    print(demo_feature_layer(example_batch).numpy())

with tf.device(device):
    feature_columns = _create_feature_columns()
    feature_layer = tf.keras.layers.DenseFeatures(feature_columns)
    demo(feature_columns)
```
**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
55138,tf.image.adjust_jpeg_quality gives unexpected result,"This issue is about the function `tf.image.adjust_jpeg_quality`. In particular, I am concerned about the docs example and I am surprised by the result with quality 100.

1. The [example provided in the documentation](https://www.tensorflow.org/api_docs/python/tf/image/adjust_jpeg_quality) is misleading. The example uses a float tensor with values in range 1-12. The result of `tf.image.adjust_jpeg_quality` are all one. I assume this is happening because the data type conversion sees a float tensor and clips all values larger than 1. If the input was a uint8 tensor, then the result would differ significantly. In my opinion, the docs should clarify the expected input data type.

2. The output of `tf.image.adjust_jpeg_quality` with quality 100 looks suspicious to me. I know that even with quality 100 JPEG compression is not necessarily lossless due to rounding errors. Nevertheless, I am surprised how much information is lost. In comparison, the results with Pillow at the same quality are far less lossy.
 
Please take a look at the example below. The input is a 8x8 grayscale image with values from 0 through 63. The pixel values after TensorFlow's JPEG compression show quite some difference to the input, whereas JPEG compression with Pillow preserves the input array. Can anyone verify whether TensorFlow is behaving as expected here? Is there any documentation on how TensorFlow implements JPEG compression?

```python
import tensorflow as tf
import numpy as np
import tempfile
from PIL import Image


def compress_PIL(img, quality):
    """"""
    Apply JPEG compression
    :param img: image with pixel intensities in range [0, 255]
    :return: img with intensities in range [0, 255]
    """"""

    if len(img.shape) == 3:
        # Remove singleton channel dimension
        img = np.squeeze(img, axis=2)

    # Apply JPEG compression
    with tempfile.NamedTemporaryFile(suffix="".jpg"") as f:
        im = Image.fromarray(img)
        im.save(f.name, quality=quality)
        # Read back in
        im_recovered = Image.open(f.name)
        return np.array(im_recovered)


x = np.arange(64, dtype=np.uint8).reshape((8, 8, 1))

quality = 100

x_jpeg_tf = tf.image.adjust_jpeg_quality(x, quality)
print(""TensorFlow"")
print(x_jpeg_tf.numpy().squeeze())

x_jpeg_pil = compress_PIL(x, quality)
print(""PIL"")
print(x_jpeg_pil)
```

Output:
```
TensorFlow
[[ 0  0  0  0  1  2  3  5]
 [ 5  7  8  9 10 11 12 13]
 [14 15 16 17 19 20 21 22]
 [23 24 25 26 27 28 29 30]
 [32 33 34 35 36 37 38 39]
 [40 41 42 43 45 46 47 48]
 [49 50 51 52 53 54 55 57]
 [57 59 60 61 62 63 64 65]]
PIL
[[ 0  1  2  3  4  5  6  7]
 [ 8  9 10 11 12 13 14 15]
 [16 17 18 19 20 21 22 23]
 [24 25 26 27 28 29 30 31]
 [32 33 34 35 36 37 38 39]
 [40 41 42 43 44 45 46 47]
 [48 49 50 51 52 53 54 55]
 [56 57 58 59 60 61 62 63]]
```


**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes, see example above
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.7
- Python version: 3.7.11
- CUDA/cuDNN version: 11
- GPU model and memory: RTX 2080 Ti"
55137,please publish TensorFlowLiteObjC 2.8,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using):
Android 2.8
iOS 2.7
- Are you willing to contribute it (Yes/No):
NO


**Describe the feature and the current behavior/state.**

**Will this change the current api? How?**

**Who will benefit with this feature?**

**Any Other info.**
"
55135,Setting `converter.inference_type=uint8` does not produce quantized TFLite model of uint8 weight data type,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04.1 LTS
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): v2.8.0-rc1-32-g3f878cff5b6 2.8.0
- Python version: 3.8.8
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source): N/A
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
I was trying to convert [a TF model](http://download.tensorflow.org/models/official/20181001_resnet/savedmodels/resnet_v1_fp32_savedmodel_NHWC.tar.gz) to TFLite model and quantize by the way. With `converter.optimizations = [tf.lite.Optimize.DEFAULT]` set, I could get a quantized model of int8 weight data type. I would also want a quantized model of uint8 type, so I tried `converter.inference_type=uint8`, but the produced model is still in int8 data type.

**Describe the expected behavior**
Set `converter.inference_type=uint8` to produce a quantized TFLite model of **uint8 weight data type**.

**[Contributing](https://www.tensorflow.org/community/contribute)**

- Do you want to contribute a PR? (yes/no): No
- Briefly describe your candidate solution(if contributing):

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.
```python
 import tensorflow as tf

 tf_path = ""./resnet_v1_fp32_savedmodel_NHWC/1538686669""
 tflite_path = ""{}.tflite"".format(""resnet50.uint8.nhwc"")

 converter = tf.lite.TFLiteConverter.from_saved_model(tf_path)
 converter.optimizations = [tf.lite.Optimize.DEFAULT]
 converter.inference_type = tf.uint8
 tf_lite_model = converter.convert()
 with open(tflite_path, 'wb') as f:
     f.write(tf_lite_model)
```

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
```
$ python tf2tflite.py
2022-03-08 19:46:26.965733: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'global_step:0' shape=() dtype=int64_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'resnet_model/conv2d/kernel:0' shape=(7, 7, 3, 64) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'resnet_model/batch_normalization/gamma:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'resnet_model/batch_normalization/beta:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'resnet_model/batch_normalization/moving_mean:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'global_step:0' shape=() dtype=int64_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'resnet_model/conv2d/kernel:0' shape=(7, 7, 3, 64) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'resnet_model/batch_normalization/gamma:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'resnet_model/batch_normalization/beta:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'resnet_model/batch_normalization/moving_mean:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'global_step:0' shape=() dtype=int64_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'resnet_model/conv2d/kernel:0' shape=(7, 7, 3, 64) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'resnet_model/batch_normalization/gamma:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'resnet_model/batch_normalization/beta:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'resnet_model/batch_normalization/moving_mean:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'global_step:0' shape=() dtype=int64_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'resnet_model/conv2d/kernel:0' shape=(7, 7, 3, 64) dtype=float32_ref> because it
 is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_r
esource_variables().
WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'resnet_model/batch_normalization/gamma:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'resnet_model/batch_normalization/beta:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
WARNING:tensorflow:Unable to create a python object for variable <tf.Variable 'resnet_model/batch_normalization/moving_mean:0' shape=(64,) dtype=float32_ref> because it is a reference variable. It may not be visible to training APIs. If this is a problem, consider rebuilding the SavedModel after running tf.compat.v1.enable_resource_variables().
2022-03-08 19:46:28.726330: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:357] Ignored output_format.
2022-03-08 19:46:28.726362: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:360] Ignored drop_control_dependency.
2022-03-08 19:46:28.727314: I tensorflow/cc/saved_model/reader.cc:43] Reading SavedModel from: ./resnet_v1_fp32_savedmodel_NHWC/1538686669
2022-03-08 19:46:28.732979: I tensorflow/cc/saved_model/reader.cc:78] Reading meta graph with tags { serve }
2022-03-08 19:46:28.733019: I tensorflow/cc/saved_model/reader.cc:119] Reading SavedModel debug info (if present) from: ./resnet_v1_fp32_savedmodel_NHWC/1538686669
2022-03-08 19:46:28.765293: I tensorflow/cc/saved_model/loader.cc:228] Restoring SavedModel bundle.
2022-03-08 19:46:28.997319: I tensorflow/cc/saved_model/loader.cc:212] Running initialization op on SavedModel bundle at path: ./resnet_v1_fp32_savedmodel_NHWC/1538686669
2022-03-08 19:46:29.010577: I tensorflow/cc/saved_model/loader.cc:301] SavedModel load for tags { serve }; Status: success: OK. Took 283266 microseconds.
2022-03-08 19:46:29.097206: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:237] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2022-03-08 19:46:30.323709: I tensorflow/compiler/mlir/lite/flatbuffer_export.cc:1963] Estimated count of arithmetic ops: 1049.200 G  ops, equivalently 524.600 G  MACs

Estimated count of arithmetic ops: 1049.200 G  ops, equivalently 524.600 G  MACs
```

"
55133,Unit test build failure - fatal error: mlir/Parser.h: No such file or directory,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: n/a
- TensorFlow installed from (source or binary): source
- TensorFlow version: git HEAD
- Python version: 3.7.5
- Installed using virtualenv? pip? conda?: no
- Bazel version (if compiling from source): 5.0.0
- GCC/Compiler version (if compiling from source): 10.3.0
- CUDA/cuDNN version: n/a
- GPU model and memory: n/a



**Describe the problem**

Unit test build fails with

# Execution platform: @local_execution_config_platform//:platform
tensorflow/core/function/runtime_client_test.cc:25:10: fatal error: mlir/Parser.h: No such file or directory
   25 | #include ""mlir/Parser.h""  // from @llvm-project
      |          ^~~~~~~~~~~~~~~
compilation terminated.


**Provide the exact sequence of commands / steps that you executed before running into the problem**

bazel test --test_timeout=300,500,-1,-1 --flaky_test_attempts=3 --test_output=all --cache_test_results=no --config=nonccl --verbose_failures --build_tag_filters=-no_oss,-oss_serial,-gpu,-tpu,-benchmark-test,-v1only,-no_aarch64,-requires-gpu --test_tag_filters=-no_oss,-oss_serial,-gpu,-tpu,-benchmark-test,-v1only,-no_aarch64,-requires-gpu --jobs=75 -- //tensorflow/... -//tensorflow/compiler/tf2tensorrt/... -//tensorflow/compiler/xrt/... -//tensorflow/core/tpu/... -//tensorflow/go/... -//tensorflow/java/... -//tensorflow/python/integration_testing/... -//tensorflow/tools/toolchains/... -//tensorflow/lite/... -//tensorflow/python/tools/... -//tensorflow/compiler/mlir/lite/tests:const-fold.mlir.test -//tensorflow/compiler/mlir/lite/tests:prepare-tf.mlir.test -//tensorflow/python/data/experimental/kernel_tests/service:fault_tolerance_test -//tensorflow/python/eager:function_test -//tensorflow/python/kernel_tests/linalg:self_adjoint_eig_op_test

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.

Header file was moved by https://github.com/llvm/llvm-project/commit/9eaff42360f4430e2baba28dd8d119137caae486
"
55132,CVE-2022-23593 and CVE-2022-23592 are reported incorrectly for TensorFlow 2.7.1,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): RedHat Enterprise Linux 8.5
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.7.1
- Python version: 3.9
- Bazel version (if compiling from source): -
- GCC/Compiler version (if compiling from source): -
- CUDA/cuDNN version: -
- GPU model and memory: -


**Describe the current behavior**

Vulnerability scanners such as twistlock flag the following two vulnerabilities for TensorFlow 2.7.1:
- https://nvd.nist.gov/vuln/detail/CVE-2022-23593
- https://nvd.nist.gov/vuln/detail/CVE-2022-23592 

This appears to be incorrect. According to https://github.com/tensorflow/tensorflow/tree/master/tensorflow/security , these two issues ([TFSA-2022-058](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/security/advisory/tfsa-2022-058.md) and [TFSA-2022-055](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/security/advisory/tfsa-2022-055.md)) _only_ affect TensorFlow 2.8.0. It's the only two issues that didn't get cherry-picked into 2.7.1 - most likely exactly because of that reason.

**Describe the expected behavior**
The _Known Affected Software Configurations_ in the two CVEs above should be updated to have a ""From (including)"" of 2.8.0 instead of 2.7.0. Or the two CVEs should be pulled, as they only seem to affect Tensorflow 2.8 rc0 and rc1, not the final version. 

**[Contributing](https://www.tensorflow.org/community/contribute)**

- Do you want to contribute a PR? (yes/no): No
- Briefly describe your candidate solution(if contributing):

**Standalone code to reproduce the issue**
Not needed. The error is visible in the CVE descriptions. 

**Other info / logs** 
- 







"
55128,I cannot start my tensorflow certificate exam due to error,"So i purchased the tensorflow exam and tried to start it, however for some wierd reason i cannot start the exam. the error in the screenshot keeps coming at every try
![Uploading Screen Shot 2022-03-08 at 3.17.40 AM.png…]()

Does anyone know the solution to this"
55123,"A/libc: Fatal signal 11 (SIGSEGV), code 2 (SEGV_ACCERR), fault addr 0xb9124f40 in tid 9093 (superresolution), pid 9093 (superresolution)","**System information**
- Android Device information (use `adb shell getprop ro.build.fingerprint`
  if possible):
- TensorFlow Lite in Play Services SDK version (found in `build.gradle`):
- Google Play Services version
  (`Settings` > `Apps` > `Google Play Services` > `App details`):
`
D/goldfish-address-space: allocate: Ask for block of size 0x100
D/goldfish-address-space: allocate: ioctl allocate returned offset 0x3fb9b8000 size 0x2000
D/HostConnection: HostComposition ext ANDROID_EMU_CHECKSUM_HELPER_v1 ANDROID_EMU_native_sync_v2 ANDROID_EMU_native_sync_v3 ANDROID_EMU_native_sync_v4 ANDROID_EMU_dma_v1 ANDROID_EMU_direct_mem ANDROID_EMU_host_composition_v1 ANDROID_EMU_host_composition_v2 ANDROID_EMU_vulkan ANDROID_EMU_deferred_vulkan_commands ANDROID_EMU_vulkan_null_optional_strings ANDROID_EMU_vulkan_create_resources_with_requirements ANDROID_EMU_YUV_Cache ANDROID_EMU_async_unmap_buffer ANDROID_EMU_vulkan_ignored_handles ANDROID_EMU_vulkan_free_memory_sync ANDROID_EMU_vulkan_shader_float16_int8 ANDROID_EMU_vulkan_async_queue_submit GL_OES_vertex_array_object GL_KHR_texture_compression_astc_ldr ANDROID_EMU_host_side_tracing ANDROID_EMU_gles_max_version_2 
I/tflite: Initialized TensorFlow Lite runtime.
I/super_resolution::: Interpreter is created successfully
I/System.out: s-------------------------------------------------
A/libc: Fatal signal 11 (SIGSEGV), code 2 (SEGV_ACCERR), fault addr 0xb9124f40 in tid 9093 (superresolution), pid 9093 (superresolution)`


when i run a image(250 * 250), a very lagre image(default size 50 * 50), an error is  A/libc: Fatal signal 11 (SIGSEGV), code 2 (SEGV_ACCERR), fault addr 0xb9124f40 in tid 9093 (superresolution), pid 9093 (superresolution). So how to run a big image with tflite in tensorflowlite

private static final int LR_IMAGE_HEIGHT = 250;
private static final int LR_IMAGE_WIDTH = 250;


**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to or attach code demonstrating
the problem.
`/*
 * Copyright 2020 The TensorFlow Authors
 *
 * Licensed under the Apache License, Version 2.0 (the ""License"");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     https://www.apache.org/licenses/LICENSE2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an ""AS IS"" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.tensorflow.lite.examples.superresolution;

import android.content.res.AssetFileDescriptor;
import android.content.res.AssetManager;
import android.graphics.Bitmap;
import android.graphics.BitmapFactory;
import android.graphics.drawable.BitmapDrawable;
import android.os.Bundle;
import android.os.SystemClock;
import androidx.appcompat.app.AppCompatActivity;
import android.util.Log;
import android.view.MotionEvent;
import android.view.View;
import android.widget.Button;
import android.widget.ImageView;
import android.widget.LinearLayout;
import android.widget.Switch;
import android.widget.TextView;
import android.widget.Toast;
import androidx.annotation.WorkerThread;
import java.io.FileInputStream;
import java.io.IOException;
import java.io.InputStream;
import java.nio.MappedByteBuffer;
import java.nio.channels.FileChannel;

/** A super resolution class to generate super resolution images from low resolution images * */
public class MainActivity extends AppCompatActivity {
  static {
    System.loadLibrary(""SuperResolution"");
  }

  private static final String TAG = ""SuperResolution"";
  private static final String MODEL_NAME = ""ESRGAN.tflite"";
  private static final int LR_IMAGE_HEIGHT = 250;
  private static final int LR_IMAGE_WIDTH = 250;
  private static final int UPSCALE_FACTOR = 4;
  private static final int SR_IMAGE_HEIGHT = LR_IMAGE_HEIGHT * UPSCALE_FACTOR;
  private static final int SR_IMAGE_WIDTH = LR_IMAGE_WIDTH * UPSCALE_FACTOR;
  private static final String LR_IMG_1 = ""lr-1.jpg"";
  private static final String LR_IMG_2 = ""lr-2.jpg"";
  private static final String LR_IMG_3 = ""lr-3.jpg"";

  private MappedByteBuffer model;
  private long superResolutionNativeHandle = 0;
  private Bitmap selectedLRBitmap = null;
  private boolean useGPU = false;

  private ImageView lowResImageView1;
  private ImageView lowResImageView2;
  private ImageView lowResImageView3;
  private TextView selectedImageTextView;
  private Switch gpuSwitch;

  @Override
  protected void onCreate(Bundle savedInstanceState) {
    super.onCreate(savedInstanceState);
    setContentView(R.layout.activity_main);

    final Button superResolutionButton = findViewById(R.id.upsample_button);
    lowResImageView1 = findViewById(R.id.low_resolution_image_1);
    lowResImageView2 = findViewById(R.id.low_resolution_image_2);
    lowResImageView3 = findViewById(R.id.low_resolution_image_3);
    selectedImageTextView = findViewById(R.id.chosen_image_tv);
    gpuSwitch = findViewById(R.id.switch_use_gpu);

    ImageView[] lowResImageViews = {lowResImageView1, lowResImageView2, lowResImageView3};

    AssetManager assetManager = getAssets();
    try {
      InputStream inputStream1 = assetManager.open(LR_IMG_1);
      Bitmap bitmap1 = BitmapFactory.decodeStream(inputStream1);
      lowResImageView1.setImageBitmap(bitmap1);

      InputStream inputStream2 = assetManager.open(LR_IMG_2);
      Bitmap bitmap2 = BitmapFactory.decodeStream(inputStream2);
      lowResImageView2.setImageBitmap(bitmap2);

      InputStream inputStream3 = assetManager.open(LR_IMG_3);
      Bitmap bitmap3 = BitmapFactory.decodeStream(inputStream3);
      lowResImageView3.setImageBitmap(bitmap3);
    } catch (IOException e) {
      Log.e(TAG, ""Failed to open an low resolution image"");
    }

    for (ImageView iv : lowResImageViews) {
      setLRImageViewListener(iv);
    }

    superResolutionButton.setOnClickListener(
        new View.OnClickListener() {
          @Override
          public void onClick(View view) {
            if (selectedLRBitmap == null) {
              Toast.makeText(
                      getApplicationContext(),
                      ""Please choose one low resolution image"",
                      Toast.LENGTH_LONG)
                  .show();
              return;
            }

            if (superResolutionNativeHandle == 0) {
                superResolutionNativeHandle = initTFLiteInterpreter(gpuSwitch.isChecked());
            } else if (useGPU != gpuSwitch.isChecked()) {
              // We need to reinitialize interpreter when execution hardware is changed
              deinit();
              superResolutionNativeHandle = initTFLiteInterpreter(gpuSwitch.isChecked());
            }
            useGPU = gpuSwitch.isChecked();
            if (superResolutionNativeHandle == 0) {
              showToast(""TFLite interpreter failed to create!"");
              return;
            }

            int[] lowResRGB = new int[LR_IMAGE_HEIGHT * LR_IMAGE_WIDTH];
            selectedLRBitmap.getPixels(
                lowResRGB, 0, LR_IMAGE_WIDTH, 0, 0, LR_IMAGE_WIDTH, LR_IMAGE_HEIGHT);

            final long startTime = SystemClock.uptimeMillis();
            int[] superResRGB = doSuperResolution(lowResRGB);
            final long processingTimeMs = SystemClock.uptimeMillis() - startTime;
            if (superResRGB == null) {
              showToast(""Super resolution failed!"");
              return;
            }

            final LinearLayout resultLayout = findViewById(R.id.result_layout);
            final ImageView superResolutionImageView = findViewById(R.id.super_resolution_image);
            final ImageView nativelyScaledImageView = findViewById(R.id.natively_scaled_image);
            final TextView superResolutionTextView = findViewById(R.id.super_resolution_tv);
            final TextView nativelyScaledImageTextView =
                findViewById(R.id.natively_scaled_image_tv);
            final TextView logTextView = findViewById(R.id.log_view);

            // Force refreshing the ImageView
            superResolutionImageView.setImageDrawable(null);
            Bitmap srImgBitmap =
                Bitmap.createBitmap(
                    superResRGB, SR_IMAGE_WIDTH, SR_IMAGE_HEIGHT, Bitmap.Config.ARGB_8888);
            superResolutionImageView.setImageBitmap(srImgBitmap);
            nativelyScaledImageView.setImageBitmap(selectedLRBitmap);
            resultLayout.setVisibility(View.VISIBLE);
            logTextView.setText(""Inference time: "" + processingTimeMs + ""ms"");
          }
        });
  }

  @Override
  public void onDestroy() {
    super.onDestroy();
    deinit();
  }

  private void setLRImageViewListener(ImageView iv) {
    iv.setOnTouchListener(
        new View.OnTouchListener() {
          @Override
          public boolean onTouch(View v, MotionEvent event) {
            if (v.equals(lowResImageView1)) {
              selectedLRBitmap = ((BitmapDrawable) lowResImageView1.getDrawable()).getBitmap();
              selectedImageTextView.setText(
                  ""You are using low resolution image: 1 (""
                      + getResources().getString(R.string.low_resolution_1)
                      + "")"");
            } else if (v.equals(lowResImageView2)) {
              selectedLRBitmap = ((BitmapDrawable) lowResImageView2.getDrawable()).getBitmap();
              selectedImageTextView.setText(
                  ""You are using low resolution image: 2 (""
                      + getResources().getString(R.string.low_resolution_2)
                      + "")"");
            } else if (v.equals(lowResImageView3)) {
              selectedLRBitmap = ((BitmapDrawable) lowResImageView3.getDrawable()).getBitmap();
              selectedImageTextView.setText(
                  ""You are using low resolution image: 3 (""
                      + getResources().getString(R.string.low_resolution_3)
                      + "")"");
            }
            return false;
          }
        });
  }

  @WorkerThread
  public synchronized int[] doSuperResolution(int[] lowResRGB) {
    return superResolutionFromJNI(superResolutionNativeHandle, lowResRGB);
  }

  private MappedByteBuffer loadModelFile() throws IOException {
    try (AssetFileDescriptor fileDescriptor =
            AssetsUtil.getAssetFileDescriptorOrCached(getApplicationContext(), MODEL_NAME);
        FileInputStream inputStream = new FileInputStream(fileDescriptor.getFileDescriptor())) {
      FileChannel fileChannel = inputStream.getChannel();
      long startOffset = fileDescriptor.getStartOffset();
      long declaredLength = fileDescriptor.getDeclaredLength();
      return fileChannel.map(FileChannel.MapMode.READ_ONLY, startOffset, declaredLength);
    }
  }

  private void showToast(String str) {
    Toast.makeText(getApplicationContext(), str, Toast.LENGTH_LONG).show();
  }

  private long initTFLiteInterpreter(boolean useGPU) {
    try {
      model = loadModelFile();
    } catch (IOException e) {
      Log.e(TAG, ""Fail to load model"", e);
    }
    return initWithByteBufferFromJNI(model, useGPU);
  }

  private void deinit() {
    deinitFromJNI(superResolutionNativeHandle);
  }

  private native int[] superResolutionFromJNI(long superResolutionNativeHandle, int[] lowResRGB);

  private native long initWithByteBufferFromJNI(MappedByteBuffer modelBuffer, boolean useGPU);

  private native void deinitFromJNI(long superResolutionNativeHandle);
}
`


**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem.
If including tracebacks, please include the full traceback. Large logs and files
should be attached.


SDK version: 28
device information： huawei p40
log
https://github.com/douzaikongcheng/log/blob/main/test.txt
"
55118,Support pad_sequences in Autograph,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are using): 2.8.0
- Are you willing to contribute it (Yes/No): No



**Describe the feature and the current behavior/state.**
The following works in eager:
```
def pad_function(x):
    padded_inputs = tf.keras.preprocessing.sequence.pad_sequences(x,padding='post')
    return padded_inputs

pad_function([tf.constant([[1, 2, 3], [1, 2, 3]]), tf.constant([[1, 2, 3]])])

>> output:
array([[[1, 2, 3],
        [1, 2, 3]],

       [[1, 2, 3],
        [0, 0, 0]]], dtype=int32)
```
However, when having the @tf.function decorator, it does not work:
```
@tf.function
def pad_function(x):
    padded_inputs = tf.keras.preprocessing.sequence.pad_sequences(x,padding='post')
    return padded_inputs

>> output:

ValueError: `sequences` must be a list of iterables. Found non-iterable: Tensor(""x:0"", shape=(2, 3), dtype=int32)
```

If you have any other workarounds, please let me know. Much appreciated! Thanks!
**Will this change the current api? How?**
No
**Who will benefit with this feature?**
Everyone who uses tensor padding
**Any Other info.**
"
55113,Instantiating a `tf.keras.applications` Model Nullifies Augmentation Layers,"Hi! 👋 

I'm having a very weird problem which I couldn't find in the Issues tab, so I hope I'm not duplicating anything.

First, I'm using TensorFlow v2.8.0 on Google Colab (Python v3.7.12).

When creating an augmentation layer, be it a single layer, or a `tf.keras.Sequential` collection of them, they work as expected.
However, right after instantiating a model from `tf.keras.applications` (I've seen it happen with EfficientNetB0 and ResNet152V2), the augmentation layers become a no-op. This behavior does not occur with TensorFlow v2.7.0 on Colab.

A Colab notebook showing this behavior can be found here: https://colab.research.google.com/drive/14K2-OgcPjkHRk2aeOMnW1CnaThow6Fia?usp=sharing

Thank you for your time and patience,
Ben
"
55075,Issue created for Rollback of PR #54432: Add appropriate dtype check for `tf.boolean_mask`'s mask,"Merged PR #54432 is rolled back in 6643f0796d1f9cde90eaa95593bb7f27f315262b.
    Please follow up with the reviewer and close this issue once its resolved."
55073,TFHub Object Detection Models Cannot Quantize,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): source
- TensorFlow version (use command below): v2.8.0-rc1-32-g3f878cff5b6 2.8.0
- Python version: 3.8.2
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: N/A
- GPU model and memory: Nvidia GeForce GTX 1050 8GB

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
When taking the Object Detection Saved Models provided on [https://tfhub.dev/tensorflow/collections/object_detection/1](https://tfhub.dev/tensorflow/collections/object_detection/1) and converting them to TFLite with quantization enabled, the model outputted remains as a fully float model.

**Describe the expected behavior**
When converting these Saved Models using quantization enabled, one can produce a quantized TFLite.

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

```
import tensorflow as tf
import tensorflow_hub as hub
import numpy as np

def dataset_gen():
    for _ in range(10):
        yield [np.random.randint(0,256, [1,300,300,3]).astype(np.uint8)]

inputs = tf.keras.Input(shape=(300,300,3), dtype=tf.uint8)
layers = hub.KerasLayer('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2')(inputs)
keras_model = tf.keras.Model(inputs=inputs, outputs=layers)

converter = tf.lite.TFLiteConverter.from_keras_model(keras_model)
converter.optimizations = [tf.lite.Optimize.DEFAULT]
converter.representative_dataset = dataset_gen
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS] # [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]
tflite_model = converter.convert()

with open('ssd_mobilenet_v2_tfhub_quant.tflite', 'wb') as f:
    f.write(tflite_model)
```

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

>>> tflite_model = converter.convert()
2022-03-07 10:52:09.875517: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.
WARNING:absl:Found untraced functions such as restored_function_body, restored_function_body, restored_function_body, restored_function_body, restored_function_body while saving (showing 5 of 50). These functions will not be directly callable after loading.
INFO:tensorflow:Assets written to: C:\Users\m\AppData\Local\Temp\tmpmpwp187_\assets
INFO:tensorflow:Assets written to: C:\Users\m\AppData\Local\Temp\tmpmpwp187_\assets
C:\Users\m\venv\lib\site-packages\tensorflow\lite\python\convert.py:746: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.
  warnings.warn(""Statistics for quantized inputs were expected, but not ""
2022-03-07 10:54:23.844584: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:357] Ignored output_format.
2022-03-07 10:54:23.845355: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:360] Ignored drop_control_dependency.
2022-03-07 10:54:23.864084: I tensorflow/cc/saved_model/reader.cc:43] Reading SavedModel from: C:\Users\m_qui\AppData\Local\Temp\tmpmpwp187_
2022-03-07 10:54:24.146714: I tensorflow/cc/saved_model/reader.cc:78] Reading meta graph with tags { serve }
2022-03-07 10:54:24.147497: I tensorflow/cc/saved_model/reader.cc:119] Reading SavedModel debug info (if present) from: C:\Users\m_qui\AppData\Local\Temp\tmpmpwp187_
2022-03-07 10:54:27.534765: I tensorflow/cc/saved_model/loader.cc:228] Restoring SavedModel bundle.
2022-03-07 10:54:32.634691: I tensorflow/cc/saved_model/loader.cc:212] Running initialization op on SavedModel bundle at path: C:\Users\m\AppData\Local\Temp\tmpmpwp187_
2022-03-07 10:54:35.731075: I tensorflow/cc/saved_model/loader.cc:301] SavedModel load for tags { serve }; Status: success: OK. Took 11867479 microseconds.
2022-03-07 10:54:40.800205: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:237] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
fully_quantize: 0, inference_type: 6, input_inference_type: 0, output_inference_type: 0
"
55072,Cannot find documentation on how to use FILE autosharding,"## URL(s) with the issue:

https://tensorflow.google.cn/guide/distributed_training?hl=en

## Description of issue (what needs changing):

### Clear description

I would like to use the FILE autoshard policy for my distributed training. However, I cannot find any examples in the documentation of how to do this. I am using the Librispeech dataset, which is split across many audio files. I have created a `tf.data.Dataset` that is the list of the file names (as strings), but when I try to use it, I get errors of the form ``AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy``. There are a number of Github issues discussing this problem, and I think the fact that there are no concrete examples of using FILE sharding is a contributor to this. (The other contributor is many people using Tensor-based datasets rather than file-based ones, and this is what was addressed in the discussion of those Github issues, not how to actually make a file-based dataset suitable for sharding.)

The fact that this warning even comes up in the examples on the ""Distributed Training"" page again highlights the fact that this warning is something users will see regularly. The warning itself tells users how to turn it off (good, though some including myself have had problems actually getting it to turn off), but nowhere have I seen anything pointing to how to actually get FILE sharding working.

### Usage example

No, there is no usage example, which is the core problem here I believe. I would be happy to contribute one, except I cannot get this working myself, hence the request for an example."
55067,Initial running of TensorFlow on WSL Ubuntu 20.04 looks very very slow.,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **WSL2 Ubuntu 20.04**
- TensorFlow version (use command below)**: 2.1.0**
- Python version: **Python 3.7**
- CUDA/cuDNN version:
       **nvcc: NVIDIA (R) Cuda compiler driver
       Copyright (c) 2005-2019 NVIDIA Corporation
       Built on Sun_Jul_28_19:07:16_PDT_2019
       Cuda compilation tools, release 10.1, V10.1.243**
- GPU model and memory: **RTX 3050 Ti Laptop GPU**

# Issue

Dear all,

I would like to ask for help to solve the issue I've been experiencing with Tensorflow on WSL2.
I'm a relatively light user and a novice of Tensorflow and I've been using different machine learning (ML) models on Windows. Recently, I found that I can take some advantages of performing MLs using Linux on WSL2 instead of Windows, so I set the environment in WSL2 and was able to run the code with GPU. (It was a very painful process to set the same environment as it is on Windows.) 

However, when I run my code in WSL Ubuntu, I found that the **(1) initial running takes very very long compare to Windows.** Also, **(2) there are multiple lines showing which I didn't see with Windows. And it only appears in the initial run.** You can find them in the images below.
Since the code is running, I believe that the code is using GPU properly on WSL2 system. But if it takes this long, there is no reason for using Linux on WSL2 instead of Windows. Maybe this is true since I'm a light user, but I want to learn a Linux and develop my capability. So I'm asking for help.

I have copied the code I made for test at the end.

# Questions
To summarise, there are three questions to be addressed:

### Q1. Why does initial running take very very long compare to Windows? How can I fix this?

### Q2. Why there are multiple warning lines with the initial run?

### Q3. Did I properly set CUDA and Tensorflow-gpu on WSL2 system? Could you guide me how to set Tensorflow-gpu on WSL2?
-> To use GPU and Tensorflow in WSL2, I went through a very hard time. And possibly I did make something wrong with set up. Let me briefly explain the process I went through:
Step 1. Install CUDA v10.1
Step 2. Install CuDNN v7.6.5
Step 3. Set the environment with these commands:
$ echo 'export LD_LIBRARY_PATH=/usr/lib/cuda/lib64:$LD_LIBRARY_PATH' >> ~/.bashrc
$ echo 'export LD_LIBRARY_PATH=/usr/lib/cuda/include:$LD_LIBRARY_PATH' >> ~/.bashrc
Step 4. Install tensorflow-gpu v2.1.0 under Miniconda environment with python v3.7

I would appreciate any comment from all of you. Thanks.


### image no.1 - from the initial run, time duration = 5m 53.3s
![image](https://user-images.githubusercontent.com/49014051/157073727-0666bf17-a5ca-479d-ba74-b3d7a42adaee.png)
### image no.2 - warnings from the initial run
![image](https://user-images.githubusercontent.com/49014051/157073811-f33f43ea-daf1-45ef-b23f-85d1b6b7f608.png)

# Test code
import tensorflow as tf

mnist = tf.keras.datasets.mnist
(x_train, y_train), (x_test, y_test) = mnist.load_data()
x_train, x_test = x_train / 255.0, x_test / 255.0

model = tf.keras.models.Sequential([
  tf.keras.layers.Flatten(input_shape=(28, 28)),
  tf.keras.layers.Dense(128, activation='relu'),
  tf.keras.layers.Dropout(0.2),
  tf.keras.layers.Dense(10)
])

predictions = model(x_train[:1]).numpy()
tf.nn.softmax(predictions).numpy()
loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)
loss_fn(y_train[:1], predictions).numpy()

model.compile(optimizer='adam',
              loss=loss_fn,
              metrics=['accuracy'])

model.fit(x_train, y_train, epochs=5)
model.evaluate(x_test,  y_test, verbose=2)"
55065,Error during Inference of LSTM Tflite model,"### 1. System information

- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Raspbian Buster
- TensorFlow library (version, if pip package or github SHA, if built from source): tflite-runtime 2.7 compiled using pip 
- Device: Raspberry pi 4 32 bit armv7l

### 2. Issue

I did create a custom LSTM model using the below architecture

```
def My_LSTM(X_train, y_train, X_test, y_test):
    model = Sequential()
    model.add(Masking(mask_value= -27/255 , input_shape=(None, 600)))
    model.add(LSTM(32, return_sequences=True))
    model.add(LSTM(32, return_sequences=False))
    model.add(Dropout(0.5))
    model.add(Dense(16,activation='tanh'))
    model.add(Dropout(0.5))
    model.add(Dense(4,activation='softmax'))

    model.compile(loss = 'sparse_categorical_crossentropy', optimizer= Adam(learning_rate = 1e-3, decay = 1e-6),metrics = ['accuracy'])

    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, min_lr=1e-9)
    stop = EarlyStopping(monitor='val_accuracy', patience=20, verbose=1, mode='auto', baseline=None, restore_best_weights=True)

    
    model.fit(X_train, y_train, epochs=40, batch_size= 128, validation_data=(X_test, y_test), callbacks=[reduce_lr, stop], verbose =1)
    
    
    return model
```

and then I did convert it to tflite extension using the following converter, which successfully converted the model.

```
def Create_tflite_Model(ModelName, savePath):
    
    keras_model = tf.keras.models.load_model(ModelName, compile = False)
    converter = tf.lite.TFLiteConverter.from_keras_model(keras_model)
    converter.optimizations = [tf.lite.Optimize.DEFAULT]
    converter.experimental_new_converter=True
    converter.target_spec.supported_ops = [tf.lite.OpsSet.SELECT_TF_OPS, tf.lite.OpsSet.TFLITE_BUILTINS]
    tflite_model = converter.convert()
    tflite_model_dir = pathlib.Path(savePath)
    tflite_model_file = tflite_model_dir/""My_model.tflite""
    tflite_model_file.write_bytes(tflite_model)
    
    return tflite_model
```

I did make inference using ``` tf.lite.Interpreter ``` in Tensorflow 2.7 on my PC and was working fine. But when I migrate to my Raspberrypi 4 with armv7l 32bit and try to make inference using ```tflite-runtime 2.7``` using the following code: 

```
Super_Interpreter = tf.lite.Interpreter(model_path='My_model.tflite')
Super_Interpreter.get_signature_list()
Super = Super_Interpreter.get_signature_runner('serving_default')
Result = Super(masking_input = ""File to Classify"")
object = np.argmax(Result.get('dense_1'))
print(Classes[object])
```

It returns this error: 

```
RuntimeError: Select TensorFlow op(s), included in the given model, is(are) not supported by this interpreter. Make sure you apply/link the Flex delegate before inference. For the Android, it can be resolved by adding ""org.tensorflow:tensorflow-lite-select-tf-ops"" dependency. See instructions: https://www.tensorflow.org/lite/guide/ops_selectNode number 14 (FlexTensorListReserve) failed to prepare.
```

I also tried using tflite-runtime 2.5 which returns this error:
``` Unsupported data type 14 in tensor  ``` 

In addition, I tried using the tensorflow 2.4 library on armv7l, which is the last version that can be installed on this system and tried making the same inference but I still get this error:
``` Unsupported data type 14 in tensor  ``` 

Is there any solution for this issue? 

"
55060,`val_loss` is not available in training,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Window 10 - 21H2
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No
- TensorFlow installed from (source or binary): No
- TensorFlow version (use command below): v2.8.0-rc1-32-g3f878cff5b6 2.8.0
- Python version: 3.8.12 (default, Oct 12 2021, 03:01:40) [MSC v.1916 64 bit (AMD64)]
- Bazel version (if compiling from source): No
- GCC/Compiler version (if compiling from source): No
- CUDA/cuDNN version:
_Built on Fri_Dec_17_18:28:54_Pacific_Standard_Time_2021
Cuda compilation tools, release 11.6, V11.6.55
Build cuda_11.6.r11.6/compiler.30794723_0_
- GPU model and memory: GTX 1080 - 8 GB

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**
I train a multi-scale deep convolutional autoencoder. After some epochs `val_loss` cannot be identified by tensorflow callbacks any more:
_WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr
WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr_

My callbacks are:
```python3
    callbacks = [tf.keras.callbacks.ReduceLROnPlateau(monitor=""val_loss"",
                                                      factor=0.5, patience=8, min_lr=0.00001),
                 tf.keras.callbacks.ModelCheckpoint(""models/ms-model1-1"", monitor=""val_loss""),
                 tf.keras.callbacks.EarlyStopping(monitor=""val_loss"", patience=25),
                 tf.keras.callbacks.TensorBoard(log_dir=""train/ms-log1-1/"", histogram_freq=1),
                 tf.keras.callbacks.ModelCheckpoint('models/ms-models-epochs/model{epoch:08d}', period=5)]
```
The last `ModelCheckpoint` callback I added to work around this bug. This sadly means that I have to put more work into it, in order for it to work as I have to reduce the LR manually.

In tensorboard it looks like this:
![grafik](https://user-images.githubusercontent.com/16071970/157038199-bf8110cb-57e6-46ae-8c86-8881afd66d5c.png)

You can see that the `val_loss` is not even calculated any more. This happens after epoch 4, so after the `ModelCheckpoint` was first reached.

**Describe the expected behavior**

The expected behaviour would be that `val_loss` is further calculated and can therefore also be used in the `ModelCheckpoint`s, `EarlyStopping`s and other callbacks I use.

I am not entirely sure if it is me using the library wrong or whether it really fails due to a bug (I am by no means an expert in TF). The code for the network generation is also included in the PR, the data sets are too big though and are not online available. The used data are Copernicus 4 channel 256x256 images. This is why I did not include the dataloading code as it seems irrelevant to me (I can include it though if you need it).

**[Contributing](https://www.tensorflow.org/community/contribute)**

- Do you want to contribute a PR? (yes/no): no (found a hacky workaround which is good enough for my problem)
- Briefly describe your candidate solution(if contributing): N/A

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

``` python3
def create_normalized_convolution(filters: int,
                                  activation=None,
                                  strides=1,
                                  kernel_size=3,
                                  padding='SAME',
                                  seq_name=None,
                                  **kwargs) -> tf.keras.Sequential:
    if activation is None:
        activation = LeakyReLU()
    return tf.keras.Sequential([
        Conv2D(filters=filters, strides=strides, kernel_size=kernel_size, padding=padding, **kwargs),
        BatchNormalization(),
        activation
    ], seq_name)


def create_normalized_convolution_transpose(filters: int,
                                            activation=None,
                                            strides=1,
                                            kernel_size=3,
                                            padding='SAME',
                                            seq_name=None,
                                            **kwargs) -> tf.keras.Sequential:
    if activation is None:
        activation = LeakyReLU()
    return tf.keras.Sequential([
        Conv2DTranspose(filters=filters, strides=strides, kernel_size=kernel_size, padding=padding, **kwargs),
        BatchNormalization(),
        activation
    ], name=seq_name)


class BaseAutoencoder(tf.keras.Model):
    """"""
    Base class for all used AEs.
    The advantage of a base class is that it only requires you to specify the network structure in the constructor and
    removes almost all boilerplate code.
    """"""

    def __init__(self, latent_dim: int, image_size=256, channels=4):
        super(BaseAutoencoder, self).__init__()

        self._latent_dim = latent_dim
        self._image_size = image_size
        self._channels = channels
        self._encoder: tf.keras.Sequential = None
        self._decoder: tf.keras.Sequential = None

    def get_latent_dim(self) -> int:
        return self._latent_dim

    def get_image_size(self) -> int:
        return self._image_size

    def get_channels(self) -> int:
        return self._channels

    def call(self, inputs):
        bottleneck = self._encoder(inputs)
        return self._decoder(bottleneck)

    def encoder(self) -> tf.keras.Sequential:
        return self._encoder

    def decoder(self) -> tf.keras.Sequential:
        return self._decoder


class MultiscaleAutoencoder(BaseAutoencoder):
    """"""
    A custom multiscale implementation of an AutoEncoder.
    """"""

    def __init__(self, latent_dim: int, image_size=256, channels=4, base_filter_count=32):
        super(MultiscaleAutoencoder, self).__init__(latent_dim, image_size, channels)
        self._base_filter_count = base_filter_count

        raw_inp = Input(shape=(image_size, image_size, channels), dtype=tf.float32)
        enc_inp = InputLayer(name='Input-ENCODER_0')(raw_inp)

        high_res_enc = tf.keras.Sequential([
            create_normalized_convolution(filters=base_filter_count,
                                          strides=2,
                                          seq_name=""NormConv-LeakyReLU-HR_ENCODER_1""),
            create_normalized_convolution(filters=base_filter_count * 2,
                                          strides=2,
                                          seq_name=""NormConv-LeakyReLU-HR_ENCODER_2""),
            create_normalized_convolution(filters=base_filter_count * 4,
                                          strides=2,
                                          seq_name=""NormConv-LeakyReLU-HR_ENCODER_3""),
            create_normalized_convolution(filters=base_filter_count * 8,
                                          strides=2,
                                          seq_name=""NormConv-LeakyReLU-HR_ENCODER_4""),
        ], name=""HighResolution_ENCODER"")(enc_inp)

        med_res = MaxPooling2D(padding='same', name=""MaxPoolingMR_ENCODER"")(enc_inp),

        medium_res_enc = tf.keras.Sequential([
            create_normalized_convolution(filters=base_filter_count * 2,
                                          strides=2,
                                          seq_name=""NormConv-LeakyReLU-MR_ENCODER_1"",
                                          input_shape=(int(image_size / 2), int(image_size / 2), channels)),
            create_normalized_convolution(filters=base_filter_count * 4,
                                          strides=2,
                                          seq_name=""NormConv-LeakyReLU-MR_ENCODER_2""),
            create_normalized_convolution(filters=base_filter_count * 8,
                                          strides=2,
                                          seq_name=""NormConv-LeakyReLU-MR_ENCODER_3""),
        ], name=""MediumResolution_ENCODER"")(med_res)

        low_res_enc = tf.keras.Sequential([
            MaxPooling2D(padding='same', name=""MaxPoolingLR_ENCODER"",
                         input_shape=(int(image_size / 2), int(image_size / 2), channels)),
            create_normalized_convolution(filters=base_filter_count * 4,
                                          strides=2,
                                          seq_name=""NormConv-LeakyReLU-LR_ENCODER_1""),
            create_normalized_convolution(filters=base_filter_count * 8,
                                          strides=2,
                                          seq_name=""NormConv-LeakyReLU-LR_ENCODER_2""),
        ], name=""LowResolution_ENCODER"")(med_res)

        lower_res_concat = concatenate([
            medium_res_enc,
            low_res_enc
        ], name=""LowerResolutionsMerger_ENCODER"")

        res_concat = Concatenate(name=""Multiscale-ENCODER_2"")([
            high_res_enc,
            lower_res_concat,
        ])

        conv_3_enc = create_normalized_convolution(filters=self._latent_dim ** 2 * 3,
                                                   seq_name=""NormConv-LeakyReLU_ENCODER_3"")(res_concat)
        glob_max_pool_enc = GlobalMaxPool2D(name=""GlobalMaxPooling_ENCODER_4"")(conv_3_enc)
        out_enc = Dense(self._latent_dim ** 2 * 3, name=""Dense-ENCODER_5"")(glob_max_pool_enc)

        self._encoder = tf.keras.Model(inputs=raw_inp, outputs=out_enc, name=""Encoder"")

        raw_dec_inp = Input(shape=(self._latent_dim ** 2 * 3), dtype=tf.float32)
        dec_inp = InputLayer(name='Input-DECODER_0')(raw_dec_inp)

        reshape_dec = Reshape(target_shape=[self._latent_dim, self._latent_dim, 3], name='Reshape-DECODER_1')(dec_inp)
        conv_1_dec = create_normalized_convolution_transpose(filters=self._latent_dim ** 2 * 3,
                                                             seq_name=""NormConv-LeakyReLU_ENCODER_2"")(reshape_dec)

        hr_dec = tf.keras.Sequential([
            create_normalized_convolution_transpose(filters=base_filter_count * 8,
                                                    strides=2,
                                                    seq_name=""NormConv-LeakyReLU-HR_DECODER_1""),
            create_normalized_convolution_transpose(filters=base_filter_count * 4,
                                                    strides=2,
                                                    seq_name=""NormConv-LeakyReLU-HR_DECODER_2""),
            create_normalized_convolution_transpose(filters=base_filter_count * 2,
                                                    strides=2,
                                                    seq_name=""NormConv-LeakyReLU-HR_DECODER_3""),
            create_normalized_convolution_transpose(filters=base_filter_count,
                                                    strides=2,
                                                    seq_name=""NormConv-LeakyReLU-HR_DECODER_4"")
        ], name=""HighResolution_DECODER"")(conv_1_dec)

        mr_dec = tf.keras.Sequential([
            create_normalized_convolution_transpose(filters=base_filter_count * 8,
                                                    strides=2,
                                                    seq_name=""NormConv-LeakyReLU-MR_DECODER_1""),
            create_normalized_convolution_transpose(filters=base_filter_count * 4,
                                                    strides=2,
                                                    seq_name=""NormConv-LeakyReLU-MR_DECODER_2""),
            create_normalized_convolution_transpose(filters=base_filter_count * 2,
                                                    strides=2,
                                                    seq_name=""NormConv-LeakyReLU-MR_DECODER_3"")
        ], name=""MediumResolution_DECODER"")(conv_1_dec)

        lr_dec = tf.keras.Sequential([
            create_normalized_convolution_transpose(filters=base_filter_count * 8,
                                                    strides=2,
                                                    seq_name=""NormConv-LeakyReLU-LR_DECODER_1""),
            create_normalized_convolution_transpose(filters=base_filter_count * 4,
                                                    strides=2,
                                                    seq_name=""NormConv-LeakyReLU-LR_DECODER_2""),
            UpSampling2D(name=""UpSampling2x-LR_DECODER"")
        ], name=""LowResolution_DECODER"")(conv_1_dec)

        concat_lower_res = Concatenate(name=""LowerResolutionsMerger_DECODER"")([
            mr_dec,
            lr_dec
        ])

        up_sample_mr = UpSampling2D(name=""UpSampling2x-MR_DECODER"")(concat_lower_res)

        concat_high_res = Concatenate(name=""HighResolutionMerger_DECODER"")([
            hr_dec,
            up_sample_mr
        ])

        norm_conv_4_dec = create_normalized_convolution_transpose(
            filters=4,
            activation=Activation('sigmoid'),
            seq_name='NormConv-Sigmoid-DECODER_4'
        )(concat_high_res)

        self._decoder = tf.keras.Model(inputs=raw_dec_inp, outputs=norm_conv_4_dec, name='Decoder')


BATCH_SIZE = 24
IMG_SIZE = 256
model = autoencoder.MultiscaleAutoencoder(16)
callbacks = [tf.keras.callbacks.ReduceLROnPlateau(monitor=""val_loss"",
                                                      factor=0.5, patience=8, min_lr=0.00001),
                 tf.keras.callbacks.ModelCheckpoint(""models/ms-model1-1"", monitor=""val_loss""),
                 tf.keras.callbacks.EarlyStopping(monitor=""val_loss"", patience=25),
                 tf.keras.callbacks.TensorBoard(log_dir=""train/ms-log1-1/"", histogram_freq=1),
                 tf.keras.callbacks.ModelCheckpoint('models/ms-models-epochs/model{epoch:08d}', period=5)]
model.build(tf.TensorShape((None, IMG_SIZE, IMG_SIZE, 4)))
loss = MeanAbsoluteError()
model.compile(optimizer=tf.keras.optimizers.Adamax(learning_rate=0.032), loss=loss, metrics=['accuracy'])
model.fit(train_ds_final,
          validation_data=val_ds_final,
          epochs=150,
          callbacks=callbacks,
          shuffle=True)
```
"
55059,tensorflow/core/kernels/conv_ops_gpu.cc:336] None of the algorithms provided by cuDNN frontend heuristics worked,"**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): ubuntu 16.04
- TensorFlow installed from (source or binary): source
- TensorFlow version: master
- Python version: 3.9.9
- Bazel version (if compiling from source): bazel 5.0.0
- GCC/Compiler version (if compiling from source): g++ (Ubuntu 7.5.0-3ubuntu1~16.04) 7.5.0
- CUDA/cuDNN version: 11.4
- GPU model and memory: NVIDIA GeForce RTX 3090 sm_8.6 with 25447170048B RAM and 82 cores



**Describe the problem**

after I build and installed, when I run model with conv3d ops, it will return the following msg:

> 2022-02-25 09:26:56.521222: W tensorflow/core/kernels/conv_ops_gpu.cc:336] None of the algorithms provided by cuDNN frontend heuristics worked; trying fallback algorithms.  Conv: batch: 1
> in_depths: 1
> out_depths: 40
> in: 256
> in: 256
> in: 256
> data_format: 1
> filter: 3
> filter: 3
> filter: 3
> dilation: 1
> dilation: 1
> dilation: 1
> stride: 1
> stride: 1
> stride: 1
> padding: 2
> padding: 2
> padding: 2
> dtype: DT_FLOAT
> group_count: 1
> device_identifier: ""NVIDIA GeForce RTX 3090 sm_8.6 with 25447170048B RAM and 82 cores""
> version: 1
> 

**Provide the exact sequence of commands / steps that you executed before running into the problem**

anything that use conv3d ops

**Any other info / logs**

the model, like unet, can be finished even with the above msg. But I think this msg shows that cuDNN is not envolved? and hence the gpu is not used?
"
55057,libstdc++ 6.0.24 is statically linked into libtensorflow_framework.so on PyPI,"**System information**

- OS Platform and Distribution: PyPI packages for Linux
- TensorFlow installed from (source or binary): binary via PyPI
- TensorFlow version: 2.4 and 2.6
- Python version: 3.7
- Installed using virtualenv? pip? conda?: pip

**Describe the problem**

The PyPI packages for TensorFlow, at least versions 2.4.0 and 2.6.0, ship a compiled shared object `libtensorflow_framework.so`. This library is loaded when one does `import tensorflow` in Python. The TF shared library contains symbols from libstdc++ 6.0.24. When one uses a custom C++ library with Python via `ctypes`, the dynamic linker will resolves symbols that the custom library need first from `libtensorflow_framework.so`, and only then from the system wide installed `libstdc++.so`. This means that no matter which version of libstdc++ is installed system wide, one gets certain symbols from libstdc++ 6.0.24.

This a huge problem because that version of libstdc++ has a [bug in `std::execute_native_thread_routine`](https://gcc.gnu.org/bugzilla/show_bug.cgi?id=55917) which force unwinds the stack when an exception escapes a thread. Once the exception hits the top stack frame of the thread, `std::terminate()`/`abort()` will be called and a core dump triggered. Due to the force unwinding of the stack, the stack trace in the core dump is completely useless and only contains the following:

```
#0  0x00007f40fce54438 in raise () from /lib/x86_64-linux-gnu/libc.so.6
#1  0x00007f40fce5603a in abort () from /lib/x86_64-linux-gnu/libc.so.6
#2  0x00007f4076e65dde in ?? () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6
#3  0x00007f4076e717a6 in ?? () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6
#4  0x00007f4076e71811 in std::terminate() () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6
#5  0x00007f4078beaf2e in std::execute_native_thread_routine (__p=0x2da6d20)
    at /dt7-src/libstdc++-v3/src/nonshared11/../c++11/thread.cc:91
#6  0x00007f40fd1f06ba in start_thread () from /lib/x86_64-linux-gnu/libpthread.so.0
#7  0x00007f40fcf2651d in clone () from /lib/x86_64-linux-gnu/libc.so.6
```

You can see the `/dt7-src` there, which is the “dev tools GCC 7” which are used in the CD system of TensorFlow. The libstdc++ version with the fix is associated with GCC 8, so the GCC 7 one is still affected.

One can work around this by using `LD_PRELOAD=/usr/lib/x86_64-linux-gnu/libstdc++.so python …`. However, I would think that statically linking the standard library into a shared library is a bad thing to do. I am not sure why that was done, perhaps there are good reasons for that.

I would think that changing the linking should be changed such that libstdc++ is not linked statically into the dynamic library when building Python packages for PyPI. If that is not possible, I would suggest to use GCC 8 such that this bug is fixed.

There is a [very enlightening blog post](https://le.qun.ch/en/blog/libstdc++-bug/), which describes the issue with that version of libstdc++ in a context without TensorFlow.

**Provide the exact sequence of commands / steps that you executed before running into the problem**

1. Write a C++ library that uses `std::thread` somewhere.
2. Have a bug in your code which raises an exception that is not caught anywhere your code.
3. Use both your C++ library and TensorFlow from within the same Python process.
4. Have it crash your application and write a core dump.
5. Look at the core dump using GDB (`gdb python PATH_TO_CORE_FILE`). Print the back trace. Notice that the whole stack within the tread is missing, although it should be present with Itanium ABI on Linux."
55053,"tensorflow
","<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary):
- TensorFlow version (use command below):
- Python version:
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version:
- GPU model and memory:

You can collect some of this information using our environment capture
[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)
You can also obtain the TensorFlow version with:
1. TF 1.0: `python -c ""import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)""`
2. TF 2.0: `python -c ""import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)""`

**Describe the current behavior**

**Describe the expected behavior**

**[Contributing](https://www.tensorflow.org/community/contribute)**

- Do you want to contribute a PR? (yes/no):
- Briefly describe your candidate solution(if contributing):

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
55043,Custom operation on extracted volume patches,"<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>


**System information**
- TensorFlow version (you are ): I'm using TensorFlow version 2.8
- Are you willing to contribute it (Yes/No):



**Describe the feature and the current behavior/state.**
Custom operation on sliding kernels on volumes of data would be really helpful. I know off the function _tf.extract_volume_patches_ but there are some drawbacks to this. It collects the patches but consumes lots of memory resource. I mean what I had in mind was performing some kind of custom operation on data collected through a sliding window and using this function would eventually lead to exhausting my available resource. And also it would be great to add a kernel mask to specify how the sampling would be performed. In short two I recommend more arguments to this function :
1) An argument to specify a function or a lambda to call upon every sampled window right after sampling and return and save the result instead of the sampled window itself
2) A sampling mask. Specifying which elements should be sampled ( I know it can be done using the this very function but again the constrain is the memory usage) 


**Will this change the current api? How?**
I think it wouldn't change anything 

**Who will benefit with this feature?**
This would be very helpful for image processing and feature extraction out of large volumes of data 

**Any Other info.**
"
55040,TFLite Python:  interpreter._get_tensor_details(index) can't read tensor with sparsity,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): NO
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 11
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): Source
- TensorFlow version (use command below): 2.8.0
- Python version: 3.7.0
- Bazel version (if compiling from source):  5.0.0
- GCC/Compiler version (if compiling from source): MSVC 2019
- CUDA/cuDNN version:
- GPU model and memory:


**Describe the current behavior**

In the Python code below, load the [Mediapipe pose_detection tflie model](https://github.com/google/mediapipe/blob/master/mediapipe/modules/pose_detection/pose_detection.tflite), and try to get details of tensor index 15. The program crashes during `interpreter._get_tensor_details(15)`, and the `print(details)` never executes.

```
import tensorflow as tf

interpreter = tf.lite.Interpreter(""pose_detection.tflite"")
details = interpreter._get_tensor_details(15)
print(details)
```

I analysed it and found the call stack is
`interpreter._get_tensor_details(index)` ->
`_interpreter.TensorSparsityParameters()` ->
`InterpreterWrapper::TensorSparsityParameters()` ->
`PyDictFromSparsityParam()` ->
`PyArrayFromIntVector()`

tensorflow\lite\python\interpreter.py
```
  def _get_tensor_details(self, tensor_index):
  ...
    tensor_sparsity_params = self._interpreter.TensorSparsityParameters(
        tensor_index)
```

tensorflow\lite\python\interpreter_wrapper\interpreter_wrapper.cc
```
PyObject* InterpreterWrapper::TensorSparsityParameters(int i) const {
  TFLITE_PY_ENSURE_VALID_INTERPRETER();
  TFLITE_PY_TENSOR_BOUNDS_CHECK(i);
  const TfLiteTensor* tensor = interpreter_->tensor(i);
  if (tensor->sparsity == nullptr) {
    return PyDict_New();
  }

  return PyDictFromSparsityParam(*tensor->sparsity);
}


PyObject* PyDictFromSparsityParam(const TfLiteSparsity& param) {
  PyObject* result = PyDict_New();
  PyDict_SetItemString(result, ""traversal_order"",
                       PyArrayFromIntVector(param.traversal_order->data,
                                            param.traversal_order->size));
  PyDict_SetItemString(
      result, ""block_map"",
      PyArrayFromIntVector(param.block_map->data, param.block_map->size));
...
}

PyObject* PyArrayFromIntVector(const int* data, npy_intp size) {
  void* pydata = malloc(size * sizeof(int));
  memcpy(pydata, data, size * sizeof(int));
  PyObject* obj = PyArray_SimpleNewFromData(1, &size, NPY_INT32, pydata);
  PyArray_ENABLEFLAGS(reinterpret_cast<PyArrayObject*>(obj), NPY_ARRAY_OWNDATA);
  return obj;
}
```

In the tensor index 15 of pose_detection.tflite, `tensor->sparsity` is not null, but `tensor->sparsity->traversal_order->data` is null.
So the `memcpy()` in `PyArrayFromIntVector()` crashed with null pointer exception.

Could you check why pose_detection.tflite can be inferred normally in Mediapipe, but can't be read by `interpreter._get_tensor_details(index)`?
Thanks.
"
55038,AutoGraph could not transform when fine-tuning HuggingFace Pretrained Model,"**System information**
Macbook OS 11.6

```
numpy==1.19.5
pathlib2==2.3.5
python==3.8.8
tensorflow==2.7.0
transformers==4.2.0
```

**Describe the current behavior**
During` .fit()`, receiving warnings: 

```
WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.Socket(zmq.PUSH) at XXX >> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
```
and

```
The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).
The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.
```
_Would not have submitted except for the ""please report"" phrase in first warning. Happy to close quickly if this is resolved/trivial._

**Describe the expected behavior**

Neither of these warnings to appear prior to training.

**Standalone code to reproduce the issue**

```
# train_texts is a list of strings
# train_labels is a list of integers (0,1)

import tensorflow as tf
from transformers import AutoTokenizer, TFAutoModelForSequenceClassification
from sklearn.model_selection import train_test_split

train_texts, val_texts, train_labels, val_labels = train_test_split(train_texts, train_labels, test_size=.2)
checkpoint = ""cardiffnlp/twitter-xlm-roberta-base-sentiment""
tokenizer = AutoTokenizer.from_pretrained(checkpoint)

train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=512, return_tensors='tf')['input_ids']
val_encodings = tokenizer(val_texts, truncation=True, padding=True, max_length=512, return_tensors='tf')['input_ids']
test_encodings = tokenizer(test_texts, truncation=True, padding=True, max_length=512, return_tensors='tf')['input_ids']

train_dataset = tf.data.Dataset.from_tensor_slices((
    train_encodings,
    train_labels
))
val_dataset = tf.data.Dataset.from_tensor_slices((
    val_encodings,
    val_labels
))
test_dataset = tf.data.Dataset.from_tensor_slices((
    test_encodings,
    test_labels
))

model = TFAutoModelForSequenceClassification.from_pretrained(checkpoint)

optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)
model.compile(optimizer=optimizer, loss=model.compute_loss) 
## Warnings occur here:
model.fit(train_dataset.shuffle(1000).batch(16), epochs=3, batch_size=16)
```

**Other info / logs** 
Verbose==10 logs leading up to warning:
[tf_verbose_log.txt](https://github.com/tensorflow/tensorflow/files/8191826/tf_verbose_log.txt)
"
55037,Mulitple inputs not parsing properly with dictionary,"I'm getting an error with multiple inputs 
something like this


`    
    customer = Input(shape=(1,), name=""customer_id"")  # 1-length sequence of ints
    age = Input(shape=(1,), name=""age"")  # 1-length sequence of ints
    other_customer_input = Input(shape=(None,7), name=""customer_info"")# 7-length sequence of ints
    other_customer_input = layers.Dense(7,kernel_regularizer='l1')(other_customer_input)
    cust_embedding = layers.Embedding(num_of_cx, 256)(customer)
    dem_embedding = layers.Embedding(num_of_age, 16)(age)

    x = layers.concatenate(axis=2,inputs=[customer_embedding,postal_code_embedding,other_customer_input])
    x = layers.Dense(450,kernel_regularizer='l1')(x)

    pref = layers.Dense(619, name=""pref"",kernel_regularizer='l1')(x)

    model = tf.keras.Model(
        inputs=[age, customer, other_customer_input],
        outputs=[pref]
    )

    x = layers.concatenate(axis=2,inputs=[customer_embedding,postal_code_embedding,other_customer_input])
    x = layers.Dense(450,kernel_regularizer='l1')(x)
    model.compile()

    X= {""customer_id"": data['customer_id'], ""age"": data['age'], ""customer_info"": data[cols]}
    Y={""pref"": data[cols])}

    pref_model.fit(X,Y,
        epochs=2,
        batch_size=64)
`
This is the full error message 

It's not accepting a dictionary as an input

INFO:tensorflow:Allowlisted: <function TensorLikeDataAdapter.__init__.<locals>.slice_batch_indices at 0x7fb010938940>: DoNotConvert rule for keras
INFO:tensorflow:Converted call: <function TensorLikeDataAdapter.slice_inputs.<locals>.grab_batch at 0x7faf82c8cd30>
    args: (<tf.Tensor 'args_0:0' shape=(None,) dtype=int64>, ({'customer_id': <tf.Tensor 'args_2:0' shape=(1362281, 1) dtype=int64>, 'age': <tf.Tensor 'args_1:0' shape=(1362281, 1) dtype=float32>, 'customer_info': <tf.Tensor 'args_3:0' shape=(1362281, 7) dtype=float64>}, {'pref': <tf.Tensor 'args_4:0' shape=(1362281, 619) dtype=int64>}))
    kwargs: {}

INFO:tensorflow:Allowlisted: <function TensorLikeDataAdapter.slice_inputs.<locals>.grab_batch at 0x7faf82c8cd30>: DoNotConvert rule for keras
Epoch 1/2
INFO:tensorflow:Converted call: <function Model.make_train_function.<locals>.train_function at 0x7faf82c8cdc0>
    args: (<tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x7faf82c9ef40>,)
    kwargs: {}

INFO:tensorflow:Cache hit for <function Model.make_train_function.<locals>.train_function at 0x7faf82c8cdc0> subkey ConversionOptions[{}]: <tensorflow.python.autograph.pyct.transpiler._PythonFnFactory object at 0x7fb0133f89a0>
INFO:tensorflow:Error transforming entity <function Model.make_train_function.<locals>.train_function at 0x7faf82c8cdc0>
Traceback (most recent call last):
  File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py"", line 427, in converted_call
  File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py"", line 269, in _convert_actual
  File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/transpiler.py"", line 282, in transform
  File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/transpiler.py"", line 490, in transform_function
  File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/transpiler.py"", line 201, in instantiate
ValueError: closure mismatch, requested ('self', 'step_function'), but source function had ()
WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7faf82c8cdc0> and will run it as-is.
Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.
Cause: closure mismatch, requested ('self', 'step_function'), but source function had ()
To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert
INFO:tensorflow:Converted call: <function Model.make_train_function.<locals>.step_function.<locals>.run_step at 0x7faf82c8c790>
    args: (({'customer_id': <tf.Tensor 'IteratorGetNext:1' shape=(None, 1) dtype=int64>, 'age': <tf.Tensor 'IteratorGetNext:0' shape=(None, 1) dtype=float32>, 'customer_info': <tf.Tensor 'IteratorGetNext:2' shape=(None, 7) dtype=float64>}, {'pref': <tf.Tensor 'IteratorGetNext:3' shape=(None, 619) dtype=int64>}),)
    kwargs: {}

INFO:tensorflow:Allowlisted: <function Model.make_train_function.<locals>.step_function.<locals>.run_step at 0x7faf82c8c790>: DoNotConvert rule for keras
"
55035,The documentation of tf.sparse.softmax has inexecutable example code,"## URL(s) with the issue:
https://www.tensorflow.org/versions/r2.8/api_docs/python/tf/sparse/softmax

## Description of issue (what needs changing):
The documentation of tf.sparse.softmax has inexecutable example code:
```
import tensorflow as tf
# First batch:
# [?   e.]
# [1.  ? ]
# Second batch:
# [e   ? ]
# [e   e ]
shape = [2, 2, 2]  # 3-D SparseTensor
values = np.asarray([[[0., np.e], [1., 0.]], [[np.e, 0.], [np.e, np.e]]])
indices = np.vstack(np.where(values)).astype(np.int64).T

result = tf.sparse.softmax(tf.sparse.SparseTensor(indices, values, shape)) # ValueError
# ...returning a 3-D SparseTensor, equivalent to:
# [?   1.]     [1    ?]
# [1.  ? ] and [.5  .5]
# where ? means implicitly zero.
```
Outputs:
```
ValueError: Shape (2, 2, 2) must have rank 1
```

**Reason**
The `values` passed to `tf.sparse.SparseTensor` must be a rank-1 tensor instead of a rank-3 tensor.

**Fix**
The above code should be changed to:
```
import tensorflow as tf
shape = [2, 2, 2]  # 3-D SparseTensor
values = np.asarray([[[0., np.e], [1., 0.]], [[np.e, 0.], [np.e, np.e]]])
indices = np.vstack(np.where(values)).astype(np.int64).T
values = values[np.where(values)] # Flatten values
result = tf.sparse.softmax(tf.sparse.SparseTensor(indices, values, shape)) 
print(tf.sparse.to_dense(result))
```
Output as expected:
```
tf.Tensor(
[[[0.  1. ]
  [1.  0. ]]

 [[1.  0. ]
  [0.5 0.5]]], shape=(2, 2, 2), dtype=float64)
```"
55030,How to make pipeline parallelism in Tensorflow runtime with custom CUDA steam,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.5.0
- Python version: 3.8.7
- Bazel version (if compiling from source): 3.7.2
- GCC/Compiler version (if compiling from source): 7.3.1
- CUDA/cuDNN version: cuda-11.0, cudnn-8.2
- GPU model and memory: A100, 40GB HBM.


# Description
I'm trying to run a recommender-system for advertisement application with TensorFlow, on A100 X 16, and run a sparse embedding_lookup on a model-parallized embedding layer (embedding layer is splitted to 16 partitions on each GPU, and every worker send the lookup indices to others, and gather the lookup  results to local).

One problem is: I'm trying to split a whole batch input into several mini-batches, and let the k-th mini-batch be parallized to the (k+1)-th mini-batch, with a stage step bebind, to overlap the element-wise computations between mini-batches. But I haven't found a method to implement the idea, since the TensorFlow runtime run an op in graph when its upstream ops are finished.

Another problem is in an AsyncOpKernel, I found that a cudaStream created by cudaStreamCreate(), not d.stream(), is not synchronizable to the host code:
```c++
cudaStreamCreate(&custom_stream);
... ...
CUDACHECK(cudaStreamSynchronize(custom_stream));  // Block the custom stream.
CUDACHECK(cudaStreamSynchronize(d.stream()));  // stream from the context->eigen_device<GPUDevice>(), I found it somehow not working (will not wait the custom_stream finished). I'm really confused about it.

```

I struggled with it for several weeks, I will be really appreciated if someone could answer the issue (X0X) !"
55027,TensorFlow Developer Certificate error sign in on pycharm ,"I am able to successfully sign in to the Certification Assistant. However, I keep getting this error on pycharm ""An error occurred while trying to sign in: Connection reset"". I don't know why it happened
![Screenshot 2022-03-05 at 2 43 15 PM](https://user-images.githubusercontent.com/39478293/156871893-b6fcf86b-266a-48a2-9cd6-d568ddb150a1.png)
."
55023,the update ordering in ,"**System information**
-  tf_v5    tf.image.NonMaxSupressionWithScore

**Describe the current behavior**
I think there is a little bug in the implementation of *non_max_suppression_op.cc* in the  function *DoNonMaxSuppressionOp*
![image](https://user-images.githubusercontent.com/31850863/156863445-27c3d631-d426-4e9d-89f6-d281ce597503.png)
I has tried to change it as 
![image](https://user-images.githubusercontent.com/31850863/156863575-a06b6771-90ee-47de-9f91-d90b2c1b2458.png)
In some extreme cases, I find they have different results because the value of a\*b\*c\*d != d\*c\*b\*a in numerical meaning and I think my change of the order is the normal order of the NMS algorithm proposed.

**Describe the expected behavior**
Just change the sequence as I showed above.




"
55014,Issue with XLA devices or MLIR optimization?,"Hi All, 

Having a little trouble using tensorflow.  I thought it might be an issue related to the following warnings:

` Not creating XLA devices, tf_xla_enable_xla_devices not set`
or
`None of the MLIR optimization passes are enabled (registered 2)`

but upon reading other posts, I've found that people say these warnings can be ignored?

I get latter when creating a model:

`model = N2V(config, model_name, basedir=basedir)`

which takes about 5 minutes to execute and I get the following output:

 /home/sam/miniconda3/envs/n2v/lib/python3.7/site-packages/n2v/models/n2v_standard.py:416: UserWarning: output path for model already exists, files may be overwritten: /home/sam/models/BSD68_reproducability_5x5
  'output path for model already exists, files may be overwritten: %s' % str(self.logdir.resolve()))
2022-03-04 10:33:12.171788: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set
2022-03-04 10:33:12.172307: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1
2022-03-04 10:33:12.205486: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-03-04 10:33:12.205618: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:61:00.0 name: NVIDIA RTX A5000 computeCapability: 8.6
coreClock: 1.695GHz coreCount: 64 deviceMemorySize: 23.68GiB deviceMemoryBandwidth: 715.34GiB/s
2022-03-04 10:33:12.205630: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2022-03-04 10:33:12.206557: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2022-03-04 10:33:12.206579: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2022-03-04 10:33:12.207523: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-03-04 10:33:12.207667: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-03-04 10:33:12.208436: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2022-03-04 10:33:12.208839: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2022-03-04 10:33:12.210569: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2022-03-04 10:33:12.210663: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-03-04 10:33:12.210860: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-03-04 10:33:12.210941: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2022-03-04 10:33:12.211272: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-03-04 10:33:12.212089: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-03-04 10:33:12.212184: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: 
pciBusID: 0000:61:00.0 name: NVIDIA RTX A5000 computeCapability: 8.6
coreClock: 1.695GHz coreCount: 64 deviceMemorySize: 23.68GiB deviceMemoryBandwidth: 715.34GiB/s
2022-03-04 10:33:12.212194: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2022-03-04 10:33:12.212205: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10
2022-03-04 10:33:12.212212: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10
2022-03-04 10:33:12.212218: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10
2022-03-04 10:33:12.212224: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10
2022-03-04 10:33:12.212230: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10
2022-03-04 10:33:12.212236: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10
2022-03-04 10:33:12.212243: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7
2022-03-04 10:33:12.212276: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-03-04 10:33:12.212384: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-03-04 10:33:12.212461: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0
2022-03-04 10:33:12.212481: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1
2022-03-04 10:38:35.925719: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:
2022-03-04 10:38:35.925741: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 
2022-03-04 10:38:35.925746: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N 
2022-03-04 10:38:35.925939: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-03-04 10:38:35.926079: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-03-04 10:38:35.926191: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:941] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-03-04 10:38:35.926283: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2022-03-04 10:38:35.926306: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 21899 MB memory) -> physical GPU (device: 0, name: NVIDIA RTX A5000, pci bus id: 0000:61:00.0, compute capability: 8.6)
2022-03-04 10:38:35.926510: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set



If I then continue with:

`history = model.train(X, X_val)`

I get the following output, after which, it just stops:

/home/sam/miniconda3/envs/n2v/lib/python3.7/site-packages/n2v/models/n2v_standard.py:194: UserWarning: small number of validation images (only 0.1% of all images)
  warnings.warn(""small number of validation images (only %.1f%% of all images)"" % (100 * frac_val))

8 blind-spots will be generated per training patch of size (64, 64).

Preparing validation data: 100%|██████████████████████████████████████| 4/4 [00:00<00:00, 533.12it/s]

Epoch 1/200


2022-03-04 10:40:59.811781: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)
2022-03-04 10:40:59.830334: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 3892985000 Hz
2022-03-04 10:41:00.455851: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7



Any thoughts??

Thanks!
Sam
"
54991,TensorFlow API Versions Hyperlink for 2.7 points to 2.8,"## URL(s) with the issue:

https://www.tensorflow.org/versions

## Description of issue (what needs changing):
The link to version r2.7 points to `https://www.tensorflow.org/api_docs/python/tf` but should point point to `https://www.tensorflow.org/versions/r2.7/api_docs/python/tf`.
"
54988,Build of unit tests fails,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: n/a
- TensorFlow installed from (source or binary): source
- TensorFlow version: git HEAD
- Python version: 3.7.5
- Installed using virtualenv? pip? conda?: no
- Bazel version (if compiling from source): 5.0.0
- GCC/Compiler version (if compiling from source): 10.3.0
- CUDA/cuDNN version: n/a
- GPU model and memory: n/a



**Describe the problem**

Building unit tests fails with

================================================================================
ERROR: /tmp/workspace/tensorflow-git/tensorflow/compiler/mlir/lite/quantization/BUILD:152:20: Compiling tensorflow/compiler/mlir/lite/quantization/tools/tflite_op_coverage_spec_getters_gen.cc failed: (Exit 1): gcc failed: error executing command 
  (cd /root/.cache/bazel/_bazel_root/db210f68f81d95ddcca9ae96b16ed72c/execroot/org_tensorflow && \
  exec env - \
    LD_LIBRARY_PATH=/opt/rh/devtoolset-10/root/usr/lib64:/opt/rh/devtoolset-10/root/usr/lib:/opt/rh/devtoolset-10/root/usr/lib64/dyninst:/opt/rh/devtoolset-10/root/usr/lib/dyninst:/usr/local/lib64:/usr/lib \
    PATH=/tmp/workspace/venv-cp310-cp310/bin:/opt/rh/devtoolset-10/root/usr/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \
    PWD=/proc/self/cwd \
  /opt/rh/devtoolset-10/root/usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections -fdata-sections '-std=c++11' -MD -MF bazel-out/aarch64-opt-exec-50AE0418/bin/tensorflow/compiler/mlir/lite/quantization/_objs/tflite_op_coverage_spec_getters_gen/tflite_op_coverage_spec_getters_gen.d '-frandom-seed=bazel-out/aarch64-opt-exec-50AE0418/bin/tensorflow/compiler/mlir/lite/quantization/_objs/tflite_op_coverage_spec_getters_gen/tflite_op_coverage_spec_getters_gen.o' '-DLLVM_ON_UNIX=1' '-DHAVE_BACKTRACE=1' '-DBACKTRACE_HEADER=<execinfo.h>' '-DLTDL_SHLIB_EXT="".so""' '-DLLVM_PLUGIN_EXT="".so""' '-DLLVM_ENABLE_THREADS=1' '-DHAVE_DEREGISTER_FRAME=1' '-DHAVE_LIBPTHREAD=1' '-DHAVE_PTHREAD_GETNAME_NP=1' '-DHAVE_PTHREAD_GETSPECIFIC=1' '-DHAVE_PTHREAD_H=1' '-DHAVE_PTHREAD_SETNAME_NP=1' '-DHAVE_REGISTER_FRAME=1' '-DHAVE_SETENV_R=1' '-DHAVE_STRERROR_R=1' '-DHAVE_SYSEXITS_H=1' '-DHAVE_UNISTD_H=1' -D_GNU_SOURCE '-DHAVE_LINK_H=1' '-DHAVE_LSEEK64=1' '-DHAVE_MALLINFO=1' '-DHAVE_SBRK=1' '-DHAVE_STRUCT_STAT_ST_MTIM_TV_NSEC=1' '-DLLVM_NATIVE_ARCH=""AArch64""' '-DLLVM_NATIVE_ASMPARSER=LLVMInitializeAArch64AsmParser' '-DLLVM_NATIVE_ASMPRINTER=LLVMInitializeAArch64AsmPrinter' '-DLLVM_NATIVE_DISASSEMBLER=LLVMInitializeAArch64Disassembler' '-DLLVM_NATIVE_TARGET=LLVMInitializeAArch64Target' '-DLLVM_NATIVE_TARGETINFO=LLVMInitializeAArch64TargetInfo' '-DLLVM_NATIVE_TARGETMC=LLVMInitializeAArch64TargetMC' '-DLLVM_NATIVE_TARGETMCA=LLVMInitializeAArch64TargetMCA' '-DLLVM_HOST_TRIPLE=""aarch64-unknown-linux-gnu""' '-DLLVM_DEFAULT_TARGET_TRIPLE=""aarch64-unknown-linux-gnu""' -D__STDC_LIMIT_MACROS -D__STDC_CONSTANT_MACROS -D__STDC_FORMAT_MACROS -iquote. -iquotebazel-out/aarch64-opt-exec-50AE0418/bin -iquoteexternal/com_google_absl -iquotebazel-out/aarch64-opt-exec-50AE0418/bin/external/com_google_absl -iquoteexternal/llvm-project -iquotebazel-out/aarch64-opt-exec-50AE0418/bin/external/llvm-project -iquoteexternal/llvm_terminfo -iquotebazel-out/aarch64-opt-exec-50AE0418/bin/external/llvm_terminfo -iquoteexternal/llvm_zlib -iquotebazel-out/aarch64-opt-exec-50AE0418/bin/external/llvm_zlib -iquoteexternal/bazel_tools -iquotebazel-out/aarch64-opt-exec-50AE0418/bin/external/bazel_tools -Ibazel-out/aarch64-opt-exec-50AE0418/bin/external/llvm-project/mlir/_virtual_includes/BuiltinAttributeInterfacesIncGen -Ibazel-out/aarch64-opt-exec-50AE0418/bin/external/llvm-project/mlir/_virtual_includes/BuiltinAttributesIncGen -Ibazel-out/aarch64-opt-exec-50AE0418/bin/external/llvm-project/mlir/_virtual_includes/BuiltinDialectIncGen -Ibazel-out/aarch64-opt-exec-50AE0418/bin/external/llvm-project/mlir/_virtual_includes/BuiltinLocationAttributesIncGen -Ibazel-out/aarch64-opt-exec-50AE0418/bin/external/llvm-project/mlir/_virtual_includes/BuiltinOpsIncGen -Ibazel-out/aarch64-opt-exec-50AE0418/bin/external/llvm-project/mlir/_virtual_includes/BuiltinTypeInterfacesIncGen -Ibazel-out/aarch64-opt-exec-50AE0418/bin/external/llvm-project/mlir/_virtual_includes/BuiltinTypesIncGen -Ibazel-out/aarch64-opt-exec-50AE0418/bin/external/llvm-project/mlir/_virtual_includes/CallOpInterfacesIncGen -Ibazel-out/aarch64-opt-exec-50AE0418/bin/external/llvm-project/mlir/_virtual_includes/CastOpInterfacesIncGen -Ibazel-out/aarch64-opt-exec-50AE0418/bin/external/llvm-project/mlir/_virtual_includes/FunctionInterfacesIncGen -Ibazel-out/aarch64-opt-exec-50AE0418/bin/external/llvm-project/mlir/_virtual_includes/InferTypeOpInterfaceIncGen -Ibazel-out/aarch64-opt-exec-50AE0418/bin/external/llvm-project/mlir/_virtual_includes/OpAsmInterfaceIncGen -Ibazel-out/aarch64-opt-exec-50AE0418/bin/external/llvm-project/mlir/_virtual_includes/RegionKindInterfaceIncGen -Ibazel-out/aarch64-opt-exec-50AE0418/bin/external/llvm-project/mlir/_virtual_includes/SideEffectInterfacesIncGen -Ibazel-out/aarch64-opt-exec-50AE0418/bin/external/llvm-project/mlir/_virtual_includes/SubElementInterfacesIncGen -Ibazel-out/aarch64-opt-exec-50AE0418/bin/external/llvm-project/mlir/_virtual_includes/SymbolInterfacesIncGen -Ibazel-out/aarch64-opt-exec-50AE0418/bin/external/llvm-project/mlir/_virtual_includes/TensorEncodingIncGen -isystem external/llvm-project/llvm/include -isystem bazel-out/aarch64-opt-exec-50AE0418/bin/external/llvm-project/llvm/include -isystem external/llvm-project/mlir/include -isystem bazel-out/aarch64-opt-exec-50AE0418/bin/external/llvm-project/mlir/include -g0 -w -g0 '-std=c++14' -DEIGEN_AVOID_STL_ARRAY -Iexternal/gemmlowp -Wno-sign-compare '-ftemplate-depth=900' -fno-exceptions '-DTENSORFLOW_USE_XLA=1' -pthread -fno-canonical-system-headers -Wno-builtin-macro-redefined '-D__DATE__=""redacted""' '-D__TIMESTAMP__=""redacted""' '-D__TIME__=""redacted""' -c tensorflow/compiler/mlir/lite/quantization/tools/tflite_op_coverage_spec_getters_gen.cc -o bazel-out/aarch64-opt-exec-50AE0418/bin/tensorflow/compiler/mlir/lite/quantization/_objs/tflite_op_coverage_spec_getters_gen/tflite_op_coverage_spec_getters_gen.o)
# Configuration: 60dfdb78461e1be6bbf375554f969ad44a05ceccb450bdfffe3de8778874f0b9
# Execution platform: @local_execution_config_platform//:platform
tensorflow/compiler/mlir/lite/quantization/tools/tflite_op_coverage_spec_getters_gen.cc: In function 'bool CheckTypeConstraints(llvm::Init*, std::list<std::basic_string<char> >, bool)':
tensorflow/compiler/mlir/lite/quantization/tools/tflite_op_coverage_spec_getters_gen.cc:139:49: error: no matching function for call to 'StrContains(llvm::StringRef&, const string&)'
  139 |     if (!absl::StrContains(supported_types, type)) return false;
      |                                                 ^
In file included from tensorflow/compiler/mlir/lite/quantization/tools/tflite_op_coverage_spec_getters_gen.cc:20:
external/com_google_absl/absl/strings/match.h:46:13: note: candidate: 'bool absl::lts_20211102::StrContains(absl::lts_20211102::string_view, absl::lts_20211102::string_view)'
   46 | inline bool StrContains(absl::string_view haystack,
      |             ^~~~~~~~~~~
external/com_google_absl/absl/strings/match.h:46:43: note:   no known conversion for argument 1 from 'llvm::StringRef' to 'absl::lts_20211102::string_view'
   46 | inline bool StrContains(absl::string_view haystack,
      |                         ~~~~~~~~~~~~~~~~~~^~~~~~~~
external/com_google_absl/absl/strings/match.h:51:13: note: candidate: 'bool absl::lts_20211102::StrContains(absl::lts_20211102::string_view, char)'
   51 | inline bool StrContains(absl::string_view haystack, char needle) noexcept {
      |             ^~~~~~~~~~~
external/com_google_absl/absl/strings/match.h:51:43: note:   no known conversion for argument 1 from 'llvm::StringRef' to 'absl::lts_20211102::string_view'
   51 | inline bool StrContains(absl::string_view haystack, char needle) noexcept {
      |                         ~~~~~~~~~~~~~~~~~~^~~~~~~~
INFO: Elapsed time: 64.881s, Critical Path: 44.85s


**Provide the exact sequence of commands / steps that you executed before running into the problem**

bazel test --test_timeout=300,500,-1,-1 --flaky_test_attempts=3 --test_output=all --cache_test_results=no --config=nonccl --verbose_failures --build_tag_filters=-no_oss,-oss_serial,-gpu,-tpu,-benchmark-test,-v1only,-no_aarch64,-requires-gpu --test_tag_filters=-no_oss,-oss_serial,-gpu,-tpu,-benchmark-test,-v1only,-no_aarch64,-requires-gpu --jobs=75 -- //tensorflow/... -//tensorflow/compiler/tf2tensorrt/... -//tensorflow/compiler/xrt/... -//tensorflow/core/tpu/... -//tensorflow/go/... -//tensorflow/java/... -//tensorflow/python/integration_testing/... -//tensorflow/tools/toolchains/... -//tensorflow/lite/... -//tensorflow/python/tools/... -//tensorflow/compiler/mlir/lite/tests:const-fold.mlir.test -//tensorflow/compiler/mlir/lite/tests:prepare-tf.mlir.test -//tensorflow/python/data/experimental/kernel_tests/service:fault_tolerance_test -//tensorflow/python/eager:function_test -//tensorflow/python/kernel_tests/linalg:self_adjoint_eig_op_test

**Any other info / logs**
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.
"
54986,Not able to build tensorflow2.5.3 from source,"
### System information

-   **Have I written custom code (as opposed to using a stock example script
    provided in TensorFlow)**: - Yes
-   **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:  Centos 7
-   **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue
    happens on a mobile device**: No 
-   **TensorFlow installed from (source or binary)**: source
-   **TensorFlow version (use command below)**: 2.5.3
-   **Python version**: 3.8
-   **Bazel version (if compiling from source)**: 3.7.2
-   **GCC/Compiler version (if compiling from source)**: 9.3.0
-   **CUDA/cuDNN version**: not applied
-   **GPU model and memory**: not applied
-   **Exact command to reproduce**:  bazel --output_user_root=/cache/ build --config=v2 --copt=-m64 --copt=-march=native --config=monolithic --config=opt --verbose_failures -c opt --cxxopt=-std=c++17 --cxxopt=""-D_GLIBCXX_USE_CXX11_ABI=0"" //tensorflow:tensorflow_cc //tensorflow:install_headers tensorflow:tensorflow_framework //tensorflow/tools/... //tensorflow/examples/...


### Describe the problem
Describe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.

I have built bazel 3.7.0 from the source and now building TensorFlow 2.5.3 from the source with GCC 9.3.0 from devtoolset in centos 7. I am getting the below error.  

### Source code / logs
Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.

Error Message -

bazel --output_user_root=/cache/ build --config=v2 --copt=-m64 --copt=-march=native --config=monolithic --config=opt --verbose_failures -c opt --cxxopt=-std=c++17 --cxxopt=""-D_GLIBCXX_USE_CXX11_ABI=0"" //tensorflow:tensorflow_cc //tensorflow:install_headers tensorflow:tensorflow_framework //tensorflow/tools/... //tensorflow/examples/...
Extracting Bazel installation...
Starting local Bazel server and connecting to it...
WARNING: The following configs were expanded more than once: [v2]. For repeatable flags, repeats are counted twice and may lead to unexpected behavior.
INFO: Options provided by the client:
  Inherited 'common' options: --isatty=1 --terminal_columns=138
INFO: Reading rc options for 'build' from /tensorflow-2.5.3/.bazelrc:
  Inherited 'common' options: --experimental_repo_remote_exec
INFO: Reading rc options for 'build' from /tensorflow-2.5.3/.bazelrc:
  'build' options: --define framework_shared_object=true --java_toolchain=@tf_toolchains//toolchains/java:tf_java_toolchain --host_java_toolchain=@tf_toolchains//toolchains/java:tf_java_toolchain --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --noincompatible_prohibit_aapt1 --enable_platform_specific_config --define=with_xla_support=true --config=short_logs --config=v2
INFO: Reading rc options for 'build' from /tensorflow-2.5.3/.tf_configure.bazelrc:
  'build' options: --action_env PYTHON_BIN_PATH=/remote/home/rrajeev/Software/anaconda3/envs/tf/bin/python3 --action_env PYTHON_LIB_PATH=/remote/home/rrajeev/Software/anaconda3/envs/tf/lib/python3.8/site-packages --python_path=/remote/home/rrajeev/Software/anaconda3/envs/tf/bin/python3
INFO: Found applicable config definition build:short_logs in file /tensorflow-2.5.3/.bazelrc: --output_filter=DONT_MATCH_ANYTHING
INFO: Found applicable config definition build:v2 in file /tensorflow-2.5.3/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1
INFO: Found applicable config definition build:v2 in file /tensorflow-2.5.3/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1
INFO: Found applicable config definition build:monolithic in file /tensorflow-2.5.3/.bazelrc: --define framework_shared_object=false
INFO: Found applicable config definition build:opt in file /tensorflow-2.5.3/.tf_configure.bazelrc: --copt=-Wno-sign-compare --host_copt=-Wno-sign-compare
INFO: Found applicable config definition build:linux in file /tensorflow-2.5.3/.bazelrc: --copt=-w --host_copt=-w --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --define=PROTOBUF_INCLUDE_PATH=$(PREFIX)/include --cxxopt=-std=c++14 --host_cxxopt=-std=c++14 --config=dynamic_kernels
INFO: Found applicable config definition build:dynamic_kernels in file /tensorflow-2.5.3/.bazelrc: --define=dynamic_loaded_kernels=true --copt=-DAUTOLOAD_DYNAMIC_KERNELS
DEBUG: Rule 'io_bazel_rules_docker' indicated that a canonical reproducible form can be obtained by modifying arguments shallow_since = ""1556410077 -0400""
DEBUG: Repository io_bazel_rules_docker instantiated at:
  /tensorflow-2.5.3/WORKSPACE:23:14: in <toplevel>
  /tensorflow-2.5.3/tensorflow/workspace0.bzl:105:34: in workspace
  /cache/1c211944fffc93afc232f5e22d2690de/external/bazel_toolchains/repositories/repositories.bzl:37:23: in repositories
Repository rule git_repository defined at:
  /cache/1c211944fffc93afc232f5e22d2690de/external/bazel_tools/tools/build_defs/repo/git.bzl:199:33: in <toplevel>
INFO: Analyzed 193 targets (453 packages loaded, 36344 targets configured).
INFO: Found 193 targets...
ERROR: /tensorflow-2.5.3/tensorflow/compiler/mlir/lite/BUILD:627:20: Linking of rule '//tensorflow/compiler/mlir/lite:converter-gen' failed (Exit 1): gcc failed: error executing command 
  (cd /cache/1c211944fffc93afc232f5e22d2690de/execroot/org_tensorflow && \
  exec env - \
    LD_LIBRARY_PATH=/usr/path \
    PATH= /usr/path
    PWD=/proc/self/cwd \
  /opt/rh/devtoolset-9/root/usr/bin/gcc @bazel-out/k8-opt-exec-50AE0418/bin/tensorflow/compiler/mlir/lite/converter-gen-2.params)
Execution platform: @local_execution_config_platform//:platform
bazel-out/k8-opt-exec-50AE0418/bin/tensorflow/compiler/mlir/lite/_objs/converter-gen/converter_gen.o:converter_gen.cc:function llvm::detail::provider_format_adapter<int&>::~provider_format_adapter(): error: undefined reference to 'operator delete(void*, unsigned long)'
bazel-out/k8-opt-exec-50AE0418/bin/tensorflow/compiler/mlir/lite/_objs/converter-gen/converter_gen.o:converter_gen.cc:function llvm::detail::provider_format_adapter<unsigned long>::~provider_format_adapter(): error: undefined reference to 'operator delete(void*, unsigned long)'
bazel-out/k8-opt-exec-50AE0418/bin/tensorflow/compiler/mlir/lite/_objs/converter-gen/converter_gen.o:converter_gen.cc:function llvm::detail::provider_format_adapter<llvm::StringRef>::~provider_format_adapter(): error: undefined reference to 'operator delete(void*, unsigned long)'
bazel-out/k8-opt-exec-50AE0418/bin/tensorflow/compiler/mlir/lite/_objs/converter-gen/converter_gen.o:converter_gen.cc:function llvm::detail::provider_format_adapter<llvm::StringRef&>::~provider_format_adapter(): error: undefined reference to 'operator delete(void*, unsigned long)'
bazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/llvm/_objs/TableGen/Main.o:Main.cpp:function llvm::TableGenMain(char const*, bool (*)(llvm::raw_ostream&, llvm::RecordKeeper&)): error: undefined reference to 'std::_V2::system_category()'
bazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/llvm/_objs/TableGen/Main.o:Main.cpp:function llvm::TableGenMain(char const*, bool (*)(llvm::raw_ostream&, llvm::RecordKeeper&)): error: undefined reference to 'std::_V2::system_category()'
bazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/llvm/_objs/Support/CommandLine.o:CommandLine.cpp:function ExpandResponseFile(llvm::StringRef, llvm::StringSaver&, void (*)(llvm::StringRef, llvm::StringSaver&, llvm::SmallVectorImpl<char const*>&, bool), llvm::SmallVectorImpl<char const*>&, bool, bool, llvm::vfs::FileSystem&): error: undefined reference to 'std::_V2::generic_category()'
bazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/llvm/_objs/Support/ConvertUTFWrapper.o:ConvertUTFWrapper.cpp:function llvm::convertUTF16ToUTF8String(llvm::ArrayRef<char>, std::string&): error: undefined reference to 'std::__throw_out_of_range_fmt(char const*, ...)'
bazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/llvm/_objs/Support/Error.o:Error.cpp:function (anonymous namespace)::ErrorErrorCategory::~ErrorErrorCategory(): error: undefined reference to 'std::_V2::error_category::~error_category()'
bazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/llvm/_objs/Support/Error.o:Error.cpp:function (anonymous namespace)::ErrorErrorCategory::~ErrorErrorCategory(): error: undefined reference to 'std::_V2::error_category::~error_category()'
bazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/llvm/_objs/Support/Error.o:Error.cpp:function llvm::object_deleter<(anonymous namespace)::ErrorErrorCategory>::call(void*): error: undefined reference to 'std::_V2::error_category::~error_category()'
bazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/llvm/_objs/Support/Error.o:Error.cpp:function llvm::errorToErrorCode(llvm::Error): error: undefined reference to 'std::_V2::system_category()'
bazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/llvm/_objs/Support/Error.o:Error.cpp:typeinfo for (anonymous namespace)::ErrorErrorCategory: error: undefined reference to 'typeinfo for std::_V2::error_category'
bazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/llvm/_objs/Support/Error.o:Error.cpp:vtable for (anonymous namespace)::ErrorErrorCategory: error: undefined reference to 'std::_V2::error_category::_M_message(int) const'
bazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/llvm/_objs/Support/Error.o:Error.cpp:vtable for (anonymous namespace)::ErrorErrorCategory: error: undefined reference to 'std::_V2::error_category::default_error_condition(int) const'
bazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/llvm/_objs/Support/Error.o:Error.cpp:vtable for (anonymous namespace)::ErrorErrorCategory: error: undefined reference to 'std::_V2::error_category::equivalent(int, std::error_condition const&) const'
bazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/llvm/_objs/Support/Error.o:Error.cpp:vtable for (anonymous namespace)::ErrorErrorCategory: error: undefined reference to 'std::_V2::error_category::equivalent(std::error_code const&, int) const'
bazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/llvm/_objs/Support/raw_ostream.o:raw_ostream.cpp:function getFD(llvm::StringRef, std::error_code&, llvm::sys::fs::CreationDisposition, llvm::sys::fs::FileAccess, llvm::sys::fs::OpenFlags): error: undefined reference to 'std::_V2::system_category()'
bazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/llvm/_objs/Support/raw_ostream.o:raw_ostream.cpp:function llvm::raw_fd_ostream::write_impl(char const*, unsigned long): error: undefined reference to 'std::_V2::generic_category()'
bazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/llvm/_objs/Support/raw_ostream.o:raw_ostream.cpp:function llvm::raw_fd_ostream::seek(unsigned long): error: undefined reference to 'std::_V2::generic_category()'
bazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/llvm/_objs/Support/MemoryBuffer.o:MemoryBuffer.cpp:function getMemBufferCopyImpl(llvm::StringRef, llvm::Twine const&): error: undefined reference to 'std::_V2::generic_category()'
bazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/llvm/_objs/Support/SmallPtrSet.o:SmallPtrSet.cpp:function llvm::SmallPtrSetImplBase::Grow(unsigned int): warning: memset used with constant zero length parameter; this could be due to transposed parameters
bazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/llvm/_objs/Support/SourceMgr.o:SourceMgr.cpp:function llvm::SMDiagnostic::print(char const*, llvm::raw_ostream&, bool, bool) const: error: undefined reference to 'std::__throw_out_of_range_fmt(char const*, ...)'
bazel-out/k8-opt-exec-50AE0418/bin/external/llvm-project/llvm/_objs/Support/StringRef.o:StringRef.cpp:function unsigned int llvm::ComputeEditDistance<char>(llvm::ArrayRef<char>, llvm::ArrayRef<char>, bool, unsigned int): error: undefined reference to '__cxa_throw_bad_array_new_length'
collect2: error: ld returned 1 exit status
ERROR: /tensorflow-2.5.3/tensorflow/python/BUILD:5209:24 Linking of rule '//tensorflow/compiler/mlir/lite:converter-gen' failed (Exit 1): gcc failed: error executing command 
  (cd /cache/1c211944fffc93afc232f5e22d2690de/execroot/org_tensorflow && \
  exec env - \
    LD_LIBRARY_PATH=/usr/path \
    PATH= /usr/path
    PWD=/proc/self/cwd \
  /opt/rh/devtoolset-9/root/usr/bin/gcc @bazel-out/k8-opt-exec-50AE0418/bin/tensorflow/compiler/mlir/lite/converter-gen-2.params)
Execution platform: @local_execution_config_platform//:platform

"
54984,gradient tape with rank 0 tensors causes integer division or modulo by zero,"**System information**
- Have I written custom code? Yes
- OS Platform and Distribution: Linux Ubuntu 20.04
- TensorFlow installed from: binary (via apt-get)
- TensorFlow version: 2.3.1
- Python version: 3.8.10
- GPU model: GeForce GTX 1050 Ti Mobile

**Describe the current behavior**
The simple repro below throws the following exception:
```
Traceback (most recent call last):
  File ""bug.py"", line 16, in <module>
    grads = tape.gradient(loss, model.trainable_variables)
  File ""/home/mike/.local/lib/python3.8/site-packages/tensorflow/python/eager/backprop.py"", line 1067, in gradient
    flat_grad = imperative_grad.imperative_grad(
  File ""/home/mike/.local/lib/python3.8/site-packages/tensorflow/python/eager/imperative_grad.py"", line 71, in imperative_grad
    return pywrap_tfe.TFE_Py_TapeGradient(
  File ""/home/mike/.local/lib/python3.8/site-packages/tensorflow/python/eager/backprop.py"", line 162, in _gradient_function
    return grad_fn(mock_op, *out_grads)
  File ""/home/mike/.local/lib/python3.8/site-packages/tensorflow/python/ops/array_grad.py"", line 228, in _ConcatGradV2
    return _ConcatGradHelper(
  File ""/home/mike/.local/lib/python3.8/site-packages/tensorflow/python/ops/array_grad.py"", line 118, in _ConcatGradHelper
    concat_dim._numpy().item(0) % input_values[0]._rank())  # pylint: disable=protected-access
ZeroDivisionError: integer division or modulo by zero

```
**Describe the expected behavior**
It should either compute a gradient (or throw a meaningful exception if that is not possible).

**[Contributing](https://www.tensorflow.org/community/contribute)**

- Do you want to contribute a PR? No

**Standalone code to reproduce the issue**
```
import tensorflow as tf

class MyModel(tf.keras.Model):
    def __init__(self) -> None:
        super().__init__()
        self.layer = tf.keras.layers.Dense(1)

    def call(self, inputs: tf.Tensor) -> tf.Tensor:
        return self.layer(inputs)

model = MyModel()
x = tf.zeros((1, 1))
with tf.GradientTape() as tape:
    theta = model(x)[0,0]
    loss = tf.concat([tf.math.cos(theta), tf.math.sin(theta)], axis=0)
grads = tape.gradient(loss, model.trainable_variables)

```
**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
54980,Model accurate missing after converting to tflite,"### 1. System information

- Windows 10
- Pip package
- 2.7.0

### 2. Code

import tensorflow as tf

model = tf.keras.models.load_model('liveness.model')
converter = tf.lite.TFLiteConverter.from_keras_model(model)
tflite_model = converter.convert()
open(""liveness4.tflite"", ""wb"").write(tflite_model)

### 3. Failure after conversion
If the conversion is successful, but the generated model is wrong, then state what is wrong:

- Model produces wrong results and/or has lesser accuracy.


Also Im  getting this warning after converting to tflite model.

WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded
"
54979,Per thread allocation of MKL primitives,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):
Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):
Linux Ubuntu 18.04
- TensorFlow installed from (source or binary):
From source using Docker container script from here: https://github.com/ARM-software/Tool-Solutions/tree/master/docker/tensorflow-aarch64 and container available here: https://hub.docker.com/r/armswdev/tensorflow-arm-neoverse
- TensorFlow version (use command below):
v2.8.0-0-g3f878cff5b6 2.8.0
- Python version:
3.8.10
- Bazel version (if compiling from source):
4.2.2
- GCC/Compiler version (if compiling from source):
10.3.0
- CUDA/cuDNN version:
N/A
- GPU model and memory:
N/A

**Describe the current behavior**

We have noticed when running a simple example (https://github.com/ARM-software/Tool-Solutions/blob/master/docker/tensorflow-aarch64/examples/py-api/detect_objects.py) on AArch64 using this container: https://hub.docker.com/r/armswdev/tensorflow-arm-neoverse, with the command line:

`python detect_objects.py -m ./ssd_resnet34.yml -i https://raw.githubusercontent.com/zhreshold/mxnet-ssd/master/data/demo/street.jpg --inter_threads 64 -r 100`

that amount of resident memory grows to ~50GiB. The TF (MKL) build in the container uses oneDNN and Compute Library as backend. When setting TF `inter_op_parallelism_threads` to 1 (via the `--inter_threads` switch in the script) the amount of resident memory is ~2GiB.

We have also noticed that on x86, when running the same script using TF (MKL) build with oneDNN backend, memory grows from 900MiB, when then number of inter parallel threads is 1, to around 1.4GiB when it set to 64. The more significant increase observed on AArch64 is due to additional memory per operation required by Compute Library.

**Describe the expected behavior**

The size of allocated memory should not increase due to change in number of inter parallel threads.

**Standalone code to reproduce the issue**

Run the command line referenced above.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.

We have tracked the issue down to the per-thread caching here: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/util/mkl_util.h#L1860. For some models when using inter parallelism > 1 it seems that TF starts cloning working threads and each of these thread has its own cache; so it is not aware of same primitives created in other threads.

For this particular model we counted there are about 50 convolution operations. When setting inter parallelism to 64 the number of convolution operations allocated is `64*50`, where `63*50` are simply duplicated. By making this cache global and shared among these multiple threads we have noticed that resident memory doesn’t grow with increased number of threads and it stays flat to ~2GiB on AArch64 when setting inter parallelism to be 64."
54973,Tensor shape error using TF 2.8.0 with XLA enabled,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): `Ubuntu 20.04`
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): `TF 2.8.0` / `TF 2.6.3` / `tf-nightly 2.9.0-dev20220303`
- Python version: `3.8.10`
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: `cuda-driver-dev-11-2, 11.2.152-1`, `libcudnn8, 8.3.2.44-1+cuda11.5`
- GPU model and memory: `RTX 2080 Ti, 11016MiB` / `RTX 8000, 46080MiB`

**Describe the current behavior**
When I upgrade my `TF 2.6.3 -> 2.8.0`, my daily using training script throws me out with error `Must have updates.shape = indices.shape[:batch_dim] + buffer_shape[num_index_dims:], got updates.shape: [32], indices.shape: [320,2], buffer_shape:
 [32,10], num_index_dims: 2, and batch_dim: 1`, with setting `TF_XLA_FLAGS=""--tf_xla_auto_jit=2""` flag, which used to work well in `TF 2.6.3`. 

**Describe the expected behavior**
Expect still working well like old `TF 2.6.3` time.

**[Contributing](https://www.tensorflow.org/community/contribute)**

- Do you want to contribute a PR? (yes/no): no
- Briefly describe your candidate solution(if contributing): have no idea...

**Standalone code to reproduce the issue**
This is my standalone code for reproducing, that simplified most details:
```py
#!/usr/bin/env python3

import tensorflow as tf
from tensorflow import keras


class NormDense(keras.layers.Layer):
    def __init__(self, units=1000, append_norm=False, **kwargs):
        super().__init__(**kwargs)
        self.units, self.append_norm = units, append_norm

    def build(self, input_shape):
        self.w = self.add_weight(name=""norm_dense_w"", shape=(input_shape[-1], self.units), trainable=True)
        super().build(input_shape)

    def call(self, inputs, **kwargs):
        # tf.print(""tf.reduce_mean(self.w):"", tf.reduce_mean(self.w))
        norm_w = tf.nn.l2_normalize(self.w, axis=0)
        norm_inputs = tf.nn.l2_normalize(inputs, axis=1)
        output = tf.matmul(norm_inputs, norm_w)
        if self.append_norm:
            output = tf.concat([output, tf.norm(inputs, axis=1, keepdims=True) * -1], axis=-1)
        return output

    def get_config(self):
        config = super().get_config()
        config.update({""units"": self.units, ""append_norm"": self.append_norm})
        return config


class NormDenseLoss(tf.keras.losses.Loss):
    def __init__(self, from_logits=True, **kwargs):
        super().__init__(**kwargs)
        self.from_logits = from_logits

    def call(self, y_true, y_pred):
        if y_pred.shape[-1] == y_true.shape[-1]:
            norm_logits = y_pred
            margin = 0.3
            regularizer_loss = 0.0
        else:
            norm_logits, feature_norm = y_pred[:, :-1], y_pred[:, -1] * -1
            margin = 0.04 * (feature_norm - 10) + 10.0  # This triggers the error
            regularizer_loss = feature_norm / 1e4 + 1.0 / feature_norm

        pick_cond = tf.where(y_true > 0)
        y_pred_vals = tf.gather_nd(norm_logits, pick_cond)
        theta_valid = y_pred_vals - margin

        # tf.print("">>>>"", norm_logits.shape, pick_cond, tf.reduce_sum(tf.cast(y_true > 0, ""float32"")), theta_valid.shape)
        logits = tf.tensor_scatter_nd_update(norm_logits, pick_cond, theta_valid)
        # theta_one_hot = tf.expand_dims(theta_valid, 1) * tf.cast(y_true, dtype=tf.float32)
        # logits = tf.where(tf.cast(y_true, dtype=tf.bool), theta_one_hot, norm_logits)
        # tf.print("">>>>"", norm_logits.shape, logits.shape, y_true.shape)
        cls_loss = tf.keras.losses.categorical_crossentropy(y_true, logits, from_logits=self.from_logits)

        # tf.print("">>>>"", cls_loss.shape, regularizer_loss.shape)
        return cls_loss + regularizer_loss * 35.0

    def get_config(self):
        config = super().get_config()
        config.update({""from_logits"": self.from_logits})
        return config


if __name__ == ""__main__"":
    import sys
    import argparse

    parser = argparse.ArgumentParser(formatter_class=argparse.ArgumentDefaultsHelpFormatter)
    parser.add_argument(""--append_norm"", action=""store_true"", help=""append norm"")
    args = parser.parse_known_args(sys.argv[1:])[0]

    xx = tf.random.uniform([160, 32, 32, 3])
    yy = tf.one_hot(tf.cast(tf.random.uniform([160], 0, 10), ""int32""), 10)
    mm = keras.models.Sequential([keras.layers.Input([32, 32, 3]), keras.layers.Flatten(), keras.layers.Dense(32), NormDense(10, append_norm=args.append_norm)])
    mm.compile(loss=NormDenseLoss(), optimizer=""adam"")
    mm.fit(xx, yy)
```
Run test using `TF 2.6.3`:
```sh
# Pass
CUDA_VISIBLE_DEVICES='0' TF_XLA_FLAGS=""--tf_xla_auto_jit=2"" python ./tf_280_xla_test.py
# Pass
CUDA_VISIBLE_DEVICES='0' TF_XLA_FLAGS=""--tf_xla_auto_jit=2"" python ./tf_280_xla_test.py --append_norm
```
Run test using `TF 2.8.0` / `tf-nightly 2.9.0-dev20220303`:
```sh
# Pass
CUDA_VISIBLE_DEVICES='0' TF_XLA_FLAGS=""--tf_xla_auto_jit=2"" python ./tf_280_xla_test.py
# Error
CUDA_VISIBLE_DEVICES='0' TF_XLA_FLAGS=""--tf_xla_auto_jit=2"" python ./tf_280_xla_test.py --append_norm
# Must have updates.shape = indices.shape[:batch_dim] + buffer_shape[num_index_dims:], got updates.shape: [32], indices.shape: [320,2], buffer_shape: [32,10], num_index_dims: 2, and batch_dim: 1

# Pass
CUDA_VISIBLE_DEVICES='0' python ./tf_280_xla_test.py --append_norm
```
Maybe some part of this script is not needed for this reproduce, not sure. I think something went wrong with `margin = 0.04 * (feature_norm - 10) + 10.0`, but cannot tell what exactly happens here... Please take a check.
"
54969,tf.distribute.experimental.CentralStorageStrategy does not work with tf.keras.layers.Discretization,"### System information

-   **Have I written custom code (as opposed to using a stock example script
    provided in TensorFlow)**: Yes
-   **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: CentOS Linux release 7.2
-   **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue
    happens on a mobile device**: N/A
-   **TensorFlow installed from (source or binary)**: binary
-   **TensorFlow version (use command below)**: v2.8.0-rc1-32-g3f878cff5b6 2.8.0
-   **Python version**: 3.8.8
-   **Bazel version (if compiling from source)**: N/A
-   **GCC/Compiler version (if compiling from source)**: N/A
-   **CUDA/cuDNN version**: CUDA 11.2/cuDNN 8.2.1
-   **GPU model and memory**: two A100 GPUs, each with 40GB GPU memory
-   **Exact command to reproduce**:

### Describe the problem
I wrote a subclassed Keras model and use tf.keras.layers.Discretization to preprocessing two numerical features. In the preprocessing layer, the code also uses Normalization/StringLookup/IntegerLookup to preprocess numerical and categorical features. The training data is in TFRecord format and read using TFRecordDataset API.

The model training works fine with default strategy, tf.distribute.OneDeviceStrategy(device=""/gpu:0""), and tf.distribute.MirroredStrategy(). However, the following error occurred if the distributed strategy is switched to CentralStorageStrategy.

```
INVALID_ARGUMENT:  indices[28] = -1 is not in [0, 10)
	 [[{{node MMoE/u-age_dis_embedding/embedding_lookup}}]]
```
This vocabulary size of the u-age_dis_embedding is 10, and the index is computed by the Discretization. I do not quite understand why Discretization output -1 under CentralStorageStrategy, and since the training code works fine with other distributed strategies, I guess this is a bug between CentralStorageStrategy and Discretization.

Here is the compute device info with CentralStorageStrategy.
`strategy = tf.distribute.experimental.CentralStorageStrategy()`
`INFO:tensorflow:ParameterServerStrategy (CentralStorageStrategy if you are using a single machine) with compute_devices = ['/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1'], variable_device = '/device:CPU:0'`

### Source code / logs
Here is the code snippets and the logs
```
# strategy = tf.distribute.MirroredStrategy() # this works fine
# strategy = tf.distribute.OneDeviceStrategy(device=""/gpu:0"") # this works fine
# strategy = tf.distribute.get_strategy() # this works fine
strategy = tf.distribute.experimental.CentralStorageStrategy() #this strategy failed
with strategy.scope():
    mmoe_model = MMoE(config, preprocessing_layer, name='MMoE')
    optimizer=tf.keras.optimizers.Adam()

    mmoe_model.compile(
        optimizer=optimizer,
    #     run_eagerly=True,
    #     jit_compile=True,
    )
dataset_train = make_dataset_ceph_v0('2022-01-20/14', num_hours=1, batch_size=4096, block_length=None, data_dir='/group/30039/sample_tfrecord/')
mmoe_model.fit(dataset_train, epochs=1)
```
```
---------------------------------------------------------------------------
InvalidArgumentError                      Traceback (most recent call last)
<ipython-input-70-b48f111214ea> in <module>
----> 1 mmoe_model.fit(dataset_train, epochs=1)

/data/miniconda3/envs/env-3.8.8/lib/python3.8/site-packages/keras/utils/traceback_utils.py in error_handler(*args, **kwargs)
     65     except Exception as e:  # pylint: disable=broad-except
     66       filtered_tb = _process_traceback_frames(e.__traceback__)
---> 67       raise e.with_traceback(filtered_tb) from None
     68     finally:
     69       del filtered_tb

/data/miniconda3/envs/env-3.8.8/lib/python3.8/site-packages/tensorflow/python/eager/execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)
     52   try:
     53     ctx.ensure_initialized()
---> 54     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
     55                                         inputs, attrs, num_outputs)
     56   except core._NotOkStatusException as e:

InvalidArgumentError: Graph execution error:

Detected at node 'MMoE/u-age_dis_embedding/embedding_lookup' defined at (most recent call last):
    File ""/data/miniconda3/envs/env-3.8.8/lib/python3.8/threading.py"", line 890, in _bootstrap
      self._bootstrap_inner()
    File ""/data/miniconda3/envs/env-3.8.8/lib/python3.8/threading.py"", line 932, in _bootstrap_inner
      self.run()
    File ""/data/miniconda3/envs/env-3.8.8/lib/python3.8/site-packages/keras/engine/training.py"", line 1000, in run_step
      outputs = model.train_step(data)
    File ""<ipython-input-22-cbffbfa5ad65>"", line 245, in train_step
      y_pred = self(x, training=True)  # Forward pass y_pred[task].shape = (batch_size, 1)
    File ""/data/miniconda3/envs/env-3.8.8/lib/python3.8/site-packages/keras/utils/traceback_utils.py"", line 64, in error_handler
      return fn(*args, **kwargs)
    File ""/data/miniconda3/envs/env-3.8.8/lib/python3.8/site-packages/keras/engine/base_layer.py"", line 1096, in __call__
      outputs = call_fn(inputs, *args, **kwargs)
    File ""/data/miniconda3/envs/env-3.8.8/lib/python3.8/site-packages/keras/utils/traceback_utils.py"", line 92, in error_handler
      return fn(*args, **kwargs)
    File ""<ipython-input-23-0f0cbc0afd9c>"", line 62, in call
      for feature_name, config in self._config.items():
    File ""<ipython-input-23-0f0cbc0afd9c>"", line 68, in call
      if isinstance(embedding_fn, list):
    File ""<ipython-input-23-0f0cbc0afd9c>"", line 69, in call
      for layer in embedding_fn:
    File ""<ipython-input-23-0f0cbc0afd9c>"", line 70, in call
      bottom = layer(bottom)
    File ""/data/miniconda3/envs/env-3.8.8/lib/python3.8/site-packages/keras/utils/traceback_utils.py"", line 64, in error_handler
      return fn(*args, **kwargs)
    File ""/data/miniconda3/envs/env-3.8.8/lib/python3.8/site-packages/keras/engine/base_layer.py"", line 1096, in __call__
      outputs = call_fn(inputs, *args, **kwargs)
    File ""/data/miniconda3/envs/env-3.8.8/lib/python3.8/site-packages/keras/utils/traceback_utils.py"", line 92, in error_handler
      return fn(*args, **kwargs)
    File ""/data/miniconda3/envs/env-3.8.8/lib/python3.8/site-packages/keras/layers/embeddings.py"", line 197, in call
      out = tf.nn.embedding_lookup(self.embeddings, inputs)
Node: 'MMoE/u-age_dis_embedding/embedding_lookup'
Detected at node 'MMoE/u-age_dis_embedding/embedding_lookup' defined at (most recent call last):
    File ""/data/miniconda3/envs/env-3.8.8/lib/python3.8/threading.py"", line 890, in _bootstrap
      self._bootstrap_inner()
    File ""/data/miniconda3/envs/env-3.8.8/lib/python3.8/threading.py"", line 932, in _bootstrap_inner
      self.run()
    File ""/data/miniconda3/envs/env-3.8.8/lib/python3.8/site-packages/keras/engine/training.py"", line 1000, in run_step
      outputs = model.train_step(data)
    File ""<ipython-input-22-cbffbfa5ad65>"", line 245, in train_step
      y_pred = self(x, training=True)  # Forward pass y_pred[task].shape = (batch_size, 1)
    File ""/data/miniconda3/envs/env-3.8.8/lib/python3.8/site-packages/keras/utils/traceback_utils.py"", line 64, in error_handler
      return fn(*args, **kwargs)
    File ""/data/miniconda3/envs/env-3.8.8/lib/python3.8/site-packages/keras/engine/base_layer.py"", line 1096, in __call__
      outputs = call_fn(inputs, *args, **kwargs)
    File ""/data/miniconda3/envs/env-3.8.8/lib/python3.8/site-packages/keras/utils/traceback_utils.py"", line 92, in error_handler
      return fn(*args, **kwargs)
    File ""<ipython-input-23-0f0cbc0afd9c>"", line 62, in call
      for feature_name, config in self._config.items():
    File ""<ipython-input-23-0f0cbc0afd9c>"", line 68, in call
      if isinstance(embedding_fn, list):
    File ""<ipython-input-23-0f0cbc0afd9c>"", line 69, in call
      for layer in embedding_fn:
    File ""<ipython-input-23-0f0cbc0afd9c>"", line 70, in call
      bottom = layer(bottom)
    File ""/data/miniconda3/envs/env-3.8.8/lib/python3.8/site-packages/keras/utils/traceback_utils.py"", line 64, in error_handler
      return fn(*args, **kwargs)
    File ""/data/miniconda3/envs/env-3.8.8/lib/python3.8/site-packages/keras/engine/base_layer.py"", line 1096, in __call__
      outputs = call_fn(inputs, *args, **kwargs)
    File ""/data/miniconda3/envs/env-3.8.8/lib/python3.8/site-packages/keras/utils/traceback_utils.py"", line 92, in error_handler
      return fn(*args, **kwargs)
    File ""/data/miniconda3/envs/env-3.8.8/lib/python3.8/site-packages/keras/layers/embeddings.py"", line 197, in call
      out = tf.nn.embedding_lookup(self.embeddings, inputs)
Node: 'MMoE/u-age_dis_embedding/embedding_lookup'
Detected at node 'MMoE/u-age_dis_embedding/embedding_lookup' defined at (most recent call last):
    File ""/data/miniconda3/envs/env-3.8.8/lib/python3.8/threading.py"", line 890, in _bootstrap
      self._bootstrap_inner()
    File ""/data/miniconda3/envs/env-3.8.8/lib/python3.8/threading.py"", line 932, in _bootstrap_inner
      self.run()
    File ""/data/miniconda3/envs/env-3.8.8/lib/python3.8/site-packages/keras/engine/training.py"", line 1000, in run_step
      outputs = model.train_step(data)
    File ""<ipython-input-22-cbffbfa5ad65>"", line 245, in train_step
      y_pred = self(x, training=True)  # Forward pass y_pred[task].shape = (batch_size, 1)
    File ""/data/miniconda3/envs/env-3.8.8/lib/python3.8/site-packages/keras/utils/traceback_utils.py"", line 64, in error_handler
      return fn(*args, **kwargs)
    File ""/data/miniconda3/envs/env-3.8.8/lib/python3.8/site-packages/keras/engine/base_layer.py"", line 1096, in __call__
      outputs = call_fn(inputs, *args, **kwargs)
    File ""/data/miniconda3/envs/env-3.8.8/lib/python3.8/site-packages/keras/utils/traceback_utils.py"", line 92, in error_handler
      return fn(*args, **kwargs)
    File ""<ipython-input-23-0f0cbc0afd9c>"", line 62, in call
      for feature_name, config in self._config.items():
    File ""<ipython-input-23-0f0cbc0afd9c>"", line 68, in call
      if isinstance(embedding_fn, list):
    File ""<ipython-input-23-0f0cbc0afd9c>"", line 69, in call
      for layer in embedding_fn:
    File ""<ipython-input-23-0f0cbc0afd9c>"", line 70, in call
      bottom = layer(bottom)
    File ""/data/miniconda3/envs/env-3.8.8/lib/python3.8/site-packages/keras/utils/traceback_utils.py"", line 64, in error_handler
      return fn(*args, **kwargs)
    File ""/data/miniconda3/envs/env-3.8.8/lib/python3.8/site-packages/keras/engine/base_layer.py"", line 1096, in __call__
      outputs = call_fn(inputs, *args, **kwargs)
    File ""/data/miniconda3/envs/env-3.8.8/lib/python3.8/site-packages/keras/utils/traceback_utils.py"", line 92, in error_handler
      return fn(*args, **kwargs)
    File ""/data/miniconda3/envs/env-3.8.8/lib/python3.8/site-packages/keras/layers/embeddings.py"", line 197, in call
      out = tf.nn.embedding_lookup(self.embeddings, inputs)
Node: 'MMoE/u-age_dis_embedding/embedding_lookup'
3 root error(s) found.
  (0) INVALID_ARGUMENT:  indices[28] = -1 is not in [0, 10)
	 [[{{node MMoE/u-age_dis_embedding/embedding_lookup}}]]
	 [[replica_1/MMoE/i-grade_embedding/embedding_lookup/_352]]
  (1) INVALID_ARGUMENT:  indices[28] = -1 is not in [0, 10)
	 [[{{node MMoE/u-age_dis_embedding/embedding_lookup}}]]
	 [[Add_41/ReadVariableOp_1/_2648]]
  (2) INVALID_ARGUMENT:  indices[28] = -1 is not in [0, 10)
	 [[{{node MMoE/u-age_dis_embedding/embedding_lookup}}]]
0 successful operations.
0 derived errors ignored. [Op:__inference_train_function_562346]
```"
54958,Suspicious usage of clGetProgramInfo parameters in CLProgram::GetBinary,"<em>Please make sure that this is a bug. As per our
[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),
we only address code/doc bugs, performance issues, feature requests and
build/installation issues on GitHub. tag:bug_template</em>

**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Android 12
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Samsung Galaxy S22
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below):  tensorflow lite tag 2.8.0
- Python version: 3.7
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: N/A
- GPU model and memory: Exynos Samsung GPU

**benchmark build**
- bazel build -c opt --config=android_arm64 tensorflow/lite/tools/benchmark:benchmark_model)

**run**
/data/local/tmp/benchmark_model --graph=/data/local/tmp/--mini_cnn.tflite --use_gpu=true --num_runs=10 --num_threads=1 --gpu_backend=cl --delegate_serialize_dir=/data/local/tmp/cache --delegate_serialize_token=mini

**Describe the current behavior**
clGetProgramInfo in CLProgram::GetBinary **parameters**
CL_PROGRAM_BINARIES: 0x1166
**binary_size: 5592** (the current codes are intended for kernel size not address size)

**Describe the expected behavior**
clGetProgramInfo in CLProgram::GetBinary **parameters**
CL_PROGRAM_BINARIES: 0x1166
**binary_size: sizof(binary_ptr) maybe**

In OpenCL Spec(https://www.khronos.org/registry/OpenCL/sdk/2.0/docs/man/xhtml/), it says 
- **param_value_size** (third param in clGetProgramInfo)
Used to specify the size in bytes of memory pointed to by param_value
- **param_value** (forth param in clGetProgramInfo)
Return type: unsigned char *[] (double pointers) in case of clGetProgramInfo's CL_PROGRAM_BINARIES

Therefore, param_value_size should be size of  unsigned char * (maybe address)
size of binary address, not binary itself.

**[Contributing](https://www.tensorflow.org/community/contribute)**

- Do you want to contribute a PR? (yes/no): yes
- Briefly describe your candidate solution(if contributing):
`  cl_int error_code = clGetProgramInfo(program_, CL_PROGRAM_BINARIES,
                                       sizeof(binary_ptr), &binary_ptr, nullptr);`

**Standalone code to reproduce the issue**
Provide a reproducible test case that is the bare minimum necessary to generate
the problem. If possible, please share a link to Colab/Jupyter/any notebook.

**Other info / logs** Include any logs or source code that would be helpful to
diagnose the problem. If including tracebacks, please include the full
traceback. Large logs and files should be attached.
"
54925,TF_CPP_MIN_VLOG_LEVEL and TF_CPP_MIN_LOG_LEVEL do not output log info in TF 2.8.0/2.9,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 20
- TensorFlow installed from (source or binary): Yes
- TensorFlow version (use command below): v2.8.0-2-ge994fb9c3ad and 2.9 (master branch)
- Python version: 3.8.10
- Bazel version (if compiling from source): 4.2.1
- GCC/Compiler version (if compiling from source): 9.3.0
- CUDA/cuDNN version: NA
- GPU model and memory: NA

**Describe the current behavior**
Setting TF_CPP_MIN_LOG_LEVEL and TF_CPP_MIN_VLOG_LEVEL does not work with the latest release 2.8.0 and 2.9 of the master branch (both built from source) -- Nor exporting an envvar before launching the TF script, nor using the os module in the code (tried setting it before and after the tensorflow module import).

For source build, I followed the steps mentioned in the [official guide](https://www.tensorflow.org/install/source
), using the build command: 
`bazel build //tensorflow/tools/pip_package:build_pip_package` 

Both builds are CPU only without CUDA nor ROCm support. 

**Describe the expected behavior**
As discussed in #31870, setting TF_CPP_MIN_LOG_LEVEL=0 and/or TF_CPP_MIN_VLOG_LEVEL=2 should show logging/debugging information regarding the C++ implementation inner operations, memory allocations, etc. 


**Standalone code to reproduce the issue**
```
import os 

#os.environ['TF_CPP_MIN_VLOG_LEVEL'] = ""2""

import tensorflow as tf

os.environ['TF_CPP_MIN_VLOG_LEVEL'] = ""2""

a = tf.Variable(tf.zeros(shape=(2)), name=""a"")

print(a)

```

"
54923,Calling `tf.random.set_seed` with invalid seed breaks the Context!,"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Y
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N
- TensorFlow installed from (source or binary): binary
- TensorFlow version (use command below): 2.7.0
- Python version: 3.8
- Bazel version (if compiling from source): N/A
- GCC/Compiler version (if compiling from source):N/A
- CUDA/cuDNN version: N/A
- GPU model and memory: N/A

**Standalone code to reproduce the issue**
```
import tensorflow as tf
a = tf.random.uniform([1, 20]) # All good
print(a)
try:
  s = [[1,2]]
  tf.random.set_seed(s) # This will fail
except Exception as e:
  print(""Error:""+str(e)) # Error:only size-1 arrays can be converted to Python scalars

print(tf.add(2,3)) # OK
b = tf.random.uniform([1, 20]) # AttributeError: 'Context' object has no attribute '_rng'

```

**Describe the current behavior**
[`tf.random.set_seed`](https://www.tensorflow.org/api_docs/python/tf/random/set_seed) should be called with an integer, however, although it has validity checking (which appeared to be working), calling `tf.random.set_seed([[1,2]])` will result in an error, but this would break some Context object and the random APIs are not working any more!
Error message is:
```
AttributeError: 'Context' object has no attribute '_rng'
```

"
54916,problem with the eager execution,"I retrain the resnet152v2 from keras to calassify my own set of image. I did so using a data generator that looks like this:
```
class My_Custom_Generator(Sq):

    def __init__(self, image_filenames, labels, batch_size):
        self.image_filenames = image_filenames
        self.labels = labels
        self.batch_size = batch_size

    def __len__(self):
        return (np.ceil(len(self.image_filenames) / float(self.batch_size))).astype(int)

    def __getitem__(self, idx):
        batch_x = self.image_filenames[idx * self.batch_size: (idx + 1) * self.batch_size]
        batch_y = self.labels[idx * self.batch_size: (idx + 1) * self.batch_size]
        return np.array([
            resize(imread('E:\\data\\allFrames\\' + str(file_name)), (559, 331))
            for file_name in batch_x]) / 255.0, np.array(batch_y)
```
for training the model the code looks like this:
```
 baseModel = EfficientNetB2(weights=None, include_top=False,
                               input_tensor=Input(shape=(559, 331, 3)))
    # construct the head of the model that will be placed on top of the
    # the base model
    headModel = baseModel.output
    headModel = AveragePooling2D(pool_size=(7, 7))(headModel)
    headModel = Flatten(name=""flatten"")(headModel)
    headModel = Dense(512, activation=""relu"")(headModel)
    headModel = Dropout(0.5)(headModel)
    headModel = Dense(5, activation=""softmax"")(headModel)
    # place the head FC model on top of the base model (this will become
    # the actual model we will train)
    model = Model(inputs=baseModel.input, outputs=headModel)
    # loop over all layers in the base model and freeze them so they will
    # *not* be updated during the training process
    for layer in baseModel.layers:
        layer.trainable = False
opt = SGD(learning_rate=0.005, momentum=0.9, decay=1e-4 / 50)
    model.compile(loss=""categorical_crossentropy"", optimizer=opt,
                  metrics=[""accuracy""])
    model.summary()
    NAME = 'resnet152-559x331-{}'.format(int(time.time()))
    tboard_log_dir = os.path.join(""C:\\Users\\dsyr\\PycharmProjects\\VideoProcessingProject\\tmp\\checkpoint"", NAME)
    model_checkpoint_callback = ModelCheckpoint(
        filepath=tboard_log_dir,
        save_weights_only=False,
        monitor='val_accuracy',
        mode='max',
        save_freq=1000,
        save_best_only=False)
    print(""[INFO] training model..."")
    model.fit(my_training_batch_generator,
                  steps_per_epoch=int(621108 // batch_size),
                  epochs=50,
                  verbose=1,
                  validation_data=my_validation_batch_generator,
                  validation_steps=int(155277 // batch_size),
                  callbacks=[model_checkpoint_callback])
```
till there there was no problem, I've a couple of thousand images to validate and produce the output. The issue is that I've not been able to get the same prediction with and without the batch generator. 
when I do model.predict(img, verbose=0, use_multiprocessing=True, workers=4)
where img is a numpy array that is the same as generated by the batch I get this:

> 
> in user code:
>     File ""C:\Users\dsyr\anaconda3\envs\intel\lib\site-packages\keras\engine\training.py"", line 1801, in predict_function  *
>         return step_function(self, iterator)
>     File ""C:\Users\dsyr\anaconda3\envs\intel\lib\site-packages\keras\engine\training.py"", line 1790, in step_function  **
>         outputs = model.distribute_strategy.run(run_step, args=(data,))
>     File ""C:\Users\dsyr\anaconda3\envs\intel\lib\site-packages\keras\engine\training.py"", line 1783, in run_step  **
>         outputs = model.predict_step(data)
>     File ""C:\Users\dsyr\anaconda3\envs\intel\lib\site-packages\keras\engine\training.py"", line 1751, in predict_step
>         return self(x, training=False)
>     File ""C:\Users\dsyr\anaconda3\envs\intel\lib\site-packages\keras\utils\traceback_utils.py"", line 67, in error_handler
>         raise e.with_traceback(filtered_tb) from None
>     File ""C:\Users\dsyr\anaconda3\envs\intel\lib\site-packages\keras\engine\input_spec.py"", line 264, in assert_input_compatibility
>         raise ValueError(f'Input {input_index} of layer ""{layer_name}"" is '
> 
>     ValueError: Input 0 of layer ""model"" is incompatible with the layer: expected shape=(None, 559, 331, 3), found shape=(None, 331, 559, 3)

the exact same error happens if I run the prediction (or training) with the comand ""disable_eager_execution()""
it is to say with eager execution eneable batch processing can be done, with the picture in the format I wanted (559, 331, 3) if eager execution is disabled I cant. I've tried even transposing the picture but the result is widly different than the real forecast done in the batch. 
 
I'm using intel-tensorflow 2.8.0 and intel python 3.9.7 on a windows computer without GPU"
54911,TFT convert error: ValueError: Input 0 of node StatefulPartitionedCall/my_model/conv_root/AssignVariableOp was passed float from Func/StatefulPartitionedCall/input/_1:0 incompatible with expected resource.,"**System information**
- OS is Ubuntu 18.04
- CUDA is 11.5
- Code is being run under `nvcr.io/nvidia/tensorflow:21.12-tf2-py3` (`TensorFlow` version in it is `2.6.2`)

**Describe the current behavior**
I'm trying to convert a `TensorFlow` saved model to `TF-TRT` using [tf.experimental.tensorrt.Converter](https://www.tensorflow.org/api_docs/python/tf/experimental/tensorrt/Converter)

I'm getting the following error:
```
Traceback (most recent call last):
  File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/importer.py"", line 496, in _import_graph_def_internal
    results = c_api.TF_GraphImportGraphDefWithResults(
tensorflow.python.framework.errors_impl.InvalidArgumentError: Input 0 of node StatefulPartitionedCall/my_model/conv_root/AssignVariableOp was passed float from Func/StatefulPartitionedCall/input/_1:0 incompatible with expected resource.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""tmp_stdconv_model.py"", line 56, in <module>
    converter.convert()
  File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/compiler/tensorrt/trt_convert.py"", line 1198, in convert
    frozen_func = convert_to_constants.convert_variables_to_constants_v2(func)
  File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/convert_to_constants.py"", line 1153, in convert_variables_to_constants_v2
    return _construct_concrete_function(func, output_graph_def,
  File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/convert_to_constants.py"", line 1078, in _construct_concrete_function
    new_func = wrap_function.function_from_graph_def(output_graph_def,
  File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/wrap_function.py"", line 650, in function_from_graph_def
    wrapped_import = wrap_function(_imports_graph_def, [])
  File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/wrap_function.py"", line 621, in wrap_function
    func_graph.func_graph_from_py_func(
  File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/func_graph.py"", line 1007, in func_graph_from_py_func
    func_outputs = python_func(*func_args, **func_kwargs)
  File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/wrap_function.py"", line 87, in __call__
    return self.call_with_variable_creator_scope(self._fn)(*args, **kwargs)
  File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/wrap_function.py"", line 93, in wrapped
    return fn(*args, **kwargs)
  File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/wrap_function.py"", line 648, in _imports_graph_def
    importer.import_graph_def(graph_def, name="""")
  File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/deprecation.py"", line 549, in new_func
    return func(*args, **kwargs)
  File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/importer.py"", line 400, in import_graph_def
    return _import_graph_def_internal(
  File ""/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/importer.py"", line 501, in _import_graph_def_internal
    raise ValueError(str(e))
ValueError: Input 0 of node StatefulPartitionedCall/my_model/conv_root/AssignVariableOp was passed float from Func/StatefulPartitionedCall/input/_1:0 incompatible with expected resource.
```

**Standalone code to reproduce the issue**

Here's a fully reproducible code
```
import tensorflow as tf
import numpy as np


class StdConv(tf.keras.layers.Conv2D):
    """"""Weight Standardization Conv2D.

    See https://arxiv.org/pdf/1903.10520v1.pdf.

    """"""

    def _standardize_wts(self, wts):
        wts_mean = tf.math.reduce_mean(wts, axis=(0, 1, 2), keepdims=True)
        wts_var = tf.math.reduce_variance(wts, axis=(0, 1, 2), keepdims=True)
        return (wts - wts_mean) / tf.math.sqrt(wts_var + 1e-5)

    def call(self, inputs):
        standardized_wts = self._standardize_wts(self.kernel)
        self.kernel.assign(standardized_wts)
        return super().call(inputs)


class MyModel(tf.keras.Model):
    def __init__(self):
        super().__init__()
        self.root = StdConv(
            64,
            kernel_size=7,
            padding=""same"",
            name=""conv_root"",
        )

    def call(self, inputs, training=True):
        return self.root(inputs, training=training)


model = MyModel()
inp = np.ndarray((1, 256, 256, 3))
op = model(inp, training=False)
print(""op shape: "", op.shape)

# save tf model
tf.keras.models.save_model(model, ""stdconvmodel"")


# convert to trt
params = tf.experimental.tensorrt.ConversionParams(precision_mode=""FP32"")

converter = tf.experimental.tensorrt.Converter(
    input_saved_model_dir=""stdconvmodel"", conversion_params=params
)

print(""\nconverter.convert..."")
converter.convert()
print(""\nconverter.save..."")
converter.save(trt_model)
print(""\nsaved!"")
```

I've tried this with a couple of other tensorflow versions, and have also tried using `trt_convert.TrtGraphConverterV2` from `tensorflow.python.compiler.tensorrt`
"
54900,MirroredStrategy with custom model throws AttributeError: 'NoneTensorSpec' object has no attribute 'rank',"**System information**
- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Arch Linux
- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:
- TensorFlow installed from (source or binary): Binary
- TensorFlow version (use command below): v2.8.0-rc1-32-g3f878cff5b6 2.8.0
- Python version: 3.10.2
- Bazel version (if compiling from source):
- GCC/Compiler version (if compiling from source):
- CUDA/cuDNN version: 11.6/8.3
- GPU model and memory: GTX1080Ti 11GB

**Describe the current behavior**
When training a custom model with `keras.fit` and `MirroredStrategy` an `AttributeError` is thrown. Without the `MirroredStrategy` training proceeds without error. I also notice that the console output does not mention something like `INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)` even though the strategy reports having 3 replicas in sync

Code snippet
```
    ### ----- create datasets
    
    strategy = tf.distribute.MirroredStrategy()
    print(""Number of devices: {}"".format(strategy.num_replicas_in_sync))

    # with strategy.scope():
        model = MyModel()

        # Setup the optimiser with the learning rate schedule
        lr_schedule = CosineDecayWithWarmup(
            initial_learning_rate=args.lr,
            decay_steps=args.num_epochs,
            warmup_steps=args.warmup_steps,
            warmup_learning_rate=args.warmup_lr,
            hold_base_rate_steps=args.hold_base_rate_steps,
        )
        optimiser = tf.keras.optimizers.Adam(learning_rate=lr_schedule)

        # Compile the model
        model.compile(optimizer=optimiser, loss=MyLoss())

    # Build the model and print a summary
    model.build(input_shape=(args.batch_size, image_shape[0], image_shape[1], 3))
    model.summary()

    history = model.fit(
        training_dataset,
        epochs=args.num_epochs,
        validation_data=validation_dataset,
        callbacks=callbacks,
    )
```

Console output
```
2022-03-03 14:30:59.481815: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-03-03 14:31:00.853869: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 8972 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:09:00.0, compute capability: 6.1
2022-03-03 14:31:00.854710: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 10405 MB memory:  -> device: 1, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:0a:00.0, compute capability: 6.1
2022-03-03 14:31:00.855231: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 10405 MB memory:  -> device: 2, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:43:00.0, compute capability: 6.1
Number of devices: 3

#### ----- MODEL SUMMARY ----

Traceback (most recent call last):
  File ""$HOME/network/train.py"", line 279, in <module>
    main()
  File ""$HOME/network/train.py"", line 242, in main
    history = model.fit(
  File ""$HOME/.local/lib/python3.10/site-packages/keras/utils/traceback_utils.py"", line 67, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File ""$HOME/.local/lib/python3.10/site-packages/tensorflow/python/data/experimental/ops/distribute.py"", line 513, in get_static_batch_dim
    if output_shape.rank is None:
AttributeError: 'NoneTensorSpec' object has no attribute 'rank'
```

**Describe the expected behavior**
Network trains with the `MirroredStrategy` with no error.
"
54899,Unable to find valid certification path,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04
- TensorFlow installed from (source or binary): source
- TensorFlow version: 2.5.0
- Python version: 3.7.0
- Installed using virtualenv? pip? conda?: source build
- Bazel version (if compiling from source): 3.7.2
- GCC/Compiler version (if compiling from source): 7.5.0
- CUDA/cuDNN version:
- GPU model and memory:


**Describe the problem**

**Provide the exact sequence of commands / steps that you executed before running into the problem**

~/tensorflow$ ./configure
You have bazel 3.7.2 installed.
Please specify the location of python. [Default is /home/user/miniconda3/envs/tf-2.5/bin/python3]: /home/user/miniconda3/envs/tf-2.5/bin/python3]^H


Invalid python path: /home/user/miniconda3/envs/tf-2.5/bin/python3 cannot be found.
Please specify the location of python. [Default is /home/user/miniconda3/envs/tf-2.5/bin/python3]: /home/user/miniconda3/envs/tf-2.5/bin/python3


Found possible Python library paths:
  /home/user/miniconda3/envs/tf-2.5/lib/python3.7/site-packages
Please input the desired Python library path to use.  Default is [/home/user/miniconda3/envs/tf-2.5/lib/python3.7/site-packages]
/home/user/miniconda3/envs/tf-2.5/lib/python3.7/site-packages
Do you wish to build TensorFlow with ROCm support? [y/N]: N
No ROCm support will be enabled for TensorFlow.

Do you wish to build TensorFlow with CUDA support? [y/N]: N
No CUDA support will be enabled for TensorFlow.

Do you wish to download a fresh release of clang? (Experimental) [y/N]: N
Clang will not be downloaded.

Please specify optimization flags to use during compilation when bazel option ""--config=opt"" is specified [Default is -Wno-sign-compare]:


Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: N
Not configuring the WORKSPACE for Android builds.

Preconfigured Bazel build configs. You can use any of the below by adding ""--config=<>"" to your build command. See .bazelrc for more details.
        --config=mkl            # Build with MKL support.
        --config=mkl_aarch64    # Build with oneDNN and Compute Library for the Arm Architecture (ACL).
        --config=monolithic     # Config for mostly static monolithic build.
        --config=numa           # Build with NUMA support.
        --config=dynamic_kernels        # (Experimental) Build kernels into separate shared objects.
        --config=v2             # Build TensorFlow 2.x instead of 1.x.
Preconfigured Bazel build configs to DISABLE default on features:
        --config=noaws          # Disable AWS S3 filesystem support.
        --config=nogcp          # Disable GCP support.
        --config=nohdfs         # Disable HDFS support.
        --config=nonccl         # Disable NVIDIA NCCL support.
Configuration finished


$ bazel build  --config=opt //tensorflow/tools/pip_package:build_pip_package

**Any other info / logs**


INFO: Options provided by the client:
  Inherited 'common' options: --isatty=1 --terminal_columns=252
INFO: Reading rc options for 'build' from /home/user/tensorflow/.bazelrc:
  Inherited 'common' options: --experimental_repo_remote_exec
INFO: Reading rc options for 'build' from /home/user/tensorflow/.bazelrc:
  'build' options: --define framework_shared_object=true --java_toolchain=@tf_toolchains//toolchains/java:tf_java_toolchain --host_java_toolchain=@tf_toolchains//toolchains/java:tf_java_toolchain --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --noincompatible_prohibit_aapt1 --enable_platform_specific_config --define=with_xla_support=true --config=short_logs --config=v2
INFO: Reading rc options for 'build' from /home/user/tensorflow/.tf_configure.bazelrc:
  'build' options: --action_env PYTHON_BIN_PATH=/home/user/miniconda3/envs/tf-2.5/bin/python3 --action_env PYTHON_LIB_PATH=/home/user/miniconda3/envs/tf-2.5/lib/python3.7/site-packages --python_path=/home/user/miniconda3/envs/tf-2.5/bin/python3
INFO: Found applicable config definition build:short_logs in file /home/user/tensorflow/.bazelrc: --output_filter=DONT_MATCH_ANYTHING
INFO: Found applicable config definition build:v2 in file /home/user/tensorflow/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1
INFO: Found applicable config definition build:opt in file /home/user/tensorflow/.tf_configure.bazelrc: --copt=-Wno-sign-compare --host_copt=-Wno-sign-compare
INFO: Found applicable config definition build:linux in file /home/user/tensorflow/.bazelrc: --copt=-w --host_copt=-w --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --define=PROTOBUF_INCLUDE_PATH=$(PREFIX)/include --cxxopt=-std=c++14 --host_cxxopt=-std=c++14 --config=dynamic_kernels
INFO: Found applicable config definition build:dynamic_kernels in file /home/user/tensorflow/.bazelrc: --define=dynamic_loaded_kernels=true --copt=-DAUTOLOAD_DYNAMIC_KERNELS
INFO: Repository io_bazel_rules_closure instantiated at:
  /home/user/tensorflow/WORKSPACE:11:14: in <toplevel>
  /home/user/tensorflow/tensorflow/workspace3.bzl:6:17: in workspace
Repository rule http_archive defined at:
  /home/user/.cache/bazel/_bazel_taegeon.um/f9f5c94ad789d21bcfdb930889866229/external/bazel_tools/tools/build_defs/repo/http.bzl:336:31: in <toplevel>
WARNING: Download from https://storage.googleapis.com/mirror.tensorflow.org/github.com/bazelbuild/rules_closure/archive/308b05b2419edb5c8ee0471b67a40403df940149.tar.gz failed: class javax.net.ssl.SSLHandshakeException PKIX path building failed: sun.security.provider.certpath.SunCertPathBuilderException: unable to find valid certification path to requested target
WARNING: Download from https://github.com/bazelbuild/rules_closure/archive/308b05b2419edb5c8ee0471b67a40403df940149.tar.gz failed: class javax.net.ssl.SSLHandshakeException PKIX path building failed: sun.security.provider.certpath.SunCertPathBuilderException: unable to find valid certification path to requested target
ERROR: An error occurred during the fetch of repository 'io_bazel_rules_closure':
   Traceback (most recent call last):
        File ""/home/user/.cache/bazel/_bazel_taegeon.um/f9f5c94ad789d21bcfdb930889866229/external/bazel_tools/tools/build_defs/repo/http.bzl"", line 111, column 45, in _http_archive_impl
                download_info = ctx.download_and_extract(
Error in download_and_extract: java.io.IOException: Error downloading [https://storage.googleapis.com/mirror.tensorflow.org/github.com/bazelbuild/rules_closure/archive/308b05b2419edb5c8ee0471b67a40403df940149.tar.gz, https://github.com/bazelbuild/rules_closure/archive/308b05b2419edb5c8ee0471b67a40403df940149.tar.gz] to /home/user/.cache/bazel/_bazel_taegeon.um/f9f5c94ad789d21bcfdb930889866229/external/io_bazel_rules_closure/temp13563286205250891784/308b05b2419edb5c8ee0471b67a40403df940149.tar.gz: PKIX path building failed: sun.security.provider.certpath.SunCertPathBuilderException: unable to find valid certification path to requested target
ERROR: no such package '@io_bazel_rules_closure//closure': java.io.IOException: Error downloading [https://storage.googleapis.com/mirror.tensorflow.org/github.com/bazelbuild/rules_closure/archive/308b05b2419edb5c8ee0471b67a40403df940149.tar.gz, https://github.com/bazelbuild/rules_closure/archive/308b05b2419edb5c8ee0471b67a40403df940149.tar.gz] to /home/user/.cache/bazel/_bazel_taegeon.um/f9f5c94ad789d21bcfdb930889866229/external/io_bazel_rules_closure/temp13563286205250891784/308b05b2419edb5c8ee0471b67a40403df940149.tar.gz: PKIX path building failed: sun.security.provider.certpath.SunCertPathBuilderException: unable to find valid certification path to requested target
INFO: Elapsed time: 28.763s
INFO: 0 processes.
FAILED: Build did NOT complete successfully (0 packages loaded)

"
54868,How to suppress outputs stemming from running Tensorflow when not using eager execution (UNSOLVED),"This is not an error but an inconvenience. When I do not use eager execution, whenever I call the model, the model fills up the terminal with graph information. How do I suppress such outputs? This is an issue because it can fill up the terminal with garbage and crash the system.

Example:


```
fast_rnn_cell_keras/W/Initializer/random_normal/RandomStandardNormal: (RandomStandardNormal): /job:localhost/replica:0/task:0/device:GPU:0
fast_rnn_cell_keras/W/Initializer/random_normal/mul: (Mul): /job:localhost/replica:0/task:0/device:GPU:0
fast_rnn_cell_keras/W/Initializer/random_normal: (Add): /job:localhost/replica:0/task:0/device:GPU:0
fast_rnn_cell_keras/W/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp): /job:localhost/replica:0/task:0/device:GPU:0
fast_rnn_cell_keras/W/Assign: (AssignVariableOp): /job:localhost/replica:0/task:0/device:GPU:0
fast_rnn_cell_keras/W/Read/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:GPU:0
fast_rnn_cell_keras/U/Initializer/random_normal/RandomStandardNormal: (RandomStandardNormal): /job:localhost/replica:0/task:0/device:GPU:0
fast_rnn_cell_keras/U/Initializer/random_normal/mul: (Mul): /job:localhost/replica:0/task:0/device:GPU:0
fast_rnn_cell_keras/U/Initializer/random_normal: (Add): /job:localhost/replica:0/task:0/device:GPU:0
fast_rnn_cell_keras/U/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp): /job:localhost/replica:0/task:0/device:GPU:0
fast_rnn_cell_keras/U/Assign: (AssignVariableOp): /job:localhost/replica:0/task:0/device:GPU:0
fast_rnn_cell_keras/U/Read/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:GPU:0
fast_rnn_cell_keras/alpha/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp): /job:localhost/replica:0/task:0/device:GPU:0
fast_rnn_cell_keras/alpha/Assign: (AssignVariableOp): /job:localhost/replica:0/task:0/device:GPU:0
fast_rnn_cell_keras/alpha/Read/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:GPU:0
fast_rnn_cell_keras/beta/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp): /job:localhost/replica:0/task:0/device:GPU:0
fast_rnn_cell_keras/beta/Assign: (AssignVariableOp): /job:localhost/replica:0/task:0/device:GPU:0
fast_rnn_cell_keras/beta/Read/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:GPU:0
fast_rnn_cell_keras/B_h/IsInitialized/VarIsInitializedOp: (VarIsInitializedOp): /job:localhost/replica:0/task:0/device:GPU:0
fast_rnn_cell_keras/B_h/Assign: (AssignVariableOp): /job:localhost/replica:0/task:0/device:GPU:0
fast_rnn_cell_keras/B_h/Read/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:GPU:0
rnn/Shape: (Shape): /job:localhost/replica:0/task:0/device:GPU:0
rnn/strided_slice: (StridedSlice): /job:localhost/replica:0/task:0/device:GPU:0
rnn/FastRNNCellKerasZeroState/ExpandDims: (ExpandDims): /job:localhost/replica:0/task:0/device:GPU:0
rnn/FastRNNCellKerasZeroState/concat: (ConcatV2): /job:localhost/replica:0/task:0/device:GPU:0
rnn/FastRNNCellKerasZeroState/zeros: (Fill): /job:localhost/replica:0/task:0/device:GPU:0
rnn/FastRNNCellKerasZeroState/ExpandDims_1: (ExpandDims): /job:localhost/replica:0/task:0/device:GPU:0
rnn/transpose: (Transpose): /job:localhost/replica:0/task:0/device:GPU:0
rnn/Shape_1: (Shape): /job:localhost/replica:0/task:0/device:GPU:0
rnn/strided_slice_1: (StridedSlice): /job:localhost/replica:0/task:0/device:GPU:0
rnn/TensorArrayV2: (TensorListReserve): /job:localhost/replica:0/task:0/device:GPU:0
rnn/TensorArrayUnstack/TensorListFromTensor: (TensorListFromTensor): /job:localhost/replica:0/task:0/device:GPU:0
rnn/strided_slice_2: (StridedSlice): /job:localhost/replica:0/task:0/device:GPU:0
rnn/fast_rnn_cell_keras_2/fast_rnn_cell_keras/MatMul/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:GPU:0
rnn/fast_rnn_cell_keras_2/fast_rnn_cell_keras/MatMul: (MatMul): /job:localhost/replica:0/task:0/device:GPU:0
rnn/fast_rnn_cell_keras_2/fast_rnn_cell_keras/MatMul_1/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:GPU:0
rnn/fast_rnn_cell_keras_2/fast_rnn_cell_keras/MatMul_1: (MatMul): /job:localhost/replica:0/task:0/device:GPU:0
rnn/fast_rnn_cell_keras_2/fast_rnn_cell_keras/add: (AddV2): /job:localhost/replica:0/task:0/device:GPU:0
rnn/fast_rnn_cell_keras_2/fast_rnn_cell_keras/add_1/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:GPU:0
rnn/fast_rnn_cell_keras_2/fast_rnn_cell_keras/add_1: (AddV2): /job:localhost/replica:0/task:0/device:GPU:0
rnn/fast_rnn_cell_keras_2/fast_rnn_cell_keras/Tanh: (Tanh): /job:localhost/replica:0/task:0/device:GPU:0
rnn/fast_rnn_cell_keras_2/fast_rnn_cell_keras/Sigmoid/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:GPU:0
rnn/fast_rnn_cell_keras_2/fast_rnn_cell_keras/Sigmoid: (Sigmoid): /job:localhost/replica:0/task:0/device:GPU:0
rnn/fast_rnn_cell_keras_2/fast_rnn_cell_keras/mul: (Mul): /job:localhost/replica:0/task:0/device:GPU:0
rnn/fast_rnn_cell_keras_2/fast_rnn_cell_keras/Sigmoid_1/ReadVariableOp: (ReadVariableOp): /job:localhost/replica:0/task:0/device:GPU:0
rnn/fast_rnn_cell_keras_2/fast_rnn_cell_keras/Sigmoid_1: (Sigmoid): /job:localhost/replica:0/task:0/device:GPU:0
rnn/fast_rnn_cell_keras_2/fast_rnn_cell_keras/mul_1: (Mul): /job:localhost/replica:0/task:0/device:GPU:0
rnn/fast_rnn_cell_keras_2/fast_rnn_cell_keras/add_2: (AddV2): /job:localhost/replica:0/task:0/device:GPU:0
rnn/TensorArrayV2_1: (TensorListReserve): /job:localhost/replica:0/task:0/device:GPU:0
rnn/while/EmptyTensorList: (EmptyTensorList): /job:localhost/replica:0/task:0/device:GPU:0
rnn/while/EmptyTensorList_1: (EmptyTensorList): /job:localhost/replica:0/task:0/device:GPU:0
rnn/while/EmptyTensorList_2: (EmptyTensorList): /job:localhost/replica:0/task:0/device:GPU:0
```"
54857,Error while creating the wheel file for Raspberry pi. ,"<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>

**System information**
- Build target = Raspberry Pi
- TensorFlow version: 2.5.2
- Python version: 3.8




**Describe the problem**

I tried creating the TensorFlow wheel file and was getting failed as it was unable to find the updates from [http://security.ubuntu.com/ubuntu/dists/xenial-security/main/binary-armhf/Packages](http://security.ubuntu.com/ubuntu/dists/xenial-security/main/binary-armhf/Packages) (No Xenial security branch)



"
